{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"medium\"\n",
    "label = \"KG_atanh_\" + level\n",
    "\n",
    "x = np.linspace(0,2,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(1.0)\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "                    \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_atanh_medium\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 17374.201 Test MSE 10.128379509026898 Test RE 2.3058850340961152\n",
      "1 Train Loss 8858.83 Test MSE 9.697369165758332 Test RE 2.2562885116957156\n",
      "2 Train Loss 6318.4404 Test MSE 10.026235362125462 Test RE 2.2942282085246135\n",
      "3 Train Loss 2517.015 Test MSE 13.313902315568143 Test RE 2.643749793200671\n",
      "4 Train Loss 1115.2002 Test MSE 17.83043233596078 Test RE 3.0594869457697484\n",
      "5 Train Loss 511.6539 Test MSE 21.479941435058226 Test RE 3.358027234900067\n",
      "6 Train Loss 317.50745 Test MSE 24.219409723602276 Test RE 3.5657381270359743\n",
      "7 Train Loss 211.62675 Test MSE 26.986967398726527 Test RE 3.7639574897944947\n",
      "8 Train Loss 158.2183 Test MSE 27.85936400418634 Test RE 3.8243115624524417\n",
      "9 Train Loss 128.27501 Test MSE 28.853352992318143 Test RE 3.891937094354779\n",
      "10 Train Loss 106.648155 Test MSE 29.009621038625124 Test RE 3.9024621129662944\n",
      "11 Train Loss 94.2586 Test MSE 28.88342311471688 Test RE 3.8939645978675475\n",
      "12 Train Loss 84.40765 Test MSE 28.583854579430156 Test RE 3.873718560748239\n",
      "13 Train Loss 77.00568 Test MSE 28.117877803778484 Test RE 3.842013948636321\n",
      "14 Train Loss 69.7781 Test MSE 27.640097423727678 Test RE 3.8092322487380033\n",
      "15 Train Loss 64.50726 Test MSE 27.102851117762427 Test RE 3.772030166892809\n",
      "16 Train Loss 59.629223 Test MSE 26.67404967010183 Test RE 3.742072052177294\n",
      "17 Train Loss 56.237965 Test MSE 26.53949858249834 Test RE 3.732622110671378\n",
      "18 Train Loss 53.21608 Test MSE 26.023983194180815 Test RE 3.696192253975307\n",
      "19 Train Loss 50.31425 Test MSE 25.367869177818545 Test RE 3.649300800083873\n",
      "20 Train Loss 47.34752 Test MSE 24.64099561358892 Test RE 3.596638537320667\n",
      "21 Train Loss 44.425205 Test MSE 23.764223127758026 Test RE 3.532071434158898\n",
      "22 Train Loss 42.18662 Test MSE 23.133277218355826 Test RE 3.484867328048511\n",
      "23 Train Loss 39.17562 Test MSE 22.18790189403583 Test RE 3.412917467416916\n",
      "24 Train Loss 36.691105 Test MSE 21.465430924570235 Test RE 3.3568928062630494\n",
      "25 Train Loss 34.118263 Test MSE 20.99277212030037 Test RE 3.3197284730752576\n",
      "26 Train Loss 32.720665 Test MSE 20.858739506272467 Test RE 3.3091137629187664\n",
      "27 Train Loss 31.603804 Test MSE 20.95395774025832 Test RE 3.3166580634732448\n",
      "28 Train Loss 30.72033 Test MSE 20.81733700425581 Test RE 3.305828002474336\n",
      "29 Train Loss 29.818419 Test MSE 20.714702750277404 Test RE 3.297668687459316\n",
      "30 Train Loss 28.884855 Test MSE 20.372302763918768 Test RE 3.270301010586272\n",
      "31 Train Loss 28.282099 Test MSE 20.137340880076746 Test RE 3.2513874758980896\n",
      "32 Train Loss 27.553474 Test MSE 19.995346820859968 Test RE 3.2399039725527827\n",
      "33 Train Loss 26.872427 Test MSE 19.699993095416733 Test RE 3.2158864412249004\n",
      "34 Train Loss 26.418026 Test MSE 19.423177497750913 Test RE 3.1932124004392333\n",
      "35 Train Loss 25.687933 Test MSE 19.11515897754748 Test RE 3.167791760122581\n",
      "36 Train Loss 25.37257 Test MSE 19.05824890964255 Test RE 3.1630726357006673\n",
      "37 Train Loss 24.982183 Test MSE 18.904334430305717 Test RE 3.150274250992229\n",
      "38 Train Loss 24.60416 Test MSE 18.79404594679851 Test RE 3.141071409254474\n",
      "39 Train Loss 24.130173 Test MSE 18.61413274856321 Test RE 3.1260007008359874\n",
      "40 Train Loss 23.716679 Test MSE 18.4595844762201 Test RE 3.112996469064507\n",
      "41 Train Loss 23.32214 Test MSE 18.205877565857282 Test RE 3.0915300805869284\n",
      "42 Train Loss 22.864408 Test MSE 18.04448154949202 Test RE 3.077796290650892\n",
      "43 Train Loss 22.560776 Test MSE 17.82248500625878 Test RE 3.0588050368569895\n",
      "44 Train Loss 22.224985 Test MSE 17.82903399354348 Test RE 3.059366974078282\n",
      "45 Train Loss 21.991983 Test MSE 17.84804179581659 Test RE 3.0609973583061203\n",
      "46 Train Loss 21.592674 Test MSE 17.567010171415568 Test RE 3.036802819930472\n",
      "47 Train Loss 21.315983 Test MSE 17.53395795078276 Test RE 3.033944612041347\n",
      "48 Train Loss 20.955448 Test MSE 17.28969930477625 Test RE 3.012738156020343\n",
      "49 Train Loss 20.75563 Test MSE 17.15241571843489 Test RE 3.00075345396106\n",
      "50 Train Loss 20.522675 Test MSE 17.01673454788675 Test RE 2.9888614233587165\n",
      "51 Train Loss 20.21422 Test MSE 16.805048050534197 Test RE 2.9702126742324912\n",
      "52 Train Loss 20.012646 Test MSE 16.720955586118407 Test RE 2.962771881664623\n",
      "53 Train Loss 19.762064 Test MSE 16.642125471007468 Test RE 2.9557797103829606\n",
      "54 Train Loss 19.502247 Test MSE 16.510287199519627 Test RE 2.944048644903774\n",
      "55 Train Loss 19.323399 Test MSE 16.324441671459375 Test RE 2.927432135143621\n",
      "56 Train Loss 19.08781 Test MSE 16.18448961495434 Test RE 2.9148564511941504\n",
      "57 Train Loss 18.84419 Test MSE 16.07930503392327 Test RE 2.9053690425766714\n",
      "58 Train Loss 18.541412 Test MSE 15.885087018332877 Test RE 2.887769111701848\n",
      "59 Train Loss 18.332418 Test MSE 15.737838878273493 Test RE 2.874353742186389\n",
      "60 Train Loss 18.13172 Test MSE 15.575146960197896 Test RE 2.8594581465620363\n",
      "61 Train Loss 17.999739 Test MSE 15.472653906534573 Test RE 2.850034211780724\n",
      "62 Train Loss 17.815693 Test MSE 15.417691759546662 Test RE 2.8449677456137015\n",
      "63 Train Loss 17.569399 Test MSE 15.42157030417137 Test RE 2.845325569620524\n",
      "64 Train Loss 17.345175 Test MSE 15.325429302396493 Test RE 2.8364425530440363\n",
      "65 Train Loss 17.110245 Test MSE 15.20975583571969 Test RE 2.825717809362159\n",
      "66 Train Loss 16.928503 Test MSE 15.083015671676163 Test RE 2.813920081326817\n",
      "67 Train Loss 16.764343 Test MSE 15.0039237680698 Test RE 2.8065326055914834\n",
      "68 Train Loss 16.55369 Test MSE 14.906077125659257 Test RE 2.797366371055982\n",
      "69 Train Loss 16.319864 Test MSE 14.784621937952712 Test RE 2.7859465463854263\n",
      "70 Train Loss 16.123426 Test MSE 14.667221972347717 Test RE 2.774863344171984\n",
      "71 Train Loss 16.018408 Test MSE 14.554748335219847 Test RE 2.7642035341234656\n",
      "72 Train Loss 15.805222 Test MSE 14.47154933976998 Test RE 2.756291732743888\n",
      "73 Train Loss 15.624149 Test MSE 14.255389806537362 Test RE 2.7356291093426672\n",
      "74 Train Loss 15.433295 Test MSE 14.143751280122059 Test RE 2.724896260785452\n",
      "75 Train Loss 15.266191 Test MSE 14.080397726366165 Test RE 2.7187866506728993\n",
      "76 Train Loss 15.123708 Test MSE 14.039994815111314 Test RE 2.7148831455646145\n",
      "77 Train Loss 14.913084 Test MSE 14.050631858363758 Test RE 2.7159113817628424\n",
      "78 Train Loss 14.758659 Test MSE 13.956320290835356 Test RE 2.7067810759546775\n",
      "79 Train Loss 14.5649185 Test MSE 13.857814430330697 Test RE 2.6972117214659677\n",
      "80 Train Loss 14.342045 Test MSE 13.7748667101774 Test RE 2.689127352989348\n",
      "81 Train Loss 14.130228 Test MSE 13.618011319013258 Test RE 2.6737728745800613\n",
      "82 Train Loss 13.90779 Test MSE 13.432065291101056 Test RE 2.6554557250388204\n",
      "83 Train Loss 13.59613 Test MSE 13.24892663409551 Test RE 2.6372907725220944\n",
      "84 Train Loss 13.181056 Test MSE 13.195948169716408 Test RE 2.6320126253473557\n",
      "85 Train Loss 12.88205 Test MSE 13.078000267295456 Test RE 2.6202235073648654\n",
      "86 Train Loss 12.525468 Test MSE 12.84752155889533 Test RE 2.5970322647875914\n",
      "87 Train Loss 12.261857 Test MSE 12.741829438033578 Test RE 2.5863277601913577\n",
      "88 Train Loss 12.047321 Test MSE 12.687606776626334 Test RE 2.5808188539497987\n",
      "89 Train Loss 11.845747 Test MSE 12.536898138876722 Test RE 2.565445046887336\n",
      "90 Train Loss 11.585069 Test MSE 12.439787024052386 Test RE 2.5554897313309075\n",
      "91 Train Loss 11.384897 Test MSE 12.186167679645747 Test RE 2.529305232527969\n",
      "92 Train Loss 11.109082 Test MSE 12.059584904490958 Test RE 2.5161344697467443\n",
      "93 Train Loss 10.888902 Test MSE 11.969208247800172 Test RE 2.506688561346991\n",
      "94 Train Loss 10.584956 Test MSE 11.711063321884767 Test RE 2.4795098178414356\n",
      "95 Train Loss 10.332314 Test MSE 11.442947425667647 Test RE 2.450962231336706\n",
      "96 Train Loss 10.025321 Test MSE 11.204400050880968 Test RE 2.425280478452263\n",
      "97 Train Loss 9.747616 Test MSE 11.034386190252988 Test RE 2.4068097241329616\n",
      "98 Train Loss 9.361467 Test MSE 10.78020638817111 Test RE 2.378927492904185\n",
      "99 Train Loss 9.069794 Test MSE 10.600947274755795 Test RE 2.3590655301763315\n",
      "100 Train Loss 8.866887 Test MSE 10.482204263055296 Test RE 2.3458161767049885\n",
      "101 Train Loss 8.715857 Test MSE 10.37413461987841 Test RE 2.333692375474651\n",
      "102 Train Loss 8.557221 Test MSE 10.432461384934177 Test RE 2.340243569607358\n",
      "103 Train Loss 8.355355 Test MSE 10.077190871056166 Test RE 2.30005070349188\n",
      "104 Train Loss 8.173194 Test MSE 9.789998160591628 Test RE 2.2670389027401523\n",
      "105 Train Loss 7.582782 Test MSE 9.229893039515995 Test RE 2.2012329331585123\n",
      "106 Train Loss 7.222456 Test MSE 8.813267621826997 Test RE 2.1509788824428067\n",
      "107 Train Loss 6.970933 Test MSE 8.486104538806197 Test RE 2.110677382523691\n",
      "108 Train Loss 6.723994 Test MSE 8.017938163562524 Test RE 2.0516298960537824\n",
      "109 Train Loss 6.4897428 Test MSE 7.792338351159911 Test RE 2.022560719786514\n",
      "110 Train Loss 6.294104 Test MSE 7.6523661957289555 Test RE 2.004312984308136\n",
      "111 Train Loss 6.112451 Test MSE 7.3674043448965225 Test RE 1.9666402374714185\n",
      "112 Train Loss 5.932469 Test MSE 7.027995634070365 Test RE 1.9208055820986285\n",
      "113 Train Loss 5.6980567 Test MSE 6.809870007257454 Test RE 1.8907629280124754\n",
      "114 Train Loss 5.49983 Test MSE 6.750099225183017 Test RE 1.8824469504103603\n",
      "115 Train Loss 5.2926073 Test MSE 6.453644264183831 Test RE 1.8406456084318843\n",
      "116 Train Loss 5.094096 Test MSE 6.26679099955229 Test RE 1.8138036568627878\n",
      "117 Train Loss 4.858594 Test MSE 5.829082262928557 Test RE 1.749313951454401\n",
      "118 Train Loss 4.672345 Test MSE 5.664702940408273 Test RE 1.7244723596010991\n",
      "119 Train Loss 4.521935 Test MSE 5.4037563105525255 Test RE 1.6842848627290177\n",
      "120 Train Loss 4.399889 Test MSE 5.175197371725551 Test RE 1.648280521641394\n",
      "121 Train Loss 4.275667 Test MSE 5.000218965087179 Test RE 1.6201759423671256\n",
      "122 Train Loss 4.0537806 Test MSE 4.755866396869705 Test RE 1.5800924231170201\n",
      "123 Train Loss 3.9392295 Test MSE 4.607207332982304 Test RE 1.5552010687312228\n",
      "124 Train Loss 3.7805219 Test MSE 4.47164707464898 Test RE 1.532150500497575\n",
      "125 Train Loss 3.62756 Test MSE 4.138985158028439 Test RE 1.4740581020557417\n",
      "126 Train Loss 3.497842 Test MSE 3.9435755154875083 Test RE 1.4388408138320263\n",
      "127 Train Loss 3.3541608 Test MSE 3.717284046394675 Test RE 1.3969489692424897\n",
      "128 Train Loss 3.2131917 Test MSE 3.435155022379673 Test RE 1.3428912313535075\n",
      "129 Train Loss 3.1068282 Test MSE 3.1114453730162457 Test RE 1.2780526875842488\n",
      "130 Train Loss 2.9602418 Test MSE 2.7865404506299782 Test RE 1.2094846016094707\n",
      "131 Train Loss 2.8002284 Test MSE 2.8166449069654966 Test RE 1.216000398389541\n",
      "132 Train Loss 2.5383935 Test MSE 2.3274488508355766 Test RE 1.1053701701242045\n",
      "133 Train Loss 2.3489265 Test MSE 1.8731622391325677 Test RE 0.9916430325487129\n",
      "134 Train Loss 2.1585224 Test MSE 1.614475493121914 Test RE 0.9206263396921099\n",
      "135 Train Loss 1.9694738 Test MSE 1.405159027906216 Test RE 0.8588758802462132\n",
      "136 Train Loss 1.7544187 Test MSE 1.0416734489778126 Test RE 0.7394919743168588\n",
      "137 Train Loss 1.4813055 Test MSE 0.7603304183090769 Test RE 0.6317843305999001\n",
      "138 Train Loss 1.3196816 Test MSE 0.7210521025370972 Test RE 0.6152491061599112\n",
      "139 Train Loss 1.2030765 Test MSE 0.6304884532361144 Test RE 0.5753157139068211\n",
      "140 Train Loss 1.0452383 Test MSE 0.45406874432115363 Test RE 0.4882345081360496\n",
      "141 Train Loss 0.921328 Test MSE 0.33330128883898297 Test RE 0.4182983622114748\n",
      "142 Train Loss 0.8351709 Test MSE 0.24825074069891873 Test RE 0.36100477315893664\n",
      "143 Train Loss 0.72583014 Test MSE 0.2008758200635489 Test RE 0.32473679421029245\n",
      "144 Train Loss 0.6658478 Test MSE 0.15871597142735175 Test RE 0.28865426808996997\n",
      "145 Train Loss 0.58421344 Test MSE 0.15633793320790365 Test RE 0.2864836562891\n",
      "146 Train Loss 0.51456815 Test MSE 0.16002355919707242 Test RE 0.28984087389571384\n",
      "147 Train Loss 0.45858172 Test MSE 0.15577682046820965 Test RE 0.28596908467468096\n",
      "148 Train Loss 0.42951488 Test MSE 0.13305849847916124 Test RE 0.26429501805439315\n",
      "149 Train Loss 0.3981767 Test MSE 0.1262803624339699 Test RE 0.2574753027555756\n",
      "150 Train Loss 0.36858484 Test MSE 0.1203236946946323 Test RE 0.2513293726363269\n",
      "151 Train Loss 0.33659673 Test MSE 0.08847148537047245 Test RE 0.21551094291395778\n",
      "152 Train Loss 0.3086573 Test MSE 0.09060538590206263 Test RE 0.21809448060136194\n",
      "153 Train Loss 0.29292622 Test MSE 0.08387040253391549 Test RE 0.20983215038372308\n",
      "154 Train Loss 0.26539978 Test MSE 0.07319184320407121 Test RE 0.19601937934485186\n",
      "155 Train Loss 0.2574743 Test MSE 0.072449925515689 Test RE 0.19502336215972915\n",
      "156 Train Loss 0.24306554 Test MSE 0.058622712447897046 Test RE 0.17542869077315798\n",
      "157 Train Loss 0.20801663 Test MSE 0.048819660378898073 Test RE 0.16009030962599496\n",
      "158 Train Loss 0.19777872 Test MSE 0.0438470776724005 Test RE 0.15171830933334926\n",
      "159 Train Loss 0.16719042 Test MSE 0.036012941190474046 Test RE 0.13749818440299688\n",
      "160 Train Loss 0.15140165 Test MSE 0.03093249201166137 Test RE 0.12743100914697764\n",
      "161 Train Loss 0.14306216 Test MSE 0.02569448432454635 Test RE 0.11614155078365491\n",
      "162 Train Loss 0.13329335 Test MSE 0.02132052040708243 Test RE 0.1057953472019628\n",
      "163 Train Loss 0.1276754 Test MSE 0.01863415368119574 Test RE 0.09890596944162809\n",
      "164 Train Loss 0.12347179 Test MSE 0.01708368760948731 Test RE 0.09470185333738931\n",
      "165 Train Loss 0.113436535 Test MSE 0.018392344069779347 Test RE 0.09826213793317244\n",
      "166 Train Loss 0.107309416 Test MSE 0.01698710157475451 Test RE 0.0944337659722947\n",
      "167 Train Loss 0.10145719 Test MSE 0.017217364235947035 Test RE 0.0950716434137193\n",
      "168 Train Loss 0.09764424 Test MSE 0.017972289919371432 Test RE 0.09713357551616787\n",
      "169 Train Loss 0.094831124 Test MSE 0.01635548829330245 Test RE 0.09266152104740423\n",
      "170 Train Loss 0.092241816 Test MSE 0.01524069224607561 Test RE 0.08944787229026695\n",
      "171 Train Loss 0.08796737 Test MSE 0.014278303060212853 Test RE 0.08657768429677384\n",
      "172 Train Loss 0.08418861 Test MSE 0.013784022961133372 Test RE 0.08506593141241275\n",
      "173 Train Loss 0.07878454 Test MSE 0.01275476088943714 Test RE 0.08182835645702245\n",
      "174 Train Loss 0.07477283 Test MSE 0.012856942834231522 Test RE 0.08215547748588997\n",
      "175 Train Loss 0.0718197 Test MSE 0.011506898638935791 Test RE 0.07772250892458495\n",
      "176 Train Loss 0.06734096 Test MSE 0.008280792290778034 Test RE 0.0659331178652979\n",
      "177 Train Loss 0.06269623 Test MSE 0.006490347489077709 Test RE 0.058371605986971505\n",
      "178 Train Loss 0.05822804 Test MSE 0.004292706964006824 Test RE 0.0474715365514861\n",
      "179 Train Loss 0.054958526 Test MSE 0.003759897818013367 Test RE 0.04442789009292782\n",
      "180 Train Loss 0.053578015 Test MSE 0.0038352606043972424 Test RE 0.04487093377074069\n",
      "181 Train Loss 0.05202002 Test MSE 0.004171308027403988 Test RE 0.04679546835069317\n",
      "182 Train Loss 0.050669182 Test MSE 0.0040827335476620675 Test RE 0.04629596983090569\n",
      "183 Train Loss 0.048783977 Test MSE 0.0039740445631144495 Test RE 0.04567557612955226\n",
      "184 Train Loss 0.04659932 Test MSE 0.0034635030971270054 Test RE 0.04264081116903704\n",
      "185 Train Loss 0.04545822 Test MSE 0.0032655285226067176 Test RE 0.04140420101259393\n",
      "186 Train Loss 0.044525236 Test MSE 0.00316241143171007 Test RE 0.04074523746899426\n",
      "187 Train Loss 0.043194663 Test MSE 0.003197095042013512 Test RE 0.04096806398791819\n",
      "188 Train Loss 0.041715305 Test MSE 0.0031440169281456857 Test RE 0.040626565138852634\n",
      "189 Train Loss 0.040794358 Test MSE 0.0033154838561311214 Test RE 0.0417196951597769\n",
      "190 Train Loss 0.039945897 Test MSE 0.003453181475512506 Test RE 0.0425772265989282\n",
      "191 Train Loss 0.03901212 Test MSE 0.003457628068506401 Test RE 0.042604630703083866\n",
      "192 Train Loss 0.036637582 Test MSE 0.0032420730142827614 Test RE 0.041255234809691926\n",
      "193 Train Loss 0.03472109 Test MSE 0.0037015030520058828 Test RE 0.04408153647321931\n",
      "194 Train Loss 0.034199473 Test MSE 0.004031367099705547 Test RE 0.0460038142511941\n",
      "195 Train Loss 0.033527713 Test MSE 0.0038983543577968964 Test RE 0.045238513348294276\n",
      "196 Train Loss 0.032593425 Test MSE 0.004094184226188673 Test RE 0.04636084659545775\n",
      "197 Train Loss 0.03214837 Test MSE 0.003804056414909925 Test RE 0.04468802302701711\n",
      "198 Train Loss 0.030683624 Test MSE 0.003132807085172008 Test RE 0.04055407442175822\n",
      "199 Train Loss 0.02901132 Test MSE 0.00345629768106152 Test RE 0.042596433447921474\n",
      "200 Train Loss 0.02833373 Test MSE 0.0031411094952128325 Test RE 0.04060777606480541\n",
      "201 Train Loss 0.027890159 Test MSE 0.003288147263233342 Test RE 0.0415473470270065\n",
      "202 Train Loss 0.027279317 Test MSE 0.0030683851418584008 Test RE 0.04013493862555435\n",
      "203 Train Loss 0.026657999 Test MSE 0.002712696160914312 Test RE 0.03773707578677192\n",
      "204 Train Loss 0.025588205 Test MSE 0.0027086651534682453 Test RE 0.03770902712638778\n",
      "205 Train Loss 0.02462631 Test MSE 0.002544263034168766 Test RE 0.03654674236433724\n",
      "206 Train Loss 0.024377244 Test MSE 0.002615021167753072 Test RE 0.037051455403074404\n",
      "207 Train Loss 0.024064109 Test MSE 0.0027623200937898613 Test RE 0.03808067772415681\n",
      "208 Train Loss 0.023774443 Test MSE 0.0029654449894749055 Test RE 0.0394559590047358\n",
      "209 Train Loss 0.023509314 Test MSE 0.002975140168044113 Test RE 0.03952040471492772\n",
      "210 Train Loss 0.022556333 Test MSE 0.002740520762338305 Test RE 0.03793011993806318\n",
      "211 Train Loss 0.021843895 Test MSE 0.002382952615148124 Test RE 0.035369210920540906\n",
      "212 Train Loss 0.021215716 Test MSE 0.0020582498169723204 Test RE 0.03287128716349746\n",
      "213 Train Loss 0.020270152 Test MSE 0.0015349622239273402 Test RE 0.028386804941084955\n",
      "214 Train Loss 0.019931858 Test MSE 0.0014882599320838227 Test RE 0.02795162508086333\n",
      "215 Train Loss 0.019508762 Test MSE 0.0014310952686661992 Test RE 0.027409552214716706\n",
      "216 Train Loss 0.018759754 Test MSE 0.0016396062221186907 Test RE 0.029338468977437346\n",
      "217 Train Loss 0.018102104 Test MSE 0.0017959811454462875 Test RE 0.030705668304108615\n",
      "218 Train Loss 0.017628126 Test MSE 0.0018425541541791858 Test RE 0.031101246698752614\n",
      "219 Train Loss 0.017136972 Test MSE 0.0018157342419285432 Test RE 0.030874064671570355\n",
      "220 Train Loss 0.016935904 Test MSE 0.001743053948757943 Test RE 0.03024984001960818\n",
      "221 Train Loss 0.016509563 Test MSE 0.001482520283038712 Test RE 0.027897673652270395\n",
      "222 Train Loss 0.015887886 Test MSE 0.0014872025196066537 Test RE 0.027941693465988765\n",
      "223 Train Loss 0.015289006 Test MSE 0.001328889373040181 Test RE 0.026412656410167285\n",
      "224 Train Loss 0.0148097705 Test MSE 0.0013048398840687211 Test RE 0.026172564523230742\n",
      "225 Train Loss 0.014392634 Test MSE 0.0012474251135487302 Test RE 0.02559027242313914\n",
      "226 Train Loss 0.013964923 Test MSE 0.0013467959417084005 Test RE 0.026590014072606426\n",
      "227 Train Loss 0.013726248 Test MSE 0.0012396732077209554 Test RE 0.025510635365050566\n",
      "228 Train Loss 0.013413183 Test MSE 0.0012169145662383573 Test RE 0.025275381091911114\n",
      "229 Train Loss 0.013235427 Test MSE 0.0012152081898083242 Test RE 0.025257654110284876\n",
      "230 Train Loss 0.012966607 Test MSE 0.0011588698008636836 Test RE 0.024665219830023972\n",
      "231 Train Loss 0.012739539 Test MSE 0.0011104003088561322 Test RE 0.02414390172024216\n",
      "232 Train Loss 0.012310851 Test MSE 0.001112898963341624 Test RE 0.02417105110431752\n",
      "233 Train Loss 0.011943585 Test MSE 0.0010377771126132529 Test RE 0.02334101361074672\n",
      "234 Train Loss 0.011781858 Test MSE 0.0010387057103210897 Test RE 0.023351453986191362\n",
      "235 Train Loss 0.011620719 Test MSE 0.0009470989682624537 Test RE 0.022297971159519106\n",
      "236 Train Loss 0.0114517175 Test MSE 0.0009474464034737254 Test RE 0.02230206069515431\n",
      "237 Train Loss 0.011361029 Test MSE 0.0009285039690178939 Test RE 0.02207799089555844\n",
      "238 Train Loss 0.01124606 Test MSE 0.0008648045234448515 Test RE 0.021307212831259345\n",
      "239 Train Loss 0.011125704 Test MSE 0.0008627100665646271 Test RE 0.021281395383236167\n",
      "240 Train Loss 0.010792912 Test MSE 0.0007602155624774172 Test RE 0.019977265688969695\n",
      "241 Train Loss 0.010473279 Test MSE 0.0007173389120461815 Test RE 0.019405724547306272\n",
      "242 Train Loss 0.0103295045 Test MSE 0.0007045580507441277 Test RE 0.019232071217761677\n",
      "243 Train Loss 0.010079025 Test MSE 0.000653812962853925 Test RE 0.018526544805529996\n",
      "244 Train Loss 0.009923488 Test MSE 0.0006158340906623302 Test RE 0.01798040752877847\n",
      "245 Train Loss 0.009720773 Test MSE 0.0005583364627037939 Test RE 0.01712046921419395\n",
      "246 Train Loss 0.00956196 Test MSE 0.0004831449392472319 Test RE 0.01592598803340128\n",
      "247 Train Loss 0.009428162 Test MSE 0.0004310354790262158 Test RE 0.015042643983119369\n",
      "248 Train Loss 0.009293957 Test MSE 0.0004126889915011426 Test RE 0.014719027264362224\n",
      "249 Train Loss 0.00919664 Test MSE 0.0004039300895839356 Test RE 0.014561991411757517\n",
      "250 Train Loss 0.008996291 Test MSE 0.0003800012266238657 Test RE 0.014124079938823652\n",
      "251 Train Loss 0.008765173 Test MSE 0.0004115263727322589 Test RE 0.014698279574160516\n",
      "252 Train Loss 0.008417767 Test MSE 0.00041573157807027337 Test RE 0.01477318629830076\n",
      "253 Train Loss 0.008243793 Test MSE 0.00042521529519681475 Test RE 0.014940739945595399\n",
      "254 Train Loss 0.008131235 Test MSE 0.00040845205051801096 Test RE 0.014643274645745013\n",
      "255 Train Loss 0.008039953 Test MSE 0.00040103430777932105 Test RE 0.0145096999393096\n",
      "256 Train Loss 0.007934293 Test MSE 0.0003700989955283851 Test RE 0.01393883961069487\n",
      "257 Train Loss 0.007887107 Test MSE 0.00039207730622042516 Test RE 0.014346749667557456\n",
      "258 Train Loss 0.007784927 Test MSE 0.0003920038700612759 Test RE 0.01434540603007418\n",
      "259 Train Loss 0.0076234904 Test MSE 0.00039905349374247184 Test RE 0.014473821967608165\n",
      "260 Train Loss 0.007455313 Test MSE 0.0003862348496340035 Test RE 0.014239455944328435\n",
      "261 Train Loss 0.00737219 Test MSE 0.00046955408794856234 Test RE 0.015700391449864164\n",
      "262 Train Loss 0.007321229 Test MSE 0.0004566485227975244 Test RE 0.015483127716661606\n",
      "263 Train Loss 0.00724191 Test MSE 0.00044279565553424267 Test RE 0.01524647139306033\n",
      "264 Train Loss 0.0071614226 Test MSE 0.00043093484134003145 Test RE 0.015040887810678874\n",
      "265 Train Loss 0.007092073 Test MSE 0.0004648844086045668 Test RE 0.015622126786037121\n",
      "266 Train Loss 0.007017849 Test MSE 0.00048360473442162134 Test RE 0.01593356438418122\n",
      "267 Train Loss 0.006963372 Test MSE 0.0004914065065085288 Test RE 0.01606157458931139\n",
      "268 Train Loss 0.006882911 Test MSE 0.0005701472549199439 Test RE 0.0173006008517322\n",
      "269 Train Loss 0.006801873 Test MSE 0.0005538999530030696 Test RE 0.017052314419493193\n",
      "270 Train Loss 0.0067363605 Test MSE 0.0005289234399156059 Test RE 0.01666341745682298\n",
      "271 Train Loss 0.006708905 Test MSE 0.0004861501591448056 Test RE 0.015975442035053952\n",
      "272 Train Loss 0.0066464148 Test MSE 0.00047268459500306056 Test RE 0.01575264159376798\n",
      "273 Train Loss 0.0064878287 Test MSE 0.0005735746145072594 Test RE 0.017352522995595\n",
      "274 Train Loss 0.006324999 Test MSE 0.0005864361683060786 Test RE 0.01754599662077939\n",
      "275 Train Loss 0.0061275642 Test MSE 0.0005569756002407318 Test RE 0.017099592180798446\n",
      "276 Train Loss 0.005918175 Test MSE 0.0004753002385048983 Test RE 0.015796165808086415\n",
      "277 Train Loss 0.0058078202 Test MSE 0.00044803862218847164 Test RE 0.015336469460969471\n",
      "278 Train Loss 0.0057354975 Test MSE 0.0004780410042998025 Test RE 0.01584164375530746\n",
      "279 Train Loss 0.0056777014 Test MSE 0.00043486462209598077 Test RE 0.01510931259759683\n",
      "280 Train Loss 0.005626017 Test MSE 0.00043936906321480123 Test RE 0.01518736409819407\n",
      "281 Train Loss 0.0055706445 Test MSE 0.000422793635806626 Test RE 0.01489813441694402\n",
      "282 Train Loss 0.0055252276 Test MSE 0.0004517896480653801 Test RE 0.015400534907376662\n",
      "283 Train Loss 0.0054635075 Test MSE 0.0004688524392454859 Test RE 0.015688656616768534\n",
      "284 Train Loss 0.0053931233 Test MSE 0.0005066020396766671 Test RE 0.016308016217117152\n",
      "285 Train Loss 0.0053489315 Test MSE 0.00048532917077353843 Test RE 0.01596194703371523\n",
      "286 Train Loss 0.0052884864 Test MSE 0.00048035837409385774 Test RE 0.01587999461178389\n",
      "287 Train Loss 0.005179598 Test MSE 0.0005020580189522137 Test RE 0.016234713231601337\n",
      "288 Train Loss 0.005073193 Test MSE 0.00048259014772597525 Test RE 0.01591684156374869\n",
      "289 Train Loss 0.00499771 Test MSE 0.00046467806756181053 Test RE 0.015618659425505632\n",
      "290 Train Loss 0.0049448637 Test MSE 0.00039202503014778027 Test RE 0.014345793202190933\n",
      "291 Train Loss 0.0048873345 Test MSE 0.0003459116158552415 Test RE 0.013475666074467535\n",
      "292 Train Loss 0.004818463 Test MSE 0.00034302471129506965 Test RE 0.013419315738866377\n",
      "293 Train Loss 0.0047757328 Test MSE 0.00032812382962883323 Test RE 0.01312461442295124\n",
      "294 Train Loss 0.004740789 Test MSE 0.00031448268048865126 Test RE 0.012848902508796743\n",
      "295 Train Loss 0.004712421 Test MSE 0.0003103628791999761 Test RE 0.012764463144524296\n",
      "296 Train Loss 0.004670683 Test MSE 0.0003447433785751611 Test RE 0.01345289134075308\n",
      "297 Train Loss 0.0046200044 Test MSE 0.00032510738843052656 Test RE 0.013064147868041148\n",
      "298 Train Loss 0.0045320997 Test MSE 0.0003158508091490179 Test RE 0.012876821175591541\n",
      "299 Train Loss 0.0044930275 Test MSE 0.00035127332018989845 Test RE 0.013579702337695381\n",
      "Training time: 160.34\n",
      "KG_atanh_medium\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 19688.367 Test MSE 14.170600797030744 Test RE 2.7274814115778367\n",
      "1 Train Loss 6087.4326 Test MSE 15.289090868561194 Test RE 2.833077784282825\n",
      "2 Train Loss 1858.6974 Test MSE 19.111177448485975 Test RE 3.1674618305673308\n",
      "3 Train Loss 967.70087 Test MSE 22.6630830817607 Test RE 3.4492697771304908\n",
      "4 Train Loss 620.8662 Test MSE 23.09904785283182 Test RE 3.482288165694335\n",
      "5 Train Loss 392.99316 Test MSE 22.32376544951017 Test RE 3.423350707949567\n",
      "6 Train Loss 228.06128 Test MSE 22.815945243583737 Test RE 3.4608828644543626\n",
      "7 Train Loss 133.98582 Test MSE 22.398434961449954 Test RE 3.429071215354235\n",
      "8 Train Loss 92.61124 Test MSE 22.23099142552709 Test RE 3.4162298510185054\n",
      "9 Train Loss 75.58167 Test MSE 22.187170605993618 Test RE 3.4128612240120617\n",
      "10 Train Loss 62.769722 Test MSE 21.85840949552048 Test RE 3.3874816127375187\n",
      "11 Train Loss 53.858128 Test MSE 21.28366903159809 Test RE 3.342650084163403\n",
      "12 Train Loss 46.390594 Test MSE 20.2728862900269 Test RE 3.262311746517148\n",
      "13 Train Loss 39.34416 Test MSE 19.662012453040933 Test RE 3.212784908148751\n",
      "14 Train Loss 35.49062 Test MSE 19.289738852944296 Test RE 3.182224695388851\n",
      "15 Train Loss 32.850204 Test MSE 18.706618339701908 Test RE 3.133756952504373\n",
      "16 Train Loss 30.732878 Test MSE 18.364297236324138 Test RE 3.1049515255863342\n",
      "17 Train Loss 28.672209 Test MSE 17.831975565281464 Test RE 3.0596193426661014\n",
      "18 Train Loss 27.15034 Test MSE 17.816360115577464 Test RE 3.0582793958943326\n",
      "19 Train Loss 25.522194 Test MSE 17.6868844465594 Test RE 3.047146515749514\n",
      "20 Train Loss 24.157799 Test MSE 17.444915181832474 Test RE 3.02623116022084\n",
      "21 Train Loss 23.31048 Test MSE 17.349617809682897 Test RE 3.0179540546179298\n",
      "22 Train Loss 22.563585 Test MSE 17.207133637537257 Test RE 3.005535994399942\n",
      "23 Train Loss 21.978046 Test MSE 17.113369507367533 Test RE 2.9973360108508595\n",
      "24 Train Loss 21.530663 Test MSE 16.99397643738194 Test RE 2.9868621092046785\n",
      "25 Train Loss 21.199827 Test MSE 16.82547564672314 Test RE 2.9720173664225578\n",
      "26 Train Loss 20.84584 Test MSE 16.69997530156019 Test RE 2.9609125588669247\n",
      "27 Train Loss 20.457058 Test MSE 16.652018123641348 Test RE 2.956658088505055\n",
      "28 Train Loss 20.009974 Test MSE 16.523742263874244 Test RE 2.945248027333076\n",
      "29 Train Loss 19.75341 Test MSE 16.516073684575375 Test RE 2.944564511190221\n",
      "30 Train Loss 19.451998 Test MSE 16.389671510671274 Test RE 2.933275077714207\n",
      "31 Train Loss 19.193933 Test MSE 16.25124217974663 Test RE 2.920861395812431\n",
      "32 Train Loss 18.899227 Test MSE 16.054095405695584 Test RE 2.903090585763294\n",
      "33 Train Loss 18.571194 Test MSE 15.745049036950329 Test RE 2.875012097300588\n",
      "34 Train Loss 18.397543 Test MSE 15.599491363770566 Test RE 2.8616919817618185\n",
      "35 Train Loss 18.031887 Test MSE 15.30319003954017 Test RE 2.834383775719593\n",
      "36 Train Loss 17.709131 Test MSE 15.052810092675275 Test RE 2.8111010601313753\n",
      "37 Train Loss 17.437332 Test MSE 14.77201523433552 Test RE 2.7847585182874766\n",
      "38 Train Loss 17.08422 Test MSE 14.35815266665567 Test RE 2.745471571164794\n",
      "39 Train Loss 16.564573 Test MSE 13.921344569003294 Test RE 2.703387236883356\n",
      "40 Train Loss 16.105213 Test MSE 13.345799947799856 Test RE 2.6469148648555194\n",
      "41 Train Loss 15.433832 Test MSE 12.356150707533626 Test RE 2.5468845918059944\n",
      "42 Train Loss 14.579294 Test MSE 11.171498640960097 Test RE 2.421716976075646\n",
      "43 Train Loss 13.637912 Test MSE 9.798933270082687 Test RE 2.2680732043170884\n",
      "44 Train Loss 12.2301 Test MSE 9.244948572108223 Test RE 2.2030274951587154\n",
      "45 Train Loss 11.119039 Test MSE 8.148877192694709 Test RE 2.0683143926760064\n",
      "46 Train Loss 10.269382 Test MSE 7.733375331318086 Test RE 2.0148940389397523\n",
      "47 Train Loss 9.298398 Test MSE 6.894353926784889 Test RE 1.902455271465534\n",
      "48 Train Loss 8.390403 Test MSE 6.590884998481605 Test RE 1.8601138849650811\n",
      "49 Train Loss 7.68341 Test MSE 6.122363169683853 Test RE 1.7927808788324417\n",
      "50 Train Loss 7.130946 Test MSE 5.479356195487794 Test RE 1.696025721513976\n",
      "51 Train Loss 6.736828 Test MSE 5.2211775063367005 Test RE 1.6555865777725767\n",
      "52 Train Loss 6.246693 Test MSE 4.566976065695599 Test RE 1.5483959811645678\n",
      "53 Train Loss 5.688884 Test MSE 4.103977529933345 Test RE 1.4678110565634708\n",
      "54 Train Loss 5.23213 Test MSE 3.802447758245208 Test RE 1.4128605394454894\n",
      "55 Train Loss 4.8731036 Test MSE 3.20318775871811 Test RE 1.2967577902840792\n",
      "56 Train Loss 4.3714414 Test MSE 2.4917390319721884 Test RE 1.143717971390467\n",
      "57 Train Loss 4.0253983 Test MSE 2.2017971109326564 Test RE 1.0751184539793368\n",
      "58 Train Loss 3.447 Test MSE 1.713053012822032 Test RE 0.9483159806041764\n",
      "59 Train Loss 3.2065818 Test MSE 1.5577187752763353 Test RE 0.9042993005033525\n",
      "60 Train Loss 2.884997 Test MSE 1.2166840918604613 Test RE 0.7992020376416265\n",
      "61 Train Loss 2.561199 Test MSE 0.8625197499641075 Test RE 0.6729025774630659\n",
      "62 Train Loss 2.3668923 Test MSE 0.6194598494644089 Test RE 0.5702617585128222\n",
      "63 Train Loss 2.112797 Test MSE 0.3914291512371045 Test RE 0.45330890509282284\n",
      "64 Train Loss 1.8148948 Test MSE 0.15950364922361232 Test RE 0.2893696502883996\n",
      "65 Train Loss 1.467781 Test MSE 0.09083277999715943 Test RE 0.2183679870776951\n",
      "66 Train Loss 1.24951 Test MSE 0.06526963872666523 Test RE 0.18510718316661376\n",
      "67 Train Loss 1.0996542 Test MSE 0.04515809256281767 Test RE 0.15396977047497235\n",
      "68 Train Loss 0.9511086 Test MSE 0.04503074246705133 Test RE 0.15375251253095246\n",
      "69 Train Loss 0.85135454 Test MSE 0.024151586835317516 Test RE 0.11260054768648328\n",
      "70 Train Loss 0.7681618 Test MSE 0.018409603460898767 Test RE 0.09830823175846143\n",
      "71 Train Loss 0.7003796 Test MSE 0.01975190177268371 Test RE 0.10182915179091775\n",
      "72 Train Loss 0.6128633 Test MSE 0.01998360044796212 Test RE 0.10242466131709774\n",
      "73 Train Loss 0.57561845 Test MSE 0.0157442192943031 Test RE 0.09091346967735442\n",
      "74 Train Loss 0.5229331 Test MSE 0.009784573674531519 Test RE 0.07167020084052053\n",
      "75 Train Loss 0.45890534 Test MSE 0.008268533431894164 Test RE 0.06588429619950306\n",
      "76 Train Loss 0.41617998 Test MSE 0.014631777813434568 Test RE 0.08764279446897702\n",
      "77 Train Loss 0.3794764 Test MSE 0.01345577935840644 Test RE 0.08404697678027377\n",
      "78 Train Loss 0.3518254 Test MSE 0.011558150821117483 Test RE 0.0778954061818591\n",
      "79 Train Loss 0.3345491 Test MSE 0.010494335303840687 Test RE 0.07422413340570452\n",
      "80 Train Loss 0.31951782 Test MSE 0.00959300927207785 Test RE 0.07096514586379714\n",
      "81 Train Loss 0.3005611 Test MSE 0.006267073684468299 Test RE 0.057358801478408133\n",
      "82 Train Loss 0.28449994 Test MSE 0.005471611649037711 Test RE 0.0535951265091814\n",
      "83 Train Loss 0.2638794 Test MSE 0.005050909322840785 Test RE 0.05149350496308195\n",
      "84 Train Loss 0.25254267 Test MSE 0.005481314535204758 Test RE 0.053642625957805244\n",
      "85 Train Loss 0.23436001 Test MSE 0.005077269363560979 Test RE 0.05162769906770764\n",
      "86 Train Loss 0.22626995 Test MSE 0.005652407784371165 Test RE 0.054473390920145276\n",
      "87 Train Loss 0.21097618 Test MSE 0.005156616675254038 Test RE 0.05202955266689782\n",
      "88 Train Loss 0.19098249 Test MSE 0.004672174339074856 Test RE 0.04952530827847463\n",
      "89 Train Loss 0.17799878 Test MSE 0.0040407174735418655 Test RE 0.046057134094643744\n",
      "90 Train Loss 0.16404074 Test MSE 0.0031596591112376567 Test RE 0.04072750284390517\n",
      "91 Train Loss 0.15113634 Test MSE 0.0028153847003844113 Test RE 0.03844470570755739\n",
      "92 Train Loss 0.14725289 Test MSE 0.0030257595937192372 Test RE 0.0398551893823546\n",
      "93 Train Loss 0.140054 Test MSE 0.0029501721272054246 Test RE 0.039354223290466776\n",
      "94 Train Loss 0.13208541 Test MSE 0.002907816788603838 Test RE 0.03907069957398562\n",
      "95 Train Loss 0.12580006 Test MSE 0.002857742086043238 Test RE 0.03873282583522294\n",
      "96 Train Loss 0.11719393 Test MSE 0.0022516529235793985 Test RE 0.03438099107418249\n",
      "97 Train Loss 0.11286591 Test MSE 0.0020055142209402057 Test RE 0.03244744766215508\n",
      "98 Train Loss 0.10908989 Test MSE 0.0018498268531012818 Test RE 0.03116256572295135\n",
      "99 Train Loss 0.09887813 Test MSE 0.002475354704545741 Test RE 0.03604843271058214\n",
      "100 Train Loss 0.09588416 Test MSE 0.0020101954824514683 Test RE 0.03248529492632759\n",
      "101 Train Loss 0.093719184 Test MSE 0.0016862213157339224 Test RE 0.029752602163486026\n",
      "102 Train Loss 0.0897759 Test MSE 0.0017464615595909963 Test RE 0.030279394283403063\n",
      "103 Train Loss 0.08721652 Test MSE 0.0014126492207813788 Test RE 0.02723233210566366\n",
      "104 Train Loss 0.08342387 Test MSE 0.0018138770824492666 Test RE 0.0308582714102002\n",
      "105 Train Loss 0.07942888 Test MSE 0.0013156579793053293 Test RE 0.026280835608611067\n",
      "106 Train Loss 0.0763626 Test MSE 0.001213112958079663 Test RE 0.025235870407078375\n",
      "107 Train Loss 0.07216588 Test MSE 0.0011341260461774345 Test RE 0.02440047776088375\n",
      "108 Train Loss 0.069539204 Test MSE 0.0012710151246379876 Test RE 0.025831107506913975\n",
      "109 Train Loss 0.06765003 Test MSE 0.0013218264864620505 Test RE 0.026342372858620785\n",
      "110 Train Loss 0.062181856 Test MSE 0.0009328700577326702 Test RE 0.02212983850053969\n",
      "111 Train Loss 0.05954814 Test MSE 0.0007884083337665834 Test RE 0.020344324331349143\n",
      "112 Train Loss 0.057501733 Test MSE 0.0008961757059978505 Test RE 0.021690234681826855\n",
      "113 Train Loss 0.05499511 Test MSE 0.0008895788741051102 Test RE 0.021610255318725402\n",
      "114 Train Loss 0.05314624 Test MSE 0.0007241338414096475 Test RE 0.019497417425155556\n",
      "115 Train Loss 0.051036134 Test MSE 0.000784726222146022 Test RE 0.020296761578659818\n",
      "116 Train Loss 0.046493478 Test MSE 0.0010923914428057437 Test RE 0.02394731419961541\n",
      "117 Train Loss 0.04537963 Test MSE 0.001142759162347556 Test RE 0.02449317151410817\n",
      "118 Train Loss 0.044219397 Test MSE 0.001178906237818185 Test RE 0.0248775323966108\n",
      "119 Train Loss 0.042795468 Test MSE 0.0011243952343909912 Test RE 0.024295574097033663\n",
      "120 Train Loss 0.04118506 Test MSE 0.0011109432853694883 Test RE 0.024149804082320137\n",
      "121 Train Loss 0.040039167 Test MSE 0.001294889148904505 Test RE 0.02607257728085785\n",
      "122 Train Loss 0.038742356 Test MSE 0.001429886551933493 Test RE 0.027397974584757682\n",
      "123 Train Loss 0.038058463 Test MSE 0.0013705862616579573 Test RE 0.026823834123270756\n",
      "124 Train Loss 0.03760816 Test MSE 0.0015260459350022707 Test RE 0.02830423822347366\n",
      "125 Train Loss 0.03643514 Test MSE 0.001496034973952021 Test RE 0.02802454310731848\n",
      "126 Train Loss 0.035675358 Test MSE 0.0015331972611761324 Test RE 0.0283704800885617\n",
      "127 Train Loss 0.035080787 Test MSE 0.0014799085330408977 Test RE 0.027873089210393182\n",
      "128 Train Loss 0.0342601 Test MSE 0.001412946428286953 Test RE 0.02723519666245368\n",
      "129 Train Loss 0.03314523 Test MSE 0.0012670213516931582 Test RE 0.025790492433262594\n",
      "130 Train Loss 0.032007884 Test MSE 0.0011376776250549238 Test RE 0.024438653624317914\n",
      "131 Train Loss 0.030929755 Test MSE 0.0009275078043441364 Test RE 0.02206614430281686\n",
      "132 Train Loss 0.02968841 Test MSE 0.000943561654438052 Test RE 0.022256291931952808\n",
      "133 Train Loss 0.029005483 Test MSE 0.0009342232674476751 Test RE 0.022145883318429704\n",
      "134 Train Loss 0.028502254 Test MSE 0.0009099428217605176 Test RE 0.021856203180114497\n",
      "135 Train Loss 0.027744396 Test MSE 0.0009946180613697032 Test RE 0.022850506885644776\n",
      "136 Train Loss 0.027041651 Test MSE 0.00101034385765125 Test RE 0.02303044186184346\n",
      "137 Train Loss 0.025741924 Test MSE 0.0008517220263537224 Test RE 0.021145434181066375\n",
      "138 Train Loss 0.024963511 Test MSE 0.0007474088134239872 Test RE 0.019808280395011493\n",
      "139 Train Loss 0.024182567 Test MSE 0.000811141889771361 Test RE 0.02063555162183233\n",
      "140 Train Loss 0.02335969 Test MSE 0.0008415058801035806 Test RE 0.02101823508097532\n",
      "141 Train Loss 0.023050778 Test MSE 0.0008306723156946868 Test RE 0.020882502208493133\n",
      "142 Train Loss 0.022742324 Test MSE 0.0007382021212642577 Test RE 0.019685901695656684\n",
      "143 Train Loss 0.022098538 Test MSE 0.0007201182697310905 Test RE 0.01944328232227162\n",
      "144 Train Loss 0.021527821 Test MSE 0.0008516142774425991 Test RE 0.021144096614641724\n",
      "145 Train Loss 0.020713205 Test MSE 0.0007697555371622375 Test RE 0.02010222263117759\n",
      "146 Train Loss 0.020020634 Test MSE 0.0008418084372359991 Test RE 0.021022013215855583\n",
      "147 Train Loss 0.019765567 Test MSE 0.0008622934597534482 Test RE 0.02127625631900964\n",
      "148 Train Loss 0.019576352 Test MSE 0.000890058747118137 Test RE 0.021616083233760738\n",
      "149 Train Loss 0.019281713 Test MSE 0.0008355115778278507 Test RE 0.02094324165210877\n",
      "150 Train Loss 0.018709792 Test MSE 0.0008279105773145431 Test RE 0.02084775925260553\n",
      "151 Train Loss 0.018185174 Test MSE 0.0008627341056605533 Test RE 0.021281691880264055\n",
      "152 Train Loss 0.017710565 Test MSE 0.0008933372783185764 Test RE 0.021655858058721573\n",
      "153 Train Loss 0.017430292 Test MSE 0.0008767304516881932 Test RE 0.021453626393497932\n",
      "154 Train Loss 0.017137008 Test MSE 0.0008335151570281682 Test RE 0.020918205176867592\n",
      "155 Train Loss 0.016958363 Test MSE 0.0008361632103577112 Test RE 0.020951407091097905\n",
      "156 Train Loss 0.016764743 Test MSE 0.000822056720839245 Test RE 0.02077392502177047\n",
      "157 Train Loss 0.01660643 Test MSE 0.0008019110679636248 Test RE 0.020517799022674907\n",
      "158 Train Loss 0.01623577 Test MSE 0.0007897356691114322 Test RE 0.020361442608469348\n",
      "159 Train Loss 0.016000936 Test MSE 0.0008409143762136666 Test RE 0.021010846806226283\n",
      "160 Train Loss 0.015677419 Test MSE 0.0007949752076530975 Test RE 0.020428875422451944\n",
      "161 Train Loss 0.015301066 Test MSE 0.0007348919260380648 Test RE 0.019641715021461916\n",
      "162 Train Loss 0.015098166 Test MSE 0.0007292341644802423 Test RE 0.019565960443843233\n",
      "163 Train Loss 0.015001622 Test MSE 0.0007455666066543246 Test RE 0.019783853695071293\n",
      "164 Train Loss 0.014884942 Test MSE 0.0007934884963986439 Test RE 0.020409764101828463\n",
      "165 Train Loss 0.014420094 Test MSE 0.0007204195063221098 Test RE 0.019447348609670435\n",
      "166 Train Loss 0.014137631 Test MSE 0.0007302352539412588 Test RE 0.01957938587015145\n",
      "167 Train Loss 0.013823508 Test MSE 0.0007089699390931942 Test RE 0.01929219212224738\n",
      "168 Train Loss 0.013464374 Test MSE 0.0006750933655355574 Test RE 0.01882563298477299\n",
      "169 Train Loss 0.012942869 Test MSE 0.0006586969293353614 Test RE 0.018595612475254153\n",
      "170 Train Loss 0.012749524 Test MSE 0.0006358142361080905 Test RE 0.018269757862949973\n",
      "171 Train Loss 0.012619366 Test MSE 0.0006004197506396609 Test RE 0.01775395654472887\n",
      "172 Train Loss 0.012485535 Test MSE 0.0006444338596606296 Test RE 0.018393180937446716\n",
      "173 Train Loss 0.012030643 Test MSE 0.0005866844406139576 Test RE 0.017549710344754697\n",
      "174 Train Loss 0.011471638 Test MSE 0.0005012392995468023 Test RE 0.016221470640648713\n",
      "175 Train Loss 0.01132682 Test MSE 0.0005213533977693459 Test RE 0.01654374288188936\n",
      "176 Train Loss 0.011099381 Test MSE 0.000478425992218878 Test RE 0.0158480214655725\n",
      "177 Train Loss 0.010864436 Test MSE 0.0004637834480219041 Test RE 0.01560361730213523\n",
      "178 Train Loss 0.01059465 Test MSE 0.0004802503248515169 Test RE 0.01587820853083215\n",
      "179 Train Loss 0.010487528 Test MSE 0.00046895858805978224 Test RE 0.015690432482596127\n",
      "180 Train Loss 0.010426248 Test MSE 0.0004289388220394126 Test RE 0.015006013922148361\n",
      "181 Train Loss 0.010302472 Test MSE 0.00042490319472559884 Test RE 0.014935255820275644\n",
      "182 Train Loss 0.010111228 Test MSE 0.00038450484064025405 Test RE 0.014207529728727778\n",
      "183 Train Loss 0.009871757 Test MSE 0.00036976523589699804 Test RE 0.01393255308822792\n",
      "184 Train Loss 0.009443226 Test MSE 0.00036577871173870793 Test RE 0.013857244526803649\n",
      "185 Train Loss 0.009199852 Test MSE 0.0003649154581185023 Test RE 0.01384088301866102\n",
      "186 Train Loss 0.009038076 Test MSE 0.0003537120638740304 Test RE 0.01362675989941559\n",
      "187 Train Loss 0.008875739 Test MSE 0.0003338493942672009 Test RE 0.01323862754586884\n",
      "188 Train Loss 0.0086725475 Test MSE 0.0003267650708263829 Test RE 0.013097411757575289\n",
      "189 Train Loss 0.0084772045 Test MSE 0.0002886437657625375 Test RE 0.012309736556316788\n",
      "190 Train Loss 0.008321601 Test MSE 0.0002839397600276769 Test RE 0.012209019099228011\n",
      "191 Train Loss 0.008182983 Test MSE 0.000300133284692424 Test RE 0.01255234155987437\n",
      "192 Train Loss 0.00799882 Test MSE 0.00028357140525244465 Test RE 0.012201097154794796\n",
      "193 Train Loss 0.007899383 Test MSE 0.00028421672177819716 Test RE 0.012214972135042461\n",
      "194 Train Loss 0.0077541107 Test MSE 0.0002543459908899481 Test RE 0.011555270485574937\n",
      "195 Train Loss 0.007661044 Test MSE 0.0002594444648625643 Test RE 0.011670511004716682\n",
      "196 Train Loss 0.007582147 Test MSE 0.0002584770390001874 Test RE 0.011648731972318185\n",
      "197 Train Loss 0.0074637565 Test MSE 0.00023470838874353292 Test RE 0.011100229899984243\n",
      "198 Train Loss 0.007415677 Test MSE 0.00022362272033580387 Test RE 0.010834918047957689\n",
      "199 Train Loss 0.0073732994 Test MSE 0.00021687146073773726 Test RE 0.010670109344458745\n",
      "200 Train Loss 0.0073337615 Test MSE 0.00020558026394473165 Test RE 0.010388632356990496\n",
      "201 Train Loss 0.0072536934 Test MSE 0.0001919794092938893 Test RE 0.010039104921135926\n",
      "202 Train Loss 0.0072073718 Test MSE 0.00018666233581218485 Test RE 0.009899106934083602\n",
      "203 Train Loss 0.0071381773 Test MSE 0.00017076102063056563 Test RE 0.009468082611298846\n",
      "204 Train Loss 0.0070648957 Test MSE 0.00015204991407501996 Test RE 0.008934304646346584\n",
      "205 Train Loss 0.0069800564 Test MSE 0.00015684291739201682 Test RE 0.009074028178621256\n",
      "206 Train Loss 0.006841018 Test MSE 0.00017130627369539044 Test RE 0.009483186721544369\n",
      "207 Train Loss 0.006745946 Test MSE 0.0001695908276522587 Test RE 0.00943558535147806\n",
      "208 Train Loss 0.0066362675 Test MSE 0.00016347296548949953 Test RE 0.009263831310194877\n",
      "209 Train Loss 0.006484257 Test MSE 0.0001748557654720851 Test RE 0.00958092953414401\n",
      "210 Train Loss 0.0063799876 Test MSE 0.0001765811600879358 Test RE 0.009628083553922676\n",
      "211 Train Loss 0.0062489617 Test MSE 0.00018824111133714912 Test RE 0.009940881726527944\n",
      "212 Train Loss 0.0061497493 Test MSE 0.00016961998130407026 Test RE 0.009436396332687244\n",
      "213 Train Loss 0.006032586 Test MSE 0.0001715821673648298 Test RE 0.00949082012149651\n",
      "214 Train Loss 0.005943605 Test MSE 0.00016225769097398933 Test RE 0.009229332946292506\n",
      "215 Train Loss 0.0058440785 Test MSE 0.00016335324582894905 Test RE 0.009260438498830499\n",
      "216 Train Loss 0.0057968255 Test MSE 0.0001565977447685358 Test RE 0.009066933266685348\n",
      "217 Train Loss 0.0057340227 Test MSE 0.00015409343698649945 Test RE 0.008994141973241105\n",
      "218 Train Loss 0.005681191 Test MSE 0.0001409607295490443 Test RE 0.008602342641802816\n",
      "219 Train Loss 0.0056320312 Test MSE 0.00014158390522004766 Test RE 0.008621336793029824\n",
      "220 Train Loss 0.005565403 Test MSE 0.00013828404991549534 Test RE 0.008520276971518853\n",
      "221 Train Loss 0.005515975 Test MSE 0.00015489153569625576 Test RE 0.009017403647056606\n",
      "222 Train Loss 0.0054517156 Test MSE 0.00016984481709564955 Test RE 0.009442648358586455\n",
      "223 Train Loss 0.0053078905 Test MSE 0.00017499711908715814 Test RE 0.009584801369390857\n",
      "224 Train Loss 0.0051854784 Test MSE 0.00017662110803229943 Test RE 0.009629172572692144\n",
      "225 Train Loss 0.0050980314 Test MSE 0.0001930663784826381 Test RE 0.010067485035929826\n",
      "226 Train Loss 0.004957375 Test MSE 0.00019523468510004266 Test RE 0.010123860582800568\n",
      "227 Train Loss 0.0047677536 Test MSE 0.00022404238062628215 Test RE 0.010845079925918032\n",
      "228 Train Loss 0.0046075475 Test MSE 0.0002356699451765233 Test RE 0.011122944443825914\n",
      "229 Train Loss 0.0044960254 Test MSE 0.00021853594325391026 Test RE 0.010710977477255666\n",
      "230 Train Loss 0.004414575 Test MSE 0.00022642175774271886 Test RE 0.010902516344746392\n",
      "231 Train Loss 0.0043527344 Test MSE 0.00024884552494398686 Test RE 0.011429640884095225\n",
      "232 Train Loss 0.0043100896 Test MSE 0.00023270446819889857 Test RE 0.011052741904459842\n",
      "233 Train Loss 0.0042874455 Test MSE 0.00022707935576313782 Test RE 0.010918336986714136\n",
      "234 Train Loss 0.0042697364 Test MSE 0.0002350495718731044 Test RE 0.01110829487771887\n",
      "235 Train Loss 0.0042484202 Test MSE 0.00022495064513857065 Test RE 0.010867040588548198\n",
      "236 Train Loss 0.0042262254 Test MSE 0.00020782791414023787 Test RE 0.010445268473317785\n",
      "237 Train Loss 0.0041974336 Test MSE 0.00020522018984027516 Test RE 0.010379530518109987\n",
      "238 Train Loss 0.0041687945 Test MSE 0.00019441744921093603 Test RE 0.010102649550299046\n",
      "239 Train Loss 0.0041399472 Test MSE 0.00020848078370899146 Test RE 0.010461661965842148\n",
      "240 Train Loss 0.0041044913 Test MSE 0.0002229809680393511 Test RE 0.010819359858325822\n",
      "241 Train Loss 0.0040505924 Test MSE 0.00023183343185784582 Test RE 0.01103203674596299\n",
      "242 Train Loss 0.0039721695 Test MSE 0.00028331558789212666 Test RE 0.012195592444749345\n",
      "243 Train Loss 0.0038869753 Test MSE 0.0002923953770150532 Test RE 0.012389475424618806\n",
      "244 Train Loss 0.0037991775 Test MSE 0.0002686287301999133 Test RE 0.011875281062592946\n",
      "245 Train Loss 0.0037508735 Test MSE 0.0002673773571526869 Test RE 0.011847589025708637\n",
      "246 Train Loss 0.0037092534 Test MSE 0.00024359282592479836 Test RE 0.01130836751887349\n",
      "247 Train Loss 0.0036602707 Test MSE 0.00021478454107771774 Test RE 0.010618646856637553\n",
      "248 Train Loss 0.003624085 Test MSE 0.00021396611408660762 Test RE 0.01059839660553007\n",
      "249 Train Loss 0.0036044389 Test MSE 0.00020936287275238858 Test RE 0.010483770422818861\n",
      "250 Train Loss 0.003577137 Test MSE 0.0002056948014698878 Test RE 0.010391525928894946\n",
      "251 Train Loss 0.0035448421 Test MSE 0.00020092980628196762 Test RE 0.010270458933976274\n",
      "252 Train Loss 0.0034964222 Test MSE 0.00016802191962369403 Test RE 0.009391838992782448\n",
      "253 Train Loss 0.003477064 Test MSE 0.00015860550353687016 Test RE 0.009124872275526047\n",
      "254 Train Loss 0.0034565353 Test MSE 0.0001487980649623782 Test RE 0.008838250559139737\n",
      "255 Train Loss 0.0033912938 Test MSE 0.0001398182289434928 Test RE 0.00856741029780798\n",
      "256 Train Loss 0.0033648682 Test MSE 0.00014288031699357883 Test RE 0.008660717448267768\n",
      "257 Train Loss 0.0033414904 Test MSE 0.00014536048614995775 Test RE 0.00873556201210554\n",
      "258 Train Loss 0.0032836942 Test MSE 0.00013669304084349855 Test RE 0.008471120705387953\n",
      "259 Train Loss 0.0032306784 Test MSE 0.00013600046209495968 Test RE 0.008449633260000476\n",
      "260 Train Loss 0.003207131 Test MSE 0.00012257479940932595 Test RE 0.008021734120701772\n",
      "261 Train Loss 0.0031825795 Test MSE 0.00010886768808129942 Test RE 0.007559919443696019\n",
      "262 Train Loss 0.0031489967 Test MSE 0.00011216339593385688 Test RE 0.007673495496219188\n",
      "263 Train Loss 0.003116036 Test MSE 0.00010043484703698365 Test RE 0.007261224743352088\n",
      "264 Train Loss 0.0030906242 Test MSE 0.00010546294157482256 Test RE 0.007440765331989937\n",
      "265 Train Loss 0.0030784837 Test MSE 0.00010563796600169233 Test RE 0.007446937053502514\n",
      "266 Train Loss 0.003059472 Test MSE 9.714221710594146e-05 Test RE 0.007141207843058747\n",
      "267 Train Loss 0.0030274575 Test MSE 9.79422677938145e-05 Test RE 0.007170554573312463\n",
      "268 Train Loss 0.002988128 Test MSE 9.620119551665297e-05 Test RE 0.007106535047955022\n",
      "269 Train Loss 0.0029647343 Test MSE 9.604050439400614e-05 Test RE 0.007100597313195758\n",
      "270 Train Loss 0.002947437 Test MSE 9.365432246050885e-05 Test RE 0.007011833271295855\n",
      "271 Train Loss 0.0029217908 Test MSE 8.807454984970513e-05 Test RE 0.0067997490297628345\n",
      "272 Train Loss 0.0029014626 Test MSE 8.470440125577712e-05 Test RE 0.006668384849422384\n",
      "273 Train Loss 0.0028857284 Test MSE 8.009864304525914e-05 Test RE 0.006484556028220536\n",
      "274 Train Loss 0.0028716123 Test MSE 7.948825728967948e-05 Test RE 0.006459801238915402\n",
      "275 Train Loss 0.0028636316 Test MSE 7.714744391811208e-05 Test RE 0.006363974610816854\n",
      "276 Train Loss 0.0028449986 Test MSE 7.42878998637155e-05 Test RE 0.006244917538988257\n",
      "277 Train Loss 0.0028292174 Test MSE 7.223919710739084e-05 Test RE 0.006158204728588435\n",
      "278 Train Loss 0.002812376 Test MSE 7.124636819209555e-05 Test RE 0.006115740271147048\n",
      "279 Train Loss 0.0027860547 Test MSE 6.793393983430894e-05 Test RE 0.0059718799509039305\n",
      "280 Train Loss 0.0027617067 Test MSE 6.851882137849056e-05 Test RE 0.005997532493684536\n",
      "281 Train Loss 0.0027370653 Test MSE 6.099415437711333e-05 Test RE 0.005658636218287356\n",
      "282 Train Loss 0.0027201958 Test MSE 5.683664514648122e-05 Test RE 0.005462379697646655\n",
      "283 Train Loss 0.0027061529 Test MSE 5.504725962903778e-05 Test RE 0.005375706131185495\n",
      "284 Train Loss 0.0026899327 Test MSE 5.264512981341251e-05 Test RE 0.0052571064144734956\n",
      "285 Train Loss 0.0026791536 Test MSE 4.895848479271326e-05 Test RE 0.005069692893184909\n",
      "286 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "287 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "288 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "289 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "290 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "291 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "292 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "293 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "294 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "295 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "296 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "297 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "298 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "299 Train Loss 0.0026716068 Test MSE 4.962689283412755e-05 Test RE 0.0051041826855059425\n",
      "Training time: 176.39\n",
      "KG_atanh_medium\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 37751.926 Test MSE 8.720931663383482 Test RE 2.139681389787303\n",
      "1 Train Loss 13259.237 Test MSE 10.4348041954262 Test RE 2.340506328279874\n",
      "2 Train Loss 7566.093 Test MSE 10.906874714137006 Test RE 2.392862975107053\n",
      "3 Train Loss 4659.9053 Test MSE 13.765315341974462 Test RE 2.688194883006597\n",
      "4 Train Loss 2403.6172 Test MSE 14.553514520804152 Test RE 2.764086370076014\n",
      "5 Train Loss 1381.7092 Test MSE 16.453021430204426 Test RE 2.9389385080064225\n",
      "6 Train Loss 889.87366 Test MSE 17.21871103639456 Test RE 3.006546925061906\n",
      "7 Train Loss 678.939 Test MSE 18.140359431370335 Test RE 3.085962267565744\n",
      "8 Train Loss 500.3881 Test MSE 18.650097369100582 Test RE 3.1290191379086085\n",
      "9 Train Loss 312.52615 Test MSE 19.184799301637515 Test RE 3.1735569615091737\n",
      "10 Train Loss 205.4257 Test MSE 18.79205572454737 Test RE 3.140905090736935\n",
      "11 Train Loss 130.93643 Test MSE 17.976383667789946 Test RE 3.071983169202872\n",
      "12 Train Loss 100.93623 Test MSE 17.4527655192601 Test RE 3.0269119965389684\n",
      "13 Train Loss 83.48898 Test MSE 17.17261196531973 Test RE 3.0025195646195977\n",
      "14 Train Loss 64.92426 Test MSE 17.201336116912685 Test RE 3.0050296310150744\n",
      "15 Train Loss 53.20575 Test MSE 17.099085679655374 Test RE 2.996084873003925\n",
      "16 Train Loss 43.922295 Test MSE 16.926577322043283 Test RE 2.980933188888883\n",
      "17 Train Loss 37.494827 Test MSE 16.98875489518675 Test RE 2.986403204698763\n",
      "18 Train Loss 30.68243 Test MSE 16.83791943048162 Test RE 2.973116185461644\n",
      "19 Train Loss 26.499344 Test MSE 16.692949150448406 Test RE 2.960289623582871\n",
      "20 Train Loss 24.489132 Test MSE 16.702946493317047 Test RE 2.961175943918773\n",
      "21 Train Loss 22.876408 Test MSE 16.62963109784702 Test RE 2.954669949825966\n",
      "22 Train Loss 21.85804 Test MSE 16.658130130622585 Test RE 2.957200649077264\n",
      "23 Train Loss 21.068262 Test MSE 16.661275875662046 Test RE 2.9574798568893654\n",
      "24 Train Loss 20.365683 Test MSE 16.529754935575784 Test RE 2.9457838381229244\n",
      "25 Train Loss 19.957594 Test MSE 16.552103063238288 Test RE 2.94777450638135\n",
      "26 Train Loss 19.6618 Test MSE 16.486237299827156 Test RE 2.9419036223208006\n",
      "27 Train Loss 19.294188 Test MSE 16.448049431347528 Test RE 2.938494410152581\n",
      "28 Train Loss 18.984852 Test MSE 16.3758334264481 Test RE 2.9320365086840208\n",
      "29 Train Loss 18.780785 Test MSE 16.29583839081398 Test RE 2.9248663238277843\n",
      "30 Train Loss 18.582197 Test MSE 16.192714803218994 Test RE 2.915597042905091\n",
      "31 Train Loss 18.295185 Test MSE 16.111354931561102 Test RE 2.9082631485534463\n",
      "32 Train Loss 18.149761 Test MSE 16.090378964336917 Test RE 2.906369344419705\n",
      "33 Train Loss 17.992466 Test MSE 16.08191610924404 Test RE 2.905604930553194\n",
      "34 Train Loss 17.842098 Test MSE 15.94904590331396 Test RE 2.8935768529658037\n",
      "35 Train Loss 17.651684 Test MSE 15.853852463244527 Test RE 2.8849286310138664\n",
      "36 Train Loss 17.494053 Test MSE 15.743556366972314 Test RE 2.8748758149063978\n",
      "37 Train Loss 17.380232 Test MSE 15.567427862156729 Test RE 2.858749479950195\n",
      "38 Train Loss 17.176987 Test MSE 15.348209925150348 Test RE 2.838549898035393\n",
      "39 Train Loss 16.954676 Test MSE 14.79693575148146 Test RE 2.787106484267984\n",
      "40 Train Loss 16.508839 Test MSE 14.008552361684629 Test RE 2.7118414623666585\n",
      "41 Train Loss 15.973738 Test MSE 13.508004827233995 Test RE 2.662951588726001\n",
      "42 Train Loss 14.761873 Test MSE 12.438037104304573 Test RE 2.5553099831079056\n",
      "43 Train Loss 14.045301 Test MSE 12.228890523693641 Test RE 2.533735032437318\n",
      "44 Train Loss 13.2463665 Test MSE 11.731670355335092 Test RE 2.4816903578571936\n",
      "45 Train Loss 12.5039835 Test MSE 11.004841912854731 Test RE 2.403585479765543\n",
      "46 Train Loss 11.926171 Test MSE 10.365918058398636 Test RE 2.3327680224642755\n",
      "47 Train Loss 10.93392 Test MSE 8.952680052426349 Test RE 2.167924731062521\n",
      "48 Train Loss 10.075865 Test MSE 7.939247632334531 Test RE 2.041537406320309\n",
      "49 Train Loss 8.960539 Test MSE 6.5351086024206575 Test RE 1.8522264097916594\n",
      "50 Train Loss 7.8896194 Test MSE 6.069644402863753 Test RE 1.7850455048426956\n",
      "51 Train Loss 7.0100975 Test MSE 5.336167221008898 Test RE 1.6737183708979477\n",
      "52 Train Loss 6.247107 Test MSE 4.6853545728447825 Test RE 1.56833523231908\n",
      "53 Train Loss 5.746272 Test MSE 4.5045029926924745 Test RE 1.537769020758987\n",
      "54 Train Loss 5.228733 Test MSE 4.444534013103669 Test RE 1.5274984728032912\n",
      "55 Train Loss 4.827834 Test MSE 3.947811485232101 Test RE 1.4396133678648009\n",
      "56 Train Loss 4.545881 Test MSE 3.630440720557152 Test RE 1.3805347488324093\n",
      "57 Train Loss 4.1919146 Test MSE 3.41073383401627 Test RE 1.3381092791382263\n",
      "58 Train Loss 3.9968836 Test MSE 3.15363757155119 Test RE 1.2866889111313213\n",
      "59 Train Loss 3.7840488 Test MSE 2.9818431166362243 Test RE 1.2511519662441226\n",
      "60 Train Loss 3.6170332 Test MSE 2.8073324801121844 Test RE 1.213988556204929\n",
      "61 Train Loss 3.2795706 Test MSE 2.336664832107592 Test RE 1.107556470863479\n",
      "62 Train Loss 2.9718444 Test MSE 2.020879493146163 Test RE 1.0300015449090374\n",
      "63 Train Loss 2.6635416 Test MSE 1.7355659383245314 Test RE 0.9545270204065065\n",
      "64 Train Loss 2.4261405 Test MSE 1.4612416907091428 Test RE 0.8758479038879411\n",
      "65 Train Loss 2.079536 Test MSE 1.0340140467587342 Test RE 0.7367682239562027\n",
      "66 Train Loss 1.7099081 Test MSE 0.6639591450353407 Test RE 0.5903891209270224\n",
      "67 Train Loss 1.4951029 Test MSE 0.4401574277389523 Test RE 0.48069730266024435\n",
      "68 Train Loss 1.26741 Test MSE 0.29560546739564164 Test RE 0.393934392685364\n",
      "69 Train Loss 1.0433986 Test MSE 0.2553000006848258 Test RE 0.3660943915117713\n",
      "70 Train Loss 0.8987551 Test MSE 0.221234079923472 Test RE 0.34079536689352147\n",
      "71 Train Loss 0.7563441 Test MSE 0.124362758907528 Test RE 0.25551290620405587\n",
      "72 Train Loss 0.66809994 Test MSE 0.0955741015559504 Test RE 0.22399471919528743\n",
      "73 Train Loss 0.5458133 Test MSE 0.08688033086017165 Test RE 0.21356417419273624\n",
      "74 Train Loss 0.47867504 Test MSE 0.07002022875008149 Test RE 0.1917253018833992\n",
      "75 Train Loss 0.430615 Test MSE 0.05563553279584641 Test RE 0.170900681032206\n",
      "76 Train Loss 0.34770122 Test MSE 0.026039051078797903 Test RE 0.11691769490203736\n",
      "77 Train Loss 0.29674923 Test MSE 0.03071374956256587 Test RE 0.12697963869894702\n",
      "78 Train Loss 0.2752039 Test MSE 0.022352632611622156 Test RE 0.10832582560660663\n",
      "79 Train Loss 0.25483364 Test MSE 0.021882252233036588 Test RE 0.107179981447236\n",
      "80 Train Loss 0.2101817 Test MSE 0.022676428437894112 Test RE 0.10910759790563593\n",
      "81 Train Loss 0.18786542 Test MSE 0.013634052744734202 Test RE 0.08460190700316311\n",
      "82 Train Loss 0.16212335 Test MSE 0.010967836316967327 Test RE 0.07588014425968197\n",
      "83 Train Loss 0.14816348 Test MSE 0.010009645182718132 Test RE 0.07248981796964407\n",
      "84 Train Loss 0.13353303 Test MSE 0.008978637739756436 Test RE 0.06865511396336768\n",
      "85 Train Loss 0.12165063 Test MSE 0.006676951960270797 Test RE 0.059204782968457596\n",
      "86 Train Loss 0.10693072 Test MSE 0.0035796422187843895 Test RE 0.04334983795931936\n",
      "87 Train Loss 0.100849226 Test MSE 0.0025793994350489903 Test RE 0.0367982332441746\n",
      "88 Train Loss 0.08522421 Test MSE 0.00312792297710829 Test RE 0.04052244978996695\n",
      "89 Train Loss 0.07841359 Test MSE 0.0036996168517340407 Test RE 0.044070303576743644\n",
      "90 Train Loss 0.06740609 Test MSE 0.0016281109935668545 Test RE 0.029235442531354443\n",
      "91 Train Loss 0.06251795 Test MSE 0.0012607322827045484 Test RE 0.025726405130638366\n",
      "92 Train Loss 0.060128957 Test MSE 0.0008351993903276339 Test RE 0.020939328582982\n",
      "93 Train Loss 0.056219004 Test MSE 0.0006912255278832338 Test RE 0.019049235551832768\n",
      "94 Train Loss 0.05470738 Test MSE 0.0007844451561894175 Test RE 0.020293126400264937\n",
      "95 Train Loss 0.052355222 Test MSE 0.000668736829103028 Test RE 0.01873679427809424\n",
      "96 Train Loss 0.048395768 Test MSE 0.001023854793927105 Test RE 0.02318391904836717\n",
      "97 Train Loss 0.04671493 Test MSE 0.0010637039707704075 Test RE 0.02363078004901652\n",
      "98 Train Loss 0.044916805 Test MSE 0.001071662999501044 Test RE 0.02371902243368998\n",
      "99 Train Loss 0.042391434 Test MSE 0.0014301731477224316 Test RE 0.027400720169963\n",
      "100 Train Loss 0.040909357 Test MSE 0.001108630948043659 Test RE 0.024124658072483526\n",
      "101 Train Loss 0.03839443 Test MSE 0.0007466835139989498 Test RE 0.019798666900160522\n",
      "102 Train Loss 0.036425192 Test MSE 0.0006389985300803521 Test RE 0.018315450156821397\n",
      "103 Train Loss 0.034143366 Test MSE 0.0008979277572003822 Test RE 0.021711426868621247\n",
      "104 Train Loss 0.03351914 Test MSE 0.000997846328935402 Test RE 0.02288756019914713\n",
      "105 Train Loss 0.03196641 Test MSE 0.0008100707450763314 Test RE 0.02062192209293129\n",
      "106 Train Loss 0.030626988 Test MSE 0.0006534717122861912 Test RE 0.018521709310168378\n",
      "107 Train Loss 0.029539937 Test MSE 0.0006948959417074192 Test RE 0.01909974439680276\n",
      "108 Train Loss 0.028152721 Test MSE 0.0009711343695304164 Test RE 0.02257913654490469\n",
      "109 Train Loss 0.027066277 Test MSE 0.0010183413530295983 Test RE 0.023121412277631075\n",
      "110 Train Loss 0.02595966 Test MSE 0.0007937574628126016 Test RE 0.020413222926985105\n",
      "111 Train Loss 0.025041327 Test MSE 0.001018626184735303 Test RE 0.02312464559955876\n",
      "112 Train Loss 0.024163455 Test MSE 0.0008695886491973388 Test RE 0.021366067631763908\n",
      "113 Train Loss 0.023581091 Test MSE 0.0007050881843407954 Test RE 0.0192393052916063\n",
      "114 Train Loss 0.022947934 Test MSE 0.0007196999256285147 Test RE 0.019437633830548497\n",
      "115 Train Loss 0.021967607 Test MSE 0.0006567342735590948 Test RE 0.018567888030461246\n",
      "116 Train Loss 0.020989243 Test MSE 0.0005240268952868971 Test RE 0.016586106754719342\n",
      "117 Train Loss 0.020504849 Test MSE 0.0005065955670836062 Test RE 0.016307912037226934\n",
      "118 Train Loss 0.020009337 Test MSE 0.00048723553406867896 Test RE 0.015993265414029602\n",
      "119 Train Loss 0.019005379 Test MSE 0.0004009445879158903 Test RE 0.01450807678501783\n",
      "120 Train Loss 0.017503086 Test MSE 0.0005402836461099713 Test RE 0.016841415037063774\n",
      "121 Train Loss 0.016634015 Test MSE 0.000471644275684576 Test RE 0.015735297254291233\n",
      "122 Train Loss 0.016197907 Test MSE 0.0005059873183381081 Test RE 0.01629811897261366\n",
      "123 Train Loss 0.015762968 Test MSE 0.00046239794348128406 Test RE 0.015580292781915132\n",
      "124 Train Loss 0.015056345 Test MSE 0.00038706676399774905 Test RE 0.01425478293514842\n",
      "125 Train Loss 0.014702694 Test MSE 0.00043702506092379987 Test RE 0.015146798175245923\n",
      "126 Train Loss 0.014305384 Test MSE 0.0004772856692892383 Test RE 0.0158291234082628\n",
      "127 Train Loss 0.013570203 Test MSE 0.000278151522531002 Test RE 0.012083935219266947\n",
      "128 Train Loss 0.012829829 Test MSE 0.00022589992119454922 Test RE 0.01088994552690501\n",
      "129 Train Loss 0.012284446 Test MSE 0.00025164713211212384 Test RE 0.01149380064778711\n",
      "130 Train Loss 0.011990492 Test MSE 0.000232587527023726 Test RE 0.011049964383553431\n",
      "131 Train Loss 0.011754922 Test MSE 0.00023285479464167668 Test RE 0.011056311348438947\n",
      "132 Train Loss 0.011561454 Test MSE 0.00024693479471305695 Test RE 0.011385675769498742\n",
      "133 Train Loss 0.011408474 Test MSE 0.0002709290779976716 Test RE 0.011926018458015157\n",
      "134 Train Loss 0.011095963 Test MSE 0.0003031162627279958 Test RE 0.012614565219536692\n",
      "135 Train Loss 0.010689382 Test MSE 0.00028180412133177614 Test RE 0.012163017673517412\n",
      "136 Train Loss 0.009978266 Test MSE 0.00021394585032924677 Test RE 0.010597894730681335\n",
      "137 Train Loss 0.009597378 Test MSE 0.00022329993656867344 Test RE 0.01082709550065487\n",
      "138 Train Loss 0.009298178 Test MSE 0.000239954088332566 Test RE 0.011223588736760482\n",
      "139 Train Loss 0.009169493 Test MSE 0.0002380178899018601 Test RE 0.011178215244560282\n",
      "140 Train Loss 0.008924821 Test MSE 0.00021219702970733573 Test RE 0.01055449158250008\n",
      "141 Train Loss 0.008767483 Test MSE 0.00019301413038235292 Test RE 0.010066122699918622\n",
      "142 Train Loss 0.0083891265 Test MSE 0.00016270304851802772 Test RE 0.009241990393886929\n",
      "143 Train Loss 0.008144009 Test MSE 0.00019328683015804415 Test RE 0.010073231144526771\n",
      "144 Train Loss 0.007844398 Test MSE 0.0002486473521470068 Test RE 0.01142508887329419\n",
      "145 Train Loss 0.0076443073 Test MSE 0.0002695864222550065 Test RE 0.011896430594807824\n",
      "146 Train Loss 0.0074127386 Test MSE 0.00027328644982803623 Test RE 0.011977790621446273\n",
      "147 Train Loss 0.007203674 Test MSE 0.0002727807503609362 Test RE 0.011966703414170542\n",
      "148 Train Loss 0.0070989123 Test MSE 0.00030796354021673817 Test RE 0.01271502795585979\n",
      "149 Train Loss 0.0069704764 Test MSE 0.000266483472096972 Test RE 0.011827768258068383\n",
      "150 Train Loss 0.006760313 Test MSE 0.0003047774342175277 Test RE 0.012649083863286758\n",
      "151 Train Loss 0.0065043876 Test MSE 0.00035529850958973595 Test RE 0.013657284627356377\n",
      "152 Train Loss 0.006255167 Test MSE 0.0004150698661888512 Test RE 0.014761424519282638\n",
      "153 Train Loss 0.005970464 Test MSE 0.0003878320526589672 Test RE 0.014268867891408245\n",
      "154 Train Loss 0.005821694 Test MSE 0.0003696154830727567 Test RE 0.013929731500010483\n",
      "155 Train Loss 0.0057457676 Test MSE 0.0003609158617353539 Test RE 0.013764823664554997\n",
      "156 Train Loss 0.0056746583 Test MSE 0.00038839884880380077 Test RE 0.014279290684644995\n",
      "157 Train Loss 0.0056118234 Test MSE 0.0004310081034728638 Test RE 0.015042166287823228\n",
      "158 Train Loss 0.0054996233 Test MSE 0.0003877127404090213 Test RE 0.014266672892727992\n",
      "159 Train Loss 0.0053249537 Test MSE 0.0004151417901003544 Test RE 0.01476270340446324\n",
      "160 Train Loss 0.005147531 Test MSE 0.0003992642443293204 Test RE 0.014477643465080528\n",
      "161 Train Loss 0.0050365846 Test MSE 0.000480436035772006 Test RE 0.015881278254636946\n",
      "162 Train Loss 0.004945907 Test MSE 0.00044547358860207273 Test RE 0.015292505589721818\n",
      "163 Train Loss 0.004864028 Test MSE 0.00042025758008363396 Test RE 0.014853385248099578\n",
      "164 Train Loss 0.004765502 Test MSE 0.00041063126044625544 Test RE 0.014682285735685639\n",
      "165 Train Loss 0.0046769413 Test MSE 0.0004250911529082215 Test RE 0.014938558799870905\n",
      "166 Train Loss 0.0045976327 Test MSE 0.00042603879744937065 Test RE 0.01495520059862086\n",
      "167 Train Loss 0.0045075477 Test MSE 0.00037453845916615345 Test RE 0.014022190965642516\n",
      "168 Train Loss 0.004403477 Test MSE 0.0004026794683342837 Test RE 0.014539431005185769\n",
      "169 Train Loss 0.0043016453 Test MSE 0.0004421959771419992 Test RE 0.015236143743024124\n",
      "170 Train Loss 0.0041974857 Test MSE 0.00042927789843486865 Test RE 0.015011943881962446\n",
      "171 Train Loss 0.004151443 Test MSE 0.00045735643651670133 Test RE 0.015495124332591937\n",
      "172 Train Loss 0.004108479 Test MSE 0.0004466513809121935 Test RE 0.015312708253279374\n",
      "173 Train Loss 0.004058713 Test MSE 0.00040308150104922274 Test RE 0.014546687233927793\n",
      "174 Train Loss 0.0039915927 Test MSE 0.00040342854795298583 Test RE 0.014552948122326523\n",
      "175 Train Loss 0.0039503397 Test MSE 0.0004147608239383105 Test RE 0.014755928151454725\n",
      "176 Train Loss 0.0038914187 Test MSE 0.000424724567543668 Test RE 0.014932116136769376\n",
      "177 Train Loss 0.003839787 Test MSE 0.00040780157521177996 Test RE 0.014631610016034184\n",
      "178 Train Loss 0.0037973349 Test MSE 0.00041335300173351897 Test RE 0.014730863849161098\n",
      "179 Train Loss 0.003756042 Test MSE 0.0003998205995448468 Test RE 0.014487726897989831\n",
      "180 Train Loss 0.0037225946 Test MSE 0.0004256488127438093 Test RE 0.014948354232947615\n",
      "181 Train Loss 0.0036817759 Test MSE 0.0004177081046628834 Test RE 0.014808262983857397\n",
      "182 Train Loss 0.0036564264 Test MSE 0.00042771619407334455 Test RE 0.014984612426519215\n",
      "183 Train Loss 0.003641857 Test MSE 0.00043096190259405337 Test RE 0.015041360061767626\n",
      "184 Train Loss 0.0036140697 Test MSE 0.0004320479387316027 Test RE 0.015060300462274563\n",
      "185 Train Loss 0.0035679126 Test MSE 0.0004024437198286707 Test RE 0.014535174330550833\n",
      "186 Train Loss 0.0035226159 Test MSE 0.0003710138393648339 Test RE 0.01395605661355814\n",
      "187 Train Loss 0.0034675 Test MSE 0.000341606587693825 Test RE 0.013391548121719945\n",
      "188 Train Loss 0.003383864 Test MSE 0.000312397152074857 Test RE 0.012806227144939895\n",
      "189 Train Loss 0.0033468637 Test MSE 0.0003052203391865076 Test RE 0.012658271400819024\n",
      "190 Train Loss 0.0033046238 Test MSE 0.0003025690903115687 Test RE 0.012603174441888344\n",
      "191 Train Loss 0.0032832774 Test MSE 0.00030271774463633933 Test RE 0.012606270075885951\n",
      "192 Train Loss 0.0032449353 Test MSE 0.0002998694312194014 Test RE 0.012546822833175634\n",
      "193 Train Loss 0.0032098265 Test MSE 0.0003085732842106165 Test RE 0.01272760911753795\n",
      "194 Train Loss 0.003180672 Test MSE 0.00029943826406713113 Test RE 0.012537799366095162\n",
      "195 Train Loss 0.0031427813 Test MSE 0.00030600021253103667 Test RE 0.012674432759189986\n",
      "196 Train Loss 0.003114164 Test MSE 0.0002959438936112087 Test RE 0.012464428173737531\n",
      "197 Train Loss 0.0030691 Test MSE 0.00027601491694976193 Test RE 0.012037434708343524\n",
      "198 Train Loss 0.0030442476 Test MSE 0.0002705841352985156 Test RE 0.0119184240291224\n",
      "199 Train Loss 0.002978628 Test MSE 0.0002639159824348673 Test RE 0.0117706518206261\n",
      "200 Train Loss 0.0029454217 Test MSE 0.00025451747830877725 Test RE 0.011559165277871139\n",
      "201 Train Loss 0.0029312111 Test MSE 0.00025674452430826927 Test RE 0.01160962689091173\n",
      "202 Train Loss 0.0029074831 Test MSE 0.00025589064295743994 Test RE 0.011590305154597434\n",
      "203 Train Loss 0.0028907713 Test MSE 0.0002582680485948804 Test RE 0.011644021756044896\n",
      "204 Train Loss 0.0028705338 Test MSE 0.00025760863700097176 Test RE 0.011629147461173673\n",
      "205 Train Loss 0.002846315 Test MSE 0.00024310802136515527 Test RE 0.01129710881573023\n",
      "206 Train Loss 0.0028237219 Test MSE 0.0002361552719435758 Test RE 0.01113439156809482\n",
      "207 Train Loss 0.0028075972 Test MSE 0.00023102065823703085 Test RE 0.011012681424703928\n",
      "208 Train Loss 0.0027880422 Test MSE 0.00023001191565003286 Test RE 0.010988611901890346\n",
      "209 Train Loss 0.002719467 Test MSE 0.0002344745791590125 Test RE 0.011094699661317901\n",
      "210 Train Loss 0.0026784528 Test MSE 0.0002359621639265792 Test RE 0.01112983825029362\n",
      "211 Train Loss 0.0026469496 Test MSE 0.0002454809224378235 Test RE 0.011352108698696245\n",
      "212 Train Loss 0.0026138253 Test MSE 0.00024602924544106785 Test RE 0.011364780050534859\n",
      "213 Train Loss 0.0025891175 Test MSE 0.0002500602232928159 Test RE 0.011457502877101693\n",
      "214 Train Loss 0.0025745265 Test MSE 0.0002527702877237744 Test RE 0.011519421751362046\n",
      "215 Train Loss 0.0025597862 Test MSE 0.0002577285765833115 Test RE 0.011631854343973475\n",
      "216 Train Loss 0.002541112 Test MSE 0.0002525532182544566 Test RE 0.011514474469273997\n",
      "217 Train Loss 0.0025246372 Test MSE 0.00026267355602060927 Test RE 0.011742913029228195\n",
      "218 Train Loss 0.0025053248 Test MSE 0.00025268866135260136 Test RE 0.011517561634559024\n",
      "219 Train Loss 0.0024832517 Test MSE 0.0002493400934772615 Test RE 0.011440993177609507\n",
      "220 Train Loss 0.002442241 Test MSE 0.00024238165929531597 Test RE 0.011280219348613403\n",
      "221 Train Loss 0.002418447 Test MSE 0.00023228667076385421 Test RE 0.011042815404512626\n",
      "222 Train Loss 0.0023802458 Test MSE 0.00023918820493734058 Test RE 0.011205662744324935\n",
      "223 Train Loss 0.0023464037 Test MSE 0.00024822531187292254 Test RE 0.011415388598144272\n",
      "224 Train Loss 0.0023239625 Test MSE 0.000252651290174977 Test RE 0.011516709913007992\n",
      "225 Train Loss 0.0023021107 Test MSE 0.00025305487738643993 Test RE 0.011525904685237225\n",
      "226 Train Loss 0.00227725 Test MSE 0.00026110011735214184 Test RE 0.011707689639662351\n",
      "227 Train Loss 0.002264007 Test MSE 0.00026928821463892503 Test RE 0.01188984905449484\n",
      "228 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "229 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "230 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "231 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "232 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "233 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "234 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "235 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "236 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "237 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "238 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "239 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "240 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "241 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "242 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "243 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "244 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "245 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "246 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "247 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "248 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "249 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "250 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "251 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "252 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "253 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "254 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "255 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "256 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "257 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "258 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "259 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "260 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "261 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "262 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "263 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "264 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "265 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "266 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "267 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "268 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "269 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "270 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "271 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "272 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "273 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "274 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "275 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "276 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "277 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "278 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "279 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "280 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "281 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "282 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "283 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "284 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "285 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "286 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "287 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "288 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "289 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "290 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "291 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "292 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "293 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "294 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "295 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "296 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "297 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "298 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "299 Train Loss 0.002253175 Test MSE 0.00026767771600076813 Test RE 0.011854241663428805\n",
      "Training time: 210.47\n",
      "KG_atanh_medium\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 38875.82 Test MSE 7.130044419412442 Test RE 1.9347006848202393\n",
      "1 Train Loss 11211.154 Test MSE 9.065691543352283 Test RE 2.1815648965780956\n",
      "2 Train Loss 8015.68 Test MSE 10.514667953205421 Test RE 2.349445898854021\n",
      "3 Train Loss 5553.0693 Test MSE 10.451917979078136 Test RE 2.342424836210114\n",
      "4 Train Loss 3960.8738 Test MSE 11.73375100822688 Test RE 2.4819104163459125\n",
      "5 Train Loss 1424.5281 Test MSE 14.878705822847836 Test RE 2.7947968571926123\n",
      "6 Train Loss 640.801 Test MSE 17.294146893947453 Test RE 3.01312562834588\n",
      "7 Train Loss 393.33954 Test MSE 18.031398981889886 Test RE 3.0766803600304957\n",
      "8 Train Loss 244.82857 Test MSE 18.45701714779716 Test RE 3.1127799863417613\n",
      "9 Train Loss 121.33779 Test MSE 17.717103956036905 Test RE 3.04974855608845\n",
      "10 Train Loss 76.91206 Test MSE 17.205751501633387 Test RE 3.0054152845037985\n",
      "11 Train Loss 56.61732 Test MSE 16.658242904840332 Test RE 2.9572106590670666\n",
      "12 Train Loss 49.081455 Test MSE 16.463941768710946 Test RE 2.939913674780531\n",
      "13 Train Loss 42.000458 Test MSE 16.253917430352598 Test RE 2.921101799425151\n",
      "14 Train Loss 35.614502 Test MSE 16.14039655029175 Test RE 2.9108831219474225\n",
      "15 Train Loss 31.875013 Test MSE 16.072423100552488 Test RE 2.904747227890061\n",
      "16 Train Loss 28.375536 Test MSE 15.782384781854715 Test RE 2.878418792316846\n",
      "17 Train Loss 26.016432 Test MSE 15.537180955472312 Test RE 2.8559709101208437\n",
      "18 Train Loss 24.058647 Test MSE 15.34295923975051 Test RE 2.8380643167361606\n",
      "19 Train Loss 22.54939 Test MSE 15.141266724638788 Test RE 2.8193485664562843\n",
      "20 Train Loss 21.497952 Test MSE 15.182662132695466 Test RE 2.8231999095088156\n",
      "21 Train Loss 20.534794 Test MSE 15.196429486919124 Test RE 2.8244796319204393\n",
      "22 Train Loss 19.762407 Test MSE 15.00014234270648 Test RE 2.8061789193657\n",
      "23 Train Loss 19.210434 Test MSE 14.877823164227118 Test RE 2.794713957236284\n",
      "24 Train Loss 18.496296 Test MSE 14.53490158374707 Test RE 2.762318267065139\n",
      "25 Train Loss 17.960289 Test MSE 14.315829187566527 Test RE 2.7414221761340887\n",
      "26 Train Loss 17.443636 Test MSE 14.257652339645997 Test RE 2.7358461923529465\n",
      "27 Train Loss 16.925697 Test MSE 13.875771746339405 Test RE 2.698958714214931\n",
      "28 Train Loss 16.434229 Test MSE 13.700624327793628 Test RE 2.6818707688635772\n",
      "29 Train Loss 15.816566 Test MSE 13.321922294486187 Test RE 2.6445459394035766\n",
      "30 Train Loss 15.387105 Test MSE 13.149286927029774 Test RE 2.62735506917201\n",
      "31 Train Loss 14.90129 Test MSE 12.96834612902435 Test RE 2.609215587679295\n",
      "32 Train Loss 14.498916 Test MSE 12.725876127015738 Test RE 2.5847081570403407\n",
      "33 Train Loss 14.202538 Test MSE 12.60956299023044 Test RE 2.5728690658921463\n",
      "34 Train Loss 13.884403 Test MSE 12.28865233550448 Test RE 2.53991858812614\n",
      "35 Train Loss 13.5273285 Test MSE 12.0085495319635 Test RE 2.5108047669880476\n",
      "36 Train Loss 13.129456 Test MSE 11.776451835604517 Test RE 2.486422331776949\n",
      "37 Train Loss 12.841227 Test MSE 11.53129273445156 Test RE 2.460405370442534\n",
      "38 Train Loss 12.595946 Test MSE 11.35889260437147 Test RE 2.4419437982061263\n",
      "39 Train Loss 12.386625 Test MSE 11.264062719120814 Test RE 2.4317291319898118\n",
      "40 Train Loss 12.163626 Test MSE 11.078799607466257 Test RE 2.411648565902218\n",
      "41 Train Loss 11.924727 Test MSE 10.91520182664064 Test RE 2.393776244856507\n",
      "42 Train Loss 11.703453 Test MSE 10.61986552655275 Test RE 2.3611695639527586\n",
      "43 Train Loss 11.36765 Test MSE 10.075622145626845 Test RE 2.299871671036044\n",
      "44 Train Loss 11.015675 Test MSE 9.532164804943129 Test RE 2.2369868897882315\n",
      "45 Train Loss 10.343853 Test MSE 9.061667233169109 Test RE 2.181080638521386\n",
      "46 Train Loss 9.788424 Test MSE 8.419700797886556 Test RE 2.102403142369337\n",
      "47 Train Loss 9.262905 Test MSE 7.999172604339711 Test RE 2.049227624127773\n",
      "48 Train Loss 8.7484 Test MSE 7.4178970763237215 Test RE 1.973367944582025\n",
      "49 Train Loss 8.267923 Test MSE 6.782324969629449 Test RE 1.8869351083860961\n",
      "50 Train Loss 7.793195 Test MSE 6.441956882149962 Test RE 1.8389781724895204\n",
      "51 Train Loss 7.2614965 Test MSE 6.224603220016817 Test RE 1.8076881212500482\n",
      "52 Train Loss 6.6888614 Test MSE 5.712879161681573 Test RE 1.731789836953778\n",
      "53 Train Loss 6.311546 Test MSE 5.304058089055858 Test RE 1.668675169441581\n",
      "54 Train Loss 5.9964542 Test MSE 5.184252124137405 Test RE 1.6497218434309808\n",
      "55 Train Loss 5.5313215 Test MSE 4.74118656189246 Test RE 1.5776519190083902\n",
      "56 Train Loss 5.2443585 Test MSE 4.51841161057025 Test RE 1.5401412865754995\n",
      "57 Train Loss 4.8818293 Test MSE 4.157097667339146 Test RE 1.4772798755979097\n",
      "58 Train Loss 4.365047 Test MSE 3.8220566079888627 Test RE 1.4164988464189072\n",
      "59 Train Loss 4.0268784 Test MSE 3.5043351911334284 Test RE 1.3563459895873151\n",
      "60 Train Loss 3.7456453 Test MSE 3.1900049512507245 Test RE 1.2940866179241854\n",
      "61 Train Loss 3.5184484 Test MSE 2.841748274647779 Test RE 1.2214071841901533\n",
      "62 Train Loss 3.2667615 Test MSE 2.4456401673771957 Test RE 1.1330888004925794\n",
      "63 Train Loss 3.0218654 Test MSE 2.102145491497661 Test RE 1.0505072475294346\n",
      "64 Train Loss 2.647754 Test MSE 1.4190628069669349 Test RE 0.8631146267086033\n",
      "65 Train Loss 2.3195472 Test MSE 1.1738505812130988 Test RE 0.7850079903449401\n",
      "66 Train Loss 2.0546086 Test MSE 1.0321242615410116 Test RE 0.7360946497193391\n",
      "67 Train Loss 1.8110673 Test MSE 0.8519292517977063 Test RE 0.6687586814837719\n",
      "68 Train Loss 1.5686424 Test MSE 0.6379669791286605 Test RE 0.5787177032757195\n",
      "69 Train Loss 1.3522 Test MSE 0.47870541599744215 Test RE 0.5013047713329548\n",
      "70 Train Loss 1.1012703 Test MSE 0.3616492483404632 Test RE 0.43572396908524996\n",
      "71 Train Loss 0.8942529 Test MSE 0.31077571963574774 Test RE 0.40391614059775105\n",
      "72 Train Loss 0.738382 Test MSE 0.22443997086764303 Test RE 0.3432557092850681\n",
      "73 Train Loss 0.6428543 Test MSE 0.23419198352192525 Test RE 0.35063372064461\n",
      "74 Train Loss 0.59633726 Test MSE 0.24112529231257362 Test RE 0.35578616089990045\n",
      "75 Train Loss 0.5462576 Test MSE 0.22722854446771068 Test RE 0.3453815315022988\n",
      "76 Train Loss 0.46893615 Test MSE 0.2036852227136717 Test RE 0.3269997561281208\n",
      "77 Train Loss 0.4235546 Test MSE 0.17433351283959203 Test RE 0.30252279788061376\n",
      "78 Train Loss 0.3838884 Test MSE 0.16099760474020677 Test RE 0.29072165015619417\n",
      "79 Train Loss 0.3565706 Test MSE 0.15888863931414815 Test RE 0.2888112396088137\n",
      "80 Train Loss 0.3258017 Test MSE 0.16233856897149082 Test RE 0.29192986356128864\n",
      "81 Train Loss 0.2849142 Test MSE 0.12745180434715608 Test RE 0.2586667829332817\n",
      "82 Train Loss 0.2626091 Test MSE 0.10856743310344552 Test RE 0.23873574686492474\n",
      "83 Train Loss 0.2452109 Test MSE 0.09472081245340665 Test RE 0.2229925607976046\n",
      "84 Train Loss 0.22913599 Test MSE 0.09753900193746526 Test RE 0.22628554968927955\n",
      "85 Train Loss 0.20749637 Test MSE 0.08989108392787679 Test RE 0.2172330882438463\n",
      "86 Train Loss 0.1938805 Test MSE 0.08353720039716946 Test RE 0.20941492274144313\n",
      "87 Train Loss 0.1802743 Test MSE 0.06402077991862487 Test RE 0.18332772449664683\n",
      "88 Train Loss 0.16807102 Test MSE 0.06475168161468493 Test RE 0.18437124716987224\n",
      "89 Train Loss 0.15872975 Test MSE 0.06343172547171805 Test RE 0.18248237737188927\n",
      "90 Train Loss 0.1468323 Test MSE 0.06035699241446969 Test RE 0.17800469735700636\n",
      "91 Train Loss 0.13847314 Test MSE 0.05476433265431076 Test RE 0.16955732937398843\n",
      "92 Train Loss 0.1313485 Test MSE 0.054995507019786914 Test RE 0.16991482509907244\n",
      "93 Train Loss 0.12370634 Test MSE 0.052958083917755396 Test RE 0.16673769726906446\n",
      "94 Train Loss 0.1174656 Test MSE 0.04515694062204498 Test RE 0.1539678066499144\n",
      "95 Train Loss 0.112205185 Test MSE 0.03633715272328449 Test RE 0.1381157209567175\n",
      "96 Train Loss 0.10049095 Test MSE 0.023480574742950434 Test RE 0.11102531887900366\n",
      "97 Train Loss 0.09160675 Test MSE 0.017916029904783713 Test RE 0.09698142407147013\n",
      "98 Train Loss 0.08015045 Test MSE 0.020856017354359938 Test RE 0.10463653685522004\n",
      "99 Train Loss 0.07505992 Test MSE 0.018214014125563872 Test RE 0.09778460869317541\n",
      "100 Train Loss 0.06952622 Test MSE 0.016423983018581844 Test RE 0.09285534572159783\n",
      "101 Train Loss 0.064006634 Test MSE 0.010795604912842087 Test RE 0.07528200180523105\n",
      "102 Train Loss 0.06107455 Test MSE 0.010205324958225188 Test RE 0.07319494464742832\n",
      "103 Train Loss 0.05621161 Test MSE 0.007292736794184983 Test RE 0.06187467594159564\n",
      "104 Train Loss 0.052582934 Test MSE 0.005229514853836331 Test RE 0.052396028307288824\n",
      "105 Train Loss 0.048818387 Test MSE 0.00628315014512214 Test RE 0.05743232350424163\n",
      "106 Train Loss 0.046667743 Test MSE 0.006668689744374909 Test RE 0.0591681409407109\n",
      "107 Train Loss 0.04339902 Test MSE 0.005719236827604817 Test RE 0.05479446714572596\n",
      "108 Train Loss 0.040964633 Test MSE 0.004709193940845792 Test RE 0.049721126077660514\n",
      "109 Train Loss 0.039875377 Test MSE 0.004183196233935922 Test RE 0.04686210432908838\n",
      "110 Train Loss 0.03796935 Test MSE 0.0031609582768005375 Test RE 0.040735875002015184\n",
      "111 Train Loss 0.036020085 Test MSE 0.0028442205515980326 Test RE 0.03864108413800494\n",
      "112 Train Loss 0.0349417 Test MSE 0.0025383511780082764 Test RE 0.03650425761807101\n",
      "113 Train Loss 0.03431821 Test MSE 0.0024199426843257653 Test RE 0.03564266819050656\n",
      "114 Train Loss 0.033322264 Test MSE 0.0018941242213735738 Test RE 0.031533479626308404\n",
      "115 Train Loss 0.031816967 Test MSE 0.00231355210242741 Test RE 0.034850363308288175\n",
      "116 Train Loss 0.03140243 Test MSE 0.0021241534623585474 Test RE 0.03339339791294151\n",
      "117 Train Loss 0.030099493 Test MSE 0.0018860729006711207 Test RE 0.031466388849798244\n",
      "118 Train Loss 0.029377136 Test MSE 0.0017730574984273961 Test RE 0.030509077591577508\n",
      "119 Train Loss 0.028642613 Test MSE 0.0013340175226071338 Test RE 0.02646357021615175\n",
      "120 Train Loss 0.027471032 Test MSE 0.001072448729136395 Test RE 0.023727716082744457\n",
      "121 Train Loss 0.027094034 Test MSE 0.0010402335994822212 Test RE 0.023368622141900816\n",
      "122 Train Loss 0.026604796 Test MSE 0.0014429442806915044 Test RE 0.027522789477459064\n",
      "123 Train Loss 0.025637148 Test MSE 0.001580826393585882 Test RE 0.028807777682446262\n",
      "124 Train Loss 0.025054106 Test MSE 0.0015073610895131961 Test RE 0.0281304265678558\n",
      "125 Train Loss 0.024672924 Test MSE 0.0012076446117743585 Test RE 0.02517892832962061\n",
      "126 Train Loss 0.023371056 Test MSE 0.0009376086805428725 Test RE 0.022185972859943788\n",
      "127 Train Loss 0.022193087 Test MSE 0.0005691038675719756 Test RE 0.017284763281675716\n",
      "128 Train Loss 0.021385452 Test MSE 0.000541730540931277 Test RE 0.016863950851168333\n",
      "129 Train Loss 0.020894684 Test MSE 0.00043648937614094546 Test RE 0.01513751221208914\n",
      "130 Train Loss 0.020138342 Test MSE 0.0004490806011563056 Test RE 0.015354292699303213\n",
      "131 Train Loss 0.0193939 Test MSE 0.0004477373525848146 Test RE 0.015331312328502085\n",
      "132 Train Loss 0.01897978 Test MSE 0.00034784396037671194 Test RE 0.013513252792650768\n",
      "133 Train Loss 0.018809494 Test MSE 0.00033935303599458717 Test RE 0.013347303538426435\n",
      "134 Train Loss 0.018443635 Test MSE 0.00032105448419746005 Test RE 0.012982461331402892\n",
      "135 Train Loss 0.017811373 Test MSE 0.0003318476039449248 Test RE 0.013198877883265467\n",
      "136 Train Loss 0.016994944 Test MSE 0.000329195702679503 Test RE 0.013146033852349817\n",
      "137 Train Loss 0.016572678 Test MSE 0.00028735392057223374 Test RE 0.01228220186823117\n",
      "138 Train Loss 0.016306218 Test MSE 0.00029222665788501966 Test RE 0.01238590039691513\n",
      "139 Train Loss 0.016105745 Test MSE 0.00031236397626682565 Test RE 0.012805547131996702\n",
      "140 Train Loss 0.015673388 Test MSE 0.00032375206781187494 Test RE 0.01303688825837112\n",
      "141 Train Loss 0.0150475 Test MSE 0.0003438750802531209 Test RE 0.013435938894042224\n",
      "142 Train Loss 0.014661714 Test MSE 0.00040593615497003233 Test RE 0.014598106729354531\n",
      "143 Train Loss 0.014348696 Test MSE 0.00034892346778042486 Test RE 0.013534205227800678\n",
      "144 Train Loss 0.013994312 Test MSE 0.00036510324524439264 Test RE 0.013844443850749427\n",
      "145 Train Loss 0.013680075 Test MSE 0.00034660055644683725 Test RE 0.013489078915934753\n",
      "146 Train Loss 0.013298889 Test MSE 0.00030531241720049943 Test RE 0.012660180612706198\n",
      "147 Train Loss 0.012808615 Test MSE 0.00030328233190011827 Test RE 0.012618020335288355\n",
      "148 Train Loss 0.012492295 Test MSE 0.0002775371464604417 Test RE 0.01207058245267598\n",
      "149 Train Loss 0.012270513 Test MSE 0.0002648682943255516 Test RE 0.011791869251033767\n",
      "150 Train Loss 0.012026405 Test MSE 0.0002645053407939228 Test RE 0.011783787181772388\n",
      "151 Train Loss 0.011847898 Test MSE 0.00025762740329078127 Test RE 0.011629571033883937\n",
      "152 Train Loss 0.011547386 Test MSE 0.0002578229910361309 Test RE 0.011633984714260803\n",
      "153 Train Loss 0.011197334 Test MSE 0.00027759133090729743 Test RE 0.012071760683990995\n",
      "154 Train Loss 0.011030077 Test MSE 0.00029980135366475876 Test RE 0.012545398537445348\n",
      "155 Train Loss 0.010811639 Test MSE 0.00028208566222135035 Test RE 0.012169091984867946\n",
      "156 Train Loss 0.010620438 Test MSE 0.00028958077952843757 Test RE 0.012329700692422068\n",
      "157 Train Loss 0.010400405 Test MSE 0.0002790785045300179 Test RE 0.012104054241256103\n",
      "158 Train Loss 0.010019777 Test MSE 0.00027502009459548754 Test RE 0.012015722260640287\n",
      "159 Train Loss 0.009778369 Test MSE 0.00027254299374752163 Test RE 0.011961487167959218\n",
      "160 Train Loss 0.009644483 Test MSE 0.0002831815814769288 Test RE 0.012192707885988488\n",
      "161 Train Loss 0.009492784 Test MSE 0.0003238000752375057 Test RE 0.013037854807014124\n",
      "162 Train Loss 0.009382149 Test MSE 0.0003370123207106586 Test RE 0.013301191827835875\n",
      "163 Train Loss 0.009195983 Test MSE 0.0003202426191026959 Test RE 0.012966036270540294\n",
      "164 Train Loss 0.009053885 Test MSE 0.0003212316780944525 Test RE 0.012986043426826145\n",
      "165 Train Loss 0.008925572 Test MSE 0.00031487119563656705 Test RE 0.01285683689235747\n",
      "166 Train Loss 0.008811307 Test MSE 0.00029871950157347315 Test RE 0.012522742649282142\n",
      "167 Train Loss 0.008695271 Test MSE 0.00027769929244660454 Test RE 0.012074107946001366\n",
      "168 Train Loss 0.008553145 Test MSE 0.00028772139471031023 Test RE 0.012290052725987885\n",
      "169 Train Loss 0.0084692435 Test MSE 0.00029245763290510743 Test RE 0.012390794318192767\n",
      "170 Train Loss 0.008343386 Test MSE 0.0002946129630425658 Test RE 0.012436368831418156\n",
      "171 Train Loss 0.008199188 Test MSE 0.0002896765658676618 Test RE 0.012331739707663601\n",
      "172 Train Loss 0.008044268 Test MSE 0.0002655452295682922 Test RE 0.011806928128133946\n",
      "173 Train Loss 0.0079212 Test MSE 0.00027210607682483457 Test RE 0.011951895520951163\n",
      "174 Train Loss 0.007847363 Test MSE 0.00027351209750259476 Test RE 0.011982734523580577\n",
      "175 Train Loss 0.0077984673 Test MSE 0.00028254327632519093 Test RE 0.012178958653437464\n",
      "176 Train Loss 0.0077396897 Test MSE 0.0002743712717402012 Test RE 0.012001540244664795\n",
      "177 Train Loss 0.007676336 Test MSE 0.00026669199803140833 Test RE 0.01183239502554243\n",
      "178 Train Loss 0.0075881598 Test MSE 0.00029926495755226793 Test RE 0.012534170576683603\n",
      "179 Train Loss 0.007494538 Test MSE 0.0002934734122353054 Test RE 0.012412293847380258\n",
      "180 Train Loss 0.0073485756 Test MSE 0.0003028908731733689 Test RE 0.01260987441222263\n",
      "181 Train Loss 0.007136514 Test MSE 0.0002972324403814969 Test RE 0.012491533909785217\n",
      "182 Train Loss 0.0070306524 Test MSE 0.0002856520281274021 Test RE 0.012245776353818868\n",
      "183 Train Loss 0.0069231456 Test MSE 0.0002625152659334571 Test RE 0.011739374289221548\n",
      "184 Train Loss 0.0068721958 Test MSE 0.0002590833173826336 Test RE 0.011662385482732728\n",
      "185 Train Loss 0.00682719 Test MSE 0.00025055694807567274 Test RE 0.011468876941447966\n",
      "186 Train Loss 0.0067611462 Test MSE 0.0002485664322120952 Test RE 0.01142322962832111\n",
      "187 Train Loss 0.0066914335 Test MSE 0.00023878880959813704 Test RE 0.011196303254120939\n",
      "188 Train Loss 0.006639327 Test MSE 0.00024187053602663515 Test RE 0.011268319468565928\n",
      "189 Train Loss 0.006556515 Test MSE 0.00026316089392207614 Test RE 0.01175380128684074\n",
      "190 Train Loss 0.0064668935 Test MSE 0.00024977399671311917 Test RE 0.011450943695493331\n",
      "191 Train Loss 0.006384413 Test MSE 0.0002530071789745457 Test RE 0.011524818372924824\n",
      "192 Train Loss 0.006325072 Test MSE 0.0002549133149666417 Test RE 0.011568150444122774\n",
      "193 Train Loss 0.0062430543 Test MSE 0.00027723677754517314 Test RE 0.01206404889616202\n",
      "194 Train Loss 0.0061464366 Test MSE 0.0002957290814197003 Test RE 0.01245990367224085\n",
      "195 Train Loss 0.0060722195 Test MSE 0.0003042146066878104 Test RE 0.012637399037550644\n",
      "196 Train Loss 0.0060055507 Test MSE 0.0003160030311753213 Test RE 0.012879923747507578\n",
      "197 Train Loss 0.0059531042 Test MSE 0.0003113501260928172 Test RE 0.01278474854594094\n",
      "198 Train Loss 0.0059004263 Test MSE 0.00030727001601896735 Test RE 0.01270070296511558\n",
      "199 Train Loss 0.005814055 Test MSE 0.000295861589107927 Test RE 0.012462694821693487\n",
      "200 Train Loss 0.005769124 Test MSE 0.00029219136324028 Test RE 0.012385152400209433\n",
      "201 Train Loss 0.0057065133 Test MSE 0.0002814471252156813 Test RE 0.012155311032987776\n",
      "202 Train Loss 0.0056214575 Test MSE 0.0003054528213420779 Test RE 0.012663091299232999\n",
      "203 Train Loss 0.005496703 Test MSE 0.00029455880886147074 Test RE 0.01243522578544576\n",
      "204 Train Loss 0.005381959 Test MSE 0.0002900045760768736 Test RE 0.012338719547582366\n",
      "205 Train Loss 0.0052971216 Test MSE 0.0002611763497041082 Test RE 0.011709398638475964\n",
      "206 Train Loss 0.005228691 Test MSE 0.00024745432952951964 Test RE 0.011397646838457358\n",
      "207 Train Loss 0.005169213 Test MSE 0.000256212837983523 Test RE 0.011597599606399334\n",
      "208 Train Loss 0.005127183 Test MSE 0.0002596337555860905 Test RE 0.011674767631807609\n",
      "209 Train Loss 0.005093817 Test MSE 0.0002604784422146544 Test RE 0.01169374342387445\n",
      "210 Train Loss 0.005065596 Test MSE 0.0002553904743778503 Test RE 0.011578972301715626\n",
      "211 Train Loss 0.005029261 Test MSE 0.0002586893792438081 Test RE 0.011653515737262646\n",
      "212 Train Loss 0.0049898205 Test MSE 0.00026807673997991676 Test RE 0.01186307386148357\n",
      "213 Train Loss 0.004954111 Test MSE 0.000261785393086783 Test RE 0.011723043401979664\n",
      "214 Train Loss 0.00492219 Test MSE 0.00026294508654482144 Test RE 0.011748980894959148\n",
      "215 Train Loss 0.0048841005 Test MSE 0.0002742078645980051 Test RE 0.01199796583713618\n",
      "216 Train Loss 0.0048559816 Test MSE 0.0002723080739757908 Test RE 0.011956330925308005\n",
      "217 Train Loss 0.0048234826 Test MSE 0.0002772947469259338 Test RE 0.012065310108502298\n",
      "218 Train Loss 0.0047925278 Test MSE 0.0002707150835367174 Test RE 0.011921307619931047\n",
      "219 Train Loss 0.004759946 Test MSE 0.00026107472165541286 Test RE 0.01170712025622311\n",
      "220 Train Loss 0.004699279 Test MSE 0.0002597808990815336 Test RE 0.011678075412009863\n",
      "221 Train Loss 0.004661003 Test MSE 0.0002586975945698131 Test RE 0.01165370077901249\n",
      "222 Train Loss 0.0046246313 Test MSE 0.0002568832890145969 Test RE 0.011612763839695624\n",
      "223 Train Loss 0.004571656 Test MSE 0.00025456979598158653 Test RE 0.011560353246486682\n",
      "224 Train Loss 0.0045361887 Test MSE 0.0002560487047009755 Test RE 0.011593884224559358\n",
      "225 Train Loss 0.004498304 Test MSE 0.00025735290640209967 Test RE 0.011623373844054633\n",
      "226 Train Loss 0.004472839 Test MSE 0.0002601848160857235 Test RE 0.011687150638757623\n",
      "227 Train Loss 0.0044530868 Test MSE 0.0002603921045337434 Test RE 0.011691805270462268\n",
      "228 Train Loss 0.004436803 Test MSE 0.00026374800415544043 Test RE 0.011766905309068364\n",
      "229 Train Loss 0.004407086 Test MSE 0.0002627284312436803 Test RE 0.011744139573175114\n",
      "230 Train Loss 0.004350004 Test MSE 0.0002605926021863378 Test RE 0.01169630565353688\n",
      "231 Train Loss 0.004319591 Test MSE 0.0002694458273240753 Test RE 0.011893328072151575\n",
      "232 Train Loss 0.004299486 Test MSE 0.00027263191501663436 Test RE 0.011963438316771713\n",
      "233 Train Loss 0.0042779185 Test MSE 0.000274681943345925 Test RE 0.01200833301654134\n",
      "234 Train Loss 0.004245534 Test MSE 0.0002655923065285738 Test RE 0.011807974672360087\n",
      "235 Train Loss 0.0041938056 Test MSE 0.0002799224746457739 Test RE 0.0121223425514011\n",
      "236 Train Loss 0.00414788 Test MSE 0.00029214432818637254 Test RE 0.012384155519690031\n",
      "237 Train Loss 0.004072206 Test MSE 0.0003020881863448606 Test RE 0.012593154702594674\n",
      "238 Train Loss 0.0039942525 Test MSE 0.0003012054650557864 Test RE 0.01257474223441565\n",
      "239 Train Loss 0.0039267386 Test MSE 0.00031007422528646605 Test RE 0.01275852595038156\n",
      "240 Train Loss 0.0038456367 Test MSE 0.0003042659478750322 Test RE 0.012638465376384028\n",
      "241 Train Loss 0.0037961141 Test MSE 0.00030711513531889216 Test RE 0.01269750164118709\n",
      "242 Train Loss 0.0037484453 Test MSE 0.00030578291901615516 Test RE 0.01266993184542081\n",
      "243 Train Loss 0.0037214453 Test MSE 0.00031322463006993326 Test RE 0.012823176504302987\n",
      "244 Train Loss 0.003702841 Test MSE 0.0003140017496965552 Test RE 0.012839073991095564\n",
      "245 Train Loss 0.0036875682 Test MSE 0.00031248461912562585 Test RE 0.01280801980617015\n",
      "246 Train Loss 0.0036706668 Test MSE 0.0003141555519334906 Test RE 0.012842217980826815\n",
      "247 Train Loss 0.0036507712 Test MSE 0.00030831057911664375 Test RE 0.012722190113573685\n",
      "248 Train Loss 0.0036224916 Test MSE 0.00029998492055888237 Test RE 0.012549238692615051\n",
      "249 Train Loss 0.003596809 Test MSE 0.00029084569292667055 Test RE 0.012356599938905964\n",
      "250 Train Loss 0.0035658546 Test MSE 0.0002843728728387204 Test RE 0.01221832717856415\n",
      "251 Train Loss 0.0035413478 Test MSE 0.00029472910042496357 Test RE 0.012438819818292809\n",
      "252 Train Loss 0.003514963 Test MSE 0.0002824742519447274 Test RE 0.012177470923071611\n",
      "253 Train Loss 0.0034734576 Test MSE 0.00028722531878729723 Test RE 0.012279453184930402\n",
      "254 Train Loss 0.003446833 Test MSE 0.0002903365290476511 Test RE 0.012345779269280776\n",
      "255 Train Loss 0.0034042906 Test MSE 0.00029748709281632817 Test RE 0.012496883794350464\n",
      "256 Train Loss 0.0033856079 Test MSE 0.0002973798510520943 Test RE 0.012494631077003255\n",
      "257 Train Loss 0.0033729076 Test MSE 0.00030708388753428173 Test RE 0.012696855663760907\n",
      "258 Train Loss 0.003362639 Test MSE 0.0003089420141216365 Test RE 0.01273521128088685\n",
      "259 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "260 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "261 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "262 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "263 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "264 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "265 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "266 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "267 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "268 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "269 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "270 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "271 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "272 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "273 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "274 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "275 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "276 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "277 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "278 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "279 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "280 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "281 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "282 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "283 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "284 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "285 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "286 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "287 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "288 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "289 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "290 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "291 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "292 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "293 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "294 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "295 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "296 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "297 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "298 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "299 Train Loss 0.0033516297 Test MSE 0.000305578421019481 Test RE 0.012665694510934643\n",
      "Training time: 227.41\n",
      "KG_atanh_medium\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 26601.473 Test MSE 12.59360340197546 Test RE 2.5712403444235874\n",
      "1 Train Loss 9912.251 Test MSE 10.764178644498847 Test RE 2.377158369869959\n",
      "2 Train Loss 7630.888 Test MSE 11.33705156096986 Test RE 2.439594966099266\n",
      "3 Train Loss 5458.1514 Test MSE 11.159615071177603 Test RE 2.420428594770449\n",
      "4 Train Loss 2557.635 Test MSE 14.060720261633032 Test RE 2.71688622378851\n",
      "5 Train Loss 1238.9045 Test MSE 15.411404939038235 Test RE 2.8443876449887804\n",
      "6 Train Loss 550.3927 Test MSE 16.412069499691352 Test RE 2.9352786881032196\n",
      "7 Train Loss 247.87344 Test MSE 16.38200820004714 Test RE 2.932589242545298\n",
      "8 Train Loss 120.2993 Test MSE 16.868912194720227 Test RE 2.9758511648802393\n",
      "9 Train Loss 80.23063 Test MSE 17.41199892499536 Test RE 3.0233747624041003\n",
      "10 Train Loss 55.230427 Test MSE 17.379598998308342 Test RE 3.0205605326100606\n",
      "11 Train Loss 40.37112 Test MSE 17.281731991067673 Test RE 3.0120439219710233\n",
      "12 Train Loss 33.900757 Test MSE 17.228389994322356 Test RE 3.007391824335618\n",
      "13 Train Loss 28.05205 Test MSE 17.128885157373922 Test RE 2.998694454034681\n",
      "14 Train Loss 25.375444 Test MSE 16.879830894041294 Test RE 2.9768140950205066\n",
      "15 Train Loss 23.046625 Test MSE 16.853372975364774 Test RE 2.9744802093103075\n",
      "16 Train Loss 21.120066 Test MSE 16.770294524473343 Test RE 2.967139824125406\n",
      "17 Train Loss 20.039677 Test MSE 16.70739191637738 Test RE 2.9615699703285228\n",
      "18 Train Loss 19.2251 Test MSE 16.54113792210856 Test RE 2.9467979501611845\n",
      "19 Train Loss 18.899374 Test MSE 16.48084298910742 Test RE 2.9414222862735864\n",
      "20 Train Loss 18.56247 Test MSE 16.438936418474253 Test RE 2.93768026353666\n",
      "21 Train Loss 18.282438 Test MSE 16.356684186734963 Test RE 2.930321704561075\n",
      "22 Train Loss 17.99243 Test MSE 16.236973996754077 Test RE 2.9195788927294752\n",
      "23 Train Loss 17.748022 Test MSE 16.214874648165775 Test RE 2.917591368432512\n",
      "24 Train Loss 17.44182 Test MSE 16.084300597787422 Test RE 2.9058203316540396\n",
      "25 Train Loss 17.208174 Test MSE 15.87883015350585 Test RE 2.8872003341899592\n",
      "26 Train Loss 16.81191 Test MSE 15.62102666143513 Test RE 2.863666601720048\n",
      "27 Train Loss 16.507584 Test MSE 15.263915667489426 Test RE 2.8307443333231017\n",
      "28 Train Loss 16.126057 Test MSE 14.692622793178922 Test RE 2.7772650708605635\n",
      "29 Train Loss 15.578988 Test MSE 14.008195816586108 Test RE 2.7118069513083833\n",
      "30 Train Loss 14.587224 Test MSE 13.02239183418238 Test RE 2.6146469001221666\n",
      "31 Train Loss 13.589379 Test MSE 11.865807060315781 Test RE 2.495837517953428\n",
      "32 Train Loss 12.6326475 Test MSE 11.384020760435458 Test RE 2.4446433415709854\n",
      "33 Train Loss 11.997119 Test MSE 10.889300454636405 Test RE 2.390934386507345\n",
      "34 Train Loss 11.105187 Test MSE 9.912781301846442 Test RE 2.2812108579158243\n",
      "35 Train Loss 10.293416 Test MSE 9.417338218522818 Test RE 2.2234724450979244\n",
      "36 Train Loss 9.325964 Test MSE 8.078243467278428 Test RE 2.059330902889007\n",
      "37 Train Loss 8.716888 Test MSE 7.359024027889076 Test RE 1.9655214066546047\n",
      "38 Train Loss 7.9933763 Test MSE 6.570468262680363 Test RE 1.8572305915752139\n",
      "39 Train Loss 7.233499 Test MSE 5.690722842845825 Test RE 1.7284283652866648\n",
      "40 Train Loss 6.3921895 Test MSE 5.0859489056372675 Test RE 1.634006064597542\n",
      "41 Train Loss 5.611303 Test MSE 4.390562341362762 Test RE 1.5181956463135915\n",
      "42 Train Loss 4.892835 Test MSE 4.295200488354018 Test RE 1.5016177311805852\n",
      "43 Train Loss 4.4306774 Test MSE 4.086395917439129 Test RE 1.4646635998093354\n",
      "44 Train Loss 3.9556162 Test MSE 3.671724451667974 Test RE 1.388361968452143\n",
      "45 Train Loss 3.5315 Test MSE 3.3845836072374893 Test RE 1.3329697414094757\n",
      "46 Train Loss 3.2245855 Test MSE 3.0700421879992983 Test RE 1.2695208543742103\n",
      "47 Train Loss 2.84985 Test MSE 2.443665886828857 Test RE 1.1326313564947335\n",
      "48 Train Loss 2.4398623 Test MSE 2.002991719105591 Test RE 1.0254328936649741\n",
      "49 Train Loss 2.1002672 Test MSE 1.7007479558206864 Test RE 0.944903910808227\n",
      "50 Train Loss 1.9030315 Test MSE 1.41279872111677 Test RE 0.861207521598444\n",
      "51 Train Loss 1.6671242 Test MSE 1.0960923137021006 Test RE 0.7585622633439797\n",
      "52 Train Loss 1.5054929 Test MSE 0.9385574842045649 Test RE 0.7019369531337223\n",
      "53 Train Loss 1.3029429 Test MSE 0.6222969538083319 Test RE 0.5715661561032519\n",
      "54 Train Loss 1.1262287 Test MSE 0.5653749590248698 Test RE 0.5447985616306482\n",
      "55 Train Loss 0.99965876 Test MSE 0.5414165720020209 Test RE 0.5331303909171305\n",
      "56 Train Loss 0.83152664 Test MSE 0.42871858809906643 Test RE 0.47440998871642154\n",
      "57 Train Loss 0.74493235 Test MSE 0.3827007866917421 Test RE 0.44822630995844864\n",
      "58 Train Loss 0.6173021 Test MSE 0.34728921834283427 Test RE 0.4269856877495559\n",
      "59 Train Loss 0.55165005 Test MSE 0.2414225075777146 Test RE 0.3560053675028026\n",
      "60 Train Loss 0.5046773 Test MSE 0.23017545164001857 Test RE 0.3476139283557902\n",
      "61 Train Loss 0.45256436 Test MSE 0.23549530178906353 Test RE 0.35160803514994193\n",
      "62 Train Loss 0.40361676 Test MSE 0.19138894046596616 Test RE 0.31697578549583144\n",
      "63 Train Loss 0.36272752 Test MSE 0.1834028156763298 Test RE 0.3102920631596835\n",
      "64 Train Loss 0.325984 Test MSE 0.1718610502105838 Test RE 0.3003698919540535\n",
      "65 Train Loss 0.28530994 Test MSE 0.12144103412622612 Test RE 0.2524936125497731\n",
      "66 Train Loss 0.24419558 Test MSE 0.09322877939514995 Test RE 0.22122931099764126\n",
      "67 Train Loss 0.2219011 Test MSE 0.0880850455417882 Test RE 0.21503975632894076\n",
      "68 Train Loss 0.19753273 Test MSE 0.09371089985750185 Test RE 0.2218006026110918\n",
      "69 Train Loss 0.18300055 Test MSE 0.08497461795029466 Test RE 0.21120893076662245\n",
      "70 Train Loss 0.1636005 Test MSE 0.0705941900253954 Test RE 0.19250949177200047\n",
      "71 Train Loss 0.15284693 Test MSE 0.07067274850608811 Test RE 0.19261657599642196\n",
      "72 Train Loss 0.14045338 Test MSE 0.05552568606489405 Test RE 0.17073188462069808\n",
      "73 Train Loss 0.12712573 Test MSE 0.05389209592396178 Test RE 0.16820163177720046\n",
      "74 Train Loss 0.1140182 Test MSE 0.05519223429918327 Test RE 0.1702184593700362\n",
      "75 Train Loss 0.10364725 Test MSE 0.041276580723713756 Test RE 0.14720397061385151\n",
      "76 Train Loss 0.09448023 Test MSE 0.033960904678051795 Test RE 0.13352337248289065\n",
      "77 Train Loss 0.09129522 Test MSE 0.03651179223094684 Test RE 0.1384472211965544\n",
      "78 Train Loss 0.0882986 Test MSE 0.032559919750254185 Test RE 0.13074025586312712\n",
      "79 Train Loss 0.08206121 Test MSE 0.02088306956714697 Test RE 0.10470437657031004\n",
      "80 Train Loss 0.07927051 Test MSE 0.018851240708446446 Test RE 0.09948042616909435\n",
      "81 Train Loss 0.075794384 Test MSE 0.01888250296527595 Test RE 0.09956287947750336\n",
      "82 Train Loss 0.0733419 Test MSE 0.015758998150012804 Test RE 0.09095612920431363\n",
      "83 Train Loss 0.070963584 Test MSE 0.015192514694275476 Test RE 0.08930638296571894\n",
      "84 Train Loss 0.06718149 Test MSE 0.018632788322238143 Test RE 0.0989023458634545\n",
      "85 Train Loss 0.061109647 Test MSE 0.014300995312218812 Test RE 0.08664645516711778\n",
      "86 Train Loss 0.0591588 Test MSE 0.014775298695397334 Test RE 0.08807158297146517\n",
      "87 Train Loss 0.055694908 Test MSE 0.012560429092693448 Test RE 0.08120259452495986\n",
      "88 Train Loss 0.05320608 Test MSE 0.011106364282992278 Test RE 0.07635783824488468\n",
      "89 Train Loss 0.05068429 Test MSE 0.007851186678746125 Test RE 0.06420004308550382\n",
      "90 Train Loss 0.047060005 Test MSE 0.0069019028378781155 Test RE 0.06019384536258405\n",
      "91 Train Loss 0.045185104 Test MSE 0.007761557662878348 Test RE 0.06383253790733362\n",
      "92 Train Loss 0.041831683 Test MSE 0.009191350859722182 Test RE 0.06946360844586852\n",
      "93 Train Loss 0.03866134 Test MSE 0.00693067452930873 Test RE 0.06031917874049014\n",
      "94 Train Loss 0.036947157 Test MSE 0.00586300106402406 Test RE 0.0554788760573901\n",
      "95 Train Loss 0.036228757 Test MSE 0.005266095111742911 Test RE 0.05257896307394523\n",
      "96 Train Loss 0.033723652 Test MSE 0.005252497355807445 Test RE 0.052511036268921174\n",
      "97 Train Loss 0.031511176 Test MSE 0.005717073282314364 Test RE 0.05478410199310954\n",
      "98 Train Loss 0.029848862 Test MSE 0.0050390369850222575 Test RE 0.05143295072235381\n",
      "99 Train Loss 0.02899591 Test MSE 0.005440851554139774 Test RE 0.05344426467763165\n",
      "100 Train Loss 0.027381942 Test MSE 0.003874149688791464 Test RE 0.04509785294249776\n",
      "101 Train Loss 0.026293637 Test MSE 0.003581354615409099 Test RE 0.043360205369827\n",
      "102 Train Loss 0.025578279 Test MSE 0.003167196108435251 Test RE 0.0407760492575968\n",
      "103 Train Loss 0.024515864 Test MSE 0.00225407793346806 Test RE 0.034399500100644166\n",
      "104 Train Loss 0.023674276 Test MSE 0.0016833293733554675 Test RE 0.029727077716096968\n",
      "105 Train Loss 0.022725282 Test MSE 0.001324454243067679 Test RE 0.02636854383362845\n",
      "106 Train Loss 0.02208499 Test MSE 0.0013998444173867225 Test RE 0.02710862890533852\n",
      "107 Train Loss 0.021243803 Test MSE 0.0014494492038352453 Test RE 0.027584757327234616\n",
      "108 Train Loss 0.020671431 Test MSE 0.001494739231698156 Test RE 0.028012404203004385\n",
      "109 Train Loss 0.020414926 Test MSE 0.0014850767380528887 Test RE 0.027921716638170543\n",
      "110 Train Loss 0.019815112 Test MSE 0.001314811299125896 Test RE 0.02627237784677451\n",
      "111 Train Loss 0.019461697 Test MSE 0.0011394388433763527 Test RE 0.024457562829521065\n",
      "112 Train Loss 0.018957289 Test MSE 0.001507508645139915 Test RE 0.028131803378354414\n",
      "113 Train Loss 0.018527523 Test MSE 0.0016662638038655948 Test RE 0.029576007506105173\n",
      "114 Train Loss 0.018217321 Test MSE 0.001712331200482462 Test RE 0.029982065781133476\n",
      "115 Train Loss 0.018028585 Test MSE 0.0015969158018161976 Test RE 0.028954007117499216\n",
      "116 Train Loss 0.017633973 Test MSE 0.0012769495988564535 Test RE 0.025891341063328743\n",
      "117 Train Loss 0.017176189 Test MSE 0.0010473971660232761 Test RE 0.023448948072214232\n",
      "118 Train Loss 0.016989663 Test MSE 0.0009813255163318732 Test RE 0.02269730080678921\n",
      "119 Train Loss 0.016468376 Test MSE 0.0009986278803795923 Test RE 0.022896521651415123\n",
      "120 Train Loss 0.015346936 Test MSE 0.001096352466748177 Test RE 0.023990691531951717\n",
      "121 Train Loss 0.0147352945 Test MSE 0.0009770691189429006 Test RE 0.022648023724073648\n",
      "122 Train Loss 0.014529086 Test MSE 0.0011730540293400852 Test RE 0.024815708296374347\n",
      "123 Train Loss 0.014357346 Test MSE 0.0011169364301741342 Test RE 0.024214856278660445\n",
      "124 Train Loss 0.01408291 Test MSE 0.00099534763364195 Test RE 0.022858886001635572\n",
      "125 Train Loss 0.013437709 Test MSE 0.0005215266185797029 Test RE 0.01654649100107747\n",
      "126 Train Loss 0.012990513 Test MSE 0.0004236563963926588 Test RE 0.014913327375741693\n",
      "127 Train Loss 0.012679094 Test MSE 0.00040869713625776063 Test RE 0.014647667229397462\n",
      "128 Train Loss 0.012414321 Test MSE 0.000357755118416533 Test RE 0.013704417968335053\n",
      "129 Train Loss 0.012205951 Test MSE 0.00034246504898027564 Test RE 0.013408364120926143\n",
      "130 Train Loss 0.011982848 Test MSE 0.0002943623836364815 Test RE 0.012431078906634255\n",
      "131 Train Loss 0.011785452 Test MSE 0.0002835250732720154 Test RE 0.012200100361611902\n",
      "132 Train Loss 0.011370886 Test MSE 0.0003373860520816308 Test RE 0.013308564993358488\n",
      "133 Train Loss 0.0109565705 Test MSE 0.00031110676604380723 Test RE 0.012779751109005724\n",
      "134 Train Loss 0.01076859 Test MSE 0.0003591624828059641 Test RE 0.013731347252888097\n",
      "135 Train Loss 0.010699643 Test MSE 0.0003615101086678132 Test RE 0.013776150875283959\n",
      "136 Train Loss 0.010611891 Test MSE 0.0003378358196985174 Test RE 0.01331743282881863\n",
      "137 Train Loss 0.010350863 Test MSE 0.0002994368755456766 Test RE 0.012537770296624619\n",
      "138 Train Loss 0.009914565 Test MSE 0.00020641943092680973 Test RE 0.010409813667925623\n",
      "139 Train Loss 0.009670142 Test MSE 0.00018180140951314685 Test RE 0.009769363982476829\n",
      "140 Train Loss 0.009438221 Test MSE 0.00018180119674102702 Test RE 0.009769358265665015\n",
      "141 Train Loss 0.009259902 Test MSE 0.0001737263308442818 Test RE 0.009549936663768745\n",
      "142 Train Loss 0.00906578 Test MSE 0.00019279537741560455 Test RE 0.010060416852211044\n",
      "143 Train Loss 0.008950289 Test MSE 0.00018088890843133483 Test RE 0.009744815852147187\n",
      "144 Train Loss 0.008688755 Test MSE 0.00017398398756725926 Test RE 0.009557015883444616\n",
      "145 Train Loss 0.00836541 Test MSE 0.00015207099363823812 Test RE 0.008934923932170708\n",
      "146 Train Loss 0.008102422 Test MSE 0.0001334849641195998 Test RE 0.00837112529314424\n",
      "147 Train Loss 0.007869913 Test MSE 0.0001360637404901708 Test RE 0.008451598757194593\n",
      "148 Train Loss 0.007703255 Test MSE 0.00016993382702804366 Test RE 0.009445122321045819\n",
      "149 Train Loss 0.007511643 Test MSE 0.00012317547837459544 Test RE 0.008041365391299758\n",
      "150 Train Loss 0.0074330494 Test MSE 0.0001175898935116956 Test RE 0.007856926061491975\n",
      "151 Train Loss 0.007329339 Test MSE 0.00011549605393747842 Test RE 0.007786660518127333\n",
      "152 Train Loss 0.0072210943 Test MSE 0.00010823227529053241 Test RE 0.007537825196300005\n",
      "153 Train Loss 0.00704201 Test MSE 9.344400812332938e-05 Test RE 0.0070039558030384474\n",
      "154 Train Loss 0.006920621 Test MSE 8.075151446215853e-05 Test RE 0.006510929692541313\n",
      "155 Train Loss 0.006765797 Test MSE 9.123210891400265e-05 Test RE 0.0069205645645324665\n",
      "156 Train Loss 0.006366397 Test MSE 8.278899211737902e-05 Test RE 0.006592558092115528\n",
      "157 Train Loss 0.006145346 Test MSE 4.506828475251475e-05 Test RE 0.004864107700465533\n",
      "158 Train Loss 0.0058797034 Test MSE 3.897437525928848e-05 Test RE 0.004523319334069448\n",
      "159 Train Loss 0.0057300925 Test MSE 3.88460230332769e-05 Test RE 0.004515864988912723\n",
      "160 Train Loss 0.0056532375 Test MSE 4.877939169779068e-05 Test RE 0.005060411776256841\n",
      "161 Train Loss 0.0055695698 Test MSE 5.79036480344273e-05 Test RE 0.0055134143289729595\n",
      "162 Train Loss 0.0055188905 Test MSE 6.275112833753499e-05 Test RE 0.0057395578466412555\n",
      "163 Train Loss 0.005477217 Test MSE 6.817458447211165e-05 Test RE 0.005982447794223082\n",
      "164 Train Loss 0.0054139257 Test MSE 6.007740772361318e-05 Test RE 0.00561595035759119\n",
      "165 Train Loss 0.0053240904 Test MSE 7.228658173278215e-05 Test RE 0.0061602241058791194\n",
      "166 Train Loss 0.005248502 Test MSE 7.310497206861784e-05 Test RE 0.006194997356703591\n",
      "167 Train Loss 0.0050328593 Test MSE 5.856101693700532e-05 Test RE 0.005544622366823891\n",
      "168 Train Loss 0.004956884 Test MSE 6.423927721646718e-05 Test RE 0.005807216142000858\n",
      "169 Train Loss 0.0048712725 Test MSE 6.89295195002603e-05 Test RE 0.006015480082876495\n",
      "170 Train Loss 0.0046805018 Test MSE 7.554661539109961e-05 Test RE 0.0062976014681462265\n",
      "171 Train Loss 0.0045995703 Test MSE 7.240092478614816e-05 Test RE 0.006165094307858144\n",
      "172 Train Loss 0.0045441953 Test MSE 8.931833885450504e-05 Test RE 0.00684759374223586\n",
      "173 Train Loss 0.0044962736 Test MSE 8.107884469082724e-05 Test RE 0.006524112533322548\n",
      "174 Train Loss 0.0044396454 Test MSE 8.78714636478117e-05 Test RE 0.006791904923939072\n",
      "175 Train Loss 0.0043682214 Test MSE 6.421332759378838e-05 Test RE 0.0058060431035131905\n",
      "176 Train Loss 0.0043264143 Test MSE 4.18156578686288e-05 Test RE 0.0046852970926893394\n",
      "177 Train Loss 0.0042638658 Test MSE 3.250775690757212e-05 Test RE 0.004131056828715069\n",
      "178 Train Loss 0.004213227 Test MSE 3.2307525163085694e-05 Test RE 0.004118314540874272\n",
      "179 Train Loss 0.004165586 Test MSE 2.932518630730217e-05 Test RE 0.003923630100589347\n",
      "180 Train Loss 0.004123939 Test MSE 2.493709567545526e-05 Test RE 0.0036181836218809643\n",
      "181 Train Loss 0.004043412 Test MSE 2.7994563671601297e-05 Test RE 0.0038335798980757597\n",
      "182 Train Loss 0.0039941194 Test MSE 2.838456933574629e-05 Test RE 0.003860191252889764\n",
      "183 Train Loss 0.0039090803 Test MSE 2.4777722772390088e-05 Test RE 0.003606603189302181\n",
      "184 Train Loss 0.0038577951 Test MSE 2.8199736483903525e-05 Test RE 0.003847602450471218\n",
      "185 Train Loss 0.0038314587 Test MSE 2.869187049563872e-05 Test RE 0.0038810308829389613\n",
      "186 Train Loss 0.0038088185 Test MSE 2.657444320900024e-05 Test RE 0.0037350786788939248\n",
      "187 Train Loss 0.0037831392 Test MSE 2.6384563107934647e-05 Test RE 0.0037217107875151386\n",
      "188 Train Loss 0.003719601 Test MSE 2.9640514875187486e-05 Test RE 0.0039446687476018165\n",
      "189 Train Loss 0.0036795074 Test MSE 3.098191892971148e-05 Test RE 0.004032940588718908\n",
      "190 Train Loss 0.0036334756 Test MSE 3.217389876056591e-05 Test RE 0.004109788883609567\n",
      "191 Train Loss 0.0035761646 Test MSE 3.307665604490915e-05 Test RE 0.004167047646276116\n",
      "192 Train Loss 0.0035151727 Test MSE 3.63662986656827e-05 Test RE 0.004369353859634295\n",
      "193 Train Loss 0.0034660853 Test MSE 3.651732351214749e-05 Test RE 0.004378417159136274\n",
      "194 Train Loss 0.0034187953 Test MSE 3.893581313472036e-05 Test RE 0.00452108104327241\n",
      "195 Train Loss 0.0033767035 Test MSE 4.241746925031518e-05 Test RE 0.004718892071846398\n",
      "196 Train Loss 0.0033287322 Test MSE 3.8670521189372836e-05 Test RE 0.004505652362853979\n",
      "197 Train Loss 0.0032864676 Test MSE 4.2116688803886536e-05 Test RE 0.0047021315768423465\n",
      "198 Train Loss 0.0032576346 Test MSE 4.575546551130661e-05 Test RE 0.004901050266040365\n",
      "199 Train Loss 0.0032295748 Test MSE 4.9200037019255205e-05 Test RE 0.005082183974591851\n",
      "200 Train Loss 0.0031966812 Test MSE 4.941379914645678e-05 Test RE 0.0050932124317567854\n",
      "201 Train Loss 0.003172743 Test MSE 5.299172378908016e-05 Test RE 0.005274383342949229\n",
      "202 Train Loss 0.003158062 Test MSE 5.2413598521329375e-05 Test RE 0.005245533398326795\n",
      "203 Train Loss 0.0031407059 Test MSE 5.589113453434838e-05 Test RE 0.005416754220414645\n",
      "204 Train Loss 0.003123458 Test MSE 5.63476484507507e-05 Test RE 0.005438831019972289\n",
      "205 Train Loss 0.0031030872 Test MSE 5.726620927864175e-05 Test RE 0.005482982827329517\n",
      "206 Train Loss 0.003085763 Test MSE 6.037419485424353e-05 Test RE 0.005629804886817182\n",
      "207 Train Loss 0.0030704706 Test MSE 5.914248400786177e-05 Test RE 0.005572081348644316\n",
      "208 Train Loss 0.0030571169 Test MSE 6.103053586489667e-05 Test RE 0.0056603235842053075\n",
      "209 Train Loss 0.003039419 Test MSE 5.822832605262798e-05 Test RE 0.005528850162150531\n",
      "210 Train Loss 0.0030171694 Test MSE 6.0679154454671254e-05 Test RE 0.0056440054941675494\n",
      "211 Train Loss 0.0029853985 Test MSE 7.081093045034063e-05 Test RE 0.00609702278704468\n",
      "212 Train Loss 0.002959381 Test MSE 6.717892754816932e-05 Test RE 0.005938601735503258\n",
      "213 Train Loss 0.0029328016 Test MSE 6.843758544617167e-05 Test RE 0.005993976101220376\n",
      "214 Train Loss 0.0029063511 Test MSE 8.18788574905358e-05 Test RE 0.00655622054909353\n",
      "215 Train Loss 0.0028771611 Test MSE 8.968533340564742e-05 Test RE 0.006861647146643691\n",
      "216 Train Loss 0.0028530196 Test MSE 8.60629398613772e-05 Test RE 0.0067216478564938046\n",
      "217 Train Loss 0.002841463 Test MSE 8.493762726962592e-05 Test RE 0.006677558940209212\n",
      "218 Train Loss 0.0028264169 Test MSE 9.002722076664236e-05 Test RE 0.006874713268492585\n",
      "219 Train Loss 0.0028126328 Test MSE 9.278748433827575e-05 Test RE 0.0069793080549128235\n",
      "220 Train Loss 0.0028029594 Test MSE 9.660114451178389e-05 Test RE 0.007121292159604639\n",
      "221 Train Loss 0.002794021 Test MSE 0.00010013004188492614 Test RE 0.007250197990387933\n",
      "222 Train Loss 0.002782729 Test MSE 9.004554955804226e-05 Test RE 0.006875413050023166\n",
      "223 Train Loss 0.0027701815 Test MSE 9.520789734625095e-05 Test RE 0.0070697515958765295\n",
      "224 Train Loss 0.0027624879 Test MSE 9.711645708281253e-05 Test RE 0.007140260933045226\n",
      "225 Train Loss 0.0027479604 Test MSE 9.064872349302834e-05 Test RE 0.006898402238809015\n",
      "226 Train Loss 0.002731229 Test MSE 7.962436034822672e-05 Test RE 0.006465329242094817\n",
      "227 Train Loss 0.0027142842 Test MSE 6.892053555824166e-05 Test RE 0.006015088055732662\n",
      "228 Train Loss 0.0026948147 Test MSE 6.798024622155627e-05 Test RE 0.0059739149357576245\n",
      "229 Train Loss 0.0026668725 Test MSE 6.343307698185728e-05 Test RE 0.005770660928781217\n",
      "230 Train Loss 0.0026390816 Test MSE 5.2970617558168926e-05 Test RE 0.005273332863442943\n",
      "231 Train Loss 0.0026019174 Test MSE 5.035539205081674e-05 Test RE 0.005141509687709651\n",
      "232 Train Loss 0.002565684 Test MSE 4.575651320928219e-05 Test RE 0.004901106377272004\n",
      "233 Train Loss 0.002527837 Test MSE 4.1703514662219814e-05 Test RE 0.004679010249245914\n",
      "234 Train Loss 0.0024948716 Test MSE 3.990246511664583e-05 Test RE 0.004576858975687058\n",
      "235 Train Loss 0.0024500485 Test MSE 4.120543046617588e-05 Test RE 0.004650984534561297\n",
      "236 Train Loss 0.002413136 Test MSE 3.976730014198525e-05 Test RE 0.0045691006103821975\n",
      "237 Train Loss 0.0023902413 Test MSE 4.535249057997595e-05 Test RE 0.0048794204109491495\n",
      "238 Train Loss 0.0023739515 Test MSE 4.639814450164177e-05 Test RE 0.0049353501962576376\n",
      "239 Train Loss 0.0023628941 Test MSE 4.479820794181645e-05 Test RE 0.004849511441486288\n",
      "240 Train Loss 0.0023557316 Test MSE 4.394842012909184e-05 Test RE 0.00480329545630034\n",
      "241 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "242 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "243 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "244 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "245 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "246 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "247 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "248 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "249 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "250 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "251 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "252 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "253 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "254 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "255 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "256 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "257 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "258 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "259 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "260 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "261 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "262 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "263 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "264 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "265 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "266 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "267 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "268 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "269 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "270 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "271 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "272 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "273 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "274 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "275 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "276 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "277 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "278 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "279 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "280 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "281 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "282 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "283 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "284 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "285 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "286 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "287 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "288 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "289 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "290 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "291 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "292 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "293 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "294 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "295 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "296 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "297 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "298 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "299 Train Loss 0.0023514086 Test MSE 4.592129319081204e-05 Test RE 0.004909923465537194\n",
      "Training time: 216.89\n",
      "KG_atanh_medium\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 30253.28 Test MSE 8.785731466823076 Test RE 2.1476159966690815\n",
      "1 Train Loss 11568.884 Test MSE 9.822159378172335 Test RE 2.270759585238628\n",
      "2 Train Loss 8655.057 Test MSE 12.458675335923107 Test RE 2.5574290964589066\n",
      "3 Train Loss 6610.398 Test MSE 12.68358775404409 Test RE 2.580410061693898\n",
      "4 Train Loss 2708.3792 Test MSE 15.191326405119428 Test RE 2.8240053507458676\n",
      "5 Train Loss 950.72705 Test MSE 17.085728431805506 Test RE 2.9949144225042974\n",
      "6 Train Loss 477.24893 Test MSE 16.947798417595433 Test RE 2.982801223169363\n",
      "7 Train Loss 214.78395 Test MSE 17.762056997639746 Test RE 3.053615119783548\n",
      "8 Train Loss 121.44618 Test MSE 18.310692632796155 Test RE 3.1004166030529996\n",
      "9 Train Loss 93.80985 Test MSE 18.485822822206195 Test RE 3.1152080809861507\n",
      "10 Train Loss 78.78854 Test MSE 18.318464645958358 Test RE 3.1010745225190255\n",
      "11 Train Loss 69.77164 Test MSE 18.35155349903745 Test RE 3.1038740121648787\n",
      "12 Train Loss 57.226044 Test MSE 17.77013426231493 Test RE 3.054309353962169\n",
      "13 Train Loss 51.862286 Test MSE 17.58219808411702 Test RE 3.0381153008507087\n",
      "14 Train Loss 47.765133 Test MSE 17.300733646670395 Test RE 3.0136993722889582\n",
      "15 Train Loss 42.55706 Test MSE 16.88930010216425 Test RE 2.9776489410647207\n",
      "16 Train Loss 38.505013 Test MSE 16.93841301895867 Test RE 2.9819751968421144\n",
      "17 Train Loss 35.72346 Test MSE 16.848154503551463 Test RE 2.974019665212831\n",
      "18 Train Loss 33.079575 Test MSE 16.737908321473434 Test RE 2.9642734215433952\n",
      "19 Train Loss 29.870174 Test MSE 16.665715387848035 Test RE 2.9578738511263496\n",
      "20 Train Loss 28.058907 Test MSE 16.50067055794319 Test RE 2.9431911194071643\n",
      "21 Train Loss 26.67448 Test MSE 16.322481384172562 Test RE 2.927256362507698\n",
      "22 Train Loss 24.611082 Test MSE 16.075584150721635 Test RE 2.905032860001415\n",
      "23 Train Loss 23.388922 Test MSE 15.88810000635245 Test RE 2.8880429660781695\n",
      "24 Train Loss 21.915796 Test MSE 15.641368529143797 Test RE 2.8655305437186485\n",
      "25 Train Loss 20.974535 Test MSE 15.435067467329795 Test RE 2.8465704306653374\n",
      "26 Train Loss 19.90705 Test MSE 15.07418182077067 Test RE 2.8130959294546\n",
      "27 Train Loss 19.219666 Test MSE 14.773537805513316 Test RE 2.784902028964252\n",
      "28 Train Loss 18.377762 Test MSE 14.211516742556183 Test RE 2.7314162144273766\n",
      "29 Train Loss 17.568172 Test MSE 14.102517257092524 Test RE 2.7209213448084943\n",
      "30 Train Loss 16.518494 Test MSE 13.453063504964241 Test RE 2.6575305382128245\n",
      "31 Train Loss 15.595782 Test MSE 13.26047544247928 Test RE 2.6384399573659993\n",
      "32 Train Loss 14.991001 Test MSE 12.930587885053074 Test RE 2.6054143622237156\n",
      "33 Train Loss 14.31886 Test MSE 12.507727653193298 Test RE 2.5624587077215266\n",
      "34 Train Loss 13.814924 Test MSE 12.405178746244562 Test RE 2.5519324880963965\n",
      "35 Train Loss 13.402663 Test MSE 11.99647451794004 Test RE 2.509542098754199\n",
      "36 Train Loss 12.722633 Test MSE 11.465755692432552 Test RE 2.453403664027108\n",
      "37 Train Loss 12.30124 Test MSE 11.0037596290136 Test RE 2.4034672851695755\n",
      "38 Train Loss 11.771289 Test MSE 10.44184235767219 Test RE 2.3412955182930357\n",
      "39 Train Loss 10.83309 Test MSE 9.427349674834117 Test RE 2.2246540042462892\n",
      "40 Train Loss 9.999727 Test MSE 8.992405337517813 Test RE 2.1727292199572608\n",
      "41 Train Loss 9.002504 Test MSE 7.990512656538875 Test RE 2.048118071254559\n",
      "42 Train Loss 7.968952 Test MSE 7.424191491521808 Test RE 1.9742050122298347\n",
      "43 Train Loss 7.493007 Test MSE 7.043989503583792 Test RE 1.922989964176073\n",
      "44 Train Loss 7.0117197 Test MSE 6.405300404178386 Test RE 1.8337385664303487\n",
      "45 Train Loss 6.548837 Test MSE 5.781816887577313 Test RE 1.7422073206492215\n",
      "46 Train Loss 5.773481 Test MSE 4.760976553226246 Test RE 1.5809410961896446\n",
      "47 Train Loss 5.2561235 Test MSE 3.9952935344540785 Test RE 1.4482449202633856\n",
      "48 Train Loss 4.7629476 Test MSE 3.2269861836278713 Test RE 1.3015660760111514\n",
      "49 Train Loss 4.2085276 Test MSE 2.6168629490020554 Test RE 1.172082432800438\n",
      "50 Train Loss 3.7005634 Test MSE 2.1602465566907045 Test RE 1.064925749976615\n",
      "51 Train Loss 3.2614303 Test MSE 1.6423267888988111 Test RE 0.9285332415568305\n",
      "52 Train Loss 2.7304132 Test MSE 1.184183065330326 Test RE 0.788455325114624\n",
      "53 Train Loss 2.3202102 Test MSE 0.7606869881178722 Test RE 0.6319324562088939\n",
      "54 Train Loss 2.077092 Test MSE 0.49114566726387693 Test RE 0.5077767671348544\n",
      "55 Train Loss 1.8020347 Test MSE 0.34844547161757855 Test RE 0.4276958931435057\n",
      "56 Train Loss 1.5490144 Test MSE 0.3642143878740645 Test RE 0.4372665104603734\n",
      "57 Train Loss 1.3150059 Test MSE 0.2601306712811638 Test RE 0.36954169669926046\n",
      "58 Train Loss 1.1055592 Test MSE 0.1772852855540405 Test RE 0.30507316891237585\n",
      "59 Train Loss 0.9466954 Test MSE 0.2191151325914292 Test RE 0.33915939636031794\n",
      "60 Train Loss 0.7949051 Test MSE 0.1881928720414211 Test RE 0.31431800022939776\n",
      "61 Train Loss 0.7032609 Test MSE 0.16632880427552812 Test RE 0.29549585980782483\n",
      "62 Train Loss 0.61577696 Test MSE 0.1397476832442031 Test RE 0.27085694519948206\n",
      "63 Train Loss 0.55916864 Test MSE 0.1399929534637058 Test RE 0.27109453060098065\n",
      "64 Train Loss 0.5055663 Test MSE 0.13788028067917263 Test RE 0.26904117253836835\n",
      "65 Train Loss 0.48009628 Test MSE 0.12343077345370085 Test RE 0.254553687610695\n",
      "66 Train Loss 0.4180501 Test MSE 0.11198591662841445 Test RE 0.24246517613316335\n",
      "67 Train Loss 0.38266307 Test MSE 0.10944339912067368 Test RE 0.23969692031947726\n",
      "68 Train Loss 0.33482307 Test MSE 0.07816878284878331 Test RE 0.2025742979606398\n",
      "69 Train Loss 0.31223977 Test MSE 0.07467247965032296 Test RE 0.1979921420516914\n",
      "70 Train Loss 0.28261116 Test MSE 0.05353115232482274 Test RE 0.16763741825935918\n",
      "71 Train Loss 0.25900698 Test MSE 0.04877753912459981 Test RE 0.16002123233505205\n",
      "72 Train Loss 0.23668069 Test MSE 0.03676554106275235 Test RE 0.138927476914485\n",
      "73 Train Loss 0.21885417 Test MSE 0.033168076788642566 Test RE 0.13195559604670806\n",
      "74 Train Loss 0.20687129 Test MSE 0.03677159730105057 Test RE 0.1389389189228943\n",
      "75 Train Loss 0.19281869 Test MSE 0.03039534104735429 Test RE 0.1263197268796489\n",
      "76 Train Loss 0.17742065 Test MSE 0.020650844493525056 Test RE 0.104120579318567\n",
      "77 Train Loss 0.17120579 Test MSE 0.021040742303283302 Test RE 0.1050989062319963\n",
      "78 Train Loss 0.15718968 Test MSE 0.020104294181769275 Test RE 0.10273349969355079\n",
      "79 Train Loss 0.14875548 Test MSE 0.018699356729633278 Test RE 0.09907886001804668\n",
      "80 Train Loss 0.14224933 Test MSE 0.012238166511065853 Test RE 0.08015411929037286\n",
      "81 Train Loss 0.1321862 Test MSE 0.009279079575762092 Test RE 0.06979432593311921\n",
      "82 Train Loss 0.12656693 Test MSE 0.00985629187238905 Test RE 0.07193238258592999\n",
      "83 Train Loss 0.12331212 Test MSE 0.00840377308223514 Test RE 0.06642091074205986\n",
      "84 Train Loss 0.115138605 Test MSE 0.006073151560845158 Test RE 0.05646440126916862\n",
      "85 Train Loss 0.10926515 Test MSE 0.005872305156673099 Test RE 0.055522878776793204\n",
      "86 Train Loss 0.106236294 Test MSE 0.003823029589659235 Test RE 0.04479932777500827\n",
      "87 Train Loss 0.102466546 Test MSE 0.0036746902617180934 Test RE 0.04392158831134815\n",
      "88 Train Loss 0.09697018 Test MSE 0.004213715109770329 Test RE 0.047032736978973644\n",
      "89 Train Loss 0.09406701 Test MSE 0.0050088120139050495 Test RE 0.051278467078163394\n",
      "90 Train Loss 0.08966555 Test MSE 0.00445537152423221 Test RE 0.048362598811077885\n",
      "91 Train Loss 0.08681641 Test MSE 0.00392913970597095 Test RE 0.045416786608086936\n",
      "92 Train Loss 0.083174355 Test MSE 0.004029406430149642 Test RE 0.045992625832283474\n",
      "93 Train Loss 0.07693444 Test MSE 0.004593395850748706 Test RE 0.049106005092790984\n",
      "94 Train Loss 0.07489084 Test MSE 0.004204447035905055 Test RE 0.046980984211487005\n",
      "95 Train Loss 0.069546804 Test MSE 0.0028869917727258596 Test RE 0.038930541162851495\n",
      "96 Train Loss 0.06509351 Test MSE 0.0026494268753072562 Test RE 0.03729440101553869\n",
      "97 Train Loss 0.06259302 Test MSE 0.0021648938204344584 Test RE 0.03371211253811499\n",
      "98 Train Loss 0.05980668 Test MSE 0.0012403716735168888 Test RE 0.025517821047938843\n",
      "99 Train Loss 0.056119956 Test MSE 0.001172305362071915 Test RE 0.02480778808411292\n",
      "100 Train Loss 0.05341536 Test MSE 0.0009572874392007832 Test RE 0.022417586174264075\n",
      "101 Train Loss 0.0522026 Test MSE 0.0007803729086152153 Test RE 0.020240384559261703\n",
      "102 Train Loss 0.050725963 Test MSE 0.0007368055977067078 Test RE 0.01966727208245031\n",
      "103 Train Loss 0.04860537 Test MSE 0.0008127179748314571 Test RE 0.020655589793796687\n",
      "104 Train Loss 0.046218734 Test MSE 0.0011582459062572108 Test RE 0.02465857949418915\n",
      "105 Train Loss 0.044988364 Test MSE 0.0012716808413168442 Test RE 0.025837871371345425\n",
      "106 Train Loss 0.04263069 Test MSE 0.0009968142245060142 Test RE 0.02287572046838185\n",
      "107 Train Loss 0.041196577 Test MSE 0.000957125156180779 Test RE 0.02241568593634635\n",
      "108 Train Loss 0.040619176 Test MSE 0.0009997322783625144 Test RE 0.022909178961210936\n",
      "109 Train Loss 0.039520927 Test MSE 0.0009835198214210206 Test RE 0.02272266292734176\n",
      "110 Train Loss 0.037824314 Test MSE 0.001099726356162665 Test RE 0.024027577372082803\n",
      "111 Train Loss 0.03635534 Test MSE 0.0009563836264622673 Test RE 0.02240700101261212\n",
      "112 Train Loss 0.03445539 Test MSE 0.0009551483596073928 Test RE 0.022392525875167588\n",
      "113 Train Loss 0.032566592 Test MSE 0.0011397275718573047 Test RE 0.02446066134933961\n",
      "114 Train Loss 0.031001039 Test MSE 0.0010659365000385674 Test RE 0.023655565495401265\n",
      "115 Train Loss 0.029632892 Test MSE 0.0009296129453692939 Test RE 0.022091171594965944\n",
      "116 Train Loss 0.027911069 Test MSE 0.000860646887949105 Test RE 0.021255932829716155\n",
      "117 Train Loss 0.026988542 Test MSE 0.0008119664953205957 Test RE 0.020646037991807944\n",
      "118 Train Loss 0.025624767 Test MSE 0.000824454531534489 Test RE 0.020804200103653272\n",
      "119 Train Loss 0.024668595 Test MSE 0.0008526620311633523 Test RE 0.021157099564824557\n",
      "120 Train Loss 0.023949139 Test MSE 0.0009170800280340398 Test RE 0.021941751159745584\n",
      "121 Train Loss 0.023217335 Test MSE 0.0011643276336149246 Test RE 0.024723233472319493\n",
      "122 Train Loss 0.022574661 Test MSE 0.0010401647045243556 Test RE 0.023367848273946116\n",
      "123 Train Loss 0.021546893 Test MSE 0.0010167055152424918 Test RE 0.023102833987834626\n",
      "124 Train Loss 0.020621419 Test MSE 0.0010878005152371814 Test RE 0.023896940252165388\n",
      "125 Train Loss 0.019913359 Test MSE 0.001140657216576282 Test RE 0.02447063526330566\n",
      "126 Train Loss 0.019344538 Test MSE 0.001013865126993944 Test RE 0.023070540018260373\n",
      "127 Train Loss 0.018822469 Test MSE 0.0008507523785709144 Test RE 0.02113339418346364\n",
      "128 Train Loss 0.018345214 Test MSE 0.0008784290529266935 Test RE 0.02147439875451827\n",
      "129 Train Loss 0.017772758 Test MSE 0.0008936590307031643 Test RE 0.021659757591884588\n",
      "130 Train Loss 0.01711042 Test MSE 0.0009337351069621893 Test RE 0.02214009660869176\n",
      "131 Train Loss 0.016734563 Test MSE 0.0009464637792038962 Test RE 0.022290492636513788\n",
      "132 Train Loss 0.016505819 Test MSE 0.0010947316127586702 Test RE 0.023972950982266004\n",
      "133 Train Loss 0.015766023 Test MSE 0.001057662903049221 Test RE 0.023563581650516547\n",
      "134 Train Loss 0.015223443 Test MSE 0.0010438831074224887 Test RE 0.023409578952676185\n",
      "135 Train Loss 0.01474925 Test MSE 0.0009674789388454134 Test RE 0.02253660160524258\n",
      "136 Train Loss 0.014372818 Test MSE 0.0008972854327968559 Test RE 0.021703659944116417\n",
      "137 Train Loss 0.014058626 Test MSE 0.0008270911698478161 Test RE 0.020837439878148192\n",
      "138 Train Loss 0.013754649 Test MSE 0.000807052717025811 Test RE 0.020583471367152724\n",
      "139 Train Loss 0.013584188 Test MSE 0.0007812799358124613 Test RE 0.020252143839748302\n",
      "140 Train Loss 0.013340427 Test MSE 0.0007317234659698471 Test RE 0.019599327010104205\n",
      "141 Train Loss 0.013132324 Test MSE 0.0006820189272772286 Test RE 0.01892194959659084\n",
      "142 Train Loss 0.0128706135 Test MSE 0.000661331988731467 Test RE 0.01863277041039863\n",
      "143 Train Loss 0.012479387 Test MSE 0.000654736308587412 Test RE 0.018539622223472947\n",
      "144 Train Loss 0.012099645 Test MSE 0.0006035866582084707 Test RE 0.01780071649429415\n",
      "145 Train Loss 0.011921048 Test MSE 0.0006091746590477251 Test RE 0.01788292610979716\n",
      "146 Train Loss 0.011754663 Test MSE 0.0006354462353090479 Test RE 0.018264469951616256\n",
      "147 Train Loss 0.011611152 Test MSE 0.0006094512462561743 Test RE 0.01788698539495347\n",
      "148 Train Loss 0.011455445 Test MSE 0.0005756115253406538 Test RE 0.017383307322955517\n",
      "149 Train Loss 0.011260205 Test MSE 0.000560679988471233 Test RE 0.01715636177173296\n",
      "150 Train Loss 0.011055943 Test MSE 0.0005651559861697404 Test RE 0.017224706625955318\n",
      "151 Train Loss 0.010864488 Test MSE 0.0005375381422543105 Test RE 0.016798569893669645\n",
      "152 Train Loss 0.010616304 Test MSE 0.0005296098494634253 Test RE 0.01667422641280437\n",
      "153 Train Loss 0.010445999 Test MSE 0.000540658140041437 Test RE 0.016847250782081994\n",
      "154 Train Loss 0.010234518 Test MSE 0.0005493042925794033 Test RE 0.01698142627961245\n",
      "155 Train Loss 0.010011031 Test MSE 0.0005425434893369515 Test RE 0.016876599558852696\n",
      "156 Train Loss 0.009804958 Test MSE 0.0005161344687922738 Test RE 0.01646073030087915\n",
      "157 Train Loss 0.009602548 Test MSE 0.000508107786927839 Test RE 0.016332233975126446\n",
      "158 Train Loss 0.00953565 Test MSE 0.0005041703531417432 Test RE 0.016268829950574524\n",
      "159 Train Loss 0.00931543 Test MSE 0.0004889955342077565 Test RE 0.016022124942832627\n",
      "160 Train Loss 0.009139442 Test MSE 0.0004840707600787618 Test RE 0.01594123972445628\n",
      "161 Train Loss 0.008954507 Test MSE 0.000451882061803878 Test RE 0.015402109919375165\n",
      "162 Train Loss 0.008757292 Test MSE 0.00043077610192085534 Test RE 0.01503811732024834\n",
      "163 Train Loss 0.008624903 Test MSE 0.000433165112118973 Test RE 0.015079759072155172\n",
      "164 Train Loss 0.008474869 Test MSE 0.00046429040926061716 Test RE 0.015612143122374928\n",
      "165 Train Loss 0.008333877 Test MSE 0.00044660339086522306 Test RE 0.01531188560125163\n",
      "166 Train Loss 0.008187649 Test MSE 0.00044988120215685393 Test RE 0.015367973081222343\n",
      "167 Train Loss 0.00806858 Test MSE 0.0004449163024673791 Test RE 0.015282937156755333\n",
      "168 Train Loss 0.007824367 Test MSE 0.0004367928025643074 Test RE 0.01514277273329334\n",
      "169 Train Loss 0.0076371864 Test MSE 0.0004060545310272664 Test RE 0.014600235069406876\n",
      "170 Train Loss 0.0074369637 Test MSE 0.0004075945697856426 Test RE 0.014627895946109389\n",
      "171 Train Loss 0.007291307 Test MSE 0.00043609918890266956 Test RE 0.015130744825554153\n",
      "172 Train Loss 0.007212447 Test MSE 0.0004416889763686566 Test RE 0.015227406720828516\n",
      "173 Train Loss 0.0070819277 Test MSE 0.00043230303657080496 Test RE 0.015064745898572686\n",
      "174 Train Loss 0.006868624 Test MSE 0.0003890468503551264 Test RE 0.014291197447951782\n",
      "175 Train Loss 0.006661995 Test MSE 0.00040409537275177735 Test RE 0.014564970399916052\n",
      "176 Train Loss 0.0063563483 Test MSE 0.00040852750841391833 Test RE 0.0146446271908783\n",
      "177 Train Loss 0.006193714 Test MSE 0.00038410575921772345 Test RE 0.014200154745936009\n",
      "178 Train Loss 0.006083027 Test MSE 0.00039979029762429567 Test RE 0.014487177883921804\n",
      "179 Train Loss 0.006002723 Test MSE 0.00040532875776409186 Test RE 0.014587181158358197\n",
      "180 Train Loss 0.005935155 Test MSE 0.0004152562635339221 Test RE 0.01476473863785301\n",
      "181 Train Loss 0.0057938844 Test MSE 0.0004048834259162429 Test RE 0.014579165539540919\n",
      "182 Train Loss 0.0056987046 Test MSE 0.0003967728516417903 Test RE 0.014432402825749596\n",
      "183 Train Loss 0.0056080446 Test MSE 0.00039393502786751194 Test RE 0.01438069803813786\n",
      "184 Train Loss 0.00550415 Test MSE 0.0003847241199590379 Test RE 0.014211580358349211\n",
      "185 Train Loss 0.0054567317 Test MSE 0.00038829932832151845 Test RE 0.01427746115690111\n",
      "186 Train Loss 0.005393147 Test MSE 0.00038764389086854697 Test RE 0.014265406107578697\n",
      "187 Train Loss 0.0053581866 Test MSE 0.0003822717734030265 Test RE 0.01416621351640191\n",
      "188 Train Loss 0.005316328 Test MSE 0.0003820204971353091 Test RE 0.014161556857634656\n",
      "189 Train Loss 0.005246279 Test MSE 0.0003599040494408256 Test RE 0.013745515573347052\n",
      "190 Train Loss 0.005180703 Test MSE 0.0003578704161593492 Test RE 0.013706626128455399\n",
      "191 Train Loss 0.0051324232 Test MSE 0.00034240399897838707 Test RE 0.013407168937443996\n",
      "192 Train Loss 0.005088214 Test MSE 0.0003383275383155996 Test RE 0.013327121038596167\n",
      "193 Train Loss 0.0050263717 Test MSE 0.00032804448941736763 Test RE 0.013123027563746933\n",
      "194 Train Loss 0.004981541 Test MSE 0.00033216604350413915 Test RE 0.013205209158499622\n",
      "195 Train Loss 0.004934334 Test MSE 0.00033981083086647194 Test RE 0.013356303410406589\n",
      "196 Train Loss 0.004894427 Test MSE 0.0003383322987173013 Test RE 0.013327214797187063\n",
      "197 Train Loss 0.0048274803 Test MSE 0.0003390077801019523 Test RE 0.013340512074370781\n",
      "198 Train Loss 0.0047678044 Test MSE 0.0003515189083026688 Test RE 0.013584448543247363\n",
      "199 Train Loss 0.0047288504 Test MSE 0.0003542149553256564 Test RE 0.013636443407209943\n",
      "200 Train Loss 0.0046973783 Test MSE 0.00035790885053770146 Test RE 0.013707362137199244\n",
      "201 Train Loss 0.004646645 Test MSE 0.00034672589668519255 Test RE 0.01349151770535627\n",
      "202 Train Loss 0.004600274 Test MSE 0.0003488088199540053 Test RE 0.013531981538602307\n",
      "203 Train Loss 0.00457128 Test MSE 0.0003399454636567625 Test RE 0.013358949026963001\n",
      "204 Train Loss 0.0045218137 Test MSE 0.00034457186692646947 Test RE 0.01344954448224143\n",
      "205 Train Loss 0.004446374 Test MSE 0.0003430630259662287 Test RE 0.013420065163464966\n",
      "206 Train Loss 0.004398588 Test MSE 0.0003429398698918224 Test RE 0.013417656115015424\n",
      "207 Train Loss 0.00434162 Test MSE 0.0003592945927061076 Test RE 0.013733872405455188\n",
      "208 Train Loss 0.004282613 Test MSE 0.0003580578076778433 Test RE 0.013710214255916278\n",
      "209 Train Loss 0.0042281365 Test MSE 0.0003629184491533535 Test RE 0.013802958773007207\n",
      "210 Train Loss 0.0041771503 Test MSE 0.0003612196898001318 Test RE 0.013770616233394354\n",
      "211 Train Loss 0.0041152146 Test MSE 0.00036533289096751364 Test RE 0.013848797163927852\n",
      "212 Train Loss 0.00403018 Test MSE 0.0003675771901141549 Test RE 0.013891269737321682\n",
      "213 Train Loss 0.003957358 Test MSE 0.0003582682031602573 Test RE 0.013714241738993908\n",
      "214 Train Loss 0.0038917747 Test MSE 0.0003536563018892661 Test RE 0.013625685741639708\n",
      "215 Train Loss 0.0038455534 Test MSE 0.00037486491285699543 Test RE 0.014028300617188953\n",
      "216 Train Loss 0.003775565 Test MSE 0.00039425597422226404 Test RE 0.014386554959457716\n",
      "217 Train Loss 0.0037393633 Test MSE 0.0004089623406010826 Test RE 0.014652418908138837\n",
      "218 Train Loss 0.003701187 Test MSE 0.00042820640816429646 Test RE 0.01499319704958429\n",
      "219 Train Loss 0.003663939 Test MSE 0.000428895160202419 Test RE 0.015005250168934635\n",
      "220 Train Loss 0.0036355963 Test MSE 0.00042395035047603397 Test RE 0.014918500286323091\n",
      "221 Train Loss 0.0036001399 Test MSE 0.00042524930685878566 Test RE 0.014941337465535586\n",
      "222 Train Loss 0.003562891 Test MSE 0.0004224387089516873 Test RE 0.014891879760119709\n",
      "223 Train Loss 0.0035168822 Test MSE 0.00043208769686110197 Test RE 0.015060993389549492\n",
      "224 Train Loss 0.0034877001 Test MSE 0.00043006719708595407 Test RE 0.015025738518904349\n",
      "225 Train Loss 0.0034425838 Test MSE 0.0004282170082129588 Test RE 0.014993382623213924\n",
      "226 Train Loss 0.0033975071 Test MSE 0.00043437092299569805 Test RE 0.015100733407629664\n",
      "227 Train Loss 0.0033656294 Test MSE 0.00044846363835449054 Test RE 0.015343741939315916\n",
      "228 Train Loss 0.0033287713 Test MSE 0.0004540932451692269 Test RE 0.015439747315620823\n",
      "229 Train Loss 0.003301274 Test MSE 0.00044465263105730474 Test RE 0.01527840791072334\n",
      "230 Train Loss 0.00324916 Test MSE 0.0004547064623715162 Test RE 0.015450168880453868\n",
      "231 Train Loss 0.003182803 Test MSE 0.0004552291848928685 Test RE 0.01545904695035565\n",
      "232 Train Loss 0.003086047 Test MSE 0.0004754294746463195 Test RE 0.015798313184211064\n",
      "233 Train Loss 0.0030486712 Test MSE 0.00047555955295367825 Test RE 0.015800474258989602\n",
      "234 Train Loss 0.002995452 Test MSE 0.0004696295020852362 Test RE 0.015701652203374366\n",
      "235 Train Loss 0.0029497677 Test MSE 0.00046664099216403224 Test RE 0.015651613360732352\n",
      "236 Train Loss 0.0029030305 Test MSE 0.0004674785878845673 Test RE 0.01566565396909082\n",
      "237 Train Loss 0.002832018 Test MSE 0.0004556973645299208 Test RE 0.015466994322042049\n",
      "238 Train Loss 0.002772126 Test MSE 0.000448369240309076 Test RE 0.015342126986226355\n",
      "239 Train Loss 0.002741457 Test MSE 0.0004470956088542769 Test RE 0.015320321173165074\n",
      "240 Train Loss 0.0027051163 Test MSE 0.0004400924258037137 Test RE 0.015199860941868832\n",
      "241 Train Loss 0.0026652627 Test MSE 0.0004370932478883932 Test RE 0.015147979770994174\n",
      "242 Train Loss 0.0026240177 Test MSE 0.0004334955388871928 Test RE 0.015085509542406379\n",
      "243 Train Loss 0.0025906744 Test MSE 0.00043652676035202284 Test RE 0.015138160443026842\n",
      "244 Train Loss 0.0025435518 Test MSE 0.00044197485114912447 Test RE 0.01523233374826609\n",
      "245 Train Loss 0.002504899 Test MSE 0.000444469914469041 Test RE 0.015275268487705967\n",
      "246 Train Loss 0.0024718784 Test MSE 0.0004592937391788409 Test RE 0.015527907323596733\n",
      "247 Train Loss 0.0024420493 Test MSE 0.0004606375248097643 Test RE 0.015550606238106826\n",
      "248 Train Loss 0.0024120463 Test MSE 0.0004577489968999089 Test RE 0.015501772831193474\n",
      "249 Train Loss 0.0023825993 Test MSE 0.00045516037113623034 Test RE 0.01545787848913367\n",
      "250 Train Loss 0.0023565113 Test MSE 0.0004552904525612375 Test RE 0.015460087204284214\n",
      "251 Train Loss 0.002335261 Test MSE 0.0004469888430937823 Test RE 0.015318491829093957\n",
      "252 Train Loss 0.0023199185 Test MSE 0.0004435486804146772 Test RE 0.015259430074025679\n",
      "253 Train Loss 0.0023009696 Test MSE 0.0004420106041047085 Test RE 0.015232949835286972\n",
      "254 Train Loss 0.0022603187 Test MSE 0.00044068820573162825 Test RE 0.015210145951063118\n",
      "255 Train Loss 0.0022278095 Test MSE 0.00044573319611447554 Test RE 0.01529696092804119\n",
      "256 Train Loss 0.002202671 Test MSE 0.0004387166038116184 Test RE 0.015176083354024292\n",
      "257 Train Loss 0.0021670132 Test MSE 0.00042174050744196983 Test RE 0.014879568112899233\n",
      "258 Train Loss 0.002154965 Test MSE 0.00041995929418532434 Test RE 0.014848113074534174\n",
      "259 Train Loss 0.0021281205 Test MSE 0.0004290345148992221 Test RE 0.015007687690333251\n",
      "260 Train Loss 0.002114645 Test MSE 0.0004309044448800902 Test RE 0.015040357338595472\n",
      "261 Train Loss 0.0020965098 Test MSE 0.00042812602957682414 Test RE 0.01499178979768815\n",
      "262 Train Loss 0.0020837116 Test MSE 0.0004190771572634728 Test RE 0.014832510426375164\n",
      "263 Train Loss 0.0020698605 Test MSE 0.0004167644326313808 Test RE 0.014791526362203457\n",
      "264 Train Loss 0.002045738 Test MSE 0.0004038442071887462 Test RE 0.014560443266154872\n",
      "265 Train Loss 0.0020189984 Test MSE 0.000408252561268218 Test RE 0.014639698298613382\n",
      "266 Train Loss 0.0020008564 Test MSE 0.000404357693881665 Test RE 0.014569697105407991\n",
      "267 Train Loss 0.0019799585 Test MSE 0.0003899012127813189 Test RE 0.014306880862594185\n",
      "268 Train Loss 0.001963514 Test MSE 0.0003844110844370784 Test RE 0.014205797468021125\n",
      "269 Train Loss 0.001948542 Test MSE 0.0003841665812804334 Test RE 0.014201278978642757\n",
      "270 Train Loss 0.0019341992 Test MSE 0.00038512441849896365 Test RE 0.014218971883274137\n",
      "271 Train Loss 0.0019254634 Test MSE 0.0003876747320575354 Test RE 0.0142659735785818\n",
      "272 Train Loss 0.0019097573 Test MSE 0.00038604945881362773 Test RE 0.01423603809987674\n",
      "273 Train Loss 0.0018930453 Test MSE 0.0003929135493608764 Test RE 0.014362041270085538\n",
      "274 Train Loss 0.0018786133 Test MSE 0.00039140974882954726 Test RE 0.014334530956213268\n",
      "275 Train Loss 0.0018664363 Test MSE 0.0003976154295258038 Test RE 0.01444771886152334\n",
      "276 Train Loss 0.0018535925 Test MSE 0.00039439664555777654 Test RE 0.014389121306630918\n",
      "277 Train Loss 0.0018379743 Test MSE 0.00038409554254096 Test RE 0.01419996589253785\n",
      "278 Train Loss 0.0018151206 Test MSE 0.00037367682015510966 Test RE 0.014006052404607283\n",
      "279 Train Loss 0.0017953283 Test MSE 0.0003620920916585811 Test RE 0.01378723529743432\n",
      "280 Train Loss 0.0017798532 Test MSE 0.00036174146637838747 Test RE 0.013780558371613998\n",
      "281 Train Loss 0.0017630176 Test MSE 0.0003456039852147889 Test RE 0.013469672563851285\n",
      "282 Train Loss 0.0017460443 Test MSE 0.0003425157348372753 Test RE 0.01340935632331887\n",
      "283 Train Loss 0.0017341846 Test MSE 0.0003439347063615714 Test RE 0.013437103703693467\n",
      "284 Train Loss 0.0017268657 Test MSE 0.0003429324585463915 Test RE 0.013417511128342323\n",
      "285 Train Loss 0.0017153744 Test MSE 0.0003419446518833586 Test RE 0.013398172823226228\n",
      "286 Train Loss 0.0016936972 Test MSE 0.0003429013074637165 Test RE 0.013416901708790032\n",
      "287 Train Loss 0.0016802851 Test MSE 0.00034574850711751833 Test RE 0.013472488589308067\n",
      "288 Train Loss 0.0016618224 Test MSE 0.0003470056190397732 Test RE 0.013496958773206624\n",
      "289 Train Loss 0.0016443001 Test MSE 0.00035202365142953556 Test RE 0.013594197944038721\n",
      "290 Train Loss 0.0016326979 Test MSE 0.0003481724273322447 Test RE 0.013519631528743418\n",
      "291 Train Loss 0.0016210438 Test MSE 0.0003588630245323111 Test RE 0.013725621678525172\n",
      "292 Train Loss 0.0016057922 Test MSE 0.000357063174509018 Test RE 0.013691158510046642\n",
      "293 Train Loss 0.001594363 Test MSE 0.00036283874965536733 Test RE 0.013801443075347046\n",
      "294 Train Loss 0.0015877356 Test MSE 0.000361672788499052 Test RE 0.013779250165978876\n",
      "295 Train Loss 0.0015782042 Test MSE 0.00036577634580889617 Test RE 0.013857199711017624\n",
      "296 Train Loss 0.001566935 Test MSE 0.00036572838917357055 Test RE 0.013856291278222294\n",
      "297 Train Loss 0.0015581776 Test MSE 0.0003690568074767058 Test RE 0.013919200090561551\n",
      "298 Train Loss 0.001550761 Test MSE 0.0003658832176465705 Test RE 0.01385922394830911\n",
      "299 Train Loss 0.0015447653 Test MSE 0.0003682665919117699 Test RE 0.013904290376879605\n",
      "Training time: 250.62\n",
      "KG_atanh_medium\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 35732.844 Test MSE 7.710487109020087 Test RE 2.0119101209035173\n",
      "1 Train Loss 17946.13 Test MSE 9.728765883647574 Test RE 2.2599380998686436\n",
      "2 Train Loss 5865.9434 Test MSE 9.027780149538366 Test RE 2.1769986253198814\n",
      "3 Train Loss 1513.4832 Test MSE 12.625838028833153 Test RE 2.5745289188414393\n",
      "4 Train Loss 727.6887 Test MSE 15.546452011410413 Test RE 2.8568228638142124\n",
      "5 Train Loss 413.52042 Test MSE 17.808145826196476 Test RE 3.057574299902\n",
      "6 Train Loss 258.2827 Test MSE 18.917335097273746 Test RE 3.151357299633235\n",
      "7 Train Loss 172.99095 Test MSE 19.239951124512796 Test RE 3.1781153058104974\n",
      "8 Train Loss 131.83719 Test MSE 19.379277339622462 Test RE 3.189601718589705\n",
      "9 Train Loss 110.374466 Test MSE 19.702632634784422 Test RE 3.2161018772026226\n",
      "10 Train Loss 89.186264 Test MSE 19.85020273618063 Test RE 3.2281234970487396\n",
      "11 Train Loss 76.34402 Test MSE 20.1290383050317 Test RE 3.250717137353024\n",
      "12 Train Loss 65.98331 Test MSE 20.563819091247833 Test RE 3.285636806289553\n",
      "13 Train Loss 58.29322 Test MSE 20.950080935524838 Test RE 3.316351232882388\n",
      "14 Train Loss 52.031322 Test MSE 21.39468642293586 Test RE 3.351356516260034\n",
      "15 Train Loss 46.944317 Test MSE 21.7917920485073 Test RE 3.382315692994199\n",
      "16 Train Loss 43.705467 Test MSE 22.200486422781825 Test RE 3.4138851990623267\n",
      "17 Train Loss 41.477077 Test MSE 22.518929706599465 Test RE 3.438282369156681\n",
      "18 Train Loss 39.300774 Test MSE 22.442700108360935 Test RE 3.432457912283176\n",
      "19 Train Loss 37.720673 Test MSE 22.64033838748239 Test RE 3.4475384972349103\n",
      "20 Train Loss 36.026104 Test MSE 22.673111334852127 Test RE 3.450032831401469\n",
      "21 Train Loss 34.911297 Test MSE 22.632830478037928 Test RE 3.4469668195366667\n",
      "22 Train Loss 33.531166 Test MSE 22.64181954179685 Test RE 3.44765126615469\n",
      "23 Train Loss 32.43407 Test MSE 22.562139083192374 Test RE 3.44157948053654\n",
      "24 Train Loss 31.533012 Test MSE 22.417161557169496 Test RE 3.4305043827626793\n",
      "25 Train Loss 30.75232 Test MSE 22.377021676436243 Test RE 3.427431698188981\n",
      "26 Train Loss 30.058607 Test MSE 22.32018684398598 Test RE 3.42307630727133\n",
      "27 Train Loss 29.383963 Test MSE 22.46403638919167 Test RE 3.4340891439872028\n",
      "28 Train Loss 28.93851 Test MSE 22.515359476260773 Test RE 3.438009799661272\n",
      "29 Train Loss 28.353502 Test MSE 22.63761263965718 Test RE 3.4473309605087534\n",
      "30 Train Loss 27.74683 Test MSE 22.684886219288703 Test RE 3.450928572271661\n",
      "31 Train Loss 27.347406 Test MSE 22.757830895801483 Test RE 3.456472457961722\n",
      "32 Train Loss 26.997469 Test MSE 22.749865375055297 Test RE 3.4558675010831923\n",
      "33 Train Loss 26.615244 Test MSE 22.655192641418562 Test RE 3.4486692713070743\n",
      "34 Train Loss 26.211208 Test MSE 22.66960504128778 Test RE 3.449766055142779\n",
      "35 Train Loss 25.859934 Test MSE 22.569048855306992 Test RE 3.4421064409765108\n",
      "36 Train Loss 25.571022 Test MSE 22.525847035736344 Test RE 3.438810411673379\n",
      "37 Train Loss 25.346766 Test MSE 22.44181487875111 Test RE 3.4323902167000444\n",
      "38 Train Loss 25.128784 Test MSE 22.48866272194309 Test RE 3.4359709486608128\n",
      "39 Train Loss 24.82472 Test MSE 22.30985978739941 Test RE 3.422284324819093\n",
      "40 Train Loss 24.620966 Test MSE 22.16490616987621 Test RE 3.411148421056446\n",
      "41 Train Loss 24.319733 Test MSE 22.08412604615849 Test RE 3.4049267724848944\n",
      "42 Train Loss 24.148514 Test MSE 21.94690679637992 Test RE 3.394332069131452\n",
      "43 Train Loss 23.88578 Test MSE 21.86432128504872 Test RE 3.3879396681247935\n",
      "44 Train Loss 23.65425 Test MSE 21.84198470751258 Test RE 3.3862086673460694\n",
      "45 Train Loss 23.498392 Test MSE 21.749044691350086 Test RE 3.3789966444339496\n",
      "46 Train Loss 23.337263 Test MSE 21.644066823342637 Test RE 3.37083194240515\n",
      "47 Train Loss 23.16145 Test MSE 21.600604189393344 Test RE 3.367445821445085\n",
      "48 Train Loss 23.020283 Test MSE 21.55317478812442 Test RE 3.363746764975668\n",
      "49 Train Loss 22.801395 Test MSE 21.349946903525865 Test RE 3.347850586217417\n",
      "50 Train Loss 22.661417 Test MSE 21.173363189686054 Test RE 3.333976936643269\n",
      "51 Train Loss 22.459688 Test MSE 20.870327994312202 Test RE 3.3100328572996727\n",
      "52 Train Loss 22.269104 Test MSE 20.479873132702455 Test RE 3.278923607953231\n",
      "53 Train Loss 22.098318 Test MSE 20.121669846143657 Test RE 3.2501221022682203\n",
      "54 Train Loss 21.773188 Test MSE 19.76949511966929 Test RE 3.2215543068353334\n",
      "55 Train Loss 21.55225 Test MSE 19.438182484670854 Test RE 3.1944455884721314\n",
      "56 Train Loss 21.28082 Test MSE 18.95669315860694 Test RE 3.1546338411647428\n",
      "57 Train Loss 21.112715 Test MSE 18.592429255074357 Test RE 3.124177760045919\n",
      "58 Train Loss 20.826748 Test MSE 18.26141032198013 Test RE 3.096241483989182\n",
      "59 Train Loss 20.60344 Test MSE 17.987129114003714 Test RE 3.07290117638003\n",
      "60 Train Loss 20.229225 Test MSE 17.496779494371935 Test RE 3.0307263645038356\n",
      "61 Train Loss 20.00372 Test MSE 17.36532706952012 Test RE 3.019320052934352\n",
      "62 Train Loss 19.778189 Test MSE 17.183506041579424 Test RE 3.0034717928296466\n",
      "63 Train Loss 19.574486 Test MSE 17.12713586059031 Test RE 2.9985413284678457\n",
      "64 Train Loss 19.316639 Test MSE 16.986497801801388 Test RE 2.9862048142086617\n",
      "65 Train Loss 19.085094 Test MSE 16.79150380168403 Test RE 2.96901549203528\n",
      "66 Train Loss 18.875893 Test MSE 16.42573841395542 Test RE 2.9365007680552595\n",
      "67 Train Loss 18.564426 Test MSE 16.071453742437782 Test RE 2.904659631180597\n",
      "68 Train Loss 18.334517 Test MSE 16.01725909843039 Test RE 2.8997580856167438\n",
      "69 Train Loss 18.105537 Test MSE 15.623814523729646 Test RE 2.863922127561803\n",
      "70 Train Loss 17.773209 Test MSE 15.073693642576393 Test RE 2.8130503779538216\n",
      "71 Train Loss 17.573114 Test MSE 14.792083188453676 Test RE 2.786649439677233\n",
      "72 Train Loss 17.324553 Test MSE 14.580923784501048 Test RE 2.7666880074461293\n",
      "73 Train Loss 17.159195 Test MSE 14.399916303953603 Test RE 2.7494615559466253\n",
      "74 Train Loss 16.994051 Test MSE 14.261226318058206 Test RE 2.7361890693679896\n",
      "75 Train Loss 16.781708 Test MSE 13.996523261928841 Test RE 2.710676887450975\n",
      "76 Train Loss 16.615124 Test MSE 13.848527221361229 Test RE 2.696307763365449\n",
      "77 Train Loss 16.435915 Test MSE 13.4770238053422 Test RE 2.6598960553046265\n",
      "78 Train Loss 16.248554 Test MSE 13.259229944809643 Test RE 2.63831604597232\n",
      "79 Train Loss 16.097824 Test MSE 13.050949976642137 Test RE 2.6175122940854507\n",
      "80 Train Loss 15.89095 Test MSE 13.002902318533689 Test RE 2.6126896067609953\n",
      "81 Train Loss 15.626321 Test MSE 12.724337776443882 Test RE 2.5845519278187505\n",
      "82 Train Loss 15.3925 Test MSE 12.368175884449979 Test RE 2.548123622089747\n",
      "83 Train Loss 15.221526 Test MSE 12.266324713645039 Test RE 2.5376101118445256\n",
      "84 Train Loss 14.98903 Test MSE 12.118468128681409 Test RE 2.5222697430114587\n",
      "85 Train Loss 14.605425 Test MSE 11.884628193136434 Test RE 2.497816139239625\n",
      "86 Train Loss 14.310274 Test MSE 11.681230023199312 Test RE 2.476349595539559\n",
      "87 Train Loss 14.024401 Test MSE 11.457590641457992 Test RE 2.4525299434395937\n",
      "88 Train Loss 13.671307 Test MSE 11.34580088523263 Test RE 2.4405361583796985\n",
      "89 Train Loss 13.360843 Test MSE 11.222234677062241 Test RE 2.4272099334792308\n",
      "90 Train Loss 13.045125 Test MSE 11.01453538287362 Test RE 2.4046438300606243\n",
      "91 Train Loss 12.602182 Test MSE 10.918624709979804 Test RE 2.3941515459595344\n",
      "92 Train Loss 12.38199 Test MSE 10.857047904561961 Test RE 2.387390957982041\n",
      "93 Train Loss 12.132601 Test MSE 10.758632034998378 Test RE 2.3765458350636113\n",
      "94 Train Loss 11.745078 Test MSE 10.510106645888817 Test RE 2.348936243804102\n",
      "95 Train Loss 11.536055 Test MSE 10.386500394706253 Test RE 2.3350828201279765\n",
      "96 Train Loss 11.321589 Test MSE 10.277382910073374 Test RE 2.3227845915860295\n",
      "97 Train Loss 11.1228485 Test MSE 10.17424895516731 Test RE 2.3111005864536893\n",
      "98 Train Loss 10.863822 Test MSE 9.983125528274464 Test RE 2.2892906453853765\n",
      "99 Train Loss 10.570626 Test MSE 9.892544823116797 Test RE 2.278881175764972\n",
      "100 Train Loss 10.285498 Test MSE 9.745373014798595 Test RE 2.2618661494284122\n",
      "101 Train Loss 9.965225 Test MSE 9.427939488191525 Test RE 2.2247235948613695\n",
      "102 Train Loss 9.381644 Test MSE 9.219974120779506 Test RE 2.2000498360418987\n",
      "103 Train Loss 8.938347 Test MSE 8.805193295262287 Test RE 2.1499933407356577\n",
      "104 Train Loss 8.525456 Test MSE 8.470988808703604 Test RE 2.1087967405002734\n",
      "105 Train Loss 8.065551 Test MSE 8.315337139300276 Test RE 2.0893326867777513\n",
      "106 Train Loss 7.6725593 Test MSE 8.123648970898415 Test RE 2.0651102492241153\n",
      "107 Train Loss 7.309392 Test MSE 7.775028759299536 Test RE 2.020313052725063\n",
      "108 Train Loss 6.793997 Test MSE 7.110210201377306 Test RE 1.9320078545483776\n",
      "109 Train Loss 6.442464 Test MSE 6.890878522868433 Test RE 1.901975702674591\n",
      "110 Train Loss 5.9073973 Test MSE 5.943998777531806 Test RE 1.7664730797321033\n",
      "111 Train Loss 5.3329744 Test MSE 5.189858328517428 Test RE 1.6506135997146734\n",
      "112 Train Loss 4.6937723 Test MSE 4.324788635711854 Test RE 1.506780916621551\n",
      "113 Train Loss 4.054998 Test MSE 3.640263167043638 Test RE 1.3824010606735164\n",
      "114 Train Loss 3.35383 Test MSE 2.7353964514395166 Test RE 1.1983337948008406\n",
      "115 Train Loss 2.2800608 Test MSE 1.7011122954217395 Test RE 0.9450051155391397\n",
      "116 Train Loss 1.9573457 Test MSE 1.3996433946599762 Test RE 0.8571885615312936\n",
      "117 Train Loss 1.626605 Test MSE 1.1392812373031278 Test RE 0.77336255465201\n",
      "118 Train Loss 1.3861179 Test MSE 1.0164298676564907 Test RE 0.7304767150794023\n",
      "119 Train Loss 1.1828121 Test MSE 0.8236801139196711 Test RE 0.65757752025327\n",
      "120 Train Loss 1.0419956 Test MSE 0.6072312434772965 Test RE 0.564605002971987\n",
      "121 Train Loss 0.8595019 Test MSE 0.49627426019132165 Test RE 0.5104210104776055\n",
      "122 Train Loss 0.69724506 Test MSE 0.3950720985233451 Test RE 0.4554134442611635\n",
      "123 Train Loss 0.5980759 Test MSE 0.37478707901416924 Test RE 0.4435677599801831\n",
      "124 Train Loss 0.51672417 Test MSE 0.280457922844728 Test RE 0.3837085921950432\n",
      "125 Train Loss 0.46271783 Test MSE 0.2546800554881979 Test RE 0.36564962769016074\n",
      "126 Train Loss 0.41254297 Test MSE 0.25986309901675697 Test RE 0.369351591187834\n",
      "127 Train Loss 0.37967554 Test MSE 0.22924409989173936 Test RE 0.3469099458121043\n",
      "128 Train Loss 0.34953183 Test MSE 0.23549688456808232 Test RE 0.3516092167380278\n",
      "129 Train Loss 0.32891956 Test MSE 0.18965122617592026 Test RE 0.3155335147581064\n",
      "130 Train Loss 0.29229903 Test MSE 0.18234244890178683 Test RE 0.3093937663003217\n",
      "131 Train Loss 0.26540607 Test MSE 0.14028020017651158 Test RE 0.2713725128371088\n",
      "132 Train Loss 0.23483965 Test MSE 0.12936428606413672 Test RE 0.2606002726086721\n",
      "133 Train Loss 0.20800085 Test MSE 0.0968595151339938 Test RE 0.22549598469435714\n",
      "134 Train Loss 0.1902008 Test MSE 0.09823165046161658 Test RE 0.22708758311519497\n",
      "135 Train Loss 0.16354205 Test MSE 0.07672490409946435 Test RE 0.2006946727859778\n",
      "136 Train Loss 0.15402445 Test MSE 0.07625469669669142 Test RE 0.20007875054997115\n",
      "137 Train Loss 0.14768277 Test MSE 0.07523443678331782 Test RE 0.1987357530172457\n",
      "138 Train Loss 0.13861749 Test MSE 0.06705160283730789 Test RE 0.18761702691580778\n",
      "139 Train Loss 0.13120407 Test MSE 0.064826351819795 Test RE 0.1844775229593584\n",
      "140 Train Loss 0.12562786 Test MSE 0.05907186841146859 Test RE 0.17609945886846068\n",
      "141 Train Loss 0.11872328 Test MSE 0.06195716977779089 Test RE 0.18034888143432387\n",
      "142 Train Loss 0.10633985 Test MSE 0.05265957611980173 Test RE 0.16626710963205166\n",
      "143 Train Loss 0.10248134 Test MSE 0.048075614974182834 Test RE 0.15886568212191973\n",
      "144 Train Loss 0.0991824 Test MSE 0.04159707283712695 Test RE 0.1477743483773046\n",
      "145 Train Loss 0.09431238 Test MSE 0.04104475340395428 Test RE 0.14679000762447678\n",
      "146 Train Loss 0.091570795 Test MSE 0.039764529200580774 Test RE 0.14448261391544906\n",
      "147 Train Loss 0.08483369 Test MSE 0.0346195344631684 Test RE 0.13481191547398594\n",
      "148 Train Loss 0.0823994 Test MSE 0.033688756624627655 Test RE 0.13298729697291614\n",
      "149 Train Loss 0.07888758 Test MSE 0.028544748679559296 Test RE 0.12241391270389597\n",
      "150 Train Loss 0.07433226 Test MSE 0.027816492693915295 Test RE 0.12084226384396753\n",
      "151 Train Loss 0.07090781 Test MSE 0.03051596528716256 Test RE 0.12657012929587994\n",
      "152 Train Loss 0.06805706 Test MSE 0.03055753420547243 Test RE 0.12665630701904673\n",
      "153 Train Loss 0.06420253 Test MSE 0.030842963692801 Test RE 0.12724646289284083\n",
      "154 Train Loss 0.06179612 Test MSE 0.03015154884331822 Test RE 0.125812120065101\n",
      "155 Train Loss 0.059553158 Test MSE 0.033642684597845904 Test RE 0.1328963305624243\n",
      "156 Train Loss 0.055139627 Test MSE 0.030548115788991814 Test RE 0.12663678656667088\n",
      "157 Train Loss 0.05230902 Test MSE 0.025220959836150428 Test RE 0.11506638597589548\n",
      "158 Train Loss 0.05070527 Test MSE 0.02622723866992421 Test RE 0.11733942395523626\n",
      "159 Train Loss 0.048060723 Test MSE 0.021586593542125977 Test RE 0.10645344605265802\n",
      "160 Train Loss 0.04567368 Test MSE 0.020010054050384057 Test RE 0.1024924320169428\n",
      "161 Train Loss 0.043965325 Test MSE 0.01893313885102986 Test RE 0.09969628550145686\n",
      "162 Train Loss 0.04298839 Test MSE 0.017584418804488716 Test RE 0.09607970855033288\n",
      "163 Train Loss 0.040661406 Test MSE 0.01489831028771095 Test RE 0.08843744257395934\n",
      "164 Train Loss 0.03898615 Test MSE 0.01355780202781296 Test RE 0.0843650001565639\n",
      "165 Train Loss 0.03797052 Test MSE 0.013458127203071279 Test RE 0.08405430896942938\n",
      "166 Train Loss 0.03739904 Test MSE 0.013680526043864901 Test RE 0.08474597220006592\n",
      "167 Train Loss 0.036411628 Test MSE 0.012199502527185751 Test RE 0.08002740385579422\n",
      "168 Train Loss 0.033268362 Test MSE 0.012312887638862173 Test RE 0.08039844069630143\n",
      "169 Train Loss 0.031720094 Test MSE 0.011362270653153378 Test RE 0.0772325248281766\n",
      "170 Train Loss 0.030936465 Test MSE 0.011859059059565188 Test RE 0.07890286693866819\n",
      "171 Train Loss 0.029956754 Test MSE 0.011455002365529899 Test RE 0.07754704606621877\n",
      "172 Train Loss 0.029425727 Test MSE 0.010340653436193665 Test RE 0.07367864990600562\n",
      "173 Train Loss 0.028413856 Test MSE 0.009358855520464228 Test RE 0.07009370864821662\n",
      "174 Train Loss 0.027635317 Test MSE 0.007795307498314079 Test RE 0.06397116992406444\n",
      "175 Train Loss 0.02650993 Test MSE 0.007392639410405244 Test RE 0.062297042481105014\n",
      "176 Train Loss 0.025892619 Test MSE 0.007369792716186766 Test RE 0.06220070457294039\n",
      "177 Train Loss 0.024721546 Test MSE 0.007036218111693656 Test RE 0.060776727838390776\n",
      "178 Train Loss 0.024245739 Test MSE 0.006624698412513985 Test RE 0.05897266084995143\n",
      "179 Train Loss 0.0235191 Test MSE 0.007324824175477083 Test RE 0.06201064802419869\n",
      "180 Train Loss 0.022541221 Test MSE 0.006727378516658215 Test RE 0.05942792952329601\n",
      "181 Train Loss 0.021641884 Test MSE 0.006430415120636477 Test RE 0.05810147699069546\n",
      "182 Train Loss 0.020859746 Test MSE 0.006522131461799413 Test RE 0.05851435764231801\n",
      "183 Train Loss 0.020088011 Test MSE 0.0071273244704308245 Test RE 0.06116893693235345\n",
      "184 Train Loss 0.019575404 Test MSE 0.006414780329558197 Test RE 0.058030800581884645\n",
      "185 Train Loss 0.019059597 Test MSE 0.005839633852851148 Test RE 0.05536820910729215\n",
      "186 Train Loss 0.018403878 Test MSE 0.005621035051121575 Test RE 0.05432200790059259\n",
      "187 Train Loss 0.017448256 Test MSE 0.005332115126520401 Test RE 0.05290752264921356\n",
      "188 Train Loss 0.016596895 Test MSE 0.005258558279635663 Test RE 0.05254132411199101\n",
      "189 Train Loss 0.01612376 Test MSE 0.004933662338305391 Test RE 0.05089233521390597\n",
      "190 Train Loss 0.015851228 Test MSE 0.005007138019182247 Test RE 0.05126989747559316\n",
      "191 Train Loss 0.015291488 Test MSE 0.00500202384547005 Test RE 0.0512437078491888\n",
      "192 Train Loss 0.0148239825 Test MSE 0.005190725535919649 Test RE 0.05220134590528684\n",
      "193 Train Loss 0.0144713055 Test MSE 0.005198536234842209 Test RE 0.05224060590150779\n",
      "194 Train Loss 0.01395105 Test MSE 0.004986932415005044 Test RE 0.05116634665858239\n",
      "195 Train Loss 0.013442428 Test MSE 0.005084628882720928 Test RE 0.05166510278084992\n",
      "196 Train Loss 0.013073204 Test MSE 0.0050900851125061895 Test RE 0.0516928158249142\n",
      "197 Train Loss 0.012706159 Test MSE 0.004646435003109863 Test RE 0.04938870067584059\n",
      "198 Train Loss 0.012565553 Test MSE 0.004716115091430374 Test RE 0.04975765048672913\n",
      "199 Train Loss 0.012321296 Test MSE 0.004517867200847601 Test RE 0.04870060968081763\n",
      "200 Train Loss 0.012057914 Test MSE 0.004595009652984018 Test RE 0.04911463056554235\n",
      "201 Train Loss 0.011806092 Test MSE 0.004464264931463104 Test RE 0.048410843257341074\n",
      "202 Train Loss 0.011541898 Test MSE 0.00408652830397292 Test RE 0.046317480066396285\n",
      "203 Train Loss 0.011278932 Test MSE 0.003848463185964327 Test RE 0.04494809974025168\n",
      "204 Train Loss 0.011034567 Test MSE 0.0035612733532369768 Test RE 0.043238470473549846\n",
      "205 Train Loss 0.010761631 Test MSE 0.0032777830401040974 Test RE 0.04148181683731527\n",
      "206 Train Loss 0.010606725 Test MSE 0.0032816221257946825 Test RE 0.04150610240532654\n",
      "207 Train Loss 0.010419402 Test MSE 0.0032628819036696084 Test RE 0.041387419141937005\n",
      "208 Train Loss 0.010154476 Test MSE 0.0032047967292090232 Test RE 0.041017379603689\n",
      "209 Train Loss 0.009887706 Test MSE 0.003106562071956007 Test RE 0.040383846778998825\n",
      "210 Train Loss 0.009674822 Test MSE 0.0027994907694018343 Test RE 0.03833603453245009\n",
      "211 Train Loss 0.009415627 Test MSE 0.0026571009564205846 Test RE 0.03734837369082446\n",
      "212 Train Loss 0.009083767 Test MSE 0.002378076478396141 Test RE 0.03533300511737295\n",
      "213 Train Loss 0.008957836 Test MSE 0.0021672631442914664 Test RE 0.03373055526018683\n",
      "214 Train Loss 0.008768622 Test MSE 0.0020489132544793762 Test RE 0.0327966476181118\n",
      "215 Train Loss 0.008562418 Test MSE 0.001985928812863773 Test RE 0.03228862164912756\n",
      "216 Train Loss 0.00844331 Test MSE 0.002083434677577766 Test RE 0.033071783168079356\n",
      "217 Train Loss 0.008385277 Test MSE 0.002186308974303674 Test RE 0.03387844251287089\n",
      "218 Train Loss 0.008229507 Test MSE 0.0023205840198614147 Test RE 0.03490328602918696\n",
      "219 Train Loss 0.008041007 Test MSE 0.0019247298240205922 Test RE 0.031787220576666095\n",
      "220 Train Loss 0.007944683 Test MSE 0.0018796051554135088 Test RE 0.03141239004561527\n",
      "221 Train Loss 0.007829686 Test MSE 0.0019250501687743868 Test RE 0.031789865739004726\n",
      "222 Train Loss 0.0077276113 Test MSE 0.0019030671888015823 Test RE 0.03160783346159534\n",
      "223 Train Loss 0.007628614 Test MSE 0.0017965194629136654 Test RE 0.030710269733031047\n",
      "224 Train Loss 0.0074614966 Test MSE 0.0015556287591651271 Test RE 0.02857726416203913\n",
      "225 Train Loss 0.007342253 Test MSE 0.0013527719792908713 Test RE 0.02664894172321204\n",
      "226 Train Loss 0.007237146 Test MSE 0.0014244053444239827 Test RE 0.027345411611690313\n",
      "227 Train Loss 0.007126472 Test MSE 0.0013864205932102788 Test RE 0.026978336538158485\n",
      "228 Train Loss 0.0070511512 Test MSE 0.001348151173218019 Test RE 0.02660338898821983\n",
      "229 Train Loss 0.007001174 Test MSE 0.001302057032453 Test RE 0.02614464031599202\n",
      "230 Train Loss 0.006970551 Test MSE 0.0012949271211165128 Test RE 0.026072959563069008\n",
      "231 Train Loss 0.006916903 Test MSE 0.0013428594169452818 Test RE 0.02655112590709798\n",
      "232 Train Loss 0.006865869 Test MSE 0.0013307672822154893 Test RE 0.026431312236616475\n",
      "233 Train Loss 0.0067821364 Test MSE 0.0012854608875703347 Test RE 0.0259774849058364\n",
      "234 Train Loss 0.0066828947 Test MSE 0.0011956402020200574 Test RE 0.025053472104951267\n",
      "235 Train Loss 0.006627399 Test MSE 0.0012221079330008507 Test RE 0.025329256925995434\n",
      "236 Train Loss 0.006598845 Test MSE 0.0011962373535879022 Test RE 0.025059727687772\n",
      "237 Train Loss 0.006524898 Test MSE 0.0012220893887417788 Test RE 0.025329064752263587\n",
      "238 Train Loss 0.006463536 Test MSE 0.001196042496496122 Test RE 0.02505768659429156\n",
      "239 Train Loss 0.0063970657 Test MSE 0.0011810342815292123 Test RE 0.0248999754906793\n",
      "240 Train Loss 0.0063151787 Test MSE 0.0010990826550067493 Test RE 0.024020544330107613\n",
      "241 Train Loss 0.006237251 Test MSE 0.00104247749953479 Test RE 0.023393812928326263\n",
      "242 Train Loss 0.0061767697 Test MSE 0.0009338093378415351 Test RE 0.02214097664745513\n",
      "243 Train Loss 0.0061115334 Test MSE 0.0009087424828728668 Test RE 0.0218417827640537\n",
      "244 Train Loss 0.0060495026 Test MSE 0.0009309785922680237 Test RE 0.022107392145906197\n",
      "245 Train Loss 0.005951014 Test MSE 0.0009695763952163708 Test RE 0.022561017613088947\n",
      "246 Train Loss 0.005903403 Test MSE 0.0009040589932730666 Test RE 0.02178542581562257\n",
      "247 Train Loss 0.0058263647 Test MSE 0.0008577525260218878 Test RE 0.021220160798368186\n",
      "248 Train Loss 0.005785903 Test MSE 0.0008665567360585523 Test RE 0.021328787576689257\n",
      "249 Train Loss 0.0057385378 Test MSE 0.0008820487175174881 Test RE 0.02151859709425509\n",
      "250 Train Loss 0.005702895 Test MSE 0.0008975388310683391 Test RE 0.021706724343405842\n",
      "251 Train Loss 0.0056408835 Test MSE 0.0008488144341331761 Test RE 0.021109310387417524\n",
      "252 Train Loss 0.005560921 Test MSE 0.0008095571107803463 Test RE 0.020615383277620018\n",
      "253 Train Loss 0.005523597 Test MSE 0.0007874437658606073 Test RE 0.02033187552330394\n",
      "254 Train Loss 0.0054690167 Test MSE 0.0008509959415925801 Test RE 0.021136419120636876\n",
      "255 Train Loss 0.005409795 Test MSE 0.00081090910152874 Test RE 0.02063259032827813\n",
      "256 Train Loss 0.00537402 Test MSE 0.0007750597296388331 Test RE 0.02017136341658897\n",
      "257 Train Loss 0.005329803 Test MSE 0.0007911807661899542 Test RE 0.02038006327750479\n",
      "258 Train Loss 0.0052948706 Test MSE 0.0007805501092559053 Test RE 0.02024268243857737\n",
      "259 Train Loss 0.0052665696 Test MSE 0.0007756557817016001 Test RE 0.020179118220266933\n",
      "260 Train Loss 0.0052529206 Test MSE 0.0007458812774330056 Test RE 0.019788028200651217\n",
      "261 Train Loss 0.005211139 Test MSE 0.0006767882439671441 Test RE 0.018849249835149136\n",
      "262 Train Loss 0.005172538 Test MSE 0.000665208066289429 Test RE 0.018687294121464134\n",
      "263 Train Loss 0.005121311 Test MSE 0.0006548074152521206 Test RE 0.01854062893021364\n",
      "264 Train Loss 0.0050520566 Test MSE 0.0006311539918361006 Test RE 0.01820267999911858\n",
      "265 Train Loss 0.0049833613 Test MSE 0.0005577276494572984 Test RE 0.01711113253992947\n",
      "266 Train Loss 0.0049182046 Test MSE 0.000526247736661393 Test RE 0.01662121579956264\n",
      "267 Train Loss 0.0048849164 Test MSE 0.00048750630698573476 Test RE 0.015997708790320142\n",
      "268 Train Loss 0.004836594 Test MSE 0.0004883376887289286 Test RE 0.016011344036877633\n",
      "269 Train Loss 0.004810301 Test MSE 0.0004791500117192031 Test RE 0.015860008626534253\n",
      "270 Train Loss 0.0047772164 Test MSE 0.00045668410928400264 Test RE 0.015483731002726731\n",
      "271 Train Loss 0.0047449125 Test MSE 0.0004454581589123526 Test RE 0.0152922407472423\n",
      "272 Train Loss 0.004692335 Test MSE 0.00045281937676142965 Test RE 0.015418075533742753\n",
      "273 Train Loss 0.0046281675 Test MSE 0.0004407209024191325 Test RE 0.01521071019598536\n",
      "274 Train Loss 0.00458624 Test MSE 0.0004370664706017332 Test RE 0.015147515764731079\n",
      "275 Train Loss 0.0045349356 Test MSE 0.0004541417954417954 Test RE 0.015440572679038209\n",
      "276 Train Loss 0.004510793 Test MSE 0.00043102788014774023 Test RE 0.015042511386462093\n",
      "277 Train Loss 0.0044858726 Test MSE 0.00039331367663818397 Test RE 0.014369352270413959\n",
      "278 Train Loss 0.0044399127 Test MSE 0.00038776599464354156 Test RE 0.014267652657612475\n",
      "279 Train Loss 0.004394596 Test MSE 0.0003538895461013458 Test RE 0.013630178222731703\n",
      "280 Train Loss 0.0043477635 Test MSE 0.00034020397683201943 Test RE 0.013364027500422409\n",
      "281 Train Loss 0.0042737485 Test MSE 0.0002922709077323896 Test RE 0.012386838116731443\n",
      "282 Train Loss 0.0042362856 Test MSE 0.0002664500166282701 Test RE 0.011827025780593114\n",
      "283 Train Loss 0.0042028488 Test MSE 0.0002587080492558169 Test RE 0.01165393625578939\n",
      "284 Train Loss 0.0041836663 Test MSE 0.0002642820965924671 Test RE 0.011778813336140545\n",
      "285 Train Loss 0.004158211 Test MSE 0.0002805068028343715 Test RE 0.012134988434384852\n",
      "286 Train Loss 0.0041389917 Test MSE 0.0002805856165955788 Test RE 0.01213669309341715\n",
      "287 Train Loss 0.0041101323 Test MSE 0.0002802587640956597 Test RE 0.012129622053110781\n",
      "288 Train Loss 0.004073588 Test MSE 0.0002490459071038291 Test RE 0.011434241801168182\n",
      "289 Train Loss 0.004037716 Test MSE 0.00023074542144702455 Test RE 0.011006119244391354\n",
      "290 Train Loss 0.004014451 Test MSE 0.00021370198278329464 Test RE 0.010591852969457539\n",
      "291 Train Loss 0.003995275 Test MSE 0.0002127341093806867 Test RE 0.010567840074142234\n",
      "292 Train Loss 0.00395769 Test MSE 0.00021197784279846065 Test RE 0.010549039093133372\n",
      "293 Train Loss 0.0039226273 Test MSE 0.00020577320174339984 Test RE 0.01039350609770261\n",
      "294 Train Loss 0.003907949 Test MSE 0.00020556566801777245 Test RE 0.010388263560862677\n",
      "295 Train Loss 0.0038830577 Test MSE 0.0002045884196335208 Test RE 0.010363541514475057\n",
      "296 Train Loss 0.0038547793 Test MSE 0.00018527263185423752 Test RE 0.009862188589694407\n",
      "297 Train Loss 0.003827077 Test MSE 0.00016723315541599914 Test RE 0.00936976847688075\n",
      "298 Train Loss 0.0037807552 Test MSE 0.00015459312996804028 Test RE 0.00900871323621812\n",
      "299 Train Loss 0.0037400427 Test MSE 0.00014975655957810932 Test RE 0.008866671012771204\n",
      "Training time: 247.29\n",
      "KG_atanh_medium\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 34011.32 Test MSE 6.989423639813244 Test RE 1.9155273176833445\n",
      "1 Train Loss 11280.438 Test MSE 10.707767069546845 Test RE 2.3709212287669943\n",
      "2 Train Loss 8097.4307 Test MSE 10.109332123417605 Test RE 2.3037157951639045\n",
      "3 Train Loss 5911.1523 Test MSE 9.906082687654846 Test RE 2.2804399575307595\n",
      "4 Train Loss 4068.8467 Test MSE 9.458996710379083 Test RE 2.2283848894106293\n",
      "5 Train Loss 1734.6531 Test MSE 10.20237998894398 Test RE 2.3142933907334875\n",
      "6 Train Loss 769.7907 Test MSE 11.869282341546864 Test RE 2.4962029841301274\n",
      "7 Train Loss 293.64346 Test MSE 13.347756034396175 Test RE 2.6471088361799655\n",
      "8 Train Loss 137.6513 Test MSE 14.471835498937843 Test RE 2.7563189839466116\n",
      "9 Train Loss 73.88216 Test MSE 15.35450716280482 Test RE 2.839132154541962\n",
      "10 Train Loss 50.4196 Test MSE 15.749242538600301 Test RE 2.875394934003278\n",
      "11 Train Loss 38.95205 Test MSE 15.800731258531233 Test RE 2.8800913375553607\n",
      "12 Train Loss 33.701084 Test MSE 15.94054249579166 Test RE 2.8928053791158117\n",
      "13 Train Loss 29.55217 Test MSE 15.679801203546974 Test RE 2.8690488558976845\n",
      "14 Train Loss 26.610819 Test MSE 15.731063857404381 Test RE 2.8737349817891684\n",
      "15 Train Loss 24.225475 Test MSE 15.643916894288598 Test RE 2.8657639670515724\n",
      "16 Train Loss 22.630962 Test MSE 15.582485549386517 Test RE 2.8601317170091067\n",
      "17 Train Loss 21.232515 Test MSE 15.493080697290088 Test RE 2.85191487980222\n",
      "18 Train Loss 20.31702 Test MSE 15.41874145499534 Test RE 2.845064592110311\n",
      "19 Train Loss 19.63504 Test MSE 15.348507788943284 Test RE 2.8385774418708323\n",
      "20 Train Loss 19.007776 Test MSE 15.21084515995732 Test RE 2.8258189966468126\n",
      "21 Train Loss 18.439945 Test MSE 15.241560757737178 Test RE 2.8286706773172883\n",
      "22 Train Loss 18.092068 Test MSE 15.151056164145814 Test RE 2.8202598304568864\n",
      "23 Train Loss 17.706398 Test MSE 15.046744400174305 Test RE 2.8105346212867364\n",
      "24 Train Loss 17.303335 Test MSE 14.925086590099738 Test RE 2.7991495194042\n",
      "25 Train Loss 16.736677 Test MSE 14.750640865801845 Test RE 2.782743085694181\n",
      "26 Train Loss 16.347466 Test MSE 14.520665507557613 Test RE 2.7609651720054824\n",
      "27 Train Loss 15.710948 Test MSE 14.30439843333528 Test RE 2.7403274864537854\n",
      "28 Train Loss 15.022688 Test MSE 13.858865902176685 Test RE 2.6973140459850105\n",
      "29 Train Loss 14.247722 Test MSE 13.702008284985828 Test RE 2.682006218917683\n",
      "30 Train Loss 13.770305 Test MSE 13.47655708202507 Test RE 2.6598499974258134\n",
      "31 Train Loss 13.352761 Test MSE 13.291066997209533 Test RE 2.6414816085907225\n",
      "32 Train Loss 12.743575 Test MSE 12.928716584151374 Test RE 2.6052258290071193\n",
      "33 Train Loss 12.117567 Test MSE 12.412382402410827 Test RE 2.5526733309563987\n",
      "34 Train Loss 11.442362 Test MSE 11.791547697431632 Test RE 2.4880154545425617\n",
      "35 Train Loss 10.913672 Test MSE 11.282285960055228 Test RE 2.433695388677991\n",
      "36 Train Loss 10.314965 Test MSE 10.74983336171873 Test RE 2.3755738375416335\n",
      "37 Train Loss 9.821762 Test MSE 10.118888235070864 Test RE 2.304804361900223\n",
      "38 Train Loss 9.392867 Test MSE 9.807380043689712 Test RE 2.269050544072265\n",
      "39 Train Loss 8.69848 Test MSE 9.057691153907657 Test RE 2.1806020786288394\n",
      "40 Train Loss 8.234736 Test MSE 8.314083475911815 Test RE 2.0891751815206066\n",
      "41 Train Loss 7.7357965 Test MSE 7.783516612906071 Test RE 2.0214155209244447\n",
      "42 Train Loss 6.862154 Test MSE 6.471209621872435 Test RE 1.843148816482576\n",
      "43 Train Loss 6.184473 Test MSE 5.13322251484134 Test RE 1.6415824969537753\n",
      "44 Train Loss 5.4082584 Test MSE 4.79417457614131 Test RE 1.5864434278593398\n",
      "45 Train Loss 4.951219 Test MSE 4.451744585458742 Test RE 1.528737036245704\n",
      "46 Train Loss 4.363517 Test MSE 4.032125711109491 Test RE 1.4549052115742882\n",
      "47 Train Loss 3.9803772 Test MSE 3.745504277156836 Test RE 1.4022415006648559\n",
      "48 Train Loss 3.665664 Test MSE 3.4456588672456165 Test RE 1.3449427770245652\n",
      "49 Train Loss 3.497713 Test MSE 3.284898926503479 Test RE 1.3131933453662124\n",
      "50 Train Loss 3.30949 Test MSE 2.9110269654008394 Test RE 1.236205814178977\n",
      "51 Train Loss 3.1057014 Test MSE 2.7136538251445237 Test RE 1.1935617432335928\n",
      "52 Train Loss 2.9282117 Test MSE 2.401377756371309 Test RE 1.122788380082465\n",
      "53 Train Loss 2.7047498 Test MSE 2.0927006794693606 Test RE 1.0481446581668152\n",
      "54 Train Loss 2.5296671 Test MSE 1.8226713897776374 Test RE 0.9781869304859732\n",
      "55 Train Loss 2.3798382 Test MSE 1.6355999607944052 Test RE 0.9266296945485263\n",
      "56 Train Loss 2.1501968 Test MSE 1.2272725154721313 Test RE 0.8026721077662561\n",
      "57 Train Loss 1.9423834 Test MSE 0.8761105076828559 Test RE 0.6781833327285206\n",
      "58 Train Loss 1.7939055 Test MSE 0.5868748714406105 Test RE 0.555060630788555\n",
      "59 Train Loss 1.5295829 Test MSE 0.3147117584637625 Test RE 0.40646593335772924\n",
      "60 Train Loss 1.2991422 Test MSE 0.19694092920129114 Test RE 0.32154048239335636\n",
      "61 Train Loss 1.0518909 Test MSE 0.10810851253163863 Test RE 0.23823063788556173\n",
      "62 Train Loss 0.88901675 Test MSE 0.08030142555646737 Test RE 0.20531907321594173\n",
      "63 Train Loss 0.7493046 Test MSE 0.06745789860540168 Test RE 0.1881845963283908\n",
      "64 Train Loss 0.60931873 Test MSE 0.05005504983810572 Test RE 0.16210321066845035\n",
      "65 Train Loss 0.5017837 Test MSE 0.029190201576037234 Test RE 0.1237901857712437\n",
      "66 Train Loss 0.4344045 Test MSE 0.023943085076618183 Test RE 0.11211345127568875\n",
      "67 Train Loss 0.38597313 Test MSE 0.018366436177495844 Test RE 0.09819290635470586\n",
      "68 Train Loss 0.338947 Test MSE 0.01827614156428304 Test RE 0.09795123686086372\n",
      "69 Train Loss 0.29221806 Test MSE 0.015585405119105453 Test RE 0.09045377896005542\n",
      "70 Train Loss 0.2673168 Test MSE 0.015443920115995925 Test RE 0.09004227118858248\n",
      "71 Train Loss 0.22997713 Test MSE 0.012434083087001427 Test RE 0.08079315172245347\n",
      "72 Train Loss 0.20556033 Test MSE 0.01150623733143702 Test RE 0.0777202755158237\n",
      "73 Train Loss 0.18189661 Test MSE 0.010462321490800253 Test RE 0.07411083359081083\n",
      "74 Train Loss 0.15830848 Test MSE 0.009837871848868994 Test RE 0.0718651353983834\n",
      "75 Train Loss 0.14329751 Test MSE 0.00971976324069208 Test RE 0.07143244422894837\n",
      "76 Train Loss 0.13071933 Test MSE 0.008273465305090677 Test RE 0.06590394203869579\n",
      "77 Train Loss 0.115626834 Test MSE 0.0063055657132752374 Test RE 0.057534679167655436\n",
      "78 Train Loss 0.10723007 Test MSE 0.006378478925902771 Test RE 0.057866368738879154\n",
      "79 Train Loss 0.095771186 Test MSE 0.0028812001580393763 Test RE 0.03889147214138079\n",
      "80 Train Loss 0.08772271 Test MSE 0.0013792416898371867 Test RE 0.026908398802069442\n",
      "81 Train Loss 0.08116737 Test MSE 0.001103016623628701 Test RE 0.024063494539685003\n",
      "82 Train Loss 0.075301126 Test MSE 0.0013036915017533793 Test RE 0.026161044823925814\n",
      "83 Train Loss 0.07035747 Test MSE 0.0014971784578162535 Test RE 0.028035251243252016\n",
      "84 Train Loss 0.06646772 Test MSE 0.001517279338692963 Test RE 0.028222822189591296\n",
      "85 Train Loss 0.06437703 Test MSE 0.0016053484815226782 Test RE 0.029030353781588865\n",
      "86 Train Loss 0.060630817 Test MSE 0.0015096306453292157 Test RE 0.02815159586838013\n",
      "87 Train Loss 0.057897966 Test MSE 0.0014008034484876333 Test RE 0.027117913353890518\n",
      "88 Train Loss 0.05410861 Test MSE 0.0011457655018735269 Test RE 0.024525368334997886\n",
      "89 Train Loss 0.051210936 Test MSE 0.0008393924430364907 Test RE 0.02099182490142287\n",
      "90 Train Loss 0.04928364 Test MSE 0.0008545784743358361 Test RE 0.021180862568269582\n",
      "91 Train Loss 0.047263425 Test MSE 0.0009872547362670778 Test RE 0.022765766681385045\n",
      "92 Train Loss 0.044753075 Test MSE 0.0014969686340103841 Test RE 0.028033286658068722\n",
      "93 Train Loss 0.043437615 Test MSE 0.0013747238031196886 Test RE 0.02686429166127879\n",
      "94 Train Loss 0.041543942 Test MSE 0.0017607156821638807 Test RE 0.030402709082131364\n",
      "95 Train Loss 0.039612133 Test MSE 0.002346623376931633 Test RE 0.03509856526488047\n",
      "96 Train Loss 0.037133753 Test MSE 0.002470168267073031 Test RE 0.03601064802921477\n",
      "97 Train Loss 0.034845836 Test MSE 0.0024236590711249825 Test RE 0.035670026508715175\n",
      "98 Train Loss 0.033475503 Test MSE 0.0025854239483344126 Test RE 0.03684118164253114\n",
      "99 Train Loss 0.032196403 Test MSE 0.0024762392860881626 Test RE 0.03605487318754517\n",
      "100 Train Loss 0.03102151 Test MSE 0.0024796043720349352 Test RE 0.036079363259273876\n",
      "101 Train Loss 0.030121602 Test MSE 0.002608863318809548 Test RE 0.03700780532811119\n",
      "102 Train Loss 0.029155416 Test MSE 0.002306125176008194 Test RE 0.03479438031538376\n",
      "103 Train Loss 0.027658327 Test MSE 0.002728760201195181 Test RE 0.03784864653666028\n",
      "104 Train Loss 0.026173605 Test MSE 0.002741541090690484 Test RE 0.03793718019751276\n",
      "105 Train Loss 0.02513234 Test MSE 0.0025962771167549036 Test RE 0.03691842715755223\n",
      "106 Train Loss 0.024618689 Test MSE 0.0026118567358854616 Test RE 0.03702903067107343\n",
      "107 Train Loss 0.02417799 Test MSE 0.0024124967714371803 Test RE 0.03558779154716004\n",
      "108 Train Loss 0.02359732 Test MSE 0.0025240680869126546 Test RE 0.03640140952282533\n",
      "109 Train Loss 0.022691527 Test MSE 0.002142254865781006 Test RE 0.033535380369288915\n",
      "110 Train Loss 0.02209197 Test MSE 0.0019070572978542853 Test RE 0.03164095175215667\n",
      "111 Train Loss 0.020831194 Test MSE 0.0018191098399325813 Test RE 0.030902750047438882\n",
      "112 Train Loss 0.02011131 Test MSE 0.001871060674682622 Test RE 0.031340910062652556\n",
      "113 Train Loss 0.019505206 Test MSE 0.0016331714947017979 Test RE 0.029280842140911173\n",
      "114 Train Loss 0.018988665 Test MSE 0.0015738001814879759 Test RE 0.028743686214920985\n",
      "115 Train Loss 0.01772254 Test MSE 0.0015074598218034801 Test RE 0.028131347825536803\n",
      "116 Train Loss 0.01709171 Test MSE 0.0013450857220891278 Test RE 0.02657312613585122\n",
      "117 Train Loss 0.016648678 Test MSE 0.0013121250595638245 Test RE 0.026245526090795196\n",
      "118 Train Loss 0.01602584 Test MSE 0.0011822424757113995 Test RE 0.024912708531526672\n",
      "119 Train Loss 0.015386181 Test MSE 0.0008735201580091004 Test RE 0.021414312369600234\n",
      "120 Train Loss 0.014878934 Test MSE 0.0007944911116898372 Test RE 0.020422654447235022\n",
      "121 Train Loss 0.014337356 Test MSE 0.0008525117998840834 Test RE 0.02115523563865379\n",
      "122 Train Loss 0.013811423 Test MSE 0.0009543951046555259 Test RE 0.022383694468173516\n",
      "123 Train Loss 0.013410602 Test MSE 0.0009575189162620274 Test RE 0.022420296354666528\n",
      "124 Train Loss 0.012902788 Test MSE 0.0009181505141546544 Test RE 0.021954553471981365\n",
      "125 Train Loss 0.0123250345 Test MSE 0.0009187794576692304 Test RE 0.02196207174372951\n",
      "126 Train Loss 0.01184123 Test MSE 0.000902929992069796 Test RE 0.021771818597606345\n",
      "127 Train Loss 0.011354761 Test MSE 0.0009178481100909595 Test RE 0.02195093767432883\n",
      "128 Train Loss 0.011056265 Test MSE 0.0010285382930865393 Test RE 0.023236884554601808\n",
      "129 Train Loss 0.01061775 Test MSE 0.0012859122667820838 Test RE 0.0259820453975667\n",
      "130 Train Loss 0.010161598 Test MSE 0.0013132024788436035 Test RE 0.02625629931441575\n",
      "131 Train Loss 0.009941318 Test MSE 0.001366111375947816 Test RE 0.026780009180856715\n",
      "132 Train Loss 0.009672158 Test MSE 0.0012281675013279905 Test RE 0.025391974208982412\n",
      "133 Train Loss 0.009285349 Test MSE 0.0012318092692069872 Test RE 0.025429592542004248\n",
      "134 Train Loss 0.008907282 Test MSE 0.0012133276428421154 Test RE 0.025238103305974334\n",
      "135 Train Loss 0.008671334 Test MSE 0.0011001752808248969 Test RE 0.024032481078996065\n",
      "136 Train Loss 0.008469852 Test MSE 0.001078318719165343 Test RE 0.02379256365329331\n",
      "137 Train Loss 0.00829449 Test MSE 0.0011132354153002534 Test RE 0.02417470452803328\n",
      "138 Train Loss 0.008078182 Test MSE 0.0011071684135819135 Test RE 0.024108739886111046\n",
      "139 Train Loss 0.007855765 Test MSE 0.0011651124434312358 Test RE 0.024731564360992504\n",
      "140 Train Loss 0.0076832627 Test MSE 0.0012724114113452142 Test RE 0.025845292126422545\n",
      "141 Train Loss 0.0074924184 Test MSE 0.0012280687923110355 Test RE 0.025390953799643772\n",
      "142 Train Loss 0.007330204 Test MSE 0.001154792188910714 Test RE 0.024621787935274895\n",
      "143 Train Loss 0.0071902685 Test MSE 0.001109889320323412 Test RE 0.024138345761506055\n",
      "144 Train Loss 0.007060184 Test MSE 0.0010586853506140575 Test RE 0.0235749684103394\n",
      "145 Train Loss 0.006842042 Test MSE 0.0010223326369627932 Test RE 0.02316667896218117\n",
      "146 Train Loss 0.006682017 Test MSE 0.0009550226222693746 Test RE 0.02239105193175627\n",
      "147 Train Loss 0.006563913 Test MSE 0.000918662667528455 Test RE 0.021960675851088962\n",
      "148 Train Loss 0.0063976883 Test MSE 0.0008123232701846027 Test RE 0.02065057338733876\n",
      "149 Train Loss 0.0061862664 Test MSE 0.0006573610137568977 Test RE 0.018576745849499872\n",
      "150 Train Loss 0.006029059 Test MSE 0.0006172191205569862 Test RE 0.01800061541911475\n",
      "151 Train Loss 0.0059004 Test MSE 0.0005681447109089221 Test RE 0.017270191436267266\n",
      "152 Train Loss 0.0057710544 Test MSE 0.0005718453706926503 Test RE 0.017326345587334493\n",
      "153 Train Loss 0.005657319 Test MSE 0.0005349813730653281 Test RE 0.01675857155983544\n",
      "154 Train Loss 0.005603332 Test MSE 0.0005263356898066062 Test RE 0.016622604714923047\n",
      "155 Train Loss 0.005458066 Test MSE 0.0004905717312359802 Test RE 0.01604792651578556\n",
      "156 Train Loss 0.00539675 Test MSE 0.0004931171832571234 Test RE 0.016089506953825872\n",
      "157 Train Loss 0.0053063654 Test MSE 0.00047203243309951713 Test RE 0.015741770900301502\n",
      "158 Train Loss 0.0052632876 Test MSE 0.00048379358522866506 Test RE 0.01593667516099046\n",
      "159 Train Loss 0.005205382 Test MSE 0.0004890293640470877 Test RE 0.01602267915703329\n",
      "160 Train Loss 0.0051539936 Test MSE 0.000478482724859821 Test RE 0.0158489610815982\n",
      "161 Train Loss 0.0051119737 Test MSE 0.00047824522847009096 Test RE 0.015845027252814732\n",
      "162 Train Loss 0.0050403923 Test MSE 0.0005007222482928025 Test RE 0.016213101887600605\n",
      "163 Train Loss 0.004966232 Test MSE 0.0004882097099116726 Test RE 0.016009245850325243\n",
      "164 Train Loss 0.0048765 Test MSE 0.0005022057569216689 Test RE 0.016237101707689428\n",
      "165 Train Loss 0.004783899 Test MSE 0.0005135492267621339 Test RE 0.016419453854353512\n",
      "166 Train Loss 0.00468274 Test MSE 0.0005212832599732769 Test RE 0.01654263002763607\n",
      "167 Train Loss 0.0046063173 Test MSE 0.0005258134309899092 Test RE 0.01661435574319196\n",
      "168 Train Loss 0.0045541897 Test MSE 0.0005356429852308057 Test RE 0.016768931031642\n",
      "169 Train Loss 0.0045038518 Test MSE 0.0005519995957252118 Test RE 0.017023037171722624\n",
      "170 Train Loss 0.0044543166 Test MSE 0.0005434484172616094 Test RE 0.01689066824052963\n",
      "171 Train Loss 0.004425249 Test MSE 0.0005439326115010382 Test RE 0.016898191073563766\n",
      "172 Train Loss 0.0043665357 Test MSE 0.0005327259390072323 Test RE 0.016723207921712054\n",
      "173 Train Loss 0.004293255 Test MSE 0.0005386396845487873 Test RE 0.016815773198454977\n",
      "174 Train Loss 0.0042359713 Test MSE 0.0005701077438260353 Test RE 0.017300001377208576\n",
      "175 Train Loss 0.0041861944 Test MSE 0.0005803163622194519 Test RE 0.017454205124594262\n",
      "176 Train Loss 0.0041647954 Test MSE 0.0005789031531204953 Test RE 0.017432939588597186\n",
      "177 Train Loss 0.0041440935 Test MSE 0.000586462274777071 Test RE 0.017546387165376365\n",
      "178 Train Loss 0.0041089975 Test MSE 0.0005972560411811595 Test RE 0.017707120522243557\n",
      "179 Train Loss 0.0040553794 Test MSE 0.0006209581506440897 Test RE 0.018055055744329855\n",
      "180 Train Loss 0.003998484 Test MSE 0.0006335188178801815 Test RE 0.01823674928014387\n",
      "181 Train Loss 0.003968885 Test MSE 0.0006452255934073891 Test RE 0.018404476147818656\n",
      "182 Train Loss 0.003933621 Test MSE 0.0006376385472928675 Test RE 0.018295949357348483\n",
      "183 Train Loss 0.0038913712 Test MSE 0.0006205786521881988 Test RE 0.018049537729172133\n",
      "184 Train Loss 0.0038270287 Test MSE 0.0006189670952985417 Test RE 0.018026086418347465\n",
      "185 Train Loss 0.0037841264 Test MSE 0.0006048813051037236 Test RE 0.017819796851259385\n",
      "186 Train Loss 0.003747647 Test MSE 0.0006010131935717842 Test RE 0.01776272820648712\n",
      "187 Train Loss 0.0037235855 Test MSE 0.0006199542686433706 Test RE 0.018040455342539875\n",
      "188 Train Loss 0.0036889021 Test MSE 0.0006431151773306835 Test RE 0.018374352641138278\n",
      "189 Train Loss 0.0036236828 Test MSE 0.0006109826128257889 Test RE 0.01790944358710525\n",
      "190 Train Loss 0.0035560844 Test MSE 0.0005973170771617921 Test RE 0.017708025279818247\n",
      "191 Train Loss 0.0035053524 Test MSE 0.0005962040194780516 Test RE 0.017691518766787206\n",
      "192 Train Loss 0.0034471245 Test MSE 0.0006086215603892316 Test RE 0.017874805886437063\n",
      "193 Train Loss 0.0034074807 Test MSE 0.0005971928658787792 Test RE 0.017706184004067656\n",
      "194 Train Loss 0.0033570023 Test MSE 0.0005925939529610356 Test RE 0.017637875607606573\n",
      "195 Train Loss 0.00330286 Test MSE 0.0005670024960664808 Test RE 0.017252822451607152\n",
      "196 Train Loss 0.0032460226 Test MSE 0.0005309945794952385 Test RE 0.01669601058972102\n",
      "197 Train Loss 0.0032085625 Test MSE 0.0005333426632048181 Test RE 0.016732885152538977\n",
      "198 Train Loss 0.0031674628 Test MSE 0.0005363187990912816 Test RE 0.016779506269262275\n",
      "199 Train Loss 0.003140421 Test MSE 0.0005356160831273587 Test RE 0.016768509925425598\n",
      "200 Train Loss 0.0031125424 Test MSE 0.0005254879661267573 Test RE 0.01660921301982566\n",
      "201 Train Loss 0.0030845602 Test MSE 0.000510710184231574 Test RE 0.016374005307282183\n",
      "202 Train Loss 0.0030471054 Test MSE 0.0005010851169308591 Test RE 0.016218975563802574\n",
      "203 Train Loss 0.003007194 Test MSE 0.0005047471862908129 Test RE 0.01627813406540376\n",
      "204 Train Loss 0.0029694312 Test MSE 0.0005166498666476872 Test RE 0.01646894686917282\n",
      "205 Train Loss 0.0029242453 Test MSE 0.0005075727982077005 Test RE 0.016323633573458698\n",
      "206 Train Loss 0.0028975464 Test MSE 0.0005128364454594854 Test RE 0.016408055196851446\n",
      "207 Train Loss 0.0028539943 Test MSE 0.0005224652666463283 Test RE 0.01656137456517601\n",
      "208 Train Loss 0.0028275556 Test MSE 0.0005109163629932536 Test RE 0.016377310147857743\n",
      "209 Train Loss 0.0028135867 Test MSE 0.0005111036562623959 Test RE 0.01638031169480407\n",
      "210 Train Loss 0.0027975058 Test MSE 0.000502372548754699 Test RE 0.016239797804951116\n",
      "211 Train Loss 0.0027871486 Test MSE 0.0005012822127426729 Test RE 0.016222165019809373\n",
      "212 Train Loss 0.0027771248 Test MSE 0.0005002015775321564 Test RE 0.016204670183434394\n",
      "213 Train Loss 0.0027609307 Test MSE 0.0004994677582209943 Test RE 0.01619277931291093\n",
      "214 Train Loss 0.002749523 Test MSE 0.0004890003619656163 Test RE 0.016022204034300033\n",
      "215 Train Loss 0.0027341337 Test MSE 0.0004939857912467384 Test RE 0.016103671259852168\n",
      "216 Train Loss 0.0027161904 Test MSE 0.0004932638195421927 Test RE 0.016091899012184583\n",
      "217 Train Loss 0.0026927046 Test MSE 0.000488371199706669 Test RE 0.016011893397086103\n",
      "218 Train Loss 0.0026589134 Test MSE 0.0004811382556257247 Test RE 0.015892880295240254\n",
      "219 Train Loss 0.0026340291 Test MSE 0.00047221492439830334 Test RE 0.015744813549930698\n",
      "220 Train Loss 0.0026069917 Test MSE 0.0004750048115316477 Test RE 0.01579125592329731\n",
      "221 Train Loss 0.0025890714 Test MSE 0.00047823077513716247 Test RE 0.015844787820018722\n",
      "222 Train Loss 0.0025631695 Test MSE 0.000464914011506839 Test RE 0.015622624170894595\n",
      "223 Train Loss 0.0025435584 Test MSE 0.0004590189038541523 Test RE 0.015523260780764206\n",
      "224 Train Loss 0.0025220779 Test MSE 0.00045227809044193576 Test RE 0.015408857632195527\n",
      "225 Train Loss 0.0024993652 Test MSE 0.00044321420239832275 Test RE 0.015253675455981042\n",
      "226 Train Loss 0.0024779993 Test MSE 0.0004326902027027446 Test RE 0.0150714903042261\n",
      "227 Train Loss 0.0024611217 Test MSE 0.00043183007264248146 Test RE 0.015056502802094543\n",
      "228 Train Loss 0.002445318 Test MSE 0.00042374948490377643 Test RE 0.014914965711905252\n",
      "229 Train Loss 0.0024179108 Test MSE 0.00042907247771160407 Test RE 0.015008351647905099\n",
      "230 Train Loss 0.002392701 Test MSE 0.00042678118801114977 Test RE 0.014968224960912315\n",
      "231 Train Loss 0.0023618315 Test MSE 0.00041515700838573393 Test RE 0.014762973987887803\n",
      "232 Train Loss 0.002336128 Test MSE 0.0004178386794323942 Test RE 0.014810577320614577\n",
      "233 Train Loss 0.0023096483 Test MSE 0.00041460669147083993 Test RE 0.014753186114571519\n",
      "234 Train Loss 0.002287168 Test MSE 0.0004184552707335496 Test RE 0.014821501042012367\n",
      "235 Train Loss 0.0022733721 Test MSE 0.00041640161552539416 Test RE 0.014785086528495424\n",
      "236 Train Loss 0.002247225 Test MSE 0.00039944894075840645 Test RE 0.014480991698637516\n",
      "237 Train Loss 0.0022231352 Test MSE 0.00040119354176420364 Test RE 0.014512580251538423\n",
      "238 Train Loss 0.0021968042 Test MSE 0.0003861112451636581 Test RE 0.014237177277282131\n",
      "239 Train Loss 0.0021749379 Test MSE 0.00037700547491764826 Test RE 0.014068295961810392\n",
      "240 Train Loss 0.0021522471 Test MSE 0.00037899416919894284 Test RE 0.014105352110028762\n",
      "241 Train Loss 0.0021368302 Test MSE 0.000375566984014703 Test RE 0.014041431024748087\n",
      "242 Train Loss 0.0021084684 Test MSE 0.0003706712020825484 Test RE 0.013949610802991794\n",
      "243 Train Loss 0.0020854848 Test MSE 0.0003674679867040507 Test RE 0.013889206107215018\n",
      "244 Train Loss 0.0020621433 Test MSE 0.0003537753010414141 Test RE 0.013627977951149345\n",
      "245 Train Loss 0.0020414398 Test MSE 0.0003422167229688015 Test RE 0.013403501946809268\n",
      "246 Train Loss 0.0020217488 Test MSE 0.0003362426019469156 Test RE 0.013285993526686449\n",
      "247 Train Loss 0.0019948187 Test MSE 0.0003373146019026066 Test RE 0.013307155703177186\n",
      "248 Train Loss 0.0019672408 Test MSE 0.0003365829543363222 Test RE 0.01329271601797345\n",
      "249 Train Loss 0.0019479576 Test MSE 0.00032601121645751475 Test RE 0.01308229502210543\n",
      "250 Train Loss 0.0019321047 Test MSE 0.0003260228196446651 Test RE 0.013082527828461765\n",
      "251 Train Loss 0.0019162722 Test MSE 0.0003273552375089539 Test RE 0.013109233965293014\n",
      "252 Train Loss 0.0018963994 Test MSE 0.00032439060033193995 Test RE 0.013049738178750773\n",
      "253 Train Loss 0.0018882084 Test MSE 0.0003218625283705034 Test RE 0.012998788482030824\n",
      "254 Train Loss 0.0018743724 Test MSE 0.00032267589919875416 Test RE 0.013015202576965012\n",
      "255 Train Loss 0.0018577039 Test MSE 0.00032300227717942586 Test RE 0.013021783176779912\n",
      "256 Train Loss 0.0018423228 Test MSE 0.00032786761593943755 Test RE 0.013119489280743463\n",
      "257 Train Loss 0.001829879 Test MSE 0.00032527285229028797 Test RE 0.01306747195330443\n",
      "258 Train Loss 0.0018210381 Test MSE 0.0003206655773048934 Test RE 0.012974595846139442\n",
      "259 Train Loss 0.0018098151 Test MSE 0.00032600534518302505 Test RE 0.013082177219270763\n",
      "260 Train Loss 0.0017901628 Test MSE 0.0003180862763226269 Test RE 0.012922309355746928\n",
      "261 Train Loss 0.0017749106 Test MSE 0.00031437624193787756 Test RE 0.01284672793069405\n",
      "262 Train Loss 0.0017615389 Test MSE 0.0003191268814845636 Test RE 0.012943429477768196\n",
      "263 Train Loss 0.0017466614 Test MSE 0.00032383771710916686 Test RE 0.013038612612574895\n",
      "264 Train Loss 0.0017393472 Test MSE 0.0003195440302172251 Test RE 0.012951886258165797\n",
      "265 Train Loss 0.0017251372 Test MSE 0.0003143197351749971 Test RE 0.012845573327490884\n",
      "266 Train Loss 0.0017140565 Test MSE 0.00031673148254469637 Test RE 0.012894760626120577\n",
      "267 Train Loss 0.0017055692 Test MSE 0.0003079923878215756 Test RE 0.012715623463874181\n",
      "268 Train Loss 0.0016995991 Test MSE 0.000307752397210373 Test RE 0.012710668430788654\n",
      "269 Train Loss 0.0016927227 Test MSE 0.0003053506979028569 Test RE 0.012660974267644821\n",
      "270 Train Loss 0.0016790029 Test MSE 0.00029890293052167033 Test RE 0.01252658685929356\n",
      "271 Train Loss 0.0016692239 Test MSE 0.00029698225987349864 Test RE 0.012486275741835503\n",
      "272 Train Loss 0.001666888 Test MSE 0.0002958778101395131 Test RE 0.012463036459477793\n",
      "273 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "274 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "275 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "276 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "277 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "278 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "279 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "280 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "281 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "282 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "283 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "284 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "285 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "286 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "287 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "288 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "289 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "290 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "291 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "292 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "293 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "294 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "295 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "296 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "297 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "298 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "299 Train Loss 0.0016668867 Test MSE 0.0002958778104432379 Test RE 0.012463036465874577\n",
      "Training time: 229.77\n",
      "KG_atanh_medium\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 37210.22 Test MSE 8.01582933920734 Test RE 2.0513600753389483\n",
      "1 Train Loss 10709.98 Test MSE 9.951855244037754 Test RE 2.285702444725813\n",
      "2 Train Loss 7873.459 Test MSE 10.167342654582086 Test RE 2.310316063441779\n",
      "3 Train Loss 5680.9785 Test MSE 12.144340543560228 Test RE 2.524960776866701\n",
      "4 Train Loss 1805.2657 Test MSE 15.106121562303088 Test RE 2.8160745990156926\n",
      "5 Train Loss 1042.6691 Test MSE 20.142612519729628 Test RE 3.2518130291436416\n",
      "6 Train Loss 794.1003 Test MSE 23.353002394728588 Test RE 3.501378249425465\n",
      "7 Train Loss 580.27026 Test MSE 25.9300456154346 Test RE 3.689515235255095\n",
      "8 Train Loss 403.71106 Test MSE 27.22312735247441 Test RE 3.780390603943374\n",
      "9 Train Loss 251.8242 Test MSE 28.53180990324934 Test RE 3.8701903752648077\n",
      "10 Train Loss 172.66031 Test MSE 29.33112729234464 Test RE 3.924027524275102\n",
      "11 Train Loss 135.78645 Test MSE 29.360062618167316 Test RE 3.9259625850198736\n",
      "12 Train Loss 122.24096 Test MSE 29.41895287251307 Test RE 3.9298979498540585\n",
      "13 Train Loss 109.67863 Test MSE 29.30699344930093 Test RE 3.9224128343286098\n",
      "14 Train Loss 96.696945 Test MSE 28.838943332159825 Test RE 3.890965136354457\n",
      "15 Train Loss 85.426926 Test MSE 28.838217953673016 Test RE 3.8909162018266126\n",
      "16 Train Loss 77.29554 Test MSE 28.798614168522825 Test RE 3.888243568744398\n",
      "17 Train Loss 70.489426 Test MSE 28.70378229387449 Test RE 3.8818364292273566\n",
      "18 Train Loss 65.8124 Test MSE 28.37792039436835 Test RE 3.8597391113007204\n",
      "19 Train Loss 61.45713 Test MSE 28.046163399752448 Test RE 3.8371113089405706\n",
      "20 Train Loss 57.13925 Test MSE 27.92381831658498 Test RE 3.8287328939569214\n",
      "21 Train Loss 53.572193 Test MSE 27.285020643396106 Test RE 3.784685628010507\n",
      "22 Train Loss 49.41583 Test MSE 26.99774135208578 Test RE 3.764708753454582\n",
      "23 Train Loss 47.132496 Test MSE 26.06412125595598 Test RE 3.699041564763786\n",
      "24 Train Loss 45.43776 Test MSE 25.496237438442297 Test RE 3.6585223720893625\n",
      "25 Train Loss 42.842075 Test MSE 24.09202218753539 Test RE 3.5563483554047464\n",
      "26 Train Loss 40.41597 Test MSE 22.717832965730675 Test RE 3.4534336678485107\n",
      "27 Train Loss 37.324734 Test MSE 21.84688453856094 Test RE 3.3865884615858093\n",
      "28 Train Loss 34.694332 Test MSE 20.9917535450524 Test RE 3.3196479350155204\n",
      "29 Train Loss 33.064064 Test MSE 20.16717746196219 Test RE 3.2537953007918228\n",
      "30 Train Loss 31.825853 Test MSE 19.88454201499705 Test RE 3.2309144895303743\n",
      "31 Train Loss 30.136114 Test MSE 19.198510157972006 Test RE 3.174690786560367\n",
      "32 Train Loss 28.729141 Test MSE 18.688447947731564 Test RE 3.1322346189325976\n",
      "33 Train Loss 27.454382 Test MSE 18.662419564234312 Test RE 3.1300526450572463\n",
      "34 Train Loss 26.306818 Test MSE 18.3217986639572 Test RE 3.10135671232265\n",
      "35 Train Loss 25.34245 Test MSE 18.15072292453804 Test RE 3.086843638814377\n",
      "36 Train Loss 24.548927 Test MSE 18.035426854838747 Test RE 3.0770239768963585\n",
      "37 Train Loss 23.897757 Test MSE 17.84273454424708 Test RE 3.0605422189950624\n",
      "38 Train Loss 23.018759 Test MSE 17.55265025469374 Test RE 3.035561369320631\n",
      "39 Train Loss 22.544916 Test MSE 17.353157188451487 Test RE 3.0182618751677444\n",
      "40 Train Loss 22.01279 Test MSE 17.230260402304275 Test RE 3.007555069334473\n",
      "41 Train Loss 21.465597 Test MSE 17.095287894467425 Test RE 2.995752132445763\n",
      "42 Train Loss 21.01872 Test MSE 16.816620608368105 Test RE 2.971235195628219\n",
      "43 Train Loss 20.54686 Test MSE 16.78202200291309 Test RE 2.9681771042693863\n",
      "44 Train Loss 20.190783 Test MSE 16.710935605372306 Test RE 2.961884032706538\n",
      "45 Train Loss 19.843344 Test MSE 16.646293900912816 Test RE 2.956149861092812\n",
      "46 Train Loss 19.579054 Test MSE 16.58570564328984 Test RE 2.950765141691884\n",
      "47 Train Loss 19.223 Test MSE 16.389487198783787 Test RE 2.9332585844310533\n",
      "48 Train Loss 18.937551 Test MSE 16.305262688104957 Test RE 2.925711963828186\n",
      "49 Train Loss 18.632645 Test MSE 16.18972765867417 Test RE 2.9153281037060097\n",
      "50 Train Loss 18.364182 Test MSE 15.997956730435957 Test RE 2.8980103124651504\n",
      "51 Train Loss 18.134727 Test MSE 15.883283791657279 Test RE 2.8876052016748885\n",
      "52 Train Loss 17.877987 Test MSE 15.710240891526182 Test RE 2.8718323927035008\n",
      "53 Train Loss 17.600136 Test MSE 15.443258097856885 Test RE 2.8473255978999\n",
      "54 Train Loss 17.35825 Test MSE 15.215617138153174 Test RE 2.8262622228135967\n",
      "55 Train Loss 17.035261 Test MSE 14.7539825693182 Test RE 2.783058277956993\n",
      "56 Train Loss 16.811295 Test MSE 14.433917091847748 Test RE 2.7527056283156295\n",
      "57 Train Loss 16.419065 Test MSE 13.80220054177054 Test RE 2.691794083921126\n",
      "58 Train Loss 15.814576 Test MSE 12.996450118747974 Test RE 2.6120413019955158\n",
      "59 Train Loss 14.597213 Test MSE 11.70039625099747 Test RE 2.478380324650684\n",
      "60 Train Loss 13.681877 Test MSE 10.770382651446756 Test RE 2.3778433168189186\n",
      "61 Train Loss 12.492021 Test MSE 9.800249683821761 Test RE 2.268225548576123\n",
      "62 Train Loss 10.9315405 Test MSE 8.489756471521698 Test RE 2.11113149092245\n",
      "63 Train Loss 9.848024 Test MSE 7.750977088796071 Test RE 2.0171857626037553\n",
      "64 Train Loss 8.930627 Test MSE 7.232034457354486 Test RE 1.9484887874410877\n",
      "65 Train Loss 8.057384 Test MSE 6.480787618844465 Test RE 1.8445123286673963\n",
      "66 Train Loss 7.258068 Test MSE 5.80910788551533 Test RE 1.7463142132311418\n",
      "67 Train Loss 6.4967937 Test MSE 5.3161045787111885 Test RE 1.6705690285511519\n",
      "68 Train Loss 5.8648634 Test MSE 4.85946953367072 Test RE 1.5972102900669793\n",
      "69 Train Loss 5.439767 Test MSE 4.478816106622469 Test RE 1.5333781954400902\n",
      "70 Train Loss 5.108422 Test MSE 4.211465775525824 Test RE 1.486908710185466\n",
      "71 Train Loss 4.853202 Test MSE 3.9231188989108197 Test RE 1.4351040925800835\n",
      "72 Train Loss 4.5616026 Test MSE 3.5830476148826835 Test RE 1.3714941434018444\n",
      "73 Train Loss 4.283511 Test MSE 3.366479516245426 Test RE 1.3293999429352434\n",
      "74 Train Loss 4.07241 Test MSE 3.227624740553139 Test RE 1.3016948467700797\n",
      "75 Train Loss 3.9110625 Test MSE 2.872540421602879 Test RE 1.2280067160219803\n",
      "76 Train Loss 3.6371417 Test MSE 2.481016574376605 Test RE 1.1412544933133753\n",
      "77 Train Loss 3.240911 Test MSE 2.1310984155447734 Test RE 1.0577168446125629\n",
      "78 Train Loss 2.902074 Test MSE 1.625163737618756 Test RE 0.9236687046895506\n",
      "79 Train Loss 2.6057782 Test MSE 1.301651302224024 Test RE 0.8266372969069896\n",
      "80 Train Loss 2.2792964 Test MSE 1.2376310280350267 Test RE 0.8060523751977772\n",
      "81 Train Loss 2.0063417 Test MSE 1.0913163210540306 Test RE 0.7569078210754544\n",
      "82 Train Loss 1.7569153 Test MSE 0.7474134688115183 Test RE 0.6263947765993653\n",
      "83 Train Loss 1.4660587 Test MSE 0.43173466055162196 Test RE 0.4760758217407971\n",
      "84 Train Loss 1.3000691 Test MSE 0.3560819816030741 Test RE 0.43235717121370865\n",
      "85 Train Loss 1.0537922 Test MSE 0.2767993333605531 Test RE 0.3811976262337285\n",
      "86 Train Loss 0.94063807 Test MSE 0.1977867090230622 Test RE 0.322230184370144\n",
      "87 Train Loss 0.7966986 Test MSE 0.15357773894480745 Test RE 0.2839434156735494\n",
      "88 Train Loss 0.70157593 Test MSE 0.14047815401247807 Test RE 0.27156391651331196\n",
      "89 Train Loss 0.63948995 Test MSE 0.10442742492513395 Test RE 0.23413964313398283\n",
      "90 Train Loss 0.54373765 Test MSE 0.10275377419738178 Test RE 0.232255795074935\n",
      "91 Train Loss 0.4899929 Test MSE 0.08570996368024318 Test RE 0.21212083263665793\n",
      "92 Train Loss 0.44508767 Test MSE 0.08255984275640996 Test RE 0.20818627577869792\n",
      "93 Train Loss 0.40286505 Test MSE 0.08444276085829479 Test RE 0.21054691370783055\n",
      "94 Train Loss 0.36643234 Test MSE 0.07290047810548193 Test RE 0.19562882927566355\n",
      "95 Train Loss 0.34102222 Test MSE 0.06772296785330059 Test RE 0.18855396036815725\n",
      "96 Train Loss 0.31714866 Test MSE 0.07090590605181767 Test RE 0.19293404651530138\n",
      "97 Train Loss 0.296411 Test MSE 0.0667583824521019 Test RE 0.18720634760080282\n",
      "98 Train Loss 0.2669364 Test MSE 0.06257220430514 Test RE 0.1812418117928069\n",
      "99 Train Loss 0.25578538 Test MSE 0.06342320380207091 Test RE 0.1824701192569131\n",
      "100 Train Loss 0.23886125 Test MSE 0.06011115158546034 Test RE 0.17764181086875355\n",
      "101 Train Loss 0.22167253 Test MSE 0.06594502462215118 Test RE 0.18606242846664145\n",
      "102 Train Loss 0.2022237 Test MSE 0.06499313872226616 Test RE 0.1847146847672493\n",
      "103 Train Loss 0.19459818 Test MSE 0.06040498387029814 Test RE 0.17807545143843478\n",
      "104 Train Loss 0.17379698 Test MSE 0.052198252501923045 Test RE 0.16553721699980706\n",
      "105 Train Loss 0.16669536 Test MSE 0.050690152000989946 Test RE 0.1631283578767939\n",
      "106 Train Loss 0.15072584 Test MSE 0.045713336869329727 Test RE 0.1549134513004564\n",
      "107 Train Loss 0.14228499 Test MSE 0.04353604419438538 Test RE 0.1511792374059791\n",
      "108 Train Loss 0.13407141 Test MSE 0.03817760134698176 Test RE 0.1415702460939851\n",
      "109 Train Loss 0.12878224 Test MSE 0.03274182336775037 Test RE 0.13110495273637784\n",
      "110 Train Loss 0.119165495 Test MSE 0.03378296785189638 Test RE 0.13317311786121114\n",
      "111 Train Loss 0.11221351 Test MSE 0.03561873359534664 Test RE 0.13674356711795305\n",
      "112 Train Loss 0.1089368 Test MSE 0.03542355574876108 Test RE 0.13636839968854755\n",
      "113 Train Loss 0.1019667 Test MSE 0.035694668181378446 Test RE 0.1368892494162319\n",
      "114 Train Loss 0.09398652 Test MSE 0.034247110490520094 Test RE 0.13408482672713778\n",
      "115 Train Loss 0.08887347 Test MSE 0.03071366500058324 Test RE 0.12697946389682183\n",
      "116 Train Loss 0.086591385 Test MSE 0.029126669020216475 Test RE 0.12365539754582434\n",
      "117 Train Loss 0.083881244 Test MSE 0.026330916010213878 Test RE 0.11757111896181105\n",
      "118 Train Loss 0.07937755 Test MSE 0.021300342915338475 Test RE 0.10574527361081058\n",
      "119 Train Loss 0.07683112 Test MSE 0.021517185250892273 Test RE 0.10628216611722864\n",
      "120 Train Loss 0.07125777 Test MSE 0.018181480669642414 Test RE 0.09769723934440346\n",
      "121 Train Loss 0.068984136 Test MSE 0.018879588601891043 Test RE 0.09955519581374586\n",
      "122 Train Loss 0.068005845 Test MSE 0.01872746051696573 Test RE 0.09915328626207007\n",
      "123 Train Loss 0.06432442 Test MSE 0.017049746040428547 Test RE 0.09460773057830472\n",
      "124 Train Loss 0.059591707 Test MSE 0.017003979705431067 Test RE 0.09448066831527774\n",
      "125 Train Loss 0.058928702 Test MSE 0.01619127052641678 Test RE 0.09219516209173396\n",
      "126 Train Loss 0.057517685 Test MSE 0.01756460630517292 Test RE 0.09602556642378125\n",
      "127 Train Loss 0.05565477 Test MSE 0.015937262714096487 Test RE 0.09146912687391985\n",
      "128 Train Loss 0.052578066 Test MSE 0.013726484647898793 Test RE 0.08488820141623556\n",
      "129 Train Loss 0.05121837 Test MSE 0.012654195728204998 Test RE 0.0815051294367859\n",
      "130 Train Loss 0.049162522 Test MSE 0.01195202050137289 Test RE 0.07921151731091816\n",
      "131 Train Loss 0.0436751 Test MSE 0.010168786493590258 Test RE 0.07306379600488701\n",
      "132 Train Loss 0.04198051 Test MSE 0.00958752855853151 Test RE 0.07094487093266219\n",
      "133 Train Loss 0.040902715 Test MSE 0.00779098377154827 Test RE 0.06395342641464774\n",
      "134 Train Loss 0.039702665 Test MSE 0.007256591184150104 Test RE 0.06172114811686414\n",
      "135 Train Loss 0.03721113 Test MSE 0.007001374739356642 Test RE 0.060626057811716504\n",
      "136 Train Loss 0.033756025 Test MSE 0.0069353152212013125 Test RE 0.060339369840221375\n",
      "137 Train Loss 0.032346066 Test MSE 0.00730449153188704 Test RE 0.061924521956963456\n",
      "138 Train Loss 0.03172233 Test MSE 0.007093523759060045 Test RE 0.061023720398546914\n",
      "139 Train Loss 0.031167872 Test MSE 0.006564148811272186 Test RE 0.05870253777638904\n",
      "140 Train Loss 0.030411266 Test MSE 0.0056669161151679135 Test RE 0.05454325596858143\n",
      "141 Train Loss 0.029039722 Test MSE 0.005070927356984455 Test RE 0.0515954449667939\n",
      "142 Train Loss 0.028400358 Test MSE 0.004713807424823193 Test RE 0.04974547541084776\n",
      "143 Train Loss 0.027951386 Test MSE 0.00479092789792701 Test RE 0.05015075610399416\n",
      "144 Train Loss 0.027405668 Test MSE 0.0046933250831779315 Test RE 0.04963728123020936\n",
      "145 Train Loss 0.025875716 Test MSE 0.003796698520391932 Test RE 0.04464478380083348\n",
      "146 Train Loss 0.024800759 Test MSE 0.003703525091513632 Test RE 0.044093575155529606\n",
      "147 Train Loss 0.024473792 Test MSE 0.003546746178651892 Test RE 0.04315019099765263\n",
      "148 Train Loss 0.023753868 Test MSE 0.003144699512241113 Test RE 0.04063097502958642\n",
      "149 Train Loss 0.022913117 Test MSE 0.0033184189013432965 Test RE 0.04173815733742198\n",
      "150 Train Loss 0.022237137 Test MSE 0.002967879693311332 Test RE 0.03947215284167188\n",
      "151 Train Loss 0.02151584 Test MSE 0.002516554418977356 Test RE 0.0363471891248493\n",
      "152 Train Loss 0.021010395 Test MSE 0.0023726111006295773 Test RE 0.03529237999407877\n",
      "153 Train Loss 0.020490149 Test MSE 0.0025266431547413507 Test RE 0.03641997324615294\n",
      "154 Train Loss 0.02028315 Test MSE 0.002588059537208244 Test RE 0.036859954864530656\n",
      "155 Train Loss 0.019950569 Test MSE 0.0024964564599468395 Test RE 0.03620175839775102\n",
      "156 Train Loss 0.019455064 Test MSE 0.002355335153027107 Test RE 0.03516365614800301\n",
      "157 Train Loss 0.01896567 Test MSE 0.0021784476955711285 Test RE 0.03381747955613889\n",
      "158 Train Loss 0.018613957 Test MSE 0.0018010162830545344 Test RE 0.030748680741815873\n",
      "159 Train Loss 0.018388512 Test MSE 0.0016185271896100937 Test RE 0.02914926895482101\n",
      "160 Train Loss 0.017984893 Test MSE 0.0016516133687967144 Test RE 0.029445698600310197\n",
      "161 Train Loss 0.017613156 Test MSE 0.0016054850409254872 Test RE 0.029031588492780078\n",
      "162 Train Loss 0.017472895 Test MSE 0.0015146261707168391 Test RE 0.028198135683563223\n",
      "163 Train Loss 0.017320072 Test MSE 0.0014556850559662507 Test RE 0.027644031516739463\n",
      "164 Train Loss 0.017003052 Test MSE 0.0014019339428419924 Test RE 0.027128853670051932\n",
      "165 Train Loss 0.01679191 Test MSE 0.0012769104641452578 Test RE 0.02589094431395067\n",
      "166 Train Loss 0.016412774 Test MSE 0.0012398983263451433 Test RE 0.025512951563546226\n",
      "167 Train Loss 0.016010348 Test MSE 0.0013499113834812033 Test RE 0.02662075064771368\n",
      "168 Train Loss 0.0156978 Test MSE 0.0013675361129576746 Test RE 0.026793970168262224\n",
      "169 Train Loss 0.015427567 Test MSE 0.001419759496493956 Test RE 0.027300780220621504\n",
      "170 Train Loss 0.015184534 Test MSE 0.001262520262135575 Test RE 0.025744641352007675\n",
      "171 Train Loss 0.014898063 Test MSE 0.0012285999933943003 Test RE 0.0253964446337229\n",
      "172 Train Loss 0.014773093 Test MSE 0.0011247871453836684 Test RE 0.02429980787209407\n",
      "173 Train Loss 0.014586784 Test MSE 0.001138832660791637 Test RE 0.024451056240294748\n",
      "174 Train Loss 0.014328166 Test MSE 0.0010741502594551866 Test RE 0.023746531633522465\n",
      "175 Train Loss 0.014149887 Test MSE 0.0009601446582760605 Test RE 0.02245101617103865\n",
      "176 Train Loss 0.014035624 Test MSE 0.0009432379737621003 Test RE 0.02225247419015478\n",
      "177 Train Loss 0.013928916 Test MSE 0.000917927468882481 Test RE 0.021951886612510955\n",
      "178 Train Loss 0.01375138 Test MSE 0.0009512216162203671 Test RE 0.022346449126477853\n",
      "179 Train Loss 0.01356819 Test MSE 0.0009326700859266357 Test RE 0.02212746647620617\n",
      "180 Train Loss 0.013213137 Test MSE 0.0008894600214183865 Test RE 0.021608811645333827\n",
      "181 Train Loss 0.012998725 Test MSE 0.0009205292693814304 Test RE 0.021982975133678948\n",
      "182 Train Loss 0.0127693415 Test MSE 0.0008438295959311561 Test RE 0.021047234721052747\n",
      "183 Train Loss 0.012545476 Test MSE 0.0008713856221057931 Test RE 0.021388132334496993\n",
      "184 Train Loss 0.012429966 Test MSE 0.0008337659665257732 Test RE 0.020921352144185466\n",
      "185 Train Loss 0.012359247 Test MSE 0.0008467615110569332 Test RE 0.02108376768742006\n",
      "186 Train Loss 0.012262719 Test MSE 0.000827130132935965 Test RE 0.02083793068343958\n",
      "187 Train Loss 0.012202645 Test MSE 0.0008416964637110764 Test RE 0.021020615043125076\n",
      "188 Train Loss 0.012115543 Test MSE 0.0008353849058926959 Test RE 0.020941653989185318\n",
      "189 Train Loss 0.011934298 Test MSE 0.0008680088200457934 Test RE 0.02134665035815423\n",
      "190 Train Loss 0.011618145 Test MSE 0.0009230214332712094 Test RE 0.022012712453581634\n",
      "191 Train Loss 0.011274235 Test MSE 0.0009498687625040883 Test RE 0.02233055260305363\n",
      "192 Train Loss 0.010963049 Test MSE 0.0008912854043894574 Test RE 0.02163097348470715\n",
      "193 Train Loss 0.01081421 Test MSE 0.0009199882491466365 Test RE 0.021976514186280296\n",
      "194 Train Loss 0.010720931 Test MSE 0.0009131418427940135 Test RE 0.02189458861927054\n",
      "195 Train Loss 0.010562126 Test MSE 0.0008899955569378408 Test RE 0.021615315897646266\n",
      "196 Train Loss 0.010420122 Test MSE 0.000865493609210348 Test RE 0.021315700051803017\n",
      "197 Train Loss 0.010233339 Test MSE 0.000796102251031771 Test RE 0.020443351392220123\n",
      "198 Train Loss 0.01009741 Test MSE 0.0008177376912880498 Test RE 0.020719280765315148\n",
      "199 Train Loss 0.009846617 Test MSE 0.0007029384822732958 Test RE 0.01920995410723264\n",
      "200 Train Loss 0.009645799 Test MSE 0.0006997151274861237 Test RE 0.019165859462327465\n",
      "201 Train Loss 0.009597097 Test MSE 0.0006708579138734863 Test RE 0.01876648522951113\n",
      "202 Train Loss 0.009533044 Test MSE 0.0006368018759711181 Test RE 0.018283941989729796\n",
      "203 Train Loss 0.009397042 Test MSE 0.0005894149687764689 Test RE 0.01759050258969068\n",
      "204 Train Loss 0.009269095 Test MSE 0.0005832130749472632 Test RE 0.017497713187340152\n",
      "205 Train Loss 0.009133984 Test MSE 0.000594850513501146 Test RE 0.017671425659893297\n",
      "206 Train Loss 0.008862314 Test MSE 0.0005336107142011764 Test RE 0.016737089488165102\n",
      "207 Train Loss 0.008666591 Test MSE 0.000594477177055454 Test RE 0.01766587937341094\n",
      "208 Train Loss 0.008561628 Test MSE 0.0006221210608858683 Test RE 0.01807195429704651\n",
      "209 Train Loss 0.008494891 Test MSE 0.0006373756190425012 Test RE 0.018292176829811588\n",
      "210 Train Loss 0.008445003 Test MSE 0.0006573678720306322 Test RE 0.018576842755213145\n",
      "211 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "212 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "213 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "214 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "215 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "216 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "217 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "218 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "219 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "220 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "221 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "222 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "223 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "224 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "225 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "226 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "227 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "228 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "229 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "230 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "231 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "232 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "233 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "234 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "235 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "236 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "237 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "238 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "239 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "240 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "241 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "242 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "243 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "244 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "245 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "246 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "247 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "248 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "249 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "250 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "251 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "252 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "253 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "254 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "255 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "256 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "257 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "258 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "259 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "260 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "261 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "262 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "263 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "264 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "265 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "266 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "267 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "268 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "269 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "270 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "271 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "272 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "273 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "274 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "275 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "276 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "277 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "278 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "279 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "280 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "281 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "282 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "283 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "284 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "285 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "286 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "287 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "288 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "289 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "290 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "291 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "292 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "293 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "294 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "295 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "296 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "297 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "298 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "299 Train Loss 0.008423547 Test MSE 0.0006398502191697674 Test RE 0.018327651964798332\n",
      "Training time: 131.33\n",
      "KG_atanh_medium\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 43700.99 Test MSE 13.35108516312331 Test RE 2.6474389297410084\n",
      "1 Train Loss 12508.346 Test MSE 10.093019521731549 Test RE 2.301856385970047\n",
      "2 Train Loss 8261.63 Test MSE 9.751899306945512 Test RE 2.262623387181248\n",
      "3 Train Loss 5148.34 Test MSE 9.056971358962013 Test RE 2.1805154330636434\n",
      "4 Train Loss 819.1961 Test MSE 11.169842562273205 Test RE 2.421537470055809\n",
      "5 Train Loss 251.21187 Test MSE 10.913361941556321 Test RE 2.3935744868454476\n",
      "6 Train Loss 118.95778 Test MSE 10.38066181119189 Test RE 2.33442641556215\n",
      "7 Train Loss 54.344227 Test MSE 10.134205678118157 Test RE 2.3065481483026686\n",
      "8 Train Loss 29.672596 Test MSE 9.959765829109456 Test RE 2.286610700095903\n",
      "9 Train Loss 21.330437 Test MSE 9.734850877765853 Test RE 2.260644744502797\n",
      "10 Train Loss 17.124193 Test MSE 9.400318972051354 Test RE 2.2214623793381256\n",
      "11 Train Loss 14.316013 Test MSE 8.74178933141688 Test RE 2.1422385770977637\n",
      "12 Train Loss 12.152316 Test MSE 8.219438487557914 Test RE 2.0772498796163066\n",
      "13 Train Loss 10.825029 Test MSE 7.514231876072939 Test RE 1.9861404843169708\n",
      "14 Train Loss 10.00868 Test MSE 7.0626877571971205 Test RE 1.9255405588354328\n",
      "15 Train Loss 8.909841 Test MSE 6.0172302898627485 Test RE 1.7773214575982665\n",
      "16 Train Loss 7.0645194 Test MSE 5.190047774954857 Test RE 1.6506437257790698\n",
      "17 Train Loss 5.7892523 Test MSE 4.625433418445518 Test RE 1.5582742155931781\n",
      "18 Train Loss 5.271596 Test MSE 4.290227861573226 Test RE 1.5007482552410392\n",
      "19 Train Loss 4.9381576 Test MSE 3.858621790921886 Test RE 1.4232584598500837\n",
      "20 Train Loss 4.607684 Test MSE 3.4774240889038026 Test RE 1.3511280081843957\n",
      "21 Train Loss 4.1807666 Test MSE 3.4691301757635813 Test RE 1.3495157762705439\n",
      "22 Train Loss 3.9281855 Test MSE 3.2330422657103566 Test RE 1.3027868274787595\n",
      "23 Train Loss 3.7748585 Test MSE 3.0067841683524055 Test RE 1.2563735798578952\n",
      "24 Train Loss 3.580883 Test MSE 3.0164885783170563 Test RE 1.258399422372872\n",
      "25 Train Loss 3.4750237 Test MSE 2.9483137627284624 Test RE 1.2440977868673813\n",
      "26 Train Loss 3.3171196 Test MSE 2.709065257801664 Test RE 1.1925522085013234\n",
      "27 Train Loss 3.1452549 Test MSE 2.408904989338483 Test RE 1.1245467200911636\n",
      "28 Train Loss 2.8349836 Test MSE 1.7384390743510318 Test RE 0.9553167777528208\n",
      "29 Train Loss 2.6711035 Test MSE 1.7202452140198679 Test RE 0.9503046334291414\n",
      "30 Train Loss 2.4134912 Test MSE 1.4381252134518434 Test RE 0.8688924386502659\n",
      "31 Train Loss 2.1617382 Test MSE 1.119325760138857 Test RE 0.7665595825512048\n",
      "32 Train Loss 1.95568 Test MSE 0.9882807574965599 Test RE 0.720290749634896\n",
      "33 Train Loss 1.7071308 Test MSE 0.6421802449065764 Test RE 0.5806255441730515\n",
      "34 Train Loss 1.3147466 Test MSE 0.30709514558465784 Test RE 0.40151719003878616\n",
      "35 Train Loss 1.1487772 Test MSE 0.21399965450632297 Test RE 0.335176995566056\n",
      "36 Train Loss 0.9368066 Test MSE 0.23068432914125284 Test RE 0.34799797288385526\n",
      "37 Train Loss 0.78474015 Test MSE 0.15247883260063702 Test RE 0.2829257310895002\n",
      "38 Train Loss 0.6670327 Test MSE 0.10385087533320522 Test RE 0.23349239956719053\n",
      "39 Train Loss 0.5840768 Test MSE 0.10174291055674109 Test RE 0.23111053680550506\n",
      "40 Train Loss 0.5236769 Test MSE 0.10169871472649869 Test RE 0.2310603356098726\n",
      "41 Train Loss 0.47368032 Test MSE 0.08846463634349443 Test RE 0.21550260085423115\n",
      "42 Train Loss 0.42411602 Test MSE 0.0844514213227903 Test RE 0.21055771029537543\n",
      "43 Train Loss 0.3889812 Test MSE 0.09195860595027669 Test RE 0.21971709944141277\n",
      "44 Train Loss 0.32344192 Test MSE 0.08218216724980885 Test RE 0.2077095489478376\n",
      "45 Train Loss 0.29896143 Test MSE 0.07429273238254534 Test RE 0.19748805533787397\n",
      "46 Train Loss 0.2608533 Test MSE 0.050157742990631256 Test RE 0.16226941128488934\n",
      "47 Train Loss 0.23918048 Test MSE 0.049335757800983954 Test RE 0.16093428295343948\n",
      "48 Train Loss 0.22065805 Test MSE 0.0392780924900136 Test RE 0.1435961717610568\n",
      "49 Train Loss 0.20333579 Test MSE 0.03970923119844795 Test RE 0.14438211757306438\n",
      "50 Train Loss 0.18560946 Test MSE 0.03175619386692845 Test RE 0.12911654309551898\n",
      "51 Train Loss 0.15786527 Test MSE 0.024989257576315413 Test RE 0.11453661514249924\n",
      "52 Train Loss 0.15165797 Test MSE 0.02462723273510409 Test RE 0.11370392981638991\n",
      "53 Train Loss 0.13065517 Test MSE 0.016350515508976166 Test RE 0.09264743339739541\n",
      "54 Train Loss 0.12111812 Test MSE 0.011837846171871834 Test RE 0.07883226661531326\n",
      "55 Train Loss 0.11492852 Test MSE 0.010178852680898694 Test RE 0.07309995036476297\n",
      "56 Train Loss 0.110361315 Test MSE 0.00894588859398092 Test RE 0.06852979148253024\n",
      "57 Train Loss 0.102819726 Test MSE 0.006245095991924751 Test RE 0.05725813876837596\n",
      "58 Train Loss 0.09532514 Test MSE 0.0056837968988297525 Test RE 0.054624433122788515\n",
      "59 Train Loss 0.09007345 Test MSE 0.003818212924988184 Test RE 0.044771097369783255\n",
      "60 Train Loss 0.08330221 Test MSE 0.00557112267358586 Test RE 0.05408029206899776\n",
      "61 Train Loss 0.078704566 Test MSE 0.006727240217135036 Test RE 0.05942731866896865\n",
      "62 Train Loss 0.07478841 Test MSE 0.004790655822596245 Test RE 0.050149332060721946\n",
      "63 Train Loss 0.07041465 Test MSE 0.0034526949714883196 Test RE 0.04257422723126481\n",
      "64 Train Loss 0.06862137 Test MSE 0.0031678615138898926 Test RE 0.040780332412116364\n",
      "65 Train Loss 0.0666581 Test MSE 0.002916148197331314 Test RE 0.03912663176654521\n",
      "66 Train Loss 0.065751046 Test MSE 0.003082838716917392 Test RE 0.04022935503604765\n",
      "67 Train Loss 0.061340995 Test MSE 0.0028234434823515304 Test RE 0.03849968862191704\n",
      "68 Train Loss 0.058945775 Test MSE 0.002274395523262927 Test RE 0.03455418575441359\n",
      "69 Train Loss 0.056681395 Test MSE 0.0021190027789648987 Test RE 0.0333528869008706\n",
      "70 Train Loss 0.055397898 Test MSE 0.001784740747081578 Test RE 0.030609429634199412\n",
      "71 Train Loss 0.054262694 Test MSE 0.001205136093601227 Test RE 0.025152763913079745\n",
      "72 Train Loss 0.05333765 Test MSE 0.0011025425120393733 Test RE 0.02405832235658988\n",
      "73 Train Loss 0.052099895 Test MSE 0.0010946600667743375 Test RE 0.023972167595552797\n",
      "74 Train Loss 0.049785685 Test MSE 0.0009541783388903573 Test RE 0.022381152389862106\n",
      "75 Train Loss 0.04843369 Test MSE 0.0009559015525828771 Test RE 0.02240135307430677\n",
      "76 Train Loss 0.046352312 Test MSE 0.000770061753584491 Test RE 0.020106220665829653\n",
      "77 Train Loss 0.043467116 Test MSE 0.0008789175302029375 Test RE 0.021480368672006644\n",
      "78 Train Loss 0.042582642 Test MSE 0.0009572471999503533 Test RE 0.02241711501152503\n",
      "79 Train Loss 0.041678958 Test MSE 0.0011160203715555074 Test RE 0.024204924299872744\n",
      "80 Train Loss 0.040196396 Test MSE 0.0005941178779202964 Test RE 0.017660539980419665\n",
      "81 Train Loss 0.037527353 Test MSE 0.0006375511907384014 Test RE 0.01829469604083562\n",
      "82 Train Loss 0.03673967 Test MSE 0.0004907230261517435 Test RE 0.01605040095771218\n",
      "83 Train Loss 0.035138305 Test MSE 0.0005285519093226775 Test RE 0.016657564003884337\n",
      "84 Train Loss 0.03403634 Test MSE 0.0005741048263983858 Test RE 0.017360541471784473\n",
      "85 Train Loss 0.033334147 Test MSE 0.0005851253761866237 Test RE 0.017526376394781575\n",
      "86 Train Loss 0.032619365 Test MSE 0.0007266161661601533 Test RE 0.01953080732647356\n",
      "87 Train Loss 0.03179705 Test MSE 0.000636712835842592 Test RE 0.018282663678909246\n",
      "88 Train Loss 0.030724686 Test MSE 0.0006453439130197034 Test RE 0.018406163550397744\n",
      "89 Train Loss 0.02911576 Test MSE 0.0007043374692607561 Test RE 0.019229060414831578\n",
      "90 Train Loss 0.028278755 Test MSE 0.0006750552903015727 Test RE 0.018825102094881\n",
      "91 Train Loss 0.02740194 Test MSE 0.0006759164894459852 Test RE 0.01883710629268193\n",
      "92 Train Loss 0.026236698 Test MSE 0.0007827797060093349 Test RE 0.020271572854764906\n",
      "93 Train Loss 0.025183683 Test MSE 0.0007978941466105048 Test RE 0.02046634577562977\n",
      "94 Train Loss 0.023743961 Test MSE 0.000850766593116402 Test RE 0.021133570733271614\n",
      "95 Train Loss 0.02299622 Test MSE 0.0008704000872550094 Test RE 0.021376033951961547\n",
      "96 Train Loss 0.022393959 Test MSE 0.0008244376972818938 Test RE 0.020803987705677412\n",
      "97 Train Loss 0.021961097 Test MSE 0.0007871957520667654 Test RE 0.02032867340086699\n",
      "98 Train Loss 0.021206407 Test MSE 0.00092875009926477 Test RE 0.022080916947282453\n",
      "99 Train Loss 0.020336213 Test MSE 0.0010738856985729305 Test RE 0.02374360709378167\n",
      "100 Train Loss 0.019724835 Test MSE 0.000962571882197883 Test RE 0.022479376088910975\n",
      "101 Train Loss 0.01926524 Test MSE 0.0008870350019386853 Test RE 0.021579334460480822\n",
      "102 Train Loss 0.019044619 Test MSE 0.0009647223005899137 Test RE 0.022504471926663213\n",
      "103 Train Loss 0.018867057 Test MSE 0.0010049869154348443 Test RE 0.02296930588624753\n",
      "104 Train Loss 0.017911334 Test MSE 0.0009340873794368578 Test RE 0.02214427263842588\n",
      "105 Train Loss 0.016807681 Test MSE 0.0008884247991447624 Test RE 0.02159623298224913\n",
      "106 Train Loss 0.016447851 Test MSE 0.0008603562155681805 Test RE 0.021252343068074508\n",
      "107 Train Loss 0.01613659 Test MSE 0.0008188900835330666 Test RE 0.02073387489043179\n",
      "108 Train Loss 0.016025405 Test MSE 0.0008239544611634071 Test RE 0.020797889784703587\n",
      "109 Train Loss 0.015729358 Test MSE 0.0008109839672201459 Test RE 0.02063354273927393\n",
      "110 Train Loss 0.015249353 Test MSE 0.0009035147369955354 Test RE 0.02177886726143367\n",
      "111 Train Loss 0.0147701455 Test MSE 0.0008040507281069654 Test RE 0.020545153596828833\n",
      "112 Train Loss 0.01414865 Test MSE 0.0006340763136098415 Test RE 0.018244771673343926\n",
      "113 Train Loss 0.013659804 Test MSE 0.000613279357252775 Test RE 0.017943073702122243\n",
      "114 Train Loss 0.0134392325 Test MSE 0.0005456474839493672 Test RE 0.016924807824866595\n",
      "115 Train Loss 0.013304635 Test MSE 0.0004411818023559777 Test RE 0.015218661694752972\n",
      "116 Train Loss 0.013179597 Test MSE 0.0004204258831003985 Test RE 0.014856359161516768\n",
      "117 Train Loss 0.012759533 Test MSE 0.0005807994113938925 Test RE 0.017461467960984953\n",
      "118 Train Loss 0.012433114 Test MSE 0.0005686524212241869 Test RE 0.017277906280878785\n",
      "119 Train Loss 0.012078171 Test MSE 0.0006284451583911548 Test RE 0.018163576191800528\n",
      "120 Train Loss 0.011696596 Test MSE 0.0007054031846060084 Test RE 0.019243602420448588\n",
      "121 Train Loss 0.011498529 Test MSE 0.0007158626484707017 Test RE 0.019385746041896558\n",
      "122 Train Loss 0.011310749 Test MSE 0.0007545360383465185 Test RE 0.01990250132001171\n",
      "123 Train Loss 0.011149969 Test MSE 0.0007504851635137179 Test RE 0.019849004178364618\n",
      "124 Train Loss 0.010957931 Test MSE 0.0008485439360383032 Test RE 0.021105946587863002\n",
      "125 Train Loss 0.0108779725 Test MSE 0.0009321970274745466 Test RE 0.0221218541418731\n",
      "126 Train Loss 0.010788676 Test MSE 0.0009103229740226525 Test RE 0.02186076820182293\n",
      "127 Train Loss 0.0106693 Test MSE 0.0008208901346158273 Test RE 0.020759179580190697\n",
      "128 Train Loss 0.010473239 Test MSE 0.0008509568674485471 Test RE 0.021135933867461612\n",
      "129 Train Loss 0.010304057 Test MSE 0.0009061439547508937 Test RE 0.021810532371673217\n",
      "130 Train Loss 0.010132067 Test MSE 0.0010826041810597276 Test RE 0.023839795060506166\n",
      "131 Train Loss 0.010055921 Test MSE 0.001112563236442692 Test RE 0.024167405003282398\n",
      "132 Train Loss 0.009968316 Test MSE 0.0011539340283288708 Test RE 0.024612637641826526\n",
      "133 Train Loss 0.009876379 Test MSE 0.0012390807793961499 Test RE 0.025504538988631073\n",
      "134 Train Loss 0.009759926 Test MSE 0.0012235829905553521 Test RE 0.025344538245981783\n",
      "135 Train Loss 0.009546859 Test MSE 0.0012097386123130643 Test RE 0.025200748430176688\n",
      "136 Train Loss 0.009427346 Test MSE 0.0012474446187842546 Test RE 0.02559047249219904\n",
      "137 Train Loss 0.009181461 Test MSE 0.0012410773619688682 Test RE 0.025525078981775015\n",
      "138 Train Loss 0.008951371 Test MSE 0.0012150425429189823 Test RE 0.02525593259686148\n",
      "139 Train Loss 0.008780706 Test MSE 0.0012116347037276786 Test RE 0.02522048997338971\n",
      "140 Train Loss 0.008539054 Test MSE 0.0012783901383662207 Test RE 0.025905941086229088\n",
      "141 Train Loss 0.008309255 Test MSE 0.00125310432893473 Test RE 0.02564845933429466\n",
      "142 Train Loss 0.008204455 Test MSE 0.0012968059693436317 Test RE 0.026091867722728965\n",
      "143 Train Loss 0.008091258 Test MSE 0.001454961509604429 Test RE 0.02763716044788242\n",
      "144 Train Loss 0.008036954 Test MSE 0.0014197711616943448 Test RE 0.027300892376384032\n",
      "145 Train Loss 0.007955569 Test MSE 0.0014720733691473177 Test RE 0.02779920624939383\n",
      "146 Train Loss 0.0078023113 Test MSE 0.0014696665119373674 Test RE 0.027776470938467274\n",
      "147 Train Loss 0.007706678 Test MSE 0.0014561265261934858 Test RE 0.0276482230455588\n",
      "148 Train Loss 0.0075939936 Test MSE 0.0013728728577293496 Test RE 0.026846200359830694\n",
      "149 Train Loss 0.0074561364 Test MSE 0.0013986983087234987 Test RE 0.027097529173074463\n",
      "150 Train Loss 0.007303926 Test MSE 0.0012795180064518797 Test RE 0.025917366409999552\n",
      "151 Train Loss 0.0071224547 Test MSE 0.0012003917619521846 Test RE 0.02510320489120754\n",
      "152 Train Loss 0.0070121954 Test MSE 0.0009869849432562713 Test RE 0.022762655800177625\n",
      "153 Train Loss 0.006912376 Test MSE 0.0009792218455175132 Test RE 0.02267295961462581\n",
      "154 Train Loss 0.0068074106 Test MSE 0.0009760050589408803 Test RE 0.022635688148019428\n",
      "155 Train Loss 0.0067020226 Test MSE 0.000920316861051649 Test RE 0.021980438746962386\n",
      "156 Train Loss 0.0066319653 Test MSE 0.0009283524654187426 Test RE 0.02207618959386683\n",
      "157 Train Loss 0.0065683485 Test MSE 0.0008301377030615678 Test RE 0.020875781239148457\n",
      "158 Train Loss 0.0064737177 Test MSE 0.0008195504269141784 Test RE 0.020742232982851373\n",
      "159 Train Loss 0.0064135026 Test MSE 0.0007980238203792428 Test RE 0.020468008803475716\n",
      "160 Train Loss 0.00632193 Test MSE 0.000843561351441113 Test RE 0.02104388910866341\n",
      "161 Train Loss 0.0062487177 Test MSE 0.0008646397218328338 Test RE 0.021305182528321767\n",
      "162 Train Loss 0.00618272 Test MSE 0.0008109170119249728 Test RE 0.020632690963211475\n",
      "163 Train Loss 0.0061342157 Test MSE 0.0008078607328075766 Test RE 0.020593772806287915\n",
      "164 Train Loss 0.0060876966 Test MSE 0.0007957865362565029 Test RE 0.020439297322463083\n",
      "165 Train Loss 0.006032833 Test MSE 0.000753280832765104 Test RE 0.019885940064029484\n",
      "166 Train Loss 0.0059489394 Test MSE 0.0007745841685736604 Test RE 0.020165174095539657\n",
      "167 Train Loss 0.0058187502 Test MSE 0.0007106958448150433 Test RE 0.019315660159068545\n",
      "168 Train Loss 0.005737716 Test MSE 0.0006221703073415487 Test RE 0.018072669561438385\n",
      "169 Train Loss 0.0056531937 Test MSE 0.0005780029976136798 Test RE 0.017419380790918048\n",
      "170 Train Loss 0.005600584 Test MSE 0.0005785208131943068 Test RE 0.017427181795001995\n",
      "171 Train Loss 0.0055675283 Test MSE 0.0006014889737936451 Test RE 0.01776975757204147\n",
      "172 Train Loss 0.005521516 Test MSE 0.0006047506783605642 Test RE 0.017817872616131037\n",
      "173 Train Loss 0.005477394 Test MSE 0.000605729442338283 Test RE 0.017832285532007126\n",
      "174 Train Loss 0.0054232134 Test MSE 0.0006117633055258304 Test RE 0.01792088197182398\n",
      "175 Train Loss 0.0053649563 Test MSE 0.0006335388233650095 Test RE 0.01823703722118095\n",
      "176 Train Loss 0.0053079566 Test MSE 0.0006540776287819227 Test RE 0.018530294233370527\n",
      "177 Train Loss 0.0052304957 Test MSE 0.0006063745368553939 Test RE 0.017841778589200354\n",
      "178 Train Loss 0.005143722 Test MSE 0.0005868987816891742 Test RE 0.0175529158842378\n",
      "179 Train Loss 0.0050557368 Test MSE 0.0005666485858190298 Test RE 0.01724743719863005\n",
      "180 Train Loss 0.005010351 Test MSE 0.0005422925263276731 Test RE 0.016872695823762197\n",
      "181 Train Loss 0.0049888543 Test MSE 0.000545091811006062 Test RE 0.016916187741718432\n",
      "182 Train Loss 0.0049656252 Test MSE 0.000532172706980357 Test RE 0.016714522200996854\n",
      "183 Train Loss 0.0049337125 Test MSE 0.0005019309168320857 Test RE 0.01623265809354161\n",
      "184 Train Loss 0.0048904833 Test MSE 0.0004882963829480627 Test RE 0.016010666867094066\n",
      "185 Train Loss 0.004837545 Test MSE 0.0004874195153926046 Test RE 0.01599628467701563\n",
      "186 Train Loss 0.0047972538 Test MSE 0.0004627159116301278 Test RE 0.015585648758899279\n",
      "187 Train Loss 0.0047473246 Test MSE 0.0004703377577186736 Test RE 0.015713487696970375\n",
      "188 Train Loss 0.0046976223 Test MSE 0.0004916068814829211 Test RE 0.016064848873987615\n",
      "189 Train Loss 0.0046632905 Test MSE 0.0004977780460099037 Test RE 0.016165365814673593\n",
      "190 Train Loss 0.0046166284 Test MSE 0.0004908997473459784 Test RE 0.016053290765762614\n",
      "191 Train Loss 0.0045810137 Test MSE 0.0005119962364702578 Test RE 0.016394608564010895\n",
      "192 Train Loss 0.00454589 Test MSE 0.0005077279405203088 Test RE 0.016326128085363496\n",
      "193 Train Loss 0.0045085032 Test MSE 0.00047000221603021506 Test RE 0.01570788165024558\n",
      "194 Train Loss 0.0044760667 Test MSE 0.000469850811749624 Test RE 0.015705351415281385\n",
      "195 Train Loss 0.0044250833 Test MSE 0.0004543654880662397 Test RE 0.015444374924334061\n",
      "196 Train Loss 0.0043831863 Test MSE 0.0004527669798968092 Test RE 0.015417183475861506\n",
      "197 Train Loss 0.0043372097 Test MSE 0.00042793320497699965 Test RE 0.014988413325295916\n",
      "198 Train Loss 0.004265941 Test MSE 0.0004352563723277914 Test RE 0.015116116720022147\n",
      "199 Train Loss 0.004193917 Test MSE 0.0003985746622133916 Test RE 0.014465135660288184\n",
      "200 Train Loss 0.0041013714 Test MSE 0.00038516150220205427 Test RE 0.014219656440541335\n",
      "201 Train Loss 0.004029284 Test MSE 0.0003734511677040166 Test RE 0.014001822844246383\n",
      "202 Train Loss 0.0039916807 Test MSE 0.00034629835447553707 Test RE 0.01348319705118735\n",
      "203 Train Loss 0.0039746608 Test MSE 0.0003218098426835972 Test RE 0.01299772455245246\n",
      "204 Train Loss 0.0039587994 Test MSE 0.00031322318264612734 Test RE 0.012823146876057635\n",
      "205 Train Loss 0.003947265 Test MSE 0.00030432078470363596 Test RE 0.012639604219131045\n",
      "206 Train Loss 0.0039244276 Test MSE 0.00029141397713265297 Test RE 0.012368665845324152\n",
      "207 Train Loss 0.0038886995 Test MSE 0.0002612709799823776 Test RE 0.0117115197403706\n",
      "208 Train Loss 0.0038312161 Test MSE 0.00024002876295255735 Test RE 0.011225335012544973\n",
      "209 Train Loss 0.0038030054 Test MSE 0.00022941756459756362 Test RE 0.01097440542572051\n",
      "210 Train Loss 0.0037742443 Test MSE 0.0002299863855672803 Test RE 0.010988002046623844\n",
      "211 Train Loss 0.0037555015 Test MSE 0.0002227304552256524 Test RE 0.01081328052789362\n",
      "212 Train Loss 0.0037140169 Test MSE 0.0002168541775393203 Test RE 0.01066968416797268\n",
      "213 Train Loss 0.003665399 Test MSE 0.00021329053702175854 Test RE 0.010581651677441887\n",
      "214 Train Loss 0.0036027173 Test MSE 0.00017889528903300265 Test RE 0.009690967112198282\n",
      "215 Train Loss 0.0035552906 Test MSE 0.00019273547821265934 Test RE 0.010058853905598715\n",
      "216 Train Loss 0.003521243 Test MSE 0.00017316331521685722 Test RE 0.009534449296628118\n",
      "217 Train Loss 0.0034918115 Test MSE 0.00015980566895588434 Test RE 0.009159331095499785\n",
      "218 Train Loss 0.003461214 Test MSE 0.00014851192140103716 Test RE 0.008829748346749771\n",
      "219 Train Loss 0.003421229 Test MSE 0.00014880404892316404 Test RE 0.008838428273860225\n",
      "220 Train Loss 0.003370214 Test MSE 0.00014469789821118344 Test RE 0.008715629879520537\n",
      "221 Train Loss 0.0033399793 Test MSE 0.00014640706952576962 Test RE 0.00876695326876743\n",
      "222 Train Loss 0.0032976787 Test MSE 0.00015361245662865472 Test RE 0.008980094046417263\n",
      "223 Train Loss 0.003248585 Test MSE 0.00014665836097183088 Test RE 0.008774473793066546\n",
      "224 Train Loss 0.0032204236 Test MSE 0.00013471498227167857 Test RE 0.008409605375151306\n",
      "225 Train Loss 0.0031988479 Test MSE 0.00012617636372963602 Test RE 0.00813873056578711\n",
      "226 Train Loss 0.00318142 Test MSE 0.00012188060917649281 Test RE 0.007998986719823966\n",
      "227 Train Loss 0.0031621284 Test MSE 0.00012104559356087907 Test RE 0.007971538718391468\n",
      "228 Train Loss 0.0031437129 Test MSE 0.0001207518334803014 Test RE 0.00796185995906023\n",
      "229 Train Loss 0.0031198242 Test MSE 0.00011650026273368599 Test RE 0.007820438769494288\n",
      "230 Train Loss 0.0030962906 Test MSE 0.00011257431989388032 Test RE 0.007687539027785035\n",
      "231 Train Loss 0.003079607 Test MSE 0.0001143429749233438 Test RE 0.007747693137350924\n",
      "232 Train Loss 0.0030574084 Test MSE 0.0001157803516498461 Test RE 0.0077962382009874355\n",
      "233 Train Loss 0.003042325 Test MSE 0.00011708196783513777 Test RE 0.007839938830871161\n",
      "234 Train Loss 0.0030150553 Test MSE 0.00011813574882136695 Test RE 0.007875140973858382\n",
      "235 Train Loss 0.0029947802 Test MSE 0.0001249596376440053 Test RE 0.008099394377358973\n",
      "236 Train Loss 0.0029726785 Test MSE 0.00012089652047415077 Test RE 0.007966628552117222\n",
      "237 Train Loss 0.0029560237 Test MSE 0.000115098806357165 Test RE 0.007773257911226163\n",
      "238 Train Loss 0.0029388305 Test MSE 0.00011396677959986704 Test RE 0.007734937446761886\n",
      "239 Train Loss 0.0029128678 Test MSE 0.00011855272077376779 Test RE 0.007889026781050582\n",
      "240 Train Loss 0.0028915398 Test MSE 0.0001225111720004022 Test RE 0.008019651847620133\n",
      "241 Train Loss 0.0028778748 Test MSE 0.0001243323361001067 Test RE 0.008079039184481855\n",
      "242 Train Loss 0.0028613682 Test MSE 0.00012038848752971193 Test RE 0.007949872194628628\n",
      "243 Train Loss 0.00285283 Test MSE 0.00011725439295659603 Test RE 0.007845709596005704\n",
      "244 Train Loss 0.0028360873 Test MSE 0.00010961804981338732 Test RE 0.007585927772139906\n",
      "245 Train Loss 0.0028013298 Test MSE 0.00010826936881174536 Test RE 0.0075391167727986074\n",
      "246 Train Loss 0.0027697135 Test MSE 0.00010675536541812723 Test RE 0.007486218925318546\n",
      "247 Train Loss 0.002733444 Test MSE 0.00010913034820387931 Test RE 0.007569033686635169\n",
      "248 Train Loss 0.0027018497 Test MSE 0.00010504035338406464 Test RE 0.007425842859186842\n",
      "249 Train Loss 0.0026825503 Test MSE 0.00010851116092493437 Test RE 0.0075475304284130795\n",
      "250 Train Loss 0.002661801 Test MSE 0.00011808253699756665 Test RE 0.007873367176270003\n",
      "251 Train Loss 0.002620452 Test MSE 0.00010807515902696938 Test RE 0.007532352036632961\n",
      "252 Train Loss 0.0025760457 Test MSE 0.00010980178503396602 Test RE 0.0075922826496071846\n",
      "253 Train Loss 0.0025628828 Test MSE 0.00010295866069086714 Test RE 0.0073518918530367725\n",
      "254 Train Loss 0.0025520225 Test MSE 0.00011002252074642853 Test RE 0.0075999102419137\n",
      "255 Train Loss 0.0025384463 Test MSE 0.00011412984543853703 Test RE 0.007740469116667192\n",
      "256 Train Loss 0.002504788 Test MSE 0.0001332089570754131 Test RE 0.008362466321136014\n",
      "257 Train Loss 0.0024782296 Test MSE 0.0001337489210126789 Test RE 0.008379397853945387\n",
      "258 Train Loss 0.0024621561 Test MSE 0.0001335084874635019 Test RE 0.008371862860052169\n",
      "259 Train Loss 0.002448821 Test MSE 0.0001279827671213397 Test RE 0.008196782580122424\n",
      "260 Train Loss 0.0024114542 Test MSE 0.00012155010680272214 Test RE 0.007988133973176006\n",
      "261 Train Loss 0.0023693966 Test MSE 0.00012873386069044992 Test RE 0.00822079965866958\n",
      "262 Train Loss 0.0023522964 Test MSE 0.00013574587172966268 Test RE 0.00844172077618231\n",
      "263 Train Loss 0.0023400239 Test MSE 0.0001354372568431652 Test RE 0.008432119294055558\n",
      "264 Train Loss 0.0023282524 Test MSE 0.0001334097443918712 Test RE 0.008368766366425789\n",
      "265 Train Loss 0.0023140006 Test MSE 0.0001449064143314463 Test RE 0.008721907424327874\n",
      "266 Train Loss 0.0023000555 Test MSE 0.00014587291111272367 Test RE 0.008750945773240294\n",
      "267 Train Loss 0.0022837576 Test MSE 0.00012727142170317797 Test RE 0.008173971429558035\n",
      "268 Train Loss 0.0022699567 Test MSE 0.00012083987820468049 Test RE 0.00796476207661261\n",
      "269 Train Loss 0.002252796 Test MSE 0.0001159070496667974 Test RE 0.007800502732169619\n",
      "270 Train Loss 0.0022396245 Test MSE 0.00012103999219772986 Test RE 0.007971354275494882\n",
      "271 Train Loss 0.002223671 Test MSE 0.00011725830233210128 Test RE 0.007845840386709959\n",
      "272 Train Loss 0.002199417 Test MSE 0.00011082803197833829 Test RE 0.007627680233442078\n",
      "273 Train Loss 0.002188102 Test MSE 0.00010209063864822856 Test RE 0.007320835156985648\n",
      "274 Train Loss 0.0021714517 Test MSE 9.538250320862657e-05 Test RE 0.007076231387274714\n",
      "275 Train Loss 0.002157042 Test MSE 0.00010129527706272667 Test RE 0.0072922620364023515\n",
      "276 Train Loss 0.0021292772 Test MSE 0.00010535364407046541 Test RE 0.00743690867919302\n",
      "277 Train Loss 0.0021042197 Test MSE 0.00010880536046698777 Test RE 0.007557755076971679\n",
      "278 Train Loss 0.00208771 Test MSE 0.00010712924595879577 Test RE 0.007499316652144066\n",
      "279 Train Loss 0.002069754 Test MSE 0.00010179452089000257 Test RE 0.0073102102673024034\n",
      "280 Train Loss 0.0020536857 Test MSE 9.936436393870443e-05 Test RE 0.007222424257977\n",
      "281 Train Loss 0.0020362758 Test MSE 9.967347448443093e-05 Test RE 0.0072336495797621445\n",
      "282 Train Loss 0.0020228554 Test MSE 0.00010116063490122212 Test RE 0.007287413970249128\n",
      "283 Train Loss 0.0019997626 Test MSE 9.978416489973241e-05 Test RE 0.007237665058827232\n",
      "284 Train Loss 0.0019839243 Test MSE 9.907588920334019e-05 Test RE 0.007211932562371229\n",
      "285 Train Loss 0.0019667768 Test MSE 9.758902493288314e-05 Test RE 0.007157612075367492\n",
      "286 Train Loss 0.0019487441 Test MSE 9.110546909800179e-05 Test RE 0.006915759658752267\n",
      "287 Train Loss 0.001930966 Test MSE 9.609467605087821e-05 Test RE 0.007102599577231796\n",
      "288 Train Loss 0.0019197051 Test MSE 9.512105439037973e-05 Test RE 0.007066526557771254\n",
      "289 Train Loss 0.0019050947 Test MSE 9.772178741997157e-05 Test RE 0.007162479115544504\n",
      "290 Train Loss 0.0018997687 Test MSE 9.705916413584109e-05 Test RE 0.007138154457195018\n",
      "291 Train Loss 0.0018842936 Test MSE 9.247343225051832e-05 Test RE 0.006967486826568004\n",
      "292 Train Loss 0.0018686429 Test MSE 9.066848691897826e-05 Test RE 0.006899154199930514\n",
      "293 Train Loss 0.0018568677 Test MSE 8.738555887263013e-05 Test RE 0.006773100218296164\n",
      "294 Train Loss 0.0018410925 Test MSE 8.919564162741516e-05 Test RE 0.006842888832168718\n",
      "295 Train Loss 0.0018265169 Test MSE 9.40375396315231e-05 Test RE 0.00702616422638971\n",
      "296 Train Loss 0.0018134402 Test MSE 8.758144358992971e-05 Test RE 0.0067806873079544645\n",
      "297 Train Loss 0.0017995144 Test MSE 8.452330768834159e-05 Test RE 0.006661252706808696\n",
      "298 Train Loss 0.0017814591 Test MSE 8.334719825922333e-05 Test RE 0.006614745970130422\n",
      "299 Train Loss 0.0017633812 Test MSE 8.484677123775414e-05 Test RE 0.006673986560941451\n",
      "Training time: 137.46\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1c000c9ed0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.010834938104436715\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
