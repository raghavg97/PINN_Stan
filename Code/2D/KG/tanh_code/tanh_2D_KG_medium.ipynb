{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"medium\"\n",
    "label = \"KG_tanh_\" + level\n",
    "\n",
    "x = np.linspace(0,2,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "                    \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_tanh_medium\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 28089.43 Test MSE 5.404841060669437 Test RE 1.6844539059293908\n",
      "1 Train Loss 9015.408 Test MSE 9.120418836816265 Test RE 2.1881397673422183\n",
      "2 Train Loss 7795.852 Test MSE 10.13335775074917 Test RE 2.3064516520267535\n",
      "3 Train Loss 5030.7666 Test MSE 12.984974139203548 Test RE 2.610887819605754\n",
      "4 Train Loss 1635.9475 Test MSE 15.62143254333025 Test RE 2.8637038048726486\n",
      "5 Train Loss 543.9165 Test MSE 16.763173200302887 Test RE 2.9665097753166343\n",
      "6 Train Loss 242.74559 Test MSE 15.62612883830752 Test RE 2.864134232335901\n",
      "7 Train Loss 146.54268 Test MSE 16.12031230616137 Test RE 2.909071484748211\n",
      "8 Train Loss 96.38084 Test MSE 15.951254282848854 Test RE 2.893777175127939\n",
      "9 Train Loss 77.36693 Test MSE 16.398163594941632 Test RE 2.934034897498357\n",
      "10 Train Loss 65.45233 Test MSE 16.246384205600616 Test RE 2.920424797503241\n",
      "11 Train Loss 54.384506 Test MSE 16.536932897641325 Test RE 2.94642336453232\n",
      "12 Train Loss 47.465694 Test MSE 16.32707986105236 Test RE 2.9276686764336937\n",
      "13 Train Loss 41.268578 Test MSE 16.168062786204743 Test RE 2.9133768245650526\n",
      "14 Train Loss 37.80262 Test MSE 16.27439330926856 Test RE 2.92294114990083\n",
      "15 Train Loss 34.294247 Test MSE 16.18105432732211 Test RE 2.914547083955341\n",
      "16 Train Loss 31.644682 Test MSE 16.10852428438849 Test RE 2.9080076570534237\n",
      "17 Train Loss 29.52163 Test MSE 15.92073193146775 Test RE 2.8910072620363936\n",
      "18 Train Loss 27.530853 Test MSE 15.900071353158674 Test RE 2.889130800801235\n",
      "19 Train Loss 25.843672 Test MSE 15.783313741387373 Test RE 2.8785035036981386\n",
      "20 Train Loss 24.352482 Test MSE 15.823835015160952 Test RE 2.882196196566396\n",
      "21 Train Loss 22.9539 Test MSE 15.769689264819625 Test RE 2.877260844162266\n",
      "22 Train Loss 22.068954 Test MSE 15.739898263334036 Test RE 2.874541798741265\n",
      "23 Train Loss 21.504572 Test MSE 15.650946254018768 Test RE 2.866407738798916\n",
      "24 Train Loss 20.5903 Test MSE 15.526155898346 Test RE 2.8549574434475518\n",
      "25 Train Loss 20.001194 Test MSE 15.607234727924347 Test RE 2.8624021451065222\n",
      "26 Train Loss 19.59662 Test MSE 15.556219749683153 Test RE 2.8577201848330067\n",
      "27 Train Loss 19.121864 Test MSE 15.446533127525441 Test RE 2.8476274960296095\n",
      "28 Train Loss 18.537243 Test MSE 15.305901073907494 Test RE 2.8346348270205652\n",
      "29 Train Loss 18.131523 Test MSE 15.15654387006359 Test RE 2.8207705326557537\n",
      "30 Train Loss 17.74018 Test MSE 15.008959460357048 Test RE 2.8070035373683995\n",
      "31 Train Loss 17.480402 Test MSE 15.048307232597894 Test RE 2.810680575802501\n",
      "32 Train Loss 17.060865 Test MSE 14.85689943289988 Test RE 2.7927480641927525\n",
      "33 Train Loss 16.567423 Test MSE 14.604112393500007 Test RE 2.7688871191188005\n",
      "34 Train Loss 16.255816 Test MSE 14.524817014666775 Test RE 2.761359828413719\n",
      "35 Train Loss 15.900126 Test MSE 14.374879754233858 Test RE 2.7470703275335047\n",
      "36 Train Loss 15.653177 Test MSE 14.243057313994552 Test RE 2.7344455420816125\n",
      "37 Train Loss 15.368742 Test MSE 14.187706899292484 Test RE 2.729127160571888\n",
      "38 Train Loss 15.114362 Test MSE 14.057098544503873 Test RE 2.7165362976503356\n",
      "39 Train Loss 14.915363 Test MSE 13.953995004985856 Test RE 2.706555575902034\n",
      "40 Train Loss 14.657313 Test MSE 13.723622230570365 Test RE 2.6841207226053383\n",
      "41 Train Loss 14.381749 Test MSE 13.587760067979834 Test RE 2.6708014442342467\n",
      "42 Train Loss 14.062843 Test MSE 13.271804252968874 Test RE 2.6395667648120615\n",
      "43 Train Loss 13.720507 Test MSE 12.98164249817028 Test RE 2.610552851706242\n",
      "44 Train Loss 13.071445 Test MSE 12.809229531174134 Test RE 2.5931591503873204\n",
      "45 Train Loss 12.673069 Test MSE 12.571665731214674 Test RE 2.568999857385571\n",
      "46 Train Loss 12.364424 Test MSE 12.179794938791588 Test RE 2.5286437975689164\n",
      "47 Train Loss 12.036986 Test MSE 11.798762200221578 Test RE 2.48877646786126\n",
      "48 Train Loss 11.71691 Test MSE 11.543333473748485 Test RE 2.4616895876967018\n",
      "49 Train Loss 11.280447 Test MSE 11.309366982519585 Test RE 2.436614453917951\n",
      "50 Train Loss 10.754585 Test MSE 10.618039615848495 Test RE 2.360966573147456\n",
      "51 Train Loss 10.15039 Test MSE 10.153997180890224 Test RE 2.3087993256171564\n",
      "52 Train Loss 9.629188 Test MSE 9.548147547131883 Test RE 2.238861501223783\n",
      "53 Train Loss 9.202301 Test MSE 9.179129132280616 Test RE 2.195171256534879\n",
      "54 Train Loss 8.853634 Test MSE 8.85558405169932 Test RE 2.1561366033613525\n",
      "55 Train Loss 8.167171 Test MSE 7.620194273680716 Test RE 2.0000953007582023\n",
      "56 Train Loss 7.336326 Test MSE 6.621987985384626 Test RE 1.8644977425597171\n",
      "57 Train Loss 6.734211 Test MSE 6.149261718371121 Test RE 1.7967148461095492\n",
      "58 Train Loss 6.0838594 Test MSE 5.0997396581509005 Test RE 1.6362199010673029\n",
      "59 Train Loss 5.6509185 Test MSE 4.243690184270065 Test RE 1.4925864776860471\n",
      "60 Train Loss 5.0334034 Test MSE 3.574531323631444 Test RE 1.3698632702657008\n",
      "61 Train Loss 4.537461 Test MSE 2.933330542033569 Test RE 1.2409325310167556\n",
      "62 Train Loss 4.087542 Test MSE 2.581169576449266 Test RE 1.1640615288038363\n",
      "63 Train Loss 3.454581 Test MSE 1.8799668591325613 Test RE 0.993442566206346\n",
      "64 Train Loss 2.9822903 Test MSE 1.6910771516259993 Test RE 0.9422136215597877\n",
      "65 Train Loss 2.5820556 Test MSE 1.2757061056975278 Test RE 0.8183573450377157\n",
      "66 Train Loss 2.1668077 Test MSE 1.007064547130532 Test RE 0.7271036441529919\n",
      "67 Train Loss 1.7116066 Test MSE 0.49289778657897004 Test RE 0.5086816854554616\n",
      "68 Train Loss 1.499494 Test MSE 0.346190355368161 Test RE 0.426309636671348\n",
      "69 Train Loss 1.2694377 Test MSE 0.25678178678010033 Test RE 0.36715527813757254\n",
      "70 Train Loss 1.0786684 Test MSE 0.16400576964683194 Test RE 0.2934250795165509\n",
      "71 Train Loss 0.96639854 Test MSE 0.1162552527829146 Test RE 0.24704380061434777\n",
      "72 Train Loss 0.84014827 Test MSE 0.09944223173913833 Test RE 0.2284825824901353\n",
      "73 Train Loss 0.688529 Test MSE 0.06842541609012125 Test RE 0.18952931420405641\n",
      "74 Train Loss 0.62550956 Test MSE 0.0812855313246561 Test RE 0.20657334978607267\n",
      "75 Train Loss 0.584928 Test MSE 0.07410949607407824 Test RE 0.19724436176513602\n",
      "76 Train Loss 0.5367966 Test MSE 0.06994639657687478 Test RE 0.1916241937504314\n",
      "77 Train Loss 0.48978248 Test MSE 0.05448260058407225 Test RE 0.16912062786735782\n",
      "78 Train Loss 0.44539893 Test MSE 0.058758440104453885 Test RE 0.1756316561261362\n",
      "79 Train Loss 0.41537425 Test MSE 0.05451253976702948 Test RE 0.1691670889205915\n",
      "80 Train Loss 0.37721187 Test MSE 0.057041816504834336 Test RE 0.1730471062454463\n",
      "81 Train Loss 0.3518515 Test MSE 0.05030643807759064 Test RE 0.1625097610952116\n",
      "82 Train Loss 0.30974686 Test MSE 0.051493754567312276 Test RE 0.16441632889693283\n",
      "83 Train Loss 0.28194958 Test MSE 0.03949477345908212 Test RE 0.14399170731415903\n",
      "84 Train Loss 0.22641331 Test MSE 0.01706556371700225 Test RE 0.09465160594036037\n",
      "85 Train Loss 0.19864923 Test MSE 0.00870543223569374 Test RE 0.06760251252234152\n",
      "86 Train Loss 0.18729234 Test MSE 0.007236206143548273 Test RE 0.06163439436847087\n",
      "87 Train Loss 0.16366285 Test MSE 0.007287003384313023 Test RE 0.061850348817205886\n",
      "88 Train Loss 0.14881651 Test MSE 0.005587976025668778 Test RE 0.05416203016704369\n",
      "89 Train Loss 0.1384141 Test MSE 0.004419946346578203 Test RE 0.04816994677051653\n",
      "90 Train Loss 0.13035032 Test MSE 0.004707905001637098 Test RE 0.04971432110258338\n",
      "91 Train Loss 0.123838544 Test MSE 0.0052369739236878855 Test RE 0.05243338228587781\n",
      "92 Train Loss 0.11663284 Test MSE 0.006648125088981404 Test RE 0.059076840251680085\n",
      "93 Train Loss 0.102774374 Test MSE 0.004950834955451157 Test RE 0.050980828847519546\n",
      "94 Train Loss 0.0967948 Test MSE 0.0034761360036774593 Test RE 0.042718505206484916\n",
      "95 Train Loss 0.09257713 Test MSE 0.0030115945433073156 Test RE 0.039761789190681775\n",
      "96 Train Loss 0.08916084 Test MSE 0.0022028764490089783 Test RE 0.03400656276816416\n",
      "97 Train Loss 0.083723895 Test MSE 0.0019001053044629163 Test RE 0.03158322707820519\n",
      "98 Train Loss 0.078681044 Test MSE 0.0013945269717253286 Test RE 0.027057092530769954\n",
      "99 Train Loss 0.075287096 Test MSE 0.0016651691942554162 Test RE 0.029566291307335298\n",
      "100 Train Loss 0.06870646 Test MSE 0.0015314095040493555 Test RE 0.028353934819721212\n",
      "101 Train Loss 0.0659539 Test MSE 0.0013898443813309084 Test RE 0.027011627717175805\n",
      "102 Train Loss 0.06231413 Test MSE 0.0012239313883476745 Test RE 0.02534814623693016\n",
      "103 Train Loss 0.058801204 Test MSE 0.0015123086167411015 Test RE 0.028176554213359403\n",
      "104 Train Loss 0.05404655 Test MSE 0.0017437621565120562 Test RE 0.030255984693341887\n",
      "105 Train Loss 0.05234426 Test MSE 0.001624142107167037 Test RE 0.029199786808051246\n",
      "106 Train Loss 0.0507604 Test MSE 0.0015717904279279784 Test RE 0.02872532741035119\n",
      "107 Train Loss 0.0479999 Test MSE 0.0013994418536450825 Test RE 0.027104730709353334\n",
      "108 Train Loss 0.046044685 Test MSE 0.001451700494782988 Test RE 0.027606171399215073\n",
      "109 Train Loss 0.044143632 Test MSE 0.0013198315792767095 Test RE 0.026322487332111722\n",
      "110 Train Loss 0.041406114 Test MSE 0.0013133880094338374 Test RE 0.026258154007329667\n",
      "111 Train Loss 0.039926454 Test MSE 0.0013175636996084939 Test RE 0.02629986251354076\n",
      "112 Train Loss 0.0381343 Test MSE 0.001234259959740595 Test RE 0.025454876121837753\n",
      "113 Train Loss 0.03708419 Test MSE 0.0011170554687021052 Test RE 0.024216146604578447\n",
      "114 Train Loss 0.034540474 Test MSE 0.000842623225939184 Test RE 0.02103218438749828\n",
      "115 Train Loss 0.033396967 Test MSE 0.0008168044276451524 Test RE 0.02070745419067951\n",
      "116 Train Loss 0.032784518 Test MSE 0.0008037584081191822 Test RE 0.020541418568179596\n",
      "117 Train Loss 0.030374547 Test MSE 0.0008279014470085453 Test RE 0.02084764429638239\n",
      "118 Train Loss 0.02897981 Test MSE 0.0010024396519876452 Test RE 0.02294017814640181\n",
      "119 Train Loss 0.028456762 Test MSE 0.0010197800587324229 Test RE 0.023137739399566128\n",
      "120 Train Loss 0.027012624 Test MSE 0.0012649817402276174 Test RE 0.02576972570721076\n",
      "121 Train Loss 0.026388247 Test MSE 0.0011755345639013809 Test RE 0.02484193203086967\n",
      "122 Train Loss 0.026005065 Test MSE 0.0013767473842663832 Test RE 0.026884056389142715\n",
      "123 Train Loss 0.02482925 Test MSE 0.001666712725707095 Test RE 0.02957999139555767\n",
      "124 Train Loss 0.024170151 Test MSE 0.0015651825047565497 Test RE 0.028664882114177385\n",
      "125 Train Loss 0.023515612 Test MSE 0.0017164900882683351 Test RE 0.030018453725923752\n",
      "126 Train Loss 0.022862695 Test MSE 0.0018218826456120718 Test RE 0.030926293071415895\n",
      "127 Train Loss 0.02176938 Test MSE 0.00164117063464905 Test RE 0.029352462131692167\n",
      "128 Train Loss 0.02103165 Test MSE 0.0016964383934291408 Test RE 0.029842603862046298\n",
      "129 Train Loss 0.020552497 Test MSE 0.0017371990972433742 Test RE 0.03019899325806479\n",
      "130 Train Loss 0.01994663 Test MSE 0.0018539363424069821 Test RE 0.031197161173055737\n",
      "131 Train Loss 0.019076813 Test MSE 0.0018741994084034562 Test RE 0.031367186482365465\n",
      "132 Train Loss 0.01770759 Test MSE 0.0021480035789776266 Test RE 0.03358034610277834\n",
      "133 Train Loss 0.017032765 Test MSE 0.002033204037806114 Test RE 0.03267067815916485\n",
      "134 Train Loss 0.016715938 Test MSE 0.002076522159225781 Test RE 0.03301687402010648\n",
      "135 Train Loss 0.016094407 Test MSE 0.0023031968756539304 Test RE 0.03477228247739667\n",
      "136 Train Loss 0.015285307 Test MSE 0.0020598932872773618 Test RE 0.032884408069457964\n",
      "137 Train Loss 0.014512805 Test MSE 0.0018210120805182408 Test RE 0.030918903306681497\n",
      "138 Train Loss 0.014012824 Test MSE 0.0017876458290015558 Test RE 0.03063433149865385\n",
      "139 Train Loss 0.0137447715 Test MSE 0.001793080562308486 Test RE 0.03068086282837933\n",
      "140 Train Loss 0.0135560855 Test MSE 0.0019761257339019076 Test RE 0.032208830397459254\n",
      "141 Train Loss 0.013343425 Test MSE 0.0018722783684178967 Test RE 0.031351106798417606\n",
      "142 Train Loss 0.013013291 Test MSE 0.0018571232496329697 Test RE 0.031223963541105654\n",
      "143 Train Loss 0.012488637 Test MSE 0.0015936675877386104 Test RE 0.028924545111041675\n",
      "144 Train Loss 0.012086419 Test MSE 0.0014677719893410345 Test RE 0.02775856207232037\n",
      "145 Train Loss 0.011821471 Test MSE 0.0014496778907709053 Test RE 0.02758693333478459\n",
      "146 Train Loss 0.011605096 Test MSE 0.0014059404737525227 Test RE 0.027167591245765902\n",
      "147 Train Loss 0.0113520725 Test MSE 0.0012926550425990185 Test RE 0.026050075719375152\n",
      "148 Train Loss 0.011146578 Test MSE 0.0012291235307184789 Test RE 0.02540185508895726\n",
      "149 Train Loss 0.010829799 Test MSE 0.0011201445997006288 Test RE 0.02424960743283462\n",
      "150 Train Loss 0.010663109 Test MSE 0.001111714104639659 Test RE 0.024158180705470548\n",
      "151 Train Loss 0.010481756 Test MSE 0.001093794752004954 Test RE 0.023962690876575203\n",
      "152 Train Loss 0.010341703 Test MSE 0.0010309679037847047 Test RE 0.02326431342263905\n",
      "153 Train Loss 0.01024962 Test MSE 0.0010201462272110893 Test RE 0.023141893016010048\n",
      "154 Train Loss 0.010164322 Test MSE 0.0010193604122262835 Test RE 0.02313297824027469\n",
      "155 Train Loss 0.010075046 Test MSE 0.0010343333372719583 Test RE 0.023302253841638268\n",
      "156 Train Loss 0.009911956 Test MSE 0.0010503248641335497 Test RE 0.02348169760422893\n",
      "157 Train Loss 0.009829972 Test MSE 0.0010003821870384843 Test RE 0.022916624182058896\n",
      "158 Train Loss 0.009696147 Test MSE 0.001133705914937461 Test RE 0.024395957825651182\n",
      "159 Train Loss 0.009433376 Test MSE 0.001195315417075156 Test RE 0.02505006909825926\n",
      "160 Train Loss 0.009272207 Test MSE 0.0011515350411909625 Test RE 0.024587039938692035\n",
      "161 Train Loss 0.009156306 Test MSE 0.0011043834718329694 Test RE 0.024078399555757374\n",
      "162 Train Loss 0.009032689 Test MSE 0.0011513228714548865 Test RE 0.02458477475964825\n",
      "163 Train Loss 0.008919738 Test MSE 0.001229088009105081 Test RE 0.025401488030084494\n",
      "164 Train Loss 0.008806291 Test MSE 0.0012347306341758961 Test RE 0.025459729158411815\n",
      "165 Train Loss 0.008676717 Test MSE 0.0012895896944722996 Test RE 0.026019170356328773\n",
      "166 Train Loss 0.008475238 Test MSE 0.0014279650505417117 Test RE 0.02737955950683694\n",
      "167 Train Loss 0.008251 Test MSE 0.001419110233760267 Test RE 0.027294537118821488\n",
      "168 Train Loss 0.0080558015 Test MSE 0.00147999938166012 Test RE 0.02787394473380923\n",
      "169 Train Loss 0.007936101 Test MSE 0.0014806795553205876 Test RE 0.027880349109872644\n",
      "170 Train Loss 0.007875322 Test MSE 0.0015702526178932373 Test RE 0.028711271812982147\n",
      "171 Train Loss 0.007793882 Test MSE 0.0015584231233291598 Test RE 0.02860291920785979\n",
      "172 Train Loss 0.007678256 Test MSE 0.0016313541225990672 Test RE 0.029264545935007224\n",
      "173 Train Loss 0.0075312713 Test MSE 0.0016579617984644058 Test RE 0.029502235639039226\n",
      "174 Train Loss 0.007207365 Test MSE 0.0016763736620118669 Test RE 0.029665596279408155\n",
      "175 Train Loss 0.0070732054 Test MSE 0.0014408107502454932 Test RE 0.027502434418640528\n",
      "176 Train Loss 0.007004884 Test MSE 0.001346719709261449 Test RE 0.02658926152708002\n",
      "177 Train Loss 0.006959548 Test MSE 0.0013187572011335593 Test RE 0.026311771547203412\n",
      "178 Train Loss 0.006869663 Test MSE 0.0012028623732314588 Test RE 0.02512902495422375\n",
      "179 Train Loss 0.0067760292 Test MSE 0.0011030604190190925 Test RE 0.02406397225672669\n",
      "180 Train Loss 0.006629505 Test MSE 0.0011185511883530473 Test RE 0.02423235370027778\n",
      "181 Train Loss 0.006522019 Test MSE 0.0011599853303610112 Test RE 0.024677088360035977\n",
      "182 Train Loss 0.006389379 Test MSE 0.0011603431538198153 Test RE 0.024680894166897543\n",
      "183 Train Loss 0.006245471 Test MSE 0.0010608991309747858 Test RE 0.023599603939421038\n",
      "184 Train Loss 0.006112999 Test MSE 0.001032936475815079 Test RE 0.023286513743084405\n",
      "185 Train Loss 0.0060253046 Test MSE 0.0009725403344916722 Test RE 0.0225954751661207\n",
      "186 Train Loss 0.0059252693 Test MSE 0.0009812985925609723 Test RE 0.02269698944164665\n",
      "187 Train Loss 0.0058670384 Test MSE 0.0009790386996571742 Test RE 0.022670839230520348\n",
      "188 Train Loss 0.005783043 Test MSE 0.0010357962905807705 Test RE 0.0233187272851844\n",
      "189 Train Loss 0.0057006613 Test MSE 0.0011185504853057334 Test RE 0.024232346084848984\n",
      "190 Train Loss 0.00562226 Test MSE 0.0012009245683583674 Test RE 0.025108775432825754\n",
      "191 Train Loss 0.0054918686 Test MSE 0.0012022812929830171 Test RE 0.02512295454072497\n",
      "192 Train Loss 0.005425268 Test MSE 0.001096611013055024 Test RE 0.02399352015652217\n",
      "193 Train Loss 0.0052833534 Test MSE 0.0011656274230776758 Test RE 0.02473702943232427\n",
      "194 Train Loss 0.0051843515 Test MSE 0.001028296750319004 Test RE 0.023234155909978915\n",
      "195 Train Loss 0.005113641 Test MSE 0.000986612345116067 Test RE 0.02275835881273342\n",
      "196 Train Loss 0.0050088055 Test MSE 0.0010487083877850601 Test RE 0.02346362118531619\n",
      "197 Train Loss 0.004935935 Test MSE 0.0010926295994164248 Test RE 0.02394992448204264\n",
      "198 Train Loss 0.0048690196 Test MSE 0.001038704419382864 Test RE 0.023351439475202514\n",
      "199 Train Loss 0.0047958754 Test MSE 0.0009976599573624071 Test RE 0.022885422700783704\n",
      "200 Train Loss 0.0047241524 Test MSE 0.0009915138686824169 Test RE 0.022814820922122808\n",
      "201 Train Loss 0.0046323254 Test MSE 0.0008871712451374585 Test RE 0.021580991624326414\n",
      "202 Train Loss 0.0045014275 Test MSE 0.0008626665918545727 Test RE 0.021280859157807735\n",
      "203 Train Loss 0.0043862634 Test MSE 0.0009748435769510546 Test RE 0.0226222154870296\n",
      "204 Train Loss 0.004256718 Test MSE 0.0009618184411613639 Test RE 0.02247057664218128\n",
      "205 Train Loss 0.0041956827 Test MSE 0.000876425802025675 Test RE 0.02144989867541688\n",
      "206 Train Loss 0.00409049 Test MSE 0.0008915406998239205 Test RE 0.02163407119805392\n",
      "207 Train Loss 0.0040382305 Test MSE 0.0009578325756225076 Test RE 0.022423968219465608\n",
      "208 Train Loss 0.003995481 Test MSE 0.0009407458542479937 Test RE 0.02222305822886054\n",
      "209 Train Loss 0.003958346 Test MSE 0.0009199021618732923 Test RE 0.021975485943557627\n",
      "210 Train Loss 0.003909058 Test MSE 0.0008548090189186585 Test RE 0.02118371941756891\n",
      "211 Train Loss 0.0038509022 Test MSE 0.0008151134276531563 Test RE 0.020686008146982043\n",
      "212 Train Loss 0.0038035933 Test MSE 0.0007848706497748109 Test RE 0.020298629286273046\n",
      "213 Train Loss 0.0037581122 Test MSE 0.0007294346064788822 Test RE 0.01956864927203392\n",
      "214 Train Loss 0.003712412 Test MSE 0.0007104175792121941 Test RE 0.01931187836543568\n",
      "215 Train Loss 0.0036627243 Test MSE 0.0006747743725307068 Test RE 0.01882118474464561\n",
      "216 Train Loss 0.0036285697 Test MSE 0.0006894633668691314 Test RE 0.019024938676176724\n",
      "217 Train Loss 0.0035854352 Test MSE 0.0007137055088811019 Test RE 0.019356516055727812\n",
      "218 Train Loss 0.003542577 Test MSE 0.0006788992463088373 Test RE 0.01887862374260165\n",
      "219 Train Loss 0.003473776 Test MSE 0.0006933290506391302 Test RE 0.019078198646890827\n",
      "220 Train Loss 0.0034295872 Test MSE 0.0007535033947565374 Test RE 0.019888877565798872\n",
      "221 Train Loss 0.003407483 Test MSE 0.0007335810037269221 Test RE 0.019624188460994094\n",
      "222 Train Loss 0.003364668 Test MSE 0.0007416761865351959 Test RE 0.01973216939881276\n",
      "223 Train Loss 0.003315952 Test MSE 0.0007478039893831571 Test RE 0.01981351629914389\n",
      "224 Train Loss 0.0032645613 Test MSE 0.000685480112923733 Test RE 0.018969902443572155\n",
      "225 Train Loss 0.0032089946 Test MSE 0.0006700047698803509 Test RE 0.018754548568051223\n",
      "226 Train Loss 0.0031793797 Test MSE 0.0006031362751053626 Test RE 0.01779407400316613\n",
      "227 Train Loss 0.0031411988 Test MSE 0.000563456411121222 Test RE 0.017198787477375237\n",
      "228 Train Loss 0.0031133154 Test MSE 0.0005304292229457804 Test RE 0.016687119997285664\n",
      "229 Train Loss 0.0030995505 Test MSE 0.0005293310342022528 Test RE 0.016669836727800404\n",
      "230 Train Loss 0.0030881858 Test MSE 0.0005352049086427785 Test RE 0.016762072378669085\n",
      "231 Train Loss 0.003067363 Test MSE 0.0005143792975328975 Test RE 0.01643271821641423\n",
      "232 Train Loss 0.003042256 Test MSE 0.000511455359478312 Test RE 0.016385946576786947\n",
      "233 Train Loss 0.003022902 Test MSE 0.0005022873872852802 Test RE 0.016238421273068765\n",
      "234 Train Loss 0.002993021 Test MSE 0.00047992662919655167 Test RE 0.015872856557917977\n",
      "235 Train Loss 0.0029539398 Test MSE 0.00043935132625405696 Test RE 0.015187057544521924\n",
      "236 Train Loss 0.0029046617 Test MSE 0.0004198911164815878 Test RE 0.01484690777754811\n",
      "237 Train Loss 0.002866365 Test MSE 0.00037326660950858057 Test RE 0.01399836259197129\n",
      "238 Train Loss 0.0028288052 Test MSE 0.00040394419868257706 Test RE 0.014562245731483186\n",
      "239 Train Loss 0.0028011885 Test MSE 0.0003861992354467109 Test RE 0.01423879942881419\n",
      "240 Train Loss 0.002763838 Test MSE 0.0003401047552529175 Test RE 0.013362078527601408\n",
      "241 Train Loss 0.002718296 Test MSE 0.0003477876234651655 Test RE 0.013512158443112765\n",
      "242 Train Loss 0.002683219 Test MSE 0.0003769000047531724 Test RE 0.014066327967474356\n",
      "243 Train Loss 0.0026068103 Test MSE 0.0003197789753102993 Test RE 0.012956646827447753\n",
      "244 Train Loss 0.0025669192 Test MSE 0.0002780529501324123 Test RE 0.012081793853982965\n",
      "245 Train Loss 0.002517097 Test MSE 0.0002688390051901303 Test RE 0.011879927970871665\n",
      "246 Train Loss 0.0024673208 Test MSE 0.0002516533928700882 Test RE 0.011493943624692455\n",
      "247 Train Loss 0.0024327245 Test MSE 0.00021701501619495757 Test RE 0.010673640235574865\n",
      "248 Train Loss 0.002406597 Test MSE 0.0002048655175037866 Test RE 0.010370557413934885\n",
      "249 Train Loss 0.0023823876 Test MSE 0.00020348554001592566 Test RE 0.010335570273428778\n",
      "250 Train Loss 0.002347177 Test MSE 0.00019039238103753977 Test RE 0.009997523881657465\n",
      "251 Train Loss 0.0023040439 Test MSE 0.00016460763402382158 Test RE 0.009295925916726353\n",
      "252 Train Loss 0.0022360436 Test MSE 0.00015524411600382714 Test RE 0.009027660991643283\n",
      "253 Train Loss 0.002169931 Test MSE 0.00013254285610437433 Test RE 0.008341532189078273\n",
      "254 Train Loss 0.0021128084 Test MSE 0.00011482384759537007 Test RE 0.007763967617844532\n",
      "255 Train Loss 0.002069894 Test MSE 8.698140898552126e-05 Test RE 0.006757419595220879\n",
      "256 Train Loss 0.0020389443 Test MSE 8.085695996551009e-05 Test RE 0.006515179298789854\n",
      "257 Train Loss 0.0019976413 Test MSE 6.821120159043185e-05 Test RE 0.005984054188993186\n",
      "258 Train Loss 0.0019708707 Test MSE 7.444580216026835e-05 Test RE 0.006251550943527164\n",
      "259 Train Loss 0.0019531032 Test MSE 7.334533003878932e-05 Test RE 0.006205173101530695\n",
      "260 Train Loss 0.0019398262 Test MSE 7.094519067296024e-05 Test RE 0.0061028001435952635\n",
      "261 Train Loss 0.0019151032 Test MSE 7.4599008804727e-05 Test RE 0.006257980365019236\n",
      "262 Train Loss 0.001896323 Test MSE 6.631867887955443e-05 Test RE 0.005900456333714678\n",
      "263 Train Loss 0.0018765114 Test MSE 7.30048377832224e-05 Test RE 0.006190753157003156\n",
      "264 Train Loss 0.0018609215 Test MSE 8.197275628551023e-05 Test RE 0.0065599788136218385\n",
      "265 Train Loss 0.0018332659 Test MSE 7.763616549725101e-05 Test RE 0.006384100368597872\n",
      "266 Train Loss 0.0018130271 Test MSE 7.924177050615613e-05 Test RE 0.0064497777966732355\n",
      "267 Train Loss 0.0017904594 Test MSE 7.769750344598736e-05 Test RE 0.0063866218114320954\n",
      "268 Train Loss 0.0017764582 Test MSE 7.534969173499672e-05 Test RE 0.00628938828803374\n",
      "269 Train Loss 0.0017675854 Test MSE 7.261082303366142e-05 Test RE 0.006174024483535937\n",
      "270 Train Loss 0.0017571927 Test MSE 7.349162445709396e-05 Test RE 0.006211358430403899\n",
      "271 Train Loss 0.0017431594 Test MSE 6.309609441338178e-05 Test RE 0.005755312456329601\n",
      "272 Train Loss 0.0017304149 Test MSE 6.0200485155898785e-05 Test RE 0.00562169996575137\n",
      "273 Train Loss 0.001719497 Test MSE 6.493141301651787e-05 Test RE 0.005838416785528326\n",
      "274 Train Loss 0.0017121653 Test MSE 6.0673743715209446e-05 Test RE 0.005643753851537343\n",
      "275 Train Loss 0.0016993403 Test MSE 5.7309907154284006e-05 Test RE 0.005485074366262907\n",
      "276 Train Loss 0.0016810813 Test MSE 6.052071609825594e-05 Test RE 0.00563663219232414\n",
      "277 Train Loss 0.0016693205 Test MSE 6.245462643715478e-05 Test RE 0.005725981956647827\n",
      "278 Train Loss 0.0016579155 Test MSE 6.262702019206342e-05 Test RE 0.005733879236117662\n",
      "279 Train Loss 0.0016404478 Test MSE 7.170632030846639e-05 Test RE 0.006135449502598036\n",
      "280 Train Loss 0.0016191187 Test MSE 6.582432386866165e-05 Test RE 0.00587842350366249\n",
      "281 Train Loss 0.0016045603 Test MSE 6.171696055560355e-05 Test RE 0.005692066070645891\n",
      "282 Train Loss 0.0015909147 Test MSE 6.311481844600129e-05 Test RE 0.005756166349629966\n",
      "283 Train Loss 0.0015846398 Test MSE 6.381145161363186e-05 Test RE 0.005787846168818949\n",
      "284 Train Loss 0.0015736992 Test MSE 6.332679842935255e-05 Test RE 0.005765824693322633\n",
      "285 Train Loss 0.0015626396 Test MSE 6.308640645875593e-05 Test RE 0.005754870595807983\n",
      "286 Train Loss 0.0015488485 Test MSE 5.345432106678566e-05 Test RE 0.00529735498303095\n",
      "287 Train Loss 0.0015412687 Test MSE 5.1785575983842395e-05 Test RE 0.005214012561992588\n",
      "288 Train Loss 0.0015317845 Test MSE 4.705193740705589e-05 Test RE 0.004970000391605302\n",
      "289 Train Loss 0.0015238115 Test MSE 4.366607568131861e-05 Test RE 0.004787841328392414\n",
      "290 Train Loss 0.0015077878 Test MSE 4.959778638824664e-05 Test RE 0.005102685650345183\n",
      "291 Train Loss 0.0014948922 Test MSE 4.50610473613625e-05 Test RE 0.0048637171279859275\n",
      "292 Train Loss 0.0014723189 Test MSE 3.557889376392313e-05 Test RE 0.004321792266055022\n",
      "293 Train Loss 0.0014527093 Test MSE 3.540032293066477e-05 Test RE 0.00431093306341498\n",
      "294 Train Loss 0.001423766 Test MSE 3.8126401537055485e-05 Test RE 0.004473841320646453\n",
      "295 Train Loss 0.0014000713 Test MSE 4.342502139532928e-05 Test RE 0.004774607635171393\n",
      "296 Train Loss 0.0013838923 Test MSE 5.192719810834617e-05 Test RE 0.005221137281161259\n",
      "297 Train Loss 0.0013585294 Test MSE 5.5823911645662956e-05 Test RE 0.00541349574817267\n",
      "298 Train Loss 0.0013366225 Test MSE 5.855568411831733e-05 Test RE 0.005544369902466961\n",
      "299 Train Loss 0.0013247519 Test MSE 5.688598104189289e-05 Test RE 0.005464749937273774\n",
      "Training time: 133.56\n",
      "KG_tanh_medium\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 25304.527 Test MSE 17.161080951765822 Test RE 3.001511333961319\n",
      "1 Train Loss 10157.61 Test MSE 10.769579154957743 Test RE 2.377754618745077\n",
      "2 Train Loss 7444.9155 Test MSE 10.341527373615904 Test RE 2.3300219406258034\n",
      "3 Train Loss 3563.091 Test MSE 9.207736547926839 Test RE 2.198589299956277\n",
      "4 Train Loss 724.79846 Test MSE 13.649366012056012 Test RE 2.6768492094701832\n",
      "5 Train Loss 224.82298 Test MSE 15.62593209800119 Test RE 2.864116201881086\n",
      "6 Train Loss 91.34092 Test MSE 16.45005676367318 Test RE 2.938673712716342\n",
      "7 Train Loss 50.248 Test MSE 16.709342181383274 Test RE 2.9617428183038315\n",
      "8 Train Loss 35.382824 Test MSE 16.600877688688275 Test RE 2.9521144635117196\n",
      "9 Train Loss 28.908072 Test MSE 16.544892955757717 Test RE 2.947132410147964\n",
      "10 Train Loss 25.158604 Test MSE 16.547767726842885 Test RE 2.9473884396992673\n",
      "11 Train Loss 23.100718 Test MSE 16.515249341794803 Test RE 2.9444910263889366\n",
      "12 Train Loss 21.581724 Test MSE 16.4200558893661 Test RE 2.9359927792862117\n",
      "13 Train Loss 20.861061 Test MSE 16.396459448634765 Test RE 2.9338824366872123\n",
      "14 Train Loss 20.354256 Test MSE 16.39033683368363 Test RE 2.9333346138557426\n",
      "15 Train Loss 19.919863 Test MSE 16.355192883282935 Test RE 2.9301881170186452\n",
      "16 Train Loss 19.50068 Test MSE 16.33657546537863 Test RE 2.928519898536472\n",
      "17 Train Loss 19.169413 Test MSE 16.316737372669916 Test RE 2.9267412547448437\n",
      "18 Train Loss 18.860546 Test MSE 16.238409228702356 Test RE 2.919707924786488\n",
      "19 Train Loss 18.557722 Test MSE 16.11978621222968 Test RE 2.909024014906659\n",
      "20 Train Loss 18.31468 Test MSE 16.050273876990648 Test RE 2.902745038286925\n",
      "21 Train Loss 18.059261 Test MSE 15.93239611745319 Test RE 2.8920661038158335\n",
      "22 Train Loss 17.753845 Test MSE 15.641300259086554 Test RE 2.8655242901051174\n",
      "23 Train Loss 17.384933 Test MSE 15.387179074752387 Test RE 2.842151156802898\n",
      "24 Train Loss 16.990065 Test MSE 15.104960131106191 Test RE 2.8159663402628636\n",
      "25 Train Loss 16.414474 Test MSE 14.399735391178401 Test RE 2.749444284516979\n",
      "26 Train Loss 15.857078 Test MSE 13.746385332777452 Test RE 2.6863458494128687\n",
      "27 Train Loss 14.75555 Test MSE 13.336930583112629 Test RE 2.6460351740493504\n",
      "28 Train Loss 13.885169 Test MSE 12.892540805468613 Test RE 2.6015784409558336\n",
      "29 Train Loss 13.064638 Test MSE 12.225576709473366 Test RE 2.5333917103650516\n",
      "30 Train Loss 12.450196 Test MSE 11.046532941477924 Test RE 2.408134078626764\n",
      "31 Train Loss 11.18906 Test MSE 9.653218208367592 Test RE 2.2511463467698722\n",
      "32 Train Loss 9.800331 Test MSE 8.636165130967346 Test RE 2.129257259290917\n",
      "33 Train Loss 8.629953 Test MSE 7.901541627414212 Test RE 2.036683682186871\n",
      "34 Train Loss 7.2784896 Test MSE 6.339467058999913 Test RE 1.8242906926253128\n",
      "35 Train Loss 6.4687114 Test MSE 5.567054911048852 Test RE 1.7095445395754836\n",
      "36 Train Loss 5.861951 Test MSE 5.291525202647985 Test RE 1.6667025586063147\n",
      "37 Train Loss 5.08207 Test MSE 4.460511851823262 Test RE 1.5302416432755748\n",
      "38 Train Loss 4.543118 Test MSE 3.927727507855243 Test RE 1.435946775723141\n",
      "39 Train Loss 4.1563835 Test MSE 3.4165317731044786 Test RE 1.3392461285933093\n",
      "40 Train Loss 3.596786 Test MSE 2.7081311779644666 Test RE 1.1923465960659916\n",
      "41 Train Loss 3.211729 Test MSE 2.2782349365752848 Test RE 1.0936212021990699\n",
      "42 Train Loss 2.8482695 Test MSE 1.8340668512948368 Test RE 0.9812400104494734\n",
      "43 Train Loss 2.3918395 Test MSE 1.2443671569170458 Test RE 0.8082429734044658\n",
      "44 Train Loss 1.9334949 Test MSE 0.724216377006532 Test RE 0.6165976119381278\n",
      "45 Train Loss 1.5726398 Test MSE 0.4862761530306104 Test RE 0.505253294254444\n",
      "46 Train Loss 1.2430528 Test MSE 0.29634698976637186 Test RE 0.3944281728030199\n",
      "47 Train Loss 0.9286298 Test MSE 0.12344647683915481 Test RE 0.25456987979450557\n",
      "48 Train Loss 0.8029488 Test MSE 0.10658351975669313 Test RE 0.2365444140208491\n",
      "49 Train Loss 0.696038 Test MSE 0.10316533290293987 Test RE 0.23272045621759835\n",
      "50 Train Loss 0.5885224 Test MSE 0.09433258951233878 Test RE 0.22253511267905915\n",
      "51 Train Loss 0.5096921 Test MSE 0.0951520279853076 Test RE 0.2234995700926934\n",
      "52 Train Loss 0.44496801 Test MSE 0.09200122823960703 Test RE 0.21976801235380256\n",
      "53 Train Loss 0.38183123 Test MSE 0.09950028437069927 Test RE 0.22854926482261825\n",
      "54 Train Loss 0.32302317 Test MSE 0.07862229757127805 Test RE 0.2031610894924859\n",
      "55 Train Loss 0.25387925 Test MSE 0.06900257947221658 Test RE 0.19032696865126122\n",
      "56 Train Loss 0.21913484 Test MSE 0.061080815282046605 Test RE 0.17906886472851138\n",
      "57 Train Loss 0.1922677 Test MSE 0.05244514608597209 Test RE 0.1659282441007701\n",
      "58 Train Loss 0.17201948 Test MSE 0.03597923419930907 Test RE 0.13743382233045467\n",
      "59 Train Loss 0.15684775 Test MSE 0.03934923046817231 Test RE 0.1437261490539141\n",
      "60 Train Loss 0.14192335 Test MSE 0.033478687025293344 Test RE 0.13257202081474376\n",
      "61 Train Loss 0.12796532 Test MSE 0.02878239843590311 Test RE 0.12292243595080118\n",
      "62 Train Loss 0.11799731 Test MSE 0.030835710769013706 Test RE 0.12723150059592686\n",
      "63 Train Loss 0.10656461 Test MSE 0.021265563238216184 Test RE 0.10565890671502914\n",
      "64 Train Loss 0.098420545 Test MSE 0.018015727476406274 Test RE 0.0972508866359195\n",
      "65 Train Loss 0.08759141 Test MSE 0.015308635560893631 Test RE 0.08964703078740946\n",
      "66 Train Loss 0.08294164 Test MSE 0.011611231295711523 Test RE 0.07807406749674567\n",
      "67 Train Loss 0.078051746 Test MSE 0.00961961232854385 Test RE 0.07106347698599075\n",
      "68 Train Loss 0.07159049 Test MSE 0.008390893372173632 Test RE 0.06636999253570146\n",
      "69 Train Loss 0.06886541 Test MSE 0.007345514701756121 Test RE 0.0620981674061834\n",
      "70 Train Loss 0.06403367 Test MSE 0.006613976880535977 Test RE 0.05892492031451758\n",
      "71 Train Loss 0.05927743 Test MSE 0.004468498981734676 Test RE 0.048433795005196\n",
      "72 Train Loss 0.055243 Test MSE 0.004141656263153181 Test RE 0.046628848806679224\n",
      "73 Train Loss 0.05063903 Test MSE 0.0035749502838575056 Test RE 0.04332141873488328\n",
      "74 Train Loss 0.046358097 Test MSE 0.0030125775836960743 Test RE 0.03976827815440934\n",
      "75 Train Loss 0.04174646 Test MSE 0.0018990591689559827 Test RE 0.03157453153796978\n",
      "76 Train Loss 0.04063144 Test MSE 0.001847814358334739 Test RE 0.03114560965839779\n",
      "77 Train Loss 0.038696226 Test MSE 0.001977590015522193 Test RE 0.03222076133485973\n",
      "78 Train Loss 0.03615314 Test MSE 0.0012982830064350586 Test RE 0.026106722562184322\n",
      "79 Train Loss 0.03496499 Test MSE 0.001238289117327345 Test RE 0.02549639012435837\n",
      "80 Train Loss 0.033199344 Test MSE 0.0011604048934242216 Test RE 0.02468155076937256\n",
      "81 Train Loss 0.03201234 Test MSE 0.001091945070328303 Test RE 0.02394242102957204\n",
      "82 Train Loss 0.03097988 Test MSE 0.0007270221219362411 Test RE 0.019536262432830732\n",
      "83 Train Loss 0.029665103 Test MSE 0.0005944055458231746 Test RE 0.017664815020665994\n",
      "84 Train Loss 0.028842462 Test MSE 0.0005603648312762754 Test RE 0.017151539314194112\n",
      "85 Train Loss 0.027517179 Test MSE 0.000539092390518575 Test RE 0.016822838220100243\n",
      "86 Train Loss 0.026457567 Test MSE 0.00047045627415101245 Test RE 0.01571546732668216\n",
      "87 Train Loss 0.025833385 Test MSE 0.00040023603866493225 Test RE 0.014495251780226991\n",
      "88 Train Loss 0.024863848 Test MSE 0.00034322777932866165 Test RE 0.013423287217872074\n",
      "89 Train Loss 0.024229875 Test MSE 0.0003017014342748455 Test RE 0.012585090851168988\n",
      "90 Train Loss 0.022758244 Test MSE 0.00024004555240679908 Test RE 0.011225727598730533\n",
      "91 Train Loss 0.021833865 Test MSE 0.00025214858603660385 Test RE 0.011505246721069843\n",
      "92 Train Loss 0.021249758 Test MSE 0.00023583261077806452 Test RE 0.011126782456231481\n",
      "93 Train Loss 0.0206615 Test MSE 0.00026049163548028353 Test RE 0.011694039564907022\n",
      "94 Train Loss 0.019183042 Test MSE 0.0003972735661910385 Test RE 0.01444150656807479\n",
      "95 Train Loss 0.018065207 Test MSE 0.0005208860684476945 Test RE 0.016536326502226344\n",
      "96 Train Loss 0.01747114 Test MSE 0.00046001193565219843 Test RE 0.015540043056254933\n",
      "97 Train Loss 0.016965253 Test MSE 0.0004935343311558967 Test RE 0.016096310899642485\n",
      "98 Train Loss 0.016215112 Test MSE 0.0006644062049995904 Test RE 0.018676027619315798\n",
      "99 Train Loss 0.015815377 Test MSE 0.0009011713607993451 Test RE 0.02175060584405184\n",
      "100 Train Loss 0.0154734505 Test MSE 0.0008651132432143819 Test RE 0.021311015639123826\n",
      "101 Train Loss 0.014932526 Test MSE 0.0009917780732469914 Test RE 0.022817860404737277\n",
      "102 Train Loss 0.014402434 Test MSE 0.0008205172668338506 Test RE 0.020754464388662245\n",
      "103 Train Loss 0.013373176 Test MSE 0.0007793589781362603 Test RE 0.02022723122382743\n",
      "104 Train Loss 0.012932889 Test MSE 0.0007740842939738695 Test RE 0.02015866629074231\n",
      "105 Train Loss 0.012607034 Test MSE 0.0007951226105936171 Test RE 0.02043076927820135\n",
      "106 Train Loss 0.012218998 Test MSE 0.0008420296761472759 Test RE 0.02102477547242832\n",
      "107 Train Loss 0.0118355965 Test MSE 0.0009326101076692834 Test RE 0.022126754976911578\n",
      "108 Train Loss 0.011525467 Test MSE 0.0008651901628450718 Test RE 0.02131196302897701\n",
      "109 Train Loss 0.011050767 Test MSE 0.0006763258992282558 Test RE 0.0188428103465372\n",
      "110 Train Loss 0.01069661 Test MSE 0.0006521968993024006 Test RE 0.01850363412655269\n",
      "111 Train Loss 0.010246335 Test MSE 0.0006326658016079673 Test RE 0.01822446749506125\n",
      "112 Train Loss 0.0098844115 Test MSE 0.0006394174083351345 Test RE 0.018321452273073708\n",
      "113 Train Loss 0.009730299 Test MSE 0.0006356493983011979 Test RE 0.018267389449455707\n",
      "114 Train Loss 0.009442458 Test MSE 0.0006660464820573832 Test RE 0.018699066970538376\n",
      "115 Train Loss 0.009269293 Test MSE 0.0006116253017060931 Test RE 0.017918860528535252\n",
      "116 Train Loss 0.0089013195 Test MSE 0.0005821553304989679 Test RE 0.017481838621761885\n",
      "117 Train Loss 0.0084242 Test MSE 0.0005396532234952469 Test RE 0.016831586581284638\n",
      "118 Train Loss 0.008133346 Test MSE 0.0005272799314140022 Test RE 0.016637508437105143\n",
      "119 Train Loss 0.007900361 Test MSE 0.0005084820458114644 Test RE 0.016338247815744892\n",
      "120 Train Loss 0.007720525 Test MSE 0.00048773272255566027 Test RE 0.01600142331650873\n",
      "121 Train Loss 0.007480205 Test MSE 0.0004682806051397442 Test RE 0.015679086392428487\n",
      "122 Train Loss 0.0072855847 Test MSE 0.0004998859352092905 Test RE 0.01619955655811472\n",
      "123 Train Loss 0.007143644 Test MSE 0.0004529590552818073 Test RE 0.015420453311769363\n",
      "124 Train Loss 0.0069620903 Test MSE 0.0004048750822205503 Test RE 0.014579015317600924\n",
      "125 Train Loss 0.006814152 Test MSE 0.00041625664792535534 Test RE 0.014782512637074072\n",
      "126 Train Loss 0.0066864453 Test MSE 0.0003907367673203745 Test RE 0.014322202412365296\n",
      "127 Train Loss 0.0065329573 Test MSE 0.0003604648089562782 Test RE 0.013756219716031363\n",
      "128 Train Loss 0.0064348653 Test MSE 0.0003238548157934928 Test RE 0.013038956828468463\n",
      "129 Train Loss 0.006329555 Test MSE 0.00034269808140733216 Test RE 0.013412925246635963\n",
      "130 Train Loss 0.0060762637 Test MSE 0.0003071851233962659 Test RE 0.012698948367514142\n",
      "131 Train Loss 0.005986585 Test MSE 0.00028250709965228315 Test RE 0.012178178935169964\n",
      "132 Train Loss 0.005896068 Test MSE 0.0002749497114305927 Test RE 0.012014184629949035\n",
      "133 Train Loss 0.0058341227 Test MSE 0.00027933417268789735 Test RE 0.012109597328178453\n",
      "134 Train Loss 0.0057884622 Test MSE 0.000264098334151555 Test RE 0.01177471756138351\n",
      "135 Train Loss 0.005685544 Test MSE 0.0002514776745663952 Test RE 0.011489930070687751\n",
      "136 Train Loss 0.0055622705 Test MSE 0.00022919377202029498 Test RE 0.010969051455299562\n",
      "137 Train Loss 0.005443827 Test MSE 0.00020496299133502285 Test RE 0.01037302424623543\n",
      "138 Train Loss 0.0052630086 Test MSE 0.00021522503737809092 Test RE 0.010629530039520947\n",
      "139 Train Loss 0.005160977 Test MSE 0.00021762206527217823 Test RE 0.010688558324482157\n",
      "140 Train Loss 0.005076578 Test MSE 0.00022371110046844368 Test RE 0.010837058923662738\n",
      "141 Train Loss 0.0050117886 Test MSE 0.0002152235929322175 Test RE 0.010629494370328483\n",
      "142 Train Loss 0.004941425 Test MSE 0.00020930266736419174 Test RE 0.010482262932874378\n",
      "143 Train Loss 0.0048730755 Test MSE 0.00022093107538548215 Test RE 0.010769513150215399\n",
      "144 Train Loss 0.004834887 Test MSE 0.00023564843452345571 Test RE 0.011122436811724767\n",
      "145 Train Loss 0.004789283 Test MSE 0.0002393593786729256 Test RE 0.01120967166295604\n",
      "146 Train Loss 0.0047535794 Test MSE 0.00023504772702198667 Test RE 0.011108251284381792\n",
      "147 Train Loss 0.0047049085 Test MSE 0.00022256117623271839 Test RE 0.010809170606859275\n",
      "148 Train Loss 0.00464131 Test MSE 0.00020023031546106173 Test RE 0.010252566229974775\n",
      "149 Train Loss 0.00457619 Test MSE 0.00020641632935353938 Test RE 0.010409735460847539\n",
      "150 Train Loss 0.0045245904 Test MSE 0.00020452667791635425 Test RE 0.010361977615763887\n",
      "151 Train Loss 0.004442473 Test MSE 0.0002118356313000787 Test RE 0.01054549993467027\n",
      "152 Train Loss 0.004361881 Test MSE 0.0002130058764891225 Test RE 0.010574588109737753\n",
      "153 Train Loss 0.0042963238 Test MSE 0.00022472500345013994 Test RE 0.0108615890091779\n",
      "154 Train Loss 0.0041950596 Test MSE 0.0002382706670846373 Test RE 0.011184149353031228\n",
      "155 Train Loss 0.0041362857 Test MSE 0.00023406960337210236 Test RE 0.011085114344027869\n",
      "156 Train Loss 0.004074167 Test MSE 0.00021654311436352926 Test RE 0.010662028938691663\n",
      "157 Train Loss 0.004010121 Test MSE 0.00020525958872394422 Test RE 0.010380526819424453\n",
      "158 Train Loss 0.003925568 Test MSE 0.0001966819139485941 Test RE 0.010161314202139029\n",
      "159 Train Loss 0.0038403482 Test MSE 0.0002083736781998715 Test RE 0.010458974318662984\n",
      "160 Train Loss 0.0037827962 Test MSE 0.0002079738308105468 Test RE 0.010448934658802436\n",
      "161 Train Loss 0.0037170032 Test MSE 0.0001978033704299304 Test RE 0.01019024231679935\n",
      "162 Train Loss 0.003644436 Test MSE 0.00020519228371095096 Test RE 0.010378824782556636\n",
      "163 Train Loss 0.0035739108 Test MSE 0.00022292481630578894 Test RE 0.010817997490789532\n",
      "164 Train Loss 0.0035414542 Test MSE 0.00023107521973283552 Test RE 0.011013981812518765\n",
      "165 Train Loss 0.003496583 Test MSE 0.00022562903963626945 Test RE 0.010883414381947086\n",
      "166 Train Loss 0.0034502668 Test MSE 0.0002250644039482529 Test RE 0.010869788003097305\n",
      "167 Train Loss 0.0033967823 Test MSE 0.00023254821954336454 Test RE 0.011049030617636728\n",
      "168 Train Loss 0.003330963 Test MSE 0.00022856627145459668 Test RE 0.010954025297247124\n",
      "169 Train Loss 0.003260819 Test MSE 0.000233087596532112 Test RE 0.01106183686740489\n",
      "170 Train Loss 0.0031994602 Test MSE 0.0002240121508919274 Test RE 0.010844348245278131\n",
      "171 Train Loss 0.0031455643 Test MSE 0.00020253288016355183 Test RE 0.010311347829266168\n",
      "172 Train Loss 0.003043875 Test MSE 0.00021309883733297246 Test RE 0.010576895359237195\n",
      "173 Train Loss 0.0029846665 Test MSE 0.00021021283664772507 Test RE 0.010505029685690188\n",
      "174 Train Loss 0.00294249 Test MSE 0.00020491541894805681 Test RE 0.010371820374850122\n",
      "175 Train Loss 0.0029090187 Test MSE 0.0001875286764228653 Test RE 0.009922052298408422\n",
      "176 Train Loss 0.0028867056 Test MSE 0.00019010020319890745 Test RE 0.009989849791881871\n",
      "177 Train Loss 0.0028404174 Test MSE 0.00017942232174055655 Test RE 0.009705231603178759\n",
      "178 Train Loss 0.002802013 Test MSE 0.00016786849024642394 Test RE 0.009387549930020356\n",
      "179 Train Loss 0.0027688553 Test MSE 0.0001636812232430283 Test RE 0.0092697302997688\n",
      "180 Train Loss 0.0027332422 Test MSE 0.0001641113114761343 Test RE 0.009281900866298414\n",
      "181 Train Loss 0.002678466 Test MSE 0.00015899515279330868 Test RE 0.009136074026347444\n",
      "182 Train Loss 0.002654453 Test MSE 0.00015548778085263412 Test RE 0.009034742938562565\n",
      "183 Train Loss 0.0026352885 Test MSE 0.00015710790846834607 Test RE 0.009081690372603583\n",
      "184 Train Loss 0.0026194528 Test MSE 0.00015789908114430774 Test RE 0.009104528694880385\n",
      "185 Train Loss 0.0025995085 Test MSE 0.00015354154455878122 Test RE 0.008978021068162305\n",
      "186 Train Loss 0.002585406 Test MSE 0.00015391000992457095 Test RE 0.008988787234203377\n",
      "187 Train Loss 0.0025538157 Test MSE 0.0001563480720605284 Test RE 0.009059702419210244\n",
      "188 Train Loss 0.0025298453 Test MSE 0.00015692539874845467 Test RE 0.00907641381321896\n",
      "189 Train Loss 0.0025160837 Test MSE 0.00015705382056171364 Test RE 0.009080126950652145\n",
      "190 Train Loss 0.0025046444 Test MSE 0.00015054110978402377 Test RE 0.008889866195611508\n",
      "191 Train Loss 0.0024699715 Test MSE 0.0001412250265421361 Test RE 0.008610403427878232\n",
      "192 Train Loss 0.0024348337 Test MSE 0.00013239655322614988 Test RE 0.00833692716108439\n",
      "193 Train Loss 0.002412424 Test MSE 0.00012839447434634624 Test RE 0.008209956091870575\n",
      "194 Train Loss 0.0023890643 Test MSE 0.00013036066840559177 Test RE 0.008272579642685407\n",
      "195 Train Loss 0.0023745152 Test MSE 0.00013112125758587613 Test RE 0.008296677722287664\n",
      "196 Train Loss 0.0023553525 Test MSE 0.00013198942163483574 Test RE 0.00832409888214334\n",
      "197 Train Loss 0.0023226351 Test MSE 0.00012998347560470714 Test RE 0.008260602802011406\n",
      "198 Train Loss 0.002297769 Test MSE 0.00012714944222239015 Test RE 0.008170053441560571\n",
      "199 Train Loss 0.0022791235 Test MSE 0.0001236471566383204 Test RE 0.00805674715867458\n",
      "200 Train Loss 0.0022563369 Test MSE 0.00012528278121981608 Test RE 0.008109860066288738\n",
      "201 Train Loss 0.0022347555 Test MSE 0.000125229704729501 Test RE 0.00810814199895181\n",
      "202 Train Loss 0.002223157 Test MSE 0.00012963409241620677 Test RE 0.008249493475443934\n",
      "203 Train Loss 0.002214309 Test MSE 0.00012773716094729922 Test RE 0.008188913758272765\n",
      "204 Train Loss 0.002205436 Test MSE 0.00012845484488719204 Test RE 0.008211886008418396\n",
      "205 Train Loss 0.0021891869 Test MSE 0.00013217649525510439 Test RE 0.008329995824141562\n",
      "206 Train Loss 0.0021814674 Test MSE 0.00012962879519352486 Test RE 0.00824932492468091\n",
      "207 Train Loss 0.002174113 Test MSE 0.00012840709191847194 Test RE 0.008210359486054008\n",
      "208 Train Loss 0.002162877 Test MSE 0.00012883957168747625 Test RE 0.00822417425877107\n",
      "209 Train Loss 0.0021510513 Test MSE 0.00012620259398144412 Test RE 0.008139576484357265\n",
      "210 Train Loss 0.0021398128 Test MSE 0.000128339081475022 Test RE 0.008208184901542325\n",
      "211 Train Loss 0.0021274264 Test MSE 0.00012981853862761234 Test RE 0.008255360168907187\n",
      "212 Train Loss 0.002108281 Test MSE 0.00012958703104326634 Test RE 0.008247995922896536\n",
      "213 Train Loss 0.0020949573 Test MSE 0.00013051876693645896 Test RE 0.008277594523329513\n",
      "214 Train Loss 0.0020791215 Test MSE 0.000131336164629804 Test RE 0.008303474043978066\n",
      "215 Train Loss 0.0020631622 Test MSE 0.00013109577957223155 Test RE 0.008295871624399763\n",
      "216 Train Loss 0.0020354262 Test MSE 0.00013087282090342993 Test RE 0.008288814098966805\n",
      "217 Train Loss 0.0020171865 Test MSE 0.0001351938340281511 Test RE 0.008424538317560456\n",
      "218 Train Loss 0.002009085 Test MSE 0.0001349650366268347 Test RE 0.00841740659926505\n",
      "219 Train Loss 0.0019978832 Test MSE 0.00013390998193256792 Test RE 0.008384441586128012\n",
      "220 Train Loss 0.0019863897 Test MSE 0.00013261710766229026 Test RE 0.008343868358143484\n",
      "221 Train Loss 0.0019723026 Test MSE 0.00012799933897125152 Test RE 0.008197313243182932\n",
      "222 Train Loss 0.0019551401 Test MSE 0.00012069705775770469 Test RE 0.007960053915668687\n",
      "223 Train Loss 0.0019329903 Test MSE 0.00011455518609872868 Test RE 0.007754879345882213\n",
      "224 Train Loss 0.0019168115 Test MSE 0.00011006017552393688 Test RE 0.0076012106504396\n",
      "225 Train Loss 0.00191042 Test MSE 0.00010947888038458542 Test RE 0.007581110752797973\n",
      "226 Train Loss 0.0018923327 Test MSE 0.00010763629758631338 Test RE 0.007517043146254618\n",
      "227 Train Loss 0.0018772002 Test MSE 0.00010505756043334924 Test RE 0.007426451061689355\n",
      "228 Train Loss 0.0018644037 Test MSE 0.00010592289234646707 Test RE 0.007456973216701378\n",
      "229 Train Loss 0.0018528893 Test MSE 0.0001057899040401087 Test RE 0.007452290557061167\n",
      "230 Train Loss 0.0018365085 Test MSE 0.0001040916036121915 Test RE 0.007392230788296514\n",
      "231 Train Loss 0.0018109464 Test MSE 0.00010271441065743988 Test RE 0.007343166185502624\n",
      "232 Train Loss 0.0017956126 Test MSE 9.913294237853684e-05 Test RE 0.007214008771006206\n",
      "233 Train Loss 0.0017835372 Test MSE 9.861587841619931e-05 Test RE 0.007195170529524326\n",
      "234 Train Loss 0.0017655188 Test MSE 0.000101155672778981 Test RE 0.0072872352372744375\n",
      "235 Train Loss 0.0017437676 Test MSE 9.875414206870101e-05 Test RE 0.007200212730229258\n",
      "236 Train Loss 0.0017217463 Test MSE 9.561193380299605e-05 Test RE 0.007084736767230851\n",
      "237 Train Loss 0.0017040984 Test MSE 9.107042854011044e-05 Test RE 0.006914429577338259\n",
      "238 Train Loss 0.0016904906 Test MSE 8.578302753071442e-05 Test RE 0.00671070816256164\n",
      "239 Train Loss 0.0016804717 Test MSE 8.562122452945075e-05 Test RE 0.0067043763435059335\n",
      "240 Train Loss 0.0016684388 Test MSE 8.748845694768419e-05 Test RE 0.006777086769047477\n",
      "241 Train Loss 0.0016551504 Test MSE 9.058578431165714e-05 Test RE 0.006896006975180357\n",
      "242 Train Loss 0.0016383998 Test MSE 9.275747426980192e-05 Test RE 0.006978179311891503\n",
      "243 Train Loss 0.001621643 Test MSE 9.049452387634533e-05 Test RE 0.0068925324168484054\n",
      "244 Train Loss 0.0016079871 Test MSE 8.376763923064862e-05 Test RE 0.006631408868244069\n",
      "245 Train Loss 0.0015948563 Test MSE 8.273569677955029e-05 Test RE 0.006590435773884409\n",
      "246 Train Loss 0.0015824833 Test MSE 8.375623425764371e-05 Test RE 0.006630957419365418\n",
      "247 Train Loss 0.0015715581 Test MSE 8.390002853189522e-05 Test RE 0.006636647054442185\n",
      "248 Train Loss 0.0015589513 Test MSE 8.67279288898403e-05 Test RE 0.006747566218999061\n",
      "249 Train Loss 0.0015486152 Test MSE 8.765394122089464e-05 Test RE 0.006783493165325776\n",
      "250 Train Loss 0.0015380979 Test MSE 9.134489740399503e-05 Test RE 0.0069248411231784\n",
      "251 Train Loss 0.0015289466 Test MSE 9.287150747257863e-05 Test RE 0.006982467374535971\n",
      "252 Train Loss 0.0015226449 Test MSE 9.128607986612666e-05 Test RE 0.006922611290403013\n",
      "253 Train Loss 0.0015161827 Test MSE 9.266170003142956e-05 Test RE 0.006974575815678916\n",
      "254 Train Loss 0.0015094753 Test MSE 9.526903676054293e-05 Test RE 0.007072021213804176\n",
      "255 Train Loss 0.0015009001 Test MSE 9.456176391773574e-05 Test RE 0.007045721133992915\n",
      "256 Train Loss 0.0014896725 Test MSE 9.279767948451142e-05 Test RE 0.006979691474682711\n",
      "257 Train Loss 0.0014846044 Test MSE 9.333894448632072e-05 Test RE 0.007000017251801477\n",
      "258 Train Loss 0.0014786803 Test MSE 9.559008145438192e-05 Test RE 0.007083927103737245\n",
      "259 Train Loss 0.0014694453 Test MSE 9.409691008223574e-05 Test RE 0.0070283818552117315\n",
      "260 Train Loss 0.001462335 Test MSE 9.355184691764069e-05 Test RE 0.007007996085436423\n",
      "261 Train Loss 0.0014526581 Test MSE 8.887460754122858e-05 Test RE 0.006830563225354309\n",
      "262 Train Loss 0.0014456218 Test MSE 8.730777159695256e-05 Test RE 0.006770084970005972\n",
      "263 Train Loss 0.0014371125 Test MSE 8.370004141376077e-05 Test RE 0.00662873266035721\n",
      "264 Train Loss 0.0014272328 Test MSE 8.637640763928974e-05 Test RE 0.006733877887810326\n",
      "265 Train Loss 0.0014200099 Test MSE 8.756148882078173e-05 Test RE 0.00677991479980435\n",
      "266 Train Loss 0.0014074269 Test MSE 8.482008137504869e-05 Test RE 0.006672936775588242\n",
      "267 Train Loss 0.0014028357 Test MSE 8.325999457735842e-05 Test RE 0.006611284659046914\n",
      "268 Train Loss 0.0013972935 Test MSE 8.336913025037644e-05 Test RE 0.006615616215385508\n",
      "269 Train Loss 0.0013910696 Test MSE 8.379692401344805e-05 Test RE 0.006632567922028489\n",
      "270 Train Loss 0.0013817289 Test MSE 8.42649758928172e-05 Test RE 0.006651065397063833\n",
      "271 Train Loss 0.0013741859 Test MSE 8.548503251789304e-05 Test RE 0.006699042117737084\n",
      "272 Train Loss 0.0013641202 Test MSE 8.291251091691421e-05 Test RE 0.006597474212828458\n",
      "273 Train Loss 0.0013529788 Test MSE 8.389414247897497e-05 Test RE 0.006636414251536059\n",
      "274 Train Loss 0.0013439081 Test MSE 8.390111234180365e-05 Test RE 0.006636689919985459\n",
      "275 Train Loss 0.0013312696 Test MSE 8.1657195142729e-05 Test RE 0.006547340038368995\n",
      "276 Train Loss 0.0013201581 Test MSE 8.35598278234124e-05 Test RE 0.006623178135154808\n",
      "277 Train Loss 0.0013082542 Test MSE 8.402592490821274e-05 Test RE 0.006641624505734978\n",
      "278 Train Loss 0.0012992211 Test MSE 8.278161869921491e-05 Test RE 0.006592264509788229\n",
      "279 Train Loss 0.0012876634 Test MSE 7.987415121561601e-05 Test RE 0.006475462545395496\n",
      "280 Train Loss 0.0012802857 Test MSE 8.120815361807417e-05 Test RE 0.006529312964452306\n",
      "281 Train Loss 0.0012648844 Test MSE 7.836050385927925e-05 Test RE 0.006413812763869974\n",
      "282 Train Loss 0.0012483846 Test MSE 7.920565698350289e-05 Test RE 0.00644830792327655\n",
      "283 Train Loss 0.0012399671 Test MSE 8.154884441343859e-05 Test RE 0.006542994771847354\n",
      "284 Train Loss 0.0012319381 Test MSE 8.070852343188959e-05 Test RE 0.006509196295696842\n",
      "285 Train Loss 0.0012241837 Test MSE 8.30709401088002e-05 Test RE 0.006603774430162859\n",
      "286 Train Loss 0.0012111897 Test MSE 8.29587688376827e-05 Test RE 0.006599314362651552\n",
      "287 Train Loss 0.0012008712 Test MSE 8.677984943329773e-05 Test RE 0.006749585665860318\n",
      "288 Train Loss 0.0011903651 Test MSE 8.496120277575028e-05 Test RE 0.006678485596123189\n",
      "289 Train Loss 0.0011782467 Test MSE 8.305106301759543e-05 Test RE 0.006602984312225314\n",
      "290 Train Loss 0.0011636219 Test MSE 8.490336478235167e-05 Test RE 0.006676211993851271\n",
      "291 Train Loss 0.0011552004 Test MSE 8.489779326546664e-05 Test RE 0.006675992937526501\n",
      "292 Train Loss 0.0011434016 Test MSE 8.597156888060131e-05 Test RE 0.006718078801942706\n",
      "293 Train Loss 0.0011316793 Test MSE 8.376854699133097e-05 Test RE 0.00663144479927893\n",
      "294 Train Loss 0.0011261103 Test MSE 8.230799637041991e-05 Test RE 0.006573379143694672\n",
      "295 Train Loss 0.0011226765 Test MSE 8.116071299830493e-05 Test RE 0.006527405521100527\n",
      "296 Train Loss 0.0011171509 Test MSE 8.189525983197705e-05 Test RE 0.006556877202021118\n",
      "297 Train Loss 0.001112269 Test MSE 8.165750865096969e-05 Test RE 0.0065473526070292535\n",
      "298 Train Loss 0.0011086034 Test MSE 8.094930923155128e-05 Test RE 0.006518898832195194\n",
      "299 Train Loss 0.0010985471 Test MSE 8.224147238439912e-05 Test RE 0.006570722197864806\n",
      "Training time: 165.90\n",
      "KG_tanh_medium\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 33434.094 Test MSE 8.866053143723278 Test RE 2.157410721755109\n",
      "1 Train Loss 10267.534 Test MSE 10.04673463087964 Test RE 2.2965723578751382\n",
      "2 Train Loss 4858.308 Test MSE 13.683985387574811 Test RE 2.6802417539008903\n",
      "3 Train Loss 1726.7106 Test MSE 17.662988668917517 Test RE 3.045087403921281\n",
      "4 Train Loss 1122.9562 Test MSE 23.29900768213756 Test RE 3.4973281209860976\n",
      "5 Train Loss 740.8868 Test MSE 27.01726331781472 Test RE 3.7660696308925345\n",
      "6 Train Loss 563.6934 Test MSE 27.509070330344873 Test RE 3.800192744727095\n",
      "7 Train Loss 388.37366 Test MSE 28.30556529619689 Test RE 3.854815388202741\n",
      "8 Train Loss 269.1809 Test MSE 29.337438306959847 Test RE 3.9244496570973046\n",
      "9 Train Loss 198.95528 Test MSE 29.683934065671924 Test RE 3.94755688310087\n",
      "10 Train Loss 154.2264 Test MSE 30.05870023661725 Test RE 3.9723981078034605\n",
      "11 Train Loss 120.235146 Test MSE 29.6782192485244 Test RE 3.947176868584844\n",
      "12 Train Loss 107.46889 Test MSE 29.281575079582257 Test RE 3.9207114832968157\n",
      "13 Train Loss 96.21544 Test MSE 28.971849048204266 Test RE 3.89992068413482\n",
      "14 Train Loss 82.52577 Test MSE 29.07261212099743 Test RE 3.906696691109807\n",
      "15 Train Loss 73.63846 Test MSE 29.157315993359205 Test RE 3.91238368711126\n",
      "16 Train Loss 66.91443 Test MSE 28.923042408981598 Test RE 3.8966343517240887\n",
      "17 Train Loss 62.01448 Test MSE 28.487639682494063 Test RE 3.8671934855459926\n",
      "18 Train Loss 56.543533 Test MSE 28.15745092284922 Test RE 3.844716624468895\n",
      "19 Train Loss 52.10964 Test MSE 27.29914002721203 Test RE 3.7856647461560327\n",
      "20 Train Loss 48.53016 Test MSE 26.9226988052912 Test RE 3.7594729465038896\n",
      "21 Train Loss 45.59317 Test MSE 26.16089836353025 Test RE 3.705902545316344\n",
      "22 Train Loss 42.776966 Test MSE 24.70169761663972 Test RE 3.601065892344836\n",
      "23 Train Loss 40.16397 Test MSE 23.3836440497539 Test RE 3.5036745891493117\n",
      "24 Train Loss 37.05272 Test MSE 21.367558267432802 Test RE 3.349231106303283\n",
      "25 Train Loss 34.178097 Test MSE 20.526741666531258 Test RE 3.282673399703479\n",
      "26 Train Loss 32.41466 Test MSE 19.91609314752796 Test RE 3.2334767463363856\n",
      "27 Train Loss 30.438293 Test MSE 19.56312530928261 Test RE 3.204695614350021\n",
      "28 Train Loss 28.23406 Test MSE 18.784677615654676 Test RE 3.1402884414677743\n",
      "29 Train Loss 26.119154 Test MSE 18.160752021451604 Test RE 3.0876963315379915\n",
      "30 Train Loss 24.13521 Test MSE 17.565866712003764 Test RE 3.0367039836105483\n",
      "31 Train Loss 22.837765 Test MSE 17.38337780010148 Test RE 3.02088889114097\n",
      "32 Train Loss 21.717752 Test MSE 17.09986816869343 Test RE 2.996153425697138\n",
      "33 Train Loss 20.92673 Test MSE 16.82009142377024 Test RE 2.971541799346811\n",
      "34 Train Loss 20.447447 Test MSE 16.658521139269855 Test RE 2.95723535538077\n",
      "35 Train Loss 20.054577 Test MSE 16.599237302542285 Test RE 2.95196860594345\n",
      "36 Train Loss 19.761108 Test MSE 16.518240430345845 Test RE 2.944757653748913\n",
      "37 Train Loss 19.406298 Test MSE 16.361080927085077 Test RE 2.9307155190358913\n",
      "38 Train Loss 19.066494 Test MSE 16.25977459486262 Test RE 2.9216280674089408\n",
      "39 Train Loss 18.709995 Test MSE 16.102283115187717 Test RE 2.907444255781649\n",
      "40 Train Loss 18.388264 Test MSE 16.01720071385245 Test RE 2.8997528006517816\n",
      "41 Train Loss 18.25872 Test MSE 15.989364108500391 Test RE 2.8972319364514325\n",
      "42 Train Loss 18.075932 Test MSE 15.883533544018922 Test RE 2.8876279042656456\n",
      "43 Train Loss 17.893286 Test MSE 15.882911652999613 Test RE 2.8875713737891666\n",
      "44 Train Loss 17.713314 Test MSE 15.821809248565188 Test RE 2.8820117013523734\n",
      "45 Train Loss 17.477802 Test MSE 15.598362940698516 Test RE 2.861588476539054\n",
      "46 Train Loss 17.327559 Test MSE 15.467602947285098 Test RE 2.8495689851374286\n",
      "47 Train Loss 16.97789 Test MSE 15.109031495024494 Test RE 2.8163458199571325\n",
      "48 Train Loss 16.770866 Test MSE 14.826865179346159 Test RE 2.7899237690527863\n",
      "49 Train Loss 16.532276 Test MSE 14.677817433043044 Test RE 2.775865430583723\n",
      "50 Train Loss 16.218643 Test MSE 14.286812776716797 Test RE 2.7386425054764847\n",
      "51 Train Loss 15.904831 Test MSE 14.112140866274432 Test RE 2.721849569801391\n",
      "52 Train Loss 15.654321 Test MSE 13.86156379543303 Test RE 2.6975765750875276\n",
      "53 Train Loss 15.428993 Test MSE 13.569481395492922 Test RE 2.669004417579731\n",
      "54 Train Loss 15.183156 Test MSE 13.263735468836439 Test RE 2.6387642615454583\n",
      "55 Train Loss 14.767485 Test MSE 12.758734450031705 Test RE 2.5880428753486333\n",
      "56 Train Loss 14.483565 Test MSE 12.692869655348279 Test RE 2.5813540663282195\n",
      "57 Train Loss 13.901738 Test MSE 11.740207883545194 Test RE 2.482593198095891\n",
      "58 Train Loss 13.157235 Test MSE 11.115912274563719 Test RE 2.4156845572985968\n",
      "59 Train Loss 12.223443 Test MSE 9.845139320754857 Test RE 2.2734143700623504\n",
      "60 Train Loss 10.895226 Test MSE 8.77136522112091 Test RE 2.145859409745125\n",
      "61 Train Loss 10.153598 Test MSE 8.561483991320776 Test RE 2.120030905831736\n",
      "62 Train Loss 9.526046 Test MSE 7.729139038319489 Test RE 2.014342090378329\n",
      "63 Train Loss 8.815652 Test MSE 7.323709466152 Test RE 1.9607996527646847\n",
      "64 Train Loss 7.9263363 Test MSE 6.76658121311923 Test RE 1.884743772304212\n",
      "65 Train Loss 7.1715684 Test MSE 6.253645590830173 Test RE 1.8119003137409448\n",
      "66 Train Loss 6.5266547 Test MSE 5.883420841784368 Test RE 1.7574485711646568\n",
      "67 Train Loss 5.8032036 Test MSE 5.163119085519062 Test RE 1.6463559541335124\n",
      "68 Train Loss 5.335512 Test MSE 4.721807638069375 Test RE 1.5744244040326498\n",
      "69 Train Loss 4.954592 Test MSE 4.054491786165314 Test RE 1.4589347881427432\n",
      "70 Train Loss 4.6688323 Test MSE 3.6309480261641234 Test RE 1.3806312011102555\n",
      "71 Train Loss 4.3048716 Test MSE 3.05678634028267 Test RE 1.2667771168222097\n",
      "72 Train Loss 3.7753935 Test MSE 2.2757748622639817 Test RE 1.0930305879352962\n",
      "73 Train Loss 3.35647 Test MSE 1.8089715295227664 Test RE 0.9745037923316832\n",
      "74 Train Loss 2.829891 Test MSE 1.557390731518058 Test RE 0.9042040762030664\n",
      "75 Train Loss 2.4171906 Test MSE 1.289930338927757 Test RE 0.8229070752528536\n",
      "76 Train Loss 1.9899113 Test MSE 0.8586402185945096 Test RE 0.6713875461981075\n",
      "77 Train Loss 1.5804865 Test MSE 0.6398684925205601 Test RE 0.5795795195851081\n",
      "78 Train Loss 1.1945312 Test MSE 0.3109494325196085 Test RE 0.404029012406767\n",
      "79 Train Loss 0.9137825 Test MSE 0.19044589395207762 Test RE 0.3161938906652092\n",
      "80 Train Loss 0.8159662 Test MSE 0.14219987607889542 Test RE 0.2732230132201266\n",
      "81 Train Loss 0.71990395 Test MSE 0.12532599328104221 Test RE 0.2565005172995485\n",
      "82 Train Loss 0.63054615 Test MSE 0.11818217280462355 Test RE 0.24908275051536696\n",
      "83 Train Loss 0.48236337 Test MSE 0.11636410558127566 Test RE 0.24715943030219387\n",
      "84 Train Loss 0.38023692 Test MSE 0.10960316378725413 Test RE 0.23987181041485414\n",
      "85 Train Loss 0.3267615 Test MSE 0.10355176137532872 Test RE 0.23315590169252415\n",
      "86 Train Loss 0.29542837 Test MSE 0.072511845047271 Test RE 0.19510668299204206\n",
      "87 Train Loss 0.2706308 Test MSE 0.06753146941088238 Test RE 0.18828718712799766\n",
      "88 Train Loss 0.24977052 Test MSE 0.06358165846920262 Test RE 0.18269791605525842\n",
      "89 Train Loss 0.233241 Test MSE 0.05941620272282041 Test RE 0.176611961516627\n",
      "90 Train Loss 0.22209607 Test MSE 0.06179665572889937 Test RE 0.18011511266285415\n",
      "91 Train Loss 0.20337881 Test MSE 0.0484062419096946 Test RE 0.15941102382796332\n",
      "92 Train Loss 0.19121194 Test MSE 0.04635534285991833 Test RE 0.15599747413947732\n",
      "93 Train Loss 0.17450696 Test MSE 0.047552058725669206 Test RE 0.15799826927755795\n",
      "94 Train Loss 0.15880904 Test MSE 0.03751897491353642 Test RE 0.14034377358501324\n",
      "95 Train Loss 0.14456922 Test MSE 0.0399790945413943 Test RE 0.14487189620875032\n",
      "96 Train Loss 0.13073888 Test MSE 0.030644499905153593 Test RE 0.12683640873329416\n",
      "97 Train Loss 0.11882695 Test MSE 0.02680279448153257 Test RE 0.11861994157617738\n",
      "98 Train Loss 0.1124076 Test MSE 0.026679609852887348 Test RE 0.11834704127502466\n",
      "99 Train Loss 0.1067878 Test MSE 0.025633437181782417 Test RE 0.11600349924555532\n",
      "100 Train Loss 0.10141037 Test MSE 0.02307924440910057 Test RE 0.11007240632758712\n",
      "101 Train Loss 0.09858183 Test MSE 0.020793971094657773 Test RE 0.10448077505641953\n",
      "102 Train Loss 0.092702754 Test MSE 0.021626934994862387 Test RE 0.10655287077479887\n",
      "103 Train Loss 0.0884064 Test MSE 0.025380115720189226 Test RE 0.11542887597744177\n",
      "104 Train Loss 0.08377233 Test MSE 0.022572395369714792 Test RE 0.10885703272695242\n",
      "105 Train Loss 0.08186455 Test MSE 0.02255094062039163 Test RE 0.10880528687676577\n",
      "106 Train Loss 0.07332584 Test MSE 0.019231275760657338 Test RE 0.10047816968056328\n",
      "107 Train Loss 0.069511764 Test MSE 0.018364685879558158 Test RE 0.09818822741387338\n",
      "108 Train Loss 0.06758307 Test MSE 0.018423928496549693 Test RE 0.09834647253536692\n",
      "109 Train Loss 0.0660281 Test MSE 0.01867072826304222 Test RE 0.09900298675784612\n",
      "110 Train Loss 0.063276045 Test MSE 0.018886335652253103 Test RE 0.09957298338138508\n",
      "111 Train Loss 0.060895532 Test MSE 0.01776633215613955 Test RE 0.09657540905488304\n",
      "112 Train Loss 0.059357062 Test MSE 0.016514776088010812 Test RE 0.09311164782109736\n",
      "113 Train Loss 0.058115445 Test MSE 0.015200238363733687 Test RE 0.08932908116120775\n",
      "114 Train Loss 0.05748794 Test MSE 0.014537722954871905 Test RE 0.08736065102011367\n",
      "115 Train Loss 0.056872465 Test MSE 0.013654571371616814 Test RE 0.08466554407310295\n",
      "116 Train Loss 0.055518553 Test MSE 0.013026693800937508 Test RE 0.08269605081394797\n",
      "117 Train Loss 0.054142665 Test MSE 0.014247182113948183 Test RE 0.08648328059848863\n",
      "118 Train Loss 0.05339065 Test MSE 0.014503650530188456 Test RE 0.08725821629443922\n",
      "119 Train Loss 0.05274424 Test MSE 0.013984433559847593 Test RE 0.0856821010762799\n",
      "120 Train Loss 0.05110687 Test MSE 0.013387283422487035 Test RE 0.08383278549645139\n",
      "121 Train Loss 0.048847683 Test MSE 0.011563164163094114 Test RE 0.07791229789655728\n",
      "122 Train Loss 0.046570223 Test MSE 0.010569760903004974 Test RE 0.07449039021287623\n",
      "123 Train Loss 0.045703705 Test MSE 0.010941472402388894 Test RE 0.07578889101685006\n",
      "124 Train Loss 0.045160282 Test MSE 0.01035265343970216 Test RE 0.07372138838990322\n",
      "125 Train Loss 0.044184558 Test MSE 0.009454187939484047 Test RE 0.07044980305124568\n",
      "126 Train Loss 0.04345052 Test MSE 0.008652223661551271 Test RE 0.06739559881425708\n",
      "127 Train Loss 0.042435512 Test MSE 0.008837087078835426 Test RE 0.06811178075427154\n",
      "128 Train Loss 0.04088676 Test MSE 0.009357549444822718 Test RE 0.07008881751171513\n",
      "129 Train Loss 0.03974063 Test MSE 0.009511198502868988 Test RE 0.07066189669090965\n",
      "130 Train Loss 0.038899437 Test MSE 0.00971581365762244 Test RE 0.07141792962444656\n",
      "131 Train Loss 0.03823355 Test MSE 0.009787453730014394 Test RE 0.07168074800254651\n",
      "132 Train Loss 0.037028503 Test MSE 0.01013376687553262 Test RE 0.07293787768913071\n",
      "133 Train Loss 0.036144122 Test MSE 0.009599494714170138 Test RE 0.07098913013035384\n",
      "134 Train Loss 0.03519306 Test MSE 0.010137639034535397 Test RE 0.07295181130775392\n",
      "135 Train Loss 0.034824982 Test MSE 0.01006532702782747 Test RE 0.07269116221847172\n",
      "136 Train Loss 0.033716694 Test MSE 0.009159364677223534 Test RE 0.06934263536419609\n",
      "137 Train Loss 0.03289346 Test MSE 0.007927410898125493 Test RE 0.06451093735866513\n",
      "138 Train Loss 0.032161616 Test MSE 0.007942863272271264 Test RE 0.06457378018681503\n",
      "139 Train Loss 0.03171581 Test MSE 0.007650679938273794 Test RE 0.06337495800991536\n",
      "140 Train Loss 0.031359613 Test MSE 0.00742866645006733 Test RE 0.062448656141632405\n",
      "141 Train Loss 0.031018412 Test MSE 0.00699122606974725 Test RE 0.060582102375902246\n",
      "142 Train Loss 0.030489443 Test MSE 0.006609277244539801 Test RE 0.058903981710389\n",
      "143 Train Loss 0.029647939 Test MSE 0.006642845836044637 Test RE 0.059053379236820004\n",
      "144 Train Loss 0.028799385 Test MSE 0.006409674722186763 Test RE 0.05800770224918711\n",
      "145 Train Loss 0.028230809 Test MSE 0.006090728910067071 Test RE 0.056546053883138346\n",
      "146 Train Loss 0.027711794 Test MSE 0.005772784969702922 Test RE 0.055050384675526365\n",
      "147 Train Loss 0.027202193 Test MSE 0.006199343089869833 Test RE 0.057048010545931185\n",
      "148 Train Loss 0.027027834 Test MSE 0.00605359687732741 Test RE 0.056373424309696\n",
      "149 Train Loss 0.026849726 Test MSE 0.006215722141414842 Test RE 0.05712332303670663\n",
      "150 Train Loss 0.026329637 Test MSE 0.005878466223933769 Test RE 0.055551997709068615\n",
      "151 Train Loss 0.025590736 Test MSE 0.005424187755830724 Test RE 0.053362359539514334\n",
      "152 Train Loss 0.024916746 Test MSE 0.004841034382204936 Test RE 0.05041232776119363\n",
      "153 Train Loss 0.024644757 Test MSE 0.00457576911587038 Test RE 0.04901169463572308\n",
      "154 Train Loss 0.024427844 Test MSE 0.004659963255023457 Test RE 0.04946054685044831\n",
      "155 Train Loss 0.024124581 Test MSE 0.004862594821377171 Test RE 0.05052446334392954\n",
      "156 Train Loss 0.023892717 Test MSE 0.004848068664606449 Test RE 0.05044894037298498\n",
      "157 Train Loss 0.023631804 Test MSE 0.004754292368538822 Test RE 0.04995864035702706\n",
      "158 Train Loss 0.023196628 Test MSE 0.004864023043609376 Test RE 0.05053188272253263\n",
      "159 Train Loss 0.02291332 Test MSE 0.004886248638739031 Test RE 0.05064720095898486\n",
      "160 Train Loss 0.022585807 Test MSE 0.004395618871325769 Test RE 0.048037199670798524\n",
      "161 Train Loss 0.02224908 Test MSE 0.004472774891464221 Test RE 0.0484569626300131\n",
      "162 Train Loss 0.022094093 Test MSE 0.004510959435316977 Test RE 0.04866336411018028\n",
      "163 Train Loss 0.021933297 Test MSE 0.004410316165626298 Test RE 0.04811744180535784\n",
      "164 Train Loss 0.02144959 Test MSE 0.004125211301846824 Test RE 0.04653618390901641\n",
      "165 Train Loss 0.021270059 Test MSE 0.003986357475946346 Test RE 0.04574628047457556\n",
      "166 Train Loss 0.020927984 Test MSE 0.003829970080862346 Test RE 0.04483997464189605\n",
      "167 Train Loss 0.020608021 Test MSE 0.003821311934433163 Test RE 0.044789262662662165\n",
      "168 Train Loss 0.020291466 Test MSE 0.0036421959419980997 Test RE 0.04372696357401966\n",
      "169 Train Loss 0.019998973 Test MSE 0.0036733684961063 Test RE 0.04391368842560563\n",
      "170 Train Loss 0.019647643 Test MSE 0.003927852270316937 Test RE 0.04540934528692638\n",
      "171 Train Loss 0.019372195 Test MSE 0.00383552400977603 Test RE 0.044872474610281515\n",
      "172 Train Loss 0.019227846 Test MSE 0.003787199924677323 Test RE 0.044588902577635856\n",
      "173 Train Loss 0.019024082 Test MSE 0.003505219125292115 Test RE 0.042896835352884535\n",
      "174 Train Loss 0.018889584 Test MSE 0.003320504920365212 Test RE 0.04175127396225426\n",
      "175 Train Loss 0.018666081 Test MSE 0.00324769630300294 Test RE 0.04129099735845728\n",
      "176 Train Loss 0.018583963 Test MSE 0.00314139379361686 Test RE 0.04060961370604819\n",
      "177 Train Loss 0.018466406 Test MSE 0.0030831100831701327 Test RE 0.040231125587493914\n",
      "178 Train Loss 0.018131342 Test MSE 0.003058842237786192 Test RE 0.04007247871454633\n",
      "179 Train Loss 0.017661953 Test MSE 0.0029406164301738185 Test RE 0.03929043683536286\n",
      "180 Train Loss 0.017053291 Test MSE 0.002823214742225836 Test RE 0.03849812907202006\n",
      "181 Train Loss 0.016425105 Test MSE 0.002490917228383868 Test RE 0.036161573182149485\n",
      "182 Train Loss 0.016046535 Test MSE 0.0023210469384416 Test RE 0.03490676717310831\n",
      "183 Train Loss 0.015804222 Test MSE 0.0022267458035145856 Test RE 0.03419030609468809\n",
      "184 Train Loss 0.015572708 Test MSE 0.0020928260489653464 Test RE 0.033146237189108876\n",
      "185 Train Loss 0.015240072 Test MSE 0.0019482221932605624 Test RE 0.031980622339019917\n",
      "186 Train Loss 0.014995072 Test MSE 0.0019407114489400769 Test RE 0.03191891730671976\n",
      "187 Train Loss 0.014765639 Test MSE 0.0018311405512881254 Test RE 0.031004769558693614\n",
      "188 Train Loss 0.014436964 Test MSE 0.0018339299615759033 Test RE 0.031028375641831123\n",
      "189 Train Loss 0.013865312 Test MSE 0.0020211056274113677 Test RE 0.032573331061658384\n",
      "190 Train Loss 0.0135928765 Test MSE 0.001994936464040758 Test RE 0.032361765154079035\n",
      "191 Train Loss 0.013252247 Test MSE 0.0019557496364709594 Test RE 0.03204234533835199\n",
      "192 Train Loss 0.01290359 Test MSE 0.001600796797885167 Test RE 0.028989169333588204\n",
      "193 Train Loss 0.012365707 Test MSE 0.0014597946189467326 Test RE 0.027683025123637846\n",
      "194 Train Loss 0.012013007 Test MSE 0.0011983744887744472 Test RE 0.025082102899050027\n",
      "195 Train Loss 0.011721452 Test MSE 0.00118794034937287 Test RE 0.02497267036108324\n",
      "196 Train Loss 0.011527591 Test MSE 0.0012211611890680877 Test RE 0.025319443976687308\n",
      "197 Train Loss 0.01135527 Test MSE 0.0010857478293803831 Test RE 0.02387438277345957\n",
      "198 Train Loss 0.011205631 Test MSE 0.0011513850400266458 Test RE 0.024585438509035943\n",
      "199 Train Loss 0.011113161 Test MSE 0.001121369614520379 Test RE 0.02426286376201978\n",
      "200 Train Loss 0.01104617 Test MSE 0.0011304338309557804 Test RE 0.024360726773710577\n",
      "201 Train Loss 0.0109087685 Test MSE 0.0011826161802809627 Test RE 0.02491664565001472\n",
      "202 Train Loss 0.010729167 Test MSE 0.0011412174534762968 Test RE 0.024476643935196253\n",
      "203 Train Loss 0.010588688 Test MSE 0.0010269402717806928 Test RE 0.023218826174424636\n",
      "204 Train Loss 0.010472141 Test MSE 0.0010557946125353847 Test RE 0.023542760709211415\n",
      "205 Train Loss 0.0103459135 Test MSE 0.0010046588598394029 Test RE 0.022965556671093904\n",
      "206 Train Loss 0.010206667 Test MSE 0.0009845326845230942 Test RE 0.022734360212952432\n",
      "207 Train Loss 0.010097407 Test MSE 0.0009528845431200173 Test RE 0.022365973643108675\n",
      "208 Train Loss 0.009981887 Test MSE 0.0009219242328450173 Test RE 0.021999625249757015\n",
      "209 Train Loss 0.009853817 Test MSE 0.0009835309975044588 Test RE 0.022722792029801042\n",
      "210 Train Loss 0.009716716 Test MSE 0.0009284797019042895 Test RE 0.022077702381652294\n",
      "211 Train Loss 0.009598905 Test MSE 0.0008819692622429207 Test RE 0.021517627870836758\n",
      "212 Train Loss 0.009500111 Test MSE 0.0008377912204178185 Test RE 0.020971793371330212\n",
      "213 Train Loss 0.009382071 Test MSE 0.0008215847562175315 Test RE 0.020767960734219347\n",
      "214 Train Loss 0.009220101 Test MSE 0.0007973085023539046 Test RE 0.020458833376830743\n",
      "215 Train Loss 0.008997853 Test MSE 0.0006754219574018776 Test RE 0.018830213978784902\n",
      "216 Train Loss 0.008832618 Test MSE 0.0007312873282680585 Test RE 0.019593485131335735\n",
      "217 Train Loss 0.00871742 Test MSE 0.0007467781781911319 Test RE 0.019799921893322733\n",
      "218 Train Loss 0.008623107 Test MSE 0.0006720982054902611 Test RE 0.018783825090567256\n",
      "219 Train Loss 0.008479872 Test MSE 0.0005706664250907569 Test RE 0.017308475933154897\n",
      "220 Train Loss 0.008401044 Test MSE 0.00059926371386098 Test RE 0.017736856744570668\n",
      "221 Train Loss 0.008347833 Test MSE 0.0005847893620445289 Test RE 0.017521343322998064\n",
      "222 Train Loss 0.008290752 Test MSE 0.0005278449163248781 Test RE 0.01664641966620817\n",
      "223 Train Loss 0.008242609 Test MSE 0.0005581327654685275 Test RE 0.01711734590897236\n",
      "224 Train Loss 0.008188183 Test MSE 0.0005608357690381902 Test RE 0.017158744986937934\n",
      "225 Train Loss 0.008094621 Test MSE 0.0005323751113177359 Test RE 0.016717700464490774\n",
      "226 Train Loss 0.0080446815 Test MSE 0.0005099436454126811 Test RE 0.0163617125977718\n",
      "227 Train Loss 0.007971263 Test MSE 0.0005501934638178551 Test RE 0.016995164830855437\n",
      "228 Train Loss 0.007935216 Test MSE 0.0005610678135356869 Test RE 0.017162294315297047\n",
      "229 Train Loss 0.007875265 Test MSE 0.0005784476184072548 Test RE 0.01742607931158169\n",
      "230 Train Loss 0.007813036 Test MSE 0.0005510597143206717 Test RE 0.017008538562847116\n",
      "231 Train Loss 0.0077251424 Test MSE 0.0005379623515633137 Test RE 0.01680519705534633\n",
      "232 Train Loss 0.007638008 Test MSE 0.000525631194284295 Test RE 0.01661147638745191\n",
      "233 Train Loss 0.0075739394 Test MSE 0.0005179573212318595 Test RE 0.01648977218627226\n",
      "234 Train Loss 0.0075342045 Test MSE 0.0004915606203601931 Test RE 0.01606409299011191\n",
      "235 Train Loss 0.0073917424 Test MSE 0.0005017074934490714 Test RE 0.01622904488807134\n",
      "236 Train Loss 0.0072585503 Test MSE 0.0005044026212728843 Test RE 0.016272576993211746\n",
      "237 Train Loss 0.0071613993 Test MSE 0.00045972979927593214 Test RE 0.01553527678437423\n",
      "238 Train Loss 0.0071158567 Test MSE 0.0004487156388530203 Test RE 0.015348052308380513\n",
      "239 Train Loss 0.007008549 Test MSE 0.00042828881359468547 Test RE 0.014994639649923789\n",
      "240 Train Loss 0.0069313045 Test MSE 0.00042654612354418327 Test RE 0.014964102259938472\n",
      "241 Train Loss 0.0068051037 Test MSE 0.0003969658451274396 Test RE 0.014435912417060031\n",
      "242 Train Loss 0.0067426604 Test MSE 0.0004258854378090806 Test RE 0.014952508671696537\n",
      "243 Train Loss 0.0066860337 Test MSE 0.0003970883725483527 Test RE 0.014438140138500987\n",
      "244 Train Loss 0.006639526 Test MSE 0.00037101154766266145 Test RE 0.013956013511157023\n",
      "245 Train Loss 0.0065749655 Test MSE 0.0003981717177140438 Test RE 0.014457821948100729\n",
      "246 Train Loss 0.0065086028 Test MSE 0.0003504694170324263 Test RE 0.013564154589004054\n",
      "247 Train Loss 0.006442109 Test MSE 0.0003565103423247665 Test RE 0.0136805555613732\n",
      "248 Train Loss 0.00640016 Test MSE 0.0003122899868742282 Test RE 0.01280403042258125\n",
      "249 Train Loss 0.006367128 Test MSE 0.00031689343691915277 Test RE 0.01289805694510609\n",
      "250 Train Loss 0.006318687 Test MSE 0.0002883858532340291 Test RE 0.012304235753634252\n",
      "251 Train Loss 0.006204628 Test MSE 0.00025043634608798616 Test RE 0.011466116419641363\n",
      "252 Train Loss 0.0059993938 Test MSE 0.0002485513653085691 Test RE 0.011422883412411192\n",
      "253 Train Loss 0.0057853004 Test MSE 0.0002529879919203545 Test RE 0.011524381366536163\n",
      "254 Train Loss 0.005629789 Test MSE 0.0002583979727328144 Test RE 0.011646950204381468\n",
      "255 Train Loss 0.0054514473 Test MSE 0.00025609325986713843 Test RE 0.011594892909544924\n",
      "256 Train Loss 0.0053536007 Test MSE 0.0002747078889924224 Test RE 0.012008900139015191\n",
      "257 Train Loss 0.005312105 Test MSE 0.0002528520163039335 Test RE 0.011521283896441244\n",
      "258 Train Loss 0.0052838055 Test MSE 0.00022890569856102015 Test RE 0.010962155792055953\n",
      "259 Train Loss 0.0052622505 Test MSE 0.000232286395675762 Test RE 0.011042808865721761\n",
      "260 Train Loss 0.005242429 Test MSE 0.0002307294454854921 Test RE 0.011005738226254171\n",
      "261 Train Loss 0.0052159918 Test MSE 0.00022917122433624995 Test RE 0.010968511883941448\n",
      "262 Train Loss 0.0051858076 Test MSE 0.00020546577784326175 Test RE 0.010385739278571808\n",
      "263 Train Loss 0.005158898 Test MSE 0.00019955254881251668 Test RE 0.010235199384800248\n",
      "264 Train Loss 0.0051030875 Test MSE 0.00017987093478549396 Test RE 0.009717357116117908\n",
      "265 Train Loss 0.005057792 Test MSE 0.00016902009293525084 Test RE 0.009419694885431316\n",
      "266 Train Loss 0.005006116 Test MSE 0.0001526657075588458 Test RE 0.008952378077986791\n",
      "267 Train Loss 0.0049764016 Test MSE 0.00014491119992915037 Test RE 0.008722051445542278\n",
      "268 Train Loss 0.004937347 Test MSE 0.00012702013099107548 Test RE 0.008165897904583327\n",
      "269 Train Loss 0.004899719 Test MSE 0.0001183802828749852 Test RE 0.00788328729981051\n",
      "270 Train Loss 0.0048440974 Test MSE 0.00011647123320895329 Test RE 0.007819464360683755\n",
      "271 Train Loss 0.00478426 Test MSE 0.0001108044546386224 Test RE 0.0076268688413662624\n",
      "272 Train Loss 0.0047138236 Test MSE 0.0001091755519499533 Test RE 0.007570601139038348\n",
      "273 Train Loss 0.004658632 Test MSE 9.703829294480818e-05 Test RE 0.007137386936700742\n",
      "274 Train Loss 0.00460675 Test MSE 9.29140770902562e-05 Test RE 0.0069840674719221525\n",
      "275 Train Loss 0.004548919 Test MSE 0.00010024263787583395 Test RE 0.00725427326014008\n",
      "276 Train Loss 0.004510988 Test MSE 0.00010150777993159811 Test RE 0.007299907085492259\n",
      "277 Train Loss 0.004471008 Test MSE 0.00011003747004185311 Test RE 0.007600426542774648\n",
      "278 Train Loss 0.0044452106 Test MSE 0.00011967164450065167 Test RE 0.007926168436888262\n",
      "279 Train Loss 0.004415959 Test MSE 0.00012798359735537287 Test RE 0.008196809166658162\n",
      "280 Train Loss 0.0043984875 Test MSE 0.0001279034552570014 Test RE 0.008194242383218898\n",
      "281 Train Loss 0.00435994 Test MSE 0.00012559539734344666 Test RE 0.008119971964372478\n",
      "282 Train Loss 0.0043233214 Test MSE 0.00012736878320083913 Test RE 0.008177097339314668\n",
      "283 Train Loss 0.004295083 Test MSE 0.00013933579830185461 Test RE 0.008552616973868027\n",
      "284 Train Loss 0.004264324 Test MSE 0.0001367727737053225 Test RE 0.00847359094171959\n",
      "285 Train Loss 0.004231358 Test MSE 0.00012395863454798766 Test RE 0.008066888598268117\n",
      "286 Train Loss 0.00419759 Test MSE 0.00011682564895170184 Test RE 0.007831352430096672\n",
      "287 Train Loss 0.0041528163 Test MSE 0.00011492999122182769 Test RE 0.0077675553103602754\n",
      "288 Train Loss 0.0041270093 Test MSE 0.0001227725696021305 Test RE 0.008028202907526321\n",
      "289 Train Loss 0.0041022063 Test MSE 0.0001231044478574609 Test RE 0.008039046485304133\n",
      "290 Train Loss 0.0040908093 Test MSE 0.0001265600750846212 Test RE 0.008151096402723438\n",
      "291 Train Loss 0.004080003 Test MSE 0.00012417233506606574 Test RE 0.008073839126293446\n",
      "292 Train Loss 0.0040785866 Test MSE 0.00012176412016765479 Test RE 0.007995163237191715\n",
      "293 Train Loss 0.0040785866 Test MSE 0.00012176412016765479 Test RE 0.007995163237191715\n",
      "294 Train Loss 0.0040785866 Test MSE 0.00012176412016765479 Test RE 0.007995163237191715\n",
      "295 Train Loss 0.0040785866 Test MSE 0.00012176412016765479 Test RE 0.007995163237191715\n",
      "296 Train Loss 0.0040785866 Test MSE 0.00012176412016765479 Test RE 0.007995163237191715\n",
      "297 Train Loss 0.0040785866 Test MSE 0.00012176412016765479 Test RE 0.007995163237191715\n",
      "298 Train Loss 0.0040785866 Test MSE 0.00012176412016765479 Test RE 0.007995163237191715\n",
      "299 Train Loss 0.0040785866 Test MSE 0.00012176412016765479 Test RE 0.007995163237191715\n",
      "Training time: 161.94\n",
      "KG_tanh_medium\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 19986.924 Test MSE 9.785996976115374 Test RE 2.26657558458006\n",
      "1 Train Loss 9478.769 Test MSE 9.330958299822687 Test RE 2.213251625888161\n",
      "2 Train Loss 6703.036 Test MSE 10.559454463574557 Test RE 2.3544442342039753\n",
      "3 Train Loss 3540.1138 Test MSE 11.871807945780322 Test RE 2.4964685471737535\n",
      "4 Train Loss 1448.9122 Test MSE 14.686140723377404 Test RE 2.776652368407463\n",
      "5 Train Loss 746.4049 Test MSE 17.10400675644361 Test RE 2.996515975091294\n",
      "6 Train Loss 473.7221 Test MSE 18.43672154368332 Test RE 3.1110680865643343\n",
      "7 Train Loss 316.13776 Test MSE 18.923710540844617 Test RE 3.1518882837291757\n",
      "8 Train Loss 194.32533 Test MSE 20.7124467208931 Test RE 3.2974891087291436\n",
      "9 Train Loss 114.81284 Test MSE 21.56944306178872 Test RE 3.365015998656434\n",
      "10 Train Loss 83.14617 Test MSE 21.172593067015107 Test RE 3.333916303985438\n",
      "11 Train Loss 68.54262 Test MSE 20.69317255674624 Test RE 3.295954496719399\n",
      "12 Train Loss 56.379612 Test MSE 20.374132935408614 Test RE 3.270447903093366\n",
      "13 Train Loss 50.09024 Test MSE 19.74240020468272 Test RE 3.2193459128444517\n",
      "14 Train Loss 44.987186 Test MSE 19.305785682345036 Test RE 3.18354804148606\n",
      "15 Train Loss 41.02098 Test MSE 18.712930598794348 Test RE 3.134285626822572\n",
      "16 Train Loss 37.946056 Test MSE 18.53668471521188 Test RE 3.1194907289550584\n",
      "17 Train Loss 34.35854 Test MSE 18.2844317955024 Test RE 3.09819252690476\n",
      "18 Train Loss 31.108526 Test MSE 17.605418164518234 Test RE 3.0401207954147678\n",
      "19 Train Loss 28.311285 Test MSE 17.040799730489837 Test RE 2.9909741108312327\n",
      "20 Train Loss 26.433655 Test MSE 16.539415975537924 Test RE 2.946644564078761\n",
      "21 Train Loss 24.217077 Test MSE 16.107688884206535 Test RE 2.9079322503438862\n",
      "22 Train Loss 22.022919 Test MSE 15.720930336677394 Test RE 2.872809241975152\n",
      "23 Train Loss 20.315657 Test MSE 15.308018485178845 Test RE 2.834830891275023\n",
      "24 Train Loss 19.271559 Test MSE 15.009392037228633 Test RE 2.807043987742825\n",
      "25 Train Loss 18.142048 Test MSE 14.696271833617592 Test RE 2.777609928396711\n",
      "26 Train Loss 17.10283 Test MSE 14.363245902155343 Test RE 2.7459584754952098\n",
      "27 Train Loss 16.348907 Test MSE 14.147726894828113 Test RE 2.7252791993806538\n",
      "28 Train Loss 15.595678 Test MSE 13.979974797321072 Test RE 2.709073960545214\n",
      "29 Train Loss 14.923421 Test MSE 13.65188365331151 Test RE 2.677096072044502\n",
      "30 Train Loss 14.410069 Test MSE 13.495791142986207 Test RE 2.661747421063465\n",
      "31 Train Loss 14.05906 Test MSE 13.354290218296178 Test RE 2.647756682139279\n",
      "32 Train Loss 13.616331 Test MSE 13.157564395668738 Test RE 2.6281818983309337\n",
      "33 Train Loss 13.268982 Test MSE 12.918636830242662 Test RE 2.60421006091419\n",
      "34 Train Loss 12.994814 Test MSE 12.627151412554568 Test RE 2.574662821099427\n",
      "35 Train Loss 12.708207 Test MSE 12.447723932859466 Test RE 2.556304835911325\n",
      "36 Train Loss 12.38254 Test MSE 12.17177877509846 Test RE 2.527811543865353\n",
      "37 Train Loss 11.782113 Test MSE 11.746304681532248 Test RE 2.483237731175031\n",
      "38 Train Loss 11.170256 Test MSE 11.131408427376037 Test RE 2.4173677650750487\n",
      "39 Train Loss 10.588161 Test MSE 10.256056896678073 Test RE 2.320373400933615\n",
      "40 Train Loss 9.867787 Test MSE 9.300813944265723 Test RE 2.209673696772498\n",
      "41 Train Loss 8.880646 Test MSE 8.527622116822128 Test RE 2.1158342417726135\n",
      "42 Train Loss 7.941461 Test MSE 7.879781770465827 Test RE 2.03387736278309\n",
      "43 Train Loss 7.1617074 Test MSE 7.115674140246181 Test RE 1.9327500509985454\n",
      "44 Train Loss 6.3179135 Test MSE 6.28126046295929 Test RE 1.8158964052804738\n",
      "45 Train Loss 5.600721 Test MSE 5.926801688147189 Test RE 1.763915861867101\n",
      "46 Train Loss 5.074953 Test MSE 5.535426157533277 Test RE 1.7046813055769452\n",
      "47 Train Loss 4.556855 Test MSE 4.665615343673884 Test RE 1.565028075635596\n",
      "48 Train Loss 4.0878997 Test MSE 4.294708060701145 Test RE 1.5015316514630603\n",
      "49 Train Loss 3.4715843 Test MSE 3.8147334147829217 Test RE 1.4151411652727321\n",
      "50 Train Loss 3.080079 Test MSE 3.4705027212653743 Test RE 1.3497827147450316\n",
      "51 Train Loss 2.8054934 Test MSE 3.1451012234358493 Test RE 1.2849463096150147\n",
      "52 Train Loss 2.4296706 Test MSE 2.815862625785985 Test RE 1.2158315236616803\n",
      "53 Train Loss 2.0381038 Test MSE 2.1086030996681666 Test RE 1.052119543732403\n",
      "54 Train Loss 1.8425473 Test MSE 1.723567131686025 Test RE 0.9512217443083265\n",
      "55 Train Loss 1.613934 Test MSE 1.4324586729926605 Test RE 0.867178932159021\n",
      "56 Train Loss 1.4529824 Test MSE 1.1960673458654023 Test RE 0.7924018567978276\n",
      "57 Train Loss 1.2788304 Test MSE 1.0460651534775487 Test RE 0.7410491870986604\n",
      "58 Train Loss 1.0845453 Test MSE 0.7551664127824418 Test RE 0.629635201611179\n",
      "59 Train Loss 0.9787567 Test MSE 0.5686291983093525 Test RE 0.5463642137744612\n",
      "60 Train Loss 0.86870193 Test MSE 0.4807196884592908 Test RE 0.5023583466448\n",
      "61 Train Loss 0.75439477 Test MSE 0.4972203307518449 Test RE 0.5109072984118976\n",
      "62 Train Loss 0.6283915 Test MSE 0.4635296170083209 Test RE 0.4932946573637958\n",
      "63 Train Loss 0.5688257 Test MSE 0.3581504620991837 Test RE 0.43361113434716675\n",
      "64 Train Loss 0.50326884 Test MSE 0.3647011960158117 Test RE 0.4375586376021041\n",
      "65 Train Loss 0.4712143 Test MSE 0.3754081204166046 Test RE 0.4439351151199312\n",
      "66 Train Loss 0.43596083 Test MSE 0.3257395245091753 Test RE 0.4135260725085141\n",
      "67 Train Loss 0.40087155 Test MSE 0.25110578567314445 Test RE 0.36307473354002046\n",
      "68 Train Loss 0.37479645 Test MSE 0.21039610343867457 Test RE 0.3323429831554315\n",
      "69 Train Loss 0.34046745 Test MSE 0.1416007966319724 Test RE 0.27264686977977887\n",
      "70 Train Loss 0.30887654 Test MSE 0.12998894396927219 Test RE 0.2612286917349609\n",
      "71 Train Loss 0.28692073 Test MSE 0.09490527198597339 Test RE 0.22320958330968735\n",
      "72 Train Loss 0.2606106 Test MSE 0.07427160621611938 Test RE 0.1974599741108425\n",
      "73 Train Loss 0.23950385 Test MSE 0.06656897680644723 Test RE 0.1869405897758842\n",
      "74 Train Loss 0.20537621 Test MSE 0.0647861981003988 Test RE 0.18442038102639344\n",
      "75 Train Loss 0.18342692 Test MSE 0.05386343582291396 Test RE 0.16815690057157404\n",
      "76 Train Loss 0.15894708 Test MSE 0.050603420684284806 Test RE 0.16298874106880726\n",
      "77 Train Loss 0.14717233 Test MSE 0.039402730360775434 Test RE 0.14382382214160627\n",
      "78 Train Loss 0.13761453 Test MSE 0.03614833375473816 Test RE 0.13775640779143672\n",
      "79 Train Loss 0.12697151 Test MSE 0.033724863342958995 Test RE 0.13305854402163977\n",
      "80 Train Loss 0.11835403 Test MSE 0.02695579321740128 Test RE 0.11895801966660649\n",
      "81 Train Loss 0.10874361 Test MSE 0.024738835631814116 Test RE 0.11396127387392602\n",
      "82 Train Loss 0.10346008 Test MSE 0.021702304273597612 Test RE 0.10673837621959718\n",
      "83 Train Loss 0.093762666 Test MSE 0.015258505481945473 Test RE 0.08950013011152987\n",
      "84 Train Loss 0.08450499 Test MSE 0.010636389118133206 Test RE 0.07472480255293379\n",
      "85 Train Loss 0.07807232 Test MSE 0.009039834708479506 Test RE 0.06888868781468668\n",
      "86 Train Loss 0.07338046 Test MSE 0.008964629682875721 Test RE 0.06860153678540408\n",
      "87 Train Loss 0.06561595 Test MSE 0.00751121342962849 Test RE 0.06279466081215528\n",
      "88 Train Loss 0.05874703 Test MSE 0.006561207994351982 Test RE 0.05868938658488614\n",
      "89 Train Loss 0.054724514 Test MSE 0.008339166303116374 Test RE 0.066165101803245\n",
      "90 Train Loss 0.04905221 Test MSE 0.008652257540334942 Test RE 0.06739573076176367\n",
      "91 Train Loss 0.044669982 Test MSE 0.007280391336244128 Test RE 0.06182228170446472\n",
      "92 Train Loss 0.04032863 Test MSE 0.005385022302814861 Test RE 0.05316935853986171\n",
      "93 Train Loss 0.039585114 Test MSE 0.005142080401017512 Test RE 0.051956166408868104\n",
      "94 Train Loss 0.038320087 Test MSE 0.00467628932484073 Test RE 0.04954711301761832\n",
      "95 Train Loss 0.033382703 Test MSE 0.003282785831382576 Test RE 0.04151346105299823\n",
      "96 Train Loss 0.03212204 Test MSE 0.003142766763986744 Test RE 0.04061848710894182\n",
      "97 Train Loss 0.029991329 Test MSE 0.002682758571475408 Test RE 0.03752826297431734\n",
      "98 Train Loss 0.028216183 Test MSE 0.0025227080252812665 Test RE 0.03639160098563027\n",
      "99 Train Loss 0.027159102 Test MSE 0.0016867777405055852 Test RE 0.029757510688603966\n",
      "100 Train Loss 0.025398364 Test MSE 0.001613790002536755 Test RE 0.02910657991998637\n",
      "101 Train Loss 0.02405889 Test MSE 0.0012337166184447823 Test RE 0.025449272679983436\n",
      "102 Train Loss 0.023467984 Test MSE 0.001267846912829541 Test RE 0.025798893302380468\n",
      "103 Train Loss 0.022240426 Test MSE 0.0011214069316964745 Test RE 0.024263267471026737\n",
      "104 Train Loss 0.020632807 Test MSE 0.0012888932734657643 Test RE 0.02601214380209339\n",
      "105 Train Loss 0.019483428 Test MSE 0.0014763356326421286 Test RE 0.027839422280995944\n",
      "106 Train Loss 0.018785678 Test MSE 0.0014743215365488037 Test RE 0.027820425784762303\n",
      "107 Train Loss 0.018139806 Test MSE 0.0014777301097244672 Test RE 0.02785256708106722\n",
      "108 Train Loss 0.01778324 Test MSE 0.0013851496791126982 Test RE 0.026965968354342132\n",
      "109 Train Loss 0.01729432 Test MSE 0.0013639763237780261 Test RE 0.02675907418422705\n",
      "110 Train Loss 0.016324945 Test MSE 0.0012117099887204122 Test RE 0.02522127349952392\n",
      "111 Train Loss 0.015832558 Test MSE 0.0010380643553190131 Test RE 0.02334424362611139\n",
      "112 Train Loss 0.015298865 Test MSE 0.0009544034178309298 Test RE 0.022383791953571434\n",
      "113 Train Loss 0.014709158 Test MSE 0.0008399281929299361 Test RE 0.020998522944808674\n",
      "114 Train Loss 0.01423311 Test MSE 0.0007734175071281903 Test RE 0.02014998220461971\n",
      "115 Train Loss 0.013845611 Test MSE 0.0007621675766036185 Test RE 0.020002897171855036\n",
      "116 Train Loss 0.013620867 Test MSE 0.0006938308492349976 Test RE 0.0190851013446179\n",
      "117 Train Loss 0.013351275 Test MSE 0.0006742276957229517 Test RE 0.018813559091968662\n",
      "118 Train Loss 0.01298775 Test MSE 0.0007219285500124584 Test RE 0.019467705878239188\n",
      "119 Train Loss 0.012498539 Test MSE 0.0008107162636578373 Test RE 0.02063013692052155\n",
      "120 Train Loss 0.012179657 Test MSE 0.0007634834739700225 Test RE 0.020020157423441612\n",
      "121 Train Loss 0.011975929 Test MSE 0.0006743016552498498 Test RE 0.01881459094202616\n",
      "122 Train Loss 0.011481058 Test MSE 0.0006923428383002121 Test RE 0.01906462511317865\n",
      "123 Train Loss 0.011075966 Test MSE 0.0006308509955353004 Test RE 0.018198310220214675\n",
      "124 Train Loss 0.010892017 Test MSE 0.0005444360619937226 Test RE 0.01690600953746174\n",
      "125 Train Loss 0.010709321 Test MSE 0.0004908920634362592 Test RE 0.016053165126545744\n",
      "126 Train Loss 0.010433722 Test MSE 0.000477916014149929 Test RE 0.015839572616164727\n",
      "127 Train Loss 0.010052962 Test MSE 0.0003577471804272558 Test RE 0.013704265928405039\n",
      "128 Train Loss 0.009760555 Test MSE 0.0003443219820709234 Test RE 0.013444666766811223\n",
      "129 Train Loss 0.00938715 Test MSE 0.00034615079294596696 Test RE 0.01348032407598035\n",
      "130 Train Loss 0.009170585 Test MSE 0.00035009456630416286 Test RE 0.013556898758296243\n",
      "131 Train Loss 0.008778155 Test MSE 0.00034195341341080975 Test RE 0.013398344470459775\n",
      "132 Train Loss 0.008638096 Test MSE 0.00031692972476078023 Test RE 0.012898795409831035\n",
      "133 Train Loss 0.008547753 Test MSE 0.00032364655784062517 Test RE 0.013034763740985581\n",
      "134 Train Loss 0.008349672 Test MSE 0.0003478518066140077 Test RE 0.01351340519948001\n",
      "135 Train Loss 0.008145043 Test MSE 0.00037325957487994744 Test RE 0.013998230683914467\n",
      "136 Train Loss 0.007969248 Test MSE 0.0003670484213897681 Test RE 0.013881274676875279\n",
      "137 Train Loss 0.007839659 Test MSE 0.00032800027755802404 Test RE 0.013122143212664092\n",
      "138 Train Loss 0.007735341 Test MSE 0.0003116892221721325 Test RE 0.012791708681793608\n",
      "139 Train Loss 0.007586246 Test MSE 0.000304879601590677 Test RE 0.012651203796131305\n",
      "140 Train Loss 0.0074762334 Test MSE 0.00028584083826927115 Test RE 0.012249822788995472\n",
      "141 Train Loss 0.007357406 Test MSE 0.0002924631995175091 Test RE 0.012390912240266509\n",
      "142 Train Loss 0.007181376 Test MSE 0.0002854051260132276 Test RE 0.012240482917408002\n",
      "143 Train Loss 0.007110552 Test MSE 0.00030075991511791433 Test RE 0.012565438370929619\n",
      "144 Train Loss 0.0069980775 Test MSE 0.00029414658815098214 Test RE 0.01242652149257265\n",
      "145 Train Loss 0.0068865116 Test MSE 0.0002878425265846213 Test RE 0.012292639534778325\n",
      "146 Train Loss 0.006747503 Test MSE 0.00025932698021142623 Test RE 0.01166786831744661\n",
      "147 Train Loss 0.006647745 Test MSE 0.00027446591187001797 Test RE 0.012003609939115534\n",
      "148 Train Loss 0.0065389345 Test MSE 0.00025885073345082 Test RE 0.01165714953675891\n",
      "149 Train Loss 0.0064474447 Test MSE 0.00025306895871461503 Test RE 0.011526225362298097\n",
      "150 Train Loss 0.0063523324 Test MSE 0.0002635763506542145 Test RE 0.01176307559432448\n",
      "151 Train Loss 0.0062892796 Test MSE 0.000280484530776777 Test RE 0.01213450666972952\n",
      "152 Train Loss 0.00620404 Test MSE 0.000276139344636034 Test RE 0.012040147643939233\n",
      "153 Train Loss 0.006142623 Test MSE 0.00029063367435139736 Test RE 0.012352095305696658\n",
      "154 Train Loss 0.0060514947 Test MSE 0.00027107689533853896 Test RE 0.011929271397789949\n",
      "155 Train Loss 0.0059055723 Test MSE 0.0002678023498375911 Test RE 0.011857001078192568\n",
      "156 Train Loss 0.005789063 Test MSE 0.00028279390539560277 Test RE 0.012184359108405096\n",
      "157 Train Loss 0.005694904 Test MSE 0.0002553105854257918 Test RE 0.011577161145060876\n",
      "158 Train Loss 0.005606108 Test MSE 0.0002623249315414903 Test RE 0.011735117752338651\n",
      "159 Train Loss 0.0055514984 Test MSE 0.0002615553819461787 Test RE 0.011717892191859638\n",
      "160 Train Loss 0.005479042 Test MSE 0.0002507076833245568 Test RE 0.01147232626525481\n",
      "161 Train Loss 0.005392749 Test MSE 0.00024157029717636954 Test RE 0.011261323498956897\n",
      "162 Train Loss 0.005310739 Test MSE 0.0002416233556930869 Test RE 0.011262560149990736\n",
      "163 Train Loss 0.0052544107 Test MSE 0.0002507787942095154 Test RE 0.011473953158817902\n",
      "164 Train Loss 0.0051909033 Test MSE 0.0002794192990278997 Test RE 0.012111442371276175\n",
      "165 Train Loss 0.0051286104 Test MSE 0.00027535320124508916 Test RE 0.0120229968304377\n",
      "166 Train Loss 0.005062212 Test MSE 0.00027351889221207694 Test RE 0.011982883362873196\n",
      "167 Train Loss 0.0050219037 Test MSE 0.00027975897700126604 Test RE 0.012118801814007703\n",
      "168 Train Loss 0.0049567637 Test MSE 0.0003113890190459896 Test RE 0.01278554703782753\n",
      "169 Train Loss 0.0048923744 Test MSE 0.00032581188930979075 Test RE 0.013078295074970535\n",
      "170 Train Loss 0.0048345393 Test MSE 0.000308027523806833 Test RE 0.01271634874676238\n",
      "171 Train Loss 0.004794516 Test MSE 0.0003120329646324352 Test RE 0.012798760324039472\n",
      "172 Train Loss 0.0047226483 Test MSE 0.00032491828568093046 Test RE 0.013060347853461704\n",
      "173 Train Loss 0.0045721554 Test MSE 0.0002911780426929905 Test RE 0.012363657874927058\n",
      "174 Train Loss 0.004514284 Test MSE 0.00026683290678319296 Test RE 0.011835520480848655\n",
      "175 Train Loss 0.0044343723 Test MSE 0.00023883108261031386 Test RE 0.011197294256419564\n",
      "176 Train Loss 0.0043567405 Test MSE 0.00023592243594935404 Test RE 0.011128901268350937\n",
      "177 Train Loss 0.0042793625 Test MSE 0.00022079422491511503 Test RE 0.010766177174871243\n",
      "178 Train Loss 0.0042288136 Test MSE 0.00022062983653743317 Test RE 0.010762168546593957\n",
      "179 Train Loss 0.0041879015 Test MSE 0.00020472253472340283 Test RE 0.010366937795641002\n",
      "180 Train Loss 0.0041395104 Test MSE 0.0002049134372087337 Test RE 0.010371770221733072\n",
      "181 Train Loss 0.0040306584 Test MSE 0.0002001171739409378 Test RE 0.010249669179052965\n",
      "182 Train Loss 0.003941745 Test MSE 0.00021382190987927191 Test RE 0.010594824565669804\n",
      "183 Train Loss 0.0038188219 Test MSE 0.00022269805693553706 Test RE 0.010812494051387756\n",
      "184 Train Loss 0.003687967 Test MSE 0.00023103043267500595 Test RE 0.01101291439441708\n",
      "185 Train Loss 0.0035446857 Test MSE 0.0002716478567564613 Test RE 0.011941827928920576\n",
      "186 Train Loss 0.003485423 Test MSE 0.0002661279555615379 Test RE 0.01181987589130808\n",
      "187 Train Loss 0.003433372 Test MSE 0.0002951024246213382 Test RE 0.012446695258527317\n",
      "188 Train Loss 0.0033942973 Test MSE 0.00032138616241185637 Test RE 0.01298916562655752\n",
      "189 Train Loss 0.0033492416 Test MSE 0.00032138664429583424 Test RE 0.012989175364482151\n",
      "190 Train Loss 0.0032887002 Test MSE 0.0002706204168433113 Test RE 0.0119192230492506\n",
      "191 Train Loss 0.0032471828 Test MSE 0.0002633272689658941 Test RE 0.011757516181920512\n",
      "192 Train Loss 0.0032062533 Test MSE 0.0002528239474220473 Test RE 0.011520644394852748\n",
      "193 Train Loss 0.0031359368 Test MSE 0.00024976104066946984 Test RE 0.011450646705309745\n",
      "194 Train Loss 0.0030905495 Test MSE 0.00025397807528857266 Test RE 0.01154691001799949\n",
      "195 Train Loss 0.003035078 Test MSE 0.0002548253790228466 Test RE 0.01156615497367872\n",
      "196 Train Loss 0.0029694661 Test MSE 0.00025455773697657214 Test RE 0.011560079435510417\n",
      "197 Train Loss 0.0029169607 Test MSE 0.0002487695664315114 Test RE 0.011427896338394665\n",
      "198 Train Loss 0.002871661 Test MSE 0.00023612733680949098 Test RE 0.011133732997321127\n",
      "199 Train Loss 0.0028334116 Test MSE 0.0002275612445355795 Test RE 0.010929915836780818\n",
      "200 Train Loss 0.0027852189 Test MSE 0.00023966335064701995 Test RE 0.011216787208048128\n",
      "201 Train Loss 0.0027587034 Test MSE 0.00022538234433574873 Test RE 0.010877462972768813\n",
      "202 Train Loss 0.002721103 Test MSE 0.00022315043390481104 Test RE 0.010823470442207843\n",
      "203 Train Loss 0.0026801797 Test MSE 0.00022310453649404245 Test RE 0.01082235730340156\n",
      "204 Train Loss 0.0026493908 Test MSE 0.000221440555978977 Test RE 0.010781923578052006\n",
      "205 Train Loss 0.0026240498 Test MSE 0.00022410824865000232 Test RE 0.010846674024953208\n",
      "206 Train Loss 0.0025983169 Test MSE 0.00022874106628859318 Test RE 0.010958213012905383\n",
      "207 Train Loss 0.0025727518 Test MSE 0.00023263110699187048 Test RE 0.011050999552005385\n",
      "208 Train Loss 0.0025570905 Test MSE 0.00023513693359379748 Test RE 0.011110359015917027\n",
      "209 Train Loss 0.0025443025 Test MSE 0.0002289495496357739 Test RE 0.010963205742530091\n",
      "210 Train Loss 0.0025328156 Test MSE 0.0002275978576997383 Test RE 0.010930795078561043\n",
      "211 Train Loss 0.0025223126 Test MSE 0.00022412681207026642 Test RE 0.010847123243578973\n",
      "212 Train Loss 0.0025048414 Test MSE 0.00021868765825728032 Test RE 0.010714694792637593\n",
      "213 Train Loss 0.0024763353 Test MSE 0.00022322343109753992 Test RE 0.010825240589685096\n",
      "214 Train Loss 0.002444911 Test MSE 0.00022739988965385287 Test RE 0.010926040159233182\n",
      "215 Train Loss 0.0024281791 Test MSE 0.00022812005010446174 Test RE 0.010943327507315977\n",
      "216 Train Loss 0.0024057082 Test MSE 0.00023647021604441407 Test RE 0.011141813681787016\n",
      "217 Train Loss 0.0023779452 Test MSE 0.00023475098308841413 Test RE 0.01110123707653663\n",
      "218 Train Loss 0.00235401 Test MSE 0.00023625283591269 Test RE 0.011136691333098157\n",
      "219 Train Loss 0.002314533 Test MSE 0.00023921434097138862 Test RE 0.011206274947554246\n",
      "220 Train Loss 0.0022891916 Test MSE 0.0002477025975700327 Test RE 0.011403362968104706\n",
      "221 Train Loss 0.0022701533 Test MSE 0.0002443792339082961 Test RE 0.011326606612241703\n",
      "222 Train Loss 0.0022551045 Test MSE 0.00024017045853017647 Test RE 0.011228647835636351\n",
      "223 Train Loss 0.002239093 Test MSE 0.00023816490110893673 Test RE 0.011181666811260607\n",
      "224 Train Loss 0.002225405 Test MSE 0.00024302081079627733 Test RE 0.011295082318095772\n",
      "225 Train Loss 0.0022156031 Test MSE 0.00023926187275578385 Test RE 0.011207388233207615\n",
      "226 Train Loss 0.0021999895 Test MSE 0.00023124914431780575 Test RE 0.011018126008285082\n",
      "227 Train Loss 0.0021767286 Test MSE 0.00023639231123874393 Test RE 0.011139978202574391\n",
      "228 Train Loss 0.0021607666 Test MSE 0.00024159041836467311 Test RE 0.011261792485614472\n",
      "229 Train Loss 0.0021428834 Test MSE 0.00023878031079250953 Test RE 0.011196104006819621\n",
      "230 Train Loss 0.0021296642 Test MSE 0.00024702929651357927 Test RE 0.011387854206803124\n",
      "231 Train Loss 0.0021075234 Test MSE 0.0002554730045148702 Test RE 0.011580843039030852\n",
      "232 Train Loss 0.0020939521 Test MSE 0.00025438001418472253 Test RE 0.011556043321084921\n",
      "233 Train Loss 0.00207601 Test MSE 0.0002485355583423831 Test RE 0.011422520179639423\n",
      "234 Train Loss 0.0020526317 Test MSE 0.00024257780186071024 Test RE 0.011284782572862558\n",
      "235 Train Loss 0.0020346558 Test MSE 0.0002389261950149965 Test RE 0.011199523647083938\n",
      "236 Train Loss 0.00202306 Test MSE 0.0002404966494250184 Test RE 0.011236270421529212\n",
      "237 Train Loss 0.0020131816 Test MSE 0.00023991399943463089 Test RE 0.011222651140529376\n",
      "238 Train Loss 0.0019998343 Test MSE 0.00023098693686963477 Test RE 0.011011877651933505\n",
      "239 Train Loss 0.001989279 Test MSE 0.00023000214924588546 Test RE 0.010988378608837293\n",
      "240 Train Loss 0.0019805522 Test MSE 0.00023112591706982066 Test RE 0.011015189966566452\n",
      "241 Train Loss 0.0019633172 Test MSE 0.00022884645275591978 Test RE 0.010960737077321488\n",
      "242 Train Loss 0.0019485992 Test MSE 0.00022686030720748732 Test RE 0.010913069614470321\n",
      "243 Train Loss 0.0019363901 Test MSE 0.00022591103300725464 Test RE 0.010890213356894518\n",
      "244 Train Loss 0.0019196096 Test MSE 0.00022912327258432091 Test RE 0.010967364299033687\n",
      "245 Train Loss 0.001907577 Test MSE 0.000222438566797727 Test RE 0.010806192798909807\n",
      "246 Train Loss 0.001897334 Test MSE 0.0002317462295517565 Test RE 0.011029961744272388\n",
      "247 Train Loss 0.0018830079 Test MSE 0.0002369327227029037 Test RE 0.01115270436777807\n",
      "248 Train Loss 0.0018670817 Test MSE 0.00024226284035418387 Test RE 0.011277454147603764\n",
      "249 Train Loss 0.001853653 Test MSE 0.0002457481994947644 Test RE 0.011358287045942793\n",
      "250 Train Loss 0.0018416834 Test MSE 0.00024259029440517552 Test RE 0.011285073147333938\n",
      "251 Train Loss 0.0018254084 Test MSE 0.00023484122860275875 Test RE 0.01110337070036839\n",
      "252 Train Loss 0.0018019058 Test MSE 0.0002301865937760611 Test RE 0.010992783654995819\n",
      "253 Train Loss 0.001779396 Test MSE 0.0002394876963449653 Test RE 0.011212675945166891\n",
      "254 Train Loss 0.0017645499 Test MSE 0.0002362609512916413 Test RE 0.011136882606345655\n",
      "255 Train Loss 0.0017458647 Test MSE 0.0002415598973726267 Test RE 0.01126108109164078\n",
      "256 Train Loss 0.0017297826 Test MSE 0.00024234827380186592 Test RE 0.01127944245679086\n",
      "257 Train Loss 0.0017188983 Test MSE 0.00022907213058488284 Test RE 0.010966140232541353\n",
      "258 Train Loss 0.0017046451 Test MSE 0.00023148365443927872 Test RE 0.011023711342089291\n",
      "259 Train Loss 0.0016920854 Test MSE 0.0002301751597774898 Test RE 0.01099251063076916\n",
      "260 Train Loss 0.0016747904 Test MSE 0.0002405586841579418 Test RE 0.011237719493881798\n",
      "261 Train Loss 0.0016614337 Test MSE 0.00023842232866688872 Test RE 0.01118770819638528\n",
      "262 Train Loss 0.0016432869 Test MSE 0.00023224414941637843 Test RE 0.011041804634329341\n",
      "263 Train Loss 0.0016296002 Test MSE 0.00021839647437415716 Test RE 0.010707559077458796\n",
      "264 Train Loss 0.001610655 Test MSE 0.00021489082277116194 Test RE 0.010621273740739097\n",
      "265 Train Loss 0.0015916069 Test MSE 0.00020339885170579265 Test RE 0.01033336847430712\n",
      "266 Train Loss 0.001574896 Test MSE 0.00020051303663836181 Test RE 0.010259801885356206\n",
      "267 Train Loss 0.0015541682 Test MSE 0.0001894331457740052 Test RE 0.009972307307894718\n",
      "268 Train Loss 0.0015413287 Test MSE 0.0001879222057911471 Test RE 0.009932457567434496\n",
      "269 Train Loss 0.001527235 Test MSE 0.00018334400922428803 Test RE 0.009810723356429095\n",
      "270 Train Loss 0.0015098962 Test MSE 0.00018796363343600154 Test RE 0.009933552317380882\n",
      "271 Train Loss 0.0014989999 Test MSE 0.00017489539326012604 Test RE 0.009582015141858724\n",
      "272 Train Loss 0.0014892081 Test MSE 0.00016460772548794534 Test RE 0.009295928499363556\n",
      "273 Train Loss 0.0014755281 Test MSE 0.00015723438661729974 Test RE 0.009085345199141419\n",
      "274 Train Loss 0.001463232 Test MSE 0.0001483943842920489 Test RE 0.008826253581794487\n",
      "275 Train Loss 0.0014510369 Test MSE 0.0001360021815381805 Test RE 0.008449686673858349\n",
      "276 Train Loss 0.0014405698 Test MSE 0.0001338900158438114 Test RE 0.008383816499248867\n",
      "277 Train Loss 0.0014331404 Test MSE 0.00013265269199754128 Test RE 0.008344987712575861\n",
      "278 Train Loss 0.0014271238 Test MSE 0.00012897032639292618 Test RE 0.008228346411680113\n",
      "279 Train Loss 0.0014119225 Test MSE 0.00011894700209946063 Test RE 0.00790213451065738\n",
      "280 Train Loss 0.0013920956 Test MSE 0.0001203619833070166 Test RE 0.007948997041257911\n",
      "281 Train Loss 0.0013591892 Test MSE 0.0001024770782764242 Test RE 0.007334677702814164\n",
      "282 Train Loss 0.0013430762 Test MSE 0.00010140822893642964 Test RE 0.007296326614719869\n",
      "283 Train Loss 0.0013341496 Test MSE 9.954076824970895e-05 Test RE 0.007228832500099238\n",
      "284 Train Loss 0.001324622 Test MSE 9.603818167713867e-05 Test RE 0.007100511449543895\n",
      "285 Train Loss 0.0013185871 Test MSE 9.614553676969402e-05 Test RE 0.0071044789505123294\n",
      "286 Train Loss 0.0013144101 Test MSE 9.081355533293e-05 Test RE 0.006904671273032801\n",
      "287 Train Loss 0.0013081771 Test MSE 8.656953174918526e-05 Test RE 0.006741401632465509\n",
      "288 Train Loss 0.0013019321 Test MSE 8.172646478107624e-05 Test RE 0.006550116497528693\n",
      "289 Train Loss 0.0012953574 Test MSE 7.98323271665477e-05 Test RE 0.006473766968530489\n",
      "290 Train Loss 0.0012869763 Test MSE 7.537019623533541e-05 Test RE 0.006290243978277186\n",
      "291 Train Loss 0.0012803181 Test MSE 7.490500048551483e-05 Test RE 0.006270801784127412\n",
      "292 Train Loss 0.0012704054 Test MSE 6.866307345791944e-05 Test RE 0.0060038424508854936\n",
      "293 Train Loss 0.0012615861 Test MSE 6.524507807911726e-05 Test RE 0.0058525016558320314\n",
      "294 Train Loss 0.0012525291 Test MSE 6.947139079748084e-05 Test RE 0.0060390783534218315\n",
      "295 Train Loss 0.0012458022 Test MSE 6.965331085722701e-05 Test RE 0.006046980247968807\n",
      "296 Train Loss 0.0012451356 Test MSE 6.885722603481036e-05 Test RE 0.006012324729478365\n",
      "297 Train Loss 0.001241623 Test MSE 7.066163056949292e-05 Test RE 0.006090591822967236\n",
      "298 Train Loss 0.0012324273 Test MSE 6.227558403412482e-05 Test RE 0.005717768558948561\n",
      "299 Train Loss 0.0012250809 Test MSE 6.161808439443631e-05 Test RE 0.005687504640239528\n",
      "Training time: 164.23\n",
      "KG_tanh_medium\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "1 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "2 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "3 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "4 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "5 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "6 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "7 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "8 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "9 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "10 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "11 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "12 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "13 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "14 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "15 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "16 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "17 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "18 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "19 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "20 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "21 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "22 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "23 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "24 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "25 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "26 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "27 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "28 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "29 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "30 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "31 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "32 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "33 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "34 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "35 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "36 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "37 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "38 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "39 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "40 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "41 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "42 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "43 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "44 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "45 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "46 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "47 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "48 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "49 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "50 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "51 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "52 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "53 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "54 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "55 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "56 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "57 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "58 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "59 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "60 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "61 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "62 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "63 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "64 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "65 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "66 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "67 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "68 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "69 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "70 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "71 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "72 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "73 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "74 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "75 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "76 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "77 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "78 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "79 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "80 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "81 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "82 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "83 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "84 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "85 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "86 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "87 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "88 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "89 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "90 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "91 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "92 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "93 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "94 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "95 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "96 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "97 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "98 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "99 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "100 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "101 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "102 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "103 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "104 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "105 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "106 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "107 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "108 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "109 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "110 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "111 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "112 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "113 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "114 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "115 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "116 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "117 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "118 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "119 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "120 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "121 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "122 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "123 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "124 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "125 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "126 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "127 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "128 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "129 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "130 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "131 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "132 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "133 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "134 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "135 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "136 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "137 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "138 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "139 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "140 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "141 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "142 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "143 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "144 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "145 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "146 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "147 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "148 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "149 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "150 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "151 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "152 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "153 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "154 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "155 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "156 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "157 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "158 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "159 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "160 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "161 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "162 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "163 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "164 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "165 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "166 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "167 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "168 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "169 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "170 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "171 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "172 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "173 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "174 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "175 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "176 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "177 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "178 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "179 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "180 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "181 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "182 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "183 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "184 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "185 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "186 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "187 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "188 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "189 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "190 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "191 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "192 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "193 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "194 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "195 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "196 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "197 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "198 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "199 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "200 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "201 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "202 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "203 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "204 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "205 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "206 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "207 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "208 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "209 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "210 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "211 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "212 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "213 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "214 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "215 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "216 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "217 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "218 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "219 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "220 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "221 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "222 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "223 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "224 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "225 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "226 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "227 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "228 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "229 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "230 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "231 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "232 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "233 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "234 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "235 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "236 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "237 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "238 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "239 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "240 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "241 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "242 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "243 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "244 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "245 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "246 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "247 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "248 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "249 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "250 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "251 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "252 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "253 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "254 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "255 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "256 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "257 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "258 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "259 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "260 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "261 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "262 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "263 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "264 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "265 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "266 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "267 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "268 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "269 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "270 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "271 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "272 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "273 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "274 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "275 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "276 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "277 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "278 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "279 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "280 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "281 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "282 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "283 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "284 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "285 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "286 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "287 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "288 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "289 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "290 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "291 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "292 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "293 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "294 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "295 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "296 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "297 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "298 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "299 Train Loss 49118.72 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "Training time: 55.21\n",
      "KG_tanh_medium\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 32850.914 Test MSE 7.727017786897715 Test RE 2.0140656547225038\n",
      "1 Train Loss 11707.96 Test MSE 10.509357638231384 Test RE 2.348852543293754\n",
      "2 Train Loss 8838.062 Test MSE 10.195391596179686 Test RE 2.3135006364096147\n",
      "3 Train Loss 6811.901 Test MSE 11.078823781586575 Test RE 2.4116511970289136\n",
      "4 Train Loss 5007.666 Test MSE 11.802000982684072 Test RE 2.489118031338575\n",
      "5 Train Loss 2196.0989 Test MSE 14.551028938670216 Test RE 2.763850322038985\n",
      "6 Train Loss 921.8406 Test MSE 17.8994757182698 Test RE 3.0654047280316203\n",
      "7 Train Loss 467.7948 Test MSE 18.441457817386137 Test RE 3.111467667469476\n",
      "8 Train Loss 259.583 Test MSE 17.67976694786609 Test RE 3.046533342644927\n",
      "9 Train Loss 147.4839 Test MSE 17.153255763997088 Test RE 3.0008269345366387\n",
      "10 Train Loss 98.94083 Test MSE 17.502707616138608 Test RE 3.031239744505433\n",
      "11 Train Loss 78.500275 Test MSE 17.309613077310818 Test RE 3.014472648798688\n",
      "12 Train Loss 66.8108 Test MSE 17.04605216832538 Test RE 2.9914350250918553\n",
      "13 Train Loss 56.0945 Test MSE 16.670769160708474 Test RE 2.9583222954074286\n",
      "14 Train Loss 48.11083 Test MSE 16.26411011489147 Test RE 2.9220175541349622\n",
      "15 Train Loss 41.73453 Test MSE 15.9162168068093 Test RE 2.890597287675884\n",
      "16 Train Loss 37.012592 Test MSE 15.798149780357956 Test RE 2.8798560574122787\n",
      "17 Train Loss 33.468025 Test MSE 15.678283451226465 Test RE 2.868909995369969\n",
      "18 Train Loss 30.514404 Test MSE 15.373437371013434 Test RE 2.840881764838958\n",
      "19 Train Loss 27.686283 Test MSE 15.304011437880312 Test RE 2.8344598424377936\n",
      "20 Train Loss 25.0657 Test MSE 15.2238098609832 Test RE 2.8270230091422057\n",
      "21 Train Loss 23.680607 Test MSE 15.138225064031223 Test RE 2.8190653691404246\n",
      "22 Train Loss 22.489248 Test MSE 14.973624227564988 Test RE 2.8036973598015815\n",
      "23 Train Loss 21.432066 Test MSE 14.809529897334142 Test RE 2.788292329783292\n",
      "24 Train Loss 20.438509 Test MSE 14.467668603840341 Test RE 2.7559221400588707\n",
      "25 Train Loss 19.681757 Test MSE 14.323730687102836 Test RE 2.7421786240368147\n",
      "26 Train Loss 18.935192 Test MSE 14.109854947497066 Test RE 2.7216291149788074\n",
      "27 Train Loss 18.207314 Test MSE 13.854217572726773 Test RE 2.6968616620775894\n",
      "28 Train Loss 17.590939 Test MSE 13.762109985712133 Test RE 2.6878818816783263\n",
      "29 Train Loss 16.822502 Test MSE 13.737852260881628 Test RE 2.685511945075466\n",
      "30 Train Loss 16.336077 Test MSE 13.376287662757525 Test RE 2.649936502789945\n",
      "31 Train Loss 16.004446 Test MSE 13.289030356934115 Test RE 2.641279218747321\n",
      "32 Train Loss 15.532488 Test MSE 13.134650712675933 Test RE 2.6258924332550935\n",
      "33 Train Loss 15.159069 Test MSE 12.902730555175319 Test RE 2.602606329780274\n",
      "34 Train Loss 14.857755 Test MSE 12.81069267963516 Test RE 2.5933072493993854\n",
      "35 Train Loss 14.472527 Test MSE 12.569021116389997 Test RE 2.5687296317610255\n",
      "36 Train Loss 14.014946 Test MSE 12.487936164777434 Test RE 2.560430563554244\n",
      "37 Train Loss 13.882774 Test MSE 12.332083445973247 Test RE 2.5444029769212384\n",
      "38 Train Loss 13.516306 Test MSE 11.35452947209841 Test RE 2.4414747583311196\n",
      "39 Train Loss 12.829858 Test MSE 10.980627185701705 Test RE 2.4009396344687715\n",
      "40 Train Loss 12.087382 Test MSE 10.164260437638987 Test RE 2.3099658522159454\n",
      "41 Train Loss 11.249688 Test MSE 9.499527562917352 Test RE 2.233153989009019\n",
      "42 Train Loss 10.819238 Test MSE 8.550920797812298 Test RE 2.1187226508298607\n",
      "43 Train Loss 10.311692 Test MSE 7.988024680309469 Test RE 2.047799188974285\n",
      "44 Train Loss 9.425481 Test MSE 7.518424599760326 Test RE 1.9866945114692454\n",
      "45 Train Loss 8.600122 Test MSE 6.806873446456021 Test RE 1.8903468841314734\n",
      "46 Train Loss 7.9193115 Test MSE 6.704840355144942 Test RE 1.876125509030376\n",
      "47 Train Loss 6.981426 Test MSE 6.200421522291726 Test RE 1.804173398824101\n",
      "48 Train Loss 6.368019 Test MSE 5.747592450099545 Test RE 1.7370433241689962\n",
      "49 Train Loss 5.863371 Test MSE 5.338901310319483 Test RE 1.6741470971076489\n",
      "50 Train Loss 5.430412 Test MSE 4.90746855715032 Test RE 1.6050790657585539\n",
      "51 Train Loss 5.003444 Test MSE 4.359213994143063 Test RE 1.5127660250209785\n",
      "52 Train Loss 4.6608186 Test MSE 4.285448009700121 Test RE 1.4999120113737818\n",
      "53 Train Loss 4.40896 Test MSE 3.9829912841434916 Test RE 1.4460134937445954\n",
      "54 Train Loss 4.1989584 Test MSE 3.7157812088184774 Test RE 1.3966665588042815\n",
      "55 Train Loss 3.9255097 Test MSE 3.6503524298202015 Test RE 1.3843154493071752\n",
      "56 Train Loss 3.7024376 Test MSE 3.421247615271411 Test RE 1.3401700912409111\n",
      "57 Train Loss 3.529334 Test MSE 3.1853700051601934 Test RE 1.2931461488487066\n",
      "58 Train Loss 3.387566 Test MSE 2.9492299960749104 Test RE 1.2442910830062919\n",
      "59 Train Loss 3.1743674 Test MSE 2.845482267009592 Test RE 1.2222093713417055\n",
      "60 Train Loss 3.024481 Test MSE 2.8802371021423094 Test RE 1.2296507751718246\n",
      "61 Train Loss 2.8917236 Test MSE 2.7051931635557964 Test RE 1.1916996403076334\n",
      "62 Train Loss 2.7357264 Test MSE 2.583633624350273 Test RE 1.164617017133852\n",
      "63 Train Loss 2.5781276 Test MSE 2.368535586730385 Test RE 1.1150841039715962\n",
      "64 Train Loss 2.4743598 Test MSE 2.243872410157814 Test RE 1.0853423437437677\n",
      "65 Train Loss 2.3253949 Test MSE 2.001070068625192 Test RE 1.024940880531319\n",
      "66 Train Loss 2.207102 Test MSE 1.869240685829682 Test RE 0.9906044630115597\n",
      "67 Train Loss 2.0528731 Test MSE 1.6118673574265028 Test RE 0.9198824173017396\n",
      "68 Train Loss 1.949672 Test MSE 1.5066870341161547 Test RE 0.889363277483187\n",
      "69 Train Loss 1.7767824 Test MSE 1.3416969686313405 Test RE 0.8392568350925844\n",
      "70 Train Loss 1.6583471 Test MSE 1.26884044156973 Test RE 0.8161522342250149\n",
      "71 Train Loss 1.5593396 Test MSE 1.1039091709237974 Test RE 0.761262327277139\n",
      "72 Train Loss 1.4348648 Test MSE 0.9658005026101787 Test RE 0.7120514598816768\n",
      "73 Train Loss 1.29031 Test MSE 0.9440397924423776 Test RE 0.7039840475176841\n",
      "74 Train Loss 1.1771806 Test MSE 0.8651662758376243 Test RE 0.6739341423029827\n",
      "75 Train Loss 1.0424764 Test MSE 0.7416457381416746 Test RE 0.6239731762335878\n",
      "76 Train Loss 0.9470806 Test MSE 0.5938200667300297 Test RE 0.55833532053208\n",
      "77 Train Loss 0.8399497 Test MSE 0.5116272432968476 Test RE 0.5182561907416249\n",
      "78 Train Loss 0.74372727 Test MSE 0.4261745612991263 Test RE 0.4730003139878403\n",
      "79 Train Loss 0.6570849 Test MSE 0.3515377880144119 Test RE 0.4295895174766191\n",
      "80 Train Loss 0.5992082 Test MSE 0.29904392627156956 Test RE 0.3962188751523862\n",
      "81 Train Loss 0.55483305 Test MSE 0.21724613082806807 Test RE 0.3377098227246736\n",
      "82 Train Loss 0.52223057 Test MSE 0.1889267079383495 Test RE 0.3149302269590934\n",
      "83 Train Loss 0.48332852 Test MSE 0.19690511473124428 Test RE 0.32151124437356504\n",
      "84 Train Loss 0.44026247 Test MSE 0.17627633183221492 Test RE 0.3042038246290126\n",
      "85 Train Loss 0.40781856 Test MSE 0.1775727362015072 Test RE 0.3053203918047206\n",
      "86 Train Loss 0.38179296 Test MSE 0.15874825697239464 Test RE 0.28868362520636237\n",
      "87 Train Loss 0.3487109 Test MSE 0.12130587446351189 Test RE 0.25235306511219674\n",
      "88 Train Loss 0.3333229 Test MSE 0.09626776364349071 Test RE 0.22480610918235727\n",
      "89 Train Loss 0.31170377 Test MSE 0.08514402613633094 Test RE 0.2114193624646245\n",
      "90 Train Loss 0.2942172 Test MSE 0.07504488396511738 Test RE 0.1984852382161756\n",
      "91 Train Loss 0.2772813 Test MSE 0.06960424906355804 Test RE 0.19115494788031734\n",
      "92 Train Loss 0.25518006 Test MSE 0.051616490414089986 Test RE 0.16461215620800906\n",
      "93 Train Loss 0.23959956 Test MSE 0.04507583599674291 Test RE 0.1538294767141981\n",
      "94 Train Loss 0.22162029 Test MSE 0.03844477909681226 Test RE 0.1420647569130807\n",
      "95 Train Loss 0.21282393 Test MSE 0.03217086627346929 Test RE 0.12995681090260705\n",
      "96 Train Loss 0.20381862 Test MSE 0.031074836579641475 Test RE 0.12772387743184954\n",
      "97 Train Loss 0.1972881 Test MSE 0.031995851708631055 Test RE 0.12960283609617285\n",
      "98 Train Loss 0.1856729 Test MSE 0.033730733278494504 Test RE 0.1330701231803888\n",
      "99 Train Loss 0.17721523 Test MSE 0.027398008106687997 Test RE 0.11992981467294471\n",
      "100 Train Loss 0.1633274 Test MSE 0.02290775472621109 Test RE 0.1096626988535155\n",
      "101 Train Loss 0.15619867 Test MSE 0.02207983335895512 Test RE 0.10766277346221208\n",
      "102 Train Loss 0.15156884 Test MSE 0.022069326219223948 Test RE 0.10763715364892554\n",
      "103 Train Loss 0.14378834 Test MSE 0.019859270291390223 Test RE 0.10210554106397432\n",
      "104 Train Loss 0.13370147 Test MSE 0.020587050759997873 Test RE 0.10395963243414304\n",
      "105 Train Loss 0.12784953 Test MSE 0.021331449027566986 Test RE 0.105822458385264\n",
      "106 Train Loss 0.12323189 Test MSE 0.02330787590550916 Test RE 0.11061627161574938\n",
      "107 Train Loss 0.11985242 Test MSE 0.023907161796263808 Test RE 0.11202931435822193\n",
      "108 Train Loss 0.109918766 Test MSE 0.0225813887112055 Test RE 0.10887871609195868\n",
      "109 Train Loss 0.10690508 Test MSE 0.023348223226828654 Test RE 0.11071197189495881\n",
      "110 Train Loss 0.1021419 Test MSE 0.024870941635782184 Test RE 0.11426514677501119\n",
      "111 Train Loss 0.09852988 Test MSE 0.02646941579220952 Test RE 0.11787992359471289\n",
      "112 Train Loss 0.09607608 Test MSE 0.026912218384692734 Test RE 0.11886183120889557\n",
      "113 Train Loss 0.09228875 Test MSE 0.02510368743100467 Test RE 0.11479855646571284\n",
      "114 Train Loss 0.089505486 Test MSE 0.02478388670559875 Test RE 0.1140649922256177\n",
      "115 Train Loss 0.08795953 Test MSE 0.02361663688334444 Test RE 0.11134653166458726\n",
      "116 Train Loss 0.08528165 Test MSE 0.022988219627974177 Test RE 0.1098551285190415\n",
      "117 Train Loss 0.081845716 Test MSE 0.022858536332085563 Test RE 0.109544827759855\n",
      "118 Train Loss 0.07806595 Test MSE 0.024000874185662345 Test RE 0.11224866843244882\n",
      "119 Train Loss 0.07628688 Test MSE 0.02325369461458891 Test RE 0.11048762798722121\n",
      "120 Train Loss 0.07379168 Test MSE 0.020085497483345257 Test RE 0.10268546263816057\n",
      "121 Train Loss 0.068188705 Test MSE 0.01605080965742408 Test RE 0.09179438995114915\n",
      "122 Train Loss 0.06595241 Test MSE 0.014564917077084061 Test RE 0.0874423208344688\n",
      "123 Train Loss 0.063969634 Test MSE 0.01445709971171121 Test RE 0.0871180720626536\n",
      "124 Train Loss 0.06282665 Test MSE 0.013906345153469191 Test RE 0.08544254381729155\n",
      "125 Train Loss 0.06030657 Test MSE 0.013117980937516904 Test RE 0.08298529943336311\n",
      "126 Train Loss 0.05865754 Test MSE 0.01161144360447927 Test RE 0.07807478127691553\n",
      "127 Train Loss 0.0577546 Test MSE 0.011508011046130414 Test RE 0.07772626567048843\n",
      "128 Train Loss 0.056292493 Test MSE 0.01078817980127227 Test RE 0.07525610823951799\n",
      "129 Train Loss 0.0545629 Test MSE 0.010165051062334906 Test RE 0.07305037503984599\n",
      "130 Train Loss 0.052966524 Test MSE 0.009653219936706264 Test RE 0.07118750439440248\n",
      "131 Train Loss 0.051384054 Test MSE 0.009065772066464002 Test RE 0.06898744574400792\n",
      "132 Train Loss 0.04899837 Test MSE 0.009286579178201288 Test RE 0.06982252506499188\n",
      "133 Train Loss 0.048179492 Test MSE 0.00826339533488893 Test RE 0.06586382264675596\n",
      "134 Train Loss 0.047294643 Test MSE 0.008575727144850281 Test RE 0.0670970065249911\n",
      "135 Train Loss 0.045768745 Test MSE 0.008200980986195159 Test RE 0.06561461276974638\n",
      "136 Train Loss 0.04334094 Test MSE 0.008166326851595946 Test RE 0.06547583517833933\n",
      "137 Train Loss 0.042493455 Test MSE 0.007778967235427988 Test RE 0.06390408763818138\n",
      "138 Train Loss 0.041605 Test MSE 0.007204568810465683 Test RE 0.06149951126582433\n",
      "139 Train Loss 0.041128706 Test MSE 0.006812354224477162 Test RE 0.05980207849239758\n",
      "140 Train Loss 0.04049374 Test MSE 0.006546634842293936 Test RE 0.05862417261770851\n",
      "141 Train Loss 0.03964114 Test MSE 0.006755467810968938 Test RE 0.059551867083254884\n",
      "142 Train Loss 0.038362414 Test MSE 0.006445690896234781 Test RE 0.058170447549430224\n",
      "143 Train Loss 0.03760137 Test MSE 0.006176744560968893 Test RE 0.05694393676527677\n",
      "144 Train Loss 0.036482017 Test MSE 0.00598258321914586 Test RE 0.05604179561140127\n",
      "145 Train Loss 0.03524147 Test MSE 0.005499331773128498 Test RE 0.05373071605275293\n",
      "146 Train Loss 0.034288745 Test MSE 0.005540142037732399 Test RE 0.05392971401791244\n",
      "147 Train Loss 0.03359251 Test MSE 0.00569504132103101 Test RE 0.05467843898516614\n",
      "148 Train Loss 0.03292373 Test MSE 0.00546741483918373 Test RE 0.05357456842529781\n",
      "149 Train Loss 0.03173312 Test MSE 0.0053221009809005975 Test RE 0.05285781698640889\n",
      "150 Train Loss 0.030038895 Test MSE 0.00465380681987334 Test RE 0.049427864051194155\n",
      "151 Train Loss 0.02915178 Test MSE 0.004345125902270996 Test RE 0.047760498389383704\n",
      "152 Train Loss 0.02862786 Test MSE 0.004201615126475918 Test RE 0.04696515950232929\n",
      "153 Train Loss 0.028295208 Test MSE 0.004022003293748697 Test RE 0.04595035580744327\n",
      "154 Train Loss 0.027350288 Test MSE 0.004222030881918324 Test RE 0.047079123687429794\n",
      "155 Train Loss 0.026827876 Test MSE 0.004022918969394213 Test RE 0.04595558618943358\n",
      "156 Train Loss 0.02628539 Test MSE 0.003924390012576924 Test RE 0.045389327538382325\n",
      "157 Train Loss 0.02595104 Test MSE 0.0038067492128312955 Test RE 0.04470383700481318\n",
      "158 Train Loss 0.025531514 Test MSE 0.003763668807354944 Test RE 0.04445016398457824\n",
      "159 Train Loss 0.024880191 Test MSE 0.003804786401748076 Test RE 0.0446923105690808\n",
      "160 Train Loss 0.024489969 Test MSE 0.004068096693459022 Test RE 0.046212908350420155\n",
      "161 Train Loss 0.024119375 Test MSE 0.0040044793086302325 Test RE 0.04585014301362345\n",
      "162 Train Loss 0.023557456 Test MSE 0.004106992878147587 Test RE 0.046433309899447196\n",
      "163 Train Loss 0.023123013 Test MSE 0.003973697599735343 Test RE 0.04567358217881689\n",
      "164 Train Loss 0.02279179 Test MSE 0.0038783709119863934 Test RE 0.04512241527110516\n",
      "165 Train Loss 0.022406789 Test MSE 0.0035900425422468163 Test RE 0.04341276678105368\n",
      "166 Train Loss 0.021857984 Test MSE 0.003361669983366226 Test RE 0.042009276866691043\n",
      "167 Train Loss 0.021414543 Test MSE 0.0034505396303096273 Test RE 0.04256093669866456\n",
      "168 Train Loss 0.021054057 Test MSE 0.0034087595303916376 Test RE 0.042302482086927544\n",
      "169 Train Loss 0.020687407 Test MSE 0.003253303044318875 Test RE 0.04132662385922229\n",
      "170 Train Loss 0.02046113 Test MSE 0.003284065846108709 Test RE 0.04152155367088124\n",
      "171 Train Loss 0.02019151 Test MSE 0.003213726080194894 Test RE 0.04107448210396147\n",
      "172 Train Loss 0.019488838 Test MSE 0.0030757200050603698 Test RE 0.04018288054810708\n",
      "173 Train Loss 0.018807482 Test MSE 0.003103056643078008 Test RE 0.0403610558840111\n",
      "174 Train Loss 0.018284364 Test MSE 0.0029367877493420174 Test RE 0.03926485044166293\n",
      "175 Train Loss 0.017664885 Test MSE 0.0026650780702042846 Test RE 0.037404395075488595\n",
      "176 Train Loss 0.017305505 Test MSE 0.0024952742886034623 Test RE 0.03619318589714332\n",
      "177 Train Loss 0.017110057 Test MSE 0.0024119228185924945 Test RE 0.03558355798103834\n",
      "178 Train Loss 0.016935844 Test MSE 0.0023426999477656257 Test RE 0.035069211525429224\n",
      "179 Train Loss 0.016659675 Test MSE 0.0021995314984193815 Test RE 0.03398073438228698\n",
      "180 Train Loss 0.01649741 Test MSE 0.002147069623713361 Test RE 0.03357304491594905\n",
      "181 Train Loss 0.01628674 Test MSE 0.0021293539392169283 Test RE 0.033434250759485175\n",
      "182 Train Loss 0.01608506 Test MSE 0.002136566518730714 Test RE 0.0334908273878269\n",
      "183 Train Loss 0.01578503 Test MSE 0.0021527392879033703 Test RE 0.03361734305919577\n",
      "184 Train Loss 0.015163844 Test MSE 0.002027736627395418 Test RE 0.032626721859889664\n",
      "185 Train Loss 0.014526656 Test MSE 0.0020899796156043744 Test RE 0.033123688574077846\n",
      "186 Train Loss 0.013900584 Test MSE 0.0018984064212641339 Test RE 0.03156910464704742\n",
      "187 Train Loss 0.013401747 Test MSE 0.0018235003299495976 Test RE 0.03094002004761444\n",
      "188 Train Loss 0.013006532 Test MSE 0.0015536692557451724 Test RE 0.028559260222642557\n",
      "189 Train Loss 0.012799435 Test MSE 0.0014709582646188267 Test RE 0.027788675220798996\n",
      "190 Train Loss 0.012516645 Test MSE 0.001411590575465127 Test RE 0.027222126180636443\n",
      "191 Train Loss 0.012220812 Test MSE 0.001451719218197977 Test RE 0.027606349424964396\n",
      "192 Train Loss 0.011926291 Test MSE 0.0013735293361483924 Test RE 0.026852618231931826\n",
      "193 Train Loss 0.011738423 Test MSE 0.0013425475164253538 Test RE 0.026548042266773077\n",
      "194 Train Loss 0.011440555 Test MSE 0.0013962293483242055 Test RE 0.027073602542139197\n",
      "195 Train Loss 0.011242642 Test MSE 0.0014105280365161693 Test RE 0.027211878869924874\n",
      "196 Train Loss 0.0108707985 Test MSE 0.0012452378663055199 Test RE 0.02556782746459672\n",
      "197 Train Loss 0.010499841 Test MSE 0.0012253702211150548 Test RE 0.0253630412838061\n",
      "198 Train Loss 0.010162404 Test MSE 0.0012130988439791653 Test RE 0.02523572360185108\n",
      "199 Train Loss 0.009822009 Test MSE 0.0011661633537074817 Test RE 0.024742715558092824\n",
      "200 Train Loss 0.00960603 Test MSE 0.0011640263704757565 Test RE 0.024720034767518412\n",
      "201 Train Loss 0.009486603 Test MSE 0.0011220181107307692 Test RE 0.024269878443366043\n",
      "202 Train Loss 0.009399951 Test MSE 0.0010909108196309324 Test RE 0.023931079647745684\n",
      "203 Train Loss 0.009308664 Test MSE 0.001077262792376984 Test RE 0.02378091155161477\n",
      "204 Train Loss 0.009187298 Test MSE 0.0010104508758771488 Test RE 0.023031661551431448\n",
      "205 Train Loss 0.00901484 Test MSE 0.0009470203165360719 Test RE 0.02229704527405345\n",
      "206 Train Loss 0.008853615 Test MSE 0.0008750308137194879 Test RE 0.021432821203523494\n",
      "207 Train Loss 0.008520285 Test MSE 0.000862970844196537 Test RE 0.021284611581112084\n",
      "208 Train Loss 0.008319 Test MSE 0.000782182259042733 Test RE 0.02026383536398127\n",
      "209 Train Loss 0.008176117 Test MSE 0.0007052229820324877 Test RE 0.019241144274347227\n",
      "210 Train Loss 0.008085639 Test MSE 0.0006438088037321986 Test RE 0.01838425872166485\n",
      "211 Train Loss 0.008006465 Test MSE 0.0006520702089428529 Test RE 0.0185018368580309\n",
      "212 Train Loss 0.007922617 Test MSE 0.000667774290712498 Test RE 0.018723305131638317\n",
      "213 Train Loss 0.007828694 Test MSE 0.0006304869867469829 Test RE 0.018193059138138647\n",
      "214 Train Loss 0.007715844 Test MSE 0.0006123627477987113 Test RE 0.017929659798042317\n",
      "215 Train Loss 0.007646996 Test MSE 0.0006084259903169704 Test RE 0.017871933774949004\n",
      "216 Train Loss 0.0075390516 Test MSE 0.0006385718681585952 Test RE 0.01830933448544366\n",
      "217 Train Loss 0.007378929 Test MSE 0.0006538023593604793 Test RE 0.01852639457380925\n",
      "218 Train Loss 0.0072013675 Test MSE 0.0006658702305553962 Test RE 0.01869659270125735\n",
      "219 Train Loss 0.0070923353 Test MSE 0.0006655841006050495 Test RE 0.01869257522929582\n",
      "220 Train Loss 0.0069568977 Test MSE 0.0006459074870309093 Test RE 0.018414198778967276\n",
      "221 Train Loss 0.0068562785 Test MSE 0.0006213980601888914 Test RE 0.018061450044121137\n",
      "222 Train Loss 0.0067839557 Test MSE 0.0006173045992678847 Test RE 0.018001861829085895\n",
      "223 Train Loss 0.0067165056 Test MSE 0.0005686311242877738 Test RE 0.01727758273533235\n",
      "224 Train Loss 0.006613307 Test MSE 0.0005008587533635129 Test RE 0.016215311715315556\n",
      "225 Train Loss 0.0065079485 Test MSE 0.0004809415606843155 Test RE 0.015889631365562956\n",
      "226 Train Loss 0.006396411 Test MSE 0.00044181148761206993 Test RE 0.015229518386829576\n",
      "227 Train Loss 0.0063209827 Test MSE 0.00041464670051686046 Test RE 0.01475389792973897\n",
      "228 Train Loss 0.006241125 Test MSE 0.00040525386570738014 Test RE 0.014585833469049712\n",
      "229 Train Loss 0.0061911666 Test MSE 0.0003994359684712798 Test RE 0.0144807565583127\n",
      "230 Train Loss 0.006117152 Test MSE 0.000418886919813522 Test RE 0.014829143481640987\n",
      "231 Train Loss 0.005997249 Test MSE 0.00042709617801133085 Test RE 0.01497374766397173\n",
      "232 Train Loss 0.005894505 Test MSE 0.0004277522751007128 Test RE 0.014985244444685542\n",
      "233 Train Loss 0.005804812 Test MSE 0.0004093064987629711 Test RE 0.014658582909790626\n",
      "234 Train Loss 0.0057292734 Test MSE 0.00041111037937965856 Test RE 0.01469084878360458\n",
      "235 Train Loss 0.0056620445 Test MSE 0.0004143467816831685 Test RE 0.014748561130601247\n",
      "236 Train Loss 0.0055879895 Test MSE 0.0004064386088962376 Test RE 0.014607138454713694\n",
      "237 Train Loss 0.0055428613 Test MSE 0.0003743767818643374 Test RE 0.014019164154035908\n",
      "238 Train Loss 0.0054726307 Test MSE 0.0003539751595035238 Test RE 0.013631826837921506\n",
      "239 Train Loss 0.0054354826 Test MSE 0.0003579991354834558 Test RE 0.01370909091592141\n",
      "240 Train Loss 0.0053893137 Test MSE 0.0003848645841236273 Test RE 0.014214174471228616\n",
      "241 Train Loss 0.005321896 Test MSE 0.0003693503655547232 Test RE 0.013924734850140768\n",
      "242 Train Loss 0.0052839136 Test MSE 0.0003603476740379623 Test RE 0.01375398445678161\n",
      "243 Train Loss 0.005239502 Test MSE 0.0003517172341768715 Test RE 0.013588280154675664\n",
      "244 Train Loss 0.005204445 Test MSE 0.0003673824405488181 Test RE 0.01388758931693148\n",
      "245 Train Loss 0.005162917 Test MSE 0.0003714645964558794 Test RE 0.013964531879506532\n",
      "246 Train Loss 0.0051040514 Test MSE 0.0003733685680503684 Test RE 0.014000274302193956\n",
      "247 Train Loss 0.0050585456 Test MSE 0.0003783783343921656 Test RE 0.014093887423881755\n",
      "248 Train Loss 0.005013293 Test MSE 0.0003862844044594947 Test RE 0.014240369392613746\n",
      "249 Train Loss 0.004971794 Test MSE 0.00036048872678607735 Test RE 0.013756676089935313\n",
      "250 Train Loss 0.0049002715 Test MSE 0.00036128372108594004 Test RE 0.013771836697306604\n",
      "251 Train Loss 0.004865534 Test MSE 0.00036631951930195776 Test RE 0.01386748478194222\n",
      "252 Train Loss 0.0048342356 Test MSE 0.0003821635449566631 Test RE 0.014164208011522348\n",
      "253 Train Loss 0.004805057 Test MSE 0.00040354897636981436 Test RE 0.014555120077854491\n",
      "254 Train Loss 0.0047838716 Test MSE 0.00040234684646474204 Test RE 0.014533424823838827\n",
      "255 Train Loss 0.004731397 Test MSE 0.0004056667901126256 Test RE 0.014593262532273405\n",
      "256 Train Loss 0.004628355 Test MSE 0.0004299630028046291 Test RE 0.015023918232592791\n",
      "257 Train Loss 0.004516822 Test MSE 0.0004535453830590774 Test RE 0.01543043050066075\n",
      "258 Train Loss 0.0044053057 Test MSE 0.00043512714466647666 Test RE 0.015113872565139762\n",
      "259 Train Loss 0.004310143 Test MSE 0.00046945253960175345 Test RE 0.01569869363160756\n",
      "260 Train Loss 0.0042324015 Test MSE 0.00047434765972791777 Test RE 0.015780328829841227\n",
      "261 Train Loss 0.0041739997 Test MSE 0.0005012971959732625 Test RE 0.016222407456720905\n",
      "262 Train Loss 0.004144062 Test MSE 0.0004927862015173482 Test RE 0.016084106384671674\n",
      "263 Train Loss 0.00411627 Test MSE 0.0004906562066706254 Test RE 0.01604930816613964\n",
      "264 Train Loss 0.0040867208 Test MSE 0.000500478727021404 Test RE 0.0162091588679311\n",
      "265 Train Loss 0.0040472806 Test MSE 0.00047434085330911165 Test RE 0.01578021561339543\n",
      "266 Train Loss 0.0040215356 Test MSE 0.00045783264954395706 Test RE 0.015503189224297269\n",
      "267 Train Loss 0.0039987126 Test MSE 0.0004707864123139414 Test RE 0.015720980448635718\n",
      "268 Train Loss 0.0039754687 Test MSE 0.0004666473938639211 Test RE 0.01565172072012593\n",
      "269 Train Loss 0.0039548883 Test MSE 0.0004768097921219912 Test RE 0.01582123023500077\n",
      "270 Train Loss 0.0039173802 Test MSE 0.00046039250677581457 Test RE 0.015546469920975135\n",
      "271 Train Loss 0.0038744241 Test MSE 0.00042167163871954387 Test RE 0.014878353173065982\n",
      "272 Train Loss 0.003826971 Test MSE 0.0003835140438558265 Test RE 0.014189212852989153\n",
      "273 Train Loss 0.0037683807 Test MSE 0.0003472381101489779 Test RE 0.013501479445673927\n",
      "274 Train Loss 0.003660049 Test MSE 0.0002684324689447261 Test RE 0.01187094220535699\n",
      "275 Train Loss 0.00361524 Test MSE 0.0002635786218449226 Test RE 0.011763126274384307\n",
      "276 Train Loss 0.0035621999 Test MSE 0.0002664026681078848 Test RE 0.011825974894842751\n",
      "277 Train Loss 0.0035398668 Test MSE 0.00022892881367686792 Test RE 0.010962709262559444\n",
      "278 Train Loss 0.0035117608 Test MSE 0.00021283946808826684 Test RE 0.010570456664758865\n",
      "279 Train Loss 0.003492375 Test MSE 0.000197463029795608 Test RE 0.01018147187310524\n",
      "280 Train Loss 0.003474658 Test MSE 0.0001991997490170661 Test RE 0.010226147699683887\n",
      "281 Train Loss 0.003450144 Test MSE 0.00019201559924385793 Test RE 0.010040051110067604\n",
      "282 Train Loss 0.0034342816 Test MSE 0.0001866376599595527 Test RE 0.009898452605570682\n",
      "283 Train Loss 0.0034098856 Test MSE 0.0001856337226964156 Test RE 0.0098717944675159\n",
      "284 Train Loss 0.0033925397 Test MSE 0.000181171526393318 Test RE 0.009752425453903646\n",
      "285 Train Loss 0.0033720403 Test MSE 0.0001855689942420112 Test RE 0.00987007322392833\n",
      "286 Train Loss 0.0033550272 Test MSE 0.00020073772418671362 Test RE 0.010265548654588393\n",
      "287 Train Loss 0.0033125896 Test MSE 0.00018015026641566567 Test RE 0.009724899502558913\n",
      "288 Train Loss 0.0032798036 Test MSE 0.00018672269608525062 Test RE 0.009900707322557822\n",
      "289 Train Loss 0.003245023 Test MSE 0.00017573258930622966 Test RE 0.009604921542977266\n",
      "290 Train Loss 0.0032140315 Test MSE 0.00017587676404065116 Test RE 0.009608860775612982\n",
      "291 Train Loss 0.0031907975 Test MSE 0.00016800902720205828 Test RE 0.009391478665179675\n",
      "292 Train Loss 0.0031566143 Test MSE 0.0001611796008753999 Test RE 0.009198620579603377\n",
      "293 Train Loss 0.0031282026 Test MSE 0.00016933091301599693 Test RE 0.00942835209734734\n",
      "294 Train Loss 0.0030994706 Test MSE 0.00016495735103289478 Test RE 0.00930579550315824\n",
      "295 Train Loss 0.0030843979 Test MSE 0.00016283210462810532 Test RE 0.009245655042197815\n",
      "296 Train Loss 0.0030714278 Test MSE 0.00015058153166091256 Test RE 0.008891059626956223\n",
      "297 Train Loss 0.0030265201 Test MSE 0.00013062787018416327 Test RE 0.008281053504031181\n",
      "298 Train Loss 0.0030005 Test MSE 0.00013024917033821603 Test RE 0.00826904109855906\n",
      "299 Train Loss 0.0029610414 Test MSE 0.00012196649558597714 Test RE 0.008001804572750673\n",
      "Training time: 165.68\n",
      "KG_tanh_medium\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 31906.137 Test MSE 13.057330474551295 Test RE 2.618152055597079\n",
      "1 Train Loss 9486.88 Test MSE 8.983565577314547 Test RE 2.1716610336941837\n",
      "2 Train Loss 2596.479 Test MSE 15.149171545935237 Test RE 2.8200844209582825\n",
      "3 Train Loss 1068.379 Test MSE 21.632246523256914 Test RE 3.3699113740373092\n",
      "4 Train Loss 496.14224 Test MSE 23.653577923617682 Test RE 3.5238392542191104\n",
      "5 Train Loss 282.137 Test MSE 22.642232035832254 Test RE 3.447682671075652\n",
      "6 Train Loss 178.31725 Test MSE 21.171024904873594 Test RE 3.3337928373386267\n",
      "7 Train Loss 133.89189 Test MSE 20.205223747061524 Test RE 3.2568630700121095\n",
      "8 Train Loss 104.2686 Test MSE 19.926865355967408 Test RE 3.234351088923909\n",
      "9 Train Loss 90.822525 Test MSE 19.918029537608327 Test RE 3.233633933794435\n",
      "10 Train Loss 75.04356 Test MSE 18.828708850901517 Test RE 3.1439667012222023\n",
      "11 Train Loss 64.08622 Test MSE 18.71434542588403 Test RE 3.134404111427967\n",
      "12 Train Loss 54.284378 Test MSE 18.52899558785089 Test RE 3.1188436701686135\n",
      "13 Train Loss 47.39842 Test MSE 18.268808135277666 Test RE 3.0968685740305917\n",
      "14 Train Loss 40.434166 Test MSE 17.43048983450524 Test RE 3.024979693434907\n",
      "15 Train Loss 35.465195 Test MSE 17.34513525881998 Test RE 3.0175641611166633\n",
      "16 Train Loss 31.570784 Test MSE 17.091136189065477 Test RE 2.9953883411012994\n",
      "17 Train Loss 29.229832 Test MSE 16.987483862338223 Test RE 2.986291487048021\n",
      "18 Train Loss 27.309158 Test MSE 16.906829256022085 Test RE 2.9791937691468102\n",
      "19 Train Loss 25.801804 Test MSE 16.940756228215463 Test RE 2.982181448462026\n",
      "20 Train Loss 24.556532 Test MSE 16.67950488883972 Test RE 2.959097296080581\n",
      "21 Train Loss 23.647223 Test MSE 16.5346636689465 Test RE 2.946221200749196\n",
      "22 Train Loss 22.568373 Test MSE 16.503991597030467 Test RE 2.9434872880066627\n",
      "23 Train Loss 21.636044 Test MSE 16.406105696737402 Test RE 2.9347453301901187\n",
      "24 Train Loss 20.832993 Test MSE 16.26030983879979 Test RE 2.921676154509767\n",
      "25 Train Loss 20.126793 Test MSE 16.003548409435577 Test RE 2.898516731126494\n",
      "26 Train Loss 19.672028 Test MSE 15.831292460105635 Test RE 2.8828752761837553\n",
      "27 Train Loss 19.195633 Test MSE 15.757127132134839 Test RE 2.8761146030113753\n",
      "28 Train Loss 18.725224 Test MSE 15.640806948875094 Test RE 2.8654791019329053\n",
      "29 Train Loss 18.378002 Test MSE 15.559208492497849 Test RE 2.857994691770123\n",
      "30 Train Loss 17.920424 Test MSE 15.539325355803028 Test RE 2.8561679900698986\n",
      "31 Train Loss 17.547009 Test MSE 15.280277266300608 Test RE 2.8322610836518085\n",
      "32 Train Loss 17.243572 Test MSE 15.144410550536465 Test RE 2.8196412460965004\n",
      "33 Train Loss 16.851511 Test MSE 14.951578241943444 Test RE 2.801632627888647\n",
      "34 Train Loss 16.513811 Test MSE 14.824295762870559 Test RE 2.789682019141301\n",
      "35 Train Loss 16.123447 Test MSE 14.43083804327038 Test RE 2.752412008560378\n",
      "36 Train Loss 15.624623 Test MSE 14.024534166236773 Test RE 2.713387937865956\n",
      "37 Train Loss 14.992359 Test MSE 13.579971979081577 Test RE 2.6700359236343933\n",
      "38 Train Loss 14.479744 Test MSE 13.176232507462593 Test RE 2.6300456856356798\n",
      "39 Train Loss 14.090518 Test MSE 12.813752411160136 Test RE 2.5936169262610353\n",
      "40 Train Loss 13.536179 Test MSE 12.731382234133706 Test RE 2.5852672596422503\n",
      "41 Train Loss 12.901176 Test MSE 11.867374128308393 Test RE 2.4960023199742905\n",
      "42 Train Loss 11.840994 Test MSE 10.598050885986021 Test RE 2.3587432364459917\n",
      "43 Train Loss 11.135293 Test MSE 9.406295541702226 Test RE 2.2221684519227693\n",
      "44 Train Loss 10.194801 Test MSE 8.316479675431745 Test RE 2.0894762201097206\n",
      "45 Train Loss 9.511147 Test MSE 7.258077652662194 Test RE 1.9519939748280348\n",
      "46 Train Loss 8.760428 Test MSE 6.8534746379479605 Test RE 1.8968066895949762\n",
      "47 Train Loss 7.6096873 Test MSE 6.163525639315824 Test RE 1.7987974826129562\n",
      "48 Train Loss 6.684503 Test MSE 5.177555631796739 Test RE 1.6486560272638473\n",
      "49 Train Loss 5.709393 Test MSE 4.8048479886239415 Test RE 1.5882084189766603\n",
      "50 Train Loss 5.005648 Test MSE 3.9851098093161297 Test RE 1.4463980048474177\n",
      "51 Train Loss 4.3741617 Test MSE 2.519074527201507 Test RE 1.1499744088802986\n",
      "52 Train Loss 3.6041112 Test MSE 1.491166584987181 Test RE 0.8847707348349154\n",
      "53 Train Loss 3.0724728 Test MSE 1.1450972088458413 Test RE 0.775334029622319\n",
      "54 Train Loss 2.6434162 Test MSE 1.0284201163128073 Test RE 0.7347725936789183\n",
      "55 Train Loss 2.108562 Test MSE 0.6150850783238907 Test RE 0.568244529339766\n",
      "56 Train Loss 1.7291155 Test MSE 0.7285156021182372 Test RE 0.618425083311674\n",
      "57 Train Loss 1.4501386 Test MSE 0.5730618349853669 Test RE 0.5484896169669338\n",
      "58 Train Loss 1.2215421 Test MSE 0.563272364772893 Test RE 0.5437845820648669\n",
      "59 Train Loss 1.1022567 Test MSE 0.44407856428032605 Test RE 0.4828336979344989\n",
      "60 Train Loss 0.9084574 Test MSE 0.4348525094141966 Test RE 0.4777917625544679\n",
      "61 Train Loss 0.7400798 Test MSE 0.3356786845641704 Test RE 0.41978754591306716\n",
      "62 Train Loss 0.6330005 Test MSE 0.3281580256129433 Test RE 0.4150583761978906\n",
      "63 Train Loss 0.55779034 Test MSE 0.2011180845432012 Test RE 0.3249325581510927\n",
      "64 Train Loss 0.4558476 Test MSE 0.15862522187133926 Test RE 0.2885717338877053\n",
      "65 Train Loss 0.40088338 Test MSE 0.1174766194072282 Test RE 0.24833811933092748\n",
      "66 Train Loss 0.35955665 Test MSE 0.06997301433769346 Test RE 0.19166065110953376\n",
      "67 Train Loss 0.31772014 Test MSE 0.05500941424766232 Test RE 0.1699363077159963\n",
      "68 Train Loss 0.26849556 Test MSE 0.03003742736759554 Test RE 0.125573799365105\n",
      "69 Train Loss 0.23750986 Test MSE 0.03596729816392634 Test RE 0.13741102374849132\n",
      "70 Train Loss 0.22500008 Test MSE 0.03132703108023747 Test RE 0.12824111537316027\n",
      "71 Train Loss 0.19276446 Test MSE 0.023339764752113377 Test RE 0.11069191599531507\n",
      "72 Train Loss 0.1666901 Test MSE 0.02639999286689058 Test RE 0.11772523672649213\n",
      "73 Train Loss 0.15616266 Test MSE 0.02284948776804732 Test RE 0.10952314392393171\n",
      "74 Train Loss 0.13362388 Test MSE 0.025925590455172863 Test RE 0.11666269258474361\n",
      "75 Train Loss 0.12572867 Test MSE 0.024744807472590023 Test RE 0.11397502790678254\n",
      "76 Train Loss 0.11923525 Test MSE 0.021575547891681313 Test RE 0.10642620697004465\n",
      "77 Train Loss 0.110093 Test MSE 0.02030666680959181 Test RE 0.10324926985458496\n",
      "78 Train Loss 0.10449663 Test MSE 0.01968573982486704 Test RE 0.10165846275042088\n",
      "79 Train Loss 0.09780955 Test MSE 0.01949104381795996 Test RE 0.10115450205563165\n",
      "80 Train Loss 0.09254982 Test MSE 0.018026486973970298 Test RE 0.09727992277934992\n",
      "81 Train Loss 0.07891721 Test MSE 0.014303784200805615 Test RE 0.0866549033738561\n",
      "82 Train Loss 0.07714174 Test MSE 0.01373960861527534 Test RE 0.08492877275877986\n",
      "83 Train Loss 0.07148513 Test MSE 0.011140246474382715 Test RE 0.07647422199823779\n",
      "84 Train Loss 0.06420342 Test MSE 0.00969977638589254 Test RE 0.0713589627785859\n",
      "85 Train Loss 0.061747298 Test MSE 0.009854938619040417 Test RE 0.0719274443150087\n",
      "86 Train Loss 0.059245337 Test MSE 0.008918343445312478 Test RE 0.06842420562680872\n",
      "87 Train Loss 0.05383678 Test MSE 0.008475589283333303 Test RE 0.06670411388088897\n",
      "88 Train Loss 0.051994327 Test MSE 0.008344507125237141 Test RE 0.06618628614378029\n",
      "89 Train Loss 0.049683504 Test MSE 0.008537039713440464 Test RE 0.06694548904910635\n",
      "90 Train Loss 0.044493947 Test MSE 0.007010896906132987 Test RE 0.06066727080938566\n",
      "91 Train Loss 0.04267951 Test MSE 0.006521252024750116 Test RE 0.05851041250343687\n",
      "92 Train Loss 0.04120453 Test MSE 0.0065757423846421175 Test RE 0.05875435500032694\n",
      "93 Train Loss 0.039502494 Test MSE 0.0064614482080120675 Test RE 0.058241506679034515\n",
      "94 Train Loss 0.037586816 Test MSE 0.006820734742895463 Test RE 0.059838851270473795\n",
      "95 Train Loss 0.0358644 Test MSE 0.006839314028654094 Test RE 0.0599202946262068\n",
      "96 Train Loss 0.03513087 Test MSE 0.006778837709970134 Test RE 0.05965478516410943\n",
      "97 Train Loss 0.033060774 Test MSE 0.006471764477067411 Test RE 0.058287981974010236\n",
      "98 Train Loss 0.03202888 Test MSE 0.006229025862943374 Test RE 0.05718442185689004\n",
      "99 Train Loss 0.03133066 Test MSE 0.006307292833836833 Test RE 0.05754255812161674\n",
      "100 Train Loss 0.031048704 Test MSE 0.006269267649562851 Test RE 0.05736884062928097\n",
      "101 Train Loss 0.030816805 Test MSE 0.006266722748363013 Test RE 0.05735719550110437\n",
      "102 Train Loss 0.030045351 Test MSE 0.0064968222183038535 Test RE 0.05840071429998281\n",
      "103 Train Loss 0.028658401 Test MSE 0.005971519209003774 Test RE 0.055989950621388146\n",
      "104 Train Loss 0.027739584 Test MSE 0.005741782085618948 Test RE 0.054902360942246674\n",
      "105 Train Loss 0.027473683 Test MSE 0.005691966415279257 Test RE 0.05466367581332951\n",
      "106 Train Loss 0.027117457 Test MSE 0.005623149780947001 Test RE 0.05433222537536869\n",
      "107 Train Loss 0.026566517 Test MSE 0.005564524108854384 Test RE 0.05404825561445759\n",
      "108 Train Loss 0.025571002 Test MSE 0.005660988325510086 Test RE 0.054514721441377555\n",
      "109 Train Loss 0.024724692 Test MSE 0.0054780201391777545 Test RE 0.05362650330931605\n",
      "110 Train Loss 0.024400806 Test MSE 0.005342653757666067 Test RE 0.052959781239072745\n",
      "111 Train Loss 0.023709398 Test MSE 0.0052524418325529555 Test RE 0.05251075872557961\n",
      "112 Train Loss 0.02308013 Test MSE 0.005222919908995099 Test RE 0.052362979550569455\n",
      "113 Train Loss 0.022541953 Test MSE 0.0049826462947393756 Test RE 0.05114435395456135\n",
      "114 Train Loss 0.02208187 Test MSE 0.004982607412474166 Test RE 0.05114415440074032\n",
      "115 Train Loss 0.021802275 Test MSE 0.00500075066705905 Test RE 0.05123718583563424\n",
      "116 Train Loss 0.02081929 Test MSE 0.004670109504782235 Test RE 0.04951436338982076\n",
      "117 Train Loss 0.019784033 Test MSE 0.004283368271955983 Test RE 0.04741987178182129\n",
      "118 Train Loss 0.018768756 Test MSE 0.004008391821410962 Test RE 0.04587253612153477\n",
      "119 Train Loss 0.018122701 Test MSE 0.003932553181326195 Test RE 0.045436510445528655\n",
      "120 Train Loss 0.017875535 Test MSE 0.004031080488114022 Test RE 0.04600217889270985\n",
      "121 Train Loss 0.017553078 Test MSE 0.004069685931631917 Test RE 0.04622193421093231\n",
      "122 Train Loss 0.017062807 Test MSE 0.0039557253071118015 Test RE 0.04557017858350977\n",
      "123 Train Loss 0.016059346 Test MSE 0.004111337141210776 Test RE 0.04645786134185457\n",
      "124 Train Loss 0.015631326 Test MSE 0.0039013443440712946 Test RE 0.04525585869396722\n",
      "125 Train Loss 0.01510261 Test MSE 0.004058270372856709 Test RE 0.04615706191460056\n",
      "126 Train Loss 0.01479905 Test MSE 0.004051999969757274 Test RE 0.0461213896650441\n",
      "127 Train Loss 0.014499741 Test MSE 0.003846058028128239 Test RE 0.04493405203273832\n",
      "128 Train Loss 0.0142740905 Test MSE 0.0038221693205138293 Test RE 0.04479428705444543\n",
      "129 Train Loss 0.014061829 Test MSE 0.00387572816549419 Test RE 0.04510703930162712\n",
      "130 Train Loss 0.013902276 Test MSE 0.0037905432042758197 Test RE 0.044608579421469306\n",
      "131 Train Loss 0.013584061 Test MSE 0.003675681717085144 Test RE 0.04392751307704093\n",
      "132 Train Loss 0.012920205 Test MSE 0.0036006554028986254 Test RE 0.0434768876984037\n",
      "133 Train Loss 0.012790162 Test MSE 0.0035315874271237804 Test RE 0.04305788055373245\n",
      "134 Train Loss 0.012623004 Test MSE 0.0032664310577230427 Test RE 0.041409922316734724\n",
      "135 Train Loss 0.012426879 Test MSE 0.003103554320537263 Test RE 0.0403642923673766\n",
      "136 Train Loss 0.012273617 Test MSE 0.003080214377792042 Test RE 0.04021222829701333\n",
      "137 Train Loss 0.011980906 Test MSE 0.00310713688620339 Test RE 0.04038758276370733\n",
      "138 Train Loss 0.011665209 Test MSE 0.0029475186082693534 Test RE 0.03933652082016746\n",
      "139 Train Loss 0.01147895 Test MSE 0.00282686139482442 Test RE 0.03852298442494953\n",
      "140 Train Loss 0.011130124 Test MSE 0.002871649940795042 Test RE 0.038826962512808934\n",
      "141 Train Loss 0.010896952 Test MSE 0.0029075913913579163 Test RE 0.03906918527659638\n",
      "142 Train Loss 0.01073083 Test MSE 0.002900703674167037 Test RE 0.039022882853668714\n",
      "143 Train Loss 0.010615216 Test MSE 0.0028161027116393083 Test RE 0.03844960769691178\n",
      "144 Train Loss 0.010476704 Test MSE 0.002637481118855591 Test RE 0.03721022938759882\n",
      "145 Train Loss 0.010291398 Test MSE 0.002527806524866477 Test RE 0.03642835690584479\n",
      "146 Train Loss 0.01004076 Test MSE 0.002438629012424559 Test RE 0.035780016441965413\n",
      "147 Train Loss 0.009750462 Test MSE 0.002305810028774664 Test RE 0.0347920027932396\n",
      "148 Train Loss 0.009569796 Test MSE 0.0021888357985165086 Test RE 0.03389801434596725\n",
      "149 Train Loss 0.009358935 Test MSE 0.002140477391021398 Test RE 0.033521464970422486\n",
      "150 Train Loss 0.009127495 Test MSE 0.0020647792115096077 Test RE 0.03292338474002335\n",
      "151 Train Loss 0.008812692 Test MSE 0.0019227458590933423 Test RE 0.03177083360386804\n",
      "152 Train Loss 0.0086320555 Test MSE 0.0019578463425032095 Test RE 0.032059516601171845\n",
      "153 Train Loss 0.008372027 Test MSE 0.0019260164804613415 Test RE 0.031797843469997096\n",
      "154 Train Loss 0.008085326 Test MSE 0.0017883349962810463 Test RE 0.03064023595248171\n",
      "155 Train Loss 0.007949044 Test MSE 0.0018519534718203705 Test RE 0.031180473307020073\n",
      "156 Train Loss 0.0077573247 Test MSE 0.0017418348229291216 Test RE 0.03023925950604211\n",
      "157 Train Loss 0.0076197363 Test MSE 0.0017283763032012107 Test RE 0.03012220912471829\n",
      "158 Train Loss 0.007528579 Test MSE 0.0017783058333720933 Test RE 0.030554198390298153\n",
      "159 Train Loss 0.0073964354 Test MSE 0.0017967957818277411 Test RE 0.03071263138351327\n",
      "160 Train Loss 0.007267036 Test MSE 0.0017642120039950547 Test RE 0.030432880034501772\n",
      "161 Train Loss 0.00709479 Test MSE 0.0016908996116912927 Test RE 0.0297938467696099\n",
      "162 Train Loss 0.006976749 Test MSE 0.0015808884723353708 Test RE 0.02880834331484734\n",
      "163 Train Loss 0.006840261 Test MSE 0.0016114752478803857 Test RE 0.029085697782756666\n",
      "164 Train Loss 0.006716042 Test MSE 0.0015983206099538848 Test RE 0.028966739749765862\n",
      "165 Train Loss 0.0066135316 Test MSE 0.0015939129550779215 Test RE 0.028926771693791566\n",
      "166 Train Loss 0.0065560485 Test MSE 0.0015273245239436981 Test RE 0.028316093013700836\n",
      "167 Train Loss 0.006502342 Test MSE 0.001565990622918925 Test RE 0.02867228113075674\n",
      "168 Train Loss 0.0064250613 Test MSE 0.0015275210440906946 Test RE 0.02831791466446477\n",
      "169 Train Loss 0.006252691 Test MSE 0.0014638335225721235 Test RE 0.027721294835906383\n",
      "170 Train Loss 0.006058627 Test MSE 0.0014320774437899969 Test RE 0.027418956327593853\n",
      "171 Train Loss 0.005920156 Test MSE 0.0014178470782714645 Test RE 0.02728238692814074\n",
      "172 Train Loss 0.005812006 Test MSE 0.0013671883308129468 Test RE 0.02679056292480829\n",
      "173 Train Loss 0.0057479865 Test MSE 0.0013685698125505388 Test RE 0.02680409483109575\n",
      "174 Train Loss 0.005655138 Test MSE 0.001377805143938837 Test RE 0.026894381961962602\n",
      "175 Train Loss 0.00558853 Test MSE 0.0013518043596851747 Test RE 0.02663940920345676\n",
      "176 Train Loss 0.0055522565 Test MSE 0.001330238560407656 Test RE 0.02642606105569221\n",
      "177 Train Loss 0.00550975 Test MSE 0.0013237684150064712 Test RE 0.02636171587822952\n",
      "178 Train Loss 0.0054570427 Test MSE 0.001260808923577785 Test RE 0.02572718708261074\n",
      "179 Train Loss 0.005432158 Test MSE 0.0012221232749967438 Test RE 0.02532941591364523\n",
      "180 Train Loss 0.005378217 Test MSE 0.0012301009511181645 Test RE 0.025411953080218028\n",
      "181 Train Loss 0.0052636433 Test MSE 0.0013017611622926552 Test RE 0.026141669686359482\n",
      "182 Train Loss 0.0051332773 Test MSE 0.0013262256392021466 Test RE 0.02638617129394733\n",
      "183 Train Loss 0.005051634 Test MSE 0.0013450119286388424 Test RE 0.026572397204777994\n",
      "184 Train Loss 0.0049514407 Test MSE 0.0013278033457376172 Test RE 0.026401861407359384\n",
      "185 Train Loss 0.0049175425 Test MSE 0.0013174860529875725 Test RE 0.02629908755080365\n",
      "186 Train Loss 0.004886788 Test MSE 0.0012993103460593994 Test RE 0.02611704972764544\n",
      "187 Train Loss 0.004861548 Test MSE 0.0012729840303379333 Test RE 0.025851107006870717\n",
      "188 Train Loss 0.004830054 Test MSE 0.0012510338974913706 Test RE 0.02562726184558681\n",
      "189 Train Loss 0.004759147 Test MSE 0.0012379847649705447 Test RE 0.025493256622178082\n",
      "190 Train Loss 0.0046833237 Test MSE 0.0012629942292042401 Test RE 0.02574947334067632\n",
      "191 Train Loss 0.004619828 Test MSE 0.0012662666921903559 Test RE 0.025782810660905847\n",
      "192 Train Loss 0.0045853057 Test MSE 0.0012747854502237214 Test RE 0.025869391696129698\n",
      "193 Train Loss 0.00453052 Test MSE 0.0012273890203809588 Test RE 0.025383925509809082\n",
      "194 Train Loss 0.0044752867 Test MSE 0.0012412826255268656 Test RE 0.025527189709144544\n",
      "195 Train Loss 0.0044038896 Test MSE 0.001261097799374205 Test RE 0.025730134212769106\n",
      "196 Train Loss 0.004347687 Test MSE 0.0012322582714051574 Test RE 0.025434226742666235\n",
      "197 Train Loss 0.0042891316 Test MSE 0.0012017574191769747 Test RE 0.025117480492387625\n",
      "198 Train Loss 0.004266495 Test MSE 0.0011958186041953018 Test RE 0.025055341156860932\n",
      "199 Train Loss 0.0042329943 Test MSE 0.001191762416726057 Test RE 0.025012811509027694\n",
      "200 Train Loss 0.0042045536 Test MSE 0.0011729846164339336 Test RE 0.02481497407788548\n",
      "201 Train Loss 0.0041796616 Test MSE 0.0011581423636119498 Test RE 0.024657477279365937\n",
      "202 Train Loss 0.0041431766 Test MSE 0.0011331517104424594 Test RE 0.02438999419696865\n",
      "203 Train Loss 0.004073065 Test MSE 0.001095881366253707 Test RE 0.02398553660168898\n",
      "204 Train Loss 0.0040056384 Test MSE 0.0010961061458651918 Test RE 0.02398799634930775\n",
      "205 Train Loss 0.0038962106 Test MSE 0.001070701421284199 Test RE 0.023708378782743927\n",
      "206 Train Loss 0.0038589125 Test MSE 0.001031008442912195 Test RE 0.023264770811124852\n",
      "207 Train Loss 0.0038274713 Test MSE 0.001048404142540765 Test RE 0.023460217373028076\n",
      "208 Train Loss 0.0037895045 Test MSE 0.001025072115252958 Test RE 0.023197697318216658\n",
      "209 Train Loss 0.0037699617 Test MSE 0.0010253149284953857 Test RE 0.023200444624721945\n",
      "210 Train Loss 0.0037603863 Test MSE 0.0010199924187810445 Test RE 0.023140148387488933\n",
      "211 Train Loss 0.0037458988 Test MSE 0.0010177527883182046 Test RE 0.023114729639156985\n",
      "212 Train Loss 0.0037313302 Test MSE 0.0009955688142808696 Test RE 0.022861425648084327\n",
      "213 Train Loss 0.003707054 Test MSE 0.000979308019157333 Test RE 0.022673957227414686\n",
      "214 Train Loss 0.0036790671 Test MSE 0.0009873315560213728 Test RE 0.022766652383179885\n",
      "215 Train Loss 0.0036556697 Test MSE 0.0009985234938969078 Test RE 0.022895324934464785\n",
      "216 Train Loss 0.003624355 Test MSE 0.001011654494346107 Test RE 0.023045374777668205\n",
      "217 Train Loss 0.0035705806 Test MSE 0.000992659995899362 Test RE 0.02282800335750879\n",
      "218 Train Loss 0.0035092528 Test MSE 0.0009822535285127641 Test RE 0.022708030373005506\n",
      "219 Train Loss 0.0034413696 Test MSE 0.0009734761952099366 Test RE 0.022606344192393595\n",
      "220 Train Loss 0.0033624605 Test MSE 0.0008848434419070945 Test RE 0.021552660398133257\n",
      "221 Train Loss 0.003288184 Test MSE 0.0008870061695964278 Test RE 0.02157898374838296\n",
      "222 Train Loss 0.003252998 Test MSE 0.0009104231214937309 Test RE 0.02186197065441618\n",
      "223 Train Loss 0.0032289915 Test MSE 0.0009064053347224957 Test RE 0.021813677801963534\n",
      "224 Train Loss 0.0032142538 Test MSE 0.0009149402788602035 Test RE 0.02191613874831415\n",
      "225 Train Loss 0.003199458 Test MSE 0.0008963972930645213 Test RE 0.02169291606360555\n",
      "226 Train Loss 0.0031855572 Test MSE 0.0008930784792592366 Test RE 0.021652720989556593\n",
      "227 Train Loss 0.0031654548 Test MSE 0.0008728782555575206 Test RE 0.021406442816911807\n",
      "228 Train Loss 0.003137316 Test MSE 0.0008701570179868167 Test RE 0.021373048991477822\n",
      "229 Train Loss 0.0031182326 Test MSE 0.0008689562733177717 Test RE 0.021358297381352812\n",
      "230 Train Loss 0.0030954324 Test MSE 0.0008486114957884343 Test RE 0.021106786782481155\n",
      "231 Train Loss 0.0030728264 Test MSE 0.0008649351376161756 Test RE 0.021308821818491395\n",
      "232 Train Loss 0.0030566652 Test MSE 0.0008771176376966114 Test RE 0.021458363098526067\n",
      "233 Train Loss 0.003036805 Test MSE 0.0008598979431421992 Test RE 0.02124668223834306\n",
      "234 Train Loss 0.003027455 Test MSE 0.0008630186651431067 Test RE 0.021285201309131016\n",
      "235 Train Loss 0.0030132355 Test MSE 0.0008530586036590604 Test RE 0.021162019068750596\n",
      "236 Train Loss 0.0030030096 Test MSE 0.0008512533173588163 Test RE 0.021139615135179105\n",
      "237 Train Loss 0.0029915015 Test MSE 0.0008500484490873334 Test RE 0.021124649278269188\n",
      "238 Train Loss 0.0029804504 Test MSE 0.0008494171025052789 Test RE 0.021116802988768068\n",
      "239 Train Loss 0.002967384 Test MSE 0.0008505014730017141 Test RE 0.021130277602515478\n",
      "240 Train Loss 0.0029452525 Test MSE 0.0008477499173455808 Test RE 0.021096069410231975\n",
      "241 Train Loss 0.002933203 Test MSE 0.0008476380179576515 Test RE 0.021094677068510627\n",
      "242 Train Loss 0.0029136734 Test MSE 0.0008456483025919898 Test RE 0.02106990407444317\n",
      "243 Train Loss 0.0029034554 Test MSE 0.0008409861516828026 Test RE 0.02101174346779532\n",
      "244 Train Loss 0.0028937957 Test MSE 0.0008376337893798461 Test RE 0.02096982285275959\n",
      "245 Train Loss 0.0028852795 Test MSE 0.0008343390719770916 Test RE 0.020928541260638436\n",
      "246 Train Loss 0.0028755579 Test MSE 0.0008226643756577077 Test RE 0.02078160152596804\n",
      "247 Train Loss 0.0028615713 Test MSE 0.0008154291626518786 Test RE 0.020690014132027\n",
      "248 Train Loss 0.002844456 Test MSE 0.0008070967815159173 Test RE 0.020584033280749713\n",
      "249 Train Loss 0.0028137765 Test MSE 0.0008075077658327736 Test RE 0.020589273444243293\n",
      "250 Train Loss 0.0027752824 Test MSE 0.0007768570264370467 Test RE 0.020194737701433263\n",
      "251 Train Loss 0.002748725 Test MSE 0.0007603656306248303 Test RE 0.0199792373687566\n",
      "252 Train Loss 0.0027085121 Test MSE 0.0007325875531574942 Test RE 0.019610895950647595\n",
      "253 Train Loss 0.0026573767 Test MSE 0.0007259075163615426 Test RE 0.01952128105969046\n",
      "254 Train Loss 0.0026235047 Test MSE 0.0006901989229943089 Test RE 0.019035084378236245\n",
      "255 Train Loss 0.00258904 Test MSE 0.0006879756172366438 Test RE 0.01900440123182329\n",
      "256 Train Loss 0.0025675658 Test MSE 0.0006908910590583585 Test RE 0.01904462624119436\n",
      "257 Train Loss 0.0025290311 Test MSE 0.0006425140719492919 Test RE 0.018365763585313666\n",
      "258 Train Loss 0.0025078822 Test MSE 0.0006227744056328194 Test RE 0.01808144129147856\n",
      "259 Train Loss 0.002496586 Test MSE 0.0006150812474969952 Test RE 0.0179694138482991\n",
      "260 Train Loss 0.0024761877 Test MSE 0.0005960522882989891 Test RE 0.01768926741848619\n",
      "261 Train Loss 0.0024549102 Test MSE 0.0005875343491146301 Test RE 0.01756241755918179\n",
      "262 Train Loss 0.0024299144 Test MSE 0.0005518759315329997 Test RE 0.017021130233679804\n",
      "263 Train Loss 0.002412427 Test MSE 0.0005599778587827231 Test RE 0.017145616101472427\n",
      "264 Train Loss 0.0023974879 Test MSE 0.0005589147657823709 Test RE 0.01712933327584916\n",
      "265 Train Loss 0.0023867716 Test MSE 0.0005528071846441633 Test RE 0.017035485180465163\n",
      "266 Train Loss 0.0023727862 Test MSE 0.0005214048700701759 Test RE 0.016544559529001746\n",
      "267 Train Loss 0.0023610194 Test MSE 0.0005279427562713366 Test RE 0.01664796236302432\n",
      "268 Train Loss 0.0023548184 Test MSE 0.0005235269610517321 Test RE 0.01657819309485174\n",
      "269 Train Loss 0.0023464113 Test MSE 0.0005174913410641401 Test RE 0.016482353007627633\n",
      "270 Train Loss 0.002332609 Test MSE 0.00048376113665561947 Test RE 0.015936140706777815\n",
      "271 Train Loss 0.002303453 Test MSE 0.0004789040427974387 Test RE 0.015855937281546186\n",
      "272 Train Loss 0.0022795931 Test MSE 0.00047729616175593286 Test RE 0.015829297398022045\n",
      "273 Train Loss 0.0022444343 Test MSE 0.00047799546166973027 Test RE 0.01584088912620755\n",
      "274 Train Loss 0.0022160502 Test MSE 0.0004597064645714054 Test RE 0.015534882513985162\n",
      "275 Train Loss 0.0021747006 Test MSE 0.0004546280829474763 Test RE 0.015448837221869757\n",
      "276 Train Loss 0.002144683 Test MSE 0.00044418073303253427 Test RE 0.015270298474353886\n",
      "277 Train Loss 0.0021245265 Test MSE 0.0004454804836298642 Test RE 0.015292623937751569\n",
      "278 Train Loss 0.0021086242 Test MSE 0.0004382616614618903 Test RE 0.015168212630888023\n",
      "279 Train Loss 0.0020929885 Test MSE 0.000439497604623796 Test RE 0.015189585536365959\n",
      "280 Train Loss 0.0020854105 Test MSE 0.0004491810328713584 Test RE 0.015356009508868132\n",
      "281 Train Loss 0.002077011 Test MSE 0.0004535065083456624 Test RE 0.015429769192619317\n",
      "282 Train Loss 0.0020644753 Test MSE 0.00044457048101269325 Test RE 0.015276996494507158\n",
      "283 Train Loss 0.0020583398 Test MSE 0.000443678963305492 Test RE 0.01526167097427546\n",
      "284 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "285 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "286 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "287 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "288 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "289 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "290 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "291 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "292 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "293 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "294 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "295 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "296 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "297 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "298 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "299 Train Loss 0.002056796 Test MSE 0.00044059093693068937 Test RE 0.015208467264992196\n",
      "Training time: 160.06\n",
      "KG_tanh_medium\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 25294.623 Test MSE 15.123331688084933 Test RE 2.8176782933159883\n",
      "1 Train Loss 10805.31 Test MSE 12.415804084387773 Test RE 2.5530251503807766\n",
      "2 Train Loss 7623.382 Test MSE 10.530800628251312 Test RE 2.3512475876915904\n",
      "3 Train Loss 4059.9873 Test MSE 11.133832307525527 Test RE 2.417630943397855\n",
      "4 Train Loss 1129.204 Test MSE 13.533735041017643 Test RE 2.6654865935974237\n",
      "5 Train Loss 526.94836 Test MSE 14.16391914372301 Test RE 2.72683831132414\n",
      "6 Train Loss 353.36856 Test MSE 15.039762870453636 Test RE 2.8098825165165584\n",
      "7 Train Loss 198.37926 Test MSE 17.40713286173429 Test RE 3.0229522675218523\n",
      "8 Train Loss 121.608345 Test MSE 18.297855793737874 Test RE 3.099329628146329\n",
      "9 Train Loss 79.072235 Test MSE 18.97458102944003 Test RE 3.1561218743483224\n",
      "10 Train Loss 60.50482 Test MSE 19.049594240966044 Test RE 3.1623543521270387\n",
      "11 Train Loss 46.4368 Test MSE 19.082577829529527 Test RE 3.165090911296527\n",
      "12 Train Loss 38.229637 Test MSE 19.202528419110262 Test RE 3.1750230016406036\n",
      "13 Train Loss 32.478344 Test MSE 19.231225608801125 Test RE 3.177394570097427\n",
      "14 Train Loss 28.955986 Test MSE 19.186093475443442 Test RE 3.1736640010711703\n",
      "15 Train Loss 26.552507 Test MSE 19.09643144751369 Test RE 3.1662396031932953\n",
      "16 Train Loss 25.263414 Test MSE 18.91696419961172 Test RE 3.1513264063605364\n",
      "17 Train Loss 24.004404 Test MSE 18.74679701272221 Test RE 3.137120539061196\n",
      "18 Train Loss 23.277607 Test MSE 18.55975840608097 Test RE 3.121431631034662\n",
      "19 Train Loss 22.579584 Test MSE 18.373497278823983 Test RE 3.1057291787917483\n",
      "20 Train Loss 21.983538 Test MSE 18.065819300900433 Test RE 3.0796155130162646\n",
      "21 Train Loss 21.443062 Test MSE 17.92485732112999 Test RE 3.0675773425870525\n",
      "22 Train Loss 21.000952 Test MSE 17.66998742337286 Test RE 3.0456906344592256\n",
      "23 Train Loss 20.561888 Test MSE 17.499147688529227 Test RE 3.0309314624083816\n",
      "24 Train Loss 20.216578 Test MSE 17.31273211120051 Test RE 3.014744226759382\n",
      "25 Train Loss 19.954893 Test MSE 17.13481304222401 Test RE 2.999213296258659\n",
      "26 Train Loss 19.657862 Test MSE 17.092541983000775 Test RE 2.995511528118569\n",
      "27 Train Loss 19.290031 Test MSE 16.852652938884134 Test RE 2.974416668405442\n",
      "28 Train Loss 18.940905 Test MSE 16.652312535171117 Test RE 2.9566842255887664\n",
      "29 Train Loss 18.557568 Test MSE 16.58964151685509 Test RE 2.9511152368233176\n",
      "30 Train Loss 18.219522 Test MSE 16.33185276864505 Test RE 2.9280965689626206\n",
      "31 Train Loss 17.888779 Test MSE 16.034488173568235 Test RE 2.9013172388357087\n",
      "32 Train Loss 17.531683 Test MSE 15.754464128200933 Test RE 2.8758715565452118\n",
      "33 Train Loss 17.117634 Test MSE 15.384554546896267 Test RE 2.841908759448941\n",
      "34 Train Loss 16.80731 Test MSE 15.027553020348133 Test RE 2.8087417003132766\n",
      "35 Train Loss 16.48179 Test MSE 14.7646009644472 Test RE 2.784059577002362\n",
      "36 Train Loss 16.067595 Test MSE 14.241897685623634 Test RE 2.7343342245075744\n",
      "37 Train Loss 15.765249 Test MSE 13.793601352874292 Test RE 2.690955418658666\n",
      "38 Train Loss 15.446208 Test MSE 13.52642104124738 Test RE 2.664766245410342\n",
      "39 Train Loss 15.139323 Test MSE 13.08323821472509 Test RE 2.620748175462075\n",
      "40 Train Loss 14.946759 Test MSE 12.918377805063887 Test RE 2.6041839529212645\n",
      "41 Train Loss 14.616417 Test MSE 12.386377461929753 Test RE 2.5499979008364577\n",
      "42 Train Loss 14.337874 Test MSE 12.202116039036076 Test RE 2.5309597756380793\n",
      "43 Train Loss 14.131388 Test MSE 12.047011201741256 Test RE 2.514822427171508\n",
      "44 Train Loss 13.85726 Test MSE 11.873539874061718 Test RE 2.496650640196988\n",
      "45 Train Loss 13.467987 Test MSE 11.568895981150188 Test RE 2.464413764352913\n",
      "46 Train Loss 13.286902 Test MSE 11.467629522643561 Test RE 2.453604133765576\n",
      "47 Train Loss 12.994422 Test MSE 11.230836584129793 Test RE 2.428139990438312\n",
      "48 Train Loss 12.672197 Test MSE 10.981808030585846 Test RE 2.4010687282363103\n",
      "49 Train Loss 12.449448 Test MSE 10.75819874850373 Test RE 2.3764979788129867\n",
      "50 Train Loss 12.1089945 Test MSE 10.487883179020509 Test RE 2.3464515339627328\n",
      "51 Train Loss 11.840922 Test MSE 10.347189423499323 Test RE 2.330659704019145\n",
      "52 Train Loss 11.60155 Test MSE 10.195392320183197 Test RE 2.3135007185537155\n",
      "53 Train Loss 11.384184 Test MSE 9.978051478812805 Test RE 2.288708791020207\n",
      "54 Train Loss 11.079453 Test MSE 9.780001126754971 Test RE 2.2658811163473027\n",
      "55 Train Loss 10.752227 Test MSE 9.618751212867235 Test RE 2.247123872989094\n",
      "56 Train Loss 10.5149975 Test MSE 9.46470048138826 Test RE 2.2290566457308403\n",
      "57 Train Loss 10.313718 Test MSE 9.325135315403514 Test RE 2.2125609282881076\n",
      "58 Train Loss 10.078642 Test MSE 9.104848314070376 Test RE 2.1862711561265797\n",
      "59 Train Loss 9.868711 Test MSE 8.802323117600729 Test RE 2.1496429017615104\n",
      "60 Train Loss 9.635023 Test MSE 8.612028682992403 Test RE 2.1262797417947743\n",
      "61 Train Loss 9.361934 Test MSE 8.383061149203558 Test RE 2.0978236863603437\n",
      "62 Train Loss 9.149379 Test MSE 7.937756004850775 Test RE 2.0413456150768132\n",
      "63 Train Loss 8.935701 Test MSE 7.595615608625121 Test RE 1.996867077470089\n",
      "64 Train Loss 8.505343 Test MSE 7.153411086564571 Test RE 1.937868303856373\n",
      "65 Train Loss 8.145215 Test MSE 6.475419285334825 Test RE 1.8437482233351086\n",
      "66 Train Loss 7.5920067 Test MSE 5.490171465426197 Test RE 1.6976987222123558\n",
      "67 Train Loss 6.8141026 Test MSE 4.712336172263644 Test RE 1.5728445437755192\n",
      "68 Train Loss 6.0636287 Test MSE 3.837013332489413 Test RE 1.4192677086879733\n",
      "69 Train Loss 5.3988867 Test MSE 3.5392807456072135 Test RE 1.3630920171004899\n",
      "70 Train Loss 4.8625603 Test MSE 2.8629474784777393 Test RE 1.2259545168532335\n",
      "71 Train Loss 4.2325335 Test MSE 2.2413118649959998 Test RE 1.0847229098255924\n",
      "72 Train Loss 3.793238 Test MSE 1.8764591569051468 Test RE 0.992515335050641\n",
      "73 Train Loss 3.3690703 Test MSE 1.7814535199884216 Test RE 0.9670633296473676\n",
      "74 Train Loss 3.0486076 Test MSE 1.5130030157759191 Test RE 0.8912254185741586\n",
      "75 Train Loss 2.7006595 Test MSE 1.3227357760957368 Test RE 0.8333054413210306\n",
      "76 Train Loss 2.3387775 Test MSE 0.9650762211289419 Test RE 0.7117844159060693\n",
      "77 Train Loss 1.8689363 Test MSE 0.6904036755267307 Test RE 0.6020314995361579\n",
      "78 Train Loss 1.3981929 Test MSE 0.30388841732354904 Test RE 0.3994153408030355\n",
      "79 Train Loss 0.99606544 Test MSE 0.23159845699411738 Test RE 0.34868679322394575\n",
      "80 Train Loss 0.71063054 Test MSE 0.1507719946578058 Test RE 0.28133774870275313\n",
      "81 Train Loss 0.52688247 Test MSE 0.10801555284233064 Test RE 0.23812819170315908\n",
      "82 Train Loss 0.40144306 Test MSE 0.12211611867096592 Test RE 0.25319443952237597\n",
      "83 Train Loss 0.35930234 Test MSE 0.12929295923997697 Test RE 0.26052841988466086\n",
      "84 Train Loss 0.31040972 Test MSE 0.11984358855101394 Test RE 0.2508274541085786\n",
      "85 Train Loss 0.27589905 Test MSE 0.09006933829195081 Test RE 0.21744836859469566\n",
      "86 Train Loss 0.24656552 Test MSE 0.09272630980372326 Test RE 0.22063233232496599\n",
      "87 Train Loss 0.21146607 Test MSE 0.0820944843037017 Test RE 0.20759871318932882\n",
      "88 Train Loss 0.19832517 Test MSE 0.08213363764028797 Test RE 0.20764821233320246\n",
      "89 Train Loss 0.18524794 Test MSE 0.07505035576046037 Test RE 0.19849247422446906\n",
      "90 Train Loss 0.16170076 Test MSE 0.059955020427913994 Test RE 0.1774109597365411\n",
      "91 Train Loss 0.14318068 Test MSE 0.04403217057796609 Test RE 0.15203819848858466\n",
      "92 Train Loss 0.13446075 Test MSE 0.043682739117583136 Test RE 0.15143372281994488\n",
      "93 Train Loss 0.12371042 Test MSE 0.03968676355708031 Test RE 0.14434126580477286\n",
      "94 Train Loss 0.11562298 Test MSE 0.03548745461799647 Test RE 0.13649133851130638\n",
      "95 Train Loss 0.10619431 Test MSE 0.031201895446986355 Test RE 0.12798472991055468\n",
      "96 Train Loss 0.1001124 Test MSE 0.03080350499218848 Test RE 0.12716504096709583\n",
      "97 Train Loss 0.09266966 Test MSE 0.03205398623424531 Test RE 0.12972052291667077\n",
      "98 Train Loss 0.086153656 Test MSE 0.025968283129855566 Test RE 0.11675870956115666\n",
      "99 Train Loss 0.08157824 Test MSE 0.019965099058376 Test RE 0.10237723649539628\n",
      "100 Train Loss 0.07818723 Test MSE 0.019822641880487393 Test RE 0.10201133594599172\n",
      "101 Train Loss 0.075708084 Test MSE 0.021933395249632996 Test RE 0.10730515842663428\n",
      "102 Train Loss 0.071547486 Test MSE 0.01974276429961725 Test RE 0.10180559535624702\n",
      "103 Train Loss 0.06889608 Test MSE 0.018436342458377268 Test RE 0.09837959966597094\n",
      "104 Train Loss 0.06558355 Test MSE 0.017776875982916624 Test RE 0.09660406222145805\n",
      "105 Train Loss 0.06141185 Test MSE 0.016335343048194596 Test RE 0.09260443732785995\n",
      "106 Train Loss 0.059145547 Test MSE 0.016516551452762988 Test RE 0.0931166525118731\n",
      "107 Train Loss 0.05565891 Test MSE 0.014493241561791232 Test RE 0.0872268989707873\n",
      "108 Train Loss 0.054723207 Test MSE 0.015493072603958437 Test RE 0.09018544357529479\n",
      "109 Train Loss 0.04915706 Test MSE 0.012857303984205282 Test RE 0.08215663134651471\n",
      "110 Train Loss 0.04719913 Test MSE 0.012542947417983076 Test RE 0.08114606573865742\n",
      "111 Train Loss 0.045740377 Test MSE 0.01099039171932895 Test RE 0.07595812810757885\n",
      "112 Train Loss 0.04314315 Test MSE 0.009771026001091103 Test RE 0.07162056654679615\n",
      "113 Train Loss 0.041335437 Test MSE 0.009504968299389951 Test RE 0.07063874975988287\n",
      "114 Train Loss 0.03972606 Test MSE 0.010238253704608282 Test RE 0.07331293582812921\n",
      "115 Train Loss 0.038194638 Test MSE 0.009299402463295296 Test RE 0.06987071532189944\n",
      "116 Train Loss 0.03636076 Test MSE 0.008103284627090552 Test RE 0.0652226161003373\n",
      "117 Train Loss 0.033751402 Test MSE 0.00614859419654992 Test RE 0.05681402827308222\n",
      "118 Train Loss 0.032719515 Test MSE 0.004918841086115866 Test RE 0.05081583469298204\n",
      "119 Train Loss 0.030932475 Test MSE 0.004344500128179961 Test RE 0.0477570590921931\n",
      "120 Train Loss 0.028280826 Test MSE 0.004319366913521452 Test RE 0.04761871988650757\n",
      "121 Train Loss 0.0268557 Test MSE 0.0038820993937086594 Test RE 0.0451440993350862\n",
      "122 Train Loss 0.026414825 Test MSE 0.003183690078924964 Test RE 0.040882087149283604\n",
      "123 Train Loss 0.025389498 Test MSE 0.002854723208813444 Test RE 0.038712362032077896\n",
      "124 Train Loss 0.024636423 Test MSE 0.0022818137149558386 Test RE 0.03461049102310447\n",
      "125 Train Loss 0.02404488 Test MSE 0.0024313768155023565 Test RE 0.03572677404024407\n",
      "126 Train Loss 0.023137027 Test MSE 0.0018909857929007812 Test RE 0.031507344434670626\n",
      "127 Train Loss 0.021807306 Test MSE 0.0014998054776543344 Test RE 0.028059836449523933\n",
      "128 Train Loss 0.02123078 Test MSE 0.00129005022599203 Test RE 0.02602381585656559\n",
      "129 Train Loss 0.020667762 Test MSE 0.001166582417535172 Test RE 0.024747160838298143\n",
      "130 Train Loss 0.019686168 Test MSE 0.001332234210332802 Test RE 0.02644587607377508\n",
      "131 Train Loss 0.018786866 Test MSE 0.0013414794879573597 Test RE 0.026537480366396825\n",
      "132 Train Loss 0.018093456 Test MSE 0.0012762537396398474 Test RE 0.025884285505498848\n",
      "133 Train Loss 0.017727483 Test MSE 0.0011497649087205935 Test RE 0.024568135148731404\n",
      "134 Train Loss 0.016721506 Test MSE 0.0010475371259193247 Test RE 0.02345051471895097\n",
      "135 Train Loss 0.015992148 Test MSE 0.0008794478625768684 Test RE 0.021486848242964842\n",
      "136 Train Loss 0.01555829 Test MSE 0.0008200680797637224 Test RE 0.020748782659780977\n",
      "137 Train Loss 0.015280885 Test MSE 0.0008687670909312553 Test RE 0.021355972273783375\n",
      "138 Train Loss 0.015032759 Test MSE 0.0008266182982791372 Test RE 0.020831482347699035\n",
      "139 Train Loss 0.0147452615 Test MSE 0.0007914731934462892 Test RE 0.020383829253408595\n",
      "140 Train Loss 0.014312643 Test MSE 0.0006560779024519528 Test RE 0.018558606900780057\n",
      "141 Train Loss 0.013678285 Test MSE 0.0006018005789022057 Test RE 0.01777435984284429\n",
      "142 Train Loss 0.013267115 Test MSE 0.0005777737270342954 Test RE 0.01741592566381514\n",
      "143 Train Loss 0.013072527 Test MSE 0.0006202046791967887 Test RE 0.018044098405060858\n",
      "144 Train Loss 0.01253369 Test MSE 0.0006020983988900693 Test RE 0.017778757399991144\n",
      "145 Train Loss 0.012046127 Test MSE 0.0005669418701340787 Test RE 0.01725190006024546\n",
      "146 Train Loss 0.011612245 Test MSE 0.0005832654302538414 Test RE 0.01749849855860409\n",
      "147 Train Loss 0.011317374 Test MSE 0.0005796483545135906 Test RE 0.017444156380867774\n",
      "148 Train Loss 0.011011919 Test MSE 0.0006312062656591967 Test RE 0.01820343378027607\n",
      "149 Train Loss 0.010847188 Test MSE 0.0005980094514427313 Test RE 0.01771828535010831\n",
      "150 Train Loss 0.010616971 Test MSE 0.0006336302998748653 Test RE 0.01823835379424482\n",
      "151 Train Loss 0.010356528 Test MSE 0.0006900359728104304 Test RE 0.01903283723361362\n",
      "152 Train Loss 0.010150239 Test MSE 0.0006998012562901676 Test RE 0.019167039000752863\n",
      "153 Train Loss 0.009852353 Test MSE 0.0006727596414970534 Test RE 0.018793065736400192\n",
      "154 Train Loss 0.009524675 Test MSE 0.0006459213495896484 Test RE 0.01841439638198914\n",
      "155 Train Loss 0.009425517 Test MSE 0.0006451068003944985 Test RE 0.018402781838235068\n",
      "156 Train Loss 0.009260557 Test MSE 0.000616495925897153 Test RE 0.017990066682025872\n",
      "157 Train Loss 0.009079314 Test MSE 0.0005810897865373565 Test RE 0.017465832413306827\n",
      "158 Train Loss 0.008882007 Test MSE 0.0005555426116656124 Test RE 0.017077581071860824\n",
      "159 Train Loss 0.008445133 Test MSE 0.000551828596980765 Test RE 0.01702040026448849\n",
      "160 Train Loss 0.008222223 Test MSE 0.0005517394761024909 Test RE 0.017019025803036575\n",
      "161 Train Loss 0.0079694865 Test MSE 0.0005164526760858913 Test RE 0.01646580370488912\n",
      "162 Train Loss 0.007829298 Test MSE 0.00047954889862478347 Test RE 0.015866608891068452\n",
      "163 Train Loss 0.0077015823 Test MSE 0.0004536528926761328 Test RE 0.015432259227662549\n",
      "164 Train Loss 0.007498946 Test MSE 0.00045820789169314995 Test RE 0.01550954117247573\n",
      "165 Train Loss 0.0073363767 Test MSE 0.0003877945773176982 Test RE 0.014268178490405714\n",
      "166 Train Loss 0.0070788297 Test MSE 0.0003367169106744842 Test RE 0.013295360932704172\n",
      "167 Train Loss 0.0068394463 Test MSE 0.0002897724732514892 Test RE 0.012333780961867725\n",
      "168 Train Loss 0.0066012545 Test MSE 0.00029101044475789644 Test RE 0.012360099190062089\n",
      "169 Train Loss 0.0065124724 Test MSE 0.00029236334040244513 Test RE 0.012388796672954885\n",
      "170 Train Loss 0.006436322 Test MSE 0.00029358828242899714 Test RE 0.012414722795022155\n",
      "171 Train Loss 0.0063221534 Test MSE 0.00030673372637330873 Test RE 0.012689614623075164\n",
      "172 Train Loss 0.0061648516 Test MSE 0.00028507934813026695 Test RE 0.012233494925884308\n",
      "173 Train Loss 0.006023901 Test MSE 0.0002705687448261134 Test RE 0.011918085072102087\n",
      "174 Train Loss 0.0058885873 Test MSE 0.0002475057010501267 Test RE 0.011398829852845307\n",
      "175 Train Loss 0.005831437 Test MSE 0.00024254906841455134 Test RE 0.0112841142093675\n",
      "176 Train Loss 0.0057517784 Test MSE 0.0002367687208560955 Test RE 0.011148843818851504\n",
      "177 Train Loss 0.005623424 Test MSE 0.00022201965430105195 Test RE 0.01079601249923785\n",
      "178 Train Loss 0.0055344086 Test MSE 0.00020268493883149484 Test RE 0.010315217906140078\n",
      "179 Train Loss 0.0054080593 Test MSE 0.0002146525166709082 Test RE 0.01061538280409971\n",
      "180 Train Loss 0.005311202 Test MSE 0.0002247998151515831 Test RE 0.01086339678829858\n",
      "181 Train Loss 0.005215248 Test MSE 0.0002292782264799681 Test RE 0.010971072234445461\n",
      "182 Train Loss 0.00509551 Test MSE 0.0002737522161204177 Test RE 0.011987993242405386\n",
      "183 Train Loss 0.005005419 Test MSE 0.0002270144515697881 Test RE 0.010916776526723664\n",
      "184 Train Loss 0.0047739283 Test MSE 0.00021452742326481087 Test RE 0.010612289181120798\n",
      "185 Train Loss 0.0046781823 Test MSE 0.00018032900968133352 Test RE 0.009729722779739321\n",
      "186 Train Loss 0.004602355 Test MSE 0.00017056109468040743 Test RE 0.009462538401668184\n",
      "187 Train Loss 0.0045067067 Test MSE 0.00017965352268698223 Test RE 0.009711482598943237\n",
      "188 Train Loss 0.004452084 Test MSE 0.00018418192667829901 Test RE 0.009833116248808014\n",
      "189 Train Loss 0.004406484 Test MSE 0.00018279444009130944 Test RE 0.009796008621084262\n",
      "190 Train Loss 0.00434467 Test MSE 0.00018646815905707848 Test RE 0.009893956787954813\n",
      "191 Train Loss 0.0042544347 Test MSE 0.00018417213788332734 Test RE 0.009832854942936205\n",
      "192 Train Loss 0.0041716155 Test MSE 0.00017641940426899058 Test RE 0.009623672677463477\n",
      "193 Train Loss 0.004133929 Test MSE 0.00017216881724033307 Test RE 0.009507031122601114\n",
      "194 Train Loss 0.0040895543 Test MSE 0.00017604918260605854 Test RE 0.00961356958452122\n",
      "195 Train Loss 0.003992277 Test MSE 0.00018526942857935953 Test RE 0.00986210333307235\n",
      "196 Train Loss 0.003918932 Test MSE 0.0001875449413080035 Test RE 0.009922482572713512\n",
      "197 Train Loss 0.0038144107 Test MSE 0.0001720557453926026 Test RE 0.009503908739150605\n",
      "198 Train Loss 0.0037412024 Test MSE 0.00016641960370566815 Test RE 0.009346949782342757\n",
      "199 Train Loss 0.0035979566 Test MSE 0.00015528854579486862 Test RE 0.009028952726261249\n",
      "200 Train Loss 0.0035294944 Test MSE 0.00013261651692682595 Test RE 0.008343849774476098\n",
      "201 Train Loss 0.0034821737 Test MSE 0.00013494266193620294 Test RE 0.00841670884568523\n",
      "202 Train Loss 0.0034372252 Test MSE 0.00013496959800178118 Test RE 0.008417548838411334\n",
      "203 Train Loss 0.0033678908 Test MSE 0.00013125088558229195 Test RE 0.008300777805114543\n",
      "204 Train Loss 0.0033027683 Test MSE 0.00013302268375602527 Test RE 0.00835661743029998\n",
      "205 Train Loss 0.0032662533 Test MSE 0.00012890547716070972 Test RE 0.008226277451106693\n",
      "206 Train Loss 0.0032333361 Test MSE 0.0001294532291120687 Test RE 0.008243736689566933\n",
      "207 Train Loss 0.0031951633 Test MSE 0.00012598675361931953 Test RE 0.008132613073802093\n",
      "208 Train Loss 0.0031250045 Test MSE 0.00012343604041389672 Test RE 0.008049866140359437\n",
      "209 Train Loss 0.0030725843 Test MSE 0.0001210105051297397 Test RE 0.007970383248570361\n",
      "210 Train Loss 0.003041925 Test MSE 0.00011912664122468691 Test RE 0.007908099339319293\n",
      "211 Train Loss 0.0030031845 Test MSE 0.00011915717026638049 Test RE 0.007909112593894884\n",
      "212 Train Loss 0.002951856 Test MSE 0.0001225057239230206 Test RE 0.008019473528496742\n",
      "213 Train Loss 0.0029135547 Test MSE 0.0001204412059486779 Test RE 0.00795161263854472\n",
      "214 Train Loss 0.002827742 Test MSE 0.0001066080645061741 Test RE 0.007481052405029919\n",
      "215 Train Loss 0.0027803327 Test MSE 0.00010766727179220774 Test RE 0.007518124648030624\n",
      "216 Train Loss 0.0027268305 Test MSE 9.417970633835816e-05 Test RE 0.007031473326285152\n",
      "217 Train Loss 0.002704665 Test MSE 9.673226192309246e-05 Test RE 0.007126123410697422\n",
      "218 Train Loss 0.002666002 Test MSE 0.00010277214524610457 Test RE 0.007345229650201631\n",
      "219 Train Loss 0.0026235327 Test MSE 0.00010211145982387003 Test RE 0.007321581653557674\n",
      "220 Train Loss 0.002585923 Test MSE 0.00010721817342368575 Test RE 0.0075024285795785815\n",
      "221 Train Loss 0.0025629757 Test MSE 0.00011136358806884485 Test RE 0.007646087703811298\n",
      "222 Train Loss 0.0025308323 Test MSE 0.00010631329663059466 Test RE 0.007470702811148317\n",
      "223 Train Loss 0.0025118077 Test MSE 0.00010961065743131497 Test RE 0.00758567197931183\n",
      "224 Train Loss 0.0024797574 Test MSE 0.00011324454769275972 Test RE 0.007710389515418277\n",
      "225 Train Loss 0.0024214676 Test MSE 0.00010722729309573774 Test RE 0.007502747640383389\n",
      "226 Train Loss 0.0023833776 Test MSE 9.942794085073095e-05 Test RE 0.007224734472560265\n",
      "227 Train Loss 0.002338698 Test MSE 9.747856798344878e-05 Test RE 0.007153560227137746\n",
      "228 Train Loss 0.0023101459 Test MSE 9.047755223014479e-05 Test RE 0.006891886062231012\n",
      "229 Train Loss 0.0022806986 Test MSE 9.192355643279481e-05 Test RE 0.006946740516657223\n",
      "230 Train Loss 0.0022578393 Test MSE 9.051825515860498e-05 Test RE 0.006893436106392861\n",
      "231 Train Loss 0.0022425628 Test MSE 8.941721717999244e-05 Test RE 0.006851382949066932\n",
      "232 Train Loss 0.00223422 Test MSE 9.174198393905265e-05 Test RE 0.006939876332276552\n",
      "233 Train Loss 0.0022217163 Test MSE 8.88071629811265e-05 Test RE 0.006827970967688364\n",
      "234 Train Loss 0.002211697 Test MSE 8.797324252686341e-05 Test RE 0.006795837215418575\n",
      "235 Train Loss 0.0022030086 Test MSE 8.645999735136177e-05 Test RE 0.006737135413876992\n",
      "236 Train Loss 0.0021940086 Test MSE 8.51534672789206e-05 Test RE 0.0066860379262510565\n",
      "237 Train Loss 0.0021764752 Test MSE 8.542449353449494e-05 Test RE 0.006696669626235168\n",
      "238 Train Loss 0.0021578395 Test MSE 9.077723995308502e-05 Test RE 0.006903290582497545\n",
      "239 Train Loss 0.0021406997 Test MSE 8.975538748954316e-05 Test RE 0.006864326473106911\n",
      "240 Train Loss 0.0021279608 Test MSE 9.213563210058846e-05 Test RE 0.006954749268438345\n",
      "241 Train Loss 0.0021187775 Test MSE 9.684554399549528e-05 Test RE 0.007130294851572052\n",
      "242 Train Loss 0.0020996295 Test MSE 9.347481952190248e-05 Test RE 0.007005110419005641\n",
      "243 Train Loss 0.0020747953 Test MSE 9.189406015676554e-05 Test RE 0.006945625898034949\n",
      "244 Train Loss 0.0020619847 Test MSE 8.856407693425628e-05 Test RE 0.006818619684655676\n",
      "245 Train Loss 0.002047104 Test MSE 8.896270868009794e-05 Test RE 0.0068339479454335465\n",
      "246 Train Loss 0.0020349543 Test MSE 8.816114795982576e-05 Test RE 0.006803091089096765\n",
      "247 Train Loss 0.002025196 Test MSE 8.88043120717934e-05 Test RE 0.00682786137020922\n",
      "248 Train Loss 0.002018225 Test MSE 9.075540289010235e-05 Test RE 0.00690246021654768\n",
      "249 Train Loss 0.0020108346 Test MSE 8.925017713397918e-05 Test RE 0.006844980433156562\n",
      "250 Train Loss 0.0020042704 Test MSE 8.929942769721745e-05 Test RE 0.006846868791575377\n",
      "251 Train Loss 0.0019926492 Test MSE 9.134320637711925e-05 Test RE 0.006924777024651943\n",
      "252 Train Loss 0.001977954 Test MSE 9.447628266925577e-05 Test RE 0.007042535844368098\n",
      "253 Train Loss 0.0019600373 Test MSE 9.147832537122703e-05 Test RE 0.0069298968533609215\n",
      "254 Train Loss 0.0019371258 Test MSE 8.667913562351763e-05 Test RE 0.006745667856384268\n",
      "255 Train Loss 0.0019182431 Test MSE 9.218942405721214e-05 Test RE 0.006956779183325061\n",
      "256 Train Loss 0.0019036792 Test MSE 8.99448486604206e-05 Test RE 0.006871567474369058\n",
      "257 Train Loss 0.0018923859 Test MSE 9.072101976920559e-05 Test RE 0.006901152577558503\n",
      "258 Train Loss 0.001883528 Test MSE 9.02704501774071e-05 Test RE 0.006883993820268886\n",
      "259 Train Loss 0.0018685552 Test MSE 9.086681628565424e-05 Test RE 0.006906695725575532\n",
      "260 Train Loss 0.0018536653 Test MSE 8.733670396039729e-05 Test RE 0.006771206624645675\n",
      "261 Train Loss 0.0018422096 Test MSE 8.59883845788653e-05 Test RE 0.006718735784617197\n",
      "262 Train Loss 0.0018319547 Test MSE 8.741183886701544e-05 Test RE 0.0067741185996939715\n",
      "263 Train Loss 0.0018215365 Test MSE 8.839672228513604e-05 Test RE 0.006812174253642436\n",
      "264 Train Loss 0.0018089816 Test MSE 9.159922923960924e-05 Test RE 0.006934474848620321\n",
      "265 Train Loss 0.0017982643 Test MSE 9.108917552388638e-05 Test RE 0.006915141213546693\n",
      "266 Train Loss 0.0017835263 Test MSE 9.248038300828494e-05 Test RE 0.0069677486769286045\n",
      "267 Train Loss 0.00177185 Test MSE 9.267222000556369e-05 Test RE 0.006974971719675721\n",
      "268 Train Loss 0.0017548185 Test MSE 9.370155871430115e-05 Test RE 0.007013601320941055\n",
      "269 Train Loss 0.0017355509 Test MSE 9.189319724723358e-05 Test RE 0.006945593287326201\n",
      "270 Train Loss 0.0017141812 Test MSE 9.246859909992407e-05 Test RE 0.0069673047453350755\n",
      "271 Train Loss 0.0016974859 Test MSE 9.117358025841013e-05 Test RE 0.006918344313738658\n",
      "272 Train Loss 0.0016844909 Test MSE 9.12446570927105e-05 Test RE 0.006921040479734453\n",
      "273 Train Loss 0.0016696865 Test MSE 8.980931506276646e-05 Test RE 0.006866388304114699\n",
      "274 Train Loss 0.0016536749 Test MSE 9.189882783375618e-05 Test RE 0.00694580607328904\n",
      "275 Train Loss 0.0016463859 Test MSE 9.304176236676006e-05 Test RE 0.00698886468055234\n",
      "276 Train Loss 0.0016406679 Test MSE 9.330516020187857e-05 Test RE 0.006998750299519599\n",
      "277 Train Loss 0.0016336802 Test MSE 9.424752690224321e-05 Test RE 0.00703400461823271\n",
      "278 Train Loss 0.0016261751 Test MSE 9.34774224482114e-05 Test RE 0.007005207951471419\n",
      "279 Train Loss 0.0016093459 Test MSE 9.552810849788984e-05 Test RE 0.0070816304058077565\n",
      "280 Train Loss 0.0015968245 Test MSE 9.627367416149558e-05 Test RE 0.007109211600199824\n",
      "281 Train Loss 0.001587677 Test MSE 9.591244527631284e-05 Test RE 0.0070958618135966295\n",
      "282 Train Loss 0.0015747638 Test MSE 9.116723688126679e-05 Test RE 0.006918103638586792\n",
      "283 Train Loss 0.0015628203 Test MSE 9.379497770216382e-05 Test RE 0.007017096675341241\n",
      "284 Train Loss 0.0015451143 Test MSE 9.414411708975068e-05 Test RE 0.0070301446509923125\n",
      "285 Train Loss 0.0015342946 Test MSE 9.825224522337307e-05 Test RE 0.007181892651545704\n",
      "286 Train Loss 0.0015269577 Test MSE 9.89240463985783e-05 Test RE 0.007206403972236463\n",
      "287 Train Loss 0.0015206195 Test MSE 0.00010258810813581652 Test RE 0.007338650043669319\n",
      "288 Train Loss 0.0015033368 Test MSE 0.00010142271746176413 Test RE 0.007296847821127348\n",
      "289 Train Loss 0.0014855382 Test MSE 0.000104855984734199 Test RE 0.0074193230129109625\n",
      "290 Train Loss 0.0014745827 Test MSE 0.00011083253974117318 Test RE 0.007627835354052085\n",
      "291 Train Loss 0.0014627087 Test MSE 0.00011737962120579595 Test RE 0.00784989810554381\n",
      "292 Train Loss 0.001449249 Test MSE 0.00012218017194953363 Test RE 0.00800881079314953\n",
      "293 Train Loss 0.0014244984 Test MSE 0.00011818035804779097 Test RE 0.007876627699056418\n",
      "294 Train Loss 0.0014089507 Test MSE 0.00011840705604954533 Test RE 0.00788417870118966\n",
      "295 Train Loss 0.0013985289 Test MSE 0.000122293284462508 Test RE 0.008012517152090608\n",
      "296 Train Loss 0.0013916082 Test MSE 0.0001210760272763584 Test RE 0.007972540771778985\n",
      "297 Train Loss 0.0013834218 Test MSE 0.00011977543540294338 Test RE 0.007929604864460158\n",
      "298 Train Loss 0.0013754246 Test MSE 0.00011870605521390769 Test RE 0.00789412691123054\n",
      "299 Train Loss 0.001367103 Test MSE 0.00011160456475850527 Test RE 0.007654355815780668\n",
      "Training time: 165.49\n",
      "KG_tanh_medium\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 34303.125 Test MSE 6.290258763443298 Test RE 1.8171966326611186\n",
      "1 Train Loss 10532.349 Test MSE 10.74272474984525 Test RE 2.374788252105455\n",
      "2 Train Loss 7901.234 Test MSE 10.587883778658075 Test RE 2.357611549578595\n",
      "3 Train Loss 5703.416 Test MSE 12.117756799717922 Test RE 2.5221957159218924\n",
      "4 Train Loss 2467.4075 Test MSE 16.86219711788029 Test RE 2.9752588013037644\n",
      "5 Train Loss 1290.8302 Test MSE 18.206464297391737 Test RE 3.0915798964655434\n",
      "6 Train Loss 799.3486 Test MSE 19.239500912984084 Test RE 3.178078121918725\n",
      "7 Train Loss 478.62622 Test MSE 20.984283128628572 Test RE 3.3190571944864584\n",
      "8 Train Loss 297.91458 Test MSE 21.7070147599945 Test RE 3.375730117600734\n",
      "9 Train Loss 188.27559 Test MSE 21.724147568847698 Test RE 3.3770620449041138\n",
      "10 Train Loss 130.00299 Test MSE 21.64598690297176 Test RE 3.370981455023637\n",
      "11 Train Loss 83.69899 Test MSE 21.31136731661857 Test RE 3.3448244172579273\n",
      "12 Train Loss 62.34501 Test MSE 20.56491431673983 Test RE 3.2857243013520923\n",
      "13 Train Loss 49.427856 Test MSE 20.235887479019816 Test RE 3.2593334637099867\n",
      "14 Train Loss 42.126904 Test MSE 19.905513568024343 Test RE 3.2326178085853616\n",
      "15 Train Loss 37.962643 Test MSE 19.67639210377996 Test RE 3.2139595153084266\n",
      "16 Train Loss 33.756485 Test MSE 19.12917590649538 Test RE 3.1689530001378374\n",
      "17 Train Loss 30.763767 Test MSE 19.00292656932528 Test RE 3.158478411026132\n",
      "18 Train Loss 28.950245 Test MSE 18.659877654072417 Test RE 3.129839473781713\n",
      "19 Train Loss 27.315948 Test MSE 18.492731191283514 Test RE 3.1157901215340713\n",
      "20 Train Loss 25.96584 Test MSE 18.274076773524637 Test RE 3.097315102996225\n",
      "21 Train Loss 24.789661 Test MSE 18.091173619148144 Test RE 3.0817757852404237\n",
      "22 Train Loss 23.931849 Test MSE 18.057257151948733 Test RE 3.0788856470943866\n",
      "23 Train Loss 23.120918 Test MSE 17.92626077571697 Test RE 3.0676974306063833\n",
      "24 Train Loss 22.468708 Test MSE 17.805613881366117 Test RE 3.0573569307072828\n",
      "25 Train Loss 22.040703 Test MSE 17.701920188417443 Test RE 3.048441440685061\n",
      "26 Train Loss 21.65319 Test MSE 17.469020071633047 Test RE 3.028321218734993\n",
      "27 Train Loss 21.290075 Test MSE 17.34952949645653 Test RE 3.0179463735957395\n",
      "28 Train Loss 20.97863 Test MSE 17.18649910415126 Test RE 3.0037333572497547\n",
      "29 Train Loss 20.625622 Test MSE 17.05464277061834 Test RE 2.9921887184221347\n",
      "30 Train Loss 20.195032 Test MSE 16.833428309608266 Test RE 2.9727196544440107\n",
      "31 Train Loss 19.894476 Test MSE 16.568442386771263 Test RE 2.9492290877318785\n",
      "32 Train Loss 19.543142 Test MSE 16.395343735703555 Test RE 2.9337826155560007\n",
      "33 Train Loss 19.174692 Test MSE 16.17096815747422 Test RE 2.913638577046107\n",
      "34 Train Loss 18.853529 Test MSE 15.989763945735106 Test RE 2.8972681609678053\n",
      "35 Train Loss 18.379827 Test MSE 15.68189716186851 Test RE 2.8692406059652713\n",
      "36 Train Loss 17.890766 Test MSE 15.445424964569744 Test RE 2.8475253471565742\n",
      "37 Train Loss 17.247875 Test MSE 15.040565435651695 Test RE 2.8099574872409563\n",
      "38 Train Loss 16.633152 Test MSE 14.658130599087777 Test RE 2.7740032212083348\n",
      "39 Train Loss 15.96945 Test MSE 14.357387121613279 Test RE 2.7453983789437792\n",
      "40 Train Loss 15.548615 Test MSE 14.215067267254895 Test RE 2.7317573938828223\n",
      "41 Train Loss 15.203243 Test MSE 14.109380132765065 Test RE 2.7215833214367957\n",
      "42 Train Loss 14.703361 Test MSE 13.857584958900523 Test RE 2.6971893898206507\n",
      "43 Train Loss 14.203305 Test MSE 13.502695178908066 Test RE 2.6624281684892135\n",
      "44 Train Loss 13.878195 Test MSE 13.358681852496895 Test RE 2.648192011265195\n",
      "45 Train Loss 13.406403 Test MSE 13.139304104674357 Test RE 2.626357547441281\n",
      "46 Train Loss 13.030658 Test MSE 12.769960500741567 Test RE 2.5891811979872434\n",
      "47 Train Loss 12.708826 Test MSE 12.658620836456077 Test RE 2.577869115787184\n",
      "48 Train Loss 12.45023 Test MSE 12.541457467993851 Test RE 2.5659114958016027\n",
      "49 Train Loss 12.108485 Test MSE 11.986362020620975 Test RE 2.508484159272036\n",
      "50 Train Loss 11.554706 Test MSE 11.621423659951144 Test RE 2.470002168299977\n",
      "51 Train Loss 11.148462 Test MSE 11.393968850693676 Test RE 2.4457112516903363\n",
      "52 Train Loss 10.807589 Test MSE 11.215532022044398 Test RE 2.4264849806857214\n",
      "53 Train Loss 10.345256 Test MSE 11.070790371932254 Test RE 2.4107766775079402\n",
      "54 Train Loss 9.969353 Test MSE 10.837867742986464 Test RE 2.385281232294909\n",
      "55 Train Loss 9.745003 Test MSE 10.553152637160386 Test RE 2.353741569436438\n",
      "56 Train Loss 9.248133 Test MSE 10.043828098349172 Test RE 2.296240133258994\n",
      "57 Train Loss 8.751334 Test MSE 9.218623045889123 Test RE 2.1998886348848488\n",
      "58 Train Loss 8.086931 Test MSE 8.755026365854945 Test RE 2.143859878995434\n",
      "59 Train Loss 7.489966 Test MSE 7.9268157802501396 Test RE 2.039938386140997\n",
      "60 Train Loss 7.0366745 Test MSE 7.466437098016374 Test RE 1.9798139179558731\n",
      "61 Train Loss 6.540099 Test MSE 6.820284789904023 Test RE 1.8922082097607456\n",
      "62 Train Loss 6.0260115 Test MSE 6.359656574697006 Test RE 1.8271933236483302\n",
      "63 Train Loss 5.5491505 Test MSE 5.651081968353613 Test RE 1.7223978353861549\n",
      "64 Train Loss 4.9602327 Test MSE 4.738462457145952 Test RE 1.5771986246142324\n",
      "65 Train Loss 4.527691 Test MSE 4.277675668731618 Test RE 1.498551229703085\n",
      "66 Train Loss 4.1735477 Test MSE 3.7080314961472163 Test RE 1.3952093397995564\n",
      "67 Train Loss 3.8098965 Test MSE 2.878148317459429 Test RE 1.2292048150902177\n",
      "68 Train Loss 3.343453 Test MSE 2.385641905932909 Test RE 1.1191036059660906\n",
      "69 Train Loss 2.9779997 Test MSE 1.779455005035481 Test RE 0.9665207297837816\n",
      "70 Train Loss 2.390867 Test MSE 1.0373517446975986 Test RE 0.7379563744189921\n",
      "71 Train Loss 1.9617543 Test MSE 0.6962396033916881 Test RE 0.6045706075201089\n",
      "72 Train Loss 1.6314238 Test MSE 0.5939258298246464 Test RE 0.5583850398372407\n",
      "73 Train Loss 1.2280021 Test MSE 0.3762710801665182 Test RE 0.44444506443713394\n",
      "74 Train Loss 0.9902366 Test MSE 0.2652052302025273 Test RE 0.37312874722643735\n",
      "75 Train Loss 0.83512646 Test MSE 0.2323636395495674 Test RE 0.34926233470073353\n",
      "76 Train Loss 0.7353022 Test MSE 0.29902890088109874 Test RE 0.39620892106609484\n",
      "77 Train Loss 0.6686904 Test MSE 0.27057931471900387 Test RE 0.3768903032360824\n",
      "78 Train Loss 0.5897423 Test MSE 0.25412048401985227 Test RE 0.36524771241126097\n",
      "79 Train Loss 0.520207 Test MSE 0.2430362716279385 Test RE 0.3571932265052513\n",
      "80 Train Loss 0.46515107 Test MSE 0.1948161536553065 Test RE 0.31980124486577644\n",
      "81 Train Loss 0.41818905 Test MSE 0.21055646949473367 Test RE 0.3324696166355076\n",
      "82 Train Loss 0.36921877 Test MSE 0.19876103911213108 Test RE 0.3230228889513835\n",
      "83 Train Loss 0.34019163 Test MSE 0.16903747255261428 Test RE 0.2978922213321342\n",
      "84 Train Loss 0.31051654 Test MSE 0.16499850822708492 Test RE 0.29431180112440863\n",
      "85 Train Loss 0.2804851 Test MSE 0.13743157773543382 Test RE 0.26860304628899206\n",
      "86 Train Loss 0.24507071 Test MSE 0.1255819017580592 Test RE 0.2567622634089309\n",
      "87 Train Loss 0.22937682 Test MSE 0.1079427668036751 Test RE 0.23804794710807378\n",
      "88 Train Loss 0.2143157 Test MSE 0.0933783172433692 Test RE 0.2214066644936714\n",
      "89 Train Loss 0.1939504 Test MSE 0.06709711110968514 Test RE 0.1876806844435617\n",
      "90 Train Loss 0.1766103 Test MSE 0.057292090664759564 Test RE 0.17342631767593739\n",
      "91 Train Loss 0.16316204 Test MSE 0.04651266829306103 Test RE 0.15626196988414165\n",
      "92 Train Loss 0.1441313 Test MSE 0.03736989059603397 Test RE 0.14006466305548104\n",
      "93 Train Loss 0.13326551 Test MSE 0.0343024351313802 Test RE 0.13419308697531748\n",
      "94 Train Loss 0.12549002 Test MSE 0.025022630304942835 Test RE 0.11461307047590588\n",
      "95 Train Loss 0.119200386 Test MSE 0.016215600021402377 Test RE 0.09226440371608499\n",
      "96 Train Loss 0.111109644 Test MSE 0.02007378921464481 Test RE 0.10265552949243205\n",
      "97 Train Loss 0.10329472 Test MSE 0.015326901110153465 Test RE 0.08970049617002332\n",
      "98 Train Loss 0.09965484 Test MSE 0.014695010780508734 Test RE 0.0878319696806499\n",
      "99 Train Loss 0.093975164 Test MSE 0.011523030790732226 Test RE 0.07777697156501358\n",
      "100 Train Loss 0.088698275 Test MSE 0.01059067034521101 Test RE 0.07456403345722966\n",
      "101 Train Loss 0.08296156 Test MSE 0.008444889583890737 Test RE 0.06658319875085915\n",
      "102 Train Loss 0.07895705 Test MSE 0.006015083787540074 Test RE 0.05619381382421832\n",
      "103 Train Loss 0.07513216 Test MSE 0.004673843719488938 Test RE 0.04953415525097823\n",
      "104 Train Loss 0.07206422 Test MSE 0.003710670485195444 Test RE 0.04413609061362619\n",
      "105 Train Loss 0.068496175 Test MSE 0.0037624220350558155 Test RE 0.04444280097970721\n",
      "106 Train Loss 0.064280674 Test MSE 0.002926626847258457 Test RE 0.03919686595898125\n",
      "107 Train Loss 0.058138043 Test MSE 0.0030400110336167496 Test RE 0.03994893883120598\n",
      "108 Train Loss 0.056430213 Test MSE 0.0024720900245376056 Test RE 0.036024653204068315\n",
      "109 Train Loss 0.054207876 Test MSE 0.001707473796503414 Test RE 0.029939510218937274\n",
      "110 Train Loss 0.052679658 Test MSE 0.0015405866242298508 Test RE 0.028438764775654976\n",
      "111 Train Loss 0.051420167 Test MSE 0.0011108576113679578 Test RE 0.024148872869057363\n",
      "112 Train Loss 0.049687985 Test MSE 0.0010666363971616423 Test RE 0.023663330378849035\n",
      "113 Train Loss 0.04828043 Test MSE 0.001176914119564619 Test RE 0.02485650445616556\n",
      "114 Train Loss 0.04512463 Test MSE 0.0009492346944127846 Test RE 0.022323098176122536\n",
      "115 Train Loss 0.043042533 Test MSE 0.0010143848204800779 Test RE 0.02307645208339401\n",
      "116 Train Loss 0.042355288 Test MSE 0.001012923560995774 Test RE 0.023059824844636468\n",
      "117 Train Loss 0.040166516 Test MSE 0.001022817068617279 Test RE 0.02317216706999645\n",
      "118 Train Loss 0.038440745 Test MSE 0.0010485529652991933 Test RE 0.023461882422900957\n",
      "119 Train Loss 0.037630126 Test MSE 0.0010527075772447918 Test RE 0.023508317203172608\n",
      "120 Train Loss 0.03645003 Test MSE 0.0012515353192804838 Test RE 0.025632397110175825\n",
      "121 Train Loss 0.035513636 Test MSE 0.000998585084941685 Test RE 0.022896031039652747\n",
      "122 Train Loss 0.033082396 Test MSE 0.0008845604206355051 Test RE 0.02154921326335871\n",
      "123 Train Loss 0.032188103 Test MSE 0.0010378320143394737 Test RE 0.02334163100969274\n",
      "124 Train Loss 0.031737395 Test MSE 0.0013196517592222235 Test RE 0.026320694121366624\n",
      "125 Train Loss 0.031371724 Test MSE 0.001273757752608181 Test RE 0.025858961991064817\n",
      "126 Train Loss 0.030225882 Test MSE 0.001321895204416395 Test RE 0.026343057581792804\n",
      "127 Train Loss 0.028780917 Test MSE 0.0013728882602238928 Test RE 0.02684635095545666\n",
      "128 Train Loss 0.028305434 Test MSE 0.0013753613059533463 Test RE 0.02687051984944492\n",
      "129 Train Loss 0.027225135 Test MSE 0.001381265464270851 Test RE 0.026928133040254085\n",
      "130 Train Loss 0.026153853 Test MSE 0.0014287400588470982 Test RE 0.0273869884378379\n",
      "131 Train Loss 0.025274469 Test MSE 0.0012561614092890968 Test RE 0.02567972633879782\n",
      "132 Train Loss 0.024912123 Test MSE 0.0014942847588482041 Test RE 0.028008145317993036\n",
      "133 Train Loss 0.024343908 Test MSE 0.0016594609739392261 Test RE 0.029515570998876774\n",
      "134 Train Loss 0.023420502 Test MSE 0.0014006126181253496 Test RE 0.027116066164875115\n",
      "135 Train Loss 0.022683006 Test MSE 0.0013878407469690847 Test RE 0.026992150376416512\n",
      "136 Train Loss 0.022160174 Test MSE 0.001355321408274543 Test RE 0.02667404115087197\n",
      "137 Train Loss 0.021499192 Test MSE 0.0013848494349106499 Test RE 0.026963045632501292\n",
      "138 Train Loss 0.021163272 Test MSE 0.001184802590533982 Test RE 0.02493966785031201\n",
      "139 Train Loss 0.020930402 Test MSE 0.0011676920389448744 Test RE 0.024758927453494145\n",
      "140 Train Loss 0.020371262 Test MSE 0.0011467267035997007 Test RE 0.02453565354793813\n",
      "141 Train Loss 0.019516047 Test MSE 0.001247736708626343 Test RE 0.025593468328429212\n",
      "142 Train Loss 0.01875629 Test MSE 0.001262191406541498 Test RE 0.025741288209501452\n",
      "143 Train Loss 0.018338082 Test MSE 0.001165900448907024 Test RE 0.024739926349640725\n",
      "144 Train Loss 0.018124323 Test MSE 0.0012792943759691413 Test RE 0.02591510142959178\n",
      "145 Train Loss 0.017790308 Test MSE 0.0012990818847148481 Test RE 0.026114753510031015\n",
      "146 Train Loss 0.017358167 Test MSE 0.001629022889716918 Test RE 0.029243628691773937\n",
      "147 Train Loss 0.017052056 Test MSE 0.0018343850433394872 Test RE 0.0310322251814348\n",
      "148 Train Loss 0.016774151 Test MSE 0.001961362997772136 Test RE 0.0320882961035355\n",
      "149 Train Loss 0.016635517 Test MSE 0.002120258444745543 Test RE 0.03336276746279333\n",
      "150 Train Loss 0.016054824 Test MSE 0.00220035414004511 Test RE 0.033987088315689404\n",
      "151 Train Loss 0.015437764 Test MSE 0.002414949904707194 Test RE 0.03560588056902543\n",
      "152 Train Loss 0.0151668545 Test MSE 0.0024102219110790322 Test RE 0.03557100886151697\n",
      "153 Train Loss 0.01488173 Test MSE 0.002368897606938975 Test RE 0.03526475023377815\n",
      "154 Train Loss 0.014595767 Test MSE 0.002597905673011125 Test RE 0.036930004178682245\n",
      "155 Train Loss 0.014354594 Test MSE 0.002671867296346469 Test RE 0.03745200819691967\n",
      "156 Train Loss 0.0140943425 Test MSE 0.0024865674890144343 Test RE 0.03612998599314642\n",
      "157 Train Loss 0.013797468 Test MSE 0.0022902840188012506 Test RE 0.03467467019262414\n",
      "158 Train Loss 0.013507856 Test MSE 0.0025427121440366705 Test RE 0.03653560188446569\n",
      "159 Train Loss 0.013304029 Test MSE 0.002582648071995593 Test RE 0.036821398807842284\n",
      "160 Train Loss 0.013071909 Test MSE 0.0024897610141407715 Test RE 0.03615317961161337\n",
      "161 Train Loss 0.012837908 Test MSE 0.0024231166503874114 Test RE 0.035666034766439834\n",
      "162 Train Loss 0.012549146 Test MSE 0.0023274472117683228 Test RE 0.03495486164380562\n",
      "163 Train Loss 0.012186657 Test MSE 0.0024088205615673836 Test RE 0.035560666522635814\n",
      "164 Train Loss 0.0119022885 Test MSE 0.0023641656046982863 Test RE 0.03522951099541032\n",
      "165 Train Loss 0.0116144875 Test MSE 0.002172711784556531 Test RE 0.03377292904731573\n",
      "166 Train Loss 0.011084022 Test MSE 0.0024021525660292754 Test RE 0.0355114136450509\n",
      "167 Train Loss 0.010518469 Test MSE 0.002178848277507348 Test RE 0.03382058866194138\n",
      "168 Train Loss 0.0102547575 Test MSE 0.0021193869307756076 Test RE 0.03335591001895725\n",
      "169 Train Loss 0.0101485485 Test MSE 0.0020557307579519963 Test RE 0.03285116568380328\n",
      "170 Train Loss 0.010054496 Test MSE 0.0021137371124233272 Test RE 0.03331142059791592\n",
      "171 Train Loss 0.009803954 Test MSE 0.0020280741672081717 Test RE 0.03262943729126635\n",
      "172 Train Loss 0.0096521005 Test MSE 0.0018462273257903391 Test RE 0.031132231768521125\n",
      "173 Train Loss 0.009440904 Test MSE 0.0016843965762243303 Test RE 0.02973649945983417\n",
      "174 Train Loss 0.009281417 Test MSE 0.0016351639787946129 Test RE 0.029298698143450104\n",
      "175 Train Loss 0.009134944 Test MSE 0.0013926900662542018 Test RE 0.02703926652236286\n",
      "176 Train Loss 0.009041096 Test MSE 0.0014608952067598818 Test RE 0.027693458735056818\n",
      "177 Train Loss 0.008933176 Test MSE 0.0014836451190512968 Test RE 0.02790825507847215\n",
      "178 Train Loss 0.008780574 Test MSE 0.0014145938726793366 Test RE 0.027251069663717053\n",
      "179 Train Loss 0.008574552 Test MSE 0.0013938255767398492 Test RE 0.027050287321448957\n",
      "180 Train Loss 0.008370232 Test MSE 0.001204385284897812 Test RE 0.025144927513341134\n",
      "181 Train Loss 0.0082434295 Test MSE 0.0012188721059099325 Test RE 0.025295702025298426\n",
      "182 Train Loss 0.0081490185 Test MSE 0.0011692704484765305 Test RE 0.024775655549750805\n",
      "183 Train Loss 0.008057857 Test MSE 0.001237998221304482 Test RE 0.025493395171880706\n",
      "184 Train Loss 0.008009556 Test MSE 0.001211161525637625 Test RE 0.025215564830280243\n",
      "185 Train Loss 0.007924839 Test MSE 0.0012065824000591675 Test RE 0.02516785253956702\n",
      "186 Train Loss 0.007872231 Test MSE 0.0012304429397148565 Test RE 0.02541548530829099\n",
      "187 Train Loss 0.007814262 Test MSE 0.0012169956841601647 Test RE 0.02527622348967581\n",
      "188 Train Loss 0.0077411626 Test MSE 0.001226325281012369 Test RE 0.025372923401511732\n",
      "189 Train Loss 0.007646344 Test MSE 0.0012556483181142607 Test RE 0.02567448123788797\n",
      "190 Train Loss 0.007536149 Test MSE 0.0011556262833357334 Test RE 0.024630678361270975\n",
      "191 Train Loss 0.007445684 Test MSE 0.0011809462460126627 Test RE 0.0248990474384245\n",
      "192 Train Loss 0.0073515787 Test MSE 0.0011406118908488705 Test RE 0.02447014906975599\n",
      "193 Train Loss 0.007261442 Test MSE 0.0011778885811181117 Test RE 0.024866792673396237\n",
      "194 Train Loss 0.007112649 Test MSE 0.0010848410243760557 Test RE 0.02386441087601896\n",
      "195 Train Loss 0.0070133884 Test MSE 0.0010668893918560414 Test RE 0.023666136556334\n",
      "196 Train Loss 0.0069284225 Test MSE 0.001019000725015002 Test RE 0.02312889657766657\n",
      "197 Train Loss 0.006851462 Test MSE 0.0010378545019696104 Test RE 0.02334188389027185\n",
      "198 Train Loss 0.006785337 Test MSE 0.0010082958499123425 Test RE 0.023007088203990618\n",
      "199 Train Loss 0.0066758427 Test MSE 0.000971315676310697 Test RE 0.022581244162358648\n",
      "200 Train Loss 0.0066029057 Test MSE 0.0009245855271095674 Test RE 0.022031355235490404\n",
      "201 Train Loss 0.0065538557 Test MSE 0.0009037956817856261 Test RE 0.02178225303007174\n",
      "202 Train Loss 0.0065269982 Test MSE 0.0009062631715532712 Test RE 0.021811967075506023\n",
      "203 Train Loss 0.00650068 Test MSE 0.0009271232083090244 Test RE 0.022061568906523606\n",
      "204 Train Loss 0.0064640483 Test MSE 0.0008952275804465855 Test RE 0.021678757854373506\n",
      "205 Train Loss 0.006374731 Test MSE 0.0009051689006079957 Test RE 0.021798794626337534\n",
      "206 Train Loss 0.0062576854 Test MSE 0.0008555086068848976 Test RE 0.021192386174644078\n",
      "207 Train Loss 0.0062082 Test MSE 0.0008983801247798788 Test RE 0.021716895186563355\n",
      "208 Train Loss 0.0061626425 Test MSE 0.0008835276809641239 Test RE 0.021536630048919765\n",
      "209 Train Loss 0.0060752393 Test MSE 0.0008602455273099339 Test RE 0.021250975924755795\n",
      "210 Train Loss 0.006011849 Test MSE 0.0008651582213245304 Test RE 0.02131156962252306\n",
      "211 Train Loss 0.0059542074 Test MSE 0.0008854840140104988 Test RE 0.021560460385439635\n",
      "212 Train Loss 0.005907523 Test MSE 0.0009142796775927418 Test RE 0.02190822542128151\n",
      "213 Train Loss 0.005865784 Test MSE 0.0008786813233734171 Test RE 0.02147748208108899\n",
      "214 Train Loss 0.0057680435 Test MSE 0.0008195871624755169 Test RE 0.020742697852985336\n",
      "215 Train Loss 0.005700099 Test MSE 0.0008486921341443808 Test RE 0.021107789583034043\n",
      "216 Train Loss 0.005593805 Test MSE 0.0007535022118703838 Test RE 0.01988886195453071\n",
      "217 Train Loss 0.0054979357 Test MSE 0.0007137182929377447 Test RE 0.019356689414127375\n",
      "218 Train Loss 0.0054493365 Test MSE 0.0006938716143659522 Test RE 0.019085661996561448\n",
      "219 Train Loss 0.0053988113 Test MSE 0.0006914723729423324 Test RE 0.01905263660529271\n",
      "220 Train Loss 0.0053679347 Test MSE 0.0007124335383381 Test RE 0.019339259710073064\n",
      "221 Train Loss 0.005343151 Test MSE 0.0007026626856921821 Test RE 0.019206185242978752\n",
      "222 Train Loss 0.005275582 Test MSE 0.0007019078103027379 Test RE 0.019195865801763863\n",
      "223 Train Loss 0.0052253483 Test MSE 0.0006515722658922034 Test RE 0.018494771192058942\n",
      "224 Train Loss 0.0051675416 Test MSE 0.0006469621378522856 Test RE 0.018429226185488954\n",
      "225 Train Loss 0.0051037204 Test MSE 0.0006046182468158271 Test RE 0.01781592158269265\n",
      "226 Train Loss 0.0050710877 Test MSE 0.0005807073911114734 Test RE 0.0174600846323939\n",
      "227 Train Loss 0.005036365 Test MSE 0.0005840844291377142 Test RE 0.01751077960830036\n",
      "228 Train Loss 0.0049892575 Test MSE 0.0005766881340966094 Test RE 0.017399556370447298\n",
      "229 Train Loss 0.0049304324 Test MSE 0.0005565786048954311 Test RE 0.01709349705869381\n",
      "230 Train Loss 0.0048623243 Test MSE 0.0005424356862391014 Test RE 0.016874922789953693\n",
      "231 Train Loss 0.004800834 Test MSE 0.000530046057439061 Test RE 0.01668109178124507\n",
      "232 Train Loss 0.0047714743 Test MSE 0.0005231622898750143 Test RE 0.016572418184686005\n",
      "233 Train Loss 0.00474641 Test MSE 0.0005239147525572193 Test RE 0.01658433193092209\n",
      "234 Train Loss 0.0046858597 Test MSE 0.0005319798459801976 Test RE 0.016711493229820525\n",
      "235 Train Loss 0.004664626 Test MSE 0.0005305754483877933 Test RE 0.01668941993971767\n",
      "236 Train Loss 0.0046205437 Test MSE 0.0005180317350115996 Test RE 0.016490956668232293\n",
      "237 Train Loss 0.0045891246 Test MSE 0.0005351791696596895 Test RE 0.016761669314461512\n",
      "238 Train Loss 0.0045541083 Test MSE 0.0005287419307238707 Test RE 0.01666055804208243\n",
      "239 Train Loss 0.0045011565 Test MSE 0.0005437812542862891 Test RE 0.01689583982541953\n",
      "240 Train Loss 0.004458377 Test MSE 0.000533741348679487 Test RE 0.016739138085667928\n",
      "241 Train Loss 0.0044126506 Test MSE 0.0005316363071584764 Test RE 0.016706096433408958\n",
      "242 Train Loss 0.004357691 Test MSE 0.0005387520939735819 Test RE 0.01681752775984125\n",
      "243 Train Loss 0.0042825574 Test MSE 0.0005039007013648208 Test RE 0.016264478737128555\n",
      "244 Train Loss 0.0042223474 Test MSE 0.0004893518810399794 Test RE 0.01602796179949719\n",
      "245 Train Loss 0.0041740783 Test MSE 0.00047679140828646926 Test RE 0.01582092523109481\n",
      "246 Train Loss 0.0041474756 Test MSE 0.00047551749649959074 Test RE 0.015799775580339993\n",
      "247 Train Loss 0.004097125 Test MSE 0.0004716546379278352 Test RE 0.01573547010922739\n",
      "248 Train Loss 0.0040312414 Test MSE 0.0004866392355616797 Test RE 0.015983475816107987\n",
      "249 Train Loss 0.0039377357 Test MSE 0.00045927308047346026 Test RE 0.015527558102561826\n",
      "250 Train Loss 0.0038587828 Test MSE 0.00046447141595479653 Test RE 0.015615186074575486\n",
      "251 Train Loss 0.0038191455 Test MSE 0.00046843471093265264 Test RE 0.015681666084239015\n",
      "252 Train Loss 0.0037717149 Test MSE 0.00045817686015742665 Test RE 0.015509015981794225\n",
      "253 Train Loss 0.0037213068 Test MSE 0.0004335072006819533 Test RE 0.015085712454451847\n",
      "254 Train Loss 0.003636548 Test MSE 0.00042128469121595043 Test RE 0.014871525036599687\n",
      "255 Train Loss 0.0035659708 Test MSE 0.0004059118030339571 Test RE 0.014597668855702286\n",
      "256 Train Loss 0.0035171441 Test MSE 0.00038950174745326784 Test RE 0.01429955007309789\n",
      "257 Train Loss 0.0034936913 Test MSE 0.00038670855083347756 Test RE 0.014248185322894458\n",
      "258 Train Loss 0.003469101 Test MSE 0.00038017608186635725 Test RE 0.014127329119634368\n",
      "259 Train Loss 0.0034417992 Test MSE 0.0003822994800401662 Test RE 0.014166726882877217\n",
      "260 Train Loss 0.0034153233 Test MSE 0.00038353513100779576 Test RE 0.014189602937758823\n",
      "261 Train Loss 0.0033592673 Test MSE 0.00038124826902571527 Test RE 0.014147236311323051\n",
      "262 Train Loss 0.0033092774 Test MSE 0.0003774254834855802 Test RE 0.01407613027782331\n",
      "263 Train Loss 0.0032843926 Test MSE 0.0003707321543967675 Test RE 0.013950757676697194\n",
      "264 Train Loss 0.0032354675 Test MSE 0.0003822222838849477 Test RE 0.014165296496338058\n",
      "265 Train Loss 0.0031734633 Test MSE 0.0003575907688782908 Test RE 0.01370126976250679\n",
      "266 Train Loss 0.0031316946 Test MSE 0.0003521462504062737 Test RE 0.013596564957826917\n",
      "267 Train Loss 0.003076073 Test MSE 0.00033701155012410156 Test RE 0.01330117662108401\n",
      "268 Train Loss 0.0030283732 Test MSE 0.00032401857894786656 Test RE 0.013042253106191606\n",
      "269 Train Loss 0.0029736892 Test MSE 0.0003179853831219781 Test RE 0.012920259791447104\n",
      "270 Train Loss 0.0029282954 Test MSE 0.0003226624675734696 Test RE 0.013014931690382387\n",
      "271 Train Loss 0.0028722167 Test MSE 0.00031897538146794874 Test RE 0.012940356777410707\n",
      "272 Train Loss 0.0028414165 Test MSE 0.0003066670334809823 Test RE 0.012688235001212718\n",
      "273 Train Loss 0.0028199812 Test MSE 0.0003041003328006901 Test RE 0.01263502528507285\n",
      "274 Train Loss 0.0027919249 Test MSE 0.0003092669710939702 Test RE 0.012741907210627965\n",
      "275 Train Loss 0.0027446744 Test MSE 0.000300847008637602 Test RE 0.012567257577852327\n",
      "276 Train Loss 0.0026771564 Test MSE 0.0003090171943361294 Test RE 0.012736760726465091\n",
      "277 Train Loss 0.002605465 Test MSE 0.0002952343376996327 Test RE 0.012449476832493976\n",
      "278 Train Loss 0.0025405297 Test MSE 0.0002832174308374555 Test RE 0.012193479629238365\n",
      "279 Train Loss 0.0024998884 Test MSE 0.00026385367400640904 Test RE 0.011769262260768253\n",
      "280 Train Loss 0.0024852734 Test MSE 0.00025993844199520067 Test RE 0.01168161593247009\n",
      "281 Train Loss 0.0024716002 Test MSE 0.0002633164480462182 Test RE 0.011757274603359819\n",
      "282 Train Loss 0.0024520797 Test MSE 0.00026800410961693035 Test RE 0.011861466713976912\n",
      "283 Train Loss 0.00243786 Test MSE 0.00027231130820467805 Test RE 0.011956401928336817\n",
      "284 Train Loss 0.0024218448 Test MSE 0.00027856986602195613 Test RE 0.012093019002525096\n",
      "285 Train Loss 0.0024063557 Test MSE 0.00027672775861134426 Test RE 0.01205296874536085\n",
      "286 Train Loss 0.0023896217 Test MSE 0.00026853341415675354 Test RE 0.011873174055598294\n",
      "287 Train Loss 0.0023581476 Test MSE 0.00026258318450936746 Test RE 0.011740892810470976\n",
      "288 Train Loss 0.0023364485 Test MSE 0.0002459649274583839 Test RE 0.011363294439537553\n",
      "289 Train Loss 0.0023146996 Test MSE 0.00024211463643498867 Test RE 0.011274004137291798\n",
      "290 Train Loss 0.002287961 Test MSE 0.00023828478520168482 Test RE 0.011184480692160522\n",
      "291 Train Loss 0.0022627327 Test MSE 0.00023584789444368063 Test RE 0.011127142998538845\n",
      "292 Train Loss 0.0022456162 Test MSE 0.00023613438355714466 Test RE 0.011133899128067781\n",
      "293 Train Loss 0.0022163056 Test MSE 0.0002357850433495066 Test RE 0.011125660263844534\n",
      "294 Train Loss 0.0021928232 Test MSE 0.00022994962882796007 Test RE 0.010987123952765243\n",
      "295 Train Loss 0.0021666754 Test MSE 0.00023362729729700513 Test RE 0.011074635982540364\n",
      "296 Train Loss 0.0021355413 Test MSE 0.00022727959864364932 Test RE 0.010923149924176511\n",
      "297 Train Loss 0.0021222848 Test MSE 0.00023080196823573287 Test RE 0.011007467749100656\n",
      "298 Train Loss 0.0020980032 Test MSE 0.00023214034824966368 Test RE 0.011039336799718802\n",
      "299 Train Loss 0.0020707494 Test MSE 0.00022809878549392382 Test RE 0.010942817444696332\n",
      "Training time: 164.76\n",
      "KG_tanh_medium\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 39456.43 Test MSE 12.80901219490119 Test RE 2.593137151018265\n",
      "1 Train Loss 26455.994 Test MSE 16.629776785889472 Test RE 2.9546828923601614\n",
      "2 Train Loss 6898.4 Test MSE 19.634602515878665 Test RE 3.2105447268605882\n",
      "3 Train Loss 2883.1626 Test MSE 18.64040835924483 Test RE 3.128206245749452\n",
      "4 Train Loss 1160.9716 Test MSE 17.69432928119238 Test RE 3.047787756869871\n",
      "5 Train Loss 443.8845 Test MSE 9.6266563329 Test RE 2.2480470768064276\n",
      "6 Train Loss 204.21677 Test MSE 4.382321509425825 Test RE 1.5167701943544682\n",
      "7 Train Loss 105.82379 Test MSE 2.221888499580983 Test RE 1.0800125402119465\n",
      "8 Train Loss 71.854164 Test MSE 2.2161721131707814 Test RE 1.0786223388062333\n",
      "9 Train Loss 50.912888 Test MSE 2.0271276721013893 Test RE 1.0315926014840515\n",
      "10 Train Loss 36.6389 Test MSE 1.7872787073185874 Test RE 0.9686431428150176\n",
      "11 Train Loss 25.59448 Test MSE 1.1628624566611085 Test RE 0.7813252190201977\n",
      "12 Train Loss 14.810856 Test MSE 0.6905672764045514 Test RE 0.6021028252338351\n",
      "13 Train Loss 9.8028345 Test MSE 0.6445630587305997 Test RE 0.5817017541370101\n",
      "14 Train Loss 6.5250454 Test MSE 0.461214283411754 Test RE 0.49206110995295843\n",
      "15 Train Loss 4.918011 Test MSE 0.3092396377299822 Test RE 0.40291667890532257\n",
      "16 Train Loss 3.2607405 Test MSE 0.29852898716308063 Test RE 0.3958775933473752\n",
      "17 Train Loss 2.3743653 Test MSE 0.23766359237753784 Test RE 0.353223017537916\n",
      "18 Train Loss 1.8930236 Test MSE 0.2720638159273226 Test RE 0.377922770942653\n",
      "19 Train Loss 1.5382096 Test MSE 0.22862347721464363 Test RE 0.3464400403811884\n",
      "20 Train Loss 1.2864175 Test MSE 0.1351311667975827 Test RE 0.2663455413249252\n",
      "21 Train Loss 1.0085891 Test MSE 0.09089605140951952 Test RE 0.21844402815979416\n",
      "22 Train Loss 0.87111485 Test MSE 0.06195736811295244 Test RE 0.18034917009741191\n",
      "23 Train Loss 0.78449917 Test MSE 0.05316418180533298 Test RE 0.16706183020142248\n",
      "24 Train Loss 0.6385111 Test MSE 0.05036742362803325 Test RE 0.16260823502595842\n",
      "25 Train Loss 0.5714011 Test MSE 0.04569184793881784 Test RE 0.15487703615418152\n",
      "26 Train Loss 0.53596306 Test MSE 0.04360252168438245 Test RE 0.15129461516800555\n",
      "27 Train Loss 0.47782052 Test MSE 0.03484334866590606 Test RE 0.13524699081896133\n",
      "28 Train Loss 0.44622847 Test MSE 0.030570518816084823 Test RE 0.1266832137738404\n",
      "29 Train Loss 0.40724507 Test MSE 0.03192834389424219 Test RE 0.12946603986195013\n",
      "30 Train Loss 0.3744706 Test MSE 0.02876604441970159 Test RE 0.12288750902919932\n",
      "31 Train Loss 0.34488884 Test MSE 0.03295232417413359 Test RE 0.1315257216534957\n",
      "32 Train Loss 0.3049193 Test MSE 0.019970132064592635 Test RE 0.10239013983228873\n",
      "33 Train Loss 0.27125204 Test MSE 0.01719848739060278 Test RE 0.09501951159894827\n",
      "34 Train Loss 0.24944738 Test MSE 0.0194282206683037 Test RE 0.10099135088086605\n",
      "35 Train Loss 0.23373418 Test MSE 0.02175377216950196 Test RE 0.10686486846553152\n",
      "36 Train Loss 0.21676932 Test MSE 0.03216770571832651 Test RE 0.1299504270870145\n",
      "37 Train Loss 0.20251864 Test MSE 0.030465228713777177 Test RE 0.12646486626312606\n",
      "38 Train Loss 0.19370364 Test MSE 0.03234225243615186 Test RE 0.13030251520893704\n",
      "39 Train Loss 0.1751438 Test MSE 0.030887617628283886 Test RE 0.12733854224506935\n",
      "40 Train Loss 0.16229844 Test MSE 0.02487689064064656 Test RE 0.11427881178375468\n",
      "41 Train Loss 0.14803803 Test MSE 0.017111404547712792 Test RE 0.09477864535355952\n",
      "42 Train Loss 0.13972355 Test MSE 0.014289794192577976 Test RE 0.08661251601095778\n",
      "43 Train Loss 0.13167724 Test MSE 0.013667313148484812 Test RE 0.08470503773023141\n",
      "44 Train Loss 0.12907888 Test MSE 0.01205783710158735 Test RE 0.07956139216958695\n",
      "45 Train Loss 0.12294388 Test MSE 0.010458412969905224 Test RE 0.07409698911087682\n",
      "46 Train Loss 0.12005526 Test MSE 0.011974525567394265 Test RE 0.0792860579314855\n",
      "47 Train Loss 0.11358165 Test MSE 0.010043704921403749 Test RE 0.07261304349262446\n",
      "48 Train Loss 0.10630689 Test MSE 0.0090069958923987 Test RE 0.068763448734289\n",
      "49 Train Loss 0.101151615 Test MSE 0.00614995190190661 Test RE 0.05682030063797406\n",
      "50 Train Loss 0.09862314 Test MSE 0.006132969980275721 Test RE 0.05674179718474287\n",
      "51 Train Loss 0.09252317 Test MSE 0.005972202791707552 Test RE 0.055993155221860595\n",
      "52 Train Loss 0.086884014 Test MSE 0.005534017369959523 Test RE 0.0538998959268421\n",
      "53 Train Loss 0.08516218 Test MSE 0.004256682128919613 Test RE 0.04727192388610577\n",
      "54 Train Loss 0.08245851 Test MSE 0.003919272362758423 Test RE 0.04535972262378415\n",
      "55 Train Loss 0.07581137 Test MSE 0.003431563243283889 Test RE 0.04244374252214643\n",
      "56 Train Loss 0.07325095 Test MSE 0.004163385545297007 Test RE 0.04675100838050853\n",
      "57 Train Loss 0.07012535 Test MSE 0.005725081361490575 Test RE 0.05482245744892413\n",
      "58 Train Loss 0.06563719 Test MSE 0.005865216038792724 Test RE 0.055489354710339264\n",
      "59 Train Loss 0.064216726 Test MSE 0.004931355157433712 Test RE 0.05088043416101519\n",
      "60 Train Loss 0.06256075 Test MSE 0.004454792108854774 Test RE 0.048359453961719284\n",
      "61 Train Loss 0.060524326 Test MSE 0.0037607307201667365 Test RE 0.04443281071019407\n",
      "62 Train Loss 0.05822492 Test MSE 0.004474979235725842 Test RE 0.04846890182577778\n",
      "63 Train Loss 0.056405995 Test MSE 0.004504782371144883 Test RE 0.04863003420520155\n",
      "64 Train Loss 0.05486236 Test MSE 0.004614347675488805 Test RE 0.049217871115276146\n",
      "65 Train Loss 0.052591603 Test MSE 0.00432045209234322 Test RE 0.04762470127013895\n",
      "66 Train Loss 0.050878353 Test MSE 0.004082706773075702 Test RE 0.046295818026059705\n",
      "67 Train Loss 0.050076507 Test MSE 0.004214306440541012 Test RE 0.04703603702752993\n",
      "68 Train Loss 0.04935169 Test MSE 0.0037461459965466852 Test RE 0.04434656819049045\n",
      "69 Train Loss 0.047078107 Test MSE 0.0028586656275469465 Test RE 0.03873908400715211\n",
      "70 Train Loss 0.04506493 Test MSE 0.0024834719555627462 Test RE 0.036107489839234085\n",
      "71 Train Loss 0.04444927 Test MSE 0.002398513245313944 Test RE 0.035484503112446136\n",
      "72 Train Loss 0.042439036 Test MSE 0.0021087535578601614 Test RE 0.03327212828322257\n",
      "73 Train Loss 0.039721653 Test MSE 0.0017362251626849732 Test RE 0.030190526765452478\n",
      "74 Train Loss 0.03765586 Test MSE 0.0016105874183333522 Test RE 0.029077684411261923\n",
      "75 Train Loss 0.036166564 Test MSE 0.0016187486502275078 Test RE 0.029151263111711078\n",
      "76 Train Loss 0.035486132 Test MSE 0.0013543616652941797 Test RE 0.026664595141508624\n",
      "77 Train Loss 0.034726307 Test MSE 0.001215921701877415 Test RE 0.025265068064787018\n",
      "78 Train Loss 0.033643745 Test MSE 0.0010782059337136884 Test RE 0.023791319343442318\n",
      "79 Train Loss 0.032784186 Test MSE 0.0010584397871846135 Test RE 0.02357223412964512\n",
      "80 Train Loss 0.031871676 Test MSE 0.0009137130836838934 Test RE 0.02190143592834931\n",
      "81 Train Loss 0.031075163 Test MSE 0.0008810991607555268 Test RE 0.02150701120836113\n",
      "82 Train Loss 0.030420784 Test MSE 0.0008550490787207769 Test RE 0.02118669376762436\n",
      "83 Train Loss 0.02971452 Test MSE 0.0008408569541872717 Test RE 0.02101012942879108\n",
      "84 Train Loss 0.028578162 Test MSE 0.000925664274933835 Test RE 0.022044203883681373\n",
      "85 Train Loss 0.027376221 Test MSE 0.0008237741214820806 Test RE 0.02079561363338439\n",
      "86 Train Loss 0.026005182 Test MSE 0.0008658697053172753 Test RE 0.021320330866519313\n",
      "87 Train Loss 0.025264885 Test MSE 0.0007895068680070858 Test RE 0.020358492850584838\n",
      "88 Train Loss 0.024779497 Test MSE 0.0008223337455370392 Test RE 0.020777425026941753\n",
      "89 Train Loss 0.024169508 Test MSE 0.0007774733554051185 Test RE 0.020202746983538963\n",
      "90 Train Loss 0.023852075 Test MSE 0.0008105293379171427 Test RE 0.020627758452179002\n",
      "91 Train Loss 0.023254048 Test MSE 0.0008179904755710309 Test RE 0.02072248295587545\n",
      "92 Train Loss 0.022925083 Test MSE 0.0008069195533053584 Test RE 0.02058177316042863\n",
      "93 Train Loss 0.022503944 Test MSE 0.0008798340525527016 Test RE 0.021491565460997633\n",
      "94 Train Loss 0.02197885 Test MSE 0.0008852024178800751 Test RE 0.021557031850938716\n",
      "95 Train Loss 0.02131747 Test MSE 0.0008628006176175569 Test RE 0.02128251221394829\n",
      "96 Train Loss 0.020965252 Test MSE 0.0008892779365898707 Test RE 0.021606599720088483\n",
      "97 Train Loss 0.02054909 Test MSE 0.0008126989272509208 Test RE 0.020655347741001265\n",
      "98 Train Loss 0.02004609 Test MSE 0.0008422279411255932 Test RE 0.02102725058192975\n",
      "99 Train Loss 0.019514328 Test MSE 0.0008275572053711096 Test RE 0.020843309617779523\n",
      "100 Train Loss 0.018912528 Test MSE 0.0008009891766843777 Test RE 0.02050600181711281\n",
      "101 Train Loss 0.018408518 Test MSE 0.0008254743584132538 Test RE 0.02081706322987298\n",
      "102 Train Loss 0.018098054 Test MSE 0.0007516460459576909 Test RE 0.01986434988921911\n",
      "103 Train Loss 0.017686917 Test MSE 0.000749584092783188 Test RE 0.019837084736576815\n",
      "104 Train Loss 0.017203193 Test MSE 0.0007667259270847563 Test RE 0.02006262438466889\n",
      "105 Train Loss 0.01690148 Test MSE 0.0007227011585631492 Test RE 0.01947812027033881\n",
      "106 Train Loss 0.01661261 Test MSE 0.0006550525328749161 Test RE 0.018544098812775873\n",
      "107 Train Loss 0.016264286 Test MSE 0.0005991894180155851 Test RE 0.01773575721561331\n",
      "108 Train Loss 0.01587184 Test MSE 0.0005571617625200907 Test RE 0.017102449606783407\n",
      "109 Train Loss 0.015570432 Test MSE 0.0005172375184055342 Test RE 0.01647831032376631\n",
      "110 Train Loss 0.015428979 Test MSE 0.0005066184157948198 Test RE 0.016308279796634514\n",
      "111 Train Loss 0.015124638 Test MSE 0.00047280923808355936 Test RE 0.015754718378557558\n",
      "112 Train Loss 0.014770237 Test MSE 0.0004459061673127275 Test RE 0.015299928709035498\n",
      "113 Train Loss 0.014492021 Test MSE 0.0004396611399259014 Test RE 0.015192411265564101\n",
      "114 Train Loss 0.0143573545 Test MSE 0.0004144517110970881 Test RE 0.014750428479378042\n",
      "115 Train Loss 0.014183642 Test MSE 0.0004067170158909073 Test RE 0.014612140481155732\n",
      "116 Train Loss 0.013936286 Test MSE 0.0003917347497010031 Test RE 0.014340480946461625\n",
      "117 Train Loss 0.013796491 Test MSE 0.00037921521446933657 Test RE 0.01410946492644055\n",
      "118 Train Loss 0.0136600165 Test MSE 0.0004029948445686898 Test RE 0.014545123490027692\n",
      "119 Train Loss 0.013390737 Test MSE 0.0003686502293467531 Test RE 0.013911530808029043\n",
      "120 Train Loss 0.013165304 Test MSE 0.0003929695622400324 Test RE 0.014363064943887274\n",
      "121 Train Loss 0.013067785 Test MSE 0.00039548256713655463 Test RE 0.014408917007990341\n",
      "122 Train Loss 0.012924087 Test MSE 0.00040663448791156245 Test RE 0.014610657912735319\n",
      "123 Train Loss 0.012827824 Test MSE 0.000390437957405915 Test RE 0.014316725023313\n",
      "124 Train Loss 0.012577147 Test MSE 0.00034180382569237976 Test RE 0.013395413593128142\n",
      "125 Train Loss 0.012260586 Test MSE 0.00035770239603780184 Test RE 0.013703408120957645\n",
      "126 Train Loss 0.011997034 Test MSE 0.00038499595318300774 Test RE 0.014216600185997961\n",
      "127 Train Loss 0.011724437 Test MSE 0.0004258244429055612 Test RE 0.014951437891387944\n",
      "128 Train Loss 0.011617264 Test MSE 0.0004172591101759755 Test RE 0.01480030214226286\n",
      "129 Train Loss 0.011468324 Test MSE 0.00037633371090438545 Test RE 0.014055756636527767\n",
      "130 Train Loss 0.011350622 Test MSE 0.0003691301378722875 Test RE 0.013920582871925706\n",
      "131 Train Loss 0.011151797 Test MSE 0.00036880217235236594 Test RE 0.01391439740335203\n",
      "132 Train Loss 0.010924907 Test MSE 0.0003681398587787995 Test RE 0.013901897700013634\n",
      "133 Train Loss 0.010679757 Test MSE 0.00034008022214814687 Test RE 0.013361596589052713\n",
      "134 Train Loss 0.010534276 Test MSE 0.0003143706935868382 Test RE 0.012846614565780845\n",
      "135 Train Loss 0.01041329 Test MSE 0.000304506719900317 Test RE 0.012643464928863108\n",
      "136 Train Loss 0.010299576 Test MSE 0.0003217791952255655 Test RE 0.012997105620633942\n",
      "137 Train Loss 0.01010761 Test MSE 0.00032835366641984415 Test RE 0.013129210235475265\n",
      "138 Train Loss 0.010038431 Test MSE 0.00032314074862103704 Test RE 0.013024574104282661\n",
      "139 Train Loss 0.009970412 Test MSE 0.00031302519883984187 Test RE 0.01281909357337231\n",
      "140 Train Loss 0.009910555 Test MSE 0.0003104903261486153 Test RE 0.012767083665559889\n",
      "141 Train Loss 0.009840337 Test MSE 0.00030124215414631514 Test RE 0.012575508060174876\n",
      "142 Train Loss 0.009690984 Test MSE 0.000314928263765512 Test RE 0.012858001943962083\n",
      "143 Train Loss 0.009603404 Test MSE 0.0003327239386475762 Test RE 0.01321629402313704\n",
      "144 Train Loss 0.009493149 Test MSE 0.00031811979676783786 Test RE 0.012922990224718309\n",
      "145 Train Loss 0.009385223 Test MSE 0.00032736230845312815 Test RE 0.013109375545677808\n",
      "146 Train Loss 0.009241638 Test MSE 0.0003384985269762218 Test RE 0.01333048833577101\n",
      "147 Train Loss 0.008992406 Test MSE 0.0003993784798427341 Test RE 0.014479714452873736\n",
      "148 Train Loss 0.008732916 Test MSE 0.0003939590324966436 Test RE 0.01438113617899868\n",
      "149 Train Loss 0.008588352 Test MSE 0.0003607871969012835 Test RE 0.013762369897886078\n",
      "150 Train Loss 0.0084300665 Test MSE 0.00030358186463000147 Test RE 0.012624249806880056\n",
      "151 Train Loss 0.008269685 Test MSE 0.00030825218742298996 Test RE 0.012720985313195638\n",
      "152 Train Loss 0.008152087 Test MSE 0.0002618639404541496 Test RE 0.011724801989662604\n",
      "153 Train Loss 0.008055755 Test MSE 0.0002782030537240854 Test RE 0.012085054520637645\n",
      "154 Train Loss 0.007981713 Test MSE 0.0003043515781110937 Test RE 0.012640243686852182\n",
      "155 Train Loss 0.007827228 Test MSE 0.00027436474916895726 Test RE 0.012001397588755465\n",
      "156 Train Loss 0.0077150348 Test MSE 0.0002715118807973246 Test RE 0.011938838756137975\n",
      "157 Train Loss 0.0076530734 Test MSE 0.0002680853663508109 Test RE 0.011863264729314621\n",
      "158 Train Loss 0.0075817304 Test MSE 0.0002754499404014693 Test RE 0.012025108649778168\n",
      "159 Train Loss 0.007509411 Test MSE 0.00028549330768260476 Test RE 0.012242373743391153\n",
      "160 Train Loss 0.0074718236 Test MSE 0.0002933289730940711 Test RE 0.012409238985104324\n",
      "161 Train Loss 0.0074277096 Test MSE 0.0003051812125529409 Test RE 0.012657460033821745\n",
      "162 Train Loss 0.0073753055 Test MSE 0.0003297893115931226 Test RE 0.013157881042478526\n",
      "163 Train Loss 0.007283972 Test MSE 0.00031082524051080835 Test RE 0.012773967498784778\n",
      "164 Train Loss 0.0071803196 Test MSE 0.0003378526903573647 Test RE 0.013317765343975455\n",
      "165 Train Loss 0.0071156733 Test MSE 0.00033939481146243227 Test RE 0.013348125061488587\n",
      "166 Train Loss 0.007010209 Test MSE 0.0003524285929332683 Test RE 0.013602014567655295\n",
      "167 Train Loss 0.0069361376 Test MSE 0.0003457810247926527 Test RE 0.013473122118734759\n",
      "168 Train Loss 0.0068203844 Test MSE 0.00035175022351940655 Test RE 0.013588917396576371\n",
      "169 Train Loss 0.00673334 Test MSE 0.00037249078539066505 Test RE 0.013983807424035797\n",
      "170 Train Loss 0.0067010014 Test MSE 0.00038436872460577984 Test RE 0.014205014748964694\n",
      "171 Train Loss 0.0066511417 Test MSE 0.00039372552898771587 Test RE 0.014376873624751181\n",
      "172 Train Loss 0.006601542 Test MSE 0.0004209484394839556 Test RE 0.014865588938794501\n",
      "173 Train Loss 0.00655048 Test MSE 0.00042029168157721247 Test RE 0.014853987869409375\n",
      "174 Train Loss 0.0064819804 Test MSE 0.00040550760546547305 Test RE 0.014590399035262594\n",
      "175 Train Loss 0.006419316 Test MSE 0.000417359791020011 Test RE 0.014802087623992129\n",
      "176 Train Loss 0.006359889 Test MSE 0.0003951183792874384 Test RE 0.014402281113561911\n",
      "177 Train Loss 0.006299003 Test MSE 0.00040707878084595745 Test RE 0.014618637609604237\n",
      "178 Train Loss 0.0062707644 Test MSE 0.0004150955076931132 Test RE 0.014761880465757044\n",
      "179 Train Loss 0.0062278206 Test MSE 0.00042372174135562056 Test RE 0.01491447745073047\n",
      "180 Train Loss 0.006162984 Test MSE 0.00042938529612513294 Test RE 0.01501382162512002\n",
      "181 Train Loss 0.006119429 Test MSE 0.00042931426600664263 Test RE 0.015012579759544512\n",
      "182 Train Loss 0.0060772225 Test MSE 0.0004198304770403817 Test RE 0.014845835665441853\n",
      "183 Train Loss 0.006019653 Test MSE 0.0004108096440449531 Test RE 0.014685474478044172\n",
      "184 Train Loss 0.005963592 Test MSE 0.0004239480015908417 Test RE 0.014918458958496717\n",
      "185 Train Loss 0.00591561 Test MSE 0.0004579493478768491 Test RE 0.01550516492553397\n",
      "186 Train Loss 0.005880636 Test MSE 0.0004683387885189458 Test RE 0.0156800604172802\n",
      "187 Train Loss 0.005827575 Test MSE 0.00047024784151246694 Test RE 0.015711985622439417\n",
      "188 Train Loss 0.005759141 Test MSE 0.00048020593701316377 Test RE 0.015877474730558196\n",
      "189 Train Loss 0.005703732 Test MSE 0.00048254104645526207 Test RE 0.015916031811383628\n",
      "190 Train Loss 0.005670939 Test MSE 0.00046729817406125147 Test RE 0.01566263075760964\n",
      "191 Train Loss 0.005631176 Test MSE 0.00044948815373093944 Test RE 0.015361258333530107\n",
      "192 Train Loss 0.005565096 Test MSE 0.00042800079149871417 Test RE 0.01498959689169823\n",
      "193 Train Loss 0.005492294 Test MSE 0.00040971546556548 Test RE 0.014665904290068088\n",
      "194 Train Loss 0.005457679 Test MSE 0.0004015756128586704 Test RE 0.014519489034126101\n",
      "195 Train Loss 0.0054268544 Test MSE 0.00040441093534890343 Test RE 0.014570656264254448\n",
      "196 Train Loss 0.0053959712 Test MSE 0.0004082613036992387 Test RE 0.014639855047008253\n",
      "197 Train Loss 0.005362608 Test MSE 0.00040992744426270007 Test RE 0.014669697724212751\n",
      "198 Train Loss 0.005332635 Test MSE 0.0003838584005682849 Test RE 0.014195581660655909\n",
      "199 Train Loss 0.0052684154 Test MSE 0.0003719662696597198 Test RE 0.013973958440995957\n",
      "200 Train Loss 0.0052173752 Test MSE 0.00035597020022556795 Test RE 0.013670188057060368\n",
      "201 Train Loss 0.005161015 Test MSE 0.00034568926113867973 Test RE 0.013471334245971798\n",
      "202 Train Loss 0.0050788242 Test MSE 0.00035975142831148215 Test RE 0.013742600798471392\n",
      "203 Train Loss 0.004988206 Test MSE 0.00035667606705470673 Test RE 0.013683734912276643\n",
      "204 Train Loss 0.004909263 Test MSE 0.0003932562355169704 Test RE 0.014368302952919248\n",
      "205 Train Loss 0.0048143608 Test MSE 0.0003702707395985349 Test RE 0.013942073387897732\n",
      "206 Train Loss 0.004763661 Test MSE 0.0003628701421724889 Test RE 0.013802040107317157\n",
      "207 Train Loss 0.004716721 Test MSE 0.00035503802550255 Test RE 0.013652277348263735\n",
      "208 Train Loss 0.004676722 Test MSE 0.00036148747335659894 Test RE 0.013775719583964296\n",
      "209 Train Loss 0.004652281 Test MSE 0.00035964645969106915 Test RE 0.013740595737511116\n",
      "210 Train Loss 0.0046275957 Test MSE 0.00035502635917241017 Test RE 0.013652053043722138\n",
      "211 Train Loss 0.0046023163 Test MSE 0.00035648548764288595 Test RE 0.013680078672286647\n",
      "212 Train Loss 0.004574411 Test MSE 0.0003720809255627289 Test RE 0.013976111960692473\n",
      "213 Train Loss 0.004534613 Test MSE 0.0003532551327304741 Test RE 0.01361795541719535\n",
      "214 Train Loss 0.0045136297 Test MSE 0.00035466471527856384 Test RE 0.013645098011458983\n",
      "215 Train Loss 0.004489464 Test MSE 0.00037437149609497036 Test RE 0.014019065186453532\n",
      "216 Train Loss 0.0044807196 Test MSE 0.00036595591177382176 Test RE 0.013860600663752233\n",
      "217 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "218 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "219 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "220 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "221 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "222 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "223 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "224 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "225 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "226 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "227 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "228 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "229 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "230 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "231 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "232 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "233 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "234 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "235 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "236 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "237 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "238 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "239 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "240 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "241 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "242 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "243 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "244 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "245 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "246 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "247 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "248 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "249 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "250 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "251 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "252 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "253 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "254 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "255 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "256 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "257 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "258 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "259 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "260 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "261 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "262 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "263 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "264 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "265 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "266 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "267 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "268 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "269 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "270 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "271 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "272 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "273 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "274 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "275 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "276 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "277 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "278 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "279 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "280 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "281 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "282 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "283 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "284 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "285 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "286 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "287 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "288 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "289 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "290 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "291 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "292 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "293 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "294 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "295 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "296 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "297 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "298 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "299 Train Loss 0.0044805203 Test MSE 0.00036597351704117747 Test RE 0.013860934059986334\n",
      "Training time: 134.53\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9790669fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.15938184126387894\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
