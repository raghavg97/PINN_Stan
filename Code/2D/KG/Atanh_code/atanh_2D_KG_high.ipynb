{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"high\"\n",
    "label = \"KG_atanh_\" + level\n",
    "\n",
    "x = np.linspace(-2,2,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(1.0)\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "                    \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_atanh_high\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 61232.652 Test MSE 5.368527882370035 Test RE 1.6740309511934262\n",
      "1 Train Loss 40905.07 Test MSE 6.467430922405771 Test RE 1.8373918102911404\n",
      "2 Train Loss 29339.887 Test MSE 8.031517820058324 Test RE 2.0475508239167284\n",
      "3 Train Loss 22482.615 Test MSE 7.579274106496141 Test RE 1.9890682437128342\n",
      "4 Train Loss 17566.557 Test MSE 8.37618599595645 Test RE 2.0910240750668927\n",
      "5 Train Loss 8946.318 Test MSE 6.915131962715303 Test RE 1.899923493363062\n",
      "6 Train Loss 3540.4968 Test MSE 14.05721715748814 Test RE 2.708853722443791\n",
      "7 Train Loss 1556.7786 Test MSE 14.590921821267882 Test RE 2.75979766041886\n",
      "8 Train Loss 876.4149 Test MSE 15.181252866332532 Test RE 2.8150731463802376\n",
      "9 Train Loss 511.6543 Test MSE 14.968156143053374 Test RE 2.7952459658415227\n",
      "10 Train Loss 315.4944 Test MSE 15.69383700826316 Test RE 2.8622030871637114\n",
      "11 Train Loss 224.5887 Test MSE 15.895517487556253 Test RE 2.8805353713439423\n",
      "12 Train Loss 154.94565 Test MSE 16.513359897193595 Test RE 2.935983428469646\n",
      "13 Train Loss 122.306366 Test MSE 16.958547949390045 Test RE 2.9752962079065868\n",
      "14 Train Loss 97.75317 Test MSE 17.318882604148676 Test RE 3.0067395557794\n",
      "15 Train Loss 84.83374 Test MSE 17.323525595013916 Test RE 3.007142564711616\n",
      "16 Train Loss 74.962135 Test MSE 17.52632098399677 Test RE 3.0246926955359696\n",
      "17 Train Loss 64.53636 Test MSE 17.275176017374726 Test RE 3.002943198311407\n",
      "18 Train Loss 56.675716 Test MSE 17.093022068778904 Test RE 2.9870693358659204\n",
      "19 Train Loss 51.95571 Test MSE 17.088194795870834 Test RE 2.986647514112641\n",
      "20 Train Loss 46.93275 Test MSE 17.018865515832537 Test RE 2.9805827257680213\n",
      "21 Train Loss 42.239464 Test MSE 16.940095288852078 Test RE 2.973677051772951\n",
      "22 Train Loss 39.245365 Test MSE 16.90128398520995 Test RE 2.970268615696499\n",
      "23 Train Loss 37.108486 Test MSE 16.912368536554776 Test RE 2.9712424676989806\n",
      "24 Train Loss 34.259735 Test MSE 16.76272584360646 Test RE 2.9580683040066114\n",
      "25 Train Loss 31.50559 Test MSE 16.625161375789904 Test RE 2.945905502923703\n",
      "26 Train Loss 30.350445 Test MSE 16.641267612440622 Test RE 2.94733213464341\n",
      "27 Train Loss 28.9607 Test MSE 16.4704827485941 Test RE 2.932169291875666\n",
      "28 Train Loss 27.426615 Test MSE 16.31992302550714 Test RE 2.9187367737461773\n",
      "29 Train Loss 26.710735 Test MSE 16.28233789546673 Test RE 2.915373879973593\n",
      "30 Train Loss 25.927284 Test MSE 16.165711954857663 Test RE 2.9049141026372585\n",
      "31 Train Loss 25.133718 Test MSE 16.035319750748037 Test RE 2.8931749026158293\n",
      "32 Train Loss 24.34121 Test MSE 15.86442034490845 Test RE 2.877716329027323\n",
      "33 Train Loss 23.635647 Test MSE 15.767756941166297 Test RE 2.8689358355102548\n",
      "34 Train Loss 22.994713 Test MSE 15.609301060455348 Test RE 2.8544839499152643\n",
      "35 Train Loss 21.7066 Test MSE 15.434927711746631 Test RE 2.8384952827418752\n",
      "36 Train Loss 21.249676 Test MSE 15.320874317568789 Test RE 2.827988583237395\n",
      "37 Train Loss 20.894306 Test MSE 15.214606744223465 Test RE 2.818163869237179\n",
      "38 Train Loss 20.372095 Test MSE 15.10210970160055 Test RE 2.8077257644753173\n",
      "39 Train Loss 19.80435 Test MSE 14.905673267274608 Test RE 2.7894056453769975\n",
      "40 Train Loss 19.496798 Test MSE 14.816010291890667 Test RE 2.781003352481403\n",
      "41 Train Loss 19.17289 Test MSE 14.794727144681957 Test RE 2.779005183815447\n",
      "42 Train Loss 18.852293 Test MSE 14.703027728777522 Test RE 2.7703795008467016\n",
      "43 Train Loss 18.583809 Test MSE 14.555332299460414 Test RE 2.7564298181824283\n",
      "44 Train Loss 18.251673 Test MSE 14.498812192595235 Test RE 2.7510728383323824\n",
      "45 Train Loss 18.083141 Test MSE 14.501809185999115 Test RE 2.7513571554548575\n",
      "46 Train Loss 17.928238 Test MSE 14.45438381421464 Test RE 2.7468545796060324\n",
      "47 Train Loss 17.669733 Test MSE 14.384929522518693 Test RE 2.740247221843479\n",
      "48 Train Loss 17.525808 Test MSE 14.378059099223726 Test RE 2.73959275541677\n",
      "49 Train Loss 17.363468 Test MSE 14.316655203869832 Test RE 2.733736552750414\n",
      "50 Train Loss 17.204355 Test MSE 14.224660912463662 Test RE 2.7249393353663844\n",
      "51 Train Loss 16.988892 Test MSE 14.113730517889376 Test RE 2.7142933792588244\n",
      "52 Train Loss 16.874443 Test MSE 14.13125123853206 Test RE 2.7159776124269013\n",
      "53 Train Loss 16.695961 Test MSE 14.117585704197639 Test RE 2.714664060567536\n",
      "54 Train Loss 16.442791 Test MSE 14.00854665320904 Test RE 2.7041602047943583\n",
      "55 Train Loss 16.272352 Test MSE 13.858642010627 Test RE 2.6896527590753174\n",
      "56 Train Loss 16.115767 Test MSE 13.74938136081018 Test RE 2.6790292534678346\n",
      "57 Train Loss 15.90145 Test MSE 13.670478321206529 Test RE 2.671331172962609\n",
      "58 Train Loss 15.73542 Test MSE 13.568791817435965 Test RE 2.6613774117549993\n",
      "59 Train Loss 15.48284 Test MSE 13.41581353012573 Test RE 2.646332335863876\n",
      "60 Train Loss 15.351019 Test MSE 13.357552051473776 Test RE 2.6405799083521577\n",
      "61 Train Loss 15.11784 Test MSE 13.18448494930341 Test RE 2.6234178021950534\n",
      "62 Train Loss 14.798195 Test MSE 13.142098059618057 Test RE 2.619197385600105\n",
      "63 Train Loss 14.593955 Test MSE 13.083574055258113 Test RE 2.613359012167006\n",
      "64 Train Loss 14.440869 Test MSE 12.933633467412042 Test RE 2.5983410311582746\n",
      "65 Train Loss 14.278726 Test MSE 12.821686481910412 Test RE 2.587071630138899\n",
      "66 Train Loss 14.075345 Test MSE 12.730857262623164 Test RE 2.577891896579538\n",
      "67 Train Loss 13.809104 Test MSE 12.518563467562924 Test RE 2.5563076791086794\n",
      "68 Train Loss 13.4946575 Test MSE 12.061771144930821 Test RE 2.50923547542314\n",
      "69 Train Loss 13.171925 Test MSE 11.661394324266816 Test RE 2.467238409399355\n",
      "70 Train Loss 12.755445 Test MSE 11.2122218650495 Test RE 2.419255395741745\n",
      "71 Train Loss 12.224246 Test MSE 11.019188739367493 Test RE 2.39833965234633\n",
      "72 Train Loss 11.812421 Test MSE 10.65378379066607 Test RE 2.3582389945573348\n",
      "73 Train Loss 10.667319 Test MSE 9.749818931625601 Test RE 2.2559743216680874\n",
      "74 Train Loss 10.148437 Test MSE 9.247787506768011 Test RE 2.197125162912742\n",
      "75 Train Loss 9.368209 Test MSE 8.593922022587945 Test RE 2.1180274350800437\n",
      "76 Train Loss 8.993484 Test MSE 8.213532972967359 Test RE 2.0706222639533194\n",
      "77 Train Loss 8.438716 Test MSE 7.796690937632885 Test RE 2.0173954473184286\n",
      "78 Train Loss 7.9294543 Test MSE 7.451121518632874 Test RE 1.9721806800138124\n",
      "79 Train Loss 7.431573 Test MSE 7.125262722406512 Test RE 1.9285740465688208\n",
      "80 Train Loss 6.776556 Test MSE 6.154929639737481 Test RE 1.7924515405340322\n",
      "81 Train Loss 6.257654 Test MSE 5.879799497725238 Test RE 1.7519315561420514\n",
      "82 Train Loss 5.882391 Test MSE 5.554756743389873 Test RE 1.702818654754324\n",
      "83 Train Loss 5.4076724 Test MSE 5.062969697368808 Test RE 1.62569301948793\n",
      "84 Train Loss 5.1393685 Test MSE 4.748993711826904 Test RE 1.5744782809339042\n",
      "85 Train Loss 4.8161154 Test MSE 4.102415772701504 Test RE 1.4633752768358836\n",
      "86 Train Loss 4.4435287 Test MSE 3.615560486843063 Test RE 1.3738005713007158\n",
      "87 Train Loss 4.144125 Test MSE 3.377688944266834 Test RE 1.3278398649194192\n",
      "88 Train Loss 3.6734986 Test MSE 3.129571347313877 Test RE 1.2781396434833983\n",
      "89 Train Loss 3.189267 Test MSE 2.5384282516911467 Test RE 1.1511139663882148\n",
      "90 Train Loss 2.9517868 Test MSE 2.31590918021564 Test RE 1.0995035578715908\n",
      "91 Train Loss 2.6910899 Test MSE 1.9709422572995572 Test RE 1.014314951774103\n",
      "92 Train Loss 2.4885516 Test MSE 1.9589877867320662 Test RE 1.0112341814753474\n",
      "93 Train Loss 2.341357 Test MSE 1.8576428970604304 Test RE 0.9847295999487798\n",
      "94 Train Loss 2.1689765 Test MSE 1.6352958773313668 Test RE 0.9239193181462683\n",
      "95 Train Loss 2.0911598 Test MSE 1.466993648918704 Test RE 0.8750845045992167\n",
      "96 Train Loss 2.012461 Test MSE 1.4386255039349516 Test RE 0.866582180672979\n",
      "97 Train Loss 1.913886 Test MSE 1.3090125431052768 Test RE 0.8266235633278637\n",
      "98 Train Loss 1.8680364 Test MSE 1.2735380543565533 Test RE 0.8153458033192165\n",
      "99 Train Loss 1.796417 Test MSE 1.335611049632515 Test RE 0.8349796260052276\n",
      "100 Train Loss 1.7305609 Test MSE 1.312855511718869 Test RE 0.8278360651980592\n",
      "101 Train Loss 1.6742598 Test MSE 1.2498013834245434 Test RE 0.8077117066617455\n",
      "102 Train Loss 1.6271975 Test MSE 1.2010194193965644 Test RE 0.7917916029599095\n",
      "103 Train Loss 1.5611951 Test MSE 1.2072451866156375 Test RE 0.7938411694828476\n",
      "104 Train Loss 1.501223 Test MSE 1.1428578985092235 Test RE 0.7723817328080452\n",
      "105 Train Loss 1.427121 Test MSE 1.1232225835252556 Test RE 0.7657178835801852\n",
      "106 Train Loss 1.371565 Test MSE 1.1428078397769914 Test RE 0.7723648169369679\n",
      "107 Train Loss 1.3412731 Test MSE 1.1654311450397827 Test RE 0.7799723134834707\n",
      "108 Train Loss 1.2896041 Test MSE 1.1359197927014624 Test RE 0.7700336612858384\n",
      "109 Train Loss 1.2236997 Test MSE 1.0792056876857585 Test RE 0.7505644485532368\n",
      "110 Train Loss 1.1830854 Test MSE 1.0406355956648816 Test RE 0.7370300844683921\n",
      "111 Train Loss 1.148518 Test MSE 1.005230843684068 Test RE 0.7243838841737023\n",
      "112 Train Loss 1.1236451 Test MSE 0.9786454969417218 Test RE 0.7147408066446901\n",
      "113 Train Loss 1.1062996 Test MSE 0.9666532290434359 Test RE 0.7103481110070041\n",
      "114 Train Loss 1.0678025 Test MSE 0.9722014469859783 Test RE 0.7123837567760269\n",
      "115 Train Loss 1.0270547 Test MSE 0.8821720918414296 Test RE 0.6785979355879453\n",
      "116 Train Loss 1.0096352 Test MSE 0.8411391049829101 Test RE 0.662628008278972\n",
      "117 Train Loss 0.985539 Test MSE 0.8239768865337427 Test RE 0.6558331903189222\n",
      "118 Train Loss 0.965322 Test MSE 0.7936641323922498 Test RE 0.6436566400576791\n",
      "119 Train Loss 0.9381574 Test MSE 0.80913369481788 Test RE 0.6498992269061451\n",
      "120 Train Loss 0.90666187 Test MSE 0.7745659986438646 Test RE 0.63586524968885\n",
      "121 Train Loss 0.87135434 Test MSE 0.7337134004379181 Test RE 0.6188695323581833\n",
      "122 Train Loss 0.84957284 Test MSE 0.7311438021384424 Test RE 0.6177848848149476\n",
      "123 Train Loss 0.8286845 Test MSE 0.7279880808544501 Test RE 0.6164502191185555\n",
      "124 Train Loss 0.80558175 Test MSE 0.7294023817936517 Test RE 0.6170487337867366\n",
      "125 Train Loss 0.7820033 Test MSE 0.7411458494784144 Test RE 0.6219961797746005\n",
      "126 Train Loss 0.7437106 Test MSE 0.690518640114138 Test RE 0.6003763555087193\n",
      "127 Train Loss 0.6942577 Test MSE 0.607419614879788 Test RE 0.5630932002358892\n",
      "128 Train Loss 0.6597557 Test MSE 0.5332911449747256 Test RE 0.5276161288455196\n",
      "129 Train Loss 0.6377387 Test MSE 0.4517763954984963 Test RE 0.48562120798355596\n",
      "130 Train Loss 0.616797 Test MSE 0.40735640051864075 Test RE 0.4611297577511503\n",
      "131 Train Loss 0.589526 Test MSE 0.36296904897287596 Test RE 0.4352819652197091\n",
      "132 Train Loss 0.5423921 Test MSE 0.3531030712547475 Test RE 0.42932544071405854\n",
      "133 Train Loss 0.51118004 Test MSE 0.34096902658283074 Test RE 0.42188427854502597\n",
      "134 Train Loss 0.49251473 Test MSE 0.31604062220349916 Test RE 0.4061695211614152\n",
      "135 Train Loss 0.4705339 Test MSE 0.2972816356663381 Test RE 0.3939307816687392\n",
      "136 Train Loss 0.45656022 Test MSE 0.2774515465372975 Test RE 0.38056553234437196\n",
      "137 Train Loss 0.44743055 Test MSE 0.2592843074164384 Test RE 0.36789509139853804\n",
      "138 Train Loss 0.43628216 Test MSE 0.25292083100948126 Test RE 0.3633525203214659\n",
      "139 Train Loss 0.4252893 Test MSE 0.23446428700161046 Test RE 0.34984383702530547\n",
      "140 Train Loss 0.4063987 Test MSE 0.2148871088465799 Test RE 0.33491998130248263\n",
      "141 Train Loss 0.3871756 Test MSE 0.19238072825572441 Test RE 0.3168959282974567\n",
      "142 Train Loss 0.36872 Test MSE 0.18365785945705876 Test RE 0.30962829125386143\n",
      "143 Train Loss 0.33759436 Test MSE 0.18815636792899218 Test RE 0.31339736267256435\n",
      "144 Train Loss 0.32051173 Test MSE 0.19903451400228742 Test RE 0.3223295139052654\n",
      "145 Train Loss 0.31039056 Test MSE 0.19506190592080677 Test RE 0.31909654987717767\n",
      "146 Train Loss 0.2938431 Test MSE 0.19176040865944283 Test RE 0.31638461026047016\n",
      "147 Train Loss 0.28729406 Test MSE 0.18411759062085672 Test RE 0.31001557880764774\n",
      "148 Train Loss 0.2760027 Test MSE 0.179778377340998 Test RE 0.3063406327078614\n",
      "149 Train Loss 0.27100658 Test MSE 0.17451890930809666 Test RE 0.30182632924859404\n",
      "150 Train Loss 0.2548884 Test MSE 0.15638773051348837 Test RE 0.28571774610405204\n",
      "151 Train Loss 0.2483602 Test MSE 0.14938045808898529 Test RE 0.279243305557306\n",
      "152 Train Loss 0.23954779 Test MSE 0.13266564366633649 Test RE 0.26315711170548206\n",
      "153 Train Loss 0.23298216 Test MSE 0.1298256400899674 Test RE 0.260325141514784\n",
      "154 Train Loss 0.22533932 Test MSE 0.12227275453757279 Test RE 0.25263919270663165\n",
      "155 Train Loss 0.21611477 Test MSE 0.11559522678589483 Test RE 0.2456438115772457\n",
      "156 Train Loss 0.21239424 Test MSE 0.10358664259103337 Test RE 0.23253469238582872\n",
      "157 Train Loss 0.2084695 Test MSE 0.09486381713796256 Test RE 0.2225287737860363\n",
      "158 Train Loss 0.20605741 Test MSE 0.09334917947508457 Test RE 0.22074512910959843\n",
      "159 Train Loss 0.20291637 Test MSE 0.08785223265397014 Test RE 0.2141471398851085\n",
      "160 Train Loss 0.19994557 Test MSE 0.0895763673825781 Test RE 0.2162382908768503\n",
      "161 Train Loss 0.19773245 Test MSE 0.09375093781828846 Test RE 0.22121964308072326\n",
      "162 Train Loss 0.19485575 Test MSE 0.09248157099111344 Test RE 0.21971690670640723\n",
      "163 Train Loss 0.1894611 Test MSE 0.09011104367313598 Test RE 0.21688268780342074\n",
      "164 Train Loss 0.18424395 Test MSE 0.085867207772781 Test RE 0.21171398524598647\n",
      "165 Train Loss 0.18005106 Test MSE 0.08307694116857062 Test RE 0.2082457399000015\n",
      "166 Train Loss 0.17792515 Test MSE 0.07926115504536083 Test RE 0.20340708466912738\n",
      "167 Train Loss 0.17354609 Test MSE 0.07999237680793714 Test RE 0.20434319404610748\n",
      "168 Train Loss 0.16773553 Test MSE 0.07451285667203637 Test RE 0.19722024035124944\n",
      "169 Train Loss 0.1642151 Test MSE 0.07111659625476283 Test RE 0.19267322118163138\n",
      "170 Train Loss 0.16133888 Test MSE 0.06479417540546738 Test RE 0.18390937162676138\n",
      "171 Train Loss 0.15742904 Test MSE 0.0601723011281527 Test RE 0.17722875514696332\n",
      "172 Train Loss 0.15516165 Test MSE 0.05522356508712561 Test RE 0.16978452225594026\n",
      "173 Train Loss 0.15136868 Test MSE 0.05780062500119423 Test RE 0.17370093018499108\n",
      "174 Train Loss 0.1467803 Test MSE 0.0538157013092999 Test RE 0.16760631548093186\n",
      "175 Train Loss 0.14269204 Test MSE 0.05065582416986887 Test RE 0.16261124306702593\n",
      "176 Train Loss 0.13853641 Test MSE 0.046627360472848885 Test RE 0.15601138505132559\n",
      "177 Train Loss 0.13415979 Test MSE 0.04583658444815583 Test RE 0.15468279151833134\n",
      "178 Train Loss 0.12950628 Test MSE 0.04187528795221734 Test RE 0.14784777058067447\n",
      "179 Train Loss 0.12740321 Test MSE 0.040021699520687376 Test RE 0.14453853229420444\n",
      "180 Train Loss 0.12422201 Test MSE 0.03587160669104574 Test RE 0.13683944103038656\n",
      "181 Train Loss 0.12145263 Test MSE 0.03304987840737091 Test RE 0.1313471972114005\n",
      "182 Train Loss 0.11914772 Test MSE 0.02915921785970861 Test RE 0.12337404735298192\n",
      "183 Train Loss 0.11759362 Test MSE 0.029442926266224495 Test RE 0.12397278642903715\n",
      "184 Train Loss 0.11563331 Test MSE 0.029362641964473364 Test RE 0.12380364796227726\n",
      "185 Train Loss 0.114405416 Test MSE 0.02748641479582688 Test RE 0.11978292802417623\n",
      "186 Train Loss 0.11271683 Test MSE 0.024032592188510574 Test RE 0.11200468406547043\n",
      "187 Train Loss 0.111613825 Test MSE 0.026630097466263516 Test RE 0.11790229392441666\n",
      "188 Train Loss 0.11013931 Test MSE 0.027604846587259337 Test RE 0.12004070734222257\n",
      "189 Train Loss 0.10757215 Test MSE 0.02674083313317732 Test RE 0.11814717557879542\n",
      "190 Train Loss 0.106460236 Test MSE 0.02713966228366848 Test RE 0.11902497432638363\n",
      "191 Train Loss 0.10469915 Test MSE 0.028886674209700067 Test RE 0.12279612113260634\n",
      "192 Train Loss 0.102939814 Test MSE 0.02774841822984559 Test RE 0.12035246583470736\n",
      "193 Train Loss 0.10198099 Test MSE 0.027667893997990967 Test RE 0.1201777111714459\n",
      "194 Train Loss 0.10052904 Test MSE 0.02543660016237727 Test RE 0.11522995932363565\n",
      "195 Train Loss 0.09922483 Test MSE 0.02260051605968455 Test RE 0.10861631258885099\n",
      "196 Train Loss 0.098034725 Test MSE 0.021490989665348615 Test RE 0.10591661302417067\n",
      "197 Train Loss 0.09714789 Test MSE 0.021736355698257617 Test RE 0.1065195303809103\n",
      "198 Train Loss 0.09585096 Test MSE 0.022189815936138217 Test RE 0.10762489153754348\n",
      "199 Train Loss 0.094005406 Test MSE 0.02310788311161825 Test RE 0.1098287290478937\n",
      "200 Train Loss 0.09097153 Test MSE 0.02203243075696778 Test RE 0.10724253810093613\n",
      "201 Train Loss 0.08755787 Test MSE 0.020832694822994234 Test RE 0.10428182016599684\n",
      "202 Train Loss 0.08629872 Test MSE 0.019605382461449383 Test RE 0.10116342777548466\n",
      "203 Train Loss 0.08537067 Test MSE 0.020120900597186547 Test RE 0.10248482990746476\n",
      "204 Train Loss 0.08371642 Test MSE 0.01929772516311584 Test RE 0.10036653599197631\n",
      "205 Train Loss 0.08197647 Test MSE 0.017395642836627943 Test RE 0.09529192889769181\n",
      "206 Train Loss 0.079532675 Test MSE 0.014755672990356338 Test RE 0.08776379369877868\n",
      "207 Train Loss 0.076828256 Test MSE 0.01361084644532912 Test RE 0.08429046391368482\n",
      "208 Train Loss 0.0750233 Test MSE 0.012324062601930244 Test RE 0.08020710196734666\n",
      "209 Train Loss 0.0742049 Test MSE 0.012013445784145859 Test RE 0.07918987788941646\n",
      "210 Train Loss 0.073116 Test MSE 0.0118033590875094 Test RE 0.07849440227593037\n",
      "211 Train Loss 0.07175956 Test MSE 0.00983716374148433 Test RE 0.07165901382299918\n",
      "212 Train Loss 0.070542105 Test MSE 0.00876627779734638 Test RE 0.06764621341429604\n",
      "213 Train Loss 0.06948861 Test MSE 0.008623042763995056 Test RE 0.06709129069071411\n",
      "214 Train Loss 0.06873048 Test MSE 0.007974816047205707 Test RE 0.0645202756182\n",
      "215 Train Loss 0.06732332 Test MSE 0.008840430880215149 Test RE 0.06793171726101516\n",
      "216 Train Loss 0.065540776 Test MSE 0.007850832559425164 Test RE 0.06401676654465076\n",
      "217 Train Loss 0.06373353 Test MSE 0.007658643947793344 Test RE 0.06322834534152631\n",
      "218 Train Loss 0.062605985 Test MSE 0.006702094045461885 Test RE 0.05914814593500731\n",
      "219 Train Loss 0.05978354 Test MSE 0.005960334050831107 Test RE 0.05577905821365124\n",
      "220 Train Loss 0.05786553 Test MSE 0.005361181816854747 Test RE 0.05290127567753571\n",
      "221 Train Loss 0.056845065 Test MSE 0.004587702952577484 Test RE 0.048936569539788075\n",
      "222 Train Loss 0.056020748 Test MSE 0.003994870391145775 Test RE 0.045665395541924864\n",
      "223 Train Loss 0.05539514 Test MSE 0.003891612323989195 Test RE 0.04507135990524625\n",
      "224 Train Loss 0.054213863 Test MSE 0.0028649917267641435 Test RE 0.03867208280597599\n",
      "225 Train Loss 0.05348384 Test MSE 0.0029305953533353187 Test RE 0.039112340511018105\n",
      "226 Train Loss 0.052612007 Test MSE 0.002405490232610449 Test RE 0.03543542743917527\n",
      "227 Train Loss 0.05091966 Test MSE 0.002336247530531158 Test RE 0.03492169416298883\n",
      "228 Train Loss 0.04956017 Test MSE 0.0017713762937214272 Test RE 0.03040824046834236\n",
      "229 Train Loss 0.048596703 Test MSE 0.001688132709136346 Test RE 0.029685144636334305\n",
      "230 Train Loss 0.047634415 Test MSE 0.0016174790840231441 Test RE 0.029057297079244985\n",
      "231 Train Loss 0.046918068 Test MSE 0.0017495975306582915 Test RE 0.030220730324063038\n",
      "232 Train Loss 0.046232514 Test MSE 0.0015918178624225589 Test RE 0.028825879297904086\n",
      "233 Train Loss 0.04541923 Test MSE 0.001261649340979103 Test RE 0.02566286914462087\n",
      "234 Train Loss 0.04412241 Test MSE 0.001284737874958327 Test RE 0.025896623374139154\n",
      "235 Train Loss 0.043079242 Test MSE 0.0014412589567621393 Test RE 0.02742880497205114\n",
      "236 Train Loss 0.042309254 Test MSE 0.0013647905122853008 Test RE 0.026691247614461705\n",
      "237 Train Loss 0.041707724 Test MSE 0.0012594852582141854 Test RE 0.02564085018631793\n",
      "238 Train Loss 0.04122856 Test MSE 0.001212721514615357 Test RE 0.02516033493049665\n",
      "239 Train Loss 0.04081651 Test MSE 0.001069177668454229 Test RE 0.023624401586436146\n",
      "240 Train Loss 0.040205214 Test MSE 0.001032522674788015 Test RE 0.023215908091585157\n",
      "241 Train Loss 0.03972251 Test MSE 0.0009286138980610528 Test RE 0.0220167629512313\n",
      "242 Train Loss 0.038882118 Test MSE 0.0009192663436601012 Test RE 0.021905670804621694\n",
      "243 Train Loss 0.038119316 Test MSE 0.0009862324123714578 Test RE 0.02268953066820617\n",
      "244 Train Loss 0.037425485 Test MSE 0.0008307375227001012 Test RE 0.020824174311759966\n",
      "245 Train Loss 0.03693 Test MSE 0.0008625849551049127 Test RE 0.02121958160192563\n",
      "246 Train Loss 0.036541633 Test MSE 0.000751400148501296 Test RE 0.019804848072133386\n",
      "247 Train Loss 0.03562862 Test MSE 0.0006780408384675092 Test RE 0.018813248976066576\n",
      "248 Train Loss 0.034811717 Test MSE 0.0006273738281202609 Test RE 0.018096687030013464\n",
      "249 Train Loss 0.034351844 Test MSE 0.0005646097091391197 Test RE 0.017167618267993935\n",
      "250 Train Loss 0.033986658 Test MSE 0.0005565411293002727 Test RE 0.017044509561425072\n",
      "251 Train Loss 0.03366609 Test MSE 0.0005294911028830487 Test RE 0.016625136141793118\n",
      "252 Train Loss 0.03335198 Test MSE 0.000457131896687129 Test RE 0.015447444361940479\n",
      "253 Train Loss 0.033034753 Test MSE 0.00043360172286733927 Test RE 0.015044625326223334\n",
      "254 Train Loss 0.032683108 Test MSE 0.00046118016281477273 Test RE 0.015515693291631329\n",
      "255 Train Loss 0.03240158 Test MSE 0.0004254527354383833 Test RE 0.014902582578783852\n",
      "256 Train Loss 0.03189833 Test MSE 0.00043365358491593057 Test RE 0.015045525024862836\n",
      "257 Train Loss 0.031488426 Test MSE 0.0004336504583677281 Test RE 0.015045470787280527\n",
      "258 Train Loss 0.031155873 Test MSE 0.00041243225783708237 Test RE 0.014672772697579056\n",
      "259 Train Loss 0.0306786 Test MSE 0.00039110127982211007 Test RE 0.014288297870718008\n",
      "260 Train Loss 0.030225229 Test MSE 0.00044699411159994335 Test RE 0.015275195522766858\n",
      "261 Train Loss 0.029968223 Test MSE 0.00044853811960211175 Test RE 0.01530155458628713\n",
      "262 Train Loss 0.02973486 Test MSE 0.0004678965199464111 Test RE 0.015628265637617923\n",
      "263 Train Loss 0.029549224 Test MSE 0.00048602016930256284 Test RE 0.015928065138322872\n",
      "264 Train Loss 0.029049326 Test MSE 0.0005289382488408881 Test RE 0.01661645452832812\n",
      "265 Train Loss 0.028852599 Test MSE 0.0004726326325205029 Test RE 0.01570716221103669\n",
      "266 Train Loss 0.028597523 Test MSE 0.00044561699472560405 Test RE 0.015251647162848238\n",
      "267 Train Loss 0.028314756 Test MSE 0.0004365029323024245 Test RE 0.01509487286773842\n",
      "268 Train Loss 0.028045693 Test MSE 0.00042494287715325133 Test RE 0.01489365034926363\n",
      "269 Train Loss 0.02771506 Test MSE 0.00042246835118781663 Test RE 0.014850222707151639\n",
      "270 Train Loss 0.027337909 Test MSE 0.0004365628475881024 Test RE 0.01509590880875958\n",
      "271 Train Loss 0.02703486 Test MSE 0.00046548709358441165 Test RE 0.015587974937646442\n",
      "272 Train Loss 0.026808023 Test MSE 0.00046207046653833176 Test RE 0.015530662516523207\n",
      "273 Train Loss 0.02659328 Test MSE 0.000499341835453164 Test RE 0.016144881195253303\n",
      "274 Train Loss 0.026358707 Test MSE 0.0005417645819874442 Test RE 0.016816715680459022\n",
      "275 Train Loss 0.026156848 Test MSE 0.000595747631533458 Test RE 0.017634657901349927\n",
      "276 Train Loss 0.025818419 Test MSE 0.0007559375180716811 Test RE 0.01986455438456733\n",
      "277 Train Loss 0.025351707 Test MSE 0.001019359099710888 Test RE 0.023067444213366314\n",
      "278 Train Loss 0.025148265 Test MSE 0.0010412318868600196 Test RE 0.023313614269602247\n",
      "279 Train Loss 0.024893876 Test MSE 0.0010380556538815235 Test RE 0.023278028523092985\n",
      "280 Train Loss 0.024576016 Test MSE 0.0012964584724375976 Test RE 0.026014481960760685\n",
      "281 Train Loss 0.024317382 Test MSE 0.0013506004313869177 Test RE 0.0265521271399189\n",
      "282 Train Loss 0.024059057 Test MSE 0.0016149230420559157 Test RE 0.02903432891943422\n",
      "283 Train Loss 0.023878835 Test MSE 0.001766167204425359 Test RE 0.03036349676728171\n",
      "284 Train Loss 0.023701614 Test MSE 0.001936319302732902 Test RE 0.031792476894025215\n",
      "285 Train Loss 0.023491545 Test MSE 0.0018322366703418039 Test RE 0.030926207275915003\n",
      "286 Train Loss 0.023341343 Test MSE 0.001870326348115548 Test RE 0.03124601039387504\n",
      "287 Train Loss 0.023203932 Test MSE 0.0019454370998332467 Test RE 0.03186724165739879\n",
      "288 Train Loss 0.023046969 Test MSE 0.0019157622918437164 Test RE 0.03162326353284715\n",
      "289 Train Loss 0.022742445 Test MSE 0.0018774825167245442 Test RE 0.03130572944856115\n",
      "290 Train Loss 0.022607079 Test MSE 0.0017498385965771903 Test RE 0.03022281221348905\n",
      "291 Train Loss 0.0224168 Test MSE 0.0018638308070539713 Test RE 0.03119170536111666\n",
      "292 Train Loss 0.02225917 Test MSE 0.0018068981961459705 Test RE 0.03071161954129394\n",
      "293 Train Loss 0.022091335 Test MSE 0.0018757531271459149 Test RE 0.031291307936015214\n",
      "294 Train Loss 0.0216274 Test MSE 0.002034271025268684 Test RE 0.0325866925827064\n",
      "295 Train Loss 0.021507861 Test MSE 0.0021050558657734583 Test RE 0.03314879072666252\n",
      "296 Train Loss 0.021439571 Test MSE 0.0022355433467451044 Test RE 0.03416075215623913\n",
      "297 Train Loss 0.021357391 Test MSE 0.002439340964680931 Test RE 0.035683885029919045\n",
      "298 Train Loss 0.021240398 Test MSE 0.0024397650286634627 Test RE 0.035686986603871346\n",
      "299 Train Loss 0.02113877 Test MSE 0.002475926729997051 Test RE 0.03595048644074141\n",
      "Training time: 172.36\n",
      "KG_atanh_high\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 48999.832 Test MSE 10.608403413085009 Test RE 2.353211110404114\n",
      "1 Train Loss 32089.348 Test MSE 10.090304378664523 Test RE 2.295028116442218\n",
      "2 Train Loss 17811.396 Test MSE 10.200793893831962 Test RE 2.3075592621395087\n",
      "3 Train Loss 6235.245 Test MSE 12.281704895601175 Test RE 2.5320087716310726\n",
      "4 Train Loss 1939.5094 Test MSE 12.96916472508282 Test RE 2.6019076624895634\n",
      "5 Train Loss 912.3177 Test MSE 11.905444413085466 Test RE 2.4929219566764784\n",
      "6 Train Loss 540.94806 Test MSE 10.62336390784294 Test RE 2.354869833108481\n",
      "7 Train Loss 395.11267 Test MSE 9.809618902431168 Test RE 2.2628821919597537\n",
      "8 Train Loss 326.52277 Test MSE 9.31299199338946 Test RE 2.2048573245332883\n",
      "9 Train Loss 260.08688 Test MSE 8.600848131368107 Test RE 2.118880755244992\n",
      "10 Train Loss 205.8783 Test MSE 7.8473263061408005 Test RE 2.0239358016860702\n",
      "11 Train Loss 172.9465 Test MSE 7.357030163270984 Test RE 1.9596889563564535\n",
      "12 Train Loss 144.4501 Test MSE 6.842927541658936 Test RE 1.8899784295834015\n",
      "13 Train Loss 119.4624 Test MSE 5.821928139941307 Test RE 1.7432886283229896\n",
      "14 Train Loss 102.45873 Test MSE 5.367303456005706 Test RE 1.6738400381011933\n",
      "15 Train Loss 85.0001 Test MSE 5.0551446704029805 Test RE 1.6244362461394426\n",
      "16 Train Loss 74.33314 Test MSE 4.902591592593598 Test RE 1.599737535287999\n",
      "17 Train Loss 64.13581 Test MSE 4.854098521813222 Test RE 1.59180612071894\n",
      "18 Train Loss 56.72243 Test MSE 4.636750183860003 Test RE 1.5557604464662256\n",
      "19 Train Loss 49.255844 Test MSE 4.434120105893577 Test RE 1.5213866574476038\n",
      "20 Train Loss 41.631332 Test MSE 3.9306293404688866 Test RE 1.4324086096390856\n",
      "21 Train Loss 34.606632 Test MSE 2.795751848972484 Test RE 1.20805077221569\n",
      "22 Train Loss 24.387907 Test MSE 1.6110092183102627 Test RE 0.9170328423359142\n",
      "23 Train Loss 19.460669 Test MSE 1.2391278608846967 Test RE 0.8042553116182893\n",
      "24 Train Loss 14.64604 Test MSE 1.0270611877774436 Test RE 0.7322072685290015\n",
      "25 Train Loss 11.398326 Test MSE 0.8595465598290123 Test RE 0.6698392318003533\n",
      "26 Train Loss 9.136486 Test MSE 0.7659296159063265 Test RE 0.6323103755190749\n",
      "27 Train Loss 8.010627 Test MSE 0.7513737541517902 Test RE 0.6262732864095056\n",
      "28 Train Loss 6.760183 Test MSE 0.667274378527091 Test RE 0.5901849106512749\n",
      "29 Train Loss 5.8798866 Test MSE 0.6136547138279626 Test RE 0.5659758680161084\n",
      "30 Train Loss 4.9789834 Test MSE 0.5822860215232332 Test RE 0.5513203956270285\n",
      "31 Train Loss 4.4234495 Test MSE 0.5323981474622174 Test RE 0.5271741964226669\n",
      "32 Train Loss 3.9454646 Test MSE 0.4902504554256087 Test RE 0.5058769363853513\n",
      "33 Train Loss 3.5095139 Test MSE 0.44867154953696786 Test RE 0.483949608310324\n",
      "34 Train Loss 3.194657 Test MSE 0.3907715802330381 Test RE 0.45164516200354043\n",
      "35 Train Loss 2.893577 Test MSE 0.31054152222819836 Test RE 0.4026203440787983\n",
      "36 Train Loss 2.5956647 Test MSE 0.2633376137836739 Test RE 0.3707595316273198\n",
      "37 Train Loss 2.3698215 Test MSE 0.21539684050568464 Test RE 0.3353169762598222\n",
      "38 Train Loss 2.1046517 Test MSE 0.17226958496086675 Test RE 0.29987494449658436\n",
      "39 Train Loss 1.9174767 Test MSE 0.15417417242607176 Test RE 0.2836884731343896\n",
      "40 Train Loss 1.7163697 Test MSE 0.1312132073811655 Test RE 0.2617126124525593\n",
      "41 Train Loss 1.5335114 Test MSE 0.13862298212291901 Test RE 0.26900075292027004\n",
      "42 Train Loss 1.4331391 Test MSE 0.13410699501698103 Test RE 0.2645827904704157\n",
      "43 Train Loss 1.3435949 Test MSE 0.12308622180501515 Test RE 0.2534781900440682\n",
      "44 Train Loss 1.2594609 Test MSE 0.11271861272525256 Test RE 0.24256810446117594\n",
      "45 Train Loss 1.1711586 Test MSE 0.10874084447646011 Test RE 0.23824962601420172\n",
      "46 Train Loss 1.0582153 Test MSE 0.09587764183879162 Test RE 0.22371471382257588\n",
      "47 Train Loss 1.0011203 Test MSE 0.100509021404585 Test RE 0.22905427364884712\n",
      "48 Train Loss 0.94681716 Test MSE 0.09651205120930166 Test RE 0.22445363847771294\n",
      "49 Train Loss 0.8887369 Test MSE 0.08768715284241904 Test RE 0.21394584738004205\n",
      "50 Train Loss 0.83941925 Test MSE 0.08700139844420139 Test RE 0.2131076272317412\n",
      "51 Train Loss 0.8031824 Test MSE 0.08376528181920576 Test RE 0.20910667861398072\n",
      "52 Train Loss 0.73752815 Test MSE 0.07262443472335282 Test RE 0.19470506954871342\n",
      "53 Train Loss 0.6815145 Test MSE 0.06494495553579416 Test RE 0.184123231632679\n",
      "54 Train Loss 0.64703375 Test MSE 0.06082397638371652 Test RE 0.17818587798718633\n",
      "55 Train Loss 0.6037219 Test MSE 0.059346686204042244 Test RE 0.17600869131761862\n",
      "56 Train Loss 0.5629782 Test MSE 0.056126875337754886 Test RE 0.17116750073109124\n",
      "57 Train Loss 0.52708966 Test MSE 0.052229473588635944 Test RE 0.16511772689265808\n",
      "58 Train Loss 0.49190485 Test MSE 0.04917802975165108 Test RE 0.16022173842460302\n",
      "59 Train Loss 0.46970576 Test MSE 0.045635348785462174 Test RE 0.15434286725807278\n",
      "60 Train Loss 0.43516392 Test MSE 0.039773752703824924 Test RE 0.14409010620650337\n",
      "61 Train Loss 0.41504973 Test MSE 0.03542633736396646 Test RE 0.13598750443832208\n",
      "62 Train Loss 0.39923418 Test MSE 0.03145127252012652 Test RE 0.12813122780505617\n",
      "63 Train Loss 0.38661793 Test MSE 0.030826887137831133 Test RE 0.12685299141361353\n",
      "64 Train Loss 0.36342412 Test MSE 0.027293312260269154 Test RE 0.11936142606460715\n",
      "65 Train Loss 0.34754527 Test MSE 0.023806282641645197 Test RE 0.11147607514131481\n",
      "66 Train Loss 0.33574468 Test MSE 0.02026413740405153 Test RE 0.1028489678591154\n",
      "67 Train Loss 0.316367 Test MSE 0.017610829907208303 Test RE 0.09587950608651674\n",
      "68 Train Loss 0.29967162 Test MSE 0.019144261315776224 Test RE 0.09996666038236138\n",
      "69 Train Loss 0.2859706 Test MSE 0.018791049583106314 Test RE 0.09904017433615504\n",
      "70 Train Loss 0.2693108 Test MSE 0.017095865617952826 Test RE 0.09446728298312705\n",
      "71 Train Loss 0.25964493 Test MSE 0.015219841170039251 Test RE 0.0891334952305757\n",
      "72 Train Loss 0.24847034 Test MSE 0.01445647096492189 Test RE 0.08686943983536212\n",
      "73 Train Loss 0.23867178 Test MSE 0.012886153905264677 Test RE 0.08201580159566647\n",
      "74 Train Loss 0.2275821 Test MSE 0.011149320453295083 Test RE 0.07628867568862888\n",
      "75 Train Loss 0.2135298 Test MSE 0.011356691740967977 Test RE 0.07699487101261114\n",
      "76 Train Loss 0.20524246 Test MSE 0.012485318150167315 Test RE 0.08073013591348047\n",
      "77 Train Loss 0.20027661 Test MSE 0.012652208802125413 Test RE 0.08126790274045355\n",
      "78 Train Loss 0.19414312 Test MSE 0.01200610508763975 Test RE 0.07916568009894578\n",
      "79 Train Loss 0.18802896 Test MSE 0.011613819516009883 Test RE 0.0778616160080316\n",
      "80 Train Loss 0.18125474 Test MSE 0.010985033939418413 Test RE 0.07572452859606014\n",
      "81 Train Loss 0.17726243 Test MSE 0.010575691468388248 Test RE 0.07430024795260819\n",
      "82 Train Loss 0.17200927 Test MSE 0.009964726268382882 Test RE 0.0721221331693762\n",
      "83 Train Loss 0.16765158 Test MSE 0.009760593044136224 Test RE 0.07137957861289146\n",
      "84 Train Loss 0.16246198 Test MSE 0.009567110113349746 Test RE 0.0706685634649832\n",
      "85 Train Loss 0.15801792 Test MSE 0.009819783048199256 Test RE 0.07159568083383336\n",
      "86 Train Loss 0.1531509 Test MSE 0.009805303688474562 Test RE 0.07154287711935975\n",
      "87 Train Loss 0.14849652 Test MSE 0.008974842690625612 Test RE 0.0684461932990964\n",
      "88 Train Loss 0.143466 Test MSE 0.008618104420749532 Test RE 0.06707207663362987\n",
      "89 Train Loss 0.13839453 Test MSE 0.007912771770283036 Test RE 0.06426880082916216\n",
      "90 Train Loss 0.13429144 Test MSE 0.007503886764626309 Test RE 0.06258626184998366\n",
      "91 Train Loss 0.13014588 Test MSE 0.0068473788171164235 Test RE 0.05978580129739271\n",
      "92 Train Loss 0.12721895 Test MSE 0.00642815095563823 Test RE 0.05792671631310929\n",
      "93 Train Loss 0.12431645 Test MSE 0.0058755593855828485 Test RE 0.05538096092064009\n",
      "94 Train Loss 0.121707805 Test MSE 0.005406776378491049 Test RE 0.053125750799691236\n",
      "95 Train Loss 0.11809664 Test MSE 0.005573761681995407 Test RE 0.053939892264474563\n",
      "96 Train Loss 0.113694794 Test MSE 0.005763400229401763 Test RE 0.05484982756899707\n",
      "97 Train Loss 0.11132134 Test MSE 0.005953591916370579 Test RE 0.055747501566235994\n",
      "98 Train Loss 0.10850924 Test MSE 0.005735462205003863 Test RE 0.05471672407602124\n",
      "99 Train Loss 0.10576113 Test MSE 0.00553434804700152 Test RE 0.05374884185526706\n",
      "100 Train Loss 0.10301072 Test MSE 0.005574197165614618 Test RE 0.05394199941239712\n",
      "101 Train Loss 0.10128738 Test MSE 0.005582298243808326 Test RE 0.05398118260656389\n",
      "102 Train Loss 0.09917288 Test MSE 0.0060783722502684295 Test RE 0.05632867345113731\n",
      "103 Train Loss 0.09692879 Test MSE 0.005716593507404646 Test RE 0.0546266455596329\n",
      "104 Train Loss 0.093748145 Test MSE 0.005163513252766737 Test RE 0.05191687279377512\n",
      "105 Train Loss 0.090807036 Test MSE 0.004632619200748318 Test RE 0.04917554460698976\n",
      "106 Train Loss 0.088833906 Test MSE 0.004559109588382844 Test RE 0.048783829895018685\n",
      "107 Train Loss 0.087377146 Test MSE 0.0044006116154099665 Test RE 0.04792834108386221\n",
      "108 Train Loss 0.0855513 Test MSE 0.003829001732448886 Test RE 0.04470732222798036\n",
      "109 Train Loss 0.08381412 Test MSE 0.0033169589148808296 Test RE 0.04161078634475922\n",
      "110 Train Loss 0.079838485 Test MSE 0.0030108520838995163 Test RE 0.03964428476162721\n",
      "111 Train Loss 0.07745797 Test MSE 0.0030363380933589542 Test RE 0.03981172000195496\n",
      "112 Train Loss 0.07525038 Test MSE 0.0033540383298906024 Test RE 0.04184271801172678\n",
      "113 Train Loss 0.07293721 Test MSE 0.0035903623696952537 Test RE 0.04329173771832892\n",
      "114 Train Loss 0.07144278 Test MSE 0.003962133736648163 Test RE 0.04547790416385688\n",
      "115 Train Loss 0.07024762 Test MSE 0.0042222909668480765 Test RE 0.04694722816543488\n",
      "116 Train Loss 0.06885992 Test MSE 0.0038373407910232563 Test RE 0.044755979063239026\n",
      "117 Train Loss 0.067742065 Test MSE 0.0034641123486229644 Test RE 0.042523779863396956\n",
      "118 Train Loss 0.06596098 Test MSE 0.003444459754271897 Test RE 0.04240298539105472\n",
      "119 Train Loss 0.065009326 Test MSE 0.0035321384332628884 Test RE 0.04293927773405112\n",
      "120 Train Loss 0.06377323 Test MSE 0.0035933549176683914 Test RE 0.04330977567724759\n",
      "121 Train Loss 0.062549606 Test MSE 0.0034534421958548178 Test RE 0.04245823851838817\n",
      "122 Train Loss 0.061173677 Test MSE 0.0033417237603875194 Test RE 0.04176583324698257\n",
      "123 Train Loss 0.060036276 Test MSE 0.003384423994569742 Test RE 0.04203182619459572\n",
      "124 Train Loss 0.0586386 Test MSE 0.003266569197624658 Test RE 0.04129351077429005\n",
      "125 Train Loss 0.057563644 Test MSE 0.003107563668776212 Test RE 0.040275959417017324\n",
      "126 Train Loss 0.056875337 Test MSE 0.003259323786346558 Test RE 0.04124768983211796\n",
      "127 Train Loss 0.056116752 Test MSE 0.0032683530840557566 Test RE 0.04130478451057827\n",
      "128 Train Loss 0.05480627 Test MSE 0.0034287415122677455 Test RE 0.042306125137115645\n",
      "129 Train Loss 0.053237975 Test MSE 0.003198467808691066 Test RE 0.04086080034287833\n",
      "130 Train Loss 0.052349757 Test MSE 0.003141770241170728 Test RE 0.04049702197911298\n",
      "131 Train Loss 0.05138007 Test MSE 0.0030209613383305263 Test RE 0.03971078392920569\n",
      "132 Train Loss 0.050097443 Test MSE 0.0030591831366734816 Test RE 0.03996120864624975\n",
      "133 Train Loss 0.048615195 Test MSE 0.003082524507597238 Test RE 0.04011336968122149\n",
      "134 Train Loss 0.04766845 Test MSE 0.0029815892999264094 Test RE 0.03945116090856944\n",
      "135 Train Loss 0.04661788 Test MSE 0.003066751317721968 Test RE 0.040010608572656\n",
      "136 Train Loss 0.045539327 Test MSE 0.002923616850717889 Test RE 0.039065744475078996\n",
      "137 Train Loss 0.04466854 Test MSE 0.0029983357640845083 Test RE 0.039561796932150645\n",
      "138 Train Loss 0.043495446 Test MSE 0.0029641737549025494 Test RE 0.03933577451060471\n",
      "139 Train Loss 0.042530965 Test MSE 0.00297111501278363 Test RE 0.039381804217156376\n",
      "140 Train Loss 0.041582737 Test MSE 0.0029163808282572246 Test RE 0.03901737019314834\n",
      "141 Train Loss 0.040601004 Test MSE 0.002844707921277509 Test RE 0.03853494273505413\n",
      "142 Train Loss 0.039856985 Test MSE 0.0028640479715966354 Test RE 0.03866571280780943\n",
      "143 Train Loss 0.03879127 Test MSE 0.0025878689938246225 Test RE 0.03675420391378489\n",
      "144 Train Loss 0.03824017 Test MSE 0.002432280612171816 Test RE 0.03563220644591497\n",
      "145 Train Loss 0.03778273 Test MSE 0.0023342687754396942 Test RE 0.034906902040724795\n",
      "146 Train Loss 0.0373535 Test MSE 0.002317563323043891 Test RE 0.03478177020819159\n",
      "147 Train Loss 0.036834314 Test MSE 0.0022406703459092884 Test RE 0.03419990188803977\n",
      "148 Train Loss 0.036072653 Test MSE 0.0020432569355327518 Test RE 0.032658585274731734\n",
      "149 Train Loss 0.034912936 Test MSE 0.0016993629799499778 Test RE 0.029783720894612998\n",
      "150 Train Loss 0.034015663 Test MSE 0.0014773307122431954 Test RE 0.027769927129641735\n",
      "151 Train Loss 0.033255555 Test MSE 0.0012605474445181882 Test RE 0.0256516600071957\n",
      "152 Train Loss 0.03257455 Test MSE 0.001111760524657777 Test RE 0.02409026079713176\n",
      "153 Train Loss 0.03210415 Test MSE 0.0010120355562560452 Test RE 0.022984431292578125\n",
      "154 Train Loss 0.03174661 Test MSE 0.0009233637047355341 Test RE 0.02195443558923199\n",
      "155 Train Loss 0.031339366 Test MSE 0.0009372147848725686 Test RE 0.022118488345652245\n",
      "156 Train Loss 0.03090452 Test MSE 0.0008483442142481004 Test RE 0.021043691577863167\n",
      "157 Train Loss 0.030452 Test MSE 0.0008087516078862987 Test RE 0.020546765078242768\n",
      "158 Train Loss 0.030083723 Test MSE 0.0008096480746923307 Test RE 0.020558149532508483\n",
      "159 Train Loss 0.029687881 Test MSE 0.00073081902803473 Test RE 0.019531733956190896\n",
      "160 Train Loss 0.029377177 Test MSE 0.0007272692993239675 Test RE 0.019484241520054065\n",
      "161 Train Loss 0.0290089 Test MSE 0.0007133823457853832 Test RE 0.019297322534155885\n",
      "162 Train Loss 0.028661111 Test MSE 0.0006703010690053987 Test RE 0.018705565100803737\n",
      "163 Train Loss 0.028118614 Test MSE 0.0006635957195518538 Test RE 0.018611769481834448\n",
      "164 Train Loss 0.027536409 Test MSE 0.0006608761766477736 Test RE 0.018573593022366414\n",
      "165 Train Loss 0.02683777 Test MSE 0.0005694045517027139 Test RE 0.017240360553719362\n",
      "166 Train Loss 0.026467899 Test MSE 0.000543830083289849 Test RE 0.016848742417833223\n",
      "167 Train Loss 0.025942242 Test MSE 0.0005482556734370896 Test RE 0.01691715950662851\n",
      "168 Train Loss 0.025575109 Test MSE 0.0005500104888355306 Test RE 0.016944211461406462\n",
      "169 Train Loss 0.025096646 Test MSE 0.0005512593979956573 Test RE 0.016963438168839294\n",
      "170 Train Loss 0.02467197 Test MSE 0.0005492578852996896 Test RE 0.016932614738181976\n",
      "171 Train Loss 0.024386128 Test MSE 0.0005352659629540942 Test RE 0.016715550764843826\n",
      "172 Train Loss 0.023885129 Test MSE 0.0005310666793548264 Test RE 0.016649853002958293\n",
      "173 Train Loss 0.023450058 Test MSE 0.0004995664910578127 Test RE 0.016148512605568783\n",
      "174 Train Loss 0.022627482 Test MSE 0.00044591389116864396 Test RE 0.015256727092323326\n",
      "175 Train Loss 0.022215135 Test MSE 0.0004247759532194642 Test RE 0.014890724837352043\n",
      "176 Train Loss 0.02192337 Test MSE 0.00040913215951438996 Test RE 0.014613952317872894\n",
      "177 Train Loss 0.021671962 Test MSE 0.0003990030985875001 Test RE 0.01443191661967885\n",
      "178 Train Loss 0.021411652 Test MSE 0.00039205774040495465 Test RE 0.0143057586273688\n",
      "179 Train Loss 0.021219395 Test MSE 0.0003880438242265411 Test RE 0.01423233851568144\n",
      "180 Train Loss 0.021020273 Test MSE 0.00037112587853644616 Test RE 0.013918630196271433\n",
      "181 Train Loss 0.020801838 Test MSE 0.0003718534055110874 Test RE 0.013932266029439493\n",
      "182 Train Loss 0.020549156 Test MSE 0.00037509141126330545 Test RE 0.013992793880626415\n",
      "183 Train Loss 0.020164948 Test MSE 0.0004034806032436388 Test RE 0.014512666242950459\n",
      "184 Train Loss 0.019844705 Test MSE 0.0004216235495163599 Test RE 0.014835367427517282\n",
      "185 Train Loss 0.01960598 Test MSE 0.00045672944080113676 Test RE 0.015440642950917337\n",
      "186 Train Loss 0.019377207 Test MSE 0.0004711926576065241 Test RE 0.0156832163682673\n",
      "187 Train Loss 0.019103754 Test MSE 0.0004992770353578127 Test RE 0.016143833592478923\n",
      "188 Train Loss 0.018767335 Test MSE 0.0005654172847200185 Test RE 0.017179891520696048\n",
      "189 Train Loss 0.018378083 Test MSE 0.0005305535378459721 Test RE 0.016641807124860235\n",
      "190 Train Loss 0.018031998 Test MSE 0.0005501684763792096 Test RE 0.01694664485330871\n",
      "191 Train Loss 0.017759828 Test MSE 0.0005949925339882631 Test RE 0.0176234785795498\n",
      "192 Train Loss 0.017325837 Test MSE 0.0005624520232751475 Test RE 0.017134783387330467\n",
      "193 Train Loss 0.016862877 Test MSE 0.0005860515032294472 Test RE 0.01749056219067729\n",
      "194 Train Loss 0.016609406 Test MSE 0.0006226530964222334 Test RE 0.0180284733801511\n",
      "195 Train Loss 0.016422195 Test MSE 0.0006369756286183081 Test RE 0.018234643834125937\n",
      "196 Train Loss 0.016281513 Test MSE 0.0005938240572268317 Test RE 0.017606165130933955\n",
      "197 Train Loss 0.01604608 Test MSE 0.0005980639823016879 Test RE 0.017668907659530716\n",
      "198 Train Loss 0.015785057 Test MSE 0.0006112193548351018 Test RE 0.017862178537934155\n",
      "199 Train Loss 0.015643757 Test MSE 0.000674060045194167 Test RE 0.01875794117066493\n",
      "200 Train Loss 0.015468329 Test MSE 0.0007072924492288097 Test RE 0.019214778734850398\n",
      "201 Train Loss 0.015257796 Test MSE 0.000729070105653225 Test RE 0.019508349269555678\n",
      "202 Train Loss 0.015096696 Test MSE 0.0007037339786222875 Test RE 0.019166381891815375\n",
      "203 Train Loss 0.014888345 Test MSE 0.0007647833186289953 Test RE 0.019980441488790534\n",
      "204 Train Loss 0.014715415 Test MSE 0.0007561401778559563 Test RE 0.019867216956823624\n",
      "205 Train Loss 0.014539646 Test MSE 0.0008656926909481674 Test RE 0.021257772370196236\n",
      "206 Train Loss 0.014339309 Test MSE 0.0008242149446983042 Test RE 0.02074226217758538\n",
      "207 Train Loss 0.014184643 Test MSE 0.0007519084396643092 Test RE 0.01981154552051745\n",
      "208 Train Loss 0.013982449 Test MSE 0.0007581049386970791 Test RE 0.019893011781084213\n",
      "209 Train Loss 0.013752956 Test MSE 0.0006739017730276753 Test RE 0.018755738819179427\n",
      "210 Train Loss 0.013571182 Test MSE 0.0006132729247055689 Test RE 0.01789215997806644\n",
      "211 Train Loss 0.013446992 Test MSE 0.0006056071611988128 Test RE 0.01777998449396436\n",
      "212 Train Loss 0.013267287 Test MSE 0.0005770609984830485 Test RE 0.017355883980718273\n",
      "213 Train Loss 0.013105718 Test MSE 0.0006076353976735103 Test RE 0.017809733043889865\n",
      "214 Train Loss 0.012940844 Test MSE 0.0006161310130746573 Test RE 0.01793380369877482\n",
      "215 Train Loss 0.012811092 Test MSE 0.0006428550155310254 Test RE 0.018318604874958105\n",
      "216 Train Loss 0.012683558 Test MSE 0.0006375602827959036 Test RE 0.018243010335936647\n",
      "217 Train Loss 0.012599158 Test MSE 0.0005970562034812289 Test RE 0.017654014722483527\n",
      "218 Train Loss 0.012474638 Test MSE 0.000572448138266841 Test RE 0.017286375814044855\n",
      "219 Train Loss 0.012382824 Test MSE 0.0005874401312643575 Test RE 0.017511271560563896\n",
      "220 Train Loss 0.012256183 Test MSE 0.0005490164376203667 Test RE 0.016928892634195024\n",
      "221 Train Loss 0.012165435 Test MSE 0.0005473715409631881 Test RE 0.016903513459992414\n",
      "222 Train Loss 0.012066352 Test MSE 0.000490802312446348 Test RE 0.0160062345653532\n",
      "223 Train Loss 0.011968175 Test MSE 0.000460854613970807 Test RE 0.01551021603118404\n",
      "224 Train Loss 0.011887005 Test MSE 0.00046317241031913834 Test RE 0.015549170219415707\n",
      "225 Train Loss 0.011770164 Test MSE 0.00044106782075560086 Test RE 0.015173597646191946\n",
      "226 Train Loss 0.011686952 Test MSE 0.0004381324227765201 Test RE 0.015123021634925097\n",
      "227 Train Loss 0.011603107 Test MSE 0.00045304897662309604 Test RE 0.015378304422257565\n",
      "228 Train Loss 0.011498737 Test MSE 0.0004581689553654496 Test RE 0.01546495662795169\n",
      "229 Train Loss 0.011384045 Test MSE 0.0004421927624807096 Test RE 0.01519293542407942\n",
      "230 Train Loss 0.01127329 Test MSE 0.00045658614869302646 Test RE 0.01543822062421238\n",
      "231 Train Loss 0.011144294 Test MSE 0.00045193563225970394 Test RE 0.015359397106402075\n",
      "232 Train Loss 0.011069186 Test MSE 0.00044267464636434274 Test RE 0.015201211494876328\n",
      "233 Train Loss 0.010983569 Test MSE 0.00044570379542667444 Test RE 0.01525313250701213\n",
      "234 Train Loss 0.010857759 Test MSE 0.0004968361113533908 Test RE 0.016104322309917225\n",
      "235 Train Loss 0.010706818 Test MSE 0.0005228249072163656 Test RE 0.016520150954918614\n",
      "236 Train Loss 0.010618421 Test MSE 0.0004959748646696997 Test RE 0.01609035813765582\n",
      "237 Train Loss 0.010535532 Test MSE 0.0004988341329577406 Test RE 0.016136671507561935\n",
      "238 Train Loss 0.01043838 Test MSE 0.0005341513949218946 Test RE 0.016698138554450903\n",
      "239 Train Loss 0.010364052 Test MSE 0.0005254533610670111 Test RE 0.01656162565797541\n",
      "240 Train Loss 0.010268745 Test MSE 0.0005517855525547026 Test RE 0.016971531692185814\n",
      "241 Train Loss 0.010160856 Test MSE 0.0005674031566919103 Test RE 0.017210034887173785\n",
      "242 Train Loss 0.010078474 Test MSE 0.0005474864169748029 Test RE 0.016905287123941733\n",
      "243 Train Loss 0.009941231 Test MSE 0.0005592102545059674 Test RE 0.0170853327026313\n",
      "244 Train Loss 0.009840542 Test MSE 0.0005677700683953118 Test RE 0.017215598429288582\n",
      "245 Train Loss 0.009744741 Test MSE 0.000536348089906098 Test RE 0.016732438832037275\n",
      "246 Train Loss 0.009610905 Test MSE 0.0005779990262531953 Test RE 0.017369984474903406\n",
      "247 Train Loss 0.009493634 Test MSE 0.0006291519260018317 Test RE 0.018122313627944985\n",
      "248 Train Loss 0.009400323 Test MSE 0.0006282142411057156 Test RE 0.018108803889382866\n",
      "249 Train Loss 0.009302924 Test MSE 0.0006119288704513288 Test RE 0.017872542917541985\n",
      "250 Train Loss 0.0092223175 Test MSE 0.0006404355819642264 Test RE 0.018284100650719278\n",
      "251 Train Loss 0.009153841 Test MSE 0.0006348881478519516 Test RE 0.01820474025244812\n",
      "252 Train Loss 0.009095549 Test MSE 0.0006430058280667293 Test RE 0.01832075350347811\n",
      "253 Train Loss 0.009017885 Test MSE 0.0006007199359536017 Test RE 0.01770809729135909\n",
      "254 Train Loss 0.008960758 Test MSE 0.000586577611642314 Test RE 0.017498411217262252\n",
      "255 Train Loss 0.008903594 Test MSE 0.0005574848006429681 Test RE 0.01705895377944081\n",
      "256 Train Loss 0.0088367 Test MSE 0.000558725741706724 Test RE 0.01707792953346478\n",
      "257 Train Loss 0.008724106 Test MSE 0.0005597836884374096 Test RE 0.017094090409668083\n",
      "258 Train Loss 0.008638619 Test MSE 0.0005589244667126439 Test RE 0.017080966363231295\n",
      "259 Train Loss 0.008573777 Test MSE 0.0005478072774690369 Test RE 0.01691024016397392\n",
      "260 Train Loss 0.008501606 Test MSE 0.0005211446676876307 Test RE 0.01649358360130552\n",
      "261 Train Loss 0.008430142 Test MSE 0.0005497511731651499 Test RE 0.016940216612519113\n",
      "262 Train Loss 0.00836554 Test MSE 0.0005239837975223148 Test RE 0.01653845004996721\n",
      "263 Train Loss 0.00829317 Test MSE 0.0005194135318755288 Test RE 0.016466166661271712\n",
      "264 Train Loss 0.008225966 Test MSE 0.0005065611686084646 Test RE 0.016261171285283763\n",
      "265 Train Loss 0.008149934 Test MSE 0.00048349321412224954 Test RE 0.015886603936888146\n",
      "266 Train Loss 0.0080403285 Test MSE 0.0004901433428758775 Test RE 0.015995485671108523\n",
      "267 Train Loss 0.007919512 Test MSE 0.0004553931038534657 Test RE 0.01541803764562799\n",
      "268 Train Loss 0.007821031 Test MSE 0.00042445054137866265 Test RE 0.014885020010453996\n",
      "269 Train Loss 0.0077497666 Test MSE 0.00038981207711974013 Test RE 0.014264728889592033\n",
      "270 Train Loss 0.0077143214 Test MSE 0.0003863112723204729 Test RE 0.014200530445208439\n",
      "271 Train Loss 0.007658015 Test MSE 0.0003733867629315658 Test RE 0.013960961700176237\n",
      "272 Train Loss 0.00759651 Test MSE 0.0003644119329314482 Test RE 0.013792156352112407\n",
      "273 Train Loss 0.007517831 Test MSE 0.0003522419844169754 Test RE 0.01355989842957755\n",
      "274 Train Loss 0.00744837 Test MSE 0.00034442745077016676 Test RE 0.01340864076290302\n",
      "275 Train Loss 0.0073693153 Test MSE 0.0003144241925235927 Test RE 0.01281131926061748\n",
      "276 Train Loss 0.0073019858 Test MSE 0.00031816170099970936 Test RE 0.012887237339356717\n",
      "277 Train Loss 0.007268202 Test MSE 0.0003196002247587808 Test RE 0.012916338405515633\n",
      "278 Train Loss 0.00722413 Test MSE 0.0003067485635917255 Test RE 0.012653980059871265\n",
      "279 Train Loss 0.007169044 Test MSE 0.00029991992436331267 Test RE 0.012512339965503029\n",
      "280 Train Loss 0.0070959176 Test MSE 0.0002953075653107114 Test RE 0.012415755838962112\n",
      "281 Train Loss 0.0070446436 Test MSE 0.00029802602946443 Test RE 0.012472771762036585\n",
      "282 Train Loss 0.006970894 Test MSE 0.00030808869966756784 Test RE 0.012681591556344485\n",
      "283 Train Loss 0.0068847993 Test MSE 0.00031655033688262994 Test RE 0.01285456151524805\n",
      "284 Train Loss 0.006815445 Test MSE 0.0003257073464828788 Test RE 0.013039161189552171\n",
      "285 Train Loss 0.006776358 Test MSE 0.00032595210392911327 Test RE 0.013044059501628406\n",
      "286 Train Loss 0.0067300163 Test MSE 0.0003420015222005635 Test RE 0.013361336338411307\n",
      "287 Train Loss 0.006699283 Test MSE 0.0003473421938656995 Test RE 0.013465257048657827\n",
      "288 Train Loss 0.0066502434 Test MSE 0.00034251870753508677 Test RE 0.013371435235990917\n",
      "289 Train Loss 0.0065527186 Test MSE 0.0003348625458846837 Test RE 0.013221147922122412\n",
      "290 Train Loss 0.0064788507 Test MSE 0.0003403055117380434 Test RE 0.013328165242709168\n",
      "291 Train Loss 0.006407843 Test MSE 0.0003286269686044611 Test RE 0.01309747195698091\n",
      "292 Train Loss 0.006377915 Test MSE 0.0003260202083297776 Test RE 0.013045422142711831\n",
      "293 Train Loss 0.006364919 Test MSE 0.00033277980054745147 Test RE 0.013179967988634933\n",
      "294 Train Loss 0.0063342704 Test MSE 0.000331514040169823 Test RE 0.013154878462433475\n",
      "295 Train Loss 0.0063063134 Test MSE 0.0003442229933312085 Test RE 0.01340466038428689\n",
      "296 Train Loss 0.0062662796 Test MSE 0.0003598523971220191 Test RE 0.013705600763697357\n",
      "297 Train Loss 0.006231673 Test MSE 0.0003712329388508711 Test RE 0.013920637635742172\n",
      "298 Train Loss 0.0062011587 Test MSE 0.00037452138476695804 Test RE 0.013982157412131869\n",
      "299 Train Loss 0.006173534 Test MSE 0.00037077738372042884 Test RE 0.013912093721747152\n",
      "Training time: 204.12\n",
      "KG_atanh_high\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 47505.195 Test MSE 8.67151969822359 Test RE 2.1275681702574474\n",
      "1 Train Loss 37429.555 Test MSE 9.62160503246951 Test RE 2.2410917633848997\n",
      "2 Train Loss 33547.484 Test MSE 8.893519370999268 Test RE 2.1546300104733014\n",
      "3 Train Loss 22109.447 Test MSE 5.642816164713698 Test RE 1.7162629522591943\n",
      "4 Train Loss 12263.376 Test MSE 14.659976481932548 Test RE 2.766320618282705\n",
      "5 Train Loss 6292.458 Test MSE 16.6589987519387 Test RE 2.9489018961939686\n",
      "6 Train Loss 3159.0093 Test MSE 19.612715664630727 Test RE 3.199666711138987\n",
      "7 Train Loss 1686.2688 Test MSE 21.962819981963694 Test RE 3.385945222404952\n",
      "8 Train Loss 1085.7936 Test MSE 22.97491867727146 Test RE 3.463082743690956\n",
      "9 Train Loss 731.89685 Test MSE 22.77516351229687 Test RE 3.447995010614825\n",
      "10 Train Loss 566.42194 Test MSE 23.89068481236958 Test RE 3.5314265373810385\n",
      "11 Train Loss 417.1982 Test MSE 24.87819833100156 Test RE 3.60367270021245\n",
      "12 Train Loss 301.67242 Test MSE 25.626015189643848 Test RE 3.6574333151437375\n",
      "13 Train Loss 223.70438 Test MSE 26.028222140691575 Test RE 3.6860237503089333\n",
      "14 Train Loss 168.43034 Test MSE 25.580115930440417 Test RE 3.6541563968192343\n",
      "15 Train Loss 136.90012 Test MSE 25.023576270943302 Test RE 3.6141865521116747\n",
      "16 Train Loss 113.932724 Test MSE 24.62506045524835 Test RE 3.5852919795394618\n",
      "17 Train Loss 97.102264 Test MSE 24.50853668277456 Test RE 3.5767992666822606\n",
      "18 Train Loss 86.27949 Test MSE 24.273015847880004 Test RE 3.559571710788484\n",
      "19 Train Loss 78.4839 Test MSE 24.101395867842097 Test RE 3.546965587182262\n",
      "20 Train Loss 69.37177 Test MSE 23.575875118994446 Test RE 3.508082418601008\n",
      "21 Train Loss 65.22407 Test MSE 23.040674235061815 Test RE 3.4680349752666095\n",
      "22 Train Loss 61.536564 Test MSE 22.50877017013676 Test RE 3.4277706848804494\n",
      "23 Train Loss 55.68355 Test MSE 21.58716552713344 Test RE 3.356863544881264\n",
      "24 Train Loss 51.58344 Test MSE 20.995641655643745 Test RE 3.3105522966338925\n",
      "25 Train Loss 48.832737 Test MSE 20.52794239917108 Test RE 3.2734716729701274\n",
      "26 Train Loss 45.949467 Test MSE 20.019418130687544 Test RE 3.2326717063572104\n",
      "27 Train Loss 43.928562 Test MSE 19.620428313912292 Test RE 3.2002957795946028\n",
      "28 Train Loss 41.56846 Test MSE 19.579533577781252 Test RE 3.1969588616605864\n",
      "29 Train Loss 39.64852 Test MSE 19.413334974251104 Test RE 3.183361437576193\n",
      "30 Train Loss 37.991596 Test MSE 19.330120557328392 Test RE 3.1765314403465825\n",
      "31 Train Loss 36.64225 Test MSE 19.32128382836183 Test RE 3.1758052846018114\n",
      "32 Train Loss 35.576473 Test MSE 19.25629472462142 Test RE 3.1704597136454433\n",
      "33 Train Loss 34.592907 Test MSE 19.173909427267255 Test RE 3.163670265178275\n",
      "34 Train Loss 33.550755 Test MSE 18.99900051742118 Test RE 3.1492073340569933\n",
      "35 Train Loss 32.16882 Test MSE 18.779175268154564 Test RE 3.1309355985518965\n",
      "36 Train Loss 30.809576 Test MSE 18.5670396778102 Test RE 3.1132013467166892\n",
      "37 Train Loss 29.727797 Test MSE 18.292685169943475 Test RE 3.0901147486189133\n",
      "38 Train Loss 28.839388 Test MSE 18.288961559955183 Test RE 3.089800224872188\n",
      "39 Train Loss 27.962559 Test MSE 18.25815698214749 Test RE 3.087197012452155\n",
      "40 Train Loss 27.358637 Test MSE 18.179142651979166 Test RE 3.0805096647400423\n",
      "41 Train Loss 26.459743 Test MSE 18.132853801490903 Test RE 3.076585273482931\n",
      "42 Train Loss 25.804813 Test MSE 18.096666478283094 Test RE 3.0735138047345973\n",
      "43 Train Loss 25.260191 Test MSE 18.048319734002202 Test RE 3.0694054855453388\n",
      "44 Train Loss 24.777502 Test MSE 18.003119467906707 Test RE 3.0655595619463387\n",
      "45 Train Loss 24.513716 Test MSE 17.99890151056845 Test RE 3.0652004253831184\n",
      "46 Train Loss 24.07366 Test MSE 17.901436905475094 Test RE 3.0568900826466487\n",
      "47 Train Loss 23.877905 Test MSE 17.896274079890087 Test RE 3.05644924293965\n",
      "48 Train Loss 23.647242 Test MSE 17.91857826111974 Test RE 3.0583532809013376\n",
      "49 Train Loss 23.37374 Test MSE 17.87890014665383 Test RE 3.0549652625516623\n",
      "50 Train Loss 23.091549 Test MSE 17.832955560843747 Test RE 3.051037464950594\n",
      "51 Train Loss 22.916256 Test MSE 17.78532173475674 Test RE 3.046959908450194\n",
      "52 Train Loss 22.579203 Test MSE 17.71781068141774 Test RE 3.0411714539573165\n",
      "53 Train Loss 22.444935 Test MSE 17.712515089983114 Test RE 3.040716939419827\n",
      "54 Train Loss 22.318583 Test MSE 17.69541599884981 Test RE 3.039248879969622\n",
      "55 Train Loss 22.165382 Test MSE 17.58421634711776 Test RE 3.029684367886652\n",
      "56 Train Loss 21.991625 Test MSE 17.5421726625304 Test RE 3.0260602278299698\n",
      "57 Train Loss 21.713102 Test MSE 17.477206094480596 Test RE 3.0204515980665367\n",
      "58 Train Loss 21.568962 Test MSE 17.406935495309067 Test RE 3.0143733175987824\n",
      "59 Train Loss 21.483223 Test MSE 17.346261447399833 Test RE 3.0091152443245686\n",
      "60 Train Loss 21.32971 Test MSE 17.271844685063044 Test RE 3.0026536416659466\n",
      "61 Train Loss 21.173988 Test MSE 17.24055372896872 Test RE 2.9999324935215173\n",
      "62 Train Loss 21.036417 Test MSE 17.21868331314049 Test RE 2.9980291152262466\n",
      "63 Train Loss 20.865534 Test MSE 17.05317427510739 Test RE 2.9835855290350612\n",
      "64 Train Loss 20.739916 Test MSE 16.972090736383556 Test RE 2.9764839794552778\n",
      "65 Train Loss 20.624346 Test MSE 16.875735722335975 Test RE 2.968022812877716\n",
      "66 Train Loss 20.481089 Test MSE 16.86671226336215 Test RE 2.9672292056079006\n",
      "67 Train Loss 20.397083 Test MSE 16.79647323998896 Test RE 2.9610444580950657\n",
      "68 Train Loss 20.286274 Test MSE 16.721369068196534 Test RE 2.9544169970113354\n",
      "69 Train Loss 20.21927 Test MSE 16.662504817179457 Test RE 2.94921219390925\n",
      "70 Train Loss 20.14652 Test MSE 16.628173041935963 Test RE 2.946172317840911\n",
      "71 Train Loss 20.06256 Test MSE 16.548923810767484 Test RE 2.9391432609861243\n",
      "72 Train Loss 19.972637 Test MSE 16.46348722032614 Test RE 2.931546533818934\n",
      "73 Train Loss 19.888533 Test MSE 16.42670852358683 Test RE 2.9282702308624797\n",
      "74 Train Loss 19.808176 Test MSE 16.347306687116074 Test RE 2.921184463012607\n",
      "75 Train Loss 19.670387 Test MSE 16.22794945836998 Test RE 2.9105006466415873\n",
      "76 Train Loss 19.600897 Test MSE 16.148389993849275 Test RE 2.9033573417705414\n",
      "77 Train Loss 19.53229 Test MSE 16.0523648532157 Test RE 2.894712176752563\n",
      "78 Train Loss 19.409994 Test MSE 15.959179764894563 Test RE 2.886297945473232\n",
      "79 Train Loss 19.288334 Test MSE 15.936826546283614 Test RE 2.8842758911592736\n",
      "80 Train Loss 19.208712 Test MSE 15.86861949565351 Test RE 2.87809715495366\n",
      "81 Train Loss 19.093266 Test MSE 15.811707806576555 Test RE 2.8729314725718895\n",
      "82 Train Loss 19.030897 Test MSE 15.72005089350882 Test RE 2.864592501504749\n",
      "83 Train Loss 18.953304 Test MSE 15.659153473894696 Test RE 2.8590385892964933\n",
      "84 Train Loss 18.875473 Test MSE 15.611173188413384 Test RE 2.8546551234663124\n",
      "85 Train Loss 18.814243 Test MSE 15.565940081208868 Test RE 2.850516466180998\n",
      "86 Train Loss 18.731833 Test MSE 15.461418997489508 Test RE 2.8409301225359664\n",
      "87 Train Loss 18.663132 Test MSE 15.397201208054652 Test RE 2.8350241936363187\n",
      "88 Train Loss 18.567024 Test MSE 15.217266283767692 Test RE 2.8184101684308245\n",
      "89 Train Loss 18.448782 Test MSE 15.040909849195176 Test RE 2.8020309694105907\n",
      "90 Train Loss 18.270489 Test MSE 14.725639744037794 Test RE 2.772508987302298\n",
      "91 Train Loss 18.006702 Test MSE 14.276181200977028 Test RE 2.729869603018745\n",
      "92 Train Loss 17.454763 Test MSE 13.658329454367163 Test RE 2.670143911643571\n",
      "93 Train Loss 16.592754 Test MSE 13.198671131193045 Test RE 2.624828789301807\n",
      "94 Train Loss 15.962986 Test MSE 13.002578202323809 Test RE 2.6052572559106273\n",
      "95 Train Loss 15.400832 Test MSE 12.703573204606064 Test RE 2.57512801839969\n",
      "96 Train Loss 14.793676 Test MSE 12.278415582926076 Test RE 2.531669684902672\n",
      "97 Train Loss 14.279508 Test MSE 12.001326292074973 Test RE 2.5029403442869835\n",
      "98 Train Loss 13.861207 Test MSE 11.666454258183336 Test RE 2.467773624530198\n",
      "99 Train Loss 13.133998 Test MSE 11.338824332081208 Test RE 2.432875530714253\n",
      "100 Train Loss 12.706013 Test MSE 11.218472275913749 Test RE 2.4199296257729164\n",
      "101 Train Loss 12.30899 Test MSE 11.106819822044965 Test RE 2.4078572725386946\n",
      "102 Train Loss 12.025533 Test MSE 10.953960801387101 Test RE 2.391230646827768\n",
      "103 Train Loss 11.5829115 Test MSE 10.826525003328664 Test RE 2.3772804479398215\n",
      "104 Train Loss 11.218142 Test MSE 10.675620841428888 Test RE 2.3606545975170623\n",
      "105 Train Loss 10.927565 Test MSE 10.354737402589766 Test RE 2.3249061252647483\n",
      "106 Train Loss 10.609635 Test MSE 10.169037908909687 Test RE 2.3039646430479315\n",
      "107 Train Loss 10.142117 Test MSE 9.851108471360485 Test RE 2.267662548097582\n",
      "108 Train Loss 9.875769 Test MSE 9.813482809379032 Test RE 2.263327810973103\n",
      "109 Train Loss 9.600297 Test MSE 9.662978136542245 Test RE 2.2459049655845305\n",
      "110 Train Loss 9.392274 Test MSE 9.539301197452556 Test RE 2.23148595476166\n",
      "111 Train Loss 9.181685 Test MSE 9.515192333198481 Test RE 2.2286643315925936\n",
      "112 Train Loss 8.982058 Test MSE 9.28347807523479 Test RE 2.201360831826671\n",
      "113 Train Loss 8.726566 Test MSE 9.206465499890301 Test RE 2.192210946006646\n",
      "114 Train Loss 8.512956 Test MSE 8.97333003819664 Test RE 2.1642762694016793\n",
      "115 Train Loss 8.288753 Test MSE 8.91477814179092 Test RE 2.1572036511061046\n",
      "116 Train Loss 8.010861 Test MSE 8.791772915867533 Test RE 2.142269516071559\n",
      "117 Train Loss 7.824019 Test MSE 8.641754374637978 Test RE 2.1239135517794114\n",
      "118 Train Loss 7.6586847 Test MSE 8.466335738181458 Test RE 2.102246413596761\n",
      "119 Train Loss 7.4139633 Test MSE 8.153111807700435 Test RE 2.062992152402343\n",
      "120 Train Loss 7.2668457 Test MSE 7.964382049583241 Test RE 2.0389750865087257\n",
      "121 Train Loss 7.034614 Test MSE 7.70665935773919 Test RE 2.005713780878174\n",
      "122 Train Loss 6.793522 Test MSE 7.328371315733606 Test RE 1.9558683095151606\n",
      "123 Train Loss 6.5379505 Test MSE 7.068498115460045 Test RE 1.9208765298513604\n",
      "124 Train Loss 6.340189 Test MSE 6.8839501704529855 Test RE 1.8956350751644622\n",
      "125 Train Loss 6.0760536 Test MSE 6.63865357381203 Test RE 1.861555034365714\n",
      "126 Train Loss 5.753858 Test MSE 6.308994091727659 Test RE 1.8147463736620768\n",
      "127 Train Loss 5.4312024 Test MSE 6.162314278866987 Test RE 1.7935265032584184\n",
      "128 Train Loss 5.167042 Test MSE 5.700516106013171 Test RE 1.725015355700033\n",
      "129 Train Loss 4.819247 Test MSE 5.225874155238477 Test RE 1.651639841347874\n",
      "130 Train Loss 4.609528 Test MSE 4.879092639558638 Test RE 1.595899023433855\n",
      "131 Train Loss 4.373652 Test MSE 4.710737822920328 Test RE 1.5681237915451942\n",
      "132 Train Loss 4.2193584 Test MSE 4.522488419119455 Test RE 1.5364718525944323\n",
      "133 Train Loss 4.0251317 Test MSE 4.225341806088096 Test RE 1.4851379650009877\n",
      "134 Train Loss 3.7662618 Test MSE 3.6228292646926046 Test RE 1.3751808327166992\n",
      "135 Train Loss 3.5152128 Test MSE 3.537934374319209 Test RE 1.3589727967354246\n",
      "136 Train Loss 3.314665 Test MSE 3.5889574711667547 Test RE 1.368737080497421\n",
      "137 Train Loss 3.0178947 Test MSE 3.110301224549531 Test RE 1.2741985383724528\n",
      "138 Train Loss 2.872897 Test MSE 2.879091179465639 Test RE 1.2259241102365714\n",
      "139 Train Loss 2.6992369 Test MSE 2.7437969376542295 Test RE 1.1967732142869167\n",
      "140 Train Loss 2.5395637 Test MSE 2.5959053222756143 Test RE 1.1640732283104795\n",
      "141 Train Loss 2.3608632 Test MSE 2.4208836261913778 Test RE 1.1241462949227181\n",
      "142 Train Loss 2.219644 Test MSE 2.2080378444087416 Test RE 1.0735916701936057\n",
      "143 Train Loss 2.0190856 Test MSE 1.8948101917346774 Test RE 0.9945319344857358\n",
      "144 Train Loss 1.8952622 Test MSE 1.821545981470944 Test RE 0.9751152448865025\n",
      "145 Train Loss 1.7942519 Test MSE 1.7707947414140774 Test RE 0.9614351341623628\n",
      "146 Train Loss 1.6994066 Test MSE 1.6309230621256912 Test RE 0.9226832015011891\n",
      "147 Train Loss 1.6214108 Test MSE 1.5951468869707106 Test RE 0.9125070263380284\n",
      "148 Train Loss 1.5318168 Test MSE 1.5090381889266486 Test RE 0.8875360292871904\n",
      "149 Train Loss 1.4173986 Test MSE 1.3281190552018978 Test RE 0.8326344597046812\n",
      "150 Train Loss 1.3588521 Test MSE 1.233177919598809 Test RE 0.8023220849322011\n",
      "151 Train Loss 1.2890553 Test MSE 1.1817547153119277 Test RE 0.78541564666322\n",
      "152 Train Loss 1.1817114 Test MSE 1.1862054822613122 Test RE 0.7868932869596693\n",
      "153 Train Loss 1.1177438 Test MSE 1.1215693468273924 Test RE 0.7651541577961822\n",
      "154 Train Loss 1.0794047 Test MSE 1.0845433244487037 Test RE 0.7524182652267265\n",
      "155 Train Loss 1.0369623 Test MSE 1.0726122936784845 Test RE 0.7482681537041564\n",
      "156 Train Loss 1.0029335 Test MSE 1.0091642481466023 Test RE 0.7257997345641825\n",
      "157 Train Loss 0.94191045 Test MSE 0.9684113854956421 Test RE 0.7109938108889936\n",
      "158 Train Loss 0.91237664 Test MSE 0.9319125532115888 Test RE 0.6974666685931554\n",
      "159 Train Loss 0.87071335 Test MSE 0.892677489777 Test RE 0.6826265389656566\n",
      "160 Train Loss 0.8444078 Test MSE 0.8573143623002051 Test RE 0.6689688976275361\n",
      "161 Train Loss 0.7950509 Test MSE 0.8798065390216046 Test RE 0.6776874914412537\n",
      "162 Train Loss 0.77741975 Test MSE 0.8486954433545949 Test RE 0.6655976993243379\n",
      "163 Train Loss 0.73232675 Test MSE 0.7603359613035581 Test RE 0.629997234023309\n",
      "164 Train Loss 0.7101779 Test MSE 0.7160013182223302 Test RE 0.6113540418911507\n",
      "165 Train Loss 0.6888577 Test MSE 0.6936209255897384 Test RE 0.6017234962473379\n",
      "166 Train Loss 0.66450524 Test MSE 0.6917290460543338 Test RE 0.6009023231561172\n",
      "167 Train Loss 0.6406696 Test MSE 0.6342409703318176 Test RE 0.575390945375958\n",
      "168 Train Loss 0.6150723 Test MSE 0.5501733449939025 Test RE 0.5359023355130705\n",
      "169 Train Loss 0.5949506 Test MSE 0.48681048539482763 Test RE 0.5040990034100116\n",
      "170 Train Loss 0.55162334 Test MSE 0.42813145754509474 Test RE 0.4727422812530336\n",
      "171 Train Loss 0.5236065 Test MSE 0.41716225702077764 Test RE 0.4666468957570737\n",
      "172 Train Loss 0.5034088 Test MSE 0.3722059246492899 Test RE 0.44078572145112294\n",
      "173 Train Loss 0.4847379 Test MSE 0.33768139560276855 Test RE 0.4198454431922469\n",
      "174 Train Loss 0.45891312 Test MSE 0.31183194455977997 Test RE 0.4034559999097984\n",
      "175 Train Loss 0.43861228 Test MSE 0.30956968876838237 Test RE 0.4019898542737958\n",
      "176 Train Loss 0.4184688 Test MSE 0.2628337166064257 Test RE 0.37040463713138816\n",
      "177 Train Loss 0.4082239 Test MSE 0.23791554235026685 Test RE 0.3524092376558077\n",
      "178 Train Loss 0.38912582 Test MSE 0.21250237780365375 Test RE 0.3330563926515786\n",
      "179 Train Loss 0.3683889 Test MSE 0.2125126069397364 Test RE 0.333064408651684\n",
      "180 Train Loss 0.34450233 Test MSE 0.21769331716947043 Test RE 0.3370997461271834\n",
      "181 Train Loss 0.3279411 Test MSE 0.19024987887768988 Test RE 0.31513603854952693\n",
      "182 Train Loss 0.3174777 Test MSE 0.17760713863576513 Test RE 0.30448512833883484\n",
      "183 Train Loss 0.2983 Test MSE 0.15158522076051104 Test RE 0.2812964861631075\n",
      "184 Train Loss 0.28185114 Test MSE 0.13760680413179935 Test RE 0.26801298220907593\n",
      "185 Train Loss 0.274603 Test MSE 0.12306058571975473 Test RE 0.25345179177305094\n",
      "186 Train Loss 0.26863563 Test MSE 0.12238020752550152 Test RE 0.25275017767095714\n",
      "187 Train Loss 0.26357827 Test MSE 0.11567969501778078 Test RE 0.2457335441290628\n",
      "188 Train Loss 0.25330022 Test MSE 0.1148164014658881 Test RE 0.24481489778663534\n",
      "189 Train Loss 0.24406797 Test MSE 0.11341963673558322 Test RE 0.24332122983658552\n",
      "190 Train Loss 0.2352456 Test MSE 0.10522912539993633 Test RE 0.23437099150385685\n",
      "191 Train Loss 0.22706799 Test MSE 0.10610280485033685 Test RE 0.23534192921170108\n",
      "192 Train Loss 0.21870057 Test MSE 0.10659629742507785 Test RE 0.23588859131167986\n",
      "193 Train Loss 0.20948635 Test MSE 0.10060261450597728 Test RE 0.22916089547833862\n",
      "194 Train Loss 0.203036 Test MSE 0.09491068491308229 Test RE 0.22258373752767666\n",
      "195 Train Loss 0.19690554 Test MSE 0.0938025420616076 Test RE 0.22128051874793703\n",
      "196 Train Loss 0.1936439 Test MSE 0.0891246010724442 Test RE 0.21569231731397712\n",
      "197 Train Loss 0.1860592 Test MSE 0.08024144509192825 Test RE 0.20466107341566853\n",
      "198 Train Loss 0.17989121 Test MSE 0.07438847916563543 Test RE 0.1970555707379932\n",
      "199 Train Loss 0.17316662 Test MSE 0.06687862205734157 Test RE 0.18684416302938478\n",
      "200 Train Loss 0.16938996 Test MSE 0.06162300000589021 Test RE 0.179352442542827\n",
      "201 Train Loss 0.16492921 Test MSE 0.05570957198880472 Test RE 0.17052999833169863\n",
      "202 Train Loss 0.15979026 Test MSE 0.055527010615071634 Test RE 0.17025035394812169\n",
      "203 Train Loss 0.15321338 Test MSE 0.05642680860650947 Test RE 0.17162423757655193\n",
      "204 Train Loss 0.15021484 Test MSE 0.05412794320411669 Test RE 0.16809184313228093\n",
      "205 Train Loss 0.14747664 Test MSE 0.04818016103430464 Test RE 0.15858788255465064\n",
      "206 Train Loss 0.14358534 Test MSE 0.04199146299371575 Test RE 0.1480527163276431\n",
      "207 Train Loss 0.13953348 Test MSE 0.040185439249396306 Test RE 0.14483390384268613\n",
      "208 Train Loss 0.13403946 Test MSE 0.03524781996870412 Test RE 0.13564444336077916\n",
      "209 Train Loss 0.13175112 Test MSE 0.03172171423985202 Test RE 0.12868093302080746\n",
      "210 Train Loss 0.12944469 Test MSE 0.03153435710804546 Test RE 0.12830035782737664\n",
      "211 Train Loss 0.12681493 Test MSE 0.029867812166034985 Test RE 0.1248640975358698\n",
      "212 Train Loss 0.123598814 Test MSE 0.032280151903992006 Test RE 0.1298086585067907\n",
      "213 Train Loss 0.120895974 Test MSE 0.030208823482210333 Test RE 0.1255748831301926\n",
      "214 Train Loss 0.11859162 Test MSE 0.029213768778187228 Test RE 0.12348939720361668\n",
      "215 Train Loss 0.116921134 Test MSE 0.031613679975941916 Test RE 0.12846162257626803\n",
      "216 Train Loss 0.11523035 Test MSE 0.034301352866649946 Test RE 0.13381090301048074\n",
      "217 Train Loss 0.11248994 Test MSE 0.0352625290700047 Test RE 0.13567274297974496\n",
      "218 Train Loss 0.10946757 Test MSE 0.03403144724326588 Test RE 0.13328340715671302\n",
      "219 Train Loss 0.10683977 Test MSE 0.03339749418934319 Test RE 0.13203613965910968\n",
      "220 Train Loss 0.10452187 Test MSE 0.03240339515831081 Test RE 0.13005622240926767\n",
      "221 Train Loss 0.10280943 Test MSE 0.03214057851412313 Test RE 0.12952772021458844\n",
      "222 Train Loss 0.1018612 Test MSE 0.03157145210064249 Test RE 0.1283757977990265\n",
      "223 Train Loss 0.10066305 Test MSE 0.03179015983218813 Test RE 0.12881968492899276\n",
      "224 Train Loss 0.099492565 Test MSE 0.031443578257458624 Test RE 0.12811555378700565\n",
      "225 Train Loss 0.09775847 Test MSE 0.030092339980749377 Test RE 0.12533254449774622\n",
      "226 Train Loss 0.09560559 Test MSE 0.02947625380605299 Test RE 0.1240429312813681\n",
      "227 Train Loss 0.09427481 Test MSE 0.02962342053697644 Test RE 0.12435220165185773\n",
      "228 Train Loss 0.09236636 Test MSE 0.028274736547204523 Test RE 0.12148849733787165\n",
      "229 Train Loss 0.090854846 Test MSE 0.02783872631646095 Test RE 0.12054815216118123\n",
      "230 Train Loss 0.08940715 Test MSE 0.028189794551043895 Test RE 0.12130587428363807\n",
      "231 Train Loss 0.088419884 Test MSE 0.0267128192475338 Test RE 0.11808527345450483\n",
      "232 Train Loss 0.0872335 Test MSE 0.027631919781800424 Test RE 0.12009955731589095\n",
      "233 Train Loss 0.08585092 Test MSE 0.027471809904032897 Test RE 0.11975110049837438\n",
      "234 Train Loss 0.08431824 Test MSE 0.027204421141656148 Test RE 0.11916689445740897\n",
      "235 Train Loss 0.0830673 Test MSE 0.026543149744046767 Test RE 0.11770966005781608\n",
      "236 Train Loss 0.08191909 Test MSE 0.025913596980015132 Test RE 0.11630535921290491\n",
      "237 Train Loss 0.08089734 Test MSE 0.02493934017704156 Test RE 0.11409808528546399\n",
      "238 Train Loss 0.07971792 Test MSE 0.024906740127039077 Test RE 0.11402348789042255\n",
      "239 Train Loss 0.07773913 Test MSE 0.02393119977259055 Test RE 0.11176816299404718\n",
      "240 Train Loss 0.076694705 Test MSE 0.02276941371970364 Test RE 0.10902141162563853\n",
      "241 Train Loss 0.07599316 Test MSE 0.02210898521286359 Test RE 0.107428690392274\n",
      "242 Train Loss 0.07474593 Test MSE 0.022883730678366184 Test RE 0.10929474743614626\n",
      "243 Train Loss 0.073555306 Test MSE 0.022726380981985185 Test RE 0.10891834115089695\n",
      "244 Train Loss 0.072676904 Test MSE 0.0224020142998204 Test RE 0.10813826863476976\n",
      "245 Train Loss 0.07200884 Test MSE 0.02211708857275357 Test RE 0.10744837590882465\n",
      "246 Train Loss 0.070870705 Test MSE 0.02146388223884164 Test RE 0.10584979356202084\n",
      "247 Train Loss 0.069627434 Test MSE 0.021200338767408865 Test RE 0.10519795011704174\n",
      "248 Train Loss 0.06860821 Test MSE 0.020841636600526157 Test RE 0.10430419760703731\n",
      "249 Train Loss 0.06764493 Test MSE 0.02136074609746362 Test RE 0.10559517780784275\n",
      "250 Train Loss 0.06682691 Test MSE 0.02197120093819965 Test RE 0.10709341679525346\n",
      "251 Train Loss 0.066126764 Test MSE 0.022086868384521553 Test RE 0.10737494354715367\n",
      "252 Train Loss 0.06565015 Test MSE 0.022795920701263395 Test RE 0.10908485173052795\n",
      "253 Train Loss 0.06517731 Test MSE 0.021731433517756832 Test RE 0.10650746906648537\n",
      "254 Train Loss 0.0646915 Test MSE 0.021908527740225288 Test RE 0.10694056488216908\n",
      "255 Train Loss 0.06409915 Test MSE 0.021441672262318755 Test RE 0.10579501479742495\n",
      "256 Train Loss 0.06360764 Test MSE 0.020567661574979194 Test RE 0.10361636098234117\n",
      "257 Train Loss 0.06282705 Test MSE 0.020100533469237826 Test RE 0.1024329472862767\n",
      "258 Train Loss 0.06228375 Test MSE 0.02076702239847554 Test RE 0.10411732282768178\n",
      "259 Train Loss 0.061395474 Test MSE 0.020569430865425196 Test RE 0.10362081757781866\n",
      "260 Train Loss 0.060861513 Test MSE 0.020701074028139695 Test RE 0.10395187234649841\n",
      "261 Train Loss 0.060065027 Test MSE 0.021039163635787075 Test RE 0.10479730458276583\n",
      "262 Train Loss 0.059554435 Test MSE 0.02090770860454593 Test RE 0.10446939898304086\n",
      "263 Train Loss 0.059022654 Test MSE 0.021128193739592117 Test RE 0.10501880258242144\n",
      "264 Train Loss 0.058418967 Test MSE 0.0217992088292621 Test RE 0.10667342584470782\n",
      "265 Train Loss 0.058062393 Test MSE 0.02261948511360413 Test RE 0.10866188492320003\n",
      "266 Train Loss 0.05731222 Test MSE 0.022140698836126065 Test RE 0.10750571184090552\n",
      "267 Train Loss 0.056705944 Test MSE 0.021666598570988686 Test RE 0.10634846979276937\n",
      "268 Train Loss 0.0560148 Test MSE 0.021317942564799842 Test RE 0.10548932679598114\n",
      "269 Train Loss 0.0553224 Test MSE 0.02029801981274796 Test RE 0.1029349156407249\n",
      "270 Train Loss 0.05465369 Test MSE 0.019199170954895827 Test RE 0.1001099200987248\n",
      "271 Train Loss 0.05390967 Test MSE 0.019189933216257775 Test RE 0.10008583310696942\n",
      "272 Train Loss 0.053391866 Test MSE 0.018757508854641773 Test RE 0.0989517449156553\n",
      "273 Train Loss 0.05290733 Test MSE 0.0189213144017085 Test RE 0.09938286856236495\n",
      "274 Train Loss 0.052483093 Test MSE 0.019124437367291646 Test RE 0.0999148890660968\n",
      "275 Train Loss 0.051530406 Test MSE 0.01770906629755955 Test RE 0.0961465508005603\n",
      "276 Train Loss 0.05059339 Test MSE 0.01649719447896967 Test RE 0.09279849308923428\n",
      "277 Train Loss 0.049094252 Test MSE 0.017425335234157496 Test RE 0.09537322050341093\n",
      "278 Train Loss 0.048335146 Test MSE 0.0178866367384224 Test RE 0.09662738363389337\n",
      "279 Train Loss 0.047908697 Test MSE 0.018185430389873452 Test RE 0.09743111414322686\n",
      "280 Train Loss 0.04737541 Test MSE 0.017999144061443796 Test RE 0.0969308013981646\n",
      "281 Train Loss 0.04690413 Test MSE 0.017825801355056035 Test RE 0.09646292088857486\n",
      "282 Train Loss 0.046298288 Test MSE 0.017220933306402283 Test RE 0.0948121989809831\n",
      "283 Train Loss 0.045866575 Test MSE 0.017349963068292562 Test RE 0.09516673160983027\n",
      "284 Train Loss 0.045350917 Test MSE 0.017076027340930174 Test RE 0.09441245650751728\n",
      "285 Train Loss 0.044914253 Test MSE 0.015984417363546128 Test RE 0.09134489528419697\n",
      "286 Train Loss 0.043751173 Test MSE 0.016207189697283048 Test RE 0.09197922258642892\n",
      "287 Train Loss 0.043146867 Test MSE 0.016121510743815248 Test RE 0.09173577734496678\n",
      "288 Train Loss 0.042629153 Test MSE 0.0158190781379634 Test RE 0.09087124171132722\n",
      "289 Train Loss 0.042121112 Test MSE 0.015980680208921235 Test RE 0.09133421644788077\n",
      "290 Train Loss 0.041686907 Test MSE 0.01542831736291711 Test RE 0.08974187906502168\n",
      "291 Train Loss 0.041015312 Test MSE 0.01420819556017719 Test RE 0.0861202615113291\n",
      "292 Train Loss 0.040406782 Test MSE 0.013696507904033014 Test RE 0.08455529384378993\n",
      "293 Train Loss 0.039721504 Test MSE 0.01313312929784967 Test RE 0.08279802677363654\n",
      "294 Train Loss 0.03919746 Test MSE 0.012408641952430546 Test RE 0.08048185978291446\n",
      "295 Train Loss 0.038384072 Test MSE 0.01250131145018075 Test RE 0.08078182574849439\n",
      "296 Train Loss 0.037784815 Test MSE 0.012346771747018101 Test RE 0.08028096545182278\n",
      "297 Train Loss 0.037263773 Test MSE 0.01295254816331627 Test RE 0.0822268180942124\n",
      "298 Train Loss 0.036419123 Test MSE 0.012773632602566865 Test RE 0.0816569373795564\n",
      "299 Train Loss 0.035861783 Test MSE 0.012496648616410509 Test RE 0.08076675903502636\n",
      "Training time: 251.92\n",
      "KG_atanh_high\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 53316.6 Test MSE 7.523580198877069 Test RE 1.9817467483612528\n",
      "1 Train Loss 33424.35 Test MSE 6.915880881745374 Test RE 1.9000263728413114\n",
      "2 Train Loss 20095.408 Test MSE 13.65929608689692 Test RE 2.6702383961962988\n",
      "3 Train Loss 10563.022 Test MSE 13.337101612705405 Test RE 2.6385577675334586\n",
      "4 Train Loss 2992.1814 Test MSE 14.296378166864873 Test RE 2.731799937045713\n",
      "5 Train Loss 1401.2407 Test MSE 18.302441850473354 Test RE 3.0909387185023194\n",
      "6 Train Loss 829.4223 Test MSE 19.886574232792317 Test RE 3.2219282497699715\n",
      "7 Train Loss 585.48956 Test MSE 18.872222357981563 Test RE 3.138682596736197\n",
      "8 Train Loss 391.61777 Test MSE 18.049277840297147 Test RE 3.069486955115168\n",
      "9 Train Loss 242.56721 Test MSE 18.03611527881808 Test RE 3.068367528628493\n",
      "10 Train Loss 152.48875 Test MSE 18.80260543026786 Test RE 3.1328881726175895\n",
      "11 Train Loss 106.03131 Test MSE 18.50398832805018 Test RE 3.1079108297751263\n",
      "12 Train Loss 79.09772 Test MSE 18.839117489822083 Test RE 3.1359285151460505\n",
      "13 Train Loss 66.419304 Test MSE 18.28995219742469 Test RE 3.089883904593928\n",
      "14 Train Loss 60.34844 Test MSE 18.117221011239046 Test RE 3.0752587866712116\n",
      "15 Train Loss 52.906445 Test MSE 17.825140328118017 Test RE 3.050368838239078\n",
      "16 Train Loss 47.71946 Test MSE 17.73866492357165 Test RE 3.0429606895458123\n",
      "17 Train Loss 42.35335 Test MSE 17.351091712738796 Test RE 3.0095341764790096\n",
      "18 Train Loss 38.398586 Test MSE 17.10911582050631 Test RE 2.9884752265774703\n",
      "19 Train Loss 35.757008 Test MSE 17.05041859341171 Test RE 2.9833444553184654\n",
      "20 Train Loss 33.099937 Test MSE 17.009561796203588 Test RE 2.9797679153775314\n",
      "21 Train Loss 31.418787 Test MSE 16.96031475327845 Test RE 2.9754511925200933\n",
      "22 Train Loss 30.270222 Test MSE 16.972235364057717 Test RE 2.9764966614826345\n",
      "23 Train Loss 28.961702 Test MSE 16.77789282304304 Test RE 2.959406237277375\n",
      "24 Train Loss 27.337755 Test MSE 16.584343361279025 Test RE 2.942286894104031\n",
      "25 Train Loss 26.301418 Test MSE 16.556066221865308 Test RE 2.939777450408619\n",
      "26 Train Loss 24.595415 Test MSE 16.441156721342523 Test RE 2.9295577355473057\n",
      "27 Train Loss 23.910223 Test MSE 16.41477957823134 Test RE 2.9272067944622653\n",
      "28 Train Loss 22.982325 Test MSE 16.303469790690695 Test RE 2.917265113271081\n",
      "29 Train Loss 22.213806 Test MSE 16.222115468517217 Test RE 2.909977433353605\n",
      "30 Train Loss 21.68452 Test MSE 16.09806158036823 Test RE 2.898829478688405\n",
      "31 Train Loss 21.107563 Test MSE 15.96203393296109 Test RE 2.886556029261278\n",
      "32 Train Loss 20.690968 Test MSE 15.758226647983003 Test RE 2.868068688317202\n",
      "33 Train Loss 20.302227 Test MSE 15.664766413729657 Test RE 2.8595509469353293\n",
      "34 Train Loss 19.91136 Test MSE 15.626129994073706 Test RE 2.856022294901244\n",
      "35 Train Loss 19.683416 Test MSE 15.508022018494009 Test RE 2.845208394504484\n",
      "36 Train Loss 19.371387 Test MSE 15.33032021719622 Test RE 2.8288602299737926\n",
      "37 Train Loss 19.009026 Test MSE 15.211216985834463 Test RE 2.817849913479904\n",
      "38 Train Loss 18.795416 Test MSE 15.123784870370754 Test RE 2.809739923762099\n",
      "39 Train Loss 18.530909 Test MSE 15.051463666958515 Test RE 2.803013853386199\n",
      "40 Train Loss 18.32959 Test MSE 14.962667173673916 Test RE 2.7947333968171644\n",
      "41 Train Loss 18.10315 Test MSE 14.883343535341009 Test RE 2.7873155007680017\n",
      "42 Train Loss 17.888895 Test MSE 14.819965074601274 Test RE 2.781374489174965\n",
      "43 Train Loss 17.711802 Test MSE 14.748941617364121 Test RE 2.774701731282123\n",
      "44 Train Loss 17.53031 Test MSE 14.722734098463611 Test RE 2.772235439733428\n",
      "45 Train Loss 17.399721 Test MSE 14.744566036467099 Test RE 2.7742901142046383\n",
      "46 Train Loss 17.275436 Test MSE 14.65287794493493 Test RE 2.7656507943251674\n",
      "47 Train Loss 17.207664 Test MSE 14.59571468263125 Test RE 2.7602508957141194\n",
      "48 Train Loss 17.031507 Test MSE 14.489294326015532 Test RE 2.7501697076992513\n",
      "49 Train Loss 16.889448 Test MSE 14.412511155026024 Test RE 2.7428730357884783\n",
      "50 Train Loss 16.738932 Test MSE 14.326669030485553 Test RE 2.7346924456676565\n",
      "51 Train Loss 16.575476 Test MSE 14.216849861693962 Test RE 2.724191072810827\n",
      "52 Train Loss 16.434105 Test MSE 14.157736899459914 Test RE 2.7185216471506304\n",
      "53 Train Loss 16.237589 Test MSE 14.03381177873156 Test RE 2.706597651425011\n",
      "54 Train Loss 16.004175 Test MSE 13.896818511865058 Test RE 2.6933548142496293\n",
      "55 Train Loss 15.878987 Test MSE 13.853817468236198 Test RE 2.689184550383318\n",
      "56 Train Loss 15.703845 Test MSE 13.788766553569582 Test RE 2.682863557985735\n",
      "57 Train Loss 15.524718 Test MSE 13.705942305728476 Test RE 2.6747939152163127\n",
      "58 Train Loss 15.357655 Test MSE 13.597893662172456 Test RE 2.6642298952048824\n",
      "59 Train Loss 15.167381 Test MSE 13.548731235801782 Test RE 2.6594093468339817\n",
      "60 Train Loss 14.929829 Test MSE 13.369209940888044 Test RE 2.64173194858858\n",
      "61 Train Loss 14.740898 Test MSE 13.230911063876292 Test RE 2.628032622795468\n",
      "62 Train Loss 14.517727 Test MSE 13.020402606937727 Test RE 2.607042334807847\n",
      "63 Train Loss 14.221544 Test MSE 12.854684486064647 Test RE 2.590398546024667\n",
      "64 Train Loss 13.989783 Test MSE 12.71469801608197 Test RE 2.5762553210934658\n",
      "65 Train Loss 13.704667 Test MSE 12.456457759494425 Test RE 2.549958759919374\n",
      "66 Train Loss 13.313787 Test MSE 12.198657451280065 Test RE 2.523433678309956\n",
      "67 Train Loss 13.028647 Test MSE 11.788908310704027 Test RE 2.480691004828718\n",
      "68 Train Loss 12.466887 Test MSE 10.990409093378236 Test RE 2.3952056424331243\n",
      "69 Train Loss 12.034911 Test MSE 10.38583988894012 Test RE 2.3283951631815842\n",
      "70 Train Loss 11.176892 Test MSE 9.566092890121153 Test RE 2.2346173878652595\n",
      "71 Train Loss 10.174639 Test MSE 9.175134163551553 Test RE 2.188477513505568\n",
      "72 Train Loss 9.611502 Test MSE 8.465368001766109 Test RE 2.1021262625296213\n",
      "73 Train Loss 8.829782 Test MSE 7.848066253509273 Test RE 2.024031220852436\n",
      "74 Train Loss 7.817807 Test MSE 6.958814037845916 Test RE 1.9059148431978785\n",
      "75 Train Loss 7.1683335 Test MSE 6.372283819463672 Test RE 1.8238261248667844\n",
      "76 Train Loss 6.4024687 Test MSE 5.51731879295042 Test RE 1.6970706245075167\n",
      "77 Train Loss 6.039683 Test MSE 5.241478577080647 Test RE 1.6541038955243026\n",
      "78 Train Loss 5.689468 Test MSE 4.644467087533629 Test RE 1.5570545276604442\n",
      "79 Train Loss 5.2348943 Test MSE 4.208114486198804 Test RE 1.4821073133230922\n",
      "80 Train Loss 4.5452304 Test MSE 3.619272679278412 Test RE 1.3745056492202108\n",
      "81 Train Loss 4.1256785 Test MSE 3.1766064890872903 Test RE 1.2877085706639713\n",
      "82 Train Loss 3.7564635 Test MSE 2.989597185731741 Test RE 1.2492294526879935\n",
      "83 Train Loss 3.4924676 Test MSE 2.7296683348757242 Test RE 1.1936879720193005\n",
      "84 Train Loss 3.2845297 Test MSE 2.6130122859779954 Test RE 1.1679025394441753\n",
      "85 Train Loss 2.9978857 Test MSE 2.4670387221301437 Test RE 1.134811844253188\n",
      "86 Train Loss 2.8814669 Test MSE 2.444384039931271 Test RE 1.1295893695015167\n",
      "87 Train Loss 2.7252336 Test MSE 2.2252972399307103 Test RE 1.0777794323139844\n",
      "88 Train Loss 2.5497265 Test MSE 2.0779231743456497 Test RE 1.04147924651618\n",
      "89 Train Loss 2.4169905 Test MSE 1.9908636615462485 Test RE 1.0194281849933249\n",
      "90 Train Loss 2.292954 Test MSE 1.8285071215105368 Test RE 0.9769766969462444\n",
      "91 Train Loss 2.1447961 Test MSE 1.6895003334484655 Test RE 0.9391068703971217\n",
      "92 Train Loss 1.9905822 Test MSE 1.4818482200304142 Test RE 0.8795038366272694\n",
      "93 Train Loss 1.8765773 Test MSE 1.4028047666850247 Test RE 0.8557255384544553\n",
      "94 Train Loss 1.7966558 Test MSE 1.3231676657115063 Test RE 0.8310809291097255\n",
      "95 Train Loss 1.7120726 Test MSE 1.322059134026851 Test RE 0.83073272207368\n",
      "96 Train Loss 1.6442748 Test MSE 1.2693456625394888 Test RE 0.8140026683979473\n",
      "97 Train Loss 1.575605 Test MSE 1.245898139752762 Test RE 0.8064494416971763\n",
      "98 Train Loss 1.5119579 Test MSE 1.1757836802592139 Test RE 0.7834289047189487\n",
      "99 Train Loss 1.4842877 Test MSE 1.1879525090307748 Test RE 0.7874725364495595\n",
      "100 Train Loss 1.4616479 Test MSE 1.2259338470419958 Test RE 0.7999620686036797\n",
      "101 Train Loss 1.408663 Test MSE 1.1277127176164554 Test RE 0.7672468533532856\n",
      "102 Train Loss 1.3585571 Test MSE 1.095541796701899 Test RE 0.756223819314022\n",
      "103 Train Loss 1.3011305 Test MSE 1.0731849667345776 Test RE 0.7484678790997347\n",
      "104 Train Loss 1.2638922 Test MSE 1.0267430311295782 Test RE 0.7320938504305333\n",
      "105 Train Loss 1.2330092 Test MSE 0.994591669299924 Test RE 0.7205403157542933\n",
      "106 Train Loss 1.2078348 Test MSE 0.9934298031753381 Test RE 0.7201193309192112\n",
      "107 Train Loss 1.1536901 Test MSE 0.9614157682141292 Test RE 0.7084211151457926\n",
      "108 Train Loss 1.112018 Test MSE 0.9250004453594785 Test RE 0.6948752572282914\n",
      "109 Train Loss 1.0814954 Test MSE 0.9171908164817277 Test RE 0.6919356798814692\n",
      "110 Train Loss 1.0418452 Test MSE 0.9070949239930863 Test RE 0.6881169334030092\n",
      "111 Train Loss 1.0047939 Test MSE 0.8600594067178984 Test RE 0.6700390311809391\n",
      "112 Train Loss 0.981483 Test MSE 0.8317014530378216 Test RE 0.6589001508969402\n",
      "113 Train Loss 0.95240235 Test MSE 0.8191955039730456 Test RE 0.653927583635191\n",
      "114 Train Loss 0.9197201 Test MSE 0.8203401707629313 Test RE 0.6543842926172307\n",
      "115 Train Loss 0.8914002 Test MSE 0.7631143512318033 Test RE 0.6311472400292579\n",
      "116 Train Loss 0.85513526 Test MSE 0.6881134057315733 Test RE 0.5993298192900497\n",
      "117 Train Loss 0.8165696 Test MSE 0.6362533844606331 Test RE 0.5763030654276537\n",
      "118 Train Loss 0.7797544 Test MSE 0.6211348234824735 Test RE 0.5694148853531278\n",
      "119 Train Loss 0.7314213 Test MSE 0.5944222037672245 Test RE 0.5570361604160391\n",
      "120 Train Loss 0.6990754 Test MSE 0.5422222469057587 Test RE 0.5320158156040126\n",
      "121 Train Loss 0.676956 Test MSE 0.5215566767214291 Test RE 0.5217790426495726\n",
      "122 Train Loss 0.6524392 Test MSE 0.5081235120924142 Test RE 0.5150157640468497\n",
      "123 Train Loss 0.61591774 Test MSE 0.4661263539875959 Test RE 0.49327341054247925\n",
      "124 Train Loss 0.5929018 Test MSE 0.43292114055835396 Test RE 0.47537930773012627\n",
      "125 Train Loss 0.5668849 Test MSE 0.40798980080064384 Test RE 0.46148812485597474\n",
      "126 Train Loss 0.54697806 Test MSE 0.3626062598934792 Test RE 0.43506437776572304\n",
      "127 Train Loss 0.52244586 Test MSE 0.33390409627716544 Test RE 0.4174906468923584\n",
      "128 Train Loss 0.49879652 Test MSE 0.3039136133226803 Test RE 0.39830059383982896\n",
      "129 Train Loss 0.486282 Test MSE 0.27807802724841146 Test RE 0.38099494521790916\n",
      "130 Train Loss 0.45967054 Test MSE 0.28605495257946406 Test RE 0.38642090432168025\n",
      "131 Train Loss 0.43421254 Test MSE 0.295326873104354 Test RE 0.39263350818547094\n",
      "132 Train Loss 0.4140962 Test MSE 0.27178361837437504 Test RE 0.3766582766732197\n",
      "133 Train Loss 0.3980172 Test MSE 0.2789520839959957 Test RE 0.38159324839137165\n",
      "134 Train Loss 0.38088828 Test MSE 0.28939441358226486 Test RE 0.3886699357562117\n",
      "135 Train Loss 0.36695752 Test MSE 0.28028403729640233 Test RE 0.382503188016947\n",
      "136 Train Loss 0.35865465 Test MSE 0.2674350980247688 Test RE 0.3736328722508921\n",
      "137 Train Loss 0.3496235 Test MSE 0.2597575064173868 Test RE 0.3682306462871244\n",
      "138 Train Loss 0.33679557 Test MSE 0.23615582136416619 Test RE 0.35110353712953035\n",
      "139 Train Loss 0.3156527 Test MSE 0.2368544053175406 Test RE 0.35162246182342877\n",
      "140 Train Loss 0.3052007 Test MSE 0.21443729472415643 Test RE 0.334569260733121\n",
      "141 Train Loss 0.29634908 Test MSE 0.20476792353495044 Test RE 0.32693908290378526\n",
      "142 Train Loss 0.2883666 Test MSE 0.19915697689503167 Test RE 0.32242866086706035\n",
      "143 Train Loss 0.28027025 Test MSE 0.20465535579755312 Test RE 0.32684920590666006\n",
      "144 Train Loss 0.26798135 Test MSE 0.20115858720663396 Test RE 0.3240448810587358\n",
      "145 Train Loss 0.26234 Test MSE 0.1954690505324322 Test RE 0.3194293947696128\n",
      "146 Train Loss 0.25685656 Test MSE 0.18749433824277226 Test RE 0.3128455312748251\n",
      "147 Train Loss 0.24479637 Test MSE 0.1701269130081075 Test RE 0.2980042019103614\n",
      "148 Train Loss 0.2386834 Test MSE 0.16270038842107326 Test RE 0.2914272591177511\n",
      "149 Train Loss 0.2322657 Test MSE 0.14854527293715056 Test RE 0.27846158764488443\n",
      "150 Train Loss 0.22637346 Test MSE 0.14515458220325206 Test RE 0.27526516331186196\n",
      "151 Train Loss 0.21810189 Test MSE 0.14055061270946467 Test RE 0.27086459926652856\n",
      "152 Train Loss 0.20456177 Test MSE 0.11834426036935751 Test RE 0.24854754440472093\n",
      "153 Train Loss 0.1948026 Test MSE 0.10957676518820175 Test RE 0.2391636179776212\n",
      "154 Train Loss 0.18646905 Test MSE 0.11076833088642363 Test RE 0.24046046504570692\n",
      "155 Train Loss 0.18014981 Test MSE 0.10239132006144479 Test RE 0.23118914984379899\n",
      "156 Train Loss 0.17343102 Test MSE 0.09464563573443038 Test RE 0.22227272469212855\n",
      "157 Train Loss 0.17021793 Test MSE 0.09395595203988008 Test RE 0.2214613921582008\n",
      "158 Train Loss 0.16577859 Test MSE 0.08822688491950735 Test RE 0.2146032771577095\n",
      "159 Train Loss 0.15926734 Test MSE 0.08496362081251561 Test RE 0.21059709826358358\n",
      "160 Train Loss 0.15498398 Test MSE 0.07905490920250051 Test RE 0.20314226899774906\n",
      "161 Train Loss 0.15135981 Test MSE 0.07657631359126524 Test RE 0.19993236560949607\n",
      "162 Train Loss 0.14625773 Test MSE 0.0708780934739467 Test RE 0.19234986704013773\n",
      "163 Train Loss 0.13915208 Test MSE 0.06595594880769642 Test RE 0.185550813619086\n",
      "164 Train Loss 0.13222575 Test MSE 0.06175518054922835 Test RE 0.1795446938464588\n",
      "165 Train Loss 0.12579237 Test MSE 0.06464856895282958 Test RE 0.1837026134407754\n",
      "166 Train Loss 0.12377394 Test MSE 0.06314539990496304 Test RE 0.1815543821617783\n",
      "167 Train Loss 0.121362425 Test MSE 0.05906815486342707 Test RE 0.17559517544853048\n",
      "168 Train Loss 0.11823539 Test MSE 0.05717167294134982 Test RE 0.17275329005936818\n",
      "169 Train Loss 0.114646226 Test MSE 0.05476200284138998 Test RE 0.1690734982529752\n",
      "170 Train Loss 0.111834526 Test MSE 0.049096242292733745 Test RE 0.16008845144884482\n",
      "171 Train Loss 0.10999883 Test MSE 0.04915224478772409 Test RE 0.1601797292851606\n",
      "172 Train Loss 0.10705463 Test MSE 0.04732878033451686 Test RE 0.15718045199046451\n",
      "173 Train Loss 0.10496289 Test MSE 0.046614188603507314 Test RE 0.155989347488969\n",
      "174 Train Loss 0.10385618 Test MSE 0.046228658490625685 Test RE 0.15534294071991323\n",
      "175 Train Loss 0.102649145 Test MSE 0.04477121722630566 Test RE 0.152874597956764\n",
      "176 Train Loss 0.10156878 Test MSE 0.04312820943946565 Test RE 0.15004329430414706\n",
      "177 Train Loss 0.09969336 Test MSE 0.0383830060392115 Test RE 0.14154853180746022\n",
      "178 Train Loss 0.09746885 Test MSE 0.03583999252012677 Test RE 0.13677912843983436\n",
      "179 Train Loss 0.09575208 Test MSE 0.03419283557398951 Test RE 0.1335990702608683\n",
      "180 Train Loss 0.09299517 Test MSE 0.032693060550870755 Test RE 0.1306362383022543\n",
      "181 Train Loss 0.09110843 Test MSE 0.03093257897463128 Test RE 0.12707026689311451\n",
      "182 Train Loss 0.08970497 Test MSE 0.02755793212416836 Test RE 0.11993865931782467\n",
      "183 Train Loss 0.08859079 Test MSE 0.02643456992210553 Test RE 0.11746865641794058\n",
      "184 Train Loss 0.08706656 Test MSE 0.02478296384255171 Test RE 0.11373981002319151\n",
      "185 Train Loss 0.085760094 Test MSE 0.024346032373066432 Test RE 0.11273271707966952\n",
      "186 Train Loss 0.0840651 Test MSE 0.02197584563291475 Test RE 0.10710473592939723\n",
      "187 Train Loss 0.082535416 Test MSE 0.022151675063262488 Test RE 0.10753235645835403\n",
      "188 Train Loss 0.08088517 Test MSE 0.02436634269170932 Test RE 0.11277973008050073\n",
      "189 Train Loss 0.07962212 Test MSE 0.02326521342848853 Test RE 0.11020197995594157\n",
      "190 Train Loss 0.078126214 Test MSE 0.022565655777117763 Test RE 0.10853251236606823\n",
      "191 Train Loss 0.07668365 Test MSE 0.021047582093145858 Test RE 0.10481826890008461\n",
      "192 Train Loss 0.07360432 Test MSE 0.019807888756636995 Test RE 0.10168455000548643\n",
      "193 Train Loss 0.07070562 Test MSE 0.01719187628909862 Test RE 0.09473217652357183\n",
      "194 Train Loss 0.06925053 Test MSE 0.016735225089488766 Test RE 0.0934655693620647\n",
      "195 Train Loss 0.06811364 Test MSE 0.016974235072794486 Test RE 0.09413063383821549\n",
      "196 Train Loss 0.067178085 Test MSE 0.016752150886432227 Test RE 0.09351282237011878\n",
      "197 Train Loss 0.0653533 Test MSE 0.01694640455958909 Test RE 0.0940534351156354\n",
      "198 Train Loss 0.0639718 Test MSE 0.01644682141041688 Test RE 0.09265670780962416\n",
      "199 Train Loss 0.063185304 Test MSE 0.01682892478151485 Test RE 0.09372685867070936\n",
      "200 Train Loss 0.06195289 Test MSE 0.01765377862964874 Test RE 0.09599634881117461\n",
      "201 Train Loss 0.05969999 Test MSE 0.01809049035329496 Test RE 0.09717645373939744\n",
      "202 Train Loss 0.058841918 Test MSE 0.01683090163844257 Test RE 0.09373236345343783\n",
      "203 Train Loss 0.05792491 Test MSE 0.016494521039913296 Test RE 0.09279097359348071\n",
      "204 Train Loss 0.05703569 Test MSE 0.016072397613858896 Test RE 0.09159593723202045\n",
      "205 Train Loss 0.056026038 Test MSE 0.014909679628082147 Test RE 0.08822060519417045\n",
      "206 Train Loss 0.05519217 Test MSE 0.013533096007744879 Test RE 0.08404936919142522\n",
      "207 Train Loss 0.05479075 Test MSE 0.013379101418591877 Test RE 0.08356979750140421\n",
      "208 Train Loss 0.054279383 Test MSE 0.013235588872734337 Test RE 0.08312037830600669\n",
      "209 Train Loss 0.053419862 Test MSE 0.013486923847539838 Test RE 0.08390586704417637\n",
      "210 Train Loss 0.05259683 Test MSE 0.012794575700313964 Test RE 0.08172385056223361\n",
      "211 Train Loss 0.051949512 Test MSE 0.012592774180452704 Test RE 0.08107679726016337\n",
      "212 Train Loss 0.051201433 Test MSE 0.01275639752603787 Test RE 0.08160183016544256\n",
      "213 Train Loss 0.050694376 Test MSE 0.012929014592528485 Test RE 0.08215208490700335\n",
      "214 Train Loss 0.04986268 Test MSE 0.012837585380577792 Test RE 0.08186109496260145\n",
      "215 Train Loss 0.048839226 Test MSE 0.013077303060107045 Test RE 0.08262186065187553\n",
      "216 Train Loss 0.04789115 Test MSE 0.010675204745063855 Test RE 0.07464899815704389\n",
      "217 Train Loss 0.047039255 Test MSE 0.009138469451741075 Test RE 0.06906732072719576\n",
      "218 Train Loss 0.046028204 Test MSE 0.00825568757093086 Test RE 0.06564663984920055\n",
      "219 Train Loss 0.04459374 Test MSE 0.0068912367773483205 Test RE 0.05997696189327789\n",
      "220 Train Loss 0.04383485 Test MSE 0.005957043326752353 Test RE 0.055763658168071835\n",
      "221 Train Loss 0.043203183 Test MSE 0.005685887500667748 Test RE 0.0544797377326488\n",
      "222 Train Loss 0.04238491 Test MSE 0.005312547169598526 Test RE 0.052660778662362726\n",
      "223 Train Loss 0.04160191 Test MSE 0.005151254923461675 Test RE 0.051855210098492664\n",
      "224 Train Loss 0.04082064 Test MSE 0.004959649821154233 Test RE 0.05088167315348793\n",
      "225 Train Loss 0.04023222 Test MSE 0.004918974074562457 Test RE 0.05067259478284314\n",
      "226 Train Loss 0.03967254 Test MSE 0.004412731636467979 Test RE 0.04799429703896452\n",
      "227 Train Loss 0.039139017 Test MSE 0.004359092658673389 Test RE 0.047701707738985875\n",
      "228 Train Loss 0.03801098 Test MSE 0.004590140536790964 Test RE 0.04894956854709319\n",
      "229 Train Loss 0.037214857 Test MSE 0.0045231285286743556 Test RE 0.04859094454695191\n",
      "230 Train Loss 0.03645186 Test MSE 0.0038318922909710263 Test RE 0.04472419408654159\n",
      "231 Train Loss 0.035591193 Test MSE 0.0031482331251188387 Test RE 0.04053865345955473\n",
      "232 Train Loss 0.035141625 Test MSE 0.003149103051813347 Test RE 0.040544253937595566\n",
      "233 Train Loss 0.03476933 Test MSE 0.003091509911329639 Test RE 0.040171791364577714\n",
      "234 Train Loss 0.034420367 Test MSE 0.0029030047900618834 Test RE 0.03892779039120892\n",
      "235 Train Loss 0.03387274 Test MSE 0.0027780359820579123 Test RE 0.03808069010781942\n",
      "236 Train Loss 0.03328927 Test MSE 0.002495746910039685 Test RE 0.03609409424137859\n",
      "237 Train Loss 0.032375015 Test MSE 0.0022702793458146847 Test RE 0.03442512500508671\n",
      "238 Train Loss 0.031859998 Test MSE 0.002176170178465538 Test RE 0.03370406659110173\n",
      "239 Train Loss 0.031353816 Test MSE 0.0022035280244419183 Test RE 0.03391526118882803\n",
      "240 Train Loss 0.03073562 Test MSE 0.0019225276465795597 Test RE 0.0316790517820678\n",
      "241 Train Loss 0.029842984 Test MSE 0.001723963886924129 Test RE 0.029998528976490028\n",
      "242 Train Loss 0.02945769 Test MSE 0.0016799810738119872 Test RE 0.029613386266783767\n",
      "243 Train Loss 0.029056361 Test MSE 0.0017235637870642515 Test RE 0.029995047724998752\n",
      "244 Train Loss 0.028713422 Test MSE 0.001712363134684954 Test RE 0.02989742682312447\n",
      "245 Train Loss 0.028529765 Test MSE 0.0016707294391417825 Test RE 0.02953173342320317\n",
      "246 Train Loss 0.028115645 Test MSE 0.0015660592297430515 Test RE 0.028591699360365565\n",
      "247 Train Loss 0.027664097 Test MSE 0.0014834865977523886 Test RE 0.027827724202242395\n",
      "248 Train Loss 0.027002718 Test MSE 0.0015843721457081562 Test RE 0.028758383855471602\n",
      "249 Train Loss 0.026436247 Test MSE 0.00154785155402706 Test RE 0.028425003750512705\n",
      "250 Train Loss 0.026067134 Test MSE 0.0015027237115310464 Test RE 0.02800757105836361\n",
      "251 Train Loss 0.0256102 Test MSE 0.001613212642958826 Test RE 0.02901894941071829\n",
      "252 Train Loss 0.02503789 Test MSE 0.0015406130327266397 Test RE 0.02835846115739653\n",
      "253 Train Loss 0.024350118 Test MSE 0.0014216136623512584 Test RE 0.02724122737649546\n",
      "254 Train Loss 0.023738323 Test MSE 0.0015452111416269895 Test RE 0.028400748915728826\n",
      "255 Train Loss 0.02350607 Test MSE 0.0015283178920162872 Test RE 0.028245074566735567\n",
      "256 Train Loss 0.023140999 Test MSE 0.001426801070824616 Test RE 0.027290883166355792\n",
      "257 Train Loss 0.02286191 Test MSE 0.0013285573899000423 Test RE 0.026334558186138668\n",
      "258 Train Loss 0.022706982 Test MSE 0.0012451040619938767 Test RE 0.0254940422889299\n",
      "259 Train Loss 0.022563027 Test MSE 0.0012220356745799917 Test RE 0.02525677056393125\n",
      "260 Train Loss 0.022384979 Test MSE 0.001174937746755239 Test RE 0.02476528356769399\n",
      "261 Train Loss 0.021979865 Test MSE 0.0011883506317617546 Test RE 0.024906240509687642\n",
      "262 Train Loss 0.021605032 Test MSE 0.0012298442732112784 Test RE 0.025337335288935062\n",
      "263 Train Loss 0.021302612 Test MSE 0.0011926892329157041 Test RE 0.024951664727054755\n",
      "264 Train Loss 0.020953218 Test MSE 0.0012956189185729763 Test RE 0.026006057434898488\n",
      "265 Train Loss 0.020700602 Test MSE 0.0011667798816650827 Test RE 0.024679158258474544\n",
      "266 Train Loss 0.020465238 Test MSE 0.0010729351272369023 Test RE 0.023665877322648823\n",
      "267 Train Loss 0.020202491 Test MSE 0.0009732688234330862 Test RE 0.022539915461873228\n",
      "268 Train Loss 0.01995124 Test MSE 0.0008667736145472446 Test RE 0.02127103969924459\n",
      "269 Train Loss 0.019710049 Test MSE 0.0009028570963727086 Test RE 0.021709278238740325\n",
      "270 Train Loss 0.019562688 Test MSE 0.0008948653421919912 Test RE 0.021612983457867125\n",
      "271 Train Loss 0.019427089 Test MSE 0.0009042615400179721 Test RE 0.02172615666290955\n",
      "272 Train Loss 0.019171057 Test MSE 0.0008982383034944311 Test RE 0.02165367739717127\n",
      "273 Train Loss 0.018961057 Test MSE 0.0008422135500463808 Test RE 0.020967516288158503\n",
      "274 Train Loss 0.018797072 Test MSE 0.0008393125686345614 Test RE 0.020931374122019192\n",
      "275 Train Loss 0.018667245 Test MSE 0.0008794284754092539 Test RE 0.02142575520913832\n",
      "276 Train Loss 0.018528473 Test MSE 0.0008706929367474468 Test RE 0.021319076480175905\n",
      "277 Train Loss 0.01836591 Test MSE 0.0008600592384337625 Test RE 0.021188492524512444\n",
      "278 Train Loss 0.018238476 Test MSE 0.0008966009270485576 Test RE 0.02163393241771859\n",
      "279 Train Loss 0.017981613 Test MSE 0.0008384878981587464 Test RE 0.02092108848525246\n",
      "280 Train Loss 0.017840628 Test MSE 0.0008498299688429466 Test RE 0.02106211103750994\n",
      "281 Train Loss 0.017693324 Test MSE 0.0007968776321187075 Test RE 0.020395375014416236\n",
      "282 Train Loss 0.017554251 Test MSE 0.0007417563203772502 Test RE 0.019677345206637026\n",
      "283 Train Loss 0.017349757 Test MSE 0.0006960526588184909 Test RE 0.019061493497031044\n",
      "284 Train Loss 0.017148806 Test MSE 0.0006424008706475113 Test RE 0.018312133143161956\n",
      "285 Train Loss 0.01686357 Test MSE 0.0005765075508250774 Test RE 0.01734755914365616\n",
      "286 Train Loss 0.01669979 Test MSE 0.0005776125643549501 Test RE 0.0173641765415611\n",
      "287 Train Loss 0.016542414 Test MSE 0.0005593031008269901 Test RE 0.017086750992472494\n",
      "288 Train Loss 0.016389897 Test MSE 0.000543873046175352 Test RE 0.0168494079348004\n",
      "289 Train Loss 0.016310573 Test MSE 0.0005632745567022332 Test RE 0.017147307818321165\n",
      "290 Train Loss 0.016182907 Test MSE 0.0005822562284944325 Test RE 0.017433835683191432\n",
      "291 Train Loss 0.016004946 Test MSE 0.0005514114468163762 Test RE 0.01696577744228176\n",
      "292 Train Loss 0.015860958 Test MSE 0.0005556990419722683 Test RE 0.017031609886863672\n",
      "293 Train Loss 0.015654977 Test MSE 0.0005209436893557608 Test RE 0.016490402936916695\n",
      "294 Train Loss 0.0154297445 Test MSE 0.0004957888008881185 Test RE 0.016087339724899088\n",
      "295 Train Loss 0.015264912 Test MSE 0.00045751466497688157 Test RE 0.015453910279859432\n",
      "296 Train Loss 0.015055535 Test MSE 0.00046924787811389513 Test RE 0.01565081780083665\n",
      "297 Train Loss 0.014898927 Test MSE 0.00046296246518873235 Test RE 0.015545645783905675\n",
      "298 Train Loss 0.014742029 Test MSE 0.0004327009290463733 Test RE 0.01502898983556971\n",
      "299 Train Loss 0.014527775 Test MSE 0.00040011223678711427 Test RE 0.014451961428298283\n",
      "Training time: 252.08\n",
      "KG_atanh_high\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 62894.723 Test MSE 4.301660299586272 Test RE 1.498490288066388\n",
      "1 Train Loss 46201.004 Test MSE 11.584899732142851 Test RE 2.459132992891202\n",
      "2 Train Loss 32335.104 Test MSE 13.535918712988872 Test RE 2.658151597982604\n",
      "3 Train Loss 18914.254 Test MSE 19.210233567177465 Test RE 3.166665565293471\n",
      "4 Train Loss 8041.535 Test MSE 10.93816302003874 Test RE 2.3895057105423234\n",
      "5 Train Loss 3279.4756 Test MSE 15.325133036846612 Test RE 2.8283816016914267\n",
      "6 Train Loss 2258.5017 Test MSE 15.53470425692128 Test RE 2.847654996085632\n",
      "7 Train Loss 1646.104 Test MSE 15.063093201388325 Test RE 2.8040965205803743\n",
      "8 Train Loss 979.6163 Test MSE 14.384084918897443 Test RE 2.7401667745706377\n",
      "9 Train Loss 632.9924 Test MSE 14.393206557823166 Test RE 2.7410354725346773\n",
      "10 Train Loss 372.47943 Test MSE 14.966062867424649 Test RE 2.7950505033949056\n",
      "11 Train Loss 247.31027 Test MSE 14.209303924922114 Test RE 2.72346801171647\n",
      "12 Train Loss 191.68466 Test MSE 13.768636508304155 Test RE 2.6809045034980548\n",
      "13 Train Loss 150.38426 Test MSE 13.606881554762309 Test RE 2.665110246865517\n",
      "14 Train Loss 123.49312 Test MSE 13.575976356489193 Test RE 2.6620819048231104\n",
      "15 Train Loss 97.38146 Test MSE 13.614690335752472 Test RE 2.66587487016252\n",
      "16 Train Loss 80.89676 Test MSE 13.679005216950753 Test RE 2.672164158138393\n",
      "17 Train Loss 67.33138 Test MSE 14.031406146153904 Test RE 2.7063656631869373\n",
      "18 Train Loss 57.565376 Test MSE 14.053481261862862 Test RE 2.708493741263713\n",
      "19 Train Loss 48.134468 Test MSE 14.307331974346127 Test RE 2.732846281812417\n",
      "20 Train Loss 40.993458 Test MSE 14.30590016661911 Test RE 2.7327095334539115\n",
      "21 Train Loss 35.47069 Test MSE 14.212977524022792 Test RE 2.723820044550712\n",
      "22 Train Loss 31.90422 Test MSE 14.172125636466525 Test RE 2.719902735094735\n",
      "23 Train Loss 28.514282 Test MSE 14.293429531753194 Test RE 2.7315182049698548\n",
      "24 Train Loss 26.381577 Test MSE 14.27119097933531 Test RE 2.729392450031056\n",
      "25 Train Loss 23.799715 Test MSE 14.339068947075207 Test RE 2.735875645473195\n",
      "26 Train Loss 22.123402 Test MSE 14.37740694968134 Test RE 2.7395306244848765\n",
      "27 Train Loss 20.79242 Test MSE 14.36878087761807 Test RE 2.7387086774436553\n",
      "28 Train Loss 20.070532 Test MSE 14.369540699022846 Test RE 2.7387810879697505\n",
      "29 Train Loss 19.170933 Test MSE 14.379354563608418 Test RE 2.7397161714105422\n",
      "30 Train Loss 18.34487 Test MSE 14.381411882409992 Test RE 2.7399121561458504\n",
      "31 Train Loss 17.781458 Test MSE 14.407293166456835 Test RE 2.742376468061552\n",
      "32 Train Loss 17.289537 Test MSE 14.398465860922737 Test RE 2.7415362163973187\n",
      "33 Train Loss 16.860113 Test MSE 14.354149605314062 Test RE 2.7373139523565926\n",
      "34 Train Loss 16.560581 Test MSE 14.311391766692019 Test RE 2.7332339851765224\n",
      "35 Train Loss 16.38638 Test MSE 14.269142717737353 Test RE 2.729196576037181\n",
      "36 Train Loss 16.259983 Test MSE 14.25552388934902 Test RE 2.727893858228365\n",
      "37 Train Loss 15.993011 Test MSE 14.150664205486843 Test RE 2.717842524713244\n",
      "38 Train Loss 15.884844 Test MSE 14.146719697943636 Test RE 2.7174636980596456\n",
      "39 Train Loss 15.790841 Test MSE 14.117129497202047 Test RE 2.714620198296526\n",
      "40 Train Loss 15.663131 Test MSE 14.14048413059588 Test RE 2.7168647325073105\n",
      "41 Train Loss 15.586544 Test MSE 14.114765734548605 Test RE 2.714392921693676\n",
      "42 Train Loss 15.4768505 Test MSE 14.086947824882209 Test RE 2.7117167888025997\n",
      "43 Train Loss 15.409843 Test MSE 14.082147093783867 Test RE 2.7112546825820716\n",
      "44 Train Loss 15.280674 Test MSE 14.046307283839207 Test RE 2.7078023412263894\n",
      "45 Train Loss 15.2060375 Test MSE 14.015371681393555 Test RE 2.7048188642063287\n",
      "46 Train Loss 15.12237 Test MSE 13.960555965133096 Test RE 2.6995242547288605\n",
      "47 Train Loss 15.029999 Test MSE 13.949264584083645 Test RE 2.6984323382264597\n",
      "48 Train Loss 14.908023 Test MSE 13.916604780941075 Test RE 2.695271529483752\n",
      "49 Train Loss 14.752188 Test MSE 13.831616482156658 Test RE 2.687028953679177\n",
      "50 Train Loss 14.617331 Test MSE 13.789413659724048 Test RE 2.682926510576345\n",
      "51 Train Loss 14.49633 Test MSE 13.75961196222713 Test RE 2.6800257704463566\n",
      "52 Train Loss 14.4144 Test MSE 13.729773098003559 Test RE 2.677118263781529\n",
      "53 Train Loss 14.303048 Test MSE 13.69799270366789 Test RE 2.674018097293151\n",
      "54 Train Loss 14.203531 Test MSE 13.680143613315664 Test RE 2.6722753474620453\n",
      "55 Train Loss 14.0024805 Test MSE 13.56934108992073 Test RE 2.6614312782528415\n",
      "56 Train Loss 13.866258 Test MSE 13.477887548461178 Test RE 2.6524474665355613\n",
      "57 Train Loss 13.743004 Test MSE 13.402226488384498 Test RE 2.6449919424495985\n",
      "58 Train Loss 13.653864 Test MSE 13.35421437707882 Test RE 2.6402499846304552\n",
      "59 Train Loss 13.517726 Test MSE 13.258603748237583 Test RE 2.6307814598226416\n",
      "60 Train Loss 13.3500185 Test MSE 13.103054881166358 Test RE 2.6153038727623525\n",
      "61 Train Loss 13.241071 Test MSE 13.020230909090575 Test RE 2.607025145437997\n",
      "62 Train Loss 13.11161 Test MSE 12.910342591593484 Test RE 2.596000431819733\n",
      "63 Train Loss 12.963694 Test MSE 12.749714267859254 Test RE 2.579800382884884\n",
      "64 Train Loss 12.680941 Test MSE 12.405169342332934 Test RE 2.5447037246848776\n",
      "65 Train Loss 12.571549 Test MSE 12.332682461248794 Test RE 2.537258123550614\n",
      "66 Train Loss 12.435365 Test MSE 12.294072321466205 Test RE 2.5332832914048957\n",
      "67 Train Loss 12.258077 Test MSE 12.110746261086032 Test RE 2.51432451274361\n",
      "68 Train Loss 12.000206 Test MSE 11.724044173749629 Test RE 2.4738570460785008\n",
      "69 Train Loss 11.842178 Test MSE 11.443534860640568 Test RE 2.4440831412364497\n",
      "70 Train Loss 11.630803 Test MSE 11.208469840596369 Test RE 2.4188505756702456\n",
      "71 Train Loss 11.305408 Test MSE 10.70056990930062 Test RE 2.363411428362719\n",
      "72 Train Loss 10.893706 Test MSE 10.169247282138851 Test RE 2.3039883614192527\n",
      "73 Train Loss 10.429379 Test MSE 9.702225235304667 Test RE 2.2504613213727263\n",
      "74 Train Loss 9.862261 Test MSE 8.917180959060643 Test RE 2.1574943491403773\n",
      "75 Train Loss 9.302401 Test MSE 8.409411141344282 Test RE 2.0951671194327046\n",
      "76 Train Loss 8.678775 Test MSE 7.826919950232767 Test RE 2.0213025456086635\n",
      "77 Train Loss 7.8987646 Test MSE 7.342037123376863 Test RE 1.9576910931759444\n",
      "78 Train Loss 7.3822994 Test MSE 7.169930485952274 Test RE 1.934609648694667\n",
      "79 Train Loss 6.803285 Test MSE 6.912739840227187 Test RE 1.8995948486711127\n",
      "80 Train Loss 6.246928 Test MSE 6.348424947526347 Test RE 1.8204085713724465\n",
      "81 Train Loss 5.8336077 Test MSE 5.926618151887926 Test RE 1.758892715678141\n",
      "82 Train Loss 5.29745 Test MSE 5.127344085460418 Test RE 1.635995513739264\n",
      "83 Train Loss 4.8311367 Test MSE 5.077184446607927 Test RE 1.627973560622169\n",
      "84 Train Loss 4.5571656 Test MSE 4.697827116329135 Test RE 1.565973440821948\n",
      "85 Train Loss 4.221614 Test MSE 4.522871650352066 Test RE 1.536536950774219\n",
      "86 Train Loss 3.9307423 Test MSE 4.391082796864061 Test RE 1.5139854099180097\n",
      "87 Train Loss 3.6880705 Test MSE 3.98912382457315 Test RE 1.4430275928097318\n",
      "88 Train Loss 3.3607383 Test MSE 3.7474965975336154 Test RE 1.3986417903942443\n",
      "89 Train Loss 3.056363 Test MSE 3.458621725200573 Test RE 1.3436538766325363\n",
      "90 Train Loss 2.7803006 Test MSE 3.13216613537345 Test RE 1.2786693988329927\n",
      "91 Train Loss 2.5742202 Test MSE 2.9615913135356857 Test RE 1.2433644349398274\n",
      "92 Train Loss 2.4712327 Test MSE 2.69221375892838 Test RE 1.1854702145522018\n",
      "93 Train Loss 2.2861927 Test MSE 2.536080573307901 Test RE 1.1505815364277725\n",
      "94 Train Loss 2.1071208 Test MSE 2.2508287812606333 Test RE 1.083944651574504\n",
      "95 Train Loss 1.9746944 Test MSE 2.05834066166425 Test RE 1.0365601380837448\n",
      "96 Train Loss 1.7712498 Test MSE 1.5972673011758913 Test RE 0.9131133185531639\n",
      "97 Train Loss 1.615946 Test MSE 1.49436083857705 Test RE 0.8832092641807462\n",
      "98 Train Loss 1.486824 Test MSE 1.3910424421447818 Test RE 0.8521304161159108\n",
      "99 Train Loss 1.3636394 Test MSE 1.1497982538109137 Test RE 0.7747234455449615\n",
      "100 Train Loss 1.3076239 Test MSE 1.0960090931163056 Test RE 0.7563850833594834\n",
      "101 Train Loss 1.2597005 Test MSE 1.0451624607560686 Test RE 0.7386314208011322\n",
      "102 Train Loss 1.213775 Test MSE 0.9916593642568988 Test RE 0.719477365166173\n",
      "103 Train Loss 1.1603067 Test MSE 0.9178275008864689 Test RE 0.6921757979801711\n",
      "104 Train Loss 1.0966833 Test MSE 0.8838095983205737 Test RE 0.6792274575045791\n",
      "105 Train Loss 1.0672821 Test MSE 0.8677083749081527 Test RE 0.6730119435794115\n",
      "106 Train Loss 1.01331 Test MSE 0.8630391630863946 Test RE 0.6711987340646307\n",
      "107 Train Loss 0.9756433 Test MSE 0.8036811194730158 Test RE 0.647705760824986\n",
      "108 Train Loss 0.92859983 Test MSE 0.8042270676408022 Test RE 0.6479257197937338\n",
      "109 Train Loss 0.89441156 Test MSE 0.7742374698678113 Test RE 0.635730385656419\n",
      "110 Train Loss 0.8658507 Test MSE 0.6956929107097513 Test RE 0.6026215605865387\n",
      "111 Train Loss 0.8247993 Test MSE 0.6504067064019048 Test RE 0.5826776798132272\n",
      "112 Train Loss 0.7864551 Test MSE 0.6084003168926534 Test RE 0.5635475845720413\n",
      "113 Train Loss 0.76161104 Test MSE 0.5426720539483647 Test RE 0.5322364399449508\n",
      "114 Train Loss 0.7306919 Test MSE 0.4803334767932827 Test RE 0.5007342578769025\n",
      "115 Train Loss 0.68682307 Test MSE 0.4374115969096867 Test RE 0.47783837349489616\n",
      "116 Train Loss 0.6480801 Test MSE 0.4087809301499099 Test RE 0.4619353418962133\n",
      "117 Train Loss 0.613429 Test MSE 0.38348583688532567 Test RE 0.4474150012912305\n",
      "118 Train Loss 0.5688697 Test MSE 0.350248269182222 Test RE 0.42758639252272723\n",
      "119 Train Loss 0.5290792 Test MSE 0.2973199798760963 Test RE 0.3939561859918988\n",
      "120 Train Loss 0.4963519 Test MSE 0.2758364302710633 Test RE 0.3794562310589217\n",
      "121 Train Loss 0.46351284 Test MSE 0.2533571329796424 Test RE 0.3636657865517661\n",
      "122 Train Loss 0.43214086 Test MSE 0.2181531603479783 Test RE 0.3374555936260552\n",
      "123 Train Loss 0.40439767 Test MSE 0.19692878901318925 Test RE 0.3206199056895612\n",
      "124 Train Loss 0.38483104 Test MSE 0.18980040915991384 Test RE 0.3147635603501213\n",
      "125 Train Loss 0.349343 Test MSE 0.18469418712644478 Test RE 0.3105006334070891\n",
      "126 Train Loss 0.32728305 Test MSE 0.17139759365566906 Test RE 0.2991150306563997\n",
      "127 Train Loss 0.30880392 Test MSE 0.1497259696730968 Test RE 0.2795660588571394\n",
      "128 Train Loss 0.29117262 Test MSE 0.13031335022081028 Test RE 0.2608136590100443\n",
      "129 Train Loss 0.2742417 Test MSE 0.1047915830596537 Test RE 0.23388322705803302\n",
      "130 Train Loss 0.26494578 Test MSE 0.09514274312280778 Test RE 0.2228556818798633\n",
      "131 Train Loss 0.25095552 Test MSE 0.08983452188845593 Test RE 0.2165496605435224\n",
      "132 Train Loss 0.23372446 Test MSE 0.08283278781613816 Test RE 0.2079395098808142\n",
      "133 Train Loss 0.22439334 Test MSE 0.07447945287918334 Test RE 0.19717602890340555\n",
      "134 Train Loss 0.21663266 Test MSE 0.06567235354195348 Test RE 0.18515147117869335\n",
      "135 Train Loss 0.21301223 Test MSE 0.06698251740585201 Test RE 0.18698923708670592\n",
      "136 Train Loss 0.20909894 Test MSE 0.06529620057526231 Test RE 0.18462046166532994\n",
      "137 Train Loss 0.20395252 Test MSE 0.05702621551528311 Test RE 0.17253338874331273\n",
      "138 Train Loss 0.19745384 Test MSE 0.047474628761413895 Test RE 0.15742244943473951\n",
      "139 Train Loss 0.19280119 Test MSE 0.040467185272984055 Test RE 0.14534074291195012\n",
      "140 Train Loss 0.1857064 Test MSE 0.037516714547064026 Test RE 0.1399420644251693\n",
      "141 Train Loss 0.17572166 Test MSE 0.028197163965989855 Test RE 0.12132172922192731\n",
      "142 Train Loss 0.16913146 Test MSE 0.024031365579065093 Test RE 0.11200182570222342\n",
      "143 Train Loss 0.16037354 Test MSE 0.021103581860806127 Test RE 0.10495761743731716\n",
      "144 Train Loss 0.15214276 Test MSE 0.021766054065959238 Test RE 0.10659227432210062\n",
      "145 Train Loss 0.14890198 Test MSE 0.020129490411164713 Test RE 0.10250670347334542\n",
      "146 Train Loss 0.1456071 Test MSE 0.021033888333951384 Test RE 0.10478416546560819\n",
      "147 Train Loss 0.13808922 Test MSE 0.018940097592781202 Test RE 0.09943218501905003\n",
      "148 Train Loss 0.13304007 Test MSE 0.017069057703999305 Test RE 0.0943931871632052\n",
      "149 Train Loss 0.13121188 Test MSE 0.01607673432223351 Test RE 0.09160829376046428\n",
      "150 Train Loss 0.12786856 Test MSE 0.016436899508103314 Test RE 0.09262875500725441\n",
      "151 Train Loss 0.123016775 Test MSE 0.018628243943605415 Test RE 0.09861019898548627\n",
      "152 Train Loss 0.11908105 Test MSE 0.018238489777186312 Test RE 0.09757314734667744\n",
      "153 Train Loss 0.11603814 Test MSE 0.0195009654761989 Test RE 0.10089367322090209\n",
      "154 Train Loss 0.11213619 Test MSE 0.02043309001911536 Test RE 0.10327683045460513\n",
      "155 Train Loss 0.108827844 Test MSE 0.018957810849609694 Test RE 0.09947866989639985\n",
      "156 Train Loss 0.10689783 Test MSE 0.019216359604050298 Test RE 0.10015472331783874\n",
      "157 Train Loss 0.10393267 Test MSE 0.019386872181621894 Test RE 0.1005980935441174\n",
      "158 Train Loss 0.10084467 Test MSE 0.016944788852840714 Test RE 0.0940489513801157\n",
      "159 Train Loss 0.09847211 Test MSE 0.015057465571643657 Test RE 0.08865675194560062\n",
      "160 Train Loss 0.09686661 Test MSE 0.014018160388269248 Test RE 0.08554239181451512\n",
      "161 Train Loss 0.094944015 Test MSE 0.013266740779239072 Test RE 0.08321813883861139\n",
      "162 Train Loss 0.091982126 Test MSE 0.012481646687079245 Test RE 0.0807182651904601\n",
      "163 Train Loss 0.08953254 Test MSE 0.012479061839321327 Test RE 0.0807099067087913\n",
      "164 Train Loss 0.087783396 Test MSE 0.011679119685951738 Test RE 0.07808020257570425\n",
      "165 Train Loss 0.08611929 Test MSE 0.011856948288419945 Test RE 0.07867238926139211\n",
      "166 Train Loss 0.08378237 Test MSE 0.011698264497365616 Test RE 0.0781441722369816\n",
      "167 Train Loss 0.0814459 Test MSE 0.011846002839034761 Test RE 0.07863606863940828\n",
      "168 Train Loss 0.079770125 Test MSE 0.011719073653329196 Test RE 0.07821364372857319\n",
      "169 Train Loss 0.07866029 Test MSE 0.011713633055312039 Test RE 0.07819548621855303\n",
      "170 Train Loss 0.07716182 Test MSE 0.01213541536008919 Test RE 0.0795908604184561\n",
      "171 Train Loss 0.075300515 Test MSE 0.011540112081909804 Test RE 0.07761414726692147\n",
      "172 Train Loss 0.07446334 Test MSE 0.011330391255382075 Test RE 0.07690566474085679\n",
      "173 Train Loss 0.07315914 Test MSE 0.011609581467125613 Test RE 0.07784740830299464\n",
      "174 Train Loss 0.07112323 Test MSE 0.010913431191592072 Test RE 0.07547733096157937\n",
      "175 Train Loss 0.06947316 Test MSE 0.010534926989932475 Test RE 0.07415691287250636\n",
      "176 Train Loss 0.06823619 Test MSE 0.009885763354371148 Test RE 0.07183580815356339\n",
      "177 Train Loss 0.06707526 Test MSE 0.00902272848936155 Test RE 0.06862854971561146\n",
      "178 Train Loss 0.06616564 Test MSE 0.0085206099119013 Test RE 0.06669161254428552\n",
      "179 Train Loss 0.06547739 Test MSE 0.008587703204717904 Test RE 0.06695367042570798\n",
      "180 Train Loss 0.06475713 Test MSE 0.00864142086598507 Test RE 0.0671627477357354\n",
      "181 Train Loss 0.06332489 Test MSE 0.00821687080805029 Test RE 0.06549212864849109\n",
      "182 Train Loss 0.061468087 Test MSE 0.007699988749721445 Test RE 0.06339878313809244\n",
      "183 Train Loss 0.059780676 Test MSE 0.007329226238218183 Test RE 0.06185359419619785\n",
      "184 Train Loss 0.058742 Test MSE 0.006866980834160161 Test RE 0.059871314660173466\n",
      "185 Train Loss 0.057441723 Test MSE 0.007297755008867368 Test RE 0.061720653641657644\n",
      "186 Train Loss 0.056251124 Test MSE 0.007354123552640407 Test RE 0.06195856317367707\n",
      "187 Train Loss 0.055260655 Test MSE 0.007602421285832308 Test RE 0.06299583589856894\n",
      "188 Train Loss 0.05412846 Test MSE 0.007807727147715186 Test RE 0.06384078092501487\n",
      "189 Train Loss 0.052854415 Test MSE 0.00793521171499081 Test RE 0.06435986672524902\n",
      "190 Train Loss 0.05149954 Test MSE 0.007104474132442967 Test RE 0.06089783393425943\n",
      "191 Train Loss 0.05085985 Test MSE 0.00700445538310664 Test RE 0.0604676462280825\n",
      "192 Train Loss 0.050129324 Test MSE 0.007089711091448373 Test RE 0.06083452842170267\n",
      "193 Train Loss 0.04921875 Test MSE 0.006882946436634163 Test RE 0.05994087409799223\n",
      "194 Train Loss 0.048041277 Test MSE 0.00664850614432333 Test RE 0.058911206086715164\n",
      "195 Train Loss 0.045764647 Test MSE 0.006126404362790484 Test RE 0.056550793873402505\n",
      "196 Train Loss 0.044523668 Test MSE 0.005706686941508021 Test RE 0.05457929243592624\n",
      "197 Train Loss 0.04347173 Test MSE 0.005534434583574758 Test RE 0.05374926206938877\n",
      "198 Train Loss 0.042660806 Test MSE 0.0055100347377314484 Test RE 0.0536306481108638\n",
      "199 Train Loss 0.04150893 Test MSE 0.005431030338033239 Test RE 0.05324477440439505\n",
      "200 Train Loss 0.0408123 Test MSE 0.005413732783428074 Test RE 0.053159915837651256\n",
      "201 Train Loss 0.03990506 Test MSE 0.005455695117759685 Test RE 0.053365541817475735\n",
      "202 Train Loss 0.038910437 Test MSE 0.005130379223301071 Test RE 0.051750030603766733\n",
      "203 Train Loss 0.038189154 Test MSE 0.0047996468612410605 Test RE 0.05005419939703244\n",
      "204 Train Loss 0.03758269 Test MSE 0.004451152678477445 Test RE 0.0482027840477587\n",
      "205 Train Loss 0.03688042 Test MSE 0.00446688088806195 Test RE 0.048287871551803814\n",
      "206 Train Loss 0.036300402 Test MSE 0.00446917981366591 Test RE 0.048300295875128296\n",
      "207 Train Loss 0.03555592 Test MSE 0.004295053841813529 Test RE 0.047350021779719136\n",
      "208 Train Loss 0.035039894 Test MSE 0.0042705329085622945 Test RE 0.047214665078959994\n",
      "209 Train Loss 0.034441877 Test MSE 0.004107146028210559 Test RE 0.04630266084515677\n",
      "210 Train Loss 0.034047518 Test MSE 0.003900461837324969 Test RE 0.04512257686539773\n",
      "211 Train Loss 0.033606756 Test MSE 0.003944798139705576 Test RE 0.04537830494268015\n",
      "212 Train Loss 0.033276305 Test MSE 0.00393061241931613 Test RE 0.04529663996480314\n",
      "213 Train Loss 0.033002324 Test MSE 0.004152456807249344 Test RE 0.046557369944181096\n",
      "214 Train Loss 0.032501828 Test MSE 0.004188759140344328 Test RE 0.04676043807077998\n",
      "215 Train Loss 0.03193746 Test MSE 0.004110516227079711 Test RE 0.046321654225837096\n",
      "216 Train Loss 0.030992206 Test MSE 0.00388544523377774 Test RE 0.04503563315138756\n",
      "217 Train Loss 0.030539768 Test MSE 0.003630083757363677 Test RE 0.043530554542206085\n",
      "218 Train Loss 0.030294295 Test MSE 0.0035604286164757967 Test RE 0.04311089294470845\n",
      "219 Train Loss 0.029993366 Test MSE 0.0034967848118075216 Test RE 0.04272384496709335\n",
      "220 Train Loss 0.029749082 Test MSE 0.0034246545710564283 Test RE 0.042280903900706046\n",
      "221 Train Loss 0.02939679 Test MSE 0.0034038284775745175 Test RE 0.042152148018263266\n",
      "222 Train Loss 0.02905924 Test MSE 0.0033546854866547482 Test RE 0.04184675456248301\n",
      "223 Train Loss 0.02875128 Test MSE 0.0032787135082173765 Test RE 0.041370199183148305\n",
      "224 Train Loss 0.028440356 Test MSE 0.0034090589661513854 Test RE 0.042184522107689346\n",
      "225 Train Loss 0.028097767 Test MSE 0.0034282614967871988 Test RE 0.042303163656100165\n",
      "226 Train Loss 0.027807692 Test MSE 0.0034042681276669332 Test RE 0.04215487018794838\n",
      "227 Train Loss 0.027542695 Test MSE 0.003408293054222105 Test RE 0.042179783051547196\n",
      "228 Train Loss 0.027075538 Test MSE 0.0033645976741801566 Test RE 0.041908531878398894\n",
      "229 Train Loss 0.026654426 Test MSE 0.003289285816631876 Test RE 0.04143684521461506\n",
      "230 Train Loss 0.026055098 Test MSE 0.0031386922633704004 Test RE 0.04047717974535292\n",
      "231 Train Loss 0.025658572 Test MSE 0.003156469916079141 Test RE 0.04059164989968012\n",
      "232 Train Loss 0.025372986 Test MSE 0.0033472518184354282 Test RE 0.04180036460877531\n",
      "233 Train Loss 0.025214296 Test MSE 0.0034590450815827835 Test RE 0.042492666812729285\n",
      "234 Train Loss 0.024959723 Test MSE 0.0035305425826881475 Test RE 0.042929576470340236\n",
      "235 Train Loss 0.024706263 Test MSE 0.0034146290275232304 Test RE 0.04221897068693376\n",
      "236 Train Loss 0.024353987 Test MSE 0.0032961857387604336 Test RE 0.04148028340144633\n",
      "237 Train Loss 0.02403515 Test MSE 0.003202402497069315 Test RE 0.04088592567020293\n",
      "238 Train Loss 0.023640443 Test MSE 0.003155810546144307 Test RE 0.04058740998734623\n",
      "239 Train Loss 0.023085564 Test MSE 0.002953398958376945 Test RE 0.0392642164873326\n",
      "240 Train Loss 0.02271355 Test MSE 0.00277066039938603 Test RE 0.038030105099049145\n",
      "241 Train Loss 0.022444349 Test MSE 0.002749317795058832 Test RE 0.037883347559314336\n",
      "242 Train Loss 0.022163002 Test MSE 0.002837369175172844 Test RE 0.038485204625860005\n",
      "243 Train Loss 0.021894475 Test MSE 0.0027885693777191076 Test RE 0.03815281650754834\n",
      "244 Train Loss 0.021511877 Test MSE 0.0028726652048493037 Test RE 0.038723837047081204\n",
      "245 Train Loss 0.021194411 Test MSE 0.002808835353636485 Test RE 0.03829120365508323\n",
      "246 Train Loss 0.020916326 Test MSE 0.0027052118475148473 Test RE 0.03757824705030414\n",
      "247 Train Loss 0.020570623 Test MSE 0.0027438581728250248 Test RE 0.03784571430539862\n",
      "248 Train Loss 0.020338805 Test MSE 0.002918214798757495 Test RE 0.03902963633122249\n",
      "249 Train Loss 0.020084245 Test MSE 0.0028624508558323524 Test RE 0.038654930476020324\n",
      "250 Train Loss 0.0199448 Test MSE 0.002747819546786158 Test RE 0.03787302383556176\n",
      "251 Train Loss 0.019639036 Test MSE 0.002617904938981409 Test RE 0.03696688131102581\n",
      "252 Train Loss 0.019272318 Test MSE 0.002673916159578101 Test RE 0.03736024966754489\n",
      "253 Train Loss 0.01902798 Test MSE 0.0025995234486293414 Test RE 0.03683687212923024\n",
      "254 Train Loss 0.01888448 Test MSE 0.0026947971854683534 Test RE 0.03750584197332718\n",
      "255 Train Loss 0.018701179 Test MSE 0.0026903522240821357 Test RE 0.03747489700589053\n",
      "256 Train Loss 0.01846456 Test MSE 0.0026622179383622045 Test RE 0.03727843567211045\n",
      "257 Train Loss 0.018130302 Test MSE 0.0025621814370820695 Test RE 0.0365713352517818\n",
      "258 Train Loss 0.017883938 Test MSE 0.002476099297058466 Test RE 0.03595173925683465\n",
      "259 Train Loss 0.017662212 Test MSE 0.0025469314774759703 Test RE 0.03646233755887432\n",
      "260 Train Loss 0.017437078 Test MSE 0.002561735235343405 Test RE 0.036568150679516506\n",
      "261 Train Loss 0.017141202 Test MSE 0.0027219115461111763 Test RE 0.037694056814662806\n",
      "262 Train Loss 0.016763963 Test MSE 0.0026129906685296005 Test RE 0.03693216832653602\n",
      "263 Train Loss 0.016564166 Test MSE 0.0025986448374419467 Test RE 0.03683064636826986\n",
      "264 Train Loss 0.016291799 Test MSE 0.0025690687470837476 Test RE 0.03662045532586074\n",
      "265 Train Loss 0.01611473 Test MSE 0.0025737550615561613 Test RE 0.03665384033731378\n",
      "266 Train Loss 0.01590071 Test MSE 0.0025853645786634905 Test RE 0.03673641513344591\n",
      "267 Train Loss 0.01573404 Test MSE 0.0025985099025706273 Test RE 0.03682969013851273\n",
      "268 Train Loss 0.0155940745 Test MSE 0.002483317248728569 Test RE 0.03600410167209521\n",
      "269 Train Loss 0.015435843 Test MSE 0.0024201644101260423 Test RE 0.035543346220088964\n",
      "270 Train Loss 0.015259448 Test MSE 0.002310313561920352 Test RE 0.03472732573363209\n",
      "271 Train Loss 0.0151226865 Test MSE 0.0023144668543863944 Test RE 0.03475852668800925\n",
      "272 Train Loss 0.014975572 Test MSE 0.0022488794665787106 Test RE 0.03426249352400438\n",
      "273 Train Loss 0.014808388 Test MSE 0.0021605519871284893 Test RE 0.033582903171395825\n",
      "274 Train Loss 0.014649439 Test MSE 0.002116926707501698 Test RE 0.03324212574232636\n",
      "275 Train Loss 0.014485997 Test MSE 0.002062356986660738 Test RE 0.03281087392238183\n",
      "276 Train Loss 0.014391955 Test MSE 0.0020157671285278337 Test RE 0.03243814839910925\n",
      "277 Train Loss 0.0142595805 Test MSE 0.0020066859313709823 Test RE 0.0323649976516952\n",
      "278 Train Loss 0.014123464 Test MSE 0.002078034701234217 Test RE 0.032935349370052366\n",
      "279 Train Loss 0.013959052 Test MSE 0.0022444334674058 Test RE 0.03422860856403807\n",
      "280 Train Loss 0.013792521 Test MSE 0.0023616115508568424 Test RE 0.03511075020496123\n",
      "281 Train Loss 0.013670814 Test MSE 0.0023720295958292404 Test RE 0.03518810900138134\n",
      "282 Train Loss 0.01353921 Test MSE 0.0023599645484235795 Test RE 0.03509850484292666\n",
      "283 Train Loss 0.013395572 Test MSE 0.0023168789418510647 Test RE 0.0347766342650335\n",
      "284 Train Loss 0.013278419 Test MSE 0.002429153913889613 Test RE 0.035609296468764554\n",
      "285 Train Loss 0.013169567 Test MSE 0.0025100562221923254 Test RE 0.0361974187140683\n",
      "286 Train Loss 0.013026353 Test MSE 0.0025583736497359643 Test RE 0.03654414989268441\n",
      "287 Train Loss 0.012837608 Test MSE 0.0026915657588804736 Test RE 0.03748334793733403\n",
      "288 Train Loss 0.012619512 Test MSE 0.0029074711306387026 Test RE 0.038957724538756365\n",
      "289 Train Loss 0.0124752065 Test MSE 0.002924277665182005 Test RE 0.03907015916957455\n",
      "290 Train Loss 0.0123053305 Test MSE 0.002946844652021391 Test RE 0.039220623893468164\n",
      "291 Train Loss 0.012211453 Test MSE 0.002902106520099776 Test RE 0.03892176725781132\n",
      "292 Train Loss 0.012093334 Test MSE 0.002991258571089865 Test RE 0.039515079034689836\n",
      "293 Train Loss 0.011991507 Test MSE 0.003004114531321535 Test RE 0.039599902798948323\n",
      "294 Train Loss 0.011918187 Test MSE 0.002938426361100229 Test RE 0.039164562784181824\n",
      "295 Train Loss 0.011781163 Test MSE 0.002929174219389414 Test RE 0.039102855985126674\n",
      "296 Train Loss 0.011635516 Test MSE 0.0028712379563724357 Test RE 0.0387142161201576\n",
      "297 Train Loss 0.011551918 Test MSE 0.0028111053072692547 Test RE 0.03830667300306796\n",
      "298 Train Loss 0.011458558 Test MSE 0.0027618345568544934 Test RE 0.03796948499485654\n",
      "299 Train Loss 0.011382552 Test MSE 0.0028041147270456974 Test RE 0.03825901335865519\n",
      "Training time: 253.00\n",
      "KG_atanh_high\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58355.73 Test MSE 4.289945558288261 Test RE 1.4964484725041405\n",
      "1 Train Loss 39765.54 Test MSE 8.156204426601468 Test RE 2.0633833799343697\n",
      "2 Train Loss 22777.756 Test MSE 11.535057571816566 Test RE 2.4538372794673733\n",
      "3 Train Loss 16763.531 Test MSE 13.429868152629114 Test RE 2.6477181432159678\n",
      "4 Train Loss 10794.344 Test MSE 11.589245472625004 Test RE 2.4595941859971617\n",
      "5 Train Loss 3233.2202 Test MSE 18.719073144761257 Test RE 3.125921355938385\n",
      "6 Train Loss 1462.8588 Test MSE 21.789365410401416 Test RE 3.3725482208565474\n",
      "7 Train Loss 868.9651 Test MSE 21.145849349952616 Test RE 3.3223734213656577\n",
      "8 Train Loss 569.3257 Test MSE 20.76603065038642 Test RE 3.292400221542061\n",
      "9 Train Loss 369.85016 Test MSE 19.056690824168175 Test RE 3.153984980898124\n",
      "10 Train Loss 225.71202 Test MSE 18.886200192387694 Test RE 3.139844724445577\n",
      "11 Train Loss 152.96419 Test MSE 18.47847874663081 Test RE 3.1057678094123395\n",
      "12 Train Loss 109.474884 Test MSE 18.57541050343665 Test RE 3.113903050635999\n",
      "13 Train Loss 79.78338 Test MSE 18.792056177475775 Test RE 3.1320091916069046\n",
      "14 Train Loss 62.123127 Test MSE 18.42090135992807 Test RE 3.10092537858656\n",
      "15 Train Loss 52.961563 Test MSE 17.734112176111005 Test RE 3.042570166339988\n",
      "16 Train Loss 46.728516 Test MSE 17.254322004605662 Test RE 3.00113012484759\n",
      "17 Train Loss 41.189342 Test MSE 17.1813194983459 Test RE 2.9947745504877914\n",
      "18 Train Loss 37.199844 Test MSE 16.987700466486306 Test RE 2.9778524447216945\n",
      "19 Train Loss 34.53592 Test MSE 16.718503856757813 Test RE 2.954163866062774\n",
      "20 Train Loss 32.058464 Test MSE 16.501000867469227 Test RE 2.9348845394924648\n",
      "21 Train Loss 30.1511 Test MSE 16.38849759866031 Test RE 2.9248624556888285\n",
      "22 Train Loss 28.23038 Test MSE 16.17102141369559 Test RE 2.90539110778504\n",
      "23 Train Loss 26.95317 Test MSE 16.03221188216037 Test RE 2.8928945202082694\n",
      "24 Train Loss 25.464535 Test MSE 15.92333025217929 Test RE 2.8830543405406117\n",
      "25 Train Loss 24.459 Test MSE 15.897743609404255 Test RE 2.88073706966029\n",
      "26 Train Loss 23.708021 Test MSE 15.860784133656143 Test RE 2.877386516026335\n",
      "27 Train Loss 23.015629 Test MSE 15.75050131588015 Test RE 2.8673655794010173\n",
      "28 Train Loss 22.259315 Test MSE 15.71489081529314 Test RE 2.864122314268557\n",
      "29 Train Loss 21.738676 Test MSE 15.670006957876984 Test RE 2.8600292288789966\n",
      "30 Train Loss 21.259296 Test MSE 15.654015721912748 Test RE 2.858569527023595\n",
      "31 Train Loss 20.775406 Test MSE 15.680239303591225 Test RE 2.8609628606271977\n",
      "32 Train Loss 20.335136 Test MSE 15.571614324159231 Test RE 2.851035967384427\n",
      "33 Train Loss 20.005743 Test MSE 15.464532991527019 Test RE 2.841216195698829\n",
      "34 Train Loss 19.679438 Test MSE 15.395017419137481 Test RE 2.834823140410248\n",
      "35 Train Loss 19.20636 Test MSE 15.271900390705426 Test RE 2.823465063263893\n",
      "36 Train Loss 18.845419 Test MSE 15.177286055945165 Test RE 2.814705337772551\n",
      "37 Train Loss 18.51877 Test MSE 15.069324215587343 Test RE 2.804676433300364\n",
      "38 Train Loss 18.271444 Test MSE 14.97740207409276 Test RE 2.7961091537091405\n",
      "39 Train Loss 17.993603 Test MSE 14.896730162929384 Test RE 2.78856872616544\n",
      "40 Train Loss 17.807938 Test MSE 14.851734018980869 Test RE 2.784354051797356\n",
      "41 Train Loss 17.626352 Test MSE 14.815208777207276 Test RE 2.780928128277157\n",
      "42 Train Loss 17.451061 Test MSE 14.763327753745392 Test RE 2.7760546252548624\n",
      "43 Train Loss 17.265745 Test MSE 14.70631955931144 Test RE 2.770689610764658\n",
      "44 Train Loss 17.1196 Test MSE 14.66472329152947 Test RE 2.766768440777413\n",
      "45 Train Loss 16.989384 Test MSE 14.599234291840736 Test RE 2.7605836789688656\n",
      "46 Train Loss 16.867582 Test MSE 14.546515078147483 Test RE 2.755594806894547\n",
      "47 Train Loss 16.74134 Test MSE 14.518976212258789 Test RE 2.752985181650788\n",
      "48 Train Loss 16.632526 Test MSE 14.513788523949636 Test RE 2.752493311398296\n",
      "49 Train Loss 16.498457 Test MSE 14.45610724508725 Test RE 2.7470183317570176\n",
      "50 Train Loss 16.370613 Test MSE 14.352632913163855 Test RE 2.737169333121992\n",
      "51 Train Loss 16.23801 Test MSE 14.26449603610434 Test RE 2.728752164608376\n",
      "52 Train Loss 16.125402 Test MSE 14.188238716589499 Test RE 2.721448500417406\n",
      "53 Train Loss 16.017435 Test MSE 14.12477404931903 Test RE 2.7153550944024296\n",
      "54 Train Loss 15.866748 Test MSE 14.007417735757274 Test RE 2.704051241486826\n",
      "55 Train Loss 15.754255 Test MSE 13.874888960084036 Test RE 2.691228882210399\n",
      "56 Train Loss 15.590815 Test MSE 13.755254888511423 Test RE 2.6796014127527696\n",
      "57 Train Loss 15.415862 Test MSE 13.657023476370835 Test RE 2.670016252087197\n",
      "58 Train Loss 15.267423 Test MSE 13.560266601711387 Test RE 2.660541214184595\n",
      "59 Train Loss 15.186147 Test MSE 13.494442571600933 Test RE 2.6540759803928786\n",
      "60 Train Loss 15.061828 Test MSE 13.46731105363182 Test RE 2.6514065355070437\n",
      "61 Train Loss 14.889341 Test MSE 13.288995810438857 Test RE 2.633794941051133\n",
      "62 Train Loss 14.610632 Test MSE 13.004355507814404 Test RE 2.6054353044382106\n",
      "63 Train Loss 14.4272 Test MSE 12.72884671388 Test RE 2.5776883289071013\n",
      "64 Train Loss 14.164242 Test MSE 12.628983478849575 Test RE 2.5675568858674316\n",
      "65 Train Loss 13.93227 Test MSE 12.294676759637648 Test RE 2.533345565086891\n",
      "66 Train Loss 13.530014 Test MSE 12.091887133759828 Test RE 2.5123660685828844\n",
      "67 Train Loss 13.168021 Test MSE 11.859028854270614 Test RE 2.488057654194923\n",
      "68 Train Loss 12.823428 Test MSE 11.562950214922568 Test RE 2.4568022703788173\n",
      "69 Train Loss 12.504006 Test MSE 11.149121448372222 Test RE 2.4124382183707582\n",
      "70 Train Loss 12.071031 Test MSE 10.760458041104679 Test RE 2.3700158806539786\n",
      "71 Train Loss 11.634824 Test MSE 10.361401770757452 Test RE 2.3256541663575385\n",
      "72 Train Loss 11.203429 Test MSE 10.113477889859626 Test RE 2.2976619992816247\n",
      "73 Train Loss 10.7176 Test MSE 9.66425459314933 Test RE 2.2460533000588287\n",
      "74 Train Loss 10.099355 Test MSE 9.36413740492367 Test RE 2.210903390756846\n",
      "75 Train Loss 9.643856 Test MSE 9.185836765286174 Test RE 2.1897535480768378\n",
      "76 Train Loss 9.123035 Test MSE 8.821659696134251 Test RE 2.1459076456641815\n",
      "77 Train Loss 8.636889 Test MSE 8.670445101872568 Test RE 2.127436339395814\n",
      "78 Train Loss 8.328334 Test MSE 8.62541841906129 Test RE 2.121905130316151\n",
      "79 Train Loss 7.9332004 Test MSE 8.38979768405731 Test RE 2.0927223906102763\n",
      "80 Train Loss 7.485084 Test MSE 8.13054947279266 Test RE 2.0601356868254945\n",
      "81 Train Loss 7.0987034 Test MSE 7.879055469367664 Test RE 2.028023372708549\n",
      "82 Train Loss 6.7848716 Test MSE 7.582548023457813 Test RE 1.989497792841903\n",
      "83 Train Loss 6.536826 Test MSE 7.444959787882989 Test RE 1.9713650605366986\n",
      "84 Train Loss 6.0659795 Test MSE 6.9110708506322345 Test RE 1.8993655188036165\n",
      "85 Train Loss 5.8182883 Test MSE 6.678483239227334 Test RE 1.867131032144875\n",
      "86 Train Loss 5.591874 Test MSE 6.250494283379168 Test RE 1.8063132100535881\n",
      "87 Train Loss 5.365798 Test MSE 5.759650660848225 Test RE 1.7339395329499603\n",
      "88 Train Loss 4.9845533 Test MSE 5.2758627678796985 Test RE 1.659520501975918\n",
      "89 Train Loss 4.6534367 Test MSE 4.659153552143388 Test RE 1.559514398366866\n",
      "90 Train Loss 4.3660297 Test MSE 4.333007743863123 Test RE 1.5039403433876748\n",
      "91 Train Loss 4.1015935 Test MSE 3.9153929698794423 Test RE 1.4296296781384963\n",
      "92 Train Loss 3.682812 Test MSE 3.3917050921246674 Test RE 1.3305920325639469\n",
      "93 Train Loss 3.4458666 Test MSE 3.132492524394481 Test RE 1.278736019306406\n",
      "94 Train Loss 3.215009 Test MSE 2.807709842618525 Test RE 1.210631553740282\n",
      "95 Train Loss 3.0750542 Test MSE 2.5052885370279343 Test RE 1.1435752632590956\n",
      "96 Train Loss 2.846358 Test MSE 2.3566042874658675 Test RE 1.1091217160155413\n",
      "97 Train Loss 2.6884096 Test MSE 2.1052482080973616 Test RE 1.0483046931223332\n",
      "98 Train Loss 2.551899 Test MSE 1.9767115497328906 Test RE 1.0157984055491323\n",
      "99 Train Loss 2.365034 Test MSE 1.8609066225349755 Test RE 0.9855942647051207\n",
      "100 Train Loss 2.2379384 Test MSE 1.8454570155725636 Test RE 0.9814944404114391\n",
      "101 Train Loss 2.126487 Test MSE 1.6816330502852554 Test RE 0.936917808768911\n",
      "102 Train Loss 2.0282013 Test MSE 1.5569495148833115 Test RE 0.9015153839293866\n",
      "103 Train Loss 1.9074241 Test MSE 1.4665041310304345 Test RE 0.8749384899043171\n",
      "104 Train Loss 1.7533933 Test MSE 1.4411266952495598 Test RE 0.8673351725177592\n",
      "105 Train Loss 1.6424159 Test MSE 1.2915230196527274 Test RE 0.8210827960158233\n",
      "106 Train Loss 1.5792248 Test MSE 1.2752844696365002 Test RE 0.815904657660393\n",
      "107 Train Loss 1.4866722 Test MSE 1.2172537216154415 Test RE 0.7971250044268211\n",
      "108 Train Loss 1.4241153 Test MSE 1.1272744727103758 Test RE 0.7670977574473113\n",
      "109 Train Loss 1.3601044 Test MSE 1.0308748579038454 Test RE 0.7335654201406254\n",
      "110 Train Loss 1.3124833 Test MSE 0.9970894606120462 Test RE 0.7214445213925759\n",
      "111 Train Loss 1.2505316 Test MSE 0.910466052949492 Test RE 0.6893944070119113\n",
      "112 Train Loss 1.1918832 Test MSE 0.8987117466014928 Test RE 0.6849298378917497\n",
      "113 Train Loss 1.1280042 Test MSE 0.8538309825097357 Test RE 0.667608460480782\n",
      "114 Train Loss 1.0649424 Test MSE 0.7336973768666762 Test RE 0.6188627745736196\n",
      "115 Train Loss 1.0180919 Test MSE 0.6766984966698373 Test RE 0.5943379784256017\n",
      "116 Train Loss 0.9617076 Test MSE 0.6715032260950463 Test RE 0.5920521037446838\n",
      "117 Train Loss 0.9288066 Test MSE 0.6701699837912218 Test RE 0.5914640640491484\n",
      "118 Train Loss 0.89366347 Test MSE 0.5949579939112125 Test RE 0.557287149745715\n",
      "119 Train Loss 0.8669155 Test MSE 0.5670299873733281 Test RE 0.5440500950026774\n",
      "120 Train Loss 0.8367392 Test MSE 0.5385481595363844 Test RE 0.5302102874543522\n",
      "121 Train Loss 0.790959 Test MSE 0.5135156389389395 Test RE 0.5177411858613156\n",
      "122 Train Loss 0.73320276 Test MSE 0.42959688739735213 Test RE 0.4735506531199208\n",
      "123 Train Loss 0.70512474 Test MSE 0.40445241907859225 Test RE 0.45948315617237967\n",
      "124 Train Loss 0.6682253 Test MSE 0.4056070716606722 Test RE 0.4601385673792871\n",
      "125 Train Loss 0.63931835 Test MSE 0.3500837453988513 Test RE 0.4274859546328253\n",
      "126 Train Loss 0.60530645 Test MSE 0.34476187475095155 Test RE 0.42422425311304585\n",
      "127 Train Loss 0.57745385 Test MSE 0.3178941317679788 Test RE 0.40735882793881806\n",
      "128 Train Loss 0.56890416 Test MSE 0.31739399745756486 Test RE 0.4070382584447778\n",
      "129 Train Loss 0.5545335 Test MSE 0.2951774552125304 Test RE 0.39253417097861176\n",
      "130 Train Loss 0.53932035 Test MSE 0.2763373569255015 Test RE 0.3798006263240536\n",
      "131 Train Loss 0.5255488 Test MSE 0.26415608418855824 Test RE 0.3713352569772148\n",
      "132 Train Loss 0.49954242 Test MSE 0.256072228432218 Test RE 0.36560920149305454\n",
      "133 Train Loss 0.4773547 Test MSE 0.2460737276260975 Test RE 0.35840041261696753\n",
      "134 Train Loss 0.4548887 Test MSE 0.22631188802514005 Test RE 0.3437079367467219\n",
      "135 Train Loss 0.43899316 Test MSE 0.21774219731071007 Test RE 0.33713758963696744\n",
      "136 Train Loss 0.4129987 Test MSE 0.21335628843392082 Test RE 0.3337248916680281\n",
      "137 Train Loss 0.39097208 Test MSE 0.18977898537120533 Test RE 0.31474579532437036\n",
      "138 Train Loss 0.37260377 Test MSE 0.15950667429689028 Test RE 0.28855280934810545\n",
      "139 Train Loss 0.35076872 Test MSE 0.13093186554007977 Test RE 0.26143188530233274\n",
      "140 Train Loss 0.33115524 Test MSE 0.11156232204960982 Test RE 0.24132074057331676\n",
      "141 Train Loss 0.3122592 Test MSE 0.09767451136052649 Test RE 0.22580133253027246\n",
      "142 Train Loss 0.29428145 Test MSE 0.09489455845116795 Test RE 0.22256482690314325\n",
      "143 Train Loss 0.27666074 Test MSE 0.09305288242256991 Test RE 0.22039452016498165\n",
      "144 Train Loss 0.259675 Test MSE 0.08051243516239144 Test RE 0.20500637111035708\n",
      "145 Train Loss 0.24933511 Test MSE 0.07781641569812335 Test RE 0.20154474932961722\n",
      "146 Train Loss 0.2403028 Test MSE 0.06679733933922613 Test RE 0.18673058548908367\n",
      "147 Train Loss 0.23054738 Test MSE 0.06067434147336758 Test RE 0.17796656277487533\n",
      "148 Train Loss 0.21396852 Test MSE 0.05715078887749868 Test RE 0.1727217349195206\n",
      "149 Train Loss 0.20266095 Test MSE 0.05066480806078763 Test RE 0.16262566210893417\n",
      "150 Train Loss 0.1894646 Test MSE 0.04355224674957841 Test RE 0.15077910425191698\n",
      "151 Train Loss 0.18061882 Test MSE 0.03501133825051842 Test RE 0.1351886504194785\n",
      "152 Train Loss 0.16721123 Test MSE 0.03652193160024362 Test RE 0.13807426697903447\n",
      "153 Train Loss 0.15461504 Test MSE 0.03240145867494214 Test RE 0.13005233615794515\n",
      "154 Train Loss 0.14646187 Test MSE 0.028306972645918756 Test RE 0.12155773228143943\n",
      "155 Train Loss 0.13852106 Test MSE 0.025053052116816552 Test RE 0.11435790689464466\n",
      "156 Train Loss 0.13250972 Test MSE 0.02270040777998282 Test RE 0.10885608383811284\n",
      "157 Train Loss 0.12748218 Test MSE 0.023512530923887814 Test RE 0.11078617463664506\n",
      "158 Train Loss 0.124204606 Test MSE 0.02543059259248052 Test RE 0.11521635111913994\n",
      "159 Train Loss 0.118078984 Test MSE 0.027298895965364642 Test RE 0.1193736350063571\n",
      "160 Train Loss 0.11491861 Test MSE 0.026267069913067986 Test RE 0.11709590079973685\n",
      "161 Train Loss 0.11192247 Test MSE 0.026993911038405188 Test RE 0.11870493732043676\n",
      "162 Train Loss 0.1071271 Test MSE 0.028241145822507384 Test RE 0.12141631099906801\n",
      "163 Train Loss 0.10399768 Test MSE 0.02639579361416254 Test RE 0.11738246866374158\n",
      "164 Train Loss 0.10147306 Test MSE 0.027087170333591433 Test RE 0.11890981303719442\n",
      "165 Train Loss 0.0982746 Test MSE 0.029104747133618346 Test RE 0.12325875936154118\n",
      "166 Train Loss 0.095834225 Test MSE 0.027714498125283194 Test RE 0.12027888296337766\n",
      "167 Train Loss 0.09125922 Test MSE 0.02817941505766835 Test RE 0.12128353979238654\n",
      "168 Train Loss 0.08832414 Test MSE 0.029019569823089664 Test RE 0.12307826402414103\n",
      "169 Train Loss 0.086852424 Test MSE 0.028964227719978263 Test RE 0.12296084911129887\n",
      "170 Train Loss 0.08411108 Test MSE 0.028165472086705712 Test RE 0.12125353097030733\n",
      "171 Train Loss 0.081887506 Test MSE 0.027082720747941633 Test RE 0.11890004603086535\n",
      "172 Train Loss 0.080082804 Test MSE 0.027804091422315564 Test RE 0.12047314025400799\n",
      "173 Train Loss 0.07796235 Test MSE 0.02822922673952907 Test RE 0.12139068661717325\n",
      "174 Train Loss 0.07622431 Test MSE 0.026878697040433646 Test RE 0.11845134133515264\n",
      "175 Train Loss 0.07466206 Test MSE 0.026103547860852526 Test RE 0.116730849508641\n",
      "176 Train Loss 0.072948255 Test MSE 0.025891422777862872 Test RE 0.11625558745618655\n",
      "177 Train Loss 0.071495436 Test MSE 0.025778282595189505 Test RE 0.1160013028777455\n",
      "178 Train Loss 0.06970049 Test MSE 0.0247880827827856 Test RE 0.11375155593929044\n",
      "179 Train Loss 0.06872425 Test MSE 0.02308881901002946 Test RE 0.10978341511624441\n",
      "180 Train Loss 0.067432255 Test MSE 0.022824342449987114 Test RE 0.10915283355293089\n",
      "181 Train Loss 0.06608717 Test MSE 0.022009753484045803 Test RE 0.10718733324312547\n",
      "182 Train Loss 0.06435124 Test MSE 0.021368487938649424 Test RE 0.10561431166753801\n",
      "183 Train Loss 0.06301464 Test MSE 0.019881358831815396 Test RE 0.10187295617343739\n",
      "184 Train Loss 0.06235412 Test MSE 0.01960294696043959 Test RE 0.10115714400919543\n",
      "185 Train Loss 0.060351975 Test MSE 0.019265651825195195 Test RE 0.10028309536714337\n",
      "186 Train Loss 0.058347017 Test MSE 0.01895981923765526 Test RE 0.09948393913560144\n",
      "187 Train Loss 0.057491343 Test MSE 0.01895186425653117 Test RE 0.09946306668221067\n",
      "188 Train Loss 0.056772456 Test MSE 0.01836324058883432 Test RE 0.09790627760447745\n",
      "189 Train Loss 0.05517664 Test MSE 0.017522145698596833 Test RE 0.09563778749622362\n",
      "190 Train Loss 0.05362573 Test MSE 0.01645903120251879 Test RE 0.0926910946744684\n",
      "191 Train Loss 0.05236631 Test MSE 0.015604338302428428 Test RE 0.09025235760451285\n",
      "192 Train Loss 0.051667027 Test MSE 0.014968404949507012 Test RE 0.08839417337639487\n",
      "193 Train Loss 0.049565714 Test MSE 0.014712131069746944 Test RE 0.08763420871088796\n",
      "194 Train Loss 0.04786558 Test MSE 0.013602971686440852 Test RE 0.08426607663114345\n",
      "195 Train Loss 0.046434026 Test MSE 0.012461376834768648 Test RE 0.0806526964333986\n",
      "196 Train Loss 0.045050222 Test MSE 0.011879023763411716 Test RE 0.07874559202412293\n",
      "197 Train Loss 0.0439781 Test MSE 0.011451910859511798 Test RE 0.07731697540177934\n",
      "198 Train Loss 0.042962 Test MSE 0.011340624009484592 Test RE 0.0769403845991059\n",
      "199 Train Loss 0.04166589 Test MSE 0.010663859584415045 Test RE 0.074609320697454\n",
      "200 Train Loss 0.04075413 Test MSE 0.01027283291791499 Test RE 0.07322864348845647\n",
      "201 Train Loss 0.039984357 Test MSE 0.010139213384664118 Test RE 0.07275083937605871\n",
      "202 Train Loss 0.0392424 Test MSE 0.009861516607728214 Test RE 0.07174765846266898\n",
      "203 Train Loss 0.037716843 Test MSE 0.009674408919815023 Test RE 0.07106374603474327\n",
      "204 Train Loss 0.036803752 Test MSE 0.008987197273774845 Test RE 0.06849328790556669\n",
      "205 Train Loss 0.03569651 Test MSE 0.008385936220821889 Test RE 0.06616246152122394\n",
      "206 Train Loss 0.035137203 Test MSE 0.007913800332642761 Test RE 0.0642729777676172\n",
      "207 Train Loss 0.034525864 Test MSE 0.007524095694008376 Test RE 0.06267048159918616\n",
      "208 Train Loss 0.033869326 Test MSE 0.007337571673687381 Test RE 0.06188879902574642\n",
      "209 Train Loss 0.033217046 Test MSE 0.007350316139459218 Test RE 0.06194252235049804\n",
      "210 Train Loss 0.032814138 Test MSE 0.007483050263838303 Test RE 0.06249930789711298\n",
      "211 Train Loss 0.03221403 Test MSE 0.007652934222719125 Test RE 0.06320477173089595\n",
      "212 Train Loss 0.03170693 Test MSE 0.007862959770906808 Test RE 0.0640661909391965\n",
      "213 Train Loss 0.030992541 Test MSE 0.008040024365914056 Test RE 0.06478352264463058\n",
      "214 Train Loss 0.030537551 Test MSE 0.007783229867831849 Test RE 0.0637405498265259\n",
      "215 Train Loss 0.029998057 Test MSE 0.007379833075364005 Test RE 0.06206677017583178\n",
      "216 Train Loss 0.029583339 Test MSE 0.007119482445418049 Test RE 0.06096212381324065\n",
      "217 Train Loss 0.029013809 Test MSE 0.007258232357549438 Test RE 0.061553295627023934\n",
      "218 Train Loss 0.028095588 Test MSE 0.0071309141655378425 Test RE 0.06101104748248203\n",
      "219 Train Loss 0.027433965 Test MSE 0.00714409954654164 Test RE 0.06106742751759192\n",
      "220 Train Loss 0.02706201 Test MSE 0.00689302790826218 Test RE 0.059984755821604376\n",
      "221 Train Loss 0.026607484 Test MSE 0.007012731912782459 Test RE 0.06050336024799048\n",
      "222 Train Loss 0.026091704 Test MSE 0.006921869347674558 Test RE 0.06011011733236348\n",
      "223 Train Loss 0.02548021 Test MSE 0.006858709344175235 Test RE 0.05983524537369384\n",
      "224 Train Loss 0.024945932 Test MSE 0.007192676277639652 Test RE 0.061274691596767454\n",
      "225 Train Loss 0.024681753 Test MSE 0.0072277280999549455 Test RE 0.06142381406444799\n",
      "226 Train Loss 0.024466291 Test MSE 0.0072393210094124985 Test RE 0.061473054669418443\n",
      "227 Train Loss 0.024129063 Test MSE 0.007472119255471129 Test RE 0.06245364268653162\n",
      "228 Train Loss 0.02360468 Test MSE 0.007750494394601798 Test RE 0.06360636545148429\n",
      "229 Train Loss 0.023177762 Test MSE 0.007789617481804366 Test RE 0.06376670005798106\n",
      "230 Train Loss 0.022666961 Test MSE 0.007160850542786442 Test RE 0.061138978964645\n",
      "231 Train Loss 0.022263153 Test MSE 0.006558074283187445 Test RE 0.05850918419466062\n",
      "232 Train Loss 0.021791495 Test MSE 0.006701758863628027 Test RE 0.05914666687251058\n",
      "233 Train Loss 0.021323826 Test MSE 0.006703361493505894 Test RE 0.05915373848991587\n",
      "234 Train Loss 0.02096502 Test MSE 0.006418004735378145 Test RE 0.05788098237409261\n",
      "235 Train Loss 0.020641742 Test MSE 0.006263321511161442 Test RE 0.057179220395181043\n",
      "236 Train Loss 0.02025374 Test MSE 0.006180963697604716 Test RE 0.05680204523174051\n",
      "237 Train Loss 0.019758364 Test MSE 0.006272631435099941 Test RE 0.05722170077246016\n",
      "238 Train Loss 0.019446742 Test MSE 0.006103589793419737 Test RE 0.05644539882223777\n",
      "239 Train Loss 0.019113362 Test MSE 0.005938653323401669 Test RE 0.05567751757118197\n",
      "240 Train Loss 0.018810328 Test MSE 0.00582925804154517 Test RE 0.05516231921608372\n",
      "241 Train Loss 0.018550938 Test MSE 0.005756261193172451 Test RE 0.0548158462189931\n",
      "242 Train Loss 0.018282017 Test MSE 0.005568217664072667 Test RE 0.053913059566422956\n",
      "243 Train Loss 0.018060194 Test MSE 0.005546319735405483 Test RE 0.05380694416269533\n",
      "244 Train Loss 0.01773114 Test MSE 0.005327895993568798 Test RE 0.05273679662734557\n",
      "245 Train Loss 0.01735048 Test MSE 0.0051984900192298305 Test RE 0.05209241408652757\n",
      "246 Train Loss 0.017085288 Test MSE 0.004975219041941145 Test RE 0.05096147387542525\n",
      "247 Train Loss 0.016721776 Test MSE 0.004931554983759631 Test RE 0.05073735424261969\n",
      "248 Train Loss 0.016516384 Test MSE 0.005140337137090331 Test RE 0.051800228893889584\n",
      "249 Train Loss 0.016312357 Test MSE 0.004983708148657334 Test RE 0.051004932565624335\n",
      "250 Train Loss 0.016149439 Test MSE 0.0049012665382650086 Test RE 0.05058130584966873\n",
      "251 Train Loss 0.015914556 Test MSE 0.004959922067541724 Test RE 0.0508830696393401\n",
      "252 Train Loss 0.01569785 Test MSE 0.004715757345942398 Test RE 0.04961484076537852\n",
      "253 Train Loss 0.015558406 Test MSE 0.004525246656272399 Test RE 0.04860232049764181\n",
      "254 Train Loss 0.015379624 Test MSE 0.004454727392060121 Test RE 0.04822213595247708\n",
      "255 Train Loss 0.015180728 Test MSE 0.004545212034651679 Test RE 0.04870941916390604\n",
      "256 Train Loss 0.0150629915 Test MSE 0.004411743171166627 Test RE 0.04798892130368226\n",
      "257 Train Loss 0.014918329 Test MSE 0.0044217837143438925 Test RE 0.04804349848339867\n",
      "258 Train Loss 0.014747821 Test MSE 0.004341435065972962 Test RE 0.04760499586471853\n",
      "259 Train Loss 0.014575346 Test MSE 0.004244666395479572 Test RE 0.04707145886630129\n",
      "260 Train Loss 0.014315299 Test MSE 0.004074098328907748 Test RE 0.046115999963376904\n",
      "261 Train Loss 0.014153676 Test MSE 0.003913586409952365 Test RE 0.04519842906137882\n",
      "262 Train Loss 0.014046951 Test MSE 0.003841700395919051 Test RE 0.044781395492088594\n",
      "263 Train Loss 0.013918931 Test MSE 0.003707985618695208 Test RE 0.04399515959152114\n",
      "264 Train Loss 0.0137538975 Test MSE 0.0034669637416523294 Test RE 0.04254127742932399\n",
      "265 Train Loss 0.013511843 Test MSE 0.0032996552194257795 Test RE 0.04150210820172361\n",
      "266 Train Loss 0.013315006 Test MSE 0.0032397759823457515 Test RE 0.04112381224315591\n",
      "267 Train Loss 0.01317922 Test MSE 0.003127374134509189 Test RE 0.04040413345013809\n",
      "268 Train Loss 0.013044252 Test MSE 0.002979570128951256 Test RE 0.03943780022705652\n",
      "269 Train Loss 0.012916402 Test MSE 0.0029412648895975908 Test RE 0.03918347475938217\n",
      "270 Train Loss 0.012756567 Test MSE 0.0029689187717276922 Test RE 0.03936724605894402\n",
      "271 Train Loss 0.012604923 Test MSE 0.002810169293514369 Test RE 0.0383002949855055\n",
      "272 Train Loss 0.012476255 Test MSE 0.002671177742308665 Test RE 0.037341114033860194\n",
      "273 Train Loss 0.012382108 Test MSE 0.002550576709486516 Test RE 0.03648842113392936\n",
      "274 Train Loss 0.012243622 Test MSE 0.0023028476369729846 Test RE 0.03467116854914341\n",
      "275 Train Loss 0.012112937 Test MSE 0.0022619377334783656 Test RE 0.034361823255404315\n",
      "276 Train Loss 0.011969413 Test MSE 0.00219133866843094 Test RE 0.033821325807002554\n",
      "277 Train Loss 0.011832264 Test MSE 0.002063698350828491 Test RE 0.03282154234131277\n",
      "278 Train Loss 0.011564715 Test MSE 0.0020696480001166813 Test RE 0.03286882059848858\n",
      "279 Train Loss 0.011372627 Test MSE 0.00187875188112247 Test RE 0.03131631054946555\n",
      "280 Train Loss 0.011190475 Test MSE 0.0018910483838522096 Test RE 0.031418626630421824\n",
      "281 Train Loss 0.010997502 Test MSE 0.0019320579430853 Test RE 0.03175747393787202\n",
      "282 Train Loss 0.010844775 Test MSE 0.001964142096402218 Test RE 0.032020073815980495\n",
      "283 Train Loss 0.010737882 Test MSE 0.0020513739990300037 Test RE 0.032723390892380785\n",
      "284 Train Loss 0.010521166 Test MSE 0.0018599276097069429 Test RE 0.031159027719933154\n",
      "285 Train Loss 0.010392755 Test MSE 0.0019055598564884507 Test RE 0.0315389459220545\n",
      "286 Train Loss 0.010292813 Test MSE 0.0018783659893670845 Test RE 0.03131309423155292\n",
      "287 Train Loss 0.010177167 Test MSE 0.0017671986549115258 Test RE 0.03037236169021387\n",
      "288 Train Loss 0.010044112 Test MSE 0.001785398637770471 Test RE 0.030528360143563155\n",
      "289 Train Loss 0.009928498 Test MSE 0.0017830133384023343 Test RE 0.030507960325116924\n",
      "290 Train Loss 0.009837198 Test MSE 0.0017345549100053685 Test RE 0.030090534570261285\n",
      "291 Train Loss 0.00972178 Test MSE 0.00160297824714927 Test RE 0.02892675327275804\n",
      "292 Train Loss 0.009616507 Test MSE 0.0015249300039632291 Test RE 0.028213751161861842\n",
      "293 Train Loss 0.0095129395 Test MSE 0.0014296011822496702 Test RE 0.027317649356655895\n",
      "294 Train Loss 0.009436882 Test MSE 0.0013477116968357052 Test RE 0.026523716403924417\n",
      "295 Train Loss 0.009369769 Test MSE 0.0013191340994874801 Test RE 0.026240998134540266\n",
      "296 Train Loss 0.009316176 Test MSE 0.0013246739235471118 Test RE 0.026296041139010906\n",
      "297 Train Loss 0.0092560705 Test MSE 0.00128087567962911 Test RE 0.02585766869641961\n",
      "298 Train Loss 0.009201413 Test MSE 0.001293286090895743 Test RE 0.025982634272771282\n",
      "299 Train Loss 0.00904946 Test MSE 0.0012148207392423008 Test RE 0.025182101823040398\n",
      "Training time: 251.38\n",
      "KG_atanh_high\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 61494.098 Test MSE 9.24614634651067 Test RE 2.1969301976582503\n",
      "1 Train Loss 43633.676 Test MSE 10.765429749649433 Test RE 2.3705633326040463\n",
      "2 Train Loss 26047.215 Test MSE 10.163906495692277 Test RE 2.3033832661980096\n",
      "3 Train Loss 8406.006 Test MSE 11.827140787590071 Test RE 2.4847102993811383\n",
      "4 Train Loss 3942.4602 Test MSE 11.884553034436458 Test RE 2.490733737479208\n",
      "5 Train Loss 1701.7545 Test MSE 13.339276144803607 Test RE 2.638772859045577\n",
      "6 Train Loss 712.7677 Test MSE 17.610736168349327 Test RE 3.0319681323472203\n",
      "7 Train Loss 383.5592 Test MSE 19.527140607136072 Test RE 3.19267861735356\n",
      "8 Train Loss 239.13945 Test MSE 19.67782104359704 Test RE 3.2049730370269507\n",
      "9 Train Loss 141.96555 Test MSE 18.430090162647684 Test RE 3.1016986914263813\n",
      "10 Train Loss 95.92525 Test MSE 17.45242063022321 Test RE 3.0183090972692437\n",
      "11 Train Loss 74.48573 Test MSE 16.879089433066248 Test RE 2.9683177154418066\n",
      "12 Train Loss 55.58339 Test MSE 16.336978796231477 Test RE 2.9202615452006544\n",
      "13 Train Loss 45.100677 Test MSE 16.031923924925024 Test RE 2.8928685402107845\n",
      "14 Train Loss 38.62847 Test MSE 16.014921155049063 Test RE 2.891334107208009\n",
      "15 Train Loss 34.375286 Test MSE 16.064000297226816 Test RE 2.8957610926155315\n",
      "16 Train Loss 30.243074 Test MSE 15.850025782113647 Test RE 2.8764104865145828\n",
      "17 Train Loss 27.80762 Test MSE 15.61638721255045 Test RE 2.855131801225767\n",
      "18 Train Loss 26.053062 Test MSE 15.495646330206137 Test RE 2.8440729034726075\n",
      "19 Train Loss 24.466572 Test MSE 15.445770370599977 Test RE 2.8394920944369604\n",
      "20 Train Loss 23.196194 Test MSE 15.405195187220329 Test RE 2.8357600476143543\n",
      "21 Train Loss 22.310667 Test MSE 15.293234864452735 Test RE 2.8254365310234406\n",
      "22 Train Loss 21.629929 Test MSE 15.211863476289045 Test RE 2.8179097934263115\n",
      "23 Train Loss 21.118523 Test MSE 15.230616906523965 Test RE 2.8196462406947695\n",
      "24 Train Loss 20.71026 Test MSE 15.195991378356442 Test RE 2.8164393025423515\n",
      "25 Train Loss 20.132017 Test MSE 15.148408750695818 Test RE 2.812026340867287\n",
      "26 Train Loss 19.65362 Test MSE 15.040929840765761 Test RE 2.802032831564604\n",
      "27 Train Loss 19.178648 Test MSE 14.970254781466375 Test RE 2.7954419153257235\n",
      "28 Train Loss 18.620335 Test MSE 14.903291298426895 Test RE 2.7891827590069367\n",
      "29 Train Loss 18.22763 Test MSE 14.915559554571965 Test RE 2.7903305379996053\n",
      "30 Train Loss 17.841795 Test MSE 14.858040125749467 Test RE 2.7849451130990106\n",
      "31 Train Loss 17.44169 Test MSE 14.853018580249742 Test RE 2.7844744618462376\n",
      "32 Train Loss 17.133335 Test MSE 14.755911047054019 Test RE 2.775357229323077\n",
      "33 Train Loss 16.841312 Test MSE 14.722941738616537 Test RE 2.7722549885943\n",
      "34 Train Loss 16.609747 Test MSE 14.658207292620718 Test RE 2.7661536912571334\n",
      "35 Train Loss 16.374063 Test MSE 14.613412367796988 Test RE 2.761923826891959\n",
      "36 Train Loss 16.204527 Test MSE 14.520855186030039 Test RE 2.753163314720403\n",
      "37 Train Loss 15.950876 Test MSE 14.424158118760898 Test RE 2.7439810901380066\n",
      "38 Train Loss 15.680239 Test MSE 14.340408630430774 Test RE 2.736003447406278\n",
      "39 Train Loss 15.474476 Test MSE 14.300983209670422 Test RE 2.7322398751410177\n",
      "40 Train Loss 15.321734 Test MSE 14.202948757647972 Test RE 2.722858902692445\n",
      "41 Train Loss 15.111376 Test MSE 14.032637623527025 Test RE 2.7064844237344907\n",
      "42 Train Loss 14.882355 Test MSE 13.922295811233774 Test RE 2.6958225727993077\n",
      "43 Train Loss 14.682255 Test MSE 13.866948425031593 Test RE 2.6904586830517188\n",
      "44 Train Loss 14.4628105 Test MSE 13.78214455902359 Test RE 2.6822192639043285\n",
      "45 Train Loss 14.3010235 Test MSE 13.744142878396742 Test RE 2.6785188528814134\n",
      "46 Train Loss 14.094071 Test MSE 13.741943634963905 Test RE 2.6783045452044685\n",
      "47 Train Loss 13.844382 Test MSE 13.55894272056106 Test RE 2.6604113374484153\n",
      "48 Train Loss 13.621748 Test MSE 13.41617796658795 Test RE 2.646368279023145\n",
      "49 Train Loss 13.36444 Test MSE 13.276552349926533 Test RE 2.6325615446579422\n",
      "50 Train Loss 13.082296 Test MSE 13.027717674293845 Test RE 2.6077745707092084\n",
      "51 Train Loss 12.74924 Test MSE 12.778191305209477 Test RE 2.5826798237183253\n",
      "52 Train Loss 12.24594 Test MSE 12.369459602562413 Test RE 2.5410384705036337\n",
      "53 Train Loss 11.640005 Test MSE 11.877640391500263 Test RE 2.4900092652462353\n",
      "54 Train Loss 10.814975 Test MSE 11.184560565731724 Test RE 2.4162693206669084\n",
      "55 Train Loss 9.616606 Test MSE 10.34690687685433 Test RE 2.3240268813177187\n",
      "56 Train Loss 9.180272 Test MSE 10.340834488506873 Test RE 2.3233448192726067\n",
      "57 Train Loss 8.678813 Test MSE 9.6408650103657 Test RE 2.243333686576427\n",
      "58 Train Loss 7.995896 Test MSE 9.289650772682494 Test RE 2.2020925660035844\n",
      "59 Train Loss 7.5564556 Test MSE 8.82515445543858 Test RE 2.1463326613856517\n",
      "60 Train Loss 7.005809 Test MSE 8.077869788040314 Test RE 2.053450796462738\n",
      "61 Train Loss 6.5276046 Test MSE 7.686772207747359 Test RE 2.003124221962001\n",
      "62 Train Loss 6.0321994 Test MSE 7.143997897186848 Test RE 1.931107879560416\n",
      "63 Train Loss 5.4430513 Test MSE 6.811882576861654 Test RE 1.885686332875611\n",
      "64 Train Loss 5.0823293 Test MSE 6.467257413902207 Test RE 1.8373671633141926\n",
      "65 Train Loss 4.776489 Test MSE 6.118900195541662 Test RE 1.7871975551478727\n",
      "66 Train Loss 4.358773 Test MSE 5.563348507808951 Test RE 1.704135054777878\n",
      "67 Train Loss 4.017167 Test MSE 5.064539228216306 Test RE 1.6259449840243005\n",
      "68 Train Loss 3.6663227 Test MSE 4.851341606433408 Test RE 1.591354018433773\n",
      "69 Train Loss 3.3670113 Test MSE 4.5207914211264 Test RE 1.5361835561909112\n",
      "70 Train Loss 3.158233 Test MSE 4.280457925947373 Test RE 1.4947927858116263\n",
      "71 Train Loss 2.9480565 Test MSE 3.93534294279616 Test RE 1.4332672229801977\n",
      "72 Train Loss 2.7684708 Test MSE 3.643584623043417 Test RE 1.379114444465644\n",
      "73 Train Loss 2.6499734 Test MSE 3.2971366722837927 Test RE 1.3119109343980309\n",
      "74 Train Loss 2.4514349 Test MSE 2.8473988655255376 Test RE 1.2191581064558008\n",
      "75 Train Loss 2.2831173 Test MSE 2.5263938580553837 Test RE 1.1483820758109344\n",
      "76 Train Loss 2.1387997 Test MSE 2.3699097917292034 Test RE 1.112248386901953\n",
      "77 Train Loss 1.8976835 Test MSE 1.9990773694269117 Test RE 1.021528948302907\n",
      "78 Train Loss 1.6722919 Test MSE 1.7562880005385004 Test RE 0.9574888911395023\n",
      "79 Train Loss 1.5664126 Test MSE 1.6466174907376105 Test RE 0.9271120782638158\n",
      "80 Train Loss 1.4553727 Test MSE 1.5588517043195553 Test RE 0.9020659250890639\n",
      "81 Train Loss 1.371743 Test MSE 1.4484989876390424 Test RE 0.8695508318649945\n",
      "82 Train Loss 1.3229109 Test MSE 1.4127532413217663 Test RE 0.8587545143286989\n",
      "83 Train Loss 1.2400968 Test MSE 1.3469847165059123 Test RE 0.8385273084704676\n",
      "84 Train Loss 1.1692659 Test MSE 1.3498397456675246 Test RE 0.8394154969770883\n",
      "85 Train Loss 1.107686 Test MSE 1.2450709803871727 Test RE 0.8061816939011404\n",
      "86 Train Loss 1.0708275 Test MSE 1.2003623651767745 Test RE 0.7915749864840905\n",
      "87 Train Loss 1.035332 Test MSE 1.1580667990070392 Test RE 0.7775040900858516\n",
      "88 Train Loss 0.982133 Test MSE 1.075393160017706 Test RE 0.7492375099109825\n",
      "89 Train Loss 0.9414646 Test MSE 1.0367120263419718 Test RE 0.7356393384847608\n",
      "90 Train Loss 0.8960381 Test MSE 0.9825807586766516 Test RE 0.7161763981205632\n",
      "91 Train Loss 0.86011267 Test MSE 0.8960858914463149 Test RE 0.6839284922385882\n",
      "92 Train Loss 0.80971897 Test MSE 0.8499230766573139 Test RE 0.6660789170777547\n",
      "93 Train Loss 0.75934106 Test MSE 0.7805295354818583 Test RE 0.6383083823331634\n",
      "94 Train Loss 0.7166778 Test MSE 0.7275189503732788 Test RE 0.616251560513124\n",
      "95 Train Loss 0.69823354 Test MSE 0.7301166598895475 Test RE 0.6173507869175405\n",
      "96 Train Loss 0.6619557 Test MSE 0.6376974930221689 Test RE 0.5769567142008849\n",
      "97 Train Loss 0.6385042 Test MSE 0.6335982873310883 Test RE 0.5750993466593913\n",
      "98 Train Loss 0.60911447 Test MSE 0.5719983421043348 Test RE 0.5464283983390235\n",
      "99 Train Loss 0.5720624 Test MSE 0.5171701504244203 Test RE 0.5195802113501193\n",
      "100 Train Loss 0.5535006 Test MSE 0.5124728401015183 Test RE 0.5172152288711354\n",
      "101 Train Loss 0.53079075 Test MSE 0.4712960931654577 Test RE 0.496001279404755\n",
      "102 Train Loss 0.51261246 Test MSE 0.43421693367270464 Test RE 0.47609021432049947\n",
      "103 Train Loss 0.49432778 Test MSE 0.41441810263491097 Test RE 0.4651095275360141\n",
      "104 Train Loss 0.47237468 Test MSE 0.3446573839249907 Test RE 0.42415996105370446\n",
      "105 Train Loss 0.4541097 Test MSE 0.3199711872239951 Test RE 0.4086874609898608\n",
      "106 Train Loss 0.43437567 Test MSE 0.3201838437109604 Test RE 0.4088232475975884\n",
      "107 Train Loss 0.41300276 Test MSE 0.2825704257305116 Test RE 0.3840601346704076\n",
      "108 Train Loss 0.3904792 Test MSE 0.26304572427687983 Test RE 0.3705539954327053\n",
      "109 Train Loss 0.37311596 Test MSE 0.25551576524459524 Test RE 0.3652117380313402\n",
      "110 Train Loss 0.3570174 Test MSE 0.2515275293868957 Test RE 0.36235031182862953\n",
      "111 Train Loss 0.3427273 Test MSE 0.23939143500830257 Test RE 0.35350062089263007\n",
      "112 Train Loss 0.32250652 Test MSE 0.22560323035721158 Test RE 0.34316938297966737\n",
      "113 Train Loss 0.29932657 Test MSE 0.19939851980213105 Test RE 0.3226241266693539\n",
      "114 Train Loss 0.28022277 Test MSE 0.19243103202925085 Test RE 0.31693735661312233\n",
      "115 Train Loss 0.26969945 Test MSE 0.1809762644590084 Test RE 0.30735953234662816\n",
      "116 Train Loss 0.25413123 Test MSE 0.1598487147224406 Test RE 0.28886202484757195\n",
      "117 Train Loss 0.24283785 Test MSE 0.1467310316773236 Test RE 0.27675588363859494\n",
      "118 Train Loss 0.23050936 Test MSE 0.135340562048048 Test RE 0.26579687142224456\n",
      "119 Train Loss 0.21609464 Test MSE 0.1224839557400476 Test RE 0.25285728986261563\n",
      "120 Train Loss 0.20544857 Test MSE 0.11108472613563111 Test RE 0.24080364209402513\n",
      "121 Train Loss 0.19780582 Test MSE 0.10750681570333248 Test RE 0.23689389907955813\n",
      "122 Train Loss 0.19216809 Test MSE 0.10614944036487751 Test RE 0.2353936436138126\n",
      "123 Train Loss 0.18386388 Test MSE 0.09874364875892881 Test RE 0.2270337708397943\n",
      "124 Train Loss 0.1745838 Test MSE 0.09224030518578054 Test RE 0.21943012094863643\n",
      "125 Train Loss 0.16827519 Test MSE 0.08929959689978202 Test RE 0.21590396900758813\n",
      "126 Train Loss 0.1626538 Test MSE 0.09199083608125913 Test RE 0.2191331894805652\n",
      "127 Train Loss 0.1561229 Test MSE 0.08707632462602766 Test RE 0.21319937233467381\n",
      "128 Train Loss 0.14642222 Test MSE 0.08390269151622042 Test RE 0.20927811904112611\n",
      "129 Train Loss 0.14016339 Test MSE 0.0897053766445864 Test RE 0.21639394970761103\n",
      "130 Train Loss 0.13472192 Test MSE 0.09102086286096749 Test RE 0.21797483169552243\n",
      "131 Train Loss 0.1267895 Test MSE 0.08485586805783471 Test RE 0.21046351393318585\n",
      "132 Train Loss 0.12169785 Test MSE 0.08213384607042877 Test RE 0.20706035624289704\n",
      "133 Train Loss 0.117771834 Test MSE 0.07825268736561357 Test RE 0.20210893213475695\n",
      "134 Train Loss 0.11359334 Test MSE 0.07299066835067644 Test RE 0.19519538573445291\n",
      "135 Train Loss 0.11073112 Test MSE 0.06545756042564836 Test RE 0.18484843778081225\n",
      "136 Train Loss 0.10706372 Test MSE 0.0664268751120554 Test RE 0.18621205297607088\n",
      "137 Train Loss 0.10316639 Test MSE 0.06510570917093496 Test RE 0.18435096437523463\n",
      "138 Train Loss 0.0996246 Test MSE 0.06583209883125254 Test RE 0.18537652106134442\n",
      "139 Train Loss 0.09520991 Test MSE 0.0648720460952676 Test RE 0.18401985107399543\n",
      "140 Train Loss 0.090874776 Test MSE 0.06014743155968617 Test RE 0.17719212651473618\n",
      "141 Train Loss 0.08746805 Test MSE 0.05405337109014951 Test RE 0.16797601308521992\n",
      "142 Train Loss 0.0845122 Test MSE 0.04986068256114628 Test RE 0.16132994531904918\n",
      "143 Train Loss 0.0831418 Test MSE 0.04890583431300533 Test RE 0.15977771758169126\n",
      "144 Train Loss 0.0807695 Test MSE 0.04596003762276414 Test RE 0.15489095756255938\n",
      "145 Train Loss 0.07709008 Test MSE 0.042934825122014894 Test RE 0.14970652377635657\n",
      "146 Train Loss 0.07498245 Test MSE 0.03926727617839448 Test RE 0.14316974959431286\n",
      "147 Train Loss 0.07261671 Test MSE 0.034056153981312676 Test RE 0.13333178007401786\n",
      "148 Train Loss 0.07060553 Test MSE 0.03271869177059862 Test RE 0.1306874373954699\n",
      "149 Train Loss 0.06846766 Test MSE 0.03291378328343926 Test RE 0.13107648284873624\n",
      "150 Train Loss 0.06715052 Test MSE 0.030451963608740428 Test RE 0.126079224239139\n",
      "151 Train Loss 0.06406431 Test MSE 0.02754881139364233 Test RE 0.11991880988364863\n",
      "152 Train Loss 0.0622915 Test MSE 0.030819577823170723 Test RE 0.12683795156553448\n",
      "153 Train Loss 0.059228305 Test MSE 0.02997611560420626 Test RE 0.125090277044198\n",
      "154 Train Loss 0.057216104 Test MSE 0.02537893583907653 Test RE 0.11509927307447318\n",
      "155 Train Loss 0.05421968 Test MSE 0.021565328082095693 Test RE 0.10609964033781193\n",
      "156 Train Loss 0.052925725 Test MSE 0.020633309481802774 Test RE 0.10378159070508951\n",
      "157 Train Loss 0.05144843 Test MSE 0.02008297907942688 Test RE 0.10238820865647003\n",
      "158 Train Loss 0.05045376 Test MSE 0.018501262372563294 Test RE 0.09827353037807898\n",
      "159 Train Loss 0.048745792 Test MSE 0.016867744464081853 Test RE 0.09383489739398651\n",
      "160 Train Loss 0.047394607 Test MSE 0.016297680811209424 Test RE 0.09223564324661188\n",
      "161 Train Loss 0.046509333 Test MSE 0.016110353699975363 Test RE 0.09170402854524759\n",
      "162 Train Loss 0.045348596 Test MSE 0.015608589810333534 Test RE 0.09026465170093428\n",
      "163 Train Loss 0.04344998 Test MSE 0.015944005951907165 Test RE 0.09122935424988778\n",
      "164 Train Loss 0.04183988 Test MSE 0.016485978685914407 Test RE 0.09276694270480287\n",
      "165 Train Loss 0.04047072 Test MSE 0.015546238614590665 Test RE 0.09008418245605297\n",
      "166 Train Loss 0.03892585 Test MSE 0.015205800675690374 Test RE 0.08909237236071725\n",
      "167 Train Loss 0.03771127 Test MSE 0.016480362332373318 Test RE 0.09275113969005552\n",
      "168 Train Loss 0.036652096 Test MSE 0.016923972177251046 Test RE 0.09399116405144745\n",
      "169 Train Loss 0.035590433 Test MSE 0.015061406357515636 Test RE 0.08866835265016175\n",
      "170 Train Loss 0.03489139 Test MSE 0.014453977887277127 Test RE 0.0868619490169947\n",
      "171 Train Loss 0.033995174 Test MSE 0.014100472244997221 Test RE 0.08579316820298871\n",
      "172 Train Loss 0.032326937 Test MSE 0.012844941226301915 Test RE 0.08188454451850305\n",
      "173 Train Loss 0.03125883 Test MSE 0.013166188112009447 Test RE 0.08290217119170833\n",
      "174 Train Loss 0.030549712 Test MSE 0.012631582440334452 Test RE 0.0812016319045843\n",
      "175 Train Loss 0.029951474 Test MSE 0.012276339081819179 Test RE 0.08005165492827498\n",
      "176 Train Loss 0.029133191 Test MSE 0.010941896521984856 Test RE 0.07557570002549187\n",
      "177 Train Loss 0.028419007 Test MSE 0.009863343841586509 Test RE 0.07175430519276775\n",
      "178 Train Loss 0.028001795 Test MSE 0.009025084040959605 Test RE 0.06863750751261026\n",
      "179 Train Loss 0.027384318 Test MSE 0.008149237304688266 Test RE 0.06522203710768651\n",
      "180 Train Loss 0.026759217 Test MSE 0.007578636024805184 Test RE 0.06289721296325378\n",
      "181 Train Loss 0.026213693 Test MSE 0.007453748673509145 Test RE 0.06237682272619197\n",
      "182 Train Loss 0.02539711 Test MSE 0.007514977139708701 Test RE 0.06263249448026811\n",
      "183 Train Loss 0.0247362 Test MSE 0.007614936741799251 Test RE 0.0630476678981047\n",
      "184 Train Loss 0.024048269 Test MSE 0.006883752554719772 Test RE 0.059944384077943\n",
      "185 Train Loss 0.023277856 Test MSE 0.007647484395148866 Test RE 0.06318226294910469\n",
      "186 Train Loss 0.022359021 Test MSE 0.00692766997667377 Test RE 0.06013529864205102\n",
      "187 Train Loss 0.02180688 Test MSE 0.006645802497075232 Test RE 0.05889922660496742\n",
      "188 Train Loss 0.021318667 Test MSE 0.005858740355541134 Test RE 0.05530163897685347\n",
      "189 Train Loss 0.0207269 Test MSE 0.004772961823760846 Test RE 0.049914859987736766\n",
      "190 Train Loss 0.02023138 Test MSE 0.003908154987501151 Test RE 0.045167054131650515\n",
      "191 Train Loss 0.01959606 Test MSE 0.003668228151796238 Test RE 0.04375866325645049\n",
      "192 Train Loss 0.018807942 Test MSE 0.002657365886746514 Test RE 0.03724444908871378\n",
      "193 Train Loss 0.018192902 Test MSE 0.0021219074172280383 Test RE 0.03328120883972971\n",
      "194 Train Loss 0.017771304 Test MSE 0.0023858908524048645 Test RE 0.03529077233306683\n",
      "195 Train Loss 0.017351165 Test MSE 0.0024202349323141892 Test RE 0.0355438640725702\n",
      "196 Train Loss 0.016811555 Test MSE 0.0023319905686675904 Test RE 0.034889863609946926\n",
      "197 Train Loss 0.016270755 Test MSE 0.002089662071070119 Test RE 0.03302736354391834\n",
      "198 Train Loss 0.01584881 Test MSE 0.002212150882499881 Test RE 0.03398155509060973\n",
      "199 Train Loss 0.015635299 Test MSE 0.0020045526441538225 Test RE 0.03234778962865514\n",
      "200 Train Loss 0.015384478 Test MSE 0.0022176548687639188 Test RE 0.03402380307197558\n",
      "201 Train Loss 0.014998451 Test MSE 0.002313931477953523 Test RE 0.03475450632965769\n",
      "202 Train Loss 0.014834251 Test MSE 0.0022508514678568022 Test RE 0.03427751230930098\n",
      "203 Train Loss 0.014599216 Test MSE 0.002178494357750283 Test RE 0.03372205998835465\n",
      "204 Train Loss 0.014202288 Test MSE 0.0019643450568006477 Test RE 0.032021728135969596\n",
      "205 Train Loss 0.013812142 Test MSE 0.0017940873096398994 Test RE 0.030602553371137892\n",
      "206 Train Loss 0.013472553 Test MSE 0.0014570086320648597 Test RE 0.027578264926942733\n",
      "207 Train Loss 0.013076568 Test MSE 0.0017612080465891616 Test RE 0.030320838512328703\n",
      "208 Train Loss 0.012801163 Test MSE 0.0017771040437394618 Test RE 0.030457363354383662\n",
      "209 Train Loss 0.012478608 Test MSE 0.001860319841780073 Test RE 0.03116231304289545\n",
      "210 Train Loss 0.012307134 Test MSE 0.001806175594163644 Test RE 0.03070547794006904\n",
      "211 Train Loss 0.012083561 Test MSE 0.0016327507668277646 Test RE 0.029194149327129014\n",
      "212 Train Loss 0.011912993 Test MSE 0.0014496192548235846 Test RE 0.027508242952824637\n",
      "213 Train Loss 0.011790333 Test MSE 0.0014319852843312278 Test RE 0.027340418271196855\n",
      "214 Train Loss 0.011640558 Test MSE 0.0013438611644058607 Test RE 0.026485798990376015\n",
      "215 Train Loss 0.011505119 Test MSE 0.0013302525679700658 Test RE 0.026351353672253313\n",
      "216 Train Loss 0.011366147 Test MSE 0.001255102739557552 Test RE 0.02559620122107637\n",
      "217 Train Loss 0.011198905 Test MSE 0.0011913473552592967 Test RE 0.024937624395626537\n",
      "218 Train Loss 0.011077576 Test MSE 0.0009870500953243508 Test RE 0.022698934637426695\n",
      "219 Train Loss 0.010958985 Test MSE 0.0008764252433710295 Test RE 0.021389139642420285\n",
      "220 Train Loss 0.010734399 Test MSE 0.000825922221584058 Test RE 0.02076373380066178\n",
      "221 Train Loss 0.010574857 Test MSE 0.0008723008086241143 Test RE 0.021338751920027047\n",
      "222 Train Loss 0.010414383 Test MSE 0.0008063193406181532 Test RE 0.02051584529113763\n",
      "223 Train Loss 0.0103028985 Test MSE 0.0007001031497152041 Test RE 0.019116874657612904\n",
      "224 Train Loss 0.010175905 Test MSE 0.0006026378796801508 Test RE 0.01773634345599179\n",
      "225 Train Loss 0.010089045 Test MSE 0.0005710412974552698 Test RE 0.01726512136550836\n",
      "226 Train Loss 0.010006062 Test MSE 0.0005357333503959191 Test RE 0.01672284707576333\n",
      "227 Train Loss 0.009929877 Test MSE 0.00047305951547248697 Test RE 0.01571425398377293\n",
      "228 Train Loss 0.00985464 Test MSE 0.00044420892226442084 Test RE 0.015227531817021628\n",
      "229 Train Loss 0.009791415 Test MSE 0.0004426938578083368 Test RE 0.01520154134667295\n",
      "230 Train Loss 0.009660431 Test MSE 0.00037856690069307974 Test RE 0.014057471013416022\n",
      "231 Train Loss 0.009539132 Test MSE 0.00035303704782820966 Test RE 0.0135751931741839\n",
      "232 Train Loss 0.009451912 Test MSE 0.000371607110056161 Test RE 0.013927651277847446\n",
      "233 Train Loss 0.009365576 Test MSE 0.00036089781919410366 Test RE 0.013725494679142174\n",
      "234 Train Loss 0.009273864 Test MSE 0.0003357601268519845 Test RE 0.013238855350557362\n",
      "235 Train Loss 0.009126693 Test MSE 0.00033095264718203927 Test RE 0.013143735366241366\n",
      "236 Train Loss 0.008989919 Test MSE 0.0003183024744995125 Test RE 0.01289008806096544\n",
      "237 Train Loss 0.008858556 Test MSE 0.0003346992450164779 Test RE 0.013217923780985219\n",
      "238 Train Loss 0.008763573 Test MSE 0.0003222094603561794 Test RE 0.012968956114904628\n",
      "239 Train Loss 0.008689165 Test MSE 0.00031521026412445626 Test RE 0.01282732363959397\n",
      "240 Train Loss 0.008625993 Test MSE 0.00030261346587707506 Test RE 0.012568400221664422\n",
      "241 Train Loss 0.008531577 Test MSE 0.00026930255378634335 Test RE 0.011856489275561113\n",
      "242 Train Loss 0.00844012 Test MSE 0.0002571371455058802 Test RE 0.011585593490616672\n",
      "243 Train Loss 0.008392311 Test MSE 0.00025595941293289837 Test RE 0.011559031030157292\n",
      "244 Train Loss 0.008297113 Test MSE 0.0002558003107930055 Test RE 0.011555437975253189\n",
      "245 Train Loss 0.008229083 Test MSE 0.00024711298412761606 Test RE 0.011357523903571871\n",
      "246 Train Loss 0.008163267 Test MSE 0.0002443559199740139 Test RE 0.011293987674293841\n",
      "247 Train Loss 0.008051633 Test MSE 0.0002455924504872751 Test RE 0.011322527472874737\n",
      "248 Train Loss 0.007986373 Test MSE 0.00025970141445577123 Test RE 0.01164321814520119\n",
      "249 Train Loss 0.007941367 Test MSE 0.0002866713503704244 Test RE 0.0122328604941914\n",
      "250 Train Loss 0.007875671 Test MSE 0.0002832536737994977 Test RE 0.012159722182774009\n",
      "251 Train Loss 0.007791932 Test MSE 0.0002729853949124389 Test RE 0.011937285560211758\n",
      "252 Train Loss 0.007682666 Test MSE 0.00025974742791458203 Test RE 0.011644249562398488\n",
      "253 Train Loss 0.0076129753 Test MSE 0.00025702277363540686 Test RE 0.011583016629595573\n",
      "254 Train Loss 0.007539154 Test MSE 0.0002530210254692036 Test RE 0.011492491273982641\n",
      "255 Train Loss 0.0074627325 Test MSE 0.0002537853157638072 Test RE 0.011509835635897313\n",
      "256 Train Loss 0.007369262 Test MSE 0.0002651493256032798 Test RE 0.011764707671083102\n",
      "257 Train Loss 0.0072756866 Test MSE 0.00026774271537108074 Test RE 0.011822102179548828\n",
      "258 Train Loss 0.007173584 Test MSE 0.00029277554219900407 Test RE 0.012362413727982443\n",
      "259 Train Loss 0.0070717027 Test MSE 0.00030945956510260175 Test RE 0.01270977412151656\n",
      "260 Train Loss 0.0070079183 Test MSE 0.00031155825368038565 Test RE 0.012752798783510585\n",
      "261 Train Loss 0.0069111087 Test MSE 0.0002899035204782628 Test RE 0.012301628897257132\n",
      "262 Train Loss 0.0067636673 Test MSE 0.00027114720890763236 Test RE 0.011897026968450252\n",
      "263 Train Loss 0.006662788 Test MSE 0.00025806522637003603 Test RE 0.01160648250488365\n",
      "264 Train Loss 0.006560268 Test MSE 0.00027795562196872807 Test RE 0.012045466057466628\n",
      "265 Train Loss 0.0064525977 Test MSE 0.00025322147668795905 Test RE 0.011497042729333166\n",
      "266 Train Loss 0.0063860305 Test MSE 0.0002527407552741276 Test RE 0.011486124421204216\n",
      "267 Train Loss 0.0063158832 Test MSE 0.0002525902145052277 Test RE 0.011482703153513008\n",
      "268 Train Loss 0.0062559503 Test MSE 0.00026985772819226986 Test RE 0.011868704218069862\n",
      "269 Train Loss 0.0062114215 Test MSE 0.00027212042589782573 Test RE 0.011918358587491483\n",
      "270 Train Loss 0.006160245 Test MSE 0.0002667762517334713 Test RE 0.011800745928622286\n",
      "271 Train Loss 0.00612141 Test MSE 0.0002690339363277366 Test RE 0.011850574636880178\n",
      "272 Train Loss 0.0060652373 Test MSE 0.0002843938940471486 Test RE 0.01218417170946423\n",
      "273 Train Loss 0.006021104 Test MSE 0.00026433441233141247 Test RE 0.01174661485846027\n",
      "274 Train Loss 0.0059815287 Test MSE 0.00027327970173651836 Test RE 0.011943718648338373\n",
      "275 Train Loss 0.0059386264 Test MSE 0.00026619182533102925 Test RE 0.011787812901942571\n",
      "276 Train Loss 0.005883427 Test MSE 0.00026276894258513427 Test RE 0.011711779671422316\n",
      "277 Train Loss 0.0058394596 Test MSE 0.00026643965785489777 Test RE 0.011793299027890815\n",
      "278 Train Loss 0.0058164154 Test MSE 0.00027038110960755826 Test RE 0.011880208150602957\n",
      "279 Train Loss 0.0057839477 Test MSE 0.00026827148387025695 Test RE 0.01183377023163814\n",
      "280 Train Loss 0.005764126 Test MSE 0.0002565326709567857 Test RE 0.011571967849351942\n",
      "281 Train Loss 0.00573762 Test MSE 0.0002494818104454701 Test RE 0.011411830708496365\n",
      "282 Train Loss 0.0057022404 Test MSE 0.00025618693962798636 Test RE 0.011564167399040665\n",
      "283 Train Loss 0.0056570973 Test MSE 0.0002646063756280475 Test RE 0.011752656120329066\n",
      "284 Train Loss 0.005623687 Test MSE 0.00025270378772709775 Test RE 0.011485284371936896\n",
      "285 Train Loss 0.0055908947 Test MSE 0.0002595691207365737 Test RE 0.011640252199004665\n",
      "286 Train Loss 0.0055491603 Test MSE 0.00024839526578164577 Test RE 0.01138695315575554\n",
      "287 Train Loss 0.0055161957 Test MSE 0.00023774184664554333 Test RE 0.01114008982756201\n",
      "288 Train Loss 0.0054759937 Test MSE 0.0002184325616087486 Test RE 0.010678114325464148\n",
      "289 Train Loss 0.005428449 Test MSE 0.00020578517953313117 Test RE 0.01036437036632445\n",
      "290 Train Loss 0.00538606 Test MSE 0.00021136307505329754 Test RE 0.010503896559733801\n",
      "291 Train Loss 0.0053635407 Test MSE 0.00020571685348507983 Test RE 0.010362649602806294\n",
      "292 Train Loss 0.005339273 Test MSE 0.00021656720202663845 Test RE 0.010632422350596795\n",
      "293 Train Loss 0.0053058644 Test MSE 0.00023985806977416802 Test RE 0.011189560894905028\n",
      "294 Train Loss 0.005275772 Test MSE 0.0002523893797395458 Test RE 0.011478137290609485\n",
      "295 Train Loss 0.0052512405 Test MSE 0.0002555314683781248 Test RE 0.01154936408012071\n",
      "296 Train Loss 0.005224775 Test MSE 0.0002783921156436936 Test RE 0.012054920277468862\n",
      "297 Train Loss 0.005198071 Test MSE 0.00026723927662276756 Test RE 0.01181098235373384\n",
      "298 Train Loss 0.0051747495 Test MSE 0.0002544792106200091 Test RE 0.011525559878960293\n",
      "299 Train Loss 0.0051465253 Test MSE 0.00025439177084431787 Test RE 0.011523579601370957\n",
      "Training time: 251.74\n",
      "KG_atanh_high\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 63382.49 Test MSE 3.324885415360775 Test RE 1.317419897146048\n",
      "1 Train Loss 35853.566 Test MSE 7.1051292645045585 Test RE 1.9258473869457329\n",
      "2 Train Loss 20743.904 Test MSE 8.982876254578745 Test RE 2.165427188708578\n",
      "3 Train Loss 7459.0107 Test MSE 6.954068812987706 Test RE 1.9052649094055436\n",
      "4 Train Loss 3183.9412 Test MSE 14.696690621562798 Test RE 2.76978241008539\n",
      "5 Train Loss 1658.063 Test MSE 17.71871848269725 Test RE 3.0412493626793466\n",
      "6 Train Loss 917.34064 Test MSE 19.376382334023212 Test RE 3.1803302829256945\n",
      "7 Train Loss 533.6505 Test MSE 20.482883222169963 Test RE 3.2698770367709598\n",
      "8 Train Loss 368.05743 Test MSE 20.737014031704692 Test RE 3.2900991626750766\n",
      "9 Train Loss 266.61465 Test MSE 19.588277298431464 Test RE 3.1976726221542333\n",
      "10 Train Loss 196.20073 Test MSE 18.8379867091439 Test RE 3.1358343997877354\n",
      "11 Train Loss 143.50237 Test MSE 17.9431695552205 Test RE 3.0604511894965283\n",
      "12 Train Loss 108.98936 Test MSE 17.715077079213728 Test RE 3.0409368404991106\n",
      "13 Train Loss 83.32333 Test MSE 16.81578865275623 Test RE 2.962746522623643\n",
      "14 Train Loss 64.62736 Test MSE 16.425584590417596 Test RE 2.9281700514402096\n",
      "15 Train Loss 54.102264 Test MSE 16.323570693967056 Test RE 2.9190629391704053\n",
      "16 Train Loss 44.341564 Test MSE 16.498190157324895 Test RE 2.9346345709868173\n",
      "17 Train Loss 39.654022 Test MSE 16.40964186915705 Test RE 2.9267486611742606\n",
      "18 Train Loss 36.037212 Test MSE 16.51007909782028 Test RE 2.935691760053023\n",
      "19 Train Loss 33.8666 Test MSE 16.567026870083446 Test RE 2.940750403005825\n",
      "20 Train Loss 31.459352 Test MSE 16.41675768324423 Test RE 2.9273831644211925\n",
      "21 Train Loss 30.209843 Test MSE 16.494258355170288 Test RE 2.9342848632324827\n",
      "22 Train Loss 29.165676 Test MSE 16.49859896566456 Test RE 2.934670929388656\n",
      "23 Train Loss 27.812859 Test MSE 16.418391302695742 Test RE 2.9275288116680045\n",
      "24 Train Loss 26.956312 Test MSE 16.398143030314746 Test RE 2.9257230413220046\n",
      "25 Train Loss 26.282192 Test MSE 16.423867179564077 Test RE 2.928016967010931\n",
      "26 Train Loss 25.7852 Test MSE 16.37771840627358 Test RE 2.9239004138422615\n",
      "27 Train Loss 25.288807 Test MSE 16.28859092765047 Test RE 2.9159336330295496\n",
      "28 Train Loss 24.85973 Test MSE 16.20190554617984 Test RE 2.9081642066403086\n",
      "29 Train Loss 24.356369 Test MSE 16.110728031565504 Test RE 2.8999696986486603\n",
      "30 Train Loss 23.937792 Test MSE 16.150450727999928 Test RE 2.9035425880013577\n",
      "31 Train Loss 23.364485 Test MSE 16.08057991995665 Test RE 2.8972550618639716\n",
      "32 Train Loss 23.130777 Test MSE 16.051487921431278 Test RE 2.894633107412704\n",
      "33 Train Loss 22.691086 Test MSE 16.1180355688453 Test RE 2.9006273112081264\n",
      "34 Train Loss 22.44321 Test MSE 16.139363572077443 Test RE 2.9025457874558733\n",
      "35 Train Loss 22.15615 Test MSE 16.090073466455927 Test RE 2.898110166822764\n",
      "36 Train Loss 21.76223 Test MSE 16.06972607277062 Test RE 2.8962771222636485\n",
      "37 Train Loss 21.503016 Test MSE 16.1090706981915 Test RE 2.899820532820533\n",
      "38 Train Loss 21.27065 Test MSE 16.08947123621216 Test RE 2.8980559300932818\n",
      "39 Train Loss 21.049252 Test MSE 16.081212601344106 Test RE 2.8973120567401467\n",
      "40 Train Loss 20.844162 Test MSE 16.118982170133094 Test RE 2.9007124858940805\n",
      "41 Train Loss 20.688175 Test MSE 16.10019524633741 Test RE 2.899021580353709\n",
      "42 Train Loss 20.458555 Test MSE 16.092437985285795 Test RE 2.89832310507739\n",
      "43 Train Loss 20.352497 Test MSE 16.070270292429445 Test RE 2.8963261647176197\n",
      "44 Train Loss 20.10456 Test MSE 16.016285905753268 Test RE 2.8914573006398827\n",
      "45 Train Loss 19.953136 Test MSE 16.019443907036113 Test RE 2.8917423472434423\n",
      "46 Train Loss 19.777216 Test MSE 16.002829032359294 Test RE 2.890242345077861\n",
      "47 Train Loss 19.629091 Test MSE 15.957778119012232 Test RE 2.8861711953356504\n",
      "48 Train Loss 19.501604 Test MSE 15.926936138642654 Test RE 2.883380760264757\n",
      "49 Train Loss 19.307003 Test MSE 15.834048978261881 Test RE 2.8749604121276486\n",
      "50 Train Loss 19.18945 Test MSE 15.857771779753298 Test RE 2.87711325973521\n",
      "51 Train Loss 19.039589 Test MSE 15.816848460533338 Test RE 2.8733984539544637\n",
      "52 Train Loss 18.904697 Test MSE 15.713020755811739 Test RE 2.8639518950622\n",
      "53 Train Loss 18.752672 Test MSE 15.604814451415345 Test RE 2.8540736857446185\n",
      "54 Train Loss 18.582626 Test MSE 15.552894706816645 Test RE 2.8493217471749412\n",
      "55 Train Loss 18.465082 Test MSE 15.506693215319233 Test RE 2.8450864962077786\n",
      "56 Train Loss 18.317516 Test MSE 15.486876524607089 Test RE 2.843267983950866\n",
      "57 Train Loss 18.190908 Test MSE 15.475469632516225 Test RE 2.8422206835043013\n",
      "58 Train Loss 17.909622 Test MSE 15.387784749661522 Test RE 2.834157153911106\n",
      "59 Train Loss 17.697294 Test MSE 15.26563729766796 Test RE 2.8228860443684916\n",
      "60 Train Loss 17.592726 Test MSE 15.199984312089411 Test RE 2.8168093052808474\n",
      "61 Train Loss 17.462284 Test MSE 15.195636812471182 Test RE 2.8164064445637274\n",
      "62 Train Loss 17.267618 Test MSE 15.157446207553125 Test RE 2.812865035474995\n",
      "63 Train Loss 17.111885 Test MSE 15.12558850240765 Test RE 2.8099074607213415\n",
      "64 Train Loss 16.956991 Test MSE 15.118306383165098 Test RE 2.8092309731713105\n",
      "65 Train Loss 16.83825 Test MSE 15.075211602527329 Test RE 2.8052242549115616\n",
      "66 Train Loss 16.767233 Test MSE 15.057401359739996 Test RE 2.8035666831437256\n",
      "67 Train Loss 16.694677 Test MSE 15.019933819438581 Test RE 2.8000764336832114\n",
      "68 Train Loss 16.625706 Test MSE 14.992751426966443 Test RE 2.797541560858762\n",
      "69 Train Loss 16.535984 Test MSE 14.954456399896468 Test RE 2.7939664856668265\n",
      "70 Train Loss 16.435228 Test MSE 14.903014988347698 Test RE 2.789156902876711\n",
      "71 Train Loss 16.371119 Test MSE 14.874971626877416 Test RE 2.7865314554150276\n",
      "72 Train Loss 16.236187 Test MSE 14.793669972674135 Test RE 2.7789058937459017\n",
      "73 Train Loss 16.16104 Test MSE 14.784644008053752 Test RE 2.7780580266067845\n",
      "74 Train Loss 16.055292 Test MSE 14.698500158538943 Test RE 2.769952920220921\n",
      "75 Train Loss 15.870331 Test MSE 14.59202790003376 Test RE 2.759902262985424\n",
      "76 Train Loss 15.772256 Test MSE 14.552201491094005 Test RE 2.756133352341853\n",
      "77 Train Loss 15.65816 Test MSE 14.427310735714963 Test RE 2.7442809429474555\n",
      "78 Train Loss 15.505949 Test MSE 14.305440053924778 Test RE 2.73266558779367\n",
      "79 Train Loss 15.317804 Test MSE 14.168796130977455 Test RE 2.7195832183452295\n",
      "80 Train Loss 15.106894 Test MSE 13.829468888407133 Test RE 2.686820342104084\n",
      "81 Train Loss 14.807088 Test MSE 13.494177034131482 Test RE 2.654049867417747\n",
      "82 Train Loss 14.48811 Test MSE 13.098848021171088 Test RE 2.6148840050074313\n",
      "83 Train Loss 14.059307 Test MSE 12.84783411477308 Test RE 2.589708231275055\n",
      "84 Train Loss 13.24404 Test MSE 12.200880475471276 Test RE 2.523663596995207\n",
      "85 Train Loss 12.662886 Test MSE 11.962745870368938 Test RE 2.4989140299193413\n",
      "86 Train Loss 12.232667 Test MSE 11.69505966537843 Test RE 2.4707971846122136\n",
      "87 Train Loss 11.778595 Test MSE 11.612307636387985 Test RE 2.4620402198068563\n",
      "88 Train Loss 11.461159 Test MSE 11.473472309063531 Test RE 2.4472780378127217\n",
      "89 Train Loss 11.0455065 Test MSE 11.313196190244355 Test RE 2.4301245686960984\n",
      "90 Train Loss 10.716557 Test MSE 11.157567458880237 Test RE 2.413351815968541\n",
      "91 Train Loss 10.423252 Test MSE 10.980692511222124 Test RE 2.394146611853634\n",
      "92 Train Loss 10.123664 Test MSE 10.791014523152072 Test RE 2.3733785631708453\n",
      "93 Train Loss 9.637032 Test MSE 10.570979995042226 Test RE 2.3490567148643478\n",
      "94 Train Loss 9.396007 Test MSE 10.284337919552778 Test RE 2.316989394734213\n",
      "95 Train Loss 9.191928 Test MSE 10.204755097574445 Test RE 2.308007257916365\n",
      "96 Train Loss 8.849244 Test MSE 9.860591486989817 Test RE 2.268753750511399\n",
      "97 Train Loss 8.632276 Test MSE 9.676731656355848 Test RE 2.2475027191211057\n",
      "98 Train Loss 8.263797 Test MSE 9.425662334991896 Test RE 2.2181546179766864\n",
      "99 Train Loss 8.080661 Test MSE 9.338292299821457 Test RE 2.207850225794689\n",
      "100 Train Loss 7.8470454 Test MSE 9.25194659276915 Test RE 2.1976191732531003\n",
      "101 Train Loss 7.6193676 Test MSE 9.042403015981701 Test RE 2.172590151994211\n",
      "102 Train Loss 7.4051714 Test MSE 8.969267443903812 Test RE 2.163786285649938\n",
      "103 Train Loss 7.1513004 Test MSE 8.698449885737274 Test RE 2.130869286807891\n",
      "104 Train Loss 6.941056 Test MSE 8.525125480495898 Test RE 2.109532724882957\n",
      "105 Train Loss 6.666119 Test MSE 8.14285549101757 Test RE 2.0616941597011955\n",
      "106 Train Loss 6.39342 Test MSE 7.788625881642864 Test RE 2.0163517598646967\n",
      "107 Train Loss 6.08628 Test MSE 7.58142277938092 Test RE 1.9893501674222647\n",
      "108 Train Loss 5.7548103 Test MSE 7.513406134948533 Test RE 1.9804063466809492\n",
      "109 Train Loss 5.484704 Test MSE 7.151200992995995 Test RE 1.9320811756605136\n",
      "110 Train Loss 5.188327 Test MSE 6.829356045650332 Test RE 1.8881033136380232\n",
      "111 Train Loss 4.927535 Test MSE 6.536363387018167 Test RE 1.8471576853870806\n",
      "112 Train Loss 4.794028 Test MSE 6.42597906564852 Test RE 1.8314941258381452\n",
      "113 Train Loss 4.6597857 Test MSE 6.313327790171742 Test RE 1.815369548555522\n",
      "114 Train Loss 4.4744883 Test MSE 6.321441804855349 Test RE 1.8165357485296012\n",
      "115 Train Loss 4.321551 Test MSE 6.208312877406485 Test RE 1.8002079478442274\n",
      "116 Train Loss 4.179267 Test MSE 6.163098014643233 Test RE 1.793640551822975\n",
      "117 Train Loss 4.067536 Test MSE 6.018699864548239 Test RE 1.772503985244727\n",
      "118 Train Loss 3.9233513 Test MSE 5.81134125556386 Test RE 1.7417028656114326\n",
      "119 Train Loss 3.762662 Test MSE 5.6279241679948 Test RE 1.7139967551374764\n",
      "120 Train Loss 3.6343157 Test MSE 5.4634523064628455 Test RE 1.6887659155838706\n",
      "121 Train Loss 3.4916198 Test MSE 5.243588013245347 Test RE 1.6544367095896833\n",
      "122 Train Loss 3.3626304 Test MSE 5.157601043029534 Test RE 1.6408154979502994\n",
      "123 Train Loss 3.2488613 Test MSE 5.022273755304385 Test RE 1.619146210406134\n",
      "124 Train Loss 3.1013713 Test MSE 4.866880353160043 Test RE 1.5939005179550305\n",
      "125 Train Loss 2.9463208 Test MSE 4.611652641579992 Test RE 1.5515442668475141\n",
      "126 Train Loss 2.847672 Test MSE 4.44522528470319 Test RE 1.5232906096649952\n",
      "127 Train Loss 2.7397475 Test MSE 4.308713039174976 Test RE 1.4997182015624013\n",
      "128 Train Loss 2.6343567 Test MSE 4.268434736013379 Test RE 1.4926919807158716\n",
      "129 Train Loss 2.5540738 Test MSE 4.068515622890481 Test RE 1.4573164624364254\n",
      "130 Train Loss 2.430652 Test MSE 3.675535602764005 Test RE 1.3851480463771755\n",
      "131 Train Loss 2.3402388 Test MSE 3.4966783244505413 Test RE 1.3510260331362203\n",
      "132 Train Loss 2.252566 Test MSE 3.104482592632056 Test RE 1.2730061196168452\n",
      "133 Train Loss 2.1871936 Test MSE 2.9610831795466317 Test RE 1.243257765456154\n",
      "134 Train Loss 2.0427396 Test MSE 2.6504024547355365 Test RE 1.176228747286578\n",
      "135 Train Loss 1.9445227 Test MSE 2.4320291661614233 Test RE 1.1267310597515539\n",
      "136 Train Loss 1.7836835 Test MSE 2.177576591922728 Test RE 1.0661605201452784\n",
      "137 Train Loss 1.7138368 Test MSE 2.082750805239143 Test RE 1.0426883769890667\n",
      "138 Train Loss 1.620398 Test MSE 1.9052154486995183 Test RE 0.9972589074511585\n",
      "139 Train Loss 1.5652659 Test MSE 1.8504963064249926 Test RE 0.9828335840616756\n",
      "140 Train Loss 1.4846797 Test MSE 1.689020051110255 Test RE 0.9389733787091533\n",
      "141 Train Loss 1.4236193 Test MSE 1.532640883826031 Test RE 0.8944500240394948\n",
      "142 Train Loss 1.3499007 Test MSE 1.3933559268255906 Test RE 0.8528387236466883\n",
      "143 Train Loss 1.2901645 Test MSE 1.3432497346968388 Test RE 0.8373639477140629\n",
      "144 Train Loss 1.2017467 Test MSE 1.25690881552217 Test RE 0.8100051180817235\n",
      "145 Train Loss 1.1405338 Test MSE 1.193875138137525 Test RE 0.789433098470041\n",
      "146 Train Loss 1.0845962 Test MSE 1.1195780668327053 Test RE 0.7644746130787473\n",
      "147 Train Loss 1.0428339 Test MSE 1.055403073020979 Test RE 0.7422411944863679\n",
      "148 Train Loss 1.0147095 Test MSE 1.0342519055237602 Test RE 0.7347659828548713\n",
      "149 Train Loss 0.9749703 Test MSE 0.9648826018961327 Test RE 0.7096972374036656\n",
      "150 Train Loss 0.95208925 Test MSE 0.9382896269423402 Test RE 0.6998489807616175\n",
      "151 Train Loss 0.91764003 Test MSE 0.9247240996524699 Test RE 0.6947714517980516\n",
      "152 Train Loss 0.8788996 Test MSE 0.9275493226518617 Test RE 0.6958319774820989\n",
      "153 Train Loss 0.85393906 Test MSE 0.8755139777646483 Test RE 0.6760322570901793\n",
      "154 Train Loss 0.8221926 Test MSE 0.8860019512016002 Test RE 0.6800693718496502\n",
      "155 Train Loss 0.7801607 Test MSE 0.8174860681804601 Test RE 0.6532449437885398\n",
      "156 Train Loss 0.7590954 Test MSE 0.7667859902176155 Test RE 0.6326637650972478\n",
      "157 Train Loss 0.7357371 Test MSE 0.7181660445051087 Test RE 0.6122775146211652\n",
      "158 Train Loss 0.7184842 Test MSE 0.6874084855681917 Test RE 0.5990227565837485\n",
      "159 Train Loss 0.69018304 Test MSE 0.6519470180698793 Test RE 0.583367228732372\n",
      "160 Train Loss 0.67289585 Test MSE 0.6353384440080543 Test RE 0.5758885507887426\n",
      "161 Train Loss 0.6439064 Test MSE 0.5556195977701001 Test RE 0.5385482943481908\n",
      "162 Train Loss 0.6221868 Test MSE 0.539515990307436 Test RE 0.5306864969451706\n",
      "163 Train Loss 0.5983308 Test MSE 0.5191964782857443 Test RE 0.5205971016213917\n",
      "164 Train Loss 0.57614404 Test MSE 0.5057902890265358 Test RE 0.513831967931777\n",
      "165 Train Loss 0.5622871 Test MSE 0.48750204893878063 Test RE 0.5044569381509145\n",
      "166 Train Loss 0.5425559 Test MSE 0.4229404062496897 Test RE 0.4698675642178121\n",
      "167 Train Loss 0.5158371 Test MSE 0.3863383122785351 Test RE 0.4490759176620937\n",
      "168 Train Loss 0.4827448 Test MSE 0.3634755101998241 Test RE 0.4355855401266259\n",
      "169 Train Loss 0.44986868 Test MSE 0.3235597638215906 Test RE 0.4109728496498165\n",
      "170 Train Loss 0.4368052 Test MSE 0.3223887365071024 Test RE 0.4102284791803523\n",
      "171 Train Loss 0.41491154 Test MSE 0.2809384464204323 Test RE 0.38294946323202944\n",
      "172 Train Loss 0.3904979 Test MSE 0.2520653163253992 Test RE 0.3627374726612952\n",
      "173 Train Loss 0.3806147 Test MSE 0.2439464521657339 Test RE 0.3568478874472874\n",
      "174 Train Loss 0.36758962 Test MSE 0.23438605439074517 Test RE 0.3497854667708526\n",
      "175 Train Loss 0.35066223 Test MSE 0.22831418308876242 Test RE 0.3452250669000107\n",
      "176 Train Loss 0.33704317 Test MSE 0.22306260091289215 Test RE 0.34123161199568014\n",
      "177 Train Loss 0.32591805 Test MSE 0.21929668361270357 Test RE 0.33833888120175304\n",
      "178 Train Loss 0.31083262 Test MSE 0.21124480898895054 Test RE 0.33206943230926744\n",
      "179 Train Loss 0.29544675 Test MSE 0.19612651354203336 Test RE 0.31996614652539723\n",
      "180 Train Loss 0.28619194 Test MSE 0.18889559124531463 Test RE 0.31401239245064094\n",
      "181 Train Loss 0.27290937 Test MSE 0.18997888222849826 Test RE 0.3149115147694651\n",
      "182 Train Loss 0.2639568 Test MSE 0.18031004653028795 Test RE 0.3067932778989215\n",
      "183 Train Loss 0.25369352 Test MSE 0.1687047260140636 Test RE 0.29675599506538697\n",
      "184 Train Loss 0.2487256 Test MSE 0.16185863762539934 Test RE 0.2906724138546152\n",
      "185 Train Loss 0.23821938 Test MSE 0.13991207311929946 Test RE 0.2702486124104635\n",
      "186 Train Loss 0.23074202 Test MSE 0.14272076910155954 Test RE 0.272947716669453\n",
      "187 Train Loss 0.22496402 Test MSE 0.13925758795007753 Test RE 0.2696157826750965\n",
      "188 Train Loss 0.2200368 Test MSE 0.13379360207703925 Test RE 0.26427345955905696\n",
      "189 Train Loss 0.21557556 Test MSE 0.12834376898896083 Test RE 0.25883516059868344\n",
      "190 Train Loss 0.20841296 Test MSE 0.1268025173339394 Test RE 0.2572763197053563\n",
      "191 Train Loss 0.20253295 Test MSE 0.1305429850796576 Test RE 0.26104335744805923\n",
      "192 Train Loss 0.1958839 Test MSE 0.128726646880565 Test RE 0.25922095439446247\n",
      "193 Train Loss 0.18834066 Test MSE 0.1262539467423534 Test RE 0.2567192045944612\n",
      "194 Train Loss 0.18132056 Test MSE 0.11388344213706997 Test RE 0.24381822738680137\n",
      "195 Train Loss 0.17802249 Test MSE 0.11224229713528593 Test RE 0.2420550512752013\n",
      "196 Train Loss 0.17195547 Test MSE 0.10977617222715316 Test RE 0.23938113321284\n",
      "197 Train Loss 0.16749199 Test MSE 0.10649226337463541 Test RE 0.23577345393465038\n",
      "198 Train Loss 0.16110441 Test MSE 0.09743910267150677 Test RE 0.2255290626124909\n",
      "199 Train Loss 0.15317595 Test MSE 0.09250808290889095 Test RE 0.21974839784073394\n",
      "200 Train Loss 0.14565693 Test MSE 0.08684650304612929 Test RE 0.21291783662643662\n",
      "201 Train Loss 0.14096656 Test MSE 0.08157957099067123 Test RE 0.20636050664435265\n",
      "202 Train Loss 0.13385859 Test MSE 0.07976581434293542 Test RE 0.2040536081661483\n",
      "203 Train Loss 0.12757684 Test MSE 0.07276873640405129 Test RE 0.19489840892689375\n",
      "204 Train Loss 0.12373238 Test MSE 0.07145609396839352 Test RE 0.19313256710719798\n",
      "205 Train Loss 0.12023451 Test MSE 0.06615575912888909 Test RE 0.18583165963516254\n",
      "206 Train Loss 0.11443345 Test MSE 0.06731917314161606 Test RE 0.18745855431657385\n",
      "207 Train Loss 0.10906464 Test MSE 0.0671573036573058 Test RE 0.18723304588746606\n",
      "208 Train Loss 0.10490043 Test MSE 0.06301835144948364 Test RE 0.1813716466192614\n",
      "209 Train Loss 0.102144256 Test MSE 0.057893956265759834 Test RE 0.17384111196016633\n",
      "210 Train Loss 0.10044529 Test MSE 0.05625099753416731 Test RE 0.17135666103089972\n",
      "211 Train Loss 0.097676866 Test MSE 0.051566556219393454 Test RE 0.1640665105097161\n",
      "212 Train Loss 0.095327824 Test MSE 0.0499725488962587 Test RE 0.16151082208865786\n",
      "213 Train Loss 0.09285119 Test MSE 0.04986775456730784 Test RE 0.16134138605607576\n",
      "214 Train Loss 0.08967971 Test MSE 0.048831323784353994 Test RE 0.15965595644272343\n",
      "215 Train Loss 0.08766398 Test MSE 0.05131352877686226 Test RE 0.16366349368578265\n",
      "216 Train Loss 0.085715696 Test MSE 0.04975506379987059 Test RE 0.16115898393969844\n",
      "217 Train Loss 0.0835276 Test MSE 0.050195828474173594 Test RE 0.16187123872726897\n",
      "218 Train Loss 0.08087334 Test MSE 0.048787045431999736 Test RE 0.15958355510874087\n",
      "219 Train Loss 0.07988691 Test MSE 0.048037350816945316 Test RE 0.1583526739433458\n",
      "220 Train Loss 0.07787299 Test MSE 0.046246664766092405 Test RE 0.1553731911700807\n",
      "221 Train Loss 0.07584867 Test MSE 0.04461823122695774 Test RE 0.15261318350255976\n",
      "222 Train Loss 0.07400044 Test MSE 0.04197152378580434 Test RE 0.14801756151040837\n",
      "223 Train Loss 0.07117228 Test MSE 0.040571135424777235 Test RE 0.14552729532878214\n",
      "224 Train Loss 0.06706062 Test MSE 0.04442821188937984 Test RE 0.15228786359686836\n",
      "225 Train Loss 0.06514875 Test MSE 0.04247528590918769 Test RE 0.14890320043988753\n",
      "226 Train Loss 0.063737094 Test MSE 0.04193172699445685 Test RE 0.147947370813321\n",
      "227 Train Loss 0.06257753 Test MSE 0.04139772836210648 Test RE 0.14700230080404406\n",
      "228 Train Loss 0.06084733 Test MSE 0.04029908582980742 Test RE 0.14503855828069118\n",
      "229 Train Loss 0.06006385 Test MSE 0.040690562468410775 Test RE 0.14574132832533104\n",
      "230 Train Loss 0.05912796 Test MSE 0.040208239309153695 Test RE 0.14487498530727466\n",
      "231 Train Loss 0.057238188 Test MSE 0.03820637798232611 Test RE 0.14122247252336895\n",
      "232 Train Loss 0.05592364 Test MSE 0.03783660677983328 Test RE 0.1405374171600023\n",
      "233 Train Loss 0.055027243 Test MSE 0.03739291495961303 Test RE 0.13971097961438306\n",
      "234 Train Loss 0.053879596 Test MSE 0.03578029445510954 Test RE 0.13666516563145348\n",
      "235 Train Loss 0.052634902 Test MSE 0.03588298485637428 Test RE 0.13686114145701062\n",
      "236 Train Loss 0.051475957 Test MSE 0.03643282556272133 Test RE 0.13790572764120604\n",
      "237 Train Loss 0.050917916 Test MSE 0.036277128047230114 Test RE 0.13761073860382775\n",
      "238 Train Loss 0.05061263 Test MSE 0.03572841684841332 Test RE 0.13656605474416125\n",
      "239 Train Loss 0.049977828 Test MSE 0.03467447328461127 Test RE 0.13453671314403062\n",
      "240 Train Loss 0.049305446 Test MSE 0.03407262772343077 Test RE 0.13336402399394773\n",
      "241 Train Loss 0.048298743 Test MSE 0.03435326248569606 Test RE 0.1339121154476413\n",
      "242 Train Loss 0.047669385 Test MSE 0.03422020478903161 Test RE 0.13365252839346822\n",
      "243 Train Loss 0.046991315 Test MSE 0.03239945628532993 Test RE 0.1300483175198789\n",
      "244 Train Loss 0.04651711 Test MSE 0.03179880094447718 Test RE 0.12883719144257513\n",
      "245 Train Loss 0.046114355 Test MSE 0.031151865399310256 Test RE 0.12751988304433695\n",
      "246 Train Loss 0.045639567 Test MSE 0.030383525491813064 Test RE 0.12593746855014307\n",
      "247 Train Loss 0.04460911 Test MSE 0.028202497438255477 Test RE 0.12133320263612744\n",
      "248 Train Loss 0.043676496 Test MSE 0.026582471152582783 Test RE 0.11779681619338266\n",
      "249 Train Loss 0.043031532 Test MSE 0.02661815323503142 Test RE 0.11787584996927751\n",
      "250 Train Loss 0.04276011 Test MSE 0.02526275640830437 Test RE 0.11483552074487594\n",
      "251 Train Loss 0.042307287 Test MSE 0.02404818789718984 Test RE 0.1120410203273013\n",
      "252 Train Loss 0.041694477 Test MSE 0.022397013194275475 Test RE 0.10812619737470007\n",
      "253 Train Loss 0.040756017 Test MSE 0.020527845174250877 Test RE 0.10351601828791201\n",
      "254 Train Loss 0.0403726 Test MSE 0.01999172618442251 Test RE 0.10215532841462782\n",
      "255 Train Loss 0.03990628 Test MSE 0.019109011315683287 Test RE 0.09987458452959694\n",
      "256 Train Loss 0.039151717 Test MSE 0.01871689799013499 Test RE 0.09884456934767163\n",
      "257 Train Loss 0.03833412 Test MSE 0.018255632924445375 Test RE 0.09761899319178818\n",
      "258 Train Loss 0.03782156 Test MSE 0.01823689075583006 Test RE 0.09756886999235218\n",
      "259 Train Loss 0.03702079 Test MSE 0.018127181542152218 Test RE 0.09727495061478912\n",
      "260 Train Loss 0.036596082 Test MSE 0.017576270537028538 Test RE 0.09578538324924409\n",
      "261 Train Loss 0.03610373 Test MSE 0.016761072468192095 Test RE 0.093537719807127\n",
      "262 Train Loss 0.03568471 Test MSE 0.017640465426939242 Test RE 0.09596014523356818\n",
      "263 Train Loss 0.0352531 Test MSE 0.017171216872911566 Test RE 0.09467523975456572\n",
      "264 Train Loss 0.034930754 Test MSE 0.01722691492645283 Test RE 0.09482866386419553\n",
      "265 Train Loss 0.034448877 Test MSE 0.01678120755751133 Test RE 0.09359388641151725\n",
      "266 Train Loss 0.034115452 Test MSE 0.016889767812378702 Test RE 0.09389613511673664\n",
      "267 Train Loss 0.033786982 Test MSE 0.016513110694270694 Test RE 0.09284324750862596\n",
      "268 Train Loss 0.033482354 Test MSE 0.015709303156316152 Test RE 0.0905553966625109\n",
      "269 Train Loss 0.033108436 Test MSE 0.016266747797316024 Test RE 0.09214807000344453\n",
      "270 Train Loss 0.032590058 Test MSE 0.015773729293604512 Test RE 0.09074089709291179\n",
      "271 Train Loss 0.0321058 Test MSE 0.016120307230536382 Test RE 0.09173235312224585\n",
      "272 Train Loss 0.03162439 Test MSE 0.015666919406383314 Test RE 0.09043315478031669\n",
      "273 Train Loss 0.031318266 Test MSE 0.015464490808438227 Test RE 0.08984702249415705\n",
      "274 Train Loss 0.031076059 Test MSE 0.014949806064803508 Test RE 0.08833923953215621\n",
      "275 Train Loss 0.03082481 Test MSE 0.014360477457729748 Test RE 0.08658054528726557\n",
      "276 Train Loss 0.030246582 Test MSE 0.014240208620457034 Test RE 0.0862172274454108\n",
      "277 Train Loss 0.029869845 Test MSE 0.014023366930659436 Test RE 0.08555827616486396\n",
      "278 Train Loss 0.028873416 Test MSE 0.013477500385056828 Test RE 0.08387654894457562\n",
      "279 Train Loss 0.028335197 Test MSE 0.013335654532141642 Test RE 0.08343399615493284\n",
      "280 Train Loss 0.027984621 Test MSE 0.012868007812108619 Test RE 0.08195803452665107\n",
      "281 Train Loss 0.027535155 Test MSE 0.01249644425926294 Test RE 0.08076609864468975\n",
      "282 Train Loss 0.027099364 Test MSE 0.012106306618530188 Test RE 0.07949534738143332\n",
      "283 Train Loss 0.026667302 Test MSE 0.011696636160810743 Test RE 0.07813873341994604\n",
      "284 Train Loss 0.026374148 Test MSE 0.011289172736801283 Test RE 0.07676565078579513\n",
      "285 Train Loss 0.02579017 Test MSE 0.01167524022786982 Test RE 0.07806723353182138\n",
      "286 Train Loss 0.025503373 Test MSE 0.01158983789132907 Test RE 0.07778118540653128\n",
      "287 Train Loss 0.02530471 Test MSE 0.011174692693701502 Test RE 0.07637543051244393\n",
      "288 Train Loss 0.02507912 Test MSE 0.011263554536572788 Test RE 0.07667850025615648\n",
      "289 Train Loss 0.024930347 Test MSE 0.01109706559339572 Test RE 0.07610969007227811\n",
      "290 Train Loss 0.024930347 Test MSE 0.01109706559339572 Test RE 0.07610969007227811\n",
      "291 Train Loss 0.024930347 Test MSE 0.01109706559339572 Test RE 0.07610969007227811\n",
      "292 Train Loss 0.024930347 Test MSE 0.01109706559339572 Test RE 0.07610969007227811\n",
      "293 Train Loss 0.024930347 Test MSE 0.01109706559339572 Test RE 0.07610969007227811\n",
      "294 Train Loss 0.024930347 Test MSE 0.01109706559339572 Test RE 0.07610969007227811\n",
      "295 Train Loss 0.024930347 Test MSE 0.01109706559339572 Test RE 0.07610969007227811\n",
      "296 Train Loss 0.024930347 Test MSE 0.01109706559339572 Test RE 0.07610969007227811\n",
      "297 Train Loss 0.024930347 Test MSE 0.01109706559339572 Test RE 0.07610969007227811\n",
      "298 Train Loss 0.024930347 Test MSE 0.01109706559339572 Test RE 0.07610969007227811\n",
      "299 Train Loss 0.024930347 Test MSE 0.01109706559339572 Test RE 0.07610969007227811\n",
      "Training time: 181.70\n",
      "KG_atanh_high\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 54119.516 Test MSE 4.17670655738198 Test RE 1.4765659829974578\n",
      "1 Train Loss 33370.055 Test MSE 10.29219541716881 Test RE 2.3178743453602513\n",
      "2 Train Loss 24344.156 Test MSE 9.762132403685488 Test RE 2.2573984563990726\n",
      "3 Train Loss 16935.37 Test MSE 8.929824897072372 Test RE 2.1590233952469036\n",
      "4 Train Loss 11579.206 Test MSE 6.911438765927168 Test RE 1.8994160751023466\n",
      "5 Train Loss 6769.6323 Test MSE 8.631910048831934 Test RE 2.122703470238291\n",
      "6 Train Loss 4775.768 Test MSE 11.988499761120218 Test RE 2.501602466144025\n",
      "7 Train Loss 2639.3328 Test MSE 12.380821346076925 Test RE 2.5422052151183774\n",
      "8 Train Loss 1752.4923 Test MSE 13.607576480765402 Test RE 2.665178301796322\n",
      "9 Train Loss 1304.1068 Test MSE 14.237569895924407 Test RE 2.726175506125872\n",
      "10 Train Loss 940.07806 Test MSE 14.775579280844466 Test RE 2.777206257727966\n",
      "11 Train Loss 697.39716 Test MSE 14.727403507826757 Test RE 2.7726750209899222\n",
      "12 Train Loss 556.09174 Test MSE 14.387071252943318 Test RE 2.7404512079806134\n",
      "13 Train Loss 385.37073 Test MSE 13.123258105565274 Test RE 2.6173193271733566\n",
      "14 Train Loss 322.95676 Test MSE 13.197234934720509 Test RE 2.624685976727458\n",
      "15 Train Loss 279.09753 Test MSE 13.464645778558491 Test RE 2.6511441565735834\n",
      "16 Train Loss 246.96446 Test MSE 13.572755076508235 Test RE 2.6617660594037487\n",
      "17 Train Loss 208.4966 Test MSE 14.528753308012442 Test RE 2.7539119573927837\n",
      "18 Train Loss 175.40414 Test MSE 15.56375070526643 Test RE 2.8503159941374188\n",
      "19 Train Loss 155.1719 Test MSE 15.97622014001242 Test RE 2.8878384531467023\n",
      "20 Train Loss 143.3303 Test MSE 16.212733112144033 Test RE 2.909135792378065\n",
      "21 Train Loss 130.69632 Test MSE 16.138933069714934 Test RE 2.9025070758565588\n",
      "22 Train Loss 112.635345 Test MSE 16.161359127916818 Test RE 2.9045229834679813\n",
      "23 Train Loss 99.557655 Test MSE 16.114845601948847 Test RE 2.900340261247082\n",
      "24 Train Loss 90.08791 Test MSE 16.08146318672748 Test RE 2.897334630324683\n",
      "25 Train Loss 84.04047 Test MSE 15.893641603264424 Test RE 2.880365395421746\n",
      "26 Train Loss 74.11879 Test MSE 15.865263574695026 Test RE 2.8777928065736056\n",
      "27 Train Loss 67.43545 Test MSE 15.924532949650928 Test RE 2.883163217786737\n",
      "28 Train Loss 63.5493 Test MSE 15.83333948462241 Test RE 2.874896000650238\n",
      "29 Train Loss 60.490585 Test MSE 15.637125733770246 Test RE 2.8570269760058933\n",
      "30 Train Loss 56.612804 Test MSE 15.580600134014992 Test RE 2.8518584631032238\n",
      "31 Train Loss 53.033104 Test MSE 15.5951798068307 Test RE 2.853192475929747\n",
      "32 Train Loss 51.279728 Test MSE 15.601230192620628 Test RE 2.853745891837694\n",
      "33 Train Loss 49.373253 Test MSE 15.689091068206007 Test RE 2.8617702780490046\n",
      "34 Train Loss 47.43677 Test MSE 15.81392061559603 Test RE 2.873132495331351\n",
      "35 Train Loss 45.670456 Test MSE 15.813013436024608 Test RE 2.8730500842534634\n",
      "36 Train Loss 43.46022 Test MSE 15.916044637546385 Test RE 2.8823947038389126\n",
      "37 Train Loss 41.67434 Test MSE 15.770483681141958 Test RE 2.869183889303988\n",
      "38 Train Loss 40.18879 Test MSE 15.739462581963625 Test RE 2.8663606071521874\n",
      "39 Train Loss 37.43072 Test MSE 15.740322643212174 Test RE 2.866438920245572\n",
      "40 Train Loss 36.856194 Test MSE 15.816736577458725 Test RE 2.8733882912086126\n",
      "41 Train Loss 34.84427 Test MSE 15.745682758292396 Test RE 2.866926938662509\n",
      "42 Train Loss 34.354088 Test MSE 15.71564705621973 Test RE 2.864191227902158\n",
      "43 Train Loss 33.65197 Test MSE 15.694376466579874 Test RE 2.862252279276202\n",
      "44 Train Loss 33.080112 Test MSE 15.651248633504595 Test RE 2.8583168677595636\n",
      "45 Train Loss 32.66106 Test MSE 15.622754203736243 Test RE 2.8557137779094237\n",
      "46 Train Loss 31.599827 Test MSE 15.625684573415827 Test RE 2.8559815893524108\n",
      "47 Train Loss 31.11692 Test MSE 15.57303212804194 Test RE 2.8511657586113675\n",
      "48 Train Loss 30.472952 Test MSE 15.455174383756509 Test RE 2.8403563620390218\n",
      "49 Train Loss 30.092896 Test MSE 15.503743022896359 Test RE 2.844815840440966\n",
      "50 Train Loss 28.694847 Test MSE 15.40601109937421 Test RE 2.8358351424257227\n",
      "51 Train Loss 27.62389 Test MSE 15.331257417678978 Test RE 2.828946698117225\n",
      "52 Train Loss 27.105331 Test MSE 15.301657477292109 Test RE 2.8262144659254615\n",
      "53 Train Loss 26.6828 Test MSE 15.346598400976669 Test RE 2.830361714893191\n",
      "54 Train Loss 25.782427 Test MSE 15.221757090815204 Test RE 2.8188260119320017\n",
      "55 Train Loss 25.271732 Test MSE 15.244025615001014 Test RE 2.82088714567733\n",
      "56 Train Loss 24.896765 Test MSE 15.249208121777315 Test RE 2.821366613004435\n",
      "57 Train Loss 23.9858 Test MSE 15.328769098620628 Test RE 2.8287171146120276\n",
      "58 Train Loss 23.505028 Test MSE 15.272290765866959 Test RE 2.8235011492636195\n",
      "59 Train Loss 23.229893 Test MSE 15.240365646926099 Test RE 2.820548489179038\n",
      "60 Train Loss 22.86866 Test MSE 15.233656950098263 Test RE 2.8199276285004693\n",
      "61 Train Loss 22.618546 Test MSE 15.230665477705417 Test RE 2.819650736685997\n",
      "62 Train Loss 22.435665 Test MSE 15.230725718340391 Test RE 2.8196563128501855\n",
      "63 Train Loss 22.326313 Test MSE 15.242702580732226 Test RE 2.8207647301344116\n",
      "64 Train Loss 22.14598 Test MSE 15.24274255630302 Test RE 2.820768429006237\n",
      "65 Train Loss 21.793879 Test MSE 15.202467712571949 Test RE 2.8170394035409156\n",
      "66 Train Loss 21.612223 Test MSE 15.169031640814433 Test RE 2.813939821918283\n",
      "67 Train Loss 21.394524 Test MSE 15.101077602666386 Test RE 2.807629820917144\n",
      "68 Train Loss 20.88056 Test MSE 15.037612126076189 Test RE 2.8017237795882375\n",
      "69 Train Loss 20.697485 Test MSE 15.041706378505852 Test RE 2.8021051627363516\n",
      "70 Train Loss 20.46175 Test MSE 14.995652107279707 Test RE 2.7978121710037\n",
      "71 Train Loss 20.12171 Test MSE 14.9235986823641 Test RE 2.7910823972227248\n",
      "72 Train Loss 19.980097 Test MSE 14.87895461509423 Test RE 2.7869044974405788\n",
      "73 Train Loss 19.78322 Test MSE 14.892496387942822 Test RE 2.7881724307581788\n",
      "74 Train Loss 19.397215 Test MSE 14.831098516911606 Test RE 2.7824190415279157\n",
      "75 Train Loss 19.112553 Test MSE 14.848782308237487 Test RE 2.784077349556718\n",
      "76 Train Loss 18.940676 Test MSE 14.809874838525847 Test RE 2.7804274726438076\n",
      "77 Train Loss 18.864502 Test MSE 14.791633254886849 Test RE 2.7787145942951352\n",
      "78 Train Loss 18.753035 Test MSE 14.76820317050886 Test RE 2.7765129672448974\n",
      "79 Train Loss 18.667946 Test MSE 14.76374015079564 Test RE 2.7760933979747753\n",
      "80 Train Loss 18.553423 Test MSE 14.74431236627442 Test RE 2.774266249218277\n",
      "81 Train Loss 18.462286 Test MSE 14.725687258682127 Test RE 2.7725134602717056\n",
      "82 Train Loss 18.33281 Test MSE 14.696541270264946 Test RE 2.7697683364527834\n",
      "83 Train Loss 18.148731 Test MSE 14.650205887024708 Test RE 2.765398614649462\n",
      "84 Train Loss 18.07305 Test MSE 14.635645139785671 Test RE 2.764024016892038\n",
      "85 Train Loss 17.987782 Test MSE 14.60872746491175 Test RE 2.7614810698616465\n",
      "86 Train Loss 17.910576 Test MSE 14.59449978909732 Test RE 2.7601360167642897\n",
      "87 Train Loss 17.767979 Test MSE 14.552267421803096 Test RE 2.7561395958514887\n",
      "88 Train Loss 17.638239 Test MSE 14.509079391113023 Test RE 2.7520467392237387\n",
      "89 Train Loss 17.562334 Test MSE 14.494071895217362 Test RE 2.7506230784046832\n",
      "90 Train Loss 17.474659 Test MSE 14.474844850007957 Test RE 2.748798059688548\n",
      "91 Train Loss 17.277021 Test MSE 14.443634086371985 Test RE 2.7458329715056955\n",
      "92 Train Loss 17.156282 Test MSE 14.40972519543479 Test RE 2.742607922281367\n",
      "93 Train Loss 17.1016 Test MSE 14.413069923537757 Test RE 2.7429262054343844\n",
      "94 Train Loss 17.050493 Test MSE 14.434267099442962 Test RE 2.7449424631763555\n",
      "95 Train Loss 16.956522 Test MSE 14.4142065815731 Test RE 2.743034361006431\n",
      "96 Train Loss 16.901789 Test MSE 14.418499177996503 Test RE 2.7434427727671653\n",
      "97 Train Loss 16.866745 Test MSE 14.417946166701784 Test RE 2.743390160863227\n",
      "98 Train Loss 16.83312 Test MSE 14.406451944210772 Test RE 2.742296405077435\n",
      "99 Train Loss 16.757702 Test MSE 14.39698011414851 Test RE 2.7413947661306155\n",
      "100 Train Loss 16.612677 Test MSE 14.372385596478471 Test RE 2.7390521879967125\n",
      "101 Train Loss 16.573837 Test MSE 14.36524712396105 Test RE 2.738371887670413\n",
      "102 Train Loss 16.537622 Test MSE 14.334839851620389 Test RE 2.7354721627733674\n",
      "103 Train Loss 16.446346 Test MSE 14.330291427201276 Test RE 2.7350381476175434\n",
      "104 Train Loss 16.409197 Test MSE 14.324334325602944 Test RE 2.7344696108995374\n",
      "105 Train Loss 16.381136 Test MSE 14.309598429868235 Test RE 2.7330627312972244\n",
      "106 Train Loss 16.33036 Test MSE 14.287907335383672 Test RE 2.730990499667633\n",
      "107 Train Loss 16.286724 Test MSE 14.266758108063861 Test RE 2.728968519572647\n",
      "108 Train Loss 16.24291 Test MSE 14.270259982674181 Test RE 2.7293034211369336\n",
      "109 Train Loss 16.209362 Test MSE 14.267100582067444 Test RE 2.729001273866186\n",
      "110 Train Loss 16.177803 Test MSE 14.24783054154274 Test RE 2.7271576710265784\n",
      "111 Train Loss 16.14268 Test MSE 14.241718715270858 Test RE 2.726572680149342\n",
      "112 Train Loss 16.10392 Test MSE 14.225519077299396 Test RE 2.7250215310638186\n",
      "113 Train Loss 16.083029 Test MSE 14.223671768876896 Test RE 2.724844591346016\n",
      "114 Train Loss 16.028833 Test MSE 14.225331672061033 Test RE 2.7250035814554874\n",
      "115 Train Loss 15.968948 Test MSE 14.227678801538094 Test RE 2.7252283801657593\n",
      "116 Train Loss 15.942426 Test MSE 14.223650338209998 Test RE 2.7248425385969175\n",
      "117 Train Loss 15.90711 Test MSE 14.203856704399803 Test RE 2.7229459329081345\n",
      "118 Train Loss 15.867828 Test MSE 14.187337709399 Test RE 2.7213620878736715\n",
      "119 Train Loss 15.817815 Test MSE 14.154786663346185 Test RE 2.7182383851200167\n",
      "120 Train Loss 15.779167 Test MSE 14.094437679597236 Test RE 2.7124375860276038\n",
      "121 Train Loss 15.721528 Test MSE 14.070473080836326 Test RE 2.71013064288681\n",
      "122 Train Loss 15.672797 Test MSE 14.047841356384481 Test RE 2.707950203996752\n",
      "123 Train Loss 15.6433115 Test MSE 14.039753731179166 Test RE 2.7071705810329116\n",
      "124 Train Loss 15.615487 Test MSE 14.009250493992928 Test RE 2.7042281374064565\n",
      "125 Train Loss 15.58693 Test MSE 13.978112672506635 Test RE 2.7012211737495426\n",
      "126 Train Loss 15.557382 Test MSE 13.9706851823932 Test RE 2.700503410201009\n",
      "127 Train Loss 15.517647 Test MSE 13.938969029529275 Test RE 2.697436336418484\n",
      "128 Train Loss 15.494608 Test MSE 13.910458240938636 Test RE 2.694676254121041\n",
      "129 Train Loss 15.474137 Test MSE 13.904336165472094 Test RE 2.694083217335063\n",
      "130 Train Loss 15.453338 Test MSE 13.88106413029613 Test RE 2.691827695930369\n",
      "131 Train Loss 15.423185 Test MSE 13.850673479119546 Test RE 2.6888793909312514\n",
      "132 Train Loss 15.386814 Test MSE 13.795977186420933 Test RE 2.683564948339546\n",
      "133 Train Loss 15.359425 Test MSE 13.732456117991314 Test RE 2.6773798271332083\n",
      "134 Train Loss 15.325144 Test MSE 13.641435750395868 Test RE 2.668492077937744\n",
      "135 Train Loss 15.295112 Test MSE 13.616643807993697 Test RE 2.6660661167365607\n",
      "136 Train Loss 15.259373 Test MSE 13.547551493669594 Test RE 2.6592935616176976\n",
      "137 Train Loss 15.232149 Test MSE 13.492470435550656 Test RE 2.6538820342500715\n",
      "138 Train Loss 15.203403 Test MSE 13.447615142218819 Test RE 2.6494669881244732\n",
      "139 Train Loss 15.167939 Test MSE 13.441226527243671 Test RE 2.6488375666582127\n",
      "140 Train Loss 15.133122 Test MSE 13.396404183796548 Test RE 2.6444173505472293\n",
      "141 Train Loss 15.101074 Test MSE 13.310563327213243 Test RE 2.6359313473015598\n",
      "142 Train Loss 15.0667 Test MSE 13.261658885639266 Test RE 2.6310845436175683\n",
      "143 Train Loss 15.03387 Test MSE 13.234046751228442 Test RE 2.6283440223816195\n",
      "144 Train Loss 14.9894085 Test MSE 13.229663676599094 Test RE 2.6279087367036227\n",
      "145 Train Loss 14.920859 Test MSE 13.149872824372627 Test RE 2.6199720196263088\n",
      "146 Train Loss 14.846108 Test MSE 13.007157076947141 Test RE 2.6057159378781387\n",
      "147 Train Loss 14.776132 Test MSE 12.924319807884453 Test RE 2.5974053149104863\n",
      "148 Train Loss 14.711791 Test MSE 12.824385580648269 Test RE 2.58734391859074\n",
      "149 Train Loss 14.664268 Test MSE 12.783553140761308 Test RE 2.5832216238760215\n",
      "150 Train Loss 14.582698 Test MSE 12.696716341298641 Test RE 2.574432950805312\n",
      "151 Train Loss 14.478722 Test MSE 12.556673804128371 Test RE 2.560195813458732\n",
      "152 Train Loss 14.392058 Test MSE 12.427331682947196 Test RE 2.5469758187984888\n",
      "153 Train Loss 14.299187 Test MSE 12.297549555132855 Test RE 2.5336415207587746\n",
      "154 Train Loss 14.172724 Test MSE 12.071570858384792 Test RE 2.5102545959080906\n",
      "155 Train Loss 14.0723505 Test MSE 11.902119518023724 Test RE 2.49257382676198\n",
      "156 Train Loss 13.982085 Test MSE 11.800451707893515 Test RE 2.4819052222285163\n",
      "157 Train Loss 13.861308 Test MSE 11.6985815732761 Test RE 2.4711691906271827\n",
      "158 Train Loss 13.754439 Test MSE 11.660107127688281 Test RE 2.4671022374977323\n",
      "159 Train Loss 13.63088 Test MSE 11.636177010285664 Test RE 2.464569311868912\n",
      "160 Train Loss 13.546451 Test MSE 11.592266517868147 Test RE 2.4599147444474068\n",
      "161 Train Loss 13.427941 Test MSE 11.46830061805796 Test RE 2.4467264178654182\n",
      "162 Train Loss 13.27366 Test MSE 11.33610998771997 Test RE 2.4325843163415515\n",
      "163 Train Loss 13.084554 Test MSE 11.08211250048879 Test RE 2.4051776204514663\n",
      "164 Train Loss 13.00602 Test MSE 11.033033477764903 Test RE 2.3998458413560884\n",
      "165 Train Loss 12.862802 Test MSE 11.014073630563406 Test RE 2.397782932946811\n",
      "166 Train Loss 12.743631 Test MSE 10.842181683955841 Test RE 2.378998768175877\n",
      "167 Train Loss 12.610311 Test MSE 10.708606779917496 Test RE 2.3642988047748976\n",
      "168 Train Loss 12.429782 Test MSE 10.560453579439805 Test RE 2.3478868466941876\n",
      "169 Train Loss 12.311432 Test MSE 10.457920580802734 Test RE 2.3364610558373546\n",
      "170 Train Loss 12.191743 Test MSE 10.314914147434626 Test RE 2.3204311436095093\n",
      "171 Train Loss 12.049719 Test MSE 10.264651064436674 Test RE 2.3147706770527643\n",
      "172 Train Loss 11.90346 Test MSE 10.160969059516818 Test RE 2.3030503956495023\n",
      "173 Train Loss 11.76782 Test MSE 9.991544483986909 Test RE 2.2837690867871463\n",
      "174 Train Loss 11.589461 Test MSE 9.95509414578276 Test RE 2.279599550452491\n",
      "175 Train Loss 11.465555 Test MSE 9.944642160335565 Test RE 2.2784025452729852\n",
      "176 Train Loss 11.3750305 Test MSE 9.94970717382747 Test RE 2.2789826903607344\n",
      "177 Train Loss 11.309414 Test MSE 9.911671025764077 Test RE 2.2746224250393388\n",
      "178 Train Loss 11.184163 Test MSE 9.91944519529489 Test RE 2.275514294544089\n",
      "179 Train Loss 11.033579 Test MSE 9.872007980935006 Test RE 2.2700667407506545\n",
      "180 Train Loss 10.934386 Test MSE 9.780437746431046 Test RE 2.2595139316645176\n",
      "181 Train Loss 10.831957 Test MSE 9.737893838389342 Test RE 2.254594248069587\n",
      "182 Train Loss 10.727931 Test MSE 9.674629877619543 Test RE 2.247258627927955\n",
      "183 Train Loss 10.586924 Test MSE 9.600657033666058 Test RE 2.238650800156952\n",
      "184 Train Loss 10.504927 Test MSE 9.607041463598623 Test RE 2.2393950270254703\n",
      "185 Train Loss 10.329148 Test MSE 9.508510141994092 Test RE 2.2278816371294226\n",
      "186 Train Loss 10.221324 Test MSE 9.512303202040835 Test RE 2.2283259573287966\n",
      "187 Train Loss 10.115036 Test MSE 9.507375597897816 Test RE 2.2277487190737117\n",
      "188 Train Loss 10.033486 Test MSE 9.44833773376901 Test RE 2.2208211322622935\n",
      "189 Train Loss 9.941795 Test MSE 9.344972716032636 Test RE 2.208639809214513\n",
      "190 Train Loss 9.808075 Test MSE 9.180369420471141 Test RE 2.1891017882003885\n",
      "191 Train Loss 9.6858635 Test MSE 9.135478311477993 Test RE 2.1837429822941985\n",
      "192 Train Loss 9.564265 Test MSE 8.98220514682009 Test RE 2.1653462980177984\n",
      "193 Train Loss 9.464352 Test MSE 8.893509858241348 Test RE 2.1546288581466286\n",
      "194 Train Loss 9.327133 Test MSE 8.902655367581984 Test RE 2.1557364138463826\n",
      "195 Train Loss 9.246302 Test MSE 8.861670002746589 Test RE 2.1507684821761885\n",
      "196 Train Loss 9.176231 Test MSE 8.808948539430636 Test RE 2.1443610658680967\n",
      "197 Train Loss 9.098557 Test MSE 8.814054130430698 Test RE 2.1449824024892723\n",
      "198 Train Loss 9.02277 Test MSE 8.783857608206104 Test RE 2.1413049472203762\n",
      "199 Train Loss 8.969019 Test MSE 8.7669271093366 Test RE 2.139240316357081\n",
      "200 Train Loss 8.911737 Test MSE 8.731636436443763 Test RE 2.1349302908577754\n",
      "201 Train Loss 8.864739 Test MSE 8.671794959919625 Test RE 2.127601937889646\n",
      "202 Train Loss 8.8292885 Test MSE 8.699194202252343 Test RE 2.1309604528946626\n",
      "203 Train Loss 8.78666 Test MSE 8.677378308410486 Test RE 2.1282867575629747\n",
      "204 Train Loss 8.737743 Test MSE 8.589318521657564 Test RE 2.1174600778633965\n",
      "205 Train Loss 8.693647 Test MSE 8.552318889833176 Test RE 2.1128945354438056\n",
      "206 Train Loss 8.67165 Test MSE 8.540636613440972 Test RE 2.111450958954203\n",
      "207 Train Loss 8.637234 Test MSE 8.57318045035981 Test RE 2.115469943976072\n",
      "208 Train Loss 8.603554 Test MSE 8.589126710372465 Test RE 2.1174364348348393\n",
      "209 Train Loss 8.566245 Test MSE 8.580276564279904 Test RE 2.116345261530026\n",
      "210 Train Loss 8.502115 Test MSE 8.548746922238807 Test RE 2.1124532528446633\n",
      "211 Train Loss 8.4570055 Test MSE 8.573879032703346 Test RE 2.11555613135168\n",
      "212 Train Loss 8.375491 Test MSE 8.51017537297109 Test RE 2.107682219583497\n",
      "213 Train Loss 8.300206 Test MSE 8.388762688553777 Test RE 2.0925933037627615\n",
      "214 Train Loss 8.25507 Test MSE 8.342741774586049 Test RE 2.0868454060314363\n",
      "215 Train Loss 8.163182 Test MSE 8.206435635305693 Test RE 2.0697274552582425\n",
      "216 Train Loss 8.098456 Test MSE 8.151255347572002 Test RE 2.062757267808221\n",
      "217 Train Loss 8.030773 Test MSE 8.063322783713678 Test RE 2.0516009883418422\n",
      "218 Train Loss 7.959457 Test MSE 8.063289126385836 Test RE 2.051596706516534\n",
      "219 Train Loss 7.916791 Test MSE 8.08035917034374 Test RE 2.0537671812545693\n",
      "220 Train Loss 7.836024 Test MSE 8.100966419286495 Test RE 2.0563843633248764\n",
      "221 Train Loss 7.762101 Test MSE 8.078627561271746 Test RE 2.0535471098222913\n",
      "222 Train Loss 7.7004795 Test MSE 8.027758110162598 Test RE 2.0470715186099913\n",
      "223 Train Loss 7.662464 Test MSE 7.994088893910883 Test RE 2.0427741972139444\n",
      "224 Train Loss 7.5575385 Test MSE 7.989524851073498 Test RE 2.042190976275347\n",
      "225 Train Loss 7.4894886 Test MSE 7.919599371790586 Test RE 2.033234560563527\n",
      "226 Train Loss 7.4282994 Test MSE 7.872798362606791 Test RE 2.0272179411982694\n",
      "227 Train Loss 7.369445 Test MSE 7.807692331193966 Test RE 2.0188182520572076\n",
      "228 Train Loss 7.278011 Test MSE 7.836347686965514 Test RE 2.0225195360322377\n",
      "229 Train Loss 7.204537 Test MSE 7.726765396927097 Test RE 2.008328447612042\n",
      "230 Train Loss 7.165755 Test MSE 7.70545577272178 Test RE 2.0055571539141144\n",
      "231 Train Loss 7.1195407 Test MSE 7.675878617046333 Test RE 2.0017043182967087\n",
      "232 Train Loss 7.0490055 Test MSE 7.642201614105644 Test RE 1.9973083717150937\n",
      "233 Train Loss 7.0121984 Test MSE 7.62786125465925 Test RE 1.9954335475111975\n",
      "234 Train Loss 6.9443517 Test MSE 7.514384791632931 Test RE 1.9805353211277852\n",
      "235 Train Loss 6.89893 Test MSE 7.492615578451624 Test RE 1.9776644296307244\n",
      "236 Train Loss 6.8707767 Test MSE 7.4664455706974024 Test RE 1.9742076417731131\n",
      "237 Train Loss 6.840948 Test MSE 7.4579921838087895 Test RE 1.9730897425537484\n",
      "238 Train Loss 6.780296 Test MSE 7.371440113212472 Test RE 1.9616072035957102\n",
      "239 Train Loss 6.7352095 Test MSE 7.297327580872492 Test RE 1.951721283354145\n",
      "240 Train Loss 6.6898193 Test MSE 7.219195818603254 Test RE 1.941244721958312\n",
      "241 Train Loss 6.6458497 Test MSE 7.142798315323729 Test RE 1.9309457421078264\n",
      "242 Train Loss 6.6248536 Test MSE 7.135606940986051 Test RE 1.929973458560683\n",
      "243 Train Loss 6.5905194 Test MSE 7.044476743483564 Test RE 1.9176098275323756\n",
      "244 Train Loss 6.5663705 Test MSE 6.994077777966166 Test RE 1.910737845671061\n",
      "245 Train Loss 6.5009494 Test MSE 6.977605374967164 Test RE 1.9084864410704807\n",
      "246 Train Loss 6.456771 Test MSE 6.9402756153836584 Test RE 1.9033744521576241\n",
      "247 Train Loss 6.4214616 Test MSE 6.942714690237437 Test RE 1.903708881595837\n",
      "248 Train Loss 6.3903418 Test MSE 6.924318819205003 Test RE 1.9011851129050772\n",
      "249 Train Loss 6.3676596 Test MSE 6.890750738217645 Test RE 1.8965711810503694\n",
      "250 Train Loss 6.3186707 Test MSE 6.8344867781796275 Test RE 1.888812424002086\n",
      "251 Train Loss 6.2507725 Test MSE 6.772240344609713 Test RE 1.880191384184301\n",
      "252 Train Loss 6.205275 Test MSE 6.75543837171819 Test RE 1.8778575521193541\n",
      "253 Train Loss 6.1641645 Test MSE 6.682850182281585 Test RE 1.8677413745050189\n",
      "254 Train Loss 6.089476 Test MSE 6.581755669626006 Test RE 1.8535604534106402\n",
      "255 Train Loss 6.011563 Test MSE 6.410996254101779 Test RE 1.8293577241281485\n",
      "256 Train Loss 5.9362226 Test MSE 6.268957769146599 Test RE 1.8089790988683079\n",
      "257 Train Loss 5.871134 Test MSE 6.147314575106564 Test RE 1.791342359789754\n",
      "258 Train Loss 5.818127 Test MSE 6.072578054717499 Test RE 1.780419858903056\n",
      "259 Train Loss 5.6933527 Test MSE 5.819101981001805 Test RE 1.7428654516126685\n",
      "260 Train Loss 5.581674 Test MSE 5.588258801444139 Test RE 1.7079459873339364\n",
      "261 Train Loss 5.454633 Test MSE 5.573884246651996 Test RE 1.705747917025879\n",
      "262 Train Loss 5.369013 Test MSE 5.501706812973781 Test RE 1.6946678811931655\n",
      "263 Train Loss 5.3000293 Test MSE 5.359934653395918 Test RE 1.6726906310224132\n",
      "264 Train Loss 5.2063656 Test MSE 5.218399008167195 Test RE 1.650458156851729\n",
      "265 Train Loss 5.1014338 Test MSE 5.08141575162252 Test RE 1.6286517926382278\n",
      "266 Train Loss 5.0000234 Test MSE 4.8362295643817585 Test RE 1.5888735328260588\n",
      "267 Train Loss 4.8734136 Test MSE 4.661840451453289 Test RE 1.5599640137492847\n",
      "268 Train Loss 4.6779766 Test MSE 4.3752940618511325 Test RE 1.5112610886380058\n",
      "269 Train Loss 4.543855 Test MSE 4.165455769691076 Test RE 1.4745759302444714\n",
      "270 Train Loss 4.3827915 Test MSE 3.8248478005120066 Test RE 1.4130025838902285\n",
      "271 Train Loss 4.2277083 Test MSE 3.4970618455162334 Test RE 1.3511001224130879\n",
      "272 Train Loss 4.0553184 Test MSE 3.183282978049862 Test RE 1.2890610925154922\n",
      "273 Train Loss 3.9263756 Test MSE 3.073579974418278 Test RE 1.2666543993591377\n",
      "274 Train Loss 3.772892 Test MSE 2.9434650046856694 Test RE 1.2395536122341517\n",
      "275 Train Loss 3.6090486 Test MSE 2.7276243074335684 Test RE 1.1932409602195977\n",
      "276 Train Loss 3.4439754 Test MSE 2.6223448652787407 Test RE 1.1699863084949274\n",
      "277 Train Loss 3.2567098 Test MSE 2.3104376042523644 Test RE 1.0982039441258529\n",
      "278 Train Loss 3.1535988 Test MSE 2.1313309168014376 Test RE 1.0547786226399125\n",
      "279 Train Loss 3.0170147 Test MSE 1.9276110003972684 Test RE 1.003103105441314\n",
      "280 Train Loss 2.8720837 Test MSE 1.7352835665423285 Test RE 0.9517460956220584\n",
      "281 Train Loss 2.7554982 Test MSE 1.6074378991693954 Test RE 0.9160158295368538\n",
      "282 Train Loss 2.6267405 Test MSE 1.4790871153875462 Test RE 0.8786840717046772\n",
      "283 Train Loss 2.4644756 Test MSE 1.3581470514425795 Test RE 0.8419945383842684\n",
      "284 Train Loss 2.308735 Test MSE 1.319922364844445 Test RE 0.8300611175078296\n",
      "285 Train Loss 2.2253463 Test MSE 1.2018040257092497 Test RE 0.7920501929755519\n",
      "286 Train Loss 2.1524718 Test MSE 1.060553136282213 Test RE 0.7440499523267472\n",
      "287 Train Loss 2.0952961 Test MSE 0.990290611676943 Test RE 0.7189806590458198\n",
      "288 Train Loss 2.0073156 Test MSE 0.9695346598292628 Test RE 0.7114060373748006\n",
      "289 Train Loss 1.9291087 Test MSE 0.9223404527475165 Test RE 0.6938754232321902\n",
      "290 Train Loss 1.864615 Test MSE 0.8443270079502907 Test RE 0.6638824952484972\n",
      "291 Train Loss 1.7745388 Test MSE 0.8399337740805632 Test RE 0.6621530735507144\n",
      "292 Train Loss 1.6841142 Test MSE 0.7263307167469146 Test RE 0.615748102794907\n",
      "293 Train Loss 1.5888834 Test MSE 0.5978124580265304 Test RE 0.5586224143652431\n",
      "294 Train Loss 1.4453952 Test MSE 0.5013101469077652 Test RE 0.5115512196713761\n",
      "295 Train Loss 1.4039426 Test MSE 0.42455061705068864 Test RE 0.4707611500143842\n",
      "296 Train Loss 1.2871882 Test MSE 0.24869722552298573 Test RE 0.36030587784590995\n",
      "297 Train Loss 1.1503687 Test MSE 0.1972352148943833 Test RE 0.32086925482981704\n",
      "298 Train Loss 1.1056801 Test MSE 0.17140854976567946 Test RE 0.2991245905479447\n",
      "299 Train Loss 0.9754394 Test MSE 0.10744207363432623 Test RE 0.2368225579706512\n",
      "Training time: 142.08\n",
      "KG_atanh_high\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 53266.27 Test MSE 5.732833948857031 Test RE 1.7298982455484253\n",
      "1 Train Loss 30767.137 Test MSE 5.620797629089672 Test RE 1.712911209782749\n",
      "2 Train Loss 13967.194 Test MSE 8.936830210085862 Test RE 2.159870089877672\n",
      "3 Train Loss 5017.658 Test MSE 10.945087637404225 Test RE 2.3902619524624305\n",
      "4 Train Loss 1757.1011 Test MSE 14.795814172360991 Test RE 2.7791072742439806\n",
      "5 Train Loss 880.3252 Test MSE 17.14310048171111 Test RE 2.991441830306607\n",
      "6 Train Loss 528.10956 Test MSE 18.40185723010815 Test RE 3.099322045087533\n",
      "7 Train Loss 371.1925 Test MSE 18.991389387298405 Test RE 3.1485764738230215\n",
      "8 Train Loss 278.37335 Test MSE 19.781762228484084 Test RE 3.2134264614028827\n",
      "9 Train Loss 196.12653 Test MSE 19.15693232296171 Test RE 3.162269354878325\n",
      "10 Train Loss 137.20718 Test MSE 18.674428017103637 Test RE 3.122191457895502\n",
      "11 Train Loss 112.25233 Test MSE 18.53819253326563 Test RE 3.1107819551325067\n",
      "12 Train Loss 91.75995 Test MSE 17.90726290750586 Test RE 3.057387472860156\n",
      "13 Train Loss 72.86215 Test MSE 17.263604673208977 Test RE 3.00193730667948\n",
      "14 Train Loss 56.78625 Test MSE 16.406744797572003 Test RE 2.926490295552426\n",
      "15 Train Loss 46.013702 Test MSE 16.0842381070775 Test RE 2.8975845928416217\n",
      "16 Train Loss 37.77124 Test MSE 16.07555012949633 Test RE 2.896801915097823\n",
      "17 Train Loss 32.654453 Test MSE 15.80800640911713 Test RE 2.8725951874664912\n",
      "18 Train Loss 28.78933 Test MSE 15.692136445788822 Test RE 2.8620480107785187\n",
      "19 Train Loss 25.735424 Test MSE 15.426722789097754 Test RE 2.8377407366054466\n",
      "20 Train Loss 24.094059 Test MSE 15.369449147974262 Test RE 2.832468104219234\n",
      "21 Train Loss 22.589897 Test MSE 15.234875004599179 Test RE 2.820040364296398\n",
      "22 Train Loss 21.849884 Test MSE 15.258754212277243 Test RE 2.8222495705675144\n",
      "23 Train Loss 20.946333 Test MSE 15.045840367852973 Test RE 2.802490194753209\n",
      "24 Train Loss 20.398703 Test MSE 15.017939851053567 Test RE 2.799890565713848\n",
      "25 Train Loss 20.066616 Test MSE 14.918843283728302 Test RE 2.7906376731581397\n",
      "26 Train Loss 19.689516 Test MSE 14.85583986258542 Test RE 2.7847389002013436\n",
      "27 Train Loss 19.176456 Test MSE 14.795723211378876 Test RE 2.7790987316010183\n",
      "28 Train Loss 18.77018 Test MSE 14.727722525668236 Test RE 2.7727050509952056\n",
      "29 Train Loss 18.520823 Test MSE 14.71632060970851 Test RE 2.7716315560589746\n",
      "30 Train Loss 18.307243 Test MSE 14.627863295084616 Test RE 2.76328909658815\n",
      "31 Train Loss 18.085924 Test MSE 14.63742010246119 Test RE 2.7641916176598667\n",
      "32 Train Loss 17.861204 Test MSE 14.598775766644104 Test RE 2.760540327136573\n",
      "33 Train Loss 17.65266 Test MSE 14.58158542289719 Test RE 2.758914553310364\n",
      "34 Train Loss 17.53572 Test MSE 14.537619714875488 Test RE 2.754752138901624\n",
      "35 Train Loss 17.38614 Test MSE 14.532691828267623 Test RE 2.754285203562853\n",
      "36 Train Loss 17.2403 Test MSE 14.486590699664795 Test RE 2.749913112104983\n",
      "37 Train Loss 17.098394 Test MSE 14.441456471235695 Test RE 2.7456259739871456\n",
      "38 Train Loss 16.943565 Test MSE 14.352369081931673 Test RE 2.7371441755749095\n",
      "39 Train Loss 16.807692 Test MSE 14.309949882637786 Test RE 2.7330962939640298\n",
      "40 Train Loss 16.638708 Test MSE 14.196575586883588 Test RE 2.722247931260336\n",
      "41 Train Loss 16.458204 Test MSE 14.078636405720951 Test RE 2.710916702773521\n",
      "42 Train Loss 16.272827 Test MSE 14.017261350006972 Test RE 2.7050012011131366\n",
      "43 Train Loss 16.073977 Test MSE 13.914333417465217 Test RE 2.6950515695430686\n",
      "44 Train Loss 15.890891 Test MSE 13.819480316036243 Test RE 2.6858498656756753\n",
      "45 Train Loss 15.727966 Test MSE 13.743986401776406 Test RE 2.678503605412937\n",
      "46 Train Loss 15.5671425 Test MSE 13.690917298582747 Test RE 2.6733274046700295\n",
      "47 Train Loss 15.345965 Test MSE 13.60915364676812 Test RE 2.6653327490935226\n",
      "48 Train Loss 15.173248 Test MSE 13.578389184729323 Test RE 2.6623184572765513\n",
      "49 Train Loss 14.974739 Test MSE 13.47960252409304 Test RE 2.6526162147187855\n",
      "50 Train Loss 14.683256 Test MSE 13.40436692019465 Test RE 2.6452031461205565\n",
      "51 Train Loss 14.447619 Test MSE 13.341439362948604 Test RE 2.6389868140556145\n",
      "52 Train Loss 14.202997 Test MSE 13.095419305817718 Test RE 2.614541750493683\n",
      "53 Train Loss 14.028122 Test MSE 12.969310844832581 Test RE 2.6019223199109827\n",
      "54 Train Loss 13.821997 Test MSE 12.884952486964776 Test RE 2.5934464654627036\n",
      "55 Train Loss 13.598489 Test MSE 12.710249102057556 Test RE 2.57580456161822\n",
      "56 Train Loss 13.259666 Test MSE 12.299545945431987 Test RE 2.533847168723938\n",
      "57 Train Loss 13.002818 Test MSE 12.013241759141676 Test RE 2.504182553006426\n",
      "58 Train Loss 12.297392 Test MSE 11.243748823948202 Test RE 2.422654286060596\n",
      "59 Train Loss 11.591005 Test MSE 10.632735984241831 Test RE 2.355908353237538\n",
      "60 Train Loss 10.738238 Test MSE 9.91984411246433 Test RE 2.2755600497540507\n",
      "61 Train Loss 9.783202 Test MSE 9.20497387841468 Test RE 2.192033349002383\n",
      "62 Train Loss 8.83775 Test MSE 8.4871067036058 Test RE 2.1048236169947065\n",
      "63 Train Loss 7.7905803 Test MSE 7.4722255333983725 Test RE 1.9749716357595526\n",
      "64 Train Loss 7.038588 Test MSE 7.122278537831239 Test RE 1.928170144013274\n",
      "65 Train Loss 6.2902875 Test MSE 6.536705047586656 Test RE 1.8472059609082454\n",
      "66 Train Loss 5.7633243 Test MSE 6.3029700586226385 Test RE 1.8138797772681636\n",
      "67 Train Loss 5.3510957 Test MSE 5.795206307206263 Test RE 1.7392833020469654\n",
      "68 Train Loss 4.9699283 Test MSE 5.434964139074893 Test RE 1.6843572814081564\n",
      "69 Train Loss 4.5639367 Test MSE 4.903519409033585 Test RE 1.599888903451067\n",
      "70 Train Loss 4.1847177 Test MSE 4.429955516636208 Test RE 1.5206720355179382\n",
      "71 Train Loss 3.8642137 Test MSE 4.070850881780851 Test RE 1.4577346398915614\n",
      "72 Train Loss 3.4899023 Test MSE 3.489231763072817 Test RE 1.3495866870926005\n",
      "73 Train Loss 3.1909316 Test MSE 3.2065986485971476 Test RE 1.2937732859026392\n",
      "74 Train Loss 2.9210541 Test MSE 2.888370314159225 Test RE 1.2278980602311738\n",
      "75 Train Loss 2.6124475 Test MSE 2.5823319291328617 Test RE 1.1610259037776243\n",
      "76 Train Loss 2.403969 Test MSE 2.332290291207721 Test RE 1.1033852628784042\n",
      "77 Train Loss 2.22423 Test MSE 2.1000672039828165 Test RE 1.0470139625074157\n",
      "78 Train Loss 2.0701356 Test MSE 1.8889903274875395 Test RE 0.993003419342273\n",
      "79 Train Loss 1.8899775 Test MSE 1.756873492261722 Test RE 0.9576484763290206\n",
      "80 Train Loss 1.7712979 Test MSE 1.672650708140513 Test RE 0.9344122132575519\n",
      "81 Train Loss 1.6305033 Test MSE 1.5298929118124227 Test RE 0.893647805336025\n",
      "82 Train Loss 1.5240417 Test MSE 1.4307914722556532 Test RE 0.8642194741764317\n",
      "83 Train Loss 1.376108 Test MSE 1.3384612507404947 Test RE 0.835870076690834\n",
      "84 Train Loss 1.2354975 Test MSE 1.2544098449553063 Test RE 0.8091994963701924\n",
      "85 Train Loss 1.1487247 Test MSE 1.224445029173991 Test RE 0.7994761697757576\n",
      "86 Train Loss 1.0816282 Test MSE 1.1736879149840016 Test RE 0.782730385333757\n",
      "87 Train Loss 1.0397278 Test MSE 1.1455085828705904 Test RE 0.7732769247799832\n",
      "88 Train Loss 0.99729055 Test MSE 1.0921495256049927 Test RE 0.7550521136222433\n",
      "89 Train Loss 0.9619014 Test MSE 1.0790096865116303 Test RE 0.7504962881483587\n",
      "90 Train Loss 0.926304 Test MSE 1.037024342695811 Test RE 0.735750138248395\n",
      "91 Train Loss 0.8993987 Test MSE 1.0130070328332679 Test RE 0.7271803036916337\n",
      "92 Train Loss 0.8760046 Test MSE 1.0037115538823564 Test RE 0.7238362660781862\n",
      "93 Train Loss 0.8456867 Test MSE 0.96920990582407 Test RE 0.7112868815986808\n",
      "94 Train Loss 0.8223336 Test MSE 0.9372214707058667 Test RE 0.6994505105522384\n",
      "95 Train Loss 0.80493605 Test MSE 0.946819795957723 Test RE 0.7030230130822319\n",
      "96 Train Loss 0.7839508 Test MSE 0.9556305633252927 Test RE 0.7062864792242975\n",
      "97 Train Loss 0.75956553 Test MSE 0.9271084645609222 Test RE 0.6956665956479434\n",
      "98 Train Loss 0.73794043 Test MSE 0.8871588243129843 Test RE 0.6805132181165509\n",
      "99 Train Loss 0.72444767 Test MSE 0.8730704968036198 Test RE 0.6750882252648881\n",
      "100 Train Loss 0.7077884 Test MSE 0.8606965765066819 Test RE 0.6702871824028467\n",
      "101 Train Loss 0.6957069 Test MSE 0.8545870421660107 Test RE 0.6679039757201206\n",
      "102 Train Loss 0.6821085 Test MSE 0.8275800636218936 Test RE 0.6572655759895442\n",
      "103 Train Loss 0.66007096 Test MSE 0.8195118353714256 Test RE 0.6540538281399181\n",
      "104 Train Loss 0.6464339 Test MSE 0.8099431655925482 Test RE 0.6502242306270407\n",
      "105 Train Loss 0.63092005 Test MSE 0.8001385798161288 Test RE 0.6462766757196048\n",
      "106 Train Loss 0.62215626 Test MSE 0.7871941786320218 Test RE 0.641027725375962\n",
      "107 Train Loss 0.6115586 Test MSE 0.7695523991265427 Test RE 0.6338039991010304\n",
      "108 Train Loss 0.60044193 Test MSE 0.7651483836930277 Test RE 0.6319878215592762\n",
      "109 Train Loss 0.5871734 Test MSE 0.7196389293789524 Test RE 0.6129050522137409\n",
      "110 Train Loss 0.5731486 Test MSE 0.6989421815207986 Test RE 0.6040272092646343\n",
      "111 Train Loss 0.5613963 Test MSE 0.6862984828373903 Test RE 0.5985389208823056\n",
      "112 Train Loss 0.54775 Test MSE 0.6899549724626389 Test RE 0.6001312630520432\n",
      "113 Train Loss 0.5333148 Test MSE 0.7021041995087195 Test RE 0.6053919785357607\n",
      "114 Train Loss 0.5190921 Test MSE 0.6932933709505067 Test RE 0.6015814009109666\n",
      "115 Train Loss 0.50291926 Test MSE 0.6938458023037697 Test RE 0.6018210298077997\n",
      "116 Train Loss 0.49152723 Test MSE 0.6800245356934962 Test RE 0.5957968025843149\n",
      "117 Train Loss 0.4792409 Test MSE 0.6754156365104289 Test RE 0.593774349115208\n",
      "118 Train Loss 0.4669565 Test MSE 0.6549260480272837 Test RE 0.5846985391424177\n",
      "119 Train Loss 0.4543072 Test MSE 0.6197349101674068 Test RE 0.568772849920462\n",
      "120 Train Loss 0.44634476 Test MSE 0.6012866514026096 Test RE 0.5602432828661239\n",
      "121 Train Loss 0.4387297 Test MSE 0.5728771543102997 Test RE 0.5468480006400828\n",
      "122 Train Loss 0.42260793 Test MSE 0.5438548461318337 Test RE 0.5328161477500813\n",
      "123 Train Loss 0.41034815 Test MSE 0.5171576277515181 Test RE 0.5195739207971791\n",
      "124 Train Loss 0.40330184 Test MSE 0.5010239088360159 Test RE 0.5114051560587689\n",
      "125 Train Loss 0.3844058 Test MSE 0.46671129411101125 Test RE 0.4935828169335128\n",
      "126 Train Loss 0.3651715 Test MSE 0.4295334447829261 Test RE 0.47351568498857016\n",
      "127 Train Loss 0.3505562 Test MSE 0.4263858170935525 Test RE 0.47177752971527803\n",
      "128 Train Loss 0.3375665 Test MSE 0.41601334588467387 Test RE 0.46600385403922673\n",
      "129 Train Loss 0.32719588 Test MSE 0.40856846112316036 Test RE 0.46181527794280014\n",
      "130 Train Loss 0.3173559 Test MSE 0.39865690950164134 Test RE 0.4561792477679023\n",
      "131 Train Loss 0.30819708 Test MSE 0.3844393543225972 Test RE 0.4479708929341169\n",
      "132 Train Loss 0.30218682 Test MSE 0.36548547009954013 Test RE 0.43678823800189137\n",
      "133 Train Loss 0.2934314 Test MSE 0.36365004955779023 Test RE 0.43569011071478575\n",
      "134 Train Loss 0.2788988 Test MSE 0.3570671098089061 Test RE 0.4317285815521851\n",
      "135 Train Loss 0.26897338 Test MSE 0.3469345747888857 Test RE 0.4255588908899974\n",
      "136 Train Loss 0.2586222 Test MSE 0.32964490514807104 Test RE 0.41481940175215387\n",
      "137 Train Loss 0.2467268 Test MSE 0.31628483875033164 Test RE 0.4063264221350748\n",
      "138 Train Loss 0.23966108 Test MSE 0.3106844880759398 Test RE 0.40271301177585944\n",
      "139 Train Loss 0.22844832 Test MSE 0.2798980350137746 Test RE 0.3822397089148205\n",
      "140 Train Loss 0.22031967 Test MSE 0.263252256266179 Test RE 0.3706994382785765\n",
      "141 Train Loss 0.21379982 Test MSE 0.24812601972139303 Test RE 0.35989186615306956\n",
      "142 Train Loss 0.20019512 Test MSE 0.23306285643583502 Test RE 0.34879673370369463\n",
      "143 Train Loss 0.18818659 Test MSE 0.22480091464162327 Test RE 0.34255863060930214\n",
      "144 Train Loss 0.18038061 Test MSE 0.2195834799006335 Test RE 0.3385600487746866\n",
      "145 Train Loss 0.17230184 Test MSE 0.2040992306849257 Test RE 0.32640481806639043\n",
      "146 Train Loss 0.16412278 Test MSE 0.19279111794269518 Test RE 0.31723375199539955\n",
      "147 Train Loss 0.1587452 Test MSE 0.18869456896012504 Test RE 0.3138452623148751\n",
      "148 Train Loss 0.15241906 Test MSE 0.1707556332424204 Test RE 0.2985543455784063\n",
      "149 Train Loss 0.147687 Test MSE 0.15105103202537556 Test RE 0.2808004020739287\n",
      "150 Train Loss 0.14332929 Test MSE 0.14427922389082923 Test RE 0.2744339114942285\n",
      "151 Train Loss 0.13941467 Test MSE 0.1413523808015082 Test RE 0.271636071399269\n",
      "152 Train Loss 0.13577795 Test MSE 0.14300236846855224 Test RE 0.273216857693646\n",
      "153 Train Loss 0.13142985 Test MSE 0.14287934225309187 Test RE 0.2730993069536503\n",
      "154 Train Loss 0.1284937 Test MSE 0.13368883910997859 Test RE 0.2641699736930901\n",
      "155 Train Loss 0.12492325 Test MSE 0.12653663540994692 Test RE 0.25700644722863686\n",
      "156 Train Loss 0.121015176 Test MSE 0.1242526087588806 Test RE 0.25467636044882813\n",
      "157 Train Loss 0.11611263 Test MSE 0.11074248996299214 Test RE 0.24043241513805402\n",
      "158 Train Loss 0.11321849 Test MSE 0.11245038230666457 Test RE 0.24227931942312325\n",
      "159 Train Loss 0.11123295 Test MSE 0.11035129821010327 Test RE 0.24000738231562457\n",
      "160 Train Loss 0.10703806 Test MSE 0.10400679301372745 Test RE 0.23300579888763612\n",
      "161 Train Loss 0.104452334 Test MSE 0.10194359804786428 Test RE 0.23068314078257135\n",
      "162 Train Loss 0.10161791 Test MSE 0.10150753055791198 Test RE 0.23018923423127294\n",
      "163 Train Loss 0.09806722 Test MSE 0.09401527104045451 Test RE 0.22153129084652456\n",
      "164 Train Loss 0.09515041 Test MSE 0.08834648385980301 Test RE 0.21474868426480775\n",
      "165 Train Loss 0.09180079 Test MSE 0.08036615601063209 Test RE 0.20482005336076206\n",
      "166 Train Loss 0.086385354 Test MSE 0.07561786859039044 Test RE 0.19867722840537652\n",
      "167 Train Loss 0.08435147 Test MSE 0.07068915781042713 Test RE 0.19209332796835682\n",
      "168 Train Loss 0.08204055 Test MSE 0.06624507835280964 Test RE 0.18595706625973238\n",
      "169 Train Loss 0.07982522 Test MSE 0.06051540229975384 Test RE 0.17773331420510544\n",
      "170 Train Loss 0.07687179 Test MSE 0.06091964690890624 Test RE 0.17832595793109587\n",
      "171 Train Loss 0.07340385 Test MSE 0.060600540543702154 Test RE 0.17785829547610982\n",
      "172 Train Loss 0.07141823 Test MSE 0.05817219585380706 Test RE 0.17425835328846806\n",
      "173 Train Loss 0.069933906 Test MSE 0.05906848320367153 Test RE 0.17559566348546718\n",
      "174 Train Loss 0.068971016 Test MSE 0.05558559199373911 Test RE 0.17034013792173422\n",
      "175 Train Loss 0.06654549 Test MSE 0.049439672979121954 Test RE 0.16064738909142542\n",
      "176 Train Loss 0.06371011 Test MSE 0.0435341518153376 Test RE 0.1507477784119326\n",
      "177 Train Loss 0.062095337 Test MSE 0.04050823645916833 Test RE 0.14541444333731596\n",
      "178 Train Loss 0.060763784 Test MSE 0.03807510684216632 Test RE 0.14097965460696596\n",
      "179 Train Loss 0.059529584 Test MSE 0.03518014800493746 Test RE 0.1355141695463338\n",
      "180 Train Loss 0.058614247 Test MSE 0.035291583668485824 Test RE 0.13572862532176216\n",
      "181 Train Loss 0.05745678 Test MSE 0.037092790903585277 Test RE 0.1391491739693862\n",
      "182 Train Loss 0.055673975 Test MSE 0.03692197413888503 Test RE 0.1388284049047091\n",
      "183 Train Loss 0.05435067 Test MSE 0.03456855794902085 Test RE 0.13433108061498505\n",
      "184 Train Loss 0.052948948 Test MSE 0.03229863816609764 Test RE 0.1298458227281251\n",
      "185 Train Loss 0.051894426 Test MSE 0.031601540181276803 Test RE 0.12843695528881702\n",
      "186 Train Loss 0.05079592 Test MSE 0.030977284971360427 Test RE 0.12716205930146865\n",
      "187 Train Loss 0.04956686 Test MSE 0.028931524154592065 Test RE 0.12289141183937148\n",
      "188 Train Loss 0.048587997 Test MSE 0.02902508278081256 Test RE 0.12308995429122402\n",
      "189 Train Loss 0.047695585 Test MSE 0.027221087253305673 Test RE 0.11920339118481427\n",
      "190 Train Loss 0.046638984 Test MSE 0.026631753459082322 Test RE 0.11790595974496176\n",
      "191 Train Loss 0.045173123 Test MSE 0.02584019222620021 Test RE 0.1161405148507443\n",
      "192 Train Loss 0.04399928 Test MSE 0.026722177890263293 Test RE 0.11810595680320111\n",
      "193 Train Loss 0.04341314 Test MSE 0.02669009082469395 Test RE 0.1180350267333102\n",
      "194 Train Loss 0.042767763 Test MSE 0.027785084879212885 Test RE 0.12043195621838981\n",
      "195 Train Loss 0.042345494 Test MSE 0.02886670857112173 Test RE 0.12275367722337212\n",
      "196 Train Loss 0.041860756 Test MSE 0.02848631873986964 Test RE 0.12194220437598471\n",
      "197 Train Loss 0.04090396 Test MSE 0.026518989844704254 Test RE 0.11765607747646627\n",
      "198 Train Loss 0.039883275 Test MSE 0.023423828618240564 Test RE 0.11057700372916497\n",
      "199 Train Loss 0.038457334 Test MSE 0.020425072355135444 Test RE 0.10325656626141558\n",
      "200 Train Loss 0.03739861 Test MSE 0.019445724278835272 Test RE 0.10075066901978201\n",
      "201 Train Loss 0.036216788 Test MSE 0.019391293214342402 Test RE 0.10060956321561887\n",
      "202 Train Loss 0.03532483 Test MSE 0.01620697030083011 Test RE 0.09197860002373144\n",
      "203 Train Loss 0.03498266 Test MSE 0.016068683320266893 Test RE 0.09158535281677523\n",
      "204 Train Loss 0.034532446 Test MSE 0.01573155417448943 Test RE 0.09061950634186307\n",
      "205 Train Loss 0.03400089 Test MSE 0.015563683164638468 Test RE 0.09013471035137485\n",
      "206 Train Loss 0.033476938 Test MSE 0.014998396377282296 Test RE 0.08848268450540749\n",
      "207 Train Loss 0.03279713 Test MSE 0.014210388471683601 Test RE 0.08612690721187456\n",
      "208 Train Loss 0.032019187 Test MSE 0.013944298625565267 Test RE 0.08531673250994781\n",
      "209 Train Loss 0.031427886 Test MSE 0.014172506355504991 Test RE 0.08601203185767829\n",
      "210 Train Loss 0.030873513 Test MSE 0.01380387481291142 Test RE 0.08488606131078194\n",
      "211 Train Loss 0.030321559 Test MSE 0.013539575023746878 Test RE 0.08406948624542668\n",
      "212 Train Loss 0.029606558 Test MSE 0.013500719107666627 Test RE 0.08394876813247917\n",
      "213 Train Loss 0.0289752 Test MSE 0.013654118859684778 Test RE 0.08442434821858495\n",
      "214 Train Loss 0.028589016 Test MSE 0.013327351612592157 Test RE 0.08340801866663689\n",
      "215 Train Loss 0.028289922 Test MSE 0.013124358271983647 Test RE 0.08277037361833975\n",
      "216 Train Loss 0.027972277 Test MSE 0.012276217723895819 Test RE 0.0800512592514145\n",
      "217 Train Loss 0.027510388 Test MSE 0.012260474482739902 Test RE 0.07999991320111328\n",
      "218 Train Loss 0.02683511 Test MSE 0.011621591793275288 Test RE 0.07788766518390068\n",
      "219 Train Loss 0.026130415 Test MSE 0.010782326877195478 Test RE 0.07502260219339703\n",
      "220 Train Loss 0.02564813 Test MSE 0.010571371634303325 Test RE 0.07428507175693082\n",
      "221 Train Loss 0.025233475 Test MSE 0.011155635961549105 Test RE 0.0763102794066961\n",
      "222 Train Loss 0.024727877 Test MSE 0.010994174610075649 Test RE 0.07575602731743884\n",
      "223 Train Loss 0.024253925 Test MSE 0.011219099014875677 Test RE 0.07652703151418984\n",
      "224 Train Loss 0.023509603 Test MSE 0.01056752868299399 Test RE 0.07427156831231893\n",
      "225 Train Loss 0.023123005 Test MSE 0.010034799848965987 Test RE 0.07237527621579819\n",
      "226 Train Loss 0.022734175 Test MSE 0.009581610993188052 Test RE 0.07072209939813959\n",
      "227 Train Loss 0.02238317 Test MSE 0.00852726804571282 Test RE 0.06671766437470998\n",
      "228 Train Loss 0.022086967 Test MSE 0.008474794751840275 Test RE 0.06651207109485834\n",
      "229 Train Loss 0.021726182 Test MSE 0.00856506395033529 Test RE 0.06686535918284679\n",
      "230 Train Loss 0.021444697 Test MSE 0.008223285444138383 Test RE 0.06551768741791907\n",
      "231 Train Loss 0.021314869 Test MSE 0.008089068399714761 Test RE 0.06498081151865776\n",
      "232 Train Loss 0.020999284 Test MSE 0.007340836537879868 Test RE 0.06190256625428426\n",
      "233 Train Loss 0.020733772 Test MSE 0.007065783791772633 Test RE 0.06073178543306879\n",
      "234 Train Loss 0.020491878 Test MSE 0.006648085852155165 Test RE 0.05890934399098147\n",
      "235 Train Loss 0.019951157 Test MSE 0.005622764856611103 Test RE 0.05417648667386142\n",
      "236 Train Loss 0.019625405 Test MSE 0.0054561066054360265 Test RE 0.05336755428777324\n",
      "237 Train Loss 0.019275552 Test MSE 0.004591853297114345 Test RE 0.048958700191184756\n",
      "238 Train Loss 0.018983679 Test MSE 0.004568280161238724 Test RE 0.0488328691768544\n",
      "239 Train Loss 0.018678404 Test MSE 0.0045221411992365694 Test RE 0.0485856409293332\n",
      "240 Train Loss 0.01839235 Test MSE 0.004243852262150671 Test RE 0.047066944461907165\n",
      "241 Train Loss 0.018174153 Test MSE 0.004037949324241693 Test RE 0.04591095313583327\n",
      "242 Train Loss 0.017984321 Test MSE 0.003979554522020804 Test RE 0.045577773566636524\n",
      "243 Train Loss 0.017740604 Test MSE 0.00403651783741713 Test RE 0.04590281450593399\n",
      "244 Train Loss 0.017549226 Test MSE 0.0039001776102194426 Test RE 0.04512093279174689\n",
      "245 Train Loss 0.017304877 Test MSE 0.0036046247444131135 Test RE 0.043377638659995346\n",
      "246 Train Loss 0.017134354 Test MSE 0.003494662754912377 Test RE 0.04271087931525988\n",
      "247 Train Loss 0.016918276 Test MSE 0.0036110170105581713 Test RE 0.04341608352045209\n",
      "248 Train Loss 0.016820263 Test MSE 0.00344011966884702 Test RE 0.042376262682749674\n",
      "249 Train Loss 0.016485807 Test MSE 0.0030430301930929804 Test RE 0.03985556843950434\n",
      "250 Train Loss 0.01609466 Test MSE 0.002750757434450872 Test RE 0.037893264787119914\n",
      "251 Train Loss 0.015796954 Test MSE 0.0028670619070945446 Test RE 0.038686052083367305\n",
      "252 Train Loss 0.015427101 Test MSE 0.002880812950495404 Test RE 0.038778714407846845\n",
      "253 Train Loss 0.0151234325 Test MSE 0.0030672725147522935 Test RE 0.04001400834692375\n",
      "254 Train Loss 0.014876445 Test MSE 0.0029922441326339254 Test RE 0.03952158822372224\n",
      "255 Train Loss 0.014648009 Test MSE 0.0030347741020211464 Test RE 0.039801465345944816\n",
      "256 Train Loss 0.01443046 Test MSE 0.0032032985695370974 Test RE 0.04089164546804984\n",
      "257 Train Loss 0.014346996 Test MSE 0.003211781126591815 Test RE 0.04094575163090526\n",
      "258 Train Loss 0.014256368 Test MSE 0.003205572461559512 Test RE 0.040906156555449116\n",
      "259 Train Loss 0.014164844 Test MSE 0.0030734588430107353 Test RE 0.04005433979781734\n",
      "260 Train Loss 0.013967537 Test MSE 0.003073803558181486 Test RE 0.040056585956324144\n",
      "261 Train Loss 0.013664186 Test MSE 0.002807373356654358 Test RE 0.03828123708466651\n",
      "262 Train Loss 0.013410207 Test MSE 0.0027317758372829284 Test RE 0.037762297254914125\n",
      "263 Train Loss 0.013215455 Test MSE 0.0026806300431202216 Test RE 0.037407123820521374\n",
      "264 Train Loss 0.013044704 Test MSE 0.0025202678170385684 Test RE 0.036270974475788\n",
      "265 Train Loss 0.012891323 Test MSE 0.0024184337086200092 Test RE 0.03553063511581316\n",
      "266 Train Loss 0.012754342 Test MSE 0.00236218695863576 Test RE 0.03511502731995006\n",
      "267 Train Loss 0.012578782 Test MSE 0.00229752037335579 Test RE 0.03463104227345772\n",
      "268 Train Loss 0.012479879 Test MSE 0.002156057283855073 Test RE 0.03354795289661297\n",
      "269 Train Loss 0.012382332 Test MSE 0.0021611570956596798 Test RE 0.03358760564527249\n",
      "270 Train Loss 0.012251132 Test MSE 0.00209244342092173 Test RE 0.03304933602156212\n",
      "271 Train Loss 0.012126348 Test MSE 0.0019916375658009023 Test RE 0.03224341488650339\n",
      "272 Train Loss 0.011980559 Test MSE 0.0018928312340125504 Test RE 0.031433433630544676\n",
      "273 Train Loss 0.011632605 Test MSE 0.001783440195837879 Test RE 0.030511611944012286\n",
      "274 Train Loss 0.011408115 Test MSE 0.0017491642873044154 Test RE 0.030216988394571827\n",
      "275 Train Loss 0.011266849 Test MSE 0.0017701613201683163 Test RE 0.030397810288888213\n",
      "276 Train Loss 0.011141449 Test MSE 0.00176654037761391 Test RE 0.03036670434706692\n",
      "277 Train Loss 0.011024702 Test MSE 0.0016843887536650236 Test RE 0.029652208378052648\n",
      "278 Train Loss 0.010984925 Test MSE 0.0016299353255894182 Test RE 0.029168967934700783\n",
      "279 Train Loss 0.0109077245 Test MSE 0.001558075583348172 Test RE 0.02851872712609941\n",
      "280 Train Loss 0.01083807 Test MSE 0.0014453202192209382 Test RE 0.027467423018986428\n",
      "281 Train Loss 0.010724821 Test MSE 0.0014503939134373459 Test RE 0.027515592003673452\n",
      "282 Train Loss 0.010617781 Test MSE 0.0014899998253374961 Test RE 0.027888745917795815\n",
      "283 Train Loss 0.010537838 Test MSE 0.001425027659128437 Test RE 0.027273917584904432\n",
      "284 Train Loss 0.01047509 Test MSE 0.0014272594627022072 Test RE 0.027295266718772394\n",
      "285 Train Loss 0.01042439 Test MSE 0.001393343753434666 Test RE 0.026969010623731613\n",
      "286 Train Loss 0.010373844 Test MSE 0.001380331515137047 Test RE 0.026842785363467903\n",
      "287 Train Loss 0.0102658495 Test MSE 0.001383840062169639 Test RE 0.026876878406818593\n",
      "288 Train Loss 0.01017334 Test MSE 0.0013177964796885994 Test RE 0.026227690396811054\n",
      "289 Train Loss 0.010082611 Test MSE 0.0012397156773461075 Test RE 0.025438817726907065\n",
      "290 Train Loss 0.010021804 Test MSE 0.001147903686209263 Test RE 0.024478714221558555\n",
      "291 Train Loss 0.009925759 Test MSE 0.0011201972227967072 Test RE 0.024181493634305103\n",
      "292 Train Loss 0.009797721 Test MSE 0.0011478414045447234 Test RE 0.02447805014330615\n",
      "293 Train Loss 0.009715794 Test MSE 0.0011760492138801208 Test RE 0.02477699452513245\n",
      "294 Train Loss 0.0096642915 Test MSE 0.0012056890724051587 Test RE 0.025087277819815137\n",
      "295 Train Loss 0.009613352 Test MSE 0.0011635498911533573 Test RE 0.02464497499377504\n",
      "296 Train Loss 0.009546333 Test MSE 0.001231200166749671 Test RE 0.02535129854680788\n",
      "297 Train Loss 0.00945368 Test MSE 0.0012166677066068274 Test RE 0.025201237508641464\n",
      "298 Train Loss 0.009384187 Test MSE 0.0012284534150206656 Test RE 0.025323003958405508\n",
      "299 Train Loss 0.009269768 Test MSE 0.001213630392769428 Test RE 0.0251697614128062\n",
      "Training time: 121.49\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f89307b6650>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGiCAYAAABd6zmYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACrfUlEQVR4nO29bawlR3kn/rv3nLnXL8yM/AIzTDBZR/E/u8gYbYYsMsrGTvyCEISw+QAKKH+i8AFisBgBIhg+hOwHD2G1kKy8YZUswhGInf0AziItQR4UMgT5H60xWNggWVrJC2bj2dnsOjNjM753zrn9/3BOnVP19PM89VR1dZ+X27+rq9NdXVVd3f10/ep5qeqNqqoq9OjRo0ePHkuIzUU3oEePHj169JDQk1SPHj169Fha9CTVo0ePHj2WFj1J9ejRo0ePpUVPUj169OjRY2nRk1SPHj169Fha9CTVo0ePHj2WFj1J9ejRo0ePpUVPUj169OjRY2nRk1SPHj169FhaLJSk/vRP/xQ33ngjrrjiChw/fhx/+7d/u8jm9OjRo0ePJcPCSOo//+f/jBMnTuDjH/84vve97+Ff/st/iTe+8Y348Y9/vKgm9ejRo0ePJcPGohaYfd3rXodf/MVfxGc/+9lZ2j/7Z/8Mb33rW3Hy5MlFNKlHjx49eiwZhos46e7uLh577DF89KMfDdLvvvtuPPLII7X8Ozs72NnZme3v7e3h//7f/4vrrrsOGxsbrbe3R48ePXqURVVVuHjxIo4dO4bNTdmotxCS+od/+AeMx2McOXIkSD9y5AjOnj1by3/y5En84R/+YVfN69GjR48eHeGZZ57BK17xCvH4QkjKgWpBVVWxmtF9992HD37wg7P98+fP45WvfCXw/z0NvOTgPONwPKl3+jtwv4MRhsM9DIZjDIZjbA7GGGCEIfYwwBgDjLGJEbaxiwH2sI0dbE7Tt7CLIcY4gN3p8cn2ACNs4zK2sDPLtzU9vhXk3cE2Ls+2hxhjC5cxwCjIP8QYmxhjCzu1dg0wDtIAYBMjDMfT6xuNZ7dgMJKtt+Phhrc9AACMBgPsTcVgPD3DaHr1exjO0nawNU0bYAfbGGMTu9O0+e/2dHtzetVbGE2Pu//xbH8bOziAy9MyI2zOyof55nVP2nEAYwxxeWcL49EAo9Emdne2UY0GwGgAjIbAeAMYYf4/nv7CS4O3H9wkdyNJ+pDZHk7/B2R/CGBQAcMRMBxjYzjG1vZOIIMHBvPn7OSiLgu702c/l7kh9rCF3ekTGs1kazCVk/n/Xi1tclmT+ty2w6a3zWFvepHj6e/I2w//XeudXAzD54Ytsr0VyMcOtnDZycZ4G7svbmFnZwujF7eAF64AXgSwg8nvC9Nft03TpX23/QLZf9F7/qgAXJomjgD8dHrwEoDL0+3L0323fRmhgI2maSBpYLY5cELnbx9AKIzu94B3fMDkpem0TiB8AQ7Ahsve9hjhtfv3zO1fBPD/4uDBg9CwEJK6/vrrMRgMalrTuXPnatoVAGxvb2N7e7te0UsOAgcPTbaH85dswyOrwXA023b/m4NJ5785fZ02McY2djDA1vRVG3qv3HDaSQxxAINpRzKYkswAW9iYEs+mt72BbWCat5pub2ILexhiE1uoMACwjT0MsDF9lSdiMcD2tC3V9H8TA1QYosIAG8CsbRsYjiekMxj5xL6BwWiPve8hSU22R4MNjDHZHmOyHd6ZTezgAA54HZFrwQEMMcIAQxzAGAMMcACD6fbm9O6MMMAmtrExvSuTTm4LwDaq6e/mlAQrbGNvehcnHdwWtqbbm9ie3o0tVBhiY2cLG6PB5P9FQlIjQlIcQTXtK4bM9ux/TlCbU1LaGG7P5G+4vYtNbGFzRj4HZgRV33aDp6G3PZHDiZwMZiQ1H1K4/wFJGwHTNGBOUpNfysp1OILyiWrsnQHAdAAzl5PRdIAxmA5uBtNnuDN97pjKxcZUFnzZqLCNvZ0tjF/cwuj5q4AD28CLGxPeGEz/t6b/mwj7YXd8E8AegI3pv49qetz9b2DOSQCAQ5iQ0CUABzEhqpdgTk4jAFdj3um6X38bXoV+Jx4TOiAUvANMuk8wPjFxJKZtc3XSdIoDCK/HgV7rZZLm36vJOWIum4WQ1NbWFo4fP47Tp0/jX/2rfzVLP336NH7jN34jvUKPoDaJFgUAw6E+SpTgjzTbxHhKhKkYDQYYjscYDweBNjUebtaIajzc9LbnWtS8DfFOqgsMMZ5SdogBRtOOb3J8MBxjPJq02T3rvRFzDa6qkbc/8n5BtqXy/rY0wI3AaVGzfcS354QyCmRkwDR4QAjJ0QfbFkab4ur1n8UA4yn1jWfy4ucfTwdv/n5YbhSU82Vurg0Ogt8JA03e673hCBgeqA8KgHpak//ZJWxg3llfAnAVJkQFL02CIwLXGV8mlbt6aUfPaS2UQFwaRyi52xJZ+WlSu3yMyDGfzOjL9xKh3vhZOsEHP/hB/PZv/zZe+9rX4tZbb8Wf/dmf4cc//jHe+973plWUSUA+uBc+PF4/Rw6pWDHyXm4froOwwCclK1w3QdO4tpWC3+FRSIQ1KzscY+QT00wWhpgNm/1HS98RSlQaOKuKf0wpPxiOagMlX36kbUkuOWLR5JEjPT4fR3wj8RkMMVblYeAdd9uORN325BnLMjAYjjEcjjEejrE3HGPWeUoEox3LIio6yqFExQkUJSOfoCg5aZqKj5imE9OaYsSUQ1Ic3HVfibnG5LbpvXjRVOPCSOrtb387/s//+T/41//6X+PZZ5/FzTffjK997Wv42Z/9WXsl5MXfJPvO1DfZrr+cvq1+nmZRw9MgkUuMdOiL63cwY0yMKZI2JdZJtCiuA5r7FpZDu/I7NToiHw7HGI8MYixpS5oW5Y7TbY6o3D5j6guuZTAOZEzejmtZ3L4Eru6wXvkmuGMTmatrU1w7Zs9nmu5rwS7dbTvNyRFW8DsYTzXQES5ja3p/N9rToq6Y1jkz+21MD1zpXR0lKg6cJuUTlKXrPSBsS6Ri2bZoV0DdNmoFR26UwN390DTRei0LwT333IN77rmneL0cIbn0wSxoohtTng9n1qNmEQCzTrhR/RGicgS1LKCaUmhGkkfXFIPhaGb6Y04yQczc5+fx02KIaFFhO2WCSd3m9mOQZD51YOY/mzkJDWt5Jul1k5/Tp9y2r41Rk5+Pmslv0oCy/yDbKlFxPhknWO5YiqkP5Lhfp5/O7VvMeTESKz2dx9XnE7b/e5WploWSVElQLcohxR+ldQjLhBSzn7W+pmUsZsAU4pmXIb4op1UNxgExBX6poXsJNuzmPnecg6ZN+elDPrJyyGlUBiLSzICUcCR/lERs89+QoDgim5vsQtOf5XlyJj+67TQnP82/1sFwEJr8htNnqxFMrhb1ItkO/FOUqOZ3TXZ05pj6HGLBEm7fqjUlEhMn9zGIAUnOv3cAk4gVn8h1rAVJ+QQ1Czsfpo0OJbStcfmEYyGfMH9o8gPm2hLVqHwtSjP1xc7dFqj5x3IuP3hiXtF4EuVXP4FMWCDHaDm6zY24Z3lCUx+VQ0owFu0mZoqLyahFU9LqGAbkMgrMflrZcUBCQ2977A08Qg3LZPKbVFTu3zfxUcJzZAVAJ6rwjtXJigYQOMRGSVyUnRSdp2lNfj6BmDj51prGgSMpOu1jRlix+5h26qWEC+mNQTL/BXmMLzqXryuta4R5+HAMqaa9GClIx1OJziF1FO4jIDQaPMGB6zO4PLE6pH3jLRgMZP+nTzZWE1+K3A2ZcilmPilIQnuO4eCrHs3nmwL5uufRfQ5slN+8kXXNiku3aGAgv6xGNcTcr8KZ9ShBcSMiaQ4SJSU/ndOmNHNfRGuSrpk2wyLnGknVpn/YzIsrTVIUlIyGjIbFgTOdLAqx0amfz2+nr01p8MPOa8cKE5EVsQ6LC5jw4Z5zoFVxJj9qlYlpUbO6LNvzgAkAs5H/cKZRNfdHNTVHS2U4WePIxxEVp03Fzuv7XN1zdKZJX6vyQ9FHXh7W5DdkTH45/yD7TnuivzWicqCmK2v4ORD6rig4oqIaVMzXlEhMMXKKdQUxTWqEOmlFsFYk5SCZ+mhkFdBONJ8FsblRfjSbAx8hOJxdg5WoXLnJrx5yzpddfAAGR1gzvxRQN/lRDSpHuzKOLiX/6CS7PHfJColUYv6oMP+IrYsjQu55+/4pS4SqFCRDQ9D9sHTJ5DceDhDMAmxCUL4fiu6D+RWJym+MNfzcr9hHSvi5tB0hJ42YNG1KarJDCkldxmSljwjWhqS0iD4Ky0vcFCnRely03zw9PXRdbJOiRYX1z+9Q6XlRVnAETYmbBk+IkAiJbsfq4H6BuRYVARekkBM0Ua/XPvdJzyv5x0L/0wi82U6r09eE/SAYn5ysvshJQ4jJz+9sZ3kM/zQfmG0g9E2xROVrTyDb7jj1SdFnSS+AC0GnhGUgJ+m6YtoUTZfqBfhI2SH5denuf4D9QVI1M8q0s8hdZcIymTIFYdj5OIm84nW7TjvUpgDUNKpwdYnwsS+DZiSBm9AbRIlxwROzwtM3xC0bxb00khYF7zjdFkeYYcCEb+rT/FHuOrlj0twpd8zio6xrS3UtKu6TlYmKqxtAjcy4uW6UnHyNkK4+UdzkR7Uo/7lSUx8QPu+AqFzEGryMnIDRpYQkf5Q0kTZxXpNGvKnaFN3mzuWD+p84kjKuN7DSJGUJiEjJt0hYl0ayBk9YtKa80PO5yJTQsrSlcsx1MM+3ZvKjZMRpUVqglfSmGLWoWVsZDb7NSbyW/PYJwVS7rZv8fJnwJ/K6/WAaAWvmG3r1R0x+TpvykUJSNH/M1HcFJjJS06iAuVbFEVTTyD7/eIJJz99OJSiJnKyMIZHTEPuLpChq4b5+4MQg/iLGlqHJiYrSQLWqmJalhav72pQGKQiiS7NebLkjag6iZiJLHWGFVV2bottun29QfVvQotRmMERjJSVajk/X/VEWMpLMy/5x9yz8OU8xkx8diNhWn7A+38z/EdkHsw2QMHSEz75GVH4lUuCEg6RJ0ZMYV4NoQk7a9WvbHLigJM4vZZw7vDYk5ROUZOrT55ukj1S7jAKUSIibN2WrL1zRmm5zsBJZLGycgxSGXM8Xal4YQPdLDUeAWzbJ75iKmPvqWpRk6otNmpX8UbFj7jhPStyk39DUZyFGPcw8nOAbLt0lh5z7c6P8bZ/4Wjf5UXMfyLZk6nMalRip5q+0UCEkLAduIqsUMOHXycBCQJbjMPxyTfNBCcrf3s8kpU3crYWlZ44wS0LXiMLVpf0Xu/l54487J9w816elhZtzecWOkvil2Cg/X5sC6kTlMAL/VtReUs8HkbiqidUfFTvm6rOcs2kejmSoNgXUiWmSNqztD6CvPlGL3IyZ/HJICsI+R05Um+LAdkOUsBxi71mkB7dqRLnalPZraRcQkpJ73+ggMbHKlQQlKKdFaX4oGq7LHee2u4RvCqFwfql54MSA6RDC+6KRT2zlc3e3FgErkfnPu7bgLKdN0W14aRSi2WNemFtMlkLSduT8ctDEpCnNgoNy/FqxcHS+nDC/zSOkeCh6ZlelkZRk7uN+6bZ0rppW5aPA2ngp5ET3rWRF06BsS9BMftJAUMBKk9RgwBNUPd/yB05YYQ0/115qztTH5XEftdPqiKVRxPwX83x6EIXVPBgsk+S0qRhRwTvG7StalGTqswyGUnxSOYvCWo/Rfc5sx2lTYR31FSZcXbHVJ6hJt5HJD0ya+5fMfdwvUA+c8CHJVAn3tUYgVoJK2ZfOybWJA2fyo9pUAlaapGIIPzBXJtihCVLnQ6XXbSEvaVWJxYWh24kr7BBp9FiQl34I0demJoXtc6T8PI6giBaVAm1+lGWfAw2akL4NFa+HJ1Pr83GgQUC+yS8Wiq4tOJts8qOBMU00KTDHWJ+UAGsXxGktJYjKSk5NtEk/T0ybYj62rlW38rAugRSD1CEs4tMeFMF8KGLymxwvuzq63I5uCM0frWtRfZymHJj8OG1qUpmt45DeEiJzsUWNLRpQbIkubl+TWS0YgtYX07bqgQ80ak/uToJvgEEPRZdNfryZ1xxAgUgamF/OF+UHTlBwxJgTpMO1xUJUOeSUqklZWMOiTfEfDahhLUhKIyi/A4stSUM7iDaJiWpVkpYVHrdpSlI+LpJvFKQtVhxo5+Ujdz7V5nBc16YoUQFyhxPsx7UoydRnib6LBU3krjEZiw60QtKotMm9Unlu9Ql/mzMJsiY/qh27X0mrspKUT06WoAlXliOkXK3d3+5Ck7KQotROH9TnRLUodz/2YMJKk9RwuCeugh4LnKinLYM5kJ/Qy0UApuy7NFsb9HxcUEUOcifuJp3Dj/qjn/Dgov00UIJqqLnHNaQ0jaspcoMoKHFJ9XBzqqjJb5LGrz7hn0M0+Y0O1AkhRlRgtoF6RxuVD9RJyaqp03q07Rxyovtta1J04MdpUUPsD5KiENfvE+zzOWv45ZjTUpZCkuYYSXlj3/KxHFukPyoGzRQECPdrtio6I95BpB8hKg5BkEQoR+F3zEampbg4rSp9P31AxUUKciY/mp9bkkqcCqCY/MIJu/JnP9y7oq0+ERCWFkDBaU6Wzh7QJ/DmwEJYkqaSo0U1IaemmhRgM/ddwRelWBuSGjAj2yZRfWXW7YutIGFbComWaRJ84b/g8qc5+IVl2zAHWlaXiJUHAL+5dHLvzOTntClKVABPVsKXdjUtSjL1ycEMzQhr1qTIeVweC7i1A7kVzH3Cspj8/Ll/kl8qtvoENfm5Z81+Z0oiKj8NzDaYbc3kx2lR0jEHzfwnaVD0N1drakOT4q4b0IMnjF3f2pBUDClkYBm55gYoUGJKXy09DJLwtakmgRMcIcRWQ/fLtOnP8kfe5tBzV1ZagLYW7Rfx4hIzH9WiUsH5mFKDJlwaJ58xeZcDKvhr0bQkTrui5me5TnlVdG71iWDSr2/yo+s0UlKi6fCOWUiK2/frsKZrddFjtC3LRFSWfUmbcnn3C0lxI9lgnzFzrDOsgRPuZV9uU582CVQXXWryq2lTQJ2o2Iq8noYQlC9rLmAiBsm8HFs2KWelFIspO4zui0Un6hF8fh2cn4quTmENReei/WZpw3Hd5DcyzJnitv1fui3tS1qTlk+CdL5ccqL7ljRum7ZNImtA16aouW8/hKCrwRGCqS/lpbXk7wqhFhWa/KhvKjdwYpkJq+6jqHeGs2PMMknj0UAmKqBOVlQ7EgN0RmR/XJvA6zpeSbuJae4lNflS8pxj8ktdFb1OTsPp/tzkNycrMmdK0540DUrrjLk1+/gL5TUHRMpw+02JqokWFbsnGlkBcuCET1QGrDRJUUikJS2yWSufaSKxwCeO+kRH3UwnBUhYtSauvjDv0Nu2EVWbq6Zrznkur7cDAISgRkIABY32s70xkhZlah9zLMcHlerHtE3itV2/pE2lPjOal5sLRyP7NJPfiEZuDjfCTpFuW0xabfSOnPbF5aHbFiJpW4vi7pEGTZOyapcJp1t6cJ/l0F486mhuug5aU/gvYpgeak0SMVm/M8Wdc1HgTD3aOn2pYetDr/OqaVNAnajYSub3lBKUr0UNjOa+WbUG813JqRLcBw41AqV+Uw4SMUltpCZAGn4upbv3VFqEtmbyGw3DjlgiKii/dDsGqdPl0rV6YwTlfi1aFN1PLaf9xq4D4DUpl75fzH0OVl9AV3AvWV7Z8JHImtIw6NwBG1FZNKBYnkWSmxZ6HuTzTH5OmxKJCqiTFZEpaekjqkXF1uqzBjpIQRISmgy4LP6w8Cu7oTZlNfn55mq3L/mlaCg69UdFTX4jJcoPJI3+gmynIENTCMpK27lEZU2T6qTn5NoXux4uwm8I/mslSjUricFwXJvMW3Ix2TaJLScSz1JGI6pwdQl9rlTKwrJavRwsEXo0ukszDwXlBi5gYtppUlPQFAFRATVSonln9QtalHQNFuKIkYSrSyprzW+RN6mdthBzu8nPr9cSip5k8pMCKACbNkW3m8JCWPR8KVqUv12aqGia1lYKLizfbe/HeVIU7sXnzBzrBkpeHFHJc6JkEaDh5001KIu5TiQf1hTIzRfjr4dqUwBDVAw0gqLLcaUOkHiflD2cvIkPNeddCL8fNQING9fKaUEvllD0FJMfgDCAQtOmuF+6Hb8xNhJKDZrwtzXyaEJMWl3aL9duCkmTcvdiN1LeeJqVgiWiz2qG08wvuX4oSiYpZkFuPpT2JV5t1Ct1Klpns4h1/Zp8R8gRCjdHihIVgBpZUfOeqC0pUx7Y/NDW8rP5oCyh5SntcSi5rp+0LiXnf/K3uSWS6kEVvMmvNmfKBVBYTH0A36k2ASUmjqisBEV/2yQqbltqm9R26br97f2mSfkExWlRPuITHfP8SRxiRGRZdcLyWfg88+FwVtahzag9DTkjcrGuwRjjcbh0zmg0CCL9aJi69rmNcDUTXoui7aSmvhixWEmraaBOU2uCxewX80uF/q34Ekk+Ifnb1OQ39oJkagEUlJQ0YmqzV7RqH/62hURSSSlWVjo/dw0aYXHk5Pb3iyZlNbFwkVO5dvsuwWtf/hyVOYFZiKp00EMbQRTaiufa/Ki5pjkXa0dGFqJi26IQFI0oLRF5N6vPqFXl1p+Th4Iz+VkHG0B8vhS3Kr5k8vNXRgcwD6DAELNw9Ekh/Zdu54DTmKzl6HZMm7ISlZXAwGxzv3Q7dk1ckMp+iO7bZAgq9UW2jHTb/GQHwC+NRGfnu7S41mX9VMfQfEw7lwVax2UJopDKxdqTQkI0X30lE2FuHaNFWcFF+qWYAtvGPBqvHrQiaT98SHo8v+SXoqHo8zyhhjXCYDJQoAEUmjbVpqkvB1aSimlTTYhK2+baI7WfM2vS+77D1BGpduXB2ddz/FFtQjL/1TrYhLbG5lLpvqZ0/1TXyIka801+mjY1y6+a+zy5ErQo2l4t1DzFp+TqkyCZFrU65vOkZBmj+eVBBj+5l66AQve1url5c7H1/QK/lZszNVtM+EC94/V/LaY+unIEB06DsmpVkoZiIakuiMrSRu56ON+U+913PqnMgIhS9bYNzqxn1Zq4ujjUV6Joj6g4/5JmNkohKr/jlLQpRzzsahRMPqBOUAFRCXJiWZ18Ur5+PDV0ndZnhXWOln//63On0lac4PxSmiZG51Fx6/v5K6PP5kwBCMLRU+dGWcipKWjdMVNbG0Ql7dPz0fbG7gslq/2qSUnzTAaoa1Olz5WDnE90WOpMbZvrELTOJSV0vTSpWZ3s/nGAbzPVpubpwrJJ4Amqlod8+TkHqfKZqonlnocrb50H15ZfShrIzI57Jr+Br00ND7gT8790G5BJq3SvWYqkShIVt03bmnIfOI3S2F2sPElZJkLSfPbw3eUIovA1Jm0xWVsUoP7ItU92uPOVjgAMJ26mL1I6bycxG01Nfo6gNKKyIqZFWbSmeT59ZQqpnLmtGQOqrohMg+SXqq8+Ea7vN0tzc6ZGQ29R4UrWpoA6+XTpm2pi6vO3m5j4rOQUtI983oa+R7VFmxE+g/1g7mti7rCYX0qhieYkmfTkdJmochaSpefMOdYE2uRe7byxz0pIK1Fw+WZ1KqubcM+3VCj6JD1vfcnSGrtPQs7kp93rmP/Vf46hObu+RFI9kII3+Y0xnzMFIAxHl/xPbRIUp0Vw55XapJngShMVd77ZtvCVasmfyy05NsT8WUgfkaTV2LKtBmKhvFJHYkmjdTWF5WOHda3J9lXeeiCF/JjdC5+6tFEMiwy8CFZGELQpYE5AElmJJj5lGaSm7e4K0iThZnXqfit6npgp1xKK7pOXH+XnNOaZNuWHo09OzmtRFoIqSWIrQVJTchKISZtj6PKyK7sMIh8a9ZqwFmg6W95qpgnLNfNP+SPC+jF9NYnh7OWUAifixGRpW2lY/RXWb0fRuv180gifBlNon9rwywS/wkr7ub4i6Vnn+p+0c/nImx8Vf4Y5z9kvyy2BxYeih/4q3+Q3C6CYfUOM0aZSCaokuHPFzGwWk18xoiLkNJV9bqmwGIJ3zpHWFbbIibUgKSk6iQu1XZSfSdOcnDmQM4PM8+iaV+y4BV0vfaRN2uXz20OhNW0KkKP+avUaXsi6/NlMc1K4uFQv2z5GxqU8bYDTltIjMUP/Ijdfyj+f5q/y62QDKCzalAUlgiraJKkmRAVMCEogJ26CuwU0SKkajmHRpVaapIbYw6ZAUBoWERkVgzZRVwuOCI+lrTjBmfpomyxog9wk0pKuT16Gh3xWIoGoRLMeo0VJYducP8oWWBEPV6dRrF2aC+ttin9aHuC1Jzn0XPdLSSY/ALNlkoIVKABemwLknrBN899SkpSnPQnkxC0N5kNbN3OeZ4TRpbHJFrXSJKWhhFljmVH6a71SnkUsLOuQGynGleMm97ptU52CmY+ust/UBJwbWGEtn1pvbO6SJT13sVl/OzVE3c2ZAlDXptzkXgcuss+BI7RSoHVypGkhqWImv1B78snJsmaltB9+KXv+7lWD0f4jKX40K9n67dFS0ihZAxfRl2OSy1kKyX/B/X1axgopb+lw9Kbhy7Tzo9FnElFF640QWYkBkcX010Sbb0JcTZ5L7mKzdFsKRZfSxQAKABgOATAmP27fT4dwLBdLQ1Kh9sRpTuxKK8qqKz7ogs8Om1dcNs3nXRuS8l/CEnNMHJZJA6NkFCMwjVz8OiZpQ/Y4TbOQUknti3Oic8hZASHV3BfTomi7rfLWxqomJTQ6ui/dz9S1/GhZoD6pl26nmPzonCkXQAEg9E2NvIVnrSRk8WNZiW8pSKquPXFmPXZ+IPPlCRGMGFRGK8bKk5RuGinbmXSJ1Mi/EoET1jb5k3ubgnZkXMdGOzJanh7z69C0KUA2SdTOk/mtMskfZV3Dr4QJkWsTkD4Ai5FOsBxVovYVmvj0gJoUk58LoAAQTu4F4mTTNhZOUhWo74ma9qSoViCU95gshYFMEznZM37BYqVJKscMp9XlbrrVuZ0DjXz8PNboPu5jiJbzu7KTtKF4bJnAXVuO1saZH9QFZiPfKvPbVVLzbjroaHuZphwzoKYZW/1SXBnN5AegHo4OoKZNWVFquaSFktScoKjviVujkgsW0gb/FmwY+9eVJikKbVQbG/E6pIT9doWUr/I2DZwI8y9GPKwmPr5sfTTPrYwg2clr9SkEpZmVmw6Wup3YW/ZclLysK6K7sil+KT8fl8edww9HBxBG+jlofab0KsRMezHykoiqNZKq+5+o74nTnmKDsxwZ2ps8hSjWhqSkm7RIn1JsbpTDAOPafup5tBdfKsO3q3sNqgkp+RgynVr9XCFRAWDJqv75jfSQ8bSJ4e2bnUvU3zS4hasPCN+HFL/UpGxkIVoajj4z9zkG2YiTSVtr+3VKUrz/iZr3uEhWbmBmHfj7efxnedkoj2tBUnU/kzx732GZAyLCY/KXd3NWPgfoEkh1Ux9tW27dEnIc6il1atoUPQ7I/qZ53XUTx4B5aePr9/Em5XTfUJpPqws0CZ6Y5Kt/gZnzS3FLJNEyfh5g+p54S2DVtKlJxXGUmPBL0RlJyf6nYWDu47UnTt5TfFIc9vYDSQ0wrk3m9WExy6wiOFKzhKpb0eV3pWKwOOsBWxs1oorV78rH8lhkKncpIomUSpoHU9+JeuBLmeAJus8FVlAykrSsgOQ0bcpBIxcuuo/+poLzRbltC0n52w0JStOe5r/xgDQLbFN5V5ykOKSaZVJvbpcamE9G8uTduTZlISpOi/LPp7WlTUjruAF1k5D/zCihciY/zfTn18sd09ojaVGlg26azOdrA6VNfrRuAND8Uv62pGUBABdAATDaFDCZ4OvgCMffT0UKYWkk5X6zSUoPkKDBEZr2pPlkc2TPKtdrRVLaqFe7ifZopvSOxxJxl1LO73Rj0X40XTtXPa0uGrE62iaymNYkmfz8Y/xac/HnKmnlmhbVdEDTVoTpoiBdi8X0y31vjPU/MWbC2lwsbtmeYYVAm/JB51CVDllPJSk/Td1PJyhfzmPkZHWzSLD2i2tDUhY/lAPXeZSe/NgEqb4nerzNCbelIv40n0Juff6IWgug0FZBoJBNfLZ0zUzHl5/7m3KwLCZsLsJPCz0H6sETkzTZL+VvcyY/v24ajg6grk1Rsx+F1dTXNBw9xR/lbwdpcYKi/ieJoDRyauKXGuyn6D7ageeOYDlntDRqWGVwq0u4X8t3peYu/wFKTuwF8kxJkn9pNoEXdbPf0Ou8JEjauGab99O59oSBFPWJvm3AOlBrCynBE4B1Tb94YMWkrjmZubrpnDj2W0cOpXrImPmwFEkBNYLiQsw5gvLl22L2c8d9pMjwvvBJbWKkEpR2c+NRUXzYZQ58R66eL3yh5mVDvxRn8suN9FtGpBBV6nJI3AgfCMmK17Rj8lLW1NcEi5KDFA1VAxdAofml6tshgQGeRka0KQDzNf2mV1ELonDJbl/SpuhxrjyEfT/N8stqUbY5UFyARCpBaX2j9K5QC9G+9ElZ0DQiJRexT8jn+q7oOWJmQXrOWL5FRfZx5kB6HEhYDkno0By0Z8Nr1rYlt9YVsftZon46cND8Um4bCOcn0mOzOpgVRlSzn8WcV2oir79t1qLKEVSKX4puc/sA379pkdk+1oqkcgioy46Em9xLXyIfmqYkBVD4H34L65IfNWfq447nQiqvRfS549Y6LSHlOR2r9jLyeerRo+tMVhwsYeihXPN5qHxQs96kPBMYgdBn5R8bYAR3qugq+FScUpZDsvqlLEET7lfcbkZQkv/J7peS3ot59GyKxkWxNiQVc3CnzmVpC1znKuXj2slF73F5Yx12rINelAZVAq7T45ZDovkAfeFabl/yRTlIgTlNTIA5ZhK+nsWahGvmN0/T5ScD00m+9rlU4XnqZt2oNjXamG3OIM2JahI4YfVHud8WCUoy+7k07teVl8Adk4iLw8qTVI7/oJ5/uX05JUyBtD5ue7LPi8QyLjgL1DufVJ+UX0fsHJNtfp6d1dRHgyb8NABB56F1HLE2L9OKKlZIS3vFnrFk8vP3a/5eIiLus+asfypFWyoV2edvi1qU/pmNUgQlkVPTgLVqP5BUjKBS/AelRrklEJu4SwMoJsdsRCZ14BwJWQmsCUqFnc/rCs1MnDaV4kOR7qllGoPleVhHo1LZkgOs0nJM73NKYIXkN6QTuiWzHmvmm4LV2KadfTh3yluNIhYcIb0a3OMpEt3XLkHFtCc5stXWB03K7QOSKo1l9B2kaFHUtCEdl/ZTzlESbTje+fOMmE4uHpzhlwf0F7NJSG6PEJwJsG7+i5sDASF6UxG5ybp+0wxuom9KZJ8U1edDCpyI/toJyoGbf5dCUCkDfk3m/f5sX6zd5yPF3KLlWXSnkhpKzvuj+DQJ2lp9XLm2iMo+yq7Pp9GWQwqP1VeiSDknbTN3nCO3VTS/lUTuQIRqRK4uP00y8UnTCiztCMx+oyFPVD5yfVJJgROh/8m1M7aSuUZGGkHFtKd4X1oP3vLz7SuS0jqamJNbK9P03Kmg5MKZ86jJjyvn0mLnqqfZxcFKKKU/Jc+dmzrM41F+tsVl/fwOsaVhaFtpWhuDoFIEWNr3aUVsuatJHt6XKIWpu30HjuSmOyzmC9BO83JE1elqEzJBzYq2RFCWZZEsfSbNczlaYnpdxnxLCemlb+IId+h65Nu0g8gxCwK2sHM5T1nxkSYxc21ykEbomjY1OV5uFXTpuExg66tZcX4n7RkB/DQMLb/07alJnnCaBi0r1T2rj1uNQiMqH1JacALpxMxxwbwHdKdBxSP88oInnJ/Ygk1TLg/f+ta38Ou//us4duwYNjY28Jd/+ZfB8aqq8IlPfALHjh3DlVdeidtvvx0/+MEPgjw7Ozu49957cf311+Pqq6/GW97yFvzkJz9JbQoLjoBiK0do4etdjCw5ErAsT5TzSQ0pT+y7Uqn1Ac0iAnPuezqJ1FcskY7lrmSih+aOi8nYos3UqbAMJDWSp/tc/gHGQoDLeHZsgNGkQ6c+nOEIA2/dOwzHHlFUfMQd/eeOIaVMxfqfmhJUeB9sBDWo/Y+C40PvXtfzhv/zMra1+5JJ6oUXXsBrXvMaPPDAA+zxT33qU/j0pz+NBx54AI8++iiOHj2Ku+66CxcvXpzlOXHiBB566CGcOnUK3/72t/H888/jzW9+M8bjZi9ayouamrf+MMuMhlO0EUcIlom5lmMxEgl9U/o5uwh8oJBs4jRM2z8mReXR/1Q0jRzlIq9WGanzZuS8OtFQOOKh56sRE5EXn6iGAVkpRDU5YZ1cQPYtBBbsV6F5b3puulAsoBNUeK/qZJRCUC7d3S93jCOm8Lx6ugXJ9po3vvGNeOMb38geq6oKf/zHf4yPf/zj+M3f/E0AwF/8xV/gyJEj+NKXvoT3vOc9OH/+PD73uc/hC1/4Au68804AwBe/+EXccMMN+MY3voE3vOENqU0CkDaCtZRvms8CyUSnfY2XQprc67e1KwJpY8FZCel+JX6V9BgkE55k7tDOnwIuGmsdkHLvfUh+K84EGKbHoze59sw/5+HNn2JNf5hM+i3mk6qTkzs/wBPU7HqE1cyppi+lzbfz1u5LcbMAdp9Usial4emnn8bZs2dx9913z9K2t7dx22234ZFHHgEAPPbYY7h8+XKQ59ixY7j55ptneSh2dnZw4cKF4N+BV/Ntju6ceS2lkGtW47Qpza9kMRVSU59sErS3uU2isoSAxya9WrSb1HDy2AtLOwcr1kW7KgFZsxqJ99zXnmhnq5n9hlNCGBCimGlUgfmPaFZUq3JgNasKgWlP9D/xGhT9YKG7LtlkV0+bl+EJylkYhrP7RY/LGpRk8rPKdFGSOnv2LADgyJEjQfqRI0dmx86ePYutrS1cc801Yh6KkydP4vDhw7P/G264AQBg/R7JssFqkksZcXaVdxFmPR+c30E6FitLbelSmnSe2JyR0kE5MYJbByKTSKieL05KEmI+ask/BRCiAniycoQ1OZngkyJ5KTkR/5NrByBrUO7aKGlY0mIExd03jqhqZlTBjD7A2LzAbFGSctjYCFcQrqqqlkah5bnvvvtw/vz52f8zzzwj1mOJxtJ8FCVn8HNI/UKuBmrisJBPnXR428SiyYhC6pQ4aNqUpllZ5EXs2BI1tlztaFmjApsQpOgnMtwjLY/fcUrERY/7n5n3/VOyRsWQFUC0I+Z/lq9OTv456CRdyyff/UFUbIWJ+T1IJyh6/y1+3Rzfb9EY4qNHjwKYaEsvf/nLZ+nnzp2baVdHjx7F7u4unnvuuUCbOnfuHF7/+tez9W5vb2N7ezt6fvnGpKmXbXQEcz+R7cFwfin6S/MB8pJK7hg9B20fR045ZFgSkh/D90v5PicO/vFYXlqO35bn32naXixvapuWHbH7bnkW/vVKeblJv7G6JvmpL2sEV8V4NP9A4mg0mGkyPkI/1SAkKis8rYgjJwAeWXokZSQo/9rqJJRGUJpFYXY5BvlM6UOKalI33ngjjh49itOnT8/Sdnd3cebMmRkBHT9+HAcOHAjyPPvss3jyySdFkoqBY+XYjdLChheBkh1/XckedE4sJaCNkmNaD9WmUuqOHY8Nhrg8+rnWd96UhlyCtjw3Tjvj84eRf7P0QWhSGxLS8LWqmmY1NFwXyevXk0tQ/jVp0X3+fZo1RyEozpfEEZRkJueemWa5qN0qUy4Pzz//PP77f//vs/2nn34ajz/+OK699lq88pWvxIkTJ3D//ffjpptuwk033YT7778fV111Fd7xjncAAA4fPox3v/vd+NCHPoTrrrsO1157LT784Q/j1a9+9SzazwpJZdTntNhuTCni0r4XJcHXlOTFZpt9ldfyYUNtrlYbi8360EbY9JhVM5JG8tb2UKTOv1sGnxK3YkmZervXrq3n1u4rHbwNvXcKmBPGeDTAcDieaVTj0TA45ghmj65UoWCT5KHkBKQRFCUjqimFabzGxWlQLj381ecQcqhbGGwxBck9zXe+8x386q/+6mz/gx/8IADgXe96Fx588EF85CMfwaVLl3DPPffgueeew+te9zo8/PDDOHjw4KzMZz7zGQyHQ7ztbW/DpUuXcMcdd+DBBx/EYNBc0FNevNjN7UrDspAMZ+pLrcPPK53D/43XU75jop1EDBaTX4pZkD+HrCHRPDGZiWv4utOfa1NJSPK1zKib8OzPV56+MTH7jccDkagmaTxZJbWfBGkAITkFvxGCmtVDCIoLnpA0Lq7u8FcPGOL2KVKe0UZVVVU823LhwoULOHz4MF5z/usYHLo6OCZHWtVvND+RLXQ2yun1fDFHpZwnTPfT/GviOsK6cMTIbkj269qS+3XznlwaTffzz40rQ/O+n6bVo+Vz10Tb7rfVcu0ctHurO5L1US41m3Ay4pdPkS8/zT9H2EZ9JRYrSXGyAyB4Lu6Y/1zoc5NkxeXZxRYAYAdbZnnKzeO3cdb+8TR9NAg+5TEauXQiV7Ev/iIkpsk+rz0Fv4SggDgZWf1QXcsOAOxeeBGfO/xxnD9/HocOHRLzrfTafT60Eaqmqob52o3ss8AfyUqmmTBP/ufjYwRlbW9T+JpOSj4/oELSkMI8/ArotBz3ojWJGuXri2tcq6bRlIB/zfTZ0vteys/KmQ59jX4wGAcaFSBrVUCdgCTQQAxKTv52CkHNynZIUKmD5RSsBUlZIqwkWPK1RV6UYGJ+Appfr7vco+VGydLxFLhrsXQ2UoQfV6e7T9Z25ZIBp9nKefnw5yYoJZcpctUmrIMVB+5d0WREukZfTvyBi0RULurPERUgR//5WhZ3HEBtGabgd1AnCE7uNN/UPI3P7+rPIShaRwoWEoLeNaTRpsbwftmU9FQ0ffFj5TVtylo/t90VUkmE03ZcWqxz07Sp+LnLRY3yg6nFB1NQWOQpVWZiz9s6CIkhNsiT2jbPU/ddOpnhiApAjayCug3ENMnHa0/u/PTaOO3HpXO+qfl+PD93Dv/8MYKy9qG7plwrTlIcpJdLM/VZ7Kop5GV9yS0dEA2IkMqlaVn6skfUp8C1iaKtEPcYQXEmP06bokQlXUd4Hpmg6iPNfM3dEkyxTihFSE3b4BBqUuHcRGD+WQnO9CeRlRUcOQEyQVnMcy4/1Yg08uLMgtL5w18bOUnvsQVrRVKpTrzUl79UZ8EvCqsvKistJBuOAtNHwNYR8bJrW5Y6aOcYkj/vy3OwhNlaop60di4TujQBpj7nCWHMn6k22LCY+Px8nI/TyQ0lKgAzrcptz+oXgic4fxVHTu463fk5cogFfvnXZvFD+fXT84fn1gkqpijE8lGsDUlpN6CE2WWZoAdO8POyuE6giclvEaQFhOY61iTDaFHWeiXEAiXiJmfbxF7tpV0m+ezy2XPXParJv3xvYm31B4YACZjwzsERFVAPUZ/Va9CoLOQ02ZfJIW7K47Ulrh5O64q1IWdAloqVJqlNctNjSHnRuxzZxkx4ORMwczsSLnyYHpPPaZ3bZFkKp+47yjUT0VExYDdP0vsdkwurrzOmjXUBX544GVx0QEVbZkH/muhke87P6eTHJ6pJXp6sktoyoHIRJwfumGb60/xQnNbl0ISgLHJjla1WFphdNDQtSstrIYCmL22sI88J/c4hpBKBEzHtjIOlE059DkPy8vCO3bg2TY9rxKKNbqVz1o8vj3YkIdc8bEWOVpla/wDyMkku3c/vyxN9zmHH7JUbjGuEo7aL5J+cK12D4nxN4bXrfijumESEfhtkQkxTHCxYaU2Kg9VfUJLpmyA1EMKyTJLlnBy071ItGqX9U0BaMEzuwMeSTlE68rREpGmT46nIedYS4UuDQqo50fNqATm+Nk6DcFKIirZbD8yJLwIbputmPk3rsrTBT6fb3D5/7S19Pn6ZkeuY08KGY/lTEH/Z5Qm3scm4bl87B3ec14bqpj6tjSWRev9jhJArE5YymvmDaytXV9MpDznl23yGTc1zVk3baTm+5pNSjkuft2FcS+cIwNe2nSYUn1JQ/1RFWA8fJDFvT12uLRrR/Jgebs7VR9ugle01KQHcTZFGB+l1t2eSKWHzl3wJ1rJNkWPyS4VlZE0d21r5lJF6/sDHbkaOyW8pxORt0T6oGDjtp0k5mk6ja6WgHFdW8nPaJ6nyssX1XSkRfrQNmmYVM/PRNtSPadpUmb5zpTWpVNbWJqOVQq7JzBKg4DrfNpzJsTq1FdFLwdJZp0QTNTFHcLLF1WeN3EvN0yNE6j1zGhbvK+S1Ke5cnL9TM6txvkzuuKz9hJqZKydpV7S9kgmQlqmXk818chmZIC0EZSfzNUSOFpUaStnUTGOBP6KjbYpFZlnq9uuap4emvmXwR8Xg7pGmTfn5/P2Uc2jlYqa+FELNaV8umn6yo4l80OckRfNJz9MHN4ewXk+o8fhpnNbk0tmoPqJV0XOmas8WzSVm/tNNgPZoPulcXHstfS13Lxb20cNlgPRiy3NdykSbpSKmLaUi5o+ieUuihGYnjXjD/fTBR4mOXqpDaoNNm8ozhbRNXMs2KLF09vEBAP/xQ9pZU63Jz8NF9dU1iHHwz7VTKkPrzg3/Tonm88ukmPksBGXRKq2yvDYkxQuGHBa8TCYXrmOwkFjqYq8ckWmfstDOvSydmYVAtE4htX5Ni4ppWJqJibZ51VEiOMNCPrHyXCcpBUq4YzRdIyp3XCLB2DG/vlSCqpse42Y+qQx3Pr0tOkGVxMqb+yydlPWmaSadJqRW/9RGygcK9Y8dSsslWdslndP/tWhKtFNqql1R049vXuHMQtTkFwNnouGOS2mWKC5rvXo9eXIXX1FflkGr+Vgb8LQJzmzHHY8FSrg0LhiCBkv48uXOXQs/z3hWOSHoLl0jlXmeZmY+ri2W9nPnycVKa1KlzDBd+Jck+C+M3VxXlhC4OuV85Tui3PufQhSyrIzZfy4fV68lGCflRV2ELLZJLlbfpvUeafmkQIlJufpoP6ZNaZPDqVaVqgXTMqkEVc+rLzbLXadsbZCnVHDt4vJaLBb7ztznYFE9uZtMj0nHu0Ds8+5cntSOpsTE3a5MfpqG66dZzDJNz58CC+F0bXYu5bds+9mnkr02CJGc/tw+laEYUXFkZfnn6uC0o5gJ0M9jT48TWMzMFyOoklgrktJIpcSNK2kCtGC+jl4z8x3NQ/NpE4Vjn+1oAyXuqzYKTKm//szjWtQyDX6aRGlKZRbhj9Q0JI2gtLySNmUhKo2sYpDC0OvtiAcuxAIpcrUoH5qVQAqlp2lWiwWHtSEp7uam2EjbIhzauTd98TVtCuBJSEvPCYawXkObxMZFYk32dbu5ny82MrcQVAwWuSo1+GlCHppm7ROddI5FfB9Ki9il91Ab7fv5pQ6ZEpXb5sgq9k/bwZFfSmSdFpnHt9lGbHJfqZfn7k0TrDRJuRseIyit44oRWZs+gpToPDmdJwJqYEgpm4LSnZNGDKnmHsnsR8tZRngl/Jy5ctWW5pXy/NPMwM3kqsn1WgamFk2DP66HnlvByRlHMCkmN0m70rQ/mq5plVYrAbffFCtNUhIWGQhRCtrqEiU0Fk3Dk0x9bZh5cgQ6ViY2Akw/Xzk/p/UcVpQcJCz6a7kSrBYRS1qK/4aa/bTybt/yz5VxdacSVCkzH1dOg6Rtae+e5JeLYe1ISlfr8zq3Uihr6ssnqi79S01gHeVyphiuDpc35QXRCCqPYJsHcjRF6cFG1+SWS1ApHXoKUZXRpGRfZ728Fu2XFyyRokXFov78tmjvm/WerRVJ2f0E8kOmeazpqbCsau5g/8ZUnHxi523qG1uEU51DzLQWIyvueK6jOwddEVgb0xlKIlcL1XyVMW1KIyp/YMSdI12TkldDp22UzHXzc6etRkHTm0VCyxprU6wFSUnRNSlalIauR7xzR3U6ocTctlp9PiRTX5skZBHsXG1Yd7LHTRFNTchdypBlCkMpaJGiXZiHueeiWVOk5xgLxJE1kfQ5Ulw5SZuz+qHq15FmBtTq9BGrn7axBFaapLTQz1y/RGpnouW3vKRNR65NOoK6yXB5RtHSCJAelzoXWoefNxUWE3KKScNidiqB1CkMtFypfF1C85FIx3LMh5IZWSItyzyp2Hk1TSlGXjm+qJhsc3VJeWNRjhpWmqQkWJx52uS4NtD0Uxda+RJzYPz9kp2U1ra27rnWMaUSQaqPs4SprwtYpjIsG2LTDVJG9Jwf0zIviuaXrThxzVyaY6RpUJp8ab41+bht+aPYuWldfpmY9hrD2pGUPpJKU0O7jBKk5jTN5Ocfl/Yt54rns5uNckguFbGXyKrNWEZy0pyWlPPm5pPa0zWk52iZcxem2+UhNzAlFoEZ91HymrnkG5JkSntO2lwpbTse8adrSSW0qLg7pX7/S8nsaoR5GZAi0LGbFzMdLSrEPb5o6HyhTO24lq6FvLdpDhyCXxhWSgcm1zkGv6isOybtu7pzkaKdx0xHloistiEtOFtywFFysjf3PC15w+36F3fDcvoXed3zyZUri2nSSlBta1FSmzmU7h9XWpPahB7+afVrSPttw76oa9oIVYorSqtjceOX2GhQL6vPY8ltjzzaXV7tnENOJKetXtvKKkAe8cU0FB+WAYBFm5LrrJ/PKlv+G8mVD7dtsqVHBObPi8rVokpjpUlKQ5qpQHtQ7XcqKYu91qOpygVO5HQeXZNZzF6eW75p/mUin5zjkzyrYVhp+r5yHSzVJLiAHIlYaJr2z+XX2hW2JW7ms5vz0tbok9ItE91d2dj9kLCWJFUXhvQ119qC1lloZjXtY4clAiesbXK/XTjWLZ1Rjg3e8oJIeazaudahaG1bNEqsXtIltHuYOhnccryJFqWVySUoa1SeZgIsNXCT2tJUzteKpPiHnzfb2Tr6WBZoJj0uL0XKF3pT6u0S2qoAHKwjXq6e0gOfUoMnGnATW1arjWfWdv0SYpNV/XRtAMJ35PVVJmhZ6z9XjmurlaC4duskFg8pT13wIGYSbIK1ISnLDdFHHWl24BSkTKLV8sU+He/yS9F30rES35YqhZyJtKkmnhyUPMcyalA+1nGJLcCmTcWIKkZWKW2hpKIRlKU+KX/uMe08pfJZsNIkFR/56jO6lwF0xJsSSaeZ3CxBE1wdOYQaM0/GYBd8uSNxkLQpl7+MacY2grSYZqRzdgnp+WnPMHUFk1IDHksghJTOHdfPJdUvL4cUq88iT5ZACIuGo2lRuQETFpSW35UmKQ0lltjR8nXZkUjaFNDMN5S6pA31R7U5ii5lJ5d8QdYOxVKfdv4YujQh55jhKBnFyEs6XxOUeNdSVi3hyMHP5/JqsmUxIVuWRvK34+HoeZpSLE+Oqa8k1o6kOOGxLjtiTbcgxayWUsckvTlRLeOKAjmIaVOTPDKxpPmk4pFMq2ryi2vLcXJatE8SkDUtmhZ7xhaicvlTBxopfVSqG8KiBZUOmEjJY9U6fawVSeX4M7jybY8M8sxnehnt44aWfJIWldrxtPURRG20S/P6+efHmmksuQMfi3lGq6cE7Kvot08ypeRDIhEOumlrLOaxEtXkOL9QMfdP2xYjKO5aLFoUrScnYILPm65FccS0aSy78iQVWx8rzLtcfqnUSKww3fZF3lJf6C0xD8eHRQMqjVyiSpkLUhpam+OaTZnPslhA67JoZqURHzjwPk1pIETroUTVRF7TlkeymflyBkQWzceST8vT9L1YaZIqYc9PvYGLnGdV7wiav+iWL/T6yPlab9sj9JwRr63eeN4S/sqmMtXmBO8SZRZpBizhK9QGt5Y1+2J5qZahEVQqcoN3SqHEwG2lSUpCyihlnhbrjPIIMfcFtUZJNSEq61I2XXcy1mdheQFkrYfXwDXNnNZnlSmtDSWREsWplUl53qXLa+ZAqw9Qs6pYtSlaD33WkiVA++faTuuJEVQJLUquqx1TX1OsHUmlOLNTbL5dIcXkNz9uj7jyy+jHl8EJLncgUl66HSs3ya8Tk6uj6Uu5KJmisJjmYlMXUiaPO8SmTJRG7n22TgpPDQDQytW1qfRli+TzpRNY6nlKWBQkrA1JaaMVbb8rxBaJTfEfaH4qi58id3JxqejEkpDNJLxZJgcpTvVS8rVoInOQ4h+1/Np+CWgdOJ9fH+RwnX/K6iWWiDUtT72Psk3qjWlR6yKLqzNdnMEQe+bRNbc/T28a+WV/iO5zG2MMGj18rXy6ViV3LNpE3cX6GkbR6xyA/zyHlWybBEh0Of9Jg/QJDio/TeVxWWB5vk52OPng0vwyLg/Ay38T7SNlikO+r003Fy4j1kaTorBGrfhYZFCED+krvG2MUkvU2WSSb4kgA02TifkOpHNYCSqmRbVpYtGQM0+vqTxZZamLpZSsfkut049NYyhr7otPcbD4PXP8TNJ5pXNZ6is54FlLkkqxj6aaDtpETih4jm9Aqks73vbk35xBRYm6LQ5uqZ4czbyJo7s0mgY9pJRrQ35ytBYuzJzmkcx+WrmYOU8/3mwOXhto6o8qibUjKZvNN21U27bNNzbqLR3mLRGb7TztjoItk3YdrGHCsXosiMnQsmjmmnkWsJFFKlGVJLsclH62NC11lYkYKUn1WCb2WrT1kv3WMpiA14Kk0pySsolnVaCFimsEpGldmqkmJ+KwTVieVSmisph0ws5keTRzC2KyFCvb9ZwsDVRbih2PPStKVCWXRIr5n+KDrubznlbBHwWsOEnFRyqxzmUxHQpd8dyHNOpNn9EfjudieVPqXhRiphLLgMQywvXzWduxaKQMJFIm/0rRfSkRfiW+VZaDlPl0EinQstYlkaRjHOwrT6SZKlOxrAP1lSYpDW2YfJqi6QvaReAERayD6TrMPDVvbBAj/efUH3MsL1L+upoX1yTwpkukLIHEEZV17l2sDakERctr5/fzrJqJz8dakpTN7Nddh5LqU0rxIeSaXJr4pTi04xjXJ9da8k2ON3+WHHmljtDnaeWWqMkd+LTxvHIiCruCpmlYzF0SSaQ+w7ylkWzm5BR5TH0nFrHShMNakZTdL2X/JlATe23pgActfwpZWf1Skhalm3raNefkE0NeuLBWX7if/xKXHrk2idBrK7pvkkeXoZKEpvmdaB4fmvYiyZAWHWqJHNW1c7umzuWLYdn9UcCKk5TFRBPrAJbJDmvVpnJ9CCmBE21EgVmRM6eDm8PCIYWsmg56LO3JRc6AxPodslIDpy60KKoZNNVu6fEct4F10dlc7dw6hyrF1Lds5mkfK01SMZRW7a2wftcpBSVXuqaIB1bYtKiUOjmk+IL4PDaicsdi/zntiM9xic+h6hIaUTWJ7tO++lwCORpAyntNicqqVVnbYRv82Mx8YdpyyVcJrPSySBosDzDWoSw7XAfRpO0lzC6LWDjU1RtbBsfPW+K89bTlMZe4JbcoxpgveSQtkyQh596lrGzRTeBNfQktTi5oPpqHLxPeb+56Yu9njLBy/Ocpk9KXHWunScmjlJyRV/kQ9bSFZNsxz7gyFoKKLYxbArrGkz4Phau/6XNrMuhZRCeS4je0ftXZgthXny3Q8qdYNHI69Jg2HpMlq0ZurV8iKGsfl/puLSOBrQ1JpXZEKR3KIpFCVKVNNFzZRUJ6Tpala2iZlHOmElSb4CMyyxhEliUSrylSfI58etxsXGLQE/NHlfR1dt2vlewrVpqkNs2jlcV0KD5iWkuKCcQalm4NmpDqLP2NqhTkhPb60IgqZTTMH7eHvOf4FdoAffbSs8olKkkbs35YswRBNtHILYvJcudLGRxr+WMEleKaWKZgsBJYaZKKIXX5EQmLjnzhOpSSo97UzsXf7iaCy/4pb6kcX689YEKrc5k6hZQ1HzWisj5XLe8yfFgzJcy8yarnWgCOpZx2XovVxx5Y0SwojEPbz3FtSapp9E+bDvG81c55ompKEk1GvxKaBGOUJv+c9dW0uihKDXq6QKqp0F/Qx5Kec/4uYZED66rnZdpT3ozchWxZn3up5712JJW7Rtai0PXIN1Ymd/SbY+orcf9j2tQ8Xz5RSTIVk6eUQU/OvbB0AvXBTjNznr2Daq5FWdua4zNqqpGnmvos5XIXnc2Rra6iUksQ1VqEoOeNkGwdStMwdT/8t0RZLYTY70Do9dom56atzde2qc8PL/fDgwfQQ4OlsHT/vllINXW1grBs147quVxIoehaWaBcx9VEjtpYsSQ2TQGIyxAXxu6XbYLUAVBbfVVbaNIHAitOUlZTzjL5DGKgDzSVqBzSTTErLQo1xOdP5XfIqT7KRXckFpmapKfNoeLKS+fvCpRs6sflwU687sm9KfmulDIh287VnrzFiKgJUSWZ+06ePIlf+qVfwsGDB/Gyl70Mb33rW/HUU08Feaqqwic+8QkcO3YMV155JW6//Xb84Ac/CPLs7Ozg3nvvxfXXX4+rr74ab3nLW/CTn/wk6wI0SEuTxEI/24I0Byon9Lvki2LtXNoMmLA8g9TPcuQsABrDMslTE2hm25yozhSC6oq0bDKlm/20T3M0a1tZE/IqTKmxTJHhkERSZ86cwfve9z783d/9HU6fPo3RaIS7774bL7zwwizPpz71KXz605/GAw88gEcffRRHjx7FXXfdhYsXL87ynDhxAg899BBOnTqFb3/723j++efx5je/GeNxuRtqXcyxfjx18mh5IbA+yJwOxVo+xZchLZuU2xlpEVdSPm7fUocV1gFP/XgzX1guLMtoxZ5pTL6ayh/Q3dws66r5KdFvse9EpeZPIahFo8mHUB1Z7Rnzb1RVVSW1zsP//t//Gy972ctw5swZ/Mqv/AqqqsKxY8dw4sQJ/P7v/z6AidZ05MgR/NEf/RHe85734Pz583jpS1+KL3zhC3j7298OAPj7v/973HDDDfja176GN7zhDdHzXrhwAYcPH8Zvnf+32Dp05Sw9x0+ghX/aQj/zRzY54fFN5oI45Di1aZplhXRJ87Lkt5S1tlVqtwWpK0NY5Ynm5bZzRsrW81nSm6KJHNG8MXkoLUdNIlRTkbc6ek6YejMtzBJ5mCJLL17YxUcPP4jz58/j0KFDYr5G0X3nz58HAFx77bUAgKeffhpnz57F3XffPcuzvb2N2267DY888ggA4LHHHsPly5eDPMeOHcPNN988y0Oxs7ODCxcuBP+AbRl8h9QOpQvkjEKto1/tP7V+rWPpGk1XA4jJjFWmmsqTpSOxIIWQZRNf2ecpmXVSzpPaJgsBpy5/RFHafKxp5ylaVBOCKo02TLnZJFVVFT74wQ/il3/5l3HzzTcDAM6ePQsAOHLkSJD3yJEjs2Nnz57F1tYWrrnmGjEPxcmTJ3H48OHZ/w033JDU1pwQ1bawjJ2KqzOnY+ki4CJ3NQBr3daBTmrdbaHJ829bplLqb2uwY30+OUQFNCcrrXzXg+km11FyLVEN2ST1/ve/H9///vfxn/7Tf6od29jYCParqqqlUWh57rvvPpw/f372/8wzz5jamDKPoc2lk6z+nJSyJQWhVMdSsk0580+4tNKEYjWZlZan3PlJKb6DXMd207KWuksh9TloMmQd4LSpnS9z2HkpZJHUvffei69+9av45je/iVe84hWz9KNHjwJATSM6d+7cTLs6evQodnd38dxzz4l5KLa3t3Ho0KHgX0OscyrRAbaFnE6ljY7FQlDlvxFkM2lM8tpXAihBVlodyyxPEvSBk02uUvJRtC1LPlL8uE2esWRgt7QvxxqQSnipqPvp0pZnW8iKE1VV4f3vfz++8pWv4K//+q9x4403BsdvvPFGHD16FKdPn56l7e7u4syZM3j9618PADh+/DgOHDgQ5Hn22Wfx5JNPzvLkYOC9MrF89bTyWlSTh5cTOVOyYykhXF3OjfERG5ykvLwWmepKnjTEOpMmZplxcBcGZjnTzrHo1dZzzMcuveQAI3Xgk2vmW+SgqEQ/kDR8ed/73ocvfelL+C//5b/g4MGDM43p8OHDuPLKK7GxsYETJ07g/vvvx0033YSbbroJ999/P6666iq84x3vmOV997vfjQ996EO47rrrcO211+LDH/4wXv3qV+POO+9MavwkiLGZH2E5Qs7rkyi5VQOsE+La8FnERr5tkNIAeasA0HLc8RJt49MXL08cLB9ELIm0IAm7LKWsAdlEJt094erQjqXUnXK8xELZbSG2wsk4eGfT25lEUp/97GcBALfffnuQ/vnPfx6/8zu/AwD4yEc+gkuXLuGee+7Bc889h9e97nV4+OGHcfDgwVn+z3zmMxgOh3jb296GS5cu4Y477sCDDz6IwaBbR2qXs71LdQbugXfZsbQ58m3emeQRVROsgjxZBz6urtJtk7AoWWpjwCPdr9z7aZWrRS7JJa1KYl2KS5oeoKHRPKlFwc2T+p3zn8TWoSvEfCm2aIfUCXVaaGd6XemfgWjD9uzDugitNs8kVQuLCXLqwrilyGod5ImrhyJXpvLM2O3JklZPSnu4sqVRcuDTpkxJbZLq0/DihV18/PDn2p0ntYyw+RGWc5X0nO9G5QZOWHwLuUvytx3lJy1Vo9XRxJ/QlTyVlrfcDxum+J2seRchS7EON0WOSvujLPWW0Mybtpm7/7HPu5TGSq8qmiM4uaNLdz5tPxVWE6B78Fa7bwnkfshukdBWqp7nqfv5tOOWc3LIkaem4OSppHkmF8ssS9TsB8yfqWT+c2jLJ+W3wcciZCoHqavwx7B2mpSGlA5lUc7krkcpKedJ/QRDKVi1qUnetMU/acxaWruWX540tC1PqV/tXUZZitUVkx9LHnpOK0EtUqZiA4wSH2R12BcklbKoY0nYvuGUrk631bk0+RT4PF/ztkkvO4U+T6S9pV96edIRq7NLDcrakecSFXe+LgY90rnbgPROW55jCflavL7dImIC1mRpkrYR+7aPxQRoRdxH0a4zuUkkHmeumddb9vs/+0GegHyZyv2w5iQ9fW4gB4ssSXkkWWrjO1Jc/RxSZConT1NYv0HG3Vcrea0dSVlHPm1PsJTA+w3yP0KX07mkjGyaElTJUXpq5zIvl/ZFXqmshiadSROUlifALlOr8mFNTm5yZKmJHGl1Sehi0JPim5RD7pt9LDOGlSap3I+PNV0/S0prAq1jmZwvb7TSrE2pH79rn5C0zgWI34M2Xqac9eAsaU1QQp6AcjKVOkWgK/9UzqBnUrZ+/6RrLNlHdaMdSbKjExXQ1vu1j7DISXA+coWgq0+J5C56Wxo5ZkBLB1MKqy5PQLu+O/888nH7s2ryXNsa9IR1Nb+XOevxLUNEn0Mb/dS+CJzI/d6Ulm5FuklEdzi3aTLJ/d6Ult4GYs+k9Hd/cupflg4l9lzakqcmstQU6QELcv62Zcl6npLXZEGT97x0P7W2mlSKYC1iJKKPcuNL3jg0HbWkCFObRJQ60nX3R2uTLwPNI4yWQ55y1uBLkScgX6ZKyVKKnFnmxs3z2pdNosjRrGIoEbWXImulNBzrsk/8PLMc0+caoMlIJ0cAFmkXruezC0Lu6CY+GuePd2F2s5oEORmR2pcrT7mz/5dJniZ52+0WShFUDpoQFVCXjRQZz5GrRfZP8cFN+nqkvmyNjWVXmqQGDVTxtpcTscAiBDltKdnJ5BJUScQ6j9wQ9pJmnHWWp1JoIiupA55cmUgt15YpsEt50iL82iCqVOwLn5QP26zvsje96YfBrOuolYTlnKXb1MSskTN5sgSaylNOm0vIU5ewym+XATmx46sqT4tA2/3TSmtSKbA+2EUIiN201+5IOEXQYnnbMPVZJ2o6LINjftn8nX4eh1WQpxw0Ne25fEA3ZsgS+ZahfyrdjrUlqZybtAiHt0Oaz6A+MTEXOS/fIgIorMdpXoembW5Dnpo8t2WUp7ZkqS3fZgoBlR78rHP/5PL7aNL2lSapkiq5pZ62R8X5PqjuzDeL7FQccka3XWo0y2KOWXZ56kKWrNr3sspSyvmWtX/yy8bSOOw7nxSFlehKCEDKN3W69hvEYG1TCYJalpcyB122PfcbTYvGMsr3onxQMSyrPHX5/FZak2qCRQlkyrdWVjkaqylSfQbA4tqb+ny6iszy0YUPKqUNFpTSyHNMxIuW/Tbza1jG/mnfkFSTG9lGtF9K6GqXHUzuy7moQAma32FZHN2lymno5SmOpia9Xp5ktC1Pa0lSXfqpcpH79UotWqlUXalo0wfVZL4Lh9S6SsrAOstTyU58GQIlpLI+cq+575/SsNIk1aYduQuTSMlvQi3KPNHVqhLA4qKqSqAreSo1uXQR8tTVwsC5Ax+unkWgq/O2LU/WZ7DSJNUGFiF4JcmqK3TVofhYBn9BChYpS8DqyFMvSzbs176pJyksT5TYsncwi+hMOCx7B7Ns8tTLkoxlCLzRsGyyBHQvT/uOpJblocfAvcRdCseydCIaSvoJSrZh2bBoWZLasGxYtDytgiwB3cvTSpPUAHsr82BLYBVe9EVjP8lDE/SyZEMvTzbkyFM/mbdHjx49eqw8epLq0aNHjx5Li56kevTo0aPH0qInqR49evTosbRY8cCJEQZL5ABu+7Pb6wLp8/Y9QvTyZEMvTzYsmzxZPx/fa1I9evTo0WNp0ZNUjx49evRYWvQk1aNHjx49lhY9SfXo0aNHj6XFcnnSEjHAOHk5jlWdad8v92NDv9yPDb082dDLkw058jQ26kgrTVI54IRuGQVj0Ytdcudfto5mGRZOXQV5WrQsSW3o5cnWhv0uT/uOpDj4grFIgViGzkTDMnyCHFiOzkSDa9+iO5dVkadelnQsgzwtUpZ6kiJYhEAse2fCYREdzCp0KD4WMfjpZcmGVZMlYP/2TStNUtKXeUvc2CHGrQtDSQEo+Yn11PO23bmU7FBy2trLUxylZKlUXRpKyVNuO5s+p67Iqm152tdf5i1FXG0KQ64AtC04uZ14Wx1LbodSsj0l5amtjmXR8iTVs0zy1IScenlqt5yGtSQpDlQwUm5maWFIfZBdqty5fqc2RsGpnUqX5qLcL7q20bGsqzztF1mi5+vlKcS+ISmKRX2CPOV8i7YHLzJQwtqpLEOEWGoHU7JjscrIomXJb4P1mZUiqhSC6uVp+fqnfT+ZV/JrUZSwY6d0KMvQqfiwtqmU/8aCZehQKKxt6lqelgnLKN/WfqBr9P3TimtS2gPMcfzGyrTt/F6EHTj1xbSMbtsOpsipu2l7Uu7xorR0iq7lKUeWYuWaypKl806tv2SQSMo5V7V/ksru68AJIM8HZRGEXMTqXZSanWPSW2SgRMp523J2W+9/TJ6adCrLKE+0nlLy1Ja8LUqWuPrWqX/Kya9hbUmKwjq6bbNjkbAsZpsUwlpEx2KprwuTTQphtdmxSOjKLGs9h+WZtCEv2oDHeq6uTIB9/yRj3/mkLDbe0oKpPTxrh7KIjq706CqGJp3KonwKTeUpx5fQRJ6WVZZcvi5glaVVlKdFoG2ZWmlNanJrRsj54mRs5NLFCLgtEpBGUrkd4iJMMT7aemmlL7rmypP2vFZZnkqhyTSFVDnran5d6leBrbLVZf/UdNDTNlaapBw4QUkRhlRBWKbVA1LaweW1vMyxzkXqQJaBwOb57J1JrjzldizLJE9A/uR1KzFocrHIoBubObnZp+r98laZWpQ8NbUAcfDb1QdOJAjDsvkNYm0p2aH5dcU6mUUETEjn66JDkepapDxJ9aam+yglT6VkKUXO0gYfTczJ5WSJq1OTqRyiks6XYyWgaGMArWFf+KQGGEWFrElnqKFkVMxoeiVtwVJ/k84wFbnPxPK8m2CR8lQabclTE1lqipKrS7QtS9bzpMpN03lTTQc9JeVqbTUpDk4IpNFEVxpVjgB0ufKxO5ck6F2Y8XLQRWfCna+XJxklZamJ3KUOGnJkSbrGlHutyZQkT4uwBEloQ65WmqSGqH+Z13KTNLWXe+BcWlfr+aWcw+6Hs72AIwySRmQlyautTqWNLzmvqzxN6tHMUPaOXJMlTm4W6c+0XFeKHOV8yFCSqUUG4Cxq0LPSJMXB+g2fUvbZVHAPukmHknMNtIz2Ukqdi7UT6Ya49E6liemjlyd73thzSB30lAInNzmyVLLtFrlKIapc8ioxB6ptrXytfVKcpuVDEsgUoW4LcXv+sFinGKtLakupEV2zTyjonUrpjqWXp2Z1pMhSjnw1WQZJen6l5Sil/hSZ4uptG1aCGs+uMvy3YK1JyiFHCEogdwKj9uBLklNK3XZhbE5c1k69q1EvV3cvT1ob8gY9baBplGBOEEbuZOCmMtXWwKepZt5UvvYFSTmkCEEbD7xpOHBX5qQUourCYZtCUKmj3q46lUXJk16+XXlKHfQsoyzF6orJjyUPPSd33mWTqS4tPSvtk+IeeuwmSw5qi0+B2n2bOrvt9uD4Y0p9wWMCPsaQfTEW5Vfw0aRTidfN+98klJSnpkjRoqwdSKx9Nr/kaslSiTX/9HPO65DuLydXi5CpHJQe/KydJmUZsVhHwMvgN4g9cHe1qfDHdnKevI6s5EtifQaxjqXJs+xKnkp32LkEZZGN1LyLkCV6v+v7doJqKkMStHotGlXbMpVjPi6NtSMpH6kC0CXow08lqFxySq2La0N6GHPKPJH0mf9ddSyrJE9yvvZkKmfQ06V/KobUVU8k5MhdE7lKOVe7PtN2DHNrTVIObY5UrEhfeYJ/4CXJias7pS0l0LRzL9WxpGAV5Cll0FNapkpo5zlIMdPR55IjR5y/yc8fOy7VR0HblrvaSQmUMB+naOrAivukNr2HarWdN51E2YbNt3TknJYv7ouSFosN/QrUn9DG5Ms2OhbLcQfLfVxGeeKgEVQ755vUa7nXKbJklbOmshgjkxJ1S/eekwkqV9Q/tUhflMV83ARro0lZo2dKjFQs0EeT6fb7eBmrb8Dii2ou7It6YXJGqrH8qR1WG/KkIWY6bkJQvC5gHwVz+RYx6dlHbLAjPe8uzccWubJikaboEv1AEkl99rOfxS233IJDhw7h0KFDuPXWW/FXf/VXs+NVVeETn/gEjh07hiuvvBK33347fvCDHwR17Ozs4N5778X111+Pq6++Gm95y1vwk5/8pPGF+MjpWGL1dYUUgkrtMKTy0rFY20r7E/RnFtei2uxcUjuUWF2LRmyQUmrAI52rbVnykRL00uQZu0Vi6b+lfVz9Of7ZlPbGUMJvXgJJJPWKV7wCn/zkJ/Gd73wH3/nOd/Brv/Zr+I3f+I0ZEX3qU5/Cpz/9aTzwwAN49NFHcfToUdx11124ePHirI4TJ07goYcewqlTp/Dtb38bzz//PN785jdjPO42coaizdGv9rCWYdXxJkTVVptKdPxtRGRZO7HS8mS9txYtKjboycEifKU5SH0O+uDERkb2fHGi0uRqGQY/DiWf2UZVVVWTCq699lr8m3/zb/C7v/u7OHbsGE6cOIHf//3fBzDRmo4cOYI/+qM/wnve8x6cP38eL33pS/GFL3wBb3/72wEAf//3f48bbrgBX/va1/CGN7zBdM4LFy7g8OHD+NT538aVh7ZMZfgO124m8fP62+FHvOL5tXPSDqULgqKwvCiaVkMdx/z2vLytbLp5xvrC0rqbzB9ahDxp5WkdUru19BykaCMWWaD7MVnSy/Lni5WT2twEKWZYa7+RKldamTbNyACwe+FFPHj4ozh//jwOHTok5sv2SY3HY5w6dQovvPACbr31Vjz99NM4e/Ys7r777lme7e1t3HbbbXjkkUcAAI899hguX74c5Dl27BhuvvnmWR4OOzs7uHDhQvAP2Ecok7zpo5S2kRPKHdPKLP+xc8TSFulTaEpQMZlpc9Qr5fW3U2VQN9stZtAjyWnKeVLbZAmiaUpQpb8tJctgXXuzmsItcrXopbtSkUxSTzzxBF7ykpdge3sb733ve/HQQw/hVa96Fc6ePQsAOHLkSJD/yJEjs2Nnz57F1tYWrrnmGjEPh5MnT+Lw4cOz/xtuuIHNF+tccjo0Ll8banWsQ7GQkxWx/IsKeiiBmGkmvb525KkN5Ph1LM86Z7Aj1d3E9E1R6n5aCUoDv3xq+C+fP102l31AXRLJJPULv/ALePzxx/F3f/d3+L3f+z28613vwg9/+MPZ8Y2NjSB/VVW1NIpYnvvuuw/nz5+f/T/zzDPRduauHpz68NsQlhT/QxPh0cqnkiSXL5fsltE8o416NbS1wnsMFi3KqpXH8jRBV1q5JkdhPjtBWQgoJX9sTt0iB0AUORHIfr7Jv41+kklqa2sLP//zP4/Xvva1OHnyJF7zmtfgT/7kT3D06FEAqGlE586dm2lXR48exe7uLp577jkxD4ft7e1ZRKH7t8DasXTlcLTaiLVyXPmmyCGq0p1L00CJLswzrs6ctiwbpA4lh3hSBjvauUvDFpGn+cF4+Snx6Q7rQrKabNlMnMsji7nBNY3nSVVVhZ2dHdx44404evQoTp8+PTu2u7uLM2fO4PWvfz0A4Pjx4zhw4ECQ59lnn8WTTz45y5MCq7B0tYJwCVg0mJQl8q2rES/T8jQl0LZ5pp5mC3NeRDSWVStuKgMSWXVpPk7RbFPvfwly0trjkLJKSUp72jQR5kxDsCJpOPyxj30Mb3zjG3HDDTfg4sWLOHXqFP7mb/4GX//617GxsYETJ07g/vvvx0033YSbbroJ999/P6666iq84x3vAAAcPnwY7373u/GhD30I1113Ha699lp8+MMfxqtf/WrceeedDS5ifvOlFy22gvAA8xnb/uxuv5yfx4omDyeVoPTw8PhXVLlVqcfQZv/zq1uXQk7kFy3nI9eUm7PKeY6sNEGKZq6VLdWWXDlqY2V061wlrUypldE5meDkTFtRQpKtpn1VW2jajiRp/l//63/ht3/7t/Hss8/i8OHDuOWWW/D1r38dd911FwDgIx/5CC5duoR77rkHzz33HF73utfh4YcfxsGDB2d1fOYzn8FwOMTb3vY2XLp0CXfccQcefPBBDAZlbmhKx7IMD1IKH+XQdN0srgx9GWOdhNTZ5JQr0Rm1RVBc2dinE6g8SQMfDm0NgFJ8i3o9ZT8Vr5FWSh4gbWI3dzyHoHK1YL8cfRYpSx81la3YIKsUSvSvjedJLQJuntSfnH+bOk/KMkPaMueEI5KcfG47Zy5M6mzvFEh29zCPfZ6Kn4cr58rE86fNp+KupYvPX1jnnXDP3SofXL6m86uk6+HqkaCRVaxz71qOSszJo/mbwvJMcudBNZEtS/2x64gR1O6FS/jC4Y+0N09qFcDZkFPsvVIZa7lSaJOgpLrqL4okyO2PxtoiKBdjRP+tbZHOu0iU0sztk5rlvLmrqZRE7N1NIShNPiRZiskVd8y6qkQsiII7Zxuk2/ZzXGmSGmAvq2NZRKfCjzTsI16pnHQu6T+lzpwor1JIfUZWgrKQUSyPhfy47bZH5RqsmnnuoEMqqw12aPmmaBJgkLuqiaX/seTPJSr+PMszaCqBlSYpHynCMsnf3UTdJkhZisQS4qnlaXvJ/aZoYqKhZVLOaRmRdtUxtDUdYdErk5dECmlwKLnslnbuWACQLXK52bW2hZJ9xdqQlIO1U7GgjZFvLERXsgNPjpX7JpBEVtbVqUsKYZMRsCV/6gCGQypRxQY+qb6cVKT4N7s2HccQCwKwwmqmT50wbtXCLXIXq98yfcFtp/ZXi3ZjWLF2JOXQpFNpijY0DslZ2fRcFqKK19HNyugOmhal5S15Xoeul6fR0MZ8uFKmY1ont90Wcv01MU3HpVn9TpqpTztXzrp7bQ+CusTakhSQ36mkjnxz0HT0WvLlTnGwW8+b077YCDUGi5nGP5br6NYQG/iUmm9TCk0+KZ9iOi49FytvHUb7e001lVSNKtYOiwkxx5+5bPJVAitNUqU7lUXDGvKpj2Lj3W/s3Nw5LWVKIWe0aCWoHEc3l+6jpO/AipzBQlvm4zaDIWJw935AfjXEOve4qTbep1iW5LL4pWLEql23y5d7T5aF1FaapCiadiqlzTmWl71ch2A3/eUQlVWbant5pSYvXJORbywtxySj1d8EuYOHJuZjS7mYDJUkNW5ulJQnTJMJSu5f5M+7cOvHa+fk9h2sMpbSZy3TIF3CWpGUQ4lOpWsflVWL4sqVDZzI7aTKj5qtHUxKSHguLKNe67nno//mHUTuoKCN59U28TSBpnE0cQHkmR05MgvlS9rWzH4p8tgkIKlrYltLkgKWU31t/lkD25yTJnXWj/PaVMk2xJDy3FKIJNUfFau/y4FPKrqaWJs7YOoaaatQ1AOurAsYx9qgLS4QNzvGtakUk592rkVipUkqtUOhWNTkSm45EgfL8jZSWXrcEomVU/eikOJLkPJbiMjPZ23HopHyfZ9SPk6tjHS+Llfbp/4qDSkExZ1HWkHfsrJ+KlE11aYkLKNcAytOUg5ax2MdWa+CbdYh5peSzHhpgRPpa3V1hZxVraU0Sz0WQnNY5KoSOWji42ziw9LOnYt5R61H7Gn+Kpkg6lpPzqc7JMKyEpVfD1cutS1N6+gCa0FSPpoQlVROUp1LdT4xW37pAIwm/qj2AyPCDkS7xyUjsuLt0mUo1RzTFlK085Q6UvN3OYgp/WxpWio5WU3HtB5KhJxMa3JG85Tot5ZhgLV2JAWkdVLLNPK1fcywrvG0FZEV06ZKIkVbKVm3JfpKqidFpmiZJj4DC3IHNu3JUreBNRQpWlSMoLhyMWuOdjx1kQHN7FcKy0Rka0lSQF6ntyxqr3Xh2TYCJ5o4vl27U7StVAHPCRvm6tAIKTdc2DLKjaHNF77ttRmtstSFX8rqj7JoKLROv2wpE7KFqCxmP6s2pbVNQkqEX0k5XmmS2ox2Ns1HvhaklKdBE22MXOu6wfzfUpdGjK7+WBvaRlcrh+RG6S3L0jM5z3yVYXm+GoFZ+ohYUA33r+X1z2GNEC1l4lwFv9RKk5SPphPl2kZs9Jiy8Kw2QrWcJzeUPH1Nv27D03WNKm9Oiyube95cLAvJNY/sKy8DqQMHe0AFTxBaBKlLi2lVMXOgD46oLGa/tnzmi/ZLrQ1JOaQIcIoTsivkRNJZyIkro7dj8SNr+gys/iKOoDTEQoRdHU1Hm4uSKQoLkVjIKD3AYnELEaeVsxFUSXMfp1Vx5bh2xJDr/2zqlyol52tHUgDfocRGu7GRa+7ItrQ5j6Y3se/bP0jXLWFZn4XlJZCIRSKmlDktVpnS2lASOqnY1+lLjRQtWV4jMmtHyHfwfNSoNhDSokdjvk7rckiapYeTH6ndOUSUU3YRK0+sNEmVeMlLOO67QkmCkuqImRVpcETp8PgcyKY3eeKlBbZVA5qPIJvKVMrk3Hhd5VeMWOycurw+wjq9wRIVGstLySpGVClYtO+phDa10iQF6CPfVG2qa7iXd97h2019skOcm/8+/0+py9IO63EKy/MqjdxBTWzi5Ty9vExp96Skn7MpUn1RbUT4xUK3rVqUbamkZubfFGtPzOeUoxFZTYcpJsYUt0oKVp6kfDTt+LoabeR0+JZ5KLaJmnw+aYXqkn6HHEgdSEyDscxvSUHTuSwpHUdpWJ9JFxpPKfmIBTP4sPgy04JjbEsjSf+0bSkm5BhRadeovQNtm/x40+aeqexakRTAm2isHYo13YLYKhK5dQBlPv+9LKtTN4X2IjvI/iUpdo3Pb9Go2nBKd4ESwTnLEGxjicSTjvnlrQTVZGmksF06UaWYqLl2cudKN0vna1P+8dSAk7UjKYfceTTWfF12Mv7LX4KgpLLx7/3kT9pNRakXSFshIFZfSoBNCd9H28jRkCk5xebcSedrghLvmh4tJ2vpEkHJLgb7wEebF6URVYo2VULTir0HbVueVpqkUka+MW1qUaD+qJRJvrGQXsvcFstnvnPMk22sOiH5FMK65O9MpY7gpDKpEy5Tzchdy6f0/Jr6vCzpqZA78ng6d1w/l0xQNF/KwCcmT5ymk2I+1uStTU2LtrUUVpqkfNhUUXuHUhJNvsMkaVFaSLHWUaSYIRdhvsnxK5YwQ5Qov6qmPoqUAUaXn95oCm1Qow2A/DzWlScsbfHLSlpVqkylalMWTYvLXyqfBWtDUkB81Evz6nXJo5BlRMrkyhhR5X/tdbEdVsoqAS49xSdFOxXuvLkoZTJJjRht45m1Xb8E6Zlz6dYOW4r4o+U1WdJkiyMreu6YZs6126JNcUhZvcJqUWiKtSIph1TzTJeIzeKX8mhaVBtzW6Q2Ub9Um7DY0eMvT1mflNShSO3SNPRl1KhyBiiL1KZ0GYkFTMkrokvHYyRjgURWDjlExdUVI+fSARTWCcupWEuSAtJuvKUzbBNpqwG0N3Ezh3i67qBSXpCU8k3zL/Pgx3IcWB3TnaYJpJpl5blT8TlTOdoUl19rl98WbeCja4g2bSrm8ogNCKVzubJWiwXFSpPUAHvqxVpHvdJ+27B2CtaVrP10e+BE2mThLmB5GSTERr257bF0Jra6lofMSprirEtsTY6lD4asGhPNK5OM5p+2T+p1+/bBTL2D9vf9bav2bQm0iJXl2xpf3FZqZ0msNEn5SBOU+IKjXP3W8m3B8j2gmDlRCy2XzpEScZgLeQTWfCImt+/KWddZi9Xvt0My+UnlLb6UtpGygkkuqPw0GQjlWko0LSq1vGwSzlu7TyMZiYi545ppjysrleFg01TL9o9rQ1IOVluvra7uyEjy/bTxPSBr3hQNLkZ0JRB7kaxmCgsRxZatsZw3Nx/fnm61fEAzQ8dXLQnzp0xHyJsqEjM75WpRHHHUycX6ZWd57T5tOxbMENOWcrQpS6i71rdaB3sWrB1JAfZRtH+s7U5A+tpuifIlAidySMa2DJPctrbuuW6aSXtxrB0Kzb8IUkmBNLVhfnz5ViSJDRrovi2KrU5enJ9K0k4kedKWQuLKSia/GFHROv36pOvj6pXKhPXLxE3rkq5Taq+GlSYp/QbkjXpTOxctv4U8mnYGsXNoJpUSZNcWrP5ELUKrKUFJ5WK2f60NtL42zch0gnhquVL5uoRGXNKxmJbA18UvjySRknScIyvpvJppL0Y2JbQpC7RIyVSTusNKk5SDZvPlttPr73ZUrJn6Yo5v7nPx2lI2ckAF/0mONomsxFJW8igwbVFQS/kUdClDJcxuVqQurdUUlmiyVFOfn86tJqHVIclLDJYlkTSNKtY22YRoI0Rp8BXTprgyTbEWJOVg7UhSlhaxpqcihzBy6kw9b86E4LY7phzEOqbYc+Q6H1kDsptkrOiK1EquBdkGLPdB0lykemKBKrQj9rV2n8y4c1j//XMOmfolX9g8re6u0DQt23XHI/3o9XLb9FxNsVYkBdhMM3LZdjuG1DBwLV+TSKlVmQ8TH/XJTm6uDpc35QWyElVOfYvyW5UeSHRNbDnmucm+fd0/jqAcuNUnctwEMoHogxxtMGQJm081F2rnixGV9r5Z79nakRRQ3ra/CKR8CLHEKgEcAeZ8hTcVOR117mAjd3RnMzHx5hGtPSXaVpIglk2LcsglJS7NEu6fQlD0XClalF/G1R2L5LP4p7T0JvOmaLtT0i0mdQkrTVID5YJjI15NxbXYsEsg5Uu8qZNuS32RN4a2PnLoYNU8Yi+cRB6WjkQqr7WppFy1JYMpzz9lgNJUrpqF6qfNmbNq6367qIykalKcnGnmtxhR0WOh+VBq86iWnqJN0evR9ptipUnKh5WoUkcATWGdid/UFzQ/zpNS6hd5rW3Q0tv93pTu6PaRo91wHY/k6I7Vk5onVxabaLqWVfX1lUu618K08G/O1KdpURIR+HloOtfxW/7DdumrTcSIisvjl+fabNXCYgMwzdSXYwKVsDYkBbQ/Q7/tEQNFaghx7ufjtWCKLj5wSFHivmpTE1JHvT4034HV5Ne2nPpoEpXZdEBVEimENC+jPweJuKiZT5s35fKlasZa6HkKUZU2+2myG5NrzZxptVhwWCuSAsr6D7rsTHxYQoibRmWV+IZUV52VNmLz02jnApQJVMgvl7e8Uptoqi2n1pOLFJOrlN+la8FUdN9CUPO8o5qsWf+5OqhWFZ5fXnwgxc/GXYOWbjH79eY+BdLNKOE/6Ao54d9thA1bNaV2gify7r8ljHx+Dq0Ti4/w5Jc/vnJJmubWvSy2aaqzanLWe6Tlo5qRD27wKnfiNoLy604d0FrnSYXtqMuan4cjO6luv14pXdNetXq5NnDYN5qUdDOa+g9Kjg4s5jW5rP6SS8EX3L+lLHdOSydWmjhTJ2RyWpRev/4SSaYLhxSClOqwoK2ov5SVSKz5uvJLcdpR/Tg/WLBoUYA2Z0qeKxUzbXGDoNg8qRhR1bdD4uCCKGJl/PNxbeHa41+/j6amPmANSMqBu3DNnNe1mUUDZ8azROSlRAe6Y1rHEiPPZZ+060MzdaRpNvHBiuZo1keb9Tlc64ISPszYc4rdL4nMOC2KG+RwBMWdO0aKFsK0hJ9zx/08EiHJ11onWf9Xa0t4Lbo5tSnWhqQcUk16lo6hDRNM6VGnFnnF5S177ubXwj0HLXLP2qGXeGEsRJh6zlxCantwtSyDDweLySimWUnBFdKgge+47aHoFo2CptfrzvMJaeSpldEiBC0BQlLUotwfjzHAHnuMYu1ICsjtzNJWEujCd6CZ+pqvqs5rZF2u1VcKtCOxkkeKKUIylczT9KWXLJ2tJa002l7gWIMlyElL5+qLd4yyFuW3idOuQm1H16SsoecD5nzU/KcRFVfeb7M71tTspxEVZ66UrjXVkgGsOEmlm27iqmtTyL4je7RUzNTXhu0//kHFZqRoQcpoV8ovlbWY7ehxrQw3mrTUa83TI0Sq5skREj0e7utRbjx51YlBC0eXSIvW6c4nkZHfnnp7bWY/Wi5m9uOvRypv/XCobfCx0iTlEOtQmkSBteknKNHZ81oWrx90ef6SSNFsY9MKrPU1LSuNUC3nSDlPClIGSsuInFG4Vo7TorgOWtKe5ts86cQ0CGmulKxV1YlKiuiLmf2kc6WY/aR89PqkfyvWgqQcmnRGKciPuLIHJtAyllXTY34pPnCirsFpa/W1PanX8sysoeXc8dxOTkvXQnZjmlZTs3FO+TafYVMt3+oj9k179ojOUUBENH2+P66lc506N8fJqqHH6vHPqRGVS6f1u3KS2a9eR57Zj27nhOPHsJwrSjbAAGO2cx1ijBEGGGCEMYZiPktdJZFqHiw1CTels07N3wZKnD+FIOh99mUhJhfScas8ORnNLU/RVIb98txzKC0fOXWFpKWb+tw5tAGMNcov1/Iy8mQJcPdwNN2e90/u1++/5vnHs7q49Lm8joL94ez4sJZXOg9tAy3L1RO/B7Z7tVaalIPE8vG87a8QEBvF2r+K2iwcvGl5qVyc+MvYqrnnpk++TNNgJGc33aYjTSk/h1UIOdc07xKIaakl6vdJy6JF+fJkJahUDUKaY+WfQ5Mx/5gWFJES7Rc7j39M9uHlmWQ1rDRJDbCXdFNShKhLzSGmTeUETMT8UXI52eTXZIKoD8tz4Dv9PNNY3R6fts6aVJclf2o9XRJXLBhm0T6qtt5BzkxI+xEtDJ126DSowvpPy0vn8n+dCY+a/mIRi02i/VKJKuVeWLDSJOVDV93jo+hVGNU6aFqQREpxf1Rah7SoDkyyqWtalLVeORJMIh75XFKHp7VNa3MXUx6s6PLZS/4nTkOKaU0caD7qh5JIgyOnsN3xTjlOdnoIup82vxaZeLVov/Ba0yYWS8EbpbA2JAXoRGXJn1p/LnI+mWFZXcLSeeSabxZBSiXut2TeAOYdw5C8uBxhWULfLSNMSzuXAd0SUfqAIqVujsikfFybOILi88U1BI60NLJy5+c0MEmz46L3qObE1UOvx0pUfh7uGmlb9q0m5RAbpeaGKKeMZHPIQkLp71FZ6oh9nkP6jlUbiGkpuoObz2f1H1iIKlVzy5GtVdLyLVgGrVDStqgfSiIoiWRiYddSuDrd5oiKyyNpMTn+Kb0d+ZN5/fyxNA4rTVLSTaEPRyqbkp6KpiPRWPkmproS5ZsiZfQcE/BYJ04JKgV1n4GdUOqDn3Qz8yI0rJKDLIe4VaPMe8eZB2OmPz8f116ZOOrkRDEcj2f/tJ320HNZQ7eEmcdMgvbrlhdDoO9IClHHsBYh6FzI7gDWcN94Phd6WRp101ts1Qd7G2h7m4zGx/BDTIc1AfOPp4CaWPS81nxpmg2X13qfnezkypBVRlPqzMGi/IsUqTJqMeOF+Xk/FpfH1a8RlMsza/9YPz89PhrQEPEw9Jxikl5/98I6wrKuT5m/v2lh6a490hQeP6///CxyaX3ea0FSQPig68f4OQcUbZFRCvwOQ4rq07SgmIluGAjwgBXIyW+djKT2Nh3t24U1bn6j0LSomGnYv7e+bHCDIlduzOThyChGULQT2S/gCMcnBIlcmp2zrm1JBMWZkGta0ijetvFwEJQbDXgC8vuseVo4Twmoz5Xy2+3XxeV3x3OJyt0b6dwSrLrUSpv7YighyE3qsBBek07ISlBantj5u/o8h7XjSckjEVTKuTSTRnguKV++LX6dYenEaKSdFZLGxKdxC7/W5UYy7flEMxiNTQTl53X5fZOg5v+RTH9SYISfxuWn10bPL5sgJV9Y3rulYW00KQdplBvLmzPaLYUUMpPak6IBjjBgOwmqTVnaVLrDpb6BGGKEYM2jt2kuBzFt26IhafLp2hd7nm3J5ipqbpSAUsFpZ2HHXycHSk7zbdvnJwBgPNwMygfaFfMYOI1qvh3KTUxrctc92ee1MotGRctTzUrDpvFZrbQmJUVptRWFlYPx9BVIKxOfQMuZBVNg0ZC0yZ6LXMOP8yPU8+gBNX4a928rW1/HTGvDMgRJtLWSftfkZgmImOe1aVGuXkkzoATla0KD0V5AUIOR/u+XceWoZuWf028H1aj8vo2L+OO0prAuWSvz0/1fKapPe49i75iEtdCk3M3yO87YiDX0MXSjMWko2WlIdS1D6G8KNGG2hrpKxBB7SejIkNbJkbSmcWky5o9o9xNytdrYAIYSkgaJtDgfFRAS1OQ3JCbzdXh5x8N5PePhJgaj8Uyrcr4qqq1IGpVr+2Q/DJrg0nwf6ry+eX+qBUn5WlVYx1yOtffX2h810qROnjyJjY0NnDhxYpZWVRU+8YlP4NixY7jyyitx++234wc/+EFQbmdnB/feey+uv/56XH311XjLW96Cn/zkJ02aAiDeIdm1qPKd+Xj6WKzgNB3O5Ff3MckdHT2mnUPKFztHG5CeR4oZj46O7efmy3GjTan+FK0wtU3Ljth9t2tCsQVjbaa+mGlwro34pr45Qc19Sb4GNCed4Tjtn5afa1eT8zhfFaepcBoV1ZA4LSu8Nvm7VZL/SdKqqGZVIvwcaEBSjz76KP7sz/4Mt9xyS5D+qU99Cp/+9KfxwAMP4NFHH8XRo0dx11134eLFi7M8J06cwEMPPYRTp07h29/+Np5//nm8+c1vxjgSwmmBZU4LN0LiyrcBnUTStLkc8tCIqklb2obVtAN4o15mcJIzsrOVT9f41omgmrRLiq6zPHNd264HTMh5RkHHPD8WEhQAlZwAYGMU/3fQyGryOzf/zTt5Sjw2opLSUomK/tL6JTcMPW7ta7NI6vnnn8c73/lO/Pmf/zmuueaaWXpVVfjjP/5jfPzjH8dv/uZv4uabb8Zf/MVf4Kc//Sm+9KUvAQDOnz+Pz33uc/i3//bf4s4778Q//+f/HF/84hfxxBNP4Bvf+EZSO6yOt2WDRgAWfxRfrpu8iyYvTUtJ0aYm+9wKAPxojzuPZrv3j9fbkaepx8otK4GlwEreEoFZtS6X19IGiaAmx+rkFGBE/hHm3WDqmfuu5lqVa4drf514eKKypuUSFd2WCIuS0iSvLcgki6Te97734U1vehPuvPPOIP3pp5/G2bNncffdd8/Stre3cdttt+GRRx4BADz22GO4fPlykOfYsWO4+eabZ3kodnZ2cOHCheDfgRPqnFBheqxt5AZTuN/QVCcHV1iCIuiK53KZ5ksvlYBOILwWxRFUk/Pw+eOmrRxNPbfcOoL6jhwspEW1DP+4r5X4Hb5EUCI5CaQ0Az1ONCxKVu68vvnPtU0y/c2viw9Nl8LVY0Q118Lq5bhza/8unwXJzoVTp07hu9/9Lh599NHasbNnzwIAjhw5EqQfOXIEP/rRj2Z5tra2Ag3M5XHlKU6ePIk//MM/VNs1QOiYTp2YS8s3zWeBVE/K3KSUhWfbJmGLw7QUmnTaKZoMdQa75+9+rXKWKjd0Iua6IFeLjJEQny6bnLSyrp1hmHlIUADRmvxtq2i6x+rKDj3NqpZ5bxZUAYSTf2nAxCStHlY+OaWcJgVNcPIuhaj7oHKb2yckaVLPPPMMPvCBD+CLX/wirrjiCjHfxsZGsF9VVS2NQstz33334fz587P/Z555hs2XchO40beWl4Z20tDNXKQQKadFSXksx1KWYYqdcxEdqaS5aFqUNArPsZWHbeFNftI5uTZwZplVhXYPU+5vKglxpj4ugo/KDs0ThpkrBOVrTGOEBMVoTWz+McmP0Azozu37qTiNKrzWelg5F5rOhbhrGpU7x/wYH1RB06R0C5I0qcceewznzp3D8ePHZ2nj8Rjf+ta38MADD+Cpp54CMNGWXv7yl8/ynDt3bqZdHT16FLu7u3juuecCbercuXN4/etfz553e3sb29vbpjb6I1aO9VM6U3+U0CZ4bUj/IB1XztJObsQDzCf4SsdT63Pty9V4cjrq+GDDHiRDpzX4Uxo0bSpFo/evsamMldTwu0Ds+WpBExoJ0XNoBCeZ+Wb5NILiNCfJvBc2Vs47adycqLwio4Ez/4V+HG45JQr6jkqh6TGNikN9ovAw+mwn5x5h0zjIT9Kk7rjjDjzxxBN4/PHHZ/+vfe1r8c53vhOPP/44fu7nfg5Hjx7F6dOnZ2V2d3dx5syZGQEdP34cBw4cCPI8++yzePLJJ0WSkiCPpuy+g9LO7Vw07WBy/UWWycJSntITemlE12xUq3RYNF3SonKjOC3RotJxrZNdtTlrVlhC8v10OuLXTXD1Y9xz1Qgr9tx9P1SUoJwW5Kdl+KSCdKpZIfRVUT+VH6JO+zWfiN090ELT5/eJ16hcmv9bD4iwr4BufwcTcPDgQdx8881B2tVXX43rrrtuln7ixAncf//9uOmmm3DTTTfh/vvvx1VXXYV3vOMdAIDDhw/j3e9+Nz70oQ/huuuuw7XXXosPf/jDePWrX10LxLBCG0VSbcqCFH9Wmz6qkChCU19M04rZgzkNSFouiW+rbQHakaJppUIbGacgVbujExbpKtDc/efS29LMU2Rbw6I0MWuoeSyNIzCubkmLooESQISggJBkQI5Z4GlOE5WJz7YBoBrO2xJOAJ4up+Q9Pqfh+5D8RhaNKge0D6Xt2TXWU3xW5kc+8hFcunQJ99xzD5577jm87nWvw8MPP4yDBw/O8nzmM5/BcDjE2972Nly6dAl33HEHHnzwQQwG+S8J7QAsnYfUkSzSbJKqnWjERtM1s1yostdXR7fWlYuU+viOp+4T4rSolIjOmNmOMy3TdP+c+21FCR+58sJpP5KPQ9r367G2Y6KpKAQVIyeLojwET2iOrNzxKZH55r852iUqWpclaMJ/Jyjoc7Jgo6qqypRziXDhwgUcPnwYZ87/P3jJoXTtw3f0+2Mq/xg/zgrT3P4utpLyx/K4ttJ2StfCXbsEblQ5+Q1VcKr2+51FMPIMroZLG2Ebu8bjtvrqJsG5hkWPcdfG3QcJ9J5K9z/27HJlwVKGnpOTZ66N9BpTB2dchyPJkX9cep40bQu7tePb2Anyhvt1WeNka2taRtKiHEEBE5KKEpRGThxZcWMVP21A0oZe+nS7Gk78VMBEqxoPNzEeTvuIgdSnhOmT5s3TXB4qP9yvtAZkSh/00wsjvOPwX+P8+fM4dOiQmH+lh3aTF0Ie3bptzuRHR7tNTCYDlP0OVcwHlEtQLh/XQXPmO5o3xRxoRbNQct4f5R9rQlAuL3dvOXmh2pZUVqp/Erhil0F3HaVkz9Le1PrC/ZTQf24UTv1Xo+AY9Y34+5KvanacmPkmaRGCoiY/ui2BC6bwTX6SduWlb7hiJKCC06gkjMn7LPcN9Ftz0lcUbEETwNx3ZcFKkxQwF1w6RyflZUudU9U1SnYcrj5JVZeIyOqD6hr1zqq5bwMI7zklEo6I6oMe2dwcnoeaTfh77HcM3Pnq5ynjp+oSVGMP0+VBBj1W3w/JjNOiZsc9Mx9LUBafVInXhJj6AnjmvxTT36Qob8bz9/3Bj/bO+2VjeSlSTK+rJcUKpJeSalN+2iLAmWqkfHx6fPIuEHdaSqMm6/EukdoOTYuy1usTh9unRCXLHK9lTerL19a5tqRi0QMy2jnRaEwuv48YQUnn4bQoycw3IygHjqBi5GQVWWPghHScBlTENCoukEnSjMI88qftpfIj733hsO9ICgg7B+uL3CVhSfOhZEKap9cXk+X9CFIHpJnq5iNzXltqSlhSeUtId+jbkJ3fFrOhNhrXysTIIaZpAYuLnFsELKZVX4OR88jTBkLZqMsJl88dN4/inUkvRlCcb8pPlyCZ9izwypYgKh9Uu+ctK/FBbkwO9iVJWZBDZCUQG72WaEfsHHRkIwmaT2iL0qgsZjt9VF134Gt1h9GNQ3Is18+5WhNsU5BD+Ln1T/Z5k662rZv9IlqUhaByAydicNrVkPwqaEpUue+5pFlZSMm6wOxKk9QQe9PnxwdAcM4+q8kvxf4fg7WsH1XDlZUiblzZdUFaYAOdG5Pmk+LnXaX7OesEtTif0KJMeqV8llaTnmbq87c1MyAg+KF8QgLiBMWZ/3z4p3SPxs9rIKJZvrG37ZWph6inBVNI/iiuD9V8pxYz+mR7nwROAJyJJa+DoHOFJmlzolsXIuA0Jc7kp0X7UJQaTefUU/db8FpU6gtCyUoa9FB5k+ZUWdCGjHEE2yWJ2k2rfNAEt02JyK/D5eUCJvxjXERfDZxGxUX2pfijWjZMhAEVRFuJzKNqAkt0nzZnUcJakBQgjx6tL2jT0Wdq+LAGq59JOi4582mZHAEtFYae61dKqU9KTx3xc/Ji8U/557dq0zTSKhXLYmK0aKx+Xi5/jIj8bb8OyexXC6awmPliBCWRU4qIWXxTXJQfl85G/oUrqFvFI0ZiOSTn57+830gK4JevcdBeXuuLnUNEuR1GLJgiJfrPT7cGRnBkpIWhj7373hZiDm9ppO0f4817cW3Rn2XvH9NMyE21lTnBrcdrqk3K1hDzR8U0LF+LcvtD8hVwlaAcJIKiWhXdToGFsGKmwQSiou/+GGmh5H65toKX1kP6PcQ0opwJlz4mHU9X0YB1fxTFyJAnrHNONJSINHty2wEU8ZE2dXqP2TJch5aiZdFjmrYUBlSEvlCg5CRbm8x1pUXZzXfp8sIFPGjbMVMf1aJmMkG0qAA+Gbl9Sloxk197Y7UkWE1/XWHf+aQmQlcpGpL+iY5lMY2kgmtzydG2tpZf14idN2VSYMqkXz8fR0S0DSlz8HIGOuFot+wcLHqetEFbeB+bmGxT/VGaqY9bHsuV8bUoNVhihHSCSvFNTRrEExpdvy8VJETdSYa/MK07v8WXRH2xuQh9Uvsgus9BM8FI+ZZpRr7WKYSaUpqvSj5fXZvSgiRSCMryDSmriSflZZBMPpyZz9KxSto2HfjEZIobLUoTKq3glq+S83alXfGj4pwBBGALjKDgyYshMrI+HwDZDyURlEROnFbWNowh6tzqFABqGlXpgAofOcuTLUcvXQCytlSejKwvvnZeurAj3U+BdZFHOhpvY+JuDspFBsY1Jc1v5cNf7sWVi01Z4Fb5SPnkC9DupN8ShFVaNqSgCX5b05ZGbB6Xz+URtSggj6A0vxS3v0CoRAXMyKqtgQ3VjHf3kybl4N9czfekdR5d+pys4FasltqvtT2VgNpYUNaCJh2hpkVZCYrWR4nKYkYG8qPzHLqSw9KdkhSp5z8PyUxr9UHFyMvlocdqWhRn5uNgDUWn20Bdu5o3PG+uVANIc6n8NqUsFJsCanbd3A8kNbnozVpak86hPhO77C1y7ttYHkvaJL1OYLG6/aixAUasyW8ZF5SdB0zMo8NywJXTyEEjKj9tsl1Oc29KHvnzBe1LiuXUbTnGbWuRmZypz6XPtseOqMj6fDEzn5WgFmnyS8QiAirqwU/7gKQAfdRqXbpGKr9IjCEvQMuld9F+1zn7HXZT1EfdHIHIhMSbi2QfRmzBUj8t1c8pmfxi0EyC/qChFGIL5MbaotVrzauVlbZp3TFTn/87y+MHDfhEYyWoEckP1Mkp1+TnAiU6gtX8Z0FsYMNZMYawfcpw5UnKIRzNlovm81dfWDRoG2IdjH8/aLqkTdHjtIxFwyr9yXhbvhHZj5eL5aFkNe/cdW2KK6uh5ERwv84mIfDS9fB584MmfAKhddlMerKpL0j3VpeYaVFUOwLyCKqJyc9HB+Y+iihRAUU0K94Mv89ICuBJSHpZm4btDiKdQCltxzb3iZIXv09NWlYC0CL/gGZhxz6aElttRQFFi0o5l2WUGHbo6Wa22GCo6WApb4AmR33a65B7XV0DjvujktOnvqgNSkycKS9GUJpG5dJ9LKHJz4H6qQajPYyp+DYgKuk5H8BlU/m1IikfJTqOZYF/HdJnm7m83LFYh0PzLCp4AsgnLa6cRFDaOagm4UJzNW0KaDaJN1ZHbHCUa76OBYE0SacTadlFXiPPRzbpyaY+/5y+FgVAJyYfEpmNSTkgLJtj8ss196WUU/JqWtVgNJ4sVIsxRgM9eliy4EzS5jeCrvohYTV77Sk2McIAm0GHbRkxNhlVtoVcAvXblB44EfuOlC14oqR5z0H3QY2Cjq/EaF0qq/s6dRNzfEAgP3PNBMitEpLjYyoJ60CGe1ZS2bhJr57uy4c738TURyL63K9k2uNMetIxkDQgj6SWAPXoP4A1AQIiYWnv4zx4ZYyd0T4y90nr9NHRr3+sa8TmTE3yzLvdevn0iMBUdK01xRzkFFqnXw+IGNWOpRAUzefLUz1PfRX0SRn99bKY+KwDLn1aRXsyb10L0VKekgtXV8yk5x/jtKgNjmRyovzg7dN6gDopcbdkjLgZbUHaVV2rAiSyssJfcb42mVrBWpAU0MycVw8SsNXT1OGthaPrn5YPvysVK19fKDbd7FcKNjIKpde+ECn1SdlMUvKiufGBDxdgkKOl0/PRY+XWASzhP2s2oIjlsZprOVMfFzABQNai6LaFoDR/FGf689Ot0EgmRkDScS6dpnn7G9PtmnvK81lNtjcRgx9V6Z7F9k60GMA0eaXBL0sTX7aGT+Pt86U6C+tisD6sE3hpPvpFXlqWmvxKEFRbJGeBpkVxgRVaPRJxlIoerZ+vGy2f07yat99G/nQwwZX10zitSjL1ue2g3GjPrkX52xaCksiptLkvhXgKw5kAD4wmX/+tQ9ewfI3JX8x3w9g9rDRJTYSSZ3FLRBagO6hLdRhNiE1qQ44G1vSz8FqZtkjJ0tHFJuem1Cvli3+mgzf5abB+/8yvL2cKRUk/FUfyseWlfN8hzUvJxeJ38su6dnCBE/NPw08LxHxMPoFpvip4+xI5+eKliQI1+TUlnRQys57by8cRliOeERFNurr8hn9PqHlUwUqTFGA3X+T4pUpqTk0QBkfI6/RZ2hrzO3HHuftW0neVsjo57ehsC47SX2JOFKKMeKcwt7BsuA3Y50dxebUBVMrgKWeuVGltKq8O3e9EzXrq8amZaYMjKoDXrGJkBvCkResFSSsBn0gUU51YxgqDv2yD7B+IXSe9N/vJ3CcRFdehNEWJiZdtEF9Onf69kTUkPsJPWsm7pDZlMQnR47GJpVaCcsccUdkGP2WXIZJkTfNh5ZwnpXypfPRZpYaYS9vBGoF+2DmnMcV8T0hMA2wTeynaNNkZtCN2n6a7evz6DEQW1OO3iaYpWAuSAlK0o7SOpI3VAHLAfbJDnxPlO/3Dt0TSprr8jlQsKiyVoKz1OJjnaDBEFdOmZmWFe6y12eofjR+zE5IUHcu1zy+TclzPWycg7rivGUumPj9gIpi8C8iEopn54JWRNCxaB8h26itECYESBVAnCIs5T8ube9ySl9sfY/+RFEDNLvWVqpsuFVMCmo9pbrlPayPNXzcJusmm9Y5DIqJFBj5Q5LRDiwbjCMoPjwWA8dDzPSlE5c5FV9wH+GdNBwEWaISj+QilOty2NWxdu/8Wf9SkDn7lc4uZ1pWvp4XHA+KSJu9yWhSYNI2sNB+VA6dRaWiiTXFlrRoUTeMIiNOi6LlAjnHXTe/Ji0weBitNUkPsYYiq1kGkmDS48GyKtqOuuNE1922pnIhAesy97Nqn463zpaxEpuXJJULfEc9Fi1nrpuRE0x1Z+URFz1H3R9leKy6/NHdqEf5RWbPRTarWdCkIwi8jDTY48x4914ASELxfSl4jJc1qFswx9eUgZmZL8U3lkqOkuWn56a/x3qw0STlYNKS634of7S5LsIRDnahCU19oBrSRmDWyzdq+kvUB+iRfbc6U33nN02QtSiKooPx0ORhXdjTgvyfVREvnBkGS+TDP5xU3cef403InSef6o9y2ZurzV5iohZ1zWpRERlaC4sx9uSSlaTFW051GRCnRfRaTI6dBce2j2+5x7irlPKwFSQF89J48z0V/IUv6oWIamDUiL36e9PYu03ekbJ2brV3S6hMaQQWfcACCCYoaUbm208AdCSlTHrgBU1OtvnnwRPwZlPBH0XRVYwKJ+KRh55wWFSMmK0Fx5j7aGfugt8bqR+KOpxAUrUMrG9OuOHID6uRFy/j595sm5ZD7zR8OtDOo+7vyoum0fb3s0Nuua1G1/GPSuQ180176p+PbWJ8vhiZkKZkAAdSWZ+HzTNIdWflERc8jyQkHamKldXHfo+ImqAO2wUtM3ktEJ/pt8usNAhmY56H5o/xtqnXROn1C8wciGz6JUNIB6mRCtSELQXFkKPmjOHHWCIHTXugxaV+qO5bGbUtalNXcR7Upl28/haBz4LSppqPIZUUtUGJcv8bxeBAQlYPmf6qH9bf32YZYHqlDC8NN5Lb5C1vO6hQIKjivt+zLbCVoQZsCbMRBr4kuYWWN8Itp/LGAi5yJwf65XT0p5dy+xR/lb9NBB33eMxkYzU19IoGkmP4s2xI5+Zet3SZ3TNKQQNJjGhRn3pPSJM2MnoszO8bMfdz1+/fG2JWsNElNBHMjeNlKRvC1SWolNDE2D0NQ/jFHVLFwczlMnZsfNZzltfioUoMt+KAI/hx1s5BAeoSg6GKX/vd0NKJy7eMDbuh94p8NJRurj8rl5eqWzIcxGdJM5DHkDGBi/iigrl1Rv1TtmY9I2LmkRXHmvRyC4kx+QL1jzoFETPS4tO/aoUX00f2YuY8ejz12qkm5/f2kSdlePjlP6blQTYhtNHsFB2o93HelNILy83AaVZAn4pdqI1jCCs2MR/M5UC2KW+yyVn6aHltIU1sOSTLT8cdk87Kfpvm0fKTOBQwjZOm8qVEtv3TumD9K0pL8ekPtaRRs17Wn8DnPtChADm6gWhb9lYhMIihOO6AdswUxc1osD0c8FpNf7FxWcx9XntumzyWCtSApgPc76eYOqkXk+ZlKhadLpFSfAyXMszIQVP2ciwmScJA6Jy6Pn89e//zaUggqqMMjK0dUkjYF2AcoFm2prQi/uSnc9n7IdfLPg1uvT/JHSYRHQ8/tpr5poqblWLSoHSGNK8+RE2fyg5cvvOg5NJNbzDRnCaLg6uDqocTktwHeMQuke7PfovsA3SRCR7s566I1Mf/55bT19/iy/GNS50SR1R4H3mqPVJvKWXjWN/GVRorZyB9hc52htLIEJSi6GCaA2oKZk3IhUU3aIAccxPxCAPX91ScGN43ws5jArWZy6ZmnPDN+QeBRbds367lyXFQfPTe72jnVrmJmPghpGlmB+fWbJnXqMY2IQjPNSYSlmfdoPTlaHAdOk/Lv436YzDsRTv4Scr/3w+VfhnlTfptq2hXRoihBubQB1xOTc3QdwWcFZ3ISo/fo6JxoUdKnAyiG4zlRDUahn2qeJ5zky5ndQjMfPzjSgiekCL88zb+Mn5Wa6ibb+tDaN9/5+fm66pqSAzeBOzD1cT4Q+i8do+Y8P+1FchxMfpcG8J20BIlsJI0GsBGPxQQokU/snE00qTFCAlew0iQF1EejpSOa2kbpdQE5gvKPOaJy2tSiTX4a5FG7xRQ1IvOi0giK5hkN5kQlaVNAXCuWogBjwROSeVAbQFlMkJyZXIJFc5ZMe5IviTP5cpN15+V0Ux8bMGH95YhJ8kdR7Ukz+VnHfb4pzUfM3EeJhyMijZwkUqIkCe84EGcPSZNy2/spcAKwaEj2OSCxka3lfBJKfVtq9nVeT4vSCMrSLukTHQ7ccb/TbUsLi0X6qWWFVSXUb91M4X/gzWlVlKgmx/glkzRwn+mIBU9IPiqHel3p4ekSUXHLE0n7Lo2Gmkt1xtflq5tyfVNfzaTLaTcgaZxGZSEvLt0/J7w8/nkpLB29ZPazmPvouXKCJ0poUtx9cPdtv5GUD/cCNglHLxHxFyOxnLaJX+c1EhSnTdXyzLTSUArbICJprTZOW+I7QxoPyeQhWlTwdVDlRXPH6NdIfdMfneQbuz+xwY5l3xLhx/tcbQM1/73RSCbF1OfySMQ0YJ77/Jnypr7g/L6pj9N0fOIBZEKSiIkLpJDOA5LmwN1KP412/lzQhEYY1nlQNI3WHTMzWgiW06IooRsNOGtFUnLgRPwzClbCyPFRpZDdOHg1B2pZdU6UFjhB/FPLbPLT/E7ysZEYMGElKB8bowlR+T4qoK5NYRB/1pxZMEZEFs0+Bn7ZMDnKLydAwk5oet2UmPy0uhZHTH20A5RIRyMkn5Q0ApPOBZLm72vgtBk/nRKFRlYSEUFI4+rmCBKok5V2PQ7+fXDp+yG6bxMjTCbz1i8j1Te1DN+NErUkkl6LDiSElBs44c6ldUT0eG6wRVuRgT7C1SXCYzWC4l447zZTotK0KVPbGhJRSoSfxTSdar7mgh3cvm/q4/xRdFtaUNiV5dZi9E19wdwoOoLXtCiJhKhGRgMmuDyaNkW3NUhEZMkTIyKXh5ZP1aTc9UniQl9t6d7sh+g+B23pI7o2GSCb4SzO6lKoE49+Hms7zIET023f5Gf9REdb4HwTDtrK6Gqd3rwo15FtWDsPMnLkNCo6yTc2CdoH9UtpwRO8DytvaaNS6/P5dVoQWwpJCj330wbBPzkv1Wg435GkRUkEFdOg6LZ/DtouoN6BhxcZ5vfJgdNqfEKhJEIJLpYnRZPy2yZB0qLc7xj7zydVao0+2WTY7jelLAg+yzE19fmk1CRwIgVdhapzfgquQ6xNHiWmPl+LMhOUD2FES7UpAGoAxTzazq4hWXxUUp3aoIwz9cWsD3Q7CAGPyEOT0HPJ1AdANvVZtCSpjJ++w6T7mhWYeuD9+k22mseoZkRJQ9OkpH1LnpgmRdsWA33XKInvN5LiYH0Bu4J0/hLtygmcCNuwOL+UlfBYf4Q0up8uNOpQu+Sc0e3Qpk3FQMkjNXhCq9MHF52Z+t01l2YB1XDYAAdCTFrouRQow5r6NO3HIUZcEmFZtC2/fpB0kG14ebjHwZEQJQ0pH1eHv6+RFfVP+eeGd35AZ46YFsURuIKVJqnJiJmaR+qXVHLR2UXDYqoZMYQ1ZAInND8VN1qnx2nHaNGwrB1efGRu7Dg5LcpKUO64QFSufn+Srwug4Kuqd/5+MMPkFIPaMQqLRsaVsfpotXurReP5oM/PDyGPhZ5LC8pSU59JiwLqhKIRkEZG1DfFmRMpabk0kDRpn/P7cKQhaT/aPph9WhcllaH366fF3htucOCfD9g/Pqn6jP/6V1Mp6EvIdR6L1sD8wGoKaurztSiOoFz6UCIkEorOBUcAdt9DSfCjaT5NiuobSp0EdzvoCNTlY6KgqDYFQA2goEQE6AES/jGOtJqtN6m/I3w5Xn5STH1SndrE3UZypxEQUCcaTVvSCIoz/wGBvFWWy5jm2bBoUoJc1rQk/zhHVq69EiFSDcr6OChJU7LaD9F9Dtpkyvoosa5tdU1E/rm4AIrUoAorNKKa5UF68ATVqqzr+lkJSEvnjjlTn+iLmjRyDm10K0ROadpUDLEACeuxyfEykXuxPLzJbhSkSZF+4T6vPc23Bd+TG4Q4zcpq6kvVokbgw8+5NEkLA2Yy5IiJzim/zHT0B0igw9AjoA3JF+UTDEiemCalaWQlIvuoNkXJar9oUg7hitTSN3F07Sq2sGesTJuwTOKVtCipHDX5xT/Rkb+obBtmQC4KrJafe2k0gqLgRq7TtI3R9B0m2tS0cTXoyx7JX37WjrnjtH7AjwgcBmkjzD/YaLEaaM9GCw+X6vDNfty2y9PY1BfTiLigCIms/DwvMvkx36fE5AhpFJE1//hwOC93YEocw6nsbUhkQvclsuJMfLScXye8a4R3XLwQb5vTotw595Mm5cAt9umPQi0rQUvk5i9WW2pOVX01dL3O4NtRhJCsBCVpU5bvTJVCfCHScLTNrUKRYgLa4F4awKZBuXQp4sq1x6BNceQzqb5OEik+JL9+H5oZW26jbTBBtSgNWug53eZWmYgiR4ui5j6tPLfaBLPtkxMlJk5zotqVbym+PJprVqPRnLRmhKVpVxb/k9unGphvtizlj3K/lLD2Q3TfJOw3fgnLENkXg1Ujs343ajwiZqFh/S2xTvD14S+NVOJzHbnzn3z4/ijO1AdAJySuP6QvKiElB6pNWdo6qY73S9FgCo7A6DHreaUBm/X9oGRUn3gbDi4o2cRCz7VVJlRTnw+rFsVpStoqE5IG5REUJafZtnfbLtOb6uHyNN8Bdymeyc8RVEBYknYlaU2+5qRpUpxmBoRkFYOvXfr7/vn3i7nPzU9xDmunTeVOWoz5AFIx/4Ku+y13y502NQrmSvH1j0fDGVFRbSqHrLpCbA0/1RQ1FrSoEfnVQF9QyYkNTIlRNvn5RGD1PWnBE9wEXw6y+ds+t5D6jST4IeVceS303O03NvVZtKjY/ovkV9CgqhcRmPUoOfmkRAmK3sUhyXcAIXE50qKEVdOugJCI6L4mx/Qd8bUp+qr54kKP0XdsTNL2o7lPWpqGe/n8l6wtn1Laen2Cv0lKz5y06xOVhtjq510g1skBCe2KaU0Ab8Lwb4P0gsOuTQ0YYpqcmjP3jdjt1OCJFK3J4pPitR1loOAdTwk9j0EMmPChaVEWoqKjfqKF+dqTRE7u179rkjblk5NfZjg95kjLJyxgTlYA6qZASWuCl64FS1BtyjWIXhS3T817Ls3XXA1YG5LyIUX7cSNP62i0NGLkOPsUx8zgwT8qixYllRsyc6Usk3ot86HaBhsB5pn6aoqhNNLjjtF0+lL7I0+iTU3asSeGolu/O6VBC56giJEX1bIG3vuQGzDhaz3+ca69sdBzydQ3g6QljVEnHo6MNJMfV256nCMoSk4jbxsAuQPhsQNeGlViHEE5UfMJy9euRsO6KXDDVUhJiNOiOMLyGwLvuARuQEi1qP2qSQF1bSp3qaRF+rDcqxnNV1tU1vYoNW1KCp5o81tRQNx8R0fi9eP8/KgNfwQHhC8KEHcAO3CjT5LutCkA0+9NjV3jvNPzPiXJ90S3J6eMB1ZI0AIuOO2MywfIJj3tvO7X15jC7VFwnJYRTX2AbNaLaVHS747+6xPUJd/chzk5UWLytSfu7aNpjoyAOUG59Bph+drViJgCncY1EvxWgExYQJ2U9PErn9e/7/6+5qDzsNIkNRhVGIyq6JI01qgmLY8zs/Dmw25IzRo0AdRJLPrp+IhfShpZ5xKYpYyUJyWyDIDtJZPSuUgolz8SVFGvqr74se97mpxmIBIY3fcDWGLgBmwpK7FI2nWqqY8rJ9XBDUrYuVEOlGwcJC2KS+NIzft3BHXpxVB74shJIyqQY5PrnYMSlK9VcYQV067YqEBKTpoWJZn4tAuSNKnpfrUfSMrBXzvNaVM5X0tl60a7C8tqE3vZ/My8KF+LkvxV4QroE23KMrmXtrWtVSdoGLKtDNeJCZlp+lhI58pJI05X1rvl89s5N0mNB7w5bbLPy5cUPMEhJqO2NftG03bxARZ+Xf51uONWU59v3vO36VfUJFPfDJLmxJGPpkWNMPE30cg+F8nnaVEWgooRFSArEDSdalB+mtOipG2qXXGmQFa78k/ma1HW117SpLz6Z/dxP5EUEBJVkA57lJ8W8rtMKL3aeU50H9WsLOHoOQEYkrO9NjL3FpSdRfXRF8sf2UE5Pj95mK5E9mE0sf/Tr/j6bZcn6ErbcvAEV58E7rySNmWJ3LOck8sjb9cXlPXJkDX1TS6srjnFyEnTmqTJvWOZoC5BJieqQdE7K/XRWuDESNjntmva1bRCR1jAlLCm6UFkIG2wlSn8Mgwx+T68543dwdqQlA8t0s/HooIluPMWmRwcIS9Om1okJGc63Y5B+govgLrph3sBY9oXfTS+6Y/RpiTETHcWv5REdBaUWoCZ06K4Ornnqa0yQdNqEZ7U1AfUCUUiJEmLko45bWo8DzP3CeqnqGtPHDlRoqLbHGgwhU9Ik3s0v/SYRqVpV2wYu69h0cGZBd675IgJ4ANMfmqscqVJipp2qDYVLpUkf4Kg6ae5Y0gNMfePzxaaJf4oaurL/VRHbc7UeBB0uIuO4vPbwHVeZvOjREqW4u5NZ7QnTpuaJ000O9/sTJcqssyJ0jR8SnwShkwdfl0aUdF5TP6vny6Z+lJWmYiZ+thPxMcIyUJKPjF5K0zkEBTVrFJMfg4+Kfn5D6CuRSFhm2pXwNwcCIQalkPKWFZaCoozjxrn8q42SQEQl6NJ+aR33ObPz7VqSxMTVz9PMPPtkbyblk/HM2Y/6ocqscqED40E48sn0ZE2MfXRqum+hazo2+5+E7Qp9/mOkFx4U14bk3rrJkRe1jmi0p51yvOh0XrzbfmbYEGeqalvBo6EfC05R4ti/p2JiiOoS962RE5Uk6J3jPND0XzUvAdv32L2o9u1OghhAXPSAubEZQFdBooLy3e/l4x1rjxJASFRcb6p/NUnullANvcckhZFCcqlbc5MfW5x2bnJb1lWnYh9n4idCEo+cBjAH3HD27ZqU9ywVBqqRkA196Z+KUvYOMCTF6dNuXpj7ae+o5B46gvMcn5Ezr/FrTIxO05Nff4/vG1KWlbCYvxT1SgMM7cSVG4YOpfuh6KPSBpHWCNy3LLtt81pUDPSGswJxwI/HN/9jsi2+33eWOdakBQga1TWKL+2o/isiE7yjWhTHEE1RWntiYIzHUnHsuFXoxGUyxcLN6fak1ePxeTnE1KuXypVZiWTnnWKRvhb77nqz7Fu6vPNgSEhZZj6rH4ojpR2MDft+dvTfNUIuLRTJygaKOGTVWoYeqzv1+ZKufISYfnHY9u0zqCd43CisQZ6bVwgif+7b8x9PhxRpX7Ou1aP8PKXIDJXvonfS1rxPEZQvjZF67N8Z8pCGNJ8KocmpMOOyEnQxAbttHxo+5Jp0Cch7pG5fJHHSU1+A8GUF/vQIQXnV5XyUZOfFpRB62eviWg7fhnJ1Bfm0U19rq2Bqc89W387lbS4hWI98nJ+qNFobq6iBEXJyhpA4fZ9cNqTn48SlOaTqgVLKHlpOY4IufZJkAhZIqm1DpyoqgoA8NN/RPB1VGCuTY2HFYARxsMBRoMKe5juo8IYFUbYw2VsYowNjLExldldXMYWRgB2p3l3sYkxgF1szMrsYtIpXMYGdgCMMcYuKuwCGGMTu9jDLiqMMcAuxriMPYwxwGWMcBlj7GGA0ZTwJv+XMcYQuziAMXaxhyH2MJj+b2IPQ1TjAaqR+58QcDUezjSryqhB7QHYGI4xAjAYjlFN3/5quIdqOEY1HGNvMJ5e7d707oyn924XwB52MMLW9Aq3pld9ALvTK3d3awfA5emoeRcVLqPCDvawi+1p2cm1XsYYl7GFHYwxxmj6t4XL0yNjbGEHl7GHrend2EWFASocwGXsjCcTurdenPqj6KjZjaSBeUcE71ewEtbgxjx0cuMQEyIbeGnT7WoA7GxPZHE8rKZyOMIuNjHC3uxZT2RrB7vYxh4w3d4K5G+MPexgC3uoMJ7K0w4OYIw97E0pZoTBtNxgSjg7U11l00uD009ml6YNvHwKmZzFkRymtDb5n7xho+nbNU/fxi7GGGMbO9jD3lRe6s+6mr41e7iMvdmbMsJlVLjqhT2MdoANp/X8FBOi2QXwAuba0E+97Remx1/00l/00ly+Xe93+j8z8Y0mZPQi5lrTGHOCGmOuYbl/n5D8NCDs7K0d/5DZPkD26e8Bkuanu7IDph7/GEiaBe46x96+T1hjhIT+3PSY688lrCRJXbx4EQDwylu0XO7Cff2+B1C/M0B/d9rFZIA0l8MXFtucHj2WCBcvXsThw4fF4xtVjMaWEHt7e3jqqafwqle9Cs888wwOHTq06CYtLS5cuIAbbrihv08R9Pcpjv4e2dDfJxuqqsLFixdx7NgxbG7K7pmV1KQ2NzfxMz/zMwCAQ4cO9YJgQH+fbOjvUxz9PbKhv09xaBqUQ350QY8ePXr06NEyepLq0aNHjx5Li5Ulqe3tbfzBH/wBtre3F92UpUZ/n2zo71Mc/T2yob9PZbGSgRM9evTo0WN/YGU1qR49evTosf7oSapHjx49eiwtepLq0aNHjx5Li56kevTo0aPH0mIlSepP//RPceONN+KKK67A8ePH8bd/+7eLblKn+Na3voVf//Vfx7Fjx7CxsYG//Mu/DI5XVYVPfOITOHbsGK688krcfvvt+MEPfhDk2dnZwb333ovrr78eV199Nd7ylrfgJz/5SYdX0S5OnjyJX/qlX8LBgwfxspe9DG9961vx1FNPBXn6+wR89rOfxS233DKbeHrrrbfir/7qr2bH+3vE4+TJk9jY2MCJEydmaf29agnViuHUqVPVgQMHqj//8z+vfvjDH1Yf+MAHqquvvrr60Y9+tOimdYavfe1r1cc//vHqy1/+cgWgeuihh4Ljn/zkJ6uDBw9WX/7yl6snnniievvb3169/OUvry5cuDDL8973vrf6mZ/5mer06dPVd7/73epXf/VXq9e85jXVaDTq+GrawRve8Ibq85//fPXkk09Wjz/+ePWmN72peuUrX1k9//zzszz9faqqr371q9V//a//tXrqqaeqp556qvrYxz5WHThwoHryySerqurvEYf/9t/+W/VP/sk/qW655ZbqAx/4wCy9v1ftYOVI6l/8i39Rvfe97w3S/uk//afVRz/60QW1aLGgJLW3t1cdPXq0+uQnPzlLe/HFF6vDhw9X/+E//IeqqqrqH//xH6sDBw5Up06dmuX5n//zf1abm5vV17/+9c7a3iXOnTtXAajOnDlTVVV/nzRcc8011X/8j/+xv0cMLl68WN10003V6dOnq9tuu21GUv29ag8rZe7b3d3FY489hrvvvjtIv/vuu/HII48sqFXLhaeffhpnz54N7tH29jZuu+222T167LHHcPny5SDPsWPHcPPNN6/tfTx//jwA4NprrwXQ3ycO4/EYp06dwgsvvIBbb721v0cM3ve+9+FNb3oT7rzzziC9v1ftYaUWmP2Hf/gHjMdjHDlyJEg/cuQIzp49u6BWLRfcfeDu0Y9+9KNZnq2tLVxzzTW1POt4H6uqwgc/+EH88i//Mm6++WYA/X3y8cQTT+DWW2/Fiy++iJe85CV46KGH8KpXvWrWcfb3aIJTp07hu9/9Lh599NHasV6e2sNKkZTDxsZGsF9VVS1tvyPnHq3rfXz/+9+P73//+/j2t79dO9bfJ+AXfuEX8Pjjj+Mf//Ef8eUvfxnvete7cObMmdnx/h4BzzzzDD7wgQ/g4YcfxhVXXCHm6+9VeayUue/666/HYDCojTrOnTtXG8HsVxw9ehQA1Ht09OhR7O7u4rnnnhPzrAvuvfdefPWrX8U3v/lNvOIVr5il9/dpjq2tLfz8z/88Xvva1+LkyZN4zWtegz/5kz/p75GHxx57DOfOncPx48cxHA4xHA5x5swZ/Lt/9+8wHA5n19rfq/JYKZLa2trC8ePHcfr06SD99OnTeP3rX7+gVi0XbrzxRhw9ejS4R7u7uzhz5szsHh0/fhwHDhwI8jz77LN48skn1+Y+VlWF97///fjKV76Cv/7rv8aNN94YHO/vk4yqqrCzs9PfIw933HEHnnjiCTz++OOz/9e+9rV45zvficcffxw/93M/19+rtrCYeI18uBD0z33uc9UPf/jD6sSJE9XVV19d/Y//8T8W3bTOcPHixep73/te9b3vfa8CUH3605+uvve9783C8D/5yU9Whw8frr7yla9UTzzxRPVbv/VbbCjsK17xiuob3/hG9d3vfrf6tV/7tbUKhf293/u96vDhw9Xf/M3fVM8+++zs/6c//eksT3+fquq+++6rvvWtb1VPP/109f3vf7/62Mc+Vm1ublYPP/xwVVX9PdLgR/dVVX+v2sLKkVRVVdW///f/vvrZn/3Zamtrq/rFX/zFWVjxfsE3v/nNCkDt/13veldVVZNw2D/4gz+ojh49Wm1vb1e/8iu/Uj3xxBNBHZcuXare//73V9dee2115ZVXVm9+85urH//4xwu4mnbA3R8A1ec///lZnv4+VdXv/u7vzt6ll770pdUdd9wxI6iq6u+RBkpS/b1qB/2nOnr06NGjx9JipXxSPXr06NFjf6EnqR49evTosbToSapHjx49eiwtepLq0aNHjx5Li56kevTo0aPH0qInqR49evTosbToSapHjx49eiwtepLq0aNHjx5Li56kevTo0aPH0qInqR49evTosbToSapHjx49eiwtepLq0aNHjx5Li/8fXudxaGC+3f4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.055814800486461535\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
