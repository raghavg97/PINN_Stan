{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"low\"\n",
    "label = \"KG_tanh_\" + level\n",
    "\n",
    "x = np.linspace(0,1,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "                    \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_tanh_low\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 10608.808 Test MSE 6.411948162343963 Test RE 5.925934752248805\n",
      "1 Train Loss 4616.673 Test MSE 11.189081752208418 Test RE 7.828149075162741\n",
      "2 Train Loss 1301.9827 Test MSE 13.860905741855174 Test RE 8.712798477480106\n",
      "3 Train Loss 270.38254 Test MSE 15.121691040203196 Test RE 9.100432741846312\n",
      "4 Train Loss 133.37105 Test MSE 15.311935770930244 Test RE 9.157499705921357\n",
      "5 Train Loss 72.59289 Test MSE 16.010124538223895 Test RE 9.3639528692328\n",
      "6 Train Loss 50.17224 Test MSE 16.07357568904269 Test RE 9.382490078679613\n",
      "7 Train Loss 38.910038 Test MSE 16.16212215336253 Test RE 9.408297817924032\n",
      "8 Train Loss 33.97141 Test MSE 16.010827018632508 Test RE 9.36415829928013\n",
      "9 Train Loss 30.708004 Test MSE 16.007867744716577 Test RE 9.363292872717725\n",
      "10 Train Loss 28.11918 Test MSE 15.920502052684501 Test RE 9.337707024358778\n",
      "11 Train Loss 26.544697 Test MSE 15.813090427411195 Test RE 9.306154133437566\n",
      "12 Train Loss 25.483524 Test MSE 15.659872110889996 Test RE 9.260959171326274\n",
      "13 Train Loss 24.20605 Test MSE 15.426606595705291 Test RE 9.191725924794518\n",
      "14 Train Loss 23.351974 Test MSE 15.275038735337596 Test RE 9.14645967830376\n",
      "15 Train Loss 22.384367 Test MSE 14.989494863145572 Test RE 9.06056672200435\n",
      "16 Train Loss 21.779037 Test MSE 14.932474087540133 Test RE 9.043316880869124\n",
      "17 Train Loss 20.869904 Test MSE 14.723069400059034 Test RE 8.979683788618912\n",
      "18 Train Loss 20.072105 Test MSE 14.454406397397033 Test RE 8.897377034582696\n",
      "19 Train Loss 19.205362 Test MSE 14.16750424381331 Test RE 8.808633480345826\n",
      "20 Train Loss 18.398378 Test MSE 13.612786821944326 Test RE 8.634464052648148\n",
      "21 Train Loss 17.519 Test MSE 13.2770014537981 Test RE 8.527306346474619\n",
      "22 Train Loss 16.484068 Test MSE 12.842932443559466 Test RE 8.386755131430524\n",
      "23 Train Loss 15.64809 Test MSE 12.616358177180611 Test RE 8.312446613572195\n",
      "24 Train Loss 14.914441 Test MSE 12.355875383621168 Test RE 8.22618787162696\n",
      "25 Train Loss 14.110828 Test MSE 11.838391059676734 Test RE 8.052082298053918\n",
      "26 Train Loss 13.37535 Test MSE 11.326712808929383 Test RE 7.876146915893472\n",
      "27 Train Loss 12.587439 Test MSE 10.862935251899499 Test RE 7.713215397041065\n",
      "28 Train Loss 11.940542 Test MSE 10.451490269831206 Test RE 7.565732366850639\n",
      "29 Train Loss 11.247636 Test MSE 10.019645715974361 Test RE 7.407779503265802\n",
      "30 Train Loss 10.273572 Test MSE 9.403071079851694 Test RE 7.176236180860288\n",
      "31 Train Loss 9.464301 Test MSE 8.916498651308423 Test RE 6.98809882572969\n",
      "32 Train Loss 8.265463 Test MSE 8.102638952939845 Test RE 6.661547175386733\n",
      "33 Train Loss 7.4355893 Test MSE 7.437326660480932 Test RE 6.382198278531799\n",
      "34 Train Loss 6.727444 Test MSE 6.928980889956172 Test RE 6.160224587443813\n",
      "35 Train Loss 5.8823028 Test MSE 6.2263276944509895 Test RE 5.839529423815615\n",
      "36 Train Loss 5.3442254 Test MSE 5.874679543513306 Test RE 5.672231596456823\n",
      "37 Train Loss 4.682271 Test MSE 5.199798625880349 Test RE 5.336482953653278\n",
      "38 Train Loss 4.1032643 Test MSE 4.471491990244957 Test RE 4.948665425934852\n",
      "39 Train Loss 3.1323495 Test MSE 3.5957856437990996 Test RE 4.437708395903868\n",
      "40 Train Loss 2.3914537 Test MSE 2.8256782538736376 Test RE 3.93389911940249\n",
      "41 Train Loss 1.9288552 Test MSE 2.657218180147058 Test RE 3.814832479889996\n",
      "42 Train Loss 1.6153152 Test MSE 2.4722181506771284 Test RE 3.679639390728653\n",
      "43 Train Loss 1.3591943 Test MSE 2.1107827015325418 Test RE 3.400036875162501\n",
      "44 Train Loss 1.1815857 Test MSE 1.7988920692881631 Test RE 3.1388055916056716\n",
      "45 Train Loss 0.95446587 Test MSE 1.4983087050677384 Test RE 2.8645902895773774\n",
      "46 Train Loss 0.7945796 Test MSE 1.2352932932139988 Test RE 2.601039249954788\n",
      "47 Train Loss 0.6993915 Test MSE 1.131172353560544 Test RE 2.489007785940644\n",
      "48 Train Loss 0.5867045 Test MSE 0.909553333118028 Test RE 2.231906252792749\n",
      "49 Train Loss 0.4841251 Test MSE 0.705479760265391 Test RE 1.9656407336039965\n",
      "50 Train Loss 0.3992346 Test MSE 0.46267022332389723 Test RE 1.5918334958108475\n",
      "51 Train Loss 0.3194368 Test MSE 0.37303922159368413 Test RE 1.429351731658906\n",
      "52 Train Loss 0.27267528 Test MSE 0.3136434882080276 Test RE 1.310629689271217\n",
      "53 Train Loss 0.2310949 Test MSE 0.2438071887913801 Test RE 1.155540356366676\n",
      "54 Train Loss 0.20332372 Test MSE 0.20619527475156446 Test RE 1.0626768465674832\n",
      "55 Train Loss 0.18467228 Test MSE 0.19806447669448302 Test RE 1.041514113586106\n",
      "56 Train Loss 0.16383387 Test MSE 0.18001577630244503 Test RE 0.9929266056971389\n",
      "57 Train Loss 0.14377126 Test MSE 0.16710575793332974 Test RE 0.9566599025451181\n",
      "58 Train Loss 0.13056853 Test MSE 0.15676468034480087 Test RE 0.9265865133232791\n",
      "59 Train Loss 0.11395746 Test MSE 0.12776931707176276 Test RE 0.8365177309922831\n",
      "60 Train Loss 0.10384754 Test MSE 0.10298572796045345 Test RE 0.7510180684112381\n",
      "61 Train Loss 0.097112566 Test MSE 0.08465137709421945 Test RE 0.6808930132008829\n",
      "62 Train Loss 0.0848223 Test MSE 0.059295535083667326 Test RE 0.5698661494787771\n",
      "63 Train Loss 0.07498861 Test MSE 0.05534623979322643 Test RE 0.5505616086699906\n",
      "64 Train Loss 0.067105494 Test MSE 0.03847241634202388 Test RE 0.45902527136027776\n",
      "65 Train Loss 0.060390502 Test MSE 0.03401022544649475 Test RE 0.43158527560050325\n",
      "66 Train Loss 0.05043278 Test MSE 0.030478583233880696 Test RE 0.4085632050258225\n",
      "67 Train Loss 0.044165246 Test MSE 0.021871877884263508 Test RE 0.3461026306412828\n",
      "68 Train Loss 0.03956348 Test MSE 0.014597081813032734 Test RE 0.28274496836826857\n",
      "69 Train Loss 0.03589668 Test MSE 0.013526112141937649 Test RE 0.27217507791148793\n",
      "70 Train Loss 0.0332547 Test MSE 0.01066591097947585 Test RE 0.24169120187076143\n",
      "71 Train Loss 0.030019233 Test MSE 0.009440289199587202 Test RE 0.22738117873180555\n",
      "72 Train Loss 0.028520202 Test MSE 0.009620258642096986 Test RE 0.22953834086420863\n",
      "73 Train Loss 0.026746498 Test MSE 0.00786935153529103 Test RE 0.20760190634704193\n",
      "74 Train Loss 0.025584979 Test MSE 0.007631044877595235 Test RE 0.20443434910424996\n",
      "75 Train Loss 0.022931749 Test MSE 0.007730866295314077 Test RE 0.2057671039410188\n",
      "76 Train Loss 0.021804951 Test MSE 0.007996941164805272 Test RE 0.2092781147839442\n",
      "77 Train Loss 0.020688904 Test MSE 0.006116090178630688 Test RE 0.18302010668007487\n",
      "78 Train Loss 0.019026354 Test MSE 0.004977368861474197 Test RE 0.1651055899329822\n",
      "79 Train Loss 0.01833679 Test MSE 0.005062304696800907 Test RE 0.16650834523253913\n",
      "80 Train Loss 0.016413309 Test MSE 0.004594678567767186 Test RE 0.15863150017068267\n",
      "81 Train Loss 0.0153802885 Test MSE 0.003881795148262137 Test RE 0.14580693154415852\n",
      "82 Train Loss 0.014965104 Test MSE 0.003954912931668696 Test RE 0.14717374037014597\n",
      "83 Train Loss 0.013191021 Test MSE 0.003753910654293819 Test RE 0.14338503609446862\n",
      "84 Train Loss 0.012312337 Test MSE 0.0038492936081236046 Test RE 0.14519524146438462\n",
      "85 Train Loss 0.011961124 Test MSE 0.004196693838749772 Test RE 0.15160569221057232\n",
      "86 Train Loss 0.0110840425 Test MSE 0.004918314219561775 Test RE 0.1641232089405276\n",
      "87 Train Loss 0.010272284 Test MSE 0.004271985748510335 Test RE 0.15295960789571897\n",
      "88 Train Loss 0.0099445665 Test MSE 0.0036432558942382526 Test RE 0.14125593434173347\n",
      "89 Train Loss 0.009018685 Test MSE 0.002957853682897142 Test RE 0.12727708126211623\n",
      "90 Train Loss 0.008596088 Test MSE 0.002618157128739385 Test RE 0.11974564224538264\n",
      "91 Train Loss 0.008315226 Test MSE 0.002587075239602774 Test RE 0.11903272987915554\n",
      "92 Train Loss 0.007587196 Test MSE 0.00217775891167071 Test RE 0.1092110955739355\n",
      "93 Train Loss 0.0071314536 Test MSE 0.0019638044713493298 Test RE 0.10370769608290063\n",
      "94 Train Loss 0.006876259 Test MSE 0.0015364680988068388 Test RE 0.09173258623382324\n",
      "95 Train Loss 0.0064057424 Test MSE 0.0013826652503718996 Test RE 0.08702026231679061\n",
      "96 Train Loss 0.00587732 Test MSE 0.0013285348971049623 Test RE 0.08529986569574591\n",
      "97 Train Loss 0.0057649827 Test MSE 0.001531046873537458 Test RE 0.09157061005691916\n",
      "98 Train Loss 0.0052148323 Test MSE 0.001253489425269283 Test RE 0.08285566385089789\n",
      "99 Train Loss 0.0049140663 Test MSE 0.0010947153063707972 Test RE 0.07743057052835355\n",
      "100 Train Loss 0.0048047225 Test MSE 0.0010548357462438203 Test RE 0.07600712113664487\n",
      "101 Train Loss 0.0046481555 Test MSE 0.0007213405351843752 Test RE 0.06285387143912104\n",
      "102 Train Loss 0.004470903 Test MSE 0.0005527361794238096 Test RE 0.0550200283966483\n",
      "103 Train Loss 0.0042499225 Test MSE 0.0004726145087517668 Test RE 0.0508762847044242\n",
      "104 Train Loss 0.0040479875 Test MSE 0.00046809689359772174 Test RE 0.05063254339176172\n",
      "105 Train Loss 0.0038758558 Test MSE 0.00040864296454148506 Test RE 0.047307922552013805\n",
      "106 Train Loss 0.0037817808 Test MSE 0.0002824050632878865 Test RE 0.039327659721502796\n",
      "107 Train Loss 0.0035076023 Test MSE 0.00013827593636726813 Test RE 0.02751915967042929\n",
      "108 Train Loss 0.0032278132 Test MSE 0.00012786488519959258 Test RE 0.026462904564430657\n",
      "109 Train Loss 0.0030811545 Test MSE 0.00011011531986364562 Test RE 0.02455758954919531\n",
      "110 Train Loss 0.0030077763 Test MSE 0.00012479569781992172 Test RE 0.026143376113442002\n",
      "111 Train Loss 0.0029405567 Test MSE 0.00011990695190786763 Test RE 0.025626190224583907\n",
      "112 Train Loss 0.002845183 Test MSE 0.00011551260120057109 Test RE 0.02515223290762087\n",
      "113 Train Loss 0.0027550175 Test MSE 0.00014406710227015662 Test RE 0.02808951719173625\n",
      "114 Train Loss 0.0027001204 Test MSE 0.00013926661993706547 Test RE 0.0276175647974523\n",
      "115 Train Loss 0.0026647898 Test MSE 0.00016616981174300452 Test RE 0.030167403207198476\n",
      "116 Train Loss 0.0026358124 Test MSE 0.00017816446846756555 Test RE 0.03123722259066845\n",
      "117 Train Loss 0.0025433172 Test MSE 0.00017279870629936293 Test RE 0.030763242389842932\n",
      "118 Train Loss 0.0024855784 Test MSE 0.0001597879497204895 Test RE 0.029582432086490928\n",
      "119 Train Loss 0.0024428915 Test MSE 0.00016210419661218003 Test RE 0.029796070496116038\n",
      "120 Train Loss 0.0023963836 Test MSE 0.00013579313462913373 Test RE 0.027270981631578834\n",
      "121 Train Loss 0.0023432323 Test MSE 0.00012441946500122501 Test RE 0.026103937972468662\n",
      "122 Train Loss 0.0022697079 Test MSE 0.00012094277873900226 Test RE 0.025736639264281727\n",
      "123 Train Loss 0.0021947774 Test MSE 0.00010985611943526439 Test RE 0.024528669467974988\n",
      "124 Train Loss 0.0021068691 Test MSE 0.0001018145978307236 Test RE 0.023613854834869687\n",
      "125 Train Loss 0.0020789502 Test MSE 0.0001180228275037635 Test RE 0.025424058051835344\n",
      "126 Train Loss 0.0020533614 Test MSE 0.00012445075901323924 Test RE 0.0261072206002651\n",
      "127 Train Loss 0.0019794265 Test MSE 0.00012726925439928167 Test RE 0.026401196770367653\n",
      "128 Train Loss 0.0019028608 Test MSE 0.00012786545440873176 Test RE 0.02646296346609995\n",
      "129 Train Loss 0.0018424612 Test MSE 0.00013901615567767634 Test RE 0.027592719196316833\n",
      "130 Train Loss 0.0018240962 Test MSE 0.00014285109327609946 Test RE 0.027970720161764034\n",
      "131 Train Loss 0.0018057904 Test MSE 0.00015518149838858515 Test RE 0.029152904807223427\n",
      "132 Train Loss 0.0017860299 Test MSE 0.00018016007630660452 Test RE 0.03141167841464557\n",
      "133 Train Loss 0.0017597135 Test MSE 0.00018023786136874657 Test RE 0.031418458761687924\n",
      "134 Train Loss 0.0017188698 Test MSE 0.00014561562933884653 Test RE 0.0282400759122325\n",
      "135 Train Loss 0.001696522 Test MSE 0.00010918125686896974 Test RE 0.024453211760540522\n",
      "136 Train Loss 0.0016833114 Test MSE 0.0001006211849570495 Test RE 0.02347505280076311\n",
      "137 Train Loss 0.0016687904 Test MSE 0.00010276700499902661 Test RE 0.02372404362379585\n",
      "138 Train Loss 0.0016445345 Test MSE 0.00010168184990805775 Test RE 0.023598455704111634\n",
      "139 Train Loss 0.0016015125 Test MSE 0.00010063575952254574 Test RE 0.02347675287170875\n",
      "140 Train Loss 0.0015499815 Test MSE 8.836873296211387e-05 Test RE 0.021999417315039203\n",
      "141 Train Loss 0.001504846 Test MSE 7.665353491607412e-05 Test RE 0.020489339458953496\n",
      "142 Train Loss 0.0014749534 Test MSE 8.131839516675112e-05 Test RE 0.021103586248797067\n",
      "143 Train Loss 0.0014557281 Test MSE 7.855912735938898e-05 Test RE 0.020742456565485335\n",
      "144 Train Loss 0.0014341321 Test MSE 6.608599761486337e-05 Test RE 0.01902464621093462\n",
      "145 Train Loss 0.0014202156 Test MSE 6.834470175449294e-05 Test RE 0.019347029344396142\n",
      "146 Train Loss 0.0014050126 Test MSE 6.848826353481227e-05 Test RE 0.019367338431024204\n",
      "147 Train Loss 0.0013599284 Test MSE 7.42271222058441e-05 Test RE 0.02016244406893553\n",
      "148 Train Loss 0.0012918389 Test MSE 7.305169312328326e-05 Test RE 0.020002165072341864\n",
      "149 Train Loss 0.0012209733 Test MSE 7.353212231750529e-05 Test RE 0.02006783005422176\n",
      "150 Train Loss 0.001168365 Test MSE 7.152225188798598e-05 Test RE 0.019791670587665722\n",
      "151 Train Loss 0.0011455416 Test MSE 6.890596444865308e-05 Test RE 0.019426308080911718\n",
      "152 Train Loss 0.0011325524 Test MSE 7.386148177350025e-05 Test RE 0.020112722984590273\n",
      "153 Train Loss 0.0011276245 Test MSE 7.478801405492311e-05 Test RE 0.020238478722595057\n",
      "154 Train Loss 0.001122495 Test MSE 7.517396441491957e-05 Test RE 0.020290632779365173\n",
      "155 Train Loss 0.0011093128 Test MSE 8.696568617678528e-05 Test RE 0.02182407412394626\n",
      "156 Train Loss 0.0010976614 Test MSE 8.802107311310605e-05 Test RE 0.021956099666536246\n",
      "157 Train Loss 0.0010718459 Test MSE 8.47390114190978e-05 Test RE 0.021542869994756818\n",
      "158 Train Loss 0.0010507297 Test MSE 8.66351111658964e-05 Test RE 0.021782555664913637\n",
      "159 Train Loss 0.0010367613 Test MSE 9.036199652326675e-05 Test RE 0.02224614548184691\n",
      "160 Train Loss 0.001028823 Test MSE 8.150376310219653e-05 Test RE 0.021127625713672923\n",
      "161 Train Loss 0.0010198997 Test MSE 8.542220416608955e-05 Test RE 0.021629538378723424\n",
      "162 Train Loss 0.0010131084 Test MSE 9.007305183652409e-05 Test RE 0.02221054947610877\n",
      "163 Train Loss 0.0010059051 Test MSE 9.005197821143412e-05 Test RE 0.022207951117536612\n",
      "164 Train Loss 0.0009956 Test MSE 8.353771698184283e-05 Test RE 0.021389624728202848\n",
      "165 Train Loss 0.0009821448 Test MSE 9.04448722295127e-05 Test RE 0.022256344694748083\n",
      "166 Train Loss 0.00096618664 Test MSE 9.281346480713121e-05 Test RE 0.022545888600806502\n",
      "167 Train Loss 0.00095099624 Test MSE 0.00010154896727216807 Test RE 0.02358303087568501\n",
      "168 Train Loss 0.0009250918 Test MSE 8.047915512763761e-05 Test RE 0.020994404875855775\n",
      "169 Train Loss 0.000901326 Test MSE 7.308277821190588e-05 Test RE 0.02000642029845183\n",
      "170 Train Loss 0.000882788 Test MSE 6.895429369817132e-05 Test RE 0.01943311949652371\n",
      "171 Train Loss 0.0008665511 Test MSE 6.329074109973415e-05 Test RE 0.01861795406961933\n",
      "172 Train Loss 0.00085760345 Test MSE 5.7791014038119445e-05 Test RE 0.017790658427819767\n",
      "173 Train Loss 0.00085350097 Test MSE 5.5389507947207524e-05 Test RE 0.01741709086633606\n",
      "174 Train Loss 0.0008471729 Test MSE 5.6371378432367006e-05 Test RE 0.017570786080015312\n",
      "175 Train Loss 0.00083449413 Test MSE 5.5394988493340816e-05 Test RE 0.01741795251696665\n",
      "176 Train Loss 0.00080292457 Test MSE 5.0122291643270866e-05 Test RE 0.01656827611653198\n",
      "177 Train Loss 0.00078000483 Test MSE 4.786758728124134e-05 Test RE 0.016191334049263307\n",
      "178 Train Loss 0.00075121195 Test MSE 5.5179643576653065e-05 Test RE 0.01738406389219752\n",
      "179 Train Loss 0.0007365356 Test MSE 5.050250983551015e-05 Test RE 0.016630999288899013\n",
      "180 Train Loss 0.00072373386 Test MSE 4.763944493446645e-05 Test RE 0.01615270309772936\n",
      "181 Train Loss 0.00071753387 Test MSE 4.4652424257955677e-05 Test RE 0.015638114378599507\n",
      "182 Train Loss 0.000712331 Test MSE 4.007609297845662e-05 Test RE 0.014815098790438824\n",
      "183 Train Loss 0.00070511183 Test MSE 3.797529827549131e-05 Test RE 0.01442156729663321\n",
      "184 Train Loss 0.0006962841 Test MSE 3.29315280628569e-05 Test RE 0.013429746207021035\n",
      "185 Train Loss 0.00068927405 Test MSE 3.123373563241232e-05 Test RE 0.013078978596370468\n",
      "186 Train Loss 0.0006804796 Test MSE 2.7671635473525045e-05 Test RE 0.012310601636041644\n",
      "187 Train Loss 0.0006660651 Test MSE 2.7010411563156535e-05 Test RE 0.012162629149420668\n",
      "188 Train Loss 0.0006554396 Test MSE 2.7469011803623584e-05 Test RE 0.0122654470519618\n",
      "189 Train Loss 0.00064416346 Test MSE 2.7153060184217164e-05 Test RE 0.012194703773398017\n",
      "190 Train Loss 0.0006356091 Test MSE 2.741859654057748e-05 Test RE 0.012254186185825536\n",
      "191 Train Loss 0.00062868674 Test MSE 2.6889655815935184e-05 Test RE 0.012135410893434763\n",
      "192 Train Loss 0.0006224927 Test MSE 2.6911337299612357e-05 Test RE 0.01214030237844225\n",
      "193 Train Loss 0.0006145828 Test MSE 2.6652969889703634e-05 Test RE 0.012081884186039577\n",
      "194 Train Loss 0.00061285327 Test MSE 2.6037653002875566e-05 Test RE 0.011941607196297808\n",
      "195 Train Loss 0.00061007164 Test MSE 2.7016268235741758e-05 Test RE 0.012163947690524986\n",
      "196 Train Loss 0.0006033927 Test MSE 2.705427562107163e-05 Test RE 0.012172501006540227\n",
      "197 Train Loss 0.0005958515 Test MSE 2.432227526253687e-05 Test RE 0.011541545383705963\n",
      "198 Train Loss 0.000586287 Test MSE 2.6800481557079925e-05 Test RE 0.01211527183013731\n",
      "199 Train Loss 0.000581347 Test MSE 2.8183602643654652e-05 Test RE 0.012423962092560824\n",
      "200 Train Loss 0.0005737919 Test MSE 2.912041293661083e-05 Test RE 0.012628757636135756\n",
      "201 Train Loss 0.00056837447 Test MSE 2.765556869313275e-05 Test RE 0.012307027209584188\n",
      "202 Train Loss 0.0005628025 Test MSE 3.183611178867151e-05 Test RE 0.01320449737400105\n",
      "203 Train Loss 0.0005566428 Test MSE 3.2715735718662975e-05 Test RE 0.013385672947466091\n",
      "204 Train Loss 0.0005517799 Test MSE 3.5437609403443716e-05 Test RE 0.013931377886000103\n",
      "205 Train Loss 0.0005451204 Test MSE 3.839274132166404e-05 Test RE 0.014500615116766613\n",
      "206 Train Loss 0.00053844746 Test MSE 3.818594402574098e-05 Test RE 0.014461509587825216\n",
      "207 Train Loss 0.00053508044 Test MSE 3.963050600645202e-05 Test RE 0.014732507565363383\n",
      "208 Train Loss 0.0005306691 Test MSE 4.3681620735764565e-05 Test RE 0.015467183428063181\n",
      "209 Train Loss 0.0005264562 Test MSE 3.943999270225909e-05 Test RE 0.014697053564437035\n",
      "210 Train Loss 0.0005224226 Test MSE 4.551647924922929e-05 Test RE 0.015788693528291153\n",
      "211 Train Loss 0.0005187395 Test MSE 4.0894702198164875e-05 Test RE 0.014965643273454869\n",
      "212 Train Loss 0.0005155227 Test MSE 4.051092851950704e-05 Test RE 0.014895255693272828\n",
      "213 Train Loss 0.0005080492 Test MSE 4.268030631515905e-05 Test RE 0.015288878448125206\n",
      "214 Train Loss 0.00050060556 Test MSE 4.0808866952947657e-05 Test RE 0.014949929081137021\n",
      "215 Train Loss 0.000493426 Test MSE 4.057977415164812e-05 Test RE 0.01490790706933902\n",
      "216 Train Loss 0.0004889262 Test MSE 4.121780322229031e-05 Test RE 0.015024647264654292\n",
      "217 Train Loss 0.00048417837 Test MSE 4.666795511306402e-05 Test RE 0.015987157362907303\n",
      "218 Train Loss 0.00047858717 Test MSE 4.830033510424757e-05 Test RE 0.016264358406072876\n",
      "219 Train Loss 0.00047537297 Test MSE 4.872294633841293e-05 Test RE 0.016335357197224957\n",
      "220 Train Loss 0.00047029817 Test MSE 4.587803677296976e-05 Test RE 0.015851277778050954\n",
      "221 Train Loss 0.00046733275 Test MSE 5.170586427491952e-05 Test RE 0.01682797138941227\n",
      "222 Train Loss 0.0004649052 Test MSE 5.0084734537188605e-05 Test RE 0.016562067570467305\n",
      "223 Train Loss 0.0004622071 Test MSE 4.3516747087398206e-05 Test RE 0.015437965855549698\n",
      "224 Train Loss 0.00045958025 Test MSE 4.081033760734847e-05 Test RE 0.014950198458634581\n",
      "225 Train Loss 0.000457415 Test MSE 4.27198647189033e-05 Test RE 0.015295962084612681\n",
      "226 Train Loss 0.00045227865 Test MSE 4.251999976664384e-05 Test RE 0.015260139044980608\n",
      "227 Train Loss 0.00044811456 Test MSE 4.2908622444388976e-05 Test RE 0.015329717443508976\n",
      "228 Train Loss 0.000443796 Test MSE 3.584182864477471e-05 Test RE 0.014010606755860905\n",
      "229 Train Loss 0.0004394823 Test MSE 3.507751168388628e-05 Test RE 0.01386041561185652\n",
      "230 Train Loss 0.00043529077 Test MSE 3.143913025198472e-05 Test RE 0.01312191213993238\n",
      "231 Train Loss 0.00043100998 Test MSE 3.227942693590422e-05 Test RE 0.013296115284827164\n",
      "232 Train Loss 0.00042685788 Test MSE 2.888588909383486e-05 Test RE 0.012577801420650483\n",
      "233 Train Loss 0.00041884655 Test MSE 2.253740389325268e-05 Test RE 0.011109993578504814\n",
      "234 Train Loss 0.0004108684 Test MSE 2.5242199516910636e-05 Test RE 0.01175778356725767\n",
      "235 Train Loss 0.00040372144 Test MSE 2.8002011707701896e-05 Test RE 0.012383872740841595\n",
      "236 Train Loss 0.00039392555 Test MSE 2.5726849887803658e-05 Test RE 0.01187012166285168\n",
      "237 Train Loss 0.00038341206 Test MSE 2.808360356279072e-05 Test RE 0.012401901591624787\n",
      "238 Train Loss 0.00037501188 Test MSE 2.469058269550591e-05 Test RE 0.01162860272540032\n",
      "239 Train Loss 0.00036824043 Test MSE 2.7808426162349654e-05 Test RE 0.012340991955495532\n",
      "240 Train Loss 0.00036096518 Test MSE 2.880290903747338e-05 Test RE 0.012559722397601428\n",
      "241 Train Loss 0.00035486787 Test MSE 2.4891908619086206e-05 Test RE 0.011675916030726714\n",
      "242 Train Loss 0.00034866895 Test MSE 2.727014400571906e-05 Test RE 0.012220967234144146\n",
      "243 Train Loss 0.00034204 Test MSE 2.5458425231379926e-05 Test RE 0.011808035010450874\n",
      "244 Train Loss 0.0003344548 Test MSE 2.5281723492995915e-05 Test RE 0.011766985074980014\n",
      "245 Train Loss 0.00033116734 Test MSE 2.738090176582667e-05 Test RE 0.012245759830801416\n",
      "246 Train Loss 0.00032944928 Test MSE 2.7568096303256366e-05 Test RE 0.012287548715321868\n",
      "247 Train Loss 0.0003289397 Test MSE 2.9104766218552762e-05 Test RE 0.012625364395100746\n",
      "248 Train Loss 0.00032893114 Test MSE 2.9123999443296053e-05 Test RE 0.012629535299029531\n",
      "249 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "250 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "251 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "252 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "253 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "254 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "255 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "256 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "257 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "258 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "259 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "260 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "261 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "262 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "263 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "264 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "265 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "266 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "267 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "268 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "269 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "270 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "271 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "272 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "273 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "274 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "275 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "276 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "277 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "278 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "279 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "280 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "281 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "282 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "283 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "284 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "285 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "286 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "287 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "288 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "289 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "290 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "291 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "292 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "293 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "294 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "295 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "296 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "297 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "298 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "299 Train Loss 0.00032825198 Test MSE 2.986006460375111e-05 Test RE 0.012788135683765339\n",
      "Training time: 142.70\n",
      "KG_tanh_low\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 6285.948 Test MSE 6.798128946283447 Test RE 6.1017802522471145\n",
      "1 Train Loss 1450.9534 Test MSE 8.03412058725606 Test RE 6.633321348295199\n",
      "2 Train Loss 192.16422 Test MSE 12.329631445764175 Test RE 8.2174469967373\n",
      "3 Train Loss 59.45125 Test MSE 13.883733293012721 Test RE 8.719970087878275\n",
      "4 Train Loss 33.921932 Test MSE 14.199140058912038 Test RE 8.81846276654973\n",
      "5 Train Loss 26.940723 Test MSE 14.423464605658188 Test RE 8.887848857912736\n",
      "6 Train Loss 23.738565 Test MSE 14.302736860592459 Test RE 8.850574015754612\n",
      "7 Train Loss 21.955025 Test MSE 13.989546497039038 Test RE 8.753136116903406\n",
      "8 Train Loss 19.95948 Test MSE 13.555516927449178 Test RE 8.616282028576212\n",
      "9 Train Loss 18.173344 Test MSE 13.17005663512252 Test RE 8.492893640978515\n",
      "10 Train Loss 16.432812 Test MSE 12.834848647726256 Test RE 8.38411525583082\n",
      "11 Train Loss 14.770881 Test MSE 12.082966046490158 Test RE 8.134832997394385\n",
      "12 Train Loss 13.168361 Test MSE 11.48767354489912 Test RE 7.931912354405934\n",
      "13 Train Loss 11.80673 Test MSE 10.894090894225174 Test RE 7.724268492482581\n",
      "14 Train Loss 10.791185 Test MSE 10.356141252681692 Test RE 7.531142180425443\n",
      "15 Train Loss 10.040717 Test MSE 9.87186540581496 Test RE 7.352947697600544\n",
      "16 Train Loss 9.41264 Test MSE 9.481842878746782 Test RE 7.206232023663123\n",
      "17 Train Loss 9.0356655 Test MSE 9.354924010841136 Test RE 7.157840161024378\n",
      "18 Train Loss 8.77812 Test MSE 9.044719657249665 Test RE 7.038164597682091\n",
      "19 Train Loss 8.479979 Test MSE 8.849106671680774 Test RE 6.961640286912676\n",
      "20 Train Loss 8.171625 Test MSE 8.590182742831887 Test RE 6.859035734593445\n",
      "21 Train Loss 7.8401327 Test MSE 8.477425787574573 Test RE 6.813870295235939\n",
      "22 Train Loss 7.6104436 Test MSE 8.364418613518682 Test RE 6.768302239395262\n",
      "23 Train Loss 7.336476 Test MSE 8.025358582010663 Test RE 6.629703214163653\n",
      "24 Train Loss 7.0114336 Test MSE 7.7259696551524994 Test RE 6.504866127767724\n",
      "25 Train Loss 6.7339897 Test MSE 7.322656501277849 Test RE 6.332806163075133\n",
      "26 Train Loss 6.4580064 Test MSE 7.019455532698288 Test RE 6.200312483486472\n",
      "27 Train Loss 6.005913 Test MSE 6.5684155904463735 Test RE 5.997802703934458\n",
      "28 Train Loss 5.7006097 Test MSE 6.318988001564649 Test RE 5.88282093696926\n",
      "29 Train Loss 5.409263 Test MSE 5.839595919974512 Test RE 5.655268931690679\n",
      "30 Train Loss 5.008686 Test MSE 5.15536310873053 Test RE 5.313632245605369\n",
      "31 Train Loss 4.6646976 Test MSE 4.538114365591284 Test RE 4.985395097033109\n",
      "32 Train Loss 4.315128 Test MSE 4.029101063898086 Test RE 4.697490869242824\n",
      "33 Train Loss 3.8890135 Test MSE 3.4233350336927613 Test RE 4.329986739486089\n",
      "34 Train Loss 3.4024227 Test MSE 2.8400481137295523 Test RE 3.9438892680443365\n",
      "35 Train Loss 3.0251458 Test MSE 2.291332420864982 Test RE 3.5424678226791855\n",
      "36 Train Loss 2.603947 Test MSE 1.8553180605313295 Test RE 3.187653081286433\n",
      "37 Train Loss 2.0864053 Test MSE 1.2700493146657836 Test RE 2.637376646560267\n",
      "38 Train Loss 1.6839228 Test MSE 0.8962229610255602 Test RE 2.2154905257160245\n",
      "39 Train Loss 1.2662722 Test MSE 0.6079286868050592 Test RE 1.8246861796345704\n",
      "40 Train Loss 0.8263511 Test MSE 0.3063783722697687 Test RE 1.2953612949162865\n",
      "41 Train Loss 0.61576897 Test MSE 0.21708623172924132 Test RE 1.0903803190928636\n",
      "42 Train Loss 0.45256916 Test MSE 0.13854181145632966 Test RE 0.8710684720963775\n",
      "43 Train Loss 0.35588923 Test MSE 0.0993624721229408 Test RE 0.7376885763034764\n",
      "44 Train Loss 0.29569545 Test MSE 0.0748196805809118 Test RE 0.6401323698853759\n",
      "45 Train Loss 0.2427264 Test MSE 0.08088703211847198 Test RE 0.6655816107534887\n",
      "46 Train Loss 0.20118189 Test MSE 0.07477834207479689 Test RE 0.6399555061790146\n",
      "47 Train Loss 0.1720088 Test MSE 0.07903166797615202 Test RE 0.6579038653387485\n",
      "48 Train Loss 0.14318532 Test MSE 0.06630991612556873 Test RE 0.6026304932919224\n",
      "49 Train Loss 0.12582655 Test MSE 0.062232068433002094 Test RE 0.5838065753153535\n",
      "50 Train Loss 0.097041555 Test MSE 0.049235730481590224 Test RE 0.5192805509187709\n",
      "51 Train Loss 0.07982345 Test MSE 0.040560697809987764 Test RE 0.47131859356354927\n",
      "52 Train Loss 0.07273563 Test MSE 0.04214293368944861 Test RE 0.4804235039803294\n",
      "53 Train Loss 0.06549505 Test MSE 0.03930575234233198 Test RE 0.4639700218888225\n",
      "54 Train Loss 0.054996543 Test MSE 0.03312765064386105 Test RE 0.4259485879031749\n",
      "55 Train Loss 0.048729703 Test MSE 0.0291767647348357 Test RE 0.3997425980798458\n",
      "56 Train Loss 0.044790976 Test MSE 0.025454058717155788 Test RE 0.3733708296808818\n",
      "57 Train Loss 0.041588966 Test MSE 0.024710447446380415 Test RE 0.3678766040709063\n",
      "58 Train Loss 0.035502743 Test MSE 0.020239089859018334 Test RE 0.33293339036098957\n",
      "59 Train Loss 0.02953311 Test MSE 0.016296459774126054 Test RE 0.2987504021243346\n",
      "60 Train Loss 0.026375983 Test MSE 0.012074621322615386 Test RE 0.2571571617584364\n",
      "61 Train Loss 0.023503281 Test MSE 0.008348167401399544 Test RE 0.2138244869316673\n",
      "62 Train Loss 0.02056934 Test MSE 0.006911702434533517 Test RE 0.19456036854987874\n",
      "63 Train Loss 0.019372672 Test MSE 0.005932308381141864 Test RE 0.18024935675288398\n",
      "64 Train Loss 0.016663002 Test MSE 0.004633989221471888 Test RE 0.15930865598328076\n",
      "65 Train Loss 0.015261876 Test MSE 0.004404569194148048 Test RE 0.15531506491562674\n",
      "66 Train Loss 0.0136890365 Test MSE 0.0030112053519365093 Test RE 0.1284198182282056\n",
      "67 Train Loss 0.012779268 Test MSE 0.002548946041134778 Test RE 0.11815230130953476\n",
      "68 Train Loss 0.012150663 Test MSE 0.002386546880284821 Test RE 0.11432648441775443\n",
      "69 Train Loss 0.011405882 Test MSE 0.0018994199376140507 Test RE 0.10199346828635335\n",
      "70 Train Loss 0.010400639 Test MSE 0.0017182092910143596 Test RE 0.09700629005716584\n",
      "71 Train Loss 0.009636222 Test MSE 0.00117783444729255 Test RE 0.08031635485778\n",
      "72 Train Loss 0.009216623 Test MSE 0.0008970660874241123 Test RE 0.07009290884722462\n",
      "73 Train Loss 0.008626952 Test MSE 0.0007646146461492316 Test RE 0.06471175383789673\n",
      "74 Train Loss 0.00803834 Test MSE 0.000716603324497218 Test RE 0.06264714349271067\n",
      "75 Train Loss 0.007671601 Test MSE 0.0006425194743970707 Test RE 0.05932052852035098\n",
      "76 Train Loss 0.007268558 Test MSE 0.000549228022857349 Test RE 0.05484514739160257\n",
      "77 Train Loss 0.006934399 Test MSE 0.000504772800132983 Test RE 0.052578699076762735\n",
      "78 Train Loss 0.0066746585 Test MSE 0.00040760757881392744 Test RE 0.04724795209120343\n",
      "79 Train Loss 0.006325801 Test MSE 0.00038754039317706314 Test RE 0.04607022696495573\n",
      "80 Train Loss 0.0061172927 Test MSE 0.000369657899227413 Test RE 0.0449947517043738\n",
      "81 Train Loss 0.0060083116 Test MSE 0.00038066359581123195 Test RE 0.04565964566533933\n",
      "82 Train Loss 0.005902852 Test MSE 0.00035934159670814774 Test RE 0.04436245896687004\n",
      "83 Train Loss 0.005604483 Test MSE 0.00033277422368271524 Test RE 0.04269103692350829\n",
      "84 Train Loss 0.005527641 Test MSE 0.000316748414994392 Test RE 0.04165039161805854\n",
      "85 Train Loss 0.0053621926 Test MSE 0.0003127442041514311 Test RE 0.04138629023291587\n",
      "86 Train Loss 0.0051985076 Test MSE 0.00031077541451399946 Test RE 0.04125581692873126\n",
      "87 Train Loss 0.004995645 Test MSE 0.00029293760493665335 Test RE 0.04005432591351166\n",
      "88 Train Loss 0.0048481687 Test MSE 0.00025470874172843174 Test RE 0.03734941374045067\n",
      "89 Train Loss 0.0047651776 Test MSE 0.0002526585958421846 Test RE 0.037198797686232916\n",
      "90 Train Loss 0.004661548 Test MSE 0.00023692160799671273 Test RE 0.03602169957317537\n",
      "91 Train Loss 0.004492337 Test MSE 0.00023906414905006663 Test RE 0.03618420959162672\n",
      "92 Train Loss 0.004410819 Test MSE 0.00026682205197439555 Test RE 0.038227220701428574\n",
      "93 Train Loss 0.0043021967 Test MSE 0.00028327030567512683 Test RE 0.03938786036668484\n",
      "94 Train Loss 0.004135321 Test MSE 0.0003105895427589142 Test RE 0.041243477731890965\n",
      "95 Train Loss 0.004022652 Test MSE 0.0002988165661785241 Test RE 0.04045425423246522\n",
      "96 Train Loss 0.003931432 Test MSE 0.0003139346066460757 Test RE 0.041464980022697294\n",
      "97 Train Loss 0.003826726 Test MSE 0.00028210444752525474 Test RE 0.039306722309513785\n",
      "98 Train Loss 0.0036773293 Test MSE 0.00028675875629932766 Test RE 0.03962964738558735\n",
      "99 Train Loss 0.003520868 Test MSE 0.0002827375047201416 Test RE 0.03935080076929899\n",
      "100 Train Loss 0.0034287525 Test MSE 0.00033784852086455225 Test RE 0.04301529196229549\n",
      "101 Train Loss 0.0033822248 Test MSE 0.000361200709866629 Test RE 0.044477069177221884\n",
      "102 Train Loss 0.0033273858 Test MSE 0.00037411893701383447 Test RE 0.045265436209854015\n",
      "103 Train Loss 0.0032406377 Test MSE 0.0003540567261352507 Test RE 0.04403502919967859\n",
      "104 Train Loss 0.003136423 Test MSE 0.0002693387225757633 Test RE 0.03840707752505478\n",
      "105 Train Loss 0.0030330317 Test MSE 0.00028430325668788445 Test RE 0.03945960934032364\n",
      "106 Train Loss 0.0029830139 Test MSE 0.0002812024031909997 Test RE 0.0392438293006978\n",
      "107 Train Loss 0.0028989578 Test MSE 0.0002569262203005736 Test RE 0.03751164226221793\n",
      "108 Train Loss 0.0027816994 Test MSE 0.0002616237666963823 Test RE 0.03785301362486888\n",
      "109 Train Loss 0.002652232 Test MSE 0.00023795985212619758 Test RE 0.03610054091418546\n",
      "110 Train Loss 0.0025831407 Test MSE 0.0002508201509051328 Test RE 0.03706321393492838\n",
      "111 Train Loss 0.0025156853 Test MSE 0.00023530601299461964 Test RE 0.03589867147522275\n",
      "112 Train Loss 0.002444037 Test MSE 0.00023134853574110592 Test RE 0.03559551179089206\n",
      "113 Train Loss 0.0023677375 Test MSE 0.0002109485004425177 Test RE 0.0339899155288116\n",
      "114 Train Loss 0.002293018 Test MSE 0.00018665898481790117 Test RE 0.0319732154231271\n",
      "115 Train Loss 0.0022139838 Test MSE 0.00019196096327155974 Test RE 0.03242412942895056\n",
      "116 Train Loss 0.002114734 Test MSE 0.00017831823351606717 Test RE 0.03125069934387483\n",
      "117 Train Loss 0.0020650371 Test MSE 0.00018618598512516656 Test RE 0.0319326791639544\n",
      "118 Train Loss 0.0020176996 Test MSE 0.00015276370984853216 Test RE 0.028924906405725703\n",
      "119 Train Loss 0.0019516263 Test MSE 0.00014587633316910702 Test RE 0.02826534450343481\n",
      "120 Train Loss 0.0018843624 Test MSE 0.00013785793075381367 Test RE 0.02747753323075393\n",
      "121 Train Loss 0.0017651262 Test MSE 0.00013159304272536984 Test RE 0.0268459222760541\n",
      "122 Train Loss 0.0016959588 Test MSE 0.00013759739586971864 Test RE 0.02745155633758545\n",
      "123 Train Loss 0.001569706 Test MSE 0.00014362348756180303 Test RE 0.02804623690752466\n",
      "124 Train Loss 0.001485109 Test MSE 0.0001370485994409229 Test RE 0.027396757452304705\n",
      "125 Train Loss 0.0014535706 Test MSE 0.00014392802957184178 Test RE 0.028075956052140645\n",
      "126 Train Loss 0.0014130969 Test MSE 0.00014373250043608725 Test RE 0.028056878693955983\n",
      "127 Train Loss 0.0013873058 Test MSE 0.00014918463430539034 Test RE 0.028584059753429435\n",
      "128 Train Loss 0.0013608637 Test MSE 0.00014715078315859985 Test RE 0.028388546227564194\n",
      "129 Train Loss 0.0013217092 Test MSE 0.00013984553928785215 Test RE 0.027674907187158593\n",
      "130 Train Loss 0.0012867465 Test MSE 0.00013762357140287884 Test RE 0.027454167306159925\n",
      "131 Train Loss 0.001260639 Test MSE 0.00014635957622894202 Test RE 0.028312122955883163\n",
      "132 Train Loss 0.0012456633 Test MSE 0.00014610768525984635 Test RE 0.028287749288824326\n",
      "133 Train Loss 0.0012285893 Test MSE 0.00013608049540283395 Test RE 0.027299821340198822\n",
      "134 Train Loss 0.0012163102 Test MSE 0.0001325261330251862 Test RE 0.026940932699079382\n",
      "135 Train Loss 0.0011991846 Test MSE 0.00014492976102186154 Test RE 0.02817349022055393\n",
      "136 Train Loss 0.0011859051 Test MSE 0.00014439261113153993 Test RE 0.028121232370775594\n",
      "137 Train Loss 0.001157451 Test MSE 0.00014158183527527763 Test RE 0.027846180431579503\n",
      "138 Train Loss 0.0011229707 Test MSE 0.00013363338691814355 Test RE 0.027053244145222585\n",
      "139 Train Loss 0.0011042492 Test MSE 0.00013722165496217074 Test RE 0.02741404936335829\n",
      "140 Train Loss 0.0010827413 Test MSE 0.00013938704439574106 Test RE 0.02762950273217719\n",
      "141 Train Loss 0.0010673429 Test MSE 0.0001411182235586964 Test RE 0.027800551692670917\n",
      "142 Train Loss 0.0010621476 Test MSE 0.00014031619033534295 Test RE 0.02772143810765635\n",
      "143 Train Loss 0.0010443674 Test MSE 0.0001355407012680282 Test RE 0.02724562207322962\n",
      "144 Train Loss 0.0010302106 Test MSE 0.00013573285245075236 Test RE 0.027264927803183618\n",
      "145 Train Loss 0.0010193705 Test MSE 0.00013623845799546385 Test RE 0.02731566159645064\n",
      "146 Train Loss 0.0009990165 Test MSE 0.0001371980602726588 Test RE 0.02741169239648482\n",
      "147 Train Loss 0.00097553147 Test MSE 0.00012233479167560982 Test RE 0.0258843257920631\n",
      "148 Train Loss 0.000952663 Test MSE 0.0001186737261148708 Test RE 0.02549406878961689\n",
      "149 Train Loss 0.0009406603 Test MSE 0.00011850680658754114 Test RE 0.025476133247040143\n",
      "150 Train Loss 0.0009238995 Test MSE 0.0001167398382356838 Test RE 0.025285491951414458\n",
      "151 Train Loss 0.00089183473 Test MSE 0.00010952603898625592 Test RE 0.02449179157174026\n",
      "152 Train Loss 0.00087282516 Test MSE 0.00011169100272995545 Test RE 0.024732667501160363\n",
      "153 Train Loss 0.00085895415 Test MSE 0.00010637845828046717 Test RE 0.02413730120716824\n",
      "154 Train Loss 0.0008498864 Test MSE 0.00010349705129586491 Test RE 0.02380816108790945\n",
      "155 Train Loss 0.0008392527 Test MSE 0.00010065990398296951 Test RE 0.023479568965802847\n",
      "156 Train Loss 0.0008274564 Test MSE 0.00010238091254240452 Test RE 0.023679436438659277\n",
      "157 Train Loss 0.0008111428 Test MSE 0.00010028349794563152 Test RE 0.023435628286959324\n",
      "158 Train Loss 0.0007898154 Test MSE 9.632745528487263e-05 Test RE 0.022968726044224518\n",
      "159 Train Loss 0.0007733021 Test MSE 9.405347247995853e-05 Test RE 0.022695997830158382\n",
      "160 Train Loss 0.0007574427 Test MSE 9.188579296463814e-05 Test RE 0.022432932410791986\n",
      "161 Train Loss 0.0007498923 Test MSE 9.204543890776632e-05 Test RE 0.02245241187710702\n",
      "162 Train Loss 0.00074461027 Test MSE 9.352988953773245e-05 Test RE 0.022632736893089755\n",
      "163 Train Loss 0.0007363689 Test MSE 9.402735328163131e-05 Test RE 0.02269284620579653\n",
      "164 Train Loss 0.00073146325 Test MSE 9.182600994850834e-05 Test RE 0.02242563353178754\n",
      "165 Train Loss 0.000724916 Test MSE 9.049726683073875e-05 Test RE 0.022262790297706767\n",
      "166 Train Loss 0.00071611744 Test MSE 9.058748852541265e-05 Test RE 0.022273885032227252\n",
      "167 Train Loss 0.0007096615 Test MSE 9.08122673034296e-05 Test RE 0.02230150250321069\n",
      "168 Train Loss 0.00070469466 Test MSE 9.049831334308633e-05 Test RE 0.022262919021028466\n",
      "169 Train Loss 0.00069652963 Test MSE 9.066142677748474e-05 Test RE 0.022282973242079934\n",
      "170 Train Loss 0.0006839175 Test MSE 8.963170460944276e-05 Test RE 0.0221560681324571\n",
      "171 Train Loss 0.0006753159 Test MSE 8.883177047889786e-05 Test RE 0.022056978661136855\n",
      "172 Train Loss 0.000661561 Test MSE 8.826342571985179e-05 Test RE 0.021986305275897705\n",
      "173 Train Loss 0.0006558295 Test MSE 8.961548500795154e-05 Test RE 0.02215406337947282\n",
      "174 Train Loss 0.0006501058 Test MSE 9.16396417657882e-05 Test RE 0.02240286467063763\n",
      "175 Train Loss 0.00064398436 Test MSE 8.789718292471375e-05 Test RE 0.02194064255463557\n",
      "176 Train Loss 0.0006362704 Test MSE 8.913446219945256e-05 Test RE 0.022094525965377063\n",
      "177 Train Loss 0.00063087675 Test MSE 9.074139053281087e-05 Test RE 0.022292797913725557\n",
      "178 Train Loss 0.00062594726 Test MSE 9.029540233628307e-05 Test RE 0.022237946586965318\n",
      "179 Train Loss 0.00062032696 Test MSE 9.040397754896035e-05 Test RE 0.022251312518847103\n",
      "180 Train Loss 0.000614137 Test MSE 8.642872867938652e-05 Test RE 0.021756594951897187\n",
      "181 Train Loss 0.00060709275 Test MSE 8.643205342924629e-05 Test RE 0.021757013415418993\n",
      "182 Train Loss 0.0005992075 Test MSE 8.500293541923122e-05 Test RE 0.021576392100591892\n",
      "183 Train Loss 0.0005926023 Test MSE 8.529533313512191e-05 Test RE 0.02161347006521662\n",
      "184 Train Loss 0.000581918 Test MSE 8.648713209777342e-05 Test RE 0.021763944619944128\n",
      "185 Train Loss 0.0005721627 Test MSE 9.159011394031055e-05 Test RE 0.02239680989395775\n",
      "186 Train Loss 0.000566251 Test MSE 9.272870772703992e-05 Test RE 0.02253559181815689\n",
      "187 Train Loss 0.0005595765 Test MSE 9.027701193618911e-05 Test RE 0.02223568187829837\n",
      "188 Train Loss 0.0005516266 Test MSE 8.928369005657791e-05 Test RE 0.022113013427114143\n",
      "189 Train Loss 0.0005448548 Test MSE 8.981801568780914e-05 Test RE 0.022179083303742686\n",
      "190 Train Loss 0.000539149 Test MSE 9.192815315164106e-05 Test RE 0.022438102707997506\n",
      "191 Train Loss 0.0005328574 Test MSE 8.845187490565198e-05 Test RE 0.022009763985354397\n",
      "192 Train Loss 0.00052805955 Test MSE 8.792035120820209e-05 Test RE 0.021943533964333895\n",
      "193 Train Loss 0.0005232004 Test MSE 9.049240757455309e-05 Test RE 0.02226219258875111\n",
      "194 Train Loss 0.0005164101 Test MSE 9.053576219047962e-05 Test RE 0.022267524821921906\n",
      "195 Train Loss 0.0005085849 Test MSE 8.600138168269075e-05 Test RE 0.021702740538127912\n",
      "196 Train Loss 0.0005020981 Test MSE 8.623854045592972e-05 Test RE 0.02173264384750754\n",
      "197 Train Loss 0.0004980825 Test MSE 8.441262253462196e-05 Test RE 0.021501341677886244\n",
      "198 Train Loss 0.0004944244 Test MSE 8.352648340252568e-05 Test RE 0.021388186514824242\n",
      "199 Train Loss 0.00049038965 Test MSE 8.441379359690113e-05 Test RE 0.021501490822185436\n",
      "200 Train Loss 0.00048696224 Test MSE 8.641356051309706e-05 Test RE 0.021754685736434635\n",
      "201 Train Loss 0.0004845405 Test MSE 8.403436787262756e-05 Test RE 0.02145311361690528\n",
      "202 Train Loss 0.0004789375 Test MSE 8.643494320177594e-05 Test RE 0.021757377124781953\n",
      "203 Train Loss 0.00047118112 Test MSE 8.629112826900779e-05 Test RE 0.021739269064203134\n",
      "204 Train Loss 0.0004628673 Test MSE 8.593520786578505e-05 Test RE 0.021694389337721626\n",
      "205 Train Loss 0.00044794282 Test MSE 8.48512366802955e-05 Test RE 0.021557130571071947\n",
      "206 Train Loss 0.0004397575 Test MSE 8.674459038218418e-05 Test RE 0.021796314429571848\n",
      "207 Train Loss 0.00042459037 Test MSE 8.767002962877952e-05 Test RE 0.021912273537293116\n",
      "208 Train Loss 0.0004174393 Test MSE 8.724841989193741e-05 Test RE 0.02185952140679504\n",
      "209 Train Loss 0.00040899648 Test MSE 8.318663591345406e-05 Test RE 0.021344630687382068\n",
      "210 Train Loss 0.00040374746 Test MSE 8.258994907311416e-05 Test RE 0.021267941800376618\n",
      "211 Train Loss 0.0003995202 Test MSE 8.113799997524141e-05 Test RE 0.021080165353952934\n",
      "212 Train Loss 0.00039419162 Test MSE 8.134830148324352e-05 Test RE 0.021107466505603818\n",
      "213 Train Loss 0.00039061057 Test MSE 8.237174221593533e-05 Test RE 0.02123982772498515\n",
      "214 Train Loss 0.00038699285 Test MSE 8.34153684715864e-05 Test RE 0.02137395547291749\n",
      "215 Train Loss 0.00038467528 Test MSE 8.239263713598604e-05 Test RE 0.021242521466487353\n",
      "216 Train Loss 0.00038208324 Test MSE 7.997608862286829e-05 Test RE 0.020928685134650463\n",
      "217 Train Loss 0.00037862762 Test MSE 7.882428754942741e-05 Test RE 0.020777433026104162\n",
      "218 Train Loss 0.00037652237 Test MSE 7.746831870713623e-05 Test RE 0.020597946667728868\n",
      "219 Train Loss 0.0003738257 Test MSE 7.701768834645014e-05 Test RE 0.02053795054257066\n",
      "220 Train Loss 0.00037080233 Test MSE 7.757815622764697e-05 Test RE 0.020612543770496202\n",
      "221 Train Loss 0.0003672368 Test MSE 7.609647325305001e-05 Test RE 0.02041475295718531\n",
      "222 Train Loss 0.00036388202 Test MSE 7.442535161758572e-05 Test RE 0.02018934882039189\n",
      "223 Train Loss 0.00035891603 Test MSE 7.377752809193502e-05 Test RE 0.020101289303688097\n",
      "224 Train Loss 0.00035475215 Test MSE 7.380983543802178e-05 Test RE 0.020105690021949712\n",
      "225 Train Loss 0.00034943776 Test MSE 7.46652290776865e-05 Test RE 0.020221858399386707\n",
      "226 Train Loss 0.00034370294 Test MSE 7.358073984707301e-05 Test RE 0.020074463122024207\n",
      "227 Train Loss 0.00033972235 Test MSE 7.445969421526874e-05 Test RE 0.020194006337639413\n",
      "228 Train Loss 0.00033488983 Test MSE 7.522563801467997e-05 Test RE 0.020297605339131046\n",
      "229 Train Loss 0.0003301622 Test MSE 7.401679695209515e-05 Test RE 0.02013385829512074\n",
      "230 Train Loss 0.0003248713 Test MSE 7.571022037787589e-05 Test RE 0.020362876120963283\n",
      "231 Train Loss 0.0003201869 Test MSE 7.524001305317157e-05 Test RE 0.020299544604306444\n",
      "232 Train Loss 0.0003150177 Test MSE 7.443599430833497e-05 Test RE 0.020190792288983794\n",
      "233 Train Loss 0.00031008438 Test MSE 7.530124777915805e-05 Test RE 0.020307803402981876\n",
      "234 Train Loss 0.00030593664 Test MSE 7.573511866176345e-05 Test RE 0.02036622414314127\n",
      "235 Train Loss 0.00030345062 Test MSE 7.528863568994841e-05 Test RE 0.020306102670516822\n",
      "236 Train Loss 0.0003017769 Test MSE 7.600303748346533e-05 Test RE 0.020402215884458494\n",
      "237 Train Loss 0.0002999804 Test MSE 7.527851934790136e-05 Test RE 0.020304738385061277\n",
      "238 Train Loss 0.00029680436 Test MSE 7.485072164374489e-05 Test RE 0.020246961634612422\n",
      "239 Train Loss 0.0002948365 Test MSE 7.537768502824086e-05 Test RE 0.02031810787302737\n",
      "240 Train Loss 0.00029279388 Test MSE 7.522613716350436e-05 Test RE 0.02029767267992938\n",
      "241 Train Loss 0.00029031825 Test MSE 7.516150747505114e-05 Test RE 0.0202889515479287\n",
      "242 Train Loss 0.00028830615 Test MSE 7.579618454526289e-05 Test RE 0.020374433220357015\n",
      "243 Train Loss 0.0002876314 Test MSE 7.589964763905423e-05 Test RE 0.020388334203854542\n",
      "244 Train Loss 0.00028675198 Test MSE 7.661055918152693e-05 Test RE 0.020483594988927985\n",
      "245 Train Loss 0.00028506975 Test MSE 7.708955533315403e-05 Test RE 0.020547530526651096\n",
      "246 Train Loss 0.00028333973 Test MSE 7.82847185246532e-05 Test RE 0.020706197936328004\n",
      "247 Train Loss 0.00028074312 Test MSE 7.845821751071141e-05 Test RE 0.02072913035621762\n",
      "248 Train Loss 0.00027919485 Test MSE 7.713548529509334e-05 Test RE 0.020553650725176325\n",
      "249 Train Loss 0.00027724434 Test MSE 7.596331773604504e-05 Test RE 0.02039688401357081\n",
      "250 Train Loss 0.00027422677 Test MSE 7.394725190923725e-05 Test RE 0.020124397340619483\n",
      "251 Train Loss 0.00027209023 Test MSE 7.311703187759643e-05 Test RE 0.02001110822199179\n",
      "252 Train Loss 0.0002717012 Test MSE 7.324557234149104e-05 Test RE 0.02002869036089934\n",
      "253 Train Loss 0.00027057764 Test MSE 7.407366577749263e-05 Test RE 0.02014159146565203\n",
      "254 Train Loss 0.00026858196 Test MSE 7.4075550071774e-05 Test RE 0.020141847646062843\n",
      "255 Train Loss 0.0002673781 Test MSE 7.248263920801284e-05 Test RE 0.019924106899174364\n",
      "256 Train Loss 0.00026623742 Test MSE 7.186181499242924e-05 Test RE 0.019838596985584135\n",
      "257 Train Loss 0.0002652119 Test MSE 7.063339147764838e-05 Test RE 0.019668303162853912\n",
      "258 Train Loss 0.0002639119 Test MSE 7.062464706492473e-05 Test RE 0.01966708565736407\n",
      "259 Train Loss 0.00026233864 Test MSE 7.055119861947243e-05 Test RE 0.019656856277877652\n",
      "260 Train Loss 0.00026052492 Test MSE 6.925077685347441e-05 Test RE 0.01947485302947865\n",
      "261 Train Loss 0.00025732417 Test MSE 6.858117601090362e-05 Test RE 0.019380471027704425\n",
      "262 Train Loss 0.00025396477 Test MSE 6.688646071557162e-05 Test RE 0.01913951691987591\n",
      "263 Train Loss 0.00025166458 Test MSE 6.566744782498626e-05 Test RE 0.01896430506525469\n",
      "264 Train Loss 0.0002502059 Test MSE 6.468819596030045e-05 Test RE 0.018822373361004657\n",
      "265 Train Loss 0.00024840605 Test MSE 6.325641181916009e-05 Test RE 0.01861290413933049\n",
      "266 Train Loss 0.00024550862 Test MSE 6.319559143479104e-05 Test RE 0.0186039539302177\n",
      "267 Train Loss 0.00024221564 Test MSE 6.287513285354966e-05 Test RE 0.018556724576949978\n",
      "268 Train Loss 0.0002389497 Test MSE 6.05178938664862e-05 Test RE 0.018205548447917073\n",
      "269 Train Loss 0.00023750607 Test MSE 5.973046722324461e-05 Test RE 0.01808672019372923\n",
      "270 Train Loss 0.00023563263 Test MSE 6.025034786669154e-05 Test RE 0.018165261049549217\n",
      "271 Train Loss 0.00023410523 Test MSE 5.908518407699192e-05 Test RE 0.017988757219280414\n",
      "272 Train Loss 0.00023235883 Test MSE 5.8842664099727463e-05 Test RE 0.017951801094261227\n",
      "273 Train Loss 0.00022971228 Test MSE 5.793303393666352e-05 Test RE 0.01781250505199847\n",
      "274 Train Loss 0.000227794 Test MSE 5.661759147808193e-05 Test RE 0.017609116198332275\n",
      "275 Train Loss 0.00022639663 Test MSE 5.516767361062201e-05 Test RE 0.017382178251706563\n",
      "276 Train Loss 0.00022528478 Test MSE 5.58415323804303e-05 Test RE 0.01748801543013835\n",
      "277 Train Loss 0.00022388043 Test MSE 5.550598449748433e-05 Test RE 0.017435394127590296\n",
      "278 Train Loss 0.00022185715 Test MSE 5.463689844644581e-05 Test RE 0.01729835808579057\n",
      "279 Train Loss 0.00022037287 Test MSE 5.478535870284783e-05 Test RE 0.017321843830612593\n",
      "280 Train Loss 0.00021819047 Test MSE 5.3551322988244185e-05 Test RE 0.017125646147484318\n",
      "281 Train Loss 0.00021667882 Test MSE 5.2932352503390485e-05 Test RE 0.017026385495291778\n",
      "282 Train Loss 0.00021526637 Test MSE 5.247316908623659e-05 Test RE 0.01695237344908541\n",
      "283 Train Loss 0.00021221182 Test MSE 5.150173361209804e-05 Test RE 0.016794720789199056\n",
      "284 Train Loss 0.00021005825 Test MSE 5.116334048293724e-05 Test RE 0.016739454840450932\n",
      "285 Train Loss 0.00020792856 Test MSE 4.874405667443949e-05 Test RE 0.01633889564841231\n",
      "286 Train Loss 0.00020563998 Test MSE 4.7291491282899966e-05 Test RE 0.016093606141659295\n",
      "287 Train Loss 0.0002032837 Test MSE 4.6593198545236126e-05 Test RE 0.01597434745924859\n",
      "288 Train Loss 0.00020121314 Test MSE 4.674916695290682e-05 Test RE 0.01600106178729903\n",
      "289 Train Loss 0.00020113225 Test MSE 4.680238413214734e-05 Test RE 0.016010166646594957\n",
      "290 Train Loss 0.00019926799 Test MSE 4.742396440351578e-05 Test RE 0.016116131116409266\n",
      "291 Train Loss 0.00019692932 Test MSE 4.7867859870253336e-05 Test RE 0.016191380151163552\n",
      "292 Train Loss 0.00019400728 Test MSE 4.6058597225087925e-05 Test RE 0.015882439784242173\n",
      "293 Train Loss 0.0001913769 Test MSE 4.4175709351725724e-05 Test RE 0.015554413138366942\n",
      "294 Train Loss 0.00018962148 Test MSE 4.4770983875463075e-05 Test RE 0.015658861514047797\n",
      "295 Train Loss 0.00018814257 Test MSE 4.445267685639594e-05 Test RE 0.015603097535213663\n",
      "296 Train Loss 0.00018700764 Test MSE 4.4138146865483184e-05 Test RE 0.015547798794306384\n",
      "297 Train Loss 0.0001857041 Test MSE 4.380330926216569e-05 Test RE 0.015488712731505773\n",
      "298 Train Loss 0.00018351103 Test MSE 4.2540797652031295e-05 Test RE 0.015263870698603459\n",
      "299 Train Loss 0.00018178116 Test MSE 4.273005748312833e-05 Test RE 0.015297786749057627\n",
      "Training time: 161.34\n",
      "KG_tanh_low\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 6341.7935 Test MSE 7.051765034253373 Test RE 6.214565655460069\n",
      "1 Train Loss 1567.9158 Test MSE 8.305639440161043 Test RE 6.744478909808094\n",
      "2 Train Loss 478.18628 Test MSE 11.890265362135848 Test RE 8.069704607435419\n",
      "3 Train Loss 244.66548 Test MSE 11.506524490051465 Test RE 7.93841770787307\n",
      "4 Train Loss 166.36124 Test MSE 10.492769824055324 Test RE 7.580658577437029\n",
      "5 Train Loss 123.79496 Test MSE 10.2434875090396 Test RE 7.490068424181558\n",
      "6 Train Loss 86.39284 Test MSE 10.113432545128893 Test RE 7.442368248410676\n",
      "7 Train Loss 66.80954 Test MSE 9.8769162698291 Test RE 7.354828496627602\n",
      "8 Train Loss 48.53649 Test MSE 9.90966965550685 Test RE 7.36701327912883\n",
      "9 Train Loss 33.961414 Test MSE 10.187904458136106 Test RE 7.469719536656631\n",
      "10 Train Loss 25.563234 Test MSE 10.534427657795721 Test RE 7.595691833844904\n",
      "11 Train Loss 21.96657 Test MSE 10.640458947663225 Test RE 7.633822265821145\n",
      "12 Train Loss 18.982718 Test MSE 10.806044603139929 Test RE 7.692991311486411\n",
      "13 Train Loss 16.578897 Test MSE 11.003271660143032 Test RE 7.762878372133849\n",
      "14 Train Loss 14.919261 Test MSE 11.125308829970153 Test RE 7.805808666547621\n",
      "15 Train Loss 13.465395 Test MSE 10.956701981204281 Test RE 7.7464333505840015\n",
      "16 Train Loss 12.409143 Test MSE 10.918345013575665 Test RE 7.732862195863496\n",
      "17 Train Loss 11.561122 Test MSE 10.733883093156413 Test RE 7.667261833969208\n",
      "18 Train Loss 11.040412 Test MSE 10.550127042202492 Test RE 7.601349630090812\n",
      "19 Train Loss 10.444105 Test MSE 10.226231130190651 Test RE 7.483756807215201\n",
      "20 Train Loss 9.851925 Test MSE 9.845256150266547 Test RE 7.343031208644702\n",
      "21 Train Loss 9.169629 Test MSE 9.165096728135207 Test RE 7.084845605827415\n",
      "22 Train Loss 8.225717 Test MSE 8.79684103531881 Test RE 6.941051010169779\n",
      "23 Train Loss 7.2645636 Test MSE 8.140275221681154 Test RE 6.677000493464481\n",
      "24 Train Loss 6.679197 Test MSE 7.716225753426754 Test RE 6.500762903439105\n",
      "25 Train Loss 5.60849 Test MSE 6.621897437922028 Test RE 6.022171081144082\n",
      "26 Train Loss 4.8598475 Test MSE 5.940924950288112 Test RE 5.704123201074964\n",
      "27 Train Loss 4.011653 Test MSE 5.034726166789176 Test RE 5.251093984659521\n",
      "28 Train Loss 3.1556447 Test MSE 4.583676888969035 Test RE 5.010359197652793\n",
      "29 Train Loss 2.4214098 Test MSE 3.768230932357436 Test RE 4.5428732433542\n",
      "30 Train Loss 1.9686048 Test MSE 3.093307469943765 Test RE 4.115981453846634\n",
      "31 Train Loss 1.6240903 Test MSE 2.0563977092229315 Test RE 3.35594952129979\n",
      "32 Train Loss 1.3572588 Test MSE 1.4492224621733991 Test RE 2.817275979426071\n",
      "33 Train Loss 1.0298039 Test MSE 1.0516153286491592 Test RE 2.3998843739806315\n",
      "34 Train Loss 0.7863394 Test MSE 0.827598400916065 Test RE 2.1289805090643794\n",
      "35 Train Loss 0.59521383 Test MSE 0.5649266216734663 Test RE 1.7589677808472166\n",
      "36 Train Loss 0.4619598 Test MSE 0.29870326431891925 Test RE 1.2790332905700075\n",
      "37 Train Loss 0.34680238 Test MSE 0.14800817324310755 Test RE 0.9003362021102916\n",
      "38 Train Loss 0.2592214 Test MSE 0.06967902585174761 Test RE 0.6177502064765155\n",
      "39 Train Loss 0.20457959 Test MSE 0.047455083336031004 Test RE 0.5098039947796336\n",
      "40 Train Loss 0.15966198 Test MSE 0.022931258122500818 Test RE 0.35438538696355576\n",
      "41 Train Loss 0.12342775 Test MSE 0.011996966758733671 Test RE 0.25632891061400587\n",
      "42 Train Loss 0.10343078 Test MSE 0.00849361315051918 Test RE 0.21567911977261744\n",
      "43 Train Loss 0.08652247 Test MSE 0.004542244905309329 Test RE 0.15772376564479795\n",
      "44 Train Loss 0.07094361 Test MSE 0.0028933360652276014 Test RE 0.1258813246357898\n",
      "45 Train Loss 0.057908468 Test MSE 0.001945809378900215 Test RE 0.10323144588823335\n",
      "46 Train Loss 0.050395314 Test MSE 0.0007887372626094804 Test RE 0.06572461389185093\n",
      "47 Train Loss 0.043916907 Test MSE 0.001408955032307051 Test RE 0.08784366161438549\n",
      "48 Train Loss 0.038312376 Test MSE 0.0008125569220729155 Test RE 0.06670966522819528\n",
      "49 Train Loss 0.033381194 Test MSE 0.0006423447118587889 Test RE 0.05931246050716949\n",
      "50 Train Loss 0.031150663 Test MSE 0.001036347480188233 Test RE 0.07533808242342319\n",
      "51 Train Loss 0.029031854 Test MSE 0.0011411388268368723 Test RE 0.07905532077564038\n",
      "52 Train Loss 0.026084794 Test MSE 0.0010116681046781182 Test RE 0.07443563421480702\n",
      "53 Train Loss 0.02377544 Test MSE 0.0014875689364528667 Test RE 0.09026105688235155\n",
      "54 Train Loss 0.021813791 Test MSE 0.0015880460627228335 Test RE 0.09325957065432808\n",
      "55 Train Loss 0.020828985 Test MSE 0.001718103607791521 Test RE 0.09700330669097441\n",
      "56 Train Loss 0.01953496 Test MSE 0.0011003584204041905 Test RE 0.07762988622208505\n",
      "57 Train Loss 0.018474385 Test MSE 0.0011207752799200176 Test RE 0.07834677708149534\n",
      "58 Train Loss 0.017502328 Test MSE 0.0011759973299397435 Test RE 0.08025369403576646\n",
      "59 Train Loss 0.016583208 Test MSE 0.0008939659048763398 Test RE 0.06997168651807745\n",
      "60 Train Loss 0.01592363 Test MSE 0.0011753890691570098 Test RE 0.08023293655302972\n",
      "61 Train Loss 0.015073822 Test MSE 0.0012448188539541096 Test RE 0.08256860415453725\n",
      "62 Train Loss 0.014636852 Test MSE 0.0014188514230894624 Test RE 0.08815162531271596\n",
      "63 Train Loss 0.013615891 Test MSE 0.00162585521279994 Test RE 0.09436322995783819\n",
      "64 Train Loss 0.013250514 Test MSE 0.0014621834974455448 Test RE 0.08948758811567262\n",
      "65 Train Loss 0.012389645 Test MSE 0.0010449067235487927 Test RE 0.0756485531049245\n",
      "66 Train Loss 0.011990637 Test MSE 0.0010882121974991666 Test RE 0.07720024147832266\n",
      "67 Train Loss 0.011437283 Test MSE 0.0010974516272397668 Test RE 0.07752728181521737\n",
      "68 Train Loss 0.010486379 Test MSE 0.0008585127794910933 Test RE 0.06857017315910403\n",
      "69 Train Loss 0.0100787 Test MSE 0.0007780272770615442 Test RE 0.0652768630398818\n",
      "70 Train Loss 0.009638161 Test MSE 0.0008232213493199319 Test RE 0.06714600469032163\n",
      "71 Train Loss 0.008801891 Test MSE 0.0005695539871455244 Test RE 0.055850788940196926\n",
      "72 Train Loss 0.008341833 Test MSE 0.0003523099726149424 Test RE 0.0439262705724731\n",
      "73 Train Loss 0.007665245 Test MSE 0.00023022629540095886 Test RE 0.03550907233923316\n",
      "74 Train Loss 0.007171155 Test MSE 0.0001600116947187449 Test RE 0.029603136419301915\n",
      "75 Train Loss 0.006874088 Test MSE 0.00014405670799469335 Test RE 0.02808850386030513\n",
      "76 Train Loss 0.0065234485 Test MSE 0.00013138034390842548 Test RE 0.026824217461660946\n",
      "77 Train Loss 0.0061573745 Test MSE 5.2467059274426504e-05 Test RE 0.016951386479663717\n",
      "78 Train Loss 0.0059441654 Test MSE 8.139231471837287e-05 Test RE 0.021113175796665624\n",
      "79 Train Loss 0.005791892 Test MSE 0.0001236042397971673 Test RE 0.026018277896413103\n",
      "80 Train Loss 0.005383978 Test MSE 5.7422294071478926e-05 Test RE 0.01773381336448272\n",
      "81 Train Loss 0.0050172033 Test MSE 4.158191264583007e-05 Test RE 0.01509086364119836\n",
      "82 Train Loss 0.0047035436 Test MSE 6.441954202270665e-05 Test RE 0.018783247475881188\n",
      "83 Train Loss 0.004417424 Test MSE 5.760023807270873e-05 Test RE 0.017761269466884545\n",
      "84 Train Loss 0.0042154333 Test MSE 7.011205784762646e-05 Test RE 0.01959558445198368\n",
      "85 Train Loss 0.004012984 Test MSE 9.796129291832872e-05 Test RE 0.02316269658452351\n",
      "86 Train Loss 0.003857781 Test MSE 0.00013570996497838192 Test RE 0.027262628980243037\n",
      "87 Train Loss 0.003792974 Test MSE 0.00012791079433168635 Test RE 0.026467654812902832\n",
      "88 Train Loss 0.0037058815 Test MSE 0.0001572425276868516 Test RE 0.029345862093167665\n",
      "89 Train Loss 0.0036318703 Test MSE 0.00013498996534004923 Test RE 0.027190212826126433\n",
      "90 Train Loss 0.0035075399 Test MSE 0.00010034728444154332 Test RE 0.023443080355373628\n",
      "91 Train Loss 0.0034594026 Test MSE 9.400592643043221e-05 Test RE 0.022690260447898077\n",
      "92 Train Loss 0.0034044615 Test MSE 9.54265027495857e-05 Test RE 0.02286106023527527\n",
      "93 Train Loss 0.0032319862 Test MSE 0.00011140380810162387 Test RE 0.0247008490867103\n",
      "94 Train Loss 0.0031271083 Test MSE 9.149388234168992e-05 Test RE 0.02238504089864379\n",
      "95 Train Loss 0.003033984 Test MSE 8.230058387218421e-05 Test RE 0.021230651534986114\n",
      "96 Train Loss 0.0029858141 Test MSE 9.83440530364492e-05 Test RE 0.023207903792867298\n",
      "97 Train Loss 0.0029173691 Test MSE 9.849050395726829e-05 Test RE 0.023225177610465587\n",
      "98 Train Loss 0.0028467579 Test MSE 0.00013179597857432916 Test RE 0.026866614484125438\n",
      "99 Train Loss 0.0027735778 Test MSE 0.00014521157201155085 Test RE 0.02820086811479676\n",
      "100 Train Loss 0.0027290613 Test MSE 0.00013471214317737118 Test RE 0.02716221839538654\n",
      "101 Train Loss 0.002686955 Test MSE 0.00013754760905200457 Test RE 0.02744658949473372\n",
      "102 Train Loss 0.0026047726 Test MSE 0.0001289401176403708 Test RE 0.026573936634512418\n",
      "103 Train Loss 0.0024963426 Test MSE 0.00015934722222133804 Test RE 0.02954160674899949\n",
      "104 Train Loss 0.0024423364 Test MSE 0.00019715099111469232 Test RE 0.03285952993129401\n",
      "105 Train Loss 0.0024151546 Test MSE 0.0001944743636922582 Test RE 0.03263570836813175\n",
      "106 Train Loss 0.00236556 Test MSE 0.00020660777253160976 Test RE 0.033638389254942634\n",
      "107 Train Loss 0.0022692052 Test MSE 0.00024291832660859171 Test RE 0.03647472316742093\n",
      "108 Train Loss 0.0021960195 Test MSE 0.00024928129431784344 Test RE 0.0369493420595062\n",
      "109 Train Loss 0.0021393304 Test MSE 0.0002165527894458165 Test RE 0.03443846257867158\n",
      "110 Train Loss 0.0021078987 Test MSE 0.00020369473293074778 Test RE 0.03340040736629779\n",
      "111 Train Loss 0.002087004 Test MSE 0.00019524001411920785 Test RE 0.03269988905940838\n",
      "112 Train Loss 0.0020665522 Test MSE 0.00017583962686515064 Test RE 0.031032748430511615\n",
      "113 Train Loss 0.0020432777 Test MSE 0.0001752808756063352 Test RE 0.03098340408152507\n",
      "114 Train Loss 0.002015487 Test MSE 0.0001894726481784174 Test RE 0.03221329328220306\n",
      "115 Train Loss 0.0019934801 Test MSE 0.0001964563508837005 Test RE 0.032801590347341904\n",
      "116 Train Loss 0.0019727764 Test MSE 0.00021256276027936696 Test RE 0.03411971969008498\n",
      "117 Train Loss 0.0019525806 Test MSE 0.0001918194352315753 Test RE 0.03241217447325339\n",
      "118 Train Loss 0.0019208606 Test MSE 0.0001533566521525913 Test RE 0.028980987102049122\n",
      "119 Train Loss 0.001882191 Test MSE 0.00014063193365833075 Test RE 0.027752610349850517\n",
      "120 Train Loss 0.001848493 Test MSE 0.00010948099149567635 Test RE 0.02448675438045497\n",
      "121 Train Loss 0.0018279438 Test MSE 0.00010072717631698126 Test RE 0.02348741350730941\n",
      "122 Train Loss 0.001781585 Test MSE 7.176994010599005e-05 Test RE 0.019825911167769956\n",
      "123 Train Loss 0.0017511528 Test MSE 5.883531274860822e-05 Test RE 0.017950679679067227\n",
      "124 Train Loss 0.0017187075 Test MSE 4.995017393193507e-05 Test RE 0.01653980429259792\n",
      "125 Train Loss 0.0016938122 Test MSE 4.156430376315357e-05 Test RE 0.015087668004331135\n",
      "126 Train Loss 0.001660118 Test MSE 4.144641635508697e-05 Test RE 0.015066256493929812\n",
      "127 Train Loss 0.001608422 Test MSE 3.290183722303808e-05 Test RE 0.013423690758293763\n",
      "128 Train Loss 0.0015561435 Test MSE 2.3596375725487495e-05 Test RE 0.011368011793148319\n",
      "129 Train Loss 0.0014978665 Test MSE 1.828093949633813e-05 Test RE 0.01000601431079983\n",
      "130 Train Loss 0.0014626416 Test MSE 1.8962880673743948e-05 Test RE 0.010190934731764042\n",
      "131 Train Loss 0.0014287047 Test MSE 2.1796222000595403e-05 Test RE 0.010925780603784317\n",
      "132 Train Loss 0.0013934567 Test MSE 1.8334871968611564e-05 Test RE 0.01002076332457495\n",
      "133 Train Loss 0.0013571614 Test MSE 1.9784095109168424e-05 Test RE 0.010409262474678074\n",
      "134 Train Loss 0.0013261216 Test MSE 2.3129385085768074e-05 Test RE 0.011254958745641176\n",
      "135 Train Loss 0.0012969272 Test MSE 3.449348017709947e-05 Test RE 0.013744545114494085\n",
      "136 Train Loss 0.0012801941 Test MSE 3.444331736451239e-05 Test RE 0.013734547342646428\n",
      "137 Train Loss 0.0012569046 Test MSE 3.6174003921831545e-05 Test RE 0.014075380847917388\n",
      "138 Train Loss 0.0012262502 Test MSE 4.4758129932164157e-05 Test RE 0.01565661348921528\n",
      "139 Train Loss 0.001209572 Test MSE 5.7812050079239964e-05 Test RE 0.01779389605029616\n",
      "140 Train Loss 0.0011941862 Test MSE 7.289588575785671e-05 Test RE 0.019980823006042845\n",
      "141 Train Loss 0.0011743681 Test MSE 8.942321948906446e-05 Test RE 0.022130285404268757\n",
      "142 Train Loss 0.0011311739 Test MSE 9.017163339947085e-05 Test RE 0.02222270045727939\n",
      "143 Train Loss 0.0011077714 Test MSE 0.00010958465390660471 Test RE 0.024498344316671215\n",
      "144 Train Loss 0.0010884348 Test MSE 0.00013494348400008675 Test RE 0.027185531195397655\n",
      "145 Train Loss 0.0010708873 Test MSE 0.00013272606712281195 Test RE 0.026961247111561514\n",
      "146 Train Loss 0.0010531939 Test MSE 0.0001273025987268444 Test RE 0.02640465507812477\n",
      "147 Train Loss 0.0010309799 Test MSE 0.0001365975278440073 Test RE 0.027351634465198872\n",
      "148 Train Loss 0.001012026 Test MSE 0.00015309659502327685 Test RE 0.028956404177072126\n",
      "149 Train Loss 0.0009959285 Test MSE 0.00014428106726263148 Test RE 0.028110368390081554\n",
      "150 Train Loss 0.00096161885 Test MSE 0.00011313188335822748 Test RE 0.02489168936498797\n",
      "151 Train Loss 0.0009413039 Test MSE 0.00010512346658291825 Test RE 0.02399449980617054\n",
      "152 Train Loss 0.00092916994 Test MSE 0.00010673357277229297 Test RE 0.024177555428356444\n",
      "153 Train Loss 0.0009087373 Test MSE 9.422828467957396e-05 Test RE 0.022717079962200373\n",
      "154 Train Loss 0.00088105537 Test MSE 7.176821697367336e-05 Test RE 0.01982567316511002\n",
      "155 Train Loss 0.00086261705 Test MSE 5.5163905370131296e-05 Test RE 0.017381584594749887\n",
      "156 Train Loss 0.0008461809 Test MSE 4.5618986750154394e-05 Test RE 0.015806462359888612\n",
      "157 Train Loss 0.000834297 Test MSE 4.1282933903455466e-05 Test RE 0.015036513244485801\n",
      "158 Train Loss 0.0008202702 Test MSE 3.779070846371228e-05 Test RE 0.014386474521279826\n",
      "159 Train Loss 0.0008035824 Test MSE 3.428006589574916e-05 Test RE 0.013701959770627612\n",
      "160 Train Loss 0.00079009717 Test MSE 2.4212480231836832e-05 Test RE 0.01151546563481611\n",
      "161 Train Loss 0.00078170485 Test MSE 2.5154600077949608e-05 Test RE 0.01173736398392173\n",
      "162 Train Loss 0.0007748071 Test MSE 2.0959347173059124e-05 Test RE 0.01071397774076789\n",
      "163 Train Loss 0.0007649177 Test MSE 1.9055858356834066e-05 Test RE 0.01021588797824427\n",
      "164 Train Loss 0.00075806753 Test MSE 1.6752429189782684e-05 Test RE 0.009578571810604165\n",
      "165 Train Loss 0.0007491574 Test MSE 1.5133498905806152e-05 Test RE 0.009103985112992864\n",
      "166 Train Loss 0.00073636096 Test MSE 1.695263309338407e-05 Test RE 0.009635637327540768\n",
      "167 Train Loss 0.00072718936 Test MSE 1.4316926437638608e-05 Test RE 0.0088549632026106\n",
      "168 Train Loss 0.00070922344 Test MSE 1.152700323030078e-05 Test RE 0.007945478768130745\n",
      "169 Train Loss 0.0006982902 Test MSE 1.0624200977108965e-05 Test RE 0.007627988029592461\n",
      "170 Train Loss 0.00068286713 Test MSE 1.2024293520107791e-05 Test RE 0.008115058381580048\n",
      "171 Train Loss 0.00067084713 Test MSE 1.2297327496069278e-05 Test RE 0.008206674975728495\n",
      "172 Train Loss 0.0006596126 Test MSE 9.7432167025244e-06 Test RE 0.007304879310564641\n",
      "173 Train Loss 0.0006484756 Test MSE 7.668852026205647e-06 Test RE 0.006480776479834136\n",
      "174 Train Loss 0.0006378814 Test MSE 7.22811964460544e-06 Test RE 0.006291794513670575\n",
      "175 Train Loss 0.000628168 Test MSE 7.540034346662519e-06 Test RE 0.006426115485845071\n",
      "176 Train Loss 0.00062112045 Test MSE 9.122283850550225e-06 Test RE 0.0070682785310959804\n",
      "177 Train Loss 0.00061458955 Test MSE 1.2242346317074677e-05 Test RE 0.008188308459185584\n",
      "178 Train Loss 0.0006049812 Test MSE 1.792327389390775e-05 Test RE 0.00990764723035438\n",
      "179 Train Loss 0.000598013 Test MSE 2.0655854220110802e-05 Test RE 0.010636125276391172\n",
      "180 Train Loss 0.00059243635 Test MSE 2.1939640091674933e-05 Test RE 0.010961667222617972\n",
      "181 Train Loss 0.0005834103 Test MSE 2.2385415331465123e-05 Test RE 0.01107246821643261\n",
      "182 Train Loss 0.0005778735 Test MSE 2.861078784678038e-05 Test RE 0.012517764377412454\n",
      "183 Train Loss 0.0005727974 Test MSE 3.1652370803517985e-05 Test RE 0.013166337591753367\n",
      "184 Train Loss 0.00056594866 Test MSE 3.0159619318630576e-05 Test RE 0.012852120588266592\n",
      "185 Train Loss 0.0005604742 Test MSE 2.822458741444079e-05 Test RE 0.012432992312393552\n",
      "186 Train Loss 0.0005540586 Test MSE 2.557712175759624e-05 Test RE 0.011835529697574676\n",
      "187 Train Loss 0.00054793444 Test MSE 2.154906056882357e-05 Test RE 0.01086365674633927\n",
      "188 Train Loss 0.0005407209 Test MSE 1.787213143634213e-05 Test RE 0.009893501840274975\n",
      "189 Train Loss 0.00053441594 Test MSE 1.7427885402142118e-05 Test RE 0.009769767123703098\n",
      "190 Train Loss 0.00052866427 Test MSE 1.7657615381996487e-05 Test RE 0.009833947613676619\n",
      "191 Train Loss 0.0005239622 Test MSE 1.5691064634119596e-05 Test RE 0.009270177924055606\n",
      "192 Train Loss 0.0005217593 Test MSE 1.5691824770006295e-05 Test RE 0.00927040246298083\n",
      "193 Train Loss 0.0005191869 Test MSE 1.550302624815361e-05 Test RE 0.009214464585086108\n",
      "194 Train Loss 0.0005140098 Test MSE 1.6577745788249906e-05 Test RE 0.009528501394483064\n",
      "195 Train Loss 0.000508217 Test MSE 1.4839768489740527e-05 Test RE 0.009015201266569114\n",
      "196 Train Loss 0.00050317583 Test MSE 1.2737475759357373e-05 Test RE 0.00835225123308821\n",
      "197 Train Loss 0.00049749704 Test MSE 1.1184870027039001e-05 Test RE 0.007826675624686804\n",
      "198 Train Loss 0.00049268646 Test MSE 1.2051839648293157e-05 Test RE 0.008124348347761167\n",
      "199 Train Loss 0.00048358503 Test MSE 1.1536884197143018e-05 Test RE 0.007948883477636663\n",
      "200 Train Loss 0.00047594344 Test MSE 1.1266948274283097e-05 Test RE 0.007855340490027432\n",
      "201 Train Loss 0.00047096104 Test MSE 1.2489943061065385e-05 Test RE 0.008270696670968213\n",
      "202 Train Loss 0.000459584 Test MSE 1.6949192278666797e-05 Test RE 0.00963465942266238\n",
      "203 Train Loss 0.00044728746 Test MSE 1.4563042461099564e-05 Test RE 0.00893074978759758\n",
      "204 Train Loss 0.00043703034 Test MSE 1.1868989259121964e-05 Test RE 0.008062481524719504\n",
      "205 Train Loss 0.00042694007 Test MSE 9.902102248574477e-06 Test RE 0.007364199873817541\n",
      "206 Train Loss 0.00042010198 Test MSE 8.762499393375226e-06 Test RE 0.006927489313378488\n",
      "207 Train Loss 0.00041638772 Test MSE 7.937661981914701e-06 Test RE 0.006593380882084757\n",
      "208 Train Loss 0.00041059512 Test MSE 8.344164650873182e-06 Test RE 0.006760102743797624\n",
      "209 Train Loss 0.00040449842 Test MSE 8.486551851307413e-06 Test RE 0.006817536920560154\n",
      "210 Train Loss 0.00040191272 Test MSE 8.690954480218785e-06 Test RE 0.006899150226802478\n",
      "211 Train Loss 0.0003986796 Test MSE 9.104431887231554e-06 Test RE 0.00706135896767992\n",
      "212 Train Loss 0.0003955332 Test MSE 9.29380906174387e-06 Test RE 0.007134421059072795\n",
      "213 Train Loss 0.00039066808 Test MSE 1.1049163266890584e-05 Test RE 0.007779049938600312\n",
      "214 Train Loss 0.0003872283 Test MSE 1.129593309134554e-05 Test RE 0.007865438138311542\n",
      "215 Train Loss 0.00038363988 Test MSE 1.13119554747645e-05 Test RE 0.007871014411109498\n",
      "216 Train Loss 0.00038045907 Test MSE 1.102418500096962e-05 Test RE 0.007770252117778707\n",
      "217 Train Loss 0.00037377712 Test MSE 1.1971243663480337e-05 Test RE 0.008097137221975732\n",
      "218 Train Loss 0.00036933908 Test MSE 1.4165457466128512e-05 Test RE 0.00880799716623746\n",
      "219 Train Loss 0.0003663647 Test MSE 1.7533310136257085e-05 Test RE 0.00979927219962667\n",
      "220 Train Loss 0.00036197764 Test MSE 2.2498787049530634e-05 Test RE 0.011100471256687248\n",
      "221 Train Loss 0.0003584478 Test MSE 2.490108690116851e-05 Test RE 0.011678068436469397\n",
      "222 Train Loss 0.00035537645 Test MSE 2.588020196277765e-05 Test RE 0.01190544668780639\n",
      "223 Train Loss 0.00035231237 Test MSE 2.883763168909585e-05 Test RE 0.012567290652414822\n",
      "224 Train Loss 0.00034821418 Test MSE 3.1024241283559044e-05 Test RE 0.013035042416741591\n",
      "225 Train Loss 0.00034500947 Test MSE 3.269126622521291e-05 Test RE 0.013380666153370946\n",
      "226 Train Loss 0.0003408491 Test MSE 3.714784195115543e-05 Test RE 0.014263583820439673\n",
      "227 Train Loss 0.0003364451 Test MSE 3.635368267576796e-05 Test RE 0.014110294237454094\n",
      "228 Train Loss 0.0003312551 Test MSE 3.137232139853873e-05 Test RE 0.013107962547115633\n",
      "229 Train Loss 0.00032612984 Test MSE 2.8847935490022493e-05 Test RE 0.012569535623458758\n",
      "230 Train Loss 0.00031892984 Test MSE 2.7231456650744047e-05 Test RE 0.012212295393206002\n",
      "231 Train Loss 0.0003127304 Test MSE 3.785442750080032e-05 Test RE 0.014398597953953962\n",
      "232 Train Loss 0.0003071585 Test MSE 3.184139861211122e-05 Test RE 0.013205593722523593\n",
      "233 Train Loss 0.0003021967 Test MSE 3.121633729673995e-05 Test RE 0.013075335353689795\n",
      "234 Train Loss 0.00029698663 Test MSE 3.057295875013764e-05 Test RE 0.012939890439065883\n",
      "235 Train Loss 0.00029093237 Test MSE 3.071656285641983e-05 Test RE 0.012970244786937533\n",
      "236 Train Loss 0.00028632334 Test MSE 2.8674028559549515e-05 Test RE 0.012531591248879108\n",
      "237 Train Loss 0.00028203812 Test MSE 2.7566059549477918e-05 Test RE 0.01228709479980184\n",
      "238 Train Loss 0.0002771915 Test MSE 2.6495088121988066e-05 Test RE 0.012046046857725394\n",
      "239 Train Loss 0.00027155294 Test MSE 2.2897855379819775e-05 Test RE 0.01119848488326183\n",
      "240 Train Loss 0.0002668919 Test MSE 1.6379369582634618e-05 Test RE 0.009471318805283183\n",
      "241 Train Loss 0.0002643462 Test MSE 1.728495051559807e-05 Test RE 0.009729621243881223\n",
      "242 Train Loss 0.0002625027 Test MSE 1.560263147268245e-05 Test RE 0.009244018148085656\n",
      "243 Train Loss 0.00026013431 Test MSE 1.454404723112504e-05 Test RE 0.008924923498193313\n",
      "244 Train Loss 0.00025741156 Test MSE 1.3672261395287513e-05 Test RE 0.008653305579627598\n",
      "245 Train Loss 0.00025529315 Test MSE 1.420343779612449e-05 Test RE 0.008819797233568641\n",
      "246 Train Loss 0.0002528507 Test MSE 1.365126362547374e-05 Test RE 0.008646658181274074\n",
      "247 Train Loss 0.00025101582 Test MSE 1.4697501905053781e-05 Test RE 0.008971883520408494\n",
      "248 Train Loss 0.0002493475 Test MSE 1.4047317457603803e-05 Test RE 0.008771190887232409\n",
      "249 Train Loss 0.0002458741 Test MSE 1.5729937321020755e-05 Test RE 0.009281653685053895\n",
      "250 Train Loss 0.0002428154 Test MSE 1.7252578186161295e-05 Test RE 0.009720505854275046\n",
      "251 Train Loss 0.00024036552 Test MSE 1.8406802185520216e-05 Test RE 0.010040400497908296\n",
      "252 Train Loss 0.00023779461 Test MSE 1.6106455024396896e-05 Test RE 0.009392081362123912\n",
      "253 Train Loss 0.00023686222 Test MSE 1.54131831426308e-05 Test RE 0.009187725966886544\n",
      "254 Train Loss 0.0002343571 Test MSE 1.6359287704418724e-05 Test RE 0.009465510883167813\n",
      "255 Train Loss 0.00023070177 Test MSE 1.1263657757443376e-05 Test RE 0.007854193328566768\n",
      "256 Train Loss 0.000228374 Test MSE 9.964779634911864e-06 Test RE 0.007387469715559168\n",
      "257 Train Loss 0.00022587607 Test MSE 9.52206970503798e-06 Test RE 0.007221502105604541\n",
      "258 Train Loss 0.0002246205 Test MSE 9.3272925500579e-06 Test RE 0.00714726135560175\n",
      "259 Train Loss 0.00022312952 Test MSE 9.048382448928741e-06 Test RE 0.007039589557343646\n",
      "260 Train Loss 0.00022079318 Test MSE 9.723620324011842e-06 Test RE 0.007297529518641175\n",
      "261 Train Loss 0.00021903853 Test MSE 9.082899243160433e-06 Test RE 0.007053003710601112\n",
      "262 Train Loss 0.00021636527 Test MSE 8.86190288716697e-06 Test RE 0.006966671894701661\n",
      "263 Train Loss 0.0002146815 Test MSE 8.908040936381912e-06 Test RE 0.00698478377055613\n",
      "264 Train Loss 0.00021306596 Test MSE 8.413664714740543e-06 Test RE 0.00678819742585786\n",
      "265 Train Loss 0.00021038708 Test MSE 9.127545925835484e-06 Test RE 0.00707031686120207\n",
      "266 Train Loss 0.00020818786 Test MSE 8.753196646010653e-06 Test RE 0.006923811036573972\n",
      "267 Train Loss 0.00020649558 Test MSE 9.237495087780297e-06 Test RE 0.0071127734193620566\n",
      "268 Train Loss 0.00020493555 Test MSE 9.331777212182564e-06 Test RE 0.007148979389006823\n",
      "269 Train Loss 0.00020242858 Test MSE 8.936628629291536e-06 Test RE 0.006995982580095479\n",
      "270 Train Loss 0.00019971465 Test MSE 8.626509396826822e-06 Test RE 0.006873523374681509\n",
      "271 Train Loss 0.0001980085 Test MSE 9.122632882215357e-06 Test RE 0.007068413751040238\n",
      "272 Train Loss 0.00019553474 Test MSE 9.28693332936536e-06 Test RE 0.00713178148224575\n",
      "273 Train Loss 0.00019091491 Test MSE 9.955049475796143e-06 Test RE 0.007383862068716751\n",
      "274 Train Loss 0.00018848489 Test MSE 9.740254387088368e-06 Test RE 0.007303768742953779\n",
      "275 Train Loss 0.0001858336 Test MSE 9.831321851657724e-06 Test RE 0.00733783295794378\n",
      "276 Train Loss 0.00018360106 Test MSE 9.715079984615156e-06 Test RE 0.007294324073160358\n",
      "277 Train Loss 0.00018181549 Test MSE 8.56399968213679e-06 Test RE 0.006848574513205896\n",
      "278 Train Loss 0.00018021638 Test MSE 9.338504475684941e-06 Test RE 0.007151555768757333\n",
      "279 Train Loss 0.0001796243 Test MSE 8.990220016752118e-06 Test RE 0.007016928062940146\n",
      "280 Train Loss 0.00017954802 Test MSE 9.032971829246511e-06 Test RE 0.007033592315941909\n",
      "281 Train Loss 0.0001786599 Test MSE 9.140617415839335e-06 Test RE 0.007075377723796035\n",
      "282 Train Loss 0.00017826236 Test MSE 9.598460754821788e-06 Test RE 0.007250411583115946\n",
      "283 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "284 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "285 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "286 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "287 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "288 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "289 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "290 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "291 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "292 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "293 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "294 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "295 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "296 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "297 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "298 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "299 Train Loss 0.0001782607 Test MSE 9.598567173722635e-06 Test RE 0.007250451775950634\n",
      "Training time: 155.07\n",
      "KG_tanh_low\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 5106.298 Test MSE 8.294201757628864 Test RE 6.73983340447214\n",
      "1 Train Loss 1784.145 Test MSE 8.615179495524504 Test RE 6.869008111033106\n",
      "2 Train Loss 760.9849 Test MSE 8.422843726924462 Test RE 6.791899258771179\n",
      "3 Train Loss 239.15883 Test MSE 9.292397692384748 Test RE 7.133879317493846\n",
      "4 Train Loss 76.42255 Test MSE 8.241418298092318 Test RE 6.718353367312815\n",
      "5 Train Loss 38.146267 Test MSE 7.467992862402836 Test RE 6.395342547632931\n",
      "6 Train Loss 21.410328 Test MSE 7.285197222312299 Test RE 6.316587560528652\n",
      "7 Train Loss 15.2658 Test MSE 6.1184085440827545 Test RE 5.78870076795224\n",
      "8 Train Loss 9.618481 Test MSE 3.832243659913163 Test RE 4.581296723159313\n",
      "9 Train Loss 6.695408 Test MSE 2.4795860139080776 Test RE 3.685118460256085\n",
      "10 Train Loss 4.5231266 Test MSE 0.8965264005184346 Test RE 2.2158655498211175\n",
      "11 Train Loss 2.874463 Test MSE 0.228498426673931 Test RE 1.1186738111117298\n",
      "12 Train Loss 2.158619 Test MSE 0.1311551321617794 Test RE 0.847528885462479\n",
      "13 Train Loss 1.7280705 Test MSE 0.10380203527590375 Test RE 0.7539886328853364\n",
      "14 Train Loss 1.2944882 Test MSE 0.08755910541353706 Test RE 0.6924884304034611\n",
      "15 Train Loss 0.9468694 Test MSE 0.07012241827577446 Test RE 0.6197125717586048\n",
      "16 Train Loss 0.7114804 Test MSE 0.06542039083407142 Test RE 0.5985748029326241\n",
      "17 Train Loss 0.54463243 Test MSE 0.04982705672662184 Test RE 0.5223895506457203\n",
      "18 Train Loss 0.40051556 Test MSE 0.046026152929723244 Test RE 0.5020699193076174\n",
      "19 Train Loss 0.3362979 Test MSE 0.03910415913551678 Test RE 0.4627786766413623\n",
      "20 Train Loss 0.27029783 Test MSE 0.03239978702256213 Test RE 0.4212432373382612\n",
      "21 Train Loss 0.22582927 Test MSE 0.026783891025976583 Test RE 0.382999933625567\n",
      "22 Train Loss 0.1852052 Test MSE 0.01970395881352403 Test RE 0.32850244746399043\n",
      "23 Train Loss 0.14595015 Test MSE 0.009988997751119213 Test RE 0.23389601453205017\n",
      "24 Train Loss 0.12288594 Test MSE 0.009068038894209582 Test RE 0.2228530340238279\n",
      "25 Train Loss 0.1070992 Test MSE 0.006578871974498234 Test RE 0.1898180823410697\n",
      "26 Train Loss 0.0907723 Test MSE 0.005375134900183255 Test RE 0.17157600370823772\n",
      "27 Train Loss 0.07584496 Test MSE 0.005128166417949274 Test RE 0.16758800042693275\n",
      "28 Train Loss 0.06504034 Test MSE 0.00419784361681162 Test RE 0.15162645867198915\n",
      "29 Train Loss 0.058048747 Test MSE 0.0037379101749035787 Test RE 0.14307913120590904\n",
      "30 Train Loss 0.051833697 Test MSE 0.0034783630675768356 Test RE 0.13802231888936908\n",
      "31 Train Loss 0.046606913 Test MSE 0.0038258170267295873 Test RE 0.1447517963156316\n",
      "32 Train Loss 0.040962458 Test MSE 0.0031339073256005908 Test RE 0.1310101484740262\n",
      "33 Train Loss 0.03511251 Test MSE 0.0026342346855605645 Test RE 0.12011274603697077\n",
      "34 Train Loss 0.03279895 Test MSE 0.002412258408289274 Test RE 0.11494068432601479\n",
      "35 Train Loss 0.028900472 Test MSE 0.002254872016163329 Test RE 0.11112782450989907\n",
      "36 Train Loss 0.026441649 Test MSE 0.0022213166935014647 Test RE 0.1102978645471744\n",
      "37 Train Loss 0.02433588 Test MSE 0.0026920051333010125 Test RE 0.12142267766424868\n",
      "38 Train Loss 0.023139335 Test MSE 0.0026012246239634335 Test RE 0.11935779642746283\n",
      "39 Train Loss 0.020980068 Test MSE 0.0017613425918275188 Test RE 0.09821634821712358\n",
      "40 Train Loss 0.018943653 Test MSE 0.0012027755728743234 Test RE 0.08116226600028657\n",
      "41 Train Loss 0.016883574 Test MSE 0.0007316356451934398 Test RE 0.06330081361198724\n",
      "42 Train Loss 0.015536579 Test MSE 0.0004361233018755171 Test RE 0.048872719944630987\n",
      "43 Train Loss 0.014761979 Test MSE 0.00034972436393517295 Test RE 0.04376478593138783\n",
      "44 Train Loss 0.013762734 Test MSE 0.00041948270498682965 Test RE 0.04793126532394509\n",
      "45 Train Loss 0.0128027145 Test MSE 0.0002457050926232131 Test RE 0.03668334607716776\n",
      "46 Train Loss 0.0123520745 Test MSE 0.00019507274462791916 Test RE 0.0326858784431465\n",
      "47 Train Loss 0.011987314 Test MSE 0.0002073345279061695 Test RE 0.03369749985679745\n",
      "48 Train Loss 0.011635614 Test MSE 0.00015500263941220656 Test RE 0.029136099446743828\n",
      "49 Train Loss 0.011215923 Test MSE 0.00013818806281669496 Test RE 0.027510414148092972\n",
      "50 Train Loss 0.010591839 Test MSE 0.00015551950383057488 Test RE 0.02918463694242246\n",
      "51 Train Loss 0.010283255 Test MSE 0.0001794530261967537 Test RE 0.031349979216952484\n",
      "52 Train Loss 0.009798663 Test MSE 0.00014579884134929545 Test RE 0.028257836006690473\n",
      "53 Train Loss 0.009444157 Test MSE 0.00014476413145234955 Test RE 0.028157386913002905\n",
      "54 Train Loss 0.009226013 Test MSE 0.00022047592393715463 Test RE 0.034749011090086435\n",
      "55 Train Loss 0.008957481 Test MSE 0.00019107023629887947 Test RE 0.032348815606853216\n",
      "56 Train Loss 0.008801622 Test MSE 0.00017676764881888548 Test RE 0.031114530831744196\n",
      "57 Train Loss 0.008501165 Test MSE 0.00019933558273419572 Test RE 0.03304108339332388\n",
      "58 Train Loss 0.0082713645 Test MSE 0.0002302504624283336 Test RE 0.03551093599734144\n",
      "59 Train Loss 0.007566859 Test MSE 0.0002777823324181208 Test RE 0.03900445142021595\n",
      "60 Train Loss 0.0074060145 Test MSE 0.0002887283267301002 Test RE 0.0397655103941854\n",
      "61 Train Loss 0.0072676647 Test MSE 0.00031750966624311444 Test RE 0.041700411418847595\n",
      "62 Train Loss 0.0068728747 Test MSE 0.0002497664126002704 Test RE 0.03698527754588439\n",
      "63 Train Loss 0.0067322827 Test MSE 0.0002668688002961472 Test RE 0.03823056933796677\n",
      "64 Train Loss 0.0065939715 Test MSE 0.0002703406972277807 Test RE 0.0384784508386254\n",
      "65 Train Loss 0.0064170146 Test MSE 0.000278892555162366 Test RE 0.03908231894812974\n",
      "66 Train Loss 0.006023342 Test MSE 0.00026872539117916966 Test RE 0.03836332278381683\n",
      "67 Train Loss 0.0057987985 Test MSE 0.0003037422221691198 Test RE 0.040786312928940735\n",
      "68 Train Loss 0.005690896 Test MSE 0.0002629743417187996 Test RE 0.037950591774753406\n",
      "69 Train Loss 0.005530295 Test MSE 0.00025724044744888187 Test RE 0.03753457408786515\n",
      "70 Train Loss 0.0053078067 Test MSE 0.00024874191276872754 Test RE 0.03690934590606794\n",
      "71 Train Loss 0.0049468405 Test MSE 0.00023618760191280297 Test RE 0.03596585693142422\n",
      "72 Train Loss 0.004860674 Test MSE 0.0002636312061292393 Test RE 0.037997959220636104\n",
      "73 Train Loss 0.0048062624 Test MSE 0.00027021232321843876 Test RE 0.038469313813371715\n",
      "74 Train Loss 0.004740438 Test MSE 0.0002646630197624154 Test RE 0.03807224580719347\n",
      "75 Train Loss 0.004665876 Test MSE 0.0002540063305167597 Test RE 0.03729787888026154\n",
      "76 Train Loss 0.004562892 Test MSE 0.00022483936080260644 Test RE 0.03509118506443966\n",
      "77 Train Loss 0.004400209 Test MSE 0.00020255191753752041 Test RE 0.03330658022582881\n",
      "78 Train Loss 0.004232539 Test MSE 0.00020613605940520717 Test RE 0.03359996684487524\n",
      "79 Train Loss 0.0041536367 Test MSE 0.00020578433145024505 Test RE 0.03357128895799866\n",
      "80 Train Loss 0.0040306267 Test MSE 0.00023985032333326373 Test RE 0.036243657539192835\n",
      "81 Train Loss 0.003896384 Test MSE 0.0002533874177458925 Test RE 0.03725241109133425\n",
      "82 Train Loss 0.003768369 Test MSE 0.00026019128842759095 Test RE 0.03774924238276371\n",
      "83 Train Loss 0.003675677 Test MSE 0.00023793234875078574 Test RE 0.03609845460548348\n",
      "84 Train Loss 0.0036218911 Test MSE 0.00023455401006272297 Test RE 0.035841262169966\n",
      "85 Train Loss 0.0035624083 Test MSE 0.00020298595524244462 Test RE 0.03334224657667686\n",
      "86 Train Loss 0.0034570245 Test MSE 0.00020176313321494316 Test RE 0.033241665176885746\n",
      "87 Train Loss 0.003316186 Test MSE 0.00020865779517209132 Test RE 0.03380486228538152\n",
      "88 Train Loss 0.003172645 Test MSE 0.0002453396858436973 Test RE 0.03665605862745867\n",
      "89 Train Loss 0.0030733107 Test MSE 0.00023588577129002335 Test RE 0.0359428687066134\n",
      "90 Train Loss 0.0030135612 Test MSE 0.00022438279941794682 Test RE 0.03505553867783251\n",
      "91 Train Loss 0.002943183 Test MSE 0.0002157274914678682 Test RE 0.03437277622828285\n",
      "92 Train Loss 0.0028612514 Test MSE 0.00022256276390689126 Test RE 0.03491307625933491\n",
      "93 Train Loss 0.0027855146 Test MSE 0.00024987162409561057 Test RE 0.0369930665568488\n",
      "94 Train Loss 0.0026910612 Test MSE 0.00024198126394851723 Test RE 0.03640430417726629\n",
      "95 Train Loss 0.0026391002 Test MSE 0.0002855778039418771 Test RE 0.03954796023819684\n",
      "96 Train Loss 0.0025879263 Test MSE 0.00031080130565856127 Test RE 0.04125753543351585\n",
      "97 Train Loss 0.0025251415 Test MSE 0.0003239790716405572 Test RE 0.04212310167460533\n",
      "98 Train Loss 0.0024872788 Test MSE 0.0003323659442009375 Test RE 0.042664840147082536\n",
      "99 Train Loss 0.0024105103 Test MSE 0.000349073960205883 Test RE 0.043724070971750024\n",
      "100 Train Loss 0.0023644732 Test MSE 0.00038424428382992577 Test RE 0.04587389030830809\n",
      "101 Train Loss 0.002330476 Test MSE 0.0003668929065031659 Test RE 0.0448261584206339\n",
      "102 Train Loss 0.002272554 Test MSE 0.0003515618054515828 Test RE 0.043879604763955596\n",
      "103 Train Loss 0.0022413116 Test MSE 0.00035729118039333805 Test RE 0.04423571099305123\n",
      "104 Train Loss 0.0022036857 Test MSE 0.00035825370984207656 Test RE 0.04429525561575577\n",
      "105 Train Loss 0.0021263473 Test MSE 0.00033948012920696915 Test RE 0.04311903605463693\n",
      "106 Train Loss 0.002064276 Test MSE 0.0003291756218765852 Test RE 0.04245958024228948\n",
      "107 Train Loss 0.0020137154 Test MSE 0.0003196935964834229 Test RE 0.04184357985145223\n",
      "108 Train Loss 0.0019572205 Test MSE 0.00035345108082961087 Test RE 0.043997350175817955\n",
      "109 Train Loss 0.0019207002 Test MSE 0.00033347715137353165 Test RE 0.042736101834695804\n",
      "110 Train Loss 0.0018830884 Test MSE 0.00034568988077914335 Test RE 0.0435116144348316\n",
      "111 Train Loss 0.0018290787 Test MSE 0.00034571854899822103 Test RE 0.043513418616416874\n",
      "112 Train Loss 0.0017861975 Test MSE 0.0003148966951517992 Test RE 0.041528468504724664\n",
      "113 Train Loss 0.0017232861 Test MSE 0.0002744812354521757 Test RE 0.03877199909749055\n",
      "114 Train Loss 0.0016733168 Test MSE 0.00026601965466590936 Test RE 0.038169698255140924\n",
      "115 Train Loss 0.0016190711 Test MSE 0.0002497638734249639 Test RE 0.03698508954554209\n",
      "116 Train Loss 0.0015625448 Test MSE 0.00022643118335301403 Test RE 0.03521518564004656\n",
      "117 Train Loss 0.0015129151 Test MSE 0.00020189930303465129 Test RE 0.03325288067499097\n",
      "118 Train Loss 0.0014665687 Test MSE 0.0001581867095652038 Test RE 0.029433835627586964\n",
      "119 Train Loss 0.0014157435 Test MSE 0.00015803891135541544 Test RE 0.02942008199163415\n",
      "120 Train Loss 0.0013603059 Test MSE 0.00014726812715194876 Test RE 0.02839986306006546\n",
      "121 Train Loss 0.001326214 Test MSE 0.0001293384646174164 Test RE 0.02661495367526364\n",
      "122 Train Loss 0.0013099489 Test MSE 0.00013047267285338574 Test RE 0.02673139625412298\n",
      "123 Train Loss 0.0012950944 Test MSE 0.00012563884955614152 Test RE 0.026231543120927722\n",
      "124 Train Loss 0.0012736471 Test MSE 0.00012065206666832427 Test RE 0.025705688870615757\n",
      "125 Train Loss 0.0012541008 Test MSE 0.00011710986647153635 Test RE 0.02532553373871682\n",
      "126 Train Loss 0.0012390071 Test MSE 0.00010863508485860627 Test RE 0.02439197229133219\n",
      "127 Train Loss 0.0012247998 Test MSE 0.00010627738076845091 Test RE 0.024125831224388473\n",
      "128 Train Loss 0.0012065938 Test MSE 9.898286269962965e-05 Test RE 0.023283157127339683\n",
      "129 Train Loss 0.0011973714 Test MSE 9.461383025891653e-05 Test RE 0.02276350725842867\n",
      "130 Train Loss 0.0011787011 Test MSE 9.967525413729386e-05 Test RE 0.02336444879951807\n",
      "131 Train Loss 0.0011644769 Test MSE 9.983230666060827e-05 Test RE 0.023382848558695803\n",
      "132 Train Loss 0.0011473759 Test MSE 9.581517145194684e-05 Test RE 0.02290756906291788\n",
      "133 Train Loss 0.0011347971 Test MSE 8.954616304451514e-05 Test RE 0.02214549309564663\n",
      "134 Train Loss 0.0011308662 Test MSE 8.878189821186926e-05 Test RE 0.022050786135855545\n",
      "135 Train Loss 0.0011238238 Test MSE 8.936554169144877e-05 Test RE 0.022123147258161415\n",
      "136 Train Loss 0.00111581 Test MSE 8.593328076799467e-05 Test RE 0.02169414608792228\n",
      "137 Train Loss 0.0011009979 Test MSE 7.918280585769378e-05 Test RE 0.020824630656182987\n",
      "138 Train Loss 0.0010886313 Test MSE 7.707991475209875e-05 Test RE 0.020546245681212594\n",
      "139 Train Loss 0.0010773134 Test MSE 7.82059871414359e-05 Test RE 0.02069578314705658\n",
      "140 Train Loss 0.0010652491 Test MSE 7.54401395376406e-05 Test RE 0.020326523458604473\n",
      "141 Train Loss 0.0010509064 Test MSE 8.012896630946454e-05 Test RE 0.020948678619407916\n",
      "142 Train Loss 0.0010381392 Test MSE 8.194705559864188e-05 Test RE 0.021185003540512698\n",
      "143 Train Loss 0.0010188954 Test MSE 8.194576232221104e-05 Test RE 0.021184836370541405\n",
      "144 Train Loss 0.0009850127 Test MSE 8.526652678354148e-05 Test RE 0.02160982005430234\n",
      "145 Train Loss 0.0009649003 Test MSE 8.453022241583092e-05 Test RE 0.0215163138176962\n",
      "146 Train Loss 0.0009443571 Test MSE 8.989450836239499e-05 Test RE 0.022188525598434043\n",
      "147 Train Loss 0.00093406794 Test MSE 8.835580293925857e-05 Test RE 0.021997807790011918\n",
      "148 Train Loss 0.00092928234 Test MSE 8.655528598452309e-05 Test RE 0.02177251818041309\n",
      "149 Train Loss 0.0009241973 Test MSE 8.281009486139134e-05 Test RE 0.021296268079691642\n",
      "150 Train Loss 0.0009175254 Test MSE 8.600593978402371e-05 Test RE 0.02170331565667795\n",
      "151 Train Loss 0.000907162 Test MSE 8.178681399060356e-05 Test RE 0.021164280525110015\n",
      "152 Train Loss 0.00089837296 Test MSE 7.898146436666716e-05 Test RE 0.020798137967036175\n",
      "153 Train Loss 0.0008873818 Test MSE 7.379525477236867e-05 Test RE 0.020103704047984842\n",
      "154 Train Loss 0.0008750509 Test MSE 6.896275013361708e-05 Test RE 0.019434311082091406\n",
      "155 Train Loss 0.0008653388 Test MSE 6.984061046819601e-05 Test RE 0.01955761431777428\n",
      "156 Train Loss 0.0008504144 Test MSE 6.456159742823309e-05 Test RE 0.01880394610542007\n",
      "157 Train Loss 0.000836875 Test MSE 6.506478792092723e-05 Test RE 0.018877082476211615\n",
      "158 Train Loss 0.0008275613 Test MSE 6.159205283748485e-05 Test RE 0.018366406981818073\n",
      "159 Train Loss 0.0008199843 Test MSE 5.914842277377121e-05 Test RE 0.017998381301486177\n",
      "160 Train Loss 0.0008060157 Test MSE 5.4129443136131274e-05 Test RE 0.017217839045668714\n",
      "161 Train Loss 0.00079767156 Test MSE 5.269615997165533e-05 Test RE 0.0169883558112613\n",
      "162 Train Loss 0.000787602 Test MSE 5.396241173835636e-05 Test RE 0.017191253313420016\n",
      "163 Train Loss 0.0007784792 Test MSE 5.241417730872169e-05 Test RE 0.016942841607484445\n",
      "164 Train Loss 0.00077151024 Test MSE 5.3072825569044736e-05 Test RE 0.01704896302810075\n",
      "165 Train Loss 0.0007622239 Test MSE 5.3118227715348546e-05 Test RE 0.017056253897112\n",
      "166 Train Loss 0.0007460134 Test MSE 5.480818923741105e-05 Test RE 0.017325452694109938\n",
      "167 Train Loss 0.00073898386 Test MSE 5.50162249188321e-05 Test RE 0.017358302699346063\n",
      "168 Train Loss 0.0007321938 Test MSE 5.4792071376977076e-05 Test RE 0.017322904993067264\n",
      "169 Train Loss 0.00072648755 Test MSE 5.154870231513543e-05 Test RE 0.01680237729346572\n",
      "170 Train Loss 0.00071698235 Test MSE 5.198809244413422e-05 Test RE 0.01687383528115714\n",
      "171 Train Loss 0.0007095438 Test MSE 5.25395097492151e-05 Test RE 0.01696308631888203\n",
      "172 Train Loss 0.00070407434 Test MSE 5.072159607283773e-05 Test RE 0.016667033933449104\n",
      "173 Train Loss 0.00069669646 Test MSE 5.33805178494071e-05 Test RE 0.017098312699722746\n",
      "174 Train Loss 0.0006864764 Test MSE 5.784455924374495e-05 Test RE 0.017798898323997312\n",
      "175 Train Loss 0.00067901076 Test MSE 5.8556171907495556e-05 Test RE 0.0179080460543158\n",
      "176 Train Loss 0.0006742535 Test MSE 5.555855481283945e-05 Test RE 0.01744364879825288\n",
      "177 Train Loss 0.0006698149 Test MSE 5.489516847540988e-05 Test RE 0.01733919477620828\n",
      "178 Train Loss 0.0006617058 Test MSE 5.383489483084283e-05 Test RE 0.01717092923980937\n",
      "179 Train Loss 0.0006470529 Test MSE 5.3444055071208165e-05 Test RE 0.01710848547671421\n",
      "180 Train Loss 0.0006207095 Test MSE 5.17481687832892e-05 Test RE 0.0168348541048575\n",
      "181 Train Loss 0.0005989997 Test MSE 5.06694341571281e-05 Test RE 0.016658461568623346\n",
      "182 Train Loss 0.0005865315 Test MSE 4.9236823761890414e-05 Test RE 0.01642127516962583\n",
      "183 Train Loss 0.0005780208 Test MSE 4.921893757401203e-05 Test RE 0.016418292232572292\n",
      "184 Train Loss 0.0005720077 Test MSE 4.709556530060383e-05 Test RE 0.016060234089673976\n",
      "185 Train Loss 0.0005613567 Test MSE 4.755074551490522e-05 Test RE 0.016137658811301595\n",
      "186 Train Loss 0.0005554102 Test MSE 4.934068840316243e-05 Test RE 0.01643858631187974\n",
      "187 Train Loss 0.0005470857 Test MSE 5.1816794480335944e-05 Test RE 0.016846013155050413\n",
      "188 Train Loss 0.000537897 Test MSE 5.267129979395485e-05 Test RE 0.016984348086914968\n",
      "189 Train Loss 0.0005336186 Test MSE 5.215495980286403e-05 Test RE 0.01690089375179563\n",
      "190 Train Loss 0.0005257972 Test MSE 5.416279396789761e-05 Test RE 0.017223142451701035\n",
      "191 Train Loss 0.00051838456 Test MSE 5.198278836616552e-05 Test RE 0.016872974483841053\n",
      "192 Train Loss 0.00050813204 Test MSE 5.0296904964999524e-05 Test RE 0.016597110856097656\n",
      "193 Train Loss 0.0004975567 Test MSE 5.220397343999423e-05 Test RE 0.016908833358573648\n",
      "194 Train Loss 0.00048947055 Test MSE 5.276703472392453e-05 Test RE 0.016999776386603015\n",
      "195 Train Loss 0.0004823145 Test MSE 5.142991899726385e-05 Test RE 0.016783007327673672\n",
      "196 Train Loss 0.00047383667 Test MSE 5.011880525633195e-05 Test RE 0.016567699881646608\n",
      "197 Train Loss 0.00046563207 Test MSE 5.012529809304886e-05 Test RE 0.016568773010643228\n",
      "198 Train Loss 0.0004607156 Test MSE 4.7955709296412e-05 Test RE 0.016206230945005274\n",
      "199 Train Loss 0.00045479287 Test MSE 4.726437254095681e-05 Test RE 0.016088991136659583\n",
      "200 Train Loss 0.00044965156 Test MSE 4.708552362271678e-05 Test RE 0.01605852182341323\n",
      "201 Train Loss 0.00044628992 Test MSE 4.665599893859896e-05 Test RE 0.015985109303522337\n",
      "202 Train Loss 0.00044353193 Test MSE 4.690551795214356e-05 Test RE 0.016027796955770106\n",
      "203 Train Loss 0.0004374357 Test MSE 4.468312905486892e-05 Test RE 0.015643490151777007\n",
      "204 Train Loss 0.00043224762 Test MSE 4.397243771269733e-05 Test RE 0.015518585568621422\n",
      "205 Train Loss 0.00042632114 Test MSE 4.4416262714172516e-05 Test RE 0.015596705458765223\n",
      "206 Train Loss 0.000423198 Test MSE 4.420727555818156e-05 Test RE 0.015559969428733129\n",
      "207 Train Loss 0.00041882132 Test MSE 4.38349140072306e-05 Test RE 0.015494299393323273\n",
      "208 Train Loss 0.00041646796 Test MSE 4.367363665953554e-05 Test RE 0.015465769826497267\n",
      "209 Train Loss 0.00041417257 Test MSE 4.25318023402251e-05 Test RE 0.015262256829765872\n",
      "210 Train Loss 0.0004110832 Test MSE 4.272433662210105e-05 Test RE 0.01529676265212648\n",
      "211 Train Loss 0.00040893306 Test MSE 4.3302571495187775e-05 Test RE 0.015399928616445334\n",
      "212 Train Loss 0.00040656017 Test MSE 4.415601497930819e-05 Test RE 0.015550945525060674\n",
      "213 Train Loss 0.00040405343 Test MSE 4.457222599794988e-05 Test RE 0.015624064601674596\n",
      "214 Train Loss 0.00040154508 Test MSE 4.487066958247483e-05 Test RE 0.015676284592712638\n",
      "215 Train Loss 0.00039804372 Test MSE 4.498301576759931e-05 Test RE 0.015695897290385275\n",
      "216 Train Loss 0.00039502565 Test MSE 4.3357895330887505e-05 Test RE 0.015409763034346272\n",
      "217 Train Loss 0.00039130825 Test MSE 4.28935438689078e-05 Test RE 0.015327023688743795\n",
      "218 Train Loss 0.0003876569 Test MSE 4.326211866052583e-05 Test RE 0.015392733705082163\n",
      "219 Train Loss 0.0003834247 Test MSE 4.403226997982093e-05 Test RE 0.015529139867733726\n",
      "220 Train Loss 0.00037892934 Test MSE 4.601666474469799e-05 Test RE 0.01587520832490594\n",
      "221 Train Loss 0.00037332115 Test MSE 4.8458467138699585e-05 Test RE 0.016290960855592892\n",
      "222 Train Loss 0.00037051082 Test MSE 4.9019813049790565e-05 Test RE 0.016385046919652306\n",
      "223 Train Loss 0.0003684505 Test MSE 5.034387582186422e-05 Test RE 0.01660485883379946\n",
      "224 Train Loss 0.00036683027 Test MSE 5.112426407992362e-05 Test RE 0.016733061174380694\n",
      "225 Train Loss 0.00036467414 Test MSE 5.1664307354369676e-05 Test RE 0.016821207560492143\n",
      "226 Train Loss 0.0003590809 Test MSE 5.3841959890386945e-05 Test RE 0.017172055922214706\n",
      "227 Train Loss 0.00035502767 Test MSE 5.316799026902535e-05 Test RE 0.017064241400590714\n",
      "228 Train Loss 0.00035304594 Test MSE 5.562598562599704e-05 Test RE 0.017454231171624847\n",
      "229 Train Loss 0.0003516373 Test MSE 5.638566989020999e-05 Test RE 0.017573013240693613\n",
      "230 Train Loss 0.00034945388 Test MSE 5.98202616625386e-05 Test RE 0.01810031021778884\n",
      "231 Train Loss 0.0003458698 Test MSE 6.086528527606295e-05 Test RE 0.018257726412273495\n",
      "232 Train Loss 0.00034356094 Test MSE 6.122084119810584e-05 Test RE 0.01831097671558152\n",
      "233 Train Loss 0.0003403702 Test MSE 6.041927262930263e-05 Test RE 0.0181907083265024\n",
      "234 Train Loss 0.00033869478 Test MSE 5.928570265052071e-05 Test RE 0.018019255768287255\n",
      "235 Train Loss 0.00033725292 Test MSE 6.015986230922526e-05 Test RE 0.018151615390807833\n",
      "236 Train Loss 0.00033620108 Test MSE 5.8689132872692436e-05 Test RE 0.01792836603848037\n",
      "237 Train Loss 0.00033460275 Test MSE 5.9836480631637016e-05 Test RE 0.01810276380515168\n",
      "238 Train Loss 0.00033232907 Test MSE 6.0710395579375795e-05 Test RE 0.018234480524947323\n",
      "239 Train Loss 0.00032859916 Test MSE 5.7575205017259825e-05 Test RE 0.017757409524837363\n",
      "240 Train Loss 0.00032675985 Test MSE 5.675166341545741e-05 Test RE 0.017629953293779668\n",
      "241 Train Loss 0.00032441708 Test MSE 5.687638548641562e-05 Test RE 0.01764931517138252\n",
      "242 Train Loss 0.00032249902 Test MSE 5.6728869506470185e-05 Test RE 0.017626412464442128\n",
      "243 Train Loss 0.00031928695 Test MSE 5.719764586788428e-05 Test RE 0.017699090148910857\n",
      "244 Train Loss 0.00031749744 Test MSE 5.760992677073468e-05 Test RE 0.01776276317894565\n",
      "245 Train Loss 0.0003145932 Test MSE 5.8441807811660444e-05 Test RE 0.017890549705131063\n",
      "246 Train Loss 0.00031222374 Test MSE 5.859488475810612e-05 Test RE 0.017913964789629422\n",
      "247 Train Loss 0.0003099008 Test MSE 5.9154875866557995e-05 Test RE 0.017999363086387752\n",
      "248 Train Loss 0.0003077681 Test MSE 6.080895167014988e-05 Test RE 0.018249275275829195\n",
      "249 Train Loss 0.00030607378 Test MSE 6.048626732713027e-05 Test RE 0.01820079073327642\n",
      "250 Train Loss 0.00030566112 Test MSE 6.165644834612218e-05 Test RE 0.01837600566451879\n",
      "251 Train Loss 0.0003036489 Test MSE 5.8817095607580375e-05 Test RE 0.017947900435064935\n",
      "252 Train Loss 0.0003020304 Test MSE 5.662767968780192e-05 Test RE 0.017610684938188733\n",
      "253 Train Loss 0.00030102886 Test MSE 5.69613028001329e-05 Test RE 0.017662485606090097\n",
      "254 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "255 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "256 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "257 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "258 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "259 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "260 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "261 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "262 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "263 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "264 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "265 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "266 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "267 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "268 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "269 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "270 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "271 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "272 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "273 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "274 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "275 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "276 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "277 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "278 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "279 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "280 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "281 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "282 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "283 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "284 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "285 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "286 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "287 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "288 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "289 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "290 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "291 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "292 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "293 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "294 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "295 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "296 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "297 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "298 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "299 Train Loss 0.00030038197 Test MSE 5.664080039799119e-05 Test RE 0.017612725029815587\n",
      "Training time: 148.80\n",
      "KG_tanh_low\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 7297.453 Test MSE 7.493458615684778 Test RE 6.406237283019415\n",
      "1 Train Loss 4322.3384 Test MSE 10.353852562885253 Test RE 7.53030994956575\n",
      "2 Train Loss 1725.7542 Test MSE 11.696574760969431 Test RE 8.003707607728147\n",
      "3 Train Loss 226.98456 Test MSE 14.036998878265626 Test RE 8.767968818108706\n",
      "4 Train Loss 87.18389 Test MSE 14.974216205114239 Test RE 9.05594786740899\n",
      "5 Train Loss 52.91841 Test MSE 15.63389899200534 Test RE 9.253275972780326\n",
      "6 Train Loss 37.012344 Test MSE 15.963838173336388 Test RE 9.350407157703776\n",
      "7 Train Loss 28.690432 Test MSE 15.560866285347636 Test RE 9.231637644815361\n",
      "8 Train Loss 25.374249 Test MSE 15.526164085125783 Test RE 9.221338187873144\n",
      "9 Train Loss 23.238129 Test MSE 15.372077206267186 Test RE 9.175466259822255\n",
      "10 Train Loss 21.515804 Test MSE 15.246765749979337 Test RE 9.137991042076075\n",
      "11 Train Loss 19.67625 Test MSE 14.885947571572192 Test RE 9.029217332391054\n",
      "12 Train Loss 18.284887 Test MSE 14.454300052450792 Test RE 8.897344304327413\n",
      "13 Train Loss 16.943394 Test MSE 13.80663199200552 Test RE 8.695723833845443\n",
      "14 Train Loss 15.380086 Test MSE 13.027889639811965 Test RE 8.44693008442335\n",
      "15 Train Loss 13.958973 Test MSE 12.470920048699274 Test RE 8.264395860896082\n",
      "16 Train Loss 12.392448 Test MSE 11.724329096595465 Test RE 8.013197820567827\n",
      "17 Train Loss 11.004407 Test MSE 10.789861440360426 Test RE 7.687228630417479\n",
      "18 Train Loss 9.691624 Test MSE 9.816148525934768 Test RE 7.332168291291475\n",
      "19 Train Loss 8.7932825 Test MSE 8.587007395114995 Test RE 6.857767901463255\n",
      "20 Train Loss 7.8965945 Test MSE 7.345168488420413 Test RE 6.342533141809152\n",
      "21 Train Loss 7.086279 Test MSE 6.896065547024526 Test RE 6.1455754430846605\n",
      "22 Train Loss 6.586046 Test MSE 6.561517217351917 Test RE 5.99465232852689\n",
      "23 Train Loss 6.0213466 Test MSE 6.073563285132036 Test RE 5.76744742933965\n",
      "24 Train Loss 5.6185403 Test MSE 5.685162356393293 Test RE 5.579988448971368\n",
      "25 Train Loss 5.241586 Test MSE 5.132465437452547 Test RE 5.30181879982126\n",
      "26 Train Loss 4.768952 Test MSE 4.205098549830973 Test RE 4.798991195869724\n",
      "27 Train Loss 4.1841903 Test MSE 3.660709414442028 Test RE 4.477591733518095\n",
      "28 Train Loss 3.559958 Test MSE 2.853009325793621 Test RE 3.9528784460632496\n",
      "29 Train Loss 2.945449 Test MSE 2.1286267777919914 Test RE 3.4143781980986336\n",
      "30 Train Loss 1.9870514 Test MSE 1.2491658852384062 Test RE 2.615603570895646\n",
      "31 Train Loss 1.2496899 Test MSE 0.8889024897205221 Test RE 2.206423758808412\n",
      "32 Train Loss 0.7917551 Test MSE 0.8136692006712779 Test RE 2.110988185198891\n",
      "33 Train Loss 0.6095252 Test MSE 0.7090473526789556 Test RE 1.9706045625259894\n",
      "34 Train Loss 0.46002665 Test MSE 0.570493610632442 Test RE 1.767613282872161\n",
      "35 Train Loss 0.36852875 Test MSE 0.5338269985279577 Test RE 1.7098662154884499\n",
      "36 Train Loss 0.3318931 Test MSE 0.50054170044599 Test RE 1.6557013251528216\n",
      "37 Train Loss 0.28283185 Test MSE 0.40928907245933616 Test RE 1.497190072881751\n",
      "38 Train Loss 0.23470615 Test MSE 0.34082871134406717 Test RE 1.366249293246109\n",
      "39 Train Loss 0.19440676 Test MSE 0.23784691684635426 Test RE 1.1413284079736414\n",
      "40 Train Loss 0.1640879 Test MSE 0.1841237611885687 Test RE 1.0041920595922686\n",
      "41 Train Loss 0.13704555 Test MSE 0.1782300194022505 Test RE 0.9879894138760008\n",
      "42 Train Loss 0.12001877 Test MSE 0.13725453027240422 Test RE 0.8670121986963379\n",
      "43 Train Loss 0.10765987 Test MSE 0.09796352760093191 Test RE 0.7324771340373043\n",
      "44 Train Loss 0.091627344 Test MSE 0.0856915418495693 Test RE 0.685063521426886\n",
      "45 Train Loss 0.07242253 Test MSE 0.05907136494320037 Test RE 0.568787923757054\n",
      "46 Train Loss 0.056768186 Test MSE 0.04017208539946488 Test RE 0.4690553055282022\n",
      "47 Train Loss 0.05052779 Test MSE 0.027755018120199378 Test RE 0.3898814940522716\n",
      "48 Train Loss 0.045433007 Test MSE 0.018977652907306033 Test RE 0.32239115169052873\n",
      "49 Train Loss 0.03998322 Test MSE 0.015740023606606243 Test RE 0.29360574806537865\n",
      "50 Train Loss 0.0355868 Test MSE 0.01268473576283794 Test RE 0.2635740054428585\n",
      "51 Train Loss 0.031579737 Test MSE 0.012111351127449384 Test RE 0.25754798810707047\n",
      "52 Train Loss 0.027753595 Test MSE 0.007128546214428692 Test RE 0.19758881142404633\n",
      "53 Train Loss 0.025876325 Test MSE 0.006135883679631155 Test RE 0.18331602141728942\n",
      "54 Train Loss 0.022920651 Test MSE 0.0026852329010488636 Test RE 0.12126985098899823\n",
      "55 Train Loss 0.02083011 Test MSE 0.0031867246101936904 Test RE 0.13210952504216314\n",
      "56 Train Loss 0.017918482 Test MSE 0.001527114097714864 Test RE 0.09145292644842141\n",
      "57 Train Loss 0.016889289 Test MSE 0.00135059470353442 Test RE 0.08600513565032834\n",
      "58 Train Loss 0.015278092 Test MSE 0.0006174100109847958 Test RE 0.05814986322716642\n",
      "59 Train Loss 0.014089511 Test MSE 0.0005510745586515862 Test RE 0.05493726627897025\n",
      "60 Train Loss 0.012530737 Test MSE 0.00045018029162036946 Test RE 0.04965409869451594\n",
      "61 Train Loss 0.011649673 Test MSE 0.0003608912448147152 Test RE 0.044458011839337785\n",
      "62 Train Loss 0.011226352 Test MSE 0.00036464561569262517 Test RE 0.04468866305694218\n",
      "63 Train Loss 0.010435725 Test MSE 0.00033045245219256905 Test RE 0.042541848194990003\n",
      "64 Train Loss 0.009478608 Test MSE 0.00021043288215420616 Test RE 0.03394834959052972\n",
      "65 Train Loss 0.00900967 Test MSE 0.00022974480908342744 Test RE 0.03547192175902063\n",
      "66 Train Loss 0.008499444 Test MSE 0.00019856990730789332 Test RE 0.03297756466268017\n",
      "67 Train Loss 0.00784041 Test MSE 0.00013022778330924533 Test RE 0.026706297841127637\n",
      "68 Train Loss 0.0075396164 Test MSE 0.00014510819456651263 Test RE 0.028190828099730725\n",
      "69 Train Loss 0.007023855 Test MSE 0.00013933411181145557 Test RE 0.027624256047085457\n",
      "70 Train Loss 0.0066742455 Test MSE 0.00011811463156818511 Test RE 0.025433944182371843\n",
      "71 Train Loss 0.0064185634 Test MSE 0.00010747713229603448 Test RE 0.024261625743527554\n",
      "72 Train Loss 0.006213316 Test MSE 0.00010112613772907704 Test RE 0.023533882154420153\n",
      "73 Train Loss 0.0058936174 Test MSE 0.00011794858045433407 Test RE 0.025416059775969113\n",
      "74 Train Loss 0.00564415 Test MSE 0.00012952484749865977 Test RE 0.02663412347887287\n",
      "75 Train Loss 0.0054150457 Test MSE 0.00012261917907589436 Test RE 0.025914394519518637\n",
      "76 Train Loss 0.0050424016 Test MSE 0.00011812758178644602 Test RE 0.02543533844697842\n",
      "77 Train Loss 0.004915706 Test MSE 9.88259083802391e-05 Test RE 0.02326469008265815\n",
      "78 Train Loss 0.0046245595 Test MSE 9.511562465960056e-05 Test RE 0.022823791760386576\n",
      "79 Train Loss 0.0044066305 Test MSE 9.676191888970923e-05 Test RE 0.0230204654402705\n",
      "80 Train Loss 0.0042409394 Test MSE 8.297439295115214e-05 Test RE 0.021317383877151676\n",
      "81 Train Loss 0.004025701 Test MSE 9.925830493429798e-05 Test RE 0.023315529950929528\n",
      "82 Train Loss 0.0038815984 Test MSE 0.00010988994749550301 Test RE 0.024532445741183618\n",
      "83 Train Loss 0.0037583208 Test MSE 0.0001482367811991088 Test RE 0.028493109830131126\n",
      "84 Train Loss 0.0036496676 Test MSE 0.00011835863829549995 Test RE 0.025460201943658032\n",
      "85 Train Loss 0.0034592007 Test MSE 0.00010752074677022186 Test RE 0.024266547956737706\n",
      "86 Train Loss 0.0033020114 Test MSE 0.00011379303140021949 Test RE 0.024964317510100725\n",
      "87 Train Loss 0.0032361906 Test MSE 0.00011297586340638657 Test RE 0.024874519403916818\n",
      "88 Train Loss 0.0031757085 Test MSE 0.00010778941151058133 Test RE 0.024296846752236572\n",
      "89 Train Loss 0.0029234549 Test MSE 9.403524711215778e-05 Test RE 0.0226937987462879\n",
      "90 Train Loss 0.0027748814 Test MSE 8.895152592762642e-05 Test RE 0.022071841326375245\n",
      "91 Train Loss 0.0027296876 Test MSE 7.647875752761211e-05 Test RE 0.020465967302185306\n",
      "92 Train Loss 0.002684853 Test MSE 7.010015230366806e-05 Test RE 0.019593920644045814\n",
      "93 Train Loss 0.0025975264 Test MSE 6.866655871481112e-05 Test RE 0.01939253149675725\n",
      "94 Train Loss 0.002455319 Test MSE 7.23332813388301e-05 Test RE 0.019903568486375835\n",
      "95 Train Loss 0.0023719023 Test MSE 6.767628960857662e-05 Test RE 0.019252189781824414\n",
      "96 Train Loss 0.0023056448 Test MSE 6.928884048944876e-05 Test RE 0.01948020446318469\n",
      "97 Train Loss 0.0022328324 Test MSE 7.254047314936148e-05 Test RE 0.019932054042662278\n",
      "98 Train Loss 0.0021441022 Test MSE 7.615267356012227e-05 Test RE 0.020422290124017792\n",
      "99 Train Loss 0.0020477884 Test MSE 6.43605961500393e-05 Test RE 0.018774651883033424\n",
      "100 Train Loss 0.0019851387 Test MSE 7.338849899190652e-05 Test RE 0.020048222179721714\n",
      "101 Train Loss 0.0019007755 Test MSE 7.883309751629128e-05 Test RE 0.02077859411101688\n",
      "102 Train Loss 0.0018783039 Test MSE 8.2477537763983e-05 Test RE 0.021253463215133505\n",
      "103 Train Loss 0.0018539052 Test MSE 7.29144464098746e-05 Test RE 0.01998336658923147\n",
      "104 Train Loss 0.0017941309 Test MSE 7.532538768969177e-05 Test RE 0.020311058257907494\n",
      "105 Train Loss 0.0017075804 Test MSE 7.21809100161505e-05 Test RE 0.01988259382705674\n",
      "106 Train Loss 0.0016511369 Test MSE 7.343373751563137e-05 Test RE 0.020054400342943556\n",
      "107 Train Loss 0.0015951225 Test MSE 6.548166518462722e-05 Test RE 0.018937459693212033\n",
      "108 Train Loss 0.0015443077 Test MSE 7.121923205889143e-05 Test RE 0.019749700192711682\n",
      "109 Train Loss 0.0014883907 Test MSE 7.456992145524019e-05 Test RE 0.02020894802132666\n",
      "110 Train Loss 0.0014469889 Test MSE 6.783075427291563e-05 Test RE 0.019274147901421474\n",
      "111 Train Loss 0.0014162883 Test MSE 6.491490329883513e-05 Test RE 0.018855327116664846\n",
      "112 Train Loss 0.0013826508 Test MSE 6.414588890549644e-05 Test RE 0.018743309559179615\n",
      "113 Train Loss 0.0013627888 Test MSE 5.461177483472842e-05 Test RE 0.01729438048808819\n",
      "114 Train Loss 0.0013335956 Test MSE 4.9104516553678794e-05 Test RE 0.01639919703340946\n",
      "115 Train Loss 0.0013107273 Test MSE 5.1613524489919556e-05 Test RE 0.016812938417207365\n",
      "116 Train Loss 0.0012632089 Test MSE 3.446427552817175e-05 Test RE 0.013738725324592707\n",
      "117 Train Loss 0.0012195518 Test MSE 3.231519608581937e-05 Test RE 0.013303480023103198\n",
      "118 Train Loss 0.0011822591 Test MSE 3.6059660590554996e-05 Test RE 0.01405311762580452\n",
      "119 Train Loss 0.0011574031 Test MSE 3.56075562724721e-05 Test RE 0.013964743035799936\n",
      "120 Train Loss 0.001139956 Test MSE 3.658364145395747e-05 Test RE 0.014154851908737822\n",
      "121 Train Loss 0.0011211791 Test MSE 3.562396135574054e-05 Test RE 0.013967959577673682\n",
      "122 Train Loss 0.0010938455 Test MSE 3.279284812633079e-05 Test RE 0.013401438968410324\n",
      "123 Train Loss 0.0010567106 Test MSE 3.0013134207007858e-05 Test RE 0.012820871256736997\n",
      "124 Train Loss 0.0010182352 Test MSE 3.0090335015192367e-05 Test RE 0.012837349808187055\n",
      "125 Train Loss 0.0009978913 Test MSE 3.4388190258531006e-05 Test RE 0.013723551754768163\n",
      "126 Train Loss 0.0009880898 Test MSE 3.255789925239206e-05 Test RE 0.013353344441574115\n",
      "127 Train Loss 0.000979434 Test MSE 3.482205861054842e-05 Test RE 0.013809853934813529\n",
      "128 Train Loss 0.0009674299 Test MSE 3.2281081645873186e-05 Test RE 0.013296456073599595\n",
      "129 Train Loss 0.00095150946 Test MSE 2.9241867732262502e-05 Test RE 0.01265506610914147\n",
      "130 Train Loss 0.00093179586 Test MSE 2.4958136676843424e-05 Test RE 0.011691438335353356\n",
      "131 Train Loss 0.00091058505 Test MSE 3.0966532145266e-05 Test RE 0.013022913333535682\n",
      "132 Train Loss 0.00089373207 Test MSE 2.66327846927737e-05 Test RE 0.012077308309433299\n",
      "133 Train Loss 0.0008846476 Test MSE 2.3378601983303394e-05 Test RE 0.011315431832633598\n",
      "134 Train Loss 0.00087222847 Test MSE 2.2136471670501406e-05 Test RE 0.01101072875254885\n",
      "135 Train Loss 0.0008605479 Test MSE 1.930556684276633e-05 Test RE 0.010282604761864107\n",
      "136 Train Loss 0.00085096096 Test MSE 2.0247089951987937e-05 Test RE 0.010530358826187724\n",
      "137 Train Loss 0.00083691854 Test MSE 1.760862311713642e-05 Test RE 0.009820295656486453\n",
      "138 Train Loss 0.0008205848 Test MSE 1.976253774257156e-05 Test RE 0.01040358980057916\n",
      "139 Train Loss 0.0008053494 Test MSE 1.813784563706537e-05 Test RE 0.009966776391111007\n",
      "140 Train Loss 0.0007913212 Test MSE 1.7466687050409588e-05 Test RE 0.009780636838951372\n",
      "141 Train Loss 0.000782555 Test MSE 1.687544450632029e-05 Test RE 0.009613675848712065\n",
      "142 Train Loss 0.00077492686 Test MSE 1.6279159734052036e-05 Test RE 0.009442301340139955\n",
      "143 Train Loss 0.00076769193 Test MSE 1.587816686786603e-05 Test RE 0.00932528352471093\n",
      "144 Train Loss 0.0007583189 Test MSE 1.7137484204927756e-05 Test RE 0.009688028278444632\n",
      "145 Train Loss 0.0007474278 Test MSE 1.741774636057591e-05 Test RE 0.009766924825746164\n",
      "146 Train Loss 0.0007316703 Test MSE 1.7246657164619272e-05 Test RE 0.009718837690161164\n",
      "147 Train Loss 0.0007169216 Test MSE 1.6239172394727262e-05 Test RE 0.009430697404132904\n",
      "148 Train Loss 0.00070338434 Test MSE 1.8386709103456864e-05 Test RE 0.01003491889183308\n",
      "149 Train Loss 0.0006849188 Test MSE 1.4982134653383107e-05 Test RE 0.00905834196858267\n",
      "150 Train Loss 0.0006740425 Test MSE 1.565902621523712e-05 Test RE 0.009260709044414606\n",
      "151 Train Loss 0.0006636073 Test MSE 1.612180364942812e-05 Test RE 0.009396555382261147\n",
      "152 Train Loss 0.0006543878 Test MSE 1.6277992150028008e-05 Test RE 0.009441962720762122\n",
      "153 Train Loss 0.0006466555 Test MSE 1.7780365615329755e-05 Test RE 0.009868069682799874\n",
      "154 Train Loss 0.00064176123 Test MSE 1.9456348678105494e-05 Test RE 0.010322681659714108\n",
      "155 Train Loss 0.0006338061 Test MSE 1.9460797918370117e-05 Test RE 0.010323861877704966\n",
      "156 Train Loss 0.00062593754 Test MSE 1.9200383752476413e-05 Test RE 0.010254554993904652\n",
      "157 Train Loss 0.00062561303 Test MSE 1.95810933274207e-05 Test RE 0.010355720794903002\n",
      "158 Train Loss 0.0006182189 Test MSE 2.1527605120503312e-05 Test RE 0.01085824716776241\n",
      "159 Train Loss 0.00061052025 Test MSE 2.1546694686885433e-05 Test RE 0.010863060366866085\n",
      "160 Train Loss 0.00060039974 Test MSE 1.98238166647525e-05 Test RE 0.010419706843410242\n",
      "161 Train Loss 0.0005944378 Test MSE 2.1459444610126238e-05 Test RE 0.010841043897327316\n",
      "162 Train Loss 0.0005847785 Test MSE 1.934457002293815e-05 Test RE 0.010292986532328309\n",
      "163 Train Loss 0.0005730133 Test MSE 2.232970755604499e-05 Test RE 0.011058682302834551\n",
      "164 Train Loss 0.00056297047 Test MSE 2.2523898032711654e-05 Test RE 0.011106664168621673\n",
      "165 Train Loss 0.00055570755 Test MSE 2.217692405828837e-05 Test RE 0.011020784713023753\n",
      "166 Train Loss 0.0005451236 Test MSE 2.1890295399998057e-05 Test RE 0.010949333278995292\n",
      "167 Train Loss 0.00053652166 Test MSE 1.696913570150775e-05 Test RE 0.0096403261114834\n",
      "168 Train Loss 0.00052899314 Test MSE 1.594019534742424e-05 Test RE 0.00934348050386867\n",
      "169 Train Loss 0.00052066165 Test MSE 1.4123311284086805e-05 Test RE 0.008794884282742093\n",
      "170 Train Loss 0.0005151944 Test MSE 1.2962105966767662e-05 Test RE 0.008425576920714061\n",
      "171 Train Loss 0.00050815387 Test MSE 1.1920116282616143e-05 Test RE 0.008079827893300643\n",
      "172 Train Loss 0.00050448487 Test MSE 1.2133593489041619e-05 Test RE 0.008151857595626531\n",
      "173 Train Loss 0.0004976619 Test MSE 1.1706675763725428e-05 Test RE 0.008007162808396967\n",
      "174 Train Loss 0.0004903632 Test MSE 1.1419244203863774e-05 Test RE 0.007908252809848542\n",
      "175 Train Loss 0.00047927292 Test MSE 1.2094770944178117e-05 Test RE 0.008138805839290246\n",
      "176 Train Loss 0.0004671962 Test MSE 1.1726670445397412e-05 Test RE 0.008013997898524456\n",
      "177 Train Loss 0.00045758125 Test MSE 1.2107413637240261e-05 Test RE 0.008143058484882637\n",
      "178 Train Loss 0.00045097424 Test MSE 1.2077388539989372e-05 Test RE 0.008132955258066673\n",
      "179 Train Loss 0.00044683504 Test MSE 1.3803846782432371e-05 Test RE 0.008694846696146355\n",
      "180 Train Loss 0.00044408208 Test MSE 1.5615455019009368e-05 Test RE 0.009247816121153088\n",
      "181 Train Loss 0.00044094675 Test MSE 1.4587440876415929e-05 Test RE 0.008938227790750077\n",
      "182 Train Loss 0.00043803838 Test MSE 1.5387205018631206e-05 Test RE 0.0091799799828893\n",
      "183 Train Loss 0.0004355099 Test MSE 1.503999856652014e-05 Test RE 0.009075817649003712\n",
      "184 Train Loss 0.00043296945 Test MSE 1.3690265914634151e-05 Test RE 0.008659001321741416\n",
      "185 Train Loss 0.00042915822 Test MSE 1.3905657274439843e-05 Test RE 0.008726852280349426\n",
      "186 Train Loss 0.00042434817 Test MSE 1.4141758415536045e-05 Test RE 0.008800626117651509\n",
      "187 Train Loss 0.00041783717 Test MSE 1.2560875910023854e-05 Test RE 0.008294148879137143\n",
      "188 Train Loss 0.00040437194 Test MSE 1.2298761498775298e-05 Test RE 0.008207153455750496\n",
      "189 Train Loss 0.00038666485 Test MSE 1.300099229599174e-05 Test RE 0.008438205825187464\n",
      "190 Train Loss 0.0003743623 Test MSE 1.0358986186753062e-05 Test RE 0.007532176548884154\n",
      "191 Train Loss 0.00036739794 Test MSE 9.518019196568132e-06 Test RE 0.007219965996980504\n",
      "192 Train Loss 0.00036265346 Test MSE 9.434712138958036e-06 Test RE 0.007188299953230599\n",
      "193 Train Loss 0.00035810188 Test MSE 1.0164739343737965e-05 Test RE 0.007461222431952197\n",
      "194 Train Loss 0.00035489706 Test MSE 1.0332064728898968e-05 Test RE 0.007522382680631855\n",
      "195 Train Loss 0.000353123 Test MSE 1.0335527490273302e-05 Test RE 0.007523643127345198\n",
      "196 Train Loss 0.000351105 Test MSE 1.0392105950911766e-05 Test RE 0.007544207882257015\n",
      "197 Train Loss 0.00034778265 Test MSE 1.0761165926396428e-05 Test RE 0.007676999776388731\n",
      "198 Train Loss 0.00034385602 Test MSE 9.014674131605948e-06 Test RE 0.00702646488386239\n",
      "199 Train Loss 0.0003381535 Test MSE 8.73330600803802e-06 Test RE 0.006915939778164605\n",
      "200 Train Loss 0.00033122004 Test MSE 8.248882868038708e-06 Test RE 0.006721395214380325\n",
      "201 Train Loss 0.00032549282 Test MSE 8.333287699496032e-06 Test RE 0.006755695275246039\n",
      "202 Train Loss 0.00032099508 Test MSE 9.446881978463003e-06 Test RE 0.007192934554867915\n",
      "203 Train Loss 0.00031569542 Test MSE 9.939193038465686e-06 Test RE 0.007377979204666011\n",
      "204 Train Loss 0.00030860782 Test MSE 1.1264232991206697e-05 Test RE 0.007854393882401126\n",
      "205 Train Loss 0.00030418165 Test MSE 1.0833828266709499e-05 Test RE 0.007702874773892389\n",
      "206 Train Loss 0.0002999979 Test MSE 1.1110783828323533e-05 Test RE 0.007800711441105939\n",
      "207 Train Loss 0.00029756303 Test MSE 1.2376624836198593e-05 Test RE 0.008233092169771842\n",
      "208 Train Loss 0.00029415748 Test MSE 1.3948937003788657e-05 Test RE 0.008740422382440837\n",
      "209 Train Loss 0.00029157085 Test MSE 1.7059311882946027e-05 Test RE 0.00966590714107479\n",
      "210 Train Loss 0.00029085015 Test MSE 1.621443472515644e-05 Test RE 0.00942351161953164\n",
      "211 Train Loss 0.00028811287 Test MSE 1.6320059708751313e-05 Test RE 0.009454155380192434\n",
      "212 Train Loss 0.00028519312 Test MSE 1.6841699042310152e-05 Test RE 0.009604058908029423\n",
      "213 Train Loss 0.00028149015 Test MSE 1.7897448839598373e-05 Test RE 0.009900506856256782\n",
      "214 Train Loss 0.00027872613 Test MSE 1.660860907172923e-05 Test RE 0.009537367017587776\n",
      "215 Train Loss 0.00027502808 Test MSE 1.585453156261658e-05 Test RE 0.00931834040569711\n",
      "216 Train Loss 0.00027205257 Test MSE 1.4072902011293766e-05 Test RE 0.008779174793020279\n",
      "217 Train Loss 0.0002686745 Test MSE 1.3300721802600354e-05 Test RE 0.008534920280211866\n",
      "218 Train Loss 0.00026433513 Test MSE 1.5028398726929746e-05 Test RE 0.009072317039093827\n",
      "219 Train Loss 0.00026170665 Test MSE 1.2120201681207195e-05 Test RE 0.008147357764258782\n",
      "220 Train Loss 0.00025916827 Test MSE 1.0542884024322134e-05 Test RE 0.007598739890706515\n",
      "221 Train Loss 0.00025663318 Test MSE 9.413826450556526e-06 Test RE 0.007180339150069163\n",
      "222 Train Loss 0.0002537093 Test MSE 9.198256272385487e-06 Test RE 0.0070976506064742255\n",
      "223 Train Loss 0.00025037982 Test MSE 1.0382351923678468e-05 Test RE 0.007540666555569338\n",
      "224 Train Loss 0.00024794228 Test MSE 8.638013682167215e-06 Test RE 0.0068781051020402415\n",
      "225 Train Loss 0.0002459316 Test MSE 8.55003776460179e-06 Test RE 0.006842989608954027\n",
      "226 Train Loss 0.00024356852 Test MSE 7.672893997209168e-06 Test RE 0.006482484144802166\n",
      "227 Train Loss 0.00024110902 Test MSE 7.794586958309922e-06 Test RE 0.006533688380781165\n",
      "228 Train Loss 0.00023825873 Test MSE 7.809569684100001e-06 Test RE 0.00653996488170147\n",
      "229 Train Loss 0.00023526906 Test MSE 6.517751520051557e-06 Test RE 0.005974626541427531\n",
      "230 Train Loss 0.00023091066 Test MSE 5.910468678058941e-06 Test RE 0.005689483262350281\n",
      "231 Train Loss 0.00022630111 Test MSE 4.890259790079799e-06 Test RE 0.005175208240186404\n",
      "232 Train Loss 0.00022337434 Test MSE 4.7141123057655394e-06 Test RE 0.005081147783002209\n",
      "233 Train Loss 0.00022082169 Test MSE 4.914078482119208e-06 Test RE 0.005187796217525206\n",
      "234 Train Loss 0.00021729073 Test MSE 4.665298980506206e-06 Test RE 0.005054772389956612\n",
      "235 Train Loss 0.0002152541 Test MSE 4.457526314244805e-06 Test RE 0.004940931373632904\n",
      "236 Train Loss 0.00021256247 Test MSE 4.160952318127055e-06 Test RE 0.004773734195780625\n",
      "237 Train Loss 0.00021072033 Test MSE 4.4114328178153875e-06 Test RE 0.004915318892083763\n",
      "238 Train Loss 0.00020839511 Test MSE 4.405483853999866e-06 Test RE 0.0049120035385212335\n",
      "239 Train Loss 0.00020624975 Test MSE 4.226729165911047e-06 Test RE 0.004811318134972777\n",
      "240 Train Loss 0.00020374055 Test MSE 4.581902113154975e-06 Test RE 0.005009389111249952\n",
      "241 Train Loss 0.00019985122 Test MSE 4.786514790263733e-06 Test RE 0.005120018929682885\n",
      "242 Train Loss 0.00019333728 Test MSE 5.44721714035716e-06 Test RE 0.005461968710521245\n",
      "243 Train Loss 0.00018896487 Test MSE 6.034986450462996e-06 Test RE 0.005749101997382597\n",
      "244 Train Loss 0.00018574002 Test MSE 6.270495105698247e-06 Test RE 0.005860204622106534\n",
      "245 Train Loss 0.00018341433 Test MSE 6.418063607939521e-06 Test RE 0.005928760032007734\n",
      "246 Train Loss 0.000181566 Test MSE 6.677445234890704e-06 Test RE 0.006047376827669316\n",
      "247 Train Loss 0.00017801306 Test MSE 7.4783372384283876e-06 Test RE 0.006399770305938942\n",
      "248 Train Loss 0.0001759841 Test MSE 6.7894614651364285e-06 Test RE 0.006097889186487288\n",
      "249 Train Loss 0.00017329962 Test MSE 6.2915209398111565e-06 Test RE 0.005870021436503994\n",
      "250 Train Loss 0.00017162375 Test MSE 7.026504635807015e-06 Test RE 0.006203424952430418\n",
      "251 Train Loss 0.00016981554 Test MSE 6.903964813374256e-06 Test RE 0.006149094235286214\n",
      "252 Train Loss 0.000168558 Test MSE 7.182212243569519e-06 Test RE 0.006271782392113961\n",
      "253 Train Loss 0.00016749398 Test MSE 7.554785072958413e-06 Test RE 0.006432398186411393\n",
      "254 Train Loss 0.00016545075 Test MSE 6.784524549098986e-06 Test RE 0.006095671761608337\n",
      "255 Train Loss 0.00016377693 Test MSE 7.1028775024884705e-06 Test RE 0.006237047139414258\n",
      "256 Train Loss 0.0001620658 Test MSE 8.437437440397147e-06 Test RE 0.006797780653333969\n",
      "257 Train Loss 0.0001601079 Test MSE 8.203549340428968e-06 Test RE 0.0067029003249957\n",
      "258 Train Loss 0.00015793307 Test MSE 8.120431619956959e-06 Test RE 0.006668857244010825\n",
      "259 Train Loss 0.0001562613 Test MSE 9.095692028050307e-06 Test RE 0.00705796885493695\n",
      "260 Train Loss 0.00015523707 Test MSE 9.330095632728504e-06 Test RE 0.007148335239548296\n",
      "261 Train Loss 0.00015387425 Test MSE 9.016114327191609e-06 Test RE 0.007027026139844458\n",
      "262 Train Loss 0.00015220682 Test MSE 8.982233249547384e-06 Test RE 0.007013810507241361\n",
      "263 Train Loss 0.00014945598 Test MSE 1.046959361016988e-05 Test RE 0.007572281948078522\n",
      "264 Train Loss 0.00014809553 Test MSE 9.945815743260235e-06 Test RE 0.007380436850940012\n",
      "265 Train Loss 0.00014622291 Test MSE 9.062227622320797e-06 Test RE 0.007044973231380173\n",
      "266 Train Loss 0.00014472156 Test MSE 8.294518179168857e-06 Test RE 0.006739961964651169\n",
      "267 Train Loss 0.00014202861 Test MSE 7.272832373724219e-06 Test RE 0.00631122484933287\n",
      "268 Train Loss 0.0001396835 Test MSE 6.53312746120253e-06 Test RE 0.005981669721115846\n",
      "269 Train Loss 0.0001384675 Test MSE 6.6563929414997215e-06 Test RE 0.006037836378426658\n",
      "270 Train Loss 0.00013779195 Test MSE 6.298860294080687e-06 Test RE 0.005873444266236683\n",
      "271 Train Loss 0.0001369475 Test MSE 5.520191328424305e-06 Test RE 0.005498432897261298\n",
      "272 Train Loss 0.0001360827 Test MSE 5.532324809716165e-06 Test RE 0.005504472408275619\n",
      "273 Train Loss 0.00013514265 Test MSE 5.934214227845354e-06 Test RE 0.0057009006722848\n",
      "274 Train Loss 0.00013497334 Test MSE 6.291559173543329e-06 Test RE 0.005870039272611401\n",
      "275 Train Loss 0.00013496679 Test MSE 6.3046361093971765e-06 Test RE 0.005876136511706119\n",
      "276 Train Loss 0.00013490953 Test MSE 6.235271145611843e-06 Test RE 0.005843721847353692\n",
      "277 Train Loss 0.00013482606 Test MSE 6.345742340699048e-06 Test RE 0.005895261595296394\n",
      "278 Train Loss 0.00013476663 Test MSE 6.390482021424261e-06 Test RE 0.005916006911848935\n",
      "279 Train Loss 0.0001346852 Test MSE 6.367609272446375e-06 Test RE 0.005905410165188133\n",
      "280 Train Loss 0.00013450364 Test MSE 6.2247312133835225e-06 Test RE 0.005838780724397105\n",
      "281 Train Loss 0.0001341041 Test MSE 6.11189683762767e-06 Test RE 0.005785619545558862\n",
      "282 Train Loss 0.00013406233 Test MSE 6.05530770723769e-06 Test RE 0.005758773170322109\n",
      "283 Train Loss 0.00013387609 Test MSE 5.922542785076812e-06 Test RE 0.005695291632715911\n",
      "284 Train Loss 0.00013382983 Test MSE 5.994580487144825e-06 Test RE 0.005729823732313301\n",
      "285 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "286 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "287 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "288 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "289 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "290 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "291 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "292 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "293 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "294 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "295 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "296 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "297 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "298 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "299 Train Loss 0.00013331228 Test MSE 5.830447775672209e-06 Test RE 0.005650837504021772\n",
      "Training time: 154.60\n",
      "KG_tanh_low\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 6308.382 Test MSE 8.813291752468256 Test RE 6.947538107790888\n",
      "1 Train Loss 1515.8871 Test MSE 9.493727839528544 Test RE 7.210746914113984\n",
      "2 Train Loss 352.9418 Test MSE 14.603216984168713 Test RE 8.943059767151885\n",
      "3 Train Loss 186.13005 Test MSE 15.641432637554171 Test RE 9.255505183335876\n",
      "4 Train Loss 105.3615 Test MSE 16.02879299939438 Test RE 9.369410655046243\n",
      "5 Train Loss 61.867615 Test MSE 15.713913742082884 Test RE 9.276925020146301\n",
      "6 Train Loss 46.090767 Test MSE 15.543277689781137 Test RE 9.226418865653354\n",
      "7 Train Loss 38.868126 Test MSE 15.49678696576636 Test RE 9.212610191263291\n",
      "8 Train Loss 31.921219 Test MSE 15.350602100368492 Test RE 9.169054862919646\n",
      "9 Train Loss 26.585335 Test MSE 14.924973744593771 Test RE 9.041045438878053\n",
      "10 Train Loss 23.362806 Test MSE 14.48758491274899 Test RE 8.907582661354688\n",
      "11 Train Loss 21.065105 Test MSE 14.105105056091709 Test RE 8.789213753312332\n",
      "12 Train Loss 18.983362 Test MSE 13.037687784928604 Test RE 8.450105913101448\n",
      "13 Train Loss 17.461016 Test MSE 12.438833282650737 Test RE 8.253757170005338\n",
      "14 Train Loss 15.890803 Test MSE 11.436196072119582 Test RE 7.914120533726613\n",
      "15 Train Loss 13.899515 Test MSE 10.410261509482902 Test RE 7.550795071502877\n",
      "16 Train Loss 12.83654 Test MSE 9.517614543081166 Test RE 7.219812518856054\n",
      "17 Train Loss 11.918948 Test MSE 9.168507536876481 Test RE 7.086163802797394\n",
      "18 Train Loss 11.080436 Test MSE 8.568756894131269 Test RE 6.85047640477559\n",
      "19 Train Loss 10.427088 Test MSE 7.755679818984873 Test RE 6.51736133599045\n",
      "20 Train Loss 9.520256 Test MSE 6.812433068277638 Test RE 6.10819633714944\n",
      "21 Train Loss 8.385671 Test MSE 6.059091043844444 Test RE 5.76057192079777\n",
      "22 Train Loss 7.293288 Test MSE 4.736059525943145 Test RE 5.092962051235101\n",
      "23 Train Loss 6.505802 Test MSE 4.27828915269087 Test RE 4.840574746963142\n",
      "24 Train Loss 5.4806848 Test MSE 3.6299131106699827 Test RE 4.458717726024058\n",
      "25 Train Loss 4.7448187 Test MSE 2.6950289728902668 Test RE 3.8418781208620185\n",
      "26 Train Loss 3.7294846 Test MSE 2.138054896687724 Test RE 3.421931329856958\n",
      "27 Train Loss 2.9509087 Test MSE 1.6569397840521323 Test RE 3.0124179510245495\n",
      "28 Train Loss 2.0417585 Test MSE 0.7099740762057101 Test RE 1.9718919302038689\n",
      "29 Train Loss 1.3025863 Test MSE 0.39167607946375 Test RE 1.4646214441890286\n",
      "30 Train Loss 0.9904098 Test MSE 0.2863425432032539 Test RE 1.252289683968728\n",
      "31 Train Loss 0.7522975 Test MSE 0.20617869407882686 Test RE 1.0626341194699076\n",
      "32 Train Loss 0.602405 Test MSE 0.21324371373351783 Test RE 1.0806871381328067\n",
      "33 Train Loss 0.4629304 Test MSE 0.18675354957492615 Test RE 1.011337932144375\n",
      "34 Train Loss 0.38648364 Test MSE 0.1479212997418117 Test RE 0.9000719368436646\n",
      "35 Train Loss 0.32137388 Test MSE 0.13502565799237598 Test RE 0.8599436921268695\n",
      "36 Train Loss 0.25731924 Test MSE 0.11867900337938449 Test RE 0.8062111669793008\n",
      "37 Train Loss 0.2231786 Test MSE 0.1054651599071971 Test RE 0.7600048640353221\n",
      "38 Train Loss 0.18162456 Test MSE 0.0908806673585577 Test RE 0.7055009742036654\n",
      "39 Train Loss 0.1521697 Test MSE 0.06839656875820758 Test RE 0.6120388938589467\n",
      "40 Train Loss 0.13030274 Test MSE 0.061805029219685316 Test RE 0.5818000739099239\n",
      "41 Train Loss 0.109536536 Test MSE 0.046792465316205775 Test RE 0.5062322718625029\n",
      "42 Train Loss 0.103352815 Test MSE 0.04422479839887233 Test RE 0.4921469465719657\n",
      "43 Train Loss 0.09145715 Test MSE 0.04157173484422386 Test RE 0.47715660328469106\n",
      "44 Train Loss 0.07618921 Test MSE 0.03602033355184254 Test RE 0.444156200275467\n",
      "45 Train Loss 0.07270302 Test MSE 0.0310365946439401 Test RE 0.4122862927615781\n",
      "46 Train Loss 0.06456069 Test MSE 0.025936529037130823 Test RE 0.37689275758078844\n",
      "47 Train Loss 0.05802912 Test MSE 0.026929251800588704 Test RE 0.38403783051476303\n",
      "48 Train Loss 0.05179472 Test MSE 0.02856424838420002 Test RE 0.39552438550696556\n",
      "49 Train Loss 0.04515221 Test MSE 0.02283289151182702 Test RE 0.3536244790057372\n",
      "50 Train Loss 0.044171933 Test MSE 0.02125373277759344 Test RE 0.3411767846742567\n",
      "51 Train Loss 0.038936667 Test MSE 0.018989057148152244 Test RE 0.3224880043987024\n",
      "52 Train Loss 0.035751186 Test MSE 0.01752595662890077 Test RE 0.309815206608296\n",
      "53 Train Loss 0.03317136 Test MSE 0.01593835907981892 Test RE 0.29544977767597447\n",
      "54 Train Loss 0.03197528 Test MSE 0.01603860966696001 Test RE 0.2963774950251821\n",
      "55 Train Loss 0.031089984 Test MSE 0.014719291834184533 Test RE 0.28392610327520124\n",
      "56 Train Loss 0.028316164 Test MSE 0.013779488381994701 Test RE 0.2747124932556228\n",
      "57 Train Loss 0.027114017 Test MSE 0.01394167975296545 Test RE 0.2763245142957645\n",
      "58 Train Loss 0.026261551 Test MSE 0.014632443858929377 Test RE 0.2830872420017668\n",
      "59 Train Loss 0.024494428 Test MSE 0.013530784377421685 Test RE 0.27222208167157463\n",
      "60 Train Loss 0.023409385 Test MSE 0.012410984318674571 Test RE 0.2607143749835871\n",
      "61 Train Loss 0.022166781 Test MSE 0.011642735468883019 Test RE 0.2525162778442856\n",
      "62 Train Loss 0.02039371 Test MSE 0.010076818995760437 Test RE 0.2349219477058634\n",
      "63 Train Loss 0.019434638 Test MSE 0.009885991494864117 Test RE 0.23268692495786952\n",
      "64 Train Loss 0.017060706 Test MSE 0.008149697523436026 Test RE 0.21126745910632938\n",
      "65 Train Loss 0.016731681 Test MSE 0.007357864129074321 Test RE 0.2007417685355152\n",
      "66 Train Loss 0.016318344 Test MSE 0.005805515269494955 Test RE 0.17831268922488505\n",
      "67 Train Loss 0.01539074 Test MSE 0.004526035398193217 Test RE 0.15744208670258705\n",
      "68 Train Loss 0.014752287 Test MSE 0.004408369720925929 Test RE 0.1553820580493541\n",
      "69 Train Loss 0.014279577 Test MSE 0.004677827074097957 Test RE 0.16006041758973405\n",
      "70 Train Loss 0.014029099 Test MSE 0.004345848118141146 Test RE 0.15427627210964287\n",
      "71 Train Loss 0.013154538 Test MSE 0.003910847379168351 Test RE 0.14635154043986948\n",
      "72 Train Loss 0.012701346 Test MSE 0.003935871029996548 Test RE 0.1468190107743909\n",
      "73 Train Loss 0.012110683 Test MSE 0.0038851624746783888 Test RE 0.14587015913379459\n",
      "74 Train Loss 0.010810196 Test MSE 0.0039009149199244384 Test RE 0.14616557628715618\n",
      "75 Train Loss 0.009836951 Test MSE 0.002767891860000771 Test RE 0.1231222159396006\n",
      "76 Train Loss 0.009447808 Test MSE 0.002102631548223007 Test RE 0.10731080486230699\n",
      "77 Train Loss 0.009233611 Test MSE 0.001794777103477124 Test RE 0.09914415696749945\n",
      "78 Train Loss 0.008694721 Test MSE 0.0014789845121372688 Test RE 0.09000024197654098\n",
      "79 Train Loss 0.0077560763 Test MSE 0.0012065646807070194 Test RE 0.08129000834902124\n",
      "80 Train Loss 0.0073739747 Test MSE 0.0010618243417503245 Test RE 0.07625849018574492\n",
      "81 Train Loss 0.007067974 Test MSE 0.0010079164169547886 Test RE 0.07429748681378552\n",
      "82 Train Loss 0.006706728 Test MSE 0.0011971330636900287 Test RE 0.08097166635562848\n",
      "83 Train Loss 0.0065386314 Test MSE 0.0013516709976147234 Test RE 0.08603939773641739\n",
      "84 Train Loss 0.0063558263 Test MSE 0.0015086276289736945 Test RE 0.09089769963645063\n",
      "85 Train Loss 0.006202875 Test MSE 0.0015051498707810936 Test RE 0.09079286839527656\n",
      "86 Train Loss 0.0059120865 Test MSE 0.001752321225992787 Test RE 0.0979644996898855\n",
      "87 Train Loss 0.0053843786 Test MSE 0.0017960383478251077 Test RE 0.09917898665383029\n",
      "88 Train Loss 0.005134676 Test MSE 0.0014122252587376902 Test RE 0.08794554640161617\n",
      "89 Train Loss 0.0050422885 Test MSE 0.0013826378540534624 Test RE 0.08701940019682851\n",
      "90 Train Loss 0.0049355226 Test MSE 0.0013258643518315313 Test RE 0.08521409009998403\n",
      "91 Train Loss 0.004693659 Test MSE 0.0013590810960151798 Test RE 0.08627491695191772\n",
      "92 Train Loss 0.0044766297 Test MSE 0.0012907035024385235 Test RE 0.08407659371063912\n",
      "93 Train Loss 0.004338654 Test MSE 0.0013664725995024157 Test RE 0.08650920637362239\n",
      "94 Train Loss 0.0042404053 Test MSE 0.0014676488005769268 Test RE 0.08965467406438629\n",
      "95 Train Loss 0.0041605416 Test MSE 0.0015018214049831104 Test RE 0.09069242384198917\n",
      "96 Train Loss 0.0040933373 Test MSE 0.001350522584440091 Test RE 0.0860028393673359\n",
      "97 Train Loss 0.00398068 Test MSE 0.0010590904432327454 Test RE 0.07616025484947718\n",
      "98 Train Loss 0.0038337102 Test MSE 0.0009392531631832286 Test RE 0.07172213305091861\n",
      "99 Train Loss 0.003647513 Test MSE 0.0010176022963336306 Test RE 0.07465362540300736\n",
      "100 Train Loss 0.0035522785 Test MSE 0.0011220787115053244 Test RE 0.07839232144365643\n",
      "101 Train Loss 0.0035028234 Test MSE 0.0010715156763231896 Test RE 0.07660570762787156\n",
      "102 Train Loss 0.0034063475 Test MSE 0.0009624807231760448 Test RE 0.07260355463864143\n",
      "103 Train Loss 0.0032892444 Test MSE 0.0010054457854373245 Test RE 0.07420637095565659\n",
      "104 Train Loss 0.0031174775 Test MSE 0.0010251110310588987 Test RE 0.07492854813439481\n",
      "105 Train Loss 0.0030058257 Test MSE 0.0009081141781672884 Test RE 0.07052321330354532\n",
      "106 Train Loss 0.0028739318 Test MSE 0.0009355229203842808 Test RE 0.07157956917980667\n",
      "107 Train Loss 0.0027967962 Test MSE 0.0008996263939089532 Test RE 0.0701928632796551\n",
      "108 Train Loss 0.0027504798 Test MSE 0.000968804271947665 Test RE 0.07284166875207274\n",
      "109 Train Loss 0.0027114057 Test MSE 0.0009659357785235656 Test RE 0.07273375183423135\n",
      "110 Train Loss 0.0026474197 Test MSE 0.0009611214626853321 Test RE 0.07255226945016528\n",
      "111 Train Loss 0.0024824576 Test MSE 0.0009155141673581967 Test RE 0.07080996809175547\n",
      "112 Train Loss 0.0023392034 Test MSE 0.0008099961731779989 Test RE 0.06660446551961034\n",
      "113 Train Loss 0.002304382 Test MSE 0.0007874220038156625 Test RE 0.06566979148877856\n",
      "114 Train Loss 0.0022616189 Test MSE 0.0006882665579545125 Test RE 0.06139601706762421\n",
      "115 Train Loss 0.002230569 Test MSE 0.0006110142093897459 Test RE 0.05784788951662667\n",
      "116 Train Loss 0.0021980663 Test MSE 0.0005207639424363745 Test RE 0.05340504890731953\n",
      "117 Train Loss 0.0021580516 Test MSE 0.0005107061865689124 Test RE 0.052886816234882075\n",
      "118 Train Loss 0.0021254467 Test MSE 0.0004940983658614694 Test RE 0.05201978738438079\n",
      "119 Train Loss 0.0020982255 Test MSE 0.0005113053807862408 Test RE 0.05291783229235\n",
      "120 Train Loss 0.0020571877 Test MSE 0.0005287104452296332 Test RE 0.0538109685775437\n",
      "121 Train Loss 0.002037654 Test MSE 0.0005359083101147352 Test RE 0.05417602162758035\n",
      "122 Train Loss 0.0020152628 Test MSE 0.0005168072985412505 Test RE 0.05320178247828583\n",
      "123 Train Loss 0.0019885832 Test MSE 0.0004648824045176688 Test RE 0.050458393398595786\n",
      "124 Train Loss 0.001962439 Test MSE 0.00045676627116127073 Test RE 0.05001599092275764\n",
      "125 Train Loss 0.0019406184 Test MSE 0.00045942581990989986 Test RE 0.050161390120288446\n",
      "126 Train Loss 0.0019073512 Test MSE 0.00040172214448820534 Test RE 0.04690560589274309\n",
      "127 Train Loss 0.0018657193 Test MSE 0.0003467405299480017 Test RE 0.04357768631201529\n",
      "128 Train Loss 0.0018194395 Test MSE 0.00028068037340220906 Test RE 0.03920738586282622\n",
      "129 Train Loss 0.0017827621 Test MSE 0.00026527195836639506 Test RE 0.038116019093443206\n",
      "130 Train Loss 0.0017636056 Test MSE 0.000265378195881634 Test RE 0.038123650781766015\n",
      "131 Train Loss 0.0017433071 Test MSE 0.0002643931926624424 Test RE 0.03805283330415016\n",
      "132 Train Loss 0.0017245669 Test MSE 0.00024594637304946126 Test RE 0.036701353033094644\n",
      "133 Train Loss 0.0017116326 Test MSE 0.000245027577814616 Test RE 0.03663273526859231\n",
      "134 Train Loss 0.0017014873 Test MSE 0.00026384511077050656 Test RE 0.038013371454861535\n",
      "135 Train Loss 0.0016883791 Test MSE 0.0002751632572185926 Test RE 0.03882013889338423\n",
      "136 Train Loss 0.0016495095 Test MSE 0.0002758943730656565 Test RE 0.038871677734513325\n",
      "137 Train Loss 0.0016125964 Test MSE 0.00028935444604353123 Test RE 0.03980860362113531\n",
      "138 Train Loss 0.001557722 Test MSE 0.0002911212014203565 Test RE 0.039929951387991706\n",
      "139 Train Loss 0.0015341263 Test MSE 0.0002950787659198171 Test RE 0.04020044340182017\n",
      "140 Train Loss 0.0015202475 Test MSE 0.00028007403723393144 Test RE 0.03916501434168678\n",
      "141 Train Loss 0.0015039778 Test MSE 0.00025393007553377593 Test RE 0.03729227988080868\n",
      "142 Train Loss 0.0014912869 Test MSE 0.00021846398296732707 Test RE 0.03459009762130895\n",
      "143 Train Loss 0.0014779683 Test MSE 0.00020307325244065295 Test RE 0.03334941547618485\n",
      "144 Train Loss 0.0014685784 Test MSE 0.00018977581063836876 Test RE 0.03223905414538257\n",
      "145 Train Loss 0.0014615653 Test MSE 0.00018930874722755306 Test RE 0.03219935741402285\n",
      "146 Train Loss 0.0014416829 Test MSE 0.00018642183279704802 Test RE 0.03195289783004953\n",
      "147 Train Loss 0.0013942154 Test MSE 0.00016605042387004865 Test RE 0.030156564086633322\n",
      "148 Train Loss 0.0013435376 Test MSE 0.00017235403765447085 Test RE 0.030723634856355528\n",
      "149 Train Loss 0.0013138462 Test MSE 0.0001556406525010854 Test RE 0.02919600204962137\n",
      "150 Train Loss 0.0012990873 Test MSE 0.00014031133215420286 Test RE 0.02772095820247501\n",
      "151 Train Loss 0.0012823294 Test MSE 0.00014150092908784686 Test RE 0.027838223018692394\n",
      "152 Train Loss 0.0012724523 Test MSE 0.00013879988144074732 Test RE 0.027571247169965937\n",
      "153 Train Loss 0.0012583247 Test MSE 0.00013514326129717688 Test RE 0.027205647184571094\n",
      "154 Train Loss 0.0012514006 Test MSE 0.00013531938189237098 Test RE 0.02722336880334031\n",
      "155 Train Loss 0.0012415206 Test MSE 0.00013745800386236946 Test RE 0.027437648017887648\n",
      "156 Train Loss 0.0012320684 Test MSE 0.0001427888619442647 Test RE 0.02796462694699329\n",
      "157 Train Loss 0.0012181457 Test MSE 0.000143928221452733 Test RE 0.028075974767180684\n",
      "158 Train Loss 0.0011996474 Test MSE 0.00013046649335875894 Test RE 0.02673076321552624\n",
      "159 Train Loss 0.0011673442 Test MSE 0.00014029756373429587 Test RE 0.02771959807300243\n",
      "160 Train Loss 0.0011273067 Test MSE 0.00014803594843756067 Test RE 0.02847380190474616\n",
      "161 Train Loss 0.0010824687 Test MSE 0.00014771301197924334 Test RE 0.028442727530235565\n",
      "162 Train Loss 0.0010508558 Test MSE 0.00014372386567768801 Test RE 0.028056035920029237\n",
      "163 Train Loss 0.0010265324 Test MSE 0.00013774442778091678 Test RE 0.027466219322639162\n",
      "164 Train Loss 0.0010037922 Test MSE 0.00012089410502485058 Test RE 0.02573145985671799\n",
      "165 Train Loss 0.0009793519 Test MSE 0.00010309683601653901 Test RE 0.023762084320675073\n",
      "166 Train Loss 0.00095106475 Test MSE 8.835109010659789e-05 Test RE 0.0219972211088543\n",
      "167 Train Loss 0.000923567 Test MSE 8.679702377797521e-05 Test RE 0.02180290090445576\n",
      "168 Train Loss 0.0009049419 Test MSE 7.948011964848608e-05 Test RE 0.020863689949562423\n",
      "169 Train Loss 0.0008871534 Test MSE 8.221975160418081e-05 Test RE 0.02122022303486376\n",
      "170 Train Loss 0.000858339 Test MSE 8.01410376938131e-05 Test RE 0.020950256513392645\n",
      "171 Train Loss 0.00082238053 Test MSE 7.478587490276437e-05 Test RE 0.020238189281194727\n",
      "172 Train Loss 0.00080587255 Test MSE 7.27886811970247e-05 Test RE 0.01996612517048929\n",
      "173 Train Loss 0.00078576145 Test MSE 6.857404890923872e-05 Test RE 0.019379463971656758\n",
      "174 Train Loss 0.00077534653 Test MSE 6.630923859347831e-05 Test RE 0.019056752104292564\n",
      "175 Train Loss 0.00076777075 Test MSE 6.621312789662692e-05 Test RE 0.019042936368174213\n",
      "176 Train Loss 0.0007599355 Test MSE 6.418600441749119e-05 Test RE 0.018749169482190537\n",
      "177 Train Loss 0.00074698153 Test MSE 6.38388076143327e-05 Test RE 0.01869839144495119\n",
      "178 Train Loss 0.00073200284 Test MSE 6.205009583572404e-05 Test RE 0.018434573417843037\n",
      "179 Train Loss 0.000718498 Test MSE 5.91631481265888e-05 Test RE 0.018000621564278303\n",
      "180 Train Loss 0.0007055632 Test MSE 5.231493500346445e-05 Test RE 0.016926794009079465\n",
      "181 Train Loss 0.0006915963 Test MSE 5.330134078865707e-05 Test RE 0.01708562739263943\n",
      "182 Train Loss 0.00067776436 Test MSE 5.6194535581119084e-05 Test RE 0.017543203743190922\n",
      "183 Train Loss 0.0006584915 Test MSE 5.5452577498469506e-05 Test RE 0.017427004075750915\n",
      "184 Train Loss 0.00061807834 Test MSE 5.6127955716012846e-05 Test RE 0.017532807978695865\n",
      "185 Train Loss 0.0006036988 Test MSE 5.5844265729203435e-05 Test RE 0.01748844342932242\n",
      "186 Train Loss 0.0005944916 Test MSE 5.6616999229594725e-05 Test RE 0.01760902409798475\n",
      "187 Train Loss 0.0005845144 Test MSE 5.698212413444838e-05 Test RE 0.01766571343708032\n",
      "188 Train Loss 0.00057927234 Test MSE 5.7792262966539886e-05 Test RE 0.01779085066478995\n",
      "189 Train Loss 0.000571346 Test MSE 6.185896494593876e-05 Test RE 0.018406159812467047\n",
      "190 Train Loss 0.0005618877 Test MSE 6.48933255143716e-05 Test RE 0.018852193090583662\n",
      "191 Train Loss 0.00055499945 Test MSE 6.660603983614986e-05 Test RE 0.01909935365415101\n",
      "192 Train Loss 0.0005452279 Test MSE 6.473662582171476e-05 Test RE 0.01882941787947685\n",
      "193 Train Loss 0.00053643534 Test MSE 6.320795420617961e-05 Test RE 0.018605773560170173\n",
      "194 Train Loss 0.00053001294 Test MSE 6.022578364516077e-05 Test RE 0.018161557660253878\n",
      "195 Train Loss 0.0005238427 Test MSE 6.226281858669747e-05 Test RE 0.018466145472194388\n",
      "196 Train Loss 0.00051958114 Test MSE 5.862749377578933e-05 Test RE 0.017918948804415035\n",
      "197 Train Loss 0.00051157654 Test MSE 5.5214350283603166e-05 Test RE 0.01738953011787036\n",
      "198 Train Loss 0.0005065654 Test MSE 5.4523599821041455e-05 Test RE 0.017280413278003108\n",
      "199 Train Loss 0.00050263107 Test MSE 5.144225175609548e-05 Test RE 0.016785019467484532\n",
      "200 Train Loss 0.0004984983 Test MSE 4.9099237649762627e-05 Test RE 0.01639831552475934\n",
      "201 Train Loss 0.0004950454 Test MSE 4.63694289927188e-05 Test RE 0.015935941910130227\n",
      "202 Train Loss 0.0004911934 Test MSE 4.504208517086395e-05 Test RE 0.015706199435537947\n",
      "203 Train Loss 0.00048535567 Test MSE 4.3155170320760665e-05 Test RE 0.0153736957333543\n",
      "204 Train Loss 0.00048174144 Test MSE 4.126068027301601e-05 Test RE 0.015032459970126259\n",
      "205 Train Loss 0.00047811182 Test MSE 3.9300364285556344e-05 Test RE 0.014671014692803377\n",
      "206 Train Loss 0.00047405178 Test MSE 3.651488644407688e-05 Test RE 0.014141544394252666\n",
      "207 Train Loss 0.00047029648 Test MSE 3.466040219404291e-05 Test RE 0.013777761511513942\n",
      "208 Train Loss 0.00046641994 Test MSE 3.528715027051362e-05 Test RE 0.013901771872936378\n",
      "209 Train Loss 0.00046321767 Test MSE 3.3861037370815325e-05 Test RE 0.013617958099347871\n",
      "210 Train Loss 0.00045906793 Test MSE 3.396582012046388e-05 Test RE 0.013639012163334518\n",
      "211 Train Loss 0.0004555685 Test MSE 3.442083606479693e-05 Test RE 0.013730064312275133\n",
      "212 Train Loss 0.0004507136 Test MSE 3.2487945723345416e-05 Test RE 0.013338991306299588\n",
      "213 Train Loss 0.0004476715 Test MSE 3.256325692383469e-05 Test RE 0.013354443097980428\n",
      "214 Train Loss 0.0004443004 Test MSE 3.217673336098131e-05 Test RE 0.013274948345679966\n",
      "215 Train Loss 0.0004431139 Test MSE 3.235025794107788e-05 Test RE 0.013310695177170559\n",
      "216 Train Loss 0.00044112324 Test MSE 3.265498475235391e-05 Test RE 0.013373239016048128\n",
      "217 Train Loss 0.0004396377 Test MSE 3.257160635478863e-05 Test RE 0.013356155071298885\n",
      "218 Train Loss 0.00043500648 Test MSE 3.161633828129251e-05 Test RE 0.013158841289997067\n",
      "219 Train Loss 0.0004328681 Test MSE 3.0782000726123064e-05 Test RE 0.012984053194413585\n",
      "220 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "221 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "222 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "223 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "224 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "225 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "226 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "227 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "228 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "229 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "230 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "231 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "232 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "233 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "234 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "235 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "236 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "237 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "238 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "239 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "240 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "241 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "242 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "243 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "244 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "245 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "246 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "247 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "248 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "249 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "250 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "251 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "252 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "253 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "254 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "255 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "256 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "257 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "258 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "259 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "260 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "261 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "262 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "263 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "264 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "265 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "266 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "267 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "268 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "269 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "270 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "271 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "272 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "273 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "274 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "275 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "276 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "277 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "278 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "279 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "280 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "281 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "282 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "283 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "284 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "285 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "286 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "287 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "288 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "289 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "290 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "291 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "292 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "293 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "294 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "295 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "296 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "297 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "298 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "299 Train Loss 0.00043113908 Test MSE 3.0717046896526204e-05 Test RE 0.012970346980890076\n",
      "Training time: 130.78\n",
      "KG_tanh_low\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 6241.752 Test MSE 7.03318501822493 Test RE 6.206373175468853\n",
      "1 Train Loss 2573.2136 Test MSE 8.053906389458238 Test RE 6.641484337432008\n",
      "2 Train Loss 1460.0038 Test MSE 9.520477214646458 Test RE 7.220898210971333\n",
      "3 Train Loss 481.2899 Test MSE 10.763399721458804 Test RE 7.677796528082173\n",
      "4 Train Loss 221.17441 Test MSE 8.985787059338072 Test RE 7.01519787287668\n",
      "5 Train Loss 142.22939 Test MSE 8.586341379273946 Test RE 6.857501949053271\n",
      "6 Train Loss 80.15182 Test MSE 8.014952093713413 Test RE 6.6254034493499905\n",
      "7 Train Loss 51.894096 Test MSE 7.839237021969904 Test RE 6.5523752601666425\n",
      "8 Train Loss 33.079956 Test MSE 8.080938585539418 Test RE 6.652620766341858\n",
      "9 Train Loss 26.236176 Test MSE 8.557620857158158 Test RE 6.846023485789446\n",
      "10 Train Loss 20.760141 Test MSE 8.998055572544576 Test RE 7.019985249330344\n",
      "11 Train Loss 16.826149 Test MSE 9.05043552175707 Test RE 7.040388151478282\n",
      "12 Train Loss 14.804659 Test MSE 8.877284353076245 Test RE 6.9727152450954435\n",
      "13 Train Loss 12.628043 Test MSE 8.280215239090216 Test RE 6.734148313748336\n",
      "14 Train Loss 10.6544895 Test MSE 7.598962076310379 Test RE 6.4511776664076335\n",
      "15 Train Loss 8.912062 Test MSE 6.301917719419786 Test RE 5.874869558899997\n",
      "16 Train Loss 7.332763 Test MSE 5.425242932218851 Test RE 5.450940719317233\n",
      "17 Train Loss 5.818241 Test MSE 3.810406133956839 Test RE 4.568225122732697\n",
      "18 Train Loss 4.3917255 Test MSE 2.864554023959526 Test RE 3.960868030258747\n",
      "19 Train Loss 2.8655927 Test MSE 1.706478087039751 Test RE 3.0571181395695115\n",
      "20 Train Loss 1.9826577 Test MSE 0.9038304751393056 Test RE 2.2248736593972085\n",
      "21 Train Loss 1.2022127 Test MSE 0.3155479499315037 Test RE 1.3146027775052584\n",
      "22 Train Loss 0.769498 Test MSE 0.16733968211539874 Test RE 0.957329261954665\n",
      "23 Train Loss 0.4376133 Test MSE 0.042292845468245875 Test RE 0.481277232003301\n",
      "24 Train Loss 0.32846692 Test MSE 0.010311463064332525 Test RE 0.23764134913081747\n",
      "25 Train Loss 0.25075412 Test MSE 0.004577389549556435 Test RE 0.15833276678900318\n",
      "26 Train Loss 0.17158602 Test MSE 0.01355265547857981 Test RE 0.2724420021336642\n",
      "27 Train Loss 0.13118339 Test MSE 0.007928915493802952 Test RE 0.20838610567406898\n",
      "28 Train Loss 0.10395737 Test MSE 0.006356800628350317 Test RE 0.18658690432875857\n",
      "29 Train Loss 0.08731852 Test MSE 0.002772524008844172 Test RE 0.12322519720592626\n",
      "30 Train Loss 0.075038135 Test MSE 0.0036385640237793556 Test RE 0.14116494868495424\n",
      "31 Train Loss 0.06601341 Test MSE 0.0023867364583235913 Test RE 0.11433102515409427\n",
      "32 Train Loss 0.05561444 Test MSE 0.0015192123222782436 Test RE 0.09121601628293231\n",
      "33 Train Loss 0.050540335 Test MSE 0.001301896058108947 Test RE 0.08444034908587227\n",
      "34 Train Loss 0.046265103 Test MSE 0.0015706698996523075 Test RE 0.09274795113525143\n",
      "35 Train Loss 0.042328846 Test MSE 0.002028930408337791 Test RE 0.10541330735926138\n",
      "36 Train Loss 0.037401322 Test MSE 0.0018609296186239042 Test RE 0.10095476870767794\n",
      "37 Train Loss 0.03233695 Test MSE 0.0019987658300775943 Test RE 0.10462677098080016\n",
      "38 Train Loss 0.030986754 Test MSE 0.002109911587770439 Test RE 0.1074964179461683\n",
      "39 Train Loss 0.027322777 Test MSE 0.0018723156459362921 Test RE 0.10126314169714001\n",
      "40 Train Loss 0.024631917 Test MSE 0.0011631209417568295 Test RE 0.07981312245294693\n",
      "41 Train Loss 0.02213431 Test MSE 0.0008620352101010852 Test RE 0.06871069898454543\n",
      "42 Train Loss 0.020072319 Test MSE 0.000979549760434759 Test RE 0.07324451631745063\n",
      "43 Train Loss 0.01689015 Test MSE 0.00047708776706386507 Test RE 0.051116487638967804\n",
      "44 Train Loss 0.015029031 Test MSE 0.00034738011447150747 Test RE 0.043617858674974204\n",
      "45 Train Loss 0.013721731 Test MSE 0.0003657400747950919 Test RE 0.04475567780630636\n",
      "46 Train Loss 0.013039595 Test MSE 0.0003672972375100502 Test RE 0.044850851750326305\n",
      "47 Train Loss 0.011710188 Test MSE 0.00046843991932767173 Test RE 0.05065109199211854\n",
      "48 Train Loss 0.010286706 Test MSE 0.00033509456698859044 Test RE 0.04283961481549883\n",
      "49 Train Loss 0.009882358 Test MSE 0.0003653652521127932 Test RE 0.044732738368475126\n",
      "50 Train Loss 0.009103225 Test MSE 0.0002770396283572856 Test RE 0.038952273598975684\n",
      "51 Train Loss 0.00884135 Test MSE 0.0003275540071453191 Test RE 0.0423548670082195\n",
      "52 Train Loss 0.008259542 Test MSE 0.00029697082893127716 Test RE 0.040329121304033586\n",
      "53 Train Loss 0.008103249 Test MSE 0.00027368812120325366 Test RE 0.038715942677920355\n",
      "54 Train Loss 0.0072822194 Test MSE 0.0004181547448494164 Test RE 0.047855336967654184\n",
      "55 Train Loss 0.006930179 Test MSE 0.00039778443161536756 Test RE 0.046675153507074234\n",
      "56 Train Loss 0.0068156836 Test MSE 0.00042203978980168106 Test RE 0.04807713319210461\n",
      "57 Train Loss 0.006247004 Test MSE 0.0004915416828103857 Test RE 0.05188502615845019\n",
      "58 Train Loss 0.0059283874 Test MSE 0.0004387869104202681 Test RE 0.04902173701666097\n",
      "59 Train Loss 0.0056641405 Test MSE 0.0005306376406363316 Test RE 0.053908952191736255\n",
      "60 Train Loss 0.005354593 Test MSE 0.0005292098110086319 Test RE 0.05383637474692822\n",
      "61 Train Loss 0.005253417 Test MSE 0.0004915121331799436 Test RE 0.05188346656905517\n",
      "62 Train Loss 0.0049761785 Test MSE 0.0005235723793825034 Test RE 0.05354885978773282\n",
      "63 Train Loss 0.0048836563 Test MSE 0.0005457843879145752 Test RE 0.054672938731220325\n",
      "64 Train Loss 0.004718721 Test MSE 0.0005326980229229922 Test RE 0.054013510774394764\n",
      "65 Train Loss 0.00454419 Test MSE 0.0005243706689067279 Test RE 0.053589667146605936\n",
      "66 Train Loss 0.004477983 Test MSE 0.00047704705645855704 Test RE 0.051114306669666244\n",
      "67 Train Loss 0.0044202544 Test MSE 0.0004789085678236357 Test RE 0.051213937533950205\n",
      "68 Train Loss 0.0043258793 Test MSE 0.0005261040932641974 Test RE 0.053678170371814236\n",
      "69 Train Loss 0.0041388925 Test MSE 0.0005353736932528569 Test RE 0.05414899215151656\n",
      "70 Train Loss 0.004079622 Test MSE 0.000553702673787596 Test RE 0.05506811039668443\n",
      "71 Train Loss 0.0040522567 Test MSE 0.0005561195744745436 Test RE 0.05518816511012018\n",
      "72 Train Loss 0.0039454466 Test MSE 0.0005482516612116881 Test RE 0.0547963766482441\n",
      "73 Train Loss 0.0037546435 Test MSE 0.0005673454832844168 Test RE 0.055742400191682084\n",
      "74 Train Loss 0.0035924427 Test MSE 0.0005708116914742725 Test RE 0.05591242053685693\n",
      "75 Train Loss 0.0035626222 Test MSE 0.0005722943335692336 Test RE 0.05598498768018371\n",
      "76 Train Loss 0.0035401476 Test MSE 0.0005592247426208364 Test RE 0.0553420258901932\n",
      "77 Train Loss 0.0034342355 Test MSE 0.0005810532397309049 Test RE 0.0564117831172602\n",
      "78 Train Loss 0.00321197 Test MSE 0.0006515918089740286 Test RE 0.059737861571467675\n",
      "79 Train Loss 0.0030617574 Test MSE 0.00066376095825192 Test RE 0.06029311418330871\n",
      "80 Train Loss 0.0030205227 Test MSE 0.0007121582353875134 Test RE 0.06245254118564366\n",
      "81 Train Loss 0.0029713768 Test MSE 0.0007076766066608071 Test RE 0.06225572338806743\n",
      "82 Train Loss 0.0029186988 Test MSE 0.0006891978025411797 Test RE 0.061437538322136734\n",
      "83 Train Loss 0.002842565 Test MSE 0.0006714578455640964 Test RE 0.060641682234600786\n",
      "84 Train Loss 0.0027844235 Test MSE 0.0006974095135206294 Test RE 0.06180246505755934\n",
      "85 Train Loss 0.0027485446 Test MSE 0.0007068546046071583 Test RE 0.06221955630198382\n",
      "86 Train Loss 0.0027076493 Test MSE 0.0006842020546879705 Test RE 0.06121446399280086\n",
      "87 Train Loss 0.002663485 Test MSE 0.0007006068213425837 Test RE 0.061943971260413844\n",
      "88 Train Loss 0.0026263401 Test MSE 0.00068539493170896 Test RE 0.06126780315429075\n",
      "89 Train Loss 0.002602713 Test MSE 0.0007062241935238469 Test RE 0.06219180473395624\n",
      "90 Train Loss 0.0025644677 Test MSE 0.0007201938200801015 Test RE 0.06280389216607615\n",
      "91 Train Loss 0.0025307266 Test MSE 0.0007265207946038124 Test RE 0.06307915815585545\n",
      "92 Train Loss 0.0024939836 Test MSE 0.0007402087971394908 Test RE 0.06367060626032625\n",
      "93 Train Loss 0.0024743183 Test MSE 0.0007403856917062017 Test RE 0.06367821378372072\n",
      "94 Train Loss 0.002464964 Test MSE 0.0007398656458937139 Test RE 0.06365584611378589\n",
      "95 Train Loss 0.00243267 Test MSE 0.0007409903525603445 Test RE 0.0637042109534639\n",
      "96 Train Loss 0.0024041708 Test MSE 0.0007490624885306662 Test RE 0.06405025875397578\n",
      "97 Train Loss 0.0023758933 Test MSE 0.0007100087024690704 Test RE 0.062358218577387235\n",
      "98 Train Loss 0.002359966 Test MSE 0.000702488981371536 Test RE 0.062027120799717395\n",
      "99 Train Loss 0.002342614 Test MSE 0.0007045438259436066 Test RE 0.06211777206027643\n",
      "100 Train Loss 0.0023189157 Test MSE 0.0006902916955913604 Test RE 0.06148627574537562\n",
      "101 Train Loss 0.0023010082 Test MSE 0.0006759841613316869 Test RE 0.060845732557210014\n",
      "102 Train Loss 0.0022783577 Test MSE 0.0006508657284942516 Test RE 0.05970456880705958\n",
      "103 Train Loss 0.0022620985 Test MSE 0.0006532066628969013 Test RE 0.05981184057419369\n",
      "104 Train Loss 0.0022407514 Test MSE 0.0006676695224487056 Test RE 0.06047037197560598\n",
      "105 Train Loss 0.002211633 Test MSE 0.0006452290511990543 Test RE 0.05944547759418821\n",
      "106 Train Loss 0.0021852655 Test MSE 0.000629120401439055 Test RE 0.058698735881173095\n",
      "107 Train Loss 0.0021655066 Test MSE 0.0006121915936100173 Test RE 0.05790359723367837\n",
      "108 Train Loss 0.0021531617 Test MSE 0.000625223872382138 Test RE 0.05851667487713612\n",
      "109 Train Loss 0.0021189773 Test MSE 0.0006204557383823902 Test RE 0.05829311547703229\n",
      "110 Train Loss 0.0020909398 Test MSE 0.0006068435413327928 Test RE 0.057650122051769156\n",
      "111 Train Loss 0.0020577137 Test MSE 0.0006081999253213025 Test RE 0.057714514313713335\n",
      "112 Train Loss 0.0020288685 Test MSE 0.0006217734737648208 Test RE 0.0583549846435921\n",
      "113 Train Loss 0.001999276 Test MSE 0.0006246048218193373 Test RE 0.05848769825505337\n",
      "114 Train Loss 0.001974863 Test MSE 0.0006135665221956553 Test RE 0.05796858396404044\n",
      "115 Train Loss 0.0019545192 Test MSE 0.0005993762997806949 Test RE 0.057294330269484044\n",
      "116 Train Loss 0.0019336222 Test MSE 0.0005885633355537004 Test RE 0.05677517299479925\n",
      "117 Train Loss 0.0019218256 Test MSE 0.0005779213512303732 Test RE 0.056259547386078954\n",
      "118 Train Loss 0.0018986915 Test MSE 0.0005808608849890663 Test RE 0.056402444926339695\n",
      "119 Train Loss 0.0018734627 Test MSE 0.0005880099152708114 Test RE 0.056748474150358996\n",
      "120 Train Loss 0.0018620385 Test MSE 0.0005933964009073937 Test RE 0.05700780480516799\n",
      "121 Train Loss 0.0018458928 Test MSE 0.0005819533234119808 Test RE 0.056455458699547975\n",
      "122 Train Loss 0.00180563 Test MSE 0.0006025912184377028 Test RE 0.05744778167753631\n",
      "123 Train Loss 0.001771781 Test MSE 0.0005839222505449766 Test RE 0.05655088114956976\n",
      "124 Train Loss 0.0017338968 Test MSE 0.000577279863440855 Test RE 0.056228314906933176\n",
      "125 Train Loss 0.0016869316 Test MSE 0.0005585590504082664 Test RE 0.05530907694941265\n",
      "126 Train Loss 0.0016587183 Test MSE 0.0005307683994752499 Test RE 0.0539155938594719\n",
      "127 Train Loss 0.001647641 Test MSE 0.0005230576950914211 Test RE 0.05352253340519505\n",
      "128 Train Loss 0.0016348409 Test MSE 0.0005160495960348647 Test RE 0.05316276802344119\n",
      "129 Train Loss 0.0016161168 Test MSE 0.0005146965268416822 Test RE 0.053093026551228904\n",
      "130 Train Loss 0.0015922638 Test MSE 0.0005030765630608777 Test RE 0.052490282080293556\n",
      "131 Train Loss 0.0015694968 Test MSE 0.0004950595821104876 Test RE 0.05207036230371909\n",
      "132 Train Loss 0.0015514935 Test MSE 0.0004819360997067901 Test RE 0.05137556290632714\n",
      "133 Train Loss 0.0015202898 Test MSE 0.00046605777272544236 Test RE 0.05052214043587803\n",
      "134 Train Loss 0.001487184 Test MSE 0.00045417482530064223 Test RE 0.04987390720967707\n",
      "135 Train Loss 0.0014750588 Test MSE 0.0004497707320307023 Test RE 0.04963150670181703\n",
      "136 Train Loss 0.0014631113 Test MSE 0.00042921657786994683 Test RE 0.04848418591084949\n",
      "137 Train Loss 0.0014501804 Test MSE 0.0004236445027356857 Test RE 0.048168447805049516\n",
      "138 Train Loss 0.0014336176 Test MSE 0.00042416177388733865 Test RE 0.04819784574043658\n",
      "139 Train Loss 0.0014192332 Test MSE 0.0004215563048933087 Test RE 0.048049586939470396\n",
      "140 Train Loss 0.0014095758 Test MSE 0.00040695590402405394 Test RE 0.04721016744559411\n",
      "141 Train Loss 0.0014003748 Test MSE 0.00040883850498993807 Test RE 0.047319239896036425\n",
      "142 Train Loss 0.0013895553 Test MSE 0.00040095709668952007 Test RE 0.04686092061417463\n",
      "143 Train Loss 0.0013782538 Test MSE 0.00039434230309297444 Test RE 0.046472768825553484\n",
      "144 Train Loss 0.0013704193 Test MSE 0.0003948313355456174 Test RE 0.04650157584212401\n",
      "145 Train Loss 0.0013656034 Test MSE 0.00039179049686142997 Test RE 0.04632216112652249\n",
      "146 Train Loss 0.0013621462 Test MSE 0.0003931674312314013 Test RE 0.04640348856311708\n",
      "147 Train Loss 0.0013558205 Test MSE 0.0004032767126675639 Test RE 0.046996274973063495\n",
      "148 Train Loss 0.0013486496 Test MSE 0.0004042886998657766 Test RE 0.04705520452174802\n",
      "149 Train Loss 0.0013371924 Test MSE 0.0003902888633962029 Test RE 0.046233305365181894\n",
      "150 Train Loss 0.0013221902 Test MSE 0.0003766267815018691 Test RE 0.04541689749665558\n",
      "151 Train Loss 0.0013119888 Test MSE 0.00037512233310745804 Test RE 0.045326097064364204\n",
      "152 Train Loss 0.0012962547 Test MSE 0.0003704860068576181 Test RE 0.045045122131846256\n",
      "153 Train Loss 0.0012795234 Test MSE 0.00036612099762136366 Test RE 0.04477897853778337\n",
      "154 Train Loss 0.0012670909 Test MSE 0.0003687944208779114 Test RE 0.04494216969678735\n",
      "155 Train Loss 0.001260726 Test MSE 0.0003593358270332569 Test RE 0.044362102818298076\n",
      "156 Train Loss 0.0012557214 Test MSE 0.00035971210693757917 Test RE 0.04438532371489847\n",
      "157 Train Loss 0.0012522761 Test MSE 0.0003599812637388306 Test RE 0.044401926405741345\n",
      "158 Train Loss 0.001249955 Test MSE 0.0003627218485785707 Test RE 0.04457062479477042\n",
      "159 Train Loss 0.0012440982 Test MSE 0.0003587299625833119 Test RE 0.044324688291486496\n",
      "160 Train Loss 0.0012370787 Test MSE 0.00035795892825568685 Test RE 0.04427702815226504\n",
      "161 Train Loss 0.0012322778 Test MSE 0.0003523577642696222 Test RE 0.04392924982104472\n",
      "162 Train Loss 0.0012283644 Test MSE 0.00034882964515756874 Test RE 0.04370876716864255\n",
      "163 Train Loss 0.0012187171 Test MSE 0.00034331736613899504 Test RE 0.04336204442713501\n",
      "164 Train Loss 0.0012085671 Test MSE 0.0003346696108123962 Test RE 0.042812442285570754\n",
      "165 Train Loss 0.0011913372 Test MSE 0.00034686485505314515 Test RE 0.043585498082501686\n",
      "166 Train Loss 0.0011815603 Test MSE 0.00034365045658203794 Test RE 0.043383074503682305\n",
      "167 Train Loss 0.0011694992 Test MSE 0.0003495354698820135 Test RE 0.04375296515874443\n",
      "168 Train Loss 0.0011650401 Test MSE 0.00035138739659502894 Test RE 0.04386871913735048\n",
      "169 Train Loss 0.001161698 Test MSE 0.0003473178582302697 Test RE 0.04361394998029857\n",
      "170 Train Loss 0.0011586556 Test MSE 0.00034804297883566087 Test RE 0.04365945424048546\n",
      "171 Train Loss 0.001153941 Test MSE 0.00035528366157042346 Test RE 0.04411126191588525\n",
      "172 Train Loss 0.0011500802 Test MSE 0.0003531626894751233 Test RE 0.0439793971331215\n",
      "173 Train Loss 0.0011434628 Test MSE 0.00035119595003098926 Test RE 0.04385676700149899\n",
      "174 Train Loss 0.0011316129 Test MSE 0.0003532383451350657 Test RE 0.043984107585607675\n",
      "175 Train Loss 0.001120563 Test MSE 0.0003486810486942685 Test RE 0.043699456520672954\n",
      "176 Train Loss 0.0011016489 Test MSE 0.0003444133701160872 Test RE 0.043431203620136215\n",
      "177 Train Loss 0.0010820699 Test MSE 0.0003399360522589056 Test RE 0.043147980851014886\n",
      "178 Train Loss 0.0010690943 Test MSE 0.0003365250629530206 Test RE 0.04293095713988314\n",
      "179 Train Loss 0.0010600149 Test MSE 0.000341813256599383 Test RE 0.04326695331998498\n",
      "180 Train Loss 0.0010490067 Test MSE 0.00033491440905691737 Test RE 0.04282809726972615\n",
      "181 Train Loss 0.0010320236 Test MSE 0.00032485437844874903 Test RE 0.04217996610008936\n",
      "182 Train Loss 0.0010223237 Test MSE 0.00032402319389984377 Test RE 0.04212596992027635\n",
      "183 Train Loss 0.0010155833 Test MSE 0.00032052711625920184 Test RE 0.0418980925907515\n",
      "184 Train Loss 0.001006695 Test MSE 0.0003210833882278042 Test RE 0.04193443371428195\n",
      "185 Train Loss 0.0009998344 Test MSE 0.00031758958467990644 Test RE 0.04170565916776002\n",
      "186 Train Loss 0.0009941431 Test MSE 0.0003183783966544318 Test RE 0.041757420186930246\n",
      "187 Train Loss 0.000984496 Test MSE 0.00029730467405900514 Test RE 0.040351783292362\n",
      "188 Train Loss 0.00096892635 Test MSE 0.00029828639884219173 Test RE 0.040418350858520045\n",
      "189 Train Loss 0.00095657463 Test MSE 0.0002924790492794726 Test RE 0.04002296372083954\n",
      "190 Train Loss 0.0009434989 Test MSE 0.00028305497336686853 Test RE 0.03937288687464393\n",
      "191 Train Loss 0.0009277525 Test MSE 0.00027062986764093006 Test RE 0.03849902461048516\n",
      "192 Train Loss 0.0009094649 Test MSE 0.00026199275936704755 Test RE 0.03787969805671785\n",
      "193 Train Loss 0.0008971161 Test MSE 0.000249266811525603 Test RE 0.03694826869895046\n",
      "194 Train Loss 0.0008854805 Test MSE 0.00024714514856401866 Test RE 0.0367906879593443\n",
      "195 Train Loss 0.0008749576 Test MSE 0.00024394921026534195 Test RE 0.03655203595905879\n",
      "196 Train Loss 0.0008610305 Test MSE 0.0002496963847699324 Test RE 0.03698009234047368\n",
      "197 Train Loss 0.0008541521 Test MSE 0.00024932946351958774 Test RE 0.03695291179053126\n",
      "198 Train Loss 0.00084522006 Test MSE 0.00024123392236959163 Test RE 0.03634804467909875\n",
      "199 Train Loss 0.0008366285 Test MSE 0.00024130177670545416 Test RE 0.03635315631306032\n",
      "200 Train Loss 0.00082754286 Test MSE 0.0002342913522830292 Test RE 0.03582118870521316\n",
      "201 Train Loss 0.0008192897 Test MSE 0.0002473819920492598 Test RE 0.0368083123153233\n",
      "202 Train Loss 0.00080766284 Test MSE 0.00024706836681407 Test RE 0.036784972547052215\n",
      "203 Train Loss 0.0008003201 Test MSE 0.00023569439465598457 Test RE 0.0359282853323496\n",
      "204 Train Loss 0.0007956599 Test MSE 0.000240378284124698 Test RE 0.036283525552011225\n",
      "205 Train Loss 0.00078580965 Test MSE 0.00023863546599010158 Test RE 0.03615175278512754\n",
      "206 Train Loss 0.00077572145 Test MSE 0.0002341424357068384 Test RE 0.03580980284604377\n",
      "207 Train Loss 0.0007698892 Test MSE 0.00023364553091327424 Test RE 0.0357717842923914\n",
      "208 Train Loss 0.0007626982 Test MSE 0.00022857651600610877 Test RE 0.035381616303047064\n",
      "209 Train Loss 0.0007548341 Test MSE 0.00022779800609910826 Test RE 0.03532131169873599\n",
      "210 Train Loss 0.00074217905 Test MSE 0.00021282299740744973 Test RE 0.034140599410134066\n",
      "211 Train Loss 0.00072814565 Test MSE 0.00020934514849181687 Test RE 0.033860495912767824\n",
      "212 Train Loss 0.00072222285 Test MSE 0.00021440707577916946 Test RE 0.03426742105133661\n",
      "213 Train Loss 0.00071625714 Test MSE 0.00021910314563948816 Test RE 0.034640660994770776\n",
      "214 Train Loss 0.0007098048 Test MSE 0.00021412619207823797 Test RE 0.03424496770077708\n",
      "215 Train Loss 0.00070096616 Test MSE 0.00021492157419195426 Test RE 0.03430851104252077\n",
      "216 Train Loss 0.0006959822 Test MSE 0.00021863344769717358 Test RE 0.03460351096557077\n",
      "217 Train Loss 0.00069199974 Test MSE 0.00021787843043671274 Test RE 0.034543710319533495\n",
      "218 Train Loss 0.0006865582 Test MSE 0.00021515648057601573 Test RE 0.034327255292210715\n",
      "219 Train Loss 0.00067738415 Test MSE 0.00021240305931482414 Test RE 0.0341069000033539\n",
      "220 Train Loss 0.00066722493 Test MSE 0.00021126076618827283 Test RE 0.03401506375524048\n",
      "221 Train Loss 0.0006583035 Test MSE 0.0002034529857774256 Test RE 0.03338058149642958\n",
      "222 Train Loss 0.0006484017 Test MSE 0.00019695270019358423 Test RE 0.03284300101201242\n",
      "223 Train Loss 0.00063210254 Test MSE 0.0001808861849784495 Test RE 0.031474914835805785\n",
      "224 Train Loss 0.00062052225 Test MSE 0.00017502818710881478 Test RE 0.030961062872024287\n",
      "225 Train Loss 0.0006088138 Test MSE 0.000171557891274784 Test RE 0.030652592646588445\n",
      "226 Train Loss 0.0005987096 Test MSE 0.00016356897366317987 Test RE 0.029930386728327377\n",
      "227 Train Loss 0.00058481406 Test MSE 0.00015822843060781853 Test RE 0.029437716893446847\n",
      "228 Train Loss 0.00057447696 Test MSE 0.00014642542056101775 Test RE 0.028318490777022063\n",
      "229 Train Loss 0.0005686979 Test MSE 0.00014658164221409114 Test RE 0.028333593284735226\n",
      "230 Train Loss 0.00056510826 Test MSE 0.00013960096563417953 Test RE 0.02765069649318568\n",
      "231 Train Loss 0.0005613556 Test MSE 0.00013878405441800526 Test RE 0.027569675183045816\n",
      "232 Train Loss 0.0005560729 Test MSE 0.00013376792932241107 Test RE 0.027066859353642565\n",
      "233 Train Loss 0.00055013073 Test MSE 0.00012718629987918778 Test RE 0.026392591174251537\n",
      "234 Train Loss 0.0005459546 Test MSE 0.00012893731639783385 Test RE 0.02657364797165346\n",
      "235 Train Loss 0.0005396394 Test MSE 0.00012928265570342947 Test RE 0.026609210944630906\n",
      "236 Train Loss 0.0005341533 Test MSE 0.00012887822882099473 Test RE 0.0265675583754037\n",
      "237 Train Loss 0.0005294889 Test MSE 0.00012766765795786854 Test RE 0.026442487622622707\n",
      "238 Train Loss 0.00052599976 Test MSE 0.00012525521509614297 Test RE 0.026191463887151826\n",
      "239 Train Loss 0.0005186497 Test MSE 0.00012566734870437464 Test RE 0.026234518053638845\n",
      "240 Train Loss 0.0005149581 Test MSE 0.0001186917840924628 Test RE 0.025496008367256538\n",
      "241 Train Loss 0.0005102634 Test MSE 0.00010958358280132473 Test RE 0.024498224590189768\n",
      "242 Train Loss 0.0005045931 Test MSE 0.00010377175707535558 Test RE 0.02383973640952687\n",
      "243 Train Loss 0.0004982381 Test MSE 9.928357193137756e-05 Test RE 0.023318497339610278\n",
      "244 Train Loss 0.0004914092 Test MSE 9.288086610756736e-05 Test RE 0.022554073546958403\n",
      "245 Train Loss 0.00048412802 Test MSE 9.873176697838566e-05 Test RE 0.023253606489242275\n",
      "246 Train Loss 0.00047967985 Test MSE 9.720409169833117e-05 Test RE 0.023073003782330355\n",
      "247 Train Loss 0.00047266937 Test MSE 0.00010398093509814234 Test RE 0.023863751799575967\n",
      "248 Train Loss 0.00046253527 Test MSE 0.0001055990138892411 Test RE 0.024048710558421657\n",
      "249 Train Loss 0.00045227353 Test MSE 9.727791876594558e-05 Test RE 0.023081764158902323\n",
      "250 Train Loss 0.00044724782 Test MSE 9.143180881806301e-05 Test RE 0.02237744610603414\n",
      "251 Train Loss 0.00044225535 Test MSE 9.509782868122957e-05 Test RE 0.02282165651338453\n",
      "252 Train Loss 0.00043628312 Test MSE 9.504397252098288e-05 Test RE 0.022815193374993867\n",
      "253 Train Loss 0.00043127796 Test MSE 9.372087999008876e-05 Test RE 0.02265583342509096\n",
      "254 Train Loss 0.00042894337 Test MSE 8.993736858672846e-05 Test RE 0.02219381453027873\n",
      "255 Train Loss 0.00042761804 Test MSE 8.916555004500502e-05 Test RE 0.022098378635340157\n",
      "256 Train Loss 0.0004260558 Test MSE 8.77884476825124e-05 Test RE 0.021927067265374828\n",
      "257 Train Loss 0.0004231741 Test MSE 8.908554149478223e-05 Test RE 0.022088461935250117\n",
      "258 Train Loss 0.00042126054 Test MSE 9.118015674882035e-05 Test RE 0.02234662963813584\n",
      "259 Train Loss 0.0004173533 Test MSE 9.210484973653255e-05 Test RE 0.022459656675101542\n",
      "260 Train Loss 0.0004138528 Test MSE 9.625949136653878e-05 Test RE 0.022960621812348175\n",
      "261 Train Loss 0.00040883527 Test MSE 9.275229442396456e-05 Test RE 0.022538457739566784\n",
      "262 Train Loss 0.00040455285 Test MSE 8.949212980292572e-05 Test RE 0.022138810657773268\n",
      "263 Train Loss 0.00040049813 Test MSE 8.74655949406817e-05 Test RE 0.021886710392470827\n",
      "264 Train Loss 0.00039492548 Test MSE 9.200183308863721e-05 Test RE 0.022447092918310905\n",
      "265 Train Loss 0.0003915962 Test MSE 9.166648885470394e-05 Test RE 0.02240614604343527\n",
      "266 Train Loss 0.00038843902 Test MSE 9.356185748335564e-05 Test RE 0.022636604428337478\n",
      "267 Train Loss 0.00038482036 Test MSE 9.370279686199912e-05 Test RE 0.022653647636279813\n",
      "268 Train Loss 0.00038229302 Test MSE 9.660532345594629e-05 Test RE 0.023001830219418724\n",
      "269 Train Loss 0.00038095488 Test MSE 9.446126211670595e-05 Test RE 0.022745146373919348\n",
      "270 Train Loss 0.00037813952 Test MSE 9.34994491100475e-05 Test RE 0.02262905354512464\n",
      "271 Train Loss 0.00037652728 Test MSE 8.914440730327607e-05 Test RE 0.022095758520218722\n",
      "272 Train Loss 0.00037340957 Test MSE 8.729939672071374e-05 Test RE 0.021865906429933076\n",
      "273 Train Loss 0.00037093513 Test MSE 8.73583459683285e-05 Test RE 0.02187328770206877\n",
      "274 Train Loss 0.0003684003 Test MSE 8.549542758347645e-05 Test RE 0.021638806750300908\n",
      "275 Train Loss 0.00036612173 Test MSE 8.502243232318088e-05 Test RE 0.021578866419407455\n",
      "276 Train Loss 0.00036441 Test MSE 8.219963563333388e-05 Test RE 0.021217626995030662\n",
      "277 Train Loss 0.00036218434 Test MSE 7.835609204671753e-05 Test RE 0.020715634883958094\n",
      "278 Train Loss 0.00035996534 Test MSE 8.111636604410338e-05 Test RE 0.02107735485055792\n",
      "279 Train Loss 0.0003580543 Test MSE 7.914085726488541e-05 Test RE 0.0208191138039463\n",
      "280 Train Loss 0.00035609107 Test MSE 8.042909369044966e-05 Test RE 0.02098787415635857\n",
      "281 Train Loss 0.00035239183 Test MSE 7.946348529726366e-05 Test RE 0.020861506560127835\n",
      "282 Train Loss 0.000351097 Test MSE 7.75562582765732e-05 Test RE 0.02060963441847229\n",
      "283 Train Loss 0.00034880626 Test MSE 7.284742716462067e-05 Test RE 0.01997418063157054\n",
      "284 Train Loss 0.00034590854 Test MSE 6.848476200420543e-05 Test RE 0.019366843337473915\n",
      "285 Train Loss 0.00034402488 Test MSE 6.90558595144073e-05 Test RE 0.019447426179039433\n",
      "286 Train Loss 0.00034193025 Test MSE 6.765144238841717e-05 Test RE 0.019248655255061493\n",
      "287 Train Loss 0.00033984976 Test MSE 6.688678937083795e-05 Test RE 0.019139563942062735\n",
      "288 Train Loss 0.00033677657 Test MSE 6.506211245708173e-05 Test RE 0.018876694359439936\n",
      "289 Train Loss 0.00033537386 Test MSE 6.601502492982884e-05 Test RE 0.019014427760846882\n",
      "290 Train Loss 0.00033371657 Test MSE 6.760733000224216e-05 Test RE 0.01924237865145531\n",
      "291 Train Loss 0.00033195163 Test MSE 6.608991977421593e-05 Test RE 0.019025210752514253\n",
      "292 Train Loss 0.00033034824 Test MSE 6.551366679491832e-05 Test RE 0.018942086600439417\n",
      "293 Train Loss 0.0003288931 Test MSE 6.312548807562964e-05 Test RE 0.01859363231184984\n",
      "294 Train Loss 0.0003270548 Test MSE 6.386781681544086e-05 Test RE 0.018702639360997607\n",
      "295 Train Loss 0.0003236103 Test MSE 6.142539223922241e-05 Test RE 0.01834154151878787\n",
      "296 Train Loss 0.0003197165 Test MSE 5.883507062095127e-05 Test RE 0.017950642742402153\n",
      "297 Train Loss 0.00031642427 Test MSE 5.9080579810785264e-05 Test RE 0.017988056310568063\n",
      "298 Train Loss 0.00031207583 Test MSE 5.8583062084577874e-05 Test RE 0.01791215745062272\n",
      "299 Train Loss 0.00030734402 Test MSE 5.7870821721928084e-05 Test RE 0.017802938376684643\n",
      "Training time: 162.25\n",
      "KG_tanh_low\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 10656.926 Test MSE 6.427023177213881 Test RE 5.932896841325147\n",
      "1 Train Loss 5802.7197 Test MSE 5.7743987099295735 Test RE 5.623610690891561\n",
      "2 Train Loss 1589.612 Test MSE 8.886149856816301 Test RE 6.976196107298212\n",
      "3 Train Loss 325.38104 Test MSE 12.822578616727995 Test RE 8.380106718012094\n",
      "4 Train Loss 113.58959 Test MSE 14.91089018044431 Test RE 9.036778758154753\n",
      "5 Train Loss 65.63602 Test MSE 15.643392720009759 Test RE 9.256085084980377\n",
      "6 Train Loss 46.807564 Test MSE 15.671155226335951 Test RE 9.264294883633044\n",
      "7 Train Loss 35.773197 Test MSE 14.973572833031604 Test RE 9.055753319442541\n",
      "8 Train Loss 30.471113 Test MSE 14.711369441761947 Test RE 8.976115143941687\n",
      "9 Train Loss 27.151035 Test MSE 14.483128718361115 Test RE 8.90621262718722\n",
      "10 Train Loss 25.229946 Test MSE 14.253182345385135 Test RE 8.835228475273327\n",
      "11 Train Loss 23.467237 Test MSE 14.012138836933945 Test RE 8.760201179748227\n",
      "12 Train Loss 21.674932 Test MSE 13.546164605852288 Test RE 8.613309211504712\n",
      "13 Train Loss 19.163721 Test MSE 12.745308459312064 Test RE 8.35481887776291\n",
      "14 Train Loss 17.167553 Test MSE 11.817696144403243 Test RE 8.04504122088349\n",
      "15 Train Loss 14.769605 Test MSE 10.504061594733082 Test RE 7.5847364349880975\n",
      "16 Train Loss 13.171567 Test MSE 9.659724271764352 Test RE 7.27351316199266\n",
      "17 Train Loss 12.071464 Test MSE 9.02810619423055 Test RE 7.031697728893879\n",
      "18 Train Loss 11.448823 Test MSE 8.580313131226193 Test RE 6.855094289075026\n",
      "19 Train Loss 10.742229 Test MSE 7.96263879032697 Test RE 6.603746167684531\n",
      "20 Train Loss 10.080953 Test MSE 7.647735120757215 Test RE 6.47184761514402\n",
      "21 Train Loss 9.326811 Test MSE 6.985057675524629 Test RE 6.185101945541081\n",
      "22 Train Loss 8.654442 Test MSE 6.387871138703747 Test RE 5.914798272333322\n",
      "23 Train Loss 7.737434 Test MSE 5.949543201782525 Test RE 5.70825906823372\n",
      "24 Train Loss 7.2751565 Test MSE 5.524080659256709 Test RE 5.5003695565031645\n",
      "25 Train Loss 6.8321075 Test MSE 5.032358427377759 Test RE 5.249859092841026\n",
      "26 Train Loss 6.2078424 Test MSE 4.597583612784294 Test RE 5.017954073266846\n",
      "27 Train Loss 5.633015 Test MSE 4.109890103008821 Test RE 4.744352712750748\n",
      "28 Train Loss 4.9673796 Test MSE 3.322006100647204 Test RE 4.265422709831143\n",
      "29 Train Loss 4.36143 Test MSE 2.8678416038424515 Test RE 3.963140275069668\n",
      "30 Train Loss 3.257678 Test MSE 1.5372575302176419 Test RE 2.901584205860699\n",
      "31 Train Loss 2.454672 Test MSE 0.9759403477576364 Test RE 2.3119237190651574\n",
      "32 Train Loss 1.8992174 Test MSE 0.6148586183008253 Test RE 1.8350567368223916\n",
      "33 Train Loss 1.5545353 Test MSE 0.4701437102737993 Test RE 1.6046383936846518\n",
      "34 Train Loss 1.3669751 Test MSE 0.43347296866212764 Test RE 1.5407879527205635\n",
      "35 Train Loss 1.1770201 Test MSE 0.3575692840504429 Test RE 1.3994003123158187\n",
      "36 Train Loss 0.95660424 Test MSE 0.32517714652959534 Test RE 1.3345101212029662\n",
      "37 Train Loss 0.8016411 Test MSE 0.27017047456763066 Test RE 1.2164123109559832\n",
      "38 Train Loss 0.63843447 Test MSE 0.2302233736673068 Test RE 1.122888336727311\n",
      "39 Train Loss 0.523866 Test MSE 0.23887961629997612 Test RE 1.143803471818507\n",
      "40 Train Loss 0.453646 Test MSE 0.23192238064909718 Test RE 1.127024077216371\n",
      "41 Train Loss 0.38260585 Test MSE 0.1815391940899377 Test RE 0.9971191695341141\n",
      "42 Train Loss 0.3301274 Test MSE 0.16018668445068554 Test RE 0.9366451103081835\n",
      "43 Train Loss 0.26502565 Test MSE 0.1366529310143805 Test RE 0.8651100148524073\n",
      "44 Train Loss 0.22504964 Test MSE 0.13009685288776004 Test RE 0.8441026417763547\n",
      "45 Train Loss 0.19434997 Test MSE 0.1106747966990837 Test RE 0.7785495006409631\n",
      "46 Train Loss 0.16386367 Test MSE 0.08392230603126 Test RE 0.6779545324163133\n",
      "47 Train Loss 0.14453873 Test MSE 0.07124538320997638 Test RE 0.6246550098143845\n",
      "48 Train Loss 0.12253138 Test MSE 0.059667618319839834 Test RE 0.571651326414651\n",
      "49 Train Loss 0.10889752 Test MSE 0.058001192914671665 Test RE 0.563612124255233\n",
      "50 Train Loss 0.0993757 Test MSE 0.042951235365972965 Test RE 0.48500888409596077\n",
      "51 Train Loss 0.08433773 Test MSE 0.042026776918382004 Test RE 0.4797609617221841\n",
      "52 Train Loss 0.07452858 Test MSE 0.030999536268266053 Test RE 0.4120400797993215\n",
      "53 Train Loss 0.063480094 Test MSE 0.02266658697077194 Test RE 0.3523343043980749\n",
      "54 Train Loss 0.05809347 Test MSE 0.018901128384471014 Test RE 0.3217404982670287\n",
      "55 Train Loss 0.05179543 Test MSE 0.015931816933418576 Test RE 0.2953891354832859\n",
      "56 Train Loss 0.04637129 Test MSE 0.01514607153998425 Test RE 0.2880128508251671\n",
      "57 Train Loss 0.042962223 Test MSE 0.013059998613092937 Test RE 0.2674443512191001\n",
      "58 Train Loss 0.04007556 Test MSE 0.009777187834111647 Test RE 0.2314029245371306\n",
      "59 Train Loss 0.037461706 Test MSE 0.009355903891116915 Test RE 0.22636263459347114\n",
      "60 Train Loss 0.032622743 Test MSE 0.006123267641028366 Test RE 0.18312746568931967\n",
      "61 Train Loss 0.030258853 Test MSE 0.0053554418339848186 Test RE 0.17126141085119123\n",
      "62 Train Loss 0.02762146 Test MSE 0.005179705025941034 Test RE 0.16842803355029928\n",
      "63 Train Loss 0.024929322 Test MSE 0.005458512539561201 Test RE 0.17290160319629186\n",
      "64 Train Loss 0.023172565 Test MSE 0.005847586404595696 Test RE 0.17895761693242346\n",
      "65 Train Loss 0.021026554 Test MSE 0.005378058448957646 Test RE 0.1716226576654296\n",
      "66 Train Loss 0.020089595 Test MSE 0.0044682648594288185 Test RE 0.15643406047320504\n",
      "67 Train Loss 0.01848987 Test MSE 0.0038955347049732195 Test RE 0.14606474435703676\n",
      "68 Train Loss 0.01676008 Test MSE 0.00339294958271353 Test RE 0.13631717182604958\n",
      "69 Train Loss 0.01596302 Test MSE 0.0031978005811152815 Test RE 0.13233890978812798\n",
      "70 Train Loss 0.015258527 Test MSE 0.0025794701960511653 Test RE 0.11885764503143414\n",
      "71 Train Loss 0.014637507 Test MSE 0.0021085832123912333 Test RE 0.10746257338167027\n",
      "72 Train Loss 0.014093841 Test MSE 0.0018247996185013146 Test RE 0.09996994536891807\n",
      "73 Train Loss 0.013101553 Test MSE 0.0017849895172121647 Test RE 0.09887345244098297\n",
      "74 Train Loss 0.012537636 Test MSE 0.0018671390881167859 Test RE 0.10112305919217668\n",
      "75 Train Loss 0.01169921 Test MSE 0.0019382040401812075 Test RE 0.10302950452927828\n",
      "76 Train Loss 0.010784054 Test MSE 0.0017792529771611888 Test RE 0.09871444647666469\n",
      "77 Train Loss 0.010473615 Test MSE 0.0014546646090152762 Test RE 0.08925720854719119\n",
      "78 Train Loss 0.00975614 Test MSE 0.00097383562010843 Test RE 0.07303057027090347\n",
      "79 Train Loss 0.009255807 Test MSE 0.0006600743342782757 Test RE 0.0601254427207171\n",
      "80 Train Loss 0.00901184 Test MSE 0.00062766101713323 Test RE 0.058630613983842075\n",
      "81 Train Loss 0.008339101 Test MSE 0.0006556673290065653 Test RE 0.059924391954860746\n",
      "82 Train Loss 0.008051717 Test MSE 0.0006983874185338654 Test RE 0.061845779471806916\n",
      "83 Train Loss 0.0077427467 Test MSE 0.0006230130850115311 Test RE 0.05841312597635616\n",
      "84 Train Loss 0.0075516356 Test MSE 0.0005271044245746802 Test RE 0.05372917781990434\n",
      "85 Train Loss 0.0072455825 Test MSE 0.00046308737696168717 Test RE 0.05036088292353841\n",
      "86 Train Loss 0.0069930754 Test MSE 0.0004593398998647159 Test RE 0.05015669940609537\n",
      "87 Train Loss 0.006523493 Test MSE 0.00042969503110099587 Test RE 0.04851120135664762\n",
      "88 Train Loss 0.006329394 Test MSE 0.00043546425023428673 Test RE 0.048835778758698836\n",
      "89 Train Loss 0.006087885 Test MSE 0.00036137266215064144 Test RE 0.044487654737306606\n",
      "90 Train Loss 0.0058366386 Test MSE 0.00029605367093485916 Test RE 0.040266797373477346\n",
      "91 Train Loss 0.0052451757 Test MSE 0.0003215926976039807 Test RE 0.04196767918617092\n",
      "92 Train Loss 0.0049131056 Test MSE 0.0003556139705816792 Test RE 0.04413176238343598\n",
      "93 Train Loss 0.004798194 Test MSE 0.00034323056456753284 Test RE 0.04335656242723131\n",
      "94 Train Loss 0.004592939 Test MSE 0.0002901982171866105 Test RE 0.03986660324762722\n",
      "95 Train Loss 0.0044759233 Test MSE 0.0002722535931016204 Test RE 0.038614345145103326\n",
      "96 Train Loss 0.004230815 Test MSE 0.00027420927289006594 Test RE 0.0387527862259191\n",
      "97 Train Loss 0.00393539 Test MSE 0.0002639041364103323 Test RE 0.03801762326398098\n",
      "98 Train Loss 0.0037621884 Test MSE 0.0002494634041816321 Test RE 0.036962836074762404\n",
      "99 Train Loss 0.0036788012 Test MSE 0.00025757278652929 Test RE 0.03755881246013592\n",
      "100 Train Loss 0.003624777 Test MSE 0.0002442958329742995 Test RE 0.036577994781279634\n",
      "101 Train Loss 0.0035407061 Test MSE 0.00024072156712752563 Test RE 0.03630942446777055\n",
      "102 Train Loss 0.003463845 Test MSE 0.00023542515942641078 Test RE 0.03590775891259532\n",
      "103 Train Loss 0.0033943283 Test MSE 0.00022101157235530292 Test RE 0.03479119701436494\n",
      "104 Train Loss 0.0032874488 Test MSE 0.00021769223398135528 Test RE 0.03452894683158327\n",
      "105 Train Loss 0.0032249717 Test MSE 0.0002016254807215367 Test RE 0.03323032371239895\n",
      "106 Train Loss 0.0031636492 Test MSE 0.0002071914232634106 Test RE 0.0336858686511536\n",
      "107 Train Loss 0.0031052018 Test MSE 0.00021648093295076025 Test RE 0.03443274842338644\n",
      "108 Train Loss 0.0030385866 Test MSE 0.0002003380394369569 Test RE 0.033124060844133656\n",
      "109 Train Loss 0.0029460152 Test MSE 0.00019113378964422128 Test RE 0.032354195054125484\n",
      "110 Train Loss 0.0027931507 Test MSE 0.0001856716019270838 Test RE 0.03188853783330562\n",
      "111 Train Loss 0.002637933 Test MSE 0.0001615601696841826 Test RE 0.029746030188356025\n",
      "112 Train Loss 0.0025525477 Test MSE 0.00016071240252717937 Test RE 0.02966788321598626\n",
      "113 Train Loss 0.0025121565 Test MSE 0.00015827893073340287 Test RE 0.029442414183930312\n",
      "114 Train Loss 0.0024478068 Test MSE 0.00015647032671763656 Test RE 0.02927371623887178\n",
      "115 Train Loss 0.0023870564 Test MSE 0.00015124031470173 Test RE 0.0287803221077608\n",
      "116 Train Loss 0.0023525392 Test MSE 0.00014985464151213277 Test RE 0.028648175174186236\n",
      "117 Train Loss 0.002300648 Test MSE 0.00015592965869811026 Test RE 0.029223096231018802\n",
      "118 Train Loss 0.0022519976 Test MSE 0.00015413589593470247 Test RE 0.029054523654053237\n",
      "119 Train Loss 0.0022263494 Test MSE 0.00016041093131552144 Test RE 0.029640044011018427\n",
      "120 Train Loss 0.0021691073 Test MSE 0.00016866558346460126 Test RE 0.03039310710624963\n",
      "121 Train Loss 0.0021307545 Test MSE 0.00017613729621471368 Test RE 0.031059004150271647\n",
      "122 Train Loss 0.0020669685 Test MSE 0.00018576755985974977 Test RE 0.03189677701172135\n",
      "123 Train Loss 0.002015122 Test MSE 0.0001952549203907723 Test RE 0.03270113732843075\n",
      "124 Train Loss 0.001959973 Test MSE 0.000218491260513265 Test RE 0.03459225702423057\n",
      "125 Train Loss 0.0019067267 Test MSE 0.00022823904846314778 Test RE 0.03535548816517848\n",
      "126 Train Loss 0.0018648446 Test MSE 0.00024298534173053184 Test RE 0.0364797540547438\n",
      "127 Train Loss 0.0018176925 Test MSE 0.00023766836077169267 Test RE 0.03607842327540435\n",
      "128 Train Loss 0.0017711594 Test MSE 0.0002632306675461789 Test RE 0.037969082832629966\n",
      "129 Train Loss 0.0017520498 Test MSE 0.000258377912658138 Test RE 0.03761746770022822\n",
      "130 Train Loss 0.0017331127 Test MSE 0.0002596566308005873 Test RE 0.03771043766445537\n",
      "131 Train Loss 0.0016944079 Test MSE 0.00025698819652384997 Test RE 0.037516166303653904\n",
      "132 Train Loss 0.0016575202 Test MSE 0.00025452087292329213 Test RE 0.0373356370557012\n",
      "133 Train Loss 0.0016251068 Test MSE 0.00024036085819645163 Test RE 0.03628221036338157\n",
      "134 Train Loss 0.0015823221 Test MSE 0.00024624372359787074 Test RE 0.036723532402500945\n",
      "135 Train Loss 0.0015662088 Test MSE 0.00026358339320577384 Test RE 0.03799451335410735\n",
      "136 Train Loss 0.0015477622 Test MSE 0.0002720806503862896 Test RE 0.03860207876785773\n",
      "137 Train Loss 0.0015401887 Test MSE 0.00026857561398512024 Test RE 0.038352630173635965\n",
      "138 Train Loss 0.001526639 Test MSE 0.00026700917207707705 Test RE 0.038240622569359395\n",
      "139 Train Loss 0.0014954788 Test MSE 0.00026342675761350143 Test RE 0.037983222472997076\n",
      "140 Train Loss 0.0014294408 Test MSE 0.00025878174564613086 Test RE 0.0376468534226386\n",
      "141 Train Loss 0.0013822084 Test MSE 0.00022420479836130394 Test RE 0.03504163128173709\n",
      "142 Train Loss 0.0013609586 Test MSE 0.00021451731331910713 Test RE 0.03427622922790801\n",
      "143 Train Loss 0.001334545 Test MSE 0.00020802754478323323 Test RE 0.03375376992084597\n",
      "144 Train Loss 0.0013235701 Test MSE 0.00020390970386867423 Test RE 0.0334180274181157\n",
      "145 Train Loss 0.0013110426 Test MSE 0.00019876095268909564 Test RE 0.032993424812029035\n",
      "146 Train Loss 0.0012791159 Test MSE 0.00017912129708249505 Test RE 0.03132098970472479\n",
      "147 Train Loss 0.001255939 Test MSE 0.0001754888743180093 Test RE 0.03100178200605423\n",
      "148 Train Loss 0.0012345788 Test MSE 0.00017431270801666475 Test RE 0.030897716853007958\n",
      "149 Train Loss 0.0012103404 Test MSE 0.00017077338504695814 Test RE 0.03058242769057889\n",
      "150 Train Loss 0.0011830728 Test MSE 0.00017237778600226138 Test RE 0.03072575146018979\n",
      "151 Train Loss 0.0011596368 Test MSE 0.00016761202234218402 Test RE 0.03029803389524743\n",
      "152 Train Loss 0.001139934 Test MSE 0.00016246515815591874 Test RE 0.029829225883964448\n",
      "153 Train Loss 0.0011317586 Test MSE 0.00015701203036223027 Test RE 0.029324345575149104\n",
      "154 Train Loss 0.0011238393 Test MSE 0.00015695947009290536 Test RE 0.029319436956020944\n",
      "155 Train Loss 0.0011127425 Test MSE 0.00016135463518178743 Test RE 0.02972710293281401\n",
      "156 Train Loss 0.0011010455 Test MSE 0.00016495883051011073 Test RE 0.03005727802730876\n",
      "157 Train Loss 0.00107176 Test MSE 0.0001368390413598646 Test RE 0.027375803541381992\n",
      "158 Train Loss 0.0010434624 Test MSE 0.00013265038984911352 Test RE 0.02695355968193868\n",
      "159 Train Loss 0.0010195296 Test MSE 0.00012327885402071994 Test RE 0.025984009021229753\n",
      "160 Train Loss 0.0009931845 Test MSE 0.00012463243464810213 Test RE 0.026126269564607906\n",
      "161 Train Loss 0.0009781803 Test MSE 0.0001239783737138804 Test RE 0.026057625111480673\n",
      "162 Train Loss 0.0009685136 Test MSE 0.0001240419669671464 Test RE 0.026064307231361585\n",
      "163 Train Loss 0.0009615554 Test MSE 0.0001252367506747796 Test RE 0.026189533316640035\n",
      "164 Train Loss 0.0009536772 Test MSE 0.00012383126588546027 Test RE 0.02604216104985062\n",
      "165 Train Loss 0.00094267534 Test MSE 0.00012171356046100243 Test RE 0.025818520238392748\n",
      "166 Train Loss 0.000934338 Test MSE 0.00012159160712881636 Test RE 0.025805582305787018\n",
      "167 Train Loss 0.0009105084 Test MSE 0.0001246082454821644 Test RE 0.026123734095656572\n",
      "168 Train Loss 0.0008846811 Test MSE 0.00011095142229009347 Test RE 0.02465064577214041\n",
      "169 Train Loss 0.00086693256 Test MSE 0.00010210500144378818 Test RE 0.02364750750334542\n",
      "170 Train Loss 0.0008556876 Test MSE 0.0001028416824309423 Test RE 0.023732661802943866\n",
      "171 Train Loss 0.000843656 Test MSE 0.00010827608562266845 Test RE 0.024351635664229647\n",
      "172 Train Loss 0.0008238002 Test MSE 0.00010202143790954121 Test RE 0.023637828869838985\n",
      "173 Train Loss 0.0008158233 Test MSE 0.00010012152119575525 Test RE 0.023416694159994766\n",
      "174 Train Loss 0.00080935174 Test MSE 9.46098695414434e-05 Test RE 0.02276303079127641\n",
      "175 Train Loss 0.0007889804 Test MSE 7.9732118856577e-05 Test RE 0.020896738921471973\n",
      "176 Train Loss 0.0007720681 Test MSE 7.2196163940312e-05 Test RE 0.019884694601046887\n",
      "177 Train Loss 0.0007573561 Test MSE 6.939773964322067e-05 Test RE 0.01949550667415094\n",
      "178 Train Loss 0.0007416084 Test MSE 6.778565213113595e-05 Test RE 0.01926773893609508\n",
      "179 Train Loss 0.0007312378 Test MSE 6.93119213959497e-05 Test RE 0.01948344873266182\n",
      "180 Train Loss 0.000710488 Test MSE 6.47901921205762e-05 Test RE 0.018837206466331413\n",
      "181 Train Loss 0.0006956318 Test MSE 5.761112060565122e-05 Test RE 0.017762947224458526\n",
      "182 Train Loss 0.0006868989 Test MSE 5.623958287170992e-05 Test RE 0.01755023392392973\n",
      "183 Train Loss 0.0006721047 Test MSE 5.721150788236497e-05 Test RE 0.017701234731760357\n",
      "184 Train Loss 0.0006584009 Test MSE 5.5582881292923e-05 Test RE 0.017447467257325055\n",
      "185 Train Loss 0.0006529051 Test MSE 5.4699460108583435e-05 Test RE 0.017308258944426235\n",
      "186 Train Loss 0.000644894 Test MSE 5.2786387744086776e-05 Test RE 0.017002893549206474\n",
      "187 Train Loss 0.00063758343 Test MSE 5.402309681575177e-05 Test RE 0.01720091707161471\n",
      "188 Train Loss 0.0006293337 Test MSE 5.303123658836301e-05 Test RE 0.017042281756213605\n",
      "189 Train Loss 0.0006249074 Test MSE 5.219619464029258e-05 Test RE 0.016907573537535636\n",
      "190 Train Loss 0.0006172838 Test MSE 5.210679632928334e-05 Test RE 0.016893088226042997\n",
      "191 Train Loss 0.00060646574 Test MSE 5.253221878054071e-05 Test RE 0.01696190928446953\n",
      "192 Train Loss 0.00059172366 Test MSE 4.96343082654948e-05 Test RE 0.016487425678912905\n",
      "193 Train Loss 0.0005800524 Test MSE 5.344785014808833e-05 Test RE 0.017109092905033433\n",
      "194 Train Loss 0.00056943955 Test MSE 5.7054594226075544e-05 Test RE 0.017676943529826582\n",
      "195 Train Loss 0.0005550197 Test MSE 5.773590735769415e-05 Test RE 0.017782174254562688\n",
      "196 Train Loss 0.00053975364 Test MSE 5.778097475446055e-05 Test RE 0.017789113090479827\n",
      "197 Train Loss 0.0005226676 Test MSE 5.837388449649017e-05 Test RE 0.017880150140325946\n",
      "198 Train Loss 0.0005112992 Test MSE 5.8674886726443846e-05 Test RE 0.017926189948858095\n",
      "199 Train Loss 0.00049953355 Test MSE 5.672522147930304e-05 Test RE 0.01762584571010811\n",
      "200 Train Loss 0.00049272575 Test MSE 5.912712873490508e-05 Test RE 0.017995141208907037\n",
      "201 Train Loss 0.00048616523 Test MSE 5.656782739158332e-05 Test RE 0.017601375722271963\n",
      "202 Train Loss 0.0004765858 Test MSE 5.7815890320586896e-05 Test RE 0.017794487031938436\n",
      "203 Train Loss 0.00047276006 Test MSE 5.757594137949695e-05 Test RE 0.01775752307930921\n",
      "204 Train Loss 0.00046959904 Test MSE 5.730605647339671e-05 Test RE 0.01771585535592281\n",
      "205 Train Loss 0.0004632669 Test MSE 5.9509011993193645e-05 Test RE 0.01805316011588379\n",
      "206 Train Loss 0.0004505092 Test MSE 5.866835169847338e-05 Test RE 0.01792519163917795\n",
      "207 Train Loss 0.00044062518 Test MSE 5.959149676068567e-05 Test RE 0.018065667423703486\n",
      "208 Train Loss 0.00043071335 Test MSE 5.708128353205876e-05 Test RE 0.01768107755444319\n",
      "209 Train Loss 0.0004219347 Test MSE 5.7846278001133725e-05 Test RE 0.017799162754750714\n",
      "210 Train Loss 0.0004126405 Test MSE 5.326964703965479e-05 Test RE 0.017080546956583606\n",
      "211 Train Loss 0.00040728686 Test MSE 5.256674605736368e-05 Test RE 0.01696748255313981\n",
      "212 Train Loss 0.0004027078 Test MSE 5.0804871913793475e-05 Test RE 0.01668071047505329\n",
      "213 Train Loss 0.00039687863 Test MSE 5.1080065011148305e-05 Test RE 0.016725826394038818\n",
      "214 Train Loss 0.00039299455 Test MSE 5.028133046042571e-05 Test RE 0.01659454099824258\n",
      "215 Train Loss 0.00038940756 Test MSE 4.9311402125295284e-05 Test RE 0.016433707007587558\n",
      "216 Train Loss 0.00038926833 Test MSE 4.9070020449505366e-05 Test RE 0.016393435773174047\n",
      "217 Train Loss 0.00038670242 Test MSE 4.8104680777979026e-05 Test RE 0.016231383259857856\n",
      "218 Train Loss 0.00038365411 Test MSE 4.821800437382282e-05 Test RE 0.0162504907215491\n",
      "219 Train Loss 0.000379066 Test MSE 4.922989901252455e-05 Test RE 0.016420120371198412\n",
      "220 Train Loss 0.00037534346 Test MSE 5.059471225763324e-05 Test RE 0.016646173971993954\n",
      "221 Train Loss 0.0003694704 Test MSE 5.0600022408207787e-05 Test RE 0.016647047495798387\n",
      "222 Train Loss 0.00036426893 Test MSE 4.872205475490328e-05 Test RE 0.01633520773580252\n",
      "223 Train Loss 0.00035306055 Test MSE 4.656514314185782e-05 Test RE 0.015969537376873583\n",
      "224 Train Loss 0.0003482741 Test MSE 4.994548082740265e-05 Test RE 0.016539027269739458\n",
      "225 Train Loss 0.00034391007 Test MSE 4.716642956652185e-05 Test RE 0.016072312391450874\n",
      "226 Train Loss 0.00034104325 Test MSE 4.688913112470882e-05 Test RE 0.016024996990034488\n",
      "227 Train Loss 0.00033654177 Test MSE 4.702075249845098e-05 Test RE 0.01604747292366161\n",
      "228 Train Loss 0.00032990766 Test MSE 4.410511897339547e-05 Test RE 0.015541980617102547\n",
      "229 Train Loss 0.00032433146 Test MSE 4.350637296734901e-05 Test RE 0.015436125588664371\n",
      "230 Train Loss 0.00031966425 Test MSE 4.340952297840949e-05 Test RE 0.0154189347563762\n",
      "231 Train Loss 0.0003159429 Test MSE 4.26979636897115e-05 Test RE 0.015292040720853783\n",
      "232 Train Loss 0.00031370917 Test MSE 4.296482187068112e-05 Test RE 0.015339753181868676\n",
      "233 Train Loss 0.00031016557 Test MSE 4.2993584443340484e-05 Test RE 0.015344886881130256\n",
      "234 Train Loss 0.00030783835 Test MSE 4.361475336052553e-05 Test RE 0.015455340391463561\n",
      "235 Train Loss 0.00030559528 Test MSE 4.2749895640090217e-05 Test RE 0.01530133746600979\n",
      "236 Train Loss 0.00030086449 Test MSE 4.20541176114686e-05 Test RE 0.015176307812282063\n",
      "237 Train Loss 0.00029673273 Test MSE 3.966777466959102e-05 Test RE 0.014739433187730406\n",
      "238 Train Loss 0.00029475687 Test MSE 3.934195530223365e-05 Test RE 0.014678775703119365\n",
      "239 Train Loss 0.0002916153 Test MSE 3.968545443392921e-05 Test RE 0.01474271747425689\n",
      "240 Train Loss 0.0002890824 Test MSE 4.111838874539026e-05 Test RE 0.015006517123369433\n",
      "241 Train Loss 0.00028674476 Test MSE 4.1445555317849715e-05 Test RE 0.015066099994570101\n",
      "242 Train Loss 0.00028490718 Test MSE 4.292089479832728e-05 Test RE 0.0153319095235327\n",
      "243 Train Loss 0.00028299188 Test MSE 4.252861565354923e-05 Test RE 0.015261685058304844\n",
      "244 Train Loss 0.00027926717 Test MSE 4.2339552950785416e-05 Test RE 0.015227724049494165\n",
      "245 Train Loss 0.00027699326 Test MSE 4.144677559790955e-05 Test RE 0.015066321788269542\n",
      "246 Train Loss 0.00027454848 Test MSE 4.0595163171737976e-05 Test RE 0.014910733555437318\n",
      "247 Train Loss 0.00027236613 Test MSE 4.053692272498249e-05 Test RE 0.01490003376501936\n",
      "248 Train Loss 0.000270598 Test MSE 4.156666903904491e-05 Test RE 0.015088097290839906\n",
      "249 Train Loss 0.00026685811 Test MSE 3.813685981450454e-05 Test RE 0.014452212187162698\n",
      "250 Train Loss 0.0002640232 Test MSE 3.6905597311482746e-05 Test RE 0.01421700065394899\n",
      "251 Train Loss 0.00026109096 Test MSE 3.504464530141476e-05 Test RE 0.013853920731583346\n",
      "252 Train Loss 0.00025952034 Test MSE 3.447544964120647e-05 Test RE 0.013740952349909057\n",
      "253 Train Loss 0.00025837764 Test MSE 3.427278067213574e-05 Test RE 0.01370050371821963\n",
      "254 Train Loss 0.00025564304 Test MSE 3.389900629670028e-05 Test RE 0.013625590977966073\n",
      "255 Train Loss 0.00025087415 Test MSE 3.3574947146303154e-05 Test RE 0.013560307342829371\n",
      "256 Train Loss 0.00024778905 Test MSE 3.324040046009282e-05 Test RE 0.013492579562341248\n",
      "257 Train Loss 0.0002451953 Test MSE 3.386308626302812e-05 Test RE 0.01361837009656366\n",
      "258 Train Loss 0.00024339397 Test MSE 3.371801646481787e-05 Test RE 0.013589168171218862\n",
      "259 Train Loss 0.00024195209 Test MSE 3.446648299262407e-05 Test RE 0.013739165305728182\n",
      "260 Train Loss 0.00024009027 Test MSE 3.3683752759961246e-05 Test RE 0.013582261869423675\n",
      "261 Train Loss 0.000238473 Test MSE 3.295971048400373e-05 Test RE 0.013435491488899783\n",
      "262 Train Loss 0.00023734741 Test MSE 3.3469464056273484e-05 Test RE 0.013538989239956327\n",
      "263 Train Loss 0.00023583967 Test MSE 3.394956991341851e-05 Test RE 0.01363574912881294\n",
      "264 Train Loss 0.00023418346 Test MSE 3.350723644798805e-05 Test RE 0.013546626885404398\n",
      "265 Train Loss 0.00023207079 Test MSE 3.5341043728336496e-05 Test RE 0.013912383791198015\n",
      "266 Train Loss 0.00022974213 Test MSE 3.4701712552367674e-05 Test RE 0.013785969650180085\n",
      "267 Train Loss 0.00022681364 Test MSE 3.644554701147816e-05 Test RE 0.01412811107005603\n",
      "268 Train Loss 0.00022164456 Test MSE 3.541217399298086e-05 Test RE 0.013926377352279869\n",
      "269 Train Loss 0.00021348675 Test MSE 3.387685361433314e-05 Test RE 0.01362113815248453\n",
      "270 Train Loss 0.00020915476 Test MSE 3.352495076285708e-05 Test RE 0.013550207268803141\n",
      "271 Train Loss 0.00020630223 Test MSE 3.30365684043293e-05 Test RE 0.013451147309789038\n",
      "272 Train Loss 0.000205016 Test MSE 3.241836874152355e-05 Test RE 0.013324700095034735\n",
      "273 Train Loss 0.00020355286 Test MSE 3.2553562971552905e-05 Test RE 0.01335245516767892\n",
      "274 Train Loss 0.00020177483 Test MSE 3.224247969138456e-05 Test RE 0.013288503695602704\n",
      "275 Train Loss 0.00019886851 Test MSE 3.0193427879279663e-05 Test RE 0.01285932210482804\n",
      "276 Train Loss 0.00019709177 Test MSE 3.0233231591606437e-05 Test RE 0.012867795474919907\n",
      "277 Train Loss 0.00019454081 Test MSE 2.980312082138078e-05 Test RE 0.01277593624059702\n",
      "278 Train Loss 0.00019197205 Test MSE 2.812247987039083e-05 Test RE 0.012410482637821628\n",
      "279 Train Loss 0.0001907374 Test MSE 2.678415106474626e-05 Test RE 0.012111580133375684\n",
      "280 Train Loss 0.00018809429 Test MSE 2.556841395241942e-05 Test RE 0.011833514805884815\n",
      "281 Train Loss 0.00018644893 Test MSE 2.5976512102549392e-05 Test RE 0.011927578479279902\n",
      "282 Train Loss 0.00018535441 Test MSE 2.5546809683919652e-05 Test RE 0.011828514330320283\n",
      "283 Train Loss 0.00018418152 Test MSE 2.5491218256660487e-05 Test RE 0.01181563753441552\n",
      "284 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "285 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "286 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "287 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "288 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "289 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "290 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "291 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "292 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "293 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "294 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "295 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "296 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "297 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "298 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "299 Train Loss 0.00018415577 Test MSE 2.5541576999753825e-05 Test RE 0.011827302866928725\n",
      "Training time: 155.19\n",
      "KG_tanh_low\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 10110.115 Test MSE 5.356782628686653 Test RE 5.416439241590287\n",
      "1 Train Loss 4487.2607 Test MSE 13.398900384067641 Test RE 8.566362398353323\n",
      "2 Train Loss 1552.6152 Test MSE 19.703147406803918 Test RE 10.387945615461092\n",
      "3 Train Loss 688.59204 Test MSE 20.824422342958915 Test RE 10.679436693301332\n",
      "4 Train Loss 486.3666 Test MSE 20.493885534768864 Test RE 10.59434269980036\n",
      "5 Train Loss 361.58057 Test MSE 18.611347534710987 Test RE 10.096033280052874\n",
      "6 Train Loss 305.32657 Test MSE 17.795166572103494 Test RE 9.872176080075157\n",
      "7 Train Loss 237.18365 Test MSE 16.34272272157948 Test RE 9.460717406209486\n",
      "8 Train Loss 180.84105 Test MSE 15.824724527521433 Test RE 9.309576893290298\n",
      "9 Train Loss 128.14929 Test MSE 13.96939793870092 Test RE 8.74683045783184\n",
      "10 Train Loss 74.765884 Test MSE 12.856504630554182 Test RE 8.391185449537726\n",
      "11 Train Loss 34.18551 Test MSE 10.306673746829505 Test RE 7.513133891598696\n",
      "12 Train Loss 21.375257 Test MSE 9.010291735416523 Test RE 7.024756752442891\n",
      "13 Train Loss 14.718412 Test MSE 7.758769217576452 Test RE 6.518659270064823\n",
      "14 Train Loss 12.355824 Test MSE 6.44390228730306 Test RE 5.940682432906882\n",
      "15 Train Loss 9.067409 Test MSE 4.370108981489955 Test RE 4.892242744137498\n",
      "16 Train Loss 5.5269947 Test MSE 2.1016300318932752 Test RE 3.3926573324449447\n",
      "17 Train Loss 3.4453897 Test MSE 1.2432362428461423 Test RE 2.6093882061613773\n",
      "18 Train Loss 2.274555 Test MSE 0.6362487223525441 Test RE 1.86670343079142\n",
      "19 Train Loss 1.4669334 Test MSE 0.14122999303620024 Test RE 0.8794787143792115\n",
      "20 Train Loss 1.0877912 Test MSE 0.04772225507658442 Test RE 0.5112370767621718\n",
      "21 Train Loss 0.7424141 Test MSE 0.028979239637280538 Test RE 0.3983871824256458\n",
      "22 Train Loss 0.5728556 Test MSE 0.030408394410443466 Test RE 0.4080924958195498\n",
      "23 Train Loss 0.434626 Test MSE 0.026627299438352656 Test RE 0.3818786909187862\n",
      "24 Train Loss 0.36699566 Test MSE 0.030331312732547036 Test RE 0.4075749345535343\n",
      "25 Train Loss 0.29864115 Test MSE 0.02173411496020581 Test RE 0.3450109221941586\n",
      "26 Train Loss 0.24491921 Test MSE 0.023596668700761738 Test RE 0.3594903290555803\n",
      "27 Train Loss 0.20052485 Test MSE 0.02565899378020684 Test RE 0.3748708533075076\n",
      "28 Train Loss 0.1818411 Test MSE 0.023854559988625398 Test RE 0.361449450730453\n",
      "29 Train Loss 0.15581587 Test MSE 0.023383817246876513 Test RE 0.3578652823439296\n",
      "30 Train Loss 0.13902462 Test MSE 0.01803094062267391 Test RE 0.3142469387269748\n",
      "31 Train Loss 0.12798503 Test MSE 0.017782583077139646 Test RE 0.31207522133492815\n",
      "32 Train Loss 0.11036884 Test MSE 0.016467376138512006 Test RE 0.3003129546264338\n",
      "33 Train Loss 0.10147804 Test MSE 0.01516348745383929 Test RE 0.2881783909747542\n",
      "34 Train Loss 0.086324774 Test MSE 0.012333855917130968 Test RE 0.2599030041399259\n",
      "35 Train Loss 0.07868843 Test MSE 0.012559412630707091 Test RE 0.2622687392720022\n",
      "36 Train Loss 0.07097955 Test MSE 0.010865490896152102 Test RE 0.2439419775519463\n",
      "37 Train Loss 0.064739384 Test MSE 0.010514028039464106 Test RE 0.2399641861119414\n",
      "38 Train Loss 0.054948807 Test MSE 0.009903184859929188 Test RE 0.23288917747363355\n",
      "39 Train Loss 0.04936924 Test MSE 0.008743702030221442 Test RE 0.21883134952752228\n",
      "40 Train Loss 0.044389457 Test MSE 0.008310611251904364 Test RE 0.2133429754776792\n",
      "41 Train Loss 0.03975473 Test MSE 0.00953196556286321 Test RE 0.22848258117813472\n",
      "42 Train Loss 0.037250213 Test MSE 0.010232794645789566 Test RE 0.23673310446732287\n",
      "43 Train Loss 0.03495599 Test MSE 0.008519193910628118 Test RE 0.21600366292146803\n",
      "44 Train Loss 0.03360238 Test MSE 0.008884620653558384 Test RE 0.22058770828832966\n",
      "45 Train Loss 0.030586941 Test MSE 0.008945294488425534 Test RE 0.22133963290305078\n",
      "46 Train Loss 0.02932137 Test MSE 0.008249725623886772 Test RE 0.21256003669459225\n",
      "47 Train Loss 0.026060406 Test MSE 0.008489994338317078 Test RE 0.21563316845778915\n",
      "48 Train Loss 0.025507154 Test MSE 0.00842213104733413 Test RE 0.2147696262651214\n",
      "49 Train Loss 0.024505813 Test MSE 0.008984006121087837 Test RE 0.22181805026605425\n",
      "50 Train Loss 0.022817265 Test MSE 0.008026698707578656 Test RE 0.20966712726201242\n",
      "51 Train Loss 0.021717517 Test MSE 0.007630575281572765 Test RE 0.2044280588100827\n",
      "52 Train Loss 0.020909738 Test MSE 0.007327866558770555 Test RE 0.20033214453689366\n",
      "53 Train Loss 0.019324455 Test MSE 0.007637047971105268 Test RE 0.2045147442055631\n",
      "54 Train Loss 0.018946584 Test MSE 0.007559130735982936 Test RE 0.20346878527914608\n",
      "55 Train Loss 0.017382022 Test MSE 0.007839996506862507 Test RE 0.2072143360549613\n",
      "56 Train Loss 0.017026074 Test MSE 0.007776240735506657 Test RE 0.20637007048927383\n",
      "57 Train Loss 0.016690314 Test MSE 0.008012209170993559 Test RE 0.20947779962705962\n",
      "58 Train Loss 0.015524851 Test MSE 0.008350076998979938 Test RE 0.2138489411235722\n",
      "59 Train Loss 0.014749249 Test MSE 0.007904276697885635 Test RE 0.20806207790086645\n",
      "60 Train Loss 0.014521266 Test MSE 0.0077225682483485604 Test RE 0.20565664261256517\n",
      "61 Train Loss 0.013478367 Test MSE 0.006934039466923051 Test RE 0.19487450213123417\n",
      "62 Train Loss 0.012801887 Test MSE 0.006765064609423534 Test RE 0.19248541971170188\n",
      "63 Train Loss 0.012515402 Test MSE 0.0068545592242365855 Test RE 0.1937544253655524\n",
      "64 Train Loss 0.012146169 Test MSE 0.006909945260145449 Test RE 0.19453563526372256\n",
      "65 Train Loss 0.011995599 Test MSE 0.00681286793084186 Test RE 0.19316429310605718\n",
      "66 Train Loss 0.011837262 Test MSE 0.006470305300654044 Test RE 0.18824534719908215\n",
      "67 Train Loss 0.011256483 Test MSE 0.006710911444579007 Test RE 0.19171346562533992\n",
      "68 Train Loss 0.010782907 Test MSE 0.0062124173189005705 Test RE 0.18445574021975852\n",
      "69 Train Loss 0.010464294 Test MSE 0.005948364359995796 Test RE 0.18049311719912833\n",
      "70 Train Loss 0.010176016 Test MSE 0.005589825100774687 Test RE 0.1749689452466081\n",
      "71 Train Loss 0.009741088 Test MSE 0.005481372452033752 Test RE 0.1732632755298222\n",
      "72 Train Loss 0.009457762 Test MSE 0.005269598240746551 Test RE 0.16988327189382793\n",
      "73 Train Loss 0.009271995 Test MSE 0.005071524925658232 Test RE 0.1666599112407941\n",
      "74 Train Loss 0.008927248 Test MSE 0.00480987968357192 Test RE 0.16230390555603819\n",
      "75 Train Loss 0.008519197 Test MSE 0.004658193100634807 Test RE 0.15972415820405422\n",
      "76 Train Loss 0.008140555 Test MSE 0.0047225480280177765 Test RE 0.16082370229802823\n",
      "77 Train Loss 0.0079094255 Test MSE 0.004441610368736763 Test RE 0.1559667753772568\n",
      "78 Train Loss 0.007683592 Test MSE 0.004425453636629826 Test RE 0.1556828457915027\n",
      "79 Train Loss 0.0075145224 Test MSE 0.004120866117788708 Test RE 0.15022980950599707\n",
      "80 Train Loss 0.007081562 Test MSE 0.003997941532942503 Test RE 0.1479721838276312\n",
      "81 Train Loss 0.0065222043 Test MSE 0.0037452228495989314 Test RE 0.1432190195210786\n",
      "82 Train Loss 0.0061251177 Test MSE 0.003535919016516369 Test RE 0.13915955103301678\n",
      "83 Train Loss 0.0059847855 Test MSE 0.0035227299450076265 Test RE 0.13889977415896046\n",
      "84 Train Loss 0.0059269406 Test MSE 0.003501956237479473 Test RE 0.13848961927236547\n",
      "85 Train Loss 0.005813098 Test MSE 0.0034289289649377863 Test RE 0.13703803043058377\n",
      "86 Train Loss 0.0057073846 Test MSE 0.003340552071755407 Test RE 0.1352604995204533\n",
      "87 Train Loss 0.0056469273 Test MSE 0.003290733801994054 Test RE 0.13424812852327078\n",
      "88 Train Loss 0.0055862507 Test MSE 0.003443070896394832 Test RE 0.13732033262435378\n",
      "89 Train Loss 0.0054570604 Test MSE 0.003452937686758811 Test RE 0.1375169509446727\n",
      "90 Train Loss 0.005310438 Test MSE 0.0034623294858478946 Test RE 0.13770384318838838\n",
      "91 Train Loss 0.0051707285 Test MSE 0.003601144112349461 Test RE 0.14043718472869743\n",
      "92 Train Loss 0.00505218 Test MSE 0.003656715829024889 Test RE 0.1415166273703717\n",
      "93 Train Loss 0.004980403 Test MSE 0.003601690029177774 Test RE 0.1404478291398486\n",
      "94 Train Loss 0.0049306834 Test MSE 0.0035560174973853363 Test RE 0.13955448829902778\n",
      "95 Train Loss 0.0048244176 Test MSE 0.0034301225671867054 Test RE 0.137061879666157\n",
      "96 Train Loss 0.0047671446 Test MSE 0.0034044758376207793 Test RE 0.1365485183702907\n",
      "97 Train Loss 0.004699332 Test MSE 0.0033464089798600914 Test RE 0.13537902205252111\n",
      "98 Train Loss 0.0046070204 Test MSE 0.003261760111864134 Test RE 0.13365581939519428\n",
      "99 Train Loss 0.0045390027 Test MSE 0.003306877098242417 Test RE 0.13457701503177877\n",
      "100 Train Loss 0.0044694375 Test MSE 0.00319414997153665 Test RE 0.13226334915825055\n",
      "101 Train Loss 0.0044441894 Test MSE 0.00320197692397123 Test RE 0.13242529921570004\n",
      "102 Train Loss 0.0044304742 Test MSE 0.0032083290342962657 Test RE 0.13255658737900586\n",
      "103 Train Loss 0.0044128443 Test MSE 0.0032331126225951215 Test RE 0.13306758669301377\n",
      "104 Train Loss 0.0043934705 Test MSE 0.003178484161837594 Test RE 0.13193860559759454\n",
      "105 Train Loss 0.004309828 Test MSE 0.002998343569315845 Test RE 0.1281452645017774\n",
      "106 Train Loss 0.0042477683 Test MSE 0.0028784369585400146 Test RE 0.1255567961406403\n",
      "107 Train Loss 0.0041856053 Test MSE 0.002727635031416231 Test RE 0.12222357816774865\n",
      "108 Train Loss 0.0041450025 Test MSE 0.0024832759452162634 Test RE 0.11662035386311316\n",
      "109 Train Loss 0.0041276254 Test MSE 0.002506185508524885 Test RE 0.11715706176051535\n",
      "110 Train Loss 0.0040883613 Test MSE 0.0024487025707432813 Test RE 0.11580568575355502\n",
      "111 Train Loss 0.004043856 Test MSE 0.002375966324343843 Test RE 0.11407277445272178\n",
      "112 Train Loss 0.004011674 Test MSE 0.002329876005731552 Test RE 0.1129609323943885\n",
      "113 Train Loss 0.0039845654 Test MSE 0.0023609163448360553 Test RE 0.11371091742713793\n",
      "114 Train Loss 0.003964907 Test MSE 0.0022860636733299227 Test RE 0.11189380057786553\n",
      "115 Train Loss 0.0038891651 Test MSE 0.0022539338299606888 Test RE 0.11110470358819477\n",
      "116 Train Loss 0.0037929418 Test MSE 0.0023089799168767773 Test RE 0.11245323196343306\n",
      "117 Train Loss 0.0036922405 Test MSE 0.0021744973110412484 Test RE 0.10912928292556474\n",
      "118 Train Loss 0.0036738296 Test MSE 0.0021498967218487154 Test RE 0.10851022469491411\n",
      "119 Train Loss 0.003663346 Test MSE 0.0021216662927191787 Test RE 0.10779544318674977\n",
      "120 Train Loss 0.0036270083 Test MSE 0.002056625681819849 Test RE 0.1061303243223371\n",
      "121 Train Loss 0.0035589982 Test MSE 0.0018706872672600002 Test RE 0.10121909714477047\n",
      "122 Train Loss 0.0034423815 Test MSE 0.0016905761872603702 Test RE 0.09622307637465555\n",
      "123 Train Loss 0.0033641832 Test MSE 0.0015529498550115677 Test RE 0.09222328341604966\n",
      "124 Train Loss 0.0033041448 Test MSE 0.001469362181044507 Test RE 0.08970699167620022\n",
      "125 Train Loss 0.0032340721 Test MSE 0.0014818636847066036 Test RE 0.09008780213578849\n",
      "126 Train Loss 0.0032014186 Test MSE 0.0015299152813867184 Test RE 0.09153676402030705\n",
      "127 Train Loss 0.0031636318 Test MSE 0.0015763823210652036 Test RE 0.09291645711172045\n",
      "128 Train Loss 0.0031442184 Test MSE 0.0015507168519851944 Test RE 0.0921569551464796\n",
      "129 Train Loss 0.0031286015 Test MSE 0.0015034534047131025 Test RE 0.09074168729724211\n",
      "130 Train Loss 0.003103504 Test MSE 0.0014551625239150247 Test RE 0.08927248309617748\n",
      "131 Train Loss 0.003053995 Test MSE 0.0014542432249673384 Test RE 0.08924427969478924\n",
      "132 Train Loss 0.0029899098 Test MSE 0.0014772720620022403 Test RE 0.08994812325469462\n",
      "133 Train Loss 0.002957477 Test MSE 0.0014656548262837526 Test RE 0.08959375013071069\n",
      "134 Train Loss 0.0029368626 Test MSE 0.0013712331025746672 Test RE 0.0866597652967719\n",
      "135 Train Loss 0.0029174944 Test MSE 0.0013725862809935599 Test RE 0.08670251412179085\n",
      "136 Train Loss 0.002896386 Test MSE 0.001338444752486503 Test RE 0.0856174105515\n",
      "137 Train Loss 0.0028814746 Test MSE 0.001276821215354076 Test RE 0.0836232243589539\n",
      "138 Train Loss 0.0028673345 Test MSE 0.0012346138895666027 Test RE 0.08222946095487713\n",
      "139 Train Loss 0.0028466284 Test MSE 0.0011305458823415444 Test RE 0.07868753856752747\n",
      "140 Train Loss 0.0028270292 Test MSE 0.0011314145867930795 Test RE 0.07871776427088942\n",
      "141 Train Loss 0.0028166783 Test MSE 0.0011010857809541882 Test RE 0.07765553949452972\n",
      "142 Train Loss 0.002809284 Test MSE 0.0010811241001902026 Test RE 0.07694840787740921\n",
      "143 Train Loss 0.0027788267 Test MSE 0.0010765328831564692 Test RE 0.07678484537989025\n",
      "144 Train Loss 0.0027067242 Test MSE 0.0009847635314234708 Test RE 0.07343918398357235\n",
      "145 Train Loss 0.0026805247 Test MSE 0.0009617573901793385 Test RE 0.07257626764154579\n",
      "146 Train Loss 0.0026216449 Test MSE 0.0008973003171467688 Test RE 0.0701020591045292\n",
      "147 Train Loss 0.0025547908 Test MSE 0.0008281504177974078 Test RE 0.067346724286172\n",
      "148 Train Loss 0.002506939 Test MSE 0.0007985174456663559 Test RE 0.066130844458801\n",
      "149 Train Loss 0.0024592145 Test MSE 0.0007718872465727147 Test RE 0.06501877708431253\n",
      "150 Train Loss 0.0024448973 Test MSE 0.0007918575635542211 Test RE 0.06585449120106017\n",
      "151 Train Loss 0.002436806 Test MSE 0.0008173116780253406 Test RE 0.06690455958421812\n",
      "152 Train Loss 0.0024309182 Test MSE 0.0008258743914951911 Test RE 0.06725411527739274\n",
      "153 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "154 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "155 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "156 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "157 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "158 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "159 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "160 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "161 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "162 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "163 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "164 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "165 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "166 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "167 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "168 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "169 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "170 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "171 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "172 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "173 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "174 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "175 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "176 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "177 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "178 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "179 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "180 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "181 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "182 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "183 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "184 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "185 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "186 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "187 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "188 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "189 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "190 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "191 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "192 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "193 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "194 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "195 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "196 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "197 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "198 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "199 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "200 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "201 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "202 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "203 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "204 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "205 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "206 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "207 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "208 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "209 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "210 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "211 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "212 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "213 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "214 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "215 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "216 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "217 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "218 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "219 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "220 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "221 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "222 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "223 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "224 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "225 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "226 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "227 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "228 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "229 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "230 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "231 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "232 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "233 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "234 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "235 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "236 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "237 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "238 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "239 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "240 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "241 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "242 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "243 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "244 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "245 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "246 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "247 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "248 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "249 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "250 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "251 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "252 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "253 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "254 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "255 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "256 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "257 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "258 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "259 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "260 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "261 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "262 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "263 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "264 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "265 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "266 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "267 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "268 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "269 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "270 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "271 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "272 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "273 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "274 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "275 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "276 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "277 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "278 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "279 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "280 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "281 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "282 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "283 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "284 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "285 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "286 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "287 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "288 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "289 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "290 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "291 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "292 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "293 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "294 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "295 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "296 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "297 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "298 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "299 Train Loss 0.0024287656 Test MSE 0.0008234691033936548 Test RE 0.06715610795400749\n",
      "Training time: 104.20\n",
      "KG_tanh_low\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 9811.922 Test MSE 10.195489258606264 Test RE 7.472499587813435\n",
      "1 Train Loss 3396.36 Test MSE 8.698465095690521 Test RE 6.9021306632156625\n",
      "2 Train Loss 1270.9117 Test MSE 9.244313361370029 Test RE 7.115397934396373\n",
      "3 Train Loss 304.41025 Test MSE 12.871441487608779 Test RE 8.396058529643604\n",
      "4 Train Loss 119.474525 Test MSE 14.094319503109409 Test RE 8.785852748241918\n",
      "5 Train Loss 56.922047 Test MSE 14.84228156979796 Test RE 9.015964585869945\n",
      "6 Train Loss 36.49994 Test MSE 15.139986689901487 Test RE 9.105936359073974\n",
      "7 Train Loss 29.890678 Test MSE 14.864799926788564 Test RE 9.022801397329792\n",
      "8 Train Loss 26.176 Test MSE 14.645559394221255 Test RE 8.956015700423906\n",
      "9 Train Loss 22.804525 Test MSE 14.10405123247331 Test RE 8.788885416372924\n",
      "10 Train Loss 20.528336 Test MSE 13.610838614030303 Test RE 8.63384616546132\n",
      "11 Train Loss 18.556099 Test MSE 12.926393410790594 Test RE 8.413962047728006\n",
      "12 Train Loss 16.970367 Test MSE 12.289362622844413 Test RE 8.204016848857565\n",
      "13 Train Loss 15.164356 Test MSE 11.545368898935244 Test RE 7.951805909249693\n",
      "14 Train Loss 13.839071 Test MSE 10.825136323421251 Test RE 7.699784158854794\n",
      "15 Train Loss 12.521174 Test MSE 9.861195213435806 Test RE 7.348972836960816\n",
      "16 Train Loss 11.50515 Test MSE 8.816991942575505 Test RE 6.948996388920263\n",
      "17 Train Loss 10.320794 Test MSE 7.976572964580377 Test RE 6.609521735994778\n",
      "18 Train Loss 8.965594 Test MSE 7.104588715239603 Test RE 6.237798403380383\n",
      "19 Train Loss 7.5993195 Test MSE 6.341250938167016 Test RE 5.8931749458348275\n",
      "20 Train Loss 6.383735 Test MSE 5.469225677971485 Test RE 5.4729916570578165\n",
      "21 Train Loss 5.465439 Test MSE 4.596055680267336 Test RE 5.017120186060266\n",
      "22 Train Loss 4.7025228 Test MSE 3.3199631404745884 Test RE 4.264110937876712\n",
      "23 Train Loss 3.597592 Test MSE 2.245232447301238 Test RE 3.5066507914149865\n",
      "24 Train Loss 2.7657301 Test MSE 1.5952675949119206 Test RE 2.9558244397997453\n",
      "25 Train Loss 1.9723939 Test MSE 0.9706747829273358 Test RE 2.305678435239536\n",
      "26 Train Loss 1.4102252 Test MSE 0.6049344855422917 Test RE 1.8201871144898631\n",
      "27 Train Loss 0.9225759 Test MSE 0.293550456728207 Test RE 1.2679532588799363\n",
      "28 Train Loss 0.6217365 Test MSE 0.2078110725794735 Test RE 1.0668324224137098\n",
      "29 Train Loss 0.4152165 Test MSE 0.18055944341573177 Test RE 0.9944248482038616\n",
      "30 Train Loss 0.3211877 Test MSE 0.09428676947346239 Test RE 0.7186000481507031\n",
      "31 Train Loss 0.25578183 Test MSE 0.0786694195995062 Test RE 0.656394354428282\n",
      "32 Train Loss 0.20585458 Test MSE 0.06066545998831 Test RE 0.5764114663646566\n",
      "33 Train Loss 0.17064369 Test MSE 0.06081874756717714 Test RE 0.5771392361226536\n",
      "34 Train Loss 0.14639878 Test MSE 0.060965059777061105 Test RE 0.5778330336389526\n",
      "35 Train Loss 0.12704714 Test MSE 0.047843848734359096 Test RE 0.5118879642708618\n",
      "36 Train Loss 0.11253777 Test MSE 0.043557626133633114 Test RE 0.48842059179742797\n",
      "37 Train Loss 0.10389097 Test MSE 0.04195284886864447 Test RE 0.47933880939264895\n",
      "38 Train Loss 0.09132335 Test MSE 0.036403445692628336 Test RE 0.44651197473210225\n",
      "39 Train Loss 0.08348444 Test MSE 0.035619636652731636 Test RE 0.44167885324303574\n",
      "40 Train Loss 0.076727845 Test MSE 0.03722659468427423 Test RE 0.4515319847357469\n",
      "41 Train Loss 0.07067062 Test MSE 0.03367663077461063 Test RE 0.42946342345242655\n",
      "42 Train Loss 0.06495047 Test MSE 0.0341872888082855 Test RE 0.43270727252160374\n",
      "43 Train Loss 0.057394788 Test MSE 0.03133029281774199 Test RE 0.41423242470475957\n",
      "44 Train Loss 0.053203482 Test MSE 0.027973712587005563 Test RE 0.3914145073481634\n",
      "45 Train Loss 0.04817689 Test MSE 0.025784034072648513 Test RE 0.3757831453913339\n",
      "46 Train Loss 0.043606844 Test MSE 0.023976355273216392 Test RE 0.36237101015963097\n",
      "47 Train Loss 0.040496424 Test MSE 0.021652694297025803 Test RE 0.34436407330515134\n",
      "48 Train Loss 0.038634907 Test MSE 0.020283391534577963 Test RE 0.3332975728565387\n",
      "49 Train Loss 0.036648642 Test MSE 0.019363210274784267 Test RE 0.325649596874719\n",
      "50 Train Loss 0.032685824 Test MSE 0.01675594590824861 Test RE 0.30293282779311415\n",
      "51 Train Loss 0.031588804 Test MSE 0.017051992345453827 Test RE 0.30559724067479144\n",
      "52 Train Loss 0.027974384 Test MSE 0.01624751108651026 Test RE 0.2983013954775282\n",
      "53 Train Loss 0.02587904 Test MSE 0.015470032321403288 Test RE 0.2910767214395051\n",
      "54 Train Loss 0.024538763 Test MSE 0.015663343997248586 Test RE 0.29288970528528596\n",
      "55 Train Loss 0.021475974 Test MSE 0.0160920339237143 Test RE 0.29687069811969324\n",
      "56 Train Loss 0.020552533 Test MSE 0.01533272519855801 Test RE 0.289782089809518\n",
      "57 Train Loss 0.019510815 Test MSE 0.015040314002038885 Test RE 0.2870055636441064\n",
      "58 Train Loss 0.017725691 Test MSE 0.013180291722503325 Test RE 0.2686732169690236\n",
      "59 Train Loss 0.016983515 Test MSE 0.011854754771358339 Test RE 0.2548051205528941\n",
      "60 Train Loss 0.016085062 Test MSE 0.010846544539410379 Test RE 0.24372920169495682\n",
      "61 Train Loss 0.014762322 Test MSE 0.010057980647671315 Test RE 0.23470225477893483\n",
      "62 Train Loss 0.013915801 Test MSE 0.009711464207853016 Test RE 0.23062385163273497\n",
      "63 Train Loss 0.01318717 Test MSE 0.008790743277885421 Test RE 0.21941921786931007\n",
      "64 Train Loss 0.012130886 Test MSE 0.007843511264497071 Test RE 0.20726077909611137\n",
      "65 Train Loss 0.011704047 Test MSE 0.007011604651610604 Test RE 0.19596141839548956\n",
      "66 Train Loss 0.011314393 Test MSE 0.006272087519228566 Test RE 0.18533947091769268\n",
      "67 Train Loss 0.010640985 Test MSE 0.005411340925847676 Test RE 0.1721528877768521\n",
      "68 Train Loss 0.010244122 Test MSE 0.005103093621464071 Test RE 0.16717781010789048\n",
      "69 Train Loss 0.01002259 Test MSE 0.005377929684634205 Test RE 0.17162060311285382\n",
      "70 Train Loss 0.009552112 Test MSE 0.005034198740250118 Test RE 0.16604547403357434\n",
      "71 Train Loss 0.009074788 Test MSE 0.004144238163141824 Test RE 0.15065523141489542\n",
      "72 Train Loss 0.008763041 Test MSE 0.0040156402246518804 Test RE 0.14829935494661795\n",
      "73 Train Loss 0.008468569 Test MSE 0.003163801413116453 Test RE 0.1316335130306288\n",
      "74 Train Loss 0.008139574 Test MSE 0.0025314942055347693 Test RE 0.11774713068944206\n",
      "75 Train Loss 0.0077214423 Test MSE 0.0025340323875749026 Test RE 0.11780614500122095\n",
      "76 Train Loss 0.00737317 Test MSE 0.0030150587899649534 Test RE 0.12850196134653216\n",
      "77 Train Loss 0.0068695233 Test MSE 0.002698275120026949 Test RE 0.12156399905027367\n",
      "78 Train Loss 0.006640312 Test MSE 0.0022429202978690036 Test RE 0.11083292238715296\n",
      "79 Train Loss 0.006502768 Test MSE 0.0020421073233058717 Test RE 0.10575505743112368\n",
      "80 Train Loss 0.006343744 Test MSE 0.00167519959073517 Test RE 0.09578447940398\n",
      "81 Train Loss 0.006166067 Test MSE 0.0014825315812385155 Test RE 0.09010810176016495\n",
      "82 Train Loss 0.0060080998 Test MSE 0.0012871843401651185 Test RE 0.08396189613154538\n",
      "83 Train Loss 0.0058461917 Test MSE 0.0011199382115102794 Test RE 0.07831751436353085\n",
      "84 Train Loss 0.0054322276 Test MSE 0.0010367635873708594 Test RE 0.07535320552244237\n",
      "85 Train Loss 0.0050981436 Test MSE 0.0010366258953257296 Test RE 0.07534820154582846\n",
      "86 Train Loss 0.0049098306 Test MSE 0.000987171306714507 Test RE 0.07352890963510916\n",
      "87 Train Loss 0.004759617 Test MSE 0.0010024984195730073 Test RE 0.07409752677560565\n",
      "88 Train Loss 0.0046244515 Test MSE 0.0010400289778272583 Test RE 0.07547177845454689\n",
      "89 Train Loss 0.0043590143 Test MSE 0.0008516992114889759 Test RE 0.0682975282774994\n",
      "90 Train Loss 0.0041698436 Test MSE 0.0006880309925476242 Test RE 0.06138550949952405\n",
      "91 Train Loss 0.0038618932 Test MSE 0.0006419629081906798 Test RE 0.05929483050207356\n",
      "92 Train Loss 0.0036809104 Test MSE 0.0005198813925549183 Test RE 0.053359776374175806\n",
      "93 Train Loss 0.0036152015 Test MSE 0.0004371101696122851 Test RE 0.04892798373894687\n",
      "94 Train Loss 0.0035396582 Test MSE 0.00032183227417796715 Test RE 0.041983308584789346\n",
      "95 Train Loss 0.003445652 Test MSE 0.0002451805872025258 Test RE 0.03664417128260895\n",
      "96 Train Loss 0.0032861305 Test MSE 0.0001977964796101813 Test RE 0.03291327836946932\n",
      "97 Train Loss 0.0030457142 Test MSE 0.00013974168208781288 Test RE 0.02766462880349454\n",
      "98 Train Loss 0.0027792426 Test MSE 8.00981121535696e-05 Test RE 0.020944645021707193\n",
      "99 Train Loss 0.0026039854 Test MSE 6.954431948977757e-05 Test RE 0.01951608472916392\n",
      "100 Train Loss 0.0025448888 Test MSE 6.895925042804313e-05 Test RE 0.019433817951889924\n",
      "101 Train Loss 0.0025007576 Test MSE 5.6920680654486594e-05 Test RE 0.017656186452165566\n",
      "102 Train Loss 0.002443305 Test MSE 3.095299701654502e-05 Test RE 0.013020066936775085\n",
      "103 Train Loss 0.0023992492 Test MSE 1.7822483511683477e-05 Test RE 0.009879750446457955\n",
      "104 Train Loss 0.0023426465 Test MSE 1.175374508995382e-05 Test RE 0.008023243960773198\n",
      "105 Train Loss 0.0022724194 Test MSE 1.2508945452427246e-05 Test RE 0.008276985862283264\n",
      "106 Train Loss 0.002217583 Test MSE 1.2161194066745132e-05 Test RE 0.008161123942549\n",
      "107 Train Loss 0.0021465854 Test MSE 1.3356069161366854e-05 Test RE 0.008552659726825418\n",
      "108 Train Loss 0.002085204 Test MSE 1.319277040943749e-05 Test RE 0.008500214132173318\n",
      "109 Train Loss 0.0020325915 Test MSE 1.3968020146799933e-05 Test RE 0.00874639910032507\n",
      "110 Train Loss 0.0020037044 Test MSE 1.9419817537368835e-05 Test RE 0.010312986199403166\n",
      "111 Train Loss 0.0019726201 Test MSE 2.312943215686457e-05 Test RE 0.011254970198236602\n",
      "112 Train Loss 0.0019293447 Test MSE 2.8707946803613248e-05 Test RE 0.012539000810236815\n",
      "113 Train Loss 0.0018574002 Test MSE 3.859419938682609e-05 Test RE 0.014538609847016094\n",
      "114 Train Loss 0.0017309048 Test MSE 3.698228623952755e-05 Test RE 0.01423176427803419\n",
      "115 Train Loss 0.0017112087 Test MSE 2.997509376653529e-05 Test RE 0.012812743711256363\n",
      "116 Train Loss 0.0016733961 Test MSE 1.6227291329148684e-05 Test RE 0.00942724688235524\n",
      "117 Train Loss 0.0016189562 Test MSE 1.6518643063705337e-05 Test RE 0.00951150079500792\n",
      "118 Train Loss 0.0015827377 Test MSE 1.3007939330044231e-05 Test RE 0.008440459986756525\n",
      "119 Train Loss 0.0015564926 Test MSE 1.0632944873230077e-05 Test RE 0.00763112636523149\n",
      "120 Train Loss 0.0015432918 Test MSE 1.2269152566779393e-05 Test RE 0.008197268253817846\n",
      "121 Train Loss 0.0015240957 Test MSE 9.888009295386618e-06 Test RE 0.0073589575386736345\n",
      "122 Train Loss 0.0014930402 Test MSE 1.0902598924265072e-05 Test RE 0.007727284140272793\n",
      "123 Train Loss 0.0014404783 Test MSE 1.0101706320301358e-05 Test RE 0.007438052394489839\n",
      "124 Train Loss 0.0013834444 Test MSE 8.547977832554219e-06 Test RE 0.006842165229979438\n",
      "125 Train Loss 0.0013511587 Test MSE 8.625873068368125e-06 Test RE 0.006873269859673615\n",
      "126 Train Loss 0.0013323829 Test MSE 9.423359752137152e-06 Test RE 0.0071839739641069615\n",
      "127 Train Loss 0.0013151352 Test MSE 1.0170022885778704e-05 Test RE 0.007463161318904024\n",
      "128 Train Loss 0.0012711838 Test MSE 8.839136371705896e-06 Test RE 0.006957717337028641\n",
      "129 Train Loss 0.0012571393 Test MSE 9.527095872277648e-06 Test RE 0.0072234077673972484\n",
      "130 Train Loss 0.001246534 Test MSE 1.0618861212004218e-05 Test RE 0.007626070860308494\n",
      "131 Train Loss 0.0012292732 Test MSE 1.2411411025109763e-05 Test RE 0.008244654164482359\n",
      "132 Train Loss 0.0012066312 Test MSE 1.7040423920272613e-05 Test RE 0.009660554643347256\n",
      "133 Train Loss 0.0011899251 Test MSE 1.844937625523895e-05 Test RE 0.010052005279059126\n",
      "134 Train Loss 0.0011658655 Test MSE 2.112015238500907e-05 Test RE 0.010754999331433857\n",
      "135 Train Loss 0.0011570412 Test MSE 2.3056143856558407e-05 Test RE 0.011237124708518797\n",
      "136 Train Loss 0.0011461831 Test MSE 2.7628318239838562e-05 Test RE 0.012300962341972007\n",
      "137 Train Loss 0.0011188475 Test MSE 1.7577361968626196e-05 Test RE 0.009811574642529275\n",
      "138 Train Loss 0.0010989826 Test MSE 1.8110840710810766e-05 Test RE 0.009959354001354764\n",
      "139 Train Loss 0.0010755128 Test MSE 1.9822946833167017e-05 Test RE 0.010419478242387025\n",
      "140 Train Loss 0.0010608045 Test MSE 2.3935292807516356e-05 Test RE 0.011449360668834223\n",
      "141 Train Loss 0.0010488322 Test MSE 2.9194882993341126e-05 Test RE 0.01264489517857827\n",
      "142 Train Loss 0.0010340693 Test MSE 2.996294403197062e-05 Test RE 0.01281014676837385\n",
      "143 Train Loss 0.0010261937 Test MSE 3.1959972366107287e-05 Test RE 0.013230158940257673\n",
      "144 Train Loss 0.0010185033 Test MSE 3.7677608518454795e-05 Test RE 0.014364930486059113\n",
      "145 Train Loss 0.0010096047 Test MSE 3.8666781871840105e-05 Test RE 0.014552274500950788\n",
      "146 Train Loss 0.0009957992 Test MSE 4.3890393154691327e-05 Test RE 0.015504101382482852\n",
      "147 Train Loss 0.0009786015 Test MSE 4.313946797379508e-05 Test RE 0.015370898559042936\n",
      "148 Train Loss 0.0009555907 Test MSE 4.9142185665605074e-05 Test RE 0.016405485912787125\n",
      "149 Train Loss 0.00093347 Test MSE 5.6234481191899895e-05 Test RE 0.017549437885800438\n",
      "150 Train Loss 0.0009217803 Test MSE 5.5486285434588e-05 Test RE 0.017432299944074643\n",
      "151 Train Loss 0.0009098349 Test MSE 5.6952249180223906e-05 Test RE 0.017661081883052664\n",
      "152 Train Loss 0.0008946593 Test MSE 5.2433233746210746e-05 Test RE 0.016945921316802417\n",
      "153 Train Loss 0.0008763321 Test MSE 3.942824346147027e-05 Test RE 0.014694864262770673\n",
      "154 Train Loss 0.000863622 Test MSE 4.334749457850647e-05 Test RE 0.015407914665771922\n",
      "155 Train Loss 0.00086361857 Test MSE 4.3287450448713974e-05 Test RE 0.015397239591746914\n",
      "156 Train Loss 0.0008527343 Test MSE 4.417798839635303e-05 Test RE 0.015554814362761703\n",
      "157 Train Loss 0.0008445838 Test MSE 4.775329492908685e-05 Test RE 0.0161719926566283\n",
      "158 Train Loss 0.00083558547 Test MSE 4.368540303890344e-05 Test RE 0.015467853049623868\n",
      "159 Train Loss 0.00082634826 Test MSE 4.301660308509971e-05 Test RE 0.015348994135656026\n",
      "160 Train Loss 0.0008214681 Test MSE 4.6712730215688076e-05 Test RE 0.015994824883307595\n",
      "161 Train Loss 0.0008137055 Test MSE 5.170735191773548e-05 Test RE 0.0168282134686332\n",
      "162 Train Loss 0.0008031729 Test MSE 5.122034887256418e-05 Test RE 0.01674877815354128\n",
      "163 Train Loss 0.00079230045 Test MSE 4.867581434105031e-05 Test RE 0.016327454305930415\n",
      "164 Train Loss 0.00077125017 Test MSE 4.9881527593202266e-05 Test RE 0.016528435089250917\n",
      "165 Train Loss 0.00075668795 Test MSE 4.787093716015949e-05 Test RE 0.01619190059191524\n",
      "166 Train Loss 0.00074339646 Test MSE 5.299665707890589e-05 Test RE 0.017036724561253776\n",
      "167 Train Loss 0.00073195156 Test MSE 5.966682001764058e-05 Test RE 0.018077081260034596\n",
      "168 Train Loss 0.000728078 Test MSE 5.923796440069313e-05 Test RE 0.018011999541829908\n",
      "169 Train Loss 0.0007204083 Test MSE 5.652493202109807e-05 Test RE 0.01759470089707381\n",
      "170 Train Loss 0.0007119199 Test MSE 4.715914861423565e-05 Test RE 0.016071071824196183\n",
      "171 Train Loss 0.00070164824 Test MSE 4.5053026083791184e-05 Test RE 0.015708106870838533\n",
      "172 Train Loss 0.0006955557 Test MSE 4.587025262149631e-05 Test RE 0.0158499329735404\n",
      "173 Train Loss 0.00068337255 Test MSE 4.301502336610718e-05 Test RE 0.015348712298895024\n",
      "174 Train Loss 0.000676328 Test MSE 3.934851279811527e-05 Test RE 0.01467999897735472\n",
      "175 Train Loss 0.00067131856 Test MSE 3.885190260883482e-05 Test RE 0.014587068075559784\n",
      "176 Train Loss 0.0006634587 Test MSE 3.978870730782461e-05 Test RE 0.014761883679228456\n",
      "177 Train Loss 0.00065207906 Test MSE 3.630504291079909e-05 Test RE 0.014100851574893835\n",
      "178 Train Loss 0.00064356974 Test MSE 4.0155768916064864e-05 Test RE 0.01482981854834332\n",
      "179 Train Loss 0.00063529145 Test MSE 4.627332423556639e-05 Test RE 0.015919419017389587\n",
      "180 Train Loss 0.0006291582 Test MSE 4.748097413235636e-05 Test RE 0.01612581504225112\n",
      "181 Train Loss 0.0006204634 Test MSE 4.963189924605403e-05 Test RE 0.01648702556241761\n",
      "182 Train Loss 0.0006142382 Test MSE 4.8337235395316915e-05 Test RE 0.01627057000869275\n",
      "183 Train Loss 0.00060850877 Test MSE 4.695190348207965e-05 Test RE 0.016035720054957396\n",
      "184 Train Loss 0.0006030405 Test MSE 4.340609362570078e-05 Test RE 0.015418325696354278\n",
      "185 Train Loss 0.0005963841 Test MSE 3.8925746862283814e-05 Test RE 0.014600924022522265\n",
      "186 Train Loss 0.0005897432 Test MSE 3.534579274613041e-05 Test RE 0.013913318510886294\n",
      "187 Train Loss 0.0005832108 Test MSE 3.0434394990211075e-05 Test RE 0.012910533842000471\n",
      "188 Train Loss 0.0005789745 Test MSE 2.8117379934322354e-05 Test RE 0.012409357282979656\n",
      "189 Train Loss 0.0005751541 Test MSE 2.6574297812889804e-05 Test RE 0.012064039845069404\n",
      "190 Train Loss 0.00057048135 Test MSE 3.0032744260861518e-05 Test RE 0.01282505903865028\n",
      "191 Train Loss 0.00056173746 Test MSE 2.657328825048215e-05 Test RE 0.012063810685358875\n",
      "192 Train Loss 0.00055106124 Test MSE 2.883524183401551e-05 Test RE 0.012566769898387386\n",
      "193 Train Loss 0.00054071227 Test MSE 2.8202021260251696e-05 Test RE 0.012428021098479273\n",
      "194 Train Loss 0.0005320264 Test MSE 2.7755343098323082e-05 Test RE 0.012329207567061837\n",
      "195 Train Loss 0.00052305154 Test MSE 2.6960337460876913e-05 Test RE 0.012151349882809484\n",
      "196 Train Loss 0.0005163809 Test MSE 2.6978321709235892e-05 Test RE 0.012155402066185246\n",
      "197 Train Loss 0.00050882803 Test MSE 2.827325961001122e-05 Test RE 0.012443707798924342\n",
      "198 Train Loss 0.0005038657 Test MSE 2.8743397098229183e-05 Test RE 0.012546740376798642\n",
      "199 Train Loss 0.00049680745 Test MSE 2.9176013373507183e-05 Test RE 0.012640808110788774\n",
      "200 Train Loss 0.00049203745 Test MSE 2.7485466811491377e-05 Test RE 0.012269120242182881\n",
      "201 Train Loss 0.00048774554 Test MSE 2.683638072336231e-05 Test RE 0.012123383300229327\n",
      "202 Train Loss 0.0004828883 Test MSE 2.4562506958427182e-05 Test RE 0.011598403391933548\n",
      "203 Train Loss 0.00047810326 Test MSE 2.417556075708241e-05 Test RE 0.011506682826758053\n",
      "204 Train Loss 0.00047212772 Test MSE 2.3264353514601462e-05 Test RE 0.01128774938104721\n",
      "205 Train Loss 0.00046458538 Test MSE 1.9918843420691054e-05 Test RE 0.010444650758175434\n",
      "206 Train Loss 0.0004517246 Test MSE 1.862875256317404e-05 Test RE 0.010100752999633816\n",
      "207 Train Loss 0.0004405867 Test MSE 1.7830372457889418e-05 Test RE 0.009881936791495786\n",
      "208 Train Loss 0.00043185157 Test MSE 1.834341903128298e-05 Test RE 0.01002309871347492\n",
      "209 Train Loss 0.0004255876 Test MSE 1.620116128951936e-05 Test RE 0.009419653699528685\n",
      "210 Train Loss 0.00042086435 Test MSE 1.3752237652404564e-05 Test RE 0.008678577546964807\n",
      "211 Train Loss 0.00041832472 Test MSE 1.3159004319462137e-05 Test RE 0.008489329273512885\n",
      "212 Train Loss 0.00041490552 Test MSE 1.383784240552775e-05 Test RE 0.008705546791903798\n",
      "213 Train Loss 0.00041160133 Test MSE 1.3426569921136324e-05 Test RE 0.00857520286407866\n",
      "214 Train Loss 0.00040749437 Test MSE 1.3532231428578758e-05 Test RE 0.008608878376526892\n",
      "215 Train Loss 0.00040467907 Test MSE 1.368944712788869e-05 Test RE 0.008658742379308658\n",
      "216 Train Loss 0.0004024529 Test MSE 1.364099662985809e-05 Test RE 0.008643406031798554\n",
      "217 Train Loss 0.00040118233 Test MSE 1.2907185722853104e-05 Test RE 0.008407708453509449\n",
      "218 Train Loss 0.00039964114 Test MSE 1.2396824993721097e-05 Test RE 0.00823980813461718\n",
      "219 Train Loss 0.00039771333 Test MSE 1.223036349118393e-05 Test RE 0.008184300114151303\n",
      "220 Train Loss 0.00039345704 Test MSE 1.2587532625243364e-05 Test RE 0.008302945144167228\n",
      "221 Train Loss 0.00039074777 Test MSE 1.3216911027728666e-05 Test RE 0.008507987580560226\n",
      "222 Train Loss 0.0003850458 Test MSE 1.1984477985378316e-05 Test RE 0.008101611716154852\n",
      "223 Train Loss 0.00038108692 Test MSE 1.159383789137819e-05 Test RE 0.007968479796582566\n",
      "224 Train Loss 0.00037471758 Test MSE 1.039266680238103e-05 Test RE 0.007544411456152842\n",
      "225 Train Loss 0.00036789733 Test MSE 1.050707641555189e-05 Test RE 0.007585824822588176\n",
      "226 Train Loss 0.00036454195 Test MSE 1.056913284010607e-05 Test RE 0.007608193372737467\n",
      "227 Train Loss 0.0003623745 Test MSE 1.0580276330079272e-05 Test RE 0.007612203138360618\n",
      "228 Train Loss 0.00036097044 Test MSE 1.0762717834609924e-05 Test RE 0.007677553320938635\n",
      "229 Train Loss 0.0003591524 Test MSE 1.0659917407852196e-05 Test RE 0.007640799153690223\n",
      "230 Train Loss 0.00035686148 Test MSE 1.0691048711405408e-05 Test RE 0.00765194814359193\n",
      "231 Train Loss 0.00035557893 Test MSE 1.0376859407636115e-05 Test RE 0.00753867169393006\n",
      "232 Train Loss 0.0003540828 Test MSE 1.0058864909406813e-05 Test RE 0.007422263218710404\n",
      "233 Train Loss 0.0003534113 Test MSE 1.0179131714182457e-05 Test RE 0.007466502778484885\n",
      "234 Train Loss 0.000352121 Test MSE 1.0315113110425493e-05 Test RE 0.007516209233649111\n",
      "235 Train Loss 0.00034945313 Test MSE 1.0876044780645816e-05 Test RE 0.007717868197035639\n",
      "236 Train Loss 0.00034753044 Test MSE 1.147011843878135e-05 Test RE 0.007925849386089187\n",
      "237 Train Loss 0.00034333553 Test MSE 1.2327277491945897e-05 Test RE 0.008216662528273468\n",
      "238 Train Loss 0.00033675742 Test MSE 1.1992021820555413e-05 Test RE 0.008104161164229887\n",
      "239 Train Loss 0.0003323241 Test MSE 1.3041713167140646e-05 Test RE 0.008451410296266459\n",
      "240 Train Loss 0.00033019893 Test MSE 1.2956807300331278e-05 Test RE 0.008423854635572853\n",
      "241 Train Loss 0.0003275898 Test MSE 1.304934825079047e-05 Test RE 0.008453883812681575\n",
      "242 Train Loss 0.0003235675 Test MSE 1.3444400772321088e-05 Test RE 0.008580895026553247\n",
      "243 Train Loss 0.00032084848 Test MSE 1.3469120348319839e-05 Test RE 0.008588780044187975\n",
      "244 Train Loss 0.00031935805 Test MSE 1.3816154768553563e-05 Test RE 0.008698722145141698\n",
      "245 Train Loss 0.0003176026 Test MSE 1.4019965137102053e-05 Test RE 0.008762647287159602\n",
      "246 Train Loss 0.0003166275 Test MSE 1.3978945891944232e-05 Test RE 0.008749819135767835\n",
      "247 Train Loss 0.00031657933 Test MSE 1.3987676167130305e-05 Test RE 0.008752550972863796\n",
      "248 Train Loss 0.00031646685 Test MSE 1.3842477237212516e-05 Test RE 0.008707004582970378\n",
      "249 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "250 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "251 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "252 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "253 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "254 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "255 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "256 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "257 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "258 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "259 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "260 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "261 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "262 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "263 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "264 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "265 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "266 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "267 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "268 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "269 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "270 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "271 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "272 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "273 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "274 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "275 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "276 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "277 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "278 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "279 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "280 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "281 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "282 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "283 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "284 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "285 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "286 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "287 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "288 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "289 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "290 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "291 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "292 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "293 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "294 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "295 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "296 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "297 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "298 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "299 Train Loss 0.00031632147 Test MSE 1.363698921071928e-05 Test RE 0.008642136319034202\n",
      "Training time: 124.41\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbf1c6e3f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.01769987692401561\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
