{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"high\"\n",
    "label = \"KG_tanh_\" + level\n",
    "\n",
    "x = np.linspace(-2,2,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "                    \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_tanh_high\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 64245.055 Test MSE 4.263706955076611 Test RE 1.491865087914055\n",
      "1 Train Loss 48031.246 Test MSE 7.229865588927301 Test RE 1.9426787451045306\n",
      "2 Train Loss 32457.516 Test MSE 4.105922878483261 Test RE 1.4640006541477706\n",
      "3 Train Loss 21795.213 Test MSE 6.762295517234622 Test RE 1.878810375296078\n",
      "4 Train Loss 14081.559 Test MSE 6.358896374953309 Test RE 1.8219092918105768\n",
      "5 Train Loss 5009.98 Test MSE 13.681603836968623 Test RE 2.6724179634921477\n",
      "6 Train Loss 2529.8423 Test MSE 15.784167626101935 Test RE 2.870428405392283\n",
      "7 Train Loss 1512.0902 Test MSE 19.754988923796322 Test RE 3.2112511451997485\n",
      "8 Train Loss 937.14685 Test MSE 22.415213443105163 Test RE 3.4206395770328744\n",
      "9 Train Loss 583.44025 Test MSE 21.921770669766378 Test RE 3.3827795149029534\n",
      "10 Train Loss 425.48593 Test MSE 22.424889060541144 Test RE 3.4213777638272256\n",
      "11 Train Loss 311.85986 Test MSE 22.537821183099524 Test RE 3.429982002950913\n",
      "12 Train Loss 244.09903 Test MSE 21.933046097326233 Test RE 3.3836493666727057\n",
      "13 Train Loss 202.99918 Test MSE 21.624243806918233 Test RE 3.359745195210991\n",
      "14 Train Loss 169.12585 Test MSE 21.10772422594462 Test RE 3.3193770166927528\n",
      "15 Train Loss 149.8725 Test MSE 20.87175385684746 Test RE 3.3007706511548784\n",
      "16 Train Loss 134.67897 Test MSE 20.768650763410875 Test RE 3.292607921047997\n",
      "17 Train Loss 121.35126 Test MSE 20.799217692581934 Test RE 3.2950300309297824\n",
      "18 Train Loss 108.8795 Test MSE 20.714288162679885 Test RE 3.2882958447254396\n",
      "19 Train Loss 98.135254 Test MSE 20.60533466829179 Test RE 3.2796365156171072\n",
      "20 Train Loss 89.73151 Test MSE 20.53189857991209 Test RE 3.2737870923492127\n",
      "21 Train Loss 83.94996 Test MSE 20.441499280252497 Test RE 3.2665721108993115\n",
      "22 Train Loss 77.82869 Test MSE 20.4298003273101 Test RE 3.26563722490439\n",
      "23 Train Loss 72.789635 Test MSE 20.387334318085134 Test RE 3.2622414325158564\n",
      "24 Train Loss 68.73356 Test MSE 20.23312145121687 Test RE 3.2498799694260687\n",
      "25 Train Loss 64.668686 Test MSE 20.228327397349414 Test RE 3.249494931885674\n",
      "26 Train Loss 61.260616 Test MSE 20.07284874243317 Test RE 3.2369827340812845\n",
      "27 Train Loss 57.902325 Test MSE 19.94422619843549 Test RE 3.2265951186048345\n",
      "28 Train Loss 55.115555 Test MSE 19.841944466212304 Test RE 3.218310867740307\n",
      "29 Train Loss 53.156635 Test MSE 19.615293595618816 Test RE 3.1998769892329277\n",
      "30 Train Loss 51.212425 Test MSE 19.5454120077487 Test RE 3.1941719509593343\n",
      "31 Train Loss 49.10448 Test MSE 19.498885842414282 Test RE 3.190367960603309\n",
      "32 Train Loss 47.963108 Test MSE 19.493620484206133 Test RE 3.189937177930564\n",
      "33 Train Loss 46.47199 Test MSE 19.366889916089033 Test RE 3.1795511714803135\n",
      "34 Train Loss 45.474148 Test MSE 19.259359241995863 Test RE 3.170711982903107\n",
      "35 Train Loss 44.518482 Test MSE 19.08279165996469 Test RE 3.156144156285687\n",
      "36 Train Loss 43.53021 Test MSE 18.950270211963534 Test RE 3.1451660592358435\n",
      "37 Train Loss 42.697063 Test MSE 18.831285788215926 Test RE 3.135276621303716\n",
      "38 Train Loss 42.05325 Test MSE 18.807338162636697 Test RE 3.1332824314987664\n",
      "39 Train Loss 41.452217 Test MSE 18.71060738163275 Test RE 3.1252144218327333\n",
      "40 Train Loss 40.95613 Test MSE 18.689451505274867 Test RE 3.123447099466723\n",
      "41 Train Loss 40.48984 Test MSE 18.622021640057593 Test RE 3.1178074494988826\n",
      "42 Train Loss 40.11804 Test MSE 18.599838224680948 Test RE 3.1159498577438525\n",
      "43 Train Loss 39.729145 Test MSE 18.53455597528045 Test RE 3.110476825768457\n",
      "44 Train Loss 39.41556 Test MSE 18.484894090849576 Test RE 3.106306891681638\n",
      "45 Train Loss 39.171566 Test MSE 18.45194845344597 Test RE 3.1035374708635675\n",
      "46 Train Loss 38.910137 Test MSE 18.446908650843135 Test RE 3.1031136054805977\n",
      "47 Train Loss 38.70819 Test MSE 18.432752341898556 Test RE 3.1019226995473885\n",
      "48 Train Loss 38.51711 Test MSE 18.382300515465488 Test RE 3.097674693172422\n",
      "49 Train Loss 38.27863 Test MSE 18.303215595739 Test RE 3.091004053334233\n",
      "50 Train Loss 37.98433 Test MSE 18.211356997419017 Test RE 3.083237864860077\n",
      "51 Train Loss 37.765106 Test MSE 18.103574457409128 Test RE 3.0741003697640177\n",
      "52 Train Loss 37.546604 Test MSE 18.004734268138428 Test RE 3.06569704243411\n",
      "53 Train Loss 37.365448 Test MSE 17.92121477386729 Test RE 3.0585782733842017\n",
      "54 Train Loss 37.117252 Test MSE 17.82989892476198 Test RE 3.0507759740600697\n",
      "55 Train Loss 36.894096 Test MSE 17.706231969623875 Test RE 3.0401775782676266\n",
      "56 Train Loss 36.69787 Test MSE 17.64041301323196 Test RE 3.03452172726008\n",
      "57 Train Loss 36.50021 Test MSE 17.54119766197207 Test RE 3.0259761318782927\n",
      "58 Train Loss 36.235443 Test MSE 17.4801276704433 Test RE 3.020704044309451\n",
      "59 Train Loss 36.058647 Test MSE 17.348394845448386 Test RE 3.009300282559913\n",
      "60 Train Loss 35.810913 Test MSE 17.21422051192721 Test RE 2.997640569981938\n",
      "61 Train Loss 35.53178 Test MSE 17.011498974347656 Test RE 2.97993758985266\n",
      "62 Train Loss 35.223206 Test MSE 16.786660283515268 Test RE 2.9601793703732877\n",
      "63 Train Loss 34.719112 Test MSE 16.449872898812472 Test RE 2.9303341761048562\n",
      "64 Train Loss 33.893112 Test MSE 15.902745292509097 Test RE 2.8811901968830758\n",
      "65 Train Loss 32.299343 Test MSE 15.139151807812645 Test RE 2.8111670180958144\n",
      "66 Train Loss 30.701414 Test MSE 14.609865735935866 Test RE 2.7615886511915697\n",
      "67 Train Loss 29.282711 Test MSE 14.105747292953692 Test RE 2.7135256205295004\n",
      "68 Train Loss 27.482622 Test MSE 13.566460418554197 Test RE 2.6611487621097893\n",
      "69 Train Loss 25.30204 Test MSE 13.126029088618424 Test RE 2.617595636784793\n",
      "70 Train Loss 23.274403 Test MSE 12.554969492329068 Test RE 2.5600220604381807\n",
      "71 Train Loss 21.891115 Test MSE 12.033730112928659 Test RE 2.5063170610001517\n",
      "72 Train Loss 20.358955 Test MSE 11.515129728204561 Test RE 2.451716751539456\n",
      "73 Train Loss 18.645153 Test MSE 10.796494690727465 Test RE 2.373981141423001\n",
      "74 Train Loss 17.43079 Test MSE 10.429477488672708 Test RE 2.3332815793623918\n",
      "75 Train Loss 16.263378 Test MSE 10.081123486328199 Test RE 2.293983787139384\n",
      "76 Train Loss 15.278461 Test MSE 9.810303146910272 Test RE 2.262961111317505\n",
      "77 Train Loss 14.539076 Test MSE 9.626736057054034 Test RE 2.241689250199202\n",
      "78 Train Loss 13.942704 Test MSE 9.411046047983932 Test RE 2.216434114847373\n",
      "79 Train Loss 13.197455 Test MSE 9.169120186862127 Test RE 2.1877601610428683\n",
      "80 Train Loss 12.639594 Test MSE 9.01215667173158 Test RE 2.1689535106525013\n",
      "81 Train Loss 12.255394 Test MSE 8.87981351780876 Test RE 2.1529691140519365\n",
      "82 Train Loss 11.859284 Test MSE 8.698046388474694 Test RE 2.1308198636401645\n",
      "83 Train Loss 11.447142 Test MSE 8.54505097983836 Test RE 2.111996557280467\n",
      "84 Train Loss 11.109276 Test MSE 8.270886989864502 Test RE 2.07783912828317\n",
      "85 Train Loss 10.756377 Test MSE 8.074458102229492 Test RE 2.05301711351151\n",
      "86 Train Loss 10.455707 Test MSE 7.801939172713238 Test RE 2.0180743240681642\n",
      "87 Train Loss 10.138509 Test MSE 7.588444870008678 Test RE 1.9902712454556486\n",
      "88 Train Loss 9.928285 Test MSE 7.3887261602628325 Test RE 1.9639058439106567\n",
      "89 Train Loss 9.691012 Test MSE 7.134656565020654 Test RE 1.9298449297977196\n",
      "90 Train Loss 9.509084 Test MSE 6.9732971905818095 Test RE 1.907897171501615\n",
      "91 Train Loss 9.339675 Test MSE 6.866175195242438 Test RE 1.893186143624358\n",
      "92 Train Loss 9.14233 Test MSE 6.691634494719888 Test RE 1.8689685033025254\n",
      "93 Train Loss 8.902871 Test MSE 6.426760912182257 Test RE 1.8316055410610814\n",
      "94 Train Loss 8.740992 Test MSE 6.214852857058732 Test RE 1.8011558885038503\n",
      "95 Train Loss 8.5755005 Test MSE 6.007384809222067 Test RE 1.7708370624699807\n",
      "96 Train Loss 8.430953 Test MSE 5.822836512682124 Test RE 1.7434246222812704\n",
      "97 Train Loss 8.26306 Test MSE 5.6978020405997345 Test RE 1.7246046593856859\n",
      "98 Train Loss 8.088078 Test MSE 5.484092834338623 Test RE 1.6919529261240143\n",
      "99 Train Loss 7.896606 Test MSE 5.256469537375396 Test RE 1.6564676275133463\n",
      "100 Train Loss 7.6858726 Test MSE 5.028932153955715 Test RE 1.6202191656620615\n",
      "101 Train Loss 7.476353 Test MSE 4.824051527385714 Test RE 1.5868718126222314\n",
      "102 Train Loss 7.3413568 Test MSE 4.7271833464446145 Test RE 1.570858623051\n",
      "103 Train Loss 7.1850443 Test MSE 4.5530082587356775 Test RE 1.541647545964271\n",
      "104 Train Loss 7.036541 Test MSE 4.360409024141387 Test RE 1.5086881937527457\n",
      "105 Train Loss 6.8496103 Test MSE 4.022610083394605 Test RE 1.4490716031507\n",
      "106 Train Loss 6.620796 Test MSE 3.5813578902964807 Test RE 1.367287169137938\n",
      "107 Train Loss 6.138402 Test MSE 3.169099652928012 Test RE 1.2861861386287177\n",
      "108 Train Loss 5.4391418 Test MSE 2.7659116223019837 Test RE 1.2015864617528023\n",
      "109 Train Loss 5.0333424 Test MSE 2.4804949573244275 Test RE 1.1379024988366184\n",
      "110 Train Loss 4.512988 Test MSE 2.0979916639741027 Test RE 1.0464964417907017\n",
      "111 Train Loss 4.044562 Test MSE 1.8081531168671896 Test RE 0.9715238779115477\n",
      "112 Train Loss 3.477242 Test MSE 1.4872977133993353 Test RE 0.8811195392075596\n",
      "113 Train Loss 3.0188708 Test MSE 1.2848656867996457 Test RE 0.8189638698717601\n",
      "114 Train Loss 2.645778 Test MSE 1.0485495448093458 Test RE 0.7398273033367965\n",
      "115 Train Loss 2.373982 Test MSE 0.9186519709905165 Test RE 0.6924866135480847\n",
      "116 Train Loss 1.9513139 Test MSE 0.6658875815701573 Test RE 0.5895713007466071\n",
      "117 Train Loss 1.6411653 Test MSE 0.5273226229878537 Test RE 0.5246553172968009\n",
      "118 Train Loss 1.3716615 Test MSE 0.4490303027213361 Test RE 0.4841430502292683\n",
      "119 Train Loss 1.2237848 Test MSE 0.38557641752498034 Test RE 0.44863288958487657\n",
      "120 Train Loss 1.092516 Test MSE 0.3515587174893688 Test RE 0.42838554954274166\n",
      "121 Train Loss 0.9442353 Test MSE 0.3647172590828188 Test RE 0.4363289556643617\n",
      "122 Train Loss 0.8496715 Test MSE 0.3380662330106432 Test RE 0.4200846127564816\n",
      "123 Train Loss 0.7435404 Test MSE 0.2918267466870028 Test RE 0.39029988534220783\n",
      "124 Train Loss 0.66921014 Test MSE 0.26248821190270055 Test RE 0.3701611017295912\n",
      "125 Train Loss 0.6215669 Test MSE 0.2579171976222899 Test RE 0.3669239225061549\n",
      "126 Train Loss 0.57420576 Test MSE 0.2556456118925287 Test RE 0.3653045219283534\n",
      "127 Train Loss 0.5357369 Test MSE 0.24893710185867882 Test RE 0.36047959917056294\n",
      "128 Train Loss 0.497948 Test MSE 0.2546602810608779 Test RE 0.36459984855434463\n",
      "129 Train Loss 0.46768898 Test MSE 0.25037708181079865 Test RE 0.3615206952831586\n",
      "130 Train Loss 0.4413684 Test MSE 0.2531792005093401 Test RE 0.36353806305711117\n",
      "131 Train Loss 0.41916618 Test MSE 0.25268084079265907 Test RE 0.3631800913733885\n",
      "132 Train Loss 0.39831814 Test MSE 0.2520321046831029 Test RE 0.36271357507749186\n",
      "133 Train Loss 0.37670562 Test MSE 0.23350199860507204 Test RE 0.34912518430343426\n",
      "134 Train Loss 0.3496433 Test MSE 0.21290792952998747 Test RE 0.3333740531249073\n",
      "135 Train Loss 0.33522683 Test MSE 0.1997513927977493 Test RE 0.32290947236552153\n",
      "136 Train Loss 0.31760818 Test MSE 0.1881946886288368 Test RE 0.31342927494579775\n",
      "137 Train Loss 0.29872978 Test MSE 0.17406487108977176 Test RE 0.3014334493634067\n",
      "138 Train Loss 0.28495288 Test MSE 0.16824550306616115 Test RE 0.2963518272898865\n",
      "139 Train Loss 0.26920918 Test MSE 0.15851237288601572 Test RE 0.2876520414518054\n",
      "140 Train Loss 0.24886034 Test MSE 0.1414281190823706 Test RE 0.2717088345668992\n",
      "141 Train Loss 0.23502545 Test MSE 0.12819714618215816 Test RE 0.25868726879490017\n",
      "142 Train Loss 0.21933427 Test MSE 0.11699319998328947 Test RE 0.2471247180614017\n",
      "143 Train Loss 0.20406923 Test MSE 0.10376132467825686 Test RE 0.23273067583607632\n",
      "144 Train Loss 0.19271268 Test MSE 0.09979032525003487 Test RE 0.2282338708510413\n",
      "145 Train Loss 0.1841502 Test MSE 0.0906671945442386 Test RE 0.21755094083836943\n",
      "146 Train Loss 0.17245229 Test MSE 0.08603102142126895 Test RE 0.21191583829323188\n",
      "147 Train Loss 0.16152745 Test MSE 0.08101476790300474 Test RE 0.20564491396977552\n",
      "148 Train Loss 0.15352283 Test MSE 0.0764299216094822 Test RE 0.19974116747339588\n",
      "149 Train Loss 0.1459069 Test MSE 0.06878298110927798 Test RE 0.1894856710842384\n",
      "150 Train Loss 0.13893324 Test MSE 0.06303353678317063 Test RE 0.18139349758025014\n",
      "151 Train Loss 0.13202588 Test MSE 0.05765984067466289 Test RE 0.17348926052360977\n",
      "152 Train Loss 0.12417777 Test MSE 0.05046409328590638 Test RE 0.1623032118047265\n",
      "153 Train Loss 0.11818561 Test MSE 0.04534710802884876 Test RE 0.1538546670242878\n",
      "154 Train Loss 0.11223629 Test MSE 0.040717585075572736 Test RE 0.1457897137098356\n",
      "155 Train Loss 0.10769263 Test MSE 0.038342640263737335 Test RE 0.14147408194211697\n",
      "156 Train Loss 0.102507465 Test MSE 0.03599723740773284 Test RE 0.1370788533818782\n",
      "157 Train Loss 0.09930751 Test MSE 0.03552016554111065 Test RE 0.13616746973081226\n",
      "158 Train Loss 0.09542149 Test MSE 0.03345720139372097 Test RE 0.1321541124086872\n",
      "159 Train Loss 0.091533706 Test MSE 0.03312812149386732 Test RE 0.1315025825756705\n",
      "160 Train Loss 0.08719154 Test MSE 0.030040355347219442 Test RE 0.12522424147673672\n",
      "161 Train Loss 0.084876776 Test MSE 0.02952699297728236 Test RE 0.12414964649380351\n",
      "162 Train Loss 0.08223383 Test MSE 0.027799865433663817 Test RE 0.12046398445274999\n",
      "163 Train Loss 0.0773778 Test MSE 0.025056684031766543 Test RE 0.11436619576775416\n",
      "164 Train Loss 0.07470615 Test MSE 0.024267306558753334 Test RE 0.11255030211749004\n",
      "165 Train Loss 0.070722446 Test MSE 0.02040861663793777 Test RE 0.1032149629025834\n",
      "166 Train Loss 0.068388 Test MSE 0.01873400063252226 Test RE 0.09888971885168174\n",
      "167 Train Loss 0.06560309 Test MSE 0.018521488556888458 Test RE 0.09832723362119293\n",
      "168 Train Loss 0.06334888 Test MSE 0.01784158800032366 Test RE 0.09650562552990645\n",
      "169 Train Loss 0.060433637 Test MSE 0.017203779820712715 Test RE 0.09476496678779191\n",
      "170 Train Loss 0.058422312 Test MSE 0.017039469552887956 Test RE 0.09431133931540488\n",
      "171 Train Loss 0.057032797 Test MSE 0.01573626973281893 Test RE 0.0906330869946525\n",
      "172 Train Loss 0.0552232 Test MSE 0.015872394806862054 Test RE 0.0910242492497409\n",
      "173 Train Loss 0.05296744 Test MSE 0.015352006393642191 Test RE 0.08951966497610914\n",
      "174 Train Loss 0.05144591 Test MSE 0.015290587151900842 Test RE 0.08934041348073757\n",
      "175 Train Loss 0.05026193 Test MSE 0.014786557321141683 Test RE 0.08785559260230806\n",
      "176 Train Loss 0.049374986 Test MSE 0.01421411157604897 Test RE 0.0861381890450387\n",
      "177 Train Loss 0.048046295 Test MSE 0.014059897257149526 Test RE 0.08566964168041119\n",
      "178 Train Loss 0.045557674 Test MSE 0.013652980126040253 Test RE 0.08442082771128517\n",
      "179 Train Loss 0.044056304 Test MSE 0.01279804230293487 Test RE 0.08173492107109445\n",
      "180 Train Loss 0.042658363 Test MSE 0.011436245166012233 Test RE 0.07726407425007453\n",
      "181 Train Loss 0.041450717 Test MSE 0.01062046609709314 Test RE 0.074457365447056\n",
      "182 Train Loss 0.040306833 Test MSE 0.010470308958498506 Test RE 0.07392913510400538\n",
      "183 Train Loss 0.03910347 Test MSE 0.010050527241681583 Test RE 0.07243197035808792\n",
      "184 Train Loss 0.038254693 Test MSE 0.009638128811242201 Test RE 0.07093037240331225\n",
      "185 Train Loss 0.037262972 Test MSE 0.008786200583454114 Test RE 0.06772303827791773\n",
      "186 Train Loss 0.03643685 Test MSE 0.008111570026347109 Test RE 0.06507112837928959\n",
      "187 Train Loss 0.035513636 Test MSE 0.007399351990036122 Test RE 0.0621487961497468\n",
      "188 Train Loss 0.034683675 Test MSE 0.006921757583576638 Test RE 0.0601096320458158\n",
      "189 Train Loss 0.033503294 Test MSE 0.006241103447883752 Test RE 0.05707771353661131\n",
      "190 Train Loss 0.032041136 Test MSE 0.005418179094469964 Test RE 0.05318174153705897\n",
      "191 Train Loss 0.030902725 Test MSE 0.005029115963989134 Test RE 0.05123676506076908\n",
      "192 Train Loss 0.03027156 Test MSE 0.0044267440732847375 Test RE 0.04807043853917677\n",
      "193 Train Loss 0.029789884 Test MSE 0.004227937669912675 Test RE 0.0469786102381316\n",
      "194 Train Loss 0.029255755 Test MSE 0.004226806470606259 Test RE 0.046972325173102805\n",
      "195 Train Loss 0.028714465 Test MSE 0.00393461637904449 Test RE 0.045319705042053085\n",
      "196 Train Loss 0.0281375 Test MSE 0.0036082683337509743 Test RE 0.043399556389774295\n",
      "197 Train Loss 0.027260162 Test MSE 0.0032732901784679478 Test RE 0.04133596973787863\n",
      "198 Train Loss 0.026573593 Test MSE 0.0032512923146201618 Test RE 0.04119683818172273\n",
      "199 Train Loss 0.026080513 Test MSE 0.0034658302742212265 Test RE 0.042534322771329486\n",
      "200 Train Loss 0.025600744 Test MSE 0.0034589146695568826 Test RE 0.04249186578139449\n",
      "201 Train Loss 0.025171997 Test MSE 0.0032910059074407806 Test RE 0.04144767823808918\n",
      "202 Train Loss 0.024763634 Test MSE 0.003376759501243413 Test RE 0.04198420579472341\n",
      "203 Train Loss 0.024319226 Test MSE 0.0032298000949803583 Test RE 0.04106044940338599\n",
      "204 Train Loss 0.023839243 Test MSE 0.00321527910681725 Test RE 0.040968042759646994\n",
      "205 Train Loss 0.023310496 Test MSE 0.0032819209270337955 Test RE 0.04139042954473311\n",
      "206 Train Loss 0.022844667 Test MSE 0.0031463826272495766 Test RE 0.04052673761412463\n",
      "207 Train Loss 0.022506833 Test MSE 0.003180696898515829 Test RE 0.04074712950420679\n",
      "208 Train Loss 0.022210494 Test MSE 0.003137747131918015 Test RE 0.04047108498790918\n",
      "209 Train Loss 0.021688165 Test MSE 0.0032877169477492506 Test RE 0.041426962107118416\n",
      "210 Train Loss 0.02129762 Test MSE 0.0032458338392179764 Test RE 0.041162241724727815\n",
      "211 Train Loss 0.020821786 Test MSE 0.0034696431581867754 Test RE 0.04255771310559206\n",
      "212 Train Loss 0.02029513 Test MSE 0.003319909827662576 Test RE 0.04162929162425931\n",
      "213 Train Loss 0.019808348 Test MSE 0.003402077672729175 Test RE 0.04214130586244541\n",
      "214 Train Loss 0.019476123 Test MSE 0.003108989546878045 Test RE 0.04028519849118315\n",
      "215 Train Loss 0.019183364 Test MSE 0.0030000201831459432 Test RE 0.03957290797734127\n",
      "216 Train Loss 0.018907761 Test MSE 0.002956873488119794 Test RE 0.03928730591569547\n",
      "217 Train Loss 0.01863105 Test MSE 0.0029656978076793602 Test RE 0.03934588560688233\n",
      "218 Train Loss 0.018418353 Test MSE 0.0029081262850290963 Test RE 0.038962113556817654\n",
      "219 Train Loss 0.018018771 Test MSE 0.0026854193578046 Test RE 0.037440525396810864\n",
      "220 Train Loss 0.017510738 Test MSE 0.002508530616882642 Test RE 0.03618641669599738\n",
      "221 Train Loss 0.017195586 Test MSE 0.0022410550891957303 Test RE 0.03420283797765159\n",
      "222 Train Loss 0.01695487 Test MSE 0.0021699789469634564 Test RE 0.03365608819553362\n",
      "223 Train Loss 0.016742852 Test MSE 0.002023691581193634 Test RE 0.032501846836259535\n",
      "224 Train Loss 0.01651695 Test MSE 0.0019903638736847545 Test RE 0.032233103082758126\n",
      "225 Train Loss 0.016293742 Test MSE 0.0019451060913667651 Test RE 0.03186453049919168\n",
      "226 Train Loss 0.016047088 Test MSE 0.002016794902423447 Test RE 0.03244641692207759\n",
      "227 Train Loss 0.01575042 Test MSE 0.0018903106004159525 Test RE 0.03141249711944203\n",
      "228 Train Loss 0.015273335 Test MSE 0.0019218925392256985 Test RE 0.03167381875962239\n",
      "229 Train Loss 0.014898472 Test MSE 0.0018341408143639037 Test RE 0.030942273066390146\n",
      "230 Train Loss 0.01449503 Test MSE 0.0017992670491812583 Test RE 0.030646698103728366\n",
      "231 Train Loss 0.014189647 Test MSE 0.0017090360645245202 Test RE 0.029868367799705333\n",
      "232 Train Loss 0.013954193 Test MSE 0.0016034772606718837 Test RE 0.028931255429241753\n",
      "233 Train Loss 0.013715481 Test MSE 0.0015845690820392893 Test RE 0.0287601711232665\n",
      "234 Train Loss 0.013433597 Test MSE 0.0015480903214025545 Test RE 0.028427196047898017\n",
      "235 Train Loss 0.013211476 Test MSE 0.0014328646195682449 Test RE 0.027348811410364732\n",
      "236 Train Loss 0.012951601 Test MSE 0.0014301629904847307 Test RE 0.027323016508367392\n",
      "237 Train Loss 0.012808482 Test MSE 0.0013624826160595497 Test RE 0.0266686702690069\n",
      "238 Train Loss 0.0126225455 Test MSE 0.0013604148361379801 Test RE 0.02664842565123288\n",
      "239 Train Loss 0.012420604 Test MSE 0.0012141828629023152 Test RE 0.025175489663907816\n",
      "240 Train Loss 0.012293406 Test MSE 0.0012373245285924787 Test RE 0.02541427284221592\n",
      "241 Train Loss 0.012139022 Test MSE 0.0012567520082440045 Test RE 0.025613013053595302\n",
      "242 Train Loss 0.012002419 Test MSE 0.0012796773896720706 Test RE 0.025845570631246168\n",
      "243 Train Loss 0.011873823 Test MSE 0.0013130379871088504 Test RE 0.026180294178456173\n",
      "244 Train Loss 0.011766084 Test MSE 0.0013324825122917284 Test RE 0.02637343122630325\n",
      "245 Train Loss 0.011611842 Test MSE 0.0013457743319205831 Test RE 0.02650464533770471\n",
      "246 Train Loss 0.011431247 Test MSE 0.0014248938960411469 Test RE 0.027272637494299964\n",
      "247 Train Loss 0.011271146 Test MSE 0.001501179550444795 Test RE 0.027993177422021908\n",
      "248 Train Loss 0.011117135 Test MSE 0.0015120452239356528 Test RE 0.02809430333854712\n",
      "249 Train Loss 0.010970154 Test MSE 0.0013887276502595868 Test RE 0.026924299827958083\n",
      "250 Train Loss 0.010839643 Test MSE 0.0013357792733171068 Test RE 0.026406036977556686\n",
      "251 Train Loss 0.010726952 Test MSE 0.0013760061869491453 Test RE 0.026800695853885868\n",
      "252 Train Loss 0.010592705 Test MSE 0.0013830348031508963 Test RE 0.026869057416971567\n",
      "253 Train Loss 0.01047616 Test MSE 0.0014298980018649164 Test RE 0.027320485110235403\n",
      "254 Train Loss 0.010366427 Test MSE 0.0013985296356674884 Test RE 0.027019151954583105\n",
      "255 Train Loss 0.01024159 Test MSE 0.001331543748408088 Test RE 0.02636413925183155\n",
      "256 Train Loss 0.010127831 Test MSE 0.0012152417041547798 Test RE 0.025186464550292883\n",
      "257 Train Loss 0.010022507 Test MSE 0.0011461998963134708 Test RE 0.02446054106216132\n",
      "258 Train Loss 0.009907208 Test MSE 0.001154543492244655 Test RE 0.02454940811248578\n",
      "259 Train Loss 0.009784754 Test MSE 0.0010489735775781176 Test RE 0.023400123600215855\n",
      "260 Train Loss 0.009601763 Test MSE 0.0009587714227199201 Test RE 0.022371413099332063\n",
      "261 Train Loss 0.009481964 Test MSE 0.0009062970641088451 Test RE 0.02175059608325478\n",
      "262 Train Loss 0.009357988 Test MSE 0.0008642097137016056 Test RE 0.021239556723031898\n",
      "263 Train Loss 0.009251321 Test MSE 0.0008338466164070715 Test RE 0.02086310588948257\n",
      "264 Train Loss 0.009081997 Test MSE 0.0008006863944407081 Test RE 0.020444057856423444\n",
      "265 Train Loss 0.00893737 Test MSE 0.0008007877877345354 Test RE 0.0204453522612989\n",
      "266 Train Loss 0.008696811 Test MSE 0.0008129262589919873 Test RE 0.020599726438323585\n",
      "267 Train Loss 0.008558455 Test MSE 0.0008383818853054714 Test RE 0.02091976588155268\n",
      "268 Train Loss 0.008467442 Test MSE 0.0008381484617813334 Test RE 0.02091685342274145\n",
      "269 Train Loss 0.008377746 Test MSE 0.0008353255656287959 Test RE 0.020881599581280413\n",
      "270 Train Loss 0.008331532 Test MSE 0.0008335300647872294 Test RE 0.020859145402779725\n",
      "271 Train Loss 0.008286239 Test MSE 0.0008232302409106612 Test RE 0.020729867905660955\n",
      "272 Train Loss 0.008227502 Test MSE 0.0008217454923670369 Test RE 0.02071116564595614\n",
      "273 Train Loss 0.008151124 Test MSE 0.0008273016521138644 Test RE 0.020781066049534537\n",
      "274 Train Loss 0.008081076 Test MSE 0.0008243808264513489 Test RE 0.02074434936960334\n",
      "275 Train Loss 0.007994787 Test MSE 0.0008171062950864283 Test RE 0.02065262003861165\n",
      "276 Train Loss 0.007910674 Test MSE 0.0008129823598865954 Test RE 0.020600437230435042\n",
      "277 Train Loss 0.007835367 Test MSE 0.0008096428664546606 Test RE 0.020558083410013802\n",
      "278 Train Loss 0.0077656545 Test MSE 0.0007956073840898899 Test RE 0.020379113096451514\n",
      "279 Train Loss 0.007714714 Test MSE 0.0008123218669621771 Test RE 0.020592067302375783\n",
      "280 Train Loss 0.0076713045 Test MSE 0.0007999148718713483 Test RE 0.020434205775994547\n",
      "281 Train Loss 0.007610145 Test MSE 0.0008131162715517056 Test RE 0.0206021337772475\n",
      "282 Train Loss 0.007533014 Test MSE 0.0008448132645990565 Test RE 0.02099985224231487\n",
      "283 Train Loss 0.0074490295 Test MSE 0.0008552541891079561 Test RE 0.0211292208206885\n",
      "284 Train Loss 0.0073892586 Test MSE 0.0008756629602986938 Test RE 0.021379835867779525\n",
      "285 Train Loss 0.0073388927 Test MSE 0.0008854199029514958 Test RE 0.021498616710532367\n",
      "286 Train Loss 0.0072400235 Test MSE 0.000883431295235083 Test RE 0.021474460744073973\n",
      "287 Train Loss 0.007189289 Test MSE 0.000879240437067608 Test RE 0.02142346447204291\n",
      "288 Train Loss 0.0071342564 Test MSE 0.0008913808450626883 Test RE 0.02157086324675038\n",
      "289 Train Loss 0.0070707398 Test MSE 0.0008730522135856807 Test RE 0.021347940603815754\n",
      "290 Train Loss 0.007020951 Test MSE 0.0008971899801997901 Test RE 0.021641037832898204\n",
      "291 Train Loss 0.0069667255 Test MSE 0.0008853680085598859 Test RE 0.021497986685174594\n",
      "292 Train Loss 0.006887067 Test MSE 0.0008958404835366485 Test RE 0.021624756165052144\n",
      "293 Train Loss 0.0068234704 Test MSE 0.0008872302683162515 Test RE 0.021520583958351536\n",
      "294 Train Loss 0.0067665284 Test MSE 0.0008817298162930933 Test RE 0.02145377098980689\n",
      "295 Train Loss 0.0067083086 Test MSE 0.0008716033154651253 Test RE 0.02133021896340649\n",
      "296 Train Loss 0.0066361483 Test MSE 0.000894304206710601 Test RE 0.021606206061804335\n",
      "297 Train Loss 0.0065871305 Test MSE 0.0008883069388634626 Test RE 0.02153363781511964\n",
      "298 Train Loss 0.006524844 Test MSE 0.0009115102228279351 Test RE 0.02181306275298451\n",
      "299 Train Loss 0.0064716 Test MSE 0.0009015754375017493 Test RE 0.021693863966328785\n",
      "Training time: 110.61\n",
      "KG_tanh_high\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 51560.59 Test MSE 10.080998007338028 Test RE 2.2939695105726314\n",
      "1 Train Loss 31951.7 Test MSE 11.458678171717017 Test RE 2.4456997429006573\n",
      "2 Train Loss 19727.85 Test MSE 12.978148002868345 Test RE 2.6028086308123495\n",
      "3 Train Loss 5998.669 Test MSE 7.182454823583309 Test RE 1.936298586451683\n",
      "4 Train Loss 1139.3629 Test MSE 3.719522198019097 Test RE 1.3934117048576804\n",
      "5 Train Loss 380.9562 Test MSE 5.125358956264096 Test RE 1.6356787828146782\n",
      "6 Train Loss 141.37521 Test MSE 3.662260124975786 Test RE 1.3826443111006246\n",
      "7 Train Loss 75.96127 Test MSE 2.2044038430823734 Test RE 1.0727078447337997\n",
      "8 Train Loss 40.812828 Test MSE 1.0481241336261276 Test RE 0.7396772089806475\n",
      "9 Train Loss 22.828959 Test MSE 0.6490164558835931 Test RE 0.5820546071391303\n",
      "10 Train Loss 12.838062 Test MSE 0.4774957180763738 Test RE 0.499252924573373\n",
      "11 Train Loss 7.302172 Test MSE 0.2979821573858133 Test RE 0.3943946426320505\n",
      "12 Train Loss 5.152111 Test MSE 0.19628210614531535 Test RE 0.3200930403728588\n",
      "13 Train Loss 3.718898 Test MSE 0.173633719174009 Test RE 0.3010598984370164\n",
      "14 Train Loss 3.0594094 Test MSE 0.16791567345876934 Test RE 0.29606119973264955\n",
      "15 Train Loss 2.5858665 Test MSE 0.1605123530032262 Test RE 0.2894610329203436\n",
      "16 Train Loss 2.1421278 Test MSE 0.14025202273221166 Test RE 0.2705767298176171\n",
      "17 Train Loss 1.8844532 Test MSE 0.12402636865358639 Test RE 0.2544443964727308\n",
      "18 Train Loss 1.6282432 Test MSE 0.11542172954907826 Test RE 0.2454593985728521\n",
      "19 Train Loss 1.4845074 Test MSE 0.11120774320344941 Test RE 0.2409369401733373\n",
      "20 Train Loss 1.3468819 Test MSE 0.10064599185407548 Test RE 0.22921029439655213\n",
      "21 Train Loss 1.250028 Test MSE 0.09516256263594113 Test RE 0.2228788925892059\n",
      "22 Train Loss 1.153137 Test MSE 0.08576371177157671 Test RE 0.2115863570283182\n",
      "23 Train Loss 1.0579094 Test MSE 0.08356330098908413 Test RE 0.20885441997715173\n",
      "24 Train Loss 0.96102697 Test MSE 0.08437673595071675 Test RE 0.2098684898141439\n",
      "25 Train Loss 0.87465256 Test MSE 0.08604245031474617 Test RE 0.21192991393170602\n",
      "26 Train Loss 0.8243605 Test MSE 0.08025393301373704 Test RE 0.20467699842828452\n",
      "27 Train Loss 0.7704357 Test MSE 0.07777036517484591 Test RE 0.20148510500767997\n",
      "28 Train Loss 0.72296923 Test MSE 0.07942819747574607 Test RE 0.20362131149116858\n",
      "29 Train Loss 0.6762129 Test MSE 0.07836825154628774 Test RE 0.2022581151022153\n",
      "30 Train Loss 0.63478327 Test MSE 0.07370385314054154 Test RE 0.19614668527538692\n",
      "31 Train Loss 0.59090495 Test MSE 0.07364999879324718 Test RE 0.19607501139683847\n",
      "32 Train Loss 0.54941833 Test MSE 0.0646165309841644 Test RE 0.18365708893795082\n",
      "33 Train Loss 0.5129085 Test MSE 0.06391205270169983 Test RE 0.18265318939075448\n",
      "34 Train Loss 0.46997052 Test MSE 0.05520154452842454 Test RE 0.16975066784236986\n",
      "35 Train Loss 0.44707206 Test MSE 0.047913085544972984 Test RE 0.1581477242524206\n",
      "36 Train Loss 0.4183797 Test MSE 0.04088866222981254 Test RE 0.14609566439598262\n",
      "37 Train Loss 0.40292603 Test MSE 0.03883927256708969 Test RE 0.14238735432033137\n",
      "38 Train Loss 0.38137558 Test MSE 0.034865899394189825 Test RE 0.13490756798855302\n",
      "39 Train Loss 0.35840246 Test MSE 0.03203471739420122 Test RE 0.12931423216428892\n",
      "40 Train Loss 0.33941844 Test MSE 0.028869513062885543 Test RE 0.12275964003196148\n",
      "41 Train Loss 0.3213629 Test MSE 0.026630515386294653 Test RE 0.11790321907193237\n",
      "42 Train Loss 0.3032002 Test MSE 0.028991056159707266 Test RE 0.12301778286103025\n",
      "43 Train Loss 0.28900847 Test MSE 0.026228261063153933 Test RE 0.11700936589052217\n",
      "44 Train Loss 0.27804166 Test MSE 0.021261461572660977 Test RE 0.10534948934408853\n",
      "45 Train Loss 0.27164188 Test MSE 0.021862383134433287 Test RE 0.1068278842986275\n",
      "46 Train Loss 0.26203403 Test MSE 0.02053704404054286 Test RE 0.10353920930844109\n",
      "47 Train Loss 0.23949486 Test MSE 0.024209453866040922 Test RE 0.11241606341696733\n",
      "48 Train Loss 0.22546591 Test MSE 0.025777373920649355 Test RE 0.11599925835908781\n",
      "49 Train Loss 0.21516004 Test MSE 0.023932429500067343 Test RE 0.11177103461387276\n",
      "50 Train Loss 0.20586446 Test MSE 0.023958934785057586 Test RE 0.11183291097556236\n",
      "51 Train Loss 0.19533028 Test MSE 0.024518322844199098 Test RE 0.11313090375805682\n",
      "52 Train Loss 0.18679792 Test MSE 0.0232209844688374 Test RE 0.11009717890472379\n",
      "53 Train Loss 0.17958951 Test MSE 0.02233909672269341 Test RE 0.10798630502742507\n",
      "54 Train Loss 0.17303702 Test MSE 0.023904104122319823 Test RE 0.11170487137492002\n",
      "55 Train Loss 0.1672193 Test MSE 0.024538850355716922 Test RE 0.11317825222624595\n",
      "56 Train Loss 0.16254568 Test MSE 0.02371717963548234 Test RE 0.11126726124848703\n",
      "57 Train Loss 0.15474394 Test MSE 0.02355242135920434 Test RE 0.11088011254425686\n",
      "58 Train Loss 0.15067272 Test MSE 0.022943870813957247 Test RE 0.10943827053788459\n",
      "59 Train Loss 0.14628528 Test MSE 0.022305660217593518 Test RE 0.10790545939639039\n",
      "60 Train Loss 0.14173454 Test MSE 0.02277864570498961 Test RE 0.1090435110542824\n",
      "61 Train Loss 0.13761689 Test MSE 0.023813928993460624 Test RE 0.11149397623214952\n",
      "62 Train Loss 0.13367704 Test MSE 0.023666318641772734 Test RE 0.11114789206529771\n",
      "63 Train Loss 0.12934381 Test MSE 0.02529890812658295 Test RE 0.1149176578078328\n",
      "64 Train Loss 0.12582165 Test MSE 0.026508543940942396 Test RE 0.1176329026662198\n",
      "65 Train Loss 0.1216726 Test MSE 0.026069262614948956 Test RE 0.11665416527969952\n",
      "66 Train Loss 0.118378244 Test MSE 0.02698996655749502 Test RE 0.11869626413364344\n",
      "67 Train Loss 0.11482021 Test MSE 0.028368229297507958 Test RE 0.12168918744747995\n",
      "68 Train Loss 0.11188156 Test MSE 0.026902757521728174 Test RE 0.11850434536971512\n",
      "69 Train Loss 0.108593725 Test MSE 0.027060726706553618 Test RE 0.11885175650141598\n",
      "70 Train Loss 0.10593751 Test MSE 0.029624641351166416 Test RE 0.12435476397189942\n",
      "71 Train Loss 0.10324502 Test MSE 0.028266702546761613 Test RE 0.12147123620472737\n",
      "72 Train Loss 0.10010284 Test MSE 0.030057031905745952 Test RE 0.1252589950544318\n",
      "73 Train Loss 0.0970072 Test MSE 0.03216529858741039 Test RE 0.12957752204533166\n",
      "74 Train Loss 0.093189396 Test MSE 0.033833717010425174 Test RE 0.13289564005073645\n",
      "75 Train Loss 0.09082259 Test MSE 0.03434016374147992 Test RE 0.13388658297039766\n",
      "76 Train Loss 0.088654175 Test MSE 0.03412691158861285 Test RE 0.13347021823273078\n",
      "77 Train Loss 0.086520284 Test MSE 0.037151807121593446 Test RE 0.1392598261196918\n",
      "78 Train Loss 0.08397429 Test MSE 0.03704482364151565 Test RE 0.13905917313665056\n",
      "79 Train Loss 0.0808622 Test MSE 0.036378651067518315 Test RE 0.13780315870222093\n",
      "80 Train Loss 0.07847367 Test MSE 0.035949264346400715 Test RE 0.13698748130523888\n",
      "81 Train Loss 0.076477915 Test MSE 0.03482066315994188 Test RE 0.13482002269062715\n",
      "82 Train Loss 0.074794464 Test MSE 0.03323339159376299 Test RE 0.13171135248898594\n",
      "83 Train Loss 0.072282165 Test MSE 0.030951891821252867 Test RE 0.1271099290506388\n",
      "84 Train Loss 0.06993061 Test MSE 0.02755151420750024 Test RE 0.11992469235652788\n",
      "85 Train Loss 0.068535395 Test MSE 0.027604935377572 Test RE 0.12004090039606426\n",
      "86 Train Loss 0.06715164 Test MSE 0.027168114499744718 Test RE 0.11908734866879297\n",
      "87 Train Loss 0.065179184 Test MSE 0.025473838788708392 Test RE 0.11531427554581224\n",
      "88 Train Loss 0.06311225 Test MSE 0.022732069813111575 Test RE 0.10893197242987777\n",
      "89 Train Loss 0.06077626 Test MSE 0.020203828996176867 Test RE 0.10269580862970074\n",
      "90 Train Loss 0.058675237 Test MSE 0.020034460479227068 Test RE 0.10226445369547761\n",
      "91 Train Loss 0.056327865 Test MSE 0.017942764745776735 Test RE 0.09677887255053394\n",
      "92 Train Loss 0.053921297 Test MSE 0.015556708433360307 Test RE 0.09011451153900432\n",
      "93 Train Loss 0.05271984 Test MSE 0.014148577022014469 Test RE 0.0859393883864043\n",
      "94 Train Loss 0.051534746 Test MSE 0.012921606749012864 Test RE 0.08212854649338137\n",
      "95 Train Loss 0.050373256 Test MSE 0.012877812380839257 Test RE 0.08198925187540833\n",
      "96 Train Loss 0.049075123 Test MSE 0.01192321639077923 Test RE 0.07889193166068331\n",
      "97 Train Loss 0.04785875 Test MSE 0.012081189246630486 Test RE 0.07941283869376585\n",
      "98 Train Loss 0.046719402 Test MSE 0.011108462475130467 Test RE 0.07614876303852645\n",
      "99 Train Loss 0.045413133 Test MSE 0.010882320702131352 Test RE 0.07536967405272693\n",
      "100 Train Loss 0.044100236 Test MSE 0.009541144568814733 Test RE 0.07057259956187607\n",
      "101 Train Loss 0.04260297 Test MSE 0.009619240232041353 Test RE 0.07086083447527936\n",
      "102 Train Loss 0.0414957 Test MSE 0.008621030158810676 Test RE 0.06708346073074897\n",
      "103 Train Loss 0.040692687 Test MSE 0.007326236684594179 Test RE 0.061840978028340925\n",
      "104 Train Loss 0.039544776 Test MSE 0.0077218064747656264 Test RE 0.06348853903394176\n",
      "105 Train Loss 0.038679574 Test MSE 0.007911858494410048 Test RE 0.06426509183561328\n",
      "106 Train Loss 0.037606597 Test MSE 0.00842091791458854 Test RE 0.06630031531813807\n",
      "107 Train Loss 0.03685714 Test MSE 0.008167715938586777 Test RE 0.06529594167444047\n",
      "108 Train Loss 0.0358705 Test MSE 0.007464749348619432 Test RE 0.062422835423910236\n",
      "109 Train Loss 0.03460057 Test MSE 0.006931456284978379 Test RE 0.060151729828791654\n",
      "110 Train Loss 0.032981616 Test MSE 0.0064689856610609464 Test RE 0.05811041421673333\n",
      "111 Train Loss 0.03233486 Test MSE 0.0060305937246348425 Test RE 0.05610685332964843\n",
      "112 Train Loss 0.03179734 Test MSE 0.0052340056042185 Test RE 0.05227005638144929\n",
      "113 Train Loss 0.031071246 Test MSE 0.004846780357194979 Test RE 0.050299370105653905\n",
      "114 Train Loss 0.030470807 Test MSE 0.0044746353565408925 Test RE 0.048329767051036476\n",
      "115 Train Loss 0.029856991 Test MSE 0.0042241367027638895 Test RE 0.04695748832018495\n",
      "116 Train Loss 0.028990861 Test MSE 0.004218464447845581 Test RE 0.046925950003653336\n",
      "117 Train Loss 0.028344017 Test MSE 0.0038702684236787094 Test RE 0.04494759098837331\n",
      "118 Train Loss 0.027937405 Test MSE 0.0036728926880496885 Test RE 0.043786476278964474\n",
      "119 Train Loss 0.0274651 Test MSE 0.0037396210007213937 Test RE 0.04418243751154065\n",
      "120 Train Loss 0.026996668 Test MSE 0.0036314485671197646 Test RE 0.04353873690745391\n",
      "121 Train Loss 0.026411463 Test MSE 0.0034980919917313165 Test RE 0.042731829807037755\n",
      "122 Train Loss 0.025899287 Test MSE 0.0033177141718142944 Test RE 0.04161552337150057\n",
      "123 Train Loss 0.02535367 Test MSE 0.0032852672755179606 Test RE 0.04141152565213089\n",
      "124 Train Loss 0.024746738 Test MSE 0.0035053369545759794 Test RE 0.0427760582587329\n",
      "125 Train Loss 0.024272144 Test MSE 0.0037428644585930176 Test RE 0.04420159357247591\n",
      "126 Train Loss 0.023857145 Test MSE 0.0035589188508091847 Test RE 0.043101751594829485\n",
      "127 Train Loss 0.023456635 Test MSE 0.003655746976881769 Test RE 0.043684155227291334\n",
      "128 Train Loss 0.022952521 Test MSE 0.003637418139604217 Test RE 0.04357450788371487\n",
      "129 Train Loss 0.022638105 Test MSE 0.003417984301031501 Test RE 0.04223970813914029\n",
      "130 Train Loss 0.022266632 Test MSE 0.003622109679945746 Test RE 0.04348271723744644\n",
      "131 Train Loss 0.021836895 Test MSE 0.003769033439319231 Test RE 0.044355846532643725\n",
      "132 Train Loss 0.021233361 Test MSE 0.0035959890960010725 Test RE 0.043325647303454666\n",
      "133 Train Loss 0.020628624 Test MSE 0.003500832655212505 Test RE 0.042748566164435134\n",
      "134 Train Loss 0.020180527 Test MSE 0.0032028955941557453 Test RE 0.0408890732999635\n",
      "135 Train Loss 0.019844538 Test MSE 0.003012923421102455 Test RE 0.039657919201528155\n",
      "136 Train Loss 0.019501194 Test MSE 0.0028123579145344856 Test RE 0.038315206634436626\n",
      "137 Train Loss 0.019190999 Test MSE 0.002697677509961657 Test RE 0.03752588061383673\n",
      "138 Train Loss 0.018946644 Test MSE 0.0025989610138449533 Test RE 0.03683288688743056\n",
      "139 Train Loss 0.018706802 Test MSE 0.0024994012699102383 Test RE 0.0361205096925812\n",
      "140 Train Loss 0.018408448 Test MSE 0.0023721994594630884 Test RE 0.035189368908312826\n",
      "141 Train Loss 0.018101433 Test MSE 0.0024306697620793878 Test RE 0.0356204052480363\n",
      "142 Train Loss 0.017842868 Test MSE 0.002383486632261102 Test RE 0.0352729869069072\n",
      "143 Train Loss 0.017572299 Test MSE 0.002412171011361872 Test RE 0.035484600805829436\n",
      "144 Train Loss 0.017379414 Test MSE 0.002425296751670937 Test RE 0.03558101390521951\n",
      "145 Train Loss 0.016895626 Test MSE 0.002291941348902021 Test RE 0.03458896977063258\n",
      "146 Train Loss 0.016500179 Test MSE 0.002501026514241315 Test RE 0.03613225152735489\n",
      "147 Train Loss 0.015937528 Test MSE 0.002241017992863241 Test RE 0.034202554895565285\n",
      "148 Train Loss 0.015628457 Test MSE 0.0023158628440999546 Test RE 0.03476900755342663\n",
      "149 Train Loss 0.015387018 Test MSE 0.002345920106640604 Test RE 0.03499391122015444\n",
      "150 Train Loss 0.015070777 Test MSE 0.002392457675784984 Test RE 0.03533930536302647\n",
      "151 Train Loss 0.0148174 Test MSE 0.0024300307502383074 Test RE 0.035615722720346535\n",
      "152 Train Loss 0.014560458 Test MSE 0.0023297676704166137 Test RE 0.034873230800885384\n",
      "153 Train Loss 0.014287692 Test MSE 0.0022592732628520422 Test RE 0.03434157887696754\n",
      "154 Train Loss 0.0140163405 Test MSE 0.002306613859608717 Test RE 0.03469950867722828\n",
      "155 Train Loss 0.013772898 Test MSE 0.0022722521322002406 Test RE 0.0344400788192327\n",
      "156 Train Loss 0.0135411965 Test MSE 0.0023259515995807467 Test RE 0.03484465858318144\n",
      "157 Train Loss 0.013223092 Test MSE 0.0022372415879901054 Test RE 0.03417372488276622\n",
      "158 Train Loss 0.012840476 Test MSE 0.002079523656601282 Test RE 0.03294714669083635\n",
      "159 Train Loss 0.012634148 Test MSE 0.002082299428693204 Test RE 0.032969128473050696\n",
      "160 Train Loss 0.012445014 Test MSE 0.0021507705447708233 Test RE 0.0335067971880839\n",
      "161 Train Loss 0.012311095 Test MSE 0.0021575779931649348 Test RE 0.03355978182437007\n",
      "162 Train Loss 0.012140678 Test MSE 0.002105630767675022 Test RE 0.03315331697277033\n",
      "163 Train Loss 0.011942212 Test MSE 0.0021730041604243323 Test RE 0.03367954035612972\n",
      "164 Train Loss 0.011773297 Test MSE 0.0020562218093719137 Test RE 0.03276203406051195\n",
      "165 Train Loss 0.011597575 Test MSE 0.0020157308160277344 Test RE 0.032437856223600695\n",
      "166 Train Loss 0.0114573985 Test MSE 0.0020065293190719155 Test RE 0.032363734659934945\n",
      "167 Train Loss 0.01128079 Test MSE 0.0019060691499417125 Test RE 0.031543160301760256\n",
      "168 Train Loss 0.011129225 Test MSE 0.001739782210156432 Test RE 0.030135841273499914\n",
      "169 Train Loss 0.010927677 Test MSE 0.0017129194385371593 Test RE 0.029902282890964568\n",
      "170 Train Loss 0.010751257 Test MSE 0.0016914801881052514 Test RE 0.029714562105715117\n",
      "171 Train Loss 0.010569765 Test MSE 0.0017540897848516586 Test RE 0.030259502718357117\n",
      "172 Train Loss 0.010380687 Test MSE 0.001869181175085131 Test RE 0.031236443195258878\n",
      "173 Train Loss 0.010228919 Test MSE 0.0018714770157795475 Test RE 0.03125562054710559\n",
      "174 Train Loss 0.010065429 Test MSE 0.0019136207322297556 Test RE 0.03160558335373399\n",
      "175 Train Loss 0.009947025 Test MSE 0.001915826530122588 Test RE 0.03162379371527153\n",
      "176 Train Loss 0.009793454 Test MSE 0.0018188405645395754 Test RE 0.0308129438565128\n",
      "177 Train Loss 0.009649222 Test MSE 0.001739716140130978 Test RE 0.030135269048225957\n",
      "178 Train Loss 0.009541154 Test MSE 0.0016339512281924981 Test RE 0.0292048796876798\n",
      "179 Train Loss 0.009437573 Test MSE 0.0015340509576160844 Test RE 0.028298001804766052\n",
      "180 Train Loss 0.009268968 Test MSE 0.0014720868524483028 Test RE 0.027720597938881934\n",
      "181 Train Loss 0.009128227 Test MSE 0.001487248193517022 Test RE 0.027862982484298544\n",
      "182 Train Loss 0.00901691 Test MSE 0.0014603500055577628 Test RE 0.027609869582584066\n",
      "183 Train Loss 0.008899826 Test MSE 0.0013702672281704121 Test RE 0.026744748141310656\n",
      "184 Train Loss 0.008793981 Test MSE 0.001294034533360759 Test RE 0.025990151439430346\n",
      "185 Train Loss 0.008698976 Test MSE 0.0012375611884725831 Test RE 0.025416703187309698\n",
      "186 Train Loss 0.008632377 Test MSE 0.0012240187865077171 Test RE 0.025277255522044205\n",
      "187 Train Loss 0.008550474 Test MSE 0.0011930060015498312 Test RE 0.024954977987459496\n",
      "188 Train Loss 0.008473887 Test MSE 0.0011527522206963483 Test RE 0.02453035654515031\n",
      "189 Train Loss 0.008414927 Test MSE 0.0011502833004618917 Test RE 0.024504073378891083\n",
      "190 Train Loss 0.008337845 Test MSE 0.0011801780250288109 Test RE 0.02482044929740891\n",
      "191 Train Loss 0.008240989 Test MSE 0.0011680201392090372 Test RE 0.024692271435600238\n",
      "192 Train Loss 0.008159183 Test MSE 0.001142216659357399 Test RE 0.02441800183008997\n",
      "193 Train Loss 0.00806934 Test MSE 0.001160326716044354 Test RE 0.024610816528332195\n",
      "194 Train Loss 0.007992598 Test MSE 0.0011488737413560422 Test RE 0.02448905511010412\n",
      "195 Train Loss 0.007941868 Test MSE 0.0011524429029915895 Test RE 0.02452706521223628\n",
      "196 Train Loss 0.007896847 Test MSE 0.0011694151740725546 Test RE 0.02470701274831476\n",
      "197 Train Loss 0.0078516435 Test MSE 0.0011650262116649217 Test RE 0.024660604898710612\n",
      "198 Train Loss 0.007809878 Test MSE 0.0011623256688796906 Test RE 0.02463200654791379\n",
      "199 Train Loss 0.0077526947 Test MSE 0.001191020575599083 Test RE 0.024934204038297287\n",
      "200 Train Loss 0.0077091884 Test MSE 0.0011608715185953324 Test RE 0.024616593548699765\n",
      "201 Train Loss 0.0076485067 Test MSE 0.001127144485682646 Test RE 0.024256362383028477\n",
      "202 Train Loss 0.0075835916 Test MSE 0.0010831839427838904 Test RE 0.02377863845080479\n",
      "203 Train Loss 0.007523903 Test MSE 0.001054525634194041 Test RE 0.023461968510885046\n",
      "204 Train Loss 0.0074520903 Test MSE 0.001008227153630596 Test RE 0.022941144041814267\n",
      "205 Train Loss 0.007402992 Test MSE 0.0009846002513791672 Test RE 0.02267074792440092\n",
      "206 Train Loss 0.0073633194 Test MSE 0.0009627314807004885 Test RE 0.02241756633268448\n",
      "207 Train Loss 0.0073166657 Test MSE 0.0009756778851023834 Test RE 0.02256779392943645\n",
      "208 Train Loss 0.0072707217 Test MSE 0.000963339435198778 Test RE 0.02242464344069721\n",
      "209 Train Loss 0.007216202 Test MSE 0.0009826317553065836 Test RE 0.022648073947743003\n",
      "210 Train Loss 0.0071584093 Test MSE 0.0010178650424824732 Test RE 0.02305053323499032\n",
      "211 Train Loss 0.0070776464 Test MSE 0.0010150088386471994 Test RE 0.023018169773494388\n",
      "212 Train Loss 0.007000105 Test MSE 0.0010107995805280917 Test RE 0.022970391826329543\n",
      "213 Train Loss 0.006923421 Test MSE 0.0010115084421767537 Test RE 0.022978444845145624\n",
      "214 Train Loss 0.0068298024 Test MSE 0.001005496618976658 Test RE 0.022910057764066714\n",
      "215 Train Loss 0.006748909 Test MSE 0.0010253342419794342 Test RE 0.023134952253762667\n",
      "216 Train Loss 0.0066755423 Test MSE 0.00101308114058622 Test RE 0.022996301407737504\n",
      "217 Train Loss 0.006590412 Test MSE 0.0010403231111357273 Test RE 0.02330343811581207\n",
      "218 Train Loss 0.006537521 Test MSE 0.0010480315477051378 Test RE 0.023389614009116343\n",
      "219 Train Loss 0.006461612 Test MSE 0.0009793799213283381 Test RE 0.022610568133442328\n",
      "220 Train Loss 0.006368783 Test MSE 0.0009622777082846647 Test RE 0.02241228257891317\n",
      "221 Train Loss 0.0062937294 Test MSE 0.0009332433115211094 Test RE 0.02207157474301833\n",
      "222 Train Loss 0.006245608 Test MSE 0.000883823333256753 Test RE 0.021479225048531645\n",
      "223 Train Loss 0.0061912257 Test MSE 0.0008513898517506995 Test RE 0.021081432175716792\n",
      "224 Train Loss 0.0061373026 Test MSE 0.0008369002680523964 Test RE 0.020901272643201223\n",
      "225 Train Loss 0.006060873 Test MSE 0.0008270743492629696 Test RE 0.02077821103283982\n",
      "226 Train Loss 0.0060133794 Test MSE 0.0008282333713270858 Test RE 0.020792764726826243\n",
      "227 Train Loss 0.005943141 Test MSE 0.0008395952098961058 Test RE 0.020934898179818764\n",
      "228 Train Loss 0.0058815675 Test MSE 0.0008500327074207623 Test RE 0.021064623215211135\n",
      "229 Train Loss 0.0058347145 Test MSE 0.0008434038149050114 Test RE 0.02098232730990111\n",
      "230 Train Loss 0.0057827113 Test MSE 0.0008398727490667332 Test RE 0.020938358046028692\n",
      "231 Train Loss 0.005725398 Test MSE 0.0008509232160311899 Test RE 0.02107565415431347\n",
      "232 Train Loss 0.005675603 Test MSE 0.0008576014141036437 Test RE 0.021158195279038918\n",
      "233 Train Loss 0.005651351 Test MSE 0.0008531860745487823 Test RE 0.021103658772363577\n",
      "234 Train Loss 0.005627193 Test MSE 0.0008483800477638811 Test RE 0.02104413600919122\n",
      "235 Train Loss 0.0056027053 Test MSE 0.0008385914963271651 Test RE 0.020922380882859044\n",
      "236 Train Loss 0.0055603804 Test MSE 0.0008367305917251826 Test RE 0.020899153734243343\n",
      "237 Train Loss 0.005497899 Test MSE 0.0008580171605643105 Test RE 0.02116332317343945\n",
      "238 Train Loss 0.005461853 Test MSE 0.0008787152647812369 Test RE 0.02141706537464608\n",
      "239 Train Loss 0.0054272376 Test MSE 0.0008837766999439514 Test RE 0.021478658385152432\n",
      "240 Train Loss 0.005369357 Test MSE 0.0009134722372266781 Test RE 0.021836526306430796\n",
      "241 Train Loss 0.005319109 Test MSE 0.0009173415564806057 Test RE 0.021882725415246274\n",
      "242 Train Loss 0.0052751126 Test MSE 0.0009207121142881117 Test RE 0.021922890043099344\n",
      "243 Train Loss 0.005235435 Test MSE 0.0008973819499017506 Test RE 0.0216433529509168\n",
      "244 Train Loss 0.005202928 Test MSE 0.0008955825424933003 Test RE 0.021621642712466332\n",
      "245 Train Loss 0.005162946 Test MSE 0.0008910964249314494 Test RE 0.021567421576857697\n",
      "246 Train Loss 0.0051221363 Test MSE 0.0008737937761642293 Test RE 0.021357005052321847\n",
      "247 Train Loss 0.0050878096 Test MSE 0.0008654136936808723 Test RE 0.02125434659428773\n",
      "248 Train Loss 0.0050575673 Test MSE 0.0008587006994727532 Test RE 0.021171751370192955\n",
      "249 Train Loss 0.0050307685 Test MSE 0.0008521929714390822 Test RE 0.021091372934545542\n",
      "250 Train Loss 0.0050158817 Test MSE 0.0008580933080770005 Test RE 0.021164262256444053\n",
      "251 Train Loss 0.0050001694 Test MSE 0.0008592608784469322 Test RE 0.021178656009009464\n",
      "252 Train Loss 0.004978013 Test MSE 0.000870093964533535 Test RE 0.021311742246269836\n",
      "253 Train Loss 0.0049528005 Test MSE 0.0008660230953433887 Test RE 0.021261828654518606\n",
      "254 Train Loss 0.0049447767 Test MSE 0.0008639284780842094 Test RE 0.02123610049834489\n",
      "255 Train Loss 0.0049175113 Test MSE 0.000870986175832332 Test RE 0.021322666184385816\n",
      "256 Train Loss 0.0048936927 Test MSE 0.0008664900121171826 Test RE 0.02126755954480871\n",
      "257 Train Loss 0.004862645 Test MSE 0.0008591337937331354 Test RE 0.021177089789116296\n",
      "258 Train Loss 0.0048324536 Test MSE 0.0008516003887940104 Test RE 0.02108403858923792\n",
      "259 Train Loss 0.004787206 Test MSE 0.0008604037819241331 Test RE 0.02119273620090794\n",
      "260 Train Loss 0.0047577596 Test MSE 0.0008779843986485633 Test RE 0.021408156764229753\n",
      "261 Train Loss 0.0047312058 Test MSE 0.0008927524485534371 Test RE 0.02158745284405326\n",
      "262 Train Loss 0.0046949876 Test MSE 0.00092064879705878 Test RE 0.021922136213264512\n",
      "263 Train Loss 0.0046651876 Test MSE 0.0009389760462148492 Test RE 0.0221392616806721\n",
      "264 Train Loss 0.0046282853 Test MSE 0.0009419490618095388 Test RE 0.02217428299574276\n",
      "265 Train Loss 0.004599453 Test MSE 0.0009327191505048165 Test RE 0.022065375564402367\n",
      "266 Train Loss 0.0045542233 Test MSE 0.0009439420278694734 Test RE 0.02219772865981483\n",
      "267 Train Loss 0.0045216605 Test MSE 0.0009262501407247866 Test RE 0.02198872360933091\n",
      "268 Train Loss 0.0044804737 Test MSE 0.0009293402660603492 Test RE 0.022025372097614005\n",
      "269 Train Loss 0.0044457493 Test MSE 0.0009328921282039059 Test RE 0.02206742153984242\n",
      "270 Train Loss 0.0044085076 Test MSE 0.0009281470203760121 Test RE 0.022011227589510397\n",
      "271 Train Loss 0.0043638274 Test MSE 0.0009029469891514267 Test RE 0.02171035895172344\n",
      "272 Train Loss 0.0043356176 Test MSE 0.0008967590700785224 Test RE 0.021635840236834035\n",
      "273 Train Loss 0.004305711 Test MSE 0.0009050624788979074 Test RE 0.02173577637538475\n",
      "274 Train Loss 0.0042840145 Test MSE 0.0009067989597488944 Test RE 0.021756617849646245\n",
      "275 Train Loss 0.0042538615 Test MSE 0.0009114444426754941 Test RE 0.02181227565677577\n",
      "276 Train Loss 0.0042302213 Test MSE 0.0008981179905991583 Test RE 0.02165222716739683\n",
      "277 Train Loss 0.0042072614 Test MSE 0.0008792582782487491 Test RE 0.021423681828954207\n",
      "278 Train Loss 0.004180313 Test MSE 0.0008588230203241086 Test RE 0.021173259261378963\n",
      "279 Train Loss 0.004159147 Test MSE 0.0008470385219351773 Test RE 0.021027491097939558\n",
      "280 Train Loss 0.004143219 Test MSE 0.0008431103573193871 Test RE 0.02097867665127967\n",
      "281 Train Loss 0.0041308855 Test MSE 0.0008386927144842449 Test RE 0.02092364351248584\n",
      "282 Train Loss 0.004107348 Test MSE 0.0008366630605055409 Test RE 0.020898310348192246\n",
      "283 Train Loss 0.0040917373 Test MSE 0.0008344425749606464 Test RE 0.020870560093506903\n",
      "284 Train Loss 0.004075528 Test MSE 0.000832936515894631 Test RE 0.020851717279879813\n",
      "285 Train Loss 0.004048091 Test MSE 0.0008251537211415291 Test RE 0.020754071479071136\n",
      "286 Train Loss 0.0040319455 Test MSE 0.0008144561149105989 Test RE 0.020619100766600937\n",
      "287 Train Loss 0.00399672 Test MSE 0.0008033058597988042 Test RE 0.020477472170455424\n",
      "288 Train Loss 0.003973132 Test MSE 0.0008081772414261594 Test RE 0.02053946773956937\n",
      "289 Train Loss 0.003944878 Test MSE 0.000799196942353321 Test RE 0.02042503379208846\n",
      "290 Train Loss 0.00391544 Test MSE 0.0008077683089532156 Test RE 0.02053427066294666\n",
      "291 Train Loss 0.0038989738 Test MSE 0.0008112302037038448 Test RE 0.020578226014978447\n",
      "292 Train Loss 0.0038829034 Test MSE 0.0008001434509117955 Test RE 0.02043712514759462\n",
      "293 Train Loss 0.0038691538 Test MSE 0.0008005549852479967 Test RE 0.02044238014128089\n",
      "294 Train Loss 0.0038437366 Test MSE 0.000787432373886207 Test RE 0.020274143212019178\n",
      "295 Train Loss 0.003814893 Test MSE 0.000765328273915919 Test RE 0.019987558869607694\n",
      "296 Train Loss 0.0037951244 Test MSE 0.0007532605394598293 Test RE 0.019829350318089623\n",
      "297 Train Loss 0.0037803838 Test MSE 0.000748213603435435 Test RE 0.019762809158753388\n",
      "298 Train Loss 0.003766926 Test MSE 0.0007459704628931969 Test RE 0.019733162521754027\n",
      "299 Train Loss 0.0037497878 Test MSE 0.0007479257815097202 Test RE 0.019759007626077196\n",
      "Training time: 167.66\n",
      "KG_tanh_high\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 46009.41 Test MSE 8.87190349658673 Test RE 2.152009982107863\n",
      "1 Train Loss 35473.992 Test MSE 9.401866916592672 Test RE 2.215352943680366\n",
      "2 Train Loss 30318.053 Test MSE 7.056767675241947 Test RE 1.9192819843641022\n",
      "3 Train Loss 22638.762 Test MSE 4.559059445858003 Test RE 1.542671671080003\n",
      "4 Train Loss 6990.998 Test MSE 5.984271486389206 Test RE 1.7674271449059415\n",
      "5 Train Loss 2359.3604 Test MSE 14.129400048626696 Test RE 2.7157997104518743\n",
      "6 Train Loss 1105.2654 Test MSE 16.67111951304751 Test RE 2.9499744827535936\n",
      "7 Train Loss 587.8429 Test MSE 17.82304941153286 Test RE 3.050189926496238\n",
      "8 Train Loss 339.2033 Test MSE 16.906886248472016 Test RE 2.9707608519092803\n",
      "9 Train Loss 208.21098 Test MSE 17.31561610136116 Test RE 3.006455992846496\n",
      "10 Train Loss 141.27911 Test MSE 17.58039124858689 Test RE 3.0293548260038876\n",
      "11 Train Loss 105.4575 Test MSE 17.2678048863465 Test RE 3.002302468241061\n",
      "12 Train Loss 77.39499 Test MSE 16.267550142944472 Test RE 2.914049696038831\n",
      "13 Train Loss 61.703346 Test MSE 15.925079767509454 Test RE 2.883212718503891\n",
      "14 Train Loss 51.970554 Test MSE 15.666591830003219 Test RE 2.8597175539129447\n",
      "15 Train Loss 43.58647 Test MSE 15.589461407386315 Test RE 2.8526693274186545\n",
      "16 Train Loss 38.80669 Test MSE 15.737758154724649 Test RE 2.866205403779133\n",
      "17 Train Loss 33.812798 Test MSE 15.717553979342213 Test RE 2.86436499188362\n",
      "18 Train Loss 30.852083 Test MSE 15.688501579885422 Test RE 2.8617165147049595\n",
      "19 Train Loss 29.281448 Test MSE 15.56771100296595 Test RE 2.850678611802561\n",
      "20 Train Loss 28.001234 Test MSE 15.62051794785862 Test RE 2.855509385803458\n",
      "21 Train Loss 26.639095 Test MSE 15.63265169994573 Test RE 2.8566182260223005\n",
      "22 Train Loss 25.543367 Test MSE 15.64365856290976 Test RE 2.857623713552495\n",
      "23 Train Loss 24.616665 Test MSE 15.56798231657956 Test RE 2.850703452466211\n",
      "24 Train Loss 23.808935 Test MSE 15.59210115083407 Test RE 2.852910836609423\n",
      "25 Train Loss 23.189255 Test MSE 15.609954880122622 Test RE 2.8545437315222744\n",
      "26 Train Loss 22.701366 Test MSE 15.585388857256715 Test RE 2.852296691142937\n",
      "27 Train Loss 22.037352 Test MSE 15.568973852476434 Test RE 2.850794232688778\n",
      "28 Train Loss 21.594671 Test MSE 15.520056681293186 Test RE 2.8463121614174134\n",
      "29 Train Loss 21.184317 Test MSE 15.530416038162706 Test RE 2.8472619338748317\n",
      "30 Train Loss 20.797232 Test MSE 15.50733553506454 Test RE 2.8451454203215265\n",
      "31 Train Loss 20.581585 Test MSE 15.486152285294343 Test RE 2.8432015008700953\n",
      "32 Train Loss 20.326538 Test MSE 15.482303315180518 Test RE 2.8428481504231042\n",
      "33 Train Loss 20.01184 Test MSE 15.421644208909141 Test RE 2.837273596552949\n",
      "34 Train Loss 19.751837 Test MSE 15.392766328753689 Test RE 2.8346158760651914\n",
      "35 Train Loss 19.59344 Test MSE 15.375055693193026 Test RE 2.832984678118166\n",
      "36 Train Loss 19.395372 Test MSE 15.347197595753254 Test RE 2.8304169688770813\n",
      "37 Train Loss 19.210007 Test MSE 15.303008675478132 Test RE 2.82633924624961\n",
      "38 Train Loss 19.11255 Test MSE 15.285989001654473 Test RE 2.824767112447992\n",
      "39 Train Loss 18.989973 Test MSE 15.25424141677555 Test RE 2.8218321977984746\n",
      "40 Train Loss 18.902706 Test MSE 15.205819971932264 Test RE 2.8173499756913363\n",
      "41 Train Loss 18.710203 Test MSE 15.155165133357544 Test RE 2.8126533706872445\n",
      "42 Train Loss 18.618134 Test MSE 15.098186342158261 Test RE 2.8073610328868135\n",
      "43 Train Loss 18.511705 Test MSE 15.045449254587203 Test RE 2.802453769462604\n",
      "44 Train Loss 18.390072 Test MSE 15.040110346625985 Test RE 2.801956497162826\n",
      "45 Train Loss 18.216162 Test MSE 14.903756370358304 Test RE 2.7892262782694637\n",
      "46 Train Loss 18.07975 Test MSE 14.855976124101344 Test RE 2.7847516713363785\n",
      "47 Train Loss 17.914852 Test MSE 14.765977422548577 Test RE 2.7763037322126056\n",
      "48 Train Loss 17.759235 Test MSE 14.749166781923487 Test RE 2.7747229111784306\n",
      "49 Train Loss 17.657192 Test MSE 14.72943052385477 Test RE 2.7728658239149375\n",
      "50 Train Loss 17.517632 Test MSE 14.638038682481431 Test RE 2.76425002466159\n",
      "51 Train Loss 17.377773 Test MSE 14.505426142738104 Test RE 2.7517002477973636\n",
      "52 Train Loss 17.209614 Test MSE 14.298854612972498 Test RE 2.7320365306185406\n",
      "53 Train Loss 17.10041 Test MSE 14.202094909475463 Test RE 2.722777055497162\n",
      "54 Train Loss 16.892262 Test MSE 13.869527702980106 Test RE 2.6907088865529762\n",
      "55 Train Loss 16.454977 Test MSE 13.515868909244782 Test RE 2.656182201988507\n",
      "56 Train Loss 16.051525 Test MSE 13.012962404780113 Test RE 2.606297361923347\n",
      "57 Train Loss 15.468711 Test MSE 12.390069316257632 Test RE 2.543154499851051\n",
      "58 Train Loss 14.531204 Test MSE 11.918260352932098 Test RE 2.494263382633618\n",
      "59 Train Loss 14.051894 Test MSE 11.61869486688839 Test RE 2.462717236685987\n",
      "60 Train Loss 13.441936 Test MSE 10.995699859394337 Test RE 2.3957820972195973\n",
      "61 Train Loss 12.942082 Test MSE 10.902773819250907 Test RE 2.3856370898985424\n",
      "62 Train Loss 12.283037 Test MSE 10.661234392749652 Test RE 2.359063454199469\n",
      "63 Train Loss 11.950426 Test MSE 10.507763105506314 Test RE 2.342022232659696\n",
      "64 Train Loss 11.56706 Test MSE 10.350895839288265 Test RE 2.3244748201421364\n",
      "65 Train Loss 11.2108755 Test MSE 10.073540592969882 Test RE 2.2931208720704874\n",
      "66 Train Loss 10.867637 Test MSE 9.8880197070526 Test RE 2.271906941881081\n",
      "67 Train Loss 10.65389 Test MSE 9.801187385568888 Test RE 2.2619094920466343\n",
      "68 Train Loss 10.497373 Test MSE 9.731253873229152 Test RE 2.253825448350523\n",
      "69 Train Loss 10.316481 Test MSE 9.67062093157651 Test RE 2.2467929733144505\n",
      "70 Train Loss 10.1678095 Test MSE 9.611613999896727 Test RE 2.239927891225138\n",
      "71 Train Loss 10.035487 Test MSE 9.537346786653448 Test RE 2.231257349774605\n",
      "72 Train Loss 9.867886 Test MSE 9.53625832701981 Test RE 2.2311300238574314\n",
      "73 Train Loss 9.692736 Test MSE 9.513190404123215 Test RE 2.2284298716643756\n",
      "74 Train Loss 9.513148 Test MSE 9.511290137575036 Test RE 2.22820729532311\n",
      "75 Train Loss 9.427026 Test MSE 9.51262921292046 Test RE 2.2283641422071443\n",
      "76 Train Loss 9.302663 Test MSE 9.53793152111419 Test RE 2.2313257478886364\n",
      "77 Train Loss 9.223467 Test MSE 9.4745423733524 Test RE 2.2238986853633707\n",
      "78 Train Loss 9.086845 Test MSE 9.369955485676568 Test RE 2.2115901180281883\n",
      "79 Train Loss 8.980096 Test MSE 9.276846659146234 Test RE 2.2005744483504373\n",
      "80 Train Loss 8.87092 Test MSE 9.238207053219707 Test RE 2.1959867873803414\n",
      "81 Train Loss 8.640544 Test MSE 9.192984979913161 Test RE 2.1906053912325003\n",
      "82 Train Loss 8.563725 Test MSE 9.140501300465997 Test RE 2.184343246956022\n",
      "83 Train Loss 8.3868065 Test MSE 9.044841138496421 Test RE 2.172883032323725\n",
      "84 Train Loss 8.219034 Test MSE 9.003753647520051 Test RE 2.1679420979584356\n",
      "85 Train Loss 8.098777 Test MSE 8.86336739194872 Test RE 2.1509744544363616\n",
      "86 Train Loss 7.9833736 Test MSE 8.77524671632062 Test RE 2.1402551199520037\n",
      "87 Train Loss 7.8429184 Test MSE 8.787475480605176 Test RE 2.141745879375474\n",
      "88 Train Loss 7.7468343 Test MSE 8.784324727963241 Test RE 2.1413618830561885\n",
      "89 Train Loss 7.635404 Test MSE 8.661488462570583 Test RE 2.1263372260770295\n",
      "90 Train Loss 7.534671 Test MSE 8.577209095622706 Test RE 2.115966928557712\n",
      "91 Train Loss 7.4171286 Test MSE 8.536739300886374 Test RE 2.1109691492430596\n",
      "92 Train Loss 7.3414636 Test MSE 8.472115775748016 Test RE 2.102963901682528\n",
      "93 Train Loss 7.295809 Test MSE 8.47402814156573 Test RE 2.103201233741476\n",
      "94 Train Loss 7.2123404 Test MSE 8.3567110571602 Test RE 2.088591806739509\n",
      "95 Train Loss 7.121039 Test MSE 8.283272374564847 Test RE 2.079394294610363\n",
      "96 Train Loss 6.9951034 Test MSE 8.189414417470873 Test RE 2.067579898758586\n",
      "97 Train Loss 6.8577833 Test MSE 8.063764140423052 Test RE 2.051657136129486\n",
      "98 Train Loss 6.7044663 Test MSE 7.897430118393217 Test RE 2.030386759873015\n",
      "99 Train Loss 6.523167 Test MSE 7.591147960298382 Test RE 1.990625692510419\n",
      "100 Train Loss 6.376768 Test MSE 7.351867786906577 Test RE 1.9590012857173402\n",
      "101 Train Loss 6.1666923 Test MSE 6.907342123220995 Test RE 1.898853067697908\n",
      "102 Train Loss 6.0081067 Test MSE 6.685123794710625 Test RE 1.8680590652182192\n",
      "103 Train Loss 5.7871346 Test MSE 6.449140723891002 Test RE 1.8347918556073495\n",
      "104 Train Loss 5.57833 Test MSE 6.5290199387975045 Test RE 1.8461197750073937\n",
      "105 Train Loss 5.353144 Test MSE 6.351523456517098 Test RE 1.8208527653486133\n",
      "106 Train Loss 5.1274314 Test MSE 6.11406353155769 Test RE 1.7864910733769537\n",
      "107 Train Loss 4.839223 Test MSE 5.761162293647815 Test RE 1.7341670561167621\n",
      "108 Train Loss 4.6244054 Test MSE 5.365671821769551 Test RE 1.6735855991332977\n",
      "109 Train Loss 4.4337134 Test MSE 5.183278106470507 Test RE 1.6448948185317356\n",
      "110 Train Loss 4.1506076 Test MSE 4.774870703643092 Test RE 1.578762073829897\n",
      "111 Train Loss 3.846123 Test MSE 4.295312445495515 Test RE 1.4973842372786799\n",
      "112 Train Loss 3.6177657 Test MSE 3.8470405288356564 Test RE 1.4170959528661387\n",
      "113 Train Loss 3.418596 Test MSE 3.5579086750398585 Test RE 1.362803609208647\n",
      "114 Train Loss 3.249763 Test MSE 3.3494738164126767 Test RE 1.322282257201991\n",
      "115 Train Loss 3.0116966 Test MSE 3.1108525247640646 Test RE 1.2743114590755655\n",
      "116 Train Loss 2.8680322 Test MSE 2.90965639058579 Test RE 1.2324143013675568\n",
      "117 Train Loss 2.6390917 Test MSE 2.3962780861002844 Test RE 1.1184188676293694\n",
      "118 Train Loss 2.3826141 Test MSE 2.0464904521096905 Test RE 1.0335720065197693\n",
      "119 Train Loss 2.2228081 Test MSE 1.8142425515418847 Test RE 0.9731584348949756\n",
      "120 Train Loss 2.0463033 Test MSE 1.634268209523623 Test RE 0.9236289635471833\n",
      "121 Train Loss 1.854704 Test MSE 1.4224759525501067 Test RE 0.8617044654393275\n",
      "122 Train Loss 1.7061574 Test MSE 1.3198291669742022 Test RE 0.8300318122638237\n",
      "123 Train Loss 1.5894539 Test MSE 1.208623540300372 Test RE 0.7942942181972122\n",
      "124 Train Loss 1.4949237 Test MSE 1.128629075164043 Test RE 0.7675585150319129\n",
      "125 Train Loss 1.3623297 Test MSE 0.9216572213667181 Test RE 0.6936183786187584\n",
      "126 Train Loss 1.2159204 Test MSE 0.7418823314921069 Test RE 0.6223051440993874\n",
      "127 Train Loss 1.1126208 Test MSE 0.46339494678040705 Test RE 0.4918260453450023\n",
      "128 Train Loss 1.0547036 Test MSE 0.31910878835629364 Test RE 0.40813633416406636\n",
      "129 Train Loss 0.9844289 Test MSE 0.3181330093003009 Test RE 0.4075118515217492\n",
      "130 Train Loss 0.8949169 Test MSE 0.24303760000572516 Test RE 0.35618252705840864\n",
      "131 Train Loss 0.8419908 Test MSE 0.20911042304853206 Test RE 0.3303875833086045\n",
      "132 Train Loss 0.80147886 Test MSE 0.19333695633376163 Test RE 0.3176825174066395\n",
      "133 Train Loss 0.7531114 Test MSE 0.19268660775569002 Test RE 0.3171477556760304\n",
      "134 Train Loss 0.70822865 Test MSE 0.17128583310429155 Test RE 0.29901749512150777\n",
      "135 Train Loss 0.66669357 Test MSE 0.1679335209449415 Test RE 0.2960769332483524\n",
      "136 Train Loss 0.63800013 Test MSE 0.1436007719239016 Test RE 0.27378790848266527\n",
      "137 Train Loss 0.59536195 Test MSE 0.13860997343009043 Test RE 0.26898813080591233\n",
      "138 Train Loss 0.56306165 Test MSE 0.13536913961579783 Test RE 0.2658249318464723\n",
      "139 Train Loss 0.53350806 Test MSE 0.11360899701596482 Test RE 0.2435242641714144\n",
      "140 Train Loss 0.49890527 Test MSE 0.11226024575397983 Test RE 0.24207440396246396\n",
      "141 Train Loss 0.46745706 Test MSE 0.099907472019208 Test RE 0.22836779675180713\n",
      "142 Train Loss 0.4347599 Test MSE 0.10483303998273368 Test RE 0.2339294861176181\n",
      "143 Train Loss 0.42182368 Test MSE 0.11409542571724698 Test RE 0.24404504451757872\n",
      "144 Train Loss 0.39665756 Test MSE 0.10624369875761765 Test RE 0.23549813263910072\n",
      "145 Train Loss 0.36573854 Test MSE 0.09437547961799701 Test RE 0.22195527081629826\n",
      "146 Train Loss 0.34585178 Test MSE 0.09276227944158541 Test RE 0.22005010639804481\n",
      "147 Train Loss 0.33387128 Test MSE 0.0883666283422693 Test RE 0.2147731660231286\n",
      "148 Train Loss 0.32313564 Test MSE 0.09115626563548594 Test RE 0.21813690129034163\n",
      "149 Train Loss 0.30641347 Test MSE 0.09498190745694202 Test RE 0.2226672371202356\n",
      "150 Train Loss 0.28915673 Test MSE 0.09015992898389318 Test RE 0.2169415093396022\n",
      "151 Train Loss 0.27633438 Test MSE 0.08408253476011762 Test RE 0.2095022900902982\n",
      "152 Train Loss 0.25985256 Test MSE 0.08540836721570509 Test RE 0.2111475694582602\n",
      "153 Train Loss 0.2329652 Test MSE 0.07041873144647136 Test RE 0.19172554258997215\n",
      "154 Train Loss 0.22397497 Test MSE 0.06861383410602326 Test RE 0.18925254174317543\n",
      "155 Train Loss 0.21648444 Test MSE 0.06696746093129638 Test RE 0.18696821998381072\n",
      "156 Train Loss 0.2026887 Test MSE 0.058720142443139334 Test RE 0.17507713338472805\n",
      "157 Train Loss 0.19165322 Test MSE 0.056279458921727504 Test RE 0.171400006320751\n",
      "158 Train Loss 0.1847523 Test MSE 0.05249746306632268 Test RE 0.16554079450226725\n",
      "159 Train Loss 0.17690134 Test MSE 0.04638990823347 Test RE 0.15561362999331202\n",
      "160 Train Loss 0.16773835 Test MSE 0.048802326231553395 Test RE 0.1596085450766482\n",
      "161 Train Loss 0.16398272 Test MSE 0.04367878559039708 Test RE 0.1509979858943629\n",
      "162 Train Loss 0.16096772 Test MSE 0.04538600248931683 Test RE 0.15392063387340926\n",
      "163 Train Loss 0.15547377 Test MSE 0.042017998130985335 Test RE 0.14809948748574642\n",
      "164 Train Loss 0.14859247 Test MSE 0.037922430753729704 Test RE 0.1406967159012775\n",
      "165 Train Loss 0.14309283 Test MSE 0.03569912237551624 Test RE 0.13651005658738904\n",
      "166 Train Loss 0.13774282 Test MSE 0.034654049450437915 Test RE 0.13449708514111317\n",
      "167 Train Loss 0.13447966 Test MSE 0.03143736803440994 Test RE 0.12810290151430362\n",
      "168 Train Loss 0.12960815 Test MSE 0.029219217285558107 Test RE 0.12350091234785034\n",
      "169 Train Loss 0.12561625 Test MSE 0.031433316815270576 Test RE 0.12809464717115265\n",
      "170 Train Loss 0.12214932 Test MSE 0.030909338127980322 Test RE 0.12702252151250837\n",
      "171 Train Loss 0.11778814 Test MSE 0.028057437329741204 Test RE 0.12102076048023386\n",
      "172 Train Loss 0.11517209 Test MSE 0.024474652317546447 Test RE 0.11303010795601534\n",
      "173 Train Loss 0.11147219 Test MSE 0.02171868078136705 Test RE 0.10647621339708045\n",
      "174 Train Loss 0.108517036 Test MSE 0.021602962017264405 Test RE 0.10619217791602806\n",
      "175 Train Loss 0.10391185 Test MSE 0.02316184979598219 Test RE 0.10995690253297538\n",
      "176 Train Loss 0.10084647 Test MSE 0.02143374683081201 Test RE 0.10577546061741293\n",
      "177 Train Loss 0.09848433 Test MSE 0.023567988582249694 Test RE 0.11091675018526398\n",
      "178 Train Loss 0.09393619 Test MSE 0.022166180011172168 Test RE 0.10756755686591501\n",
      "179 Train Loss 0.08982003 Test MSE 0.019997409080237297 Test RE 0.10216984684171429\n",
      "180 Train Loss 0.08797912 Test MSE 0.020162927623765856 Test RE 0.10259180538531874\n",
      "181 Train Loss 0.08579661 Test MSE 0.020076224506344217 Test RE 0.10237098893034578\n",
      "182 Train Loss 0.08359977 Test MSE 0.019000357386592562 Test RE 0.09959023607073994\n",
      "183 Train Loss 0.08041667 Test MSE 0.018975897928775073 Test RE 0.09952611339177794\n",
      "184 Train Loss 0.07803801 Test MSE 0.01804969353413334 Test RE 0.09706681801949424\n",
      "185 Train Loss 0.07690566 Test MSE 0.018760979990751225 Test RE 0.09896090015819631\n",
      "186 Train Loss 0.07517536 Test MSE 0.01728731322725452 Test RE 0.0949947550872619\n",
      "187 Train Loss 0.07234986 Test MSE 0.014521296657543361 Test RE 0.08706399190432225\n",
      "188 Train Loss 0.06987599 Test MSE 0.013063737094616869 Test RE 0.08257899492726475\n",
      "189 Train Loss 0.06638231 Test MSE 0.01395849083593885 Test RE 0.08536013824570185\n",
      "190 Train Loss 0.06514249 Test MSE 0.013599324384273439 Test RE 0.08425477893621854\n",
      "191 Train Loss 0.06407164 Test MSE 0.011743547826151985 Test RE 0.07829527201758574\n",
      "192 Train Loss 0.063249655 Test MSE 0.012018877153580215 Test RE 0.07920777703704891\n",
      "193 Train Loss 0.062456295 Test MSE 0.011720946885414883 Test RE 0.07821989449791589\n",
      "194 Train Loss 0.061581798 Test MSE 0.012254585264761102 Test RE 0.079980697243441\n",
      "195 Train Loss 0.05988915 Test MSE 0.012759771911011153 Test RE 0.08161262231039253\n",
      "196 Train Loss 0.058991045 Test MSE 0.012720536673177706 Test RE 0.08148704969039014\n",
      "197 Train Loss 0.05793043 Test MSE 0.013167901312638272 Test RE 0.08290756468262206\n",
      "198 Train Loss 0.05693329 Test MSE 0.013220650583912077 Test RE 0.08307345833965547\n",
      "199 Train Loss 0.05621048 Test MSE 0.013941512994253214 Test RE 0.08530821028741152\n",
      "200 Train Loss 0.055089414 Test MSE 0.013141109488192838 Test RE 0.08282317857317632\n",
      "201 Train Loss 0.05337375 Test MSE 0.012531115486649265 Test RE 0.08087806329965852\n",
      "202 Train Loss 0.051532503 Test MSE 0.012813587114703682 Test RE 0.0817845446133386\n",
      "203 Train Loss 0.049083885 Test MSE 0.01222823202372893 Test RE 0.07989465251260029\n",
      "204 Train Loss 0.04776604 Test MSE 0.011326476591440936 Test RE 0.07689237809282887\n",
      "205 Train Loss 0.046869613 Test MSE 0.011030750977944669 Test RE 0.07588193852252641\n",
      "206 Train Loss 0.045984443 Test MSE 0.010924984160845122 Test RE 0.07551727058363819\n",
      "207 Train Loss 0.044632584 Test MSE 0.010836091722440391 Test RE 0.07520941543394503\n",
      "208 Train Loss 0.043287244 Test MSE 0.012692245657986444 Test RE 0.08139638391711285\n",
      "209 Train Loss 0.042211093 Test MSE 0.012776561071892924 Test RE 0.08166629713412758\n",
      "210 Train Loss 0.041332185 Test MSE 0.012360417071246481 Test RE 0.08032531539706605\n",
      "211 Train Loss 0.04044811 Test MSE 0.011730911357117837 Test RE 0.07825313645135548\n",
      "212 Train Loss 0.039610874 Test MSE 0.011351005585875332 Test RE 0.07697559340948135\n",
      "213 Train Loss 0.03891794 Test MSE 0.011141708630252559 Test RE 0.07626262948032347\n",
      "214 Train Loss 0.03806729 Test MSE 0.011253733481106306 Test RE 0.0766450637406942\n",
      "215 Train Loss 0.0371719 Test MSE 0.010187561972687095 Test RE 0.07292408837658215\n",
      "216 Train Loss 0.035949655 Test MSE 0.01006677290937515 Test RE 0.07249048622346548\n",
      "217 Train Loss 0.03509636 Test MSE 0.009434385951571849 Test RE 0.07017666029543568\n",
      "218 Train Loss 0.03450751 Test MSE 0.009092345981533658 Test RE 0.06889280275648381\n",
      "219 Train Loss 0.034054015 Test MSE 0.00842871114342005 Test RE 0.0663309873924005\n",
      "220 Train Loss 0.03384383 Test MSE 0.00808670330767635 Test RE 0.0649713112382968\n",
      "221 Train Loss 0.03361906 Test MSE 0.007726272943191297 Test RE 0.0635068979867334\n",
      "222 Train Loss 0.033250734 Test MSE 0.007377262338991876 Test RE 0.062055958874297226\n",
      "223 Train Loss 0.032735165 Test MSE 0.006868649065488159 Test RE 0.05987858664329602\n",
      "224 Train Loss 0.03224579 Test MSE 0.006625915157480545 Test RE 0.058811033603368805\n",
      "225 Train Loss 0.031936854 Test MSE 0.006385063454520909 Test RE 0.05773225028057681\n",
      "226 Train Loss 0.03162233 Test MSE 0.006287641448331746 Test RE 0.05729012383269719\n",
      "227 Train Loss 0.030956188 Test MSE 0.006096334118104975 Test RE 0.05641183895938081\n",
      "228 Train Loss 0.030370316 Test MSE 0.006285629001354285 Test RE 0.05728095484904267\n",
      "229 Train Loss 0.029848462 Test MSE 0.00623436864781262 Test RE 0.057046908827782634\n",
      "230 Train Loss 0.029423822 Test MSE 0.006222178206508143 Test RE 0.05699110788638432\n",
      "231 Train Loss 0.028808985 Test MSE 0.005699681148417539 Test RE 0.05454578011432902\n",
      "232 Train Loss 0.028478801 Test MSE 0.005861298828772981 Test RE 0.055313712589191016\n",
      "233 Train Loss 0.027901152 Test MSE 0.005376760488005998 Test RE 0.05297808092100263\n",
      "234 Train Loss 0.02716332 Test MSE 0.004550746846910478 Test RE 0.04873906744701972\n",
      "235 Train Loss 0.026924882 Test MSE 0.004540137519170923 Test RE 0.048682220682454494\n",
      "236 Train Loss 0.02662973 Test MSE 0.004295734373967098 Test RE 0.047353772831181466\n",
      "237 Train Loss 0.026360212 Test MSE 0.004176952226817205 Test RE 0.04669448941748664\n",
      "238 Train Loss 0.026045239 Test MSE 0.004215845397898729 Test RE 0.04691138066328554\n",
      "239 Train Loss 0.025848461 Test MSE 0.004191134839744479 Test RE 0.046773696531594716\n",
      "240 Train Loss 0.025496053 Test MSE 0.004055425417204499 Test RE 0.04601019631169308\n",
      "241 Train Loss 0.025001047 Test MSE 0.00382234800209131 Test RE 0.04466846094893693\n",
      "242 Train Loss 0.024629956 Test MSE 0.0038812272717165244 Test RE 0.045011181619784096\n",
      "243 Train Loss 0.02416125 Test MSE 0.003667500043957123 Test RE 0.043754320205035606\n",
      "244 Train Loss 0.023681413 Test MSE 0.0032696713016840836 Test RE 0.041313113354588524\n",
      "245 Train Loss 0.02333676 Test MSE 0.0030777033835773107 Test RE 0.0400819883887506\n",
      "246 Train Loss 0.023067284 Test MSE 0.0030664430544606446 Test RE 0.040008597631864644\n",
      "247 Train Loss 0.022762971 Test MSE 0.0026895618731933094 Test RE 0.037469392058718215\n",
      "248 Train Loss 0.022407254 Test MSE 0.0025416934174422217 Test RE 0.036424823747615666\n",
      "249 Train Loss 0.022108406 Test MSE 0.0024791232436045044 Test RE 0.0359736856637544\n",
      "250 Train Loss 0.02181763 Test MSE 0.0022581499428701076 Test RE 0.03433304042818859\n",
      "251 Train Loss 0.021445792 Test MSE 0.0020650730158431807 Test RE 0.03283247201882465\n",
      "252 Train Loss 0.021298692 Test MSE 0.0020201649382093835 Test RE 0.03247351435905879\n",
      "253 Train Loss 0.021027569 Test MSE 0.0021318414248680355 Test RE 0.03335902319847517\n",
      "254 Train Loss 0.02066084 Test MSE 0.0020928277334882643 Test RE 0.03305237091652614\n",
      "255 Train Loss 0.020471247 Test MSE 0.002218322681911031 Test RE 0.03402892556263489\n",
      "256 Train Loss 0.020149915 Test MSE 0.0023119788470020958 Test RE 0.03473983929044604\n",
      "257 Train Loss 0.019951371 Test MSE 0.0023324869882969017 Test RE 0.034893576980778405\n",
      "258 Train Loss 0.019697124 Test MSE 0.002296797932842949 Test RE 0.034625597091056885\n",
      "259 Train Loss 0.01955635 Test MSE 0.0022994551270860645 Test RE 0.03464562069442394\n",
      "260 Train Loss 0.019465324 Test MSE 0.0024905024137383508 Test RE 0.036056150711795805\n",
      "261 Train Loss 0.019270351 Test MSE 0.0024224055514175634 Test RE 0.03555979948825051\n",
      "262 Train Loss 0.019063953 Test MSE 0.002383699393058087 Test RE 0.035274561184949316\n",
      "263 Train Loss 0.018819943 Test MSE 0.0022763079211962156 Test RE 0.034470801514154936\n",
      "264 Train Loss 0.01836071 Test MSE 0.0021867585821637938 Test RE 0.0337859625795439\n",
      "265 Train Loss 0.018029794 Test MSE 0.001973290930486906 Test RE 0.03209456079037776\n",
      "266 Train Loss 0.017796457 Test MSE 0.0017777104307180372 Test RE 0.030462559272250927\n",
      "267 Train Loss 0.017589629 Test MSE 0.0018373156486239763 Test RE 0.030969041489393955\n",
      "268 Train Loss 0.017425545 Test MSE 0.0017827074646641421 Test RE 0.03050534341140461\n",
      "269 Train Loss 0.017274138 Test MSE 0.0018070427250273314 Test RE 0.030712847786269204\n",
      "270 Train Loss 0.017007643 Test MSE 0.002009951723080757 Test RE 0.03239132323904775\n",
      "271 Train Loss 0.016834268 Test MSE 0.002089036150704309 Test RE 0.03302241679965589\n",
      "272 Train Loss 0.016498499 Test MSE 0.0021048356214461218 Test RE 0.03314705656268874\n",
      "273 Train Loss 0.016252214 Test MSE 0.002063803818201543 Test RE 0.03282238101950982\n",
      "274 Train Loss 0.016016204 Test MSE 0.0019680813843290863 Test RE 0.03205216749926478\n",
      "275 Train Loss 0.01579926 Test MSE 0.0020945226415171937 Test RE 0.03306575218776704\n",
      "276 Train Loss 0.015611061 Test MSE 0.002095956747159162 Test RE 0.033077070200426446\n",
      "277 Train Loss 0.015476128 Test MSE 0.0021008984630448884 Test RE 0.03311604076826792\n",
      "278 Train Loss 0.015313156 Test MSE 0.002078362527227032 Test RE 0.0329379471702246\n",
      "279 Train Loss 0.014992873 Test MSE 0.0019390740989046057 Test RE 0.03181508439090287\n",
      "280 Train Loss 0.014859861 Test MSE 0.0018265268013250779 Test RE 0.03087798141495011\n",
      "281 Train Loss 0.014652913 Test MSE 0.0017043406925917259 Test RE 0.029827309697835817\n",
      "282 Train Loss 0.01443324 Test MSE 0.0016850188186891281 Test RE 0.02965775373465205\n",
      "283 Train Loss 0.0142419925 Test MSE 0.0016248891587803194 Test RE 0.029123780381587288\n",
      "284 Train Loss 0.014050415 Test MSE 0.001671090994676196 Test RE 0.029534928669486503\n",
      "285 Train Loss 0.013848234 Test MSE 0.0015945419341893657 Test RE 0.028850533562742534\n",
      "286 Train Loss 0.0137465205 Test MSE 0.0016117628185456248 Test RE 0.029005906542952497\n",
      "287 Train Loss 0.0136157805 Test MSE 0.0017047397618138926 Test RE 0.029830801506907857\n",
      "288 Train Loss 0.013515995 Test MSE 0.0017869844489211374 Test RE 0.03054191495076604\n",
      "289 Train Loss 0.013314941 Test MSE 0.0019040874799712186 Test RE 0.03152675890602674\n",
      "290 Train Loss 0.013226358 Test MSE 0.0018958046610291737 Test RE 0.03145811315350517\n",
      "291 Train Loss 0.0131002525 Test MSE 0.0019708855927847014 Test RE 0.032074994036329255\n",
      "292 Train Loss 0.012905001 Test MSE 0.0019046096190810228 Test RE 0.031531081245638075\n",
      "293 Train Loss 0.012683764 Test MSE 0.0018347174229833363 Test RE 0.030947136427806377\n",
      "294 Train Loss 0.012539835 Test MSE 0.001768542501180026 Test RE 0.030383907655429133\n",
      "295 Train Loss 0.012412184 Test MSE 0.0018550254928056743 Test RE 0.03111793849308368\n",
      "296 Train Loss 0.012298805 Test MSE 0.001808672083528099 Test RE 0.03072669111260587\n",
      "297 Train Loss 0.012166778 Test MSE 0.0017240826041600963 Test RE 0.029999561852283186\n",
      "298 Train Loss 0.012026581 Test MSE 0.0015770871390677697 Test RE 0.02869219157820135\n",
      "299 Train Loss 0.011872444 Test MSE 0.0014562206993485125 Test RE 0.027570806921781262\n",
      "Training time: 165.41\n",
      "KG_tanh_high\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 50935.453 Test MSE 9.145020917746459 Test RE 2.1848832159951925\n",
      "1 Train Loss 35614.195 Test MSE 9.30045962618409 Test RE 2.203373301786589\n",
      "2 Train Loss 14186.732 Test MSE 14.957044695313796 Test RE 2.794208263019863\n",
      "3 Train Loss 4210.745 Test MSE 15.67021335678326 Test RE 2.8600480643831085\n",
      "4 Train Loss 1652.0557 Test MSE 16.74206037305121 Test RE 2.9562443546619384\n",
      "5 Train Loss 898.2688 Test MSE 20.199729639118676 Test RE 3.247197135925202\n",
      "6 Train Loss 630.2263 Test MSE 20.659818957984832 Test RE 3.2839696337968265\n",
      "7 Train Loss 430.50537 Test MSE 21.23486207051751 Test RE 3.3293587858553297\n",
      "8 Train Loss 297.29633 Test MSE 21.505786610704753 Test RE 3.3505302479209624\n",
      "9 Train Loss 222.51733 Test MSE 21.52912141397717 Test RE 3.3523474975936893\n",
      "10 Train Loss 159.78572 Test MSE 20.727278816186544 Test RE 3.2893267856962773\n",
      "11 Train Loss 129.10368 Test MSE 20.2543837056654 Test RE 3.251587111621684\n",
      "12 Train Loss 106.039825 Test MSE 19.67309296007338 Test RE 3.2045879768485483\n",
      "13 Train Loss 87.33503 Test MSE 19.538649824810904 Test RE 3.193619354687667\n",
      "14 Train Loss 73.11416 Test MSE 19.474419108008615 Test RE 3.188365733710842\n",
      "15 Train Loss 65.10638 Test MSE 19.540714471241625 Test RE 3.1937880848886113\n",
      "16 Train Loss 58.109676 Test MSE 19.322308926924734 Test RE 3.1758895303041865\n",
      "17 Train Loss 51.325077 Test MSE 18.80058313204614 Test RE 3.132719690526931\n",
      "18 Train Loss 46.58162 Test MSE 18.67422107384966 Test RE 3.1221741583495874\n",
      "19 Train Loss 42.187386 Test MSE 18.570237701874362 Test RE 3.1134694471871662\n",
      "20 Train Loss 39.44392 Test MSE 18.4403491805736 Test RE 3.10256184389235\n",
      "21 Train Loss 37.404736 Test MSE 18.270151923123446 Test RE 3.088210933682472\n",
      "22 Train Loss 35.477856 Test MSE 18.13014816939403 Test RE 3.0763557338171847\n",
      "23 Train Loss 33.37968 Test MSE 18.093579195196607 Test RE 3.0732516235221654\n",
      "24 Train Loss 32.042355 Test MSE 18.14361292518859 Test RE 3.077497883631656\n",
      "25 Train Loss 30.673935 Test MSE 18.0652485577255 Test RE 3.070844656789055\n",
      "26 Train Loss 29.305685 Test MSE 17.84546484838227 Test RE 3.0521073833391767\n",
      "27 Train Loss 28.11635 Test MSE 17.79651286038379 Test RE 3.0479183827826977\n",
      "28 Train Loss 27.193016 Test MSE 17.664681429567494 Test RE 3.0366083486392164\n",
      "29 Train Loss 26.454294 Test MSE 17.56040310470338 Test RE 3.027632213574827\n",
      "30 Train Loss 25.621073 Test MSE 17.568530307131148 Test RE 3.0283327479921365\n",
      "31 Train Loss 24.988014 Test MSE 17.524276728035897 Test RE 3.024516291532214\n",
      "32 Train Loss 24.526705 Test MSE 17.545813895842933 Test RE 3.0263742715859965\n",
      "33 Train Loss 23.98552 Test MSE 17.44030758483574 Test RE 3.0172614700677616\n",
      "34 Train Loss 23.442001 Test MSE 17.35712497420759 Test RE 3.010057363398945\n",
      "35 Train Loss 23.135876 Test MSE 17.35596223261529 Test RE 3.009956540897721\n",
      "36 Train Loss 22.80745 Test MSE 17.228951950956915 Test RE 2.9989229433451836\n",
      "37 Train Loss 22.551563 Test MSE 17.14579814175239 Test RE 2.991677189588695\n",
      "38 Train Loss 22.296968 Test MSE 17.083697326792237 Test RE 2.9862544580016572\n",
      "39 Train Loss 22.137985 Test MSE 17.032869786653283 Test RE 2.981808785882983\n",
      "40 Train Loss 21.91601 Test MSE 17.013758163482475 Test RE 2.9801354565760416\n",
      "41 Train Loss 21.811676 Test MSE 16.988272754733373 Test RE 2.9779026038237566\n",
      "42 Train Loss 21.707588 Test MSE 16.970223545287865 Test RE 2.9763202454364475\n",
      "43 Train Loss 21.575274 Test MSE 16.92975028564843 Test RE 2.972768928291646\n",
      "44 Train Loss 21.447315 Test MSE 16.88145835797549 Test RE 2.9685260049677344\n",
      "45 Train Loss 21.366901 Test MSE 16.878929575224692 Test RE 2.968303659292973\n",
      "46 Train Loss 21.261868 Test MSE 16.803547982334937 Test RE 2.9616679943835953\n",
      "47 Train Loss 21.1717 Test MSE 16.806457412046594 Test RE 2.9619243804728743\n",
      "48 Train Loss 21.065798 Test MSE 16.765770390607138 Test RE 2.9583369228808314\n",
      "49 Train Loss 20.986376 Test MSE 16.744662264725047 Test RE 2.9564740614177505\n",
      "50 Train Loss 20.902575 Test MSE 16.686274408374672 Test RE 2.9513150165717197\n",
      "51 Train Loss 20.849823 Test MSE 16.648527108552482 Test RE 2.947974928622338\n",
      "52 Train Loss 20.795572 Test MSE 16.632332304335414 Test RE 2.9465407629349993\n",
      "53 Train Loss 20.757969 Test MSE 16.612524663450152 Test RE 2.944785705160391\n",
      "54 Train Loss 20.714512 Test MSE 16.58484510499638 Test RE 2.942331401829358\n",
      "55 Train Loss 20.668282 Test MSE 16.5429197581427 Test RE 2.93861004287803\n",
      "56 Train Loss 20.616734 Test MSE 16.532433026427956 Test RE 2.9376784872383404\n",
      "57 Train Loss 20.531958 Test MSE 16.457721979117753 Test RE 2.9310331992946894\n",
      "58 Train Loss 20.474018 Test MSE 16.432457436134737 Test RE 2.9287825945174264\n",
      "59 Train Loss 20.4242 Test MSE 16.428676231196714 Test RE 2.9284456100952223\n",
      "60 Train Loss 20.374025 Test MSE 16.432504952953945 Test RE 2.928786829012875\n",
      "61 Train Loss 20.31794 Test MSE 16.392458252759585 Test RE 2.9252158641871686\n",
      "62 Train Loss 20.274664 Test MSE 16.369074347645967 Test RE 2.923128703712513\n",
      "63 Train Loss 20.233004 Test MSE 16.360103158335072 Test RE 2.922327573041833\n",
      "64 Train Loss 20.188108 Test MSE 16.362177964018247 Test RE 2.922512873512522\n",
      "65 Train Loss 20.103338 Test MSE 16.290057344235258 Test RE 2.9160648867771695\n",
      "66 Train Loss 20.064375 Test MSE 16.2722471374943 Test RE 2.914470358264156\n",
      "67 Train Loss 20.017742 Test MSE 16.246499810685307 Test RE 2.912163684599132\n",
      "68 Train Loss 19.977863 Test MSE 16.195017114047708 Test RE 2.9075459206786274\n",
      "69 Train Loss 19.889061 Test MSE 16.15474586189946 Test RE 2.9039286538567723\n",
      "70 Train Loss 19.863792 Test MSE 16.131584640901135 Test RE 2.9018462113814856\n",
      "71 Train Loss 19.843525 Test MSE 16.120578009052085 Test RE 2.900856072978577\n",
      "72 Train Loss 19.798943 Test MSE 16.09453160644584 Test RE 2.8985116344114434\n",
      "73 Train Loss 19.775095 Test MSE 16.073010231237422 Test RE 2.896573062190012\n",
      "74 Train Loss 19.75737 Test MSE 16.059209028562787 Test RE 2.8953292137613924\n",
      "75 Train Loss 19.704838 Test MSE 16.03824999283113 Test RE 2.8934392352179725\n",
      "76 Train Loss 19.664925 Test MSE 15.996135633248374 Test RE 2.889637840436503\n",
      "77 Train Loss 19.626781 Test MSE 15.961535935243667 Test RE 2.886511000240162\n",
      "78 Train Loss 19.599014 Test MSE 15.918099799414126 Test RE 2.88258079267577\n",
      "79 Train Loss 19.565802 Test MSE 15.90249543889044 Test RE 2.8811675630984337\n",
      "80 Train Loss 19.53367 Test MSE 15.894389505139872 Test RE 2.8804331648289363\n",
      "81 Train Loss 19.483067 Test MSE 15.843487898900882 Test RE 2.8758171885683304\n",
      "82 Train Loss 19.423286 Test MSE 15.791157908120121 Test RE 2.8710639435939855\n",
      "83 Train Loss 19.39305 Test MSE 15.74901365638652 Test RE 2.8672301626206322\n",
      "84 Train Loss 19.369078 Test MSE 15.70456610286635 Test RE 2.8631812928423317\n",
      "85 Train Loss 19.332605 Test MSE 15.655182905610546 Test RE 2.8586760943613165\n",
      "86 Train Loss 19.300886 Test MSE 15.61956150680339 Test RE 2.8554219633432307\n",
      "87 Train Loss 19.253937 Test MSE 15.598117575711916 Test RE 2.8534612008006532\n",
      "88 Train Loss 19.209063 Test MSE 15.576208038595835 Test RE 2.85145647225443\n",
      "89 Train Loss 19.167746 Test MSE 15.54512605998318 Test RE 2.8486100423886977\n",
      "90 Train Loss 19.137848 Test MSE 15.524110582037286 Test RE 2.84668387119393\n",
      "91 Train Loss 19.101332 Test MSE 15.466091061432527 Test RE 2.841359320032294\n",
      "92 Train Loss 19.07695 Test MSE 15.432193874498868 Test RE 2.838243894205454\n",
      "93 Train Loss 19.030003 Test MSE 15.396277602052683 Test RE 2.8349391624480584\n",
      "94 Train Loss 18.980114 Test MSE 15.37052311779403 Test RE 2.8325670645687833\n",
      "95 Train Loss 18.907625 Test MSE 15.277878785992522 Test RE 2.82401765129035\n",
      "96 Train Loss 18.829277 Test MSE 15.187849425652736 Test RE 2.8156846828708355\n",
      "97 Train Loss 18.766283 Test MSE 15.156071466226612 Test RE 2.812737472776039\n",
      "98 Train Loss 18.70733 Test MSE 15.086104956976271 Test RE 2.8062376000159652\n",
      "99 Train Loss 18.619759 Test MSE 15.00252283804041 Test RE 2.7984530505268195\n",
      "100 Train Loss 18.497057 Test MSE 14.849915731314864 Test RE 2.784183603296506\n",
      "101 Train Loss 18.384207 Test MSE 14.735784384375705 Test RE 2.7734638274510974\n",
      "102 Train Loss 18.222803 Test MSE 14.504133746417766 Test RE 2.751577660344314\n",
      "103 Train Loss 18.010967 Test MSE 14.183678457522165 Test RE 2.721011113232576\n",
      "104 Train Loss 17.713633 Test MSE 13.748805804335653 Test RE 2.678973180080651\n",
      "105 Train Loss 17.171957 Test MSE 13.374987933939328 Test RE 2.642302747463456\n",
      "106 Train Loss 16.851162 Test MSE 13.295470746883199 Test RE 2.6344365086418002\n",
      "107 Train Loss 16.506496 Test MSE 13.04241916209822 Test RE 2.609245563448073\n",
      "108 Train Loss 16.19469 Test MSE 12.93149191665303 Test RE 2.5981259056259898\n",
      "109 Train Loss 15.875405 Test MSE 12.70122752898838 Test RE 2.5748902627001864\n",
      "110 Train Loss 15.346752 Test MSE 12.402343875341087 Test RE 2.5444139105907246\n",
      "111 Train Loss 14.9550295 Test MSE 12.103318333522767 Test RE 2.5135533346297523\n",
      "112 Train Loss 14.541594 Test MSE 11.865743759307925 Test RE 2.4887619575046735\n",
      "113 Train Loss 14.170817 Test MSE 11.70994639976481 Test RE 2.472369233188645\n",
      "114 Train Loss 13.703136 Test MSE 11.49134720148796 Test RE 2.449183642579473\n",
      "115 Train Loss 13.339202 Test MSE 11.365434328217125 Test RE 2.435728598579107\n",
      "116 Train Loss 13.128868 Test MSE 11.270982529096104 Test RE 2.425586490891984\n",
      "117 Train Loss 12.938007 Test MSE 11.134955898628311 Test RE 2.4109051659476988\n",
      "118 Train Loss 12.776607 Test MSE 11.022563736685209 Test RE 2.3987069103353327\n",
      "119 Train Loss 12.629053 Test MSE 10.972316605871658 Test RE 2.393233328337439\n",
      "120 Train Loss 12.4650755 Test MSE 10.859816944202466 Test RE 2.3809327523774457\n",
      "121 Train Loss 12.344579 Test MSE 10.772111557826795 Test RE 2.3712988904397325\n",
      "122 Train Loss 12.183698 Test MSE 10.769868835683925 Test RE 2.3710520288408796\n",
      "123 Train Loss 12.051253 Test MSE 10.669573024340076 Test RE 2.359985838763846\n",
      "124 Train Loss 11.869402 Test MSE 10.563103279587928 Test RE 2.3481813797789166\n",
      "125 Train Loss 11.692215 Test MSE 10.502783010735952 Test RE 2.3414671728032364\n",
      "126 Train Loss 11.616001 Test MSE 10.434682711313062 Test RE 2.333863762655302\n",
      "127 Train Loss 11.482822 Test MSE 10.357980734819867 Test RE 2.325270202706264\n",
      "128 Train Loss 11.351101 Test MSE 10.316429293410236 Test RE 2.3206015600938588\n",
      "129 Train Loss 11.266658 Test MSE 10.298917640003229 Test RE 2.3186311675867852\n",
      "130 Train Loss 11.142793 Test MSE 10.209727210713872 Test RE 2.3085694603213462\n",
      "131 Train Loss 10.990714 Test MSE 10.117671102033466 Test RE 2.2981382739081613\n",
      "132 Train Loss 10.812162 Test MSE 10.147352483521388 Test RE 2.3015067351108875\n",
      "133 Train Loss 10.666985 Test MSE 10.157803780246908 Test RE 2.302691652037634\n",
      "134 Train Loss 10.537211 Test MSE 10.102554795640243 Test RE 2.2964208654640625\n",
      "135 Train Loss 10.361862 Test MSE 10.108036979552038 Test RE 2.297043861048913\n",
      "136 Train Loss 10.161068 Test MSE 10.08872266226776 Test RE 2.294848229605452\n",
      "137 Train Loss 10.007895 Test MSE 10.067220932959303 Test RE 2.2924014617642605\n",
      "138 Train Loss 9.866066 Test MSE 10.039968754933792 Test RE 2.289296569691031\n",
      "139 Train Loss 9.725897 Test MSE 9.994600355191805 Test RE 2.2841183005982204\n",
      "140 Train Loss 9.526516 Test MSE 9.985766373306122 Test RE 2.2831086393999107\n",
      "141 Train Loss 9.399685 Test MSE 9.91973529084912 Test RE 2.275547568166817\n",
      "142 Train Loss 9.276602 Test MSE 9.866209701761095 Test RE 2.26939998612331\n",
      "143 Train Loss 9.157765 Test MSE 9.754928108415168 Test RE 2.2565653409531463\n",
      "144 Train Loss 9.049922 Test MSE 9.656861920107264 Test RE 2.2451940763023517\n",
      "145 Train Loss 8.883125 Test MSE 9.49555286772966 Test RE 2.226363149266689\n",
      "146 Train Loss 8.736697 Test MSE 9.425140432453594 Test RE 2.2180932070906496\n",
      "147 Train Loss 8.574552 Test MSE 9.315822478110384 Test RE 2.20519235869067\n",
      "148 Train Loss 8.354424 Test MSE 9.288687986082257 Test RE 2.201978449757283\n",
      "149 Train Loss 8.23 Test MSE 9.260947291491847 Test RE 2.198687883469227\n",
      "150 Train Loss 8.086797 Test MSE 9.059618579386314 Test RE 2.1746573335863824\n",
      "151 Train Loss 7.9566646 Test MSE 8.95622221178875 Test RE 2.1622121679406736\n",
      "152 Train Loss 7.808531 Test MSE 8.848476966132585 Test RE 2.149166880206319\n",
      "153 Train Loss 7.565353 Test MSE 8.708834424112625 Test RE 2.1321408635700045\n",
      "154 Train Loss 7.369643 Test MSE 8.500989140025819 Test RE 2.10654435304376\n",
      "155 Train Loss 7.0676713 Test MSE 8.321685856377735 Test RE 2.0842102887459917\n",
      "156 Train Loss 6.8253727 Test MSE 8.21937628501035 Test RE 2.0713586791404217\n",
      "157 Train Loss 6.6096816 Test MSE 8.11300955052581 Test RE 2.057912335921874\n",
      "158 Train Loss 6.381569 Test MSE 8.044923643541376 Test RE 2.0492589481406\n",
      "159 Train Loss 6.1564093 Test MSE 7.806181262885407 Test RE 2.0186228857591355\n",
      "160 Train Loss 5.993357 Test MSE 7.716485028023267 Test RE 2.0069919744395244\n",
      "161 Train Loss 5.7881184 Test MSE 7.484802523026397 Test RE 1.9766330386666697\n",
      "162 Train Loss 5.6053104 Test MSE 7.285966413992541 Test RE 1.9502013797826179\n",
      "163 Train Loss 5.3874927 Test MSE 6.854162956381631 Test RE 1.8915293726682976\n",
      "164 Train Loss 5.21874 Test MSE 6.728264205494315 Test RE 1.874076847525105\n",
      "165 Train Loss 5.016127 Test MSE 6.531203969001366 Test RE 1.8464285230474544\n",
      "166 Train Loss 4.8026514 Test MSE 5.983771425317632 Test RE 1.7673532979908746\n",
      "167 Train Loss 4.5467424 Test MSE 5.584337708306568 Test RE 1.7073466780760653\n",
      "168 Train Loss 4.243685 Test MSE 5.330919163725444 Test RE 1.6681570123584777\n",
      "169 Train Loss 4.0441384 Test MSE 5.098315724015791 Test RE 1.6313578616171693\n",
      "170 Train Loss 3.7653427 Test MSE 4.496531386436218 Test RE 1.5320561816496623\n",
      "171 Train Loss 3.5216498 Test MSE 4.267859514185265 Test RE 1.4925913984190102\n",
      "172 Train Loss 3.3021605 Test MSE 4.052671214996188 Test RE 1.4544760111281225\n",
      "173 Train Loss 3.1524336 Test MSE 3.8927007324384015 Test RE 1.4254808432788633\n",
      "174 Train Loss 2.945962 Test MSE 3.4684505880470846 Test RE 1.3455617493716419\n",
      "175 Train Loss 2.773115 Test MSE 3.325855194794144 Test RE 1.3176120110709646\n",
      "176 Train Loss 2.6196477 Test MSE 3.1591262444101966 Test RE 1.2841606787939326\n",
      "177 Train Loss 2.4954991 Test MSE 2.9777453527906226 Test RE 1.2467507974130316\n",
      "178 Train Loss 2.4038296 Test MSE 2.8612135631466495 Test RE 1.2221120167414696\n",
      "179 Train Loss 2.3027136 Test MSE 2.733523410635974 Test RE 1.1945305897657277\n",
      "180 Train Loss 2.2021708 Test MSE 2.467105638137107 Test RE 1.134827234478252\n",
      "181 Train Loss 2.0668797 Test MSE 2.2480848353510217 Test RE 1.0832837411255427\n",
      "182 Train Loss 1.9859642 Test MSE 2.044122384679059 Test RE 1.0329738418287264\n",
      "183 Train Loss 1.8490953 Test MSE 1.9071950973151093 Test RE 0.997776882897268\n",
      "184 Train Loss 1.7485143 Test MSE 1.784477054956475 Test RE 0.9651423239298426\n",
      "185 Train Loss 1.6884482 Test MSE 1.6015004688253098 Test RE 0.9143225100566226\n",
      "186 Train Loss 1.6207781 Test MSE 1.5887682852232234 Test RE 0.9106807527419245\n",
      "187 Train Loss 1.5412338 Test MSE 1.5074687562548912 Test RE 0.8870743807983387\n",
      "188 Train Loss 1.4622631 Test MSE 1.3692500352757713 Test RE 0.8454292264417563\n",
      "189 Train Loss 1.4035033 Test MSE 1.310808914037419 Test RE 0.8271905607392214\n",
      "190 Train Loss 1.3422918 Test MSE 1.2325716132982512 Test RE 0.8021248251796924\n",
      "191 Train Loss 1.2907588 Test MSE 1.1526769399198185 Test RE 0.7756926553433866\n",
      "192 Train Loss 1.249202 Test MSE 1.176861043526307 Test RE 0.7837877480506085\n",
      "193 Train Loss 1.2073399 Test MSE 1.1697048221858923 Test RE 0.7814010978338861\n",
      "194 Train Loss 1.158187 Test MSE 1.1763096984197456 Test RE 0.7836041290216228\n",
      "195 Train Loss 1.1354668 Test MSE 1.1600227241286192 Test RE 0.7781603986031409\n",
      "196 Train Loss 1.114996 Test MSE 1.137788214173386 Test RE 0.7706666973021289\n",
      "197 Train Loss 1.0898596 Test MSE 1.0930248447054713 Test RE 0.7553546267626932\n",
      "198 Train Loss 1.039445 Test MSE 1.1070368692452897 Test RE 0.760180840357766\n",
      "199 Train Loss 1.0191287 Test MSE 1.0691477272463152 Test RE 0.7470587131957318\n",
      "200 Train Loss 1.00388 Test MSE 1.048421223020795 Test RE 0.7397820318148152\n",
      "201 Train Loss 0.9852279 Test MSE 1.0389755591941168 Test RE 0.7364419894859843\n",
      "202 Train Loss 0.9711299 Test MSE 1.037181468406475 Test RE 0.7358058750714886\n",
      "203 Train Loss 0.94523954 Test MSE 0.9868190509122508 Test RE 0.7177193240701443\n",
      "204 Train Loss 0.9334514 Test MSE 0.9818315967179132 Test RE 0.7159033241689859\n",
      "205 Train Loss 0.92010206 Test MSE 0.9447691583006422 Test RE 0.7022612911041938\n",
      "206 Train Loss 0.9079448 Test MSE 0.9237742355660866 Test RE 0.6944145301996999\n",
      "207 Train Loss 0.8959462 Test MSE 0.9065824108921865 Test RE 0.6879225112080487\n",
      "208 Train Loss 0.87701976 Test MSE 0.9026187523721666 Test RE 0.6864170348413846\n",
      "209 Train Loss 0.8614328 Test MSE 0.9031938782299657 Test RE 0.6866356838111782\n",
      "210 Train Loss 0.84909326 Test MSE 0.8941234880420008 Test RE 0.6831791895018844\n",
      "211 Train Loss 0.83755386 Test MSE 0.902464181466103 Test RE 0.6863582588379731\n",
      "212 Train Loss 0.8252195 Test MSE 0.9214665864718063 Test RE 0.6935466411539848\n",
      "213 Train Loss 0.8175776 Test MSE 0.9137873083548885 Test RE 0.6906506705520834\n",
      "214 Train Loss 0.8092996 Test MSE 0.9057038954420087 Test RE 0.6875891178902191\n",
      "215 Train Loss 0.79352075 Test MSE 0.8863684935789838 Test RE 0.6802100309463437\n",
      "216 Train Loss 0.77548563 Test MSE 0.8579468687552173 Test RE 0.6692156269196177\n",
      "217 Train Loss 0.7646737 Test MSE 0.8501352127118514 Test RE 0.6661620366809153\n",
      "218 Train Loss 0.7536555 Test MSE 0.811887754941285 Test RE 0.6510043230716915\n",
      "219 Train Loss 0.7326078 Test MSE 0.7823818271130965 Test RE 0.6390653252782462\n",
      "220 Train Loss 0.7102412 Test MSE 0.7625810015108856 Test RE 0.6309266433115672\n",
      "221 Train Loss 0.6867801 Test MSE 0.7823500952717035 Test RE 0.6390523655414152\n",
      "222 Train Loss 0.6659244 Test MSE 0.798930309727318 Test RE 0.6457885279070313\n",
      "223 Train Loss 0.65325814 Test MSE 0.776770935937998 Test RE 0.636769657210728\n",
      "224 Train Loss 0.6388943 Test MSE 0.78473627261131 Test RE 0.6400261823259208\n",
      "225 Train Loss 0.6206374 Test MSE 0.7481144566925393 Test RE 0.6249134908901068\n",
      "226 Train Loss 0.61234194 Test MSE 0.745813147374822 Test RE 0.6239515880041179\n",
      "227 Train Loss 0.6043362 Test MSE 0.7274687623319799 Test RE 0.6162303040275209\n",
      "228 Train Loss 0.58993673 Test MSE 0.6853877603193608 Test RE 0.5981416565391328\n",
      "229 Train Loss 0.57666487 Test MSE 0.6622124023920456 Test RE 0.5879420631387654\n",
      "230 Train Loss 0.5608014 Test MSE 0.639233581717991 Test RE 0.5776511842539847\n",
      "231 Train Loss 0.54558456 Test MSE 0.6164169875540572 Test RE 0.5672482650606924\n",
      "232 Train Loss 0.53321373 Test MSE 0.6109403355841533 Test RE 0.5647227405130479\n",
      "233 Train Loss 0.523599 Test MSE 0.5749495339687115 Test RE 0.5478362174056479\n",
      "234 Train Loss 0.5145803 Test MSE 0.5735400359000777 Test RE 0.5471642906755569\n",
      "235 Train Loss 0.5031696 Test MSE 0.5661691386015575 Test RE 0.5436369574627651\n",
      "236 Train Loss 0.49086064 Test MSE 0.5430924788458439 Test RE 0.532442570080398\n",
      "237 Train Loss 0.48169327 Test MSE 0.5156891753793923 Test RE 0.5188357397352812\n",
      "238 Train Loss 0.46733838 Test MSE 0.47384790788661574 Test RE 0.497342256692466\n",
      "239 Train Loss 0.4604091 Test MSE 0.45386087213253057 Test RE 0.48674023624531154\n",
      "240 Train Loss 0.44819605 Test MSE 0.4408484899656123 Test RE 0.4797119703805707\n",
      "241 Train Loss 0.43922764 Test MSE 0.44463852522931546 Test RE 0.48176963232642533\n",
      "242 Train Loss 0.4318779 Test MSE 0.41033744638437875 Test RE 0.4628139625240418\n",
      "243 Train Loss 0.4199324 Test MSE 0.3546962331790533 Test RE 0.4302928850956538\n",
      "244 Train Loss 0.41210413 Test MSE 0.3415564595846015 Test RE 0.4222475404232907\n",
      "245 Train Loss 0.40186033 Test MSE 0.34295326565828654 Test RE 0.4231100569165395\n",
      "246 Train Loss 0.38296843 Test MSE 0.2984510950150443 Test RE 0.39470485211650785\n",
      "247 Train Loss 0.36734605 Test MSE 0.2683885015575278 Test RE 0.37429827852113196\n",
      "248 Train Loss 0.35977048 Test MSE 0.24614521774069945 Test RE 0.3584524706447312\n",
      "249 Train Loss 0.35061103 Test MSE 0.2136203804297356 Test RE 0.33393136980176624\n",
      "250 Train Loss 0.34092516 Test MSE 0.19373979444299963 Test RE 0.31801330784176657\n",
      "251 Train Loss 0.32527018 Test MSE 0.17482298166952975 Test RE 0.3020891577953206\n",
      "252 Train Loss 0.3061404 Test MSE 0.19099984702192827 Test RE 0.3157565633387074\n",
      "253 Train Loss 0.29541048 Test MSE 0.17606513333741833 Test RE 0.3031604596505856\n",
      "254 Train Loss 0.28462306 Test MSE 0.17080945108867585 Test RE 0.2986013902519622\n",
      "255 Train Loss 0.27526382 Test MSE 0.1709392810752878 Test RE 0.2987148501641663\n",
      "256 Train Loss 0.26823616 Test MSE 0.170229723358252 Test RE 0.29809423260702356\n",
      "257 Train Loss 0.26136234 Test MSE 0.16367536672617106 Test RE 0.29229914043307104\n",
      "258 Train Loss 0.25747392 Test MSE 0.15909422498728543 Test RE 0.28817950069878473\n",
      "259 Train Loss 0.25162455 Test MSE 0.14696684498288975 Test RE 0.2769781833080051\n",
      "260 Train Loss 0.24436119 Test MSE 0.13804925520258876 Test RE 0.2684435112956321\n",
      "261 Train Loss 0.23786977 Test MSE 0.12908565035793768 Test RE 0.25958217109825626\n",
      "262 Train Loss 0.23119478 Test MSE 0.12236285904885058 Test RE 0.25273226224961304\n",
      "263 Train Loss 0.22399223 Test MSE 0.12228940606194395 Test RE 0.25265639475820506\n",
      "264 Train Loss 0.21421932 Test MSE 0.12986830416831915 Test RE 0.26036791280365634\n",
      "265 Train Loss 0.20463571 Test MSE 0.12428044176048282 Test RE 0.2547048830316009\n",
      "266 Train Loss 0.20128053 Test MSE 0.12547369606426564 Test RE 0.2559247115474296\n",
      "267 Train Loss 0.1963701 Test MSE 0.11917934132557546 Test RE 0.24942292465651475\n",
      "268 Train Loss 0.19384173 Test MSE 0.11938327525879847 Test RE 0.24963623367600868\n",
      "269 Train Loss 0.19084486 Test MSE 0.11286231051476919 Test RE 0.2427226725381222\n",
      "270 Train Loss 0.18849233 Test MSE 0.10573828055955287 Test RE 0.23493731380365326\n",
      "271 Train Loss 0.1860047 Test MSE 0.10343813959311941 Test RE 0.23236795040367328\n",
      "272 Train Loss 0.1835833 Test MSE 0.10108365136201224 Test RE 0.22970811474231206\n",
      "273 Train Loss 0.17932078 Test MSE 0.10000032690504733 Test RE 0.228473895627661\n",
      "274 Train Loss 0.17517848 Test MSE 0.09963926221282601 Test RE 0.2280610547005365\n",
      "275 Train Loss 0.17331715 Test MSE 0.09835786300196357 Test RE 0.22658983286241344\n",
      "276 Train Loss 0.17082195 Test MSE 0.09683347118056777 Test RE 0.22482708363118148\n",
      "277 Train Loss 0.1682792 Test MSE 0.0933305977343661 Test RE 0.22072315766367318\n",
      "278 Train Loss 0.16643529 Test MSE 0.09521671029495478 Test RE 0.22294229280511269\n",
      "279 Train Loss 0.16492568 Test MSE 0.0953787367523788 Test RE 0.2231318981579367\n",
      "280 Train Loss 0.16299658 Test MSE 0.09151281847287404 Test RE 0.21856310032048978\n",
      "281 Train Loss 0.15837438 Test MSE 0.08826759556495628 Test RE 0.214652783781056\n",
      "282 Train Loss 0.15597844 Test MSE 0.08863616006534676 Test RE 0.21510046212933706\n",
      "283 Train Loss 0.15327099 Test MSE 0.08481656316245098 Test RE 0.21041476536266107\n",
      "284 Train Loss 0.15000623 Test MSE 0.08252033941525277 Test RE 0.20754696151589702\n",
      "285 Train Loss 0.14803122 Test MSE 0.07803505330223239 Test RE 0.20182768675377358\n",
      "286 Train Loss 0.14599513 Test MSE 0.07216918611121818 Test RE 0.1940938526796297\n",
      "287 Train Loss 0.14401858 Test MSE 0.06930339441612447 Test RE 0.19020114635511223\n",
      "288 Train Loss 0.14162347 Test MSE 0.06788742337113185 Test RE 0.18824807319217143\n",
      "289 Train Loss 0.13927549 Test MSE 0.06512734258234858 Test RE 0.18438159002286608\n",
      "290 Train Loss 0.13484289 Test MSE 0.06426614442425117 Test RE 0.18315846692447027\n",
      "291 Train Loss 0.13183606 Test MSE 0.06579982053242452 Test RE 0.1853310692795252\n",
      "292 Train Loss 0.12986067 Test MSE 0.06434304476071862 Test RE 0.18326801711528662\n",
      "293 Train Loss 0.12702928 Test MSE 0.06276554429928553 Test RE 0.18100748184788581\n",
      "294 Train Loss 0.12529849 Test MSE 0.06402857996122135 Test RE 0.18281962421816275\n",
      "295 Train Loss 0.12362098 Test MSE 0.06034235512891523 Test RE 0.17747901311140063\n",
      "296 Train Loss 0.122229695 Test MSE 0.05835851162066665 Test RE 0.17453719030972542\n",
      "297 Train Loss 0.120457776 Test MSE 0.05753151682616601 Test RE 0.1732960999999527\n",
      "298 Train Loss 0.11677169 Test MSE 0.05718438573525793 Test RE 0.17277249585471763\n",
      "299 Train Loss 0.11397371 Test MSE 0.056350552489818094 Test RE 0.1715082304619159\n",
      "Training time: 166.68\n",
      "KG_tanh_high\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 53110.684 Test MSE 6.465875019595121 Test RE 1.8371707816418905\n",
      "1 Train Loss 27401.992 Test MSE 10.854648389572228 Test RE 2.380366101686111\n",
      "2 Train Loss 10719.649 Test MSE 9.841390423698385 Test RE 2.2665437557115133\n",
      "3 Train Loss 3066.7527 Test MSE 14.984882467246276 Test RE 2.7968073183414126\n",
      "4 Train Loss 1527.0679 Test MSE 17.340359773328963 Test RE 3.0086033089938984\n",
      "5 Train Loss 874.13776 Test MSE 18.226851696902777 Test RE 3.084549235744491\n",
      "6 Train Loss 587.1214 Test MSE 18.925240696213965 Test RE 3.143088305364468\n",
      "7 Train Loss 383.98126 Test MSE 18.86868508085299 Test RE 3.1383884366145125\n",
      "8 Train Loss 258.41327 Test MSE 18.613669710032596 Test RE 3.1171082066751423\n",
      "9 Train Loss 159.27727 Test MSE 18.789322435739905 Test RE 3.1317813715223077\n",
      "10 Train Loss 108.836075 Test MSE 18.95898140698373 Test RE 3.145888872332577\n",
      "11 Train Loss 80.0684 Test MSE 18.893463690766502 Test RE 3.140448447388093\n",
      "12 Train Loss 63.835583 Test MSE 18.8832674615663 Test RE 3.139600930648821\n",
      "13 Train Loss 52.443806 Test MSE 18.7171870082102 Test RE 3.1257638678243818\n",
      "14 Train Loss 45.966644 Test MSE 18.174489357955526 Test RE 3.0801153822674863\n",
      "15 Train Loss 41.18738 Test MSE 17.678356832365704 Test RE 3.0377835413086016\n",
      "16 Train Loss 38.170895 Test MSE 17.319223076030546 Test RE 3.0067691103778977\n",
      "17 Train Loss 36.07156 Test MSE 17.030187445175276 Test RE 2.9815739885645702\n",
      "18 Train Loss 33.94631 Test MSE 16.900547745836842 Test RE 2.9702039208330437\n",
      "19 Train Loss 32.226704 Test MSE 16.652136983508548 Test RE 2.9482945137723213\n",
      "20 Train Loss 30.358702 Test MSE 16.490572526460237 Test RE 2.9339569953336757\n",
      "21 Train Loss 28.84059 Test MSE 16.218413978730545 Test RE 2.909645421592437\n",
      "22 Train Loss 27.203453 Test MSE 16.03053435611811 Test RE 2.8927431676412287\n",
      "23 Train Loss 25.42808 Test MSE 15.633414177846978 Test RE 2.8566878905217385\n",
      "24 Train Loss 23.47173 Test MSE 15.256966055882167 Test RE 2.822084197581993\n",
      "25 Train Loss 21.952366 Test MSE 15.008532598089733 Test RE 2.799013501179225\n",
      "26 Train Loss 20.709173 Test MSE 14.90119076674714 Test RE 2.788986192588053\n",
      "27 Train Loss 19.892542 Test MSE 14.770376500728503 Test RE 2.7767172594488385\n",
      "28 Train Loss 19.141811 Test MSE 14.707234107530159 Test RE 2.770775760458485\n",
      "29 Train Loss 18.279284 Test MSE 14.54873900643016 Test RE 2.7558054419155167\n",
      "30 Train Loss 17.696775 Test MSE 14.484608104192716 Test RE 2.7497249328450812\n",
      "31 Train Loss 17.298553 Test MSE 14.43364095752833 Test RE 2.744882926306312\n",
      "32 Train Loss 16.924278 Test MSE 14.326692004172251 Test RE 2.7346946382897555\n",
      "33 Train Loss 16.519012 Test MSE 14.2691253247259 Test RE 2.7291949126940245\n",
      "34 Train Loss 16.164284 Test MSE 14.189477707200357 Test RE 2.721567323324135\n",
      "35 Train Loss 15.912132 Test MSE 14.135225169408793 Test RE 2.716359473467407\n",
      "36 Train Loss 15.693838 Test MSE 14.103078203369453 Test RE 2.713268881717102\n",
      "37 Train Loss 15.390247 Test MSE 14.016761460056474 Test RE 2.70495296719145\n",
      "38 Train Loss 15.242409 Test MSE 13.89426255037672 Test RE 2.693107116269635\n",
      "39 Train Loss 15.103943 Test MSE 13.876845195436013 Test RE 2.6914185951349414\n",
      "40 Train Loss 14.968154 Test MSE 13.838564956779383 Test RE 2.6877037991768167\n",
      "41 Train Loss 14.786295 Test MSE 13.805821597263247 Test RE 2.6845222348150237\n",
      "42 Train Loss 14.593979 Test MSE 13.70202026813548 Test RE 2.674411183673585\n",
      "43 Train Loss 14.478544 Test MSE 13.593193146494707 Test RE 2.6637693703196152\n",
      "44 Train Loss 14.385201 Test MSE 13.609009693499592 Test RE 2.665318652538162\n",
      "45 Train Loss 14.274213 Test MSE 13.536147409249685 Test RE 2.6581740533022726\n",
      "46 Train Loss 14.170328 Test MSE 13.454359717910664 Test RE 2.6501313174656453\n",
      "47 Train Loss 14.031821 Test MSE 13.321947990856655 Test RE 2.6370583761502884\n",
      "48 Train Loss 13.893815 Test MSE 13.152741160309356 Test RE 2.6202577467294974\n",
      "49 Train Loss 13.7447195 Test MSE 13.004585463368066 Test RE 2.60545834024606\n",
      "50 Train Loss 13.484032 Test MSE 12.826280822189394 Test RE 2.587535095801065\n",
      "51 Train Loss 13.238001 Test MSE 12.693548887535362 Test RE 2.5741118084818715\n",
      "52 Train Loss 12.897956 Test MSE 12.276112366289677 Test RE 2.531432225225154\n",
      "53 Train Loss 12.168814 Test MSE 11.583612132773716 Test RE 2.458996329383108\n",
      "54 Train Loss 11.515993 Test MSE 11.135771057581453 Test RE 2.410993412142045\n",
      "55 Train Loss 10.867981 Test MSE 10.728435709083332 Test RE 2.3664867565856076\n",
      "56 Train Loss 10.183088 Test MSE 10.222702819395446 Test RE 2.3100359824832792\n",
      "57 Train Loss 9.467624 Test MSE 9.80050775434698 Test RE 2.2618310683362455\n",
      "58 Train Loss 9.089385 Test MSE 9.708639335675459 Test RE 2.251205083734284\n",
      "59 Train Loss 8.602136 Test MSE 9.506066840589574 Test RE 2.227595381134576\n",
      "60 Train Loss 8.185212 Test MSE 9.362093476543784 Test RE 2.2106620885094608\n",
      "61 Train Loss 7.818091 Test MSE 9.228663915600935 Test RE 2.1948522588468315\n",
      "62 Train Loss 7.5417457 Test MSE 9.022152651190662 Test RE 2.170156042241489\n",
      "63 Train Loss 7.189177 Test MSE 8.883584478958849 Test RE 2.15342621267856\n",
      "64 Train Loss 6.962556 Test MSE 8.850132995850396 Test RE 2.1493679836124167\n",
      "65 Train Loss 6.769683 Test MSE 8.627724374623943 Test RE 2.122188750873126\n",
      "66 Train Loss 6.6171446 Test MSE 8.511141660701204 Test RE 2.107801874559428\n",
      "67 Train Loss 6.4016967 Test MSE 8.201215275742134 Test RE 2.0690690427120546\n",
      "68 Train Loss 6.0530343 Test MSE 7.747674977487031 Test RE 2.0110440039877795\n",
      "69 Train Loss 5.814193 Test MSE 7.390556787767371 Test RE 1.9641491170621275\n",
      "70 Train Loss 5.429588 Test MSE 6.752850128252575 Test RE 1.8774977813759246\n",
      "71 Train Loss 5.2132425 Test MSE 6.288152474376662 Test RE 1.8117464075111316\n",
      "72 Train Loss 4.832172 Test MSE 5.7107590064914335 Test RE 1.7265644461906344\n",
      "73 Train Loss 4.5233583 Test MSE 5.010035992443577 Test RE 1.6171723223148335\n",
      "74 Train Loss 4.1156893 Test MSE 4.591004162675674 Test RE 1.5480668832310687\n",
      "75 Train Loss 3.757683 Test MSE 4.159849429659943 Test RE 1.4735832708508931\n",
      "76 Train Loss 3.5472937 Test MSE 3.8416310863533756 Test RE 1.416099291194432\n",
      "77 Train Loss 3.233072 Test MSE 3.2892324871716 Test RE 1.310337476866753\n",
      "78 Train Loss 2.9950569 Test MSE 2.7911112395653856 Test RE 1.207047746845088\n",
      "79 Train Loss 2.7349963 Test MSE 2.248388040528115 Test RE 1.0833567913412596\n",
      "80 Train Loss 2.4946241 Test MSE 2.0105086096272595 Test RE 1.0244454679439816\n",
      "81 Train Loss 2.2472687 Test MSE 1.7671344437245 Test RE 0.9604409593020333\n",
      "82 Train Loss 1.9494376 Test MSE 1.6330146284903868 Test RE 0.923274656383073\n",
      "83 Train Loss 1.7649943 Test MSE 1.5010016382755322 Test RE 0.8851695384280753\n",
      "84 Train Loss 1.6256872 Test MSE 1.2486600510571488 Test RE 0.8073428168174839\n",
      "85 Train Loss 1.394625 Test MSE 0.8991233898033429 Test RE 0.6850866815262446\n",
      "86 Train Loss 1.176212 Test MSE 0.6791073413320503 Test RE 0.5953948716054948\n",
      "87 Train Loss 1.0223296 Test MSE 0.5123499742589988 Test RE 0.5171532237371348\n",
      "88 Train Loss 0.8112356 Test MSE 0.3712334830143583 Test RE 0.4402095367433557\n",
      "89 Train Loss 0.71178436 Test MSE 0.2804514436140601 Test RE 0.3826174005356018\n",
      "90 Train Loss 0.60511947 Test MSE 0.21442106569323327 Test RE 0.33455660006786114\n",
      "91 Train Loss 0.54869974 Test MSE 0.13990272812217705 Test RE 0.27023958704681655\n",
      "92 Train Loss 0.51831096 Test MSE 0.14272320624755205 Test RE 0.2729500471312288\n",
      "93 Train Loss 0.4827495 Test MSE 0.14655860332500814 Test RE 0.2765932234698546\n",
      "94 Train Loss 0.44279155 Test MSE 0.11744007107381939 Test RE 0.24759623110621562\n",
      "95 Train Loss 0.41112766 Test MSE 0.1104780919410764 Test RE 0.24014522706934222\n",
      "96 Train Loss 0.37512788 Test MSE 0.09384993753235736 Test RE 0.22133641472731294\n",
      "97 Train Loss 0.35483316 Test MSE 0.07599949630460294 Test RE 0.1991779388571784\n",
      "98 Train Loss 0.33011442 Test MSE 0.06274120059540599 Test RE 0.18097237644151573\n",
      "99 Train Loss 0.30541575 Test MSE 0.054462165352949524 Test RE 0.16861000027211356\n",
      "100 Train Loss 0.28087673 Test MSE 0.040178637401229844 Test RE 0.14482164592126331\n",
      "101 Train Loss 0.26600105 Test MSE 0.0327923788231648 Test RE 0.13083451778951266\n",
      "102 Train Loss 0.24949306 Test MSE 0.028493528771050384 Test RE 0.1219576354936017\n",
      "103 Train Loss 0.22815064 Test MSE 0.024867104023818233 Test RE 0.11393272438253985\n",
      "104 Train Loss 0.21913336 Test MSE 0.023975772883556203 Test RE 0.11187220159627886\n",
      "105 Train Loss 0.19987263 Test MSE 0.022235183831057544 Test RE 0.10773485688402445\n",
      "106 Train Loss 0.18976521 Test MSE 0.020060067248228838 Test RE 0.10232978677565101\n",
      "107 Train Loss 0.17650074 Test MSE 0.017084788588350507 Test RE 0.0944366736395812\n",
      "108 Train Loss 0.15852895 Test MSE 0.016069230616452098 Test RE 0.09158691249302311\n",
      "109 Train Loss 0.15027188 Test MSE 0.016211627430843867 Test RE 0.09199181426189071\n",
      "110 Train Loss 0.14213617 Test MSE 0.013665519939429374 Test RE 0.08445958769079899\n",
      "111 Train Loss 0.13456729 Test MSE 0.009974843062437325 Test RE 0.07215873526197004\n",
      "112 Train Loss 0.12834644 Test MSE 0.009513229705050813 Test RE 0.0704692855651978\n",
      "113 Train Loss 0.11938605 Test MSE 0.009988082862224208 Test RE 0.07220660821559427\n",
      "114 Train Loss 0.112615906 Test MSE 0.009003539138425594 Test RE 0.06855553198707327\n",
      "115 Train Loss 0.108765125 Test MSE 0.007524274372614825 Test RE 0.06267122572899878\n",
      "116 Train Loss 0.10437455 Test MSE 0.007383240583267104 Test RE 0.06208109764097065\n",
      "117 Train Loss 0.101069026 Test MSE 0.007863403630707361 Test RE 0.06406799916448744\n",
      "118 Train Loss 0.09793409 Test MSE 0.008266622152217155 Test RE 0.06569009964493097\n",
      "119 Train Loss 0.094873965 Test MSE 0.00831097046645878 Test RE 0.06586606924712915\n",
      "120 Train Loss 0.09294201 Test MSE 0.008099484138615885 Test RE 0.06502263372848381\n",
      "121 Train Loss 0.089931384 Test MSE 0.007102525379801781 Test RE 0.06088948124328388\n",
      "122 Train Loss 0.08719303 Test MSE 0.006970332468588416 Test RE 0.06032017927432077\n",
      "123 Train Loss 0.08452704 Test MSE 0.006827607305905756 Test RE 0.05969942443772124\n",
      "124 Train Loss 0.08153286 Test MSE 0.0059893172022675535 Test RE 0.05591451138858777\n",
      "125 Train Loss 0.07894393 Test MSE 0.006069177414223855 Test RE 0.05628605275311309\n",
      "126 Train Loss 0.0770484 Test MSE 0.00565153305013793 Test RE 0.054314903558726084\n",
      "127 Train Loss 0.07491105 Test MSE 0.006698306597818666 Test RE 0.05913143084845127\n",
      "128 Train Loss 0.072232544 Test MSE 0.007475577026964159 Test RE 0.06246809142862205\n",
      "129 Train Loss 0.070819154 Test MSE 0.007231389067390684 Test RE 0.061439368199300126\n",
      "130 Train Loss 0.069065765 Test MSE 0.007334752410143773 Test RE 0.06187690833453973\n",
      "131 Train Loss 0.06744817 Test MSE 0.00742370909331859 Test RE 0.0622510024609588\n",
      "132 Train Loss 0.065515034 Test MSE 0.006969506981630898 Test RE 0.060316607350325575\n",
      "133 Train Loss 0.063281 Test MSE 0.006896644875813825 Test RE 0.06000049161029554\n",
      "134 Train Loss 0.061245587 Test MSE 0.00592739851873157 Test RE 0.055624733149303274\n",
      "135 Train Loss 0.059706997 Test MSE 0.00558063675065988 Test RE 0.05397314863598237\n",
      "136 Train Loss 0.05766233 Test MSE 0.0051011031844005765 Test RE 0.05160216595426613\n",
      "137 Train Loss 0.055922598 Test MSE 0.005211143447583031 Test RE 0.052155773544120536\n",
      "138 Train Loss 0.05519338 Test MSE 0.004995338463229245 Test RE 0.05106441214500807\n",
      "139 Train Loss 0.05377465 Test MSE 0.004984319170237506 Test RE 0.05100805916918751\n",
      "140 Train Loss 0.051773384 Test MSE 0.004706788216782117 Test RE 0.049567635865231226\n",
      "141 Train Loss 0.05015013 Test MSE 0.004472210740129618 Test RE 0.04831667134432626\n",
      "142 Train Loss 0.04938908 Test MSE 0.0043564301275129174 Test RE 0.047687137426637945\n",
      "143 Train Loss 0.04871099 Test MSE 0.004168641795349748 Test RE 0.04664801479420097\n",
      "144 Train Loss 0.04685898 Test MSE 0.003978777439657341 Test RE 0.04557332339351182\n",
      "145 Train Loss 0.044759102 Test MSE 0.0038840814885404184 Test RE 0.045027728970960156\n",
      "146 Train Loss 0.043798465 Test MSE 0.003592397846920507 Test RE 0.04330400763029061\n",
      "147 Train Loss 0.043168046 Test MSE 0.0035337760569591056 Test RE 0.042949230660785785\n",
      "148 Train Loss 0.042261347 Test MSE 0.003615141352697988 Test RE 0.04344087039934081\n",
      "149 Train Loss 0.041727852 Test MSE 0.0037343194639916193 Test RE 0.044151108415508775\n",
      "150 Train Loss 0.040891137 Test MSE 0.003688396944866129 Test RE 0.043878796135438186\n",
      "151 Train Loss 0.040039383 Test MSE 0.00378158415976341 Test RE 0.04442963669182824\n",
      "152 Train Loss 0.039233033 Test MSE 0.0038261992689383705 Test RE 0.044690958488611536\n",
      "153 Train Loss 0.038044043 Test MSE 0.003746204886879522 Test RE 0.04422131367263804\n",
      "154 Train Loss 0.037062664 Test MSE 0.003578640269031622 Test RE 0.04322100878627607\n",
      "155 Train Loss 0.036410313 Test MSE 0.003494392000742888 Test RE 0.04270922473891531\n",
      "156 Train Loss 0.035940118 Test MSE 0.0033737842197994715 Test RE 0.04196570546085171\n",
      "157 Train Loss 0.035328124 Test MSE 0.0032264318453303193 Test RE 0.04103903353914331\n",
      "158 Train Loss 0.034555264 Test MSE 0.003084102548445693 Test RE 0.040123636012675046\n",
      "159 Train Loss 0.0334096 Test MSE 0.0028155409394777743 Test RE 0.03833688306637982\n",
      "160 Train Loss 0.03277204 Test MSE 0.0027753997945435156 Test RE 0.0380626176877269\n",
      "161 Train Loss 0.032181773 Test MSE 0.002667083668454645 Test RE 0.03731248697933427\n",
      "162 Train Loss 0.031597823 Test MSE 0.002674715392958511 Test RE 0.037365832738578394\n",
      "163 Train Loss 0.031133307 Test MSE 0.0025953271027993946 Test RE 0.036807127698766574\n",
      "164 Train Loss 0.03058723 Test MSE 0.002563790617115152 Test RE 0.036582817776856694\n",
      "165 Train Loss 0.029648196 Test MSE 0.0027454947031332437 Test RE 0.037856998858428755\n",
      "166 Train Loss 0.02858061 Test MSE 0.003222767940482159 Test RE 0.04101572515496874\n",
      "167 Train Loss 0.027754864 Test MSE 0.0036884639465420716 Test RE 0.04387919467436607\n",
      "168 Train Loss 0.027156387 Test MSE 0.00396621705830998 Test RE 0.045501332586894844\n",
      "169 Train Loss 0.02682396 Test MSE 0.0040473226967671465 Test RE 0.045964209254492135\n",
      "170 Train Loss 0.026323384 Test MSE 0.0048210338246114925 Test RE 0.05016559482663448\n",
      "171 Train Loss 0.025935147 Test MSE 0.005009608934812393 Test RE 0.05113729945290074\n",
      "172 Train Loss 0.02553242 Test MSE 0.0054029611773837236 Test RE 0.053107003844287445\n",
      "173 Train Loss 0.024889532 Test MSE 0.005180864209438776 Test RE 0.05200402778778748\n",
      "174 Train Loss 0.024456102 Test MSE 0.00478734606188155 Test RE 0.049990017418674704\n",
      "175 Train Loss 0.023845589 Test MSE 0.004530572095930081 Test RE 0.04863091038900033\n",
      "176 Train Loss 0.023128517 Test MSE 0.004234616258097982 Test RE 0.04701570006901411\n",
      "177 Train Loss 0.02261954 Test MSE 0.003567558273894995 Test RE 0.04315403552834365\n",
      "178 Train Loss 0.022073336 Test MSE 0.003525696877883843 Test RE 0.042900105719333496\n",
      "179 Train Loss 0.021517938 Test MSE 0.003360611302422933 Test RE 0.041883697928340326\n",
      "180 Train Loss 0.020651395 Test MSE 0.002811097472815524 Test RE 0.03830661962334121\n",
      "181 Train Loss 0.020155443 Test MSE 0.0028860166934733095 Test RE 0.038813722480368164\n",
      "182 Train Loss 0.01987288 Test MSE 0.0027488663042788486 Test RE 0.03788023684500786\n",
      "183 Train Loss 0.01948959 Test MSE 0.002601333190781378 Test RE 0.03684969248703928\n",
      "184 Train Loss 0.01918979 Test MSE 0.0024731710547452397 Test RE 0.03593047465177227\n",
      "185 Train Loss 0.018911336 Test MSE 0.0023911351100877145 Test RE 0.035329536117233884\n",
      "186 Train Loss 0.018672053 Test MSE 0.002416883818274899 Test RE 0.03551924811482963\n",
      "187 Train Loss 0.018492443 Test MSE 0.0024075463574863144 Test RE 0.03545056865655897\n",
      "188 Train Loss 0.018219272 Test MSE 0.002460854129553495 Test RE 0.03584089222151837\n",
      "189 Train Loss 0.018005526 Test MSE 0.0024973940184112734 Test RE 0.03610600271633131\n",
      "190 Train Loss 0.017730486 Test MSE 0.0024685877072699687 Test RE 0.035897165548675704\n",
      "191 Train Loss 0.017409638 Test MSE 0.0024344933167765558 Test RE 0.03564841050221626\n",
      "192 Train Loss 0.017036956 Test MSE 0.0023418160247240275 Test RE 0.03496328768227593\n",
      "193 Train Loss 0.01679855 Test MSE 0.002145790043687863 Test RE 0.0334679791554626\n",
      "194 Train Loss 0.016291304 Test MSE 0.002202183060284465 Test RE 0.033904909204925435\n",
      "195 Train Loss 0.016016949 Test MSE 0.002336421157867538 Test RE 0.03492299180975116\n",
      "196 Train Loss 0.015742961 Test MSE 0.0023973507699674773 Test RE 0.03537542517144763\n",
      "197 Train Loss 0.01564249 Test MSE 0.0022782329021346034 Test RE 0.03448537371077903\n",
      "198 Train Loss 0.015475999 Test MSE 0.002502500517772112 Test RE 0.036142897400389874\n",
      "199 Train Loss 0.015314325 Test MSE 0.002435886455327508 Test RE 0.03565860894303845\n",
      "200 Train Loss 0.015187396 Test MSE 0.0023281314690567377 Test RE 0.03486098287372471\n",
      "201 Train Loss 0.015082554 Test MSE 0.0022689804890786594 Test RE 0.034415276062338386\n",
      "202 Train Loss 0.014993572 Test MSE 0.0021805057352467035 Test RE 0.03373762398176837\n",
      "203 Train Loss 0.014883016 Test MSE 0.0021670192345544467 Test RE 0.03363312798861342\n",
      "204 Train Loss 0.014713667 Test MSE 0.002263283344322014 Test RE 0.03437204253923527\n",
      "205 Train Loss 0.014618531 Test MSE 0.0023215831241741197 Test RE 0.034811921536288794\n",
      "206 Train Loss 0.014500527 Test MSE 0.002301093810031755 Test RE 0.03465796341770697\n",
      "207 Train Loss 0.014383942 Test MSE 0.0022778117578922505 Test RE 0.034482186155237314\n",
      "208 Train Loss 0.014249803 Test MSE 0.002292160473030397 Test RE 0.03459062319355022\n",
      "209 Train Loss 0.01409622 Test MSE 0.0023823254954750727 Test RE 0.03526439408506696\n",
      "210 Train Loss 0.013940349 Test MSE 0.002373235632899519 Test RE 0.03519705340304664\n",
      "211 Train Loss 0.013764775 Test MSE 0.0024051431370889467 Test RE 0.035432870804000816\n",
      "212 Train Loss 0.013577524 Test MSE 0.0023518168457380717 Test RE 0.03503786422083956\n",
      "213 Train Loss 0.013476065 Test MSE 0.0023395485230908214 Test RE 0.0349463566955431\n",
      "214 Train Loss 0.013365641 Test MSE 0.0024173907591103524 Test RE 0.03552297299665473\n",
      "215 Train Loss 0.013229417 Test MSE 0.0024842809414786426 Test RE 0.036011086991076885\n",
      "216 Train Loss 0.013146633 Test MSE 0.0023960775968367445 Test RE 0.035366030421470546\n",
      "217 Train Loss 0.013050986 Test MSE 0.002313654090717781 Test RE 0.03475242313370594\n",
      "218 Train Loss 0.012963427 Test MSE 0.002341239123750943 Test RE 0.034958980854400426\n",
      "219 Train Loss 0.012814731 Test MSE 0.002290188528973774 Test RE 0.034575740847536854\n",
      "220 Train Loss 0.012570712 Test MSE 0.0020722637600645165 Test RE 0.032889584949659795\n",
      "221 Train Loss 0.0123998895 Test MSE 0.002095041354109563 Test RE 0.03306984633311535\n",
      "222 Train Loss 0.012239128 Test MSE 0.0023128121596756738 Test RE 0.034746099412659465\n",
      "223 Train Loss 0.012125524 Test MSE 0.002335087953876015 Test RE 0.034913026543914163\n",
      "224 Train Loss 0.011990122 Test MSE 0.0023401252723475956 Test RE 0.03495066394607177\n",
      "225 Train Loss 0.011906584 Test MSE 0.0022297219338665553 Test RE 0.034116245420702115\n",
      "226 Train Loss 0.011800181 Test MSE 0.002134642979057609 Test RE 0.03338093534122692\n",
      "227 Train Loss 0.011682276 Test MSE 0.001904572661566008 Test RE 0.031530775325713606\n",
      "228 Train Loss 0.011524846 Test MSE 0.0018299052165097788 Test RE 0.030906524781467607\n",
      "229 Train Loss 0.011382751 Test MSE 0.0017170538474632262 Test RE 0.02993834814692155\n",
      "230 Train Loss 0.011177492 Test MSE 0.0016719700041836632 Test RE 0.02954269547275674\n",
      "231 Train Loss 0.011041999 Test MSE 0.001615651317842149 Test RE 0.029040874932707968\n",
      "232 Train Loss 0.01093608 Test MSE 0.0014963691912851513 Test RE 0.027948290957903823\n",
      "233 Train Loss 0.010766678 Test MSE 0.0013916711104903228 Test RE 0.02695281825508007\n",
      "234 Train Loss 0.010655747 Test MSE 0.0013850151801487987 Test RE 0.026888287529083846\n",
      "235 Train Loss 0.010534817 Test MSE 0.0014394318610147692 Test RE 0.02741141359849697\n",
      "236 Train Loss 0.010437242 Test MSE 0.0013098918491720984 Test RE 0.02614891038910933\n",
      "237 Train Loss 0.010326613 Test MSE 0.0012414277592071898 Test RE 0.025456377524074435\n",
      "238 Train Loss 0.010201156 Test MSE 0.0012390179192336504 Test RE 0.025431657762700025\n",
      "239 Train Loss 0.010112634 Test MSE 0.0013009629146573283 Test RE 0.026059635402233605\n",
      "240 Train Loss 0.0100026755 Test MSE 0.0012579976355620323 Test RE 0.025625703054088275\n",
      "241 Train Loss 0.009895796 Test MSE 0.0011976571788015076 Test RE 0.025003576701593436\n",
      "242 Train Loss 0.009805918 Test MSE 0.001227558590458304 Test RE 0.025313779443429697\n",
      "243 Train Loss 0.009658395 Test MSE 0.001191355139356805 Test RE 0.02493770586497381\n",
      "244 Train Loss 0.009559794 Test MSE 0.0012153932764297282 Test RE 0.02518803520520317\n",
      "245 Train Loss 0.009470159 Test MSE 0.001255614167669578 Test RE 0.025601415648225035\n",
      "246 Train Loss 0.009361871 Test MSE 0.0011470522863641559 Test RE 0.024469634609891645\n",
      "247 Train Loss 0.009269166 Test MSE 0.0011078806351104275 Test RE 0.0240481882289944\n",
      "248 Train Loss 0.009210763 Test MSE 0.0010562394769213744 Test RE 0.023481026274121686\n",
      "249 Train Loss 0.009119886 Test MSE 0.0010581384317600142 Test RE 0.023502124418158882\n",
      "250 Train Loss 0.008980925 Test MSE 0.0010277354608141099 Test RE 0.023162026155445298\n",
      "251 Train Loss 0.008820014 Test MSE 0.0011368317789247592 Test RE 0.024360375565514156\n",
      "252 Train Loss 0.008718162 Test MSE 0.001089222904076967 Test RE 0.02384483158774566\n",
      "253 Train Loss 0.008622898 Test MSE 0.001098489738808486 Test RE 0.023946049676500145\n",
      "254 Train Loss 0.008489766 Test MSE 0.001244417472741981 Test RE 0.025487012214224895\n",
      "255 Train Loss 0.008398598 Test MSE 0.0011899426002795845 Test RE 0.02492291769207715\n",
      "256 Train Loss 0.008317282 Test MSE 0.0011922807306375682 Test RE 0.024947391323503668\n",
      "257 Train Loss 0.008221978 Test MSE 0.0011571866917725294 Test RE 0.024577493623245555\n",
      "258 Train Loss 0.0081068175 Test MSE 0.0011347816786608331 Test RE 0.024338400569327533\n",
      "259 Train Loss 0.00799963 Test MSE 0.0011461137689658953 Test RE 0.024459622042230397\n",
      "260 Train Loss 0.007931036 Test MSE 0.0011752909109493076 Test RE 0.02476900527733278\n",
      "261 Train Loss 0.0078355605 Test MSE 0.0011654823747205636 Test RE 0.024665432324837585\n",
      "262 Train Loss 0.007682513 Test MSE 0.0010661410404108366 Test RE 0.023590829275660054\n",
      "263 Train Loss 0.0075179613 Test MSE 0.0009659426666550393 Test RE 0.0224549220478769\n",
      "264 Train Loss 0.0074376552 Test MSE 0.0009536184583873073 Test RE 0.022311213972629557\n",
      "265 Train Loss 0.0073871547 Test MSE 0.0009510497909591936 Test RE 0.022281144958760372\n",
      "266 Train Loss 0.007312882 Test MSE 0.0010491492306504847 Test RE 0.023402082720844077\n",
      "267 Train Loss 0.0072364355 Test MSE 0.0010417702576759412 Test RE 0.023319640663764317\n",
      "268 Train Loss 0.0070723495 Test MSE 0.001070337041720286 Test RE 0.023637206791519833\n",
      "269 Train Loss 0.0069352835 Test MSE 0.0010629086608615625 Test RE 0.023555040202239357\n",
      "270 Train Loss 0.006840714 Test MSE 0.0010195455442117223 Test RE 0.023069553676794446\n",
      "271 Train Loss 0.0067500095 Test MSE 0.0009930427467688433 Test RE 0.022767736091615434\n",
      "272 Train Loss 0.006621285 Test MSE 0.0008747921128765616 Test RE 0.021369202092488652\n",
      "273 Train Loss 0.0065134014 Test MSE 0.0008939767221545201 Test RE 0.021602249719752373\n",
      "274 Train Loss 0.0063967053 Test MSE 0.0008750999548271669 Test RE 0.021372961704701616\n",
      "275 Train Loss 0.0063143023 Test MSE 0.0008749307318785957 Test RE 0.021370895100511832\n",
      "276 Train Loss 0.0062162043 Test MSE 0.0008741136704593153 Test RE 0.021360914074726758\n",
      "277 Train Loss 0.0061288355 Test MSE 0.000818383389041282 Test RE 0.020668753214058627\n",
      "278 Train Loss 0.006019638 Test MSE 0.0008148999731400885 Test RE 0.02062471844865587\n",
      "279 Train Loss 0.005952899 Test MSE 0.0008149043191249487 Test RE 0.02062477344595466\n",
      "280 Train Loss 0.0058203507 Test MSE 0.00078854438675189 Test RE 0.020288453745151\n",
      "281 Train Loss 0.00569053 Test MSE 0.0007521042630129273 Test RE 0.019814125163476467\n",
      "282 Train Loss 0.005629403 Test MSE 0.0007485780369664692 Test RE 0.01976762152350125\n",
      "283 Train Loss 0.0055835294 Test MSE 0.0007314040377167676 Test RE 0.01953954982257621\n",
      "284 Train Loss 0.005534786 Test MSE 0.0007263306995211479 Test RE 0.019471664466697534\n",
      "285 Train Loss 0.0055021057 Test MSE 0.0007327062555771636 Test RE 0.019556936543073347\n",
      "286 Train Loss 0.005437091 Test MSE 0.0006865006551312905 Test RE 0.018930250237445705\n",
      "287 Train Loss 0.005393209 Test MSE 0.0006845378811580617 Test RE 0.018903169128151123\n",
      "288 Train Loss 0.0053367284 Test MSE 0.0006736033500797642 Test RE 0.018751585570980934\n",
      "289 Train Loss 0.0052765883 Test MSE 0.0006368847215024315 Test RE 0.018233342592796062\n",
      "290 Train Loss 0.0051937113 Test MSE 0.0006450435380543366 Test RE 0.01834976012410506\n",
      "291 Train Loss 0.0051362375 Test MSE 0.0006397035848252103 Test RE 0.018273648595685386\n",
      "292 Train Loss 0.005080909 Test MSE 0.0006573592913194769 Test RE 0.018524106950994962\n",
      "293 Train Loss 0.0049701957 Test MSE 0.0007453327265517241 Test RE 0.019724725695962078\n",
      "294 Train Loss 0.004839619 Test MSE 0.0007492354686625612 Test RE 0.019776299983316446\n",
      "295 Train Loss 0.0047768992 Test MSE 0.0007726762209759863 Test RE 0.020083280334103063\n",
      "296 Train Loss 0.004694212 Test MSE 0.0007994708561699928 Test RE 0.020428533692657812\n",
      "297 Train Loss 0.0046162256 Test MSE 0.0007356196787883971 Test RE 0.019595779602915878\n",
      "298 Train Loss 0.0045156055 Test MSE 0.0006250969606899185 Test RE 0.018063818899684916\n",
      "299 Train Loss 0.004447303 Test MSE 0.0006410439452717486 Test RE 0.018292782816366766\n",
      "Training time: 172.44\n",
      "KG_tanh_high\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58771.27 Test MSE 4.076287406839724 Test RE 1.4587077001900326\n",
      "1 Train Loss 35425.895 Test MSE 7.148071504164979 Test RE 1.9316583733846686\n",
      "2 Train Loss 22676.074 Test MSE 11.899946266571456 Test RE 2.492346252295926\n",
      "3 Train Loss 10264.701 Test MSE 10.976697603800142 Test RE 2.3937110626326823\n",
      "4 Train Loss 4374.32 Test MSE 13.233479959940285 Test RE 2.6282877380691536\n",
      "5 Train Loss 2564.2742 Test MSE 15.693534926167084 Test RE 2.8621755405392557\n",
      "6 Train Loss 1214.3257 Test MSE 20.5368975174952 Test RE 3.274185605454586\n",
      "7 Train Loss 781.6623 Test MSE 22.70804912054527 Test RE 3.44291094567253\n",
      "8 Train Loss 550.2291 Test MSE 23.156086655099276 Test RE 3.476709945687325\n",
      "9 Train Loss 414.0776 Test MSE 22.879894347491017 Test RE 3.4559136630776357\n",
      "10 Train Loss 313.18088 Test MSE 23.27955465622263 Test RE 3.4859665128407804\n",
      "11 Train Loss 216.93341 Test MSE 23.302110009124206 Test RE 3.487654864915861\n",
      "12 Train Loss 179.97408 Test MSE 23.222220378223884 Test RE 3.4816711431920955\n",
      "13 Train Loss 143.12561 Test MSE 22.942338941946453 Test RE 3.460626448900631\n",
      "14 Train Loss 120.697845 Test MSE 22.67870284615686 Test RE 3.440685539319491\n",
      "15 Train Loss 103.89042 Test MSE 22.280681381209654 Test RE 3.4103590980131266\n",
      "16 Train Loss 92.92522 Test MSE 21.822196844373224 Test RE 3.3750880817978937\n",
      "17 Train Loss 78.13982 Test MSE 21.166531146520025 Test RE 3.323997755699874\n",
      "18 Train Loss 69.86737 Test MSE 20.654831588447735 Test RE 3.2835732276444483\n",
      "19 Train Loss 63.71662 Test MSE 20.089007043836926 Test RE 3.23828532998024\n",
      "20 Train Loss 59.778194 Test MSE 19.786782456559145 Test RE 3.213834188231677\n",
      "21 Train Loss 56.865097 Test MSE 19.51544073909164 Test RE 3.191722012487626\n",
      "22 Train Loss 54.211403 Test MSE 19.307262920330004 Test RE 3.1746527795387913\n",
      "23 Train Loss 52.22161 Test MSE 18.94974585679485 Test RE 3.145122545463494\n",
      "24 Train Loss 49.81688 Test MSE 18.176332559230172 Test RE 3.0802715662611937\n",
      "25 Train Loss 47.026566 Test MSE 17.702908530806862 Test RE 3.0398922460084545\n",
      "26 Train Loss 44.630554 Test MSE 17.26942222922394 Test RE 3.0024430662745094\n",
      "27 Train Loss 42.30393 Test MSE 16.85773546439301 Test RE 2.9664394913861014\n",
      "28 Train Loss 39.52989 Test MSE 16.461328462100916 Test RE 2.9313543294707314\n",
      "29 Train Loss 37.49208 Test MSE 16.13618900475799 Test RE 2.902260312129925\n",
      "30 Train Loss 35.51264 Test MSE 15.77499124936398 Test RE 2.8695938994969397\n",
      "31 Train Loss 33.232872 Test MSE 15.35487588648432 Test RE 2.8311249172391455\n",
      "32 Train Loss 31.475368 Test MSE 15.000167241354058 Test RE 2.7982333446285748\n",
      "33 Train Loss 28.950872 Test MSE 14.79417128264449 Test RE 2.778952977445623\n",
      "34 Train Loss 26.89987 Test MSE 14.455090719512897 Test RE 2.7469217475441625\n",
      "35 Train Loss 25.506943 Test MSE 14.336279901709748 Test RE 2.7356095594253937\n",
      "36 Train Loss 24.275486 Test MSE 14.208784011856284 Test RE 2.7234181859275437\n",
      "37 Train Loss 23.307615 Test MSE 14.074102870181056 Test RE 2.7104801893777024\n",
      "38 Train Loss 22.485498 Test MSE 14.03653367131942 Test RE 2.706860114361712\n",
      "39 Train Loss 22.015121 Test MSE 13.991837013626139 Test RE 2.7025469387616914\n",
      "40 Train Loss 21.550182 Test MSE 13.94187330997587 Test RE 2.697717336525481\n",
      "41 Train Loss 21.15989 Test MSE 13.908519184905716 Test RE 2.6944884346308626\n",
      "42 Train Loss 20.753912 Test MSE 13.853232130003809 Test RE 2.689127739357696\n",
      "43 Train Loss 20.375517 Test MSE 13.782632063684149 Test RE 2.6822667014719466\n",
      "44 Train Loss 20.057213 Test MSE 13.716629004513962 Test RE 2.6758364975667783\n",
      "45 Train Loss 19.74542 Test MSE 13.640035185034607 Test RE 2.6683550874634983\n",
      "46 Train Loss 19.376076 Test MSE 13.564001957874853 Test RE 2.6609076297210774\n",
      "47 Train Loss 19.114311 Test MSE 13.51378169940253 Test RE 2.6559771014609637\n",
      "48 Train Loss 18.88204 Test MSE 13.467467381932941 Test RE 2.6514219242017423\n",
      "49 Train Loss 18.63143 Test MSE 13.382882438612748 Test RE 2.643082433932192\n",
      "50 Train Loss 18.385967 Test MSE 13.278059614876254 Test RE 2.632710975588008\n",
      "51 Train Loss 18.228037 Test MSE 13.19722489803749 Test RE 2.624684978671944\n",
      "52 Train Loss 18.08657 Test MSE 13.132902796815054 Test RE 2.61828092528805\n",
      "53 Train Loss 17.96334 Test MSE 13.092064348409336 Test RE 2.614206815128369\n",
      "54 Train Loss 17.785069 Test MSE 12.963174345017382 Test RE 2.6013066902466355\n",
      "55 Train Loss 17.65274 Test MSE 12.904594971160954 Test RE 2.5954225042373316\n",
      "56 Train Loss 17.498272 Test MSE 12.824211361890072 Test RE 2.5873263440499317\n",
      "57 Train Loss 17.31373 Test MSE 12.669461217286539 Test RE 2.5716682916898366\n",
      "58 Train Loss 17.133791 Test MSE 12.437384961810105 Test RE 2.5480058179338223\n",
      "59 Train Loss 16.816061 Test MSE 12.005505305103547 Test RE 2.5033760840399144\n",
      "60 Train Loss 16.503115 Test MSE 11.695897751623582 Test RE 2.4708857136192237\n",
      "61 Train Loss 16.150585 Test MSE 11.326185256895988 Test RE 2.4315192229756475\n",
      "62 Train Loss 15.816527 Test MSE 10.942130391140248 Test RE 2.3899390189696974\n",
      "63 Train Loss 15.450967 Test MSE 10.539395262402952 Test RE 2.3455447494617565\n",
      "64 Train Loss 14.873321 Test MSE 10.014903789394864 Test RE 2.286437148557893\n",
      "65 Train Loss 14.315017 Test MSE 9.528750928146328 Test RE 2.230251624785779\n",
      "66 Train Loss 13.679147 Test MSE 9.058746612394089 Test RE 2.17455267823987\n",
      "67 Train Loss 13.186259 Test MSE 8.813380597865237 Test RE 2.1449004457029943\n",
      "68 Train Loss 12.613657 Test MSE 8.611148986127885 Test RE 2.1201492203659464\n",
      "69 Train Loss 12.142034 Test MSE 8.267324131860798 Test RE 2.0773915436889334\n",
      "70 Train Loss 11.608549 Test MSE 7.892197330453212 Test RE 2.02971398760911\n",
      "71 Train Loss 10.799301 Test MSE 7.451154583985871 Test RE 1.9721850559173495\n",
      "72 Train Loss 9.981071 Test MSE 6.967926240780764 Test RE 1.9071622828572081\n",
      "73 Train Loss 9.168361 Test MSE 6.602735640693391 Test RE 1.8565123029180222\n",
      "74 Train Loss 8.674851 Test MSE 6.237933992899664 Test RE 1.8044974154320257\n",
      "75 Train Loss 8.127093 Test MSE 5.887613689997963 Test RE 1.7530953190059\n",
      "76 Train Loss 7.679448 Test MSE 5.556655346636401 Test RE 1.703109639667494\n",
      "77 Train Loss 7.141529 Test MSE 5.247993666510072 Test RE 1.655131591042087\n",
      "78 Train Loss 6.696777 Test MSE 4.937178031428589 Test RE 1.6053704727812421\n",
      "79 Train Loss 6.086465 Test MSE 4.417071807395396 Test RE 1.5184591281998376\n",
      "80 Train Loss 5.595264 Test MSE 3.8525117309978314 Test RE 1.4181032809296934\n",
      "81 Train Loss 5.181114 Test MSE 3.5258270938263627 Test RE 1.3566455114169473\n",
      "82 Train Loss 4.7463055 Test MSE 3.1498038664180346 Test RE 1.2822645412057043\n",
      "83 Train Loss 4.3260474 Test MSE 2.880159902369142 Test RE 1.2261516215467232\n",
      "84 Train Loss 3.847967 Test MSE 2.47732457105024 Test RE 1.137175074672844\n",
      "85 Train Loss 3.444486 Test MSE 2.200033605701268 Test RE 1.0716439939039242\n",
      "86 Train Loss 3.1690955 Test MSE 2.0557206880450067 Test RE 1.0359002315358954\n",
      "87 Train Loss 2.8359396 Test MSE 1.873020377433555 Test RE 0.9887969725319277\n",
      "88 Train Loss 2.6360927 Test MSE 1.7066300016698088 Test RE 0.9438556174495545\n",
      "89 Train Loss 2.3685768 Test MSE 1.6146649759339378 Test RE 0.9180727339912944\n",
      "90 Train Loss 2.1287062 Test MSE 1.389858658995543 Test RE 0.8517677556037755\n",
      "91 Train Loss 1.8843192 Test MSE 1.2010113345658175 Test RE 0.7917889379272853\n",
      "92 Train Loss 1.7286049 Test MSE 1.1356235046261625 Test RE 0.7699332287234599\n",
      "93 Train Loss 1.6074357 Test MSE 1.0832154924025208 Test RE 0.7519575224189518\n",
      "94 Train Loss 1.4973165 Test MSE 1.0105665119837712 Test RE 0.7263038197094797\n",
      "95 Train Loss 1.3788953 Test MSE 0.9125623719357421 Test RE 0.6901876049899034\n",
      "96 Train Loss 1.2647445 Test MSE 0.8175774377043197 Test RE 0.6532814490050293\n",
      "97 Train Loss 1.1795176 Test MSE 0.789986577717675 Test RE 0.6421636716768067\n",
      "98 Train Loss 1.0978577 Test MSE 0.720214284280017 Test RE 0.6131500135794364\n",
      "99 Train Loss 1.0403587 Test MSE 0.6700828841396287 Test RE 0.5914256275411637\n",
      "100 Train Loss 0.96436083 Test MSE 0.6027040291530695 Test RE 0.5609032085067924\n",
      "101 Train Loss 0.9067983 Test MSE 0.5214810319632751 Test RE 0.5217412027728164\n",
      "102 Train Loss 0.8538428 Test MSE 0.4525140077663162 Test RE 0.486017481533457\n",
      "103 Train Loss 0.80981857 Test MSE 0.40946617230741467 Test RE 0.46232235240054176\n",
      "104 Train Loss 0.7650041 Test MSE 0.3489077062286658 Test RE 0.4267673220778075\n",
      "105 Train Loss 0.72045594 Test MSE 0.3164850812482342 Test RE 0.40645502606074085\n",
      "106 Train Loss 0.68245864 Test MSE 0.29431158592365847 Test RE 0.39195802111366634\n",
      "107 Train Loss 0.6449875 Test MSE 0.25819512459221183 Test RE 0.36712156461236767\n",
      "108 Train Loss 0.606984 Test MSE 0.24328563057537667 Test RE 0.35636423068534406\n",
      "109 Train Loss 0.56978506 Test MSE 0.22718947622158306 Test RE 0.34437370419441654\n",
      "110 Train Loss 0.5350746 Test MSE 0.21664767089105286 Test RE 0.33628917602217023\n",
      "111 Train Loss 0.5070594 Test MSE 0.1919100436604227 Test RE 0.3165080272364981\n",
      "112 Train Loss 0.47663963 Test MSE 0.19470990719554973 Test RE 0.31880850722611664\n",
      "113 Train Loss 0.45112228 Test MSE 0.18114064190708468 Test RE 0.3074990852008444\n",
      "114 Train Loss 0.42583874 Test MSE 0.1563680772895347 Test RE 0.2856997924856253\n",
      "115 Train Loss 0.3946521 Test MSE 0.13699041660850414 Test RE 0.2674120480060228\n",
      "116 Train Loss 0.3672363 Test MSE 0.11982999893506296 Test RE 0.25010285802955123\n",
      "117 Train Loss 0.35163677 Test MSE 0.1169337243639027 Test RE 0.24706189490529032\n",
      "118 Train Loss 0.33926725 Test MSE 0.10857412393718874 Test RE 0.2380669148028815\n",
      "119 Train Loss 0.3245418 Test MSE 0.10208236796828277 Test RE 0.23084009519230947\n",
      "120 Train Loss 0.30878562 Test MSE 0.09069426608631237 Test RE 0.21758341675164755\n",
      "121 Train Loss 0.29380792 Test MSE 0.08370559281425391 Test RE 0.2090321632922797\n",
      "122 Train Loss 0.27942324 Test MSE 0.07532684230909723 Test RE 0.19829454084891743\n",
      "123 Train Loss 0.26938617 Test MSE 0.06637310087455937 Test RE 0.18613666602995443\n",
      "124 Train Loss 0.25936532 Test MSE 0.06102699955154301 Test RE 0.17848301183275556\n",
      "125 Train Loss 0.24777976 Test MSE 0.056811756733366116 Test RE 0.17220865955194178\n",
      "126 Train Loss 0.23395123 Test MSE 0.05131696497085766 Test RE 0.16366897343072612\n",
      "127 Train Loss 0.22565241 Test MSE 0.04564622197384384 Test RE 0.1543612532150633\n",
      "128 Train Loss 0.21947728 Test MSE 0.04315999960339748 Test RE 0.15009858320119523\n",
      "129 Train Loss 0.21154848 Test MSE 0.04326169554615369 Test RE 0.15027531438667116\n",
      "130 Train Loss 0.20435572 Test MSE 0.041812785210134214 Test RE 0.14773739113827195\n",
      "131 Train Loss 0.19917715 Test MSE 0.042111562752129864 Test RE 0.14826428789982343\n",
      "132 Train Loss 0.19241913 Test MSE 0.04002619364339187 Test RE 0.1445466473377052\n",
      "133 Train Loss 0.18542308 Test MSE 0.03889597640079522 Test RE 0.14249125642222923\n",
      "134 Train Loss 0.1784528 Test MSE 0.03562529972334579 Test RE 0.13636883813421388\n",
      "135 Train Loss 0.17106356 Test MSE 0.03475989022133665 Test RE 0.13470231977580885\n",
      "136 Train Loss 0.16599758 Test MSE 0.03476356117132769 Test RE 0.1347094324626098\n",
      "137 Train Loss 0.15872842 Test MSE 0.03222583429410139 Test RE 0.1296993984153724\n",
      "138 Train Loss 0.15356152 Test MSE 0.030896996136231997 Test RE 0.12699715915384988\n",
      "139 Train Loss 0.14741705 Test MSE 0.027785865716195835 Test RE 0.1204336484404054\n",
      "140 Train Loss 0.14283256 Test MSE 0.025886814553902508 Test RE 0.11624524125721362\n",
      "141 Train Loss 0.138253 Test MSE 0.023123677447877813 Test RE 0.10986625683779384\n",
      "142 Train Loss 0.13461146 Test MSE 0.022291824880495657 Test RE 0.10787198941699905\n",
      "143 Train Loss 0.12988816 Test MSE 0.019231120820834682 Test RE 0.100193183302189\n",
      "144 Train Loss 0.124186605 Test MSE 0.01614992219127124 Test RE 0.09181657619063482\n",
      "145 Train Loss 0.12128459 Test MSE 0.014715516631154514 Test RE 0.08764429134021236\n",
      "146 Train Loss 0.11591627 Test MSE 0.01348151143700681 Test RE 0.0838890293065776\n",
      "147 Train Loss 0.11256977 Test MSE 0.013218975750340367 Test RE 0.08306819616958178\n",
      "148 Train Loss 0.10908133 Test MSE 0.011542564509773034 Test RE 0.07762239384998972\n",
      "149 Train Loss 0.1069888 Test MSE 0.01122501704715735 Test RE 0.07654721271295192\n",
      "150 Train Loss 0.10435191 Test MSE 0.010334272979128452 Test RE 0.07344730104967007\n",
      "151 Train Loss 0.101408556 Test MSE 0.009448168922623333 Test RE 0.07022790315701403\n",
      "152 Train Loss 0.09907918 Test MSE 0.009082669936028328 Test RE 0.06885613524837995\n",
      "153 Train Loss 0.096155986 Test MSE 0.008404941939859889 Test RE 0.0662373937323787\n",
      "154 Train Loss 0.09420631 Test MSE 0.008222423663802058 Test RE 0.06551425428073651\n",
      "155 Train Loss 0.09075714 Test MSE 0.007342067807342802 Test RE 0.06190775745717796\n",
      "156 Train Loss 0.08810903 Test MSE 0.007368910884240894 Test RE 0.06202082359879636\n",
      "157 Train Loss 0.0862655 Test MSE 0.007013537404330994 Test RE 0.060506834895715816\n",
      "158 Train Loss 0.083694346 Test MSE 0.007269511957645784 Test RE 0.06160110527219183\n",
      "159 Train Loss 0.080972575 Test MSE 0.007336858890880913 Test RE 0.06188579296698611\n",
      "160 Train Loss 0.07917832 Test MSE 0.007133850674888126 Test RE 0.06102360835943106\n",
      "161 Train Loss 0.07733005 Test MSE 0.0071459351977116664 Test RE 0.06107527254369633\n",
      "162 Train Loss 0.075071774 Test MSE 0.007545568075210594 Test RE 0.06275984288653623\n",
      "163 Train Loss 0.07381386 Test MSE 0.00789182626467801 Test RE 0.06418368308693077\n",
      "164 Train Loss 0.07248176 Test MSE 0.007389882471199818 Test RE 0.0621090151249713\n",
      "165 Train Loss 0.071181156 Test MSE 0.00739556941316021 Test RE 0.06213290876859777\n",
      "166 Train Loss 0.06965094 Test MSE 0.006639113140722623 Test RE 0.058869576528038405\n",
      "167 Train Loss 0.06753449 Test MSE 0.006389335816233901 Test RE 0.0577515618983274\n",
      "168 Train Loss 0.06544468 Test MSE 0.006517598271609814 Test RE 0.05832834727840513\n",
      "169 Train Loss 0.063670136 Test MSE 0.00723706977724723 Test RE 0.06146349570122558\n",
      "170 Train Loss 0.062360235 Test MSE 0.0071266871230053 Test RE 0.06099296182636831\n",
      "171 Train Loss 0.060880825 Test MSE 0.007134167330935603 Test RE 0.06102496269673635\n",
      "172 Train Loss 0.060007434 Test MSE 0.007102417637211907 Test RE 0.06088901940647696\n",
      "173 Train Loss 0.05894127 Test MSE 0.006746971143459251 Test RE 0.059345842989808766\n",
      "174 Train Loss 0.05796357 Test MSE 0.006849696777301747 Test RE 0.059795919722610204\n",
      "175 Train Loss 0.0570486 Test MSE 0.006860786949219361 Test RE 0.059844307180270874\n",
      "176 Train Loss 0.0556171 Test MSE 0.006873428753330026 Test RE 0.05989941688061635\n",
      "177 Train Loss 0.054589797 Test MSE 0.006958193354132325 Test RE 0.06026763137614065\n",
      "178 Train Loss 0.05341355 Test MSE 0.007194576770277862 Test RE 0.06128278624779783\n",
      "179 Train Loss 0.052444767 Test MSE 0.006931267928900632 Test RE 0.060150912538715386\n",
      "180 Train Loss 0.051688008 Test MSE 0.006773640192752028 Test RE 0.05946301677509874\n",
      "181 Train Loss 0.05040565 Test MSE 0.006891225753658026 Test RE 0.05997691392164823\n",
      "182 Train Loss 0.04855963 Test MSE 0.006389485784024707 Test RE 0.057752239654480945\n",
      "183 Train Loss 0.04737482 Test MSE 0.006123889017951805 Test RE 0.056539183527220684\n",
      "184 Train Loss 0.046288997 Test MSE 0.006308540654253457 Test RE 0.05738525686686811\n",
      "185 Train Loss 0.045350395 Test MSE 0.0062933891423174 Test RE 0.05731630303558734\n",
      "186 Train Loss 0.044328935 Test MSE 0.006220474021924595 Test RE 0.056983302740389145\n",
      "187 Train Loss 0.043716654 Test MSE 0.0061491960234408526 Test RE 0.05665588732723335\n",
      "188 Train Loss 0.042933095 Test MSE 0.005800459787133849 Test RE 0.05502589144393385\n",
      "189 Train Loss 0.04198741 Test MSE 0.005669048085319149 Test RE 0.0543990038814143\n",
      "190 Train Loss 0.04112593 Test MSE 0.0055259458593378465 Test RE 0.053708025901073285\n",
      "191 Train Loss 0.039937064 Test MSE 0.005181850554137043 Test RE 0.052008977874673935\n",
      "192 Train Loss 0.0388536 Test MSE 0.004743317931490727 Test RE 0.04975961305380321\n",
      "193 Train Loss 0.037709977 Test MSE 0.004688823514175058 Test RE 0.04947295143307539\n",
      "194 Train Loss 0.036920838 Test MSE 0.004477543859060535 Test RE 0.048345471617260084\n",
      "195 Train Loss 0.035786044 Test MSE 0.004391626271608616 Test RE 0.047879385084588465\n",
      "196 Train Loss 0.034948163 Test MSE 0.0044522783908660934 Test RE 0.04820887899043195\n",
      "197 Train Loss 0.03420092 Test MSE 0.004345827165912038 Test RE 0.04762907005234383\n",
      "198 Train Loss 0.03359425 Test MSE 0.004480212602706045 Test RE 0.04835987710995966\n",
      "199 Train Loss 0.03304192 Test MSE 0.004198292927124832 Test RE 0.046813622158551366\n",
      "200 Train Loss 0.032552272 Test MSE 0.004113965724895235 Test RE 0.04634108644889147\n",
      "201 Train Loss 0.03202874 Test MSE 0.004015965998739351 Test RE 0.045785808815386096\n",
      "202 Train Loss 0.03134049 Test MSE 0.003646358679813291 Test RE 0.04362802668856486\n",
      "203 Train Loss 0.03075034 Test MSE 0.0036197210370445456 Test RE 0.043468377277812546\n",
      "204 Train Loss 0.030254792 Test MSE 0.0035297762900587553 Test RE 0.04292491735598585\n",
      "205 Train Loss 0.029825894 Test MSE 0.003557237557956681 Test RE 0.04309156939757184\n",
      "206 Train Loss 0.029255986 Test MSE 0.003528423314798453 Test RE 0.042916689934083894\n",
      "207 Train Loss 0.028684298 Test MSE 0.003506949415284991 Test RE 0.04278589565579717\n",
      "208 Train Loss 0.028276607 Test MSE 0.0036353223610322083 Test RE 0.04356195286878887\n",
      "209 Train Loss 0.027844356 Test MSE 0.0036044860213135413 Test RE 0.04337680396306985\n",
      "210 Train Loss 0.027520904 Test MSE 0.0035849508226427347 Test RE 0.04325909984009765\n",
      "211 Train Loss 0.027301067 Test MSE 0.0035585054811242264 Test RE 0.04309924838028366\n",
      "212 Train Loss 0.026968008 Test MSE 0.003669919616377415 Test RE 0.04376875091941423\n",
      "213 Train Loss 0.026591111 Test MSE 0.003678826865714288 Test RE 0.043821834222115635\n",
      "214 Train Loss 0.026281014 Test MSE 0.003559303852664131 Test RE 0.04310408289349714\n",
      "215 Train Loss 0.025993869 Test MSE 0.0034800695199436317 Test RE 0.0426216086192178\n",
      "216 Train Loss 0.02566772 Test MSE 0.0032531891417407074 Test RE 0.04120885369407442\n",
      "217 Train Loss 0.025327496 Test MSE 0.003060834356627896 Test RE 0.03997199189141976\n",
      "218 Train Loss 0.024944002 Test MSE 0.0030530804556393254 Test RE 0.039921329985292395\n",
      "219 Train Loss 0.024605177 Test MSE 0.0028813132995845004 Test RE 0.03878208186910642\n",
      "220 Train Loss 0.024235902 Test MSE 0.002698118670465654 Test RE 0.03752894885671924\n",
      "221 Train Loss 0.023918 Test MSE 0.0025583098916971774 Test RE 0.03654369452568921\n",
      "222 Train Loss 0.023615653 Test MSE 0.002453245791753295 Test RE 0.0357854438489247\n",
      "223 Train Loss 0.023291057 Test MSE 0.0024171295322265177 Test RE 0.03552105361183667\n",
      "224 Train Loss 0.023100697 Test MSE 0.0023824101970622525 Test RE 0.03526502097748918\n",
      "225 Train Loss 0.022821987 Test MSE 0.0023723246458555985 Test RE 0.03519029740781438\n",
      "226 Train Loss 0.02262269 Test MSE 0.0023899619668493388 Test RE 0.03532086833197646\n",
      "227 Train Loss 0.022354603 Test MSE 0.002371259546108108 Test RE 0.035182396848153816\n",
      "228 Train Loss 0.022076733 Test MSE 0.0023620405218115928 Test RE 0.035113938876726335\n",
      "229 Train Loss 0.02179351 Test MSE 0.0022941756309496565 Test RE 0.034605825064309384\n",
      "230 Train Loss 0.021574493 Test MSE 0.0022303582933087644 Test RE 0.034121113437153586\n",
      "231 Train Loss 0.021359012 Test MSE 0.002240578984355245 Test RE 0.0341992046440116\n",
      "232 Train Loss 0.021200245 Test MSE 0.0021992777322939728 Test RE 0.03388253654340799\n",
      "233 Train Loss 0.020906417 Test MSE 0.002080375072557718 Test RE 0.03295389074869237\n",
      "234 Train Loss 0.020655736 Test MSE 0.002052797382546844 Test RE 0.032734741786536695\n",
      "235 Train Loss 0.02043909 Test MSE 0.002057014531490972 Test RE 0.032768348721289864\n",
      "236 Train Loss 0.020202521 Test MSE 0.002000642129415374 Test RE 0.032316221921617885\n",
      "237 Train Loss 0.019996304 Test MSE 0.0019815718403520337 Test RE 0.03216183265496905\n",
      "238 Train Loss 0.01975914 Test MSE 0.0019153981330353217 Test RE 0.0316202578266283\n",
      "239 Train Loss 0.019488296 Test MSE 0.001897429885689121 Test RE 0.03147159438119658\n",
      "240 Train Loss 0.01931475 Test MSE 0.0018512709316630847 Test RE 0.031086431276336007\n",
      "241 Train Loss 0.019093893 Test MSE 0.001799573062725046 Test RE 0.030649304138772565\n",
      "242 Train Loss 0.018851867 Test MSE 0.0018152408193063256 Test RE 0.030782437146546004\n",
      "243 Train Loss 0.018530402 Test MSE 0.001812337507197808 Test RE 0.030757810445407496\n",
      "244 Train Loss 0.018228617 Test MSE 0.0018276215778446365 Test RE 0.03088723379085739\n",
      "245 Train Loss 0.017984798 Test MSE 0.0018167734066467608 Test RE 0.030795429037063757\n",
      "246 Train Loss 0.017711535 Test MSE 0.0017679923102006893 Test RE 0.03037918109323034\n",
      "247 Train Loss 0.01741218 Test MSE 0.0016892293281523798 Test RE 0.029694784876390264\n",
      "248 Train Loss 0.017020315 Test MSE 0.0015998667271412777 Test RE 0.02889866496537578\n",
      "249 Train Loss 0.0167326 Test MSE 0.0015369303187643653 Test RE 0.028324546545191672\n",
      "250 Train Loss 0.016519621 Test MSE 0.0015001049638664165 Test RE 0.027983156476197757\n",
      "251 Train Loss 0.016306479 Test MSE 0.001452191058911999 Test RE 0.027532633654486934\n",
      "252 Train Loss 0.016100546 Test MSE 0.0014280454996708322 Test RE 0.02730278186793905\n",
      "253 Train Loss 0.015878348 Test MSE 0.0014257981068903313 Test RE 0.027281289473156254\n",
      "254 Train Loss 0.015630933 Test MSE 0.001420515974280736 Test RE 0.027230708293301275\n",
      "255 Train Loss 0.015314924 Test MSE 0.001432650808275935 Test RE 0.027346770846731976\n",
      "256 Train Loss 0.0151118 Test MSE 0.0014423787044848854 Test RE 0.02743945794270545\n",
      "257 Train Loss 0.014855926 Test MSE 0.0014216355577700173 Test RE 0.02724143715774619\n",
      "258 Train Loss 0.014632615 Test MSE 0.0014148556824053905 Test RE 0.02717640140427622\n",
      "259 Train Loss 0.014425458 Test MSE 0.0014069666329572115 Test RE 0.027100529471103144\n",
      "260 Train Loss 0.014289362 Test MSE 0.0014239700770117586 Test RE 0.027263795058159113\n",
      "261 Train Loss 0.014186155 Test MSE 0.0014206475243190718 Test RE 0.02723196914423649\n",
      "262 Train Loss 0.014020842 Test MSE 0.001488384455496547 Test RE 0.027873624152267625\n",
      "263 Train Loss 0.013821514 Test MSE 0.001441438619037145 Test RE 0.027430514507979457\n",
      "264 Train Loss 0.013664317 Test MSE 0.0014110652254446065 Test RE 0.027139973637686294\n",
      "265 Train Loss 0.013527039 Test MSE 0.0014190587435175392 Test RE 0.0272167374515334\n",
      "266 Train Loss 0.013435286 Test MSE 0.0014323512372919657 Test RE 0.02734391155704808\n",
      "267 Train Loss 0.013285284 Test MSE 0.0013754750154078266 Test RE 0.026795522497413106\n",
      "268 Train Loss 0.013159755 Test MSE 0.0013126257947868294 Test RE 0.02617618456266551\n",
      "269 Train Loss 0.013017397 Test MSE 0.0013135243746732756 Test RE 0.026185142701737624\n",
      "270 Train Loss 0.01286071 Test MSE 0.0012903132151874368 Test RE 0.025952753961063176\n",
      "271 Train Loss 0.012773208 Test MSE 0.001245173934080505 Test RE 0.025494757609438264\n",
      "272 Train Loss 0.012629724 Test MSE 0.0012433592286984901 Test RE 0.025476172919541906\n",
      "273 Train Loss 0.012501227 Test MSE 0.00119805417785381 Test RE 0.025007720447386042\n",
      "274 Train Loss 0.012394607 Test MSE 0.0011656636901719065 Test RE 0.02466735086524961\n",
      "275 Train Loss 0.012295555 Test MSE 0.0011428510784881776 Test RE 0.02442478210986373\n",
      "276 Train Loss 0.012166101 Test MSE 0.0011211346356174991 Test RE 0.024191609398460507\n",
      "277 Train Loss 0.012035911 Test MSE 0.0011125590718041865 Test RE 0.024098910931508333\n",
      "278 Train Loss 0.011897411 Test MSE 0.0010883430912509264 Test RE 0.02383519938725212\n",
      "279 Train Loss 0.01178468 Test MSE 0.0010999801080447864 Test RE 0.02396228849862546\n",
      "280 Train Loss 0.011655411 Test MSE 0.00109829617438316 Test RE 0.023943939821766822\n",
      "281 Train Loss 0.011550857 Test MSE 0.0011155008563579066 Test RE 0.024130750590158696\n",
      "282 Train Loss 0.011433602 Test MSE 0.0011171014734393627 Test RE 0.024148056827979054\n",
      "283 Train Loss 0.011324104 Test MSE 0.0011306749162098993 Test RE 0.02429432044943048\n",
      "284 Train Loss 0.011182556 Test MSE 0.0011207292203987695 Test RE 0.024187235020440248\n",
      "285 Train Loss 0.011106074 Test MSE 0.0011260037566223427 Test RE 0.024244084923386304\n",
      "286 Train Loss 0.011017077 Test MSE 0.0011263988802829039 Test RE 0.02424833827125485\n",
      "287 Train Loss 0.010923574 Test MSE 0.0011274945272102955 Test RE 0.024260128570567762\n",
      "288 Train Loss 0.010795776 Test MSE 0.0011403523377525638 Test RE 0.024398066208078113\n",
      "289 Train Loss 0.010679894 Test MSE 0.00111691111403231 Test RE 0.024145999268422112\n",
      "290 Train Loss 0.010539138 Test MSE 0.0011067606664483304 Test RE 0.024036029867093026\n",
      "291 Train Loss 0.010434597 Test MSE 0.0011018994171852578 Test RE 0.023983184783263084\n",
      "292 Train Loss 0.010351 Test MSE 0.0011026131455048004 Test RE 0.02399095078574316\n",
      "293 Train Loss 0.010253187 Test MSE 0.0011036751989108291 Test RE 0.024002502225363317\n",
      "294 Train Loss 0.010163958 Test MSE 0.0010826679003958662 Test RE 0.023772973555525902\n",
      "295 Train Loss 0.0100580165 Test MSE 0.0010659729331544444 Test RE 0.023588969321968547\n",
      "296 Train Loss 0.009961191 Test MSE 0.0010591101490632956 Test RE 0.02351291326186096\n",
      "297 Train Loss 0.009892187 Test MSE 0.0010384080201318881 Test RE 0.0232819790317396\n",
      "298 Train Loss 0.009817924 Test MSE 0.0010142017994852447 Test RE 0.02300901701649988\n",
      "299 Train Loss 0.009733812 Test MSE 0.000999053757855933 Test RE 0.022836540096121474\n",
      "Training time: 168.24\n",
      "KG_tanh_high\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 53682.516 Test MSE 8.78294913642292 Test RE 2.1411942119653364\n",
      "1 Train Loss 38337.266 Test MSE 9.804126321767953 Test RE 2.2622485891972453\n",
      "2 Train Loss 16290.11 Test MSE 8.054922104815319 Test RE 2.0505319915453253\n",
      "3 Train Loss 8587.694 Test MSE 8.290582292612974 Test RE 2.0803116162413886\n",
      "4 Train Loss 2836.9768 Test MSE 12.319084436421067 Test RE 2.5358589464164734\n",
      "5 Train Loss 1190.7594 Test MSE 12.116309848994277 Test RE 2.51490197754022\n",
      "6 Train Loss 464.36996 Test MSE 13.973541800081907 Test RE 2.700779485118209\n",
      "7 Train Loss 226.15735 Test MSE 13.54398570838057 Test RE 2.658943568709145\n",
      "8 Train Loss 150.98232 Test MSE 13.571508144925422 Test RE 2.6616437881190858\n",
      "9 Train Loss 113.28588 Test MSE 14.044292465163327 Test RE 2.7076081291008975\n",
      "10 Train Loss 90.95318 Test MSE 14.351938617341077 Test RE 2.737103128258087\n",
      "11 Train Loss 72.65305 Test MSE 14.357459975298747 Test RE 2.7376295753580018\n",
      "12 Train Loss 54.209473 Test MSE 14.821492162253753 Test RE 2.781517785505549\n",
      "13 Train Loss 44.970676 Test MSE 15.062749383475701 Test RE 2.8040645183846404\n",
      "14 Train Loss 35.905117 Test MSE 15.023425257105291 Test RE 2.800401858694406\n",
      "15 Train Loss 30.323277 Test MSE 15.08215766910374 Test RE 2.805870449172523\n",
      "16 Train Loss 26.76083 Test MSE 15.131014046891792 Test RE 2.8104113720583426\n",
      "17 Train Loss 24.780787 Test MSE 15.07696235220297 Test RE 2.80538714160931\n",
      "18 Train Loss 23.109198 Test MSE 14.932761693021725 Test RE 2.7919391206516937\n",
      "19 Train Loss 21.954027 Test MSE 14.79418334771124 Test RE 2.7789541106029216\n",
      "20 Train Loss 20.665026 Test MSE 14.687164751028238 Test RE 2.7688846275130996\n",
      "21 Train Loss 19.726406 Test MSE 14.526327095081943 Test RE 2.753682004566559\n",
      "22 Train Loss 18.770891 Test MSE 14.338426433958713 Test RE 2.7358143494544036\n",
      "23 Train Loss 17.964499 Test MSE 14.118026791880702 Test RE 2.714706468510123\n",
      "24 Train Loss 17.385494 Test MSE 14.06716827102322 Test RE 2.709812352511376\n",
      "25 Train Loss 16.88927 Test MSE 13.900765010966964 Test RE 2.6937372243606004\n",
      "26 Train Loss 16.354416 Test MSE 13.690254987222435 Test RE 2.6732627414891352\n",
      "27 Train Loss 15.982777 Test MSE 13.662621449535695 Test RE 2.6705634118698103\n",
      "28 Train Loss 15.491771 Test MSE 13.454276103917561 Test RE 2.6501230826476903\n",
      "29 Train Loss 15.103106 Test MSE 13.333770050849672 Test RE 2.6382281956483293\n",
      "30 Train Loss 14.661925 Test MSE 13.199692764404546 Test RE 2.62493037378516\n",
      "31 Train Loss 14.314049 Test MSE 13.016781006376501 Test RE 2.6066797376246162\n",
      "32 Train Loss 13.999838 Test MSE 12.857652818321307 Test RE 2.5906976089746996\n",
      "33 Train Loss 13.611765 Test MSE 12.772352763348202 Test RE 2.5820897242761656\n",
      "34 Train Loss 13.287204 Test MSE 12.519494969916833 Test RE 2.556402784363049\n",
      "35 Train Loss 13.021141 Test MSE 12.431559079362286 Test RE 2.547408983423806\n",
      "36 Train Loss 12.796829 Test MSE 12.360222000981045 Test RE 2.540089460366762\n",
      "37 Train Loss 12.611019 Test MSE 12.210059262817962 Test RE 2.524612701305488\n",
      "38 Train Loss 12.447165 Test MSE 12.11216110759157 Test RE 2.514471377324932\n",
      "39 Train Loss 12.24472 Test MSE 12.036611860492107 Test RE 2.506617140055683\n",
      "40 Train Loss 12.097067 Test MSE 11.950576739352138 Test RE 2.4976426934696003\n",
      "41 Train Loss 11.994487 Test MSE 11.900895582033373 Test RE 2.4924456634863383\n",
      "42 Train Loss 11.837559 Test MSE 11.90535748134089 Test RE 2.4929128551913564\n",
      "43 Train Loss 11.700307 Test MSE 11.806051909618327 Test RE 2.4824940777058826\n",
      "44 Train Loss 11.565105 Test MSE 11.70679419622695 Test RE 2.4720364419304324\n",
      "45 Train Loss 11.477816 Test MSE 11.589146470005774 Test RE 2.45958368027497\n",
      "46 Train Loss 11.344064 Test MSE 11.397534123225954 Test RE 2.4391658301946286\n",
      "47 Train Loss 11.232579 Test MSE 11.203778904960027 Test RE 2.418344357606218\n",
      "48 Train Loss 11.095007 Test MSE 10.976321418398836 Test RE 2.3936700445184695\n",
      "49 Train Loss 10.987367 Test MSE 10.845289216405028 Test RE 2.379339672176427\n",
      "50 Train Loss 10.8513775 Test MSE 10.526459093090597 Test RE 2.344104833811521\n",
      "51 Train Loss 10.747147 Test MSE 10.405092271973686 Test RE 2.3305522540407955\n",
      "52 Train Loss 10.618618 Test MSE 10.120073476222561 Test RE 2.298411096592597\n",
      "53 Train Loss 10.469225 Test MSE 9.78689441789303 Test RE 2.260259631014998\n",
      "54 Train Loss 10.348741 Test MSE 9.613162617769294 Test RE 2.2401083319219053\n",
      "55 Train Loss 10.200513 Test MSE 9.44237785022327 Test RE 2.220120589817568\n",
      "56 Train Loss 9.975568 Test MSE 9.189782754931999 Test RE 2.190223827338786\n",
      "57 Train Loss 9.827498 Test MSE 8.924461690159577 Test RE 2.1583749486945107\n",
      "58 Train Loss 9.57538 Test MSE 8.504448470887173 Test RE 2.1069729203886043\n",
      "59 Train Loss 9.136288 Test MSE 7.646141529268106 Test RE 1.9978231586807695\n",
      "60 Train Loss 8.66157 Test MSE 6.825463778219824 Test RE 1.8875651918597647\n",
      "61 Train Loss 8.098374 Test MSE 6.2705178946539615 Test RE 1.8092041808493329\n",
      "62 Train Loss 7.6445994 Test MSE 5.87661195178442 Test RE 1.7514566148303807\n",
      "63 Train Loss 6.9653864 Test MSE 5.29592451265708 Test RE 1.662672715062316\n",
      "64 Train Loss 6.348364 Test MSE 4.880177445808763 Test RE 1.5960764278350137\n",
      "65 Train Loss 5.830487 Test MSE 4.5760393992133395 Test RE 1.545541796889245\n",
      "66 Train Loss 5.246826 Test MSE 4.187701366022333 Test RE 1.478508170009529\n",
      "67 Train Loss 4.8022842 Test MSE 3.872852637427122 Test RE 1.4218420795291695\n",
      "68 Train Loss 4.317239 Test MSE 3.591468025338024 Test RE 1.3692157275536727\n",
      "69 Train Loss 3.8963625 Test MSE 3.0990520637213903 Test RE 1.2718922266947004\n",
      "70 Train Loss 3.475274 Test MSE 3.0137925435961344 Test RE 1.2542743873025792\n",
      "71 Train Loss 3.2518647 Test MSE 2.844244553857688 Test RE 1.2184826355365659\n",
      "72 Train Loss 3.0469053 Test MSE 2.7015216282698655 Test RE 1.1875177267645298\n",
      "73 Train Loss 2.7720418 Test MSE 2.5393996258596956 Test RE 1.1513341923135694\n",
      "74 Train Loss 2.5163393 Test MSE 2.358853391865561 Test RE 1.1096508535639336\n",
      "75 Train Loss 2.3795724 Test MSE 2.202224186029543 Test RE 1.0721773807980635\n",
      "76 Train Loss 2.156616 Test MSE 1.9992482432534355 Test RE 1.021572605650317\n",
      "77 Train Loss 2.027584 Test MSE 1.9649842501684598 Test RE 1.0127806932958874\n",
      "78 Train Loss 1.8875554 Test MSE 1.920341518549759 Test RE 1.0012098479803262\n",
      "79 Train Loss 1.7580879 Test MSE 1.8677029719387654 Test RE 0.9873924038729109\n",
      "80 Train Loss 1.6566985 Test MSE 1.8095528265293097 Test RE 0.9718998384094004\n",
      "81 Train Loss 1.588371 Test MSE 1.7460859546815106 Test RE 0.9547038773256437\n",
      "82 Train Loss 1.5218437 Test MSE 1.6681134522709133 Test RE 0.9331440027668346\n",
      "83 Train Loss 1.4484571 Test MSE 1.5259634667300481 Test RE 0.8924994250650423\n",
      "84 Train Loss 1.3958247 Test MSE 1.4152173094593088 Test RE 0.8595030908333932\n",
      "85 Train Loss 1.3148581 Test MSE 1.3251437011406983 Test RE 0.8317012710070014\n",
      "86 Train Loss 1.2711387 Test MSE 1.285056162957375 Test RE 0.8190245716680435\n",
      "87 Train Loss 1.2245823 Test MSE 1.2119899706389567 Test RE 0.795399639652482\n",
      "88 Train Loss 1.1657531 Test MSE 1.120246319054287 Test RE 0.7647027283240238\n",
      "89 Train Loss 1.1233106 Test MSE 1.128375692448858 Test RE 0.7674723498861292\n",
      "90 Train Loss 1.0938572 Test MSE 1.0810708297946099 Test RE 0.7512127517666805\n",
      "91 Train Loss 1.0455343 Test MSE 1.0448272841588169 Test RE 0.7385129742306732\n",
      "92 Train Loss 0.99311906 Test MSE 1.0052211092901633 Test RE 0.724380376792695\n",
      "93 Train Loss 0.9637575 Test MSE 1.00301806559277 Test RE 0.7235861649867745\n",
      "94 Train Loss 0.928356 Test MSE 0.9749764994118947 Test RE 0.7133997466053813\n",
      "95 Train Loss 0.89209235 Test MSE 0.9618173420381494 Test RE 0.708569049933926\n",
      "96 Train Loss 0.8458443 Test MSE 0.8677734302208301 Test RE 0.673037172206378\n",
      "97 Train Loss 0.8103626 Test MSE 0.7885022992827541 Test RE 0.6415601184978451\n",
      "98 Train Loss 0.7676589 Test MSE 0.7702214911102881 Test RE 0.634079471594749\n",
      "99 Train Loss 0.72114867 Test MSE 0.7364491869629586 Test RE 0.620022243762467\n",
      "100 Train Loss 0.69578856 Test MSE 0.685328311076748 Test RE 0.5981157151365939\n",
      "101 Train Loss 0.6612699 Test MSE 0.6684523907474328 Test RE 0.5907056398160391\n",
      "102 Train Loss 0.6231422 Test MSE 0.6280424227078119 Test RE 0.5725723437628761\n",
      "103 Train Loss 0.5924161 Test MSE 0.5652432501147806 Test RE 0.5431922554099139\n",
      "104 Train Loss 0.56826866 Test MSE 0.5522718978279227 Test RE 0.5369234218607454\n",
      "105 Train Loss 0.55044794 Test MSE 0.527709112344655 Test RE 0.5248475492875039\n",
      "106 Train Loss 0.52503717 Test MSE 0.466506895060301 Test RE 0.4934747212981234\n",
      "107 Train Loss 0.49425074 Test MSE 0.41750528313143664 Test RE 0.4668387146169188\n",
      "108 Train Loss 0.4704731 Test MSE 0.43077202254977126 Test RE 0.47419789475127905\n",
      "109 Train Loss 0.4415981 Test MSE 0.4620437491172926 Test RE 0.4911084724052214\n",
      "110 Train Loss 0.40553886 Test MSE 0.4126134190344937 Test RE 0.4640957067806432\n",
      "111 Train Loss 0.39148644 Test MSE 0.40266536308387424 Test RE 0.458466928894831\n",
      "112 Train Loss 0.37324658 Test MSE 0.3867378949793603 Test RE 0.4493080931772857\n",
      "113 Train Loss 0.3589017 Test MSE 0.3545818217166022 Test RE 0.4302234814704304\n",
      "114 Train Loss 0.34666112 Test MSE 0.34061297935425977 Test RE 0.4216639506702791\n",
      "115 Train Loss 0.32506457 Test MSE 0.3310592394487499 Test RE 0.41570833609786567\n",
      "116 Train Loss 0.31122372 Test MSE 0.30833929369968904 Test RE 0.4011901978656183\n",
      "117 Train Loss 0.28866208 Test MSE 0.27681624137883604 Test RE 0.3801295754880577\n",
      "118 Train Loss 0.27173766 Test MSE 0.24651793103343375 Test RE 0.35872375250385946\n",
      "119 Train Loss 0.2571962 Test MSE 0.21822947072724672 Test RE 0.3375146097611409\n",
      "120 Train Loss 0.2473623 Test MSE 0.2065291906891532 Test RE 0.328342120405412\n",
      "121 Train Loss 0.23854668 Test MSE 0.19751719647943045 Test RE 0.32109854173814484\n",
      "122 Train Loss 0.2296678 Test MSE 0.18087418243903405 Test RE 0.3072728350447579\n",
      "123 Train Loss 0.22293891 Test MSE 0.17967694448904392 Test RE 0.3062542002106099\n",
      "124 Train Loss 0.21625017 Test MSE 0.1633153894708884 Test RE 0.29197753137779414\n",
      "125 Train Loss 0.20986578 Test MSE 0.1526372069994091 Test RE 0.28227088324153254\n",
      "126 Train Loss 0.2040133 Test MSE 0.15110020714948919 Test RE 0.28084610606806787\n",
      "127 Train Loss 0.19968826 Test MSE 0.14268787815433162 Test RE 0.272916263551968\n",
      "128 Train Loss 0.18939444 Test MSE 0.138626929592627 Test RE 0.26900458296615376\n",
      "129 Train Loss 0.17908059 Test MSE 0.13585391346700856 Test RE 0.2663004826700746\n",
      "130 Train Loss 0.17148942 Test MSE 0.1270447281424154 Test RE 0.25752191962489895\n",
      "131 Train Loss 0.16642259 Test MSE 0.1204153863960581 Test RE 0.2507130086957021\n",
      "132 Train Loss 0.160965 Test MSE 0.1112539831778482 Test RE 0.2409870255350751\n",
      "133 Train Loss 0.1573547 Test MSE 0.10796086547280133 Test RE 0.2373936268803136\n",
      "134 Train Loss 0.15193197 Test MSE 0.11091808646208531 Test RE 0.24062295793550767\n",
      "135 Train Loss 0.14285532 Test MSE 0.09931000532383562 Test RE 0.2276839302192158\n",
      "136 Train Loss 0.13892676 Test MSE 0.09435602775281782 Test RE 0.22193239587827002\n",
      "137 Train Loss 0.13513252 Test MSE 0.08990556806154981 Test RE 0.21663527342212632\n",
      "138 Train Loss 0.13017465 Test MSE 0.08185359639343466 Test RE 0.2067067980854082\n",
      "139 Train Loss 0.12660535 Test MSE 0.07750144969230016 Test RE 0.2011364543134432\n",
      "140 Train Loss 0.12268241 Test MSE 0.0661151368773176 Test RE 0.1857745968811876\n",
      "141 Train Loss 0.1177897 Test MSE 0.057748791002716765 Test RE 0.17362302762594464\n",
      "142 Train Loss 0.11271143 Test MSE 0.05172822755787811 Test RE 0.16432349969671964\n",
      "143 Train Loss 0.1095626 Test MSE 0.04543628861816367 Test RE 0.15400587965025714\n",
      "144 Train Loss 0.10507738 Test MSE 0.048395939347102866 Test RE 0.1589426094439308\n",
      "145 Train Loss 0.09864204 Test MSE 0.04508435452346393 Test RE 0.1534082815245784\n",
      "146 Train Loss 0.09625609 Test MSE 0.044635341553315715 Test RE 0.15264244296678509\n",
      "147 Train Loss 0.09429842 Test MSE 0.045583846937645445 Test RE 0.1542557507241001\n",
      "148 Train Loss 0.09235052 Test MSE 0.04544446644974553 Test RE 0.154019738368917\n",
      "149 Train Loss 0.08958217 Test MSE 0.04490414672387165 Test RE 0.15310137849809086\n",
      "150 Train Loss 0.08719878 Test MSE 0.04373325188766869 Test RE 0.15109210182274163\n",
      "151 Train Loss 0.084996104 Test MSE 0.041212436821068905 Test RE 0.1466729490352491\n",
      "152 Train Loss 0.08337771 Test MSE 0.03947978825183958 Test RE 0.14355663976536837\n",
      "153 Train Loss 0.08145807 Test MSE 0.03703858360069006 Test RE 0.1390474606843175\n",
      "154 Train Loss 0.07942427 Test MSE 0.03534513272529723 Test RE 0.13583155899825203\n",
      "155 Train Loss 0.07814992 Test MSE 0.03340109392443872 Test RE 0.13204325519772514\n",
      "156 Train Loss 0.07654618 Test MSE 0.032135706728085925 Test RE 0.12951790310359848\n",
      "157 Train Loss 0.07475391 Test MSE 0.030422943268026168 Test RE 0.12601913395695735\n",
      "158 Train Loss 0.07293749 Test MSE 0.028984573752386906 Test RE 0.12300402868880683\n",
      "159 Train Loss 0.07172722 Test MSE 0.027581078814449128 Test RE 0.11998901868955394\n",
      "160 Train Loss 0.07057426 Test MSE 0.025661698595668265 Test RE 0.11573869381634606\n",
      "161 Train Loss 0.06960614 Test MSE 0.023426947061215057 Test RE 0.11058436411012486\n",
      "162 Train Loss 0.06848359 Test MSE 0.023615377275294187 Test RE 0.11102820560863287\n",
      "163 Train Loss 0.06777198 Test MSE 0.022293205910414594 Test RE 0.10787533082440605\n",
      "164 Train Loss 0.0668087 Test MSE 0.022194683409006002 Test RE 0.10763669498188183\n",
      "165 Train Loss 0.06543999 Test MSE 0.021333963547957798 Test RE 0.10552895832501824\n",
      "166 Train Loss 0.0640957 Test MSE 0.022498085834822615 Test RE 0.10836989724563341\n",
      "167 Train Loss 0.06267755 Test MSE 0.020742032074576824 Test RE 0.10405465835876133\n",
      "168 Train Loss 0.061270963 Test MSE 0.0225301269770193 Test RE 0.10844703847236192\n",
      "169 Train Loss 0.06074552 Test MSE 0.022644188307049336 Test RE 0.10872120464371034\n",
      "170 Train Loss 0.05963265 Test MSE 0.02240403576373849 Test RE 0.10814314749687054\n",
      "171 Train Loss 0.05843325 Test MSE 0.02189276555237878 Test RE 0.10690208852760977\n",
      "172 Train Loss 0.05730391 Test MSE 0.02061082532953293 Test RE 0.10372502980472728\n",
      "173 Train Loss 0.056400962 Test MSE 0.0197961198079485 Test RE 0.10165433734430432\n",
      "174 Train Loss 0.055644378 Test MSE 0.01911863467686352 Test RE 0.09989972994940115\n",
      "175 Train Loss 0.054389264 Test MSE 0.018209890310389318 Test RE 0.0974966159334386\n",
      "176 Train Loss 0.053043302 Test MSE 0.01731443372778031 Test RE 0.09506924022067206\n",
      "177 Train Loss 0.051987085 Test MSE 0.01683397580170913 Test RE 0.09374092316813483\n",
      "178 Train Loss 0.050859652 Test MSE 0.015277545250923535 Test RE 0.08930230449989529\n",
      "179 Train Loss 0.05019278 Test MSE 0.015012909118560274 Test RE 0.08852548294162983\n",
      "180 Train Loss 0.049169563 Test MSE 0.014618756409402855 Test RE 0.08735566852417725\n",
      "181 Train Loss 0.047712438 Test MSE 0.0134081112001961 Test RE 0.0836603502504976\n",
      "182 Train Loss 0.046757184 Test MSE 0.013150589834886615 Test RE 0.08285304861132757\n",
      "183 Train Loss 0.045971505 Test MSE 0.01308028509356813 Test RE 0.08263128029703865\n",
      "184 Train Loss 0.045397367 Test MSE 0.013308545788726086 Test RE 0.0833491506229283\n",
      "185 Train Loss 0.044547837 Test MSE 0.01316177663944204 Test RE 0.08288828139723367\n",
      "186 Train Loss 0.043890644 Test MSE 0.013128087331756555 Test RE 0.08278213166938395\n",
      "187 Train Loss 0.043409437 Test MSE 0.013021933288942071 Test RE 0.0824467631492457\n",
      "188 Train Loss 0.042813323 Test MSE 0.012929558062240082 Test RE 0.0821538115158024\n",
      "189 Train Loss 0.042277135 Test MSE 0.012057917202881178 Test RE 0.07933631518780113\n",
      "190 Train Loss 0.041951623 Test MSE 0.011758460518713805 Test RE 0.07834496836584025\n",
      "191 Train Loss 0.041590266 Test MSE 0.011724231241944853 Test RE 0.07823085282873622\n",
      "192 Train Loss 0.04072581 Test MSE 0.012527055402794987 Test RE 0.08086495998408567\n",
      "193 Train Loss 0.03978264 Test MSE 0.012453707739910589 Test RE 0.08062787460259915\n",
      "194 Train Loss 0.039250627 Test MSE 0.012120683523976472 Test RE 0.07954253592607999\n",
      "195 Train Loss 0.03843234 Test MSE 0.01083406363181884 Test RE 0.07520237698079948\n",
      "196 Train Loss 0.03745633 Test MSE 0.010641568557385957 Test RE 0.07453130070859085\n",
      "197 Train Loss 0.036401093 Test MSE 0.010177670103876109 Test RE 0.072888676042064\n",
      "198 Train Loss 0.03585999 Test MSE 0.009872114043896566 Test RE 0.0717861990391446\n",
      "199 Train Loss 0.035483196 Test MSE 0.009596634626063165 Test RE 0.07077752257763358\n",
      "200 Train Loss 0.03510798 Test MSE 0.009735570243597759 Test RE 0.07128802356254525\n",
      "201 Train Loss 0.034599356 Test MSE 0.009656643169847092 Test RE 0.07099846654892271\n",
      "202 Train Loss 0.034057576 Test MSE 0.009359192740111084 Test RE 0.06989644254748749\n",
      "203 Train Loss 0.0334261 Test MSE 0.00953592258543602 Test RE 0.07055328430162962\n",
      "204 Train Loss 0.03284694 Test MSE 0.009242493902635502 Test RE 0.06945930975894345\n",
      "205 Train Loss 0.03230734 Test MSE 0.009098829826370471 Test RE 0.06891736245966111\n",
      "206 Train Loss 0.03186002 Test MSE 0.009054586073941146 Test RE 0.06874960031238633\n",
      "207 Train Loss 0.031141639 Test MSE 0.009058442355405217 Test RE 0.06876423872795062\n",
      "208 Train Loss 0.03039183 Test MSE 0.009267688542871 Test RE 0.06955391687222937\n",
      "209 Train Loss 0.029904097 Test MSE 0.008972884089338782 Test RE 0.06843872430372308\n",
      "210 Train Loss 0.029162515 Test MSE 0.008127850181485053 Test RE 0.06513639546375981\n",
      "211 Train Loss 0.02875676 Test MSE 0.007552436965424444 Test RE 0.06278840219468018\n",
      "212 Train Loss 0.028412484 Test MSE 0.007561299205939277 Test RE 0.0628252302266614\n",
      "213 Train Loss 0.02808387 Test MSE 0.0074031988191398165 Test RE 0.06216494923538643\n",
      "214 Train Loss 0.027811887 Test MSE 0.007429768146572939 Test RE 0.06227640116691194\n",
      "215 Train Loss 0.027603269 Test MSE 0.007292501336994449 Test RE 0.06169843321622938\n",
      "216 Train Loss 0.027384577 Test MSE 0.007207932440342869 Test RE 0.06133964109893298\n",
      "217 Train Loss 0.027053786 Test MSE 0.007139147666822141 Test RE 0.061046259631186164\n",
      "218 Train Loss 0.026774501 Test MSE 0.006882521722064393 Test RE 0.059939024733369047\n",
      "219 Train Loss 0.02654552 Test MSE 0.006883710189985578 Test RE 0.05994419961955459\n",
      "220 Train Loss 0.026173882 Test MSE 0.0067992359826303025 Test RE 0.05957525832753413\n",
      "221 Train Loss 0.025808336 Test MSE 0.007052723823482319 Test RE 0.060675632990572256\n",
      "222 Train Loss 0.025478628 Test MSE 0.007134196524153387 Test RE 0.061025087554559335\n",
      "223 Train Loss 0.025133124 Test MSE 0.007133103179765048 Test RE 0.061020411204999306\n",
      "224 Train Loss 0.024771579 Test MSE 0.006803181491630302 Test RE 0.05959254119788848\n",
      "225 Train Loss 0.024546627 Test MSE 0.006889284922388166 Test RE 0.059968467436846515\n",
      "226 Train Loss 0.024206564 Test MSE 0.006497987561259008 Test RE 0.05824052949574456\n",
      "227 Train Loss 0.023490716 Test MSE 0.005692999052946362 Test RE 0.054513797009555505\n",
      "228 Train Loss 0.023199849 Test MSE 0.0056576274156802135 Test RE 0.05434418107368034\n",
      "229 Train Loss 0.022956928 Test MSE 0.005661171469798395 Test RE 0.054361199565008865\n",
      "230 Train Loss 0.02276589 Test MSE 0.005623044990390524 Test RE 0.05417783623011433\n",
      "231 Train Loss 0.022466 Test MSE 0.0057365959496216866 Test RE 0.054722131811602515\n",
      "232 Train Loss 0.022160133 Test MSE 0.005877042939632296 Test RE 0.0553879522092813\n",
      "233 Train Loss 0.02192334 Test MSE 0.005717797517903708 Test RE 0.05463239790077276\n",
      "234 Train Loss 0.021665076 Test MSE 0.005811473961881648 Test RE 0.055078109489855115\n",
      "235 Train Loss 0.021519313 Test MSE 0.005732621490804143 Test RE 0.05470317208835796\n",
      "236 Train Loss 0.021310268 Test MSE 0.005783117548178957 Test RE 0.05494357154748041\n",
      "237 Train Loss 0.02113384 Test MSE 0.005845493527792775 Test RE 0.05523908407573873\n",
      "238 Train Loss 0.020940486 Test MSE 0.005866066278878488 Test RE 0.055336203488512016\n",
      "239 Train Loss 0.020760505 Test MSE 0.00575987222026956 Test RE 0.054833037106089166\n",
      "240 Train Loss 0.020525882 Test MSE 0.005605109951311883 Test RE 0.05409136549593472\n",
      "241 Train Loss 0.020361092 Test MSE 0.0055066071277351004 Test RE 0.05361396459151471\n",
      "242 Train Loss 0.020052673 Test MSE 0.005509086875998657 Test RE 0.05362603501604219\n",
      "243 Train Loss 0.019722803 Test MSE 0.005429009920810942 Test RE 0.05323486959265909\n",
      "244 Train Loss 0.019378234 Test MSE 0.005048976973073306 Test RE 0.05133783761021785\n",
      "245 Train Loss 0.019163946 Test MSE 0.004793521588855717 Test RE 0.0500222498083013\n",
      "246 Train Loss 0.019032218 Test MSE 0.004503558540332161 Test RE 0.04848571262371143\n",
      "247 Train Loss 0.01890451 Test MSE 0.004648855365370641 Test RE 0.04926164318956557\n",
      "248 Train Loss 0.018771432 Test MSE 0.00464832257756187 Test RE 0.049258820262963174\n",
      "249 Train Loss 0.018588483 Test MSE 0.004572993277472644 Test RE 0.04885805323386825\n",
      "250 Train Loss 0.018411849 Test MSE 0.004459684994704303 Test RE 0.048248961355169345\n",
      "251 Train Loss 0.018262072 Test MSE 0.0042259145713961456 Test RE 0.046967369092159726\n",
      "252 Train Loss 0.017960686 Test MSE 0.0039644582157819935 Test RE 0.04549124254996113\n",
      "253 Train Loss 0.017697027 Test MSE 0.0035488614104542716 Test RE 0.04304080612113266\n",
      "254 Train Loss 0.017520545 Test MSE 0.003488366539491522 Test RE 0.04267238659797905\n",
      "255 Train Loss 0.017351324 Test MSE 0.0032903014371805073 Test RE 0.04144324187118113\n",
      "256 Train Loss 0.017168922 Test MSE 0.0031163270833777725 Test RE 0.04033270909024106\n",
      "257 Train Loss 0.017022453 Test MSE 0.003158821854100293 Test RE 0.04060676983904418\n",
      "258 Train Loss 0.016847948 Test MSE 0.0029826628905940105 Test RE 0.03945826292395984\n",
      "259 Train Loss 0.016734669 Test MSE 0.002904763203578557 Test RE 0.03893957831360235\n",
      "260 Train Loss 0.01661837 Test MSE 0.002826576692840124 Test RE 0.03841194193335448\n",
      "261 Train Loss 0.016491627 Test MSE 0.0028781160419933563 Test RE 0.0387605585722496\n",
      "262 Train Loss 0.01627093 Test MSE 0.0026597991219844755 Test RE 0.03726149675434541\n",
      "263 Train Loss 0.016039502 Test MSE 0.00271816682386246 Test RE 0.03766811872795672\n",
      "264 Train Loss 0.015890315 Test MSE 0.00270491377291887 Test RE 0.03757617670794185\n",
      "265 Train Loss 0.01580357 Test MSE 0.0026567168782834945 Test RE 0.03723990070513598\n",
      "266 Train Loss 0.015716271 Test MSE 0.0027293231450283492 Test RE 0.037745341234704285\n",
      "267 Train Loss 0.015574416 Test MSE 0.0027716669515778086 Test RE 0.0380370124431726\n",
      "268 Train Loss 0.015379765 Test MSE 0.0029615850169185023 Test RE 0.039318593963029766\n",
      "269 Train Loss 0.015158356 Test MSE 0.003019099000502643 Test RE 0.03969854175062476\n",
      "270 Train Loss 0.01496224 Test MSE 0.0029002500539960225 Test RE 0.03890931621570975\n",
      "271 Train Loss 0.014766486 Test MSE 0.0028831350043999264 Test RE 0.03879433988038006\n",
      "272 Train Loss 0.014536111 Test MSE 0.002589599997871541 Test RE 0.03676649414957775\n",
      "273 Train Loss 0.014329761 Test MSE 0.0024330082928821608 Test RE 0.035637536203125604\n",
      "274 Train Loss 0.014120787 Test MSE 0.002291989035423312 Test RE 0.03458932960075317\n",
      "275 Train Loss 0.013855241 Test MSE 0.0019991936893443227 Test RE 0.032304521531708305\n",
      "276 Train Loss 0.013665531 Test MSE 0.0020013209477021277 Test RE 0.032321703907026086\n",
      "277 Train Loss 0.013475585 Test MSE 0.002006786603076613 Test RE 0.03236580948741933\n",
      "278 Train Loss 0.013270663 Test MSE 0.0018630919969018051 Test RE 0.031185522655946755\n",
      "279 Train Loss 0.013114295 Test MSE 0.0017563567843516875 Test RE 0.03027905021478459\n",
      "280 Train Loss 0.012955948 Test MSE 0.0018192405841435067 Test RE 0.0308163320325318\n",
      "281 Train Loss 0.0127576385 Test MSE 0.001869417981822971 Test RE 0.03123842180654776\n",
      "282 Train Loss 0.012647139 Test MSE 0.0017790376851746787 Test RE 0.030473928959639258\n",
      "283 Train Loss 0.012562476 Test MSE 0.0017566431341168947 Test RE 0.030281518405082957\n",
      "284 Train Loss 0.0124716265 Test MSE 0.0016807317545124835 Test RE 0.029620001732612332\n",
      "285 Train Loss 0.012368562 Test MSE 0.0016805240575984788 Test RE 0.02961817152591629\n",
      "286 Train Loss 0.012247065 Test MSE 0.0016442836427545974 Test RE 0.02929707380450904\n",
      "287 Train Loss 0.012110495 Test MSE 0.0015330866470851599 Test RE 0.02828910628838726\n",
      "288 Train Loss 0.011930869 Test MSE 0.0013599120061082567 Test RE 0.02664350036421312\n",
      "289 Train Loss 0.011833617 Test MSE 0.0013823623329501495 Test RE 0.026862524379155883\n",
      "290 Train Loss 0.011678815 Test MSE 0.0013020942708968917 Test RE 0.026070964058800376\n",
      "291 Train Loss 0.011501354 Test MSE 0.0012494766777133035 Test RE 0.025538768650994217\n",
      "292 Train Loss 0.01134815 Test MSE 0.0011856034348759782 Test RE 0.024877435065173818\n",
      "293 Train Loss 0.01120377 Test MSE 0.0010659902845006205 Test RE 0.023589161305598863\n",
      "294 Train Loss 0.011017699 Test MSE 0.0009965623291758275 Test RE 0.02280804757196845\n",
      "295 Train Loss 0.010874695 Test MSE 0.0008597324981027783 Test RE 0.021184467340892233\n",
      "296 Train Loss 0.01076237 Test MSE 0.0007071649645465785 Test RE 0.019213046989831572\n",
      "297 Train Loss 0.010657586 Test MSE 0.000651914316659167 Test RE 0.018447228880602445\n",
      "298 Train Loss 0.010548989 Test MSE 0.0006229917353790503 Test RE 0.01803337523769135\n",
      "299 Train Loss 0.010487453 Test MSE 0.0006337357429931761 Test RE 0.018188210758354365\n",
      "Training time: 166.75\n",
      "KG_tanh_high\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 54563.344 Test MSE 9.775086230999793 Test RE 2.2588956833562612\n",
      "1 Train Loss 26959.926 Test MSE 2.8012150000871086 Test RE 1.209230516215155\n",
      "2 Train Loss 11843.081 Test MSE 9.768376373298441 Test RE 2.2581202697106177\n",
      "3 Train Loss 3525.6294 Test MSE 16.638496269885966 Test RE 2.947086708415916\n",
      "4 Train Loss 1649.702 Test MSE 18.613953438364604 Test RE 3.1171319636385917\n",
      "5 Train Loss 964.4647 Test MSE 20.36417935781242 Test RE 3.2603883572283174\n",
      "6 Train Loss 574.2366 Test MSE 21.962420306465727 Test RE 3.385914413849842\n",
      "7 Train Loss 385.66467 Test MSE 22.22304622502984 Test RE 3.405945322407172\n",
      "8 Train Loss 282.63208 Test MSE 21.848965655617015 Test RE 3.3771575206980256\n",
      "9 Train Loss 205.04913 Test MSE 21.72751245175518 Test RE 3.367758032371181\n",
      "10 Train Loss 166.04646 Test MSE 21.188292293039332 Test RE 3.32570600491027\n",
      "11 Train Loss 142.63156 Test MSE 20.020491570006065 Test RE 3.2327583729719866\n",
      "12 Train Loss 120.447174 Test MSE 19.275797683540166 Test RE 3.172064843240876\n",
      "13 Train Loss 95.53267 Test MSE 18.62361332801091 Test RE 3.117940691490983\n",
      "14 Train Loss 78.70503 Test MSE 18.72508480229095 Test RE 3.1264232627365085\n",
      "15 Train Loss 63.14451 Test MSE 18.250852484856658 Test RE 3.0865794069043884\n",
      "16 Train Loss 52.478382 Test MSE 17.854672638921656 Test RE 3.052894685366318\n",
      "17 Train Loss 44.933014 Test MSE 17.49513163475163 Test RE 3.02200016797371\n",
      "18 Train Loss 41.081436 Test MSE 17.59864860469819 Test RE 3.0309274206372794\n",
      "19 Train Loss 36.79171 Test MSE 17.52936305714817 Test RE 3.0249551846576317\n",
      "20 Train Loss 34.891956 Test MSE 17.511353560553097 Test RE 3.0234008806126385\n",
      "21 Train Loss 32.71477 Test MSE 17.215637097329612 Test RE 2.9977639077337885\n",
      "22 Train Loss 31.03877 Test MSE 17.160481654549066 Test RE 2.9929579386386522\n",
      "23 Train Loss 29.29205 Test MSE 17.0315606748557 Test RE 2.981694195795825\n",
      "24 Train Loss 28.360865 Test MSE 16.884417046732626 Test RE 2.9687861294052427\n",
      "25 Train Loss 27.3392 Test MSE 16.834685260590412 Test RE 2.9644107365573986\n",
      "26 Train Loss 25.898003 Test MSE 16.75812946953597 Test RE 2.957662721980592\n",
      "27 Train Loss 25.26969 Test MSE 16.786484136774533 Test RE 2.9601638393710763\n",
      "28 Train Loss 24.668903 Test MSE 16.630215824739327 Test RE 2.9463532819583143\n",
      "29 Train Loss 24.056967 Test MSE 16.6126801693046 Test RE 2.9447994878440857\n",
      "30 Train Loss 23.460873 Test MSE 16.54656531297099 Test RE 2.9389338150432467\n",
      "31 Train Loss 22.742323 Test MSE 16.51763534876813 Test RE 2.936363479611802\n",
      "32 Train Loss 22.425772 Test MSE 16.51415509321335 Test RE 2.936054118330617\n",
      "33 Train Loss 22.059559 Test MSE 16.506865696857446 Test RE 2.935406055371153\n",
      "34 Train Loss 21.723658 Test MSE 16.47794458434813 Test RE 2.9328334159478353\n",
      "35 Train Loss 21.457956 Test MSE 16.457398676857665 Test RE 2.931004409942409\n",
      "36 Train Loss 21.362394 Test MSE 16.483466617159767 Test RE 2.933324795369523\n",
      "37 Train Loss 21.121555 Test MSE 16.43064494579568 Test RE 2.9286210685690244\n",
      "38 Train Loss 21.012634 Test MSE 16.404345699674593 Test RE 2.926276322778371\n",
      "39 Train Loss 20.754711 Test MSE 16.326629383532772 Test RE 2.919336411479474\n",
      "40 Train Loss 20.521763 Test MSE 16.263157215013138 Test RE 2.9136562110172823\n",
      "41 Train Loss 20.393953 Test MSE 16.220178929751818 Test RE 2.9098037367630716\n",
      "42 Train Loss 20.202011 Test MSE 16.142667164226093 Test RE 2.9028428356261373\n",
      "43 Train Loss 20.047518 Test MSE 16.051942447480666 Test RE 2.8946740904307062\n",
      "44 Train Loss 19.809902 Test MSE 15.917997660887032 Test RE 2.882571544617509\n",
      "45 Train Loss 19.644983 Test MSE 15.939691979204033 Test RE 2.88453517513913\n",
      "46 Train Loss 19.502209 Test MSE 15.890368791281915 Test RE 2.8800688183388803\n",
      "47 Train Loss 19.387667 Test MSE 15.852809114209906 Test RE 2.876663030399933\n",
      "48 Train Loss 19.324259 Test MSE 15.82188637052543 Test RE 2.8738560283663626\n",
      "49 Train Loss 19.220774 Test MSE 15.700747898753118 Test RE 2.86283321333866\n",
      "50 Train Loss 19.139542 Test MSE 15.6347284048267 Test RE 2.856807962099088\n",
      "51 Train Loss 19.023335 Test MSE 15.591418993890855 Test RE 2.8528484282719226\n",
      "52 Train Loss 18.875792 Test MSE 15.555592248328313 Test RE 2.8495688339902574\n",
      "53 Train Loss 18.807575 Test MSE 15.497382866085452 Test RE 2.844232261016458\n",
      "54 Train Loss 18.727985 Test MSE 15.454728703253565 Test RE 2.8403154080987174\n",
      "55 Train Loss 18.655836 Test MSE 15.448500149432318 Test RE 2.8397429994674495\n",
      "56 Train Loss 18.571728 Test MSE 15.362934057370925 Test RE 2.831867700710908\n",
      "57 Train Loss 18.46264 Test MSE 15.301102345624324 Test RE 2.8261631990812526\n",
      "58 Train Loss 18.373022 Test MSE 15.234358796564106 Test RE 2.819992587736818\n",
      "59 Train Loss 18.264416 Test MSE 15.222141920710895 Test RE 2.818861643878352\n",
      "60 Train Loss 18.185654 Test MSE 15.211060511487087 Test RE 2.8178354201503915\n",
      "61 Train Loss 18.14088 Test MSE 15.128928795343157 Test RE 2.810217709671536\n",
      "62 Train Loss 18.0727 Test MSE 15.068868912315104 Test RE 2.8046340628534505\n",
      "63 Train Loss 17.972979 Test MSE 15.051912452236822 Test RE 2.8030556414143706\n",
      "64 Train Loss 17.92797 Test MSE 15.032274924466954 Test RE 2.8012265366882265\n",
      "65 Train Loss 17.862848 Test MSE 14.916712899152515 Test RE 2.7904384169693\n",
      "66 Train Loss 17.759798 Test MSE 14.779916999067462 Test RE 2.777613884865395\n",
      "67 Train Loss 17.63235 Test MSE 14.68103107757649 Test RE 2.768306394479353\n",
      "68 Train Loss 17.525562 Test MSE 14.575223538360852 Test RE 2.7583126362280623\n",
      "69 Train Loss 17.348688 Test MSE 14.220990431745227 Test RE 2.7245877458752963\n",
      "70 Train Loss 16.993599 Test MSE 13.7548772060912 Test RE 2.679564625164969\n",
      "71 Train Loss 16.151052 Test MSE 13.122147112555945 Test RE 2.617208535897374\n",
      "72 Train Loss 15.578494 Test MSE 12.729001947560976 Test RE 2.577704046860061\n",
      "73 Train Loss 15.155525 Test MSE 12.44893280579924 Test RE 2.549188427744754\n",
      "74 Train Loss 14.544703 Test MSE 12.145558696954438 Test RE 2.5179356423950052\n",
      "75 Train Loss 14.05932 Test MSE 11.761250282319414 Test RE 2.477779314031159\n",
      "76 Train Loss 13.490288 Test MSE 11.657992790372614 Test RE 2.4668785464649208\n",
      "77 Train Loss 12.987492 Test MSE 11.507734660940665 Test RE 2.450929373431598\n",
      "78 Train Loss 12.563255 Test MSE 11.348971856221238 Test RE 2.433963921426297\n",
      "79 Train Loss 12.295714 Test MSE 11.194942722485868 Test RE 2.4173905210846987\n",
      "80 Train Loss 12.064594 Test MSE 11.027595797901576 Test RE 2.3992543810964566\n",
      "81 Train Loss 11.75892 Test MSE 10.981654860108264 Test RE 2.394251521168063\n",
      "82 Train Loss 11.444259 Test MSE 10.814554599978365 Test RE 2.375965858258909\n",
      "83 Train Loss 11.123925 Test MSE 10.601982461741896 Test RE 2.352498838230342\n",
      "84 Train Loss 10.913722 Test MSE 10.487721334353445 Test RE 2.339787662075351\n",
      "85 Train Loss 10.794899 Test MSE 10.44055557684103 Test RE 2.3345204448173793\n",
      "86 Train Loss 10.552138 Test MSE 10.321166572062475 Test RE 2.321134306171977\n",
      "87 Train Loss 10.340915 Test MSE 10.169560313608939 Test RE 2.304023822023845\n",
      "88 Train Loss 10.060092 Test MSE 10.05175150893391 Test RE 2.2906395175367917\n",
      "89 Train Loss 9.903719 Test MSE 9.97873089357181 Test RE 2.2823042146708175\n",
      "90 Train Loss 9.664893 Test MSE 9.70124314626286 Test RE 2.25034741918629\n",
      "91 Train Loss 9.432226 Test MSE 9.343273146231256 Test RE 2.208438957466494\n",
      "92 Train Loss 9.271838 Test MSE 9.052332323531711 Test RE 2.173782666692071\n",
      "93 Train Loss 9.024899 Test MSE 9.054918392932539 Test RE 2.174093147527488\n",
      "94 Train Loss 8.842362 Test MSE 8.873941224421488 Test RE 2.152257108266834\n",
      "95 Train Loss 8.618628 Test MSE 8.617479961828847 Test RE 2.12092845128074\n",
      "96 Train Loss 8.372141 Test MSE 8.216353449969365 Test RE 2.070977752950155\n",
      "97 Train Loss 8.190002 Test MSE 7.820335054992492 Test RE 2.0204520919014675\n",
      "98 Train Loss 7.9014215 Test MSE 7.451676891649311 Test RE 1.9722541773740176\n",
      "99 Train Loss 7.4998665 Test MSE 6.997951603153099 Test RE 1.911266924699717\n",
      "100 Train Loss 7.2615023 Test MSE 6.465785532997623 Test RE 1.837158068534183\n",
      "101 Train Loss 6.8493934 Test MSE 5.806232867063061 Test RE 1.7409371860012042\n",
      "102 Train Loss 6.578615 Test MSE 5.256542478148669 Test RE 1.6564791203613167\n",
      "103 Train Loss 6.387071 Test MSE 4.983233371261841 Test RE 1.612840758261542\n",
      "104 Train Loss 6.0033517 Test MSE 4.5717858220662295 Test RE 1.5448233142550922\n",
      "105 Train Loss 5.3939767 Test MSE 4.138967012634827 Test RE 1.4698799281064505\n",
      "106 Train Loss 4.9992356 Test MSE 3.961184767337725 Test RE 1.4379653694474834\n",
      "107 Train Loss 4.420426 Test MSE 3.62644735665078 Test RE 1.3758673526590206\n",
      "108 Train Loss 4.0827866 Test MSE 3.261358268573759 Test RE 1.304773512632677\n",
      "109 Train Loss 3.7827437 Test MSE 2.99709709878777 Test RE 1.2507954234620613\n",
      "110 Train Loss 3.496499 Test MSE 2.9994504755226252 Test RE 1.2512864010878002\n",
      "111 Train Loss 3.2556124 Test MSE 2.8286441939708618 Test RE 1.215136421061392\n",
      "112 Train Loss 3.0313568 Test MSE 2.6035854486889263 Test RE 1.1657939433721154\n",
      "113 Train Loss 2.8167198 Test MSE 2.3187253949470845 Test RE 1.1001718693440363\n",
      "114 Train Loss 2.6489673 Test MSE 2.197723981610126 Test RE 1.0710813332434317\n",
      "115 Train Loss 2.4386802 Test MSE 2.0204322132847072 Test RE 1.0269706192579875\n",
      "116 Train Loss 2.3069048 Test MSE 1.8650391247754425 Test RE 0.9866880089480602\n",
      "117 Train Loss 2.142922 Test MSE 1.7004059618770426 Test RE 0.9421329356636124\n",
      "118 Train Loss 1.9968361 Test MSE 1.6698903861428072 Test RE 0.9336408795957105\n",
      "119 Train Loss 1.873748 Test MSE 1.5373946220165435 Test RE 0.8958360921431958\n",
      "120 Train Loss 1.7606272 Test MSE 1.3950376367278476 Test RE 0.8533532349786611\n",
      "121 Train Loss 1.5999541 Test MSE 1.2479405994841453 Test RE 0.8071101963573931\n",
      "122 Train Loss 1.4692819 Test MSE 1.2105693191958524 Test RE 0.7949333334124403\n",
      "123 Train Loss 1.3360336 Test MSE 1.0830885777801855 Test RE 0.7519134696883601\n",
      "124 Train Loss 1.2627406 Test MSE 1.0109139874713482 Test RE 0.7264286759562045\n",
      "125 Train Loss 1.1819985 Test MSE 0.9360878356926403 Test RE 0.6990273653660454\n",
      "126 Train Loss 1.0992254 Test MSE 0.8918830115686115 Test RE 0.6823227043569975\n",
      "127 Train Loss 1.0404019 Test MSE 0.8371086947591748 Test RE 0.6610385746382091\n",
      "128 Train Loss 1.0050385 Test MSE 0.7928872079661162 Test RE 0.6433415224994293\n",
      "129 Train Loss 0.9576625 Test MSE 0.7350515934869237 Test RE 0.6194336420187677\n",
      "130 Train Loss 0.90552866 Test MSE 0.6786979948561841 Test RE 0.5952154010594121\n",
      "131 Train Loss 0.86617196 Test MSE 0.6107415552826272 Test RE 0.5646308617462633\n",
      "132 Train Loss 0.8195561 Test MSE 0.5410860442442523 Test RE 0.5314581155230841\n",
      "133 Train Loss 0.7904903 Test MSE 0.48125721901846924 Test RE 0.501215514366643\n",
      "134 Train Loss 0.75959915 Test MSE 0.42944370518373004 Test RE 0.473466218144971\n",
      "135 Train Loss 0.73612183 Test MSE 0.372638700161645 Test RE 0.4410419047021086\n",
      "136 Train Loss 0.69024026 Test MSE 0.30564677329836204 Test RE 0.3994346944946951\n",
      "137 Train Loss 0.66743565 Test MSE 0.30641483413708626 Test RE 0.39993625001814287\n",
      "138 Train Loss 0.63476247 Test MSE 0.26395931952098534 Test RE 0.3711969310514951\n",
      "139 Train Loss 0.60109985 Test MSE 0.26609767727655714 Test RE 0.37269744778469927\n",
      "140 Train Loss 0.5595389 Test MSE 0.27843268019385686 Test RE 0.3812378229560905\n",
      "141 Train Loss 0.51919794 Test MSE 0.2317504541702337 Test RE 0.34781329112999443\n",
      "142 Train Loss 0.49978316 Test MSE 0.2009086732552874 Test RE 0.32384352623149776\n",
      "143 Train Loss 0.46708685 Test MSE 0.16365804760191924 Test RE 0.2922836753720868\n",
      "144 Train Loss 0.43478087 Test MSE 0.15563183551178794 Test RE 0.2850264059898518\n",
      "145 Train Loss 0.41538984 Test MSE 0.15098168343149343 Test RE 0.2807359359515914\n",
      "146 Train Loss 0.40019944 Test MSE 0.13157934414433015 Test RE 0.26207749895319027\n",
      "147 Train Loss 0.371607 Test MSE 0.11226614185353964 Test RE 0.24208076095926448\n",
      "148 Train Loss 0.34270337 Test MSE 0.11091470504145996 Test RE 0.24061929012234887\n",
      "149 Train Loss 0.3290168 Test MSE 0.10064673142237703 Test RE 0.22921113653816946\n",
      "150 Train Loss 0.31410044 Test MSE 0.09355552173884253 Test RE 0.22098896578224556\n",
      "151 Train Loss 0.29392824 Test MSE 0.07487651728790537 Test RE 0.19770092208285123\n",
      "152 Train Loss 0.2862178 Test MSE 0.0685307739005664 Test RE 0.18913795759744406\n",
      "153 Train Loss 0.2736833 Test MSE 0.06205878916962844 Test RE 0.17998550287372503\n",
      "154 Train Loss 0.26409903 Test MSE 0.05470760933497316 Test RE 0.16898950949504207\n",
      "155 Train Loss 0.25252426 Test MSE 0.06469877878668394 Test RE 0.18377393665514047\n",
      "156 Train Loss 0.23990986 Test MSE 0.055100527315896625 Test RE 0.16959527734027088\n",
      "157 Train Loss 0.23132052 Test MSE 0.0543882487495666 Test RE 0.16849554182135282\n",
      "158 Train Loss 0.21805048 Test MSE 0.04606506285890393 Test RE 0.15506783053168938\n",
      "159 Train Loss 0.2063782 Test MSE 0.04307625667838295 Test RE 0.14995289509126122\n",
      "160 Train Loss 0.20093514 Test MSE 0.039600271942850186 Test RE 0.143775524650632\n",
      "161 Train Loss 0.19301434 Test MSE 0.03754415548797277 Test RE 0.1399932341507505\n",
      "162 Train Loss 0.18709272 Test MSE 0.0332664486569544 Test RE 0.13177684246923382\n",
      "163 Train Loss 0.17349385 Test MSE 0.03466863568585259 Test RE 0.13452538774622066\n",
      "164 Train Loss 0.16659321 Test MSE 0.03531958427278856 Test RE 0.13578245869506475\n",
      "165 Train Loss 0.16363764 Test MSE 0.03528738573520389 Test RE 0.13572055262284718\n",
      "166 Train Loss 0.15793149 Test MSE 0.03741329978092039 Test RE 0.13974905628368017\n",
      "167 Train Loss 0.14771864 Test MSE 0.03646834183042359 Test RE 0.13797292945134437\n",
      "168 Train Loss 0.14266787 Test MSE 0.032516439093101396 Test RE 0.13028288487471393\n",
      "169 Train Loss 0.14010914 Test MSE 0.028548025001632067 Test RE 0.12207420681488204\n",
      "170 Train Loss 0.13824527 Test MSE 0.026032139486637334 Test RE 0.11657107680859129\n",
      "171 Train Loss 0.13545439 Test MSE 0.025437503425149027 Test RE 0.11523200523401268\n",
      "172 Train Loss 0.13060762 Test MSE 0.023348488068218515 Test RE 0.11039903021921213\n",
      "173 Train Loss 0.12315185 Test MSE 0.02235441574880189 Test RE 0.10802332446344672\n",
      "174 Train Loss 0.11829602 Test MSE 0.020284375777666286 Test RE 0.10290031414499323\n",
      "175 Train Loss 0.115762934 Test MSE 0.020426387102937125 Test RE 0.10325988948486808\n",
      "176 Train Loss 0.11414017 Test MSE 0.02176618348978888 Test RE 0.10659259122749387\n",
      "177 Train Loss 0.11146874 Test MSE 0.020486132920230094 Test RE 0.1034107933577292\n",
      "178 Train Loss 0.108637795 Test MSE 0.020391507217250634 Test RE 0.10317168906081245\n",
      "179 Train Loss 0.10626738 Test MSE 0.018912404287421705 Test RE 0.09935946593370601\n",
      "180 Train Loss 0.104171425 Test MSE 0.01912153887049591 Test RE 0.09990731723655433\n",
      "181 Train Loss 0.10183647 Test MSE 0.019815444210169862 Test RE 0.10170394126050951\n",
      "182 Train Loss 0.097915635 Test MSE 0.019906837588492057 Test RE 0.1019382124073434\n",
      "183 Train Loss 0.095718905 Test MSE 0.01935813368048102 Test RE 0.10052350413664693\n",
      "184 Train Loss 0.093810506 Test MSE 0.019677548735970822 Test RE 0.10134944510494115\n",
      "185 Train Loss 0.092511505 Test MSE 0.0208016541965721 Test RE 0.10420410147146317\n",
      "186 Train Loss 0.090464234 Test MSE 0.022798950042944084 Test RE 0.10909209961304646\n",
      "187 Train Loss 0.08907327 Test MSE 0.02264444231573424 Test RE 0.10872181442606142\n",
      "188 Train Loss 0.08706144 Test MSE 0.02355654909500061 Test RE 0.11088982839791164\n",
      "189 Train Loss 0.085370205 Test MSE 0.0223747882549399 Test RE 0.10807253632152261\n",
      "190 Train Loss 0.08321914 Test MSE 0.019786894562907744 Test RE 0.1016306484734269\n",
      "191 Train Loss 0.08142035 Test MSE 0.01808538817995868 Test RE 0.09716274913367358\n",
      "192 Train Loss 0.07950874 Test MSE 0.01380250191884262 Test RE 0.08488183994288725\n",
      "193 Train Loss 0.07852679 Test MSE 0.012211646400621837 Test RE 0.07984045202723172\n",
      "194 Train Loss 0.07621751 Test MSE 0.011494692402573791 Test RE 0.07746125944673748\n",
      "195 Train Loss 0.07339675 Test MSE 0.011226477698949857 Test RE 0.07655219289186636\n",
      "196 Train Loss 0.07134898 Test MSE 0.01102991846262914 Test RE 0.07587907497914152\n",
      "197 Train Loss 0.07018497 Test MSE 0.010718536156779373 Test RE 0.0748003475119573\n",
      "198 Train Loss 0.06888123 Test MSE 0.010123694432253314 Test RE 0.07269514229597272\n",
      "199 Train Loss 0.067603394 Test MSE 0.01055150550104614 Test RE 0.0742152392336351\n",
      "200 Train Loss 0.065254234 Test MSE 0.011565463126897681 Test RE 0.07769935095975634\n",
      "201 Train Loss 0.06310327 Test MSE 0.011911393070859094 Test RE 0.07885280648385717\n",
      "202 Train Loss 0.06120569 Test MSE 0.013285755177560633 Test RE 0.08327775318938539\n",
      "203 Train Loss 0.060029168 Test MSE 0.012896078399408225 Test RE 0.08204737846051502\n",
      "204 Train Loss 0.059254546 Test MSE 0.0136091381972344 Test RE 0.0842851742521222\n",
      "205 Train Loss 0.058247738 Test MSE 0.014386256471105405 Test RE 0.08665822237951852\n",
      "206 Train Loss 0.056695573 Test MSE 0.013992194533781638 Test RE 0.08546312995829752\n",
      "207 Train Loss 0.0555741 Test MSE 0.014156659520329738 Test RE 0.0859639316952227\n",
      "208 Train Loss 0.054149322 Test MSE 0.014483562146369726 Test RE 0.0869507976660008\n",
      "209 Train Loss 0.052587833 Test MSE 0.013620154024073258 Test RE 0.08431927939019344\n",
      "210 Train Loss 0.05126588 Test MSE 0.012761153143291558 Test RE 0.08161703943237389\n",
      "211 Train Loss 0.050196655 Test MSE 0.013177630286670738 Test RE 0.08293818674575955\n",
      "212 Train Loss 0.049221784 Test MSE 0.013177604760619573 Test RE 0.08293810641699872\n",
      "213 Train Loss 0.048426453 Test MSE 0.014000589496537366 Test RE 0.08548876397192902\n",
      "214 Train Loss 0.047811367 Test MSE 0.014175779475739616 Test RE 0.08602196346265001\n",
      "215 Train Loss 0.047170904 Test MSE 0.014282097127104093 Test RE 0.08634394114133288\n",
      "216 Train Loss 0.046622187 Test MSE 0.014430376088452075 Test RE 0.08679100191011595\n",
      "217 Train Loss 0.04561533 Test MSE 0.013751248780154924 Test RE 0.08472409655252648\n",
      "218 Train Loss 0.045044784 Test MSE 0.013764553178588738 Test RE 0.08476507212658933\n",
      "219 Train Loss 0.04413702 Test MSE 0.014087325958443024 Test RE 0.08575316512503263\n",
      "220 Train Loss 0.04299688 Test MSE 0.012788370341979672 Test RE 0.08170403015970974\n",
      "221 Train Loss 0.041759916 Test MSE 0.01292662583510492 Test RE 0.0821444953700561\n",
      "222 Train Loss 0.04069772 Test MSE 0.012961488686077353 Test RE 0.08225519181316772\n",
      "223 Train Loss 0.039953448 Test MSE 0.013101748216104969 Test RE 0.08269904634129284\n",
      "224 Train Loss 0.039105788 Test MSE 0.010948309707915388 Test RE 0.07559784472483556\n",
      "225 Train Loss 0.038124606 Test MSE 0.010407686500634247 Test RE 0.07370772008463947\n",
      "226 Train Loss 0.037307378 Test MSE 0.010250151036492763 Test RE 0.07314775629475923\n",
      "227 Train Loss 0.036485773 Test MSE 0.008970742563586338 Test RE 0.06843055680511963\n",
      "228 Train Loss 0.035367515 Test MSE 0.008023881742230538 Test RE 0.06471845434198821\n",
      "229 Train Loss 0.03462796 Test MSE 0.007347576903403105 Test RE 0.06193097924143082\n",
      "230 Train Loss 0.03418163 Test MSE 0.006987523284825218 Test RE 0.06039451680083382\n",
      "231 Train Loss 0.033349667 Test MSE 0.007345838716269646 Test RE 0.06192365342505003\n",
      "232 Train Loss 0.03295733 Test MSE 0.006925092925679956 Test RE 0.06012411261944411\n",
      "233 Train Loss 0.032570828 Test MSE 0.00692546611830359 Test RE 0.06012573263908047\n",
      "234 Train Loss 0.03222201 Test MSE 0.006891625976189991 Test RE 0.0599786555395182\n",
      "235 Train Loss 0.031752896 Test MSE 0.006678882071544653 Test RE 0.05904563050952734\n",
      "236 Train Loss 0.03144539 Test MSE 0.006484505969437214 Test RE 0.05818008134014348\n",
      "237 Train Loss 0.031019531 Test MSE 0.006252852619816636 Test RE 0.057131414020483856\n",
      "238 Train Loss 0.030640641 Test MSE 0.005980340297387696 Test RE 0.05587259279809283\n",
      "239 Train Loss 0.030104192 Test MSE 0.005814667050949649 Test RE 0.055093238625718875\n",
      "240 Train Loss 0.029693225 Test MSE 0.005113502263812192 Test RE 0.051664841713345636\n",
      "241 Train Loss 0.02911708 Test MSE 0.005058831898815342 Test RE 0.05138791547189061\n",
      "242 Train Loss 0.028827632 Test MSE 0.004874478634017319 Test RE 0.050442890234084985\n",
      "243 Train Loss 0.028403394 Test MSE 0.004635551517690803 Test RE 0.04919110550949646\n",
      "244 Train Loss 0.028021196 Test MSE 0.004493552534748917 Test RE 0.048431819898407856\n",
      "245 Train Loss 0.027640224 Test MSE 0.004441537171904825 Test RE 0.04815069138722888\n",
      "246 Train Loss 0.027448812 Test MSE 0.004112662596758975 Test RE 0.04633374643191942\n",
      "247 Train Loss 0.027311007 Test MSE 0.0042003755546797744 Test RE 0.04682523202631547\n",
      "248 Train Loss 0.027136263 Test MSE 0.0041544926039794915 Test RE 0.04656878122812597\n",
      "249 Train Loss 0.026926296 Test MSE 0.00413740460658485 Test RE 0.04647291065495298\n",
      "250 Train Loss 0.026299652 Test MSE 0.003970024946849492 Test RE 0.04552316982291063\n",
      "251 Train Loss 0.025988622 Test MSE 0.003605589587247852 Test RE 0.043383443675293766\n",
      "252 Train Loss 0.025722153 Test MSE 0.003483597350070906 Test RE 0.04264320642165526\n",
      "253 Train Loss 0.025363797 Test MSE 0.003450492950020499 Test RE 0.0424401049400797\n",
      "254 Train Loss 0.024975501 Test MSE 0.0032173138147720782 Test RE 0.040981003503667776\n",
      "255 Train Loss 0.024620928 Test MSE 0.003374683724033928 Test RE 0.04197129944842841\n",
      "256 Train Loss 0.024256613 Test MSE 0.003082105917998033 Test RE 0.040110646003053266\n",
      "257 Train Loss 0.024089755 Test MSE 0.0029235530716698577 Test RE 0.03906531836083264\n",
      "258 Train Loss 0.02389009 Test MSE 0.00288743222214062 Test RE 0.03882323995850237\n",
      "259 Train Loss 0.023674125 Test MSE 0.002839144191065389 Test RE 0.03849724062915099\n",
      "260 Train Loss 0.023412513 Test MSE 0.0031124731657887848 Test RE 0.0403077619297158\n",
      "261 Train Loss 0.022953197 Test MSE 0.0034483240190724194 Test RE 0.04242676421917356\n",
      "262 Train Loss 0.022503702 Test MSE 0.0031649572489516153 Test RE 0.04064618607074162\n",
      "263 Train Loss 0.022252832 Test MSE 0.003080825723742064 Test RE 0.040102314888993816\n",
      "264 Train Loss 0.021984875 Test MSE 0.003232726606523069 Test RE 0.0410790475623886\n",
      "265 Train Loss 0.021572297 Test MSE 0.003095003854169354 Test RE 0.04019448550304167\n",
      "266 Train Loss 0.020952955 Test MSE 0.002558956711758707 Test RE 0.036548313923236236\n",
      "267 Train Loss 0.020566627 Test MSE 0.002552723731450146 Test RE 0.036503775497060506\n",
      "268 Train Loss 0.020110594 Test MSE 0.001815013073856387 Test RE 0.03078050605844224\n",
      "269 Train Loss 0.019621499 Test MSE 0.0019030712222052302 Test RE 0.03151834448439616\n",
      "270 Train Loss 0.01923473 Test MSE 0.0017691070372693948 Test RE 0.030388756688963264\n",
      "271 Train Loss 0.018600946 Test MSE 0.0016835195779451638 Test RE 0.029644556847134417\n",
      "272 Train Loss 0.018203147 Test MSE 0.001700743076716955 Test RE 0.029795812506380557\n",
      "273 Train Loss 0.017798888 Test MSE 0.0016191161909093832 Test RE 0.02907199831121547\n",
      "274 Train Loss 0.017413193 Test MSE 0.00158843589260418 Test RE 0.028795241342411838\n",
      "275 Train Loss 0.017152045 Test MSE 0.0016141609264098016 Test RE 0.029027477160250607\n",
      "276 Train Loss 0.016999112 Test MSE 0.0015335157299278196 Test RE 0.02829306481250513\n",
      "277 Train Loss 0.01674262 Test MSE 0.0015107236768877137 Test RE 0.028082023262800758\n",
      "278 Train Loss 0.016541097 Test MSE 0.0014418325033382887 Test RE 0.027434262052583584\n",
      "279 Train Loss 0.01640142 Test MSE 0.0013798364682810196 Test RE 0.026837971437240097\n",
      "280 Train Loss 0.016117077 Test MSE 0.001403937032222149 Test RE 0.02707133615977933\n",
      "281 Train Loss 0.015911331 Test MSE 0.001438370100799068 Test RE 0.027401302068314842\n",
      "282 Train Loss 0.015732516 Test MSE 0.0014285682997861458 Test RE 0.027307779114648344\n",
      "283 Train Loss 0.015536904 Test MSE 0.0013500853569965812 Test RE 0.026547063605007384\n",
      "284 Train Loss 0.0153322015 Test MSE 0.0014445280828675401 Test RE 0.027459894954944507\n",
      "285 Train Loss 0.015232341 Test MSE 0.001401835055779958 Test RE 0.027051062947930075\n",
      "286 Train Loss 0.015125753 Test MSE 0.001462583552132969 Test RE 0.027630975607774617\n",
      "287 Train Loss 0.015042029 Test MSE 0.0014024955832714634 Test RE 0.02705743526198422\n",
      "288 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "289 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "290 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "291 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "292 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "293 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "294 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "295 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "296 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "297 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "298 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "299 Train Loss 0.014997912 Test MSE 0.001376237104557289 Test RE 0.026802944569414455\n",
      "Training time: 162.60\n",
      "KG_tanh_high\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 51988.16 Test MSE 14.924731359148778 Test RE 2.7911883145124774\n",
      "1 Train Loss 31526.102 Test MSE 8.26196466489797 Test RE 2.0767180781170937\n",
      "2 Train Loss 17302.951 Test MSE 14.748372555112834 Test RE 2.7746482022464254\n",
      "3 Train Loss 9939.143 Test MSE 11.82981484814898 Test RE 2.484991174125694\n",
      "4 Train Loss 5215.0044 Test MSE 10.757880831498706 Test RE 2.3697320454564488\n",
      "5 Train Loss 1738.4569 Test MSE 6.217750291698338 Test RE 1.8015756991949923\n",
      "6 Train Loss 689.2252 Test MSE 3.3115564904528316 Test RE 1.3147765842742523\n",
      "7 Train Loss 353.07266 Test MSE 2.591190355451406 Test RE 1.163015589361786\n",
      "8 Train Loss 192.37181 Test MSE 2.674404563942653 Test RE 1.1815427216287373\n",
      "9 Train Loss 100.87507 Test MSE 2.274722030447645 Test RE 1.0896826692543615\n",
      "10 Train Loss 67.5047 Test MSE 2.0471075786121595 Test RE 1.0337278334374906\n",
      "11 Train Loss 50.428017 Test MSE 1.7925282778208227 Test RE 0.9673171433816122\n",
      "12 Train Loss 38.310276 Test MSE 1.5690655422471995 Test RE 0.9050163379521579\n",
      "13 Train Loss 28.73682 Test MSE 1.303418517714947 Test RE 0.8248553968939871\n",
      "14 Train Loss 21.18565 Test MSE 0.9000228336843963 Test RE 0.6854292613120343\n",
      "15 Train Loss 15.918556 Test MSE 0.5696789005071138 Test RE 0.5453193949517939\n",
      "16 Train Loss 10.832701 Test MSE 0.4076662275078459 Test RE 0.4613050873747096\n",
      "17 Train Loss 7.4756136 Test MSE 0.32481483213044154 Test RE 0.41176914733058856\n",
      "18 Train Loss 5.9779863 Test MSE 0.2947233652801437 Test RE 0.3922321248425335\n",
      "19 Train Loss 5.20436 Test MSE 0.2754510845494843 Test RE 0.3791910867141462\n",
      "20 Train Loss 4.566974 Test MSE 0.25417282447374223 Test RE 0.3642507330047971\n",
      "21 Train Loss 4.063801 Test MSE 0.2288709861932938 Test RE 0.34564577080266856\n",
      "22 Train Loss 3.6359532 Test MSE 0.20149107673829744 Test RE 0.3243125729535594\n",
      "23 Train Loss 3.2737634 Test MSE 0.17664750341777602 Test RE 0.3036614271734667\n",
      "24 Train Loss 2.9257562 Test MSE 0.16077048360801585 Test RE 0.2896936902023959\n",
      "25 Train Loss 2.6279395 Test MSE 0.13810995942557758 Test RE 0.26850252597022256\n",
      "26 Train Loss 2.320714 Test MSE 0.1279111163146946 Test RE 0.25839851976305195\n",
      "27 Train Loss 2.042748 Test MSE 0.10823508474562664 Test RE 0.23769492412767473\n",
      "28 Train Loss 1.8403928 Test MSE 0.10373728609942882 Test RE 0.2327037157005221\n",
      "29 Train Loss 1.6302512 Test MSE 0.10274833533022339 Test RE 0.23159185113585462\n",
      "30 Train Loss 1.508585 Test MSE 0.10220858099461079 Test RE 0.23098275463307708\n",
      "31 Train Loss 1.3619822 Test MSE 0.1036868405933561 Test RE 0.2326471290835554\n",
      "32 Train Loss 1.2355769 Test MSE 0.09353795726101376 Test RE 0.22096822014415038\n",
      "33 Train Loss 1.1106627 Test MSE 0.08476461664533778 Test RE 0.21035032047181448\n",
      "34 Train Loss 1.0080888 Test MSE 0.08658335455476407 Test RE 0.21259501698199848\n",
      "35 Train Loss 0.9287117 Test MSE 0.07819064478359274 Test RE 0.20202879529305504\n",
      "36 Train Loss 0.8532832 Test MSE 0.07787420774431252 Test RE 0.20161957622545632\n",
      "37 Train Loss 0.79096997 Test MSE 0.06894592045133513 Test RE 0.18970997371714096\n",
      "38 Train Loss 0.7500055 Test MSE 0.06302264194188137 Test RE 0.18137782069719577\n",
      "39 Train Loss 0.67379 Test MSE 0.05575975256809457 Test RE 0.17060678377145244\n",
      "40 Train Loss 0.63735616 Test MSE 0.05711367855454496 Test RE 0.17266564820263536\n",
      "41 Train Loss 0.5989296 Test MSE 0.05256654367102847 Test RE 0.16564967498897468\n",
      "42 Train Loss 0.581658 Test MSE 0.04838587248097805 Test RE 0.15892607771411968\n",
      "43 Train Loss 0.536431 Test MSE 0.04327435132226341 Test RE 0.15029729354904772\n",
      "44 Train Loss 0.50835854 Test MSE 0.043116307281920084 Test RE 0.15002258903747995\n",
      "45 Train Loss 0.48079982 Test MSE 0.04498876854934608 Test RE 0.15324557030509037\n",
      "46 Train Loss 0.458004 Test MSE 0.043802886438487634 Test RE 0.15121234266232586\n",
      "47 Train Loss 0.43905234 Test MSE 0.043273368178493664 Test RE 0.15029558624804246\n",
      "48 Train Loss 0.41400617 Test MSE 0.043168092916023984 Test RE 0.15011265569686155\n",
      "49 Train Loss 0.40086722 Test MSE 0.04315397511961341 Test RE 0.1500881070885156\n",
      "50 Train Loss 0.38686764 Test MSE 0.03788689736025816 Test RE 0.140630783900938\n",
      "51 Train Loss 0.37055182 Test MSE 0.03420069220625818 Test RE 0.13361441819064365\n",
      "52 Train Loss 0.3521159 Test MSE 0.033529326775203136 Test RE 0.13229648137457678\n",
      "53 Train Loss 0.34004807 Test MSE 0.032327898787609846 Test RE 0.1299046256619178\n",
      "54 Train Loss 0.32985967 Test MSE 0.030390641985684846 Test RE 0.12595221635730822\n",
      "55 Train Loss 0.31999138 Test MSE 0.02898124679263528 Test RE 0.1229969690508054\n",
      "56 Train Loss 0.3083165 Test MSE 0.026746620637840966 Test RE 0.11815996015309918\n",
      "57 Train Loss 0.29605398 Test MSE 0.024858753963110616 Test RE 0.11391359418868793\n",
      "58 Train Loss 0.28508517 Test MSE 0.022278428748514257 Test RE 0.10783957204916629\n",
      "59 Train Loss 0.27115923 Test MSE 0.019894357246168424 Test RE 0.10190625295510072\n",
      "60 Train Loss 0.26133054 Test MSE 0.018897436789515654 Test RE 0.09932014103001684\n",
      "61 Train Loss 0.25269896 Test MSE 0.01837110505383859 Test RE 0.09792724062752176\n",
      "62 Train Loss 0.2402739 Test MSE 0.019379217025784296 Test RE 0.10057823035754376\n",
      "63 Train Loss 0.2308447 Test MSE 0.019583452546024685 Test RE 0.10110683295635826\n",
      "64 Train Loss 0.22324646 Test MSE 0.019940171870034565 Test RE 0.10202352519827991\n",
      "65 Train Loss 0.21561383 Test MSE 0.01900423371302178 Test RE 0.0996003944211536\n",
      "66 Train Loss 0.20686579 Test MSE 0.018263058028584453 Test RE 0.09763884343488385\n",
      "67 Train Loss 0.19993404 Test MSE 0.01774486985402979 Test RE 0.09624369455267531\n",
      "68 Train Loss 0.1913851 Test MSE 0.016595300733131722 Test RE 0.0930740131927091\n",
      "69 Train Loss 0.18525524 Test MSE 0.01654357398414523 Test RE 0.09292884638830128\n",
      "70 Train Loss 0.17771529 Test MSE 0.01653671081706838 Test RE 0.09290956843903865\n",
      "71 Train Loss 0.1729582 Test MSE 0.015641231876076682 Test RE 0.0903589871240401\n",
      "72 Train Loss 0.16840371 Test MSE 0.014293818634436965 Test RE 0.0863793656857217\n",
      "73 Train Loss 0.16398692 Test MSE 0.013660861424536834 Test RE 0.08444519051504544\n",
      "74 Train Loss 0.16027084 Test MSE 0.01297251742430083 Test RE 0.08229017923272555\n",
      "75 Train Loss 0.15657642 Test MSE 0.012897341792777517 Test RE 0.08205139734021058\n",
      "76 Train Loss 0.15113376 Test MSE 0.01230653213926485 Test RE 0.08015003604574363\n",
      "77 Train Loss 0.14735702 Test MSE 0.012362699880457281 Test RE 0.08033273257818452\n",
      "78 Train Loss 0.1406597 Test MSE 0.011780749371914517 Test RE 0.0784191869578101\n",
      "79 Train Loss 0.13631175 Test MSE 0.01136203213321002 Test RE 0.07701297199191594\n",
      "80 Train Loss 0.1326924 Test MSE 0.010808056004039647 Test RE 0.07511205950286612\n",
      "81 Train Loss 0.12998849 Test MSE 0.010310832276603682 Test RE 0.0733639553835708\n",
      "82 Train Loss 0.12583418 Test MSE 0.009509247063864922 Test RE 0.07045453330611826\n",
      "83 Train Loss 0.12351915 Test MSE 0.009683702412068057 Test RE 0.07109787069538905\n",
      "84 Train Loss 0.12099364 Test MSE 0.009317660804914248 Test RE 0.06974118545151815\n",
      "85 Train Loss 0.11938739 Test MSE 0.008788919716986183 Test RE 0.0677335168537996\n",
      "86 Train Loss 0.11667815 Test MSE 0.008663329572703288 Test RE 0.06724783313429607\n",
      "87 Train Loss 0.11228138 Test MSE 0.007819544747565509 Test RE 0.06388907664072156\n",
      "88 Train Loss 0.10941513 Test MSE 0.007748776360325402 Test RE 0.06359931532235728\n",
      "89 Train Loss 0.106144175 Test MSE 0.007606144426105984 Test RE 0.06301125951272196\n",
      "90 Train Loss 0.104315236 Test MSE 0.007414545080175617 Test RE 0.06221256849509302\n",
      "91 Train Loss 0.1012328 Test MSE 0.007315374070397011 Test RE 0.06179511519982906\n",
      "92 Train Loss 0.09807633 Test MSE 0.0069942559718943345 Test RE 0.06042360575452352\n",
      "93 Train Loss 0.095571205 Test MSE 0.006757780176089019 Test RE 0.059393361678338225\n",
      "94 Train Loss 0.09171049 Test MSE 0.005815620230918116 Test RE 0.05509775407080529\n",
      "95 Train Loss 0.08908181 Test MSE 0.005210654165707266 Test RE 0.05215332499573593\n",
      "96 Train Loss 0.085818216 Test MSE 0.004976957368554125 Test RE 0.05097037599097146\n",
      "97 Train Loss 0.08386048 Test MSE 0.0046463211293718 Test RE 0.04924821433041758\n",
      "98 Train Loss 0.08193413 Test MSE 0.004552054146420331 Test RE 0.04874606761488204\n",
      "99 Train Loss 0.07955679 Test MSE 0.004295170680761154 Test RE 0.047350665809956574\n",
      "100 Train Loss 0.07598064 Test MSE 0.0040002295315168905 Test RE 0.04569601546449119\n",
      "101 Train Loss 0.0735707 Test MSE 0.003851709937871124 Test RE 0.04483969645488266\n",
      "102 Train Loss 0.07184327 Test MSE 0.003729601522205112 Test RE 0.04412320933038051\n",
      "103 Train Loss 0.07010063 Test MSE 0.0035908960145985686 Test RE 0.04329495488061381\n",
      "104 Train Loss 0.067323565 Test MSE 0.0037529186002319454 Test RE 0.044260921266926816\n",
      "105 Train Loss 0.06606727 Test MSE 0.003765163834940748 Test RE 0.04433307097781941\n",
      "106 Train Loss 0.064714365 Test MSE 0.003915469006477039 Test RE 0.04520929890888198\n",
      "107 Train Loss 0.06358724 Test MSE 0.004071940680836779 Test RE 0.0461037867976738\n",
      "108 Train Loss 0.062526725 Test MSE 0.004022918248638065 Test RE 0.045825422788863764\n",
      "109 Train Loss 0.05976365 Test MSE 0.0038764585569906742 Test RE 0.0449835213667526\n",
      "110 Train Loss 0.057900697 Test MSE 0.0038314539410461276 Test RE 0.04472163589774905\n",
      "111 Train Loss 0.056774482 Test MSE 0.003947067611806703 Test RE 0.045391356306234615\n",
      "112 Train Loss 0.055907354 Test MSE 0.003999352810779209 Test RE 0.045691007646887154\n",
      "113 Train Loss 0.0549602 Test MSE 0.004036600729406991 Test RE 0.045903285822580395\n",
      "114 Train Loss 0.053778168 Test MSE 0.004360426118306255 Test RE 0.047709003229460596\n",
      "115 Train Loss 0.05272379 Test MSE 0.004149820189980852 Test RE 0.04654258671304526\n",
      "116 Train Loss 0.05115214 Test MSE 0.0041009570715110875 Test RE 0.046267761526143814\n",
      "117 Train Loss 0.04996918 Test MSE 0.004419868914966609 Test RE 0.04803309503218286\n",
      "118 Train Loss 0.048121113 Test MSE 0.004764770095962443 Test RE 0.049872007713438714\n",
      "119 Train Loss 0.046859387 Test MSE 0.004794075455251246 Test RE 0.05002513962974256\n",
      "120 Train Loss 0.045631565 Test MSE 0.005169977573184633 Test RE 0.0519493605895349\n",
      "121 Train Loss 0.044735894 Test MSE 0.005255830439917934 Test RE 0.052378921248590934\n",
      "122 Train Loss 0.04381407 Test MSE 0.005364935664057558 Test RE 0.052919792915259715\n",
      "123 Train Loss 0.04280562 Test MSE 0.005091175224423891 Test RE 0.05155192645419045\n",
      "124 Train Loss 0.042043168 Test MSE 0.0048449720894912845 Test RE 0.050289986225546944\n",
      "125 Train Loss 0.041236095 Test MSE 0.004718282931671107 Test RE 0.04962812492650893\n",
      "126 Train Loss 0.040073387 Test MSE 0.004596582591386325 Test RE 0.04898390575617905\n",
      "127 Train Loss 0.03922599 Test MSE 0.004594961874480593 Test RE 0.048975269335337815\n",
      "128 Train Loss 0.038330138 Test MSE 0.004603931603901907 Test RE 0.049023047831726556\n",
      "129 Train Loss 0.037753407 Test MSE 0.004581990166174613 Test RE 0.04890609118741456\n",
      "130 Train Loss 0.037305456 Test MSE 0.0046561640217204735 Test RE 0.04930035110765843\n",
      "131 Train Loss 0.036990635 Test MSE 0.004719093997919432 Test RE 0.04963239024590841\n",
      "132 Train Loss 0.035981104 Test MSE 0.004386365028436296 Test RE 0.047850696329653296\n",
      "133 Train Loss 0.03524533 Test MSE 0.004211064436049276 Test RE 0.04688477329008476\n",
      "134 Train Loss 0.034605056 Test MSE 0.004042495783099856 Test RE 0.04593679218447575\n",
      "135 Train Loss 0.034010604 Test MSE 0.0037041719683752763 Test RE 0.043972529336882935\n",
      "136 Train Loss 0.0329805 Test MSE 0.003421048434890189 Test RE 0.04225863729654041\n",
      "137 Train Loss 0.032451846 Test MSE 0.0034271807147882613 Test RE 0.04229649495509669\n",
      "138 Train Loss 0.031605706 Test MSE 0.0034825640121253208 Test RE 0.04263688133481155\n",
      "139 Train Loss 0.031044368 Test MSE 0.003368289247163244 Test RE 0.041931516200225796\n",
      "140 Train Loss 0.030791769 Test MSE 0.0032340394683853402 Test RE 0.04108738814403788\n",
      "141 Train Loss 0.030459518 Test MSE 0.0030502750545254283 Test RE 0.039902984402116565\n",
      "142 Train Loss 0.030071698 Test MSE 0.0028893411313922874 Test RE 0.038836071047090345\n",
      "143 Train Loss 0.029800892 Test MSE 0.0030077155184176905 Test RE 0.039623629596037935\n",
      "144 Train Loss 0.029317662 Test MSE 0.003021359243435317 Test RE 0.03971339909067172\n",
      "145 Train Loss 0.02870258 Test MSE 0.0031106769512299296 Test RE 0.0402961294057199\n",
      "146 Train Loss 0.028119653 Test MSE 0.0031676581005526706 Test RE 0.040663525310694795\n",
      "147 Train Loss 0.027626963 Test MSE 0.0032164290839437576 Test RE 0.04097536842232364\n",
      "148 Train Loss 0.027138311 Test MSE 0.0031520966026403197 Test RE 0.04056352013063424\n",
      "149 Train Loss 0.026772652 Test MSE 0.00318695844796284 Test RE 0.04078721737330765\n",
      "150 Train Loss 0.026493007 Test MSE 0.0030087613444334774 Test RE 0.03963051785072372\n",
      "151 Train Loss 0.0261065 Test MSE 0.0027913237202664845 Test RE 0.038171654121995\n",
      "152 Train Loss 0.025546158 Test MSE 0.0025478016595786813 Test RE 0.0364685658701179\n",
      "153 Train Loss 0.025106275 Test MSE 0.0025227657072082656 Test RE 0.03628894448516151\n",
      "154 Train Loss 0.024525488 Test MSE 0.002359407445230795 Test RE 0.035094361847806455\n",
      "155 Train Loss 0.023747455 Test MSE 0.0018823548395159552 Test RE 0.031346324443682315\n",
      "156 Train Loss 0.023301514 Test MSE 0.0016849104980183227 Test RE 0.02965680045170517\n",
      "157 Train Loss 0.022595627 Test MSE 0.001583909270675473 Test RE 0.028754182661235753\n",
      "158 Train Loss 0.022227567 Test MSE 0.0014688540081049186 Test RE 0.02769014265910694\n",
      "159 Train Loss 0.021924682 Test MSE 0.001579277937166386 Test RE 0.028712113427285295\n",
      "160 Train Loss 0.021645352 Test MSE 0.0016087273013546833 Test RE 0.02897857950005964\n",
      "161 Train Loss 0.02145218 Test MSE 0.0015776172198407126 Test RE 0.028697013094059098\n",
      "162 Train Loss 0.021217298 Test MSE 0.001579990923171309 Test RE 0.028718593928459615\n",
      "163 Train Loss 0.021037517 Test MSE 0.0016067227282298873 Test RE 0.0289605193264294\n",
      "164 Train Loss 0.020699875 Test MSE 0.0018231486934525692 Test RE 0.03084941423874954\n",
      "165 Train Loss 0.02038358 Test MSE 0.0018257735098970236 Test RE 0.03087161344996523\n",
      "166 Train Loss 0.020079402 Test MSE 0.0017803733548997223 Test RE 0.030485366454114298\n",
      "167 Train Loss 0.019703481 Test MSE 0.0017362259334371172 Test RE 0.03010502528594937\n",
      "168 Train Loss 0.019305352 Test MSE 0.001724434594453233 Test RE 0.030002624065090678\n",
      "169 Train Loss 0.01909863 Test MSE 0.0016994008971062964 Test RE 0.029784053168445852\n",
      "170 Train Loss 0.018928884 Test MSE 0.001768760264962036 Test RE 0.030385778210130422\n",
      "171 Train Loss 0.018719977 Test MSE 0.0017953781664745594 Test RE 0.030613560754046382\n",
      "172 Train Loss 0.018535767 Test MSE 0.0016856099638891241 Test RE 0.029662955605744747\n",
      "173 Train Loss 0.018300723 Test MSE 0.0017201867167534917 Test RE 0.02996564786961403\n",
      "174 Train Loss 0.018137166 Test MSE 0.00167081825359545 Test RE 0.029532518352783126\n",
      "175 Train Loss 0.017970331 Test MSE 0.0017375822749028731 Test RE 0.03011678202849496\n",
      "176 Train Loss 0.017612237 Test MSE 0.0016847164529835293 Test RE 0.02965509266942819\n",
      "177 Train Loss 0.017167997 Test MSE 0.0014568689999804724 Test RE 0.027576943416968255\n",
      "178 Train Loss 0.016773144 Test MSE 0.001455263949949388 Test RE 0.02756174830618401\n",
      "179 Train Loss 0.016392944 Test MSE 0.0014297397607697785 Test RE 0.02731897334397901\n",
      "180 Train Loss 0.01617583 Test MSE 0.001438764368359553 Test RE 0.027405057257709642\n",
      "181 Train Loss 0.015931996 Test MSE 0.0015591549569084148 Test RE 0.028528603742806583\n",
      "182 Train Loss 0.015756328 Test MSE 0.001548807080985777 Test RE 0.02843377612498269\n",
      "183 Train Loss 0.015639346 Test MSE 0.0015057660478164613 Test RE 0.028035908059202787\n",
      "184 Train Loss 0.015516194 Test MSE 0.0014605032612955333 Test RE 0.02761131829690171\n",
      "185 Train Loss 0.015248851 Test MSE 0.0014742244295960706 Test RE 0.027740716799929288\n",
      "186 Train Loss 0.014995085 Test MSE 0.0013879392483752938 Test RE 0.02691665607494572\n",
      "187 Train Loss 0.014787954 Test MSE 0.0013341784862487258 Test RE 0.026390209843875804\n",
      "188 Train Loss 0.014562674 Test MSE 0.0012113810814568544 Test RE 0.02514642610175145\n",
      "189 Train Loss 0.014381913 Test MSE 0.0012281371118202412 Test RE 0.025319743654533208\n",
      "190 Train Loss 0.014269305 Test MSE 0.0012191986767349716 Test RE 0.025227436298182727\n",
      "191 Train Loss 0.014145411 Test MSE 0.001257743816527398 Test RE 0.025623117747429612\n",
      "192 Train Loss 0.014004097 Test MSE 0.00116056672938728 Test RE 0.024613361767890803\n",
      "193 Train Loss 0.013875096 Test MSE 0.0011327420029742777 Test RE 0.02431651760631538\n",
      "194 Train Loss 0.013672774 Test MSE 0.000992125558858626 Test RE 0.022757219365938126\n",
      "195 Train Loss 0.0135283945 Test MSE 0.0009708574752147324 Test RE 0.02251197596021349\n",
      "196 Train Loss 0.013413761 Test MSE 0.0009607725266475582 Test RE 0.022394747226071113\n",
      "197 Train Loss 0.01330601 Test MSE 0.0009366029807540589 Test RE 0.022111267806869783\n",
      "198 Train Loss 0.013226183 Test MSE 0.0009173104873725117 Test RE 0.021882354843067768\n",
      "199 Train Loss 0.013166 Test MSE 0.0009022203287361946 Test RE 0.021701621321539043\n",
      "200 Train Loss 0.0130985435 Test MSE 0.000879339403560777 Test RE 0.021424670140823724\n",
      "201 Train Loss 0.013005212 Test MSE 0.0008733124173932288 Test RE 0.021351121628681986\n",
      "202 Train Loss 0.012942989 Test MSE 0.0009150095238179435 Test RE 0.02185489297716225\n",
      "203 Train Loss 0.012863946 Test MSE 0.000955495517613631 Test RE 0.022333161367583884\n",
      "204 Train Loss 0.012796473 Test MSE 0.0009590709205829341 Test RE 0.022374906980716577\n",
      "205 Train Loss 0.012658437 Test MSE 0.0009682212929203651 Test RE 0.022481391649815125\n",
      "206 Train Loss 0.0125818495 Test MSE 0.000996440686035822 Test RE 0.022806655522965586\n",
      "207 Train Loss 0.012511314 Test MSE 0.0010176190777673908 Test RE 0.023047748012904448\n",
      "208 Train Loss 0.012441853 Test MSE 0.0009896588766669819 Test RE 0.022728911576602645\n",
      "209 Train Loss 0.012365521 Test MSE 0.001011366838580445 Test RE 0.02297683638387239\n",
      "210 Train Loss 0.01227751 Test MSE 0.0009753517320416626 Test RE 0.022564021593091056\n",
      "211 Train Loss 0.012169681 Test MSE 0.0009569309482782884 Test RE 0.02234993050627888\n",
      "212 Train Loss 0.012034089 Test MSE 0.0010070147003946991 Test RE 0.022927345845852928\n",
      "213 Train Loss 0.01195417 Test MSE 0.0010537735791318042 Test RE 0.023453600843636926\n",
      "214 Train Loss 0.01189493 Test MSE 0.0010281954453257053 Test RE 0.0231672089003427\n",
      "215 Train Loss 0.011841956 Test MSE 0.001038868476879953 Test RE 0.023287140372941786\n",
      "216 Train Loss 0.0117855705 Test MSE 0.001018722869025934 Test RE 0.02306024434308367\n",
      "217 Train Loss 0.011742661 Test MSE 0.001027205756584731 Test RE 0.023156056426374673\n",
      "218 Train Loss 0.011737723 Test MSE 0.0010324950266773923 Test RE 0.023215597260497493\n",
      "219 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "220 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "221 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "222 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "223 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "224 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "225 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "226 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "227 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "228 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "229 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "230 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "231 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "232 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "233 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "234 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "235 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "236 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "237 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "238 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "239 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "240 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "241 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "242 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "243 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "244 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "245 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "246 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "247 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "248 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "249 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "250 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "251 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "252 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "253 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "254 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "255 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "256 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "257 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "258 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "259 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "260 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "261 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "262 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "263 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "264 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "265 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "266 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "267 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "268 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "269 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "270 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "271 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "272 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "273 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "274 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "275 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "276 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "277 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "278 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "279 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "280 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "281 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "282 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "283 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "284 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "285 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "286 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "287 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "288 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "289 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "290 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "291 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "292 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "293 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "294 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "295 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "296 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "297 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "298 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "299 Train Loss 0.011723417 Test MSE 0.0010434247139256027 Test RE 0.023338150512341293\n",
      "Training time: 134.86\n",
      "KG_tanh_high\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 53037.96 Test MSE 5.537102751742739 Test RE 1.7001105731095254\n",
      "1 Train Loss 27521.76 Test MSE 6.096452957930012 Test RE 1.7839163683722528\n",
      "2 Train Loss 11433.692 Test MSE 8.772273671390758 Test RE 2.1398925310766774\n",
      "3 Train Loss 4706.222 Test MSE 12.746625408968086 Test RE 2.5794878612910868\n",
      "4 Train Loss 2587.8643 Test MSE 15.16901856339536 Test RE 2.8139386089509983\n",
      "5 Train Loss 1619.4208 Test MSE 16.077201528676042 Test RE 2.8969507017153235\n",
      "6 Train Loss 998.2462 Test MSE 18.091765703267466 Test RE 3.073097605994355\n",
      "7 Train Loss 653.1533 Test MSE 19.85710651993034 Test RE 3.219540255417\n",
      "8 Train Loss 479.7785 Test MSE 20.42132477915138 Test RE 3.264959760211509\n",
      "9 Train Loss 381.78098 Test MSE 21.030121016871387 Test RE 3.313269501133959\n",
      "10 Train Loss 299.14014 Test MSE 20.94345758331492 Test RE 3.3064355950992934\n",
      "11 Train Loss 237.7476 Test MSE 21.255498587725633 Test RE 3.3309761659248354\n",
      "12 Train Loss 189.83218 Test MSE 21.336300299129267 Test RE 3.3373014297165264\n",
      "13 Train Loss 143.29993 Test MSE 20.503442788721525 Test RE 3.271517684538916\n",
      "14 Train Loss 108.19995 Test MSE 20.118526936306242 Test RE 3.240663713903981\n",
      "15 Train Loss 83.312744 Test MSE 19.418727876092433 Test RE 3.1838035657238577\n",
      "16 Train Loss 69.130295 Test MSE 18.82768016543286 Test RE 3.134976451519254\n",
      "17 Train Loss 58.88595 Test MSE 18.135761190478586 Test RE 3.076831910656565\n",
      "18 Train Loss 50.157562 Test MSE 17.48453916184814 Test RE 3.0210851905321987\n",
      "19 Train Loss 45.135647 Test MSE 17.306513104476583 Test RE 3.00566562658982\n",
      "20 Train Loss 41.549248 Test MSE 16.8956149721284 Test RE 2.9697704315384943\n",
      "21 Train Loss 37.81549 Test MSE 16.752600294552547 Test RE 2.957174756307078\n",
      "22 Train Loss 34.45359 Test MSE 16.938723860172527 Test RE 2.9735566785263328\n",
      "23 Train Loss 31.808659 Test MSE 16.8927066549664 Test RE 2.969514820658326\n",
      "24 Train Loss 29.884872 Test MSE 16.81047755196814 Test RE 2.9622786085583663\n",
      "25 Train Loss 28.464901 Test MSE 16.673214469143044 Test RE 2.950159829420895\n",
      "26 Train Loss 27.371645 Test MSE 16.562977539376018 Test RE 2.940390990338181\n",
      "27 Train Loss 26.514406 Test MSE 16.489245822146014 Test RE 2.9338389711810766\n",
      "28 Train Loss 25.488657 Test MSE 16.307348794191583 Test RE 2.9176121378222337\n",
      "29 Train Loss 24.563257 Test MSE 16.32714289833914 Test RE 2.919382321466441\n",
      "30 Train Loss 23.658892 Test MSE 16.168214797893178 Test RE 2.905138969400277\n",
      "31 Train Loss 22.898708 Test MSE 16.12230272193238 Test RE 2.901011247626094\n",
      "32 Train Loss 22.192568 Test MSE 16.09071004556634 Test RE 2.8981674959004913\n",
      "33 Train Loss 21.5045 Test MSE 15.991679404271553 Test RE 2.8892353124412025\n",
      "34 Train Loss 20.757101 Test MSE 15.90742357718557 Test RE 2.881613961350393\n",
      "35 Train Loss 20.331781 Test MSE 15.82492633059373 Test RE 2.8741321012617993\n",
      "36 Train Loss 19.916447 Test MSE 15.738749252468804 Test RE 2.8662956531323056\n",
      "37 Train Loss 19.387346 Test MSE 15.628379905163055 Test RE 2.856227898110389\n",
      "38 Train Loss 18.960686 Test MSE 15.49915909229389 Test RE 2.8443952516058566\n",
      "39 Train Loss 18.654327 Test MSE 15.398039428313934 Test RE 2.835101361633967\n",
      "40 Train Loss 18.470367 Test MSE 15.329927849335345 Test RE 2.8288240284814683\n",
      "41 Train Loss 18.174202 Test MSE 15.289000951793524 Test RE 2.825045394691644\n",
      "42 Train Loss 17.94539 Test MSE 15.254444490119187 Test RE 2.821850980672588\n",
      "43 Train Loss 17.653397 Test MSE 15.1682190165128 Test RE 2.813864447742705\n",
      "44 Train Loss 17.346024 Test MSE 15.055216367666969 Test RE 2.8033632618136584\n",
      "45 Train Loss 17.039473 Test MSE 14.945345332257864 Test RE 2.793115237870549\n",
      "46 Train Loss 16.809483 Test MSE 14.848236847616214 Test RE 2.7840262134273117\n",
      "47 Train Loss 16.644142 Test MSE 14.815411550899704 Test RE 2.780947159299397\n",
      "48 Train Loss 16.409014 Test MSE 14.732094804727128 Test RE 2.7731165925824826\n",
      "49 Train Loss 16.154448 Test MSE 14.627761034554203 Test RE 2.763279437764545\n",
      "50 Train Loss 16.011564 Test MSE 14.561519816735277 Test RE 2.7570156393979532\n",
      "51 Train Loss 15.888875 Test MSE 14.543243168836169 Test RE 2.7552848851261746\n",
      "52 Train Loss 15.758492 Test MSE 14.492866933676938 Test RE 2.750508739800119\n",
      "53 Train Loss 15.558753 Test MSE 14.430565539839733 Test RE 2.7445904806493315\n",
      "54 Train Loss 15.436883 Test MSE 14.369767218152743 Test RE 2.738802674737105\n",
      "55 Train Loss 15.336981 Test MSE 14.361571284300094 Test RE 2.7380215122154183\n",
      "56 Train Loss 15.160326 Test MSE 14.31604254111489 Test RE 2.733678058763425\n",
      "57 Train Loss 14.941453 Test MSE 14.160123128111033 Test RE 2.7187507353506817\n",
      "58 Train Loss 14.728455 Test MSE 14.061623530170518 Test RE 2.7092782475711603\n",
      "59 Train Loss 14.535137 Test MSE 13.92165474994111 Test RE 2.6957605066206725\n",
      "60 Train Loss 14.268851 Test MSE 13.81870086650853 Test RE 2.685774120644692\n",
      "61 Train Loss 14.082749 Test MSE 13.767105627833573 Test RE 2.6807554597480547\n",
      "62 Train Loss 13.903299 Test MSE 13.700055646907424 Test RE 2.674219445768002\n",
      "63 Train Loss 13.705054 Test MSE 13.561330849870794 Test RE 2.660645615544096\n",
      "64 Train Loss 13.52567 Test MSE 13.484427961501636 Test RE 2.653090964925776\n",
      "65 Train Loss 13.29373 Test MSE 13.321549154843387 Test RE 2.6370189013781955\n",
      "66 Train Loss 13.124037 Test MSE 13.137295064111546 Test RE 2.6187187275191044\n",
      "67 Train Loss 12.843454 Test MSE 12.861298326478694 Test RE 2.591064850961083\n",
      "68 Train Loss 12.610045 Test MSE 12.80454798536127 Test RE 2.585342008033977\n",
      "69 Train Loss 12.367313 Test MSE 12.578152464051401 Test RE 2.562384533207713\n",
      "70 Train Loss 12.038966 Test MSE 12.122630582801923 Test RE 2.5155578683834294\n",
      "71 Train Loss 11.683396 Test MSE 11.682826518681722 Test RE 2.4695046075115648\n",
      "72 Train Loss 11.257361 Test MSE 11.219625248297982 Test RE 2.420053976053298\n",
      "73 Train Loss 10.818223 Test MSE 10.92640994050251 Test RE 2.3882216010092265\n",
      "74 Train Loss 10.227408 Test MSE 10.350517855130878 Test RE 2.324432378275696\n",
      "75 Train Loss 9.54662 Test MSE 9.691600564106297 Test RE 2.249228771080472\n",
      "76 Train Loss 8.788699 Test MSE 9.2459578974803 Test RE 2.19690780933237\n",
      "77 Train Loss 8.259115 Test MSE 8.990461393880194 Test RE 2.166341238982692\n",
      "78 Train Loss 7.7596803 Test MSE 8.629086946412839 Test RE 2.122356322311291\n",
      "79 Train Loss 7.278987 Test MSE 8.309447904310286 Test RE 2.082677194943351\n",
      "80 Train Loss 6.850447 Test MSE 8.07297697032067 Test RE 2.052828808081185\n",
      "81 Train Loss 6.4114876 Test MSE 7.741352730683579 Test RE 2.0102233118832937\n",
      "82 Train Loss 6.1577334 Test MSE 7.552232598939015 Test RE 1.9855167515154044\n",
      "83 Train Loss 5.8437614 Test MSE 7.2949241507643405 Test RE 1.9513998497918925\n",
      "84 Train Loss 5.5484366 Test MSE 6.990660848310191 Test RE 1.9102710468575699\n",
      "85 Train Loss 5.117886 Test MSE 6.570362421802293 Test RE 1.8519554697549991\n",
      "86 Train Loss 4.794896 Test MSE 6.340373707805874 Test RE 1.8192538600998165\n",
      "87 Train Loss 4.465798 Test MSE 6.127271150464186 Test RE 1.788419624188028\n",
      "88 Train Loss 4.1731234 Test MSE 5.88631851915581 Test RE 1.7529024834238949\n",
      "89 Train Loss 3.9650366 Test MSE 5.670451019654146 Test RE 1.720460391035535\n",
      "90 Train Loss 3.7113206 Test MSE 5.338920225507043 Test RE 1.6694083934614148\n",
      "91 Train Loss 3.475133 Test MSE 5.002047373692965 Test RE 1.615882498532419\n",
      "92 Train Loss 3.235738 Test MSE 4.760284028409612 Test RE 1.5763487619693914\n",
      "93 Train Loss 3.0393026 Test MSE 4.4586074156217865 Test RE 1.5255817821249487\n",
      "94 Train Loss 2.879837 Test MSE 4.184293333012621 Test RE 1.4779064281713767\n",
      "95 Train Loss 2.7352085 Test MSE 3.8195688382247956 Test RE 1.4120271512369136\n",
      "96 Train Loss 2.539478 Test MSE 3.366272035132722 Test RE 1.325593853009745\n",
      "97 Train Loss 2.3623023 Test MSE 3.145434787749943 Test RE 1.2813749209346694\n",
      "98 Train Loss 2.1703565 Test MSE 2.797347405224161 Test RE 1.2083954447998528\n",
      "99 Train Loss 2.0208967 Test MSE 2.5590179623633045 Test RE 1.1557729982739289\n",
      "100 Train Loss 1.8571007 Test MSE 2.382021664737465 Test RE 1.1150869428367904\n",
      "101 Train Loss 1.6942108 Test MSE 2.067167455681371 Test RE 1.03878030382328\n",
      "102 Train Loss 1.576201 Test MSE 1.8693424438641773 Test RE 0.9878256759346487\n",
      "103 Train Loss 1.5083258 Test MSE 1.8061653384018874 Test RE 0.9709897126154377\n",
      "104 Train Loss 1.4454145 Test MSE 1.8258512571388252 Test RE 0.9762669210729092\n",
      "105 Train Loss 1.3891314 Test MSE 1.683177813938394 Test RE 0.9373480406645379\n",
      "106 Train Loss 1.3197482 Test MSE 1.5595730217262767 Test RE 0.9022746045287507\n",
      "107 Train Loss 1.2392637 Test MSE 1.4468191153046361 Test RE 0.8690464621141103\n",
      "108 Train Loss 1.194678 Test MSE 1.3677161304351535 Test RE 0.8449555469307581\n",
      "109 Train Loss 1.1552147 Test MSE 1.2994161211818054 Test RE 0.8235879848429671\n",
      "110 Train Loss 1.1177235 Test MSE 1.2210641755490017 Test RE 0.7983716774562781\n",
      "111 Train Loss 1.0754243 Test MSE 1.1496172534057045 Test RE 0.7746624649442004\n",
      "112 Train Loss 1.0436366 Test MSE 1.102542484235361 Test RE 0.7586361672864486\n",
      "113 Train Loss 0.9863864 Test MSE 1.0570387526617946 Test RE 0.7428161401208979\n",
      "114 Train Loss 0.9328899 Test MSE 0.9937713014273597 Test RE 0.7202430932431708\n",
      "115 Train Loss 0.8767517 Test MSE 0.9867396240193327 Test RE 0.7176904396647572\n",
      "116 Train Loss 0.8362758 Test MSE 0.9284155293357488 Test RE 0.6961568085409192\n",
      "117 Train Loss 0.8050267 Test MSE 0.8783421811585227 Test RE 0.6771232820173289\n",
      "118 Train Loss 0.78035337 Test MSE 0.8331492232643282 Test RE 0.6594733861853722\n",
      "119 Train Loss 0.74411637 Test MSE 0.81797331824339 Test RE 0.6534395931152823\n",
      "120 Train Loss 0.6988857 Test MSE 0.7511169393506175 Test RE 0.6261662491366484\n",
      "121 Train Loss 0.66862476 Test MSE 0.6931252624364808 Test RE 0.6015084613078588\n",
      "122 Train Loss 0.6425131 Test MSE 0.7101288105849933 Test RE 0.6088417747833386\n",
      "123 Train Loss 0.60475254 Test MSE 0.6991535270795594 Test RE 0.6041185249861395\n",
      "124 Train Loss 0.5826809 Test MSE 0.6882418572680002 Test RE 0.599385755741134\n",
      "125 Train Loss 0.5595468 Test MSE 0.6502795466597313 Test RE 0.582620717942592\n",
      "126 Train Loss 0.53761894 Test MSE 0.5558640384099662 Test RE 0.5386667464461155\n",
      "127 Train Loss 0.5092444 Test MSE 0.4719591633703979 Test RE 0.4963500708320505\n",
      "128 Train Loss 0.47653666 Test MSE 0.3964490787507509 Test RE 0.454914294260917\n",
      "129 Train Loss 0.44050977 Test MSE 0.328903994817106 Test RE 0.41435296519197096\n",
      "130 Train Loss 0.41288045 Test MSE 0.3080286060207666 Test RE 0.40098802404557393\n",
      "131 Train Loss 0.37866634 Test MSE 0.2537297506012234 Test RE 0.36393311372691434\n",
      "132 Train Loss 0.35897702 Test MSE 0.23252945578383902 Test RE 0.34839736724050946\n",
      "133 Train Loss 0.33801603 Test MSE 0.210643713825765 Test RE 0.3315966454826403\n",
      "134 Train Loss 0.32253665 Test MSE 0.19503409249952872 Test RE 0.31907379945052966\n",
      "135 Train Loss 0.30500254 Test MSE 0.17559703258967013 Test RE 0.3027571881912878\n",
      "136 Train Loss 0.2886615 Test MSE 0.1671054804861253 Test RE 0.29534608857641037\n",
      "137 Train Loss 0.27553102 Test MSE 0.15699885197299024 Test RE 0.2862754560897415\n",
      "138 Train Loss 0.26458406 Test MSE 0.14533436900387833 Test RE 0.27543558069596136\n",
      "139 Train Loss 0.2526527 Test MSE 0.1329130837537715 Test RE 0.2634024098956006\n",
      "140 Train Loss 0.24560964 Test MSE 0.12792108623479315 Test RE 0.2584085898901513\n",
      "141 Train Loss 0.22715668 Test MSE 0.1357893417053759 Test RE 0.2662371884498225\n",
      "142 Train Loss 0.21054555 Test MSE 0.13600630693114502 Test RE 0.26644980144053354\n",
      "143 Train Loss 0.19743785 Test MSE 0.12157679558731259 Test RE 0.251919173690947\n",
      "144 Train Loss 0.18833329 Test MSE 0.11468758012733066 Test RE 0.24467752092475897\n",
      "145 Train Loss 0.18094482 Test MSE 0.09683913941102452 Test RE 0.22483366375817082\n",
      "146 Train Loss 0.17462015 Test MSE 0.08877174256649603 Test RE 0.21526491371723078\n",
      "147 Train Loss 0.16574588 Test MSE 0.0874520393221333 Test RE 0.21365883084981374\n",
      "148 Train Loss 0.16029082 Test MSE 0.08260183869957415 Test RE 0.2076494256756365\n",
      "149 Train Loss 0.1545412 Test MSE 0.07757353508614545 Test RE 0.20122997276187035\n",
      "150 Train Loss 0.14873414 Test MSE 0.06995369480741961 Test RE 0.19109142800425613\n",
      "151 Train Loss 0.1448455 Test MSE 0.06316838528804833 Test RE 0.18158742271058148\n",
      "152 Train Loss 0.13822798 Test MSE 0.05905055373716365 Test RE 0.1755690115778677\n",
      "153 Train Loss 0.12932646 Test MSE 0.04702725407337152 Test RE 0.15667896261559572\n",
      "154 Train Loss 0.121975236 Test MSE 0.04217791078286707 Test RE 0.14838103934880995\n",
      "155 Train Loss 0.11793621 Test MSE 0.03768684742320094 Test RE 0.1402590140158438\n",
      "156 Train Loss 0.11481198 Test MSE 0.037437234321121005 Test RE 0.1397937502113264\n",
      "157 Train Loss 0.1110907 Test MSE 0.03634801041193146 Test RE 0.13774511272647208\n",
      "158 Train Loss 0.106117286 Test MSE 0.03364697013092432 Test RE 0.1325283705198373\n",
      "159 Train Loss 0.102984115 Test MSE 0.029897897675193526 Test RE 0.1249269688036095\n",
      "160 Train Loss 0.10049272 Test MSE 0.029907073489763673 Test RE 0.12494613768923954\n",
      "161 Train Loss 0.097917184 Test MSE 0.029433102377142743 Test RE 0.123952102402944\n",
      "162 Train Loss 0.094742246 Test MSE 0.02950658518105053 Test RE 0.1241067356118217\n",
      "163 Train Loss 0.09239775 Test MSE 0.02692610488947282 Test RE 0.11855575579687172\n",
      "164 Train Loss 0.08933867 Test MSE 0.027342490612791127 Test RE 0.11946891313696238\n",
      "165 Train Loss 0.08601191 Test MSE 0.025303322700443824 Test RE 0.11492768374169177\n",
      "166 Train Loss 0.08326051 Test MSE 0.025814690166736726 Test RE 0.11608319032666461\n",
      "167 Train Loss 0.07996371 Test MSE 0.026029116934839235 Test RE 0.11656430916765144\n",
      "168 Train Loss 0.076306686 Test MSE 0.023718045281141638 Test RE 0.11126929178382783\n",
      "169 Train Loss 0.07372683 Test MSE 0.02129480528268701 Test RE 0.10543206519755832\n",
      "170 Train Loss 0.070765205 Test MSE 0.021784858805329505 Test RE 0.1066383094735657\n",
      "171 Train Loss 0.0688331 Test MSE 0.022018440179665047 Test RE 0.10720848322752037\n",
      "172 Train Loss 0.06650768 Test MSE 0.02007788688605752 Test RE 0.10237522717575047\n",
      "173 Train Loss 0.0625486 Test MSE 0.019932898775254507 Test RE 0.10200491717301972\n",
      "174 Train Loss 0.05934219 Test MSE 0.020587835859256217 Test RE 0.10366716582382836\n",
      "175 Train Loss 0.05727117 Test MSE 0.020344336626224185 Test RE 0.10305228917510602\n",
      "176 Train Loss 0.055804413 Test MSE 0.020843315335680117 Test RE 0.10430839822718994\n",
      "177 Train Loss 0.053659186 Test MSE 0.020844713337929328 Test RE 0.10431189625348522\n",
      "178 Train Loss 0.052023232 Test MSE 0.0186435360905371 Test RE 0.09865066582464357\n",
      "179 Train Loss 0.049003825 Test MSE 0.016214556545848705 Test RE 0.09200012442181972\n",
      "180 Train Loss 0.047367554 Test MSE 0.01534912930838436 Test RE 0.0895112762427442\n",
      "181 Train Loss 0.045606043 Test MSE 0.014781448273087914 Test RE 0.08784041336843654\n",
      "182 Train Loss 0.043917034 Test MSE 0.012751138093103069 Test RE 0.08158500630906894\n",
      "183 Train Loss 0.04242462 Test MSE 0.011117060684280599 Test RE 0.07617822779771415\n",
      "184 Train Loss 0.040659904 Test MSE 0.010483968608162114 Test RE 0.07397734365930138\n",
      "185 Train Loss 0.03947624 Test MSE 0.01004788343219734 Test RE 0.07242244305068347\n",
      "186 Train Loss 0.038607035 Test MSE 0.009683331246939675 Test RE 0.07109650813270114\n",
      "187 Train Loss 0.037130244 Test MSE 0.007476111065470376 Test RE 0.062470322679155366\n",
      "188 Train Loss 0.03642796 Test MSE 0.006745940302228669 Test RE 0.05934130921625273\n",
      "189 Train Loss 0.035509873 Test MSE 0.005701279931423914 Test RE 0.054553429730986126\n",
      "190 Train Loss 0.035036355 Test MSE 0.0052945425588522225 Test RE 0.05257146731306776\n",
      "191 Train Loss 0.034350317 Test MSE 0.004903365158497565 Test RE 0.05059213362148466\n",
      "192 Train Loss 0.0336028 Test MSE 0.00439591551860125 Test RE 0.04790276097947644\n",
      "193 Train Loss 0.032906078 Test MSE 0.0036646683393268473 Test RE 0.043737425421835764\n",
      "194 Train Loss 0.032165844 Test MSE 0.003365649729352432 Test RE 0.04191508342571139\n",
      "195 Train Loss 0.031771485 Test MSE 0.003524201323742801 Test RE 0.04289100592455223\n",
      "196 Train Loss 0.030872576 Test MSE 0.0033984885196303837 Test RE 0.04211907069818532\n",
      "197 Train Loss 0.029726086 Test MSE 0.0034142717763501937 Test RE 0.04221676207639286\n",
      "198 Train Loss 0.029220318 Test MSE 0.0036328891367620074 Test RE 0.043547371803766395\n",
      "199 Train Loss 0.028555306 Test MSE 0.0035480093127720877 Test RE 0.04303563866478342\n",
      "200 Train Loss 0.028090736 Test MSE 0.003728161250531448 Test RE 0.044114688910085756\n",
      "201 Train Loss 0.027550703 Test MSE 0.003370622021915984 Test RE 0.041946033933827204\n",
      "202 Train Loss 0.027001183 Test MSE 0.003335027653862306 Test RE 0.04172396732265253\n",
      "203 Train Loss 0.026319332 Test MSE 0.0029081033123923255 Test RE 0.03896195966662127\n",
      "204 Train Loss 0.025545428 Test MSE 0.003091119282722133 Test RE 0.04016925332538281\n",
      "205 Train Loss 0.025049008 Test MSE 0.0029632348215261027 Test RE 0.03932954400593855\n",
      "206 Train Loss 0.024646232 Test MSE 0.0030140523828012565 Test RE 0.03966534854377271\n",
      "207 Train Loss 0.024057863 Test MSE 0.0030078029272960897 Test RE 0.03962420535392408\n",
      "208 Train Loss 0.02345652 Test MSE 0.003192587923663881 Test RE 0.040823224956348735\n",
      "209 Train Loss 0.022881526 Test MSE 0.003593766742264229 Test RE 0.04331225741371216\n",
      "210 Train Loss 0.022445375 Test MSE 0.0034817311511486293 Test RE 0.042631782689407434\n",
      "211 Train Loss 0.022043224 Test MSE 0.0034041374909845254 Test RE 0.042154061346662275\n",
      "212 Train Loss 0.021512197 Test MSE 0.0036507059445118764 Test RE 0.043654026062282\n",
      "213 Train Loss 0.021158533 Test MSE 0.0033814181952781792 Test RE 0.04201315724274525\n",
      "214 Train Loss 0.020787122 Test MSE 0.0027380180895264293 Test RE 0.03780541705925358\n",
      "215 Train Loss 0.020447863 Test MSE 0.002191790069188737 Test RE 0.0338248091083692\n",
      "216 Train Loss 0.020031286 Test MSE 0.002024048934707855 Test RE 0.032504716378386325\n",
      "217 Train Loss 0.019612364 Test MSE 0.0020700803693984946 Test RE 0.032872253724847506\n",
      "218 Train Loss 0.019342674 Test MSE 0.001989881165863589 Test RE 0.03222919422100664\n",
      "219 Train Loss 0.01893401 Test MSE 0.001844511493217908 Test RE 0.031029627333694347\n",
      "220 Train Loss 0.018431824 Test MSE 0.0015732147352925385 Test RE 0.028656944306185712\n",
      "221 Train Loss 0.017876202 Test MSE 0.0013466640043528432 Test RE 0.02651340481387992\n",
      "222 Train Loss 0.017262306 Test MSE 0.0012317039782225978 Test RE 0.0253564849369086\n",
      "223 Train Loss 0.016796352 Test MSE 0.0008943940377434816 Test RE 0.021607291184212903\n",
      "224 Train Loss 0.01641625 Test MSE 0.0009579307078439247 Test RE 0.022361602572977177\n",
      "225 Train Loss 0.016059734 Test MSE 0.0010483653405111407 Test RE 0.023393338450123008\n",
      "226 Train Loss 0.015803412 Test MSE 0.0010008416686437867 Test RE 0.022856965145901135\n",
      "227 Train Loss 0.015469312 Test MSE 0.0009046599984607361 Test RE 0.021730942898260254\n",
      "228 Train Loss 0.015222776 Test MSE 0.000777507295111889 Test RE 0.020145966766081724\n",
      "229 Train Loss 0.014971033 Test MSE 0.0006472156539147777 Test RE 0.018380629596313328\n",
      "230 Train Loss 0.014735619 Test MSE 0.000623030494235054 Test RE 0.018033936193867468\n",
      "231 Train Loss 0.01426485 Test MSE 0.0005294920107943115 Test RE 0.016625150395235523\n",
      "232 Train Loss 0.013870954 Test MSE 0.0005149178085430678 Test RE 0.016394751299682316\n",
      "233 Train Loss 0.013754005 Test MSE 0.0004913560877199003 Test RE 0.016015261986194247\n",
      "234 Train Loss 0.01343982 Test MSE 0.00047419812524486185 Test RE 0.015733153983847937\n",
      "235 Train Loss 0.0131359175 Test MSE 0.00047335526770123283 Test RE 0.015719165415967785\n",
      "236 Train Loss 0.012942026 Test MSE 0.00045998104151953145 Test RE 0.015495508871964098\n",
      "237 Train Loss 0.012720624 Test MSE 0.0004671743653081339 Test RE 0.015616200595314253\n",
      "238 Train Loss 0.012486992 Test MSE 0.0004710057007501735 Test RE 0.015680104715651757\n",
      "239 Train Loss 0.0121673765 Test MSE 0.00048063948833601154 Test RE 0.015839650737844234\n",
      "240 Train Loss 0.011807381 Test MSE 0.0005029199098707766 Test RE 0.016202621671632517\n",
      "241 Train Loss 0.01156884 Test MSE 0.0005176972745457038 Test RE 0.01643894022163273\n",
      "242 Train Loss 0.011451459 Test MSE 0.0005912945547594536 Test RE 0.017568626768388326\n",
      "243 Train Loss 0.0113300495 Test MSE 0.0006187870117342705 Test RE 0.01797241637619973\n",
      "244 Train Loss 0.011203064 Test MSE 0.0006689839782107127 Test RE 0.018687178555509335\n",
      "245 Train Loss 0.011097801 Test MSE 0.0007311389764690581 Test RE 0.019536008929644383\n",
      "246 Train Loss 0.010904604 Test MSE 0.0007646968259310962 Test RE 0.019979311618988464\n",
      "247 Train Loss 0.010683541 Test MSE 0.0007776056315325582 Test RE 0.020147240721733982\n",
      "248 Train Loss 0.010506785 Test MSE 0.000793362483889423 Test RE 0.02035034174942455\n",
      "249 Train Loss 0.010240724 Test MSE 0.0009005083522357251 Test RE 0.02168102197029641\n",
      "250 Train Loss 0.0100761065 Test MSE 0.0009818617094056493 Test RE 0.022639198051708307\n",
      "251 Train Loss 0.009873888 Test MSE 0.0010145390876203546 Test RE 0.023012842696615767\n",
      "252 Train Loss 0.009711057 Test MSE 0.0010397929723462626 Test RE 0.02329749975367271\n",
      "253 Train Loss 0.009535594 Test MSE 0.0010350943385438033 Test RE 0.023244801587960433\n",
      "254 Train Loss 0.009402393 Test MSE 0.001164031788516863 Test RE 0.024650077963203763\n",
      "255 Train Loss 0.00930802 Test MSE 0.0012225709703886868 Test RE 0.02526230164763214\n",
      "256 Train Loss 0.009233569 Test MSE 0.001246945468899948 Test RE 0.02551288712402139\n",
      "257 Train Loss 0.0091371145 Test MSE 0.0013061890384999868 Test RE 0.026111925279459634\n",
      "258 Train Loss 0.009056485 Test MSE 0.001335770758809282 Test RE 0.026405952818904423\n",
      "259 Train Loss 0.008994658 Test MSE 0.001329085696259859 Test RE 0.026339793688888193\n",
      "260 Train Loss 0.008907819 Test MSE 0.0014163577117156751 Test RE 0.02719082298946543\n",
      "261 Train Loss 0.008793195 Test MSE 0.0013059989864587305 Test RE 0.026110025552435336\n",
      "262 Train Loss 0.008670515 Test MSE 0.0013220067613052278 Test RE 0.02626955494264268\n",
      "263 Train Loss 0.008557292 Test MSE 0.0014759401016892764 Test RE 0.0277568541442622\n",
      "264 Train Loss 0.008427483 Test MSE 0.0014930436100119902 Test RE 0.02791721707196894\n",
      "265 Train Loss 0.008331363 Test MSE 0.0013780777594424327 Test RE 0.026820862443410705\n",
      "266 Train Loss 0.008210368 Test MSE 0.0014404641269268885 Test RE 0.027421240668975617\n",
      "267 Train Loss 0.008115351 Test MSE 0.0014393288842634922 Test RE 0.027410433076638607\n",
      "268 Train Loss 0.008026778 Test MSE 0.0013339330491795164 Test RE 0.026387782344954383\n",
      "269 Train Loss 0.007960165 Test MSE 0.0013883827146345098 Test RE 0.026920955858047144\n",
      "270 Train Loss 0.007890233 Test MSE 0.0012557200486188029 Test RE 0.025602495058252756\n",
      "271 Train Loss 0.007814002 Test MSE 0.0011866765138516021 Test RE 0.024888690689959265\n",
      "272 Train Loss 0.0077567315 Test MSE 0.0012005703695601232 Test RE 0.025033967680495768\n",
      "273 Train Loss 0.007693598 Test MSE 0.001186612147093638 Test RE 0.024888015684582807\n",
      "274 Train Loss 0.0076036016 Test MSE 0.0010900714383975264 Test RE 0.02385411766632666\n",
      "275 Train Loss 0.007531993 Test MSE 0.001067962693430552 Test RE 0.023610974811055004\n",
      "276 Train Loss 0.0074895294 Test MSE 0.0010531722351752196 Test RE 0.02344690790025967\n",
      "277 Train Loss 0.007434665 Test MSE 0.0010468251383613783 Test RE 0.02337614801468182\n",
      "278 Train Loss 0.0073290644 Test MSE 0.0010584682679905851 Test RE 0.0235057870996665\n",
      "279 Train Loss 0.0072621806 Test MSE 0.0009881278246326136 Test RE 0.022711323387097533\n",
      "280 Train Loss 0.0071796803 Test MSE 0.0009779240634349995 Test RE 0.022593756467396076\n",
      "281 Train Loss 0.007094891 Test MSE 0.0009272056190297068 Test RE 0.022000061978984634\n",
      "282 Train Loss 0.007002608 Test MSE 0.0008922204681749023 Test RE 0.02158102003467069\n",
      "283 Train Loss 0.006901206 Test MSE 0.0008921630955118551 Test RE 0.021580326158807096\n",
      "284 Train Loss 0.006813733 Test MSE 0.0009018644949722657 Test RE 0.021697341363027686\n",
      "285 Train Loss 0.0067073037 Test MSE 0.0008869693452330799 Test RE 0.021517419261304887\n",
      "286 Train Loss 0.006606725 Test MSE 0.0009299360278790071 Test RE 0.02203243074659152\n",
      "287 Train Loss 0.0065102936 Test MSE 0.0009266949080386105 Test RE 0.021994002254569732\n",
      "288 Train Loss 0.0064312774 Test MSE 0.0009480436924685415 Test RE 0.022245903729492613\n",
      "289 Train Loss 0.006376936 Test MSE 0.00101004486115778 Test RE 0.02296181473684455\n",
      "290 Train Loss 0.006333022 Test MSE 0.000993644700426364 Test RE 0.02277463561622098\n",
      "291 Train Loss 0.0062690764 Test MSE 0.0009773647527345102 Test RE 0.02258729444359125\n",
      "292 Train Loss 0.006202914 Test MSE 0.0010023582660874377 Test RE 0.022874276421923214\n",
      "293 Train Loss 0.0061310846 Test MSE 0.001006329641918963 Test RE 0.022919545937498627\n",
      "294 Train Loss 0.0060740816 Test MSE 0.0010025354945694296 Test RE 0.02287629855025928\n",
      "295 Train Loss 0.0060167434 Test MSE 0.0009659294796154274 Test RE 0.022454768770168294\n",
      "296 Train Loss 0.005967253 Test MSE 0.0009605476424835992 Test RE 0.022392126148446594\n",
      "297 Train Loss 0.005927031 Test MSE 0.0009398785543752191 Test RE 0.022149898834572693\n",
      "298 Train Loss 0.005880647 Test MSE 0.0008870387110661565 Test RE 0.021518260634538378\n",
      "299 Train Loss 0.005833793 Test MSE 0.0008547888392917001 Test RE 0.021123471759768364\n",
      "Training time: 142.01\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f226c1e6d10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.03711140094884699\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
