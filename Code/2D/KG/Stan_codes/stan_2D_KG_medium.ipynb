{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"medium\"\n",
    "label = \"KG_stan_\" + level\n",
    "\n",
    "x = np.linspace(0,2,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        beta_mean = 1.0*torch.ones((50,len(layers)-2))\n",
    "        beta_std = 0.01*torch.ones((50,len(layers)-2))\n",
    "        \n",
    "        self.beta = Parameter(torch.normal(beta_mean,beta_std))\n",
    "        self.beta.requiresGrad = True\n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            z1 = self.activation(z)\n",
    "            a = z1 + self.beta[:,i]*z*z1            \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_stan_medium\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 17499.686 Test MSE 15.775488376484642 Test RE 2.877789834396277\n",
      "1 Train Loss 2121.1543 Test MSE 12.821389289110817 Test RE 2.5943896969898144\n",
      "2 Train Loss 379.83792 Test MSE 12.50030321881889 Test RE 2.561698072732437\n",
      "3 Train Loss 252.15924 Test MSE 12.638154936170116 Test RE 2.57578438023106\n",
      "4 Train Loss 157.23741 Test MSE 11.793740688577786 Test RE 2.488246804249197\n",
      "5 Train Loss 89.3897 Test MSE 11.031677733211852 Test RE 2.406514322979838\n",
      "6 Train Loss 59.15907 Test MSE 10.872843575087222 Test RE 2.3891270070108725\n",
      "7 Train Loss 41.73754 Test MSE 11.290015889115955 Test RE 2.434528955192043\n",
      "8 Train Loss 32.148438 Test MSE 11.32533766038963 Test RE 2.4383342962361994\n",
      "9 Train Loss 25.67183 Test MSE 11.407521805486002 Test RE 2.447165387798286\n",
      "10 Train Loss 21.716976 Test MSE 11.368793565987469 Test RE 2.4430078247076943\n",
      "11 Train Loss 18.864866 Test MSE 11.280450261358034 Test RE 2.4334973918709246\n",
      "12 Train Loss 17.64566 Test MSE 11.210494675340373 Test RE 2.4259400034670944\n",
      "13 Train Loss 16.36173 Test MSE 11.159596999007512 Test RE 2.420426634917234\n",
      "14 Train Loss 15.3495455 Test MSE 11.155942488329627 Test RE 2.4200302855116944\n",
      "15 Train Loss 14.4059725 Test MSE 11.222382383947227 Test RE 2.4272259068770925\n",
      "16 Train Loss 13.922714 Test MSE 11.135346944766397 Test RE 2.4177953840518307\n",
      "17 Train Loss 13.408892 Test MSE 11.014312088328412 Test RE 2.4046194556066363\n",
      "18 Train Loss 13.0884 Test MSE 10.946921869304179 Test RE 2.39725192956558\n",
      "19 Train Loss 12.630957 Test MSE 10.724523719095455 Test RE 2.3727756380528087\n",
      "20 Train Loss 12.176199 Test MSE 10.557723183698942 Test RE 2.354251214335972\n",
      "21 Train Loss 11.869064 Test MSE 10.256257677113823 Test RE 2.320396113527116\n",
      "22 Train Loss 11.493977 Test MSE 10.12923223819195 Test RE 2.305982100662055\n",
      "23 Train Loss 11.221925 Test MSE 9.782661900005563 Test RE 2.2661893262224773\n",
      "24 Train Loss 10.813031 Test MSE 9.821877796899754 Test RE 2.270727035982818\n",
      "25 Train Loss 10.328702 Test MSE 9.76685364044175 Test RE 2.2643575654100814\n",
      "26 Train Loss 9.911549 Test MSE 9.50946868457865 Test RE 2.234322165551058\n",
      "27 Train Loss 9.540049 Test MSE 9.406631700085123 Test RE 2.2222081590463736\n",
      "28 Train Loss 9.189498 Test MSE 9.293117579484518 Test RE 2.2087592620488485\n",
      "29 Train Loss 8.898825 Test MSE 9.241532676499018 Test RE 2.202620461677396\n",
      "30 Train Loss 8.556364 Test MSE 9.058916175617322 Test RE 2.1807495331250593\n",
      "31 Train Loss 8.261315 Test MSE 8.830782643787167 Test RE 2.1531151924078293\n",
      "32 Train Loss 7.9101825 Test MSE 8.694222031677787 Test RE 2.1364022718160265\n",
      "33 Train Loss 7.606399 Test MSE 8.711797329205108 Test RE 2.138560541347744\n",
      "34 Train Loss 7.290412 Test MSE 8.519241704375196 Test RE 2.1147943315912276\n",
      "35 Train Loss 7.0722284 Test MSE 8.357208262639805 Test RE 2.0945864037202924\n",
      "36 Train Loss 6.8906875 Test MSE 8.37646194886126 Test RE 2.0969978135598715\n",
      "37 Train Loss 6.670694 Test MSE 8.171186138519808 Test RE 2.0711436399117495\n",
      "38 Train Loss 6.4693375 Test MSE 8.117211016156558 Test RE 2.064291791811249\n",
      "39 Train Loss 6.2461743 Test MSE 8.02260185697595 Test RE 2.052226482214252\n",
      "40 Train Loss 5.873 Test MSE 7.734312439381473 Test RE 2.0150161147586854\n",
      "41 Train Loss 5.7008233 Test MSE 7.564651991478038 Test RE 1.9927927948478272\n",
      "42 Train Loss 5.5165567 Test MSE 7.417928233680274 Test RE 1.9733720889415018\n",
      "43 Train Loss 5.2938666 Test MSE 7.176541794092 Test RE 1.9409988445055786\n",
      "44 Train Loss 5.1257095 Test MSE 6.9410733738759305 Test RE 1.9088903624977953\n",
      "45 Train Loss 4.940197 Test MSE 6.657273558136946 Test RE 1.8694586744211745\n",
      "46 Train Loss 4.76194 Test MSE 6.249437006073209 Test RE 1.8112905238733454\n",
      "47 Train Loss 4.508735 Test MSE 5.7033842507327845 Test RE 1.7303501051019776\n",
      "48 Train Loss 4.1387954 Test MSE 4.952463867910293 Test RE 1.6124205536479272\n",
      "49 Train Loss 3.6292045 Test MSE 3.9421988533433217 Test RE 1.4385896495559272\n",
      "50 Train Loss 3.272849 Test MSE 3.234055350103099 Test RE 1.3029909277527776\n",
      "51 Train Loss 2.7973905 Test MSE 2.6470608056823037 Test RE 1.1788257840356944\n",
      "52 Train Loss 2.4879131 Test MSE 2.2600978015714883 Test RE 1.089259318763697\n",
      "53 Train Loss 2.2462778 Test MSE 2.08745306684994 Test RE 1.046829680444088\n",
      "54 Train Loss 2.0098743 Test MSE 1.8323008025461185 Test RE 0.9807674717699019\n",
      "55 Train Loss 1.5617342 Test MSE 1.2836966363221423 Test RE 0.8209162815072538\n",
      "56 Train Loss 1.3325361 Test MSE 0.8759859733540751 Test RE 0.6781351309851996\n",
      "57 Train Loss 0.98660576 Test MSE 0.49859462427870765 Test RE 0.5116128730343263\n",
      "58 Train Loss 0.8148804 Test MSE 0.35157803008800803 Test RE 0.42961410527180083\n",
      "59 Train Loss 0.6457979 Test MSE 0.2677444730341175 Test RE 0.3749107772834938\n",
      "60 Train Loss 0.4953231 Test MSE 0.16634076110118054 Test RE 0.2955064807252211\n",
      "61 Train Loss 0.41101557 Test MSE 0.13142296005271745 Test RE 0.26266565493285204\n",
      "62 Train Loss 0.3563426 Test MSE 0.10464554828983068 Test RE 0.2343840458171978\n",
      "63 Train Loss 0.3130461 Test MSE 0.0849536623614199 Test RE 0.2111828860456537\n",
      "64 Train Loss 0.2640229 Test MSE 0.07244279772884273 Test RE 0.19501376850495844\n",
      "65 Train Loss 0.23522922 Test MSE 0.06061005545705806 Test RE 0.17837747348380914\n",
      "66 Train Loss 0.20290144 Test MSE 0.044279675465420776 Test RE 0.15246490315660968\n",
      "67 Train Loss 0.16627885 Test MSE 0.03274236434246106 Test RE 0.13110603581855873\n",
      "68 Train Loss 0.15098271 Test MSE 0.03419051703990111 Test RE 0.13397399313510852\n",
      "69 Train Loss 0.1374071 Test MSE 0.029695339083461753 Test RE 0.12485668844405821\n",
      "70 Train Loss 0.12795623 Test MSE 0.019963905589819652 Test RE 0.10237417650961032\n",
      "71 Train Loss 0.11261097 Test MSE 0.0192095395296706 Test RE 0.10042137068799964\n",
      "72 Train Loss 0.09476644 Test MSE 0.011119174061283507 Test RE 0.07640186008137718\n",
      "73 Train Loss 0.08989848 Test MSE 0.00810982873860594 Test RE 0.06524894727053897\n",
      "74 Train Loss 0.08201425 Test MSE 0.006354661419445168 Test RE 0.05775822997810397\n",
      "75 Train Loss 0.0704861 Test MSE 0.008533605720991929 Test RE 0.0669320234079499\n",
      "76 Train Loss 0.065011956 Test MSE 0.005572509370319929 Test RE 0.05408702215759727\n",
      "77 Train Loss 0.050713375 Test MSE 0.0016255303284440036 Test RE 0.02921226327391992\n",
      "78 Train Loss 0.04832538 Test MSE 0.001805109478833457 Test RE 0.030783602397266466\n",
      "79 Train Loss 0.04119114 Test MSE 0.0017953728613216435 Test RE 0.03070046798438832\n",
      "80 Train Loss 0.037262112 Test MSE 0.0018861619743455345 Test RE 0.031467131873512445\n",
      "81 Train Loss 0.033193823 Test MSE 0.002197390787333037 Test RE 0.033964194350263974\n",
      "82 Train Loss 0.031817336 Test MSE 0.0018347872592304577 Test RE 0.031035627130775796\n",
      "83 Train Loss 0.030183489 Test MSE 0.0011862100627863803 Test RE 0.024954476845596107\n",
      "84 Train Loss 0.027878944 Test MSE 0.001558096428383985 Test RE 0.02859992101091439\n",
      "85 Train Loss 0.026961783 Test MSE 0.0017774626866634584 Test RE 0.030546954212823583\n",
      "86 Train Loss 0.025071409 Test MSE 0.001291821612468342 Test RE 0.026041676564955034\n",
      "87 Train Loss 0.02468093 Test MSE 0.0012831270860314925 Test RE 0.025953892652987757\n",
      "88 Train Loss 0.022956338 Test MSE 0.0011480672758143946 Test RE 0.024549990969376524\n",
      "89 Train Loss 0.021849772 Test MSE 0.0011070652640392837 Test RE 0.024107616812427873\n",
      "90 Train Loss 0.021157183 Test MSE 0.00106751502412845 Test RE 0.0236730745430221\n",
      "91 Train Loss 0.019030359 Test MSE 0.0012624328039660064 Test RE 0.025743749636337448\n",
      "92 Train Loss 0.01861588 Test MSE 0.0013974985628829395 Test RE 0.027085905107266182\n",
      "93 Train Loss 0.016344508 Test MSE 0.0005798810859242872 Test RE 0.017447657982887197\n",
      "94 Train Loss 0.01612433 Test MSE 0.0005489262274283189 Test RE 0.016975581440391314\n",
      "95 Train Loss 0.014959321 Test MSE 0.00039989356292145274 Test RE 0.014489048772416782\n",
      "96 Train Loss 0.013358718 Test MSE 0.0003602912495746549 Test RE 0.013752907591813154\n",
      "97 Train Loss 0.012834957 Test MSE 0.00034232849371657265 Test RE 0.013405690614151191\n",
      "98 Train Loss 0.012464072 Test MSE 0.00034553886515362793 Test RE 0.01346840349974697\n",
      "99 Train Loss 0.011327303 Test MSE 0.0002992346439863881 Test RE 0.012533535746212862\n",
      "100 Train Loss 0.010606365 Test MSE 0.0002952183583184513 Test RE 0.012449139917707496\n",
      "101 Train Loss 0.010330263 Test MSE 0.0003087977053070191 Test RE 0.012732236583658216\n",
      "102 Train Loss 0.010168737 Test MSE 0.0003048147248710715 Test RE 0.012649857670864984\n",
      "103 Train Loss 0.0097023165 Test MSE 0.00036110652746919813 Test RE 0.01376845904603566\n",
      "104 Train Loss 0.009074461 Test MSE 0.00037431884754565893 Test RE 0.014018079388384237\n",
      "105 Train Loss 0.008708354 Test MSE 0.000333559648300663 Test RE 0.013232881434543218\n",
      "106 Train Loss 0.008560475 Test MSE 0.00034880536785488646 Test RE 0.013531914576624213\n",
      "107 Train Loss 0.008465689 Test MSE 0.00035003526994454226 Test RE 0.013555750627386884\n",
      "108 Train Loss 0.008210643 Test MSE 0.00032779112904446535 Test RE 0.013117958895489569\n",
      "109 Train Loss 0.0077298274 Test MSE 0.00035388038882874263 Test RE 0.01363000187383071\n",
      "110 Train Loss 0.0074569047 Test MSE 0.0003490468996328448 Test RE 0.013536598882087386\n",
      "111 Train Loss 0.0073933746 Test MSE 0.0003464792245810933 Test RE 0.013486717698764767\n",
      "112 Train Loss 0.0072684432 Test MSE 0.00036993858589720005 Test RE 0.013935818572437272\n",
      "113 Train Loss 0.0068555097 Test MSE 0.0003828844961937002 Test RE 0.014177562100193369\n",
      "114 Train Loss 0.0066996473 Test MSE 0.0004099787934429798 Test RE 0.01467061648846661\n",
      "115 Train Loss 0.006648469 Test MSE 0.0003974230734609771 Test RE 0.014444223722331286\n",
      "116 Train Loss 0.0063537736 Test MSE 0.00042979552294170954 Test RE 0.015020991877503704\n",
      "117 Train Loss 0.0062107076 Test MSE 0.00048588316968292656 Test RE 0.01597105464530839\n",
      "118 Train Loss 0.0060019544 Test MSE 0.00046376004371137867 Test RE 0.015603223587661828\n",
      "119 Train Loss 0.005784874 Test MSE 0.0004313966126595415 Test RE 0.015048944238622491\n",
      "120 Train Loss 0.0056765666 Test MSE 0.00042481210261003933 Test RE 0.014933654800337409\n",
      "121 Train Loss 0.005563546 Test MSE 0.000382898295838641 Test RE 0.014177817586589732\n",
      "122 Train Loss 0.005439171 Test MSE 0.0003445545010192586 Test RE 0.013449205559498724\n",
      "123 Train Loss 0.0052262894 Test MSE 0.0003572179669693452 Test RE 0.013694125853958634\n",
      "124 Train Loss 0.0048535266 Test MSE 0.0005055974710398381 Test RE 0.016291839169013708\n",
      "125 Train Loss 0.0046449336 Test MSE 0.0005252082184447861 Test RE 0.016604791408208124\n",
      "126 Train Loss 0.004432849 Test MSE 0.0003969593467150195 Test RE 0.014435794257150771\n",
      "127 Train Loss 0.0043680337 Test MSE 0.00032848313779687907 Test RE 0.013131798434679431\n",
      "128 Train Loss 0.0042829667 Test MSE 0.0003045629919803068 Test RE 0.012644633115239157\n",
      "129 Train Loss 0.0041785333 Test MSE 0.0002527352832814105 Test RE 0.011518624100460232\n",
      "130 Train Loss 0.004006571 Test MSE 0.00021213598561530686 Test RE 0.010552973333871066\n",
      "131 Train Loss 0.003782992 Test MSE 0.00022307547548859572 Test RE 0.010821652434661747\n",
      "132 Train Loss 0.0036795677 Test MSE 0.00022676490759879423 Test RE 0.01091077478365975\n",
      "133 Train Loss 0.003598022 Test MSE 0.00022773065555108452 Test RE 0.01093398354095476\n",
      "134 Train Loss 0.0035511735 Test MSE 0.00023141644191655562 Test RE 0.011022110828994675\n",
      "135 Train Loss 0.0035009768 Test MSE 0.0002231583402551455 Test RE 0.010823662181452264\n",
      "136 Train Loss 0.0034058446 Test MSE 0.00021030136261353705 Test RE 0.010507241420296813\n",
      "137 Train Loss 0.0033050538 Test MSE 0.0001831309753223856 Test RE 0.009805021986215164\n",
      "138 Train Loss 0.0031644006 Test MSE 0.00015540410680416807 Test RE 0.009032311637380991\n",
      "139 Train Loss 0.0031207555 Test MSE 0.00015716649049221543 Test RE 0.009083383394366998\n",
      "140 Train Loss 0.0030983079 Test MSE 0.00015504984233156673 Test RE 0.009022010581396754\n",
      "141 Train Loss 0.0030466001 Test MSE 0.000144715116526179 Test RE 0.008716148421940384\n",
      "142 Train Loss 0.0029791333 Test MSE 0.00014319412157650085 Test RE 0.008670222894068786\n",
      "143 Train Loss 0.0028630325 Test MSE 0.00012822582593896283 Test RE 0.008204562359008183\n",
      "144 Train Loss 0.0027191613 Test MSE 0.00012964181377969996 Test RE 0.008249739153058917\n",
      "145 Train Loss 0.0025863692 Test MSE 0.00012786569873198846 Test RE 0.008193032842192033\n",
      "146 Train Loss 0.0025433125 Test MSE 0.00012148440237916654 Test RE 0.007985974671554543\n",
      "147 Train Loss 0.0024914262 Test MSE 0.00011657679868251569 Test RE 0.007823007203310757\n",
      "148 Train Loss 0.0024437907 Test MSE 0.0001186625271057274 Test RE 0.007892679436982668\n",
      "149 Train Loss 0.0024228045 Test MSE 0.00012056497150995948 Test RE 0.007955697133956904\n",
      "150 Train Loss 0.0023723554 Test MSE 0.00011864270558802328 Test RE 0.007892020208569389\n",
      "151 Train Loss 0.0023365293 Test MSE 0.00011490908822900462 Test RE 0.007766848912776726\n",
      "152 Train Loss 0.002283377 Test MSE 0.00011393543407679207 Test RE 0.007733873661619102\n",
      "153 Train Loss 0.002192478 Test MSE 0.00011025723906107532 Test RE 0.007608012618272189\n",
      "154 Train Loss 0.0021517838 Test MSE 0.00011107709798620837 Test RE 0.00763624634107167\n",
      "155 Train Loss 0.002120621 Test MSE 0.00010551704098264635 Test RE 0.007442673534921222\n",
      "156 Train Loss 0.0020981526 Test MSE 0.00010700202740765856 Test RE 0.007494862520134\n",
      "157 Train Loss 0.002085335 Test MSE 0.00010334397184646565 Test RE 0.007365635818565337\n",
      "158 Train Loss 0.00207449 Test MSE 0.00010216108186857156 Test RE 0.007323360433944938\n",
      "159 Train Loss 0.002057358 Test MSE 0.00010124113489720704 Test RE 0.007290312924650773\n",
      "160 Train Loss 0.0020258485 Test MSE 0.00010229463644518695 Test RE 0.007328145763335164\n",
      "161 Train Loss 0.0019912259 Test MSE 9.964172774005214e-05 Test RE 0.007232497502370785\n",
      "162 Train Loss 0.0019490971 Test MSE 9.492455541018731e-05 Test RE 0.007059223846875353\n",
      "163 Train Loss 0.0018973534 Test MSE 8.873742790356982e-05 Test RE 0.006825289637834258\n",
      "164 Train Loss 0.0018652378 Test MSE 8.54859502882814e-05 Test RE 0.006699078078219307\n",
      "165 Train Loss 0.0018430317 Test MSE 8.683215038141129e-05 Test RE 0.006751619297858834\n",
      "166 Train Loss 0.0018229255 Test MSE 8.26358375338398e-05 Test RE 0.006586457354218679\n",
      "167 Train Loss 0.0017968904 Test MSE 8.047305566957735e-05 Test RE 0.006499694043796131\n",
      "168 Train Loss 0.0017770681 Test MSE 8.382991753894632e-05 Test RE 0.006633873520446347\n",
      "169 Train Loss 0.0017476756 Test MSE 8.062260905927827e-05 Test RE 0.006505730847453543\n",
      "170 Train Loss 0.0017320259 Test MSE 7.830838227534569e-05 Test RE 0.00641167933138787\n",
      "171 Train Loss 0.0017021495 Test MSE 7.489203459964987e-05 Test RE 0.006270259029848758\n",
      "172 Train Loss 0.0016752759 Test MSE 7.56535425031249e-05 Test RE 0.006302056639493812\n",
      "173 Train Loss 0.0016401344 Test MSE 6.38203079488599e-05 Test RE 0.005788247799922735\n",
      "174 Train Loss 0.001602601 Test MSE 5.922800599666071e-05 Test RE 0.005576108600285856\n",
      "175 Train Loss 0.0015866744 Test MSE 5.766504197401439e-05 Test RE 0.005502042920079186\n",
      "176 Train Loss 0.0015788699 Test MSE 5.7706243703594766e-05 Test RE 0.0055040081766542116\n",
      "177 Train Loss 0.0015695688 Test MSE 5.7506606600468845e-05 Test RE 0.005494479257733627\n",
      "178 Train Loss 0.0015615162 Test MSE 5.6732259154156954e-05 Test RE 0.005457361298254905\n",
      "179 Train Loss 0.0015473638 Test MSE 5.3708036288586e-05 Test RE 0.005309911765438386\n",
      "180 Train Loss 0.0015340613 Test MSE 5.088243474394458e-05 Test RE 0.005168346351840235\n",
      "181 Train Loss 0.0015000339 Test MSE 5.34012846461335e-05 Test RE 0.005294726360449267\n",
      "182 Train Loss 0.0014614641 Test MSE 5.532115398014844e-05 Test RE 0.0053890632773792016\n",
      "183 Train Loss 0.0014387378 Test MSE 5.8433179220113835e-05 Test RE 0.005538567151636429\n",
      "184 Train Loss 0.0014257552 Test MSE 5.577413014119758e-05 Test RE 0.005411081441631585\n",
      "185 Train Loss 0.001400203 Test MSE 5.092269024022231e-05 Test RE 0.005170390409030513\n",
      "186 Train Loss 0.0013841935 Test MSE 4.909015135999936e-05 Test RE 0.005076505408667494\n",
      "187 Train Loss 0.0013718364 Test MSE 4.8669071190564814e-05 Test RE 0.005054686169815661\n",
      "188 Train Loss 0.0013654884 Test MSE 4.905157682633198e-05 Test RE 0.005074510483946546\n",
      "189 Train Loss 0.00135296 Test MSE 4.977870854182241e-05 Test RE 0.005111983933363691\n",
      "190 Train Loss 0.0013400582 Test MSE 4.9478254130992356e-05 Test RE 0.0050965331230567465\n",
      "191 Train Loss 0.0013270987 Test MSE 4.993410381367461e-05 Test RE 0.005119956811379319\n",
      "192 Train Loss 0.0013056834 Test MSE 4.919351992037351e-05 Test RE 0.005081847367198927\n",
      "193 Train Loss 0.001284309 Test MSE 5.022709134770409e-05 Test RE 0.005134955473707886\n",
      "194 Train Loss 0.0012567735 Test MSE 4.848529588471361e-05 Test RE 0.005045133849990131\n",
      "195 Train Loss 0.0011975021 Test MSE 5.01119452574596e-05 Test RE 0.005129066129008017\n",
      "196 Train Loss 0.0011625552 Test MSE 5.924078181410519e-05 Test RE 0.005576709967013138\n",
      "197 Train Loss 0.0011456626 Test MSE 6.179296394044411e-05 Test RE 0.005695569833438672\n",
      "198 Train Loss 0.0011383542 Test MSE 7.03369690568885e-05 Test RE 0.0060765838154647036\n",
      "199 Train Loss 0.0011265074 Test MSE 8.13751687684548e-05 Test RE 0.006536023707327569\n",
      "200 Train Loss 0.0011144787 Test MSE 9.687955354171135e-05 Test RE 0.007131546725413236\n",
      "201 Train Loss 0.0011074851 Test MSE 0.0001010816745309434 Test RE 0.0072845693398526975\n",
      "202 Train Loss 0.0011029115 Test MSE 9.908134914865179e-05 Test RE 0.00721213127981506\n",
      "203 Train Loss 0.0010969837 Test MSE 9.50239039457014e-05 Test RE 0.007062916991087434\n",
      "204 Train Loss 0.0010890228 Test MSE 9.929941673100387e-05 Test RE 0.007220063487248681\n",
      "205 Train Loss 0.0010784301 Test MSE 9.56707417978959e-05 Test RE 0.007086915235447512\n",
      "206 Train Loss 0.0010645995 Test MSE 9.881624679688738e-05 Test RE 0.007202476417419174\n",
      "207 Train Loss 0.0010531092 Test MSE 0.00010014690461717087 Test RE 0.0072508084615224835\n",
      "208 Train Loss 0.0010409794 Test MSE 8.59501727791364e-05 Test RE 0.006717242771834055\n",
      "209 Train Loss 0.0010328171 Test MSE 7.783817397186135e-05 Test RE 0.006392400653327816\n",
      "210 Train Loss 0.0010224716 Test MSE 7.851206470522483e-05 Test RE 0.006420012400525176\n",
      "211 Train Loss 0.0010069949 Test MSE 6.806512339323865e-05 Test RE 0.005977643157268276\n",
      "212 Train Loss 0.0009921497 Test MSE 6.017697329871947e-05 Test RE 0.005620602055040373\n",
      "213 Train Loss 0.0009779007 Test MSE 5.299879175421339e-05 Test RE 0.005274735076313645\n",
      "214 Train Loss 0.00097029196 Test MSE 5.591075376989809e-05 Test RE 0.005417704847498712\n",
      "215 Train Loss 0.0009589017 Test MSE 5.5594990847072586e-05 Test RE 0.0054023846057825575\n",
      "216 Train Loss 0.00095536694 Test MSE 5.204454860338064e-05 Test RE 0.005227033586902167\n",
      "217 Train Loss 0.00095123163 Test MSE 5.744512997659058e-05 Test RE 0.005491541574758835\n",
      "218 Train Loss 0.0009470723 Test MSE 5.6898046881071206e-05 Test RE 0.005465329458771549\n",
      "219 Train Loss 0.00094243005 Test MSE 5.397388236858459e-05 Test RE 0.005323037144931757\n",
      "220 Train Loss 0.0009410386 Test MSE 5.477969060112248e-05 Test RE 0.0053626253292157365\n",
      "221 Train Loss 0.0009365883 Test MSE 5.56262820938571e-05 Test RE 0.005403904738867076\n",
      "222 Train Loss 0.0009349609 Test MSE 5.650683791162289e-05 Test RE 0.005446508305193282\n",
      "223 Train Loss 0.00093135424 Test MSE 5.6717822302350174e-05 Test RE 0.005456666877387147\n",
      "224 Train Loss 0.00092646945 Test MSE 5.197696094565876e-05 Test RE 0.005223638440448521\n",
      "225 Train Loss 0.0009253951 Test MSE 4.9410245168001456e-05 Test RE 0.00509302926943121\n",
      "226 Train Loss 0.00092338223 Test MSE 4.8459626144055724e-05 Test RE 0.00504379814169896\n",
      "227 Train Loss 0.0009233799 Test MSE 4.822472983625158e-05 Test RE 0.005031558996803196\n",
      "228 Train Loss 0.0009232342 Test MSE 4.8112455012620785e-05 Test RE 0.00502569844985433\n",
      "229 Train Loss 0.0009188931 Test MSE 4.59882130636023e-05 Test RE 0.004913499713214955\n",
      "230 Train Loss 0.00091162964 Test MSE 4.1406352671621754e-05 Test RE 0.004662310100928951\n",
      "231 Train Loss 0.00090095133 Test MSE 3.6667077731281786e-05 Test RE 0.004387385718808242\n",
      "232 Train Loss 0.0008936711 Test MSE 3.49828099107564e-05 Test RE 0.0042854359916453385\n",
      "233 Train Loss 0.0008877977 Test MSE 3.124310372639166e-05 Test RE 0.00404990422640201\n",
      "234 Train Loss 0.00088156154 Test MSE 3.2981674884765844e-05 Test RE 0.004161060409219043\n",
      "235 Train Loss 0.0008776363 Test MSE 3.435849897344879e-05 Test RE 0.004247024427137319\n",
      "236 Train Loss 0.00087154 Test MSE 3.411911923297811e-05 Test RE 0.004232203806122281\n",
      "237 Train Loss 0.0008639517 Test MSE 3.5133850068603545e-05 Test RE 0.004294677327255126\n",
      "238 Train Loss 0.0008592325 Test MSE 3.074216139702256e-05 Test RE 0.004017305568913391\n",
      "239 Train Loss 0.00085579674 Test MSE 3.150130669521023e-05 Test RE 0.004066604642780894\n",
      "240 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "241 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "242 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "243 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "244 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "245 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "246 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "247 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "248 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "249 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "250 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "251 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "252 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "253 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "254 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "255 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "256 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "257 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "258 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "259 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "260 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "261 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "262 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "263 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "264 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "265 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "266 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "267 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "268 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "269 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "270 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "271 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "272 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "273 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "274 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "275 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "276 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "277 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "278 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "279 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "280 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "281 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "282 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "283 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "284 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "285 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "286 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "287 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "288 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "289 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "290 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "291 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "292 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "293 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "294 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "295 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "296 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "297 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "298 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "299 Train Loss 0.0008557277 Test MSE 3.1537117084612655e-05 Test RE 0.004068915425218506\n",
      "Training time: 149.07\n",
      "KG_stan_medium\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "200 Train Loss nan Test MSE nan Test RE nan\n",
      "201 Train Loss nan Test MSE nan Test RE nan\n",
      "202 Train Loss nan Test MSE nan Test RE nan\n",
      "203 Train Loss nan Test MSE nan Test RE nan\n",
      "204 Train Loss nan Test MSE nan Test RE nan\n",
      "205 Train Loss nan Test MSE nan Test RE nan\n",
      "206 Train Loss nan Test MSE nan Test RE nan\n",
      "207 Train Loss nan Test MSE nan Test RE nan\n",
      "208 Train Loss nan Test MSE nan Test RE nan\n",
      "209 Train Loss nan Test MSE nan Test RE nan\n",
      "210 Train Loss nan Test MSE nan Test RE nan\n",
      "211 Train Loss nan Test MSE nan Test RE nan\n",
      "212 Train Loss nan Test MSE nan Test RE nan\n",
      "213 Train Loss nan Test MSE nan Test RE nan\n",
      "214 Train Loss nan Test MSE nan Test RE nan\n",
      "215 Train Loss nan Test MSE nan Test RE nan\n",
      "216 Train Loss nan Test MSE nan Test RE nan\n",
      "217 Train Loss nan Test MSE nan Test RE nan\n",
      "218 Train Loss nan Test MSE nan Test RE nan\n",
      "219 Train Loss nan Test MSE nan Test RE nan\n",
      "220 Train Loss nan Test MSE nan Test RE nan\n",
      "221 Train Loss nan Test MSE nan Test RE nan\n",
      "222 Train Loss nan Test MSE nan Test RE nan\n",
      "223 Train Loss nan Test MSE nan Test RE nan\n",
      "224 Train Loss nan Test MSE nan Test RE nan\n",
      "225 Train Loss nan Test MSE nan Test RE nan\n",
      "226 Train Loss nan Test MSE nan Test RE nan\n",
      "227 Train Loss nan Test MSE nan Test RE nan\n",
      "228 Train Loss nan Test MSE nan Test RE nan\n",
      "229 Train Loss nan Test MSE nan Test RE nan\n",
      "230 Train Loss nan Test MSE nan Test RE nan\n",
      "231 Train Loss nan Test MSE nan Test RE nan\n",
      "232 Train Loss nan Test MSE nan Test RE nan\n",
      "233 Train Loss nan Test MSE nan Test RE nan\n",
      "234 Train Loss nan Test MSE nan Test RE nan\n",
      "235 Train Loss nan Test MSE nan Test RE nan\n",
      "236 Train Loss nan Test MSE nan Test RE nan\n",
      "237 Train Loss nan Test MSE nan Test RE nan\n",
      "238 Train Loss nan Test MSE nan Test RE nan\n",
      "239 Train Loss nan Test MSE nan Test RE nan\n",
      "240 Train Loss nan Test MSE nan Test RE nan\n",
      "241 Train Loss nan Test MSE nan Test RE nan\n",
      "242 Train Loss nan Test MSE nan Test RE nan\n",
      "243 Train Loss nan Test MSE nan Test RE nan\n",
      "244 Train Loss nan Test MSE nan Test RE nan\n",
      "245 Train Loss nan Test MSE nan Test RE nan\n",
      "246 Train Loss nan Test MSE nan Test RE nan\n",
      "247 Train Loss nan Test MSE nan Test RE nan\n",
      "248 Train Loss nan Test MSE nan Test RE nan\n",
      "249 Train Loss nan Test MSE nan Test RE nan\n",
      "250 Train Loss nan Test MSE nan Test RE nan\n",
      "251 Train Loss nan Test MSE nan Test RE nan\n",
      "252 Train Loss nan Test MSE nan Test RE nan\n",
      "253 Train Loss nan Test MSE nan Test RE nan\n",
      "254 Train Loss nan Test MSE nan Test RE nan\n",
      "255 Train Loss nan Test MSE nan Test RE nan\n",
      "256 Train Loss nan Test MSE nan Test RE nan\n",
      "257 Train Loss nan Test MSE nan Test RE nan\n",
      "258 Train Loss nan Test MSE nan Test RE nan\n",
      "259 Train Loss nan Test MSE nan Test RE nan\n",
      "260 Train Loss nan Test MSE nan Test RE nan\n",
      "261 Train Loss nan Test MSE nan Test RE nan\n",
      "262 Train Loss nan Test MSE nan Test RE nan\n",
      "263 Train Loss nan Test MSE nan Test RE nan\n",
      "264 Train Loss nan Test MSE nan Test RE nan\n",
      "265 Train Loss nan Test MSE nan Test RE nan\n",
      "266 Train Loss nan Test MSE nan Test RE nan\n",
      "267 Train Loss nan Test MSE nan Test RE nan\n",
      "268 Train Loss nan Test MSE nan Test RE nan\n",
      "269 Train Loss nan Test MSE nan Test RE nan\n",
      "270 Train Loss nan Test MSE nan Test RE nan\n",
      "271 Train Loss nan Test MSE nan Test RE nan\n",
      "272 Train Loss nan Test MSE nan Test RE nan\n",
      "273 Train Loss nan Test MSE nan Test RE nan\n",
      "274 Train Loss nan Test MSE nan Test RE nan\n",
      "275 Train Loss nan Test MSE nan Test RE nan\n",
      "276 Train Loss nan Test MSE nan Test RE nan\n",
      "277 Train Loss nan Test MSE nan Test RE nan\n",
      "278 Train Loss nan Test MSE nan Test RE nan\n",
      "279 Train Loss nan Test MSE nan Test RE nan\n",
      "280 Train Loss nan Test MSE nan Test RE nan\n",
      "281 Train Loss nan Test MSE nan Test RE nan\n",
      "282 Train Loss nan Test MSE nan Test RE nan\n",
      "283 Train Loss nan Test MSE nan Test RE nan\n",
      "284 Train Loss nan Test MSE nan Test RE nan\n",
      "285 Train Loss nan Test MSE nan Test RE nan\n",
      "286 Train Loss nan Test MSE nan Test RE nan\n",
      "287 Train Loss nan Test MSE nan Test RE nan\n",
      "288 Train Loss nan Test MSE nan Test RE nan\n",
      "289 Train Loss nan Test MSE nan Test RE nan\n",
      "290 Train Loss nan Test MSE nan Test RE nan\n",
      "291 Train Loss nan Test MSE nan Test RE nan\n",
      "292 Train Loss nan Test MSE nan Test RE nan\n",
      "293 Train Loss nan Test MSE nan Test RE nan\n",
      "294 Train Loss nan Test MSE nan Test RE nan\n",
      "295 Train Loss nan Test MSE nan Test RE nan\n",
      "296 Train Loss nan Test MSE nan Test RE nan\n",
      "297 Train Loss nan Test MSE nan Test RE nan\n",
      "298 Train Loss nan Test MSE nan Test RE nan\n",
      "299 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 19.24\n",
      "KG_stan_medium\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 21373.486 Test MSE 5.502554717386534 Test RE 1.6996122498669974\n",
      "1 Train Loss 3510.6316 Test MSE 12.022232883495864 Test RE 2.5122348498963305\n",
      "2 Train Loss 761.3336 Test MSE 8.273181161486603 Test RE 2.0840298484139304\n",
      "3 Train Loss 127.177475 Test MSE 8.473340229533273 Test RE 2.1090894055378304\n",
      "4 Train Loss 56.516975 Test MSE 9.717632982823329 Test RE 2.2586446743259896\n",
      "5 Train Loss 32.914597 Test MSE 9.721774114959281 Test RE 2.2591258794610356\n",
      "6 Train Loss 19.221563 Test MSE 9.552913693102038 Test RE 2.239420217423641\n",
      "7 Train Loss 14.1914015 Test MSE 9.368494541251964 Test RE 2.2176988521215333\n",
      "8 Train Loss 12.037279 Test MSE 8.820156654367613 Test RE 2.1518193918638415\n",
      "9 Train Loss 10.718089 Test MSE 8.703314948363012 Test RE 2.137519165956026\n",
      "10 Train Loss 9.799718 Test MSE 8.165897344528013 Test RE 2.0704732583480987\n",
      "11 Train Loss 8.615149 Test MSE 7.278520647104014 Test RE 1.9547410205824\n",
      "12 Train Loss 7.313519 Test MSE 6.302602723542259 Test RE 1.8189787857923425\n",
      "13 Train Loss 6.426227 Test MSE 5.093341913098247 Test RE 1.635193240525207\n",
      "14 Train Loss 5.2433405 Test MSE 3.439284491978579 Test RE 1.3436981473312875\n",
      "15 Train Loss 3.8754776 Test MSE 2.3797159466796964 Test RE 1.1177128092549058\n",
      "16 Train Loss 3.1247413 Test MSE 1.5390817546228248 Test RE 0.8988733665106916\n",
      "17 Train Loss 2.1094823 Test MSE 0.918407015020288 Test RE 0.6943609102454504\n",
      "18 Train Loss 1.3830754 Test MSE 0.5125001831294357 Test RE 0.5186981273942004\n",
      "19 Train Loss 0.967209 Test MSE 0.3729634875134488 Test RE 0.44248731619254067\n",
      "20 Train Loss 0.70158327 Test MSE 0.289020212889109 Test RE 0.38952180673293046\n",
      "21 Train Loss 0.5569605 Test MSE 0.26117053177818605 Test RE 0.37027957306904963\n",
      "22 Train Loss 0.44279146 Test MSE 0.19138140048536664 Test RE 0.31696954162717617\n",
      "23 Train Loss 0.36349925 Test MSE 0.208007961176677 Test RE 0.3304514381225697\n",
      "24 Train Loss 0.31229737 Test MSE 0.16817434096348685 Test RE 0.2971307060093302\n",
      "25 Train Loss 0.27212936 Test MSE 0.14797347737603075 Test RE 0.27871452842336597\n",
      "26 Train Loss 0.23270743 Test MSE 0.1344074928160446 Test RE 0.2656313978251171\n",
      "27 Train Loss 0.21217513 Test MSE 0.12117118182442302 Test RE 0.25221292539931106\n",
      "28 Train Loss 0.1861766 Test MSE 0.09915907308244683 Test RE 0.22815705207294512\n",
      "29 Train Loss 0.16478272 Test MSE 0.0701414713270669 Test RE 0.19189121976372453\n",
      "30 Train Loss 0.14555135 Test MSE 0.04724144703140783 Test RE 0.1574813987575597\n",
      "31 Train Loss 0.13078511 Test MSE 0.050478318895176164 Test RE 0.16278714599290192\n",
      "32 Train Loss 0.1076748 Test MSE 0.0345992335144237 Test RE 0.13477238271937625\n",
      "33 Train Loss 0.09156831 Test MSE 0.02195614072070107 Test RE 0.10736078305538889\n",
      "34 Train Loss 0.0825185 Test MSE 0.018994096830318382 Test RE 0.0998566498324749\n",
      "35 Train Loss 0.07603933 Test MSE 0.01412386202204001 Test RE 0.08610817817028367\n",
      "36 Train Loss 0.068599075 Test MSE 0.00770205523950158 Test RE 0.06358738748679019\n",
      "37 Train Loss 0.06399302 Test MSE 0.010730107009196629 Test RE 0.07505328303328332\n",
      "38 Train Loss 0.058167234 Test MSE 0.009589269332302185 Test RE 0.07095131124542997\n",
      "39 Train Loss 0.051656347 Test MSE 0.007609247262768466 Test RE 0.06320311976917177\n",
      "40 Train Loss 0.048960883 Test MSE 0.005907566114438511 Test RE 0.05568932616638323\n",
      "41 Train Loss 0.04253454 Test MSE 0.004749814072448187 Test RE 0.04993510559341843\n",
      "42 Train Loss 0.04063332 Test MSE 0.004090619040848774 Test RE 0.04634065685808758\n",
      "43 Train Loss 0.036026407 Test MSE 0.004588608148896097 Test RE 0.049080406797577955\n",
      "44 Train Loss 0.034989722 Test MSE 0.0040102878014856526 Test RE 0.045883383755212254\n",
      "45 Train Loss 0.03199947 Test MSE 0.003314791084055206 Test RE 0.041715336256066486\n",
      "46 Train Loss 0.030755414 Test MSE 0.0030810132668038946 Test RE 0.04021744271079346\n",
      "47 Train Loss 0.026112221 Test MSE 0.002252899777263435 Test RE 0.03439050900032986\n",
      "48 Train Loss 0.025462134 Test MSE 0.0016928327522540995 Test RE 0.02981087298482149\n",
      "49 Train Loss 0.02431935 Test MSE 0.0010993497220893398 Test RE 0.024023462539676323\n",
      "50 Train Loss 0.022520948 Test MSE 0.0008316662461398738 Test RE 0.020894991820387915\n",
      "51 Train Loss 0.020723468 Test MSE 0.0009497647733525341 Test RE 0.022329330224305426\n",
      "52 Train Loss 0.020031512 Test MSE 0.0010601588827484495 Test RE 0.023591369125722347\n",
      "53 Train Loss 0.018177385 Test MSE 0.0009320566677668388 Test RE 0.022120188649612238\n",
      "54 Train Loss 0.017576052 Test MSE 0.0009168872074035224 Test RE 0.021939444357408175\n",
      "55 Train Loss 0.016276998 Test MSE 0.0008387418475473215 Test RE 0.020983688162714148\n",
      "56 Train Loss 0.015335503 Test MSE 0.0007860516875687935 Test RE 0.020313895774196407\n",
      "57 Train Loss 0.014952529 Test MSE 0.0007482162643307845 Test RE 0.019818977282872394\n",
      "58 Train Loss 0.014180408 Test MSE 0.0008208367480471364 Test RE 0.020758504532861335\n",
      "59 Train Loss 0.01325779 Test MSE 0.0007298369556239218 Test RE 0.019574045467804273\n",
      "60 Train Loss 0.012874866 Test MSE 0.000734848493473051 Test RE 0.019641134594164153\n",
      "61 Train Loss 0.012453221 Test MSE 0.0006497475634536427 Test RE 0.018468856097059033\n",
      "62 Train Loss 0.011835457 Test MSE 0.0005072945399304868 Test RE 0.016319158541635934\n",
      "63 Train Loss 0.0111696 Test MSE 0.00039192373386740583 Test RE 0.01434393966062708\n",
      "64 Train Loss 0.010695283 Test MSE 0.0004277054492625992 Test RE 0.014984424208446064\n",
      "65 Train Loss 0.010055795 Test MSE 0.0004354519357105045 Test RE 0.01511951222107236\n",
      "66 Train Loss 0.009206958 Test MSE 0.00038530410723257525 Test RE 0.014222288592077055\n",
      "67 Train Loss 0.008606868 Test MSE 0.0003989027688193921 Test RE 0.014471088284313184\n",
      "68 Train Loss 0.008423234 Test MSE 0.0004185824120899224 Test RE 0.014823752516376375\n",
      "69 Train Loss 0.008253049 Test MSE 0.0004085191999917796 Test RE 0.014644478272677074\n",
      "70 Train Loss 0.007995902 Test MSE 0.0003789094339898715 Test RE 0.014103775190287958\n",
      "71 Train Loss 0.00758549 Test MSE 0.0003731637004196043 Test RE 0.013996432794330004\n",
      "72 Train Loss 0.0072656143 Test MSE 0.00033225484733162493 Test RE 0.013206974231678482\n",
      "73 Train Loss 0.006887644 Test MSE 0.0003176749371483828 Test RE 0.012913951290637849\n",
      "74 Train Loss 0.0065617557 Test MSE 0.00031081726796324617 Test RE 0.012773803674063968\n",
      "75 Train Loss 0.006044525 Test MSE 0.0003069749888379461 Test RE 0.012694604172086149\n",
      "76 Train Loss 0.0058023822 Test MSE 0.0003312728205807221 Test RE 0.013187442237389055\n",
      "77 Train Loss 0.00568994 Test MSE 0.0003729139964801 Test RE 0.013991749126992083\n",
      "78 Train Loss 0.0054447614 Test MSE 0.00034117676166424806 Test RE 0.013383120521173578\n",
      "79 Train Loss 0.005121995 Test MSE 0.0003282461311496409 Test RE 0.013127060162355276\n",
      "80 Train Loss 0.0050134286 Test MSE 0.00035450926872261917 Test RE 0.013642107417999542\n",
      "81 Train Loss 0.004832789 Test MSE 0.0003625096419601907 Test RE 0.013795182454661006\n",
      "82 Train Loss 0.004630434 Test MSE 0.00044422854191037786 Test RE 0.015271120252671225\n",
      "83 Train Loss 0.004395743 Test MSE 0.0005031014007248291 Test RE 0.016251574044160295\n",
      "84 Train Loss 0.0042861076 Test MSE 0.000531373839543324 Test RE 0.016701972043711977\n",
      "85 Train Loss 0.004218274 Test MSE 0.000544373593970383 Test RE 0.016905039620728306\n",
      "86 Train Loss 0.0041410257 Test MSE 0.0005728352908021899 Test RE 0.01734133589975352\n",
      "87 Train Loss 0.004008925 Test MSE 0.0005660378053968132 Test RE 0.017238139339711217\n",
      "88 Train Loss 0.0037748537 Test MSE 0.00045474929135935717 Test RE 0.015450896492186722\n",
      "89 Train Loss 0.0036669318 Test MSE 0.00038319899219533665 Test RE 0.014183383531221895\n",
      "90 Train Loss 0.0036095022 Test MSE 0.0003669832414997668 Test RE 0.013880042114528306\n",
      "91 Train Loss 0.0034921134 Test MSE 0.00031380648109673816 Test RE 0.012835081246002411\n",
      "92 Train Loss 0.003353962 Test MSE 0.0002613978407402113 Test RE 0.011714362673717605\n",
      "93 Train Loss 0.0032913568 Test MSE 0.00023968397388631757 Test RE 0.011217269804802848\n",
      "94 Train Loss 0.0032461092 Test MSE 0.00022918733145309915 Test RE 0.010968897333726647\n",
      "95 Train Loss 0.003178933 Test MSE 0.00019307691277435928 Test RE 0.010067759688560917\n",
      "96 Train Loss 0.0031002213 Test MSE 0.00018519173259073875 Test RE 0.00986003519310524\n",
      "97 Train Loss 0.003002931 Test MSE 0.00018733351803092694 Test RE 0.009916888086035426\n",
      "98 Train Loss 0.0029391053 Test MSE 0.00021654344586072717 Test RE 0.010662037099725494\n",
      "99 Train Loss 0.0028607133 Test MSE 0.0002124551589681204 Test RE 0.010560909191359475\n",
      "100 Train Loss 0.0027900292 Test MSE 0.0002176704739130945 Test RE 0.010689747059205081\n",
      "101 Train Loss 0.0027537763 Test MSE 0.0002024458071315122 Test RE 0.01030913106120382\n",
      "102 Train Loss 0.0027254336 Test MSE 0.0002110221000430052 Test RE 0.010525231044152308\n",
      "103 Train Loss 0.0026883278 Test MSE 0.00021057089881804745 Test RE 0.010513972653685054\n",
      "104 Train Loss 0.0026448183 Test MSE 0.00020484971481806816 Test RE 0.01037015743002836\n",
      "105 Train Loss 0.00261347 Test MSE 0.0002007964622169699 Test RE 0.010267050450045341\n",
      "106 Train Loss 0.0025828963 Test MSE 0.0001812968539010228 Test RE 0.009755798047538258\n",
      "107 Train Loss 0.0025286193 Test MSE 0.00018422710642351773 Test RE 0.009834322204392598\n",
      "108 Train Loss 0.0024455173 Test MSE 0.00017275546485730347 Test RE 0.00952321446613196\n",
      "109 Train Loss 0.0024029873 Test MSE 0.00016686811106546656 Test RE 0.009359536505769343\n",
      "110 Train Loss 0.0023694143 Test MSE 0.00015022116026177634 Test RE 0.008880414221570094\n",
      "111 Train Loss 0.0023282557 Test MSE 0.00014301195213752455 Test RE 0.008664706074380553\n",
      "112 Train Loss 0.002286117 Test MSE 0.00014484605115221413 Test RE 0.008720090607233647\n",
      "113 Train Loss 0.0022594337 Test MSE 0.00014866227798063442 Test RE 0.008834216927091191\n",
      "114 Train Loss 0.002233856 Test MSE 0.0001460157320083816 Test RE 0.00875522865254993\n",
      "115 Train Loss 0.0022071856 Test MSE 0.0001431701176832049 Test RE 0.008669496160926781\n",
      "116 Train Loss 0.0021698945 Test MSE 0.0001401330695063919 Test RE 0.008577050855892325\n",
      "117 Train Loss 0.0021273843 Test MSE 0.00014858650040009528 Test RE 0.008831965108663081\n",
      "118 Train Loss 0.002056112 Test MSE 0.00016977777959578617 Test RE 0.009440784674950457\n",
      "119 Train Loss 0.0019816987 Test MSE 0.0001613515944508736 Test RE 0.009203527161442982\n",
      "120 Train Loss 0.0019258456 Test MSE 0.00014650058177941876 Test RE 0.00876975260999799\n",
      "121 Train Loss 0.0018813467 Test MSE 0.0001333309342716322 Test RE 0.008366294129785123\n",
      "122 Train Loss 0.0018430876 Test MSE 0.00012469865086518113 Test RE 0.008090931885928772\n",
      "123 Train Loss 0.0018140407 Test MSE 0.00011928928168756333 Test RE 0.00791349585779473\n",
      "124 Train Loss 0.0017862171 Test MSE 0.00011883819788761708 Test RE 0.007898519529995028\n",
      "125 Train Loss 0.001757587 Test MSE 0.00012042010367705143 Test RE 0.007950916014665292\n",
      "126 Train Loss 0.0017032922 Test MSE 0.0001268947421077475 Test RE 0.00816186639545459\n",
      "127 Train Loss 0.0016664631 Test MSE 0.00012972549976258182 Test RE 0.008252401396555661\n",
      "128 Train Loss 0.0016192107 Test MSE 0.00013054381994632113 Test RE 0.008278388925205556\n",
      "129 Train Loss 0.0015559389 Test MSE 0.00011627771688024894 Test RE 0.007812965661144613\n",
      "130 Train Loss 0.0015243759 Test MSE 0.00010942800238606798 Test RE 0.007579348967494954\n",
      "131 Train Loss 0.0014942489 Test MSE 0.00010111501802686307 Test RE 0.007285770709843356\n",
      "132 Train Loss 0.0014621833 Test MSE 9.23051393660458e-05 Test RE 0.00696114385643893\n",
      "133 Train Loss 0.0014353772 Test MSE 8.73666212990079e-05 Test RE 0.006772366269599893\n",
      "134 Train Loss 0.0013893733 Test MSE 8.5565246224078e-05 Test RE 0.006702184357872668\n",
      "135 Train Loss 0.0013522839 Test MSE 8.082092619449374e-05 Test RE 0.006513727397551318\n",
      "136 Train Loss 0.0013138406 Test MSE 7.78882707678642e-05 Test RE 0.006394457403025049\n",
      "137 Train Loss 0.0012922438 Test MSE 7.415418677075993e-05 Test RE 0.006239294797415838\n",
      "138 Train Loss 0.0012775653 Test MSE 7.528748900644069e-05 Test RE 0.006286791742007795\n",
      "139 Train Loss 0.0012647479 Test MSE 7.487143528092889e-05 Test RE 0.006269396642094037\n",
      "140 Train Loss 0.0012570346 Test MSE 7.463592008481253e-05 Test RE 0.006259528384916274\n",
      "141 Train Loss 0.0012400931 Test MSE 7.8489816336735e-05 Test RE 0.00641910270007006\n",
      "142 Train Loss 0.0012239945 Test MSE 8.440561191299592e-05 Test RE 0.006656613309479175\n",
      "143 Train Loss 0.0011972189 Test MSE 7.925983198322649e-05 Test RE 0.006450512799663437\n",
      "144 Train Loss 0.0011734319 Test MSE 8.012459023688928e-05 Test RE 0.006485606248221011\n",
      "145 Train Loss 0.0011520379 Test MSE 7.696839897596368e-05 Test RE 0.006356585517398639\n",
      "146 Train Loss 0.0011366069 Test MSE 7.691005734152741e-05 Test RE 0.006354175931800139\n",
      "147 Train Loss 0.0011229343 Test MSE 7.613297732462623e-05 Test RE 0.006321993932131342\n",
      "148 Train Loss 0.0011084409 Test MSE 7.427562604550636e-05 Test RE 0.006244401626242128\n",
      "149 Train Loss 0.0010990335 Test MSE 7.276924905708003e-05 Test RE 0.006180756215503398\n",
      "150 Train Loss 0.0010910768 Test MSE 7.436858869817272e-05 Test RE 0.0062483081205265325\n",
      "151 Train Loss 0.0010829777 Test MSE 7.402837199381846e-05 Test RE 0.006233999555375773\n",
      "152 Train Loss 0.001072919 Test MSE 7.179364158270284e-05 Test RE 0.006139184126406872\n",
      "153 Train Loss 0.0010605772 Test MSE 7.104614997705215e-05 Test RE 0.006107140926996729\n",
      "154 Train Loss 0.0010489373 Test MSE 7.033782550913281e-05 Test RE 0.006076620810860395\n",
      "155 Train Loss 0.001041227 Test MSE 7.036770128488369e-05 Test RE 0.006077911186884308\n",
      "156 Train Loss 0.0010345776 Test MSE 6.798061567268858e-05 Test RE 0.005973931168904467\n",
      "157 Train Loss 0.0010242729 Test MSE 7.0350974284427e-05 Test RE 0.006077188758385634\n",
      "158 Train Loss 0.001014755 Test MSE 6.762666115048038e-05 Test RE 0.005958358644950076\n",
      "159 Train Loss 0.0010065368 Test MSE 6.769330423047903e-05 Test RE 0.005961293771320615\n",
      "160 Train Loss 0.000996969 Test MSE 6.475597995711776e-05 Test RE 0.005830524272157224\n",
      "161 Train Loss 0.0009825126 Test MSE 6.623634883729775e-05 Test RE 0.005896792692579193\n",
      "162 Train Loss 0.00096893945 Test MSE 6.785286108331281e-05 Test RE 0.005968315185447889\n",
      "163 Train Loss 0.000958951 Test MSE 6.772090912953036e-05 Test RE 0.005962509136276864\n",
      "164 Train Loss 0.0009515139 Test MSE 6.956151955548608e-05 Test RE 0.006042994484971878\n",
      "165 Train Loss 0.00094408233 Test MSE 7.454996264086613e-05 Test RE 0.006255922828325541\n",
      "166 Train Loss 0.0009401104 Test MSE 7.813225726922272e-05 Test RE 0.006404464952143967\n",
      "167 Train Loss 0.0009361786 Test MSE 7.672532830101903e-05 Test RE 0.006346540347165252\n",
      "168 Train Loss 0.00093124877 Test MSE 7.55974669022376e-05 Test RE 0.006299720614567994\n",
      "169 Train Loss 0.0009260549 Test MSE 7.219620990189508e-05 Test RE 0.006156372181878012\n",
      "170 Train Loss 0.0009229398 Test MSE 6.71094538507985e-05 Test RE 0.00593553021175694\n",
      "171 Train Loss 0.00091729796 Test MSE 6.803542804650239e-05 Test RE 0.005976339056560425\n",
      "172 Train Loss 0.00090977264 Test MSE 6.62007364496236e-05 Test RE 0.005895207255689319\n",
      "173 Train Loss 0.0008982559 Test MSE 6.139778589838297e-05 Test RE 0.005677328483104972\n",
      "174 Train Loss 0.0008909829 Test MSE 5.761227123274715e-05 Test RE 0.005499524814396832\n",
      "175 Train Loss 0.0008824891 Test MSE 5.4180454297838795e-05 Test RE 0.005333213733212616\n",
      "176 Train Loss 0.00087897835 Test MSE 5.328825360401015e-05 Test RE 0.005289119889905585\n",
      "177 Train Loss 0.00087371207 Test MSE 5.17675967941434e-05 Test RE 0.005213107369212682\n",
      "178 Train Loss 0.00086584303 Test MSE 5.0723053024141605e-05 Test RE 0.00516024546194126\n",
      "179 Train Loss 0.0008585518 Test MSE 4.694928610174163e-05 Test RE 0.004964576007214086\n",
      "180 Train Loss 0.0008486539 Test MSE 4.630207770004265e-05 Test RE 0.004930238257145934\n",
      "181 Train Loss 0.0008394975 Test MSE 4.47659209193577e-05 Test RE 0.004847763553410439\n",
      "182 Train Loss 0.000831617 Test MSE 4.6847106590916764e-05 Test RE 0.004959170661380001\n",
      "183 Train Loss 0.00082502235 Test MSE 4.825671155255222e-05 Test RE 0.005033227137012168\n",
      "184 Train Loss 0.00081828964 Test MSE 4.808191279974759e-05 Test RE 0.005024103017655594\n",
      "185 Train Loss 0.00081125676 Test MSE 4.982019533024861e-05 Test RE 0.005114113715678057\n",
      "186 Train Loss 0.0007997008 Test MSE 5.008244911414972e-05 Test RE 0.005127556409743129\n",
      "187 Train Loss 0.00078967534 Test MSE 4.719170007911098e-05 Test RE 0.004977376341609211\n",
      "188 Train Loss 0.0007802116 Test MSE 4.7409611441383974e-05 Test RE 0.004988854818253434\n",
      "189 Train Loss 0.00077221723 Test MSE 4.698646656505242e-05 Test RE 0.004966541412029719\n",
      "190 Train Loss 0.00076758343 Test MSE 4.85987742331935e-05 Test RE 0.005051034390046755\n",
      "191 Train Loss 0.0007636682 Test MSE 4.968429780668416e-05 Test RE 0.005107133915847904\n",
      "192 Train Loss 0.0007573709 Test MSE 5.071676390281988e-05 Test RE 0.005159925544134098\n",
      "193 Train Loss 0.0007533479 Test MSE 4.9171317748116265e-05 Test RE 0.0050807004602062555\n",
      "194 Train Loss 0.0007473293 Test MSE 4.729217835332013e-05 Test RE 0.004982672318022901\n",
      "195 Train Loss 0.0007424464 Test MSE 4.8830713781132865e-05 Test RE 0.005063073172695369\n",
      "196 Train Loss 0.0007386713 Test MSE 4.8792622758320325e-05 Test RE 0.005061098029944741\n",
      "197 Train Loss 0.00073286786 Test MSE 4.813603979268204e-05 Test RE 0.0050269301004761706\n",
      "198 Train Loss 0.0007241615 Test MSE 4.819592720469156e-05 Test RE 0.00503005620159926\n",
      "199 Train Loss 0.0007142189 Test MSE 4.913499189364141e-05 Test RE 0.005078823401656897\n",
      "200 Train Loss 0.00070433965 Test MSE 5.053461583306912e-05 Test RE 0.0051506513337445554\n",
      "201 Train Loss 0.0006952391 Test MSE 5.08215909059338e-05 Test RE 0.005165255343201005\n",
      "202 Train Loss 0.0006858256 Test MSE 4.828042747275224e-05 Test RE 0.005034463783138592\n",
      "203 Train Loss 0.00067859225 Test MSE 4.8538969281646755e-05 Test RE 0.005047925568252268\n",
      "204 Train Loss 0.00067079125 Test MSE 4.852114446979798e-05 Test RE 0.005046998616290336\n",
      "205 Train Loss 0.00066119106 Test MSE 4.9294426358719664e-05 Test RE 0.005087056675529962\n",
      "206 Train Loss 0.0006562087 Test MSE 4.77488779892333e-05 Test RE 0.005006673297269053\n",
      "207 Train Loss 0.0006530877 Test MSE 4.9997430144866316e-05 Test RE 0.005123202342236482\n",
      "208 Train Loss 0.000648882 Test MSE 5.247555656722206e-05 Test RE 0.005248632851698754\n",
      "209 Train Loss 0.00064416276 Test MSE 5.361530712951066e-05 Test RE 0.00530532589337251\n",
      "210 Train Loss 0.00063880504 Test MSE 5.374149896757553e-05 Test RE 0.00531156567253846\n",
      "211 Train Loss 0.0006343551 Test MSE 5.2494190505043716e-05 Test RE 0.005249564657131349\n",
      "212 Train Loss 0.00062658807 Test MSE 5.49364478378872e-05 Test RE 0.005370292676296677\n",
      "213 Train Loss 0.0006222195 Test MSE 5.734360925885623e-05 Test RE 0.005486686926723296\n",
      "214 Train Loss 0.00061930297 Test MSE 5.623360475660459e-05 Test RE 0.005433324325732745\n",
      "215 Train Loss 0.0006130883 Test MSE 5.4717236185287885e-05 Test RE 0.005359567488402266\n",
      "216 Train Loss 0.0006064555 Test MSE 5.4626364538527526e-05 Test RE 0.005355115188400118\n",
      "217 Train Loss 0.0006033376 Test MSE 5.59909349766596e-05 Test RE 0.0054215882013532776\n",
      "218 Train Loss 0.0005996644 Test MSE 5.476739317189704e-05 Test RE 0.005362023370659528\n",
      "219 Train Loss 0.0005995039 Test MSE 5.4847448905176315e-05 Test RE 0.005365940883759175\n",
      "220 Train Loss 0.00059575506 Test MSE 5.622751606286758e-05 Test RE 0.005433030171165656\n",
      "221 Train Loss 0.0005925763 Test MSE 5.657551392369614e-05 Test RE 0.0054498170276728215\n",
      "222 Train Loss 0.0005908067 Test MSE 5.658444514696119e-05 Test RE 0.005450247174996789\n",
      "223 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "224 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "225 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "226 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "227 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "228 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "229 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "230 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "231 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "232 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "233 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "234 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "235 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "236 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "237 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "238 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "239 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "240 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "241 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "242 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "243 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "244 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "245 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "246 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "247 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "248 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "249 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "250 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "251 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "252 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "253 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "254 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "255 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "256 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "257 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "258 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "259 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "260 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "261 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "262 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "263 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "264 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "265 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "266 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "267 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "268 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "269 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "270 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "271 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "272 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "273 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "274 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "275 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "276 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "277 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "278 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "279 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "280 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "281 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "282 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "283 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "284 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "285 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "286 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "287 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "288 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "289 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "290 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "291 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "292 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "293 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "294 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "295 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "296 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "297 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "298 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "299 Train Loss 0.000590131 Test MSE 5.7222460162820136e-05 Test RE 0.005480888036307331\n",
      "Training time: 149.73\n",
      "KG_stan_medium\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "200 Train Loss nan Test MSE nan Test RE nan\n",
      "201 Train Loss nan Test MSE nan Test RE nan\n",
      "202 Train Loss nan Test MSE nan Test RE nan\n",
      "203 Train Loss nan Test MSE nan Test RE nan\n",
      "204 Train Loss nan Test MSE nan Test RE nan\n",
      "205 Train Loss nan Test MSE nan Test RE nan\n",
      "206 Train Loss nan Test MSE nan Test RE nan\n",
      "207 Train Loss nan Test MSE nan Test RE nan\n",
      "208 Train Loss nan Test MSE nan Test RE nan\n",
      "209 Train Loss nan Test MSE nan Test RE nan\n",
      "210 Train Loss nan Test MSE nan Test RE nan\n",
      "211 Train Loss nan Test MSE nan Test RE nan\n",
      "212 Train Loss nan Test MSE nan Test RE nan\n",
      "213 Train Loss nan Test MSE nan Test RE nan\n",
      "214 Train Loss nan Test MSE nan Test RE nan\n",
      "215 Train Loss nan Test MSE nan Test RE nan\n",
      "216 Train Loss nan Test MSE nan Test RE nan\n",
      "217 Train Loss nan Test MSE nan Test RE nan\n",
      "218 Train Loss nan Test MSE nan Test RE nan\n",
      "219 Train Loss nan Test MSE nan Test RE nan\n",
      "220 Train Loss nan Test MSE nan Test RE nan\n",
      "221 Train Loss nan Test MSE nan Test RE nan\n",
      "222 Train Loss nan Test MSE nan Test RE nan\n",
      "223 Train Loss nan Test MSE nan Test RE nan\n",
      "224 Train Loss nan Test MSE nan Test RE nan\n",
      "225 Train Loss nan Test MSE nan Test RE nan\n",
      "226 Train Loss nan Test MSE nan Test RE nan\n",
      "227 Train Loss nan Test MSE nan Test RE nan\n",
      "228 Train Loss nan Test MSE nan Test RE nan\n",
      "229 Train Loss nan Test MSE nan Test RE nan\n",
      "230 Train Loss nan Test MSE nan Test RE nan\n",
      "231 Train Loss nan Test MSE nan Test RE nan\n",
      "232 Train Loss nan Test MSE nan Test RE nan\n",
      "233 Train Loss nan Test MSE nan Test RE nan\n",
      "234 Train Loss nan Test MSE nan Test RE nan\n",
      "235 Train Loss nan Test MSE nan Test RE nan\n",
      "236 Train Loss nan Test MSE nan Test RE nan\n",
      "237 Train Loss nan Test MSE nan Test RE nan\n",
      "238 Train Loss nan Test MSE nan Test RE nan\n",
      "239 Train Loss nan Test MSE nan Test RE nan\n",
      "240 Train Loss nan Test MSE nan Test RE nan\n",
      "241 Train Loss nan Test MSE nan Test RE nan\n",
      "242 Train Loss nan Test MSE nan Test RE nan\n",
      "243 Train Loss nan Test MSE nan Test RE nan\n",
      "244 Train Loss nan Test MSE nan Test RE nan\n",
      "245 Train Loss nan Test MSE nan Test RE nan\n",
      "246 Train Loss nan Test MSE nan Test RE nan\n",
      "247 Train Loss nan Test MSE nan Test RE nan\n",
      "248 Train Loss nan Test MSE nan Test RE nan\n",
      "249 Train Loss nan Test MSE nan Test RE nan\n",
      "250 Train Loss nan Test MSE nan Test RE nan\n",
      "251 Train Loss nan Test MSE nan Test RE nan\n",
      "252 Train Loss nan Test MSE nan Test RE nan\n",
      "253 Train Loss nan Test MSE nan Test RE nan\n",
      "254 Train Loss nan Test MSE nan Test RE nan\n",
      "255 Train Loss nan Test MSE nan Test RE nan\n",
      "256 Train Loss nan Test MSE nan Test RE nan\n",
      "257 Train Loss nan Test MSE nan Test RE nan\n",
      "258 Train Loss nan Test MSE nan Test RE nan\n",
      "259 Train Loss nan Test MSE nan Test RE nan\n",
      "260 Train Loss nan Test MSE nan Test RE nan\n",
      "261 Train Loss nan Test MSE nan Test RE nan\n",
      "262 Train Loss nan Test MSE nan Test RE nan\n",
      "263 Train Loss nan Test MSE nan Test RE nan\n",
      "264 Train Loss nan Test MSE nan Test RE nan\n",
      "265 Train Loss nan Test MSE nan Test RE nan\n",
      "266 Train Loss nan Test MSE nan Test RE nan\n",
      "267 Train Loss nan Test MSE nan Test RE nan\n",
      "268 Train Loss nan Test MSE nan Test RE nan\n",
      "269 Train Loss nan Test MSE nan Test RE nan\n",
      "270 Train Loss nan Test MSE nan Test RE nan\n",
      "271 Train Loss nan Test MSE nan Test RE nan\n",
      "272 Train Loss nan Test MSE nan Test RE nan\n",
      "273 Train Loss nan Test MSE nan Test RE nan\n",
      "274 Train Loss nan Test MSE nan Test RE nan\n",
      "275 Train Loss nan Test MSE nan Test RE nan\n",
      "276 Train Loss nan Test MSE nan Test RE nan\n",
      "277 Train Loss nan Test MSE nan Test RE nan\n",
      "278 Train Loss nan Test MSE nan Test RE nan\n",
      "279 Train Loss nan Test MSE nan Test RE nan\n",
      "280 Train Loss nan Test MSE nan Test RE nan\n",
      "281 Train Loss nan Test MSE nan Test RE nan\n",
      "282 Train Loss nan Test MSE nan Test RE nan\n",
      "283 Train Loss nan Test MSE nan Test RE nan\n",
      "284 Train Loss nan Test MSE nan Test RE nan\n",
      "285 Train Loss nan Test MSE nan Test RE nan\n",
      "286 Train Loss nan Test MSE nan Test RE nan\n",
      "287 Train Loss nan Test MSE nan Test RE nan\n",
      "288 Train Loss nan Test MSE nan Test RE nan\n",
      "289 Train Loss nan Test MSE nan Test RE nan\n",
      "290 Train Loss nan Test MSE nan Test RE nan\n",
      "291 Train Loss nan Test MSE nan Test RE nan\n",
      "292 Train Loss nan Test MSE nan Test RE nan\n",
      "293 Train Loss nan Test MSE nan Test RE nan\n",
      "294 Train Loss nan Test MSE nan Test RE nan\n",
      "295 Train Loss nan Test MSE nan Test RE nan\n",
      "296 Train Loss nan Test MSE nan Test RE nan\n",
      "297 Train Loss nan Test MSE nan Test RE nan\n",
      "298 Train Loss nan Test MSE nan Test RE nan\n",
      "299 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 19.59\n",
      "KG_stan_medium\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 29843.115 Test MSE 4.979550223130375 Test RE 1.6168239216247067\n",
      "1 Train Loss 9977.655 Test MSE 3.971445372789107 Test RE 1.4439161177688378\n",
      "2 Train Loss 717.81635 Test MSE 4.722895360053867 Test RE 1.5746057368562494\n",
      "3 Train Loss 110.444435 Test MSE 2.2364386988472194 Test RE 1.0835430402451516\n",
      "4 Train Loss 41.4278 Test MSE 0.9933593934410687 Test RE 0.7221391145312855\n",
      "5 Train Loss 16.711487 Test MSE 0.5074425935275697 Test RE 0.5161324048690685\n",
      "6 Train Loss 9.05442 Test MSE 0.31167889021955736 Test RE 0.4045026415539484\n",
      "7 Train Loss 4.8314066 Test MSE 0.17699355464244848 Test RE 0.3048220597562407\n",
      "8 Train Loss 3.015566 Test MSE 0.1396368536725018 Test RE 0.2707495197571764\n",
      "9 Train Loss 2.302823 Test MSE 0.09194398055684279 Test RE 0.21969962648839345\n",
      "10 Train Loss 1.7731603 Test MSE 0.047112391780131095 Test RE 0.1572661460291549\n",
      "11 Train Loss 1.295059 Test MSE 0.041928047200835025 Test RE 0.1483610797678777\n",
      "12 Train Loss 0.9887725 Test MSE 0.030346511178445154 Test RE 0.1262182202874464\n",
      "13 Train Loss 0.763005 Test MSE 0.02616885265415452 Test RE 0.11720874305058682\n",
      "14 Train Loss 0.6294716 Test MSE 0.023120099968900153 Test RE 0.11016978996042015\n",
      "15 Train Loss 0.5154625 Test MSE 0.018223746542814816 Test RE 0.09781073015960322\n",
      "16 Train Loss 0.36974826 Test MSE 0.01510423751367955 Test RE 0.08904654443761977\n",
      "17 Train Loss 0.3147893 Test MSE 0.01581775505882983 Test RE 0.09112553492070087\n",
      "18 Train Loss 0.2679753 Test MSE 0.015345307514314382 Test RE 0.08975434163337193\n",
      "19 Train Loss 0.24101086 Test MSE 0.020973289109154726 Test RE 0.10493030600632354\n",
      "20 Train Loss 0.21252955 Test MSE 0.01706363111918316 Test RE 0.09464624635572096\n",
      "21 Train Loss 0.17846546 Test MSE 0.012439160971098047 Test RE 0.08080964736512253\n",
      "22 Train Loss 0.15539055 Test MSE 0.013705890086132324 Test RE 0.08482449641139497\n",
      "23 Train Loss 0.14270192 Test MSE 0.014296337321110091 Test RE 0.08663234316727371\n",
      "24 Train Loss 0.12679525 Test MSE 0.01183255572526143 Test RE 0.07881464919999737\n",
      "25 Train Loss 0.10981463 Test MSE 0.00598776246848106 Test RE 0.056066048649708884\n",
      "26 Train Loss 0.09537688 Test MSE 0.004287174071129938 Test RE 0.04744093352901522\n",
      "27 Train Loss 0.087683044 Test MSE 0.005138717514635223 Test RE 0.05193917413657\n",
      "28 Train Loss 0.08059073 Test MSE 0.005944430353939966 Test RE 0.055862811480701074\n",
      "29 Train Loss 0.07172639 Test MSE 0.0075653447032340854 Test RE 0.06302052663060861\n",
      "30 Train Loss 0.0683789 Test MSE 0.0063158504532004455 Test RE 0.05758158123396532\n",
      "31 Train Loss 0.06175552 Test MSE 0.004437403548558179 Test RE 0.04826498002819977\n",
      "32 Train Loss 0.05807174 Test MSE 0.003637209645501133 Test RE 0.04369702143409551\n",
      "33 Train Loss 0.052146282 Test MSE 0.0037963936622482 Test RE 0.04464299137524755\n",
      "34 Train Loss 0.046971623 Test MSE 0.003167273815307219 Test RE 0.04077654947288118\n",
      "35 Train Loss 0.045122273 Test MSE 0.003241313062498139 Test RE 0.041250399349995866\n",
      "36 Train Loss 0.04236667 Test MSE 0.0029110212766038637 Test RE 0.03909222209796109\n",
      "37 Train Loss 0.040589057 Test MSE 0.0028616061437518126 Test RE 0.03875900302542005\n",
      "38 Train Loss 0.037872385 Test MSE 0.002575158458092548 Test RE 0.03676796948248983\n",
      "39 Train Loss 0.03667552 Test MSE 0.0025966038133719343 Test RE 0.03692074985757981\n",
      "40 Train Loss 0.0338892 Test MSE 0.0031283520861238425 Test RE 0.040525229262533324\n",
      "41 Train Loss 0.03263531 Test MSE 0.003191792855162128 Test RE 0.040934078375390474\n",
      "42 Train Loss 0.030427206 Test MSE 0.0033351064413618507 Test RE 0.04184297136845518\n",
      "43 Train Loss 0.029496152 Test MSE 0.003410285311284684 Test RE 0.0423119484481262\n",
      "44 Train Loss 0.028635722 Test MSE 0.0026412491218400563 Test RE 0.03723679985543046\n",
      "45 Train Loss 0.027939199 Test MSE 0.002176068107014524 Test RE 0.03379900454868454\n",
      "46 Train Loss 0.027614936 Test MSE 0.0020194707026358685 Test RE 0.0325601536899674\n",
      "47 Train Loss 0.025794812 Test MSE 0.0018805515891272238 Test RE 0.03142029755836721\n",
      "48 Train Loss 0.025310898 Test MSE 0.0016870597121737146 Test RE 0.029759997804746557\n",
      "49 Train Loss 0.024667507 Test MSE 0.0015384793869455849 Test RE 0.028419308637689353\n",
      "50 Train Loss 0.023366336 Test MSE 0.001163765280728398 Test RE 0.024717262274664777\n",
      "51 Train Loss 0.02238351 Test MSE 0.0011712097022524026 Test RE 0.02479619244895885\n",
      "52 Train Loss 0.022034485 Test MSE 0.0010108713273332438 Test RE 0.023036452822696098\n",
      "53 Train Loss 0.021391114 Test MSE 0.0007774213111407436 Test RE 0.020202070783708923\n",
      "54 Train Loss 0.021004232 Test MSE 0.0006985844608819341 Test RE 0.019150368187623456\n",
      "55 Train Loss 0.02061269 Test MSE 0.0005980151766620304 Test RE 0.017718370165512306\n",
      "56 Train Loss 0.019927397 Test MSE 0.00048673210129284214 Test RE 0.01598500081271033\n",
      "57 Train Loss 0.019152652 Test MSE 0.00038573077725767997 Test RE 0.014230161003920529\n",
      "58 Train Loss 0.018871395 Test MSE 0.0004179543412697916 Test RE 0.01481262703518321\n",
      "59 Train Loss 0.01836684 Test MSE 0.00029506259164594677 Test RE 0.012445855201658721\n",
      "60 Train Loss 0.017720744 Test MSE 0.00025805224574592333 Test RE 0.01163915600084679\n",
      "61 Train Loss 0.017275741 Test MSE 0.00027431152386373956 Test RE 0.01200023342857358\n",
      "62 Train Loss 0.016723625 Test MSE 0.00027742505765594624 Test RE 0.012068144736125054\n",
      "63 Train Loss 0.01637011 Test MSE 0.00028863048130740767 Test RE 0.012309453283223918\n",
      "64 Train Loss 0.016215261 Test MSE 0.0002806513940253515 Test RE 0.01213811560698967\n",
      "65 Train Loss 0.016051961 Test MSE 0.00026978907156469995 Test RE 0.011900901054679246\n",
      "66 Train Loss 0.015498323 Test MSE 0.0002757722079243619 Test RE 0.012032141087577074\n",
      "67 Train Loss 0.014545377 Test MSE 0.0003324104031891835 Test RE 0.013210065506063306\n",
      "68 Train Loss 0.0142732235 Test MSE 0.00032400524219793053 Test RE 0.01304198469093783\n",
      "69 Train Loss 0.014150698 Test MSE 0.0003498166038119043 Test RE 0.013551515844647304\n",
      "70 Train Loss 0.0138978725 Test MSE 0.0003034006202383705 Test RE 0.012620480780546308\n",
      "71 Train Loss 0.013712835 Test MSE 0.00031202026439031724 Test RE 0.012798499856352773\n",
      "72 Train Loss 0.013459918 Test MSE 0.0002994295631109401 Test RE 0.012537617205615696\n",
      "73 Train Loss 0.012901034 Test MSE 0.0002714480196622266 Test RE 0.011937434632256562\n",
      "74 Train Loss 0.012398838 Test MSE 0.00029281622881370333 Test RE 0.012398388455686199\n",
      "75 Train Loss 0.012168112 Test MSE 0.0002517861299489809 Test RE 0.011496974522377893\n",
      "76 Train Loss 0.011940316 Test MSE 0.00020852190561889593 Test RE 0.010462693673180626\n",
      "77 Train Loss 0.011811523 Test MSE 0.00024253266941306532 Test RE 0.01128373273741457\n",
      "78 Train Loss 0.011629345 Test MSE 0.0002774798615641096 Test RE 0.012069336677547894\n",
      "79 Train Loss 0.011129691 Test MSE 0.0002718570872902398 Test RE 0.011946426003290647\n",
      "80 Train Loss 0.010801489 Test MSE 0.00022956673842614407 Test RE 0.010977972781258036\n",
      "81 Train Loss 0.010521529 Test MSE 0.00017982309754313504 Test RE 0.009716064849306424\n",
      "82 Train Loss 0.010280093 Test MSE 0.0001601936462879939 Test RE 0.009170442899631079\n",
      "83 Train Loss 0.01002466 Test MSE 0.00015641386908365467 Test RE 0.00906160854679971\n",
      "84 Train Loss 0.00986581 Test MSE 0.00012707406235983802 Test RE 0.008167631296411052\n",
      "85 Train Loss 0.009724065 Test MSE 0.00011823825959295096 Test RE 0.007878557008942537\n",
      "86 Train Loss 0.009550767 Test MSE 0.0001186981657961699 Test RE 0.007893864577941766\n",
      "87 Train Loss 0.009010227 Test MSE 0.0001530129258252188 Test RE 0.00896255280492299\n",
      "88 Train Loss 0.008653787 Test MSE 0.00016492929213366396 Test RE 0.009305004021356497\n",
      "89 Train Loss 0.008514086 Test MSE 0.00015007235948871544 Test RE 0.008876014908282034\n",
      "90 Train Loss 0.008432503 Test MSE 0.00015831342524830097 Test RE 0.009116466497805698\n",
      "91 Train Loss 0.008290321 Test MSE 0.00020623955299740743 Test RE 0.010405277021763417\n",
      "92 Train Loss 0.008144008 Test MSE 0.00021186992376015734 Test RE 0.010546353465540068\n",
      "93 Train Loss 0.007998615 Test MSE 0.00022980478834422915 Test RE 0.010983663127388979\n",
      "94 Train Loss 0.007877456 Test MSE 0.0002409433773015001 Test RE 0.011246701390974154\n",
      "95 Train Loss 0.0077491193 Test MSE 0.00018336719973473763 Test RE 0.009811343797995548\n",
      "96 Train Loss 0.007534625 Test MSE 0.00014206216861880242 Test RE 0.008635885740696505\n",
      "97 Train Loss 0.007415389 Test MSE 0.00012294987630090762 Test RE 0.008033997934037949\n",
      "98 Train Loss 0.007349093 Test MSE 0.00011347554097826447 Test RE 0.00771824923552892\n",
      "99 Train Loss 0.007296936 Test MSE 0.00010712261921087652 Test RE 0.007499084704046617\n",
      "100 Train Loss 0.00721892 Test MSE 8.433016937861724e-05 Test RE 0.006653637772467006\n",
      "101 Train Loss 0.0070698806 Test MSE 7.86655567997358e-05 Test RE 0.006426284939633087\n",
      "102 Train Loss 0.0069354824 Test MSE 8.085336972963724e-05 Test RE 0.006515034652675865\n",
      "103 Train Loss 0.0068271826 Test MSE 8.117104188548819e-05 Test RE 0.006527820861773379\n",
      "104 Train Loss 0.0067410762 Test MSE 9.00133276699311e-05 Test RE 0.006874182791484551\n",
      "105 Train Loss 0.0066396203 Test MSE 0.00010746304884629086 Test RE 0.00751099108598297\n",
      "106 Train Loss 0.0065355767 Test MSE 9.303840814858555e-05 Test RE 0.006988738702778408\n",
      "107 Train Loss 0.0063880417 Test MSE 8.00907315775996e-05 Test RE 0.006484235775465813\n",
      "108 Train Loss 0.006213437 Test MSE 8.438374011733567e-05 Test RE 0.0066557507985883935\n",
      "109 Train Loss 0.0060489 Test MSE 8.729152858141352e-05 Test RE 0.006769455176641262\n",
      "110 Train Loss 0.0059693377 Test MSE 9.122117319610982e-05 Test RE 0.0069201497784955246\n",
      "111 Train Loss 0.0059096483 Test MSE 9.464390649536897e-05 Test RE 0.0070487806584768175\n",
      "112 Train Loss 0.0058277613 Test MSE 9.849627886674038e-05 Test RE 0.007190806119667911\n",
      "113 Train Loss 0.0057402737 Test MSE 0.00010359090514324626 Test RE 0.007374430407705377\n",
      "114 Train Loss 0.0056691645 Test MSE 0.00010750060716494813 Test RE 0.007512303516420596\n",
      "115 Train Loss 0.0055689346 Test MSE 0.00011244322004973865 Test RE 0.007683061413520549\n",
      "116 Train Loss 0.005480488 Test MSE 0.00012456391871776604 Test RE 0.008086559732603858\n",
      "117 Train Loss 0.0054152603 Test MSE 0.00011108714183020466 Test RE 0.007636591576654209\n",
      "118 Train Loss 0.0052552233 Test MSE 0.00010285788459279862 Test RE 0.007348292950547806\n",
      "119 Train Loss 0.0051697986 Test MSE 0.00011261712111527319 Test RE 0.007689000305947457\n",
      "120 Train Loss 0.0051199165 Test MSE 0.00010716189198904041 Test RE 0.007500459217217511\n",
      "121 Train Loss 0.0050629503 Test MSE 0.00011803055552248186 Test RE 0.007871634005974687\n",
      "122 Train Loss 0.0049739145 Test MSE 0.00011649893051445655 Test RE 0.007820394054708019\n",
      "123 Train Loss 0.0048958566 Test MSE 0.00011464949226245602 Test RE 0.007758070744250413\n",
      "124 Train Loss 0.0048054797 Test MSE 0.00012541249807080385 Test RE 0.008114057424201439\n",
      "125 Train Loss 0.0047491533 Test MSE 0.00013210373021475832 Test RE 0.008327702617905594\n",
      "126 Train Loss 0.0046936125 Test MSE 0.00012938284842721888 Test RE 0.008241495421737544\n",
      "127 Train Loss 0.0045812535 Test MSE 0.0001461503038848474 Test RE 0.008759262246022503\n",
      "128 Train Loss 0.0044812835 Test MSE 0.00014996475333986457 Test RE 0.008872832160116346\n",
      "129 Train Loss 0.0044027125 Test MSE 0.00013541759027011673 Test RE 0.008431507066244888\n",
      "130 Train Loss 0.0043536555 Test MSE 0.00013261255107948152 Test RE 0.008343725013689773\n",
      "131 Train Loss 0.0043046298 Test MSE 0.00012754105537866374 Test RE 0.008182625422118816\n",
      "132 Train Loss 0.0042587738 Test MSE 0.00011048661320646346 Test RE 0.007615922188442443\n",
      "133 Train Loss 0.0042051096 Test MSE 0.00010018246346254954 Test RE 0.007252095608116014\n",
      "134 Train Loss 0.004139446 Test MSE 8.639056246896496e-05 Test RE 0.006734429618268303\n",
      "135 Train Loss 0.004065699 Test MSE 8.552210376290927e-05 Test RE 0.0067004945059880115\n",
      "136 Train Loss 0.0040050237 Test MSE 8.989695401548965e-05 Test RE 0.006869737713616156\n",
      "137 Train Loss 0.0039589615 Test MSE 9.392627382320956e-05 Test RE 0.007022006295252283\n",
      "138 Train Loss 0.0039166785 Test MSE 8.651365436618228e-05 Test RE 0.0067392256204314585\n",
      "139 Train Loss 0.0038638532 Test MSE 8.971142265446763e-05 Test RE 0.0068626450924395435\n",
      "140 Train Loss 0.0038265982 Test MSE 0.00010126055434710384 Test RE 0.00729101208254944\n",
      "141 Train Loss 0.0037859613 Test MSE 0.0001154086372911295 Test RE 0.007783713176753854\n",
      "142 Train Loss 0.0037264128 Test MSE 0.00013067411438336682 Test RE 0.008282519182070487\n",
      "143 Train Loss 0.003663164 Test MSE 0.0001309878848677533 Test RE 0.008292457079462462\n",
      "144 Train Loss 0.003594242 Test MSE 0.00011550453256185133 Test RE 0.007786946324247119\n",
      "145 Train Loss 0.0034945006 Test MSE 0.00010056758455018563 Test RE 0.00726602147822771\n",
      "146 Train Loss 0.003433144 Test MSE 9.328043122053538e-05 Test RE 0.006997822786860118\n",
      "147 Train Loss 0.003373309 Test MSE 0.00011182802874023784 Test RE 0.007662015078979795\n",
      "148 Train Loss 0.0033170222 Test MSE 0.00010750298473260191 Test RE 0.007512386589956467\n",
      "149 Train Loss 0.0032795845 Test MSE 0.00011649294632236424 Test RE 0.007820193197322262\n",
      "150 Train Loss 0.0032394326 Test MSE 0.00012112989359711297 Test RE 0.007974314052969923\n",
      "151 Train Loss 0.0031918397 Test MSE 0.00011793071965749116 Test RE 0.00786830420023676\n",
      "152 Train Loss 0.0031675438 Test MSE 0.00012031785749904285 Test RE 0.007947539820045419\n",
      "153 Train Loss 0.0031518163 Test MSE 0.0001271623408861685 Test RE 0.008170467836221105\n",
      "154 Train Loss 0.0031251567 Test MSE 0.00013559600737012543 Test RE 0.00843705963095699\n",
      "155 Train Loss 0.0030751168 Test MSE 0.0001016636563815017 Test RE 0.007305509843725949\n",
      "156 Train Loss 0.0030341207 Test MSE 0.00010079999038950452 Test RE 0.007274412309882033\n",
      "157 Train Loss 0.0029947888 Test MSE 8.975254162067113e-05 Test RE 0.006864217648843348\n",
      "158 Train Loss 0.002974694 Test MSE 9.909489888811994e-05 Test RE 0.007212624405715858\n",
      "159 Train Loss 0.002957336 Test MSE 0.00010421250040817285 Test RE 0.00739652238167097\n",
      "160 Train Loss 0.002932075 Test MSE 0.00010995671251730548 Test RE 0.007597637018937628\n",
      "161 Train Loss 0.002868191 Test MSE 9.218087809857596e-05 Test RE 0.006956456729173615\n",
      "162 Train Loss 0.0027993545 Test MSE 6.285052971985934e-05 Test RE 0.005744101942051806\n",
      "163 Train Loss 0.002755323 Test MSE 4.721215087345819e-05 Test RE 0.004978454712108769\n",
      "164 Train Loss 0.0027295025 Test MSE 4.2388618343764044e-05 Test RE 0.004717286984665988\n",
      "165 Train Loss 0.0027025177 Test MSE 4.2310108212726126e-05 Test RE 0.004712916395566077\n",
      "166 Train Loss 0.0026691416 Test MSE 3.9180915825229625e-05 Test RE 0.004535288922542891\n",
      "167 Train Loss 0.0026354904 Test MSE 3.9637339423158566e-05 Test RE 0.004561628522336238\n",
      "168 Train Loss 0.0025996815 Test MSE 3.802398166864209e-05 Test RE 0.004467828185913148\n",
      "169 Train Loss 0.0025443349 Test MSE 3.9551516724713136e-05 Test RE 0.004556687431201266\n",
      "170 Train Loss 0.0025089202 Test MSE 3.512283527544427e-05 Test RE 0.004294004063571046\n",
      "171 Train Loss 0.002489878 Test MSE 3.501289544171834e-05 Test RE 0.004287278352354739\n",
      "172 Train Loss 0.0024618732 Test MSE 3.335588577604614e-05 Test RE 0.004184599575227924\n",
      "173 Train Loss 0.0024407385 Test MSE 3.5255277689546535e-05 Test RE 0.004302092436022861\n",
      "174 Train Loss 0.002403046 Test MSE 3.4040113288120177e-05 Test RE 0.004227300938490439\n",
      "175 Train Loss 0.002360471 Test MSE 3.4645120699381e-05 Test RE 0.00426470216855305\n",
      "176 Train Loss 0.0023378092 Test MSE 3.277959861167051e-05 Test RE 0.00414829356972183\n",
      "177 Train Loss 0.0023229134 Test MSE 3.222501717712113e-05 Test RE 0.004113052437723974\n",
      "178 Train Loss 0.0023040532 Test MSE 3.328425974592411e-05 Test RE 0.004180104306643603\n",
      "179 Train Loss 0.0022582002 Test MSE 3.4511716314292355e-05 Test RE 0.004256483425251905\n",
      "180 Train Loss 0.002226122 Test MSE 3.1823646781853434e-05 Test RE 0.004087357646077042\n",
      "181 Train Loss 0.0021790473 Test MSE 3.3559201366477185e-05 Test RE 0.004197333486782606\n",
      "182 Train Loss 0.0021279813 Test MSE 3.1963043823304806e-05 Test RE 0.004096299785773161\n",
      "183 Train Loss 0.0020947973 Test MSE 3.5106718849268304e-05 Test RE 0.004293018779503187\n",
      "184 Train Loss 0.0020682334 Test MSE 4.007079756033191e-05 Test RE 0.0045865027787116205\n",
      "185 Train Loss 0.002039598 Test MSE 4.370602548765043e-05 Test RE 0.004790031009994831\n",
      "186 Train Loss 0.0020152007 Test MSE 4.951531649171417e-05 Test RE 0.005098441579539533\n",
      "187 Train Loss 0.001988196 Test MSE 4.9935302292011744e-05 Test RE 0.005120018253560497\n",
      "188 Train Loss 0.0019654937 Test MSE 5.4455893178315644e-05 Test RE 0.0053467528609452905\n",
      "189 Train Loss 0.0019455045 Test MSE 5.549264516801613e-05 Test RE 0.005397409648393907\n",
      "190 Train Loss 0.0019310797 Test MSE 5.9392547847322686e-05 Test RE 0.005583848746740204\n",
      "191 Train Loss 0.0019170595 Test MSE 6.494755607680407e-05 Test RE 0.0058391425055801405\n",
      "192 Train Loss 0.0018890424 Test MSE 6.979333773960499e-05 Test RE 0.006053055441307606\n",
      "193 Train Loss 0.0018683904 Test MSE 7.363512637528472e-05 Test RE 0.0062174197140202015\n",
      "194 Train Loss 0.0018286498 Test MSE 6.426674160043912e-05 Test RE 0.005808457396397854\n",
      "195 Train Loss 0.0017944763 Test MSE 7.134161872499806e-05 Test RE 0.0061198270264925725\n",
      "196 Train Loss 0.0017726521 Test MSE 7.016161013545452e-05 Test RE 0.006069004243970126\n",
      "197 Train Loss 0.0017528331 Test MSE 7.15590221111914e-05 Test RE 0.006129144582489814\n",
      "198 Train Loss 0.0017293015 Test MSE 7.502488758387434e-05 Test RE 0.006275818055754878\n",
      "199 Train Loss 0.0017113758 Test MSE 7.99150776016878e-05 Test RE 0.00647712130068122\n",
      "200 Train Loss 0.0016955435 Test MSE 8.110583546076054e-05 Test RE 0.00652519836630748\n",
      "201 Train Loss 0.0016569155 Test MSE 8.654613364464545e-05 Test RE 0.006740490534318973\n",
      "202 Train Loss 0.0016261953 Test MSE 0.00011579785575807953 Test RE 0.007796827510994968\n",
      "203 Train Loss 0.0015929798 Test MSE 0.00014330604998840933 Test RE 0.008673610794021134\n",
      "204 Train Loss 0.0015795294 Test MSE 0.00014508883890825225 Test RE 0.008727395759099121\n",
      "205 Train Loss 0.0015527603 Test MSE 0.00013239237519614895 Test RE 0.00833679561609418\n",
      "206 Train Loss 0.0015384124 Test MSE 0.0001409945275783949 Test RE 0.00860337386803284\n",
      "207 Train Loss 0.0015281412 Test MSE 0.0001374218664563718 Test RE 0.008493674018679188\n",
      "208 Train Loss 0.0015159716 Test MSE 0.00012730766912585705 Test RE 0.008175135336979625\n",
      "209 Train Loss 0.0015032886 Test MSE 0.00012443513952318356 Test RE 0.008082378546131228\n",
      "210 Train Loss 0.0014812195 Test MSE 0.0001166156422601377 Test RE 0.007824310414079954\n",
      "211 Train Loss 0.0014648545 Test MSE 0.00012675545499723972 Test RE 0.008157385693948183\n",
      "212 Train Loss 0.0014507759 Test MSE 0.00012796340572862277 Test RE 0.008196162546923036\n",
      "213 Train Loss 0.0014449069 Test MSE 0.00013387756917868313 Test RE 0.008383426802597203\n",
      "214 Train Loss 0.0014347896 Test MSE 0.00013079800855244188 Test RE 0.008286444644750663\n",
      "215 Train Loss 0.001419215 Test MSE 0.00011418312599309888 Test RE 0.007742275692166632\n",
      "216 Train Loss 0.0014141151 Test MSE 0.0001178842253135067 Test RE 0.007866753002602946\n",
      "217 Train Loss 0.001407658 Test MSE 0.00012544020016898988 Test RE 0.0081149535231058\n",
      "218 Train Loss 0.0014076574 Test MSE 0.00012544019771401375 Test RE 0.008114953443697372\n",
      "219 Train Loss 0.0014025843 Test MSE 0.00011921233081164138 Test RE 0.00791094303550405\n",
      "220 Train Loss 0.0013932297 Test MSE 0.00012174358875794184 Test RE 0.00799448915154081\n",
      "221 Train Loss 0.0013811283 Test MSE 0.00010490956913226398 Test RE 0.007421218513585336\n",
      "222 Train Loss 0.0013716728 Test MSE 9.66582827636689e-05 Test RE 0.007123397921582576\n",
      "223 Train Loss 0.0013549854 Test MSE 9.993853250059663e-05 Test RE 0.007243261283544574\n",
      "224 Train Loss 0.0013462554 Test MSE 9.694646539385475e-05 Test RE 0.007134009074880388\n",
      "225 Train Loss 0.0013360848 Test MSE 9.84014487864423e-05 Test RE 0.007187343710024575\n",
      "226 Train Loss 0.001318151 Test MSE 0.00010558840482466138 Test RE 0.007445189943637055\n",
      "227 Train Loss 0.0013078377 Test MSE 0.00011032968473579303 Test RE 0.007610511670054198\n",
      "228 Train Loss 0.0012995523 Test MSE 0.00011574436386893067 Test RE 0.007795026462061375\n",
      "229 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "230 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "231 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "232 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "233 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "234 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "235 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "236 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "237 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "238 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "239 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "240 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "241 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "242 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "243 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "244 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "245 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "246 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "247 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "248 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "249 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "250 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "251 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "252 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "253 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "254 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "255 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "256 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "257 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "258 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "259 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "260 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "261 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "262 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "263 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "264 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "265 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "266 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "267 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "268 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "269 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "270 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "271 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "272 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "273 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "274 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "275 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "276 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "277 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "278 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "279 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "280 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "281 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "282 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "283 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "284 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "285 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "286 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "287 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "288 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "289 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "290 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "291 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "292 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "293 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "294 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "295 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "296 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "297 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "298 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "299 Train Loss 0.0012990719 Test MSE 0.00011628823501888528 Test RE 0.007813319022045918\n",
      "Training time: 155.07\n",
      "KG_stan_medium\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 13161.256 Test MSE 25.72651111949061 Test RE 3.675006524872935\n",
      "1 Train Loss 1517.4697 Test MSE 19.57392440368599 Test RE 3.2055800087209625\n",
      "2 Train Loss 289.966 Test MSE 9.411684051331639 Test RE 2.222804858766015\n",
      "3 Train Loss 63.782936 Test MSE 3.462814207809089 Test RE 1.348286738873045\n",
      "4 Train Loss 22.305935 Test MSE 2.767671428801959 Test RE 1.205382641225199\n",
      "5 Train Loss 8.538902 Test MSE 2.4884474081466457 Test RE 1.1429622876289738\n",
      "6 Train Loss 5.1252427 Test MSE 2.181712800486726 Test RE 1.0702037231340378\n",
      "7 Train Loss 3.921471 Test MSE 1.8524375829096613 Test RE 0.9861420080015921\n",
      "8 Train Loss 3.384105 Test MSE 1.4555114969783136 Test RE 0.8741289178710312\n",
      "9 Train Loss 2.7177396 Test MSE 1.0855541455989999 Test RE 0.7549069309789646\n",
      "10 Train Loss 2.135159 Test MSE 0.6958288544763783 Test RE 0.6043922469699744\n",
      "11 Train Loss 1.3806814 Test MSE 0.3232495208708665 Test RE 0.41194251161737194\n",
      "12 Train Loss 0.72933054 Test MSE 0.09570380075082743 Test RE 0.22414665410592866\n",
      "13 Train Loss 0.5739051 Test MSE 0.06106764388335786 Test RE 0.17904955658270746\n",
      "14 Train Loss 0.46506467 Test MSE 0.032896633029401906 Test RE 0.13141453199338535\n",
      "15 Train Loss 0.3610868 Test MSE 0.02009777787523642 Test RE 0.1027168490908548\n",
      "16 Train Loss 0.27246094 Test MSE 0.015300752889589826 Test RE 0.08962394744124258\n",
      "17 Train Loss 0.21388127 Test MSE 0.011111853991698156 Test RE 0.07637670717861578\n",
      "18 Train Loss 0.16258697 Test MSE 0.007742034553511636 Test RE 0.06375220646315709\n",
      "19 Train Loss 0.13180278 Test MSE 0.004686388273833827 Test RE 0.04960058531915672\n",
      "20 Train Loss 0.10897299 Test MSE 0.004046038062123993 Test RE 0.046087446836020625\n",
      "21 Train Loss 0.094213724 Test MSE 0.003971034564225616 Test RE 0.045658275181605854\n",
      "22 Train Loss 0.076560006 Test MSE 0.0021182310392375957 Test RE 0.033346812795606355\n",
      "23 Train Loss 0.066874415 Test MSE 0.002080263911063124 Test RE 0.033046607713403606\n",
      "24 Train Loss 0.05505106 Test MSE 0.0023082270002822494 Test RE 0.034810232667691635\n",
      "25 Train Loss 0.04932579 Test MSE 0.0016047460389030086 Test RE 0.029024906128419917\n",
      "26 Train Loss 0.04343549 Test MSE 0.001682068446409004 Test RE 0.029715941839778336\n",
      "27 Train Loss 0.039616384 Test MSE 0.0023851183027957744 Test RE 0.03538527948751827\n",
      "28 Train Loss 0.03518451 Test MSE 0.001775233121694352 Test RE 0.03052778987527982\n",
      "29 Train Loss 0.03211618 Test MSE 0.0015453333069385764 Test RE 0.028482542247145567\n",
      "30 Train Loss 0.030213267 Test MSE 0.001446122213922229 Test RE 0.02755308083484863\n",
      "31 Train Loss 0.026785599 Test MSE 0.001442088451184032 Test RE 0.027514626199991257\n",
      "32 Train Loss 0.025259595 Test MSE 0.0011301154945023515 Test RE 0.02435729647412785\n",
      "33 Train Loss 0.021617755 Test MSE 0.0005995295082120068 Test RE 0.017740789765700756\n",
      "34 Train Loss 0.020006686 Test MSE 0.0006072729054809943 Test RE 0.01785499035916447\n",
      "35 Train Loss 0.018562319 Test MSE 0.000550257468006498 Test RE 0.016996153328696924\n",
      "36 Train Loss 0.016552683 Test MSE 0.0004281354227628813 Test RE 0.014991954258487974\n",
      "37 Train Loss 0.015498677 Test MSE 0.0003463473885749771 Test RE 0.013484151593729489\n",
      "38 Train Loss 0.014214369 Test MSE 0.00034727559196753583 Test RE 0.013502208119071837\n",
      "39 Train Loss 0.013152575 Test MSE 0.00030035460229226767 Test RE 0.01255696874103713\n",
      "40 Train Loss 0.012861704 Test MSE 0.0003386751067759253 Test RE 0.013333964847294523\n",
      "41 Train Loss 0.011751416 Test MSE 0.00022294978705950861 Test RE 0.010818603358703391\n",
      "42 Train Loss 0.011130601 Test MSE 0.0002127425700737272 Test RE 0.010568050219948773\n",
      "43 Train Loss 0.01045414 Test MSE 0.00021987078893488202 Test RE 0.010743639691743682\n",
      "44 Train Loss 0.010077224 Test MSE 0.00021455806385468378 Test RE 0.010613047021739814\n",
      "45 Train Loss 0.009325787 Test MSE 0.0002216800857461765 Test RE 0.010787753344917782\n",
      "46 Train Loss 0.009018249 Test MSE 0.00020052784571235265 Test RE 0.01026018075189406\n",
      "47 Train Loss 0.0083393995 Test MSE 0.0001637459526598189 Test RE 0.009271563023506185\n",
      "48 Train Loss 0.0077864644 Test MSE 0.00015990167297296669 Test RE 0.009162081938315766\n",
      "49 Train Loss 0.0075236186 Test MSE 0.00012783853344641222 Test RE 0.008192162484068266\n",
      "50 Train Loss 0.0073790275 Test MSE 0.00011625770368016932 Test RE 0.007812293265874622\n",
      "51 Train Loss 0.0069535724 Test MSE 9.62477004691128e-05 Test RE 0.007108252537751896\n",
      "52 Train Loss 0.006603015 Test MSE 0.00012312317997483947 Test RE 0.008039658090477152\n",
      "53 Train Loss 0.0063936985 Test MSE 0.00012605029468826213 Test RE 0.008134663645682112\n",
      "54 Train Loss 0.00610975 Test MSE 0.00015896536363759332 Test RE 0.009135218123900363\n",
      "55 Train Loss 0.0057092025 Test MSE 0.00013819953274416748 Test RE 0.008517672839759812\n",
      "56 Train Loss 0.0055278754 Test MSE 0.00014607269365049153 Test RE 0.008756936220515528\n",
      "57 Train Loss 0.0051101623 Test MSE 0.00019213687181275565 Test RE 0.010043221140539729\n",
      "58 Train Loss 0.0046941624 Test MSE 0.00019574524343360614 Test RE 0.010137089396497635\n",
      "59 Train Loss 0.0044735023 Test MSE 0.00023293108181781362 Test RE 0.011058122317591111\n",
      "60 Train Loss 0.004317532 Test MSE 0.00023651724409427588 Test RE 0.011142921541646053\n",
      "61 Train Loss 0.0041358764 Test MSE 0.00023114970298257587 Test RE 0.011015756756328102\n",
      "62 Train Loss 0.003952296 Test MSE 0.00022323215203828766 Test RE 0.010825452049027079\n",
      "63 Train Loss 0.0037550104 Test MSE 0.00023573728728720273 Test RE 0.011124533507407249\n",
      "64 Train Loss 0.0036954705 Test MSE 0.0002275961526919805 Test RE 0.010930754135457492\n",
      "65 Train Loss 0.0036534546 Test MSE 0.0002194316249873277 Test RE 0.010732904801475601\n",
      "66 Train Loss 0.003560192 Test MSE 0.0002202213130175151 Test RE 0.010752200184779914\n",
      "67 Train Loss 0.0034308184 Test MSE 0.00022476218914814193 Test RE 0.01086248761648803\n",
      "68 Train Loss 0.0033178555 Test MSE 0.00021181761075079073 Test RE 0.01054505137995391\n",
      "69 Train Loss 0.003252486 Test MSE 0.0002112903665940439 Test RE 0.01053191913658365\n",
      "70 Train Loss 0.003179088 Test MSE 0.00020817818138441869 Test RE 0.010454066846663616\n",
      "71 Train Loss 0.003105124 Test MSE 0.00022035777751117485 Test RE 0.010755531075634372\n",
      "72 Train Loss 0.002990994 Test MSE 0.00021626291976870374 Test RE 0.010655128673336366\n",
      "73 Train Loss 0.0028770224 Test MSE 0.00022486966573234682 Test RE 0.010865084413437412\n",
      "74 Train Loss 0.0027902182 Test MSE 0.00024375960977701102 Test RE 0.011312238179602625\n",
      "75 Train Loss 0.002679842 Test MSE 0.00026164616227871985 Test RE 0.011719925531522402\n",
      "76 Train Loss 0.0025968743 Test MSE 0.00031710830295379944 Test RE 0.012902428895445538\n",
      "77 Train Loss 0.002521921 Test MSE 0.00031767020086650565 Test RE 0.012913855021882761\n",
      "78 Train Loss 0.002456292 Test MSE 0.0003102344083095256 Test RE 0.012761821024941859\n",
      "79 Train Loss 0.0024077736 Test MSE 0.0003106699303226486 Test RE 0.012770775712973055\n",
      "80 Train Loss 0.0023570592 Test MSE 0.00029997687814637 Test RE 0.012549070472774955\n",
      "81 Train Loss 0.0022867413 Test MSE 0.00029119295657876955 Test RE 0.012363974498767643\n",
      "82 Train Loss 0.0022184516 Test MSE 0.000305195560843408 Test RE 0.01265775757962578\n",
      "83 Train Loss 0.0021670316 Test MSE 0.00030281632340881115 Test RE 0.012608322498476193\n",
      "84 Train Loss 0.0021102806 Test MSE 0.0003016525799652784 Test RE 0.012584071862283736\n",
      "85 Train Loss 0.0020570327 Test MSE 0.0002929161570724664 Test RE 0.012400503850194962\n",
      "86 Train Loss 0.002003391 Test MSE 0.00027669908129319 Test RE 0.012052344204157498\n",
      "87 Train Loss 0.0019654478 Test MSE 0.00025975301523236554 Test RE 0.011677448656091832\n",
      "88 Train Loss 0.0019128091 Test MSE 0.0002770116444902428 Test RE 0.012059149532117893\n",
      "89 Train Loss 0.0018574194 Test MSE 0.00028105415953960633 Test RE 0.012146822247576362\n",
      "90 Train Loss 0.0018022014 Test MSE 0.000288894320212069 Test RE 0.012315078071719913\n",
      "91 Train Loss 0.0017396203 Test MSE 0.0002794277289067208 Test RE 0.012111625066640895\n",
      "92 Train Loss 0.0017149651 Test MSE 0.0002799489413779259 Test RE 0.012122915622945787\n",
      "93 Train Loss 0.0016908494 Test MSE 0.00026660918152322235 Test RE 0.011830557711838632\n",
      "94 Train Loss 0.0016703577 Test MSE 0.0002617828447072921 Test RE 0.011722986342195445\n",
      "95 Train Loss 0.0016304483 Test MSE 0.0002671690798755993 Test RE 0.011842973705369953\n",
      "96 Train Loss 0.0016038694 Test MSE 0.000267216981653575 Test RE 0.01184403534407309\n",
      "97 Train Loss 0.0015609006 Test MSE 0.0002574442783162987 Test RE 0.011625437072483301\n",
      "98 Train Loss 0.001518268 Test MSE 0.0002519820788140835 Test RE 0.011501447328276371\n",
      "99 Train Loss 0.0014627476 Test MSE 0.0002460469031304753 Test RE 0.011365187872286749\n",
      "100 Train Loss 0.0014053332 Test MSE 0.00024078095497813155 Test RE 0.011242909995364604\n",
      "101 Train Loss 0.0013651839 Test MSE 0.0002162620003821561 Test RE 0.010655106024533727\n",
      "102 Train Loss 0.0013373443 Test MSE 0.00022486510835142693 Test RE 0.010864974312817298\n",
      "103 Train Loss 0.0013097652 Test MSE 0.00021016028197940796 Test RE 0.01050371643843471\n",
      "104 Train Loss 0.0012921711 Test MSE 0.00020306284949751056 Test RE 0.010324829906662976\n",
      "105 Train Loss 0.0012767438 Test MSE 0.00020195988404326997 Test RE 0.010296751317503348\n",
      "106 Train Loss 0.0012621721 Test MSE 0.00019558782753113666 Test RE 0.010133012515764208\n",
      "107 Train Loss 0.0012446821 Test MSE 0.00018867646414393908 Test RE 0.009952370426727954\n",
      "108 Train Loss 0.0012288875 Test MSE 0.00017738712703645773 Test RE 0.009650031202946047\n",
      "109 Train Loss 0.0012086345 Test MSE 0.0001802162394217068 Test RE 0.009726680022062603\n",
      "110 Train Loss 0.0011996196 Test MSE 0.0001799287233776593 Test RE 0.009718917977775743\n",
      "111 Train Loss 0.00119046 Test MSE 0.00017823710260067615 Test RE 0.009673123319927111\n",
      "112 Train Loss 0.0011794986 Test MSE 0.00017594848508817532 Test RE 0.009610819781739442\n",
      "113 Train Loss 0.0011698079 Test MSE 0.0001743684921495557 Test RE 0.009567570556927307\n",
      "114 Train Loss 0.0011598337 Test MSE 0.00018176514278432575 Test RE 0.009768389511083614\n",
      "115 Train Loss 0.0011449457 Test MSE 0.0001845006872494907 Test RE 0.00984162157507225\n",
      "116 Train Loss 0.001129807 Test MSE 0.00017551261343795626 Test RE 0.009598908109223385\n",
      "117 Train Loss 0.0011163352 Test MSE 0.00017290191154226497 Test RE 0.009527250077253023\n",
      "118 Train Loss 0.0011051947 Test MSE 0.000165758822389795 Test RE 0.009328374948926878\n",
      "119 Train Loss 0.0010899483 Test MSE 0.00016352456082388347 Test RE 0.009265293119994395\n",
      "120 Train Loss 0.0010777804 Test MSE 0.00016448736637118195 Test RE 0.009292529344380357\n",
      "121 Train Loss 0.0010577098 Test MSE 0.00016126380459962223 Test RE 0.009201023045458938\n",
      "122 Train Loss 0.0010381337 Test MSE 0.00015906730439155562 Test RE 0.00913814675486862\n",
      "123 Train Loss 0.0010173583 Test MSE 0.00017101211275485833 Test RE 0.009475041130501004\n",
      "124 Train Loss 0.0010001061 Test MSE 0.00017091386053398743 Test RE 0.009472318874246781\n",
      "125 Train Loss 0.0009790914 Test MSE 0.0001778473279438983 Test RE 0.009662540781840787\n",
      "126 Train Loss 0.0009578074 Test MSE 0.00017133247317321847 Test RE 0.009483911870238561\n",
      "127 Train Loss 0.00093186984 Test MSE 0.00016607687442031483 Test RE 0.009337320134213987\n",
      "128 Train Loss 0.00091278297 Test MSE 0.0001619269629663949 Test RE 0.009219922126123879\n",
      "129 Train Loss 0.0008966185 Test MSE 0.00016059564079772616 Test RE 0.009181941975743914\n",
      "130 Train Loss 0.0008863226 Test MSE 0.0001618781497479069 Test RE 0.009218532339063445\n",
      "131 Train Loss 0.00087553647 Test MSE 0.00015614157816523115 Test RE 0.009053717723256341\n",
      "132 Train Loss 0.0008609236 Test MSE 0.00015751364359672352 Test RE 0.009093409658141741\n",
      "133 Train Loss 0.0008491038 Test MSE 0.00015995859758568767 Test RE 0.009163712632814342\n",
      "134 Train Loss 0.0008358016 Test MSE 0.00016041255915391514 Test RE 0.009176706701610991\n",
      "135 Train Loss 0.0008160324 Test MSE 0.00015677142353971572 Test RE 0.009071959831555784\n",
      "136 Train Loss 0.0008051019 Test MSE 0.00016165417889013202 Test RE 0.00921215285778432\n",
      "137 Train Loss 0.00078901404 Test MSE 0.00015621468537178347 Test RE 0.009055837000393436\n",
      "138 Train Loss 0.00077821454 Test MSE 0.00015243468687252203 Test RE 0.008945601940859638\n",
      "139 Train Loss 0.0007710084 Test MSE 0.00015431298152051513 Test RE 0.009000546891954038\n",
      "140 Train Loss 0.000757211 Test MSE 0.00015178561097797967 Test RE 0.008926536172866597\n",
      "141 Train Loss 0.00074528693 Test MSE 0.0001505197285498362 Test RE 0.0088892348628783\n",
      "142 Train Loss 0.0007383029 Test MSE 0.00014820493480979092 Test RE 0.008820617710847474\n",
      "143 Train Loss 0.00073134236 Test MSE 0.00014446945098974153 Test RE 0.008708747098428442\n",
      "144 Train Loss 0.0007276538 Test MSE 0.00014519984273210577 Test RE 0.008730733676348527\n",
      "145 Train Loss 0.00072253495 Test MSE 0.00014604840903554745 Test RE 0.008756208269047433\n",
      "146 Train Loss 0.00071677536 Test MSE 0.00014466905847079157 Test RE 0.008714761280073346\n",
      "147 Train Loss 0.00070679776 Test MSE 0.0001389525126105825 Test RE 0.008540845579847366\n",
      "148 Train Loss 0.00069272786 Test MSE 0.0001356232661188979 Test RE 0.00843790763576231\n",
      "149 Train Loss 0.00067675405 Test MSE 0.00013903652966776732 Test RE 0.008543427282980505\n",
      "150 Train Loss 0.000664435 Test MSE 0.0001410707221398109 Test RE 0.008605698219801337\n",
      "151 Train Loss 0.0006542495 Test MSE 0.00013540367528494366 Test RE 0.008431073860670628\n",
      "152 Train Loss 0.0006459787 Test MSE 0.00013071031871707918 Test RE 0.008283666472499262\n",
      "153 Train Loss 0.00063799886 Test MSE 0.0001317893378453609 Test RE 0.008317787206180344\n",
      "154 Train Loss 0.00063207257 Test MSE 0.0001292829070050265 Test RE 0.00823831174668055\n",
      "155 Train Loss 0.0006264744 Test MSE 0.00012900903688343345 Test RE 0.008229581189620633\n",
      "156 Train Loss 0.00062171195 Test MSE 0.00012738745256036374 Test RE 0.008177696605369138\n",
      "157 Train Loss 0.0006178351 Test MSE 0.0001242521875297279 Test RE 0.008076434762140195\n",
      "158 Train Loss 0.00061398605 Test MSE 0.0001225555807980916 Test RE 0.008021105228655092\n",
      "159 Train Loss 0.00061018486 Test MSE 0.00012041231750524676 Test RE 0.007950658963737159\n",
      "160 Train Loss 0.00060075265 Test MSE 0.00011335084915326137 Test RE 0.007714007497166427\n",
      "161 Train Loss 0.0005889457 Test MSE 0.0001066008468548892 Test RE 0.007480799157108683\n",
      "162 Train Loss 0.00057627 Test MSE 0.00010193410833207372 Test RE 0.007315220674385914\n",
      "163 Train Loss 0.00057219376 Test MSE 0.00010138032473253255 Test RE 0.00729532269129325\n",
      "164 Train Loss 0.00056478556 Test MSE 0.00010198713068577207 Test RE 0.007317122980682119\n",
      "165 Train Loss 0.00055925915 Test MSE 9.937733402399899e-05 Test RE 0.007222895616109174\n",
      "166 Train Loss 0.00055455783 Test MSE 0.00010041517141124213 Test RE 0.007260513455673814\n",
      "167 Train Loss 0.0005504994 Test MSE 9.908395507372239e-05 Test RE 0.007212226121832764\n",
      "168 Train Loss 0.0005425518 Test MSE 9.93447161949816e-05 Test RE 0.007221710162144321\n",
      "169 Train Loss 0.0005371038 Test MSE 9.356524734033313e-05 Test RE 0.007008497982246436\n",
      "170 Train Loss 0.0005299745 Test MSE 9.438912492369288e-05 Test RE 0.0070392865993671215\n",
      "171 Train Loss 0.0005250904 Test MSE 9.220257767383006e-05 Test RE 0.006957275463366868\n",
      "172 Train Loss 0.00051894045 Test MSE 9.162745020974936e-05 Test RE 0.006935542993725798\n",
      "173 Train Loss 0.00051241944 Test MSE 9.35940318566854e-05 Test RE 0.007009575950387953\n",
      "174 Train Loss 0.0005080557 Test MSE 9.212638586794864e-05 Test RE 0.006954400289212645\n",
      "175 Train Loss 0.00050085183 Test MSE 8.819589918925587e-05 Test RE 0.006804431773127244\n",
      "176 Train Loss 0.0004957892 Test MSE 8.648753891686693e-05 Test RE 0.0067382083752907124\n",
      "177 Train Loss 0.00048923126 Test MSE 8.608476115575336e-05 Test RE 0.006722499940797476\n",
      "178 Train Loss 0.0004812655 Test MSE 8.491343040513973e-05 Test RE 0.00667660772751955\n",
      "179 Train Loss 0.00047501313 Test MSE 8.466472548664678e-05 Test RE 0.006666822921808211\n",
      "180 Train Loss 0.00046965375 Test MSE 8.66033915819632e-05 Test RE 0.006742719881575139\n",
      "181 Train Loss 0.00046554228 Test MSE 8.497919351765743e-05 Test RE 0.006679192651501857\n",
      "182 Train Loss 0.0004569446 Test MSE 8.232145640233392e-05 Test RE 0.006573916602264931\n",
      "183 Train Loss 0.0004519033 Test MSE 8.509614159901611e-05 Test RE 0.0066837870126319286\n",
      "184 Train Loss 0.00044856532 Test MSE 8.477682763552771e-05 Test RE 0.006671235136835578\n",
      "185 Train Loss 0.0004442482 Test MSE 8.378124156789656e-05 Test RE 0.006631947256332616\n",
      "186 Train Loss 0.00044338513 Test MSE 8.392857413343979e-05 Test RE 0.006637775963301944\n",
      "187 Train Loss 0.00044108674 Test MSE 8.229130516131873e-05 Test RE 0.00657271260330011\n",
      "188 Train Loss 0.00043764352 Test MSE 8.127965947590862e-05 Test RE 0.006532186945531569\n",
      "189 Train Loss 0.00043527738 Test MSE 7.971515137694813e-05 Test RE 0.006469014211474311\n",
      "190 Train Loss 0.00043385717 Test MSE 8.175967289391081e-05 Test RE 0.0065514471247419635\n",
      "191 Train Loss 0.00043160687 Test MSE 8.110359209111e-05 Test RE 0.006525108122904396\n",
      "192 Train Loss 0.00042850352 Test MSE 8.399485910755487e-05 Test RE 0.006640396631972391\n",
      "193 Train Loss 0.0004258719 Test MSE 8.553958142087735e-05 Test RE 0.006701179141675347\n",
      "194 Train Loss 0.0004224391 Test MSE 8.54535628132597e-05 Test RE 0.006697808941143479\n",
      "195 Train Loss 0.00041908046 Test MSE 8.69627730543236e-05 Test RE 0.00675669566148567\n",
      "196 Train Loss 0.00041516763 Test MSE 8.359954848599876e-05 Test RE 0.006624752131741613\n",
      "197 Train Loss 0.00040858437 Test MSE 7.646223672811514e-05 Test RE 0.006335649842362816\n",
      "198 Train Loss 0.00040421286 Test MSE 7.107438267189095e-05 Test RE 0.006108354250450504\n",
      "199 Train Loss 0.00040348872 Test MSE 7.044038607775426e-05 Test RE 0.006081049400062292\n",
      "200 Train Loss 0.000400837 Test MSE 6.953832923570303e-05 Test RE 0.006041987098580453\n",
      "201 Train Loss 0.00039698163 Test MSE 6.867367112128667e-05 Test RE 0.006004305758476503\n",
      "202 Train Loss 0.00039422378 Test MSE 6.771227672433003e-05 Test RE 0.005962129102725259\n",
      "203 Train Loss 0.00039135927 Test MSE 6.54416388022037e-05 Test RE 0.005861310801871873\n",
      "204 Train Loss 0.0003888528 Test MSE 6.323135097634704e-05 Test RE 0.0057614778700192226\n",
      "205 Train Loss 0.00038633545 Test MSE 6.227825889144718e-05 Test RE 0.005717891352264026\n",
      "206 Train Loss 0.000383831 Test MSE 6.246923270624147e-05 Test RE 0.00572665148546132\n",
      "207 Train Loss 0.00038101175 Test MSE 6.010174533217676e-05 Test RE 0.005617087764872967\n",
      "208 Train Loss 0.0003789041 Test MSE 5.972855457563901e-05 Test RE 0.005599621471460482\n",
      "209 Train Loss 0.00037511735 Test MSE 5.8623307974555855e-05 Test RE 0.005547570475498788\n",
      "210 Train Loss 0.0003714028 Test MSE 5.794957157591823e-05 Test RE 0.005515600247629825\n",
      "211 Train Loss 0.00036823537 Test MSE 5.67821357471056e-05 Test RE 0.0054597597113703634\n",
      "212 Train Loss 0.00036618524 Test MSE 5.631506223502258e-05 Test RE 0.005437258136660717\n",
      "213 Train Loss 0.0003660556 Test MSE 5.620670906189044e-05 Test RE 0.0054320248313247926\n",
      "214 Train Loss 0.00036605555 Test MSE 5.6206709065112286e-05 Test RE 0.005432024831480478\n",
      "215 Train Loss 0.0003660508 Test MSE 5.608080306112791e-05 Test RE 0.00542593740893047\n",
      "216 Train Loss 0.00036357497 Test MSE 5.5930641123066835e-05 Test RE 0.005418668295699966\n",
      "217 Train Loss 0.00036211684 Test MSE 5.562248720891236e-05 Test RE 0.005403720405619085\n",
      "218 Train Loss 0.00036014657 Test MSE 5.485069332272531e-05 Test RE 0.00536609958845437\n",
      "219 Train Loss 0.00035684038 Test MSE 5.4855683315372e-05 Test RE 0.005366343670952646\n",
      "220 Train Loss 0.0003552144 Test MSE 5.362986533250731e-05 Test RE 0.005306046123966886\n",
      "221 Train Loss 0.00035284465 Test MSE 5.210846636201279e-05 Test RE 0.005230242354803639\n",
      "222 Train Loss 0.00035095 Test MSE 5.0667907227556915e-05 Test RE 0.005157439605272148\n",
      "223 Train Loss 0.000347483 Test MSE 4.845467901140872e-05 Test RE 0.005043540680206771\n",
      "224 Train Loss 0.00034485242 Test MSE 4.737823075041597e-05 Test RE 0.004987203469285364\n",
      "225 Train Loss 0.00034087553 Test MSE 4.677602305024475e-05 Test RE 0.004955406829853474\n",
      "226 Train Loss 0.0003390173 Test MSE 4.634211790128102e-05 Test RE 0.0049323695337821095\n",
      "227 Train Loss 0.00033606417 Test MSE 4.422268881052407e-05 Test RE 0.004818260095908115\n",
      "228 Train Loss 0.00033471797 Test MSE 4.445400485916661e-05 Test RE 0.004830845120202778\n",
      "229 Train Loss 0.00033470828 Test MSE 4.428634799103093e-05 Test RE 0.004821726825233375\n",
      "230 Train Loss 0.0003334155 Test MSE 4.389036277635592e-05 Test RE 0.004800121749751522\n",
      "231 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "232 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "233 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "234 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "235 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "236 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "237 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "238 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "239 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "240 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "241 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "242 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "243 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "244 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "245 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "246 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "247 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "248 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "249 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "250 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "251 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "252 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "253 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "254 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "255 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "256 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "257 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "258 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "259 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "260 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "261 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "262 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "263 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "264 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "265 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "266 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "267 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "268 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "269 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "270 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "271 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "272 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "273 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "274 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "275 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "276 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "277 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "278 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "279 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "280 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "281 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "282 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "283 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "284 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "285 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "286 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "287 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "288 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "289 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "290 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "291 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "292 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "293 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "294 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "295 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "296 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "297 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "298 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "299 Train Loss 0.00033292905 Test MSE 4.3835660251178644e-05 Test RE 0.0047971295137433844\n",
      "Training time: 153.20\n",
      "KG_stan_medium\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 22578.352 Test MSE 5.146391409740791 Test RE 1.6436868261873703\n",
      "1 Train Loss 1851.6279 Test MSE 5.34126220655111 Test RE 1.6745172154602666\n",
      "2 Train Loss 185.4617 Test MSE 6.5411375456034175 Test RE 1.8530805955550744\n",
      "3 Train Loss 108.56641 Test MSE 5.955417179291094 Test RE 1.768168960114949\n",
      "4 Train Loss 47.658245 Test MSE 3.0755428490786687 Test RE 1.2706576593976162\n",
      "5 Train Loss 16.199175 Test MSE 0.9009157860779211 Test RE 0.6877170095754338\n",
      "6 Train Loss 7.276884 Test MSE 0.2859209714388352 Test RE 0.38742770416440014\n",
      "7 Train Loss 3.7223525 Test MSE 0.176459478545061 Test RE 0.3043618136968125\n",
      "8 Train Loss 2.152457 Test MSE 0.09652490159085028 Test RE 0.22510614540247298\n",
      "9 Train Loss 1.2610898 Test MSE 0.056875085029211035 Test RE 0.17279401548076925\n",
      "10 Train Loss 0.8450267 Test MSE 0.04595606263763496 Test RE 0.1553241815997495\n",
      "11 Train Loss 0.59791297 Test MSE 0.03883769002109442 Test RE 0.14278887214389677\n",
      "12 Train Loss 0.47448796 Test MSE 0.03565536069966342 Test RE 0.13681385644993446\n",
      "13 Train Loss 0.36391178 Test MSE 0.025618920594033076 Test RE 0.11597064736060349\n",
      "14 Train Loss 0.31340414 Test MSE 0.02143248160848089 Test RE 0.10607276689349389\n",
      "15 Train Loss 0.2669365 Test MSE 0.019073523348344845 Test RE 0.10006521441783552\n",
      "16 Train Loss 0.21990612 Test MSE 0.015310634572139041 Test RE 0.08965288367913654\n",
      "17 Train Loss 0.17867596 Test MSE 0.013346294582320496 Test RE 0.08370434857631527\n",
      "18 Train Loss 0.14933655 Test MSE 0.011711475728542628 Test RE 0.07841036563056376\n",
      "19 Train Loss 0.13070136 Test MSE 0.013337016540324842 Test RE 0.08367524883352499\n",
      "20 Train Loss 0.11520798 Test MSE 0.01141984673324324 Test RE 0.07742795790421983\n",
      "21 Train Loss 0.10430507 Test MSE 0.009981135024822963 Test RE 0.07238650911881477\n",
      "22 Train Loss 0.09564313 Test MSE 0.009744398377635922 Test RE 0.07152291116598992\n",
      "23 Train Loss 0.08488561 Test MSE 0.008191201667623157 Test RE 0.06557547979246371\n",
      "24 Train Loss 0.078006946 Test MSE 0.00664391648823747 Test RE 0.05905813797156731\n",
      "25 Train Loss 0.07010965 Test MSE 0.005166115345799615 Test RE 0.05207745075891148\n",
      "26 Train Loss 0.06449646 Test MSE 0.003696257814515202 Test RE 0.044050292395494704\n",
      "27 Train Loss 0.05921535 Test MSE 0.0029303906806785814 Test RE 0.03922206272624545\n",
      "28 Train Loss 0.051572315 Test MSE 0.0020374394729707787 Test RE 0.03270468914585466\n",
      "29 Train Loss 0.04820505 Test MSE 0.0020347140684204338 Test RE 0.03268280792254239\n",
      "30 Train Loss 0.04250582 Test MSE 0.0014627358260806687 Test RE 0.027710899092686224\n",
      "31 Train Loss 0.035809528 Test MSE 0.0014916421603750377 Test RE 0.027983368569920074\n",
      "32 Train Loss 0.03437982 Test MSE 0.0015344433308803617 Test RE 0.028382006464440532\n",
      "33 Train Loss 0.031451304 Test MSE 0.0017526853652673302 Test RE 0.030333299125320415\n",
      "34 Train Loss 0.029688189 Test MSE 0.0015981335717518625 Test RE 0.028965044831550036\n",
      "35 Train Loss 0.026737185 Test MSE 0.0013323619378151179 Test RE 0.026447143787883955\n",
      "36 Train Loss 0.025916148 Test MSE 0.0013397672197291858 Test RE 0.02652053870092065\n",
      "37 Train Loss 0.024256565 Test MSE 0.001569786353757993 Test RE 0.02870700879501578\n",
      "38 Train Loss 0.02335107 Test MSE 0.001837219495435521 Test RE 0.0310561910887103\n",
      "39 Train Loss 0.021076774 Test MSE 0.001677204137266711 Test RE 0.02967294353548508\n",
      "40 Train Loss 0.020115385 Test MSE 0.0018938537734734169 Test RE 0.0315312283305134\n",
      "41 Train Loss 0.018961404 Test MSE 0.001928548743509541 Test RE 0.03181873998251544\n",
      "42 Train Loss 0.01820232 Test MSE 0.0017157162647788273 Test RE 0.03001168654347157\n",
      "43 Train Loss 0.016829917 Test MSE 0.0017939151147143997 Test RE 0.030688001885545803\n",
      "44 Train Loss 0.016157594 Test MSE 0.0017986000329976645 Test RE 0.030728047547620187\n",
      "45 Train Loss 0.014969104 Test MSE 0.0015718426743483614 Test RE 0.028725804822299188\n",
      "46 Train Loss 0.014520979 Test MSE 0.001579574211882906 Test RE 0.02879636601876915\n",
      "47 Train Loss 0.01363149 Test MSE 0.0010344267392390885 Test RE 0.023303305933423557\n",
      "48 Train Loss 0.012617062 Test MSE 0.0007732554438442615 Test RE 0.02014787096240999\n",
      "49 Train Loss 0.012361506 Test MSE 0.0006967706900786817 Test RE 0.019125491486511232\n",
      "50 Train Loss 0.011649389 Test MSE 0.0005978258284305442 Test RE 0.0177155648791286\n",
      "51 Train Loss 0.01091703 Test MSE 0.0005369327945280104 Test RE 0.016789108387733682\n",
      "52 Train Loss 0.0104724 Test MSE 0.0005140459216234977 Test RE 0.016427392224166643\n",
      "53 Train Loss 0.009968092 Test MSE 0.00036877111725115106 Test RE 0.013913811557946233\n",
      "54 Train Loss 0.009268038 Test MSE 0.0001833820778935366 Test RE 0.009811741829296517\n",
      "55 Train Loss 0.009063712 Test MSE 0.00011532145552735853 Test RE 0.0077807726427346685\n",
      "56 Train Loss 0.008656678 Test MSE 9.993583745893515e-05 Test RE 0.007243163618399597\n",
      "57 Train Loss 0.008196544 Test MSE 8.136642969789538e-05 Test RE 0.006535672738433539\n",
      "58 Train Loss 0.0077996436 Test MSE 5.5091615668028886e-05 Test RE 0.005377871516148222\n",
      "59 Train Loss 0.0074820137 Test MSE 4.214962525585944e-05 Test RE 0.004703969818031212\n",
      "60 Train Loss 0.007147228 Test MSE 6.664467194624499e-05 Test RE 0.005914940562762846\n",
      "61 Train Loss 0.0069505433 Test MSE 6.171788418393586e-05 Test RE 0.005692108662939608\n",
      "62 Train Loss 0.0067281397 Test MSE 6.148911284648981e-05 Test RE 0.005681549322745981\n",
      "63 Train Loss 0.006369971 Test MSE 6.415700784991603e-05 Test RE 0.005803496384601652\n",
      "64 Train Loss 0.006116393 Test MSE 7.564818871486771e-05 Test RE 0.0063018336461437546\n",
      "65 Train Loss 0.005946903 Test MSE 8.368350107712972e-05 Test RE 0.006628077661357167\n",
      "66 Train Loss 0.0058154673 Test MSE 7.583225517749758e-05 Test RE 0.006309495769358437\n",
      "67 Train Loss 0.00562717 Test MSE 6.707815073788051e-05 Test RE 0.005934145740319275\n",
      "68 Train Loss 0.0054155625 Test MSE 5.6798630527762876e-05 Test RE 0.005460552663223856\n",
      "69 Train Loss 0.0053298464 Test MSE 6.454610934639885e-05 Test RE 0.005821068398345321\n",
      "70 Train Loss 0.0052013216 Test MSE 8.24904902866357e-05 Test RE 0.006580662381959507\n",
      "71 Train Loss 0.005004948 Test MSE 8.078588546795268e-05 Test RE 0.006512315198408266\n",
      "72 Train Loss 0.004839472 Test MSE 6.485664769462282e-05 Test RE 0.005835054492782065\n",
      "73 Train Loss 0.004768656 Test MSE 6.660299310591747e-05 Test RE 0.005913090704311542\n",
      "74 Train Loss 0.0047015934 Test MSE 6.52429877401577e-05 Test RE 0.005852407903087988\n",
      "75 Train Loss 0.0045250296 Test MSE 4.369122962688569e-05 Test RE 0.004789220153479513\n",
      "76 Train Loss 0.0043650055 Test MSE 5.2545140835725175e-05 Test RE 0.005252111626461799\n",
      "77 Train Loss 0.004259378 Test MSE 6.03021665286782e-05 Test RE 0.005626445616870508\n",
      "78 Train Loss 0.0041953786 Test MSE 5.2947735707558615e-05 Test RE 0.005272193772999798\n",
      "79 Train Loss 0.0041473564 Test MSE 4.962310501889176e-05 Test RE 0.005103987891224378\n",
      "80 Train Loss 0.004049171 Test MSE 5.355570804522108e-05 Test RE 0.005302376358050622\n",
      "81 Train Loss 0.0037256095 Test MSE 5.4268470452857615e-05 Test RE 0.00533754387854574\n",
      "82 Train Loss 0.0035347755 Test MSE 5.43767615485399e-05 Test RE 0.0053428666783939625\n",
      "83 Train Loss 0.003471212 Test MSE 5.5616345098886056e-05 Test RE 0.005403422044621075\n",
      "84 Train Loss 0.0034285388 Test MSE 5.832455652858471e-05 Test RE 0.005533416876332602\n",
      "85 Train Loss 0.003382683 Test MSE 5.86213147483583e-05 Test RE 0.00554747616440326\n",
      "86 Train Loss 0.0032524709 Test MSE 6.796752302107631e-05 Test RE 0.005973355869864788\n",
      "87 Train Loss 0.0031518592 Test MSE 6.880857330011015e-05 Test RE 0.006010200277578598\n",
      "88 Train Loss 0.003076064 Test MSE 7.946201652688649e-05 Test RE 0.006458734892074919\n",
      "89 Train Loss 0.0030139834 Test MSE 7.615501058130533e-05 Test RE 0.00632290867396388\n",
      "90 Train Loss 0.0029560276 Test MSE 7.463951987535945e-05 Test RE 0.006259679335821615\n",
      "91 Train Loss 0.0028779984 Test MSE 7.297881992373671e-05 Test RE 0.006189649911629552\n",
      "92 Train Loss 0.0028181514 Test MSE 6.9294924524325e-05 Test RE 0.006031403458413098\n",
      "93 Train Loss 0.0027301854 Test MSE 7.158217009537509e-05 Test RE 0.006130135833249457\n",
      "94 Train Loss 0.0026608133 Test MSE 8.431909476185955e-05 Test RE 0.006653200865318076\n",
      "95 Train Loss 0.0025957376 Test MSE 8.622307908275887e-05 Test RE 0.0067278985098011244\n",
      "96 Train Loss 0.0025530679 Test MSE 9.055167744434396e-05 Test RE 0.00689470862941883\n",
      "97 Train Loss 0.0025075022 Test MSE 9.240345456311877e-05 Test RE 0.006964850064430165\n",
      "98 Train Loss 0.0024692211 Test MSE 9.47218047469631e-05 Test RE 0.007051680870291887\n",
      "99 Train Loss 0.0024189688 Test MSE 7.830114919464674e-05 Test RE 0.0064113832119711165\n",
      "100 Train Loss 0.0023661335 Test MSE 7.565318809553543e-05 Test RE 0.00630204187812743\n",
      "101 Train Loss 0.0023446286 Test MSE 6.711709397764797e-05 Test RE 0.005935868069618484\n",
      "102 Train Loss 0.0023068218 Test MSE 6.68591592006304e-05 Test RE 0.005924451152232006\n",
      "103 Train Loss 0.0022670217 Test MSE 6.184668440755635e-05 Test RE 0.005698045052152153\n",
      "104 Train Loss 0.0022111447 Test MSE 6.331758222807214e-05 Test RE 0.005765405116336566\n",
      "105 Train Loss 0.0021367378 Test MSE 6.248910577167696e-05 Test RE 0.0057275623103990115\n",
      "106 Train Loss 0.0020621887 Test MSE 5.8827655544492636e-05 Test RE 0.005557230851263557\n",
      "107 Train Loss 0.0020048444 Test MSE 6.090052916886456e-05 Test RE 0.005654291585088851\n",
      "108 Train Loss 0.001971606 Test MSE 6.896991412467607e-05 Test RE 0.006017242444420843\n",
      "109 Train Loss 0.0019221238 Test MSE 6.02604464205415e-05 Test RE 0.005624498949381666\n",
      "110 Train Loss 0.0018817271 Test MSE 5.7630400060664076e-05 Test RE 0.005500390012860213\n",
      "111 Train Loss 0.0018488755 Test MSE 5.8655042972191906e-05 Test RE 0.005549071826433651\n",
      "112 Train Loss 0.001807959 Test MSE 5.475163663621415e-05 Test RE 0.005361251990233532\n",
      "113 Train Loss 0.0017645423 Test MSE 5.401860877007329e-05 Test RE 0.005325242202119721\n",
      "114 Train Loss 0.0017229854 Test MSE 5.2514094366796745e-05 Test RE 0.005250559783503465\n",
      "115 Train Loss 0.0016915266 Test MSE 5.134245943824585e-05 Test RE 0.005191657119715401\n",
      "116 Train Loss 0.0016697427 Test MSE 5.206215367796822e-05 Test RE 0.0052279175847258835\n",
      "117 Train Loss 0.0016471337 Test MSE 5.293611444760023e-05 Test RE 0.005271615156219679\n",
      "118 Train Loss 0.0016244788 Test MSE 5.252464938300064e-05 Test RE 0.005251087422414351\n",
      "119 Train Loss 0.0016008323 Test MSE 5.664389433842417e-05 Test RE 0.005453109513996948\n",
      "120 Train Loss 0.0015690797 Test MSE 5.693742790110367e-05 Test RE 0.005467220499251718\n",
      "121 Train Loss 0.0015314063 Test MSE 5.033489462945547e-05 Test RE 0.005140463142215284\n",
      "122 Train Loss 0.0014845078 Test MSE 4.26342106847271e-05 Test RE 0.004730932821241889\n",
      "123 Train Loss 0.0014482284 Test MSE 4.0826273492231884e-05 Test RE 0.004629536771082641\n",
      "124 Train Loss 0.0014177063 Test MSE 4.0572569222368246e-05 Test RE 0.004615129827400046\n",
      "125 Train Loss 0.0013931016 Test MSE 3.986809645816064e-05 Test RE 0.004574887488604848\n",
      "126 Train Loss 0.0013732131 Test MSE 4.05039509766409e-05 Test RE 0.004611225513119291\n",
      "127 Train Loss 0.0013498565 Test MSE 4.524000156244058e-05 Test RE 0.0048733653743332425\n",
      "128 Train Loss 0.0013364764 Test MSE 4.539945655444809e-05 Test RE 0.004881946263799871\n",
      "129 Train Loss 0.0013227793 Test MSE 4.93924831666699e-05 Test RE 0.0050921137657368104\n",
      "130 Train Loss 0.001303383 Test MSE 5.085441660565226e-05 Test RE 0.00516692319487647\n",
      "131 Train Loss 0.001287039 Test MSE 5.063829971046067e-05 Test RE 0.0051559325241297815\n",
      "132 Train Loss 0.001262609 Test MSE 4.616055924655708e-05 Test RE 0.004922698059437608\n",
      "133 Train Loss 0.0012262632 Test MSE 4.740708219416713e-05 Test RE 0.004988721741699181\n",
      "134 Train Loss 0.0011840664 Test MSE 4.624228742942462e-05 Test RE 0.004927053999345611\n",
      "135 Train Loss 0.0011447016 Test MSE 4.559094831081279e-05 Test RE 0.004892231285066983\n",
      "136 Train Loss 0.0010996056 Test MSE 5.359905203536825e-05 Test RE 0.005304521597790555\n",
      "137 Train Loss 0.0010570203 Test MSE 4.7909243790962676e-05 Test RE 0.005015073768667934\n",
      "138 Train Loss 0.0010343795 Test MSE 4.686694908125029e-05 Test RE 0.004960220799643542\n",
      "139 Train Loss 0.0010220559 Test MSE 4.848161302560513e-05 Test RE 0.005044942236536368\n",
      "140 Train Loss 0.0010078686 Test MSE 5.04159419241896e-05 Test RE 0.005144599964818269\n",
      "141 Train Loss 0.0009880535 Test MSE 5.152844150506185e-05 Test RE 0.005201051705690939\n",
      "142 Train Loss 0.0009753726 Test MSE 5.4327879978945665e-05 Test RE 0.005340464674100189\n",
      "143 Train Loss 0.0009591434 Test MSE 4.421266533047159e-05 Test RE 0.004817714013430584\n",
      "144 Train Loss 0.0009457574 Test MSE 4.006713934270113e-05 Test RE 0.004586293414170488\n",
      "145 Train Loss 0.0009321286 Test MSE 3.751919138967522e-05 Test RE 0.004438072602806573\n",
      "146 Train Loss 0.0009142338 Test MSE 4.063730102688409e-05 Test RE 0.004618809981547147\n",
      "147 Train Loss 0.0009020765 Test MSE 3.9885937505213315e-05 Test RE 0.004575911009425691\n",
      "148 Train Loss 0.0008918756 Test MSE 4.06290419229125e-05 Test RE 0.004618340595424653\n",
      "149 Train Loss 0.0008785592 Test MSE 3.9216645049598214e-05 Test RE 0.0045373563248375225\n",
      "150 Train Loss 0.00086662837 Test MSE 3.7656922341299765e-05 Test RE 0.00444621110462335\n",
      "151 Train Loss 0.0008529672 Test MSE 3.626702376929936e-05 Test RE 0.0043633859222412695\n",
      "152 Train Loss 0.0008393575 Test MSE 3.888632269015636e-05 Test RE 0.0045182068069466\n",
      "153 Train Loss 0.0008320089 Test MSE 4.000479358804884e-05 Test RE 0.004582723815159323\n",
      "154 Train Loss 0.0008130184 Test MSE 3.932200498992503e-05 Test RE 0.004543447296337649\n",
      "155 Train Loss 0.00080488244 Test MSE 3.864260811923185e-05 Test RE 0.004504025939290223\n",
      "156 Train Loss 0.0007941513 Test MSE 3.837048785860045e-05 Test RE 0.004488139303672285\n",
      "157 Train Loss 0.0007842104 Test MSE 4.0530064808032625e-05 Test RE 0.004612711755325833\n",
      "158 Train Loss 0.00077444955 Test MSE 4.237037806580438e-05 Test RE 0.004716271925817032\n",
      "159 Train Loss 0.0007668694 Test MSE 4.276118837733695e-05 Test RE 0.004737972664417901\n",
      "160 Train Loss 0.0007551152 Test MSE 4.412644563288593e-05 Test RE 0.004813014177418892\n",
      "161 Train Loss 0.0007423867 Test MSE 4.2599275765448356e-05 Test RE 0.004728994136035644\n",
      "162 Train Loss 0.00073261186 Test MSE 4.4393508307433654e-05 Test RE 0.004827556901633279\n",
      "163 Train Loss 0.0007212325 Test MSE 4.391079487853779e-05 Test RE 0.004801238910333383\n",
      "164 Train Loss 0.0007109744 Test MSE 4.436229609972164e-05 Test RE 0.00482585952279762\n",
      "165 Train Loss 0.00070137257 Test MSE 4.392914963022243e-05 Test RE 0.004802242266581046\n",
      "166 Train Loss 0.0006957596 Test MSE 4.573570303635157e-05 Test RE 0.004899991733001746\n",
      "167 Train Loss 0.0006846509 Test MSE 4.4077259147070866e-05 Test RE 0.004810330964920525\n",
      "168 Train Loss 0.0006789791 Test MSE 4.4078273697039364e-05 Test RE 0.00481038632558882\n",
      "169 Train Loss 0.00067383994 Test MSE 4.754684025899344e-05 Test RE 0.004996069810450483\n",
      "170 Train Loss 0.00066923717 Test MSE 4.779874464622414e-05 Test RE 0.005009286980769772\n",
      "171 Train Loss 0.0006617512 Test MSE 4.452147840909561e-05 Test RE 0.004834509926990913\n",
      "172 Train Loss 0.000653962 Test MSE 4.4069522884913666e-05 Test RE 0.004809908801483156\n",
      "173 Train Loss 0.0006461928 Test MSE 4.0649432891181014e-05 Test RE 0.0046194993801164505\n",
      "174 Train Loss 0.0006414225 Test MSE 4.2382112704539307e-05 Test RE 0.0047169249754045765\n",
      "175 Train Loss 0.00063447957 Test MSE 4.22358345234951e-05 Test RE 0.004708777911167314\n",
      "176 Train Loss 0.0006284011 Test MSE 4.106508263227282e-05 Test RE 0.004643057031122702\n",
      "177 Train Loss 0.0006244804 Test MSE 3.9349425544819684e-05 Test RE 0.004545031169470216\n",
      "178 Train Loss 0.000620522 Test MSE 4.063345120962633e-05 Test RE 0.004618591192465604\n",
      "179 Train Loss 0.0006145719 Test MSE 4.0629883848415294e-05 Test RE 0.004618388446400216\n",
      "180 Train Loss 0.0006110585 Test MSE 4.199595596931289e-05 Test RE 0.004695387111389833\n",
      "181 Train Loss 0.0006059554 Test MSE 4.296613991721648e-05 Test RE 0.004749313486084267\n",
      "182 Train Loss 0.00059874286 Test MSE 3.9087288740088825e-05 Test RE 0.004529866896931905\n",
      "183 Train Loss 0.0005912009 Test MSE 4.033545337882275e-05 Test RE 0.004601624101978101\n",
      "184 Train Loss 0.0005866091 Test MSE 4.204705972428115e-05 Test RE 0.004698243088274992\n",
      "185 Train Loss 0.0005788594 Test MSE 4.072685379826997e-05 Test RE 0.004623896436554886\n",
      "186 Train Loss 0.0005734057 Test MSE 3.774157714682918e-05 Test RE 0.004451205960979184\n",
      "187 Train Loss 0.00056850415 Test MSE 4.1910980272922714e-05 Test RE 0.00469063432247926\n",
      "188 Train Loss 0.0005642256 Test MSE 4.259687607022481e-05 Test RE 0.004728860937709424\n",
      "189 Train Loss 0.00055958296 Test MSE 4.391150198926601e-05 Test RE 0.004801277568183737\n",
      "190 Train Loss 0.00055338256 Test MSE 4.5029652503932334e-05 Test RE 0.004862022512342263\n",
      "191 Train Loss 0.0005459698 Test MSE 4.3427400046886984e-05 Test RE 0.004774738400476779\n",
      "192 Train Loss 0.0005378059 Test MSE 4.128222168464503e-05 Test RE 0.004655316348599285\n",
      "193 Train Loss 0.0005294357 Test MSE 4.505707113925991e-05 Test RE 0.0048635025341479746\n",
      "194 Train Loss 0.0005188001 Test MSE 4.656057858064423e-05 Test RE 0.004943981669154757\n",
      "195 Train Loss 0.000509648 Test MSE 4.4128863313349094e-05 Test RE 0.004813146027727646\n",
      "196 Train Loss 0.0005049416 Test MSE 4.1328433729815025e-05 Test RE 0.004657921241319808\n",
      "197 Train Loss 0.0004985208 Test MSE 3.794667392203605e-05 Test RE 0.0044632840343995775\n",
      "198 Train Loss 0.0004943024 Test MSE 3.6430238444084724e-05 Test RE 0.004373193304876985\n",
      "199 Train Loss 0.00049053505 Test MSE 4.0984299334534935e-05 Test RE 0.004638487868206389\n",
      "200 Train Loss 0.00048831134 Test MSE 4.167691440675222e-05 Test RE 0.004677517776462518\n",
      "201 Train Loss 0.0004845655 Test MSE 4.274911322818884e-05 Test RE 0.004737303649263413\n",
      "202 Train Loss 0.00047977336 Test MSE 4.401587045469524e-05 Test RE 0.004806979998627427\n",
      "203 Train Loss 0.00047690715 Test MSE 4.2967492253736956e-05 Test RE 0.004749388226560722\n",
      "204 Train Loss 0.00047260968 Test MSE 4.1791127469804684e-05 Test RE 0.004683922618714488\n",
      "205 Train Loss 0.00046633088 Test MSE 3.905910997084949e-05 Test RE 0.004528233768976435\n",
      "206 Train Loss 0.00046073087 Test MSE 3.707025415854353e-05 Test RE 0.004411440738420439\n",
      "207 Train Loss 0.0004573512 Test MSE 3.705488484092774e-05 Test RE 0.004410526152529402\n",
      "208 Train Loss 0.00045171528 Test MSE 3.612018104661046e-05 Test RE 0.0043545434354830105\n",
      "209 Train Loss 0.00044876806 Test MSE 3.541732365087304e-05 Test RE 0.004311968084620778\n",
      "210 Train Loss 0.00044610468 Test MSE 3.356198255421743e-05 Test RE 0.004197507408242455\n",
      "211 Train Loss 0.00044308088 Test MSE 3.4241405413618e-05 Test RE 0.004239781333791569\n",
      "212 Train Loss 0.00043880864 Test MSE 3.340812148867426e-05 Test RE 0.004187874859721895\n",
      "213 Train Loss 0.00043582922 Test MSE 3.167267078290734e-05 Test RE 0.004077650610554886\n",
      "214 Train Loss 0.00043251348 Test MSE 3.0838591476091424e-05 Test RE 0.004023601251571009\n",
      "215 Train Loss 0.00042840955 Test MSE 2.812289726678091e-05 Test RE 0.0038423568618963957\n",
      "216 Train Loss 0.00042485294 Test MSE 2.7033872904165996e-05 Test RE 0.003767227099118428\n",
      "217 Train Loss 0.00042107233 Test MSE 2.6523492895134528e-05 Test RE 0.003731496388708309\n",
      "218 Train Loss 0.0004179669 Test MSE 2.614403874490216e-05 Test RE 0.003704708202285283\n",
      "219 Train Loss 0.00041339107 Test MSE 2.5620821807642528e-05 Test RE 0.003667449949392374\n",
      "220 Train Loss 0.0004115494 Test MSE 2.5660404560041325e-05 Test RE 0.0036702818596761324\n",
      "221 Train Loss 0.00040948353 Test MSE 2.5719231818126726e-05 Test RE 0.0036744865676101497\n",
      "222 Train Loss 0.00040797854 Test MSE 2.5690094161787362e-05 Test RE 0.0036724045406492174\n",
      "223 Train Loss 0.00040668118 Test MSE 2.6166487040447367e-05 Test RE 0.003706298364789547\n",
      "224 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "225 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "226 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "227 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "228 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "229 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "230 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "231 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "232 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "233 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "234 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "235 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "236 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "237 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "238 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "239 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "240 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "241 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "242 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "243 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "244 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "245 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "246 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "247 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "248 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "249 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "250 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "251 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "252 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "253 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "254 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "255 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "256 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "257 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "258 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "259 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "260 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "261 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "262 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "263 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "264 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "265 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "266 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "267 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "268 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "269 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "270 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "271 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "272 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "273 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "274 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "275 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "276 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "277 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "278 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "279 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "280 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "281 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "282 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "283 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "284 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "285 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "286 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "287 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "288 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "289 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "290 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "291 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "292 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "293 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "294 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "295 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "296 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "297 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "298 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "299 Train Loss 0.00040637178 Test MSE 2.6163157724295836e-05 Test RE 0.003706062570211563\n",
      "Training time: 153.91\n",
      "KG_stan_medium\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 19805.82 Test MSE 8.482474984442662 Test RE 2.110225959990086\n",
      "1 Train Loss 2069.7852 Test MSE 11.040622482039662 Test RE 2.4074897550526626\n",
      "2 Train Loss 278.55258 Test MSE 2.7888089497386415 Test RE 1.2099768170658243\n",
      "3 Train Loss 77.74011 Test MSE 1.2437065111013297 Test RE 0.8080283931555116\n",
      "4 Train Loss 31.031574 Test MSE 0.9310604344750071 Test RE 0.6991278511690897\n",
      "5 Train Loss 12.971986 Test MSE 0.8707005846690177 Test RE 0.6760862222759678\n",
      "6 Train Loss 7.0011315 Test MSE 0.6233448875314515 Test RE 0.5720472057839895\n",
      "7 Train Loss 3.7567816 Test MSE 0.30374285087579617 Test RE 0.39931966681001757\n",
      "8 Train Loss 2.1940339 Test MSE 0.22032452524291954 Test RE 0.3400940932176388\n",
      "9 Train Loss 1.4035653 Test MSE 0.25404274369803215 Test RE 0.3651918400034303\n",
      "10 Train Loss 0.9453425 Test MSE 0.26612229707921065 Test RE 0.3737733210739481\n",
      "11 Train Loss 0.6731225 Test MSE 0.2882154428361808 Test RE 0.38897912149558755\n",
      "12 Train Loss 0.56710017 Test MSE 0.23924459721494798 Test RE 0.35439593938338204\n",
      "13 Train Loss 0.44334877 Test MSE 0.2009458090550875 Test RE 0.32479336154966154\n",
      "14 Train Loss 0.386017 Test MSE 0.20095661181495572 Test RE 0.324802091807718\n",
      "15 Train Loss 0.343275 Test MSE 0.1955047614471722 Test RE 0.3203659397583404\n",
      "16 Train Loss 0.2788858 Test MSE 0.1651730219947297 Test RE 0.29446740219060097\n",
      "17 Train Loss 0.25182217 Test MSE 0.14318681264790203 Test RE 0.27416952430400304\n",
      "18 Train Loss 0.21091394 Test MSE 0.09482268107333572 Test RE 0.22311243857094606\n",
      "19 Train Loss 0.1847844 Test MSE 0.09039373905130985 Test RE 0.21783960614227943\n",
      "20 Train Loss 0.14717284 Test MSE 0.053106536740788385 Test RE 0.1669712344133748\n",
      "21 Train Loss 0.115565255 Test MSE 0.03355846073880041 Test RE 0.13272987452414278\n",
      "22 Train Loss 0.09475192 Test MSE 0.026798065583925217 Test RE 0.1186094768781284\n",
      "23 Train Loss 0.084415264 Test MSE 0.018814558836434226 Test RE 0.0993835915570079\n",
      "24 Train Loss 0.07703682 Test MSE 0.019563101465513672 Test RE 0.10134131173093427\n",
      "25 Train Loss 0.06616127 Test MSE 0.012292580904206204 Test RE 0.08033211573868702\n",
      "26 Train Loss 0.058936693 Test MSE 0.01248755501297025 Test RE 0.08096668807063263\n",
      "27 Train Loss 0.051309105 Test MSE 0.00841266940528812 Test RE 0.06645605838185387\n",
      "28 Train Loss 0.04904254 Test MSE 0.006259896510721049 Test RE 0.05732594786628445\n",
      "29 Train Loss 0.043752793 Test MSE 0.0060657958019289205 Test RE 0.056430196263832805\n",
      "30 Train Loss 0.039903086 Test MSE 0.0036966283159266585 Test RE 0.04405250007247006\n",
      "31 Train Loss 0.035406798 Test MSE 0.0019018609233021047 Test RE 0.031597814508255426\n",
      "32 Train Loss 0.034304366 Test MSE 0.0013301891070280339 Test RE 0.026425569839223804\n",
      "33 Train Loss 0.031168709 Test MSE 0.0010154644468997305 Test RE 0.02308872914101691\n",
      "34 Train Loss 0.029776841 Test MSE 0.0008761513592865778 Test RE 0.021446540016961124\n",
      "35 Train Loss 0.028737057 Test MSE 0.0007994595187686241 Test RE 0.020486412190444152\n",
      "36 Train Loss 0.026462464 Test MSE 0.0008339407928149871 Test RE 0.020923545451896303\n",
      "37 Train Loss 0.025572186 Test MSE 0.0007772355605877666 Test RE 0.020199657182523284\n",
      "38 Train Loss 0.023365276 Test MSE 0.0007695055475352978 Test RE 0.020098958117332588\n",
      "39 Train Loss 0.021749511 Test MSE 0.0007408175022217622 Test RE 0.019720743515337848\n",
      "40 Train Loss 0.020934675 Test MSE 0.0009150788946168694 Test RE 0.021917798860548506\n",
      "41 Train Loss 0.018255288 Test MSE 0.0009358799189787211 Test RE 0.022165510190581505\n",
      "42 Train Loss 0.017401325 Test MSE 0.0009116765701246271 Test RE 0.02187701499540857\n",
      "43 Train Loss 0.016944721 Test MSE 0.001080383245174062 Test RE 0.023815329129252525\n",
      "44 Train Loss 0.016410606 Test MSE 0.001368346738095402 Test RE 0.026801910232082567\n",
      "45 Train Loss 0.015812892 Test MSE 0.001030670759943232 Test RE 0.0232609605803205\n",
      "46 Train Loss 0.015444263 Test MSE 0.0009376947100947154 Test RE 0.02218699066489926\n",
      "47 Train Loss 0.015005017 Test MSE 0.0009540946073251673 Test RE 0.022380170366922563\n",
      "48 Train Loss 0.014214483 Test MSE 0.0008128236262385447 Test RE 0.02065693233898144\n",
      "49 Train Loss 0.013996406 Test MSE 0.0008329599392182986 Test RE 0.02091123704035217\n",
      "50 Train Loss 0.013276946 Test MSE 0.0010118698416570334 Test RE 0.023047827440826545\n",
      "51 Train Loss 0.011901279 Test MSE 0.000811911878570193 Test RE 0.020645343604494423\n",
      "52 Train Loss 0.011117932 Test MSE 0.0007909857211678565 Test RE 0.02037755103562694\n",
      "53 Train Loss 0.010976414 Test MSE 0.0007552500164336183 Test RE 0.019911915442833484\n",
      "54 Train Loss 0.010699924 Test MSE 0.0007710464790737721 Test RE 0.02011907209128293\n",
      "55 Train Loss 0.010026604 Test MSE 0.0006721152643590043 Test RE 0.018784063469996677\n",
      "56 Train Loss 0.009861872 Test MSE 0.0006494994272334499 Test RE 0.018465329165968818\n",
      "57 Train Loss 0.009722712 Test MSE 0.0006612891437333412 Test RE 0.018632166830080944\n",
      "58 Train Loss 0.009242612 Test MSE 0.0005812860652245869 Test RE 0.017468781941328646\n",
      "59 Train Loss 0.008844188 Test MSE 0.0005828299234720676 Test RE 0.017491964536983037\n",
      "60 Train Loss 0.008710287 Test MSE 0.0004950600120592325 Test RE 0.01612117126167673\n",
      "61 Train Loss 0.008047225 Test MSE 0.0003185596189789804 Test RE 0.012931920594635162\n",
      "62 Train Loss 0.0076975618 Test MSE 0.00028581472905979936 Test RE 0.012249263315942227\n",
      "63 Train Loss 0.007512203 Test MSE 0.0002759905435116136 Test RE 0.012036903215062521\n",
      "64 Train Loss 0.007388568 Test MSE 0.0002543188005303618 Test RE 0.011554652822296684\n",
      "65 Train Loss 0.0071812086 Test MSE 0.0002511031003988159 Test RE 0.011481369798239903\n",
      "66 Train Loss 0.006781438 Test MSE 0.00030401754810012444 Test RE 0.012633305362618792\n",
      "67 Train Loss 0.0065514403 Test MSE 0.0002908385623176456 Test RE 0.012356448465761897\n",
      "68 Train Loss 0.0064415284 Test MSE 0.0003177426148667443 Test RE 0.01291532681654883\n",
      "69 Train Loss 0.0063691074 Test MSE 0.00031422263729180533 Test RE 0.012843589083138245\n",
      "70 Train Loss 0.006113303 Test MSE 0.0003007246238420629 Test RE 0.012564701132789046\n",
      "71 Train Loss 0.005964391 Test MSE 0.000290484968208226 Test RE 0.012348934853838379\n",
      "72 Train Loss 0.0059048627 Test MSE 0.00027588181205852157 Test RE 0.012034531903909242\n",
      "73 Train Loss 0.0058366186 Test MSE 0.00026480004497573157 Test RE 0.011790349931288026\n",
      "74 Train Loss 0.0056736926 Test MSE 0.00020784908814293877 Test RE 0.010445800554176082\n",
      "75 Train Loss 0.005493147 Test MSE 0.00016712705639843626 Test RE 0.009366795738146413\n",
      "76 Train Loss 0.00538085 Test MSE 0.000159437809795423 Test RE 0.009148783018293284\n",
      "77 Train Loss 0.0053275744 Test MSE 0.0001647956224552732 Test RE 0.00930123255967436\n",
      "78 Train Loss 0.005269072 Test MSE 0.0001608588469702037 Test RE 0.009189463208509425\n",
      "79 Train Loss 0.0050239637 Test MSE 0.0001600904591776908 Test RE 0.009167488900028612\n",
      "80 Train Loss 0.0048696427 Test MSE 0.00016952209215634855 Test RE 0.00943367302704324\n",
      "81 Train Loss 0.004819464 Test MSE 0.00016958905917645946 Test RE 0.00943553615469048\n",
      "82 Train Loss 0.0047706086 Test MSE 0.00017619555973942135 Test RE 0.00961756538373564\n",
      "83 Train Loss 0.0046756486 Test MSE 0.00017865092321244565 Test RE 0.009684346059181333\n",
      "84 Train Loss 0.0045520714 Test MSE 0.00017798458072158202 Test RE 0.009666268571292927\n",
      "85 Train Loss 0.0044164737 Test MSE 0.0002283911981442173 Test RE 0.0109498293044786\n",
      "86 Train Loss 0.00428743 Test MSE 0.000258118755051279 Test RE 0.01164065581788117\n",
      "87 Train Loss 0.0041496423 Test MSE 0.00029199238073342556 Test RE 0.012380934533607666\n",
      "88 Train Loss 0.004064108 Test MSE 0.00024291365980854058 Test RE 0.011292591970336444\n",
      "89 Train Loss 0.0039998046 Test MSE 0.00023242231012690395 Test RE 0.011046039054513313\n",
      "90 Train Loss 0.0039023003 Test MSE 0.00021241638393345135 Test RE 0.010559945415501797\n",
      "91 Train Loss 0.0037649372 Test MSE 0.00023881273989379416 Test RE 0.01119686426059195\n",
      "92 Train Loss 0.0036833019 Test MSE 0.00020877136056073758 Test RE 0.010468950067498069\n",
      "93 Train Loss 0.0036261573 Test MSE 0.00022669825431528376 Test RE 0.01090917115719901\n",
      "94 Train Loss 0.0035909552 Test MSE 0.0002171887463411322 Test RE 0.01067791174208246\n",
      "95 Train Loss 0.0035700544 Test MSE 0.00021551820329591715 Test RE 0.010636767012301072\n",
      "96 Train Loss 0.0035296283 Test MSE 0.00023398305743597582 Test RE 0.01108306482482262\n",
      "97 Train Loss 0.0034795953 Test MSE 0.00024837287335213216 Test RE 0.011418781123565515\n",
      "98 Train Loss 0.0033734047 Test MSE 0.0002597640327686519 Test RE 0.011677696305478998\n",
      "99 Train Loss 0.0033047986 Test MSE 0.0002587112162515444 Test RE 0.011654007586877624\n",
      "100 Train Loss 0.0032684128 Test MSE 0.0002552094986983517 Test RE 0.011574869009004344\n",
      "101 Train Loss 0.0032231873 Test MSE 0.0002506129708714624 Test RE 0.011470159050453729\n",
      "102 Train Loss 0.0031843414 Test MSE 0.0002513593356642674 Test RE 0.01148722632032366\n",
      "103 Train Loss 0.0031032762 Test MSE 0.000261301163093777 Test RE 0.01171219620259467\n",
      "104 Train Loss 0.00305456 Test MSE 0.00024290653886873927 Test RE 0.011292426449679805\n",
      "105 Train Loss 0.0030145484 Test MSE 0.00022552301603110227 Test RE 0.010880857010746219\n",
      "106 Train Loss 0.0029760646 Test MSE 0.00020540674419248765 Test RE 0.010384247175708398\n",
      "107 Train Loss 0.0029427146 Test MSE 0.0002161032664200726 Test RE 0.010651194940615585\n",
      "108 Train Loss 0.0028932306 Test MSE 0.00020468535597769174 Test RE 0.010365996406249599\n",
      "109 Train Loss 0.0028291564 Test MSE 0.00020803519634090504 Test RE 0.010450476095824718\n",
      "110 Train Loss 0.0027536848 Test MSE 0.0002239041406380419 Test RE 0.010841733561150719\n",
      "111 Train Loss 0.002688712 Test MSE 0.00021763665055878612 Test RE 0.01068891649835208\n",
      "112 Train Loss 0.002624788 Test MSE 0.00019365531656859535 Test RE 0.01008282849107162\n",
      "113 Train Loss 0.0025512096 Test MSE 0.00020018927533903383 Test RE 0.01025151546967662\n",
      "114 Train Loss 0.0024756151 Test MSE 0.0001881937867712443 Test RE 0.009939632059330074\n",
      "115 Train Loss 0.0024400915 Test MSE 0.00019225258704195076 Test RE 0.010046244971155579\n",
      "116 Train Loss 0.0023759585 Test MSE 0.0001972847595747995 Test RE 0.010176874903523729\n",
      "117 Train Loss 0.0022742958 Test MSE 0.0002170285013537787 Test RE 0.010673971856631216\n",
      "118 Train Loss 0.0022167237 Test MSE 0.00023194105004384759 Test RE 0.011034597010941683\n",
      "119 Train Loss 0.002164986 Test MSE 0.0002506238083669528 Test RE 0.011470407055281037\n",
      "120 Train Loss 0.0021374568 Test MSE 0.0002442815441374168 Test RE 0.011324342499640018\n",
      "121 Train Loss 0.0020989005 Test MSE 0.00025156906404317955 Test RE 0.011492017658216464\n",
      "122 Train Loss 0.0020798352 Test MSE 0.00025323513360913773 Test RE 0.011530009024605593\n",
      "123 Train Loss 0.0020502582 Test MSE 0.0002510385477178748 Test RE 0.01147989390877548\n",
      "124 Train Loss 0.0020133157 Test MSE 0.00024176842017151784 Test RE 0.01126594051912003\n",
      "125 Train Loss 0.0019728746 Test MSE 0.0002422754359235029 Test RE 0.011277747308760895\n",
      "126 Train Loss 0.0019326431 Test MSE 0.00023065813693424426 Test RE 0.01100403739458684\n",
      "127 Train Loss 0.0019028735 Test MSE 0.00023007815423176483 Test RE 0.010990194032255773\n",
      "128 Train Loss 0.0018898105 Test MSE 0.00022830994162002024 Test RE 0.010947881277958671\n",
      "129 Train Loss 0.0018665629 Test MSE 0.0002287457374465255 Test RE 0.010958324902045239\n",
      "130 Train Loss 0.0018494106 Test MSE 0.00023112751902244283 Test RE 0.011015228140091298\n",
      "131 Train Loss 0.0018230455 Test MSE 0.0002273336968300694 Test RE 0.01092444983724623\n",
      "132 Train Loss 0.0017863485 Test MSE 0.000217629284941569 Test RE 0.010688735620881915\n",
      "133 Train Loss 0.0017451219 Test MSE 0.00022271454466185454 Test RE 0.01081289430217043\n",
      "134 Train Loss 0.0017204008 Test MSE 0.0002161020034905098 Test RE 0.010651163817234516\n",
      "135 Train Loss 0.0017000684 Test MSE 0.00021169329419362974 Test RE 0.010541956460506244\n",
      "136 Train Loss 0.0016772274 Test MSE 0.00020587271938383718 Test RE 0.010396019088134862\n",
      "137 Train Loss 0.0016499594 Test MSE 0.0001973513929965787 Test RE 0.010178593390926879\n",
      "138 Train Loss 0.0016293502 Test MSE 0.00019530231878301654 Test RE 0.010125613997382023\n",
      "139 Train Loss 0.0015891995 Test MSE 0.00018603930690851047 Test RE 0.00988257284158061\n",
      "140 Train Loss 0.0015469654 Test MSE 0.00017684209202178144 Test RE 0.009635194581665014\n",
      "141 Train Loss 0.001517559 Test MSE 0.00017328001366977147 Test RE 0.009537661489936745\n",
      "142 Train Loss 0.001495943 Test MSE 0.0001728532315112215 Test RE 0.009525908798043216\n",
      "143 Train Loss 0.0014736236 Test MSE 0.0001676521172075898 Test RE 0.009381497967396301\n",
      "144 Train Loss 0.0014480589 Test MSE 0.00016488920418968067 Test RE 0.009303873108998544\n",
      "145 Train Loss 0.001412904 Test MSE 0.00016298027657253494 Test RE 0.009249860709066113\n",
      "146 Train Loss 0.0013678409 Test MSE 0.00015870635038420488 Test RE 0.00912777276873481\n",
      "147 Train Loss 0.0013303302 Test MSE 0.0001541086762793372 Test RE 0.008994586706571115\n",
      "148 Train Loss 0.001293485 Test MSE 0.00015380588109611653 Test RE 0.008985746008194675\n",
      "149 Train Loss 0.0012610693 Test MSE 0.00016872356353433732 Test RE 0.009411428286426719\n",
      "150 Train Loss 0.0012334412 Test MSE 0.0001629147620080804 Test RE 0.009248001399705469\n",
      "151 Train Loss 0.001215904 Test MSE 0.00016564543557391888 Test RE 0.009325183879935708\n",
      "152 Train Loss 0.0012011778 Test MSE 0.00015870936465347488 Test RE 0.009127859449054329\n",
      "153 Train Loss 0.0011851152 Test MSE 0.00015413822595181803 Test RE 0.008995449001796912\n",
      "154 Train Loss 0.001165283 Test MSE 0.00015012505603708684 Test RE 0.008877573137583899\n",
      "155 Train Loss 0.0011354141 Test MSE 0.0001336266876631566 Test RE 0.00837556800627272\n",
      "156 Train Loss 0.0011241661 Test MSE 0.00012869647823940142 Test RE 0.008219605971351145\n",
      "157 Train Loss 0.0011106159 Test MSE 0.00012417298557716806 Test RE 0.008073860274784808\n",
      "158 Train Loss 0.0010976207 Test MSE 0.00012782908554905367 Test RE 0.0081918597578937\n",
      "159 Train Loss 0.001085076 Test MSE 0.0001303267039464826 Test RE 0.008271501894311604\n",
      "160 Train Loss 0.0010717777 Test MSE 0.00013314890324109567 Test RE 0.00836058110714025\n",
      "161 Train Loss 0.0010597727 Test MSE 0.00012905467092207002 Test RE 0.008231036575345593\n",
      "162 Train Loss 0.0010473543 Test MSE 0.00013401002317572422 Test RE 0.008387572918629852\n",
      "163 Train Loss 0.0010383463 Test MSE 0.00013475172607489203 Test RE 0.00841075216600005\n",
      "164 Train Loss 0.0010268368 Test MSE 0.00013990529212204586 Test RE 0.008570077295872305\n",
      "165 Train Loss 0.0010104938 Test MSE 0.0001356506116029058 Test RE 0.00843875825323094\n",
      "166 Train Loss 0.0010017063 Test MSE 0.00013501692972841986 Test RE 0.008419024660385117\n",
      "167 Train Loss 0.000988807 Test MSE 0.00012878634248085038 Test RE 0.008222475201992136\n",
      "168 Train Loss 0.0009790553 Test MSE 0.00013065762001375576 Test RE 0.008281996434146465\n",
      "169 Train Loss 0.0009673046 Test MSE 0.00012795869980173995 Test RE 0.008196011836272341\n",
      "170 Train Loss 0.00095585576 Test MSE 0.00012123326803808269 Test RE 0.007977716039181406\n",
      "171 Train Loss 0.00094748277 Test MSE 0.0001234977318503117 Test RE 0.008051877488786302\n",
      "172 Train Loss 0.0009305462 Test MSE 0.0001221347600172004 Test RE 0.008007322297230418\n",
      "173 Train Loss 0.0009197693 Test MSE 0.0001227086589360363 Test RE 0.00802611304906755\n",
      "174 Train Loss 0.0009121517 Test MSE 0.00012163166524733265 Test RE 0.007990813487613033\n",
      "175 Train Loss 0.0009009245 Test MSE 0.00011970033699824231 Test RE 0.007927118569811152\n",
      "176 Train Loss 0.0008869554 Test MSE 0.00012035842605335751 Test RE 0.007948879575564161\n",
      "177 Train Loss 0.0008753882 Test MSE 0.00012442069068948218 Test RE 0.008081909288274547\n",
      "178 Train Loss 0.0008672471 Test MSE 0.0001238648244405639 Test RE 0.008063835568044004\n",
      "179 Train Loss 0.00086179643 Test MSE 0.00012083585429930608 Test RE 0.007964629464282086\n",
      "180 Train Loss 0.0008511132 Test MSE 0.00012009421309374525 Test RE 0.007940150021134674\n",
      "181 Train Loss 0.0008377753 Test MSE 0.0001188559395712287 Test RE 0.007899109103916422\n",
      "182 Train Loss 0.00082837086 Test MSE 0.00011720336707011468 Test RE 0.007844002291740967\n",
      "183 Train Loss 0.0008206414 Test MSE 0.00011633242729211511 Test RE 0.00781480350382003\n",
      "184 Train Loss 0.0008085808 Test MSE 0.0001166102103092035 Test RE 0.007824128183958941\n",
      "185 Train Loss 0.0007995042 Test MSE 0.00011300338723164646 Test RE 0.0077021752917330304\n",
      "186 Train Loss 0.00079564174 Test MSE 0.00011355674430857642 Test RE 0.0077210103391612255\n",
      "187 Train Loss 0.000785061 Test MSE 0.00011774400672867956 Test RE 0.007862073016037956\n",
      "188 Train Loss 0.0007748653 Test MSE 0.00011630997652093544 Test RE 0.00781404938549275\n",
      "189 Train Loss 0.00076615694 Test MSE 0.00011662009584711017 Test RE 0.007824459819054976\n",
      "190 Train Loss 0.00076303934 Test MSE 0.00011529389467366102 Test RE 0.0077798428177093485\n",
      "191 Train Loss 0.0007600675 Test MSE 0.00011731747676864746 Test RE 0.007847819839830792\n",
      "192 Train Loss 0.00075551536 Test MSE 0.00011450518599561835 Test RE 0.007753186768272878\n",
      "193 Train Loss 0.00074862817 Test MSE 0.00011439693958341717 Test RE 0.00774952120027832\n",
      "194 Train Loss 0.0007427277 Test MSE 0.0001148577546545072 Test RE 0.007765113868745832\n",
      "195 Train Loss 0.00073393516 Test MSE 0.00011286266506091062 Test RE 0.007697378070623851\n",
      "196 Train Loss 0.00072307227 Test MSE 0.00011129421453155885 Test RE 0.007643705781705231\n",
      "197 Train Loss 0.0007126744 Test MSE 0.00011134006404429085 Test RE 0.0076452800957878715\n",
      "198 Train Loss 0.00070627045 Test MSE 0.00010591741516035069 Test RE 0.0074567804172164225\n",
      "199 Train Loss 0.00069762906 Test MSE 0.00010674432981777152 Test RE 0.007485831979636446\n",
      "200 Train Loss 0.00068874995 Test MSE 9.830964102286142e-05 Test RE 0.007183990060552451\n",
      "201 Train Loss 0.0006779645 Test MSE 9.719961761492812e-05 Test RE 0.00714331737093517\n",
      "202 Train Loss 0.0006682954 Test MSE 9.832820482323748e-05 Test RE 0.007184668304623447\n",
      "203 Train Loss 0.00065934483 Test MSE 9.811999187895205e-05 Test RE 0.007177057397311966\n",
      "204 Train Loss 0.00065351336 Test MSE 9.774473206871956e-05 Test RE 0.007163319925594802\n",
      "205 Train Loss 0.00064827595 Test MSE 9.522306029149857e-05 Test RE 0.007070314542814512\n",
      "206 Train Loss 0.0006372659 Test MSE 9.111472577888311e-05 Test RE 0.006916110984280988\n",
      "207 Train Loss 0.0006245381 Test MSE 8.686811363290243e-05 Test RE 0.006753017311415796\n",
      "208 Train Loss 0.0006155567 Test MSE 8.506895417186528e-05 Test RE 0.006682719223391056\n",
      "209 Train Loss 0.00060940126 Test MSE 8.126692599266898e-05 Test RE 0.006531675250776195\n",
      "210 Train Loss 0.00060632784 Test MSE 8.175728602794102e-05 Test RE 0.0065513514936088365\n",
      "211 Train Loss 0.0006024861 Test MSE 8.069423931850612e-05 Test RE 0.0065086202585681666\n",
      "212 Train Loss 0.00059967715 Test MSE 7.912558966299202e-05 Test RE 0.006445047870259076\n",
      "213 Train Loss 0.00059253385 Test MSE 7.439255765985525e-05 Test RE 0.006249314952813877\n",
      "214 Train Loss 0.00058350485 Test MSE 6.92463549986137e-05 Test RE 0.00602928935152184\n",
      "215 Train Loss 0.0005775008 Test MSE 6.74178900068034e-05 Test RE 0.00594915447271234\n",
      "216 Train Loss 0.0005707168 Test MSE 6.497662958044901e-05 Test RE 0.005840449293293566\n",
      "217 Train Loss 0.00056409196 Test MSE 6.477205512814075e-05 Test RE 0.005831247918520711\n",
      "218 Train Loss 0.0005602702 Test MSE 6.51693877387959e-05 Test RE 0.005849105948419883\n",
      "219 Train Loss 0.0005600379 Test MSE 6.558636169509098e-05 Test RE 0.005867788309219876\n",
      "220 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "221 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "222 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "223 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "224 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "225 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "226 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "227 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "228 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "229 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "230 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "231 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "232 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "233 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "234 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "235 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "236 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "237 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "238 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "239 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "240 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "241 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "242 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "243 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "244 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "245 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "246 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "247 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "248 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "249 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "250 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "251 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "252 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "253 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "254 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "255 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "256 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "257 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "258 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "259 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "260 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "261 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "262 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "263 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "264 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "265 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "266 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "267 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "268 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "269 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "270 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "271 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "272 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "273 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "274 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "275 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "276 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "277 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "278 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "279 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "280 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "281 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "282 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "283 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "284 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "285 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "286 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "287 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "288 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "289 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "290 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "291 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "292 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "293 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "294 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "295 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "296 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "297 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "298 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "299 Train Loss 0.00055992004 Test MSE 6.573444466512618e-05 Test RE 0.005874408813714399\n",
      "Training time: 150.42\n",
      "KG_stan_medium\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 18458.42 Test MSE 6.97678708721313 Test RE 1.9137949422019356\n",
      "1 Train Loss 1903.7173 Test MSE 11.483298224230577 Test RE 2.4552797925271097\n",
      "2 Train Loss 342.63934 Test MSE 13.760571399423773 Test RE 2.6877316266009585\n",
      "3 Train Loss 212.36621 Test MSE 14.182633452431505 Test RE 2.728639156422713\n",
      "4 Train Loss 129.86415 Test MSE 14.721383511949945 Test RE 2.77998198157583\n",
      "5 Train Loss 74.3433 Test MSE 15.508178757321382 Test RE 2.8533041418177487\n",
      "6 Train Loss 49.275673 Test MSE 16.31839178436587 Test RE 2.926889627306121\n",
      "7 Train Loss 35.574337 Test MSE 16.70304542944507 Test RE 2.961184713833966\n",
      "8 Train Loss 30.75812 Test MSE 16.717349065224614 Test RE 2.9624523462506223\n",
      "9 Train Loss 26.927404 Test MSE 16.807307731385524 Test RE 2.9704123614656672\n",
      "10 Train Loss 25.048868 Test MSE 16.871150637102872 Test RE 2.9760486005633515\n",
      "11 Train Loss 24.422604 Test MSE 16.835272022607626 Test RE 2.9728824463513654\n",
      "12 Train Loss 23.66926 Test MSE 16.738283417485462 Test RE 2.964306635995535\n",
      "13 Train Loss 23.13294 Test MSE 16.73538360701299 Test RE 2.964049850411758\n",
      "14 Train Loss 22.665787 Test MSE 16.749882827289685 Test RE 2.9653335708284367\n",
      "15 Train Loss 22.208078 Test MSE 16.66181209401109 Test RE 2.9575274475486477\n",
      "16 Train Loss 21.936665 Test MSE 16.637171041442045 Test RE 2.955339703711828\n",
      "17 Train Loss 21.564575 Test MSE 16.50524209826829 Test RE 2.9435987993569412\n",
      "18 Train Loss 21.273384 Test MSE 16.40855370346192 Test RE 2.934964273321984\n",
      "19 Train Loss 21.10534 Test MSE 16.32268956351207 Test RE 2.9272750297782775\n",
      "20 Train Loss 20.882614 Test MSE 16.166231334565392 Test RE 2.9132118122212023\n",
      "21 Train Loss 20.693644 Test MSE 16.08037452003689 Test RE 2.9054656636735667\n",
      "22 Train Loss 20.396029 Test MSE 15.827730391899978 Test RE 2.882550931974694\n",
      "23 Train Loss 20.156 Test MSE 15.527965944638211 Test RE 2.8551238547140323\n",
      "24 Train Loss 20.024458 Test MSE 15.540697083752429 Test RE 2.8562940508515546\n",
      "25 Train Loss 19.819904 Test MSE 15.338649811338483 Test RE 2.837665720424588\n",
      "26 Train Loss 19.536175 Test MSE 14.864638143448687 Test RE 2.7934753173914246\n",
      "27 Train Loss 19.217972 Test MSE 14.481843155004187 Test RE 2.7572718528910576\n",
      "28 Train Loss 18.858652 Test MSE 14.131223034822197 Test RE 2.7236891647623303\n",
      "29 Train Loss 18.571236 Test MSE 13.943267437441726 Test RE 2.705515001491934\n",
      "30 Train Loss 18.178654 Test MSE 13.650261356212615 Test RE 2.676937003364546\n",
      "31 Train Loss 17.683132 Test MSE 13.528660855004556 Test RE 2.6649868630081897\n",
      "32 Train Loss 17.121367 Test MSE 13.270800443173263 Test RE 2.639466941418536\n",
      "33 Train Loss 16.749353 Test MSE 12.94627404010727 Test RE 2.6069942032552818\n",
      "34 Train Loss 16.379318 Test MSE 12.763738720921285 Test RE 2.5885503707422832\n",
      "35 Train Loss 16.070417 Test MSE 12.617434095327418 Test RE 2.5736719550769043\n",
      "36 Train Loss 15.833361 Test MSE 12.48283503535452 Test RE 2.5599075619310594\n",
      "37 Train Loss 15.6117325 Test MSE 12.34501984698228 Test RE 2.5457371711718797\n",
      "38 Train Loss 15.469679 Test MSE 12.239977076444829 Test RE 2.534883297822875\n",
      "39 Train Loss 15.106905 Test MSE 11.995548123086072 Test RE 2.509445200629402\n",
      "40 Train Loss 14.855881 Test MSE 11.76112213465682 Test RE 2.484803485813794\n",
      "41 Train Loss 14.44359 Test MSE 11.615242333327732 Test RE 2.4693451953953773\n",
      "42 Train Loss 14.057944 Test MSE 11.340569722211532 Test RE 2.4399734693918904\n",
      "43 Train Loss 13.709331 Test MSE 11.212573774732173 Test RE 2.426164950567957\n",
      "44 Train Loss 13.38154 Test MSE 11.002955803954249 Test RE 2.403379496878021\n",
      "45 Train Loss 13.154985 Test MSE 10.909170638151695 Test RE 2.393114813632137\n",
      "46 Train Loss 12.936042 Test MSE 10.745431492274 Test RE 2.3750874096946686\n",
      "47 Train Loss 12.387134 Test MSE 10.485906820505233 Test RE 2.3462304384431234\n",
      "48 Train Loss 11.962463 Test MSE 10.238556328078165 Test RE 2.318392854607067\n",
      "49 Train Loss 11.317231 Test MSE 9.74591653699509 Test RE 2.261929223325894\n",
      "50 Train Loss 10.748325 Test MSE 9.360451493621158 Test RE 2.21674667739189\n",
      "51 Train Loss 9.890627 Test MSE 8.678624476346405 Test RE 2.134485043841514\n",
      "52 Train Loss 9.387149 Test MSE 8.353015473446998 Test RE 2.0940609135844857\n",
      "53 Train Loss 8.5920105 Test MSE 7.708762653134623 Test RE 2.011685125763268\n",
      "54 Train Loss 7.6512465 Test MSE 7.001769313322578 Test RE 1.9172183041296136\n",
      "55 Train Loss 6.648683 Test MSE 6.218547944524798 Test RE 1.8068086504984553\n",
      "56 Train Loss 5.7147455 Test MSE 5.476443114436602 Test RE 1.6955748184277994\n",
      "57 Train Loss 4.834716 Test MSE 4.551475255159116 Test RE 1.5457660360039391\n",
      "58 Train Loss 3.979775 Test MSE 3.2250277546457813 Test RE 1.301171061678465\n",
      "59 Train Loss 3.1666832 Test MSE 2.3299994995792304 Test RE 1.1059756912745973\n",
      "60 Train Loss 2.4495652 Test MSE 1.6494849614659532 Test RE 0.9305545732940516\n",
      "61 Train Loss 1.8870394 Test MSE 1.016671331950388 Test RE 0.7305634763875705\n",
      "62 Train Loss 1.4246384 Test MSE 0.6967699648737448 Test RE 0.6048008299341472\n",
      "63 Train Loss 1.0205629 Test MSE 0.6237299945031288 Test RE 0.5722238859464113\n",
      "64 Train Loss 0.8622321 Test MSE 0.43676265015266125 Test RE 0.47883999092564367\n",
      "65 Train Loss 0.66895884 Test MSE 0.3063710349944295 Test RE 0.4010435348145993\n",
      "66 Train Loss 0.5274884 Test MSE 0.2440776191151501 Test RE 0.3579576487810084\n",
      "67 Train Loss 0.43489736 Test MSE 0.20953354182792003 Test RE 0.3316610296646153\n",
      "68 Train Loss 0.36742997 Test MSE 0.19691932361411987 Test RE 0.32152284446127755\n",
      "69 Train Loss 0.30340815 Test MSE 0.1566333493145124 Test RE 0.2867541982562501\n",
      "70 Train Loss 0.26618654 Test MSE 0.14911421907767552 Test RE 0.279786784349551\n",
      "71 Train Loss 0.22296931 Test MSE 0.107573631376146 Test RE 0.2376405683336866\n",
      "72 Train Loss 0.19918957 Test MSE 0.09513861154469064 Test RE 0.22348381281205215\n",
      "73 Train Loss 0.17831092 Test MSE 0.0901487630658475 Test RE 0.2175442224229338\n",
      "74 Train Loss 0.14254795 Test MSE 0.06794047726278735 Test RE 0.18885651195695935\n",
      "75 Train Loss 0.12290224 Test MSE 0.06232107059122358 Test RE 0.18087773886878825\n",
      "76 Train Loss 0.110203765 Test MSE 0.0512707152908563 Test RE 0.16405986727402622\n",
      "77 Train Loss 0.096949145 Test MSE 0.036975364026811806 Test RE 0.13932334628018736\n",
      "78 Train Loss 0.08533231 Test MSE 0.031267364113917 Test RE 0.12811893007505998\n",
      "79 Train Loss 0.07760263 Test MSE 0.023031384316685586 Test RE 0.10995821694120264\n",
      "80 Train Loss 0.06845981 Test MSE 0.0165686257373636 Test RE 0.09326332862209309\n",
      "81 Train Loss 0.0627083 Test MSE 0.013477114452856489 Test RE 0.08411358161642958\n",
      "82 Train Loss 0.054853793 Test MSE 0.015640707887921622 Test RE 0.09061411854387674\n",
      "83 Train Loss 0.052736808 Test MSE 0.012147555540700319 Test RE 0.07985683881212069\n",
      "84 Train Loss 0.04765933 Test MSE 0.009745664218850156 Test RE 0.071527556589192\n",
      "85 Train Loss 0.042772554 Test MSE 0.008744685310245142 Test RE 0.06775475205610934\n",
      "86 Train Loss 0.039232086 Test MSE 0.006218170447453609 Test RE 0.05713457206010194\n",
      "87 Train Loss 0.03624897 Test MSE 0.003522921913729904 Test RE 0.04300502219875644\n",
      "88 Train Loss 0.032309007 Test MSE 0.0025515335073381024 Test RE 0.03659892300615036\n",
      "89 Train Loss 0.029741494 Test MSE 0.002673615575914724 Test RE 0.037464259155923295\n",
      "90 Train Loss 0.02878706 Test MSE 0.0034189347673378376 Test RE 0.04236557205210617\n",
      "91 Train Loss 0.02554808 Test MSE 0.00231984814783146 Test RE 0.034897751562816964\n",
      "92 Train Loss 0.024708202 Test MSE 0.002152792100767363 Test RE 0.033617755421549114\n",
      "93 Train Loss 0.022980459 Test MSE 0.0020069478683487807 Test RE 0.03245904316427724\n",
      "94 Train Loss 0.02137284 Test MSE 0.0021999228324056266 Test RE 0.03398375712254478\n",
      "95 Train Loss 0.020644909 Test MSE 0.0017749042086746157 Test RE 0.03052496166850246\n",
      "96 Train Loss 0.019902758 Test MSE 0.001705792584988226 Test RE 0.029924767080371523\n",
      "97 Train Loss 0.018630762 Test MSE 0.0015163149050964825 Test RE 0.028213851077970215\n",
      "98 Train Loss 0.017495876 Test MSE 0.0015785796858408965 Test RE 0.02878729925730251\n",
      "99 Train Loss 0.016768998 Test MSE 0.001316107772670036 Test RE 0.026285327632946637\n",
      "100 Train Loss 0.016330555 Test MSE 0.001400948536246433 Test RE 0.027119317682029246\n",
      "101 Train Loss 0.015537475 Test MSE 0.001249247372643448 Test RE 0.0256089569471013\n",
      "102 Train Loss 0.014196861 Test MSE 0.0009189891919273652 Test RE 0.02196457829519079\n",
      "103 Train Loss 0.013055024 Test MSE 0.0006659758610048192 Test RE 0.01869807561120134\n",
      "104 Train Loss 0.012548392 Test MSE 0.000599271264768292 Test RE 0.017736968489146805\n",
      "105 Train Loss 0.012167015 Test MSE 0.0005618477057824587 Test RE 0.017174218089870717\n",
      "106 Train Loss 0.010548458 Test MSE 0.00036225563136892147 Test RE 0.013790348463924882\n",
      "107 Train Loss 0.009484221 Test MSE 0.00033573441948634835 Test RE 0.013275949793632046\n",
      "108 Train Loss 0.009218511 Test MSE 0.0003214733361026735 Test RE 0.012990927116111455\n",
      "109 Train Loss 0.008804243 Test MSE 0.0003680641833706943 Test RE 0.013900468778604177\n",
      "110 Train Loss 0.008435344 Test MSE 0.0003556494950492302 Test RE 0.013664028710072308\n",
      "111 Train Loss 0.008260312 Test MSE 0.00035430047537120393 Test RE 0.01363808946825621\n",
      "112 Train Loss 0.007959538 Test MSE 0.0003227131068804175 Test RE 0.013015952945300762\n",
      "113 Train Loss 0.007804268 Test MSE 0.0003156924705534528 Test RE 0.012873593143061109\n",
      "114 Train Loss 0.0076317675 Test MSE 0.0003075822302284732 Test RE 0.01270715386002055\n",
      "115 Train Loss 0.0073887324 Test MSE 0.00030145098871710936 Test RE 0.01257986625805617\n",
      "116 Train Loss 0.007182986 Test MSE 0.0002913288695259802 Test RE 0.01236685957572198\n",
      "117 Train Loss 0.007018225 Test MSE 0.0002864797369997642 Test RE 0.012263505277217765\n",
      "118 Train Loss 0.0067406357 Test MSE 0.0003035106159656695 Test RE 0.012622768305805198\n",
      "119 Train Loss 0.0063702166 Test MSE 0.0003210756508276708 Test RE 0.012982889281241156\n",
      "120 Train Loss 0.006200662 Test MSE 0.00031105456289289425 Test RE 0.012778678854498108\n",
      "121 Train Loss 0.0060181706 Test MSE 0.00029682299004477487 Test RE 0.012482927134916298\n",
      "122 Train Loss 0.0058308514 Test MSE 0.00029208802855881463 Test RE 0.01238296217641735\n",
      "123 Train Loss 0.005435255 Test MSE 0.0002618639778106878 Test RE 0.011724802825970949\n",
      "124 Train Loss 0.0053226724 Test MSE 0.00028855109518550467 Test RE 0.012307760345324598\n",
      "125 Train Loss 0.0052152425 Test MSE 0.0002869685382747499 Test RE 0.012273963018991398\n",
      "126 Train Loss 0.004993979 Test MSE 0.000271654842599743 Test RE 0.01194198147918795\n",
      "127 Train Loss 0.004702763 Test MSE 0.0002887459115928954 Test RE 0.012311914460690757\n",
      "128 Train Loss 0.004525518 Test MSE 0.0002635801112443096 Test RE 0.011763159509189517\n",
      "129 Train Loss 0.004452845 Test MSE 0.00025845851912242255 Test RE 0.011648314649066701\n",
      "130 Train Loss 0.0043352772 Test MSE 0.0002479068320910675 Test RE 0.01140806312169394\n",
      "131 Train Loss 0.0041819597 Test MSE 0.00027395015011227387 Test RE 0.011992326362757837\n",
      "132 Train Loss 0.0040833913 Test MSE 0.0002594132354978168 Test RE 0.011669808593097662\n",
      "133 Train Loss 0.004029644 Test MSE 0.0002294882473676334 Test RE 0.010976095883986388\n",
      "134 Train Loss 0.003935169 Test MSE 0.000237309119920042 Test RE 0.011161559584064142\n",
      "135 Train Loss 0.003839191 Test MSE 0.000266821255017134 Test RE 0.011835262067778478\n",
      "136 Train Loss 0.003708779 Test MSE 0.00025189135371164116 Test RE 0.011499376617666356\n",
      "137 Train Loss 0.0036225787 Test MSE 0.0002465733853875949 Test RE 0.011377340783481668\n",
      "138 Train Loss 0.003558605 Test MSE 0.00024306288179643158 Test RE 0.011296059960389217\n",
      "139 Train Loss 0.0034837704 Test MSE 0.0002335929432988633 Test RE 0.011073821711229564\n",
      "140 Train Loss 0.0033980573 Test MSE 0.00022558623686486657 Test RE 0.010882382018396534\n",
      "141 Train Loss 0.0033300838 Test MSE 0.0002334006913669495 Test RE 0.011069263778499545\n",
      "142 Train Loss 0.0032834774 Test MSE 0.00022888778087554258 Test RE 0.01096172675008656\n",
      "143 Train Loss 0.0031513257 Test MSE 0.000227602382965168 Test RE 0.010930903745012734\n",
      "144 Train Loss 0.003046156 Test MSE 0.00021634169212244976 Test RE 0.01065706902711917\n",
      "145 Train Loss 0.0029964952 Test MSE 0.00019993945397785948 Test RE 0.010245116907509243\n",
      "146 Train Loss 0.0029468373 Test MSE 0.00018819036497096786 Test RE 0.009939541696117465\n",
      "147 Train Loss 0.0028657166 Test MSE 0.00017552802430975244 Test RE 0.009599329515674774\n",
      "148 Train Loss 0.0027665985 Test MSE 0.00015038486197178132 Test RE 0.00888525156658219\n",
      "149 Train Loss 0.0026775966 Test MSE 0.0001307092692830798 Test RE 0.008283633218894\n",
      "150 Train Loss 0.002616108 Test MSE 0.0001229340065222087 Test RE 0.008033479422398971\n",
      "151 Train Loss 0.0025620908 Test MSE 0.00012100500803525887 Test RE 0.00797020221285239\n",
      "152 Train Loss 0.0025185158 Test MSE 0.00011951904726295981 Test RE 0.007921113366274272\n",
      "153 Train Loss 0.0024925862 Test MSE 0.00012009983087646011 Test RE 0.007940335731647938\n",
      "154 Train Loss 0.0024521567 Test MSE 0.00012109508875018563 Test RE 0.007973168321261334\n",
      "155 Train Loss 0.0024113408 Test MSE 0.00011385974822381546 Test RE 0.0077313044781547584\n",
      "156 Train Loss 0.0023034567 Test MSE 0.00010441332376412036 Test RE 0.0074036457091039105\n",
      "157 Train Loss 0.002236614 Test MSE 0.00010364667521280277 Test RE 0.007376415220740246\n",
      "158 Train Loss 0.002194411 Test MSE 0.00010874952175229836 Test RE 0.007555815514959759\n",
      "159 Train Loss 0.002171863 Test MSE 0.00010876671920079791 Test RE 0.007556412922697084\n",
      "160 Train Loss 0.0021412782 Test MSE 0.00010801798730846799 Test RE 0.0075303594673829695\n",
      "161 Train Loss 0.0021109914 Test MSE 0.00010542765293404153 Test RE 0.007439520361673786\n",
      "162 Train Loss 0.002088377 Test MSE 0.00010690307055260334 Test RE 0.0074913960457249976\n",
      "163 Train Loss 0.0020267433 Test MSE 0.00010677570544623812 Test RE 0.007486932063484994\n",
      "164 Train Loss 0.0019546887 Test MSE 0.00011340510648329071 Test RE 0.007715853497351777\n",
      "165 Train Loss 0.0019074382 Test MSE 0.00011813540499892421 Test RE 0.007875129513939587\n",
      "166 Train Loss 0.0018585766 Test MSE 0.0001320606247015371 Test RE 0.00832634384029005\n",
      "167 Train Loss 0.0018348901 Test MSE 0.00014329322307471014 Test RE 0.00867322261031647\n",
      "168 Train Loss 0.0018154543 Test MSE 0.0001509541507162726 Test RE 0.008902053442783917\n",
      "169 Train Loss 0.0017895025 Test MSE 0.00015203753226912805 Test RE 0.008933940867521887\n",
      "170 Train Loss 0.0017679058 Test MSE 0.00016099482325188693 Test RE 0.00919334638033188\n",
      "171 Train Loss 0.0017432462 Test MSE 0.00014949917441921192 Test RE 0.008859048204946898\n",
      "172 Train Loss 0.0016988132 Test MSE 0.00014183020547509843 Test RE 0.008628832400541799\n",
      "173 Train Loss 0.0016664708 Test MSE 0.0001402381140100718 Test RE 0.00858026495543801\n",
      "174 Train Loss 0.0016385682 Test MSE 0.00013629839523925157 Test RE 0.008458883407233891\n",
      "175 Train Loss 0.0016116127 Test MSE 0.00013539233840229698 Test RE 0.008430720900917073\n",
      "176 Train Loss 0.0016027484 Test MSE 0.00013742173152353875 Test RE 0.00849366984876137\n",
      "177 Train Loss 0.0015960499 Test MSE 0.00014208790212408252 Test RE 0.00863666786851589\n",
      "178 Train Loss 0.0015884438 Test MSE 0.00015109013397368012 Test RE 0.008906062135896375\n",
      "179 Train Loss 0.0015791948 Test MSE 0.0001546810687369022 Test RE 0.009011275130534785\n",
      "180 Train Loss 0.0015700762 Test MSE 0.00014852027860495139 Test RE 0.008829996781248007\n",
      "181 Train Loss 0.0015602771 Test MSE 0.00014206384403388158 Test RE 0.008635936664354343\n",
      "182 Train Loss 0.0015457049 Test MSE 0.00014421154316667079 Test RE 0.008700970169452019\n",
      "183 Train Loss 0.0015273913 Test MSE 0.00013620023097124834 Test RE 0.008455836747514118\n",
      "184 Train Loss 0.0014904125 Test MSE 0.00014156452244381022 Test RE 0.008620746644166422\n",
      "185 Train Loss 0.0014631647 Test MSE 0.0001321703080957854 Test RE 0.008329800859014294\n",
      "186 Train Loss 0.0014474782 Test MSE 0.00013115716558927064 Test RE 0.008297813681260627\n",
      "187 Train Loss 0.0014270118 Test MSE 0.00013160315786005429 Test RE 0.008311909823214227\n",
      "188 Train Loss 0.0014170674 Test MSE 0.00013377729458152114 Test RE 0.008380286611821405\n",
      "189 Train Loss 0.0013936034 Test MSE 0.00013175848122930643 Test RE 0.008316813402853541\n",
      "190 Train Loss 0.0013456369 Test MSE 0.00014734034708721065 Test RE 0.00879485152213794\n",
      "191 Train Loss 0.0013146499 Test MSE 0.0001568929633410898 Test RE 0.009075475748393775\n",
      "192 Train Loss 0.0012809654 Test MSE 0.00016372326252666323 Test RE 0.009270920625069913\n",
      "193 Train Loss 0.0012549902 Test MSE 0.0001604380202436207 Test RE 0.009177434947837966\n",
      "194 Train Loss 0.0012388447 Test MSE 0.00015691403859328893 Test RE 0.009076085277060272\n",
      "195 Train Loss 0.0012287918 Test MSE 0.00015065018410904165 Test RE 0.008893086181763685\n",
      "196 Train Loss 0.0012204372 Test MSE 0.00014262762519933297 Test RE 0.008653055578698525\n",
      "197 Train Loss 0.0012128344 Test MSE 0.00014639676404556266 Test RE 0.008766644713813044\n",
      "198 Train Loss 0.0012075508 Test MSE 0.0001492330190087952 Test RE 0.008851158750044167\n",
      "199 Train Loss 0.0011971891 Test MSE 0.00015023952948441593 Test RE 0.008880957158794013\n",
      "200 Train Loss 0.0011786887 Test MSE 0.00014394151893316694 Test RE 0.008692820427834452\n",
      "201 Train Loss 0.0011606106 Test MSE 0.00013402712898274625 Test RE 0.008388108220475528\n",
      "202 Train Loss 0.0011431111 Test MSE 0.00014138785422335701 Test RE 0.008615365749973469\n",
      "203 Train Loss 0.001124041 Test MSE 0.00014192736188979021 Test RE 0.008631787352537066\n",
      "204 Train Loss 0.001110746 Test MSE 0.00015025316308971032 Test RE 0.00888136010440432\n",
      "205 Train Loss 0.0011004223 Test MSE 0.00015325279872751652 Test RE 0.008969575190879936\n",
      "206 Train Loss 0.0010930263 Test MSE 0.00015276086376077956 Test RE 0.00895516764221933\n",
      "207 Train Loss 0.0010810527 Test MSE 0.00014773661307135414 Test RE 0.008806670282066076\n",
      "208 Train Loss 0.0010700751 Test MSE 0.00013395752988678251 Test RE 0.008385930002661489\n",
      "209 Train Loss 0.001060944 Test MSE 0.00013522049636904585 Test RE 0.008425369002039036\n",
      "210 Train Loss 0.0010503894 Test MSE 0.0001260240591735284 Test RE 0.008133817046336506\n",
      "211 Train Loss 0.0010424943 Test MSE 0.00012268412316533432 Test RE 0.008025310592598528\n",
      "212 Train Loss 0.0010360874 Test MSE 0.00012343528674001487 Test RE 0.008049841564947334\n",
      "213 Train Loss 0.0010312303 Test MSE 0.00012057892788321544 Test RE 0.007956157588864643\n",
      "214 Train Loss 0.0010251803 Test MSE 0.00012843898235322736 Test RE 0.008211378961204692\n",
      "215 Train Loss 0.0010180935 Test MSE 0.00012505050844615741 Test RE 0.008102338786937032\n",
      "216 Train Loss 0.0010118615 Test MSE 0.00011590785257575594 Test RE 0.007800529749864815\n",
      "217 Train Loss 0.0010042478 Test MSE 0.0001145240314621101 Test RE 0.007753824758634666\n",
      "218 Train Loss 0.000995018 Test MSE 0.00010535869622643865 Test RE 0.0074370869927791764\n",
      "219 Train Loss 0.0009874246 Test MSE 0.00010696654018149976 Test RE 0.007493619581360881\n",
      "220 Train Loss 0.0009800955 Test MSE 0.00010752460889338639 Test RE 0.007513142107989703\n",
      "221 Train Loss 0.00097298494 Test MSE 0.0001052677861106077 Test RE 0.007433877706911298\n",
      "222 Train Loss 0.0009521683 Test MSE 0.00010686805535390914 Test RE 0.007490169073465082\n",
      "223 Train Loss 0.00093631755 Test MSE 0.00011023503278393335 Test RE 0.007607246436633736\n",
      "224 Train Loss 0.0009182939 Test MSE 0.00010252726927396107 Test RE 0.0073364736640753585\n",
      "225 Train Loss 0.00090397266 Test MSE 0.00011130956208542634 Test RE 0.0076442327998554795\n",
      "226 Train Loss 0.0008877688 Test MSE 9.813397651027683e-05 Test RE 0.0071775688370489445\n",
      "227 Train Loss 0.00087710406 Test MSE 9.248529115348966e-05 Test RE 0.00696793357164576\n",
      "228 Train Loss 0.0008707136 Test MSE 9.115206349208428e-05 Test RE 0.006917527908474887\n",
      "229 Train Loss 0.0008588953 Test MSE 9.48496917522193e-05 Test RE 0.00705643961703788\n",
      "230 Train Loss 0.00085388427 Test MSE 9.180973060185442e-05 Test RE 0.0069424382274834995\n",
      "231 Train Loss 0.0008493925 Test MSE 9.50467395334867e-05 Test RE 0.007063765599519729\n",
      "232 Train Loss 0.00084001006 Test MSE 9.004169317980498e-05 Test RE 0.006875265821885435\n",
      "233 Train Loss 0.00082477886 Test MSE 8.955512539181625e-05 Test RE 0.006856664358879441\n",
      "234 Train Loss 0.0008119639 Test MSE 0.00010023926616963242 Test RE 0.007254151258742593\n",
      "235 Train Loss 0.00080680585 Test MSE 9.845354810201468e-05 Test RE 0.007189246152220716\n",
      "236 Train Loss 0.0008014108 Test MSE 9.751902784352245e-05 Test RE 0.007155044666357663\n",
      "237 Train Loss 0.0007971548 Test MSE 9.207743314424842e-05 Test RE 0.00695255238174991\n",
      "238 Train Loss 0.0007885941 Test MSE 8.918752970563095e-05 Test RE 0.006842577660904631\n",
      "239 Train Loss 0.0007805653 Test MSE 9.270984111210658e-05 Test RE 0.0069763873517176885\n",
      "240 Train Loss 0.0007761851 Test MSE 8.85234151500644e-05 Test RE 0.006817054213175656\n",
      "241 Train Loss 0.00076969515 Test MSE 8.358369454086138e-05 Test RE 0.006624123937937588\n",
      "242 Train Loss 0.0007622163 Test MSE 7.906734744740047e-05 Test RE 0.006442675420522907\n",
      "243 Train Loss 0.0007566442 Test MSE 7.603517304255689e-05 Test RE 0.006317931850180417\n",
      "244 Train Loss 0.0007519165 Test MSE 7.053106425470585e-05 Test RE 0.006084962220232659\n",
      "245 Train Loss 0.00074635027 Test MSE 7.235327962398915e-05 Test RE 0.006163065430050633\n",
      "246 Train Loss 0.0007408001 Test MSE 6.761781809119467e-05 Test RE 0.005957969066044085\n",
      "247 Train Loss 0.00072851556 Test MSE 6.379023202577079e-05 Test RE 0.0057868837559678825\n",
      "248 Train Loss 0.00071873574 Test MSE 6.325503673911715e-05 Test RE 0.005762556861838562\n",
      "249 Train Loss 0.00071375683 Test MSE 6.495811738966588e-05 Test RE 0.0058396172463381505\n",
      "250 Train Loss 0.0007107232 Test MSE 6.27946774235521e-05 Test RE 0.005741549118778217\n",
      "251 Train Loss 0.0007064378 Test MSE 6.28332719781819e-05 Test RE 0.005743313269038617\n",
      "252 Train Loss 0.0007028751 Test MSE 6.411364587502977e-05 Test RE 0.005801534840506021\n",
      "253 Train Loss 0.0007022659 Test MSE 6.44395911707577e-05 Test RE 0.005816263262798332\n",
      "254 Train Loss 0.0006979667 Test MSE 6.56674836108254e-05 Test RE 0.0058714160385050975\n",
      "255 Train Loss 0.00069152866 Test MSE 6.319554576384238e-05 Test RE 0.005759846399648916\n",
      "256 Train Loss 0.0006877961 Test MSE 6.179113246918522e-05 Test RE 0.005695485427795364\n",
      "257 Train Loss 0.0006836466 Test MSE 6.195076573528464e-05 Test RE 0.005702837635584742\n",
      "258 Train Loss 0.00067602785 Test MSE 6.135331060752431e-05 Test RE 0.005675271840710945\n",
      "259 Train Loss 0.0006682504 Test MSE 6.534209315612284e-05 Test RE 0.005856851179269059\n",
      "260 Train Loss 0.0006627316 Test MSE 6.883874375174249e-05 Test RE 0.006011517777531538\n",
      "261 Train Loss 0.00065608043 Test MSE 6.660247645965645e-05 Test RE 0.005913067770040979\n",
      "262 Train Loss 0.0006515396 Test MSE 6.75902108094239e-05 Test RE 0.005956752669775741\n",
      "263 Train Loss 0.00064661994 Test MSE 6.543918066118e-05 Test RE 0.00586120071856635\n",
      "264 Train Loss 0.0006427695 Test MSE 6.536604374213803e-05 Test RE 0.005857924470308383\n",
      "265 Train Loss 0.00063683075 Test MSE 6.63103916694169e-05 Test RE 0.005900087660438497\n",
      "266 Train Loss 0.0006335092 Test MSE 6.693608754965696e-05 Test RE 0.005927858518011382\n",
      "267 Train Loss 0.0006311234 Test MSE 6.5485598812183e-05 Test RE 0.005863279120740882\n",
      "268 Train Loss 0.00062808837 Test MSE 6.617040642271665e-05 Test RE 0.005893856649271712\n",
      "269 Train Loss 0.00062569225 Test MSE 6.583118664926083e-05 Test RE 0.005878729935061595\n",
      "270 Train Loss 0.00062283984 Test MSE 6.649101066514246e-05 Test RE 0.005908117647821562\n",
      "271 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "272 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "273 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "274 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "275 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "276 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "277 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "278 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "279 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "280 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "281 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "282 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "283 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "284 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "285 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "286 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "287 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "288 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "289 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "290 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "291 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "292 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "293 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "294 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "295 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "296 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "297 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "298 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "299 Train Loss 0.000620471 Test MSE 6.719493830004145e-05 Test RE 0.005939309366733823\n",
      "Training time: 174.82\n",
      "KG_stan_medium\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "200 Train Loss nan Test MSE nan Test RE nan\n",
      "201 Train Loss nan Test MSE nan Test RE nan\n",
      "202 Train Loss nan Test MSE nan Test RE nan\n",
      "203 Train Loss nan Test MSE nan Test RE nan\n",
      "204 Train Loss nan Test MSE nan Test RE nan\n",
      "205 Train Loss nan Test MSE nan Test RE nan\n",
      "206 Train Loss nan Test MSE nan Test RE nan\n",
      "207 Train Loss nan Test MSE nan Test RE nan\n",
      "208 Train Loss nan Test MSE nan Test RE nan\n",
      "209 Train Loss nan Test MSE nan Test RE nan\n",
      "210 Train Loss nan Test MSE nan Test RE nan\n",
      "211 Train Loss nan Test MSE nan Test RE nan\n",
      "212 Train Loss nan Test MSE nan Test RE nan\n",
      "213 Train Loss nan Test MSE nan Test RE nan\n",
      "214 Train Loss nan Test MSE nan Test RE nan\n",
      "215 Train Loss nan Test MSE nan Test RE nan\n",
      "216 Train Loss nan Test MSE nan Test RE nan\n",
      "217 Train Loss nan Test MSE nan Test RE nan\n",
      "218 Train Loss nan Test MSE nan Test RE nan\n",
      "219 Train Loss nan Test MSE nan Test RE nan\n",
      "220 Train Loss nan Test MSE nan Test RE nan\n",
      "221 Train Loss nan Test MSE nan Test RE nan\n",
      "222 Train Loss nan Test MSE nan Test RE nan\n",
      "223 Train Loss nan Test MSE nan Test RE nan\n",
      "224 Train Loss nan Test MSE nan Test RE nan\n",
      "225 Train Loss nan Test MSE nan Test RE nan\n",
      "226 Train Loss nan Test MSE nan Test RE nan\n",
      "227 Train Loss nan Test MSE nan Test RE nan\n",
      "228 Train Loss nan Test MSE nan Test RE nan\n",
      "229 Train Loss nan Test MSE nan Test RE nan\n",
      "230 Train Loss nan Test MSE nan Test RE nan\n",
      "231 Train Loss nan Test MSE nan Test RE nan\n",
      "232 Train Loss nan Test MSE nan Test RE nan\n",
      "233 Train Loss nan Test MSE nan Test RE nan\n",
      "234 Train Loss nan Test MSE nan Test RE nan\n",
      "235 Train Loss nan Test MSE nan Test RE nan\n",
      "236 Train Loss nan Test MSE nan Test RE nan\n",
      "237 Train Loss nan Test MSE nan Test RE nan\n",
      "238 Train Loss nan Test MSE nan Test RE nan\n",
      "239 Train Loss nan Test MSE nan Test RE nan\n",
      "240 Train Loss nan Test MSE nan Test RE nan\n",
      "241 Train Loss nan Test MSE nan Test RE nan\n",
      "242 Train Loss nan Test MSE nan Test RE nan\n",
      "243 Train Loss nan Test MSE nan Test RE nan\n",
      "244 Train Loss nan Test MSE nan Test RE nan\n",
      "245 Train Loss nan Test MSE nan Test RE nan\n",
      "246 Train Loss nan Test MSE nan Test RE nan\n",
      "247 Train Loss nan Test MSE nan Test RE nan\n",
      "248 Train Loss nan Test MSE nan Test RE nan\n",
      "249 Train Loss nan Test MSE nan Test RE nan\n",
      "250 Train Loss nan Test MSE nan Test RE nan\n",
      "251 Train Loss nan Test MSE nan Test RE nan\n",
      "252 Train Loss nan Test MSE nan Test RE nan\n",
      "253 Train Loss nan Test MSE nan Test RE nan\n",
      "254 Train Loss nan Test MSE nan Test RE nan\n",
      "255 Train Loss nan Test MSE nan Test RE nan\n",
      "256 Train Loss nan Test MSE nan Test RE nan\n",
      "257 Train Loss nan Test MSE nan Test RE nan\n",
      "258 Train Loss nan Test MSE nan Test RE nan\n",
      "259 Train Loss nan Test MSE nan Test RE nan\n",
      "260 Train Loss nan Test MSE nan Test RE nan\n",
      "261 Train Loss nan Test MSE nan Test RE nan\n",
      "262 Train Loss nan Test MSE nan Test RE nan\n",
      "263 Train Loss nan Test MSE nan Test RE nan\n",
      "264 Train Loss nan Test MSE nan Test RE nan\n",
      "265 Train Loss nan Test MSE nan Test RE nan\n",
      "266 Train Loss nan Test MSE nan Test RE nan\n",
      "267 Train Loss nan Test MSE nan Test RE nan\n",
      "268 Train Loss nan Test MSE nan Test RE nan\n",
      "269 Train Loss nan Test MSE nan Test RE nan\n",
      "270 Train Loss nan Test MSE nan Test RE nan\n",
      "271 Train Loss nan Test MSE nan Test RE nan\n",
      "272 Train Loss nan Test MSE nan Test RE nan\n",
      "273 Train Loss nan Test MSE nan Test RE nan\n",
      "274 Train Loss nan Test MSE nan Test RE nan\n",
      "275 Train Loss nan Test MSE nan Test RE nan\n",
      "276 Train Loss nan Test MSE nan Test RE nan\n",
      "277 Train Loss nan Test MSE nan Test RE nan\n",
      "278 Train Loss nan Test MSE nan Test RE nan\n",
      "279 Train Loss nan Test MSE nan Test RE nan\n",
      "280 Train Loss nan Test MSE nan Test RE nan\n",
      "281 Train Loss nan Test MSE nan Test RE nan\n",
      "282 Train Loss nan Test MSE nan Test RE nan\n",
      "283 Train Loss nan Test MSE nan Test RE nan\n",
      "284 Train Loss nan Test MSE nan Test RE nan\n",
      "285 Train Loss nan Test MSE nan Test RE nan\n",
      "286 Train Loss nan Test MSE nan Test RE nan\n",
      "287 Train Loss nan Test MSE nan Test RE nan\n",
      "288 Train Loss nan Test MSE nan Test RE nan\n",
      "289 Train Loss nan Test MSE nan Test RE nan\n",
      "290 Train Loss nan Test MSE nan Test RE nan\n",
      "291 Train Loss nan Test MSE nan Test RE nan\n",
      "292 Train Loss nan Test MSE nan Test RE nan\n",
      "293 Train Loss nan Test MSE nan Test RE nan\n",
      "294 Train Loss nan Test MSE nan Test RE nan\n",
      "295 Train Loss nan Test MSE nan Test RE nan\n",
      "296 Train Loss nan Test MSE nan Test RE nan\n",
      "297 Train Loss nan Test MSE nan Test RE nan\n",
      "298 Train Loss nan Test MSE nan Test RE nan\n",
      "299 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 19.42\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f625c4c5ed0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.005382861821139276\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
