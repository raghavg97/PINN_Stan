{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "#     y = xt[:,0]*np.cos(xt[:,1])\n",
    "#     return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 25000\n",
    "level = \"_low\"\n",
    "label = \"ES_atanh\" + level\n",
    "ES_val = 10.0\n",
    "\n",
    "x = np.linspace(0,1,500).reshape(-1,1)\n",
    "y = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xy = np.hstack((X,Y))\n",
    "\n",
    "# bound_pts_1 = (X == 0).reshape(-1,)\n",
    "# bound_pts_2 = np.logical_and(Y == 0,X != 0).reshape(-1,)\n",
    "# bound_pts_3 = np.logical_and(X == 1,Y != 0).reshape(-1,) \n",
    "# bound_pts_4 = np.logical_and(Y == 1,X != 1).reshape(-1,) \n",
    "\n",
    "# xy_bound_1 = xy[bound_pts_1,:]\n",
    "# xy_bound_2 = xy[bound_pts_2,:]\n",
    "# xy_bound_3 = xy[bound_pts_3,:]\n",
    "# xy_bound_4 = xy[bound_pts_4,:]\n",
    "\n",
    "# u_bound_1 = 1000*np.ones((np.shape(xy_bound_1)[0],1))\n",
    "# u_bound_2 = 800*np.ones((np.shape(xy_bound_2)[0],1))\n",
    "# u_bound_3 = 500*np.ones((np.shape(xy_bound_3)[0],1))\n",
    "# u_bound_4 = np.zeros((np.shape(xy_bound_4)[0],1))\n",
    "\n",
    "# xy_bound = np.vstack((xy_bound_1,xy_bound_2,xy_bound_3,xy_bound_4))\n",
    "# u_bound = np.vstack((u_bound_1,u_bound_2,u_bound_3,u_bound_4))\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "\n",
    "lb_xy = xy[0]\n",
    "ub_xy = xy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_data = scipy.io.loadmat('./../ES_FEA'+level+'.mat')\n",
    "\n",
    "xy = np.array(fea_data['xy'])\n",
    "u_true = np.array(fea_data['u'])\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "u_true_norm = np.linalg.norm(u_true,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_T,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    N_t = int(N_T/4)\n",
    "    \n",
    "    x_BC1 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC1 = np.zeros((N_t,1))\n",
    "    u_BC1 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC2 = np.ones((N_t,1))\n",
    "    y_BC2 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC2 = ES_val*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC3 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC3 = np.ones((N_t,1)) \n",
    "    u_BC3 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC4 = np.zeros((N_t,1))\n",
    "    y_BC4 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC4 = ES_val*np.ones((N_t,1))\n",
    "    \n",
    "    XY_corners = np.array([[0,0],[1,0],[0,1],[1,1]]).reshape(-1,2)\n",
    "    U_corners = ES_val*np.ones((4,1))\n",
    "    \n",
    "    XY_1 = np.hstack((x_BC1,y_BC1))\n",
    "    XY_2 = np.hstack((x_BC2,y_BC2))\n",
    "    XY_3 = np.hstack((x_BC3,y_BC3))\n",
    "    XY_4 = np.hstack((x_BC4,y_BC4))\n",
    "    \n",
    "    xy_BC = np.vstack((XY_1,XY_2,XY_3,XY_4,XY_corners)) #choose indices from  set 'idx' (x,t)\n",
    "    u_BC = np.vstack((u_BC1,u_BC2,u_BC3,u_BC4,U_corners))\n",
    "    \n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xy_coll = lb_xy + (ub_xy - lb_xy)*samples\n",
    "    \n",
    "    xy_coll = np.vstack((xy_coll, xy_BC)) # append training points to collocation points \n",
    "\n",
    "    return xy_coll, xy_BC, u_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)   \n",
    "        \n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xy):\n",
    "        if torch.is_tensor(xy) != True:         \n",
    "            xy = torch.from_numpy(xy)                \n",
    "        \n",
    "        ubxy = torch.from_numpy(ub_xy).float().to(device)\n",
    "        lbxy = torch.from_numpy(lb_xy).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xy = 2.0*(xy - lbxy)/(ubxy - lbxy) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xy.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "     \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xy,u):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xy), u)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xy_coll, f_hat):\n",
    "        \n",
    "        g = xy_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy = autograd.grad(u_x_y,g,torch.ones(xy_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2u_dx2 + d2u_dy2\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xy_BC,u_BC,xy_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xy_BC,u_BC)\n",
    "        loss_f = self.loss_PDE(xy_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "\n",
    "    def test(self):\n",
    "        u_pred = self.forward(xy_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "     \n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xy_BC,u_BC,xy_coll,f_hat,seed):\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xy_BC,u_BC,xy_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xy_coll_np_array, xy_BC_np_array, u_BC_np_array = trainingdata(N_T,N_f,rep*22)\n",
    "        \n",
    "    xy_coll = torch.from_numpy(xy_coll_np_array).float().to(device)\n",
    "    xy_BC = torch.from_numpy(xy_BC_np_array).float().to(device)\n",
    "    u_BC = torch.from_numpy(u_BC_np_array).float().to(device)\n",
    "        \n",
    "    f_hat = torch.zeros(xy_coll.shape[0],1).to(device)\n",
    "    \n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(xy_BC,u_BC,xy_coll,f_hat,i)\n",
    "        loss_np = PINN.loss(xy_BC,u_BC,xy_coll,f_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "        \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES_atanh_low\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 24.180353 Test MSE 7.09966389122537 Test RE 0.46638474219053644\n",
      "1 Train Loss 15.67234 Test MSE 3.5943007089006755 Test RE 0.33184298687522384\n",
      "2 Train Loss 8.453163 Test MSE 1.589043513191264 Test RE 0.2206446158855668\n",
      "3 Train Loss 5.8161273 Test MSE 1.2804417525368503 Test RE 0.19806391219055652\n",
      "4 Train Loss 4.5285783 Test MSE 0.9290324838561128 Test RE 0.16871002478356367\n",
      "5 Train Loss 3.8009553 Test MSE 0.8239169317300795 Test RE 0.1588792398869208\n",
      "6 Train Loss 3.3146338 Test MSE 0.583696611768272 Test RE 0.13372697653481697\n",
      "7 Train Loss 2.9082146 Test MSE 0.4745993254702823 Test RE 0.12058380887950775\n",
      "8 Train Loss 2.5219166 Test MSE 0.5060697159163121 Test RE 0.12451756350979848\n",
      "9 Train Loss 2.2431917 Test MSE 0.5729769160342244 Test RE 0.13249332596127353\n",
      "10 Train Loss 2.0036983 Test MSE 0.6258568063182529 Test RE 0.13847230748735673\n",
      "11 Train Loss 1.8815008 Test MSE 0.6717362761213267 Test RE 0.1434580227194702\n",
      "12 Train Loss 1.7949482 Test MSE 0.7019544291776447 Test RE 0.14664926775847037\n",
      "13 Train Loss 1.727231 Test MSE 0.6775432487429165 Test RE 0.1440767656652137\n",
      "14 Train Loss 1.6418651 Test MSE 0.735157079612149 Test RE 0.1500774740232456\n",
      "15 Train Loss 1.5490077 Test MSE 0.8062109236206708 Test RE 0.15716280761664989\n",
      "16 Train Loss 1.472018 Test MSE 0.7821967873435111 Test RE 0.15480445452339978\n",
      "17 Train Loss 1.3767805 Test MSE 0.8600068058141115 Test RE 0.16232162566538508\n",
      "18 Train Loss 1.3102459 Test MSE 0.853681634284832 Test RE 0.1617236031228635\n",
      "19 Train Loss 1.2208521 Test MSE 0.8529696401138998 Test RE 0.16165614806882922\n",
      "20 Train Loss 1.1513456 Test MSE 0.8769154523377902 Test RE 0.16390956622392766\n",
      "21 Train Loss 1.0932791 Test MSE 0.83461774138653 Test RE 0.15990765171487095\n",
      "22 Train Loss 1.0058289 Test MSE 0.7906148048544991 Test RE 0.15563522962247298\n",
      "23 Train Loss 0.97785246 Test MSE 0.7860058274999188 Test RE 0.15518092006108622\n",
      "24 Train Loss 0.9409502 Test MSE 0.7873290734109786 Test RE 0.15531148917366133\n",
      "25 Train Loss 0.91200733 Test MSE 0.8556126830527858 Test RE 0.16190641117805163\n",
      "26 Train Loss 0.88317937 Test MSE 0.9211676708048101 Test RE 0.16799439160079668\n",
      "27 Train Loss 0.8488116 Test MSE 0.9314117579349205 Test RE 0.16892592181671298\n",
      "28 Train Loss 0.8264222 Test MSE 0.9411768918434127 Test RE 0.169809141883541\n",
      "29 Train Loss 0.79056 Test MSE 0.9298433623810829 Test RE 0.16878363550237857\n",
      "30 Train Loss 0.77408344 Test MSE 0.8682002917114544 Test RE 0.1630930307199711\n",
      "31 Train Loss 0.7524261 Test MSE 0.8922544796863326 Test RE 0.16533690666050938\n",
      "32 Train Loss 0.73043066 Test MSE 0.896388335253216 Test RE 0.1657194707657806\n",
      "33 Train Loss 0.7107308 Test MSE 0.8854879057375186 Test RE 0.16470878228549068\n",
      "34 Train Loss 0.6897582 Test MSE 0.8602920551929533 Test RE 0.16234854307104524\n",
      "35 Train Loss 0.67277867 Test MSE 0.817334961711239 Test RE 0.15824335340231072\n",
      "36 Train Loss 0.6551559 Test MSE 0.8492521356548133 Test RE 0.16130348975415812\n",
      "37 Train Loss 0.63782865 Test MSE 0.8461334102279516 Test RE 0.1610070383386901\n",
      "38 Train Loss 0.6287811 Test MSE 0.8346992332464845 Test RE 0.15991545819515438\n",
      "39 Train Loss 0.6179488 Test MSE 0.8411616202733919 Test RE 0.16053331130178702\n",
      "40 Train Loss 0.61260074 Test MSE 0.8573655973736414 Test RE 0.16207217710229316\n",
      "41 Train Loss 0.60336185 Test MSE 0.8648381055341041 Test RE 0.16277692794252788\n",
      "42 Train Loss 0.5857593 Test MSE 0.8752420009077445 Test RE 0.16375309407826444\n",
      "43 Train Loss 0.5789315 Test MSE 0.8822013501292292 Test RE 0.1644028335566747\n",
      "44 Train Loss 0.56793386 Test MSE 0.915685086765925 Test RE 0.16749371297633023\n",
      "45 Train Loss 0.5498071 Test MSE 0.8882346241007736 Test RE 0.16496404175457127\n",
      "46 Train Loss 0.5356361 Test MSE 0.8673808727706255 Test RE 0.16301604786946197\n",
      "47 Train Loss 0.5261091 Test MSE 0.8831585069044231 Test RE 0.16449199496343422\n",
      "48 Train Loss 0.5149912 Test MSE 0.8883808890193308 Test RE 0.16497762344698438\n",
      "49 Train Loss 0.50333464 Test MSE 0.873677905789327 Test RE 0.16360671173832325\n",
      "50 Train Loss 0.4939173 Test MSE 0.8951667424322166 Test RE 0.16560651150110767\n",
      "51 Train Loss 0.48905423 Test MSE 0.8957377360187062 Test RE 0.16565932019984264\n",
      "52 Train Loss 0.48143137 Test MSE 0.8727317715837528 Test RE 0.16351810022843136\n",
      "53 Train Loss 0.4716815 Test MSE 0.8721757603608604 Test RE 0.16346600381849435\n",
      "54 Train Loss 0.4617859 Test MSE 0.8889741465757849 Test RE 0.16503269998476558\n",
      "55 Train Loss 0.45708796 Test MSE 0.8720886294994871 Test RE 0.16345783844053818\n",
      "56 Train Loss 0.4532823 Test MSE 0.866835183471632 Test RE 0.16296476122528544\n",
      "57 Train Loss 0.45025596 Test MSE 0.8847190006607122 Test RE 0.16463725509530827\n",
      "58 Train Loss 0.44387323 Test MSE 0.8897411766988886 Test RE 0.1651038818966489\n",
      "59 Train Loss 0.44063824 Test MSE 0.8964551709345722 Test RE 0.16572564876188764\n",
      "60 Train Loss 0.43607116 Test MSE 0.8835443782458875 Test RE 0.16452792612110045\n",
      "61 Train Loss 0.4315203 Test MSE 0.8955033914100077 Test RE 0.1656376487292377\n",
      "62 Train Loss 0.42928964 Test MSE 0.9007672020512536 Test RE 0.1661237483535811\n",
      "63 Train Loss 0.42679986 Test MSE 0.886472026376702 Test RE 0.1648002845515977\n",
      "64 Train Loss 0.42356366 Test MSE 0.8791305353095529 Test RE 0.16411645292947682\n",
      "65 Train Loss 0.4208974 Test MSE 0.8824951683548488 Test RE 0.16443020855872664\n",
      "66 Train Loss 0.41792277 Test MSE 0.8860779261385424 Test RE 0.16476364772068128\n",
      "67 Train Loss 0.41404408 Test MSE 0.872403031213856 Test RE 0.16348730035064368\n",
      "68 Train Loss 0.41009694 Test MSE 0.8768664217901422 Test RE 0.16390498386190253\n",
      "69 Train Loss 0.4079495 Test MSE 0.8788499173761939 Test RE 0.16409025790286141\n",
      "70 Train Loss 0.40600446 Test MSE 0.8743470676401796 Test RE 0.16366935405444513\n",
      "71 Train Loss 0.40389752 Test MSE 0.8722632899969323 Test RE 0.16347420615654928\n",
      "72 Train Loss 0.40016565 Test MSE 0.8611982320858058 Test RE 0.16243402437767407\n",
      "73 Train Loss 0.39663273 Test MSE 0.8528410453480807 Test RE 0.16164396186834992\n",
      "74 Train Loss 0.38933307 Test MSE 0.8770320608810391 Test RE 0.1639204638653896\n",
      "75 Train Loss 0.38568693 Test MSE 0.8504446698670812 Test RE 0.16141670256848087\n",
      "76 Train Loss 0.38270125 Test MSE 0.8299817539349456 Test RE 0.1594629198627135\n",
      "77 Train Loss 0.37977734 Test MSE 0.8350044608292593 Test RE 0.15994469396382138\n",
      "78 Train Loss 0.3780063 Test MSE 0.835057630358971 Test RE 0.15994978618139846\n",
      "79 Train Loss 0.37596783 Test MSE 0.8395963646396072 Test RE 0.1603838794519231\n",
      "80 Train Loss 0.37337756 Test MSE 0.8376430127104385 Test RE 0.16019720130289353\n",
      "81 Train Loss 0.36968255 Test MSE 0.8403814383227358 Test RE 0.16045884627401386\n",
      "82 Train Loss 0.3679822 Test MSE 0.850108751691512 Test RE 0.16138482032993245\n",
      "83 Train Loss 0.3664274 Test MSE 0.8441359322735147 Test RE 0.16081688035881056\n",
      "84 Train Loss 0.36510414 Test MSE 0.8452364917951884 Test RE 0.16092168036294713\n",
      "85 Train Loss 0.36410317 Test MSE 0.845109601504193 Test RE 0.16090960080564867\n",
      "86 Train Loss 0.36345655 Test MSE 0.8420568525386164 Test RE 0.16061871485481155\n",
      "87 Train Loss 0.36285317 Test MSE 0.8396168696983692 Test RE 0.1603858379291938\n",
      "88 Train Loss 0.3622491 Test MSE 0.8374253722153585 Test RE 0.1601763883415893\n",
      "89 Train Loss 0.36104065 Test MSE 0.8471600643504327 Test RE 0.16110468749596382\n",
      "90 Train Loss 0.3600113 Test MSE 0.8472768960011319 Test RE 0.1611157960682829\n",
      "91 Train Loss 0.3584864 Test MSE 0.8417899703771397 Test RE 0.16059325952675357\n",
      "92 Train Loss 0.357039 Test MSE 0.8495806546581064 Test RE 0.1613346855179084\n",
      "93 Train Loss 0.35528 Test MSE 0.8503509779491917 Test RE 0.16140781083364364\n",
      "94 Train Loss 0.35293096 Test MSE 0.8509397187062545 Test RE 0.16146367653900912\n",
      "95 Train Loss 0.3509883 Test MSE 0.8563338038941521 Test RE 0.16197462516066385\n",
      "96 Train Loss 0.3497122 Test MSE 0.8577806054154337 Test RE 0.16211139789652979\n",
      "97 Train Loss 0.34867775 Test MSE 0.8526893776809864 Test RE 0.16162958799832788\n",
      "98 Train Loss 0.34789374 Test MSE 0.8538246412412811 Test RE 0.1617371483549788\n",
      "99 Train Loss 0.3467253 Test MSE 0.8557534733680373 Test RE 0.1619197314089699\n",
      "100 Train Loss 0.34546095 Test MSE 0.8544661674629557 Test RE 0.16179789803007713\n",
      "101 Train Loss 0.34449396 Test MSE 0.8510359230540497 Test RE 0.16147280354785354\n",
      "102 Train Loss 0.34318724 Test MSE 0.855808140342424 Test RE 0.16192490317906774\n",
      "103 Train Loss 0.3415808 Test MSE 0.8621925169734435 Test RE 0.1625277653425834\n",
      "104 Train Loss 0.34053805 Test MSE 0.8610208629384118 Test RE 0.16241729636609029\n",
      "105 Train Loss 0.33993077 Test MSE 0.8656823897950291 Test RE 0.162856362736642\n",
      "106 Train Loss 0.33828157 Test MSE 0.8767416952452229 Test RE 0.16389332642535015\n",
      "107 Train Loss 0.33621776 Test MSE 0.8829027593589881 Test RE 0.16446817620969909\n",
      "108 Train Loss 0.3354805 Test MSE 0.8797966371987083 Test RE 0.164178615245339\n",
      "109 Train Loss 0.3331521 Test MSE 0.8724523297134625 Test RE 0.16349191952576458\n",
      "110 Train Loss 0.33039573 Test MSE 0.8726746063984492 Test RE 0.16351274480544872\n",
      "111 Train Loss 0.32898164 Test MSE 0.8676393711078729 Test RE 0.16304033722117411\n",
      "112 Train Loss 0.3282306 Test MSE 0.8665867187406052 Test RE 0.16294140390299386\n",
      "113 Train Loss 0.32744676 Test MSE 0.8620694808726138 Test RE 0.16251616845698422\n",
      "114 Train Loss 0.327049 Test MSE 0.8659695742730942 Test RE 0.1628833737639143\n",
      "115 Train Loss 0.3257712 Test MSE 0.8591042434793403 Test RE 0.16223642643012476\n",
      "116 Train Loss 0.3240261 Test MSE 0.8534991891717126 Test RE 0.16170632076811578\n",
      "117 Train Loss 0.32169753 Test MSE 0.8632453671928734 Test RE 0.16262696893268017\n",
      "118 Train Loss 0.3201555 Test MSE 0.8697847958487808 Test RE 0.16324178889487745\n",
      "119 Train Loss 0.31974667 Test MSE 0.8689913209742897 Test RE 0.1631673119592585\n",
      "120 Train Loss 0.31863984 Test MSE 0.8768831183345375 Test RE 0.16390654432410323\n",
      "121 Train Loss 0.31678745 Test MSE 0.8836950035187162 Test RE 0.16454194975605202\n",
      "122 Train Loss 0.31537783 Test MSE 0.8850584110617262 Test RE 0.16466883248790307\n",
      "123 Train Loss 0.31457758 Test MSE 0.8846909509057436 Test RE 0.16463464518681495\n",
      "124 Train Loss 0.31365383 Test MSE 0.8844291890969445 Test RE 0.1646102873866827\n",
      "125 Train Loss 0.31287116 Test MSE 0.8789673103889121 Test RE 0.16410121677429443\n",
      "126 Train Loss 0.31188563 Test MSE 0.8777018886288549 Test RE 0.16398304853221973\n",
      "127 Train Loss 0.31130373 Test MSE 0.8785231809188585 Test RE 0.16405975255003666\n",
      "128 Train Loss 0.31107017 Test MSE 0.8748632192642201 Test RE 0.16371765623457576\n",
      "129 Train Loss 0.3105713 Test MSE 0.8775122965852931 Test RE 0.16396533661841786\n",
      "130 Train Loss 0.30973682 Test MSE 0.8766361735647457 Test RE 0.1638834633039089\n",
      "131 Train Loss 0.3091243 Test MSE 0.8756906560716597 Test RE 0.1637950591910349\n",
      "132 Train Loss 0.30773288 Test MSE 0.8662154209800355 Test RE 0.162906493224762\n",
      "133 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "134 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "135 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "136 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "137 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "138 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "139 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "140 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "141 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "142 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "143 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "144 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "145 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "146 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "147 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "148 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "149 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "150 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "151 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "152 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "153 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "154 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "155 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "156 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "157 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "158 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "159 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "160 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "161 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "162 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "163 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "164 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "165 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "166 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "167 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "168 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "169 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "170 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "171 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "172 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "173 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "174 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "175 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "176 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "177 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "178 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "179 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "180 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "181 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "182 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "183 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "184 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "185 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "186 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "187 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "188 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "189 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "190 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "191 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "192 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "193 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "194 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "195 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "196 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "197 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "198 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "199 Train Loss 0.30743408 Test MSE 0.862502067088723 Test RE 0.16255693862616924\n",
      "Training time: 123.19\n",
      "Training time: 123.19\n",
      "ES_atanh_low\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 24.795296 Test MSE 7.413829159861197 Test RE 0.4765919764025072\n",
      "1 Train Loss 22.846806 Test MSE 6.466977838465706 Test RE 0.44511899302038604\n",
      "2 Train Loss 18.394167 Test MSE 5.038577722748138 Test RE 0.3928976403679342\n",
      "3 Train Loss 12.90702 Test MSE 2.9493611893804874 Test RE 0.3006003071580498\n",
      "4 Train Loss 9.360671 Test MSE 1.6666081752481743 Test RE 0.22596552939078096\n",
      "5 Train Loss 6.1648974 Test MSE 1.2775999418814044 Test RE 0.1978439987174125\n",
      "6 Train Loss 5.249568 Test MSE 1.1379599374185922 Test RE 0.18671917759084933\n",
      "7 Train Loss 4.767982 Test MSE 1.0802254784025898 Test RE 0.1819209216981824\n",
      "8 Train Loss 4.6028185 Test MSE 1.015335511381453 Test RE 0.17637223869043173\n",
      "9 Train Loss 4.425296 Test MSE 0.9037157339742634 Test RE 0.1663954173203159\n",
      "10 Train Loss 4.236821 Test MSE 0.8913787729508321 Test RE 0.1652557514582166\n",
      "11 Train Loss 4.106874 Test MSE 0.836799124547434 Test RE 0.16011648518269342\n",
      "12 Train Loss 3.791619 Test MSE 0.7337583532354766 Test RE 0.14993463566207219\n",
      "13 Train Loss 3.629576 Test MSE 0.7023021935994443 Test RE 0.14668558997589953\n",
      "14 Train Loss 3.4053328 Test MSE 0.6325109730567654 Test RE 0.13920648629447885\n",
      "15 Train Loss 3.2127423 Test MSE 0.566191326559436 Test RE 0.1317064504771376\n",
      "16 Train Loss 2.9646344 Test MSE 0.5260876737528678 Test RE 0.12695637184662914\n",
      "17 Train Loss 2.7228074 Test MSE 0.5673780906829107 Test RE 0.13184440973510514\n",
      "18 Train Loss 2.4948344 Test MSE 0.5750987593225062 Test RE 0.13273842334455727\n",
      "19 Train Loss 2.2985284 Test MSE 0.6494185942167648 Test RE 0.14105477713680895\n",
      "20 Train Loss 2.1882782 Test MSE 0.7162047879691356 Test RE 0.14813035017621543\n",
      "21 Train Loss 2.0194862 Test MSE 0.6464737121522341 Test RE 0.1407345971567271\n",
      "22 Train Loss 1.9359243 Test MSE 0.6373388579602448 Test RE 0.13973675006009192\n",
      "23 Train Loss 1.8758175 Test MSE 0.7369525158452931 Test RE 0.15026062550472516\n",
      "24 Train Loss 1.761252 Test MSE 0.8044812780399561 Test RE 0.15699412848842295\n",
      "25 Train Loss 1.6764064 Test MSE 0.7463675729991858 Test RE 0.15121741885936996\n",
      "26 Train Loss 1.617211 Test MSE 0.7264626652311691 Test RE 0.1491873807948265\n",
      "27 Train Loss 1.5653217 Test MSE 0.7744796512066215 Test RE 0.1540389129834699\n",
      "28 Train Loss 1.4938581 Test MSE 0.7125923739494263 Test RE 0.14775630589573724\n",
      "29 Train Loss 1.4432106 Test MSE 0.7112353614188927 Test RE 0.14761555031445808\n",
      "30 Train Loss 1.3755877 Test MSE 0.7443965780341026 Test RE 0.1510176206548481\n",
      "31 Train Loss 1.3414705 Test MSE 0.7456024234327946 Test RE 0.15113988761621158\n",
      "32 Train Loss 1.2974977 Test MSE 0.7747004672629494 Test RE 0.15406087084968437\n",
      "33 Train Loss 1.262138 Test MSE 0.7760730097959221 Test RE 0.15419728584527106\n",
      "34 Train Loss 1.2058183 Test MSE 0.7588301357715889 Test RE 0.15247467784386265\n",
      "35 Train Loss 1.161556 Test MSE 0.8030031841819066 Test RE 0.15684983753335652\n",
      "36 Train Loss 1.1288134 Test MSE 0.769583500583713 Test RE 0.15355123491207887\n",
      "37 Train Loss 1.0804443 Test MSE 0.7705194244134238 Test RE 0.15364457669539378\n",
      "38 Train Loss 1.0529205 Test MSE 0.8061556500742372 Test RE 0.15715742001001462\n",
      "39 Train Loss 1.0048403 Test MSE 0.8385715046408305 Test RE 0.1602859626312571\n",
      "40 Train Loss 0.97964066 Test MSE 0.8166387135796579 Test RE 0.15817593911206204\n",
      "41 Train Loss 0.947801 Test MSE 0.7683971495666229 Test RE 0.15343283585461243\n",
      "42 Train Loss 0.9238185 Test MSE 0.7663441638818296 Test RE 0.15322772961712414\n",
      "43 Train Loss 0.89809215 Test MSE 0.7846675483231839 Test RE 0.15504875573053245\n",
      "44 Train Loss 0.8713455 Test MSE 0.7843314830134341 Test RE 0.15501554925436162\n",
      "45 Train Loss 0.85135233 Test MSE 0.7700805992357841 Test RE 0.15360081873878742\n",
      "46 Train Loss 0.8251823 Test MSE 0.793864011419488 Test RE 0.15595471042990053\n",
      "47 Train Loss 0.8007365 Test MSE 0.7609484045213875 Test RE 0.15268734550381755\n",
      "48 Train Loss 0.779931 Test MSE 0.7648916767265604 Test RE 0.15308245098298678\n",
      "49 Train Loss 0.76689607 Test MSE 0.771489125381724 Test RE 0.15374122737264034\n",
      "50 Train Loss 0.7436125 Test MSE 0.7825437400374702 Test RE 0.1548387833961435\n",
      "51 Train Loss 0.71767277 Test MSE 0.758273366641662 Test RE 0.15241873069087142\n",
      "52 Train Loss 0.70585024 Test MSE 0.763815494232322 Test RE 0.15297472158313258\n",
      "53 Train Loss 0.6816749 Test MSE 0.7858332694886433 Test RE 0.15516388508509865\n",
      "54 Train Loss 0.66370815 Test MSE 0.7951211342765785 Test RE 0.15607814257592162\n",
      "55 Train Loss 0.6486293 Test MSE 0.8125086939098665 Test RE 0.15777545737152457\n",
      "56 Train Loss 0.6218672 Test MSE 0.8406328619027117 Test RE 0.1604828473518201\n",
      "57 Train Loss 0.6054722 Test MSE 0.8382863265537188 Test RE 0.16025870560496608\n",
      "58 Train Loss 0.59684443 Test MSE 0.8564884989426365 Test RE 0.16198925470166226\n",
      "59 Train Loss 0.58649737 Test MSE 0.8936546243211315 Test RE 0.16546658089712352\n",
      "60 Train Loss 0.57265353 Test MSE 0.8758840263242131 Test RE 0.16381314282788823\n",
      "61 Train Loss 0.56050885 Test MSE 0.882465362774841 Test RE 0.16442743178481628\n",
      "62 Train Loss 0.5534572 Test MSE 0.8772868548169578 Test RE 0.16394427309028906\n",
      "63 Train Loss 0.54324794 Test MSE 0.8823644745554161 Test RE 0.16441803239891722\n",
      "64 Train Loss 0.5345876 Test MSE 0.8921080300602232 Test RE 0.16532333736925706\n",
      "65 Train Loss 0.52834237 Test MSE 0.8938947685236325 Test RE 0.16548881161686624\n",
      "66 Train Loss 0.5191115 Test MSE 0.8729481721647312 Test RE 0.16353837175961214\n",
      "67 Train Loss 0.50845116 Test MSE 0.8618473782246894 Test RE 0.16249523186351242\n",
      "68 Train Loss 0.5029853 Test MSE 0.8457100779538285 Test RE 0.16096675627307153\n",
      "69 Train Loss 0.49855757 Test MSE 0.8325578587536651 Test RE 0.15971019935538783\n",
      "70 Train Loss 0.48496592 Test MSE 0.8022539538229748 Test RE 0.1567766472353701\n",
      "71 Train Loss 0.4742419 Test MSE 0.8202475081388785 Test RE 0.1585250501805944\n",
      "72 Train Loss 0.4660778 Test MSE 0.8243978676513342 Test RE 0.15892560353313076\n",
      "73 Train Loss 0.45711872 Test MSE 0.8412181650960269 Test RE 0.16053870692068548\n",
      "74 Train Loss 0.44980097 Test MSE 0.8577360708005344 Test RE 0.1621071895579756\n",
      "75 Train Loss 0.43964246 Test MSE 0.8485459266408866 Test RE 0.16123640857458146\n",
      "76 Train Loss 0.43226916 Test MSE 0.8606521183293514 Test RE 0.16238251386624167\n",
      "77 Train Loss 0.41764823 Test MSE 0.9162736625213799 Test RE 0.1675475343739008\n",
      "78 Train Loss 0.4101437 Test MSE 0.9160680728061791 Test RE 0.16752873650612607\n",
      "79 Train Loss 0.4065013 Test MSE 0.9288820059245089 Test RE 0.1686963610182483\n",
      "80 Train Loss 0.3962843 Test MSE 0.9278980150633336 Test RE 0.16860698493992507\n",
      "81 Train Loss 0.39160696 Test MSE 0.9173260520787125 Test RE 0.1676437254366981\n",
      "82 Train Loss 0.38829377 Test MSE 0.9100387676155041 Test RE 0.16697651259275365\n",
      "83 Train Loss 0.38408425 Test MSE 0.9209924474387581 Test RE 0.16797841299902533\n",
      "84 Train Loss 0.37703744 Test MSE 0.9467835530440581 Test RE 0.17031417375717367\n",
      "85 Train Loss 0.37338573 Test MSE 0.93347683481379 Test RE 0.16911308494102073\n",
      "86 Train Loss 0.36839467 Test MSE 0.9448161682627423 Test RE 0.17013712813707838\n",
      "87 Train Loss 0.35921702 Test MSE 0.9813935724334709 Test RE 0.17339918189331413\n",
      "88 Train Loss 0.3545702 Test MSE 0.9739394256950884 Test RE 0.17273940241427949\n",
      "89 Train Loss 0.35134992 Test MSE 0.9669258960822518 Test RE 0.17211631341273229\n",
      "90 Train Loss 0.34512967 Test MSE 0.9743287732576386 Test RE 0.17277392660707244\n",
      "91 Train Loss 0.34142753 Test MSE 0.9744671202218075 Test RE 0.1727861924358408\n",
      "92 Train Loss 0.33686343 Test MSE 0.9650127806207918 Test RE 0.17194595836442092\n",
      "93 Train Loss 0.33143258 Test MSE 0.9558165664925139 Test RE 0.17112470649759\n",
      "94 Train Loss 0.32854998 Test MSE 0.9518078270738898 Test RE 0.17076547693099786\n",
      "95 Train Loss 0.326222 Test MSE 0.9537804052508616 Test RE 0.17094233716400045\n",
      "96 Train Loss 0.32469344 Test MSE 0.9400524599671755 Test RE 0.16970767537028242\n",
      "97 Train Loss 0.32255825 Test MSE 0.9362839429945785 Test RE 0.16936716857443437\n",
      "98 Train Loss 0.31922418 Test MSE 0.927914528431617 Test RE 0.16860848524319372\n",
      "99 Train Loss 0.317115 Test MSE 0.9258497302024878 Test RE 0.16842078671127553\n",
      "100 Train Loss 0.31463027 Test MSE 0.9062963189082054 Test RE 0.16663282128966947\n",
      "101 Train Loss 0.31385773 Test MSE 0.9139797708074932 Test RE 0.16733767526499943\n",
      "102 Train Loss 0.31153524 Test MSE 0.9093928956568729 Test RE 0.16691724885978937\n",
      "103 Train Loss 0.30927578 Test MSE 0.9113577092467662 Test RE 0.1670974703708686\n",
      "104 Train Loss 0.3078864 Test MSE 0.9156991508432205 Test RE 0.16749499924576655\n",
      "105 Train Loss 0.30658624 Test MSE 0.9241044257228156 Test RE 0.16826196816726216\n",
      "106 Train Loss 0.30451035 Test MSE 0.9422823882844718 Test RE 0.16990884062854156\n",
      "107 Train Loss 0.30179936 Test MSE 0.9180456563568192 Test RE 0.1677094673243911\n",
      "108 Train Loss 0.2983307 Test MSE 0.9188419056237669 Test RE 0.1677821813536558\n",
      "109 Train Loss 0.29477096 Test MSE 0.9190426388842766 Test RE 0.16780050747966369\n",
      "110 Train Loss 0.29210097 Test MSE 0.9163618353409929 Test RE 0.16755559571176432\n",
      "111 Train Loss 0.28921685 Test MSE 0.922745199531228 Test RE 0.168138177917889\n",
      "112 Train Loss 0.28740522 Test MSE 0.926749686491734 Test RE 0.16850262209239006\n",
      "113 Train Loss 0.28521854 Test MSE 0.9431068238011264 Test RE 0.16998315394373156\n",
      "114 Train Loss 0.28380165 Test MSE 0.9529865236867725 Test RE 0.1708711802078357\n",
      "115 Train Loss 0.28021896 Test MSE 0.9490556367179737 Test RE 0.1705184106019206\n",
      "116 Train Loss 0.27684864 Test MSE 0.9460191425410122 Test RE 0.170245406069196\n",
      "117 Train Loss 0.27421907 Test MSE 0.9504974797409367 Test RE 0.17064789061426386\n",
      "118 Train Loss 0.27134866 Test MSE 0.9789066595195607 Test RE 0.17317934032635862\n",
      "119 Train Loss 0.2692989 Test MSE 0.9708990194626343 Test RE 0.17246956608334502\n",
      "120 Train Loss 0.26833457 Test MSE 0.9691720350989547 Test RE 0.17231610789315815\n",
      "121 Train Loss 0.2677338 Test MSE 0.9619989852426362 Test RE 0.17167724940088072\n",
      "122 Train Loss 0.2663591 Test MSE 0.9579559673501556 Test RE 0.17131611336534416\n",
      "123 Train Loss 0.26421437 Test MSE 0.9615648447200722 Test RE 0.17163850691637664\n",
      "124 Train Loss 0.26337734 Test MSE 0.9520922677439775 Test RE 0.170790991019532\n",
      "125 Train Loss 0.26305827 Test MSE 0.9506942166920945 Test RE 0.17066555031845465\n",
      "126 Train Loss 0.26136374 Test MSE 0.9529749710438657 Test RE 0.1708701445060385\n",
      "127 Train Loss 0.26029912 Test MSE 0.9470478933116415 Test RE 0.1703379478035858\n",
      "128 Train Loss 0.25970864 Test MSE 0.9494976205632434 Test RE 0.17055811196780038\n",
      "129 Train Loss 0.25941074 Test MSE 0.9514649031780509 Test RE 0.17073471187713435\n",
      "130 Train Loss 0.25917396 Test MSE 0.9543565570511218 Test RE 0.1709939600877262\n",
      "131 Train Loss 0.25796872 Test MSE 0.9448305871591888 Test RE 0.17013842636860485\n",
      "132 Train Loss 0.25692284 Test MSE 0.9377586691935903 Test RE 0.16950049988258784\n",
      "133 Train Loss 0.25613758 Test MSE 0.9382632852764627 Test RE 0.16954609859456507\n",
      "134 Train Loss 0.25448927 Test MSE 0.9386824154511386 Test RE 0.1695839632072061\n",
      "135 Train Loss 0.25334236 Test MSE 0.9348819603544727 Test RE 0.1692403166790703\n",
      "136 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "137 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "138 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "139 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "140 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "141 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "142 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "143 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "144 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "145 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "146 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "147 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "148 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "149 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "150 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "151 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "152 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "153 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "154 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "155 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "156 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "157 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "158 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "159 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "160 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "161 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "162 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "163 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "164 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "165 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "166 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "167 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "168 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "169 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "170 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "171 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "172 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "173 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "174 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "175 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "176 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "177 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "178 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "179 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "180 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "181 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "182 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "183 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "184 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "185 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "186 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "187 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "188 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "189 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "190 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "191 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "192 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "193 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "194 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "195 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "196 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "197 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "198 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "199 Train Loss 0.25299823 Test MSE 0.9314043923054565 Test RE 0.16892525388000496\n",
      "Training time: 114.13\n",
      "Training time: 114.13\n",
      "ES_atanh_low\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 23.99867 Test MSE 6.901214144523377 Test RE 0.45982035390671233\n",
      "1 Train Loss 16.602127 Test MSE 4.198256321510994 Test RE 0.35864098181183385\n",
      "2 Train Loss 10.77733 Test MSE 2.3855620061866176 Test RE 0.27034652660231423\n",
      "3 Train Loss 6.403795 Test MSE 1.3329805237405887 Test RE 0.2020865182337586\n",
      "4 Train Loss 4.802236 Test MSE 0.9035868788366668 Test RE 0.16638355425988466\n",
      "5 Train Loss 4.2828083 Test MSE 0.7936657787161586 Test RE 0.15593523779127597\n",
      "6 Train Loss 3.9077084 Test MSE 0.6700415964557682 Test RE 0.14327694799466253\n",
      "7 Train Loss 3.5804384 Test MSE 0.5938468733818495 Test RE 0.13488469573072537\n",
      "8 Train Loss 3.0694718 Test MSE 0.48210611884976595 Test RE 0.12153371158284809\n",
      "9 Train Loss 2.7118042 Test MSE 0.42859457260813627 Test RE 0.11459054186132547\n",
      "10 Train Loss 2.4681196 Test MSE 0.4760106146719585 Test RE 0.12076296242372163\n",
      "11 Train Loss 2.2141056 Test MSE 0.5450849041732583 Test RE 0.12922826595744866\n",
      "12 Train Loss 2.0542128 Test MSE 0.5713223085200252 Test RE 0.13230188461238998\n",
      "13 Train Loss 1.8839667 Test MSE 0.5896103517260137 Test RE 0.13440269878598404\n",
      "14 Train Loss 1.7069948 Test MSE 0.6063754863433325 Test RE 0.13630012604815872\n",
      "15 Train Loss 1.5988097 Test MSE 0.6154376463721372 Test RE 0.13731483796505406\n",
      "16 Train Loss 1.4636742 Test MSE 0.6930755636021143 Test RE 0.14571884923256714\n",
      "17 Train Loss 1.3743819 Test MSE 0.7566097834620744 Test RE 0.15225144243233377\n",
      "18 Train Loss 1.2983426 Test MSE 0.7612140852391307 Test RE 0.15271399812774558\n",
      "19 Train Loss 1.2356055 Test MSE 0.7338011260357866 Test RE 0.14993900565032886\n",
      "20 Train Loss 1.183404 Test MSE 0.7509121375263106 Test RE 0.15167709477121152\n",
      "21 Train Loss 1.1460184 Test MSE 0.7450334991319716 Test RE 0.1510822137397921\n",
      "22 Train Loss 1.090179 Test MSE 0.795510865308761 Test RE 0.1561163889770005\n",
      "23 Train Loss 1.0599325 Test MSE 0.7696945563232043 Test RE 0.15356231371689333\n",
      "24 Train Loss 1.0089356 Test MSE 0.811096296598317 Test RE 0.15763826588048072\n",
      "25 Train Loss 0.98643327 Test MSE 0.7886039906715796 Test RE 0.15543718579215163\n",
      "26 Train Loss 0.94688493 Test MSE 0.7614454599849184 Test RE 0.15273720544786107\n",
      "27 Train Loss 0.9198894 Test MSE 0.7657472880613808 Test RE 0.1531680464184122\n",
      "28 Train Loss 0.89210105 Test MSE 0.7697180565484146 Test RE 0.15356465797240446\n",
      "29 Train Loss 0.8691763 Test MSE 0.811496290287688 Test RE 0.15767713089558297\n",
      "30 Train Loss 0.8477992 Test MSE 0.7719179687196562 Test RE 0.1537839510736887\n",
      "31 Train Loss 0.8290677 Test MSE 0.7908469523306192 Test RE 0.15565807745791152\n",
      "32 Train Loss 0.8055397 Test MSE 0.8243406327402255 Test RE 0.15892008662738014\n",
      "33 Train Loss 0.7875823 Test MSE 0.8053694458248047 Test RE 0.15708076733685578\n",
      "34 Train Loss 0.74582845 Test MSE 0.8124057206100986 Test RE 0.1577654592174264\n",
      "35 Train Loss 0.72026336 Test MSE 0.846798672633189 Test RE 0.16107032084396108\n",
      "36 Train Loss 0.70738065 Test MSE 0.8405878049634239 Test RE 0.16047854644762535\n",
      "37 Train Loss 0.6854183 Test MSE 0.858036700888501 Test RE 0.1621355957488844\n",
      "38 Train Loss 0.6724943 Test MSE 0.8725537975312577 Test RE 0.16350142645549978\n",
      "39 Train Loss 0.6621589 Test MSE 0.8612983738511583 Test RE 0.16244346817150868\n",
      "40 Train Loss 0.6454184 Test MSE 0.8464681806069637 Test RE 0.16103888618695245\n",
      "41 Train Loss 0.6279741 Test MSE 0.8445474204892663 Test RE 0.160856072025792\n",
      "42 Train Loss 0.6144347 Test MSE 0.8486343240320203 Test RE 0.1612448067686254\n",
      "43 Train Loss 0.5952318 Test MSE 0.843764569922396 Test RE 0.16078150222699442\n",
      "44 Train Loss 0.57199055 Test MSE 0.8347488366338767 Test RE 0.15992020974533083\n",
      "45 Train Loss 0.5579147 Test MSE 0.8446910654002455 Test RE 0.16086975105266868\n",
      "46 Train Loss 0.55191666 Test MSE 0.8475739239539756 Test RE 0.16114403459446872\n",
      "47 Train Loss 0.53917456 Test MSE 0.8816797157658337 Test RE 0.16435422172441774\n",
      "48 Train Loss 0.52664715 Test MSE 0.9095360797639583 Test RE 0.16693038892095668\n",
      "49 Train Loss 0.5155517 Test MSE 0.9025022399031176 Test RE 0.1662836633284513\n",
      "50 Train Loss 0.5061187 Test MSE 0.8910395244458652 Test RE 0.1652243012467313\n",
      "51 Train Loss 0.4924293 Test MSE 0.891021388788208 Test RE 0.16522261980245803\n",
      "52 Train Loss 0.47756475 Test MSE 0.9056196454096095 Test RE 0.16657060263855225\n",
      "53 Train Loss 0.46797186 Test MSE 0.9222243287260761 Test RE 0.16809071593668426\n",
      "54 Train Loss 0.46126395 Test MSE 0.9089883854345062 Test RE 0.16688012120909623\n",
      "55 Train Loss 0.4549717 Test MSE 0.9068980237022827 Test RE 0.16668812722502785\n",
      "56 Train Loss 0.44648904 Test MSE 0.9186417991009757 Test RE 0.1677639104537033\n",
      "57 Train Loss 0.44001037 Test MSE 0.9189542833961445 Test RE 0.16779244123144127\n",
      "58 Train Loss 0.43159705 Test MSE 0.9215492169797245 Test RE 0.16802917950295895\n",
      "59 Train Loss 0.41571575 Test MSE 0.898157578978707 Test RE 0.16588293429502868\n",
      "60 Train Loss 0.40288553 Test MSE 0.8746992071992187 Test RE 0.16370230930440152\n",
      "61 Train Loss 0.3974058 Test MSE 0.8745342267799298 Test RE 0.16368687031175633\n",
      "62 Train Loss 0.3909291 Test MSE 0.8814326205443737 Test RE 0.16433118955760184\n",
      "63 Train Loss 0.38453192 Test MSE 0.8672137208960047 Test RE 0.16300033980410705\n",
      "64 Train Loss 0.3770239 Test MSE 0.8747102138191882 Test RE 0.16370333926042735\n",
      "65 Train Loss 0.36699802 Test MSE 0.8662712254356842 Test RE 0.16291174062716565\n",
      "66 Train Loss 0.36001033 Test MSE 0.8683143889628275 Test RE 0.16310374705776132\n",
      "67 Train Loss 0.35547844 Test MSE 0.8641017190860307 Test RE 0.162707613090579\n",
      "68 Train Loss 0.35110134 Test MSE 0.8594661675941612 Test RE 0.162270596376706\n",
      "69 Train Loss 0.34745103 Test MSE 0.8534131806972286 Test RE 0.16169817286092178\n",
      "70 Train Loss 0.34350455 Test MSE 0.8538901087030608 Test RE 0.16174334887737207\n",
      "71 Train Loss 0.33879876 Test MSE 0.8556383967467138 Test RE 0.16190884404324035\n",
      "72 Train Loss 0.33472687 Test MSE 0.8495103059331925 Test RE 0.1613280057963845\n",
      "73 Train Loss 0.3326718 Test MSE 0.8362069557350752 Test RE 0.16005982118390127\n",
      "74 Train Loss 0.33079457 Test MSE 0.8299645682034026 Test RE 0.15946126892213244\n",
      "75 Train Loss 0.32746664 Test MSE 0.8069597536891288 Test RE 0.15723577916617584\n",
      "76 Train Loss 0.32373387 Test MSE 0.8089164703428516 Test RE 0.15742629646578019\n",
      "77 Train Loss 0.32029724 Test MSE 0.8190506310631602 Test RE 0.15840935079665763\n",
      "78 Train Loss 0.3174202 Test MSE 0.824269311200496 Test RE 0.15891321163542\n",
      "79 Train Loss 0.3102556 Test MSE 0.822503419222741 Test RE 0.15874289471166414\n",
      "80 Train Loss 0.30434722 Test MSE 0.8228107994956806 Test RE 0.1587725540876835\n",
      "81 Train Loss 0.3016515 Test MSE 0.8215379998381432 Test RE 0.15864970454300067\n",
      "82 Train Loss 0.2995081 Test MSE 0.8259820416411545 Test RE 0.159078227032196\n",
      "83 Train Loss 0.29684857 Test MSE 0.8242389016961711 Test RE 0.1589102802412128\n",
      "84 Train Loss 0.29600796 Test MSE 0.8270266869447841 Test RE 0.15917879084850317\n",
      "85 Train Loss 0.29510233 Test MSE 0.8359021060010315 Test RE 0.1600306426166046\n",
      "86 Train Loss 0.29080445 Test MSE 0.8524233543233326 Test RE 0.1616043733064769\n",
      "87 Train Loss 0.28881034 Test MSE 0.8534739165554268 Test RE 0.16170392664044653\n",
      "88 Train Loss 0.28750914 Test MSE 0.8572593040560567 Test RE 0.16206213020781746\n",
      "89 Train Loss 0.28453928 Test MSE 0.8486108554680363 Test RE 0.1612425771803797\n",
      "90 Train Loss 0.28291467 Test MSE 0.8527505015470849 Test RE 0.16163538099194963\n",
      "91 Train Loss 0.28043425 Test MSE 0.8706937082685452 Test RE 0.16332705926780589\n",
      "92 Train Loss 0.27864057 Test MSE 0.8739835284768743 Test RE 0.1636353250010384\n",
      "93 Train Loss 0.27771682 Test MSE 0.8763109172626239 Test RE 0.16385305783120238\n",
      "94 Train Loss 0.27613086 Test MSE 0.8783995023137015 Test RE 0.16404820396715347\n",
      "95 Train Loss 0.2745632 Test MSE 0.8789386226254147 Test RE 0.1640985387820336\n",
      "96 Train Loss 0.27251473 Test MSE 0.8789987189516145 Test RE 0.1641041487020535\n",
      "97 Train Loss 0.26808876 Test MSE 0.8497372115212682 Test RE 0.161349549844587\n",
      "98 Train Loss 0.2653232 Test MSE 0.8404905958292386 Test RE 0.1604692669699186\n",
      "99 Train Loss 0.2627446 Test MSE 0.8257445684716302 Test RE 0.15905535757226355\n",
      "100 Train Loss 0.2613608 Test MSE 0.8312129855712839 Test RE 0.15958115320428135\n",
      "101 Train Loss 0.26036948 Test MSE 0.8273814592991955 Test RE 0.1592129289121967\n",
      "102 Train Loss 0.25880042 Test MSE 0.8325536523182013 Test RE 0.15970979589304107\n",
      "103 Train Loss 0.25590762 Test MSE 0.8284406018677722 Test RE 0.15931480166807732\n",
      "104 Train Loss 0.25433156 Test MSE 0.8284927611186801 Test RE 0.15931981687973043\n",
      "105 Train Loss 0.25303277 Test MSE 0.8369214255065724 Test RE 0.16012818553208522\n",
      "106 Train Loss 0.25199428 Test MSE 0.8351154048249827 Test RE 0.15995531924481662\n",
      "107 Train Loss 0.25048417 Test MSE 0.8261781515745426 Test RE 0.15909711059589157\n",
      "108 Train Loss 0.24857506 Test MSE 0.8253102615667858 Test RE 0.15901352385744758\n",
      "109 Train Loss 0.2459352 Test MSE 0.8364073357749604 Test RE 0.16007899758034502\n",
      "110 Train Loss 0.24431416 Test MSE 0.8450874297042338 Test RE 0.16090749002683707\n",
      "111 Train Loss 0.24249204 Test MSE 0.8388603810346209 Test RE 0.16031356841300495\n",
      "112 Train Loss 0.24133593 Test MSE 0.8275898202944909 Test RE 0.15923297509263115\n",
      "113 Train Loss 0.23910883 Test MSE 0.8262441014651228 Test RE 0.15910346045374812\n",
      "114 Train Loss 0.2368795 Test MSE 0.8313235134239267 Test RE 0.15959176274490855\n",
      "115 Train Loss 0.23543128 Test MSE 0.8333092065825792 Test RE 0.15978224891281168\n",
      "116 Train Loss 0.2340807 Test MSE 0.8389670721349465 Test RE 0.16032376289088532\n",
      "117 Train Loss 0.23323736 Test MSE 0.8455776171938288 Test RE 0.16095414993528412\n",
      "118 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "119 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "120 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "121 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "122 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "123 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "124 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "125 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "126 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "127 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "128 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "129 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "130 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "131 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "132 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "133 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "134 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "135 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "136 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "137 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "138 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "139 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "140 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "141 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "142 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "143 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "144 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "145 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "146 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "147 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "148 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "149 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "150 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "151 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "152 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "153 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "154 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "155 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "156 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "157 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "158 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "159 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "160 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "161 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "162 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "163 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "164 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "165 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "166 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "167 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "168 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "169 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "170 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "171 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "172 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "173 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "174 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "175 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "176 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "177 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "178 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "179 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "180 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "181 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "182 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "183 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "184 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "185 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "186 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "187 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "188 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "189 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "190 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "191 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "192 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "193 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "194 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "195 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "196 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "197 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "198 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "199 Train Loss 0.23215468 Test MSE 0.8522303747754211 Test RE 0.16158607951853318\n",
      "Training time: 106.20\n",
      "Training time: 106.20\n",
      "ES_atanh_low\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 24.160511 Test MSE 7.010031951488886 Test RE 0.4634313807418639\n",
      "1 Train Loss 21.10936 Test MSE 5.588020050796828 Test RE 0.41376563457030946\n",
      "2 Train Loss 15.964025 Test MSE 3.62271291174899 Test RE 0.33315198018595216\n",
      "3 Train Loss 9.423046 Test MSE 2.0227623159592913 Test RE 0.24894182356714553\n",
      "4 Train Loss 6.3874555 Test MSE 1.2893065055615889 Test RE 0.19874834754991044\n",
      "5 Train Loss 5.2291718 Test MSE 0.9728154093262391 Test RE 0.17263969499752627\n",
      "6 Train Loss 4.503411 Test MSE 0.9086892396042142 Test RE 0.1668526590318263\n",
      "7 Train Loss 4.185573 Test MSE 0.6776601797139109 Test RE 0.14408919757220426\n",
      "8 Train Loss 3.8973007 Test MSE 0.5747099537460193 Test RE 0.13269354569164146\n",
      "9 Train Loss 3.6334481 Test MSE 0.554580953609992 Test RE 0.1303490632834852\n",
      "10 Train Loss 3.3358307 Test MSE 0.5885396484987089 Test RE 0.13428060900788996\n",
      "11 Train Loss 3.0844564 Test MSE 0.5877889290035274 Test RE 0.13419493998097765\n",
      "12 Train Loss 2.837677 Test MSE 0.6053695692105159 Test RE 0.1361870248889807\n",
      "13 Train Loss 2.4977279 Test MSE 0.5545429018518282 Test RE 0.13034459135194432\n",
      "14 Train Loss 2.2828135 Test MSE 0.6848676812582845 Test RE 0.14485342744390192\n",
      "15 Train Loss 2.0357823 Test MSE 0.90086350141686 Test RE 0.1661326281085257\n",
      "16 Train Loss 1.7935587 Test MSE 0.8553718346534778 Test RE 0.16188362186851946\n",
      "17 Train Loss 1.6542547 Test MSE 0.9526954333222563 Test RE 0.17084508185719013\n",
      "18 Train Loss 1.588593 Test MSE 1.0049546666554796 Test RE 0.1754683026677987\n",
      "19 Train Loss 1.4996103 Test MSE 0.9052395472952431 Test RE 0.16653564325080666\n",
      "20 Train Loss 1.4282243 Test MSE 0.9152251555624 Test RE 0.1674516432397401\n",
      "21 Train Loss 1.3594797 Test MSE 0.8626702639266793 Test RE 0.16257278799700897\n",
      "22 Train Loss 1.2800354 Test MSE 0.8332927439645208 Test RE 0.15978067059883932\n",
      "23 Train Loss 1.2112365 Test MSE 0.9210538972068524 Test RE 0.1679840167704678\n",
      "24 Train Loss 1.1724052 Test MSE 0.9481650421767228 Test RE 0.1704383845193875\n",
      "25 Train Loss 1.1059984 Test MSE 0.922809560255345 Test RE 0.1681440415659454\n",
      "26 Train Loss 1.0533195 Test MSE 0.9246250061158097 Test RE 0.16830935542479206\n",
      "27 Train Loss 0.9997022 Test MSE 0.9867104005758073 Test RE 0.1738682538196902\n",
      "28 Train Loss 0.96341646 Test MSE 0.935361818269545 Test RE 0.16928374509600064\n",
      "29 Train Loss 0.92359954 Test MSE 0.8817231845351079 Test RE 0.16435827318866303\n",
      "30 Train Loss 0.8960994 Test MSE 0.8335141890013769 Test RE 0.15980189980451223\n",
      "31 Train Loss 0.86663073 Test MSE 0.7873301063730416 Test RE 0.15531159105661543\n",
      "32 Train Loss 0.83818406 Test MSE 0.7938093010119591 Test RE 0.15594933640320893\n",
      "33 Train Loss 0.8052868 Test MSE 0.7898552969318422 Test RE 0.15556045579348732\n",
      "34 Train Loss 0.7798756 Test MSE 0.8488008316876079 Test RE 0.1612606246404441\n",
      "35 Train Loss 0.76504 Test MSE 0.8253159720692346 Test RE 0.15901407398119433\n",
      "36 Train Loss 0.74170333 Test MSE 0.7946432573968826 Test RE 0.15603123315376197\n",
      "37 Train Loss 0.7215439 Test MSE 0.8139175695808036 Test RE 0.15791218804805932\n",
      "38 Train Loss 0.6808219 Test MSE 0.8502310922590959 Test RE 0.1613964324914269\n",
      "39 Train Loss 0.66268754 Test MSE 0.822968946294992 Test RE 0.1587878116443745\n",
      "40 Train Loss 0.65445644 Test MSE 0.8203051440736143 Test RE 0.15853061958425574\n",
      "41 Train Loss 0.63678116 Test MSE 0.8088396179152194 Test RE 0.15741881801721627\n",
      "42 Train Loss 0.616904 Test MSE 0.7917967670838225 Test RE 0.1557515228289848\n",
      "43 Train Loss 0.6014027 Test MSE 0.8159965906311464 Test RE 0.15811374001938103\n",
      "44 Train Loss 0.58726674 Test MSE 0.823800398444547 Test RE 0.1588680036968195\n",
      "45 Train Loss 0.57600754 Test MSE 0.8221160734976911 Test RE 0.1587055115098587\n",
      "46 Train Loss 0.56511635 Test MSE 0.8268612307471079 Test RE 0.15916286727838574\n",
      "47 Train Loss 0.55779827 Test MSE 0.8252512574658086 Test RE 0.15900783956018585\n",
      "48 Train Loss 0.54388624 Test MSE 0.8443977110745947 Test RE 0.16084181424990276\n",
      "49 Train Loss 0.52727336 Test MSE 0.8549816624856507 Test RE 0.1618466965890382\n",
      "50 Train Loss 0.52023214 Test MSE 0.8503440599986654 Test RE 0.16140715427326452\n",
      "51 Train Loss 0.51495403 Test MSE 0.85415508827415 Test RE 0.16176844306590385\n",
      "52 Train Loss 0.50805295 Test MSE 0.8448835222520515 Test RE 0.16088807652323173\n",
      "53 Train Loss 0.49889028 Test MSE 0.8517757723511212 Test RE 0.1615429766062762\n",
      "54 Train Loss 0.49558482 Test MSE 0.8408671528187378 Test RE 0.16050520970258644\n",
      "55 Train Loss 0.48710853 Test MSE 0.8566016897516554 Test RE 0.1619999583416165\n",
      "56 Train Loss 0.4790835 Test MSE 0.8525592270762365 Test RE 0.1616172523272428\n",
      "57 Train Loss 0.4720959 Test MSE 0.8655467595037655 Test RE 0.16284360452334895\n",
      "58 Train Loss 0.46529388 Test MSE 0.8697364906180707 Test RE 0.1632372558530273\n",
      "59 Train Loss 0.4623097 Test MSE 0.8703283026057077 Test RE 0.16329278378455087\n",
      "60 Train Loss 0.45846894 Test MSE 0.8753504941570267 Test RE 0.16376324301690623\n",
      "61 Train Loss 0.45438188 Test MSE 0.8891797871824916 Test RE 0.16505178685150856\n",
      "62 Train Loss 0.44614843 Test MSE 0.8772324443497858 Test RE 0.16393918899336218\n",
      "63 Train Loss 0.44105572 Test MSE 0.8613139110013985 Test RE 0.1624449333415734\n",
      "64 Train Loss 0.42451066 Test MSE 0.894319068202189 Test RE 0.16552808274903413\n",
      "65 Train Loss 0.4179056 Test MSE 0.8946688170431193 Test RE 0.1655604468112842\n",
      "66 Train Loss 0.41238546 Test MSE 0.8684225551713959 Test RE 0.1631139056850706\n",
      "67 Train Loss 0.40897304 Test MSE 0.8643523928583255 Test RE 0.16273121191735174\n",
      "68 Train Loss 0.40577668 Test MSE 0.8531531894054768 Test RE 0.1616735404084694\n",
      "69 Train Loss 0.40102553 Test MSE 0.8524663592941336 Test RE 0.16160844974553012\n",
      "70 Train Loss 0.39586395 Test MSE 0.847463899950072 Test RE 0.16113357516031013\n",
      "71 Train Loss 0.39204898 Test MSE 0.8523741829416973 Test RE 0.16159971222764152\n",
      "72 Train Loss 0.38675264 Test MSE 0.8631732180243423 Test RE 0.1626201726924617\n",
      "73 Train Loss 0.38218343 Test MSE 0.8689909173309863 Test RE 0.16316727406394305\n",
      "74 Train Loss 0.37718484 Test MSE 0.8651769709267912 Test RE 0.16280881487321186\n",
      "75 Train Loss 0.37260222 Test MSE 0.8668720946029131 Test RE 0.16296823082929876\n",
      "76 Train Loss 0.36817247 Test MSE 0.866126017963481 Test RE 0.1628980861314586\n",
      "77 Train Loss 0.36281687 Test MSE 0.8777033136235346 Test RE 0.16398318164967113\n",
      "78 Train Loss 0.3606006 Test MSE 0.8818090226215813 Test RE 0.16436627335048432\n",
      "79 Train Loss 0.35855263 Test MSE 0.8770740919642197 Test RE 0.1639243916990541\n",
      "80 Train Loss 0.35136026 Test MSE 0.8583097691746178 Test RE 0.16216139334427365\n",
      "81 Train Loss 0.34520385 Test MSE 0.8744113643021427 Test RE 0.16367537180189567\n",
      "82 Train Loss 0.33618462 Test MSE 0.8885061034660331 Test RE 0.16498924957167924\n",
      "83 Train Loss 0.3298709 Test MSE 0.8823902063142499 Test RE 0.16442042978369154\n",
      "84 Train Loss 0.32566142 Test MSE 0.8720541471747528 Test RE 0.1634546068527204\n",
      "85 Train Loss 0.32353413 Test MSE 0.8805448011529492 Test RE 0.16424840774864136\n",
      "86 Train Loss 0.3223359 Test MSE 0.8843391268786629 Test RE 0.16460190596663746\n",
      "87 Train Loss 0.32114074 Test MSE 0.8757010852010041 Test RE 0.1637960345553147\n",
      "88 Train Loss 0.31993338 Test MSE 0.8820729228636144 Test RE 0.164390866574964\n",
      "89 Train Loss 0.31834385 Test MSE 0.8981625933369258 Test RE 0.16588339735146412\n",
      "90 Train Loss 0.31587973 Test MSE 0.8924028196049859 Test RE 0.16535064996163307\n",
      "91 Train Loss 0.31270462 Test MSE 0.8895984311365872 Test RE 0.1650906371506323\n",
      "92 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "93 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "94 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "95 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "96 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "97 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "98 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "99 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "100 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "101 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "102 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "103 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "104 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "105 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "106 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "107 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "108 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "109 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "110 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "111 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "112 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "113 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "114 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "115 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "116 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "117 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "118 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "119 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "120 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "121 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "122 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "123 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "124 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "125 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "126 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "127 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "128 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "129 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "130 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "131 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "132 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "133 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "134 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "135 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "136 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "137 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "138 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "139 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "140 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "141 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "142 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "143 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "144 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "145 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "146 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "147 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "148 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "149 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "150 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "151 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "152 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "153 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "154 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "155 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "156 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "157 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "158 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "159 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "160 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "161 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "162 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "163 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "164 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "165 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "166 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "167 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "168 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "169 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "170 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "171 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "172 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "173 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "174 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "175 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "176 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "177 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "178 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "179 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "180 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "181 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "182 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "183 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "184 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "185 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "186 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "187 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "188 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "189 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "190 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "191 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "192 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "193 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "194 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "195 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "196 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "197 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "198 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "199 Train Loss 0.31132373 Test MSE 0.8933025608445969 Test RE 0.16543398414399108\n",
      "Training time: 99.38\n",
      "Training time: 99.38\n",
      "ES_atanh_low\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 23.7089 Test MSE 7.393366973799448 Test RE 0.4759338244709939\n",
      "1 Train Loss 17.13737 Test MSE 3.8759628171539635 Test RE 0.34459997416146854\n",
      "2 Train Loss 11.123721 Test MSE 2.25705917316275 Test RE 0.26296437223776\n",
      "3 Train Loss 7.1126614 Test MSE 1.5984536907679856 Test RE 0.22129697063336495\n",
      "4 Train Loss 5.426337 Test MSE 1.0502832035615284 Test RE 0.17938191233017498\n",
      "5 Train Loss 4.858347 Test MSE 0.9595462770124081 Test RE 0.17145825595914063\n",
      "6 Train Loss 4.652436 Test MSE 0.8306562038506994 Test RE 0.1595276971378039\n",
      "7 Train Loss 4.492643 Test MSE 0.7549764748791382 Test RE 0.1520870195406845\n",
      "8 Train Loss 4.391932 Test MSE 0.7144973635178725 Test RE 0.14795367424041864\n",
      "9 Train Loss 4.2892337 Test MSE 0.6749705559553678 Test RE 0.14380296927765351\n",
      "10 Train Loss 4.2212987 Test MSE 0.6397805478727749 Test RE 0.14000416483394648\n",
      "11 Train Loss 4.1484065 Test MSE 0.6274232499303011 Test RE 0.13864548888016395\n",
      "12 Train Loss 4.1068482 Test MSE 0.5945621502756074 Test RE 0.1349659042677626\n",
      "13 Train Loss 4.055451 Test MSE 0.5701925724911944 Test RE 0.1321710126286799\n",
      "14 Train Loss 3.9595416 Test MSE 0.5615331152194584 Test RE 0.13116353895392377\n",
      "15 Train Loss 3.9117124 Test MSE 0.5610303094217646 Test RE 0.13110480282974596\n",
      "16 Train Loss 3.8145726 Test MSE 0.527125828641621 Test RE 0.12708157476116685\n",
      "17 Train Loss 3.7174935 Test MSE 0.5025702105300667 Test RE 0.12408629307793718\n",
      "18 Train Loss 3.510536 Test MSE 0.460979035367164 Test RE 0.11884092592792987\n",
      "19 Train Loss 3.2163494 Test MSE 0.4445693570814392 Test RE 0.11670654218021086\n",
      "20 Train Loss 2.852248 Test MSE 0.5610349324099806 Test RE 0.13110534299192597\n",
      "21 Train Loss 2.6263127 Test MSE 0.5180678741364584 Test RE 0.12598497976012085\n",
      "22 Train Loss 2.3317785 Test MSE 0.5561305932549545 Test RE 0.13053105039103063\n",
      "23 Train Loss 2.1499982 Test MSE 0.5824000194967288 Test RE 0.1335783670026372\n",
      "24 Train Loss 1.9339564 Test MSE 0.6108167409388098 Test RE 0.13679836450878868\n",
      "25 Train Loss 1.788919 Test MSE 0.6798977941291118 Test RE 0.1443268907121966\n",
      "26 Train Loss 1.6785698 Test MSE 0.6650563293619325 Test RE 0.14274294576635146\n",
      "27 Train Loss 1.6044844 Test MSE 0.6536375127894516 Test RE 0.14151221340614342\n",
      "28 Train Loss 1.5000577 Test MSE 0.6680744311469822 Test RE 0.1430664710505605\n",
      "29 Train Loss 1.4295286 Test MSE 0.7118571702287546 Test RE 0.14768006383661963\n",
      "30 Train Loss 1.3829691 Test MSE 0.8308275160577742 Test RE 0.15954414656227014\n",
      "31 Train Loss 1.3519775 Test MSE 0.8701492418769031 Test RE 0.16327598504960245\n",
      "32 Train Loss 1.2980975 Test MSE 0.7892572395540305 Test RE 0.15550155152580317\n",
      "33 Train Loss 1.2510047 Test MSE 0.759072776978425 Test RE 0.1524990533141357\n",
      "34 Train Loss 1.201893 Test MSE 0.7655409200739726 Test RE 0.15314740572408636\n",
      "35 Train Loss 1.1568159 Test MSE 0.7601782745177803 Test RE 0.1526100611095711\n",
      "36 Train Loss 1.1168755 Test MSE 0.7896247260469569 Test RE 0.15553774889384964\n",
      "37 Train Loss 1.0705245 Test MSE 0.810134282407343 Test RE 0.15754475340670762\n",
      "38 Train Loss 1.0344312 Test MSE 0.8781825407512639 Test RE 0.16402794305363438\n",
      "39 Train Loss 0.9802328 Test MSE 0.9554475868913465 Test RE 0.17109167316092835\n",
      "40 Train Loss 0.9534159 Test MSE 0.947523473562316 Test RE 0.17038071184798984\n",
      "41 Train Loss 0.90516794 Test MSE 0.9480039340913646 Test RE 0.17042390382926098\n",
      "42 Train Loss 0.869648 Test MSE 0.9228614986514115 Test RE 0.16814877331631142\n",
      "43 Train Loss 0.8480802 Test MSE 0.917132509614514 Test RE 0.16762603930903738\n",
      "44 Train Loss 0.8208303 Test MSE 0.9112032986217836 Test RE 0.16708331417426706\n",
      "45 Train Loss 0.79530674 Test MSE 0.9182328483732191 Test RE 0.1677265646620776\n",
      "46 Train Loss 0.76557386 Test MSE 0.8605408001326047 Test RE 0.16237201211252555\n",
      "47 Train Loss 0.7560169 Test MSE 0.8333304798395781 Test RE 0.15978428841215048\n",
      "48 Train Loss 0.73639697 Test MSE 0.8811094930916128 Test RE 0.16430106542510076\n",
      "49 Train Loss 0.7099529 Test MSE 0.8939856619749299 Test RE 0.16549722506071599\n",
      "50 Train Loss 0.678118 Test MSE 0.8718942229255776 Test RE 0.16343961836036214\n",
      "51 Train Loss 0.6703669 Test MSE 0.8765930556634232 Test RE 0.16387943289876214\n",
      "52 Train Loss 0.65118283 Test MSE 0.8973749592423854 Test RE 0.16581064656155878\n",
      "53 Train Loss 0.63887626 Test MSE 0.9227044372486902 Test RE 0.16813446412365343\n",
      "54 Train Loss 0.62474626 Test MSE 0.9055022884099645 Test RE 0.16655980955362068\n",
      "55 Train Loss 0.61133146 Test MSE 0.886618666768771 Test RE 0.16481391463709474\n",
      "56 Train Loss 0.59805924 Test MSE 0.9103197112075954 Test RE 0.1670022847702296\n",
      "57 Train Loss 0.5903085 Test MSE 0.9180874401549329 Test RE 0.16771328383326664\n",
      "58 Train Loss 0.5832877 Test MSE 0.942582012778195 Test RE 0.1699358520662288\n",
      "59 Train Loss 0.57359946 Test MSE 0.9180388399743091 Test RE 0.16770884471156458\n",
      "60 Train Loss 0.56655526 Test MSE 0.9361841301051822 Test RE 0.16935814060959717\n",
      "61 Train Loss 0.55530363 Test MSE 0.898818274990321 Test RE 0.165943935865135\n",
      "62 Train Loss 0.54333186 Test MSE 0.9147529909790046 Test RE 0.16740844352276754\n",
      "63 Train Loss 0.53909665 Test MSE 0.8956150382942797 Test RE 0.1656479738442571\n",
      "64 Train Loss 0.5287817 Test MSE 0.8986472705881454 Test RE 0.1659281493072809\n",
      "65 Train Loss 0.5195697 Test MSE 0.8849161642800306 Test RE 0.1646555991507516\n",
      "66 Train Loss 0.50840276 Test MSE 0.874982173519347 Test RE 0.16372878611720698\n",
      "67 Train Loss 0.49087384 Test MSE 0.844106154622811 Test RE 0.16081404385408413\n",
      "68 Train Loss 0.47497374 Test MSE 0.8797805164613252 Test RE 0.16417711109520225\n",
      "69 Train Loss 0.47008437 Test MSE 0.8900186797689913 Test RE 0.1651296271714513\n",
      "70 Train Loss 0.46006817 Test MSE 0.8369883514040912 Test RE 0.16013458787044782\n",
      "71 Train Loss 0.45173144 Test MSE 0.8507048960982698 Test RE 0.16144139650148417\n",
      "72 Train Loss 0.44613296 Test MSE 0.8439880540645041 Test RE 0.16080279355540122\n",
      "73 Train Loss 0.43938977 Test MSE 0.8563908253206354 Test RE 0.16198001784187777\n",
      "74 Train Loss 0.43388698 Test MSE 0.863091886630739 Test RE 0.16261251117298609\n",
      "75 Train Loss 0.4258 Test MSE 0.8587499072304479 Test RE 0.16220296589494357\n",
      "76 Train Loss 0.4210249 Test MSE 0.8502504906200192 Test RE 0.1613982736428622\n",
      "77 Train Loss 0.41601762 Test MSE 0.8416029489717662 Test RE 0.16057541894506147\n",
      "78 Train Loss 0.41043177 Test MSE 0.8251477251594105 Test RE 0.1589978650435919\n",
      "79 Train Loss 0.40293092 Test MSE 0.8590134542048614 Test RE 0.16222785371224618\n",
      "80 Train Loss 0.39953816 Test MSE 0.8698345709982955 Test RE 0.1632464597446346\n",
      "81 Train Loss 0.39515284 Test MSE 0.8644162496037 Test RE 0.16273722294579965\n",
      "82 Train Loss 0.39171714 Test MSE 0.8736033514436645 Test RE 0.16359973098976197\n",
      "83 Train Loss 0.38877124 Test MSE 0.8902749373951145 Test RE 0.16515339784151412\n",
      "84 Train Loss 0.38360104 Test MSE 0.8780718795445824 Test RE 0.16401760801443271\n",
      "85 Train Loss 0.37909856 Test MSE 0.8530502698272618 Test RE 0.16166378842333692\n",
      "86 Train Loss 0.37585726 Test MSE 0.858729019477882 Test RE 0.1622009932158253\n",
      "87 Train Loss 0.37272713 Test MSE 0.8472275508993455 Test RE 0.16111110433695375\n",
      "88 Train Loss 0.36770424 Test MSE 0.8553932745098105 Test RE 0.16188565065863536\n",
      "89 Train Loss 0.36580893 Test MSE 0.8590156650739114 Test RE 0.16222806247749214\n",
      "90 Train Loss 0.36220974 Test MSE 0.8691594300243025 Test RE 0.16318309380579313\n",
      "91 Train Loss 0.3554354 Test MSE 0.8787886847467773 Test RE 0.16408454142455556\n",
      "92 Train Loss 0.34789965 Test MSE 0.8650807293165232 Test RE 0.16279975925868945\n",
      "93 Train Loss 0.3417437 Test MSE 0.8569177675992096 Test RE 0.16202984380420565\n",
      "94 Train Loss 0.33933008 Test MSE 0.858579180414733 Test RE 0.16218684142602566\n",
      "95 Train Loss 0.33664975 Test MSE 0.8622004152229169 Test RE 0.16252850977139247\n",
      "96 Train Loss 0.33061543 Test MSE 0.842483418781281 Test RE 0.1606593925398904\n",
      "97 Train Loss 0.32233194 Test MSE 0.8264602785402958 Test RE 0.15912427286937286\n",
      "98 Train Loss 0.3170504 Test MSE 0.8498414061975266 Test RE 0.16135944187270457\n",
      "99 Train Loss 0.3135297 Test MSE 0.8515622864166837 Test RE 0.16152273107004697\n",
      "100 Train Loss 0.31021854 Test MSE 0.8542299187054841 Test RE 0.1617755289788849\n",
      "101 Train Loss 0.3068134 Test MSE 0.8528248846791406 Test RE 0.1616424303479433\n",
      "102 Train Loss 0.3045687 Test MSE 0.8509721827609064 Test RE 0.16146675649609113\n",
      "103 Train Loss 0.30053732 Test MSE 0.8544325560356766 Test RE 0.16179471574388973\n",
      "104 Train Loss 0.29785112 Test MSE 0.8542423404699466 Test RE 0.16177670520215184\n",
      "105 Train Loss 0.29514983 Test MSE 0.8549156415521719 Test RE 0.16184044763848\n",
      "106 Train Loss 0.29178172 Test MSE 0.8370242694187793 Test RE 0.1601380237932802\n",
      "107 Train Loss 0.28956643 Test MSE 0.8296846854680648 Test RE 0.15943437969030888\n",
      "108 Train Loss 0.2855674 Test MSE 0.8400124274127796 Test RE 0.1604236137215766\n",
      "109 Train Loss 0.28423125 Test MSE 0.839190216616485 Test RE 0.16034508255026925\n",
      "110 Train Loss 0.28282285 Test MSE 0.844336398384235 Test RE 0.1608359746892032\n",
      "111 Train Loss 0.28181827 Test MSE 0.8469913697396285 Test RE 0.1610886463445953\n",
      "112 Train Loss 0.2788826 Test MSE 0.8432055004321036 Test RE 0.16072822733826755\n",
      "113 Train Loss 0.27673775 Test MSE 0.8387764644942801 Test RE 0.16030554961941418\n",
      "114 Train Loss 0.2739636 Test MSE 0.857334283521613 Test RE 0.16206921736695504\n",
      "115 Train Loss 0.27221066 Test MSE 0.8569733980376526 Test RE 0.16203510314489453\n",
      "116 Train Loss 0.26983425 Test MSE 0.8577030912664303 Test RE 0.16210407305678168\n",
      "117 Train Loss 0.26686382 Test MSE 0.8547688568170296 Test RE 0.16182655344479657\n",
      "118 Train Loss 0.26540345 Test MSE 0.8546847155385016 Test RE 0.16181858835101542\n",
      "119 Train Loss 0.26256368 Test MSE 0.8601229768168316 Test RE 0.1623325886188885\n",
      "120 Train Loss 0.26062655 Test MSE 0.8634404022885542 Test RE 0.16264533924564376\n",
      "121 Train Loss 0.25877807 Test MSE 0.8710836325817197 Test RE 0.16336362669808363\n",
      "122 Train Loss 0.2566967 Test MSE 0.8665339251710582 Test RE 0.16293644052819703\n",
      "123 Train Loss 0.2548764 Test MSE 0.8643614574258925 Test RE 0.1627320652060165\n",
      "124 Train Loss 0.25376588 Test MSE 0.8683890692494376 Test RE 0.16311076086108037\n",
      "125 Train Loss 0.251355 Test MSE 0.856105763379213 Test RE 0.1619530569146473\n",
      "126 Train Loss 0.24955542 Test MSE 0.8442890750870018 Test RE 0.16083146736528417\n",
      "127 Train Loss 0.24829838 Test MSE 0.8375858191758289 Test RE 0.16019173214691607\n",
      "128 Train Loss 0.24738193 Test MSE 0.8408323229092836 Test RE 0.16050188549150649\n",
      "129 Train Loss 0.24602363 Test MSE 0.8440054784559762 Test RE 0.16080445345825758\n",
      "130 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "131 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "132 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "133 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "134 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "135 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "136 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "137 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "138 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "139 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "140 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "141 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "142 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "143 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "144 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "145 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "146 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "147 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "148 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "149 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "150 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "151 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "152 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "153 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "154 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "155 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "156 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "157 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "158 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "159 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "160 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "161 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "162 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "163 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "164 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "165 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "166 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "167 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "168 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "169 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "170 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "171 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "172 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "173 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "174 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "175 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "176 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "177 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "178 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "179 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "180 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "181 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "182 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "183 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "184 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "185 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "186 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "187 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "188 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "189 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "190 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "191 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "192 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "193 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "194 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "195 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "196 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "197 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "198 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "199 Train Loss 0.24568157 Test MSE 0.8423792158285047 Test RE 0.16064945661687224\n",
      "Training time: 124.99\n",
      "Training time: 124.99\n",
      "ES_atanh_low\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 24.380959 Test MSE 7.167868619947374 Test RE 0.46861960944755165\n",
      "1 Train Loss 17.642183 Test MSE 4.418681324270119 Test RE 0.3679355742964106\n",
      "2 Train Loss 11.5918455 Test MSE 2.5083801199052314 Test RE 0.2772184395353123\n",
      "3 Train Loss 8.980583 Test MSE 2.0103961619500383 Test RE 0.24817970426827082\n",
      "4 Train Loss 6.4439034 Test MSE 1.6386388916699681 Test RE 0.22406141205490382\n",
      "5 Train Loss 5.3202705 Test MSE 1.5369478828565541 Test RE 0.21699763969132466\n",
      "6 Train Loss 4.6493816 Test MSE 1.0703130293880476 Test RE 0.18108431959937535\n",
      "7 Train Loss 4.0846357 Test MSE 0.8382729338752519 Test RE 0.16025742543265487\n",
      "8 Train Loss 3.638068 Test MSE 0.8218913711560573 Test RE 0.15868382118028324\n",
      "9 Train Loss 3.3232028 Test MSE 0.6852845355108484 Test RE 0.14489750426594558\n",
      "10 Train Loss 2.9216857 Test MSE 0.5524409427188984 Test RE 0.13009732543125643\n",
      "11 Train Loss 2.5578628 Test MSE 0.6164390084010593 Test RE 0.13742650320004274\n",
      "12 Train Loss 2.2835627 Test MSE 0.6176342858244691 Test RE 0.1375596739152181\n",
      "13 Train Loss 2.0880065 Test MSE 0.6544012367144805 Test RE 0.14159486220592057\n",
      "14 Train Loss 1.9668236 Test MSE 0.5464612379524868 Test RE 0.1293913131207321\n",
      "15 Train Loss 1.8675563 Test MSE 0.5979467484254262 Test RE 0.1353495118453471\n",
      "16 Train Loss 1.7182726 Test MSE 0.6835907873799629 Test RE 0.14471832926867892\n",
      "17 Train Loss 1.5801593 Test MSE 0.7276333116388773 Test RE 0.14930753519429524\n",
      "18 Train Loss 1.5087416 Test MSE 0.8297562751648843 Test RE 0.1594412579736512\n",
      "19 Train Loss 1.4422841 Test MSE 0.8076254890459592 Test RE 0.1573006249261185\n",
      "20 Train Loss 1.392639 Test MSE 0.81695127092613 Test RE 0.15820620605958527\n",
      "21 Train Loss 1.3539236 Test MSE 0.8488458568824627 Test RE 0.1612649016713387\n",
      "22 Train Loss 1.3050753 Test MSE 0.9164608254192684 Test RE 0.16756464557230202\n",
      "23 Train Loss 1.256798 Test MSE 0.88319532074921 Test RE 0.16449542329459985\n",
      "24 Train Loss 1.1977003 Test MSE 0.8903710959841594 Test RE 0.16516231670929532\n",
      "25 Train Loss 1.1459925 Test MSE 0.8882245807221958 Test RE 0.16496310911753964\n",
      "26 Train Loss 1.1178061 Test MSE 0.9135680971879216 Test RE 0.16729998500774007\n",
      "27 Train Loss 1.0907823 Test MSE 0.9004740907657247 Test RE 0.1660967176695445\n",
      "28 Train Loss 1.0548549 Test MSE 0.9111011363003276 Test RE 0.1670739473854515\n",
      "29 Train Loss 1.0346477 Test MSE 0.8923937515446588 Test RE 0.16534980986260772\n",
      "30 Train Loss 0.99973804 Test MSE 0.8906720488597637 Test RE 0.16519022747303297\n",
      "31 Train Loss 0.9683329 Test MSE 0.8763709994714974 Test RE 0.16385867483580266\n",
      "32 Train Loss 0.93007743 Test MSE 0.8866241455796423 Test RE 0.1648144238655298\n",
      "33 Train Loss 0.89980024 Test MSE 0.9187913876595895 Test RE 0.1677775689547864\n",
      "34 Train Loss 0.85875666 Test MSE 0.9444149318243237 Test RE 0.17010099811160836\n",
      "35 Train Loss 0.84141046 Test MSE 0.9589564975997247 Test RE 0.171405554961131\n",
      "36 Train Loss 0.80115724 Test MSE 0.9493264709423443 Test RE 0.1705427394849584\n",
      "37 Train Loss 0.78486025 Test MSE 0.9541274070716557 Test RE 0.17097343022679357\n",
      "38 Train Loss 0.7726659 Test MSE 0.9331177758102307 Test RE 0.16908055739790548\n",
      "39 Train Loss 0.75129557 Test MSE 0.9742231966175545 Test RE 0.17276456560628356\n",
      "40 Train Loss 0.74068266 Test MSE 0.9715748245214889 Test RE 0.17252958032143073\n",
      "41 Train Loss 0.7289976 Test MSE 0.944606601129912 Test RE 0.17011825826128035\n",
      "42 Train Loss 0.7154485 Test MSE 0.9152337711778741 Test RE 0.16745243140403207\n",
      "43 Train Loss 0.7046452 Test MSE 0.9151346738292596 Test RE 0.16744336566492735\n",
      "44 Train Loss 0.6861184 Test MSE 0.9176075217144427 Test RE 0.16766944311861096\n",
      "45 Train Loss 0.67140037 Test MSE 0.8877113169600921 Test RE 0.16491543996774166\n",
      "46 Train Loss 0.65941125 Test MSE 0.8911013015757503 Test RE 0.1652300287739207\n",
      "47 Train Loss 0.64945555 Test MSE 0.8986657331163549 Test RE 0.16592985377882566\n",
      "48 Train Loss 0.6418177 Test MSE 0.8616607293969626 Test RE 0.16247763525210113\n",
      "49 Train Loss 0.6290546 Test MSE 0.8471806300110831 Test RE 0.16110664297307137\n",
      "50 Train Loss 0.61782706 Test MSE 0.8537144105710215 Test RE 0.16172670770424888\n",
      "51 Train Loss 0.5984527 Test MSE 0.8833514328081756 Test RE 0.16450996061377626\n",
      "52 Train Loss 0.58923006 Test MSE 0.8831133267585315 Test RE 0.16448778741330455\n",
      "53 Train Loss 0.5815843 Test MSE 0.884023320046788 Test RE 0.16457251280367594\n",
      "54 Train Loss 0.57582307 Test MSE 0.8858443936997857 Test RE 0.16474193394645337\n",
      "55 Train Loss 0.5717443 Test MSE 0.8848840454503839 Test RE 0.16465261096195932\n",
      "56 Train Loss 0.5669664 Test MSE 0.9019896410064974 Test RE 0.1662364341221858\n",
      "57 Train Loss 0.55946803 Test MSE 0.9031265029523448 Test RE 0.16634116279926828\n",
      "58 Train Loss 0.5471434 Test MSE 0.8907032117549409 Test RE 0.16519311729130134\n",
      "59 Train Loss 0.5360579 Test MSE 0.8707727531379426 Test RE 0.16333447282377347\n",
      "60 Train Loss 0.52408063 Test MSE 0.887320616681768 Test RE 0.16487914461014752\n",
      "61 Train Loss 0.5145913 Test MSE 0.8839669100798813 Test RE 0.1645672619930401\n",
      "62 Train Loss 0.5085276 Test MSE 0.8527186598312751 Test RE 0.16163236323007038\n",
      "63 Train Loss 0.50600034 Test MSE 0.8528980112707388 Test RE 0.16164936032080413\n",
      "64 Train Loss 0.49845424 Test MSE 0.8549582861750938 Test RE 0.16184448402433121\n",
      "65 Train Loss 0.49145138 Test MSE 0.8555567510044613 Test RE 0.16190111911927688\n",
      "66 Train Loss 0.48508352 Test MSE 0.849434798164875 Test RE 0.16132083590786347\n",
      "67 Train Loss 0.48279476 Test MSE 0.8456695964008768 Test RE 0.16096290373399424\n",
      "68 Train Loss 0.4793328 Test MSE 0.8497649604114348 Test RE 0.1613521843263565\n",
      "69 Train Loss 0.47212812 Test MSE 0.8463179272250557 Test RE 0.16102459284924558\n",
      "70 Train Loss 0.4688203 Test MSE 0.8609092428646529 Test RE 0.16240676838763674\n",
      "71 Train Loss 0.46519476 Test MSE 0.8727745195626266 Test RE 0.16352210488537583\n",
      "72 Train Loss 0.45889887 Test MSE 0.8784962198807361 Test RE 0.16405723511209333\n",
      "73 Train Loss 0.4565451 Test MSE 0.8798299610207887 Test RE 0.16418172449066176\n",
      "74 Train Loss 0.45236292 Test MSE 0.8693911866478407 Test RE 0.16320484829687207\n",
      "75 Train Loss 0.44921446 Test MSE 0.8648832862322566 Test RE 0.16278117976674297\n",
      "76 Train Loss 0.44701037 Test MSE 0.8583570540477452 Test RE 0.16216586007387576\n",
      "77 Train Loss 0.44330108 Test MSE 0.8616616345105175 Test RE 0.16247772058770157\n",
      "78 Train Loss 0.43665242 Test MSE 0.8605557659813792 Test RE 0.16237342402955082\n",
      "79 Train Loss 0.42893678 Test MSE 0.8542109593674193 Test RE 0.16177373369292253\n",
      "80 Train Loss 0.42644793 Test MSE 0.8483782930439784 Test RE 0.16122048134347428\n",
      "81 Train Loss 0.42401338 Test MSE 0.8412631831636627 Test RE 0.16054300250414885\n",
      "82 Train Loss 0.4202683 Test MSE 0.8366121984879058 Test RE 0.16009860059462222\n",
      "83 Train Loss 0.41787255 Test MSE 0.8331425436800567 Test RE 0.159766269787179\n",
      "84 Train Loss 0.41525465 Test MSE 0.8272214118333651 Test RE 0.15919752920876198\n",
      "85 Train Loss 0.41332427 Test MSE 0.8338919943074131 Test RE 0.15983811224492794\n",
      "86 Train Loss 0.4101972 Test MSE 0.8453372874555934 Test RE 0.16093127514716504\n",
      "87 Train Loss 0.4070515 Test MSE 0.8422829810887499 Test RE 0.16064027993021537\n",
      "88 Train Loss 0.40329805 Test MSE 0.8545392967983281 Test RE 0.16180482160414325\n",
      "89 Train Loss 0.40127972 Test MSE 0.8617598096999548 Test RE 0.16248697644059357\n",
      "90 Train Loss 0.39748457 Test MSE 0.8625634615715846 Test RE 0.16256272407409403\n",
      "91 Train Loss 0.3961416 Test MSE 0.8655968478617171 Test RE 0.16284831625651888\n",
      "92 Train Loss 0.39489517 Test MSE 0.8739023911724465 Test RE 0.1636277291843517\n",
      "93 Train Loss 0.39230514 Test MSE 0.8668985603891494 Test RE 0.1629707185373863\n",
      "94 Train Loss 0.38930294 Test MSE 0.8750493300249796 Test RE 0.16373506924074227\n",
      "95 Train Loss 0.3860117 Test MSE 0.8644129397135261 Test RE 0.16273691138128957\n",
      "96 Train Loss 0.38351473 Test MSE 0.8526729007781254 Test RE 0.1616280263699342\n",
      "97 Train Loss 0.38089618 Test MSE 0.8628808161543391 Test RE 0.1625926263846989\n",
      "98 Train Loss 0.3790328 Test MSE 0.8745438374865964 Test RE 0.16368776972891208\n",
      "99 Train Loss 0.37627217 Test MSE 0.8821144917190483 Test RE 0.1643947400980493\n",
      "100 Train Loss 0.37194818 Test MSE 0.8857336287583567 Test RE 0.16473163405561164\n",
      "101 Train Loss 0.36886987 Test MSE 0.8867921942799738 Test RE 0.1648300423988111\n",
      "102 Train Loss 0.36664852 Test MSE 0.8992270898744229 Test RE 0.16598167021060356\n",
      "103 Train Loss 0.364558 Test MSE 0.8971447946442765 Test RE 0.16578938109840416\n",
      "104 Train Loss 0.36171564 Test MSE 0.8968319973580349 Test RE 0.16576047662845744\n",
      "105 Train Loss 0.35828617 Test MSE 0.8843382793228528 Test RE 0.16460182708890211\n",
      "106 Train Loss 0.3540162 Test MSE 0.8642749100986402 Test RE 0.1627239179328173\n",
      "107 Train Loss 0.3518757 Test MSE 0.866716796129473 Test RE 0.16295363245242858\n",
      "108 Train Loss 0.349285 Test MSE 0.8609352450342034 Test RE 0.16240922096697472\n",
      "109 Train Loss 0.34762913 Test MSE 0.8656729432280786 Test RE 0.1628554741672608\n",
      "110 Train Loss 0.34634593 Test MSE 0.8661185059309116 Test RE 0.16289737971093982\n",
      "111 Train Loss 0.34511077 Test MSE 0.8599229360685834 Test RE 0.1623137104923445\n",
      "112 Train Loss 0.34355602 Test MSE 0.8528242908143954 Test RE 0.1616423740680673\n",
      "113 Train Loss 0.34218308 Test MSE 0.8571586696626543 Test RE 0.16205261762349765\n",
      "114 Train Loss 0.339991 Test MSE 0.8548199873634572 Test RE 0.16183139344119102\n",
      "115 Train Loss 0.33845937 Test MSE 0.8612465308262228 Test RE 0.162438579222593\n",
      "116 Train Loss 0.3367949 Test MSE 0.8607576940675428 Test RE 0.16239247324918352\n",
      "117 Train Loss 0.33515656 Test MSE 0.8600120268672398 Test RE 0.16232211838738414\n",
      "118 Train Loss 0.3338694 Test MSE 0.8508817662324183 Test RE 0.16145817827714276\n",
      "119 Train Loss 0.33302695 Test MSE 0.8550927027335957 Test RE 0.16185720612078333\n",
      "120 Train Loss 0.33003592 Test MSE 0.8446171131717967 Test RE 0.1608627088703455\n",
      "121 Train Loss 0.3288583 Test MSE 0.8452085902167898 Test RE 0.16091902429805952\n",
      "122 Train Loss 0.32816195 Test MSE 0.8483211428301227 Test RE 0.16121505101820727\n",
      "123 Train Loss 0.3275688 Test MSE 0.8511563737621989 Test RE 0.16148423010745175\n",
      "124 Train Loss 0.32674658 Test MSE 0.8476314676269128 Test RE 0.16114950471452416\n",
      "125 Train Loss 0.3250486 Test MSE 0.8423479641360496 Test RE 0.16064647659677994\n",
      "126 Train Loss 0.32307643 Test MSE 0.8407987985179615 Test RE 0.1604986858157182\n",
      "127 Train Loss 0.3220979 Test MSE 0.8406080058117601 Test RE 0.16048047473119226\n",
      "128 Train Loss 0.32101607 Test MSE 0.8375368742602135 Test RE 0.16018705162034888\n",
      "129 Train Loss 0.3186331 Test MSE 0.8223062816355206 Test RE 0.15872386982623943\n",
      "130 Train Loss 0.31739423 Test MSE 0.8205607424622826 Test RE 0.15855531589104516\n",
      "131 Train Loss 0.31640688 Test MSE 0.8169800572973676 Test RE 0.1582089933387195\n",
      "132 Train Loss 0.31434 Test MSE 0.8290776262571151 Test RE 0.1593760419742508\n",
      "133 Train Loss 0.31099877 Test MSE 0.8253657110065561 Test RE 0.15901886552295857\n",
      "134 Train Loss 0.3079962 Test MSE 0.8170592844598078 Test RE 0.15821666436179616\n",
      "135 Train Loss 0.30238238 Test MSE 0.8366221556965557 Test RE 0.1600995533242323\n",
      "136 Train Loss 0.30047762 Test MSE 0.8354834524369826 Test RE 0.15999056269022316\n",
      "137 Train Loss 0.29828823 Test MSE 0.8505828879278081 Test RE 0.1614298191167722\n",
      "138 Train Loss 0.29591238 Test MSE 0.8513464150520378 Test RE 0.1615022567354123\n",
      "139 Train Loss 0.29381597 Test MSE 0.8568151787531401 Test RE 0.1620201445349954\n",
      "140 Train Loss 0.29160267 Test MSE 0.8619937148265541 Test RE 0.16250902664397648\n",
      "141 Train Loss 0.29022747 Test MSE 0.8697147902786742 Test RE 0.1632352194167111\n",
      "142 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "143 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "144 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "145 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "146 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "147 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "148 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "149 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "150 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "151 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "152 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "153 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "154 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "155 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "156 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "157 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "158 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "159 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "160 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "161 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "162 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "163 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "164 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "165 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "166 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "167 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "168 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "169 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "170 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "171 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "172 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "173 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "174 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "175 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "176 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "177 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "178 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "179 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "180 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "181 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "182 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "183 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "184 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "185 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "186 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "187 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "188 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "189 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "190 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "191 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "192 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "193 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "194 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "195 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "196 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "197 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "198 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "199 Train Loss 0.2899894 Test MSE 0.8679401186981974 Test RE 0.16306859189804954\n",
      "Training time: 135.80\n",
      "Training time: 135.80\n",
      "ES_atanh_low\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 24.146385 Test MSE 7.218725391037376 Test RE 0.47027912340444955\n",
      "1 Train Loss 17.646978 Test MSE 4.407730573021881 Test RE 0.36747936687725513\n",
      "2 Train Loss 13.4736595 Test MSE 2.9174843780921647 Test RE 0.29897144404865866\n",
      "3 Train Loss 9.596817 Test MSE 1.7575530222902063 Test RE 0.23204897658850124\n",
      "4 Train Loss 7.1129646 Test MSE 1.3580578023410708 Test RE 0.20397858134872557\n",
      "5 Train Loss 5.797839 Test MSE 1.3293345823632265 Test RE 0.2018099575140761\n",
      "6 Train Loss 5.0388417 Test MSE 1.238660588887517 Test RE 0.19480567270573312\n",
      "7 Train Loss 4.5769663 Test MSE 1.0443763095643208 Test RE 0.1788767705023574\n",
      "8 Train Loss 4.1177306 Test MSE 0.718339821762614 Test RE 0.1483509769865854\n",
      "9 Train Loss 3.7453675 Test MSE 0.7619588895009644 Test RE 0.15278869079958574\n",
      "10 Train Loss 3.439224 Test MSE 0.6290741846522551 Test RE 0.13882777753234743\n",
      "11 Train Loss 3.192978 Test MSE 0.5834687726839756 Test RE 0.13370087461382393\n",
      "12 Train Loss 2.9478972 Test MSE 0.48297127494321973 Test RE 0.12164271092701505\n",
      "13 Train Loss 2.7408977 Test MSE 0.4881925167149464 Test RE 0.12229846285121641\n",
      "14 Train Loss 2.5255492 Test MSE 0.5330384665073697 Test RE 0.12779230832267324\n",
      "15 Train Loss 2.3200915 Test MSE 0.5311909582952368 Test RE 0.127570652394233\n",
      "16 Train Loss 2.1731699 Test MSE 0.5623616416950027 Test RE 0.13126026736178759\n",
      "17 Train Loss 1.9549083 Test MSE 0.5964129782426733 Test RE 0.13517581047428903\n",
      "18 Train Loss 1.8393004 Test MSE 0.5620448389137881 Test RE 0.13122328984341233\n",
      "19 Train Loss 1.7198519 Test MSE 0.5516574280221449 Test RE 0.1300050356255624\n",
      "20 Train Loss 1.5828648 Test MSE 0.6442069930556312 Test RE 0.1404876529149869\n",
      "21 Train Loss 1.4850522 Test MSE 0.6557158182989857 Test RE 0.14173701093799937\n",
      "22 Train Loss 1.3819119 Test MSE 0.6501796054708616 Test RE 0.1411373993813648\n",
      "23 Train Loss 1.301412 Test MSE 0.6778453708576256 Test RE 0.14410888459328622\n",
      "24 Train Loss 1.2561783 Test MSE 0.6684458458497738 Test RE 0.14310623429028932\n",
      "25 Train Loss 1.1984648 Test MSE 0.6880138825599892 Test RE 0.14518576597550786\n",
      "26 Train Loss 1.1262167 Test MSE 0.7040973050492737 Test RE 0.14687293734367213\n",
      "27 Train Loss 1.0857843 Test MSE 0.7171596852721777 Test RE 0.14822906646379014\n",
      "28 Train Loss 1.0365529 Test MSE 0.7326987450397768 Test RE 0.14982633749714722\n",
      "29 Train Loss 0.99259067 Test MSE 0.7328445991261227 Test RE 0.149841249284765\n",
      "30 Train Loss 0.9716687 Test MSE 0.7715959671832261 Test RE 0.15375187264325857\n",
      "31 Train Loss 0.9278953 Test MSE 0.8227543278049245 Test RE 0.1587671055031313\n",
      "32 Train Loss 0.90627676 Test MSE 0.8319464860093629 Test RE 0.15965154853977556\n",
      "33 Train Loss 0.8855716 Test MSE 0.8488858110824413 Test RE 0.16126869690357187\n",
      "34 Train Loss 0.8708494 Test MSE 0.8871342281800816 Test RE 0.1648618266361448\n",
      "35 Train Loss 0.85732615 Test MSE 0.8949479582460047 Test RE 0.16558627264602144\n",
      "36 Train Loss 0.8313827 Test MSE 0.8914846541391481 Test RE 0.16526556600411946\n",
      "37 Train Loss 0.80622613 Test MSE 0.9248883854505507 Test RE 0.1683333251689729\n",
      "38 Train Loss 0.7918241 Test MSE 0.9170678228831197 Test RE 0.16762012774682092\n",
      "39 Train Loss 0.77599794 Test MSE 0.9254885610316173 Test RE 0.1683879334699357\n",
      "40 Train Loss 0.75393677 Test MSE 0.9152302908398805 Test RE 0.16745211302001284\n",
      "41 Train Loss 0.7425784 Test MSE 0.9289270093563095 Test RE 0.168700447556246\n",
      "42 Train Loss 0.7195188 Test MSE 0.9241674244103415 Test RE 0.1682677035052844\n",
      "43 Train Loss 0.692505 Test MSE 0.8835224488510861 Test RE 0.1645258843333169\n",
      "44 Train Loss 0.6711069 Test MSE 0.8728536293955002 Test RE 0.16352951568448362\n",
      "45 Train Loss 0.6593852 Test MSE 0.8678247214019155 Test RE 0.16305775111553042\n",
      "46 Train Loss 0.64353555 Test MSE 0.8724158539950979 Test RE 0.16348850183327848\n",
      "47 Train Loss 0.6303237 Test MSE 0.8773071051031994 Test RE 0.16394616523040348\n",
      "48 Train Loss 0.61965734 Test MSE 0.8523975458666662 Test RE 0.16160192687477487\n",
      "49 Train Loss 0.6116825 Test MSE 0.8467725773249473 Test RE 0.1610678390190663\n",
      "50 Train Loss 0.59440434 Test MSE 0.8582876055870963 Test RE 0.16215929963547215\n",
      "51 Train Loss 0.5792823 Test MSE 0.8655873745148877 Test RE 0.1628474251241139\n",
      "52 Train Loss 0.5733103 Test MSE 0.8761626021509158 Test RE 0.16383919122720703\n",
      "53 Train Loss 0.5633171 Test MSE 0.8809559091915036 Test RE 0.16428674535572688\n",
      "54 Train Loss 0.55587924 Test MSE 0.88398702627903 Test RE 0.16456913448902627\n",
      "55 Train Loss 0.54460794 Test MSE 0.8683879881631819 Test RE 0.16311065933006\n",
      "56 Train Loss 0.5378465 Test MSE 0.8786338702714201 Test RE 0.16407008756237082\n",
      "57 Train Loss 0.5335772 Test MSE 0.8816803517598736 Test RE 0.1643542810023419\n",
      "58 Train Loss 0.5235426 Test MSE 0.8972049771264263 Test RE 0.1657949417666505\n",
      "59 Train Loss 0.5148773 Test MSE 0.87581962415501 Test RE 0.16380712027503805\n",
      "60 Train Loss 0.50537294 Test MSE 0.8683608068028185 Test RE 0.16310810655159863\n",
      "61 Train Loss 0.4984558 Test MSE 0.8592807167895768 Test RE 0.16225308851118164\n",
      "62 Train Loss 0.49515927 Test MSE 0.8631839731742134 Test RE 0.162621185814072\n",
      "63 Train Loss 0.49110842 Test MSE 0.8592593013473758 Test RE 0.16225106662053462\n",
      "64 Train Loss 0.48283216 Test MSE 0.8541240058127884 Test RE 0.16176549968524945\n",
      "65 Train Loss 0.47278187 Test MSE 0.8537387864949143 Test RE 0.16172901656171312\n",
      "66 Train Loss 0.46503812 Test MSE 0.8577922559276474 Test RE 0.162112498804149\n",
      "67 Train Loss 0.45926514 Test MSE 0.8371059565302577 Test RE 0.16014583772050947\n",
      "68 Train Loss 0.45445293 Test MSE 0.8378273065485202 Test RE 0.16021482320919192\n",
      "69 Train Loss 0.4465865 Test MSE 0.8259048479091667 Test RE 0.15907079337848076\n",
      "70 Train Loss 0.4416426 Test MSE 0.8260248881482543 Test RE 0.15908235294392958\n",
      "71 Train Loss 0.43684044 Test MSE 0.8205962219656758 Test RE 0.15855874367083636\n",
      "72 Train Loss 0.43300435 Test MSE 0.8235047838514962 Test RE 0.15883949684355186\n",
      "73 Train Loss 0.43005812 Test MSE 0.8307256047819503 Test RE 0.15953436123026965\n",
      "74 Train Loss 0.42699146 Test MSE 0.8392192315396444 Test RE 0.16034785448441707\n",
      "75 Train Loss 0.42319566 Test MSE 0.8348690598981322 Test RE 0.15993172544717404\n",
      "76 Train Loss 0.41993117 Test MSE 0.8279983554814131 Test RE 0.15927227248697728\n",
      "77 Train Loss 0.41749936 Test MSE 0.8277810994916309 Test RE 0.15925137563065658\n",
      "78 Train Loss 0.41519868 Test MSE 0.8343090389384059 Test RE 0.1598780762298647\n",
      "79 Train Loss 0.41247803 Test MSE 0.8394511133104071 Test RE 0.1603700055356582\n",
      "80 Train Loss 0.4087688 Test MSE 0.8343150903133306 Test RE 0.1598786560392531\n",
      "81 Train Loss 0.40508655 Test MSE 0.8410346390062122 Test RE 0.1605211938369759\n",
      "82 Train Loss 0.4019148 Test MSE 0.8512665362941916 Test RE 0.16149467997109654\n",
      "83 Train Loss 0.39837265 Test MSE 0.8551130259731101 Test RE 0.16185912956324244\n",
      "84 Train Loss 0.39494854 Test MSE 0.8549290304018378 Test RE 0.16184171492663937\n",
      "85 Train Loss 0.3908684 Test MSE 0.8480760794592592 Test RE 0.1611917634001586\n",
      "86 Train Loss 0.38626572 Test MSE 0.8325942766372253 Test RE 0.1597136923521684\n",
      "87 Train Loss 0.38310415 Test MSE 0.8378271801901451 Test RE 0.16021481112765357\n",
      "88 Train Loss 0.3806517 Test MSE 0.8319874750907887 Test RE 0.1596554814187716\n",
      "89 Train Loss 0.37867287 Test MSE 0.8321256087719846 Test RE 0.1596687345534146\n",
      "90 Train Loss 0.3738596 Test MSE 0.8446807251339136 Test RE 0.16086876640796866\n",
      "91 Train Loss 0.3711791 Test MSE 0.8478241041644109 Test RE 0.1611678154546481\n",
      "92 Train Loss 0.36858416 Test MSE 0.8422394889799686 Test RE 0.1606361324673802\n",
      "93 Train Loss 0.36608887 Test MSE 0.8388702874782665 Test RE 0.16031451501429778\n",
      "94 Train Loss 0.36317083 Test MSE 0.8421554812692644 Test RE 0.16062812108199692\n",
      "95 Train Loss 0.3599485 Test MSE 0.8419103077192159 Test RE 0.16060473785037113\n",
      "96 Train Loss 0.35732993 Test MSE 0.8428181513342905 Test RE 0.16069130568309156\n",
      "97 Train Loss 0.35362032 Test MSE 0.8321417237780068 Test RE 0.15967028062418465\n",
      "98 Train Loss 0.35056165 Test MSE 0.830003817821802 Test RE 0.1594650393963192\n",
      "99 Train Loss 0.34832168 Test MSE 0.828728269029262 Test RE 0.1593424594500011\n",
      "100 Train Loss 0.34724116 Test MSE 0.8272140392773853 Test RE 0.15919681978846997\n",
      "101 Train Loss 0.345457 Test MSE 0.8287027722979087 Test RE 0.15934000825865022\n",
      "102 Train Loss 0.34278226 Test MSE 0.8316701812445204 Test RE 0.15962503472694714\n",
      "103 Train Loss 0.33898002 Test MSE 0.8284727445613657 Test RE 0.15931789226816\n",
      "104 Train Loss 0.3346745 Test MSE 0.8139451420228178 Test RE 0.1579148627585811\n",
      "105 Train Loss 0.33232445 Test MSE 0.8108788479396157 Test RE 0.15761713366266664\n",
      "106 Train Loss 0.3299472 Test MSE 0.811596365804332 Test RE 0.15768685314204403\n",
      "107 Train Loss 0.3286593 Test MSE 0.818772181320484 Test RE 0.15838242157468407\n",
      "108 Train Loss 0.32718524 Test MSE 0.8255810268265943 Test RE 0.15903960605302814\n",
      "109 Train Loss 0.3246525 Test MSE 0.8300498518863486 Test RE 0.15946946149774613\n",
      "110 Train Loss 0.32295957 Test MSE 0.8323222368049206 Test RE 0.15968759798847487\n",
      "111 Train Loss 0.32147428 Test MSE 0.8368769481718206 Test RE 0.1601239305510796\n",
      "112 Train Loss 0.31966174 Test MSE 0.8433001085596835 Test RE 0.16073724398374598\n",
      "113 Train Loss 0.31886992 Test MSE 0.8444371444392829 Test RE 0.16084556986161744\n",
      "114 Train Loss 0.3182205 Test MSE 0.8416517726282765 Test RE 0.16058007658403978\n",
      "115 Train Loss 0.31685477 Test MSE 0.8421918384829686 Test RE 0.1606315883324191\n",
      "116 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "117 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "118 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "119 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "120 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "121 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "122 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "123 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "124 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "125 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "126 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "127 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "128 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "129 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "130 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "131 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "132 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "133 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "134 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "135 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "136 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "137 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "138 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "139 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "140 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "141 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "142 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "143 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "144 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "145 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "146 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "147 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "148 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "149 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "150 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "151 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "152 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "153 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "154 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "155 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "156 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "157 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "158 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "159 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "160 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "161 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "162 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "163 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "164 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "165 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "166 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "167 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "168 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "169 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "170 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "171 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "172 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "173 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "174 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "175 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "176 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "177 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "178 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "179 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "180 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "181 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "182 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "183 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "184 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "185 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "186 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "187 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "188 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "189 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "190 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "191 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "192 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "193 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "194 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "195 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "196 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "197 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "198 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "199 Train Loss 0.31670296 Test MSE 0.8425943795611311 Test RE 0.1606699721573328\n",
      "Training time: 114.04\n",
      "Training time: 114.04\n",
      "ES_atanh_low\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 24.683271 Test MSE 7.353777299299515 Test RE 0.4746578593602618\n",
      "1 Train Loss 22.347149 Test MSE 6.51565694638939 Test RE 0.4467911320954809\n",
      "2 Train Loss 17.383842 Test MSE 4.702759011001752 Test RE 0.37957867162892334\n",
      "3 Train Loss 12.174375 Test MSE 2.6785895370723853 Test RE 0.286469588045702\n",
      "4 Train Loss 7.698917 Test MSE 1.6737018135140438 Test RE 0.22644591096230163\n",
      "5 Train Loss 5.4950633 Test MSE 1.3231724023924634 Test RE 0.20134166539983392\n",
      "6 Train Loss 4.8791738 Test MSE 1.259093803320355 Test RE 0.19640587873256582\n",
      "7 Train Loss 4.244363 Test MSE 1.0936149159811805 Test RE 0.18304490797506742\n",
      "8 Train Loss 3.7126849 Test MSE 0.8680496770364942 Test RE 0.16307888348373914\n",
      "9 Train Loss 3.291591 Test MSE 0.7219844521110889 Test RE 0.14872684393364585\n",
      "10 Train Loss 2.9296064 Test MSE 0.6017621216798106 Test RE 0.13578064367459902\n",
      "11 Train Loss 2.8014944 Test MSE 0.5996472433262583 Test RE 0.1355418347815762\n",
      "12 Train Loss 2.582417 Test MSE 0.6720506769785627 Test RE 0.14349159098918737\n",
      "13 Train Loss 2.3998637 Test MSE 0.6853597022565836 Test RE 0.14490545072807176\n",
      "14 Train Loss 2.22514 Test MSE 0.6888274924173584 Test RE 0.1452715852241905\n",
      "15 Train Loss 2.0923915 Test MSE 0.7609537098694388 Test RE 0.15268787777255896\n",
      "16 Train Loss 1.9527483 Test MSE 0.8333581524870037 Test RE 0.15978694139177693\n",
      "17 Train Loss 1.864362 Test MSE 0.8557195548966975 Test RE 0.16191652246833352\n",
      "18 Train Loss 1.7579812 Test MSE 0.8317094583139976 Test RE 0.15962880396726575\n",
      "19 Train Loss 1.6901666 Test MSE 0.8079551059777724 Test RE 0.15733272127575892\n",
      "20 Train Loss 1.6072915 Test MSE 0.8031483471581166 Test RE 0.15686401416476248\n",
      "21 Train Loss 1.5325785 Test MSE 0.7808709346562644 Test RE 0.15467319922112072\n",
      "22 Train Loss 1.4899492 Test MSE 0.8092292785430074 Test RE 0.15745673191770296\n",
      "23 Train Loss 1.4388465 Test MSE 0.8446972770667128 Test RE 0.16087034255140836\n",
      "24 Train Loss 1.3977983 Test MSE 0.8673800395694495 Test RE 0.16301596957329492\n",
      "25 Train Loss 1.3527429 Test MSE 0.8839614989365272 Test RE 0.16456675829861525\n",
      "26 Train Loss 1.3041587 Test MSE 0.9383866092291179 Test RE 0.1695572406739493\n",
      "27 Train Loss 1.247605 Test MSE 0.9008811955493992 Test RE 0.16613425963111603\n",
      "28 Train Loss 1.210654 Test MSE 0.8627581570360896 Test RE 0.16258106964557129\n",
      "29 Train Loss 1.1722957 Test MSE 0.8393805425227734 Test RE 0.16036326441917625\n",
      "30 Train Loss 1.1343495 Test MSE 0.8634925541191443 Test RE 0.16265025106357464\n",
      "31 Train Loss 1.0892987 Test MSE 0.9028995051084334 Test RE 0.1663202568364053\n",
      "32 Train Loss 1.0368396 Test MSE 0.87371700991479 Test RE 0.163610373056616\n",
      "33 Train Loss 0.9806758 Test MSE 0.8422025144098392 Test RE 0.16063260644110722\n",
      "34 Train Loss 0.9545127 Test MSE 0.8488179669392325 Test RE 0.16126225236471786\n",
      "35 Train Loss 0.9207054 Test MSE 0.8259420179131118 Test RE 0.1590743728437841\n",
      "36 Train Loss 0.9024377 Test MSE 0.8393834104879979 Test RE 0.16036353838065712\n",
      "37 Train Loss 0.8766235 Test MSE 0.8460063862372331 Test RE 0.16099495246433326\n",
      "38 Train Loss 0.84006035 Test MSE 0.8829746980757975 Test RE 0.1644748764880861\n",
      "39 Train Loss 0.81308216 Test MSE 0.8690828421813638 Test RE 0.1631759040336653\n",
      "40 Train Loss 0.7899791 Test MSE 0.862448037359851 Test RE 0.16255184701815653\n",
      "41 Train Loss 0.7730068 Test MSE 0.8723135552013153 Test RE 0.1634789162859918\n",
      "42 Train Loss 0.7431451 Test MSE 0.8632871642985606 Test RE 0.162630905967612\n",
      "43 Train Loss 0.7182721 Test MSE 0.8876688392709223 Test RE 0.16491149425337046\n",
      "44 Train Loss 0.69904053 Test MSE 0.9091246704414844 Test RE 0.16689263094323326\n",
      "45 Train Loss 0.6923721 Test MSE 0.8729572987731405 Test RE 0.1635392266481528\n",
      "46 Train Loss 0.6761774 Test MSE 0.871732105778465 Test RE 0.16342442294116258\n",
      "47 Train Loss 0.6649845 Test MSE 0.8911103768133275 Test RE 0.16523087014736812\n",
      "48 Train Loss 0.6520237 Test MSE 0.9135268062085932 Test RE 0.16729620419583263\n",
      "49 Train Loss 0.639748 Test MSE 0.9156172806477209 Test RE 0.16748751143995075\n",
      "50 Train Loss 0.6311015 Test MSE 0.9138481568745453 Test RE 0.16732562644116297\n",
      "51 Train Loss 0.62317085 Test MSE 0.9164951935133321 Test RE 0.16756778745428508\n",
      "52 Train Loss 0.6099587 Test MSE 0.936745708569432 Test RE 0.16940892849570863\n",
      "53 Train Loss 0.600723 Test MSE 0.9371726354049826 Test RE 0.1694475286079492\n",
      "54 Train Loss 0.5960498 Test MSE 0.9366810321931774 Test RE 0.1694030800863536\n",
      "55 Train Loss 0.5884994 Test MSE 0.9368213328905376 Test RE 0.1694157666250591\n",
      "56 Train Loss 0.57472354 Test MSE 0.9321069073625746 Test RE 0.16898894810696954\n",
      "57 Train Loss 0.5687022 Test MSE 0.928284026758437 Test RE 0.1686420521022333\n",
      "58 Train Loss 0.56365967 Test MSE 0.9119504451733007 Test RE 0.16715180061561788\n",
      "59 Train Loss 0.5560277 Test MSE 0.8972256544189676 Test RE 0.16579685223908913\n",
      "60 Train Loss 0.54538244 Test MSE 0.8817582011071036 Test RE 0.16436153680147683\n",
      "61 Train Loss 0.538608 Test MSE 0.9006031688620753 Test RE 0.16610862177655575\n",
      "62 Train Loss 0.53286535 Test MSE 0.9290227419434157 Test RE 0.16870914022749608\n",
      "63 Train Loss 0.524487 Test MSE 0.9165898038165393 Test RE 0.16757643628854368\n",
      "64 Train Loss 0.52039886 Test MSE 0.9095777307591811 Test RE 0.16693421105478362\n",
      "65 Train Loss 0.51721054 Test MSE 0.9073870653092599 Test RE 0.1667330641644281\n",
      "66 Train Loss 0.5122686 Test MSE 0.9073579837204404 Test RE 0.16673039226097475\n",
      "67 Train Loss 0.50316465 Test MSE 0.8831598223943247 Test RE 0.1644921174711585\n",
      "68 Train Loss 0.49893272 Test MSE 0.8877601383162084 Test RE 0.16491997482303333\n",
      "69 Train Loss 0.49254644 Test MSE 0.8927070989055005 Test RE 0.16537883705998993\n",
      "70 Train Loss 0.48641655 Test MSE 0.9033615540761806 Test RE 0.16636280768150064\n",
      "71 Train Loss 0.48352814 Test MSE 0.9032927963512557 Test RE 0.16635647635945996\n",
      "72 Train Loss 0.48088297 Test MSE 0.9030357612208043 Test RE 0.16633280601632947\n",
      "73 Train Loss 0.47727028 Test MSE 0.8961530871437201 Test RE 0.16569772363408297\n",
      "74 Train Loss 0.47484386 Test MSE 0.9074435048995667 Test RE 0.1667382494926442\n",
      "75 Train Loss 0.47226328 Test MSE 0.906139262657202 Test RE 0.16661838238068938\n",
      "76 Train Loss 0.46863136 Test MSE 0.9031167247172934 Test RE 0.1663402623011731\n",
      "77 Train Loss 0.46681672 Test MSE 0.9026104900019359 Test RE 0.1662936354273931\n",
      "78 Train Loss 0.46281222 Test MSE 0.8944696674655532 Test RE 0.16554201925047146\n",
      "79 Train Loss 0.4589171 Test MSE 0.8812681432438897 Test RE 0.16431585655832448\n",
      "80 Train Loss 0.45671457 Test MSE 0.8725137142342975 Test RE 0.1634976709555433\n",
      "81 Train Loss 0.45416808 Test MSE 0.8759415487460224 Test RE 0.1638185218356748\n",
      "82 Train Loss 0.45178685 Test MSE 0.878893980433548 Test RE 0.16409437136278082\n",
      "83 Train Loss 0.45005074 Test MSE 0.8818461638020891 Test RE 0.16436973481038694\n",
      "84 Train Loss 0.4485631 Test MSE 0.8737368989284452 Test RE 0.16361223523303509\n",
      "85 Train Loss 0.44662988 Test MSE 0.8769326726556003 Test RE 0.1639111755928572\n",
      "86 Train Loss 0.4443805 Test MSE 0.8747218381603858 Test RE 0.16370442701333027\n",
      "87 Train Loss 0.44162768 Test MSE 0.8678801441313078 Test RE 0.16306295778982238\n",
      "88 Train Loss 0.4378217 Test MSE 0.8521108175786449 Test RE 0.16157474487424567\n",
      "89 Train Loss 0.43487114 Test MSE 0.8466015988052855 Test RE 0.1610515769602091\n",
      "90 Train Loss 0.43045378 Test MSE 0.845300450977641 Test RE 0.16092776873260156\n",
      "91 Train Loss 0.42654568 Test MSE 0.8482800151342893 Test RE 0.16121114301473322\n",
      "92 Train Loss 0.42285544 Test MSE 0.8506516299453336 Test RE 0.16143634216550332\n",
      "93 Train Loss 0.4195927 Test MSE 0.8483927837366405 Test RE 0.16122185819769685\n",
      "94 Train Loss 0.4167562 Test MSE 0.8507126774902896 Test RE 0.16144213485148515\n",
      "95 Train Loss 0.41458097 Test MSE 0.8480324471516009 Test RE 0.16118761680338095\n",
      "96 Train Loss 0.41218638 Test MSE 0.8524512502750993 Test RE 0.16160701757408075\n",
      "97 Train Loss 0.4088268 Test MSE 0.858200934129667 Test RE 0.16215111185693734\n",
      "98 Train Loss 0.404915 Test MSE 0.8602669590009638 Test RE 0.16234617506131194\n",
      "99 Train Loss 0.40240207 Test MSE 0.8521098457867595 Test RE 0.16157465274006105\n",
      "100 Train Loss 0.39941645 Test MSE 0.8448847221736698 Test RE 0.16088819077153196\n",
      "101 Train Loss 0.39654526 Test MSE 0.8614908247094273 Test RE 0.16246161556367603\n",
      "102 Train Loss 0.39354753 Test MSE 0.873675477839402 Test RE 0.16360648440673073\n",
      "103 Train Loss 0.3911961 Test MSE 0.8825084268646161 Test RE 0.1644314437447174\n",
      "104 Train Loss 0.38940942 Test MSE 0.8777590674171151 Test RE 0.16398838986703326\n",
      "105 Train Loss 0.3871714 Test MSE 0.8905974799188955 Test RE 0.16518331229131453\n",
      "106 Train Loss 0.38481113 Test MSE 0.8879559843122592 Test RE 0.16493816506057588\n",
      "107 Train Loss 0.38322127 Test MSE 0.8922528228174972 Test RE 0.1653367531495428\n",
      "108 Train Loss 0.38150454 Test MSE 0.8953119710179718 Test RE 0.1656199446543504\n",
      "109 Train Loss 0.3804191 Test MSE 0.8912561745734632 Test RE 0.1652443866017297\n",
      "110 Train Loss 0.37944648 Test MSE 0.8963946762909886 Test RE 0.1657200569132817\n",
      "111 Train Loss 0.3784355 Test MSE 0.8957633774408114 Test RE 0.16566169126783806\n",
      "112 Train Loss 0.37714642 Test MSE 0.8905910849500943 Test RE 0.16518271923774733\n",
      "113 Train Loss 0.3744948 Test MSE 0.8959576175410404 Test RE 0.16567965159090628\n",
      "114 Train Loss 0.37212414 Test MSE 0.8908800346341748 Test RE 0.1652095135907056\n",
      "115 Train Loss 0.37092653 Test MSE 0.9006432779156963 Test RE 0.16611232062287917\n",
      "116 Train Loss 0.36994615 Test MSE 0.9053442540975639 Test RE 0.1665452743537136\n",
      "117 Train Loss 0.3683884 Test MSE 0.9029123695025036 Test RE 0.16632144168681925\n",
      "118 Train Loss 0.36772513 Test MSE 0.901924529882751 Test RE 0.16623043403311547\n",
      "119 Train Loss 0.36557037 Test MSE 0.8959961174831922 Test RE 0.16568321123946259\n",
      "120 Train Loss 0.36360472 Test MSE 0.8792718347942389 Test RE 0.16412964132276822\n",
      "121 Train Loss 0.36254388 Test MSE 0.8776064775082288 Test RE 0.16397413535119174\n",
      "122 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "123 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "124 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "125 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "126 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "127 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "128 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "129 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "130 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "131 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "132 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "133 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "134 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "135 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "136 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "137 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "138 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "139 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "140 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "141 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "142 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "143 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "144 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "145 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "146 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "147 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "148 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "149 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "150 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "151 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "152 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "153 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "154 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "155 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "156 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "157 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "158 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "159 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "160 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "161 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "162 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "163 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "164 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "165 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "166 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "167 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "168 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "169 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "170 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "171 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "172 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "173 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "174 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "175 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "176 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "177 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "178 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "179 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "180 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "181 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "182 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "183 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "184 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "185 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "186 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "187 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "188 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "189 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "190 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "191 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "192 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "193 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "194 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "195 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "196 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "197 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "198 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "199 Train Loss 0.36229968 Test MSE 0.881406437922928 Test RE 0.1643287488416696\n",
      "Training time: 119.95\n",
      "Training time: 119.95\n",
      "ES_atanh_low\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 23.711864 Test MSE 7.293580592305124 Test RE 0.4727111350773202\n",
      "1 Train Loss 19.22957 Test MSE 5.039839980124603 Test RE 0.3929468513670999\n",
      "2 Train Loss 13.866524 Test MSE 3.1241410610523856 Test RE 0.3093789469754893\n",
      "3 Train Loss 8.341457 Test MSE 1.682121087335319 Test RE 0.22701474542612615\n",
      "4 Train Loss 5.804312 Test MSE 1.245418239664082 Test RE 0.1953363419291953\n",
      "5 Train Loss 4.909946 Test MSE 1.1734727251111468 Test RE 0.1896103061203201\n",
      "6 Train Loss 4.5631847 Test MSE 1.0189810036467124 Test RE 0.17668858118477862\n",
      "7 Train Loss 4.316 Test MSE 0.869792731880307 Test RE 0.1632425336130159\n",
      "8 Train Loss 3.9699423 Test MSE 0.6746485487232133 Test RE 0.14376866324774018\n",
      "9 Train Loss 3.6798131 Test MSE 0.6021618673350606 Test RE 0.13582573517284377\n",
      "10 Train Loss 3.3557467 Test MSE 0.6682621161486146 Test RE 0.14308656577653261\n",
      "11 Train Loss 3.2332864 Test MSE 0.614624306192016 Test RE 0.13722407280031043\n",
      "12 Train Loss 3.0129118 Test MSE 0.6240899794302351 Test RE 0.13827671201932687\n",
      "13 Train Loss 2.8786304 Test MSE 0.6769901796354258 Test RE 0.14401794973257578\n",
      "14 Train Loss 2.7343836 Test MSE 0.6923877064537282 Test RE 0.14564652044226092\n",
      "15 Train Loss 2.552543 Test MSE 0.7531050554778383 Test RE 0.1518984075745636\n",
      "16 Train Loss 2.3932507 Test MSE 0.8360124417285432 Test RE 0.16004120396979563\n",
      "17 Train Loss 2.1977289 Test MSE 0.7758068201399647 Test RE 0.15417083907919352\n",
      "18 Train Loss 2.0699494 Test MSE 0.7576045014097199 Test RE 0.15235149235322432\n",
      "19 Train Loss 1.9750725 Test MSE 0.7628802245990876 Test RE 0.15288103636941472\n",
      "20 Train Loss 1.8779997 Test MSE 0.7259050148201212 Test RE 0.14913010987104147\n",
      "21 Train Loss 1.795172 Test MSE 0.7523408377635917 Test RE 0.15182131811869676\n",
      "22 Train Loss 1.7299987 Test MSE 0.777451521072964 Test RE 0.15433417270164154\n",
      "23 Train Loss 1.6896279 Test MSE 0.7598107263089217 Test RE 0.1525731629645974\n",
      "24 Train Loss 1.6455895 Test MSE 0.77683606264473 Test RE 0.1542730723816507\n",
      "25 Train Loss 1.6121322 Test MSE 0.7990367743169249 Test RE 0.15646198048159463\n",
      "26 Train Loss 1.582408 Test MSE 0.7466012096474872 Test RE 0.15124108492403526\n",
      "27 Train Loss 1.5413411 Test MSE 0.7326076611251817 Test RE 0.14981702453355553\n",
      "28 Train Loss 1.5233686 Test MSE 0.7155141579544267 Test RE 0.1480589125496635\n",
      "29 Train Loss 1.4856122 Test MSE 0.7826500568364535 Test RE 0.15484930127768304\n",
      "30 Train Loss 1.4434459 Test MSE 0.811384361890295 Test RE 0.1576662564421942\n",
      "31 Train Loss 1.402159 Test MSE 0.8451824692995841 Test RE 0.16091653770183012\n",
      "32 Train Loss 1.3497455 Test MSE 0.7933057596116925 Test RE 0.155899866458613\n",
      "33 Train Loss 1.2976389 Test MSE 0.7373934889799656 Test RE 0.15030557479819315\n",
      "34 Train Loss 1.2664595 Test MSE 0.7213208087006595 Test RE 0.14865847384510936\n",
      "35 Train Loss 1.2219075 Test MSE 0.7087843950441 Test RE 0.14736098410072354\n",
      "36 Train Loss 1.1890028 Test MSE 0.7233903044153235 Test RE 0.1488715743986041\n",
      "37 Train Loss 1.1639882 Test MSE 0.74880801150972 Test RE 0.1514644389959954\n",
      "38 Train Loss 1.1459252 Test MSE 0.7490263338406231 Test RE 0.15148651785925774\n",
      "39 Train Loss 1.1282021 Test MSE 0.7589534873999801 Test RE 0.15248707010047083\n",
      "40 Train Loss 1.1079687 Test MSE 0.7468412234652769 Test RE 0.1512653931041019\n",
      "41 Train Loss 1.0751634 Test MSE 0.7335599489554193 Test RE 0.149914363535365\n",
      "42 Train Loss 1.0422955 Test MSE 0.7364001952632843 Test RE 0.15020430736339552\n",
      "43 Train Loss 1.0274817 Test MSE 0.697661745594871 Test RE 0.14620017572264649\n",
      "44 Train Loss 1.0029396 Test MSE 0.7065677699166758 Test RE 0.14713037811807797\n",
      "45 Train Loss 0.98523015 Test MSE 0.7112924718609808 Test RE 0.14762147677745954\n",
      "46 Train Loss 0.958083 Test MSE 0.735718101125429 Test RE 0.15013472752508894\n",
      "47 Train Loss 0.94013953 Test MSE 0.7124487516839257 Test RE 0.147741415079086\n",
      "48 Train Loss 0.9243136 Test MSE 0.7326793126296932 Test RE 0.14982435066002217\n",
      "49 Train Loss 0.90466225 Test MSE 0.7434839176984461 Test RE 0.15092501540385986\n",
      "50 Train Loss 0.87932616 Test MSE 0.7838378695956308 Test RE 0.15496676261280568\n",
      "51 Train Loss 0.86185175 Test MSE 0.7970178503993376 Test RE 0.15626418944521464\n",
      "52 Train Loss 0.84821904 Test MSE 0.7787482601692791 Test RE 0.15446282880962328\n",
      "53 Train Loss 0.82470745 Test MSE 0.7933609368024743 Test RE 0.15590528805488824\n",
      "54 Train Loss 0.81374466 Test MSE 0.7818894559362727 Test RE 0.15477403957806982\n",
      "55 Train Loss 0.80597097 Test MSE 0.799541150937542 Test RE 0.15651135450161477\n",
      "56 Train Loss 0.795729 Test MSE 0.7736431179864788 Test RE 0.15395570002731981\n",
      "57 Train Loss 0.782935 Test MSE 0.7858169629691804 Test RE 0.15516227520413778\n",
      "58 Train Loss 0.7766284 Test MSE 0.7908148234042371 Test RE 0.15565491554542543\n",
      "59 Train Loss 0.76675415 Test MSE 0.8017672239047539 Test RE 0.15672908158493426\n",
      "60 Train Loss 0.7530222 Test MSE 0.8140179583100362 Test RE 0.1579219262056415\n",
      "61 Train Loss 0.7343597 Test MSE 0.8027327083500005 Test RE 0.15682341941686653\n",
      "62 Train Loss 0.7143668 Test MSE 0.8096595788716013 Test RE 0.15749858944857953\n",
      "63 Train Loss 0.7050868 Test MSE 0.7933986816167496 Test RE 0.15590899667342456\n",
      "64 Train Loss 0.7011873 Test MSE 0.7908259512577215 Test RE 0.155656010681069\n",
      "65 Train Loss 0.6919271 Test MSE 0.7979025363086067 Test RE 0.15635089163450094\n",
      "66 Train Loss 0.68301857 Test MSE 0.7963583567377782 Test RE 0.15619952554242633\n",
      "67 Train Loss 0.67539936 Test MSE 0.8017705790284841 Test RE 0.15672940951359918\n",
      "68 Train Loss 0.6638608 Test MSE 0.7838049542103496 Test RE 0.15496350885048762\n",
      "69 Train Loss 0.6486985 Test MSE 0.7743364360700565 Test RE 0.15402467005024767\n",
      "70 Train Loss 0.6378275 Test MSE 0.7816055617816893 Test RE 0.15474593878071796\n",
      "71 Train Loss 0.6244517 Test MSE 0.8206082879252325 Test RE 0.15855990938200135\n",
      "72 Train Loss 0.6134729 Test MSE 0.817672934517436 Test RE 0.158276067298745\n",
      "73 Train Loss 0.6030034 Test MSE 0.8001901724201719 Test RE 0.15657486506986212\n",
      "74 Train Loss 0.5973863 Test MSE 0.7967651632104277 Test RE 0.1562394164185505\n",
      "75 Train Loss 0.5898856 Test MSE 0.7980570917275552 Test RE 0.1563660336514618\n",
      "76 Train Loss 0.5773782 Test MSE 0.7935867884067392 Test RE 0.15592747779991528\n",
      "77 Train Loss 0.5714465 Test MSE 0.8002946311439193 Test RE 0.15658508456355225\n",
      "78 Train Loss 0.5619217 Test MSE 0.8168241502521445 Test RE 0.158193896841969\n",
      "79 Train Loss 0.5570184 Test MSE 0.8361270718789331 Test RE 0.16005217564769356\n",
      "80 Train Loss 0.5513527 Test MSE 0.856702114688571 Test RE 0.16200945421291482\n",
      "81 Train Loss 0.5466866 Test MSE 0.8456077379569865 Test RE 0.16095701662579115\n",
      "82 Train Loss 0.5413003 Test MSE 0.8443610100902419 Test RE 0.1608383187897809\n",
      "83 Train Loss 0.5386493 Test MSE 0.8431245454014605 Test RE 0.1607205115021588\n",
      "84 Train Loss 0.53226286 Test MSE 0.8409348144855935 Test RE 0.1605116672217869\n",
      "85 Train Loss 0.5230758 Test MSE 0.8407717348908891 Test RE 0.1604961027295266\n",
      "86 Train Loss 0.5157306 Test MSE 0.820370708766157 Test RE 0.15853695491186157\n",
      "87 Train Loss 0.50979805 Test MSE 0.8146349213709898 Test RE 0.15798176121265248\n",
      "88 Train Loss 0.504856 Test MSE 0.8273222839482435 Test RE 0.1592072352570491\n",
      "89 Train Loss 0.5019727 Test MSE 0.8231036529825305 Test RE 0.15880080660913343\n",
      "90 Train Loss 0.49667948 Test MSE 0.823485843737951 Test RE 0.15883767022671672\n",
      "91 Train Loss 0.49294707 Test MSE 0.8235565889296479 Test RE 0.15884449290629504\n",
      "92 Train Loss 0.48897946 Test MSE 0.8275607838487642 Test RE 0.15923018167970995\n",
      "93 Train Loss 0.4818009 Test MSE 0.842460325653027 Test RE 0.16065719062511133\n",
      "94 Train Loss 0.47458786 Test MSE 0.8626188393271198 Test RE 0.1625679423650997\n",
      "95 Train Loss 0.4717956 Test MSE 0.87072756483898 Test RE 0.16333023469004657\n",
      "96 Train Loss 0.47078663 Test MSE 0.8653108000932995 Test RE 0.16282140635807885\n",
      "97 Train Loss 0.46807492 Test MSE 0.8674530795938593 Test RE 0.163022833023689\n",
      "98 Train Loss 0.4640942 Test MSE 0.8699458158038654 Test RE 0.16325689836174484\n",
      "99 Train Loss 0.460643 Test MSE 0.8711706087332204 Test RE 0.1633717822783014\n",
      "100 Train Loss 0.45060652 Test MSE 0.8840538131704964 Test RE 0.16457535112626537\n",
      "101 Train Loss 0.44314703 Test MSE 0.8840555603378485 Test RE 0.16457551375241664\n",
      "102 Train Loss 0.43501815 Test MSE 0.8873702636393834 Test RE 0.1648837571669011\n",
      "103 Train Loss 0.42856053 Test MSE 0.8976644426475359 Test RE 0.16583738876095003\n",
      "104 Train Loss 0.42596963 Test MSE 0.8974379823632332 Test RE 0.16581646894429822\n",
      "105 Train Loss 0.4234706 Test MSE 0.8910148933753591 Test RE 0.16522201757724947\n",
      "106 Train Loss 0.4202748 Test MSE 0.8833662063524471 Test RE 0.1645113362752256\n",
      "107 Train Loss 0.41906738 Test MSE 0.8848157493327251 Test RE 0.1646462568237337\n",
      "108 Train Loss 0.41697225 Test MSE 0.8896775007489413 Test RE 0.16509797381073585\n",
      "109 Train Loss 0.41488525 Test MSE 0.8904309372416975 Test RE 0.1651678668415456\n",
      "110 Train Loss 0.41249558 Test MSE 0.8905739088814184 Test RE 0.16518112636114135\n",
      "111 Train Loss 0.41058132 Test MSE 0.8846917069842417 Test RE 0.16463471553719466\n",
      "112 Train Loss 0.40767926 Test MSE 0.8724528576733536 Test RE 0.16349196899389024\n",
      "113 Train Loss 0.40678668 Test MSE 0.8674916754740553 Test RE 0.16302645969808446\n",
      "114 Train Loss 0.40419337 Test MSE 0.8556325651146436 Test RE 0.16190829229473316\n",
      "115 Train Loss 0.40175936 Test MSE 0.8370190858530195 Test RE 0.16013752793713093\n",
      "116 Train Loss 0.39991438 Test MSE 0.8426854697388432 Test RE 0.16067865668048242\n",
      "117 Train Loss 0.39898878 Test MSE 0.8402662431299307 Test RE 0.16044784845780782\n",
      "118 Train Loss 0.39787942 Test MSE 0.8382502034864044 Test RE 0.1602552526687837\n",
      "119 Train Loss 0.39578205 Test MSE 0.8450922629056404 Test RE 0.1609079501550841\n",
      "120 Train Loss 0.39054245 Test MSE 0.8540532051593007 Test RE 0.1617587949559794\n",
      "121 Train Loss 0.38838747 Test MSE 0.8498201331395725 Test RE 0.16135742230163244\n",
      "122 Train Loss 0.38600427 Test MSE 0.8499942387128077 Test RE 0.16137395038014485\n",
      "123 Train Loss 0.3838227 Test MSE 0.8459198357541678 Test RE 0.16098671697844608\n",
      "124 Train Loss 0.38152534 Test MSE 0.8459623042036023 Test RE 0.1609907580058305\n",
      "125 Train Loss 0.37807137 Test MSE 0.8524383987539181 Test RE 0.16160579937900124\n",
      "126 Train Loss 0.37570497 Test MSE 0.8444563161207876 Test RE 0.16084739573021806\n",
      "127 Train Loss 0.37367603 Test MSE 0.8428841280622805 Test RE 0.1606975951057119\n",
      "128 Train Loss 0.37179193 Test MSE 0.8427400709317521 Test RE 0.16068386212458663\n",
      "129 Train Loss 0.3686032 Test MSE 0.8514548855220181 Test RE 0.1615125449491261\n",
      "130 Train Loss 0.36664033 Test MSE 0.855679381474436 Test RE 0.16191272168036672\n",
      "131 Train Loss 0.36344892 Test MSE 0.8596167164610137 Test RE 0.1622848078637978\n",
      "132 Train Loss 0.3608979 Test MSE 0.8635828741707587 Test RE 0.1626587573297074\n",
      "133 Train Loss 0.35840163 Test MSE 0.8588692038446717 Test RE 0.1622142320345394\n",
      "134 Train Loss 0.3571176 Test MSE 0.8634428351531886 Test RE 0.1626455683835287\n",
      "135 Train Loss 0.3549861 Test MSE 0.860676684898616 Test RE 0.16238483138380927\n",
      "136 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "137 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "138 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "139 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "140 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "141 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "142 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "143 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "144 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "145 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "146 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "147 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "148 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "149 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "150 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "151 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "152 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "153 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "154 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "155 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "156 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "157 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "158 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "159 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "160 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "161 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "162 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "163 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "164 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "165 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "166 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "167 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "168 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "169 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "170 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "171 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "172 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "173 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "174 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "175 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "176 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "177 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "178 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "179 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "180 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "181 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "182 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "183 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "184 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "185 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "186 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "187 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "188 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "189 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "190 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "191 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "192 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "193 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "194 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "195 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "196 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "197 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "198 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "199 Train Loss 0.35413876 Test MSE 0.8616496821964578 Test RE 0.1624765937001851\n",
      "Training time: 129.77\n",
      "Training time: 129.77\n",
      "ES_atanh_low\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 23.861134 Test MSE 7.047895263166992 Test RE 0.46468126208862964\n",
      "1 Train Loss 16.8979 Test MSE 4.342634594323172 Test RE 0.3647556966826328\n",
      "2 Train Loss 11.243764 Test MSE 2.2204066832781324 Test RE 0.2608204875585016\n",
      "3 Train Loss 7.4471226 Test MSE 1.3046957713460197 Test RE 0.19993096716012515\n",
      "4 Train Loss 5.202564 Test MSE 1.1351478623535245 Test RE 0.1864883288988639\n",
      "5 Train Loss 4.3547077 Test MSE 1.3379461436900315 Test RE 0.20246257475507864\n",
      "6 Train Loss 3.8991947 Test MSE 0.8598124802672135 Test RE 0.16230328568218266\n",
      "7 Train Loss 3.512427 Test MSE 0.7095230247090867 Test RE 0.14743774711408977\n",
      "8 Train Loss 3.221131 Test MSE 0.628547035176487 Test RE 0.13876959812380527\n",
      "9 Train Loss 3.0016928 Test MSE 0.6115904293721706 Test RE 0.13688497462538496\n",
      "10 Train Loss 2.7102323 Test MSE 0.5889685763694162 Test RE 0.13432953196961905\n",
      "11 Train Loss 2.375606 Test MSE 0.6157705629989972 Test RE 0.13735197268730828\n",
      "12 Train Loss 2.1169295 Test MSE 0.7847855658633024 Test RE 0.1550604153083991\n",
      "13 Train Loss 1.9049467 Test MSE 0.7556676496686605 Test RE 0.15215662082588527\n",
      "14 Train Loss 1.6290127 Test MSE 0.8106947051884243 Test RE 0.15759923598247746\n",
      "15 Train Loss 1.4908082 Test MSE 0.7656973691596506 Test RE 0.1531630538409714\n",
      "16 Train Loss 1.3846163 Test MSE 0.8203419859943926 Test RE 0.1585341795442247\n",
      "17 Train Loss 1.2442269 Test MSE 0.9022643317251754 Test RE 0.16626174490594076\n",
      "18 Train Loss 1.1392976 Test MSE 0.8804690389918332 Test RE 0.1642413416220838\n",
      "19 Train Loss 1.07095 Test MSE 0.8808726195462918 Test RE 0.16427897895786933\n",
      "20 Train Loss 1.0155835 Test MSE 0.9447182192321701 Test RE 0.17012830885600744\n",
      "21 Train Loss 0.9568346 Test MSE 0.927763639842274 Test RE 0.16859477593590247\n",
      "22 Train Loss 0.9148619 Test MSE 0.9195399445039432 Test RE 0.16784590083039883\n",
      "23 Train Loss 0.8814247 Test MSE 0.8780598764314238 Test RE 0.1640164869623395\n",
      "24 Train Loss 0.84558934 Test MSE 0.8421424189993304 Test RE 0.16062687536427664\n",
      "25 Train Loss 0.8318228 Test MSE 0.8244852189112969 Test RE 0.15893402300177437\n",
      "26 Train Loss 0.79305345 Test MSE 0.759397504310831 Test RE 0.1525316689718482\n",
      "27 Train Loss 0.76492244 Test MSE 0.7933862188535586 Test RE 0.15590777215378496\n",
      "28 Train Loss 0.7421112 Test MSE 0.8269515982457644 Test RE 0.15917156447974115\n",
      "29 Train Loss 0.72161484 Test MSE 0.8335036796655826 Test RE 0.15980089237288025\n",
      "30 Train Loss 0.70141906 Test MSE 0.8559120391279614 Test RE 0.16193473207026787\n",
      "31 Train Loss 0.6799839 Test MSE 0.8596679744654908 Test RE 0.162289646224458\n",
      "32 Train Loss 0.6663841 Test MSE 0.8788493992292593 Test RE 0.16409020953119124\n",
      "33 Train Loss 0.64974046 Test MSE 0.9093215017355792 Test RE 0.1669106966253899\n",
      "34 Train Loss 0.6307249 Test MSE 0.874858817570092 Test RE 0.1637172443782211\n",
      "35 Train Loss 0.6139721 Test MSE 0.8525381829257797 Test RE 0.16161525767475748\n",
      "36 Train Loss 0.6079083 Test MSE 0.854211710231241 Test RE 0.16177380479363596\n",
      "37 Train Loss 0.58476204 Test MSE 0.8511528441016502 Test RE 0.16148389527761037\n",
      "38 Train Loss 0.57175815 Test MSE 0.8288731811442176 Test RE 0.15935639021858933\n",
      "39 Train Loss 0.5540913 Test MSE 0.8344455274319315 Test RE 0.15989115329385178\n",
      "40 Train Loss 0.54229534 Test MSE 0.8051140951636377 Test RE 0.15705586332672483\n",
      "41 Train Loss 0.53702027 Test MSE 0.8039362579728632 Test RE 0.15694093927829011\n",
      "42 Train Loss 0.5255434 Test MSE 0.8016347151229732 Test RE 0.15671612967245402\n",
      "43 Train Loss 0.51945436 Test MSE 0.8149022857063661 Test RE 0.15800768400478268\n",
      "44 Train Loss 0.5086665 Test MSE 0.8368908916506776 Test RE 0.1601252644839506\n",
      "45 Train Loss 0.49330956 Test MSE 0.8470601086768991 Test RE 0.1610951829151543\n",
      "46 Train Loss 0.48546776 Test MSE 0.8362633968956726 Test RE 0.16006522284288968\n",
      "47 Train Loss 0.48132274 Test MSE 0.81104292179871 Test RE 0.1576330790430408\n",
      "48 Train Loss 0.47378418 Test MSE 0.7944775277122554 Test RE 0.15601496147760918\n",
      "49 Train Loss 0.46670663 Test MSE 0.7989634962697657 Test RE 0.1564548059111442\n",
      "50 Train Loss 0.46301028 Test MSE 0.79190247554559 Test RE 0.15576191924957156\n",
      "51 Train Loss 0.4544453 Test MSE 0.8057443916466227 Test RE 0.15711732815024496\n",
      "52 Train Loss 0.4484834 Test MSE 0.8174747342197946 Test RE 0.15825688342731944\n",
      "53 Train Loss 0.44350535 Test MSE 0.8195140835125451 Test RE 0.15845416171337767\n",
      "54 Train Loss 0.4328844 Test MSE 0.8097935457753365 Test RE 0.1575116188292013\n",
      "55 Train Loss 0.4266508 Test MSE 0.8244185289723995 Test RE 0.15892759504261636\n",
      "56 Train Loss 0.42274687 Test MSE 0.8187943865908165 Test RE 0.15838456924208322\n",
      "57 Train Loss 0.4183552 Test MSE 0.8101995315040391 Test RE 0.15755109769190637\n",
      "58 Train Loss 0.4088136 Test MSE 0.8213606229614391 Test RE 0.15863257672407513\n",
      "59 Train Loss 0.40490896 Test MSE 0.8216425747604736 Test RE 0.15865980161252166\n",
      "60 Train Loss 0.4017858 Test MSE 0.812137110587758 Test RE 0.15773937564496135\n",
      "61 Train Loss 0.39875317 Test MSE 0.8158327055447264 Test RE 0.15809786140821774\n",
      "62 Train Loss 0.39346647 Test MSE 0.8064233728033336 Test RE 0.15718351368109074\n",
      "63 Train Loss 0.38667697 Test MSE 0.8018713305525467 Test RE 0.15673925661403376\n",
      "64 Train Loss 0.38121 Test MSE 0.7850892504762397 Test RE 0.15509041388994782\n",
      "65 Train Loss 0.37758997 Test MSE 0.7831137953428688 Test RE 0.15489517040463288\n",
      "66 Train Loss 0.3721336 Test MSE 0.7726594856276596 Test RE 0.15385779702111008\n",
      "67 Train Loss 0.36808357 Test MSE 0.7686396763924771 Test RE 0.15345704771100852\n",
      "68 Train Loss 0.36311874 Test MSE 0.7848962694957992 Test RE 0.155071351509739\n",
      "69 Train Loss 0.3605813 Test MSE 0.7995841907561845 Test RE 0.15651556699877897\n",
      "70 Train Loss 0.35630825 Test MSE 0.7935974060252898 Test RE 0.1559285208949916\n",
      "71 Train Loss 0.35011026 Test MSE 0.790949358055069 Test RE 0.1556681551108339\n",
      "72 Train Loss 0.34656638 Test MSE 0.7894218225566584 Test RE 0.15551776397017741\n",
      "73 Train Loss 0.34163794 Test MSE 0.798520291284332 Test RE 0.15641140519926014\n",
      "74 Train Loss 0.33364058 Test MSE 0.8256094624277593 Test RE 0.15904234494098685\n",
      "75 Train Loss 0.3304977 Test MSE 0.8416197749077451 Test RE 0.16057702410710264\n",
      "76 Train Loss 0.32909173 Test MSE 0.8424225581229423 Test RE 0.1606535894506109\n",
      "77 Train Loss 0.3277902 Test MSE 0.8471248363627772 Test RE 0.1611013378025686\n",
      "78 Train Loss 0.32501933 Test MSE 0.843705013836865 Test RE 0.16077582784446243\n",
      "79 Train Loss 0.32128108 Test MSE 0.853369476519477 Test RE 0.1616940324419977\n",
      "80 Train Loss 0.3182281 Test MSE 0.8553034587549389 Test RE 0.16187715148986717\n",
      "81 Train Loss 0.31140682 Test MSE 0.8530069690881036 Test RE 0.16165968535308683\n",
      "82 Train Loss 0.30934814 Test MSE 0.8524440722199189 Test RE 0.16160633716770484\n",
      "83 Train Loss 0.30681023 Test MSE 0.8527512217878328 Test RE 0.1616354492512839\n",
      "84 Train Loss 0.30396214 Test MSE 0.8456305732306507 Test RE 0.16095918989866012\n",
      "85 Train Loss 0.30038255 Test MSE 0.8343968708565591 Test RE 0.15988649159389137\n",
      "86 Train Loss 0.29859045 Test MSE 0.828066851924284 Test RE 0.15927886027693222\n",
      "87 Train Loss 0.2976207 Test MSE 0.8316075675905055 Test RE 0.15961902579753862\n",
      "88 Train Loss 0.29545838 Test MSE 0.82786965764578 Test RE 0.15925989396400966\n",
      "89 Train Loss 0.29190522 Test MSE 0.8204746754991626 Test RE 0.15854700039916686\n",
      "90 Train Loss 0.2903592 Test MSE 0.8175510396289964 Test RE 0.15826426932804394\n",
      "91 Train Loss 0.2891982 Test MSE 0.8177009943969041 Test RE 0.1582787830357361\n",
      "92 Train Loss 0.2864465 Test MSE 0.8259004744329989 Test RE 0.15907037220814463\n",
      "93 Train Loss 0.28475666 Test MSE 0.8306715764672161 Test RE 0.1595291732880779\n",
      "94 Train Loss 0.2829469 Test MSE 0.8334062390009624 Test RE 0.15979155134616926\n",
      "95 Train Loss 0.28153205 Test MSE 0.8260932559954752 Test RE 0.15908893621588677\n",
      "96 Train Loss 0.2802561 Test MSE 0.8289480061187283 Test RE 0.15936358285614782\n",
      "97 Train Loss 0.27914968 Test MSE 0.830660043580393 Test RE 0.15952806584782195\n",
      "98 Train Loss 0.27785945 Test MSE 0.840418275254077 Test RE 0.16046236297872798\n",
      "99 Train Loss 0.2769295 Test MSE 0.8369596545062308 Test RE 0.16013184266778516\n",
      "100 Train Loss 0.2751901 Test MSE 0.8407340436466517 Test RE 0.16049250522181185\n",
      "101 Train Loss 0.27307034 Test MSE 0.8396585355528928 Test RE 0.16038981744075914\n",
      "102 Train Loss 0.27227712 Test MSE 0.8467029575840341 Test RE 0.16106121756484176\n",
      "103 Train Loss 0.27150196 Test MSE 0.8488104120073744 Test RE 0.16126153470316593\n",
      "104 Train Loss 0.27085146 Test MSE 0.8464682245751017 Test RE 0.1610388903693778\n",
      "105 Train Loss 0.27029598 Test MSE 0.8530763965893736 Test RE 0.16166626407990223\n",
      "106 Train Loss 0.26883692 Test MSE 0.8556539691635577 Test RE 0.16191031738790793\n",
      "107 Train Loss 0.26577356 Test MSE 0.8718245228117485 Test RE 0.16343308546486826\n",
      "108 Train Loss 0.2626208 Test MSE 0.8641499966389171 Test RE 0.16271215828213959\n",
      "109 Train Loss 0.25970578 Test MSE 0.8600686643191604 Test RE 0.1623274632892752\n",
      "110 Train Loss 0.2579705 Test MSE 0.8674883164681055 Test RE 0.16302614407120664\n",
      "111 Train Loss 0.25580147 Test MSE 0.8762703160170034 Test RE 0.16384926196652982\n",
      "112 Train Loss 0.25373137 Test MSE 0.8687180332063301 Test RE 0.16314165282098347\n",
      "113 Train Loss 0.25161535 Test MSE 0.8686681906755662 Test RE 0.16313697264330992\n",
      "114 Train Loss 0.24977098 Test MSE 0.8605833584076945 Test RE 0.16237602713849647\n",
      "115 Train Loss 0.24860671 Test MSE 0.8536294100267315 Test RE 0.16171865629958343\n",
      "116 Train Loss 0.24780773 Test MSE 0.857395723737274 Test RE 0.1620750245471089\n",
      "117 Train Loss 0.24719882 Test MSE 0.8547033045639645 Test RE 0.16182034808384366\n",
      "118 Train Loss 0.24562465 Test MSE 0.8579737547284566 Test RE 0.16212964845063269\n",
      "119 Train Loss 0.24437705 Test MSE 0.8561922178702285 Test RE 0.16196123418446076\n",
      "120 Train Loss 0.24305569 Test MSE 0.8510895809397202 Test RE 0.1614778939044591\n",
      "121 Train Loss 0.24166016 Test MSE 0.8428767806611777 Test RE 0.1606968947056087\n",
      "122 Train Loss 0.24066168 Test MSE 0.8430167624260849 Test RE 0.16071023811568586\n",
      "123 Train Loss 0.239137 Test MSE 0.840012318683983 Test RE 0.1604236033391903\n",
      "124 Train Loss 0.23853794 Test MSE 0.8415426813474184 Test RE 0.16056966939754672\n",
      "125 Train Loss 0.23720261 Test MSE 0.8400815767263958 Test RE 0.16043021657299172\n",
      "126 Train Loss 0.23666343 Test MSE 0.8390349420095816 Test RE 0.16033024761120135\n",
      "127 Train Loss 0.23567644 Test MSE 0.8449325293521607 Test RE 0.16089274257691347\n",
      "128 Train Loss 0.23444939 Test MSE 0.8386711167473503 Test RE 0.16029548236104094\n",
      "129 Train Loss 0.23348607 Test MSE 0.8399699367414357 Test RE 0.1604195562856229\n",
      "130 Train Loss 0.23274931 Test MSE 0.8371586472820612 Test RE 0.1601508777466511\n",
      "131 Train Loss 0.23203015 Test MSE 0.8358845943410257 Test RE 0.16002896633366356\n",
      "132 Train Loss 0.23169805 Test MSE 0.8350276366740722 Test RE 0.15994691360925983\n",
      "133 Train Loss 0.23079798 Test MSE 0.8337070221754931 Test RE 0.15982038378829808\n",
      "134 Train Loss 0.22969587 Test MSE 0.8362033497663709 Test RE 0.16005947607117268\n",
      "135 Train Loss 0.22851491 Test MSE 0.8358779975115056 Test RE 0.16002833485540735\n",
      "136 Train Loss 0.22786885 Test MSE 0.8379403572468792 Test RE 0.16022563199195666\n",
      "137 Train Loss 0.2272307 Test MSE 0.8441105812425563 Test RE 0.1608144655200587\n",
      "138 Train Loss 0.22673348 Test MSE 0.8459946856434463 Test RE 0.1609938391494195\n",
      "139 Train Loss 0.22613047 Test MSE 0.8422278830980687 Test RE 0.16063502569761384\n",
      "140 Train Loss 0.22581494 Test MSE 0.8400040916901427 Test RE 0.16042281775117057\n",
      "141 Train Loss 0.22561044 Test MSE 0.84048662878832 Test RE 0.16046888826913208\n",
      "142 Train Loss 0.22498843 Test MSE 0.8376873425221557 Test RE 0.1602014402314761\n",
      "143 Train Loss 0.22383942 Test MSE 0.8361423012048853 Test RE 0.16005363324650554\n",
      "144 Train Loss 0.22326173 Test MSE 0.8377281469851162 Test RE 0.16020534195817018\n",
      "145 Train Loss 0.2224362 Test MSE 0.8351519174055964 Test RE 0.15995881595773706\n",
      "146 Train Loss 0.22167243 Test MSE 0.8341145573403405 Test RE 0.15985944095532964\n",
      "147 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "148 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "149 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "150 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "151 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "152 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "153 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "154 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "155 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "156 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "157 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "158 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "159 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "160 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "161 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "162 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "163 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "164 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "165 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "166 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "167 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "168 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "169 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "170 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "171 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "172 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "173 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "174 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "175 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "176 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "177 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "178 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "179 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "180 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "181 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "182 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "183 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "184 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "185 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "186 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "187 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "188 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "189 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "190 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "191 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "192 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "193 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "194 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "195 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "196 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "197 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "198 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "199 Train Loss 0.2215242 Test MSE 0.8335819139699154 Test RE 0.1598083918108562\n",
      "Training time: 134.61\n",
      "Training time: 134.61\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200 #200\n",
    "\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val = 1.0\n",
    "\n",
    "N_T = 5000 #Total number of data points for 'y'\n",
    "N_f = 10000 #Total number of collocation points \n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    alpha_val = []\n",
    "\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers,n_val)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.1, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-08, \n",
    "                              tolerance_change = 1e-08, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    alpha_full.append(alpha_val)  \n",
    "\n",
    "\n",
    "    if(nan_flag == 1):\n",
    "        nan_tune.append(tune_reps)\n",
    "        break\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full, \"label\": label}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_tune' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1149/1090202970.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr_tune\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lr_tune' is not defined"
     ]
    }
   ],
   "source": [
    "lr_tune[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "img3 = ax.imshow(np.transpose(np.flipud(np.transpose(u_pred.reshape(500,500)))),vmin = 0,vmax = 1000,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "for tune_reps in range(25):\n",
    "    label = \"MW_atanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn_tune[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
