{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "#     y = xt[:,0]*np.cos(xt[:,1])\n",
    "#     return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 25000\n",
    "level = \"_high\"\n",
    "label = \"ES_rowdy\" + level\n",
    "ES_val = 1000.0\n",
    "\n",
    "\n",
    "x = np.linspace(0,1,500).reshape(-1,1)\n",
    "y = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xy = np.hstack((X,Y))\n",
    "\n",
    "# bound_pts_1 = (X == 0).reshape(-1,)\n",
    "# bound_pts_2 = np.logical_and(Y == 0,X != 0).reshape(-1,)\n",
    "# bound_pts_3 = np.logical_and(X == 1,Y != 0).reshape(-1,) \n",
    "# bound_pts_4 = np.logical_and(Y == 1,X != 1).reshape(-1,) \n",
    "\n",
    "# xy_bound_1 = xy[bound_pts_1,:]\n",
    "# xy_bound_2 = xy[bound_pts_2,:]\n",
    "# xy_bound_3 = xy[bound_pts_3,:]\n",
    "# xy_bound_4 = xy[bound_pts_4,:]\n",
    "\n",
    "# u_bound_1 = 1000*np.ones((np.shape(xy_bound_1)[0],1))\n",
    "# u_bound_2 = 800*np.ones((np.shape(xy_bound_2)[0],1))\n",
    "# u_bound_3 = 500*np.ones((np.shape(xy_bound_3)[0],1))\n",
    "# u_bound_4 = np.zeros((np.shape(xy_bound_4)[0],1))\n",
    "\n",
    "# xy_bound = np.vstack((xy_bound_1,xy_bound_2,xy_bound_3,xy_bound_4))\n",
    "# u_bound = np.vstack((u_bound_1,u_bound_2,u_bound_3,u_bound_4))\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "\n",
    "lb_xy = xy[0]\n",
    "ub_xy = xy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_data = scipy.io.loadmat('./../ES_FEA' + level + '.mat')\n",
    "\n",
    "xy = np.array(fea_data['xy'])\n",
    "u_true = np.array(fea_data['u'])\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "u_true_norm = np.linalg.norm(u_true,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_T,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    N_t = int(N_T/4)\n",
    "    \n",
    "    x_BC1 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC1 = np.zeros((N_t,1))\n",
    "    u_BC1 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC2 = np.ones((N_t,1))\n",
    "    y_BC2 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC2 = ES_val*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC3 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC3 = np.ones((N_t,1)) \n",
    "    u_BC3 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC4 = np.zeros((N_t,1))\n",
    "    y_BC4 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC4 = ES_val*np.ones((N_t,1))\n",
    "    \n",
    "    XY_corners = np.array([[0,0],[1,0],[0,1],[1,1]]).reshape(-1,2)\n",
    "    U_corners = ES_val*np.ones((4,1))\n",
    "    \n",
    "    XY_1 = np.hstack((x_BC1,y_BC1))\n",
    "    XY_2 = np.hstack((x_BC2,y_BC2))\n",
    "    XY_3 = np.hstack((x_BC3,y_BC3))\n",
    "    XY_4 = np.hstack((x_BC4,y_BC4))\n",
    "    \n",
    "    xy_BC = np.vstack((XY_1,XY_2,XY_3,XY_4,XY_corners)) #choose indices from  set 'idx' (x,t)\n",
    "    u_BC = np.vstack((u_BC1,u_BC2,u_BC3,u_BC4,U_corners))\n",
    "    \n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xy_coll = lb_xy + (ub_xy - lb_xy)*samples\n",
    "    \n",
    "    xy_coll = np.vstack((xy_coll, xy_BC)) # append training points to collocation points \n",
    "\n",
    "    return xy_coll, xy_BC, u_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "\n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        self.omega1.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        self.omega.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xy):\n",
    "        if torch.is_tensor(xy) != True:         \n",
    "            xy = torch.from_numpy(xy)                \n",
    "        \n",
    "        ubxy = torch.from_numpy(ub_xy).float().to(device)\n",
    "        lbxy = torch.from_numpy(lb_xy).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xy = 2.0*(xy - lbxy)/(ubxy - lbxy) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xy.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "                \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xy,u):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xy), u)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xy_coll, f_hat):\n",
    "        \n",
    "        g = xy_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy = autograd.grad(u_x_y,g,torch.ones(xy_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2u_dx2 + d2u_dy2\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xy_BC,u_BC,xy_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xy_BC,u_BC)\n",
    "        loss_f = self.loss_PDE(xy_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    'callable for optimizer'  \n",
    "    def closure(self):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = self.loss(xy_BC, u_BC, xy_coll,f_hat)\n",
    "        self.train_loss.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        u_pred = self.test(xy_test_tensor)\n",
    "        #self.test_loss.append(np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))) #Commented because no true values yet\n",
    "        self.beta_val.append(self.beta.cpu().detach().numpy())\n",
    "        \n",
    "        #print(self.iter,\"Train Loss\",self.train_loss[-1],\"Test Loss\",self.test_loss[-1])\n",
    "        print(self.iter,\"Train Loss\",self.train_loss[-1])\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        self.iter += 1\n",
    "  \n",
    "\n",
    "        return loss        \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        u_pred = self.forward(xy_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "     \n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    omega_val.append(PINN.omega.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xy_BC,u_BC,xy_coll,f_hat,seed):\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xy_BC,u_BC,xy_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xy_coll_np_array, xy_BC_np_array, u_BC_np_array = trainingdata(N_T,N_f,rep*22)\n",
    "        \n",
    "    xy_coll = torch.from_numpy(xy_coll_np_array).float().to(device)\n",
    "    xy_BC = torch.from_numpy(xy_BC_np_array).float().to(device)\n",
    "    u_BC = torch.from_numpy(u_BC_np_array).float().to(device)\n",
    "        \n",
    "    f_hat = torch.zeros(xy_coll.shape[0],1).to(device)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(xy_BC,u_BC,xy_coll,f_hat,i)\n",
    "        loss_np = PINN.loss(xy_BC,u_BC,xy_coll,f_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "\n",
    "            \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES_rowdy_high\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 478769.34 Test MSE 303992.4135982271 Test RE 0.9646447712793137\n",
      "1 Train Loss 429138.2 Test MSE 255096.0019929177 Test RE 0.8836654354786452\n",
      "2 Train Loss 361272.9 Test MSE 184444.0855207416 Test RE 0.7513951864511919\n",
      "3 Train Loss 322407.44 Test MSE 147401.85649680224 Test RE 0.6717188233371305\n",
      "4 Train Loss 275740.4 Test MSE 97946.22562793051 Test RE 0.547557704774788\n",
      "5 Train Loss 252163.55 Test MSE 76713.74211349247 Test RE 0.4845879671930971\n",
      "6 Train Loss 249762.53 Test MSE 74917.71602068948 Test RE 0.4788817716943218\n",
      "7 Train Loss 248334.3 Test MSE 74213.86273403474 Test RE 0.4766269116635858\n",
      "8 Train Loss 247047.47 Test MSE 73573.5391761199 Test RE 0.47456626829388443\n",
      "9 Train Loss 245730.19 Test MSE 72946.97101623648 Test RE 0.47254119313018556\n",
      "10 Train Loss 243980.12 Test MSE 72129.66760167977 Test RE 0.4698865427145621\n",
      "11 Train Loss 242731.4 Test MSE 71560.34627053238 Test RE 0.4680284556538477\n",
      "12 Train Loss 241310.61 Test MSE 70957.19552782006 Test RE 0.46605187872498494\n",
      "13 Train Loss 239419.95 Test MSE 70195.58836827948 Test RE 0.4635439862144362\n",
      "14 Train Loss 237859.14 Test MSE 69640.4555438353 Test RE 0.46170740878560657\n",
      "15 Train Loss 235649.72 Test MSE 68685.4574047329 Test RE 0.45853072208858975\n",
      "16 Train Loss 233971.98 Test MSE 67985.35758244414 Test RE 0.456187871765544\n",
      "17 Train Loss 232149.77 Test MSE 67301.38146430535 Test RE 0.45388730015955087\n",
      "18 Train Loss 228966.8 Test MSE 65841.16517216171 Test RE 0.4489363753123664\n",
      "19 Train Loss 225970.78 Test MSE 64989.05174772682 Test RE 0.4460218574351373\n",
      "20 Train Loss 224044.88 Test MSE 64110.74503511434 Test RE 0.442997682014141\n",
      "21 Train Loss 222031.22 Test MSE 63396.1754545326 Test RE 0.4405219684577115\n",
      "22 Train Loss 221165.48 Test MSE 63061.780767034405 Test RE 0.43935862563836425\n",
      "23 Train Loss 219805.05 Test MSE 62318.936355825295 Test RE 0.43676321885621555\n",
      "24 Train Loss 218380.4 Test MSE 61651.44873900723 Test RE 0.43441787321160863\n",
      "25 Train Loss 216335.19 Test MSE 60793.56775567363 Test RE 0.4313848188605232\n",
      "26 Train Loss 214036.89 Test MSE 59784.48032991053 Test RE 0.4277896481578793\n",
      "27 Train Loss 210128.0 Test MSE 58611.871496293956 Test RE 0.42357355332909086\n",
      "28 Train Loss 208186.5 Test MSE 57871.01507144751 Test RE 0.42088804669598295\n",
      "29 Train Loss 206398.4 Test MSE 57155.32460821439 Test RE 0.4182773902382952\n",
      "30 Train Loss 204258.02 Test MSE 55518.1010624168 Test RE 0.41224305075043205\n",
      "31 Train Loss 202620.45 Test MSE 54890.84771177244 Test RE 0.40990763799097835\n",
      "32 Train Loss 200956.45 Test MSE 54452.44824981472 Test RE 0.40826744161207135\n",
      "33 Train Loss 199997.44 Test MSE 54029.56586435356 Test RE 0.40667903167752495\n",
      "34 Train Loss 197926.16 Test MSE 53291.98649407289 Test RE 0.40389362317833316\n",
      "35 Train Loss 195867.3 Test MSE 53124.841056726014 Test RE 0.40325973806878984\n",
      "36 Train Loss 194852.36 Test MSE 52419.576564018564 Test RE 0.40057403587774293\n",
      "37 Train Loss 193177.1 Test MSE 51191.54343917318 Test RE 0.39585410576747876\n",
      "38 Train Loss 192405.9 Test MSE 51262.50353492604 Test RE 0.39612837096628295\n",
      "39 Train Loss 191454.4 Test MSE 51399.66418744715 Test RE 0.39665796790781993\n",
      "40 Train Loss 190023.9 Test MSE 50474.19918019384 Test RE 0.39307077990503025\n",
      "41 Train Loss 189422.12 Test MSE 50152.183774014185 Test RE 0.39181491675031743\n",
      "42 Train Loss 188829.69 Test MSE 49919.79718246397 Test RE 0.3909061003524555\n",
      "43 Train Loss 187849.56 Test MSE 49603.46150167621 Test RE 0.3896655697589209\n",
      "44 Train Loss 187469.8 Test MSE 49641.77582054483 Test RE 0.3898160319299931\n",
      "45 Train Loss 186760.9 Test MSE 49356.61549452373 Test RE 0.3886947972341886\n",
      "46 Train Loss 186123.83 Test MSE 49146.78653060309 Test RE 0.3878676913480194\n",
      "47 Train Loss 185315.88 Test MSE 48761.50125641574 Test RE 0.386344359341179\n",
      "48 Train Loss 184803.53 Test MSE 48726.078292600505 Test RE 0.3862040032377501\n",
      "49 Train Loss 183904.42 Test MSE 48186.05898545488 Test RE 0.38405793794398874\n",
      "50 Train Loss 182835.39 Test MSE 48426.677202746534 Test RE 0.3850156450163804\n",
      "51 Train Loss 182007.78 Test MSE 47815.313456565375 Test RE 0.3825776061903917\n",
      "52 Train Loss 180785.45 Test MSE 46991.3198070542 Test RE 0.37926683134137007\n",
      "53 Train Loss 180040.05 Test MSE 46583.84124413242 Test RE 0.377618871790931\n",
      "54 Train Loss 179511.53 Test MSE 46597.47821763505 Test RE 0.3776741399010083\n",
      "55 Train Loss 178667.64 Test MSE 46150.751623974495 Test RE 0.3758594129234388\n",
      "56 Train Loss 177924.5 Test MSE 46285.50435868124 Test RE 0.37640773732551086\n",
      "57 Train Loss 177142.5 Test MSE 46327.05344990234 Test RE 0.37657664432406346\n",
      "58 Train Loss 175694.92 Test MSE 45757.420134529246 Test RE 0.3742543070224967\n",
      "59 Train Loss 175097.0 Test MSE 45163.45364517321 Test RE 0.3718173183869407\n",
      "60 Train Loss 174538.97 Test MSE 45036.21748184042 Test RE 0.37129320018801204\n",
      "61 Train Loss 172979.11 Test MSE 44218.006834647065 Test RE 0.3679049431988125\n",
      "62 Train Loss 172120.1 Test MSE 44257.58539950959 Test RE 0.36806955818053644\n",
      "63 Train Loss 170856.31 Test MSE 43918.39406811553 Test RE 0.36665639782399295\n",
      "64 Train Loss 169872.69 Test MSE 43247.21382412308 Test RE 0.36384390873793676\n",
      "65 Train Loss 169270.62 Test MSE 43159.049652328045 Test RE 0.3634728517454776\n",
      "66 Train Loss 168384.78 Test MSE 42765.1256502616 Test RE 0.36181029322012764\n",
      "67 Train Loss 167320.84 Test MSE 42456.79420010483 Test RE 0.36050362922812335\n",
      "68 Train Loss 166267.94 Test MSE 41981.71667640588 Test RE 0.3584809968097288\n",
      "69 Train Loss 165414.58 Test MSE 41732.689385379876 Test RE 0.3574161960104134\n",
      "70 Train Loss 164544.7 Test MSE 41438.668309563735 Test RE 0.3561549108407652\n",
      "71 Train Loss 163794.72 Test MSE 41559.81196605091 Test RE 0.3566751305084556\n",
      "72 Train Loss 163242.28 Test MSE 41312.643430044365 Test RE 0.3556129224084574\n",
      "73 Train Loss 162612.61 Test MSE 40893.34494106723 Test RE 0.35380369138528706\n",
      "74 Train Loss 161993.16 Test MSE 40839.48742793635 Test RE 0.3535706306625061\n",
      "75 Train Loss 161344.69 Test MSE 40346.8049438833 Test RE 0.35143144336305154\n",
      "76 Train Loss 160925.61 Test MSE 40432.783382811096 Test RE 0.3518056916691068\n",
      "77 Train Loss 160100.45 Test MSE 40232.23378617517 Test RE 0.35093211594452534\n",
      "78 Train Loss 159543.14 Test MSE 40003.85183830406 Test RE 0.3499346492809783\n",
      "79 Train Loss 158794.77 Test MSE 39832.65063680865 Test RE 0.3491850531255371\n",
      "80 Train Loss 157314.95 Test MSE 39576.038523604555 Test RE 0.3480584660864623\n",
      "81 Train Loss 156603.06 Test MSE 39613.55451426426 Test RE 0.34822339751466513\n",
      "82 Train Loss 156191.81 Test MSE 39428.58797681102 Test RE 0.3474094710753193\n",
      "83 Train Loss 155758.69 Test MSE 39222.55024867245 Test RE 0.3465005719969329\n",
      "84 Train Loss 154811.05 Test MSE 38772.20814927202 Test RE 0.3445056188819512\n",
      "85 Train Loss 153933.08 Test MSE 38340.538069562965 Test RE 0.34258247575238626\n",
      "86 Train Loss 152945.72 Test MSE 38081.69443466518 Test RE 0.3414241004311485\n",
      "87 Train Loss 152249.27 Test MSE 37914.92294519182 Test RE 0.3406756794018623\n",
      "88 Train Loss 151919.53 Test MSE 37844.51733740271 Test RE 0.34035922585756256\n",
      "89 Train Loss 151510.55 Test MSE 37710.01789499069 Test RE 0.33975386904985094\n",
      "90 Train Loss 150990.44 Test MSE 37625.239054463906 Test RE 0.33937174053318675\n",
      "91 Train Loss 150145.69 Test MSE 37865.1964965205 Test RE 0.3404522034123882\n",
      "92 Train Loss 149612.0 Test MSE 37570.98690178309 Test RE 0.3391269807693564\n",
      "93 Train Loss 148733.8 Test MSE 37289.94528764404 Test RE 0.337856216998033\n",
      "94 Train Loss 148167.98 Test MSE 36620.96252256867 Test RE 0.3348119260767281\n",
      "95 Train Loss 147623.23 Test MSE 36327.7622773393 Test RE 0.3334689217929011\n",
      "96 Train Loss 146825.34 Test MSE 35943.72345763419 Test RE 0.33170160578282043\n",
      "97 Train Loss 146269.89 Test MSE 36020.11645933924 Test RE 0.3320539097355573\n",
      "98 Train Loss 146037.14 Test MSE 35744.498276644 Test RE 0.33078106763754567\n",
      "99 Train Loss 145556.1 Test MSE 35782.054379386565 Test RE 0.33095479488170376\n",
      "100 Train Loss 145033.2 Test MSE 35593.52571808323 Test RE 0.3300817753079899\n",
      "101 Train Loss 144657.2 Test MSE 35548.229974315575 Test RE 0.32987168008787066\n",
      "102 Train Loss 144082.89 Test MSE 35402.172758597764 Test RE 0.32919330973572314\n",
      "103 Train Loss 143466.11 Test MSE 35351.34789597306 Test RE 0.3289569229159107\n",
      "104 Train Loss 142794.45 Test MSE 35512.19992081385 Test RE 0.329704466313582\n",
      "105 Train Loss 142476.0 Test MSE 35393.69357106821 Test RE 0.32915388476904633\n",
      "106 Train Loss 142056.1 Test MSE 35382.69148986251 Test RE 0.32910272227549425\n",
      "107 Train Loss 141491.25 Test MSE 35368.665661851286 Test RE 0.3290374870500118\n",
      "108 Train Loss 141235.94 Test MSE 35271.531907611614 Test RE 0.32858535492194174\n",
      "109 Train Loss 140877.53 Test MSE 34755.683920900556 Test RE 0.32617371591432015\n",
      "110 Train Loss 140773.78 Test MSE 34704.00628367143 Test RE 0.32593113462389417\n",
      "111 Train Loss 140210.92 Test MSE 34152.77140193777 Test RE 0.32333224480758793\n",
      "112 Train Loss 139711.52 Test MSE 33976.19637271964 Test RE 0.3224953231799888\n",
      "113 Train Loss 139198.28 Test MSE 33982.68696391727 Test RE 0.3225261254117244\n",
      "114 Train Loss 138458.84 Test MSE 33598.53983875122 Test RE 0.3206979942571865\n",
      "115 Train Loss 138186.94 Test MSE 33512.201751980945 Test RE 0.32028568077546793\n",
      "116 Train Loss 137960.62 Test MSE 33536.70269637036 Test RE 0.320402740644211\n",
      "117 Train Loss 137615.75 Test MSE 33637.06405058216 Test RE 0.3208817983463561\n",
      "118 Train Loss 137202.48 Test MSE 33728.515426526224 Test RE 0.32131770386087766\n",
      "119 Train Loss 136722.95 Test MSE 33469.34592437313 Test RE 0.3200808225702321\n",
      "120 Train Loss 135520.8 Test MSE 33641.39517146131 Test RE 0.32090245611125906\n",
      "121 Train Loss 134466.88 Test MSE 34011.42098305857 Test RE 0.32266245238424895\n",
      "122 Train Loss 134001.62 Test MSE 33900.07715434946 Test RE 0.32213386634888014\n",
      "123 Train Loss 133585.02 Test MSE 33665.06273365857 Test RE 0.32101531771310243\n",
      "124 Train Loss 132724.0 Test MSE 33221.76726233454 Test RE 0.3188947779704251\n",
      "125 Train Loss 132131.89 Test MSE 32692.680609197865 Test RE 0.31634524261668917\n",
      "126 Train Loss 131482.19 Test MSE 31977.75863384519 Test RE 0.31286721184558447\n",
      "127 Train Loss 131128.06 Test MSE 31683.737559275058 Test RE 0.31142555386044196\n",
      "128 Train Loss 130574.18 Test MSE 31279.942420629326 Test RE 0.3094347003217262\n",
      "129 Train Loss 129818.27 Test MSE 31025.147302488076 Test RE 0.30817185170838\n",
      "130 Train Loss 128792.16 Test MSE 30565.885152909173 Test RE 0.3058824290612835\n",
      "131 Train Loss 127128.664 Test MSE 30357.008937415958 Test RE 0.3048354923969136\n",
      "132 Train Loss 126455.56 Test MSE 30038.745370896166 Test RE 0.3032333309688603\n",
      "133 Train Loss 125809.68 Test MSE 29356.359573776477 Test RE 0.2997692912581015\n",
      "134 Train Loss 125005.21 Test MSE 28961.532560426574 Test RE 0.2977466005384002\n",
      "135 Train Loss 124489.91 Test MSE 28646.94172722901 Test RE 0.2961250684779778\n",
      "136 Train Loss 123942.49 Test MSE 28461.063505751234 Test RE 0.29516278809533647\n",
      "137 Train Loss 123046.64 Test MSE 28530.59363893953 Test RE 0.2955231082402909\n",
      "138 Train Loss 122134.98 Test MSE 28724.652781974808 Test RE 0.29652644825468505\n",
      "139 Train Loss 121647.84 Test MSE 28462.890618674264 Test RE 0.2951722622158207\n",
      "140 Train Loss 121338.94 Test MSE 28308.96277114392 Test RE 0.29437303161594786\n",
      "141 Train Loss 120998.98 Test MSE 27957.615869179794 Test RE 0.2925405735915704\n",
      "142 Train Loss 120772.89 Test MSE 28024.364523864282 Test RE 0.29288958490829636\n",
      "143 Train Loss 120157.375 Test MSE 28322.789257578403 Test RE 0.2944449107572624\n",
      "144 Train Loss 119946.55 Test MSE 28306.307161368313 Test RE 0.2943592240059518\n",
      "145 Train Loss 119740.125 Test MSE 28354.354988833264 Test RE 0.294608944402356\n",
      "146 Train Loss 119454.5 Test MSE 27896.26700473376 Test RE 0.29221942874817536\n",
      "147 Train Loss 118970.586 Test MSE 27218.902375357553 Test RE 0.2886498564231403\n",
      "148 Train Loss 118570.49 Test MSE 26986.61420992479 Test RE 0.2874155375170661\n",
      "149 Train Loss 118254.234 Test MSE 26906.941891365666 Test RE 0.28699095686663634\n",
      "150 Train Loss 118009.87 Test MSE 26937.046653339716 Test RE 0.28715146152707205\n",
      "151 Train Loss 117741.95 Test MSE 27051.97275172603 Test RE 0.28776337108010414\n",
      "152 Train Loss 117416.266 Test MSE 27219.323648637714 Test RE 0.28865209016496507\n",
      "153 Train Loss 117240.53 Test MSE 27136.44621720679 Test RE 0.288212311023222\n",
      "154 Train Loss 117153.9 Test MSE 27142.06830142524 Test RE 0.2882421651528956\n",
      "155 Train Loss 117005.39 Test MSE 26924.093064028664 Test RE 0.28708240998187073\n",
      "156 Train Loss 116923.41 Test MSE 26852.246247170886 Test RE 0.28669911506935986\n",
      "157 Train Loss 116648.72 Test MSE 26809.274524735763 Test RE 0.28646962053203523\n",
      "158 Train Loss 116383.61 Test MSE 26895.26401307741 Test RE 0.28692867165420527\n",
      "159 Train Loss 116182.47 Test MSE 26697.888194110623 Test RE 0.28587389362626553\n",
      "160 Train Loss 115897.3 Test MSE 26477.15523202661 Test RE 0.28468966584789773\n",
      "161 Train Loss 115600.24 Test MSE 26356.192500428337 Test RE 0.2840386090932102\n",
      "162 Train Loss 115445.22 Test MSE 26312.935570133035 Test RE 0.28380542511192774\n",
      "163 Train Loss 115337.66 Test MSE 26249.507359368064 Test RE 0.2834631574935379\n",
      "164 Train Loss 114960.58 Test MSE 26025.057710399138 Test RE 0.2822486624093609\n",
      "165 Train Loss 114665.43 Test MSE 25829.795618085485 Test RE 0.28118783423073807\n",
      "166 Train Loss 114345.63 Test MSE 25888.31585489538 Test RE 0.2815061849676198\n",
      "167 Train Loss 114278.336 Test MSE 25812.055615133806 Test RE 0.28109125720263234\n",
      "168 Train Loss 114199.0 Test MSE 25819.172099416708 Test RE 0.2811300035094846\n",
      "169 Train Loss 114147.01 Test MSE 25757.55131698347 Test RE 0.2807943266095866\n",
      "170 Train Loss 114073.78 Test MSE 25729.810900318447 Test RE 0.28064308067205096\n",
      "171 Train Loss 114047.82 Test MSE 25736.637607661887 Test RE 0.28068030871704275\n",
      "172 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "173 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "174 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "175 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "176 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "177 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "178 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "179 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "180 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "181 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "182 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "183 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "184 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "185 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "186 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "187 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "188 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "189 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "190 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "191 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "192 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "193 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "194 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "195 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "196 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "197 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "198 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "199 Train Loss 114045.04 Test MSE 25735.982652627994 Test RE 0.2806767372685597\n",
      "Training time: 572.28\n",
      "Training time: 572.28\n",
      "ES_rowdy_high\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 490696.06 Test MSE 316338.1000875823 Test RE 0.9840378259221307\n",
      "1 Train Loss 404168.38 Test MSE 225795.55438408535 Test RE 0.8313688254035116\n",
      "2 Train Loss 277258.9 Test MSE 101042.25542343031 Test RE 0.5561443861906505\n",
      "3 Train Loss 250051.56 Test MSE 75138.74463465765 Test RE 0.4795876702816762\n",
      "4 Train Loss 250001.31 Test MSE 75081.51056074406 Test RE 0.47940498167471995\n",
      "5 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "6 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "7 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "8 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "9 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "10 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "11 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "12 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "13 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "14 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "15 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "16 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "17 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "18 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "19 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "20 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "21 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "22 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "23 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "24 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "25 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "26 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "27 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "28 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "29 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "30 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "31 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "32 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "33 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "34 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "35 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "36 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "37 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "38 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "39 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "40 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "41 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "42 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "43 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "44 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "45 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "46 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "47 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "48 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "49 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "50 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "51 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "52 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "53 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "54 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "55 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "56 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "57 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "58 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "59 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "60 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "61 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "62 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "63 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "64 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "65 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "66 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "67 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "68 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "69 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "70 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "71 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "72 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "73 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "74 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "75 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "76 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "77 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "78 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "79 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "80 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "81 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "82 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "83 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "84 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "85 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "86 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "87 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "88 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "89 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "90 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "91 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "92 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "93 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "94 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "95 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "96 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "97 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "98 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "99 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "100 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "101 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "102 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "103 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "104 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "105 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "106 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "107 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "108 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "109 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "110 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "111 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "112 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "113 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "114 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "115 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "116 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "117 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "118 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "119 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "120 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "121 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "122 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "123 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "124 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "125 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "126 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "127 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "128 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "129 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "130 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "131 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "132 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "133 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "134 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "135 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "136 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "137 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "138 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "139 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "140 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "141 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "142 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "143 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "144 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "145 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "146 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "147 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "148 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "149 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "150 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "151 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "152 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "153 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "154 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "155 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "156 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "157 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "158 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "159 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "160 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "161 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "162 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "163 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "164 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "165 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "166 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "167 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "168 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "169 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "170 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "171 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "172 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "173 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "174 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "175 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "176 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "177 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "178 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "179 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "180 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "181 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "182 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "183 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "184 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "185 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "186 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "187 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "188 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "189 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "190 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "191 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "192 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "193 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "194 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "195 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "196 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "197 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "198 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "199 Train Loss 250001.2 Test MSE 75081.26297910925 Test RE 0.4794041912539754\n",
      "Training time: 146.00\n",
      "Training time: 146.00\n",
      "ES_rowdy_high\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 484287.7 Test MSE 310371.4620888838 Test RE 0.9747133916090993\n",
      "1 Train Loss 433177.5 Test MSE 258113.8898343705 Test RE 0.8888771246634741\n",
      "2 Train Loss 365550.22 Test MSE 191045.30027034483 Test RE 0.7647231210537588\n",
      "3 Train Loss 263770.62 Test MSE 88740.22745486908 Test RE 0.5211902835129213\n",
      "4 Train Loss 249576.97 Test MSE 74877.46935852196 Test RE 0.47875312400539577\n",
      "5 Train Loss 244015.56 Test MSE 72636.54793577649 Test RE 0.47153468059316517\n",
      "6 Train Loss 233308.3 Test MSE 69008.9651827506 Test RE 0.45960929099448344\n",
      "7 Train Loss 223163.05 Test MSE 66748.69280244794 Test RE 0.45201976411498007\n",
      "8 Train Loss 214663.3 Test MSE 63480.70636714812 Test RE 0.4408155612419345\n",
      "9 Train Loss 204310.47 Test MSE 60740.96338300286 Test RE 0.4311981408967601\n",
      "10 Train Loss 193271.05 Test MSE 55923.6209010617 Test RE 0.4137458811145115\n",
      "11 Train Loss 185673.02 Test MSE 53460.61516270838 Test RE 0.40453212678775685\n",
      "12 Train Loss 179379.4 Test MSE 50320.46712859057 Test RE 0.3924717247391473\n",
      "13 Train Loss 173826.67 Test MSE 47076.71266013881 Test RE 0.3796112776879353\n",
      "14 Train Loss 165301.75 Test MSE 44114.5824650457 Test RE 0.36747443292473\n",
      "15 Train Loss 160058.73 Test MSE 41704.37763365764 Test RE 0.35729493860347394\n",
      "16 Train Loss 154196.47 Test MSE 38928.53966873931 Test RE 0.3451994522999512\n",
      "17 Train Loss 145629.22 Test MSE 35747.476975201986 Test RE 0.3307948498503418\n",
      "18 Train Loss 141289.58 Test MSE 34626.63939253289 Test RE 0.3255676269069221\n",
      "19 Train Loss 137956.56 Test MSE 33851.48779760601 Test RE 0.3219029245438122\n",
      "20 Train Loss 131587.25 Test MSE 31344.91065684483 Test RE 0.30975588056222264\n",
      "21 Train Loss 126909.9 Test MSE 29848.623385245945 Test RE 0.3022721917107462\n",
      "22 Train Loss 122240.5 Test MSE 27938.574827207016 Test RE 0.29244093658882464\n",
      "23 Train Loss 116974.766 Test MSE 25473.461321488357 Test RE 0.27924153854896616\n",
      "24 Train Loss 113412.44 Test MSE 24790.459733129836 Test RE 0.2754725518942506\n",
      "25 Train Loss 109912.86 Test MSE 24292.120734758337 Test RE 0.27268971455656854\n",
      "26 Train Loss 106905.91 Test MSE 22964.847974272143 Test RE 0.265135468413068\n",
      "27 Train Loss 103491.92 Test MSE 21875.681510894578 Test RE 0.2587717350546863\n",
      "28 Train Loss 96980.07 Test MSE 19702.39733060315 Test RE 0.24558146080851478\n",
      "29 Train Loss 93800.97 Test MSE 18090.039359975774 Test RE 0.23531835172834067\n",
      "30 Train Loss 91757.94 Test MSE 17392.068040314036 Test RE 0.2307340317008062\n",
      "31 Train Loss 89633.36 Test MSE 17059.388988147613 Test RE 0.22851661269914603\n",
      "32 Train Loss 87804.14 Test MSE 16715.853192010734 Test RE 0.226204018556049\n",
      "33 Train Loss 85230.62 Test MSE 16032.284338511452 Test RE 0.2215306109169688\n",
      "34 Train Loss 83199.71 Test MSE 15096.35800271382 Test RE 0.2149671679849765\n",
      "35 Train Loss 80922.63 Test MSE 14311.723867991437 Test RE 0.20930616286229187\n",
      "36 Train Loss 79297.64 Test MSE 13969.920447495482 Test RE 0.20679165469688768\n",
      "37 Train Loss 77433.98 Test MSE 13818.58241573999 Test RE 0.20566850366382636\n",
      "38 Train Loss 76374.164 Test MSE 13573.364665907771 Test RE 0.20383548939481264\n",
      "39 Train Loss 74660.34 Test MSE 13164.873756024399 Test RE 0.20074484017588734\n",
      "40 Train Loss 74029.875 Test MSE 13023.179931748646 Test RE 0.19966160702157756\n",
      "41 Train Loss 72788.68 Test MSE 12878.232409622096 Test RE 0.1985473847970717\n",
      "42 Train Loss 71031.78 Test MSE 11687.103152647609 Test RE 0.18914265478710357\n",
      "43 Train Loss 68633.53 Test MSE 11283.459544076288 Test RE 0.18584769535491763\n",
      "44 Train Loss 67369.16 Test MSE 10994.790996307182 Test RE 0.1834549907546355\n",
      "45 Train Loss 65995.055 Test MSE 10609.794602426264 Test RE 0.1802144165052543\n",
      "46 Train Loss 64499.11 Test MSE 10562.991514969806 Test RE 0.1798164863904667\n",
      "47 Train Loss 63169.355 Test MSE 10556.548952653322 Test RE 0.1797616413394347\n",
      "48 Train Loss 62248.95 Test MSE 10248.236770678162 Test RE 0.17711715073575982\n",
      "49 Train Loss 61678.434 Test MSE 9896.542248225238 Test RE 0.1740515051687579\n",
      "50 Train Loss 60887.64 Test MSE 9654.849558994749 Test RE 0.1719130309692036\n",
      "51 Train Loss 60540.13 Test MSE 9448.957664844984 Test RE 0.17007011032284547\n",
      "52 Train Loss 60194.586 Test MSE 9347.281511367686 Test RE 0.16915260992925363\n",
      "53 Train Loss 58741.12 Test MSE 8527.365880968488 Test RE 0.1615635884453916\n",
      "54 Train Loss 57164.562 Test MSE 8363.999673317065 Test RE 0.1600084968675747\n",
      "55 Train Loss 56275.418 Test MSE 8327.506420540936 Test RE 0.15965904600551503\n",
      "56 Train Loss 55538.473 Test MSE 8090.671766014328 Test RE 0.15737231484881664\n",
      "57 Train Loss 54948.34 Test MSE 8148.175301517184 Test RE 0.15793057763173413\n",
      "58 Train Loss 54172.28 Test MSE 7912.270969286362 Test RE 0.15562759920568917\n",
      "59 Train Loss 53058.414 Test MSE 7582.72291602598 Test RE 0.15235216673860472\n",
      "60 Train Loss 52191.035 Test MSE 7374.043447597859 Test RE 0.15024114609949915\n",
      "61 Train Loss 51807.73 Test MSE 7251.371682970177 Test RE 0.14898622802378833\n",
      "62 Train Loss 51495.54 Test MSE 7257.062231667483 Test RE 0.14904467538772745\n",
      "63 Train Loss 50840.125 Test MSE 7140.031902779544 Test RE 0.14783801339229918\n",
      "64 Train Loss 50365.35 Test MSE 7163.670646820136 Test RE 0.14808253731561843\n",
      "65 Train Loss 49995.37 Test MSE 7131.775754375254 Test RE 0.14775251478097032\n",
      "66 Train Loss 49613.734 Test MSE 7234.2570604002185 Test RE 0.14881030617895674\n",
      "67 Train Loss 48760.633 Test MSE 7127.998970655684 Test RE 0.14771338685475574\n",
      "68 Train Loss 48403.734 Test MSE 7087.731142352712 Test RE 0.1472955611995463\n",
      "69 Train Loss 48080.28 Test MSE 7009.856282404237 Test RE 0.14648413770031746\n",
      "70 Train Loss 47815.336 Test MSE 6937.976703041271 Test RE 0.14573117295318389\n",
      "71 Train Loss 47612.3 Test MSE 6848.949934158449 Test RE 0.14479315708171978\n",
      "72 Train Loss 47227.094 Test MSE 6773.024749624196 Test RE 0.14398835599849155\n",
      "73 Train Loss 46979.504 Test MSE 6713.131051538879 Test RE 0.14335029946878072\n",
      "74 Train Loss 46784.406 Test MSE 6733.690697671924 Test RE 0.14356964408662298\n",
      "75 Train Loss 46369.887 Test MSE 6698.561284490419 Test RE 0.1431946556330925\n",
      "76 Train Loss 45916.53 Test MSE 6651.9502029404275 Test RE 0.14269558509389946\n",
      "77 Train Loss 45788.133 Test MSE 6652.462635167537 Test RE 0.14270108125713424\n",
      "78 Train Loss 45725.23 Test MSE 6624.165909273172 Test RE 0.14239726320420384\n",
      "79 Train Loss 45309.117 Test MSE 6629.070158820962 Test RE 0.14244996587753803\n",
      "80 Train Loss 45088.54 Test MSE 6572.489967313291 Test RE 0.1418407463362853\n",
      "81 Train Loss 44905.08 Test MSE 6556.269949229349 Test RE 0.1416656163120854\n",
      "82 Train Loss 44665.004 Test MSE 6553.062332218344 Test RE 0.14163095753223626\n",
      "83 Train Loss 44387.22 Test MSE 6639.621557063912 Test RE 0.14256328861094852\n",
      "84 Train Loss 44261.375 Test MSE 6665.698389513673 Test RE 0.1428429699098707\n",
      "85 Train Loss 44184.59 Test MSE 6664.322539404929 Test RE 0.1428282272192636\n",
      "86 Train Loss 44088.266 Test MSE 6645.105608789848 Test RE 0.14262215213729915\n",
      "87 Train Loss 43856.867 Test MSE 6734.320655968798 Test RE 0.14357635962920776\n",
      "88 Train Loss 43436.023 Test MSE 6450.856506839495 Test RE 0.1405221327541659\n",
      "89 Train Loss 43316.473 Test MSE 6466.561559750804 Test RE 0.14069308415754975\n",
      "90 Train Loss 43254.934 Test MSE 6422.741463142237 Test RE 0.14021557656083317\n",
      "91 Train Loss 43152.516 Test MSE 6395.759734580537 Test RE 0.13992074604700808\n",
      "92 Train Loss 43087.688 Test MSE 6365.017873906497 Test RE 0.13958406944209206\n",
      "93 Train Loss 43025.31 Test MSE 6425.186967017872 Test RE 0.1402422680526132\n",
      "94 Train Loss 42970.082 Test MSE 6440.855779983976 Test RE 0.14041316516558067\n",
      "95 Train Loss 42918.785 Test MSE 6409.734673756558 Test RE 0.14007352828226063\n",
      "96 Train Loss 42792.47 Test MSE 6522.7196082514565 Test RE 0.14130267931376758\n",
      "97 Train Loss 42574.62 Test MSE 6610.824140794097 Test RE 0.1422537893749343\n",
      "98 Train Loss 42482.25 Test MSE 6524.600841233111 Test RE 0.1413230545646422\n",
      "99 Train Loss 42377.637 Test MSE 6509.149922981667 Test RE 0.14115562169949578\n",
      "100 Train Loss 42340.46 Test MSE 6506.355074295417 Test RE 0.14112531428874375\n",
      "101 Train Loss 42239.785 Test MSE 6450.721283951114 Test RE 0.1405206599336007\n",
      "102 Train Loss 42089.137 Test MSE 6453.192955890471 Test RE 0.14054757845116517\n",
      "103 Train Loss 41998.773 Test MSE 6453.008491346376 Test RE 0.14054556966028936\n",
      "104 Train Loss 41914.355 Test MSE 6418.321085911763 Test RE 0.14016731738476446\n",
      "105 Train Loss 41848.805 Test MSE 6446.8375225530535 Test RE 0.14047835219314747\n",
      "106 Train Loss 41720.89 Test MSE 6434.0286392297 Test RE 0.14033872827100943\n",
      "107 Train Loss 41657.906 Test MSE 6432.303317368365 Test RE 0.14031991069000882\n",
      "108 Train Loss 41639.91 Test MSE 6389.832061743967 Test RE 0.1398558908378669\n",
      "109 Train Loss 41631.523 Test MSE 6383.943781015583 Test RE 0.1397914368315495\n",
      "110 Train Loss 41616.34 Test MSE 6347.104105702015 Test RE 0.13938750766204897\n",
      "111 Train Loss 41605.074 Test MSE 6373.867416620666 Test RE 0.13968107043651726\n",
      "112 Train Loss 41574.234 Test MSE 6337.7877529419775 Test RE 0.13928517279885916\n",
      "113 Train Loss 41498.11 Test MSE 6358.843416845646 Test RE 0.13951635046824937\n",
      "114 Train Loss 41420.105 Test MSE 6291.633994836968 Test RE 0.13877708694269728\n",
      "115 Train Loss 41358.516 Test MSE 6266.644275804968 Test RE 0.13850120861727316\n",
      "116 Train Loss 41305.598 Test MSE 6274.6642973155185 Test RE 0.13858980687314312\n",
      "117 Train Loss 41268.035 Test MSE 6272.281564761303 Test RE 0.13856349042142707\n",
      "118 Train Loss 41247.633 Test MSE 6259.923790709543 Test RE 0.13842692284705865\n",
      "119 Train Loss 41234.848 Test MSE 6244.314020715581 Test RE 0.13825422416624622\n",
      "120 Train Loss 41193.02 Test MSE 6210.64620845528 Test RE 0.13788100394591526\n",
      "121 Train Loss 41174.242 Test MSE 6207.467489236062 Test RE 0.13784571445450275\n",
      "122 Train Loss 41143.08 Test MSE 6189.703721595762 Test RE 0.13764833818349384\n",
      "123 Train Loss 41094.8 Test MSE 6168.715718425656 Test RE 0.13741477152033676\n",
      "124 Train Loss 41050.04 Test MSE 6204.349383226584 Test RE 0.13781108909875886\n",
      "125 Train Loss 41016.07 Test MSE 6195.71613601011 Test RE 0.1377151748217084\n",
      "126 Train Loss 41006.83 Test MSE 6201.504785962415 Test RE 0.1377794933611132\n",
      "127 Train Loss 41002.934 Test MSE 6205.7465616515165 Test RE 0.1378266052979341\n",
      "128 Train Loss 40997.574 Test MSE 6209.0131633758865 Test RE 0.13786287534134942\n",
      "129 Train Loss 40995.69 Test MSE 6208.953669833984 Test RE 0.13786221485230046\n",
      "130 Train Loss 40990.145 Test MSE 6211.524238101096 Test RE 0.13789075005980256\n",
      "131 Train Loss 40971.37 Test MSE 6185.2030298930495 Test RE 0.13759828527157192\n",
      "132 Train Loss 40942.555 Test MSE 6168.555258119132 Test RE 0.1374129842958353\n",
      "133 Train Loss 40898.773 Test MSE 6221.477622816342 Test RE 0.13800118433116884\n",
      "134 Train Loss 40878.04 Test MSE 6240.588641271042 Test RE 0.13821297653791448\n",
      "135 Train Loss 40867.16 Test MSE 6215.237098092196 Test RE 0.1379319551285199\n",
      "136 Train Loss 40861.492 Test MSE 6214.575907954267 Test RE 0.13792461818604948\n",
      "137 Train Loss 40857.34 Test MSE 6224.103960605904 Test RE 0.13803030920354994\n",
      "138 Train Loss 40826.594 Test MSE 6191.350863727073 Test RE 0.13766665176567736\n",
      "139 Train Loss 40783.81 Test MSE 6186.01741100427 Test RE 0.1376073434832121\n",
      "140 Train Loss 40772.535 Test MSE 6166.0386407332635 Test RE 0.13738495089343197\n",
      "141 Train Loss 40764.184 Test MSE 6155.950129483921 Test RE 0.1372725142793781\n",
      "142 Train Loss 40754.617 Test MSE 6165.024556240405 Test RE 0.13737365306632757\n",
      "143 Train Loss 40744.43 Test MSE 6166.095521388909 Test RE 0.13738558456835007\n",
      "144 Train Loss 40738.973 Test MSE 6159.756171978117 Test RE 0.13731494349667342\n",
      "145 Train Loss 40724.203 Test MSE 6181.108431254821 Test RE 0.13755273276312302\n",
      "146 Train Loss 40695.453 Test MSE 6195.228039183112 Test RE 0.1377097501329156\n",
      "147 Train Loss 40676.562 Test MSE 6155.9344521011335 Test RE 0.13727233948303652\n",
      "148 Train Loss 40653.875 Test MSE 6158.896800208477 Test RE 0.13730536448909558\n",
      "149 Train Loss 40637.12 Test MSE 6150.7307486905265 Test RE 0.13721430803648285\n",
      "150 Train Loss 40632.176 Test MSE 6141.360685080546 Test RE 0.13710975161189445\n",
      "151 Train Loss 40620.17 Test MSE 6133.133551120248 Test RE 0.1370178828562094\n",
      "152 Train Loss 40603.297 Test MSE 6137.753527932068 Test RE 0.13706947966807767\n",
      "153 Train Loss 40589.836 Test MSE 6138.349434769528 Test RE 0.13707613345902073\n",
      "154 Train Loss 40553.23 Test MSE 6132.665804815762 Test RE 0.13701265789006256\n",
      "155 Train Loss 40521.816 Test MSE 6085.381090400929 Test RE 0.1364834312059392\n",
      "156 Train Loss 40499.332 Test MSE 6099.10396946398 Test RE 0.13663723348076856\n",
      "157 Train Loss 40480.832 Test MSE 6092.871496570394 Test RE 0.13656740309897894\n",
      "158 Train Loss 40467.406 Test MSE 6097.760625532103 Test RE 0.13662218529439682\n",
      "159 Train Loss 40457.73 Test MSE 6097.385612959049 Test RE 0.1366179840943044\n",
      "160 Train Loss 40453.332 Test MSE 6102.320934491276 Test RE 0.13667326330236498\n",
      "161 Train Loss 40447.918 Test MSE 6103.483642864503 Test RE 0.13668628323203716\n",
      "162 Train Loss 40445.375 Test MSE 6105.979089496389 Test RE 0.1367142228881152\n",
      "163 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "164 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "165 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "166 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "167 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "168 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "169 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "170 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "171 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "172 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "173 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "174 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "175 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "176 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "177 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "178 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "179 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "180 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "181 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "182 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "183 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "184 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "185 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "186 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "187 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "188 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "189 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "190 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "191 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "192 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "193 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "194 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "195 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "196 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "197 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "198 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "199 Train Loss 40444.855 Test MSE 6108.078490391207 Test RE 0.13673772389350378\n",
      "Training time: 551.62\n",
      "Training time: 551.62\n",
      "ES_rowdy_high\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 474998.88 Test MSE 298593.65392094833 Test RE 0.9560405840097929\n",
      "1 Train Loss 352449.72 Test MSE 178106.22880745167 Test RE 0.7383726401814557\n",
      "2 Train Loss 252731.25 Test MSE 77723.92445489785 Test RE 0.4877681092742342\n",
      "3 Train Loss 248070.56 Test MSE 74033.64068727227 Test RE 0.4760478359544237\n",
      "4 Train Loss 241754.23 Test MSE 71621.36457617064 Test RE 0.4682279531384198\n",
      "5 Train Loss 232533.7 Test MSE 67459.30812527535 Test RE 0.45441952477819264\n",
      "6 Train Loss 221873.58 Test MSE 63553.27841352523 Test RE 0.44106746257777035\n",
      "7 Train Loss 214943.89 Test MSE 60029.63252047227 Test RE 0.4286658477795552\n",
      "8 Train Loss 206346.11 Test MSE 56504.925469240145 Test RE 0.4158906867070665\n",
      "9 Train Loss 196162.72 Test MSE 53359.2227451915 Test RE 0.40414833063784983\n",
      "10 Train Loss 188758.64 Test MSE 51115.30521683074 Test RE 0.39555922837216334\n",
      "11 Train Loss 181939.0 Test MSE 48861.543757289495 Test RE 0.3867404817997137\n",
      "12 Train Loss 175635.9 Test MSE 46015.05851407105 Test RE 0.37530645251753153\n",
      "13 Train Loss 169914.78 Test MSE 43466.70773138199 Test RE 0.3647660542304928\n",
      "14 Train Loss 159954.16 Test MSE 40330.71647592382 Test RE 0.351361368951019\n",
      "15 Train Loss 154968.56 Test MSE 38231.15579605741 Test RE 0.3420934474736449\n",
      "16 Train Loss 148935.17 Test MSE 37234.68553351898 Test RE 0.3376057906008805\n",
      "17 Train Loss 145920.73 Test MSE 35817.98574018103 Test RE 0.3311209210659977\n",
      "18 Train Loss 140473.34 Test MSE 33334.58033248802 Test RE 0.319435763785556\n",
      "19 Train Loss 135512.97 Test MSE 33323.850136240464 Test RE 0.31938434744439276\n",
      "20 Train Loss 130089.63 Test MSE 31022.69615962732 Test RE 0.3081596779039013\n",
      "21 Train Loss 125539.71 Test MSE 30681.771351984225 Test RE 0.3064617353180181\n",
      "22 Train Loss 121697.56 Test MSE 28290.32912057804 Test RE 0.2942761339093962\n",
      "23 Train Loss 117822.32 Test MSE 26308.74001115723 Test RE 0.28378279803058104\n",
      "24 Train Loss 113397.17 Test MSE 25355.503947677487 Test RE 0.2785942606225643\n",
      "25 Train Loss 110387.86 Test MSE 24465.24714487105 Test RE 0.2736596993501699\n",
      "26 Train Loss 107075.5 Test MSE 22617.252409861885 Test RE 0.2631212745880746\n",
      "27 Train Loss 104465.06 Test MSE 21309.63543034725 Test RE 0.2554018576378579\n",
      "28 Train Loss 100942.305 Test MSE 20613.15992132238 Test RE 0.2511934600627317\n",
      "29 Train Loss 100064.36 Test MSE 20249.01529817362 Test RE 0.24896482727209868\n",
      "30 Train Loss 96290.5 Test MSE 19429.865859442703 Test RE 0.24387705559168776\n",
      "31 Train Loss 94246.06 Test MSE 18723.838969715955 Test RE 0.2394051510971067\n",
      "32 Train Loss 92035.62 Test MSE 17923.835989629002 Test RE 0.23423485626299242\n",
      "33 Train Loss 89291.74 Test MSE 16180.888096162702 Test RE 0.22255492994868356\n",
      "34 Train Loss 87689.484 Test MSE 15885.202589090544 Test RE 0.22051209777046327\n",
      "35 Train Loss 86006.62 Test MSE 15016.316787530368 Test RE 0.21439653031977018\n",
      "36 Train Loss 84506.97 Test MSE 14883.780108729956 Test RE 0.213448282405037\n",
      "37 Train Loss 83162.016 Test MSE 14323.695298883786 Test RE 0.2093936844815305\n",
      "38 Train Loss 81935.47 Test MSE 13743.314220719172 Test RE 0.20510761275538228\n",
      "39 Train Loss 79866.14 Test MSE 13565.057214127293 Test RE 0.20377310203837504\n",
      "40 Train Loss 78423.28 Test MSE 13234.994520243425 Test RE 0.20127874910943902\n",
      "41 Train Loss 76341.7 Test MSE 12460.480385590909 Test RE 0.1953005358117249\n",
      "42 Train Loss 74363.375 Test MSE 12399.499861172228 Test RE 0.19482205763342755\n",
      "43 Train Loss 73055.19 Test MSE 12055.058857647196 Test RE 0.1920970561363938\n",
      "44 Train Loss 71431.28 Test MSE 11963.047469789653 Test RE 0.19136255234714306\n",
      "45 Train Loss 70104.81 Test MSE 11669.67990486127 Test RE 0.18900161434073012\n",
      "46 Train Loss 69009.9 Test MSE 11495.938811330894 Test RE 0.18758938673616715\n",
      "47 Train Loss 67694.55 Test MSE 10689.515446515501 Test RE 0.18089020520461438\n",
      "48 Train Loss 66399.46 Test MSE 10558.489462378713 Test RE 0.17977816251438605\n",
      "49 Train Loss 64998.203 Test MSE 9843.969909137955 Test RE 0.17358859201509017\n",
      "50 Train Loss 63957.64 Test MSE 9412.143289807507 Test RE 0.16973847929017064\n",
      "51 Train Loss 62530.65 Test MSE 8786.542545008737 Test RE 0.16400045387595927\n",
      "52 Train Loss 61508.85 Test MSE 8526.052797698758 Test RE 0.16155114881189875\n",
      "53 Train Loss 60839.418 Test MSE 8398.741604665654 Test RE 0.16034046982998904\n",
      "54 Train Loss 59402.074 Test MSE 8171.519213331238 Test RE 0.15815664546741667\n",
      "55 Train Loss 58486.543 Test MSE 7938.530861582804 Test RE 0.15588564008630165\n",
      "56 Train Loss 57915.38 Test MSE 7749.612706567912 Test RE 0.15401961776383022\n",
      "57 Train Loss 56763.348 Test MSE 7721.454307332944 Test RE 0.153739546176798\n",
      "58 Train Loss 56027.562 Test MSE 7811.077172776754 Test RE 0.15462919898783725\n",
      "59 Train Loss 55499.11 Test MSE 7948.582738248789 Test RE 0.15598430113253253\n",
      "60 Train Loss 55006.785 Test MSE 8009.428122114274 Test RE 0.15658018289061088\n",
      "61 Train Loss 54268.5 Test MSE 7728.661207661867 Test RE 0.15381127665171335\n",
      "62 Train Loss 53672.402 Test MSE 7439.883082554043 Test RE 0.15091037461448478\n",
      "63 Train Loss 53016.402 Test MSE 7267.624199321777 Test RE 0.149153096166691\n",
      "64 Train Loss 52657.29 Test MSE 7199.353639144582 Test RE 0.14845088648783572\n",
      "65 Train Loss 52196.617 Test MSE 7046.139732028346 Test RE 0.1468627538753158\n",
      "66 Train Loss 51650.492 Test MSE 6827.619811608105 Test RE 0.14456751196748288\n",
      "67 Train Loss 51189.5 Test MSE 6695.505362669899 Test RE 0.14316198879811962\n",
      "68 Train Loss 50777.61 Test MSE 6616.874376582115 Test RE 0.14231886992448614\n",
      "69 Train Loss 50530.004 Test MSE 6587.357061276576 Test RE 0.14200107891553265\n",
      "70 Train Loss 50203.496 Test MSE 6522.331270147725 Test RE 0.14129847293708783\n",
      "71 Train Loss 49873.78 Test MSE 6444.02001691415 Test RE 0.140447651729381\n",
      "72 Train Loss 49432.793 Test MSE 6511.3246609162115 Test RE 0.14117920011238552\n",
      "73 Train Loss 49081.617 Test MSE 6461.183981764634 Test RE 0.14063457196487664\n",
      "74 Train Loss 48878.895 Test MSE 6581.400448653487 Test RE 0.1419368622113551\n",
      "75 Train Loss 48556.516 Test MSE 6616.863353075415 Test RE 0.1423187513750336\n",
      "76 Train Loss 47958.277 Test MSE 6683.405141168768 Test RE 0.1430325680116888\n",
      "77 Train Loss 47605.773 Test MSE 6702.158878223313 Test RE 0.1432331032208428\n",
      "78 Train Loss 47266.875 Test MSE 6653.743835982891 Test RE 0.14271482202876756\n",
      "79 Train Loss 47063.395 Test MSE 6557.315355668648 Test RE 0.14167691025250606\n",
      "80 Train Loss 46913.83 Test MSE 6604.167094781719 Test RE 0.1421821471315431\n",
      "81 Train Loss 46655.773 Test MSE 6523.565247259667 Test RE 0.14131183862094007\n",
      "82 Train Loss 46429.973 Test MSE 6497.705841763917 Test RE 0.14103148052349423\n",
      "83 Train Loss 46247.52 Test MSE 6391.73310111495 Test RE 0.13987669355852164\n",
      "84 Train Loss 46120.36 Test MSE 6393.394195118768 Test RE 0.13989486806921098\n",
      "85 Train Loss 45709.523 Test MSE 6260.5151733771045 Test RE 0.13843346137310888\n",
      "86 Train Loss 45464.03 Test MSE 6258.469138390662 Test RE 0.13841083840654778\n",
      "87 Train Loss 45383.793 Test MSE 6256.415693698922 Test RE 0.13838812979263007\n",
      "88 Train Loss 45276.492 Test MSE 6267.531130034987 Test RE 0.13851100860207313\n",
      "89 Train Loss 45158.36 Test MSE 6259.21459770217 Test RE 0.13841908136290973\n",
      "90 Train Loss 45022.48 Test MSE 6245.645858753795 Test RE 0.13826896737237096\n",
      "91 Train Loss 44956.348 Test MSE 6207.609833185456 Test RE 0.1378472949211707\n",
      "92 Train Loss 44761.316 Test MSE 6132.651669890431 Test RE 0.1370124999925946\n",
      "93 Train Loss 44632.152 Test MSE 6143.146551081405 Test RE 0.1371296854553904\n",
      "94 Train Loss 44505.855 Test MSE 6152.736805192462 Test RE 0.13723668238725228\n",
      "95 Train Loss 44376.508 Test MSE 6163.350606729966 Test RE 0.13735500170744203\n",
      "96 Train Loss 44276.844 Test MSE 6174.507327557785 Test RE 0.13747926354505147\n",
      "97 Train Loss 44112.41 Test MSE 6120.361688748957 Test RE 0.13687514297212136\n",
      "98 Train Loss 44002.047 Test MSE 6123.291213549474 Test RE 0.13690789684970178\n",
      "99 Train Loss 43818.953 Test MSE 6114.009270357999 Test RE 0.13680409211347208\n",
      "100 Train Loss 43659.266 Test MSE 6116.094464519621 Test RE 0.13682741876897084\n",
      "101 Train Loss 43571.93 Test MSE 6101.278513069196 Test RE 0.13666158928325775\n",
      "102 Train Loss 43451.516 Test MSE 6084.16809440394 Test RE 0.13646982794067017\n",
      "103 Train Loss 43372.12 Test MSE 6073.190912205237 Test RE 0.13634666151446204\n",
      "104 Train Loss 43311.957 Test MSE 6085.7922280627445 Test RE 0.13648804164283732\n",
      "105 Train Loss 43239.72 Test MSE 6076.649258058133 Test RE 0.13638547692543912\n",
      "106 Train Loss 43123.16 Test MSE 6083.80603911663 Test RE 0.13646576737256258\n",
      "107 Train Loss 43016.957 Test MSE 6082.795001962507 Test RE 0.1364544276213538\n",
      "108 Train Loss 42933.63 Test MSE 6068.036301888213 Test RE 0.13628878723472676\n",
      "109 Train Loss 42881.38 Test MSE 6080.55257429897 Test RE 0.1364292732811857\n",
      "110 Train Loss 42709.07 Test MSE 6140.407736099552 Test RE 0.13709911360561874\n",
      "111 Train Loss 42600.8 Test MSE 6121.103605665311 Test RE 0.13688343879774817\n",
      "112 Train Loss 42409.15 Test MSE 6188.475329844952 Test RE 0.13763467884851868\n",
      "113 Train Loss 42294.53 Test MSE 6235.936283256088 Test RE 0.1381614480545485\n",
      "114 Train Loss 42161.727 Test MSE 6223.154151768917 Test RE 0.13801977697190038\n",
      "115 Train Loss 42040.926 Test MSE 6190.171175343387 Test RE 0.13765353576803427\n",
      "116 Train Loss 41932.203 Test MSE 6158.010079624013 Test RE 0.13729547993674998\n",
      "117 Train Loss 41837.098 Test MSE 6137.0090890233205 Test RE 0.13706116694033\n",
      "118 Train Loss 41695.047 Test MSE 6146.770394142883 Test RE 0.13717012590320596\n",
      "119 Train Loss 41607.273 Test MSE 6105.769588031016 Test RE 0.13671187747591354\n",
      "120 Train Loss 41532.023 Test MSE 6091.694399996945 Test RE 0.13655421056840128\n",
      "121 Train Loss 41458.055 Test MSE 6027.2600109664545 Test RE 0.13583009527880874\n",
      "122 Train Loss 41400.164 Test MSE 6017.264964476652 Test RE 0.13571742456087738\n",
      "123 Train Loss 41320.773 Test MSE 6000.992555168573 Test RE 0.13553379091767603\n",
      "124 Train Loss 41225.008 Test MSE 5993.423165735287 Test RE 0.1354482857492842\n",
      "125 Train Loss 41098.613 Test MSE 5958.262580866052 Test RE 0.13505039575166228\n",
      "126 Train Loss 41039.51 Test MSE 5987.950075241803 Test RE 0.1353864271067166\n",
      "127 Train Loss 40961.586 Test MSE 5967.274455357166 Test RE 0.13515248905048857\n",
      "128 Train Loss 40903.68 Test MSE 5964.2226971586215 Test RE 0.13511792507435563\n",
      "129 Train Loss 40874.098 Test MSE 5956.940338249764 Test RE 0.13503540989847088\n",
      "130 Train Loss 40832.484 Test MSE 5928.108945806899 Test RE 0.13470823009469593\n",
      "131 Train Loss 40793.074 Test MSE 5929.39299190704 Test RE 0.13472281840722236\n",
      "132 Train Loss 40761.45 Test MSE 5919.995743410224 Test RE 0.1346160177769126\n",
      "133 Train Loss 40703.137 Test MSE 5911.924632432978 Test RE 0.13452422114033782\n",
      "134 Train Loss 40609.633 Test MSE 5891.2148954662825 Test RE 0.13428839224125594\n",
      "135 Train Loss 40477.375 Test MSE 5870.433065797727 Test RE 0.13405132534913516\n",
      "136 Train Loss 40386.312 Test MSE 5857.612578308079 Test RE 0.13390486744182573\n",
      "137 Train Loss 40324.938 Test MSE 5842.599302908383 Test RE 0.13373315580765893\n",
      "138 Train Loss 40298.56 Test MSE 5823.020737915188 Test RE 0.13350889770651303\n",
      "139 Train Loss 40277.504 Test MSE 5829.087333297749 Test RE 0.13357842636290898\n",
      "140 Train Loss 40256.21 Test MSE 5806.179368253631 Test RE 0.1333156903561596\n",
      "141 Train Loss 40233.85 Test MSE 5803.669057987001 Test RE 0.1332868676221474\n",
      "142 Train Loss 40213.914 Test MSE 5804.973677324975 Test RE 0.13330184770217593\n",
      "143 Train Loss 40193.188 Test MSE 5822.437888211998 Test RE 0.1335022158164579\n",
      "144 Train Loss 40176.99 Test MSE 5810.330552083508 Test RE 0.13336333950893778\n",
      "145 Train Loss 40155.242 Test MSE 5812.138069938404 Test RE 0.1333840816913933\n",
      "146 Train Loss 40140.4 Test MSE 5807.085889487609 Test RE 0.13332609726745248\n",
      "147 Train Loss 40108.805 Test MSE 5804.7738632117835 Test RE 0.13329955347819\n",
      "148 Train Loss 40048.234 Test MSE 5792.753032159681 Test RE 0.1331614600848655\n",
      "149 Train Loss 39988.86 Test MSE 5806.369931525919 Test RE 0.133317878099953\n",
      "150 Train Loss 39910.086 Test MSE 5805.024462159353 Test RE 0.1333024307967624\n",
      "151 Train Loss 39851.715 Test MSE 5804.466388995747 Test RE 0.13329602304621843\n",
      "152 Train Loss 39774.906 Test MSE 5800.287820539977 Test RE 0.1332480352728388\n",
      "153 Train Loss 39710.12 Test MSE 5810.92861991026 Test RE 0.13337020299712926\n",
      "154 Train Loss 39688.28 Test MSE 5825.480321328559 Test RE 0.13353709111477613\n",
      "155 Train Loss 39664.953 Test MSE 5834.74333756689 Test RE 0.13364321669146498\n",
      "156 Train Loss 39655.668 Test MSE 5838.129409101537 Test RE 0.13368198959296831\n",
      "157 Train Loss 39644.6 Test MSE 5829.474726357952 Test RE 0.13358286500764627\n",
      "158 Train Loss 39632.3 Test MSE 5826.382289119774 Test RE 0.1335474285879647\n",
      "159 Train Loss 39627.2 Test MSE 5832.871424977035 Test RE 0.13362177714618542\n",
      "160 Train Loss 39622.496 Test MSE 5839.922914086051 Test RE 0.13370252193191312\n",
      "161 Train Loss 39610.594 Test MSE 5858.441342974386 Test RE 0.1339143398758787\n",
      "162 Train Loss 39591.285 Test MSE 5862.78353565247 Test RE 0.1339639583772403\n",
      "163 Train Loss 39540.695 Test MSE 5884.150091643694 Test RE 0.1342078480951571\n",
      "164 Train Loss 39525.664 Test MSE 5894.828158697217 Test RE 0.13432956752865097\n",
      "165 Train Loss 39480.477 Test MSE 5887.510874022334 Test RE 0.13424616960106714\n",
      "166 Train Loss 39436.53 Test MSE 5905.4027296175445 Test RE 0.13444999861095752\n",
      "167 Train Loss 39404.8 Test MSE 5898.7643752176555 Test RE 0.13437440870222725\n",
      "168 Train Loss 39370.875 Test MSE 5890.602726490159 Test RE 0.13428141496027607\n",
      "169 Train Loss 39318.645 Test MSE 5870.4274234418735 Test RE 0.13405126092752834\n",
      "170 Train Loss 39266.81 Test MSE 5831.855161276104 Test RE 0.13361013614921394\n",
      "171 Train Loss 39194.36 Test MSE 5791.851722362744 Test RE 0.13315110020962204\n",
      "172 Train Loss 39112.133 Test MSE 5775.747373350983 Test RE 0.13296585682440537\n",
      "173 Train Loss 39076.785 Test MSE 5754.982457869541 Test RE 0.132726622776054\n",
      "174 Train Loss 38998.13 Test MSE 5716.683540793614 Test RE 0.13228424337491557\n",
      "175 Train Loss 38913.2 Test MSE 5633.167962431388 Test RE 0.13131441164962024\n",
      "176 Train Loss 38876.75 Test MSE 5643.323628655748 Test RE 0.1314327273848362\n",
      "177 Train Loss 38836.223 Test MSE 5625.849461431161 Test RE 0.13122908337622072\n",
      "178 Train Loss 38804.65 Test MSE 5619.122907736652 Test RE 0.13115060780593796\n",
      "179 Train Loss 38727.887 Test MSE 5592.474261957311 Test RE 0.13083924785353915\n",
      "180 Train Loss 38682.215 Test MSE 5576.228228321413 Test RE 0.13064906684518912\n",
      "181 Train Loss 38665.16 Test MSE 5581.300110932591 Test RE 0.13070846955394033\n",
      "182 Train Loss 38636.75 Test MSE 5589.439664117789 Test RE 0.13080374492977784\n",
      "183 Train Loss 38612.637 Test MSE 5582.266460947777 Test RE 0.13071978453988858\n",
      "184 Train Loss 38596.29 Test MSE 5565.974549900218 Test RE 0.130528891534426\n",
      "185 Train Loss 38579.46 Test MSE 5570.679290438884 Test RE 0.130584045833645\n",
      "186 Train Loss 38545.17 Test MSE 5561.390038991133 Test RE 0.1304751242744872\n",
      "187 Train Loss 38512.918 Test MSE 5536.227985912566 Test RE 0.13017962765900645\n",
      "188 Train Loss 38493.266 Test MSE 5544.531114965651 Test RE 0.13027721154439503\n",
      "189 Train Loss 38468.387 Test MSE 5554.20485226792 Test RE 0.1303908116185632\n",
      "190 Train Loss 38443.65 Test MSE 5570.525800778577 Test RE 0.1305822468215445\n",
      "191 Train Loss 38418.297 Test MSE 5562.2147811207915 Test RE 0.13048479850537928\n",
      "192 Train Loss 38396.855 Test MSE 5575.686650224419 Test RE 0.13064272219893353\n",
      "193 Train Loss 38372.25 Test MSE 5573.173155924679 Test RE 0.1306132723057282\n",
      "194 Train Loss 38360.035 Test MSE 5578.7126003760895 Test RE 0.13067816758612388\n",
      "195 Train Loss 38351.62 Test MSE 5578.335759835193 Test RE 0.13067375387398894\n",
      "196 Train Loss 38310.234 Test MSE 5578.7633433488745 Test RE 0.13067876189740124\n",
      "197 Train Loss 38246.8 Test MSE 5599.202011519336 Test RE 0.1309179240417454\n",
      "198 Train Loss 38223.258 Test MSE 5597.409449867984 Test RE 0.13089696594490652\n",
      "199 Train Loss 38209.434 Test MSE 5589.2889808284945 Test RE 0.13080198177706825\n",
      "Training time: 633.56\n",
      "Training time: 633.56\n",
      "ES_rowdy_high\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 483280.5 Test MSE 309178.9409969197 Test RE 0.9728390489384613\n",
      "1 Train Loss 449031.12 Test MSE 273058.85742970265 Test RE 0.9142483309711337\n",
      "2 Train Loss 336363.75 Test MSE 161180.2698421233 Test RE 0.7024120948714507\n",
      "3 Train Loss 257353.4 Test MSE 82631.8386834986 Test RE 0.5029325568140135\n",
      "4 Train Loss 249990.78 Test MSE 75072.03835646513 Test RE 0.4793747401071455\n",
      "5 Train Loss 249886.42 Test MSE 74997.00062848203 Test RE 0.479135102385027\n",
      "6 Train Loss 249648.72 Test MSE 74900.5655052029 Test RE 0.4788269546245062\n",
      "7 Train Loss 247068.86 Test MSE 73636.61637318626 Test RE 0.4747696559328002\n",
      "8 Train Loss 243119.69 Test MSE 71674.67730350676 Test RE 0.46840218791977867\n",
      "9 Train Loss 236417.17 Test MSE 69495.18417152298 Test RE 0.46122559197580976\n",
      "10 Train Loss 231509.58 Test MSE 67394.29945994988 Test RE 0.4542005162524112\n",
      "11 Train Loss 224989.5 Test MSE 65149.32746309812 Test RE 0.44657150733545936\n",
      "12 Train Loss 221492.84 Test MSE 63947.88327287106 Test RE 0.4424346464359344\n",
      "13 Train Loss 211632.53 Test MSE 59826.140457715235 Test RE 0.4279386723500661\n",
      "14 Train Loss 199096.06 Test MSE 55478.96538336552 Test RE 0.41209772647240417\n",
      "15 Train Loss 180028.53 Test MSE 47145.194796080264 Test RE 0.3798872861671229\n",
      "16 Train Loss 156530.95 Test MSE 36419.846167530864 Test RE 0.3338912940932927\n",
      "17 Train Loss 137059.67 Test MSE 32223.083881008995 Test RE 0.3140650377970924\n",
      "18 Train Loss 121281.03 Test MSE 27623.352721461204 Test RE 0.29078649741286455\n",
      "19 Train Loss 108438.16 Test MSE 23046.959183259187 Test RE 0.26560904368582033\n",
      "20 Train Loss 100992.195 Test MSE 19871.52491148715 Test RE 0.24663325780057424\n",
      "21 Train Loss 91998.7 Test MSE 16684.98338205564 Test RE 0.2259950521978853\n",
      "22 Train Loss 87465.17 Test MSE 15861.951517423926 Test RE 0.22035065758498895\n",
      "23 Train Loss 81628.305 Test MSE 14003.910494802492 Test RE 0.20704307301697944\n",
      "24 Train Loss 74969.83 Test MSE 11339.307002460868 Test RE 0.1863070540390546\n",
      "25 Train Loss 69790.68 Test MSE 10104.434947133841 Test RE 0.1758701192076777\n",
      "26 Train Loss 64572.832 Test MSE 9137.152058360065 Test RE 0.16724050413986993\n",
      "27 Train Loss 59757.21 Test MSE 7929.018603004914 Test RE 0.15579221795292014\n",
      "28 Train Loss 57392.023 Test MSE 7127.606509037495 Test RE 0.1477093203114619\n",
      "29 Train Loss 53181.24 Test MSE 6923.549041682256 Test RE 0.1455795686512539\n",
      "30 Train Loss 50437.043 Test MSE 6759.010510994183 Test RE 0.1438393138679578\n",
      "31 Train Loss 48855.25 Test MSE 6726.744383343649 Test RE 0.14349557347320513\n",
      "32 Train Loss 47240.215 Test MSE 6544.147820038978 Test RE 0.14153459032928994\n",
      "33 Train Loss 46002.875 Test MSE 6487.751317784202 Test RE 0.1409234085826042\n",
      "34 Train Loss 45220.74 Test MSE 6367.36634069554 Test RE 0.13960981786306986\n",
      "35 Train Loss 44738.918 Test MSE 6395.455443289134 Test RE 0.13991741750022815\n",
      "36 Train Loss 44239.234 Test MSE 6459.641529720332 Test RE 0.14061778440462336\n",
      "37 Train Loss 43813.58 Test MSE 6458.482788530318 Test RE 0.14060517171351358\n",
      "38 Train Loss 43528.86 Test MSE 6390.300116394666 Test RE 0.13986101296007664\n",
      "39 Train Loss 43211.434 Test MSE 6369.649050976677 Test RE 0.1396348407840118\n",
      "40 Train Loss 43096.04 Test MSE 6360.301457120377 Test RE 0.13953234463458047\n",
      "41 Train Loss 43000.664 Test MSE 6375.5493054489325 Test RE 0.13969949822304079\n",
      "42 Train Loss 42848.23 Test MSE 6384.405248755909 Test RE 0.1397964892000346\n",
      "43 Train Loss 42727.6 Test MSE 6373.86261644994 Test RE 0.13968101783947784\n",
      "44 Train Loss 42491.332 Test MSE 6297.537690788123 Test RE 0.13884218176718935\n",
      "45 Train Loss 42363.49 Test MSE 6344.3112044773925 Test RE 0.13935683710985805\n",
      "46 Train Loss 42152.207 Test MSE 6286.68544359847 Test RE 0.13872250012030413\n",
      "47 Train Loss 41910.715 Test MSE 6214.542063238238 Test RE 0.1379242426152977\n",
      "48 Train Loss 41698.87 Test MSE 6272.933248202191 Test RE 0.1385706885347374\n",
      "49 Train Loss 41541.4 Test MSE 6219.42332002288 Test RE 0.1379783987774944\n",
      "50 Train Loss 41328.926 Test MSE 6220.70392683694 Test RE 0.1379926032281232\n",
      "51 Train Loss 41177.316 Test MSE 6082.761666999989 Test RE 0.1364540537217352\n",
      "52 Train Loss 41094.184 Test MSE 6088.199757612264 Test RE 0.13651503619746702\n",
      "53 Train Loss 40921.16 Test MSE 6081.56465242082 Test RE 0.1364406268001213\n",
      "54 Train Loss 40813.773 Test MSE 5988.607255307483 Test RE 0.13539385626184156\n",
      "55 Train Loss 40693.55 Test MSE 6028.184935411448 Test RE 0.13584051690951948\n",
      "56 Train Loss 40577.16 Test MSE 5976.881604270571 Test RE 0.13526124120434543\n",
      "57 Train Loss 40448.71 Test MSE 5943.490881033365 Test RE 0.13488288367342766\n",
      "58 Train Loss 40291.965 Test MSE 6010.988198624039 Test RE 0.1356466209010673\n",
      "59 Train Loss 40233.97 Test MSE 5984.546583359059 Test RE 0.13534794548152285\n",
      "60 Train Loss 40113.043 Test MSE 5902.946562785346 Test RE 0.13442203557551263\n",
      "61 Train Loss 40036.242 Test MSE 5842.986145352982 Test RE 0.13373758301564742\n",
      "62 Train Loss 39942.93 Test MSE 5890.706931892974 Test RE 0.13428260268144004\n",
      "63 Train Loss 39897.47 Test MSE 5878.559355900464 Test RE 0.13414407517019517\n",
      "64 Train Loss 39797.746 Test MSE 5918.167401297194 Test RE 0.13459522864535334\n",
      "65 Train Loss 39586.516 Test MSE 5829.472627478423 Test RE 0.13358284095965062\n",
      "66 Train Loss 39481.574 Test MSE 5745.84500998981 Test RE 0.13262121286500325\n",
      "67 Train Loss 39395.984 Test MSE 5739.787656447357 Test RE 0.13255128882377706\n",
      "68 Train Loss 39232.86 Test MSE 5692.564088708305 Test RE 0.1320048859483572\n",
      "69 Train Loss 39163.215 Test MSE 5676.1881810460745 Test RE 0.13181487871431521\n",
      "70 Train Loss 39102.363 Test MSE 5568.136227728225 Test RE 0.13055423606461738\n",
      "71 Train Loss 39013.74 Test MSE 5589.384299878549 Test RE 0.13080309711280552\n",
      "72 Train Loss 38926.27 Test MSE 5595.580956401657 Test RE 0.13087558428622634\n",
      "73 Train Loss 38838.246 Test MSE 5551.953589805364 Test RE 0.13036438356101673\n",
      "74 Train Loss 38770.758 Test MSE 5541.620310127508 Test RE 0.13024301015629597\n",
      "75 Train Loss 38679.168 Test MSE 5524.262046239007 Test RE 0.13003886718124916\n",
      "76 Train Loss 38627.33 Test MSE 5525.59530891149 Test RE 0.1300545584633122\n",
      "77 Train Loss 38590.13 Test MSE 5506.340123769457 Test RE 0.1298277584621141\n",
      "78 Train Loss 38500.465 Test MSE 5481.216436921778 Test RE 0.12953123836238006\n",
      "79 Train Loss 38417.54 Test MSE 5554.562593745376 Test RE 0.13039501073002469\n",
      "80 Train Loss 38278.656 Test MSE 5506.411259000727 Test RE 0.12982859706793837\n",
      "81 Train Loss 38224.53 Test MSE 5470.362181459187 Test RE 0.1294029217830837\n",
      "82 Train Loss 38175.91 Test MSE 5482.9019278647365 Test RE 0.12955115245903887\n",
      "83 Train Loss 38080.99 Test MSE 5464.160069016273 Test RE 0.12932954464132554\n",
      "84 Train Loss 38003.883 Test MSE 5392.307163347889 Test RE 0.1284763983751987\n",
      "85 Train Loss 37958.793 Test MSE 5375.146964881818 Test RE 0.12827180716412812\n",
      "86 Train Loss 37901.703 Test MSE 5341.768514246273 Test RE 0.12787291744642998\n",
      "87 Train Loss 37764.906 Test MSE 5375.177329872377 Test RE 0.12827216947670658\n",
      "88 Train Loss 37664.188 Test MSE 5348.960290213714 Test RE 0.12795896797895753\n",
      "89 Train Loss 37563.992 Test MSE 5375.292341466624 Test RE 0.12827354177634326\n",
      "90 Train Loss 37348.707 Test MSE 5364.415008481543 Test RE 0.12814369017799576\n",
      "91 Train Loss 37256.62 Test MSE 5436.908350082103 Test RE 0.1290066351937301\n",
      "92 Train Loss 37038.39 Test MSE 5345.7910801644975 Test RE 0.12792105510327373\n",
      "93 Train Loss 36936.883 Test MSE 5357.487572651664 Test RE 0.12806092309493555\n",
      "94 Train Loss 36906.863 Test MSE 5399.589199435487 Test RE 0.1285631195220391\n",
      "95 Train Loss 36731.04 Test MSE 5273.381144891382 Test RE 0.12705174166092886\n",
      "96 Train Loss 36645.53 Test MSE 5210.933551554225 Test RE 0.1262972253169942\n",
      "97 Train Loss 36574.324 Test MSE 5174.76636735257 Test RE 0.1258581707334388\n",
      "98 Train Loss 36514.266 Test MSE 5181.178085182142 Test RE 0.12593611794975731\n",
      "99 Train Loss 36433.527 Test MSE 5099.152713090451 Test RE 0.12493526755567863\n",
      "100 Train Loss 36367.234 Test MSE 5115.949110618138 Test RE 0.12514086418273251\n",
      "101 Train Loss 36325.99 Test MSE 5085.177932799426 Test RE 0.1247639507809681\n",
      "102 Train Loss 36298.816 Test MSE 5084.697824148276 Test RE 0.1247580609510717\n",
      "103 Train Loss 36271.746 Test MSE 5097.859520518525 Test RE 0.12491942417796625\n",
      "104 Train Loss 36231.543 Test MSE 5094.990750536349 Test RE 0.12488427064699673\n",
      "105 Train Loss 36159.914 Test MSE 5107.119835633061 Test RE 0.12503283141996702\n",
      "106 Train Loss 36141.484 Test MSE 5104.706537443197 Test RE 0.12500328666971539\n",
      "107 Train Loss 36035.742 Test MSE 5035.723430841251 Test RE 0.12415578976662321\n",
      "108 Train Loss 35972.848 Test MSE 5002.865673472185 Test RE 0.12375007276725265\n",
      "109 Train Loss 35917.0 Test MSE 5009.003486778009 Test RE 0.12382596147472716\n",
      "110 Train Loss 35864.85 Test MSE 5041.635138742645 Test RE 0.12422864498665465\n",
      "111 Train Loss 35675.344 Test MSE 5024.576193536475 Test RE 0.12401829603483835\n",
      "112 Train Loss 35459.14 Test MSE 4959.883055855899 Test RE 0.12321732047603025\n",
      "113 Train Loss 35367.668 Test MSE 4896.363809694189 Test RE 0.12242578051035898\n",
      "114 Train Loss 35294.38 Test MSE 4837.763198805737 Test RE 0.121690967815636\n",
      "115 Train Loss 35251.0 Test MSE 4850.4996133652385 Test RE 0.12185105087247444\n",
      "116 Train Loss 35173.234 Test MSE 4850.968251317022 Test RE 0.12185693713700643\n",
      "117 Train Loss 35117.145 Test MSE 4892.892541989863 Test RE 0.12238237605532037\n",
      "118 Train Loss 35070.83 Test MSE 4903.607483972036 Test RE 0.12251630531271882\n",
      "119 Train Loss 35007.45 Test MSE 4909.607926155382 Test RE 0.12259124271838401\n",
      "120 Train Loss 34966.93 Test MSE 4879.365865195683 Test RE 0.12221309249284668\n",
      "121 Train Loss 34926.918 Test MSE 4894.703791621683 Test RE 0.12240502569676359\n",
      "122 Train Loss 34853.34 Test MSE 4864.163412997482 Test RE 0.12202255665439521\n",
      "123 Train Loss 34809.363 Test MSE 4863.897263138219 Test RE 0.12201921828685057\n",
      "124 Train Loss 34778.375 Test MSE 4817.102703273196 Test RE 0.1214308387367116\n",
      "125 Train Loss 34740.41 Test MSE 4793.253194271777 Test RE 0.12112986327781354\n",
      "126 Train Loss 34622.18 Test MSE 4774.712198796995 Test RE 0.12089536238644412\n",
      "127 Train Loss 34575.13 Test MSE 4789.040665705873 Test RE 0.12107662436590724\n",
      "128 Train Loss 34554.06 Test MSE 4759.905038875435 Test RE 0.12070775872498203\n",
      "129 Train Loss 34517.06 Test MSE 4750.612320207139 Test RE 0.12058987283844297\n",
      "130 Train Loss 34499.133 Test MSE 4768.531441084886 Test RE 0.12081708888163128\n",
      "131 Train Loss 34468.434 Test MSE 4781.2693510878935 Test RE 0.12097834721261909\n",
      "132 Train Loss 34380.176 Test MSE 4788.250618484191 Test RE 0.12106663695895123\n",
      "133 Train Loss 34306.05 Test MSE 4842.148788787335 Test RE 0.12174611373442892\n",
      "134 Train Loss 33957.66 Test MSE 4817.3584133924915 Test RE 0.12143406169915455\n",
      "135 Train Loss 33805.13 Test MSE 4790.967089564875 Test RE 0.12110097386122995\n",
      "136 Train Loss 33744.855 Test MSE 4835.153024267704 Test RE 0.12165813471607245\n",
      "137 Train Loss 33673.355 Test MSE 4864.296936888201 Test RE 0.12202423143516689\n",
      "138 Train Loss 33619.773 Test MSE 4847.950470136169 Test RE 0.12181902771741643\n",
      "139 Train Loss 33484.45 Test MSE 4771.408710943169 Test RE 0.12085353311508745\n",
      "140 Train Loss 33326.527 Test MSE 4709.2277120598 Test RE 0.12006346901605\n",
      "141 Train Loss 33260.63 Test MSE 4724.970717908397 Test RE 0.12026398839401074\n",
      "142 Train Loss 33135.01 Test MSE 4778.51889179364 Test RE 0.12094354537837211\n",
      "143 Train Loss 33004.496 Test MSE 4707.386429628029 Test RE 0.12003999463943174\n",
      "144 Train Loss 32829.81 Test MSE 4717.686251240915 Test RE 0.12017124740346338\n",
      "145 Train Loss 32490.396 Test MSE 4602.607490951011 Test RE 0.11869652697845003\n",
      "146 Train Loss 32351.836 Test MSE 4593.7164208332515 Test RE 0.11858182576822099\n",
      "147 Train Loss 32280.162 Test MSE 4551.765327330444 Test RE 0.11803912282321864\n",
      "148 Train Loss 32254.943 Test MSE 4519.307457493413 Test RE 0.11761751134338128\n",
      "149 Train Loss 32138.494 Test MSE 4447.614734314536 Test RE 0.11668086015034522\n",
      "150 Train Loss 31972.426 Test MSE 4405.968530062876 Test RE 0.11613329205953143\n",
      "151 Train Loss 31924.92 Test MSE 4368.19693108556 Test RE 0.1156344253652754\n",
      "152 Train Loss 31894.494 Test MSE 4355.401060486337 Test RE 0.11546493571700095\n",
      "153 Train Loss 31844.791 Test MSE 4359.665289674466 Test RE 0.11552144583922322\n",
      "154 Train Loss 31789.17 Test MSE 4346.905768988783 Test RE 0.11535227249034358\n",
      "155 Train Loss 31756.17 Test MSE 4378.76220337613 Test RE 0.11577418226845787\n",
      "156 Train Loss 31733.822 Test MSE 4377.308268837957 Test RE 0.1157549597062652\n",
      "157 Train Loss 31676.084 Test MSE 4448.594097787192 Test RE 0.11669370598897884\n",
      "158 Train Loss 31583.47 Test MSE 4411.197557792028 Test RE 0.11620218544029738\n",
      "159 Train Loss 31539.836 Test MSE 4430.478597134866 Test RE 0.11645586439589554\n",
      "160 Train Loss 31480.559 Test MSE 4395.908198797347 Test RE 0.11600063029934342\n",
      "161 Train Loss 31407.58 Test MSE 4406.369758591175 Test RE 0.11613857976514902\n",
      "162 Train Loss 31235.91 Test MSE 4325.902074592332 Test RE 0.11507325129752498\n",
      "163 Train Loss 31132.81 Test MSE 4294.291085919885 Test RE 0.1146520386971698\n",
      "164 Train Loss 31042.88 Test MSE 4285.28775933364 Test RE 0.1145317870253482\n",
      "165 Train Loss 30980.744 Test MSE 4249.943116331593 Test RE 0.11405848546328952\n",
      "166 Train Loss 30836.992 Test MSE 4285.222237135602 Test RE 0.11453091142450895\n",
      "167 Train Loss 30630.281 Test MSE 4257.911357487769 Test RE 0.11416535982516525\n",
      "168 Train Loss 30359.988 Test MSE 4227.178093950241 Test RE 0.11375259543429433\n",
      "169 Train Loss 30160.951 Test MSE 4257.4959355017945 Test RE 0.1141597904328766\n",
      "170 Train Loss 30100.734 Test MSE 4265.334269160636 Test RE 0.11426482999875127\n",
      "171 Train Loss 30034.057 Test MSE 4223.978627154603 Test RE 0.11370953875012191\n",
      "172 Train Loss 30011.738 Test MSE 4236.044887772555 Test RE 0.11387183484523815\n",
      "173 Train Loss 29977.725 Test MSE 4238.032823871107 Test RE 0.11389855120271344\n",
      "174 Train Loss 29938.488 Test MSE 4234.972282912713 Test RE 0.11385741724351597\n",
      "175 Train Loss 29859.5 Test MSE 4259.350142718166 Test RE 0.11418464692932515\n",
      "176 Train Loss 29831.41 Test MSE 4238.439786612606 Test RE 0.11390401970140918\n",
      "177 Train Loss 29785.729 Test MSE 4247.695617818205 Test RE 0.11402832268588503\n",
      "178 Train Loss 29708.93 Test MSE 4249.701175667806 Test RE 0.11405523885766719\n",
      "179 Train Loss 29662.588 Test MSE 4250.181480836963 Test RE 0.11406168399001379\n",
      "180 Train Loss 29572.232 Test MSE 4257.856435654333 Test RE 0.11416462352624195\n",
      "181 Train Loss 29528.137 Test MSE 4212.258411269609 Test RE 0.11355167501533715\n",
      "182 Train Loss 29468.523 Test MSE 4196.78323874872 Test RE 0.11334289761984989\n",
      "183 Train Loss 29431.332 Test MSE 4212.585315413272 Test RE 0.11355608117816905\n",
      "184 Train Loss 29412.436 Test MSE 4200.660086246495 Test RE 0.11339523671769051\n",
      "185 Train Loss 29365.166 Test MSE 4197.62782924631 Test RE 0.1133543020113893\n",
      "186 Train Loss 29315.922 Test MSE 4187.747543435934 Test RE 0.11322081796205608\n",
      "187 Train Loss 29241.24 Test MSE 4161.386730393957 Test RE 0.1128639071837346\n",
      "188 Train Loss 29166.3 Test MSE 4120.624230169344 Test RE 0.11230977257786237\n",
      "189 Train Loss 29064.904 Test MSE 4083.05323231878 Test RE 0.11179659151284768\n",
      "190 Train Loss 29011.418 Test MSE 4041.4762846656604 Test RE 0.11122593344976654\n",
      "191 Train Loss 28970.393 Test MSE 4033.371628373913 Test RE 0.11111435289284134\n",
      "192 Train Loss 28809.062 Test MSE 4034.2885183244075 Test RE 0.11112698176188658\n",
      "193 Train Loss 28674.246 Test MSE 3977.537425659501 Test RE 0.11034259141076132\n",
      "194 Train Loss 28627.266 Test MSE 3968.452047083962 Test RE 0.11021649865080395\n",
      "195 Train Loss 28573.418 Test MSE 4010.0262535014754 Test RE 0.11079231826200757\n",
      "196 Train Loss 28489.223 Test MSE 4020.451748716369 Test RE 0.1109362468717486\n",
      "197 Train Loss 28388.857 Test MSE 4004.3147802747 Test RE 0.11071338949701337\n",
      "198 Train Loss 28323.902 Test MSE 3957.3430681395757 Test RE 0.11006212475168403\n",
      "199 Train Loss 28278.986 Test MSE 3934.6348342431347 Test RE 0.10974588830462086\n",
      "Training time: 639.65\n",
      "Training time: 639.65\n",
      "ES_rowdy_high\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 462951.25 Test MSE 288922.3436718474 Test RE 0.9404302849593399\n",
      "1 Train Loss 393405.44 Test MSE 215381.14656123094 Test RE 0.8119698140475275\n",
      "2 Train Loss 276491.66 Test MSE 97726.78274187335 Test RE 0.5469439750505513\n",
      "3 Train Loss 249970.05 Test MSE 75052.12368280916 Test RE 0.47931115301854876\n",
      "4 Train Loss 249441.19 Test MSE 74745.88613312095 Test RE 0.47833227925064276\n",
      "5 Train Loss 247460.7 Test MSE 73836.77861255738 Test RE 0.47541448774678546\n",
      "6 Train Loss 243506.08 Test MSE 71934.00432389132 Test RE 0.4692487886593331\n",
      "7 Train Loss 239304.98 Test MSE 70311.17904020274 Test RE 0.4639254868342793\n",
      "8 Train Loss 234477.02 Test MSE 68517.55870528423 Test RE 0.45796994969157123\n",
      "9 Train Loss 230161.27 Test MSE 66430.1340784871 Test RE 0.45093983993546777\n",
      "10 Train Loss 227537.92 Test MSE 65533.35223065952 Test RE 0.4478857384112646\n",
      "11 Train Loss 225673.45 Test MSE 64996.68455755411 Test RE 0.4460480487702258\n",
      "12 Train Loss 222986.66 Test MSE 63871.61112680132 Test RE 0.44217071660352947\n",
      "13 Train Loss 218663.25 Test MSE 61419.495669583186 Test RE 0.43359989149950257\n",
      "14 Train Loss 216719.7 Test MSE 60873.962593232056 Test RE 0.4316699613148454\n",
      "15 Train Loss 213406.05 Test MSE 60099.47782607223 Test RE 0.42891515459651647\n",
      "16 Train Loss 209695.25 Test MSE 59171.4294642625 Test RE 0.4255906443347265\n",
      "17 Train Loss 207086.58 Test MSE 57632.46013864877 Test RE 0.42001966201966007\n",
      "18 Train Loss 203993.28 Test MSE 56722.95138600579 Test RE 0.4166922774342971\n",
      "19 Train Loss 201229.03 Test MSE 55721.02559233346 Test RE 0.41299575954095347\n",
      "20 Train Loss 198866.58 Test MSE 55275.32166009318 Test RE 0.41134069840182585\n",
      "21 Train Loss 195418.5 Test MSE 53892.63905887181 Test RE 0.40616338265041246\n",
      "22 Train Loss 192944.6 Test MSE 53451.95725966286 Test RE 0.404499368637331\n",
      "23 Train Loss 189312.55 Test MSE 51740.04619415155 Test RE 0.3979691870350033\n",
      "24 Train Loss 185998.67 Test MSE 50560.34832046774 Test RE 0.3934060826284242\n",
      "25 Train Loss 183105.55 Test MSE 49455.11956309337 Test RE 0.3890824750983389\n",
      "26 Train Loss 179399.89 Test MSE 48183.88854430651 Test RE 0.384049288299711\n",
      "27 Train Loss 175939.55 Test MSE 46544.55754725935 Test RE 0.3774596170621055\n",
      "28 Train Loss 173045.03 Test MSE 45204.615672684835 Test RE 0.3719867171800897\n",
      "29 Train Loss 169900.86 Test MSE 44497.487949838855 Test RE 0.3690657884010337\n",
      "30 Train Loss 166529.25 Test MSE 42831.39001373233 Test RE 0.3620904964027876\n",
      "31 Train Loss 162193.36 Test MSE 41254.73765893848 Test RE 0.35536361300176206\n",
      "32 Train Loss 159246.66 Test MSE 40849.57557062296 Test RE 0.35361429735560435\n",
      "33 Train Loss 156353.08 Test MSE 40048.27659273899 Test RE 0.35012889866703734\n",
      "34 Train Loss 153542.64 Test MSE 38899.61634187882 Test RE 0.34507118943785936\n",
      "35 Train Loss 151339.28 Test MSE 38018.8555667065 Test RE 0.3411422909918331\n",
      "36 Train Loss 149249.53 Test MSE 37433.303925366774 Test RE 0.3385050265501357\n",
      "37 Train Loss 146854.56 Test MSE 36853.253106236814 Test RE 0.33587212098126223\n",
      "38 Train Loss 144799.5 Test MSE 36326.175654389015 Test RE 0.3334616395493978\n",
      "39 Train Loss 143117.06 Test MSE 35631.44256522361 Test RE 0.33025754222892545\n",
      "40 Train Loss 141222.27 Test MSE 34844.855320214025 Test RE 0.32659187391704486\n",
      "41 Train Loss 139015.22 Test MSE 34812.706460817295 Test RE 0.32644117765135977\n",
      "42 Train Loss 136807.34 Test MSE 33919.933783127366 Test RE 0.32222819587172613\n",
      "43 Train Loss 135472.86 Test MSE 33189.36112795334 Test RE 0.31873920725251964\n",
      "44 Train Loss 133298.14 Test MSE 32167.059787561113 Test RE 0.3137918972180205\n",
      "45 Train Loss 130754.33 Test MSE 30561.735652754032 Test RE 0.30586166567980805\n",
      "46 Train Loss 129160.33 Test MSE 30077.481066481254 Test RE 0.30342878137167506\n",
      "47 Train Loss 128064.29 Test MSE 29737.733223295345 Test RE 0.3017101858635506\n",
      "48 Train Loss 125205.42 Test MSE 28664.443588093807 Test RE 0.2962155135320939\n",
      "49 Train Loss 123701.18 Test MSE 27828.290736051134 Test RE 0.2918631785361887\n",
      "50 Train Loss 121383.06 Test MSE 27000.059022979156 Test RE 0.28748712424828027\n",
      "51 Train Loss 119059.73 Test MSE 26767.09871718345 Test RE 0.28624419773778426\n",
      "52 Train Loss 117850.32 Test MSE 26111.975847173773 Test RE 0.2827195946720073\n",
      "53 Train Loss 115882.055 Test MSE 26234.604328989728 Test RE 0.2833826786532331\n",
      "54 Train Loss 114067.836 Test MSE 25020.55760953364 Test RE 0.2767480273536647\n",
      "55 Train Loss 112535.79 Test MSE 24426.978597782894 Test RE 0.27344558629564464\n",
      "56 Train Loss 111349.04 Test MSE 24195.06310419333 Test RE 0.27214441208520107\n",
      "57 Train Loss 110443.65 Test MSE 23793.7380114858 Test RE 0.26987793566376467\n",
      "58 Train Loss 109227.67 Test MSE 23461.625530741047 Test RE 0.267987841818986\n",
      "59 Train Loss 107842.62 Test MSE 22614.40148368216 Test RE 0.26310469072198417\n",
      "60 Train Loss 106977.34 Test MSE 22414.027792125864 Test RE 0.2619364847567753\n",
      "61 Train Loss 105885.24 Test MSE 21911.267409790074 Test RE 0.25898212582228275\n",
      "62 Train Loss 104483.23 Test MSE 21196.658914779287 Test RE 0.2547239305599598\n",
      "63 Train Loss 102931.76 Test MSE 20444.847626575014 Test RE 0.2501658251220082\n",
      "64 Train Loss 101519.625 Test MSE 20108.98270435893 Test RE 0.2481024723955076\n",
      "65 Train Loss 100559.69 Test MSE 19983.773544713968 Test RE 0.24732885768854457\n",
      "66 Train Loss 98838.57 Test MSE 19623.815999586757 Test RE 0.24509123115695355\n",
      "67 Train Loss 97721.52 Test MSE 19298.045906943826 Test RE 0.24304836809986494\n",
      "68 Train Loss 97371.46 Test MSE 19167.437060677414 Test RE 0.24222449813932545\n",
      "69 Train Loss 96798.29 Test MSE 18748.874896068144 Test RE 0.23956515374140328\n",
      "70 Train Loss 95726.625 Test MSE 18359.82751596764 Test RE 0.23706658316160623\n",
      "71 Train Loss 94204.36 Test MSE 18191.6838034634 Test RE 0.23597852989891832\n",
      "72 Train Loss 93058.28 Test MSE 18290.19447006042 Test RE 0.2366165966324976\n",
      "73 Train Loss 91995.79 Test MSE 18362.375375952597 Test RE 0.23708303188659244\n",
      "74 Train Loss 91207.47 Test MSE 18452.225350025714 Test RE 0.23766236623209525\n",
      "75 Train Loss 90109.69 Test MSE 17974.20089844285 Test RE 0.23456371838373705\n",
      "76 Train Loss 89206.86 Test MSE 17669.273845222724 Test RE 0.23256555518325897\n",
      "77 Train Loss 88141.0 Test MSE 16980.949827451608 Test RE 0.2279906471081687\n",
      "78 Train Loss 87725.09 Test MSE 16901.81067722053 Test RE 0.22745875526555215\n",
      "79 Train Loss 86905.99 Test MSE 16727.40754397019 Test RE 0.22628218355666452\n",
      "80 Train Loss 85898.8 Test MSE 16715.466580477165 Test RE 0.22620140266838906\n",
      "81 Train Loss 85257.195 Test MSE 16619.225530232055 Test RE 0.22554927349948803\n",
      "82 Train Loss 84539.33 Test MSE 16598.27831196156 Test RE 0.22540708517823896\n",
      "83 Train Loss 83596.7 Test MSE 16389.68612803381 Test RE 0.22398625070109673\n",
      "84 Train Loss 82758.484 Test MSE 15956.949779415729 Test RE 0.22100951979408462\n",
      "85 Train Loss 81947.25 Test MSE 15795.079848650175 Test RE 0.21988568392223848\n",
      "86 Train Loss 80478.78 Test MSE 14907.579191398137 Test RE 0.21361886555766196\n",
      "87 Train Loss 79951.19 Test MSE 14635.763523909358 Test RE 0.21166240854855303\n",
      "88 Train Loss 79221.086 Test MSE 14432.42227577509 Test RE 0.21018690512401747\n",
      "89 Train Loss 78516.42 Test MSE 14357.336022554378 Test RE 0.2096394319577865\n",
      "90 Train Loss 77425.93 Test MSE 13804.459372770812 Test RE 0.2055633768290898\n",
      "91 Train Loss 76527.13 Test MSE 13747.67416928452 Test RE 0.20514014449099174\n",
      "92 Train Loss 76143.02 Test MSE 13771.784446211674 Test RE 0.20531995014390306\n",
      "93 Train Loss 75692.71 Test MSE 13751.759586509981 Test RE 0.20517062313106066\n",
      "94 Train Loss 74854.12 Test MSE 13277.90103475897 Test RE 0.20160474778978063\n",
      "95 Train Loss 74250.32 Test MSE 13547.13244317385 Test RE 0.2036384253633669\n",
      "96 Train Loss 73673.86 Test MSE 13277.768274095622 Test RE 0.201603739902808\n",
      "97 Train Loss 72967.62 Test MSE 13128.12201736262 Test RE 0.20046443953371917\n",
      "98 Train Loss 72461.75 Test MSE 12966.962769934578 Test RE 0.19923020131860802\n",
      "99 Train Loss 72211.94 Test MSE 12935.564159258774 Test RE 0.19898884399091016\n",
      "100 Train Loss 71666.625 Test MSE 12692.514357412247 Test RE 0.1971105517035901\n",
      "101 Train Loss 71200.9 Test MSE 12540.037900557427 Test RE 0.19592301996055186\n",
      "102 Train Loss 70617.36 Test MSE 12280.794003142752 Test RE 0.19388725637541665\n",
      "103 Train Loss 69922.19 Test MSE 12451.585353308998 Test RE 0.19523081479545362\n",
      "104 Train Loss 69426.04 Test MSE 12200.54788963063 Test RE 0.1932527616362443\n",
      "105 Train Loss 68903.055 Test MSE 11834.298720134102 Test RE 0.1903300254141473\n",
      "106 Train Loss 68401.54 Test MSE 11627.40356031355 Test RE 0.18865895081929027\n",
      "107 Train Loss 68001.3 Test MSE 11400.817863135526 Test RE 0.1868116884044932\n",
      "108 Train Loss 67729.73 Test MSE 11341.185536208393 Test RE 0.18632248574023588\n",
      "109 Train Loss 67391.664 Test MSE 11190.044865258154 Test RE 0.18507678885549964\n",
      "110 Train Loss 66788.01 Test MSE 10848.617655753664 Test RE 0.18223141336844595\n",
      "111 Train Loss 66428.76 Test MSE 10639.858613870812 Test RE 0.18046956449869914\n",
      "112 Train Loss 66110.9 Test MSE 10596.9929364543 Test RE 0.18010566128500638\n",
      "113 Train Loss 65777.1 Test MSE 10571.359041274618 Test RE 0.17988769355383744\n",
      "114 Train Loss 65434.137 Test MSE 10542.413256069574 Test RE 0.17964124653768584\n",
      "115 Train Loss 65076.473 Test MSE 10456.973350210958 Test RE 0.17891182362836075\n",
      "116 Train Loss 64709.535 Test MSE 10270.589126151606 Test RE 0.17731019999996575\n",
      "117 Train Loss 64398.727 Test MSE 10143.94284642435 Test RE 0.17621360602274852\n",
      "118 Train Loss 63634.86 Test MSE 9833.868428507161 Test RE 0.173499504386312\n",
      "119 Train Loss 63186.387 Test MSE 9781.070024439237 Test RE 0.17303311489340095\n",
      "120 Train Loss 62920.39 Test MSE 9754.020029495767 Test RE 0.17279368375658477\n",
      "121 Train Loss 62628.39 Test MSE 9662.551816081103 Test RE 0.1719815900066024\n",
      "122 Train Loss 62287.36 Test MSE 9536.269094054118 Test RE 0.17085405496289569\n",
      "123 Train Loss 61715.562 Test MSE 9258.57620564482 Test RE 0.1683480710665445\n",
      "124 Train Loss 61076.445 Test MSE 8999.997087043264 Test RE 0.1659805602928088\n",
      "125 Train Loss 60615.473 Test MSE 8954.051888685446 Test RE 0.1655563508539077\n",
      "126 Train Loss 60422.645 Test MSE 8948.0089185381 Test RE 0.1655004755388393\n",
      "127 Train Loss 60186.414 Test MSE 8916.275607437254 Test RE 0.165206748591924\n",
      "128 Train Loss 59928.777 Test MSE 8987.54109225823 Test RE 0.1658656619874242\n",
      "129 Train Loss 59611.64 Test MSE 8863.32246272786 Test RE 0.1647154423151665\n",
      "130 Train Loss 59421.562 Test MSE 8840.175112814894 Test RE 0.16450021723625585\n",
      "131 Train Loss 58956.91 Test MSE 8574.183674044716 Test RE 0.1620064976001818\n",
      "132 Train Loss 58780.984 Test MSE 8544.106625389673 Test RE 0.1617220997976192\n",
      "133 Train Loss 58524.36 Test MSE 8470.939400668745 Test RE 0.1610281595670962\n",
      "134 Train Loss 58219.582 Test MSE 8401.072131296369 Test RE 0.1603627143419405\n",
      "135 Train Loss 57929.586 Test MSE 8310.365669701761 Test RE 0.15949464591473142\n",
      "136 Train Loss 57574.125 Test MSE 8176.8743209038375 Test RE 0.15820846001463715\n",
      "137 Train Loss 57299.95 Test MSE 8179.060346232076 Test RE 0.15822960651728052\n",
      "138 Train Loss 57118.508 Test MSE 8214.63658407764 Test RE 0.15857335664530603\n",
      "139 Train Loss 56977.223 Test MSE 8165.202462966105 Test RE 0.1580955044992951\n",
      "140 Train Loss 56731.695 Test MSE 8161.778980014736 Test RE 0.15806235810697966\n",
      "141 Train Loss 56414.29 Test MSE 7948.884285699159 Test RE 0.15598725991296866\n",
      "142 Train Loss 56185.848 Test MSE 7932.302680268659 Test RE 0.15582447798027876\n",
      "143 Train Loss 55970.15 Test MSE 7887.57972224836 Test RE 0.15538458161561855\n",
      "144 Train Loss 55873.438 Test MSE 7869.277951339875 Test RE 0.15520420533563697\n",
      "145 Train Loss 55777.82 Test MSE 7830.145978440299 Test RE 0.15481782833487462\n",
      "146 Train Loss 55667.47 Test MSE 7807.325591502849 Test RE 0.15459206110878798\n",
      "147 Train Loss 55501.36 Test MSE 7767.682758921346 Test RE 0.1541990797680591\n",
      "148 Train Loss 55271.86 Test MSE 7756.235772812305 Test RE 0.15408541874733758\n",
      "149 Train Loss 54983.99 Test MSE 7695.576745417369 Test RE 0.15348170980590678\n",
      "150 Train Loss 54775.594 Test MSE 7632.791752374472 Test RE 0.15285433100610363\n",
      "151 Train Loss 54580.336 Test MSE 7593.757396780758 Test RE 0.15246297890432278\n",
      "152 Train Loss 54390.164 Test MSE 7489.002447473423 Test RE 0.1514077229636318\n",
      "153 Train Loss 54227.125 Test MSE 7439.4776640442515 Test RE 0.15090626280976815\n",
      "154 Train Loss 53968.477 Test MSE 7353.547914586782 Test RE 0.15003220950896765\n",
      "155 Train Loss 53797.555 Test MSE 7272.67029340911 Test RE 0.14920486755284543\n",
      "156 Train Loss 53707.67 Test MSE 7241.739888665048 Test RE 0.14888724802377756\n",
      "157 Train Loss 53493.734 Test MSE 7249.506375087397 Test RE 0.1489670645419151\n",
      "158 Train Loss 53395.54 Test MSE 7212.037719913374 Test RE 0.1485816019999853\n",
      "159 Train Loss 53303.523 Test MSE 7132.917173676882 Test RE 0.1477643379811591\n",
      "160 Train Loss 53113.984 Test MSE 7160.731800584355 Test RE 0.14805215928237295\n",
      "161 Train Loss 53018.39 Test MSE 7183.90532647285 Test RE 0.14829152862100678\n",
      "162 Train Loss 52961.605 Test MSE 7168.280676540302 Test RE 0.1481301773550881\n",
      "163 Train Loss 52843.324 Test MSE 7107.187884677026 Test RE 0.1474975953629436\n",
      "164 Train Loss 52678.91 Test MSE 7079.936797495605 Test RE 0.14721454880058674\n",
      "165 Train Loss 52511.94 Test MSE 7028.579722265631 Test RE 0.1466796379954702\n",
      "166 Train Loss 52341.305 Test MSE 6984.2597131295315 Test RE 0.1462164488691804\n",
      "167 Train Loss 52163.27 Test MSE 6998.529749570304 Test RE 0.14636574524778292\n",
      "168 Train Loss 51999.793 Test MSE 6990.607414959561 Test RE 0.14628287878927232\n",
      "169 Train Loss 51871.113 Test MSE 6942.062502216005 Test RE 0.14577407744068846\n",
      "170 Train Loss 51730.79 Test MSE 6866.325262835144 Test RE 0.14497670602842236\n",
      "171 Train Loss 51529.78 Test MSE 6774.319812788296 Test RE 0.14400212127396161\n",
      "172 Train Loss 51344.473 Test MSE 6740.137034772601 Test RE 0.1436383491229702\n",
      "173 Train Loss 51163.58 Test MSE 6727.292422320176 Test RE 0.14350141876485364\n",
      "174 Train Loss 50942.746 Test MSE 6751.324100835678 Test RE 0.1437575028937553\n",
      "175 Train Loss 50782.508 Test MSE 6696.678279511993 Test RE 0.14317452778849\n",
      "176 Train Loss 50452.727 Test MSE 6687.138158159774 Test RE 0.14307250786702497\n",
      "177 Train Loss 50224.965 Test MSE 6720.642380311985 Test RE 0.14343047444187884\n",
      "178 Train Loss 49968.844 Test MSE 6672.822328381021 Test RE 0.14291928095642514\n",
      "179 Train Loss 49724.02 Test MSE 6551.950903976035 Test RE 0.1416189464057399\n",
      "180 Train Loss 49378.51 Test MSE 6516.861543692997 Test RE 0.14123921298345476\n",
      "181 Train Loss 49190.54 Test MSE 6516.950086219954 Test RE 0.1412401724663486\n",
      "182 Train Loss 49003.64 Test MSE 6541.268701609016 Test RE 0.14150345260989367\n",
      "183 Train Loss 48937.086 Test MSE 6516.256935110574 Test RE 0.14123266102431742\n",
      "184 Train Loss 48870.598 Test MSE 6506.2184280263 Test RE 0.14112383232620804\n",
      "185 Train Loss 48806.266 Test MSE 6494.119908610727 Test RE 0.14099255915121914\n",
      "186 Train Loss 48731.36 Test MSE 6501.543138816173 Test RE 0.14107311828159175\n",
      "187 Train Loss 48702.95 Test MSE 6490.153647402892 Test RE 0.1409494972170149\n",
      "188 Train Loss 48629.508 Test MSE 6474.855621421156 Test RE 0.14078328226139228\n",
      "189 Train Loss 48553.402 Test MSE 6480.523163988252 Test RE 0.14084488369047551\n",
      "190 Train Loss 48455.57 Test MSE 6473.845337509186 Test RE 0.14077229849263834\n",
      "191 Train Loss 48335.125 Test MSE 6465.120643887875 Test RE 0.1406774082694181\n",
      "192 Train Loss 48223.855 Test MSE 6448.030450034654 Test RE 0.14049134869994082\n",
      "193 Train Loss 48140.77 Test MSE 6441.405119834307 Test RE 0.14041915294928078\n",
      "194 Train Loss 48062.344 Test MSE 6426.026685507347 Test RE 0.1402514320021333\n",
      "195 Train Loss 48006.14 Test MSE 6436.815118835159 Test RE 0.1403691142620983\n",
      "196 Train Loss 47912.125 Test MSE 6433.988091424817 Test RE 0.1403382860569119\n",
      "197 Train Loss 47833.13 Test MSE 6426.976787742746 Test RE 0.14026179986088205\n",
      "198 Train Loss 47661.598 Test MSE 6438.321093532626 Test RE 0.14038553387082148\n",
      "199 Train Loss 47568.035 Test MSE 6448.730848513139 Test RE 0.14049897872399822\n",
      "Training time: 642.29\n",
      "Training time: 642.29\n",
      "ES_rowdy_high\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 477699.97 Test MSE 303911.31748312234 Test RE 0.9645160934605739\n",
      "1 Train Loss 428029.72 Test MSE 251951.4757003435 Test RE 0.8782021480597049\n",
      "2 Train Loss 292224.97 Test MSE 117744.24799236085 Test RE 0.6003519035364288\n",
      "3 Train Loss 250185.56 Test MSE 75057.09053170843 Test RE 0.47932701284082924\n",
      "4 Train Loss 249888.98 Test MSE 75032.0942278076 Test RE 0.47924719092590107\n",
      "5 Train Loss 249657.39 Test MSE 74889.63864291018 Test RE 0.4787920265368869\n",
      "6 Train Loss 248451.5 Test MSE 74195.2878245075 Test RE 0.4765672607070363\n",
      "7 Train Loss 242475.47 Test MSE 71805.08309936931 Test RE 0.4688281026510465\n",
      "8 Train Loss 236681.52 Test MSE 69075.25107955502 Test RE 0.4598299746520418\n",
      "9 Train Loss 225264.27 Test MSE 64554.9593547039 Test RE 0.4445297669569208\n",
      "10 Train Loss 206532.86 Test MSE 59519.53650189751 Test RE 0.42684068885956883\n",
      "11 Train Loss 201552.58 Test MSE 57985.13701179591 Test RE 0.4213028390035373\n",
      "12 Train Loss 190096.66 Test MSE 52315.685353487825 Test RE 0.4001768869059334\n",
      "13 Train Loss 180898.22 Test MSE 48218.86168334622 Test RE 0.38418863957697114\n",
      "14 Train Loss 170283.86 Test MSE 43951.44347838307 Test RE 0.36679432976708787\n",
      "15 Train Loss 162978.7 Test MSE 41554.76411934497 Test RE 0.3566534690045762\n",
      "16 Train Loss 154557.44 Test MSE 38367.5425599455 Test RE 0.3427031005169166\n",
      "17 Train Loss 151782.73 Test MSE 36686.48699649963 Test RE 0.33511132523514847\n",
      "18 Train Loss 149014.0 Test MSE 35131.09316153325 Test RE 0.3279305472233061\n",
      "19 Train Loss 146550.83 Test MSE 34660.40155093462 Test RE 0.32572630802537617\n",
      "20 Train Loss 142319.31 Test MSE 33959.611783473076 Test RE 0.32241660475538575\n",
      "21 Train Loss 137403.42 Test MSE 31582.967343801665 Test RE 0.3109299145306928\n",
      "22 Train Loss 133377.86 Test MSE 30944.77813860549 Test RE 0.3077724406373057\n",
      "23 Train Loss 130339.12 Test MSE 30095.939910077297 Test RE 0.30352187569248157\n",
      "24 Train Loss 128188.336 Test MSE 28954.17784670423 Test RE 0.29770879211013246\n",
      "25 Train Loss 114617.25 Test MSE 24702.778511330605 Test RE 0.2749849618018344\n",
      "26 Train Loss 111369.875 Test MSE 23068.23059732501 Test RE 0.26573158863527263\n",
      "27 Train Loss 109405.84 Test MSE 21584.777457119544 Test RE 0.2570453960012591\n",
      "28 Train Loss 107766.11 Test MSE 20687.27971357241 Test RE 0.25164466939645935\n",
      "29 Train Loss 104708.25 Test MSE 19974.97676194899 Test RE 0.24727441507504097\n",
      "30 Train Loss 101653.734 Test MSE 19559.786218617213 Test RE 0.24469105516908796\n",
      "31 Train Loss 98445.19 Test MSE 18856.300731087184 Test RE 0.24025049426890052\n",
      "32 Train Loss 96392.734 Test MSE 17865.048376767172 Test RE 0.23385041239711654\n",
      "33 Train Loss 93794.05 Test MSE 16978.57978047401 Test RE 0.22797473611952712\n",
      "34 Train Loss 91622.05 Test MSE 15894.250448747141 Test RE 0.22057488823482158\n",
      "35 Train Loss 90419.53 Test MSE 15843.44832416156 Test RE 0.22022209898620423\n",
      "36 Train Loss 88729.19 Test MSE 14521.698195449804 Test RE 0.21083598882586174\n",
      "37 Train Loss 87447.42 Test MSE 14526.952608608834 Test RE 0.2108741289657479\n",
      "38 Train Loss 84973.75 Test MSE 13777.8931509554 Test RE 0.20536548164000323\n",
      "39 Train Loss 80364.25 Test MSE 12717.213216976133 Test RE 0.197302241056636\n",
      "40 Train Loss 76638.2 Test MSE 11987.693190605867 Test RE 0.191559569097722\n",
      "41 Train Loss 74515.45 Test MSE 12285.445011595466 Test RE 0.19392396759718397\n",
      "42 Train Loss 73072.234 Test MSE 11915.890118709303 Test RE 0.19098501218547345\n",
      "43 Train Loss 71509.08 Test MSE 12192.813817639457 Test RE 0.19319149931730334\n",
      "44 Train Loss 70424.59 Test MSE 11839.295361092863 Test RE 0.19037020145081554\n",
      "45 Train Loss 69524.08 Test MSE 11300.481076897639 Test RE 0.1859878217275298\n",
      "46 Train Loss 68105.01 Test MSE 11000.63144259523 Test RE 0.18350371004215238\n",
      "47 Train Loss 65318.242 Test MSE 10859.301956937179 Test RE 0.1823211269255969\n",
      "48 Train Loss 61669.758 Test MSE 9076.749372171604 Test RE 0.16668680174389836\n",
      "49 Train Loss 59548.43 Test MSE 8611.487607510946 Test RE 0.16235853813926657\n",
      "50 Train Loss 58531.32 Test MSE 8023.2562949368485 Test RE 0.15671529141817506\n",
      "51 Train Loss 57306.66 Test MSE 7480.177712149223 Test RE 0.15131849032324735\n",
      "52 Train Loss 54775.43 Test MSE 7106.782584582249 Test RE 0.14749338964595327\n",
      "53 Train Loss 53657.29 Test MSE 7066.809553198688 Test RE 0.14707800676443508\n",
      "54 Train Loss 52742.152 Test MSE 7528.387717175149 Test RE 0.151805333614178\n",
      "55 Train Loss 52327.203 Test MSE 7375.857479798198 Test RE 0.150259624802488\n",
      "56 Train Loss 51620.734 Test MSE 7348.341957132819 Test RE 0.1499790923201022\n",
      "57 Train Loss 51189.176 Test MSE 7264.758714114738 Test RE 0.1491236891613375\n",
      "58 Train Loss 50506.887 Test MSE 7384.296308505038 Test RE 0.15034555737082142\n",
      "59 Train Loss 49518.617 Test MSE 7215.7191769944375 Test RE 0.14861951964717804\n",
      "60 Train Loss 49249.63 Test MSE 7126.952411575539 Test RE 0.14770254254475218\n",
      "61 Train Loss 48963.043 Test MSE 7007.954103051379 Test RE 0.14646426154335226\n",
      "62 Train Loss 48611.35 Test MSE 6898.290739649799 Test RE 0.1453137763176406\n",
      "63 Train Loss 48500.625 Test MSE 6923.916813612686 Test RE 0.14558343511971478\n",
      "64 Train Loss 48386.426 Test MSE 6930.5609753338185 Test RE 0.14565326899949108\n",
      "65 Train Loss 48254.805 Test MSE 6939.095013872825 Test RE 0.14574291745662096\n",
      "66 Train Loss 48135.39 Test MSE 7007.678612633916 Test RE 0.1464613826790991\n",
      "67 Train Loss 47953.992 Test MSE 7015.040276609174 Test RE 0.14653829234683385\n",
      "68 Train Loss 47753.8 Test MSE 6910.355111162949 Test RE 0.14544078992250645\n",
      "69 Train Loss 47607.535 Test MSE 6921.317732763537 Test RE 0.14555610820027526\n",
      "70 Train Loss 47532.137 Test MSE 6934.253128626977 Test RE 0.14569206114019803\n",
      "71 Train Loss 47418.746 Test MSE 6918.98961723731 Test RE 0.14553162587264898\n",
      "72 Train Loss 47336.316 Test MSE 6940.618575022674 Test RE 0.14575891637719063\n",
      "73 Train Loss 47234.043 Test MSE 6988.74453195491 Test RE 0.1462633864884078\n",
      "74 Train Loss 47147.754 Test MSE 7078.925892454924 Test RE 0.14720403844955013\n",
      "75 Train Loss 46941.406 Test MSE 7079.642891667435 Test RE 0.14721149314739637\n",
      "76 Train Loss 46705.832 Test MSE 7068.234024864089 Test RE 0.1470928294291016\n",
      "77 Train Loss 46494.46 Test MSE 7103.2667650987505 Test RE 0.14745690166581996\n",
      "78 Train Loss 46290.727 Test MSE 7049.792908712758 Test RE 0.14690082053915968\n",
      "79 Train Loss 46205.617 Test MSE 7113.344665305781 Test RE 0.1475614682877503\n",
      "80 Train Loss 46078.23 Test MSE 6943.789820283743 Test RE 0.14579221200347775\n",
      "81 Train Loss 45983.395 Test MSE 6944.231564590919 Test RE 0.14579684937421475\n",
      "82 Train Loss 45908.086 Test MSE 6923.874056565257 Test RE 0.14558298561059896\n",
      "83 Train Loss 45850.168 Test MSE 6973.789913246757 Test RE 0.14610681440806256\n",
      "84 Train Loss 45646.977 Test MSE 7058.500933707999 Test RE 0.14699151974479835\n",
      "85 Train Loss 45482.207 Test MSE 7115.80998751696 Test RE 0.14758703678385435\n",
      "86 Train Loss 45419.473 Test MSE 7030.628219537923 Test RE 0.14670101151330772\n",
      "87 Train Loss 45398.844 Test MSE 7027.586417520802 Test RE 0.14666927297621019\n",
      "88 Train Loss 45354.61 Test MSE 6999.831043085246 Test RE 0.14637935210158454\n",
      "89 Train Loss 45329.383 Test MSE 7066.013473393764 Test RE 0.1470697223237916\n",
      "90 Train Loss 45300.035 Test MSE 7035.459453272854 Test RE 0.14675140709234705\n",
      "91 Train Loss 45174.57 Test MSE 6997.345094665353 Test RE 0.1463533569146266\n",
      "92 Train Loss 44931.773 Test MSE 6978.861717948107 Test RE 0.1461599340571824\n",
      "93 Train Loss 44753.54 Test MSE 6888.401901136573 Test RE 0.14520958385330474\n",
      "94 Train Loss 44515.36 Test MSE 6703.262960296862 Test RE 0.14324490050826616\n",
      "95 Train Loss 44200.594 Test MSE 6567.575395491669 Test RE 0.14178770579162667\n",
      "96 Train Loss 43831.887 Test MSE 6365.833343049346 Test RE 0.13959301072538183\n",
      "97 Train Loss 43620.34 Test MSE 6306.1356208118705 Test RE 0.13893692897203236\n",
      "98 Train Loss 43488.4 Test MSE 6260.887269442515 Test RE 0.13843757523430938\n",
      "99 Train Loss 43331.66 Test MSE 6214.302097174505 Test RE 0.137921579711357\n",
      "100 Train Loss 43283.496 Test MSE 6237.122163412214 Test RE 0.13817458442440841\n",
      "101 Train Loss 43259.848 Test MSE 6241.287322519737 Test RE 0.13822071331707816\n",
      "102 Train Loss 43170.715 Test MSE 6215.128146769518 Test RE 0.13793074616942694\n",
      "103 Train Loss 43119.22 Test MSE 6243.200257098309 Test RE 0.13824189379727655\n",
      "104 Train Loss 42982.297 Test MSE 6194.119290549684 Test RE 0.13769742675043667\n",
      "105 Train Loss 42655.15 Test MSE 6157.167061133201 Test RE 0.13728608188540742\n",
      "106 Train Loss 42394.535 Test MSE 6178.242225682593 Test RE 0.13752083717930852\n",
      "107 Train Loss 42236.254 Test MSE 6137.2176045326805 Test RE 0.13706349536577872\n",
      "108 Train Loss 42101.707 Test MSE 6089.856977256884 Test RE 0.13653361476054368\n",
      "109 Train Loss 42013.793 Test MSE 6105.553961877703 Test RE 0.13670946345454474\n",
      "110 Train Loss 41956.656 Test MSE 6071.953218479675 Test RE 0.13633276733521552\n",
      "111 Train Loss 41936.91 Test MSE 6068.3006141010555 Test RE 0.1362917554436238\n",
      "112 Train Loss 41926.395 Test MSE 6066.153297079137 Test RE 0.136267639342612\n",
      "113 Train Loss 41889.816 Test MSE 6071.346178519244 Test RE 0.13632595227066624\n",
      "114 Train Loss 41825.61 Test MSE 6079.961635456094 Test RE 0.13642264367682036\n",
      "115 Train Loss 41794.938 Test MSE 6083.3434625561495 Test RE 0.13646057924979343\n",
      "116 Train Loss 41730.5 Test MSE 6040.741378102622 Test RE 0.13598191821000388\n",
      "117 Train Loss 41689.863 Test MSE 6058.300061553521 Test RE 0.13617940480670815\n",
      "118 Train Loss 41676.254 Test MSE 6055.773861266804 Test RE 0.13615100968616337\n",
      "119 Train Loss 41667.03 Test MSE 6049.257008072176 Test RE 0.13607773127457182\n",
      "120 Train Loss 41659.914 Test MSE 6062.301308996703 Test RE 0.13622436771303104\n",
      "121 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "122 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "123 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "124 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "125 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "126 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "127 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "128 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "129 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "130 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "131 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "132 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "133 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "134 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "135 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "136 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "137 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "138 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "139 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "140 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "141 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "142 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "143 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "144 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "145 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "146 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "147 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "148 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "149 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "150 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "151 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "152 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "153 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "154 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "155 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "156 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "157 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "158 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "159 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "160 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "161 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "162 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "163 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "164 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "165 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "166 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "167 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "168 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "169 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "170 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "171 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "172 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "173 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "174 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "175 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "176 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "177 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "178 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "179 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "180 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "181 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "182 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "183 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "184 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "185 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "186 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "187 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "188 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "189 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "190 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "191 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "192 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "193 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "194 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "195 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "196 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "197 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "198 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "199 Train Loss 41659.023 Test MSE 6061.926505595485 Test RE 0.1362201565939421\n",
      "Training time: 440.79\n",
      "Training time: 440.79\n",
      "ES_rowdy_high\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 480060.06 Test MSE 306443.2731631689 Test RE 0.9685255634757762\n",
      "1 Train Loss 406666.0 Test MSE 230859.8655014097 Test RE 0.8406404062722724\n",
      "2 Train Loss 306572.25 Test MSE 131401.576545639 Test RE 0.6342147376532333\n",
      "3 Train Loss 249962.2 Test MSE 75033.36985706876 Test RE 0.4792512647768846\n",
      "4 Train Loss 248760.31 Test MSE 74447.46389740791 Test RE 0.4773764557417472\n",
      "5 Train Loss 246820.42 Test MSE 73327.33418249531 Test RE 0.47377156344141835\n",
      "6 Train Loss 241787.81 Test MSE 71239.07268549863 Test RE 0.4669766557708576\n",
      "7 Train Loss 236218.34 Test MSE 69607.67130017551 Test RE 0.46159871829853\n",
      "8 Train Loss 229155.56 Test MSE 66345.93052450755 Test RE 0.4506539547888421\n",
      "9 Train Loss 218719.61 Test MSE 62464.37109341362 Test RE 0.4372725626550509\n",
      "10 Train Loss 208204.2 Test MSE 58802.728941637215 Test RE 0.42426263268897935\n",
      "11 Train Loss 197292.11 Test MSE 54648.242205982504 Test RE 0.4090007839369513\n",
      "12 Train Loss 188309.94 Test MSE 50939.20319049293 Test RE 0.3948772517910272\n",
      "13 Train Loss 179088.73 Test MSE 47763.15562358198 Test RE 0.3823688878732177\n",
      "14 Train Loss 167092.89 Test MSE 41822.1326384928 Test RE 0.35779900571004875\n",
      "15 Train Loss 159014.19 Test MSE 39425.03154203561 Test RE 0.34739380265996234\n",
      "16 Train Loss 152036.75 Test MSE 37024.24511456317 Test RE 0.33665041027803716\n",
      "17 Train Loss 145584.86 Test MSE 35534.616736537566 Test RE 0.3298085116597224\n",
      "18 Train Loss 140160.83 Test MSE 33216.56264178062 Test RE 0.318869797491326\n",
      "19 Train Loss 131954.39 Test MSE 32286.03226886669 Test RE 0.3143716540429813\n",
      "20 Train Loss 127914.266 Test MSE 31345.422151669623 Test RE 0.3097584078925002\n",
      "21 Train Loss 124093.734 Test MSE 29415.451866026662 Test RE 0.3000708468579288\n",
      "22 Train Loss 117334.02 Test MSE 25764.757257886155 Test RE 0.2808336014187945\n",
      "23 Train Loss 113646.71 Test MSE 24031.490291026214 Test RE 0.2712229240964656\n",
      "24 Train Loss 108717.91 Test MSE 23420.909838873726 Test RE 0.2677552055848404\n",
      "25 Train Loss 103343.5 Test MSE 21535.9029534992 Test RE 0.2567542165851244\n",
      "26 Train Loss 100111.37 Test MSE 20851.639827505205 Test RE 0.25264234816363845\n",
      "27 Train Loss 97067.805 Test MSE 20415.440840818574 Test RE 0.24998584774610202\n",
      "28 Train Loss 94190.44 Test MSE 19036.754243417723 Test RE 0.24139734740032706\n",
      "29 Train Loss 92698.08 Test MSE 18837.235650928713 Test RE 0.24012900826377753\n",
      "30 Train Loss 90530.28 Test MSE 17159.868192880553 Test RE 0.22918860208325872\n",
      "31 Train Loss 88239.88 Test MSE 16121.431338557726 Test RE 0.22214566401547067\n",
      "32 Train Loss 86202.95 Test MSE 15368.338507807952 Test RE 0.21689498016120537\n",
      "33 Train Loss 81780.875 Test MSE 13729.99966873954 Test RE 0.20500823433481105\n",
      "34 Train Loss 80228.734 Test MSE 13721.397494973844 Test RE 0.20494400298719298\n",
      "35 Train Loss 78213.88 Test MSE 12955.021495867815 Test RE 0.19913844465783692\n",
      "36 Train Loss 77079.125 Test MSE 12704.586583651182 Test RE 0.1972042682658854\n",
      "37 Train Loss 75666.38 Test MSE 12664.490675279036 Test RE 0.19689283220266246\n",
      "38 Train Loss 73744.17 Test MSE 11867.933867899124 Test RE 0.19060030912039894\n",
      "39 Train Loss 72374.02 Test MSE 11516.819399483398 Test RE 0.18775967294588553\n",
      "40 Train Loss 71052.125 Test MSE 11247.347876849159 Test RE 0.18555006285963524\n",
      "41 Train Loss 69638.04 Test MSE 10243.174776563172 Test RE 0.17707340288263557\n",
      "42 Train Loss 68335.96 Test MSE 10128.284797275524 Test RE 0.17607755306390888\n",
      "43 Train Loss 65325.906 Test MSE 9625.150350949652 Test RE 0.17164841714595577\n",
      "44 Train Loss 63873.406 Test MSE 8981.822844981622 Test RE 0.16581288827708596\n",
      "45 Train Loss 62478.227 Test MSE 8432.019948507115 Test RE 0.160657814404149\n",
      "46 Train Loss 61820.754 Test MSE 8421.732917850208 Test RE 0.16055978354978515\n",
      "47 Train Loss 61093.24 Test MSE 8393.222806957438 Test RE 0.1602877814588488\n",
      "48 Train Loss 59770.688 Test MSE 8278.25597339256 Test RE 0.15918621898221127\n",
      "49 Train Loss 58685.367 Test MSE 7910.445158541556 Test RE 0.1556096421022227\n",
      "50 Train Loss 58054.08 Test MSE 7725.232642921937 Test RE 0.15377715622618987\n",
      "51 Train Loss 57269.56 Test MSE 7478.697630142403 Test RE 0.15130351909774215\n",
      "52 Train Loss 56599.37 Test MSE 7576.5113662535805 Test RE 0.152289752684918\n",
      "53 Train Loss 56158.242 Test MSE 7644.023822348241 Test RE 0.15296675640983803\n",
      "54 Train Loss 55909.18 Test MSE 7501.90154241356 Test RE 0.15153805957096977\n",
      "55 Train Loss 55408.58 Test MSE 7367.729526244324 Test RE 0.15017681138727984\n",
      "56 Train Loss 54835.355 Test MSE 7373.602755228171 Test RE 0.15023665662798857\n",
      "57 Train Loss 54438.754 Test MSE 7321.563532105501 Test RE 0.14970557010976254\n",
      "58 Train Loss 53945.586 Test MSE 7369.246588547458 Test RE 0.15019227177110428\n",
      "59 Train Loss 53275.08 Test MSE 7334.614570805233 Test RE 0.1498389393869804\n",
      "60 Train Loss 52880.582 Test MSE 7320.382553341184 Test RE 0.14969349576058244\n",
      "61 Train Loss 51768.637 Test MSE 6920.08743113006 Test RE 0.14554317093288485\n",
      "62 Train Loss 51277.766 Test MSE 6759.135990642952 Test RE 0.1438406490354935\n",
      "63 Train Loss 50721.48 Test MSE 6692.776443495558 Test RE 0.14313281121623503\n",
      "64 Train Loss 50387.664 Test MSE 6635.03929656721 Test RE 0.14251408589138365\n",
      "65 Train Loss 49818.96 Test MSE 6479.202967044329 Test RE 0.14083053666545597\n",
      "66 Train Loss 49181.19 Test MSE 6334.9855068231145 Test RE 0.1392543769988432\n",
      "67 Train Loss 48559.56 Test MSE 6346.9780828114335 Test RE 0.13938612387319593\n",
      "68 Train Loss 48023.562 Test MSE 6389.8256344040865 Test RE 0.13985582049943218\n",
      "69 Train Loss 47715.508 Test MSE 6377.416104506846 Test RE 0.13971994915139932\n",
      "70 Train Loss 47442.652 Test MSE 6540.731844697801 Test RE 0.14149764573444468\n",
      "71 Train Loss 47087.3 Test MSE 6573.773418965515 Test RE 0.141854594729718\n",
      "72 Train Loss 46319.7 Test MSE 6699.946100983442 Test RE 0.14320945642872224\n",
      "73 Train Loss 45974.082 Test MSE 6630.095364812302 Test RE 0.14246098061331675\n",
      "74 Train Loss 45584.824 Test MSE 6692.910356279388 Test RE 0.14313424314941645\n",
      "75 Train Loss 45119.125 Test MSE 6603.072657952019 Test RE 0.14217036549250295\n",
      "76 Train Loss 44906.496 Test MSE 6543.478048631254 Test RE 0.14152734735052133\n",
      "77 Train Loss 44680.047 Test MSE 6587.549802023582 Test RE 0.14200315631877436\n",
      "78 Train Loss 44103.8 Test MSE 6482.639363721131 Test RE 0.14086787809766368\n",
      "79 Train Loss 44003.51 Test MSE 6520.817727530513 Test RE 0.1412820774444306\n",
      "80 Train Loss 43807.97 Test MSE 6431.95001723964 Test RE 0.14031605703752847\n",
      "81 Train Loss 43499.285 Test MSE 6439.326531138271 Test RE 0.14039649506573615\n",
      "82 Train Loss 43130.113 Test MSE 6469.624836438935 Test RE 0.14072640409217438\n",
      "83 Train Loss 42891.043 Test MSE 6431.052116907829 Test RE 0.14030626263371723\n",
      "84 Train Loss 42711.926 Test MSE 6352.930873379188 Test RE 0.13945147323573473\n",
      "85 Train Loss 42502.29 Test MSE 6553.979175351649 Test RE 0.14164086502453874\n",
      "86 Train Loss 42321.87 Test MSE 6378.692029843976 Test RE 0.1397339252903633\n",
      "87 Train Loss 42234.656 Test MSE 6367.858682710928 Test RE 0.13961521526340456\n",
      "88 Train Loss 42077.8 Test MSE 6413.495415677854 Test RE 0.1401146144715286\n",
      "89 Train Loss 41936.41 Test MSE 6432.361746704949 Test RE 0.14032054800297958\n",
      "90 Train Loss 41846.355 Test MSE 6310.631955877304 Test RE 0.13898645182622887\n",
      "91 Train Loss 41720.63 Test MSE 6337.272740848674 Test RE 0.13927951348929077\n",
      "92 Train Loss 41640.586 Test MSE 6291.477582293808 Test RE 0.1387753619049703\n",
      "93 Train Loss 41577.734 Test MSE 6252.740509673015 Test RE 0.13834747739816156\n",
      "94 Train Loss 41488.457 Test MSE 6228.550368777651 Test RE 0.13807960381095594\n",
      "95 Train Loss 41357.11 Test MSE 6139.824407420398 Test RE 0.137092601355315\n",
      "96 Train Loss 41210.7 Test MSE 6128.208629068447 Test RE 0.1369628589513346\n",
      "97 Train Loss 41104.348 Test MSE 6038.359696540264 Test RE 0.1359551087891033\n",
      "98 Train Loss 40976.4 Test MSE 6023.190051748596 Test RE 0.13578422731364106\n",
      "99 Train Loss 40835.75 Test MSE 6014.085063441911 Test RE 0.1356815590128814\n",
      "100 Train Loss 40765.836 Test MSE 6014.509586364363 Test RE 0.13568634768105917\n",
      "101 Train Loss 40632.59 Test MSE 6023.676799796914 Test RE 0.13578971372298954\n",
      "102 Train Loss 40540.11 Test MSE 6052.531914437508 Test RE 0.1361145607173784\n",
      "103 Train Loss 40463.07 Test MSE 6136.830882711987 Test RE 0.13705917693657169\n",
      "104 Train Loss 40324.766 Test MSE 6052.135803551224 Test RE 0.1361101066027847\n",
      "105 Train Loss 40269.465 Test MSE 6059.65918348396 Test RE 0.13619467922645867\n",
      "106 Train Loss 40219.594 Test MSE 6116.775265410963 Test RE 0.13683503389305685\n",
      "107 Train Loss 40176.98 Test MSE 6109.100107973975 Test RE 0.1367491585715688\n",
      "108 Train Loss 40088.184 Test MSE 6027.565451422526 Test RE 0.13583353693227745\n",
      "109 Train Loss 40005.453 Test MSE 6014.157251514497 Test RE 0.13568237331470256\n",
      "110 Train Loss 39935.797 Test MSE 5976.909880331068 Test RE 0.13526156115802437\n",
      "111 Train Loss 39868.008 Test MSE 6013.932864179755 Test RE 0.13567984214625867\n",
      "112 Train Loss 39812.934 Test MSE 6016.960009540268 Test RE 0.1357139854383514\n",
      "113 Train Loss 39749.305 Test MSE 6001.631338796272 Test RE 0.13554100426297017\n",
      "114 Train Loss 39689.48 Test MSE 5962.5651306933505 Test RE 0.13509914789951474\n",
      "115 Train Loss 39578.426 Test MSE 5954.939304186144 Test RE 0.13501272768784747\n",
      "116 Train Loss 39525.25 Test MSE 5908.248911565702 Test RE 0.13448239462860173\n",
      "117 Train Loss 39456.242 Test MSE 5912.109403852776 Test RE 0.13452632333536496\n",
      "118 Train Loss 39386.062 Test MSE 5899.1267699758555 Test RE 0.13437853633221447\n",
      "119 Train Loss 39361.59 Test MSE 5875.138212430053 Test RE 0.13410503559529371\n",
      "120 Train Loss 39325.516 Test MSE 5851.900850681283 Test RE 0.13383956654863383\n",
      "121 Train Loss 39225.63 Test MSE 5807.147305060244 Test RE 0.13332680229206528\n",
      "122 Train Loss 39122.895 Test MSE 5776.098606923133 Test RE 0.13296989970923567\n",
      "123 Train Loss 39078.992 Test MSE 5781.697930859773 Test RE 0.1330343343078767\n",
      "124 Train Loss 39064.555 Test MSE 5758.5931376413955 Test RE 0.13276825263255623\n",
      "125 Train Loss 39043.17 Test MSE 5725.00753098691 Test RE 0.13238051704407533\n",
      "126 Train Loss 39003.758 Test MSE 5657.836382586025 Test RE 0.13160161953051064\n",
      "127 Train Loss 38945.566 Test MSE 5602.06700986677 Test RE 0.1309514137843341\n",
      "128 Train Loss 38888.25 Test MSE 5618.910925716655 Test RE 0.13114813394716746\n",
      "129 Train Loss 38831.79 Test MSE 5570.953491973953 Test RE 0.13058725961632298\n",
      "130 Train Loss 38785.58 Test MSE 5559.768392992204 Test RE 0.1304561002635847\n",
      "131 Train Loss 38739.785 Test MSE 5545.224161923379 Test RE 0.130285353387411\n",
      "132 Train Loss 38684.74 Test MSE 5515.798123417896 Test RE 0.1299392103554272\n",
      "133 Train Loss 38645.734 Test MSE 5519.8724047057885 Test RE 0.12998719173134987\n",
      "134 Train Loss 38577.56 Test MSE 5508.640388996846 Test RE 0.129854873305115\n",
      "135 Train Loss 38537.445 Test MSE 5505.352798690556 Test RE 0.1298161184303061\n",
      "136 Train Loss 38494.01 Test MSE 5459.561048363853 Test RE 0.12927510677292017\n",
      "137 Train Loss 38422.06 Test MSE 5493.964589434767 Test RE 0.12968178204016087\n",
      "138 Train Loss 38399.367 Test MSE 5493.752900675807 Test RE 0.1296792836221697\n",
      "139 Train Loss 38384.953 Test MSE 5500.896900139488 Test RE 0.1297635727926433\n",
      "140 Train Loss 38363.105 Test MSE 5507.082509484377 Test RE 0.1298365101031932\n",
      "141 Train Loss 38295.297 Test MSE 5484.173641037523 Test RE 0.12956617574025026\n",
      "142 Train Loss 38223.535 Test MSE 5468.701840312174 Test RE 0.12938328237953553\n",
      "143 Train Loss 38187.34 Test MSE 5463.184764460332 Test RE 0.12931800203262228\n",
      "144 Train Loss 38161.066 Test MSE 5478.143272267027 Test RE 0.12949492100103863\n",
      "145 Train Loss 38122.613 Test MSE 5455.367415151363 Test RE 0.12922544742090775\n",
      "146 Train Loss 38077.117 Test MSE 5461.00565336162 Test RE 0.1292922087992239\n",
      "147 Train Loss 38010.656 Test MSE 5412.464083268249 Test RE 0.1287163024447466\n",
      "148 Train Loss 37973.684 Test MSE 5410.375307588099 Test RE 0.12869146297952458\n",
      "149 Train Loss 37922.08 Test MSE 5420.400821535669 Test RE 0.1288106414881599\n",
      "150 Train Loss 37892.473 Test MSE 5449.963748350685 Test RE 0.12916143117681672\n",
      "151 Train Loss 37873.363 Test MSE 5442.778425625859 Test RE 0.1290762588063312\n",
      "152 Train Loss 37827.36 Test MSE 5444.638778278526 Test RE 0.12909831618458473\n",
      "153 Train Loss 37784.93 Test MSE 5440.345869858198 Test RE 0.12904741138102027\n",
      "154 Train Loss 37742.355 Test MSE 5426.284639368144 Test RE 0.12888053417803555\n",
      "155 Train Loss 37699.76 Test MSE 5441.827899645006 Test RE 0.12906498738528158\n",
      "156 Train Loss 37660.36 Test MSE 5467.534377563219 Test RE 0.12936947122019973\n",
      "157 Train Loss 37621.496 Test MSE 5456.05662559707 Test RE 0.12923361008976456\n",
      "158 Train Loss 37565.074 Test MSE 5464.236962791976 Test RE 0.12933045462583237\n",
      "159 Train Loss 37437.863 Test MSE 5473.2933724227505 Test RE 0.12943758620430423\n",
      "160 Train Loss 37343.832 Test MSE 5493.300639385364 Test RE 0.12967394572944854\n",
      "161 Train Loss 37311.01 Test MSE 5481.0795919793845 Test RE 0.12952962140328964\n",
      "162 Train Loss 37294.344 Test MSE 5452.810671409604 Test RE 0.12919516210286597\n",
      "163 Train Loss 37282.617 Test MSE 5451.999260623817 Test RE 0.12918554923947725\n",
      "164 Train Loss 37245.13 Test MSE 5483.628282558682 Test RE 0.12955973340509908\n",
      "165 Train Loss 37162.94 Test MSE 5534.411587892266 Test RE 0.13015827039041075\n",
      "166 Train Loss 37091.977 Test MSE 5519.784698498111 Test RE 0.12998615903275787\n",
      "167 Train Loss 37069.69 Test MSE 5510.7967500348495 Test RE 0.12988028670770296\n",
      "168 Train Loss 37056.145 Test MSE 5515.009171139108 Test RE 0.12992991709451368\n",
      "169 Train Loss 37040.125 Test MSE 5515.870451715214 Test RE 0.12994006229478572\n",
      "170 Train Loss 37011.027 Test MSE 5528.986107615942 Test RE 0.13009445653500448\n",
      "171 Train Loss 36990.26 Test MSE 5554.5861080589775 Test RE 0.13039528673248907\n",
      "172 Train Loss 36978.215 Test MSE 5586.003967951068 Test RE 0.13076353776837443\n",
      "173 Train Loss 36967.605 Test MSE 5566.183285684313 Test RE 0.13053133906583633\n",
      "174 Train Loss 36943.082 Test MSE 5534.45270319254 Test RE 0.1301587538642495\n",
      "175 Train Loss 36921.863 Test MSE 5518.916989610023 Test RE 0.12997594173401555\n",
      "176 Train Loss 36891.875 Test MSE 5477.908812853017 Test RE 0.12949214984056942\n",
      "177 Train Loss 36872.75 Test MSE 5470.631682207995 Test RE 0.12940610930098906\n",
      "178 Train Loss 36834.793 Test MSE 5466.481971259507 Test RE 0.129357019922243\n",
      "179 Train Loss 36747.816 Test MSE 5426.233012748343 Test RE 0.12887992108062118\n",
      "180 Train Loss 36693.977 Test MSE 5389.415328411683 Test RE 0.1284419435164892\n",
      "181 Train Loss 36633.97 Test MSE 5400.285637696041 Test RE 0.12857141028130956\n",
      "182 Train Loss 36581.953 Test MSE 5435.868423468874 Test RE 0.12899429694556355\n",
      "183 Train Loss 36531.72 Test MSE 5455.420998114012 Test RE 0.12922608204959476\n",
      "184 Train Loss 36489.234 Test MSE 5435.153850349233 Test RE 0.1289858181819649\n",
      "185 Train Loss 36458.406 Test MSE 5424.97278290913 Test RE 0.12886495418247534\n",
      "186 Train Loss 36390.55 Test MSE 5451.947313449249 Test RE 0.12918493379182747\n",
      "187 Train Loss 36332.586 Test MSE 5427.012127657119 Test RE 0.128889173232492\n",
      "188 Train Loss 36264.203 Test MSE 5406.086302800967 Test RE 0.12864044362299007\n",
      "189 Train Loss 36210.64 Test MSE 5366.887036332145 Test RE 0.12817321234256496\n",
      "190 Train Loss 36152.73 Test MSE 5373.613254485104 Test RE 0.12825350572594488\n",
      "191 Train Loss 36092.508 Test MSE 5403.479681443437 Test RE 0.12860942697451191\n",
      "192 Train Loss 36004.688 Test MSE 5358.934771079441 Test RE 0.1280782182402944\n",
      "193 Train Loss 35941.582 Test MSE 5358.3632170166975 Test RE 0.12807138800433443\n",
      "194 Train Loss 35871.953 Test MSE 5399.88710106129 Test RE 0.12856666596165436\n",
      "195 Train Loss 35778.562 Test MSE 5391.141128605919 Test RE 0.1284625067292855\n",
      "196 Train Loss 35698.69 Test MSE 5366.502135925578 Test RE 0.12816861612079175\n",
      "197 Train Loss 35652.492 Test MSE 5358.681761954144 Test RE 0.12807519475317986\n",
      "198 Train Loss 35594.29 Test MSE 5367.12355826645 Test RE 0.12817603664666366\n",
      "199 Train Loss 35526.95 Test MSE 5380.187514049736 Test RE 0.12833193657528427\n",
      "Training time: 643.73\n",
      "Training time: 643.73\n",
      "ES_rowdy_high\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 481101.78 Test MSE 306956.34718568256 Test RE 0.9693360193175155\n",
      "1 Train Loss 428405.6 Test MSE 252892.48239895364 Test RE 0.8798406062591553\n",
      "2 Train Loss 334231.5 Test MSE 155959.7705846351 Test RE 0.6909431819497517\n",
      "3 Train Loss 263901.0 Test MSE 88121.73891867531 Test RE 0.5193708502192175\n",
      "4 Train Loss 250142.38 Test MSE 75187.73575855319 Test RE 0.4797439924994026\n",
      "5 Train Loss 249846.97 Test MSE 75023.27339344098 Test RE 0.4792190197520481\n",
      "6 Train Loss 248834.02 Test MSE 74452.09315288562 Test RE 0.4773912975046788\n",
      "7 Train Loss 246631.66 Test MSE 73191.64699679565 Test RE 0.4733330196365147\n",
      "8 Train Loss 245043.16 Test MSE 72788.23800526165 Test RE 0.47202678701983586\n",
      "9 Train Loss 243571.8 Test MSE 72195.70234606936 Test RE 0.47010158418287773\n",
      "10 Train Loss 242284.42 Test MSE 71955.71928923459 Test RE 0.4693196101879926\n",
      "11 Train Loss 240184.47 Test MSE 70882.53665963525 Test RE 0.46580663183452403\n",
      "12 Train Loss 237597.47 Test MSE 70471.58233827227 Test RE 0.4644543699082922\n",
      "13 Train Loss 235448.05 Test MSE 69472.67272822846 Test RE 0.4611508839593892\n",
      "14 Train Loss 232578.27 Test MSE 68706.13889732872 Test RE 0.45859974969901024\n",
      "15 Train Loss 230307.48 Test MSE 67360.8447172411 Test RE 0.4540877689745933\n",
      "16 Train Loss 229676.66 Test MSE 67129.0177534121 Test RE 0.45330570842645923\n",
      "17 Train Loss 227386.12 Test MSE 66646.02435558818 Test RE 0.451671996807358\n",
      "18 Train Loss 225858.67 Test MSE 66388.1721202152 Test RE 0.45079739473254155\n",
      "19 Train Loss 224134.9 Test MSE 66315.9222767304 Test RE 0.45055202792666393\n",
      "20 Train Loss 223047.55 Test MSE 66201.43146608034 Test RE 0.45016293320662876\n",
      "21 Train Loss 221804.52 Test MSE 66041.25035887893 Test RE 0.44961799583720713\n",
      "22 Train Loss 221021.36 Test MSE 66022.22443375616 Test RE 0.4495532256028661\n",
      "23 Train Loss 219488.72 Test MSE 65355.72863900472 Test RE 0.44727834499172753\n",
      "24 Train Loss 216009.97 Test MSE 64505.14710377644 Test RE 0.44435822861426105\n",
      "25 Train Loss 214980.08 Test MSE 63152.94751601926 Test RE 0.43967609551416764\n",
      "26 Train Loss 213810.95 Test MSE 63163.49273391156 Test RE 0.4397128023257972\n",
      "27 Train Loss 212620.2 Test MSE 62731.81749268881 Test RE 0.4382076722067881\n",
      "28 Train Loss 211412.17 Test MSE 62489.935295862066 Test RE 0.43736203270512064\n",
      "29 Train Loss 210542.83 Test MSE 61706.26908359131 Test RE 0.43461097204621585\n",
      "30 Train Loss 209309.97 Test MSE 61386.06294922633 Test RE 0.4334818638519091\n",
      "31 Train Loss 206965.45 Test MSE 60087.22095950767 Test RE 0.42887141524906347\n",
      "32 Train Loss 206129.55 Test MSE 59207.50602961506 Test RE 0.4257203649554053\n",
      "33 Train Loss 204301.53 Test MSE 58841.56675352912 Test RE 0.424402717280096\n",
      "34 Train Loss 203241.67 Test MSE 59115.447889848394 Test RE 0.4253892728922877\n",
      "35 Train Loss 202672.61 Test MSE 59112.05531766952 Test RE 0.4253770663999923\n",
      "36 Train Loss 202026.38 Test MSE 58843.139150803756 Test RE 0.4244083878056673\n",
      "37 Train Loss 201438.06 Test MSE 58157.685862092774 Test RE 0.42192921779569925\n",
      "38 Train Loss 200803.78 Test MSE 58083.66457587122 Test RE 0.4216606231382716\n",
      "39 Train Loss 199915.75 Test MSE 57914.919047161384 Test RE 0.4210476702585508\n",
      "40 Train Loss 198618.92 Test MSE 58053.9110915434 Test RE 0.4215526110155159\n",
      "41 Train Loss 198344.39 Test MSE 57189.58773776566 Test RE 0.41840274465901367\n",
      "42 Train Loss 196664.1 Test MSE 56764.59084328657 Test RE 0.4168451931128955\n",
      "43 Train Loss 196034.7 Test MSE 56571.15404352538 Test RE 0.4161343449439768\n",
      "44 Train Loss 195297.36 Test MSE 56142.47306691556 Test RE 0.41455466964246\n",
      "45 Train Loss 194568.14 Test MSE 55996.41825327436 Test RE 0.41401508586770003\n",
      "46 Train Loss 193918.61 Test MSE 55436.08238452844 Test RE 0.4119384282369715\n",
      "47 Train Loss 192715.34 Test MSE 55019.408260565004 Test RE 0.41038738218365367\n",
      "48 Train Loss 192395.75 Test MSE 54588.460778656176 Test RE 0.40877701332560507\n",
      "49 Train Loss 191416.8 Test MSE 54162.19340026669 Test RE 0.40717786761671243\n",
      "50 Train Loss 188447.31 Test MSE 54385.395816847566 Test RE 0.40801599508589154\n",
      "51 Train Loss 186926.27 Test MSE 53904.8271633836 Test RE 0.40620930804938243\n",
      "52 Train Loss 186641.33 Test MSE 53454.25869857362 Test RE 0.4045080766492888\n",
      "53 Train Loss 186079.22 Test MSE 52869.220786247446 Test RE 0.4022883877609031\n",
      "54 Train Loss 185335.48 Test MSE 52346.860090802475 Test RE 0.4002961011653332\n",
      "55 Train Loss 184809.81 Test MSE 52276.757760414825 Test RE 0.40002797533353085\n",
      "56 Train Loss 184431.84 Test MSE 52380.26639092724 Test RE 0.40042380967427654\n",
      "57 Train Loss 183923.6 Test MSE 51759.46043841867 Test RE 0.39804384435497486\n",
      "58 Train Loss 183335.78 Test MSE 51858.90000832044 Test RE 0.3984260190900053\n",
      "59 Train Loss 183016.53 Test MSE 51720.0657063707 Test RE 0.39789233760325404\n",
      "60 Train Loss 182642.75 Test MSE 51747.23427831842 Test RE 0.3979968303874422\n",
      "61 Train Loss 182465.64 Test MSE 51660.92139763171 Test RE 0.39766476829743164\n",
      "62 Train Loss 182200.69 Test MSE 51504.23972848172 Test RE 0.39706127447576217\n",
      "63 Train Loss 181978.44 Test MSE 51409.446738618506 Test RE 0.39669571272890375\n",
      "64 Train Loss 181031.81 Test MSE 51291.506291753416 Test RE 0.39624041378001557\n",
      "65 Train Loss 179911.64 Test MSE 50314.21851464586 Test RE 0.39244735612166964\n",
      "66 Train Loss 179459.53 Test MSE 50224.72316613246 Test RE 0.3920981720731533\n",
      "67 Train Loss 179380.23 Test MSE 50306.75115386707 Test RE 0.39241823259731284\n",
      "68 Train Loss 179289.44 Test MSE 50374.06423129059 Test RE 0.39268068294493125\n",
      "69 Train Loss 179081.84 Test MSE 50317.350492873025 Test RE 0.3924595705362389\n",
      "70 Train Loss 178512.45 Test MSE 50126.71357477105 Test RE 0.3917154109000946\n",
      "71 Train Loss 178292.89 Test MSE 49868.51275207135 Test RE 0.39070525269954504\n",
      "72 Train Loss 177873.88 Test MSE 49360.10340610262 Test RE 0.3887085310479804\n",
      "73 Train Loss 177680.22 Test MSE 49255.091315752485 Test RE 0.38829482821888406\n",
      "74 Train Loss 177446.08 Test MSE 49063.70984701415 Test RE 0.3875397310434581\n",
      "75 Train Loss 176989.5 Test MSE 49151.09776584161 Test RE 0.38788470316411877\n",
      "76 Train Loss 176159.48 Test MSE 49089.02608689574 Test RE 0.3876397008944761\n",
      "77 Train Loss 175486.36 Test MSE 48522.39309840416 Test RE 0.3853959511590441\n",
      "78 Train Loss 175362.64 Test MSE 48578.17925400946 Test RE 0.385617432222885\n",
      "79 Train Loss 175212.7 Test MSE 48452.31096597666 Test RE 0.385117531979867\n",
      "80 Train Loss 174905.75 Test MSE 48079.3643810656 Test RE 0.3836325076561625\n",
      "81 Train Loss 174535.2 Test MSE 48129.361786203 Test RE 0.3838319242488656\n",
      "82 Train Loss 174248.38 Test MSE 47751.7389369566 Test RE 0.3823231868867182\n",
      "83 Train Loss 174093.42 Test MSE 47666.3415586833 Test RE 0.38198116784364017\n",
      "84 Train Loss 173815.92 Test MSE 47470.811298557084 Test RE 0.3811969076428483\n",
      "85 Train Loss 173564.36 Test MSE 47420.05179423312 Test RE 0.3809930503589353\n",
      "86 Train Loss 173221.44 Test MSE 47521.05946621357 Test RE 0.3813986040064185\n",
      "87 Train Loss 172523.61 Test MSE 47611.16409015361 Test RE 0.38176001748677035\n",
      "88 Train Loss 172154.58 Test MSE 47420.14480365809 Test RE 0.38099342399757363\n",
      "89 Train Loss 171808.69 Test MSE 47292.8083142925 Test RE 0.38048154262541795\n",
      "90 Train Loss 171462.48 Test MSE 47184.13444384624 Test RE 0.38004413803644005\n",
      "91 Train Loss 171213.66 Test MSE 47477.12141353788 Test RE 0.3812222423308598\n",
      "92 Train Loss 170778.11 Test MSE 47218.95164452399 Test RE 0.38018432957632875\n",
      "93 Train Loss 170373.67 Test MSE 46736.65862689677 Test RE 0.37823775032422546\n",
      "94 Train Loss 169614.88 Test MSE 46485.906354577695 Test RE 0.37722172205881366\n",
      "95 Train Loss 169316.44 Test MSE 46520.40578679237 Test RE 0.3773616733104813\n",
      "96 Train Loss 168920.89 Test MSE 46099.24114607903 Test RE 0.3756495994035529\n",
      "97 Train Loss 168610.27 Test MSE 45744.465785937056 Test RE 0.3742013258455243\n",
      "98 Train Loss 168360.08 Test MSE 45702.217849307366 Test RE 0.37402848651375653\n",
      "99 Train Loss 167845.84 Test MSE 45180.396767909915 Test RE 0.371887055699127\n",
      "100 Train Loss 167297.03 Test MSE 44650.68032540166 Test RE 0.36970053757310883\n",
      "101 Train Loss 167073.02 Test MSE 44653.06072848682 Test RE 0.36971039212140533\n",
      "102 Train Loss 166935.2 Test MSE 44673.49656752489 Test RE 0.3697949829388941\n",
      "103 Train Loss 166576.86 Test MSE 44414.9775718569 Test RE 0.3687234557362398\n",
      "104 Train Loss 165730.5 Test MSE 44173.980456016056 Test RE 0.367721742311556\n",
      "105 Train Loss 165378.05 Test MSE 43872.337009561925 Test RE 0.36646409178424605\n",
      "106 Train Loss 165220.45 Test MSE 43768.82763650936 Test RE 0.3660315314145406\n",
      "107 Train Loss 164697.31 Test MSE 43659.90273093252 Test RE 0.36557578712613464\n",
      "108 Train Loss 164422.16 Test MSE 43514.9122263994 Test RE 0.3649682606096207\n",
      "109 Train Loss 163812.17 Test MSE 43683.96901481201 Test RE 0.36567652989051613\n",
      "110 Train Loss 163373.36 Test MSE 43639.79373138359 Test RE 0.36549158847300695\n",
      "111 Train Loss 162844.9 Test MSE 43356.267587422124 Test RE 0.3643023609914151\n",
      "112 Train Loss 162407.06 Test MSE 43203.548405472924 Test RE 0.3636601811925497\n",
      "113 Train Loss 162128.72 Test MSE 43124.26914863194 Test RE 0.3633263666294716\n",
      "114 Train Loss 161923.58 Test MSE 42860.82382703237 Test RE 0.36221488967715515\n",
      "115 Train Loss 161702.6 Test MSE 42737.789035372254 Test RE 0.36169463531431223\n",
      "116 Train Loss 161451.83 Test MSE 42670.94491896463 Test RE 0.36141167005294605\n",
      "117 Train Loss 161155.16 Test MSE 42527.29637030052 Test RE 0.36080282451734497\n",
      "118 Train Loss 160439.31 Test MSE 42484.575077293695 Test RE 0.36062155463288675\n",
      "119 Train Loss 160047.53 Test MSE 42401.934723316925 Test RE 0.3602706461027577\n",
      "120 Train Loss 159412.19 Test MSE 42298.88329654201 Test RE 0.3598325883901175\n",
      "121 Train Loss 158821.89 Test MSE 42348.971264681044 Test RE 0.36004557215510774\n",
      "122 Train Loss 158236.05 Test MSE 42127.328819750976 Test RE 0.359102148182014\n",
      "123 Train Loss 157804.58 Test MSE 42114.8244813114 Test RE 0.3590488494306025\n",
      "124 Train Loss 157474.38 Test MSE 41552.59670538815 Test RE 0.3566441677150266\n",
      "125 Train Loss 157053.28 Test MSE 41235.17693303772 Test RE 0.35527935608019967\n",
      "126 Train Loss 156363.64 Test MSE 41169.4094235524 Test RE 0.3549959189234219\n",
      "127 Train Loss 155524.05 Test MSE 40810.773365215784 Test RE 0.35344631183448383\n",
      "128 Train Loss 155104.52 Test MSE 41073.8241653741 Test RE 0.3545835727713068\n",
      "129 Train Loss 154978.03 Test MSE 41009.22101617114 Test RE 0.3543046088515573\n",
      "130 Train Loss 154606.61 Test MSE 40686.09291853829 Test RE 0.3529059942947578\n",
      "131 Train Loss 154214.16 Test MSE 40002.32078732456 Test RE 0.3499279527644015\n",
      "132 Train Loss 153922.48 Test MSE 40151.58394286745 Test RE 0.35058019889140246\n",
      "133 Train Loss 153728.12 Test MSE 40076.016251618516 Test RE 0.35025013702951807\n",
      "134 Train Loss 153516.69 Test MSE 40176.34652657593 Test RE 0.3506882884433853\n",
      "135 Train Loss 153126.84 Test MSE 40100.85008181171 Test RE 0.3503586396475726\n",
      "136 Train Loss 152209.48 Test MSE 40009.49034432446 Test RE 0.34995930989506907\n",
      "137 Train Loss 151826.0 Test MSE 39846.87120366488 Test RE 0.34924737845667336\n",
      "138 Train Loss 151416.36 Test MSE 39948.5150531282 Test RE 0.34969253559895364\n",
      "139 Train Loss 151248.16 Test MSE 40097.55621576007 Test RE 0.350344250200396\n",
      "140 Train Loss 150716.08 Test MSE 39682.622302948366 Test RE 0.34852683589559075\n",
      "141 Train Loss 150610.66 Test MSE 39749.41552791563 Test RE 0.3488200302767128\n",
      "142 Train Loss 150399.23 Test MSE 39946.796240248004 Test RE 0.3496850126347226\n",
      "143 Train Loss 149930.36 Test MSE 40031.15080954357 Test RE 0.350054028119586\n",
      "144 Train Loss 149736.2 Test MSE 39873.28060830504 Test RE 0.349363095040042\n",
      "145 Train Loss 149282.0 Test MSE 39677.35551719538 Test RE 0.3485037064124778\n",
      "146 Train Loss 149170.9 Test MSE 39590.23816695304 Test RE 0.3481209011232843\n",
      "147 Train Loss 149103.56 Test MSE 39598.02782840756 Test RE 0.348155147072727\n",
      "148 Train Loss 149023.06 Test MSE 39616.17211136239 Test RE 0.34823490233301296\n",
      "149 Train Loss 148935.31 Test MSE 39752.96701004678 Test RE 0.34883561290123655\n",
      "150 Train Loss 148780.11 Test MSE 39601.74659823448 Test RE 0.34817149483713533\n",
      "151 Train Loss 148650.73 Test MSE 39694.89858003814 Test RE 0.3485807421258758\n",
      "152 Train Loss 148499.22 Test MSE 39575.767789210484 Test RE 0.34805727557368515\n",
      "153 Train Loss 148454.97 Test MSE 39565.70918648251 Test RE 0.34801304153177476\n",
      "154 Train Loss 148402.1 Test MSE 39623.903644059545 Test RE 0.348268881615218\n",
      "155 Train Loss 148363.66 Test MSE 39558.91917813857 Test RE 0.3479831783889898\n",
      "156 Train Loss 148277.98 Test MSE 39673.94107741248 Test RE 0.3484887108248754\n",
      "157 Train Loss 148085.8 Test MSE 39607.992942259334 Test RE 0.3481989521259261\n",
      "158 Train Loss 147750.25 Test MSE 39327.341509086684 Test RE 0.3469631376790458\n",
      "159 Train Loss 147514.27 Test MSE 39122.28165038441 Test RE 0.3460573912346584\n",
      "160 Train Loss 147358.64 Test MSE 38843.83667473822 Test RE 0.34482369520852635\n",
      "161 Train Loss 147229.25 Test MSE 38666.60307975787 Test RE 0.3440361286369232\n",
      "162 Train Loss 147054.16 Test MSE 38434.78521760549 Test RE 0.34300327845075423\n",
      "163 Train Loss 146384.47 Test MSE 38422.466460471725 Test RE 0.3429483059475519\n",
      "164 Train Loss 146025.73 Test MSE 38468.597603107395 Test RE 0.3431541210975845\n",
      "165 Train Loss 145469.58 Test MSE 37971.19174399545 Test RE 0.34092838075014714\n",
      "166 Train Loss 145052.83 Test MSE 38282.60391072658 Test RE 0.3423235496687632\n",
      "167 Train Loss 144659.84 Test MSE 37955.35723141615 Test RE 0.3408572874105845\n",
      "168 Train Loss 144553.2 Test MSE 37774.79535735069 Test RE 0.34004555480623766\n",
      "169 Train Loss 144507.14 Test MSE 37810.84575203116 Test RE 0.3402077774330795\n",
      "170 Train Loss 144456.6 Test MSE 37766.27952762587 Test RE 0.3400072232515897\n",
      "171 Train Loss 144420.75 Test MSE 37704.39331815079 Test RE 0.3397285303850599\n",
      "172 Train Loss 144355.78 Test MSE 37775.64476055321 Test RE 0.3400493779131116\n",
      "173 Train Loss 144298.92 Test MSE 37817.85905295244 Test RE 0.34023932749287766\n",
      "174 Train Loss 144250.84 Test MSE 37709.08284936224 Test RE 0.3397496568092174\n",
      "175 Train Loss 144037.84 Test MSE 37773.48527234272 Test RE 0.34003965811716524\n",
      "176 Train Loss 143565.92 Test MSE 37821.39505353297 Test RE 0.34025523344800823\n",
      "177 Train Loss 143276.69 Test MSE 37861.68078315801 Test RE 0.3404363978672425\n",
      "178 Train Loss 143099.69 Test MSE 37513.32020980672 Test RE 0.3388666224098928\n",
      "179 Train Loss 142910.4 Test MSE 37402.51283717315 Test RE 0.33836577778920945\n",
      "180 Train Loss 142819.1 Test MSE 37272.34904708707 Test RE 0.3377764944251832\n",
      "181 Train Loss 142774.75 Test MSE 37141.82711910983 Test RE 0.33718455556453447\n",
      "182 Train Loss 142731.64 Test MSE 37134.09111791523 Test RE 0.3371494388758115\n",
      "183 Train Loss 142692.45 Test MSE 37126.77603670268 Test RE 0.33711622954009907\n",
      "184 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "185 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "186 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "187 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "188 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "189 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "190 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "191 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "192 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "193 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "194 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "195 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "196 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "197 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "198 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "199 Train Loss 142660.47 Test MSE 37108.073326124664 Test RE 0.33703130725241476\n",
      "Training time: 586.12\n",
      "Training time: 586.12\n",
      "ES_rowdy_high\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 478715.97 Test MSE 304227.5481889127 Test RE 0.9650177699124103\n",
      "1 Train Loss 460446.28 Test MSE 285810.97902638774 Test RE 0.935352896886334\n",
      "2 Train Loss 417075.38 Test MSE 240283.3269923891 Test RE 0.85762584483065\n",
      "3 Train Loss 395578.03 Test MSE 220252.7981895033 Test RE 0.8211013367093254\n",
      "4 Train Loss 361063.62 Test MSE 184333.12566724324 Test RE 0.7511691362563387\n",
      "5 Train Loss 338821.94 Test MSE 164123.24260323052 Test RE 0.7087957196743959\n",
      "6 Train Loss 319674.53 Test MSE 141744.36310111068 Test RE 0.658701936589238\n",
      "7 Train Loss 306703.88 Test MSE 130712.40755129194 Test RE 0.6325494009500194\n",
      "8 Train Loss 298179.44 Test MSE 121017.96468166189 Test RE 0.608640663165382\n",
      "9 Train Loss 292418.78 Test MSE 114961.80229132158 Test RE 0.593215955709527\n",
      "10 Train Loss 285017.62 Test MSE 109333.13268685066 Test RE 0.578511421799737\n",
      "11 Train Loss 278705.62 Test MSE 101962.09951624212 Test RE 0.558670097477093\n",
      "12 Train Loss 273425.72 Test MSE 98029.474908471 Test RE 0.5477903533675622\n",
      "13 Train Loss 269384.94 Test MSE 94179.34109655232 Test RE 0.5369252965599104\n",
      "14 Train Loss 265678.75 Test MSE 90429.64937600728 Test RE 0.5261280608069114\n",
      "15 Train Loss 262085.47 Test MSE 86577.4373257859 Test RE 0.5147998422650845\n",
      "16 Train Loss 259983.14 Test MSE 84478.19007361757 Test RE 0.5085203557685255\n",
      "17 Train Loss 258032.1 Test MSE 83038.06271747204 Test RE 0.504167267418296\n",
      "18 Train Loss 256890.83 Test MSE 82499.46657154516 Test RE 0.5025295588333663\n",
      "19 Train Loss 255987.23 Test MSE 80773.01903860488 Test RE 0.4972435973231235\n",
      "20 Train Loss 254590.19 Test MSE 79457.61560998354 Test RE 0.4931781260576207\n",
      "21 Train Loss 252529.81 Test MSE 78546.57433345252 Test RE 0.49034264597503463\n",
      "22 Train Loss 251611.0 Test MSE 77848.10401918215 Test RE 0.4881576074725029\n",
      "23 Train Loss 249527.03 Test MSE 76445.32689003125 Test RE 0.4837394571334353\n",
      "24 Train Loss 248698.86 Test MSE 75950.28364430089 Test RE 0.4821706175906507\n",
      "25 Train Loss 248230.0 Test MSE 75602.22657019575 Test RE 0.48106452819588963\n",
      "26 Train Loss 247624.78 Test MSE 75273.40909091344 Test RE 0.4800172389568724\n",
      "27 Train Loss 246922.56 Test MSE 74990.11908886352 Test RE 0.4791131197537154\n",
      "28 Train Loss 246426.56 Test MSE 74709.24328249843 Test RE 0.4782150179014113\n",
      "29 Train Loss 245978.06 Test MSE 74443.93936587457 Test RE 0.47736515550264097\n",
      "30 Train Loss 245692.78 Test MSE 74250.22118551022 Test RE 0.47674365059778023\n",
      "31 Train Loss 245200.3 Test MSE 73865.75752652177 Test RE 0.4755077721796149\n",
      "32 Train Loss 244879.1 Test MSE 73578.76472157624 Test RE 0.47458312098034866\n",
      "33 Train Loss 244572.61 Test MSE 73388.58006858421 Test RE 0.47396937850666665\n",
      "34 Train Loss 244278.36 Test MSE 73160.34280646408 Test RE 0.4732317861472394\n",
      "35 Train Loss 243828.22 Test MSE 72825.78926837431 Test RE 0.47214853001742974\n",
      "36 Train Loss 243324.12 Test MSE 72619.97922646182 Test RE 0.47148089798058085\n",
      "37 Train Loss 242793.56 Test MSE 72346.47638691953 Test RE 0.47059220997935197\n",
      "38 Train Loss 242468.64 Test MSE 72132.75816217766 Test RE 0.4698966092882771\n",
      "39 Train Loss 241922.95 Test MSE 71697.98089183381 Test RE 0.4684783275347611\n",
      "40 Train Loss 240991.84 Test MSE 71246.58077070306 Test RE 0.4670012631107153\n",
      "41 Train Loss 240423.69 Test MSE 71161.59058653998 Test RE 0.46672263663687247\n",
      "42 Train Loss 239867.73 Test MSE 70929.4982957679 Test RE 0.46596091115759986\n",
      "43 Train Loss 239698.62 Test MSE 70913.44511391492 Test RE 0.4659081786647088\n",
      "44 Train Loss 239167.8 Test MSE 70591.37163031955 Test RE 0.4648489476604446\n",
      "45 Train Loss 238891.78 Test MSE 70396.43150292772 Test RE 0.4642066569783478\n",
      "46 Train Loss 238478.06 Test MSE 70092.23775123584 Test RE 0.4632026171557427\n",
      "47 Train Loss 238243.28 Test MSE 70024.17237871913 Test RE 0.4629776584619744\n",
      "48 Train Loss 237997.22 Test MSE 69880.70915959736 Test RE 0.4625031486047759\n",
      "49 Train Loss 237666.42 Test MSE 69741.42230707388 Test RE 0.462041985992155\n",
      "50 Train Loss 237210.19 Test MSE 69536.16413050826 Test RE 0.4613615598166015\n",
      "51 Train Loss 236571.95 Test MSE 69510.16479379407 Test RE 0.46127530098904285\n",
      "52 Train Loss 236319.95 Test MSE 69445.07022912828 Test RE 0.4610592638952933\n",
      "53 Train Loss 235955.66 Test MSE 69240.54480355278 Test RE 0.46037982131767563\n",
      "54 Train Loss 235701.56 Test MSE 69147.38057871675 Test RE 0.46006999297489126\n",
      "55 Train Loss 235305.33 Test MSE 68761.21207663017 Test RE 0.4587835141152352\n",
      "56 Train Loss 234797.78 Test MSE 68425.42677749945 Test RE 0.45766194216352496\n",
      "57 Train Loss 234473.95 Test MSE 68215.65488009785 Test RE 0.4569598763389856\n",
      "58 Train Loss 234205.92 Test MSE 68135.03692470281 Test RE 0.4566897765968084\n",
      "59 Train Loss 233918.98 Test MSE 68170.2333948274 Test RE 0.45680771733275577\n",
      "60 Train Loss 233763.02 Test MSE 68159.13641043862 Test RE 0.45677053545609764\n",
      "61 Train Loss 233495.3 Test MSE 68002.8520790552 Test RE 0.456246562813942\n",
      "62 Train Loss 233106.64 Test MSE 67972.20509138027 Test RE 0.45614374243137873\n",
      "63 Train Loss 232950.61 Test MSE 67859.73217019468 Test RE 0.4557661979653904\n",
      "64 Train Loss 232599.39 Test MSE 67679.26368315096 Test RE 0.45515975440920003\n",
      "65 Train Loss 232407.11 Test MSE 67618.75091956994 Test RE 0.4549562272689589\n",
      "66 Train Loss 232300.98 Test MSE 67543.73601448315 Test RE 0.4547037975185775\n",
      "67 Train Loss 232267.39 Test MSE 67563.48510489301 Test RE 0.4547702680058415\n",
      "68 Train Loss 232179.12 Test MSE 67601.19854252064 Test RE 0.45489717499853954\n",
      "69 Train Loss 231935.7 Test MSE 67437.33330055086 Test RE 0.45434550532087487\n",
      "70 Train Loss 231718.61 Test MSE 67398.77730792471 Test RE 0.45421560511820486\n",
      "71 Train Loss 231511.45 Test MSE 67369.66257480085 Test RE 0.45411748913512173\n",
      "72 Train Loss 231294.84 Test MSE 67285.41913928122 Test RE 0.45383347120318357\n",
      "73 Train Loss 231096.1 Test MSE 67286.71330765449 Test RE 0.4538378357007857\n",
      "74 Train Loss 230982.2 Test MSE 67273.94047992644 Test RE 0.45379475834323757\n",
      "75 Train Loss 230838.28 Test MSE 67271.46198571348 Test RE 0.4537863989544919\n",
      "76 Train Loss 230754.67 Test MSE 67225.23036550886 Test RE 0.45363044213774606\n",
      "77 Train Loss 230435.45 Test MSE 67200.76402283671 Test RE 0.45354788617031605\n",
      "78 Train Loss 230163.33 Test MSE 67234.59522265065 Test RE 0.45366203768843394\n",
      "79 Train Loss 230087.06 Test MSE 67233.69915539116 Test RE 0.45365901459405855\n",
      "80 Train Loss 230044.31 Test MSE 67219.6563050188 Test RE 0.453611635092179\n",
      "81 Train Loss 230031.55 Test MSE 67236.80692491878 Test RE 0.4536694993017822\n",
      "82 Train Loss 229998.1 Test MSE 67218.63316810103 Test RE 0.45360818291314575\n",
      "83 Train Loss 229952.5 Test MSE 67177.71550653943 Test RE 0.45347010057891607\n",
      "84 Train Loss 229891.12 Test MSE 67144.85574151286 Test RE 0.4533591802873469\n",
      "85 Train Loss 229830.94 Test MSE 67083.52052119456 Test RE 0.4531520665923934\n",
      "86 Train Loss 229638.98 Test MSE 66999.46692360443 Test RE 0.45286808477581625\n",
      "87 Train Loss 229365.81 Test MSE 66937.01244034142 Test RE 0.45265696192782007\n",
      "88 Train Loss 229172.56 Test MSE 66812.41989623284 Test RE 0.45223549143856845\n",
      "89 Train Loss 228957.98 Test MSE 66823.50776637209 Test RE 0.4522730153030533\n",
      "90 Train Loss 228794.98 Test MSE 66806.21583791873 Test RE 0.4522144941412044\n",
      "91 Train Loss 228681.31 Test MSE 66759.88822617452 Test RE 0.4520576700304527\n",
      "92 Train Loss 228652.89 Test MSE 66773.38999853113 Test RE 0.45210338064608896\n",
      "93 Train Loss 228310.72 Test MSE 66619.88076880752 Test RE 0.4515833982419159\n",
      "94 Train Loss 227852.12 Test MSE 66291.16035766048 Test RE 0.45046790352556\n",
      "95 Train Loss 227663.28 Test MSE 66207.0256317582 Test RE 0.4501819526808056\n",
      "96 Train Loss 227497.6 Test MSE 66157.21627574826 Test RE 0.45001257872136613\n",
      "97 Train Loss 227329.86 Test MSE 66142.08308059187 Test RE 0.44996110650070853\n",
      "98 Train Loss 226970.86 Test MSE 66007.17016095172 Test RE 0.44950196950849797\n",
      "99 Train Loss 226641.0 Test MSE 65790.2668755742 Test RE 0.44876281736821694\n",
      "100 Train Loss 226452.56 Test MSE 65662.3571023687 Test RE 0.44832636164325207\n",
      "101 Train Loss 226363.92 Test MSE 65608.4822156771 Test RE 0.4481424016894201\n",
      "102 Train Loss 226048.14 Test MSE 65380.19648214802 Test RE 0.4473620630720698\n",
      "103 Train Loss 225609.61 Test MSE 65286.341762104916 Test RE 0.44704084867838056\n",
      "104 Train Loss 225455.77 Test MSE 65286.702355450485 Test RE 0.44704208323777156\n",
      "105 Train Loss 225333.56 Test MSE 65143.35306464945 Test RE 0.44655103085939096\n",
      "106 Train Loss 225261.33 Test MSE 65065.404559423754 Test RE 0.4462837863709182\n",
      "107 Train Loss 225158.77 Test MSE 64979.09797203547 Test RE 0.4459876995930915\n",
      "108 Train Loss 224990.19 Test MSE 64981.00288518147 Test RE 0.44599423678452743\n",
      "109 Train Loss 224503.28 Test MSE 64968.81645490932 Test RE 0.4459524143112485\n",
      "110 Train Loss 224266.33 Test MSE 64911.63247278048 Test RE 0.44575611283795985\n",
      "111 Train Loss 224127.3 Test MSE 65016.959223164165 Test RE 0.4461176120869155\n",
      "112 Train Loss 224028.03 Test MSE 64952.01582362221 Test RE 0.4458947499814732\n",
      "113 Train Loss 223916.27 Test MSE 64934.967691751765 Test RE 0.4458362285385663\n",
      "114 Train Loss 223851.05 Test MSE 64967.681796690325 Test RE 0.4459485200908431\n",
      "115 Train Loss 223694.22 Test MSE 64920.415547349425 Test RE 0.44578626904110763\n",
      "116 Train Loss 223469.86 Test MSE 64901.371589050366 Test RE 0.4457208800742905\n",
      "117 Train Loss 223299.94 Test MSE 64926.42987182005 Test RE 0.445806917716501\n",
      "118 Train Loss 223187.86 Test MSE 64899.57125685339 Test RE 0.4457146979921821\n",
      "119 Train Loss 222980.45 Test MSE 64847.672552738826 Test RE 0.44553644842004697\n",
      "120 Train Loss 222786.62 Test MSE 64788.21568296934 Test RE 0.4453321521334582\n",
      "121 Train Loss 222546.3 Test MSE 64594.43476214115 Test RE 0.4446656613328989\n",
      "122 Train Loss 222047.95 Test MSE 64197.899323997735 Test RE 0.44329869267313265\n",
      "123 Train Loss 221792.31 Test MSE 64056.39521795783 Test RE 0.44280986678949535\n",
      "124 Train Loss 221453.16 Test MSE 64013.33241408094 Test RE 0.4426609992154626\n",
      "125 Train Loss 221360.03 Test MSE 64000.7192196084 Test RE 0.4426173860795582\n",
      "126 Train Loss 221314.19 Test MSE 64040.4519581467 Test RE 0.4427547569751551\n",
      "127 Train Loss 221270.48 Test MSE 64010.07303823278 Test RE 0.44264972955583376\n",
      "128 Train Loss 221145.25 Test MSE 63941.404830254185 Test RE 0.44241223474753877\n",
      "129 Train Loss 221077.77 Test MSE 63905.67872411125 Test RE 0.44228862255212953\n",
      "130 Train Loss 221016.42 Test MSE 63854.88014192786 Test RE 0.44211280013663623\n",
      "131 Train Loss 220789.47 Test MSE 63832.725847971284 Test RE 0.44203609850769776\n",
      "132 Train Loss 220645.6 Test MSE 63852.55794944736 Test RE 0.4421047609675699\n",
      "133 Train Loss 220500.39 Test MSE 63814.44720237831 Test RE 0.44197280495742103\n",
      "134 Train Loss 220356.28 Test MSE 63748.31306472968 Test RE 0.44174372621014624\n",
      "135 Train Loss 220277.03 Test MSE 63686.76997592839 Test RE 0.4415304434055643\n",
      "136 Train Loss 220135.72 Test MSE 63642.27115152588 Test RE 0.44137616474701263\n",
      "137 Train Loss 220070.45 Test MSE 63663.94541666237 Test RE 0.4414513167606317\n",
      "138 Train Loss 219941.61 Test MSE 63611.35279689101 Test RE 0.441268938194772\n",
      "139 Train Loss 219857.4 Test MSE 63565.110782453376 Test RE 0.44110851970479414\n",
      "140 Train Loss 219801.8 Test MSE 63560.82261539029 Test RE 0.4410936406390248\n",
      "141 Train Loss 219785.05 Test MSE 63542.04167133748 Test RE 0.44102846867706214\n",
      "142 Train Loss 219617.77 Test MSE 63479.34889763468 Test RE 0.44081084802339365\n",
      "143 Train Loss 219456.84 Test MSE 63369.627288205054 Test RE 0.4404297209756302\n",
      "144 Train Loss 219415.28 Test MSE 63337.4048282244 Test RE 0.44031773094040005\n",
      "145 Train Loss 219337.83 Test MSE 63281.27238333363 Test RE 0.440122573044426\n",
      "146 Train Loss 219237.58 Test MSE 63304.334015874476 Test RE 0.44020276280753473\n",
      "147 Train Loss 219192.0 Test MSE 63282.56603782575 Test RE 0.4401270717184604\n",
      "148 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "149 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "150 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "151 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "152 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "153 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "154 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "155 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "156 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "157 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "158 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "159 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "160 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "161 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "162 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "163 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "164 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "165 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "166 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "167 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "168 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "169 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "170 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "171 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "172 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "173 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "174 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "175 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "176 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "177 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "178 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "179 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "180 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "181 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "182 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "183 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "184 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "185 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "186 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "187 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "188 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "189 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "190 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "191 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "192 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "193 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "194 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "195 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "196 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "197 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "198 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "199 Train Loss 219191.88 Test MSE 63282.57460848497 Test RE 0.44012710152271173\n",
      "Training time: 496.87\n",
      "Training time: 496.87\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200 #200\n",
    "\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val = 5.0\n",
    "rowdy_terms = 6\n",
    "\n",
    "N_T = 5000 #Total number of data points for 'y'\n",
    "N_f = 10000 #Total number of collocation points \n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "\n",
    "    alpha_val = []    \n",
    "    omega_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.05, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-08, \n",
    "                              tolerance_change = 1e-08, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    alpha_full.append(alpha_val)\n",
    "    omega_full.append(omega_val)\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time,\"alpha\": alpha_full,\"omega\": omega_full,  \"label\": label}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = PINN.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1541 into shape (500,500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6605/3689713413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflipud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1541 into shape (500,500)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "img3 = ax.imshow(np.transpose(np.flipud(np.transpose(u_pred.reshape(500,500)))),vmin = 0,vmax = 1000,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "for tune_reps in range(75):\n",
    "    label = \"MW_rowdy_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr_tune[31]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
