{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "#     y = xt[:,0]*np.cos(xt[:,1])\n",
    "#     return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 25000\n",
    "level = \"_medium\"\n",
    "label = \"ES_tanh\" + level\n",
    "ES_val = 200.0\n",
    "\n",
    "x = np.linspace(0,1,500).reshape(-1,1)\n",
    "y = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xy = np.hstack((X,Y))\n",
    "\n",
    "# bound_pts_1 = (X == 0).reshape(-1,)\n",
    "# bound_pts_2 = np.logical_and(Y == 0,X != 0).reshape(-1,)\n",
    "# bound_pts_3 = np.logical_and(X == 1,Y != 0).reshape(-1,) \n",
    "# bound_pts_4 = np.logical_and(Y == 1,X != 1).reshape(-1,) \n",
    "\n",
    "# xy_bound_1 = xy[bound_pts_1,:]\n",
    "# xy_bound_2 = xy[bound_pts_2,:]\n",
    "# xy_bound_3 = xy[bound_pts_3,:]\n",
    "# xy_bound_4 = xy[bound_pts_4,:]\n",
    "\n",
    "# u_bound_1 = 1000*np.ones((np.shape(xy_bound_1)[0],1))\n",
    "# u_bound_2 = 800*np.ones((np.shape(xy_bound_2)[0],1))\n",
    "# u_bound_3 = 500*np.ones((np.shape(xy_bound_3)[0],1))\n",
    "# u_bound_4 = np.zeros((np.shape(xy_bound_4)[0],1))\n",
    "\n",
    "# xy_bound = np.vstack((xy_bound_1,xy_bound_2,xy_bound_3,xy_bound_4))\n",
    "# u_bound = np.vstack((u_bound_1,u_bound_2,u_bound_3,u_bound_4))\n",
    "\n",
    "# xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "\n",
    "lb_xy = xy[0]\n",
    "ub_xy = xy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_data = scipy.io.loadmat('./../ES_FEA' + level + '.mat')\n",
    "\n",
    "xy = np.array(fea_data['xy'])\n",
    "u_true = np.array(fea_data['u'])\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "u_true_norm = np.linalg.norm(u_true,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_T,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    N_t = int(N_T/4)\n",
    "    \n",
    "    x_BC1 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC1 = np.zeros((N_t,1))\n",
    "    u_BC1 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC2 = np.ones((N_t,1))\n",
    "    y_BC2 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC2 = ES_val*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC3 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC3 = np.ones((N_t,1)) \n",
    "    u_BC3 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC4 = np.zeros((N_t,1))\n",
    "    y_BC4 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC4 = ES_val*np.ones((N_t,1))\n",
    "    \n",
    "    XY_corners = np.array([[0,0],[1,0],[0,1],[1,1]]).reshape(-1,2)\n",
    "    U_corners = ES_val*np.ones((4,1))\n",
    "    \n",
    "    XY_1 = np.hstack((x_BC1,y_BC1))\n",
    "    XY_2 = np.hstack((x_BC2,y_BC2))\n",
    "    XY_3 = np.hstack((x_BC3,y_BC3))\n",
    "    XY_4 = np.hstack((x_BC4,y_BC4))\n",
    "    \n",
    "    xy_BC = np.vstack((XY_1,XY_2,XY_3,XY_4,XY_corners)) #choose indices from  set 'idx' (x,t)\n",
    "    u_BC = np.vstack((u_BC1,u_BC2,u_BC3,u_BC4,U_corners))\n",
    "    \n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xy_coll = lb_xy + (ub_xy - lb_xy)*samples\n",
    "    \n",
    "    xy_coll = np.vstack((xy_coll, xy_BC)) # append training points to collocation points \n",
    "\n",
    "    return xy_coll, xy_BC, u_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "        \n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xy):\n",
    "        if torch.is_tensor(xy) != True:         \n",
    "            xy = torch.from_numpy(xy)                \n",
    "        \n",
    "        ubxy = torch.from_numpy(ub_xy).float().to(device)\n",
    "        lbxy = torch.from_numpy(lb_xy).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xy = 2.0*(xy - lbxy)/(ubxy - lbxy) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xy.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a =self.activation(z)\n",
    "       \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xy,u):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xy), u)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xy_coll, f_hat):\n",
    "        \n",
    "        g = xy_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy = autograd.grad(u_x_y,g,torch.ones(xy_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2u_dx2 + d2u_dy2\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xy_BC,u_BC,xy_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xy_BC,u_BC)\n",
    "        loss_f = self.loss_PDE(xy_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        u_pred = self.forward(xy_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "        \n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xy_BC,u_BC,xy_coll,f_hat,seed):\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xy_BC,u_BC,xy_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xy_coll_np_array, xy_BC_np_array, u_BC_np_array = trainingdata(N_T,N_f,rep*22)\n",
    "        \n",
    "    xy_coll = torch.from_numpy(xy_coll_np_array).float().to(device)\n",
    "    xy_BC = torch.from_numpy(xy_BC_np_array).float().to(device)\n",
    "    u_BC = torch.from_numpy(u_BC_np_array).float().to(device)\n",
    "        \n",
    "    f_hat = torch.zeros(xy_coll.shape[0],1).to(device)\n",
    "    \n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(xy_BC,u_BC,xy_coll,f_hat,i)\n",
    "        loss_np = PINN.loss(xy_BC,u_BC,xy_coll,f_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES_tanh_medium\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 9999.993 Test MSE 3003.2232925017456 Test RE 0.4796111329933651\n",
      "1 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "2 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "3 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "4 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "5 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "6 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "7 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "8 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "9 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "10 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "11 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "12 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "13 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "14 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "15 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "16 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "17 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "18 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "19 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "20 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "21 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "22 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "23 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "24 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "25 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "26 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "27 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "28 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "29 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "30 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "31 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "32 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "33 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "34 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "35 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "36 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "37 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "38 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "39 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "40 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "41 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "42 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "43 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "44 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "45 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "46 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "47 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "48 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "49 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "50 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "51 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "52 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "53 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "54 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "55 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "56 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "57 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "58 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "59 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "60 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "61 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "62 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "63 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "64 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "65 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "66 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "67 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "68 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "69 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "70 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "71 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "72 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "73 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "74 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "75 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "76 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "77 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "78 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "79 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "80 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "81 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "82 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "83 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "84 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "85 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "86 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "87 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "88 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "89 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "90 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "91 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "92 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "93 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "94 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "95 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "96 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "97 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "98 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "99 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "100 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "101 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "102 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "103 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "104 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "105 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "106 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "107 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "108 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "109 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "110 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "111 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "112 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "113 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "114 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "115 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "116 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "117 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "118 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "119 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "120 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "121 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "122 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "123 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "124 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "125 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "126 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "127 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "128 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "129 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "130 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "131 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "132 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "133 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "134 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "135 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "136 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "137 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "138 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "139 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "140 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "141 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "142 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "143 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "144 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "145 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "146 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "147 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "148 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "149 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "150 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "151 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "152 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "153 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "154 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "155 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "156 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "157 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "158 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "159 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "160 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "161 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "162 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "163 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "164 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "165 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "166 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "167 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "168 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "169 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "170 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "171 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "172 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "173 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "174 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "175 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "176 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "177 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "178 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "179 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "180 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "181 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "182 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "183 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "184 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "185 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "186 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "187 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "188 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "189 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "190 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "191 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "192 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "193 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "194 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "195 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "196 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "197 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "198 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "199 Train Loss 9999.993 Test MSE 3003.2226348173244 Test RE 0.4796110804776583\n",
      "Training time: 27.08\n",
      "Training time: 27.08\n",
      "ES_tanh_medium\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 9999.993 Test MSE 3003.2232867394005 Test RE 0.47961113253324544\n",
      "1 Train Loss 9999.993 Test MSE 3003.2232472221594 Test RE 0.4796111293778176\n",
      "2 Train Loss 9999.993 Test MSE 3003.2216354851007 Test RE 0.47961100068156837\n",
      "3 Train Loss 9999.993 Test MSE 3003.2193264109574 Test RE 0.47961081630330604\n",
      "4 Train Loss 9999.993 Test MSE 3003.2077807683368 Test RE 0.4796098943892194\n",
      "5 Train Loss 9999.978 Test MSE 3003.1846930783045 Test RE 0.4796080508428069\n",
      "6 Train Loss 9993.518 Test MSE 2999.7583592317633 Test RE 0.4793343803158892\n",
      "7 Train Loss 9923.537 Test MSE 2964.815060979689 Test RE 0.476534390125157\n",
      "8 Train Loss 9887.68 Test MSE 2947.6716468684594 Test RE 0.4751546632314949\n",
      "9 Train Loss 9863.989 Test MSE 2940.068352077478 Test RE 0.4745414548901208\n",
      "10 Train Loss 9833.93 Test MSE 2922.69963549482 Test RE 0.47313768055810695\n",
      "11 Train Loss 9780.757 Test MSE 2899.379150689407 Test RE 0.4712462959409056\n",
      "12 Train Loss 9739.201 Test MSE 2889.779195787311 Test RE 0.4704654918613202\n",
      "13 Train Loss 9694.73 Test MSE 2869.8657017920327 Test RE 0.4688416986995702\n",
      "14 Train Loss 9645.586 Test MSE 2853.7050646763764 Test RE 0.46751977670452755\n",
      "15 Train Loss 9602.249 Test MSE 2850.6504497551737 Test RE 0.46726949238695464\n",
      "16 Train Loss 9553.9 Test MSE 2836.7839883429087 Test RE 0.4661316340013958\n",
      "17 Train Loss 9508.174 Test MSE 2822.63558706424 Test RE 0.46496777007445056\n",
      "18 Train Loss 9465.565 Test MSE 2809.729892329135 Test RE 0.4639035861228008\n",
      "19 Train Loss 9420.134 Test MSE 2796.664111169158 Test RE 0.4628237090692486\n",
      "20 Train Loss 9378.053 Test MSE 2777.57422288649 Test RE 0.4612413985958583\n",
      "21 Train Loss 9295.22 Test MSE 2759.6640581082274 Test RE 0.4597519209520596\n",
      "22 Train Loss 9248.187 Test MSE 2745.4047078760345 Test RE 0.45856259971975877\n",
      "23 Train Loss 9231.19 Test MSE 2741.3070507788043 Test RE 0.45822025785162146\n",
      "24 Train Loss 9213.835 Test MSE 2741.792824460533 Test RE 0.45826085554413987\n",
      "25 Train Loss 9194.908 Test MSE 2729.716812327168 Test RE 0.45725055481388216\n",
      "26 Train Loss 9178.944 Test MSE 2732.8036492961864 Test RE 0.4575090173597355\n",
      "27 Train Loss 9168.313 Test MSE 2725.5061644297753 Test RE 0.45689775922091636\n",
      "28 Train Loss 9159.498 Test MSE 2723.9051202690525 Test RE 0.4567635417755831\n",
      "29 Train Loss 9149.718 Test MSE 2722.9396526304295 Test RE 0.45668258640416337\n",
      "30 Train Loss 9132.424 Test MSE 2721.8439699394967 Test RE 0.4565906949897372\n",
      "31 Train Loss 9096.986 Test MSE 2719.5709348128785 Test RE 0.45640000377656664\n",
      "32 Train Loss 9088.263 Test MSE 2715.665142205233 Test RE 0.4560721498064959\n",
      "33 Train Loss 9065.833 Test MSE 2708.481154260444 Test RE 0.4554685064311652\n",
      "34 Train Loss 9036.625 Test MSE 2699.39306384956 Test RE 0.45470372039939816\n",
      "35 Train Loss 9024.507 Test MSE 2702.977934978806 Test RE 0.45500554999043646\n",
      "36 Train Loss 9014.696 Test MSE 2698.046643114199 Test RE 0.4545903062236499\n",
      "37 Train Loss 8986.067 Test MSE 2686.6443323949647 Test RE 0.4536287090707734\n",
      "38 Train Loss 8974.342 Test MSE 2680.187440503591 Test RE 0.45308327150150673\n",
      "39 Train Loss 8963.934 Test MSE 2677.2751800529754 Test RE 0.4528370470948232\n",
      "40 Train Loss 8956.06 Test MSE 2673.7498428884123 Test RE 0.45253880932848867\n",
      "41 Train Loss 8947.388 Test MSE 2675.3806789081837 Test RE 0.4526767998158531\n",
      "42 Train Loss 8938.431 Test MSE 2673.5299206697305 Test RE 0.45252019775458935\n",
      "43 Train Loss 8934.968 Test MSE 2674.200201805542 Test RE 0.45257691990702925\n",
      "44 Train Loss 8918.656 Test MSE 2672.7695886682313 Test RE 0.4524558464916917\n",
      "45 Train Loss 8904.211 Test MSE 2666.339063820988 Test RE 0.4519112277706988\n",
      "46 Train Loss 8899.761 Test MSE 2662.485808582378 Test RE 0.4515845703503845\n",
      "47 Train Loss 8895.963 Test MSE 2662.3174341059407 Test RE 0.451570291116012\n",
      "48 Train Loss 8889.116 Test MSE 2659.535641945953 Test RE 0.45133431192966084\n",
      "49 Train Loss 8856.222 Test MSE 2654.080601103411 Test RE 0.45087120272093856\n",
      "50 Train Loss 8828.311 Test MSE 2647.1244465684413 Test RE 0.4502799645570756\n",
      "51 Train Loss 8813.385 Test MSE 2650.872442398251 Test RE 0.45059862174750553\n",
      "52 Train Loss 8793.914 Test MSE 2651.02670060868 Test RE 0.45061173205879956\n",
      "53 Train Loss 8781.287 Test MSE 2644.5200146974043 Test RE 0.45005840110044076\n",
      "54 Train Loss 8776.6045 Test MSE 2644.6989669032437 Test RE 0.45007362835921244\n",
      "55 Train Loss 8769.071 Test MSE 2642.923404259746 Test RE 0.44992252078433403\n",
      "56 Train Loss 8764.692 Test MSE 2640.9342503340204 Test RE 0.44975317542878185\n",
      "57 Train Loss 8763.632 Test MSE 2640.0371701844247 Test RE 0.4496767822141132\n",
      "58 Train Loss 8759.856 Test MSE 2638.8990683121415 Test RE 0.449579845481285\n",
      "59 Train Loss 8753.835 Test MSE 2638.4577642163345 Test RE 0.4495422522051787\n",
      "60 Train Loss 8741.167 Test MSE 2637.218623647673 Test RE 0.4494366769959533\n",
      "61 Train Loss 8716.149 Test MSE 2636.1155131390124 Test RE 0.44934267072510387\n",
      "62 Train Loss 8695.804 Test MSE 2634.2851729761583 Test RE 0.44918664707098366\n",
      "63 Train Loss 8679.419 Test MSE 2630.44548804279 Test RE 0.44885916465513787\n",
      "64 Train Loss 8671.375 Test MSE 2633.256545414364 Test RE 0.44909893999893463\n",
      "65 Train Loss 8665.985 Test MSE 2631.7350445308675 Test RE 0.44896917612018006\n",
      "66 Train Loss 8661.158 Test MSE 2631.4558177053827 Test RE 0.4489453576959984\n",
      "67 Train Loss 8656.513 Test MSE 2632.552195985404 Test RE 0.44903887298078066\n",
      "68 Train Loss 8649.725 Test MSE 2630.5409005317633 Test RE 0.44886730517390977\n",
      "69 Train Loss 8638.8125 Test MSE 2639.6013597993874 Test RE 0.44963966495262336\n",
      "70 Train Loss 8626.87 Test MSE 2639.6219354237305 Test RE 0.44964141741398894\n",
      "71 Train Loss 8620.126 Test MSE 2638.7721744139603 Test RE 0.44956903612035665\n",
      "72 Train Loss 8616.095 Test MSE 2636.1263195805877 Test RE 0.4493435917375402\n",
      "73 Train Loss 8611.919 Test MSE 2633.1404160748616 Test RE 0.4490890370256783\n",
      "74 Train Loss 8606.908 Test MSE 2631.6900704744266 Test RE 0.44896533985798187\n",
      "75 Train Loss 8596.92 Test MSE 2632.738107322373 Test RE 0.4490547283061828\n",
      "76 Train Loss 8577.871 Test MSE 2627.391992555699 Test RE 0.44859856480130766\n",
      "77 Train Loss 8566.864 Test MSE 2635.2642412288815 Test RE 0.4492701125087465\n",
      "78 Train Loss 8555.375 Test MSE 2639.3982025452583 Test RE 0.4496223613326939\n",
      "79 Train Loss 8529.398 Test MSE 2647.0685256632596 Test RE 0.45027520841570484\n",
      "80 Train Loss 8500.198 Test MSE 2639.6700834016515 Test RE 0.44964551823350873\n",
      "81 Train Loss 8485.1875 Test MSE 2632.3212554431952 Test RE 0.4490191765896978\n",
      "82 Train Loss 8466.787 Test MSE 2629.0246017311065 Test RE 0.44873791827384435\n",
      "83 Train Loss 8455.78 Test MSE 2624.8433825370844 Test RE 0.4483809383128282\n",
      "84 Train Loss 8444.161 Test MSE 2623.3737672560583 Test RE 0.4482553994439408\n",
      "85 Train Loss 8438.716 Test MSE 2624.049183242174 Test RE 0.4483130998337588\n",
      "86 Train Loss 8418.654 Test MSE 2622.702838258277 Test RE 0.4481980750204843\n",
      "87 Train Loss 8403.99 Test MSE 2624.6801513943274 Test RE 0.4483669963627417\n",
      "88 Train Loss 8389.739 Test MSE 2624.995486009927 Test RE 0.448393929432669\n",
      "89 Train Loss 8382.005 Test MSE 2626.583979095856 Test RE 0.448529579748445\n",
      "90 Train Loss 8367.489 Test MSE 2622.5095008416924 Test RE 0.44818155483876704\n",
      "91 Train Loss 8334.957 Test MSE 2610.90731990401 Test RE 0.4471890613097005\n",
      "92 Train Loss 8329.289 Test MSE 2618.7609676917546 Test RE 0.44786113194084237\n",
      "93 Train Loss 8314.831 Test MSE 2623.4196109786863 Test RE 0.4482593160811121\n",
      "94 Train Loss 8304.221 Test MSE 2628.9606062354733 Test RE 0.44873245667028416\n",
      "95 Train Loss 8299.896 Test MSE 2627.185328098051 Test RE 0.44858092160179536\n",
      "96 Train Loss 8296.567 Test MSE 2625.00599712744 Test RE 0.44839482717070134\n",
      "97 Train Loss 8293.446 Test MSE 2623.5188712706936 Test RE 0.44826779622084206\n",
      "98 Train Loss 8289.3 Test MSE 2631.1249879470015 Test RE 0.4489171358365099\n",
      "99 Train Loss 8285.742 Test MSE 2633.1504572703475 Test RE 0.4490898933010377\n",
      "100 Train Loss 8282.028 Test MSE 2635.925559592848 Test RE 0.449326481037855\n",
      "101 Train Loss 8279.342 Test MSE 2633.8048179395723 Test RE 0.4491456911965721\n",
      "102 Train Loss 8277.234 Test MSE 2631.7368498278183 Test RE 0.44896933011032947\n",
      "103 Train Loss 8273.827 Test MSE 2634.1067348984498 Test RE 0.4491714335777722\n",
      "104 Train Loss 8268.026 Test MSE 2630.6923112984164 Test RE 0.4488802231188169\n",
      "105 Train Loss 8260.85 Test MSE 2633.6264311277055 Test RE 0.44913048068741246\n",
      "106 Train Loss 8254.126 Test MSE 2629.6549645616283 Test RE 0.4487917121315229\n",
      "107 Train Loss 8249.604 Test MSE 2635.8604397080103 Test RE 0.4493209307541395\n",
      "108 Train Loss 8245.825 Test MSE 2639.5599214271037 Test RE 0.44963613555435133\n",
      "109 Train Loss 8238.688 Test MSE 2637.1372834974713 Test RE 0.4494297459193307\n",
      "110 Train Loss 8232.398 Test MSE 2641.527226518933 Test RE 0.4498036647496429\n",
      "111 Train Loss 8227.08 Test MSE 2649.432533978933 Test RE 0.4504762264051609\n",
      "112 Train Loss 8216.427 Test MSE 2659.758085970682 Test RE 0.451353186375269\n",
      "113 Train Loss 8211.67 Test MSE 2655.0090438733046 Test RE 0.4509500570529206\n",
      "114 Train Loss 8209.405 Test MSE 2657.880880247094 Test RE 0.4511938800945558\n",
      "115 Train Loss 8199.818 Test MSE 2663.952023363315 Test RE 0.45170889567795725\n",
      "116 Train Loss 8192.029 Test MSE 2658.734271573122 Test RE 0.4512663088561177\n",
      "117 Train Loss 8183.677 Test MSE 2644.647887231814 Test RE 0.4500692819809762\n",
      "118 Train Loss 8167.0347 Test MSE 2650.8135200048373 Test RE 0.45059361386851887\n",
      "119 Train Loss 8155.589 Test MSE 2659.9422791631278 Test RE 0.451368814628356\n",
      "120 Train Loss 8137.78 Test MSE 2653.999542836717 Test RE 0.45086431764042745\n",
      "121 Train Loss 8131.7188 Test MSE 2663.962274726267 Test RE 0.45170976480535563\n",
      "122 Train Loss 8128.9067 Test MSE 2665.6959376060518 Test RE 0.4518567235463576\n",
      "123 Train Loss 8120.06 Test MSE 2671.3811173615495 Test RE 0.45233830856910495\n",
      "124 Train Loss 8115.2344 Test MSE 2673.9374761557046 Test RE 0.45255468774844704\n",
      "125 Train Loss 8108.7026 Test MSE 2675.675080656495 Test RE 0.4527017056500539\n",
      "126 Train Loss 8091.835 Test MSE 2660.0836452083336 Test RE 0.45138080875638326\n",
      "127 Train Loss 8076.587 Test MSE 2680.9242209334984 Test RE 0.4531455432560467\n",
      "128 Train Loss 8058.9727 Test MSE 2673.616639912263 Test RE 0.45252753672062535\n",
      "129 Train Loss 8055.079 Test MSE 2678.6848600178196 Test RE 0.4529562487574581\n",
      "130 Train Loss 8047.237 Test MSE 2688.266678222484 Test RE 0.4537656515694976\n",
      "131 Train Loss 8042.924 Test MSE 2688.9307343319547 Test RE 0.45382169274456785\n",
      "132 Train Loss 8036.4204 Test MSE 2689.3970101014206 Test RE 0.45386103866070776\n",
      "133 Train Loss 8032.6885 Test MSE 2692.1478679077336 Test RE 0.45409309589878705\n",
      "134 Train Loss 8029.7607 Test MSE 2700.3789389012954 Test RE 0.45478674649458484\n",
      "135 Train Loss 8018.5576 Test MSE 2687.3609006569686 Test RE 0.4536891998213174\n",
      "136 Train Loss 8011.171 Test MSE 2693.7686145657885 Test RE 0.45422976356500766\n",
      "137 Train Loss 8006.7417 Test MSE 2701.0058715925325 Test RE 0.45483953614717626\n",
      "138 Train Loss 8004.373 Test MSE 2707.5717312063343 Test RE 0.45539203398915873\n",
      "139 Train Loss 8001.6816 Test MSE 2713.8409674054724 Test RE 0.4559189469930401\n",
      "140 Train Loss 7997.27 Test MSE 2715.741143467128 Test RE 0.4560785316346252\n",
      "141 Train Loss 7992.369 Test MSE 2716.435776281645 Test RE 0.4561368558344804\n",
      "142 Train Loss 7982.482 Test MSE 2720.919527476216 Test RE 0.456513150560818\n",
      "143 Train Loss 7977.6143 Test MSE 2705.5462790394063 Test RE 0.45522166964828037\n",
      "144 Train Loss 7974.239 Test MSE 2709.9853388049755 Test RE 0.4555949635771889\n",
      "145 Train Loss 7970.726 Test MSE 2695.299412870699 Test RE 0.4543588086862828\n",
      "146 Train Loss 7964.819 Test MSE 2694.4832577595303 Test RE 0.45429001199921487\n",
      "147 Train Loss 7958.751 Test MSE 2704.458961137741 Test RE 0.45513018712315023\n",
      "148 Train Loss 7957.0596 Test MSE 2713.059236824963 Test RE 0.4558532778073669\n",
      "149 Train Loss 7953.7856 Test MSE 2712.682442946862 Test RE 0.45582162190281805\n",
      "150 Train Loss 7946.5635 Test MSE 2706.72807651773 Test RE 0.4553210804567608\n",
      "151 Train Loss 7943.6357 Test MSE 2698.289914377632 Test RE 0.45461079998822324\n",
      "152 Train Loss 7941.348 Test MSE 2696.903776073595 Test RE 0.45449401594849725\n",
      "153 Train Loss 7938.949 Test MSE 2700.5167760742474 Test RE 0.45479835333216834\n",
      "154 Train Loss 7935.878 Test MSE 2701.045058304606 Test RE 0.45484283558489363\n",
      "155 Train Loss 7932.6143 Test MSE 2702.57003147903 Test RE 0.4549712164954238\n",
      "156 Train Loss 7929.461 Test MSE 2697.265524738346 Test RE 0.45452449665972466\n",
      "157 Train Loss 7927.2256 Test MSE 2698.5593258430576 Test RE 0.45463349478912785\n",
      "158 Train Loss 7923.438 Test MSE 2698.060809355677 Test RE 0.45459149964771745\n",
      "159 Train Loss 7918.3945 Test MSE 2700.720782442323 Test RE 0.45481553152726334\n",
      "160 Train Loss 7914.8394 Test MSE 2700.24195156819 Test RE 0.45477521092586143\n",
      "161 Train Loss 7913.0615 Test MSE 2701.5504207032172 Test RE 0.454885383878382\n",
      "162 Train Loss 7910.7534 Test MSE 2703.714938393347 Test RE 0.4550675774646467\n",
      "163 Train Loss 7908.7637 Test MSE 2700.22121748597 Test RE 0.4547734649036744\n",
      "164 Train Loss 7906.4844 Test MSE 2697.647455443004 Test RE 0.45455667567859426\n",
      "165 Train Loss 7903.4595 Test MSE 2695.177449983021 Test RE 0.45434852865227554\n",
      "166 Train Loss 7902.2437 Test MSE 2693.0751592573183 Test RE 0.45417129374812865\n",
      "167 Train Loss 7901.482 Test MSE 2692.751379813903 Test RE 0.4541439911776196\n",
      "168 Train Loss 7898.0537 Test MSE 2686.3306574454323 Test RE 0.45360222694319524\n",
      "169 Train Loss 7893.8364 Test MSE 2693.9797746431527 Test RE 0.45424756637700736\n",
      "170 Train Loss 7890.8105 Test MSE 2698.580922083249 Test RE 0.45463531397361173\n",
      "171 Train Loss 7886.464 Test MSE 2707.3510987877844 Test RE 0.45537347930201716\n",
      "172 Train Loss 7883.453 Test MSE 2708.236988779203 Test RE 0.455447976069832\n",
      "173 Train Loss 7882.5566 Test MSE 2712.323791500683 Test RE 0.45579148817149034\n",
      "174 Train Loss 7880.5347 Test MSE 2715.2411831837726 Test RE 0.4560365483167497\n",
      "175 Train Loss 7876.342 Test MSE 2708.732842447958 Test RE 0.4554896683616499\n",
      "176 Train Loss 7872.6104 Test MSE 2705.059485973652 Test RE 0.4551807151241386\n",
      "177 Train Loss 7868.8564 Test MSE 2705.8963477931206 Test RE 0.45525111910351457\n",
      "178 Train Loss 7866.5747 Test MSE 2710.705518313954 Test RE 0.4556554968126485\n",
      "179 Train Loss 7859.8003 Test MSE 2718.8677404645073 Test RE 0.45634099471600054\n",
      "180 Train Loss 7854.423 Test MSE 2729.734418764993 Test RE 0.45725202942481\n",
      "181 Train Loss 7852.9 Test MSE 2730.988844530028 Test RE 0.45735708045854584\n",
      "182 Train Loss 7851.8496 Test MSE 2733.2429629318553 Test RE 0.4575457894624259\n",
      "183 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "184 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "185 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "186 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "187 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "188 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "189 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "190 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "191 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "192 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "193 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "194 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "195 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "196 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "197 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "198 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "199 Train Loss 7851.0938 Test MSE 2731.001924634351 Test RE 0.45735817571588727\n",
      "Training time: 116.85\n",
      "Training time: 116.85\n",
      "ES_tanh_medium\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 9999.993 Test MSE 3003.2236041091674 Test RE 0.47961115787502895\n",
      "1 Train Loss 9999.993 Test MSE 3003.2228818835483 Test RE 0.4796111002057488\n",
      "2 Train Loss 9999.993 Test MSE 3003.2197472620524 Test RE 0.4796108499080328\n",
      "3 Train Loss 9999.993 Test MSE 3003.2158783808864 Test RE 0.47961054097992595\n",
      "4 Train Loss 9999.97 Test MSE 3003.2327952126293 Test RE 0.479611891778491\n",
      "5 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "6 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "7 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "8 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "9 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "10 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "11 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "12 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "13 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "14 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "15 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "16 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "17 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "18 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "19 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "20 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "21 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "22 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "23 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "24 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "25 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "26 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "27 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "28 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "29 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "30 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "31 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "32 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "33 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "34 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "35 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "36 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "37 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "38 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "39 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "40 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "41 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "42 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "43 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "44 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "45 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "46 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "47 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "48 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "49 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "50 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "51 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "52 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "53 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "54 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "55 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "56 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "57 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "58 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "59 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "60 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "61 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "62 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "63 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "64 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "65 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "66 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "67 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "68 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "69 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "70 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "71 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "72 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "73 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "74 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "75 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "76 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "77 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "78 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "79 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "80 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "81 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "82 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "83 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "84 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "85 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "86 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "87 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "88 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "89 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "90 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "91 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "92 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "93 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "94 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "95 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "96 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "97 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "98 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "99 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "100 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "101 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "102 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "103 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "104 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "105 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "106 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "107 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "108 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "109 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "110 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "111 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "112 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "113 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "114 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "115 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "116 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "117 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "118 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "119 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "120 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "121 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "122 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "123 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "124 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "125 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "126 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "127 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "128 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "129 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "130 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "131 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "132 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "133 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "134 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "135 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "136 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "137 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "138 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "139 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "140 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "141 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "142 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "143 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "144 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "145 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "146 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "147 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "148 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "149 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "150 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "151 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "152 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "153 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "154 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "155 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "156 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "157 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "158 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "159 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "160 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "161 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "162 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "163 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "164 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "165 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "166 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "167 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "168 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "169 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "170 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "171 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "172 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "173 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "174 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "175 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "176 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "177 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "178 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "179 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "180 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "181 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "182 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "183 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "184 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "185 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "186 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "187 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "188 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "189 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "190 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "191 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "192 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "193 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "194 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "195 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "196 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "197 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "198 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "199 Train Loss 9991.761 Test MSE 3000.613683280314 Test RE 0.4794027119867955\n",
      "Training time: 39.32\n",
      "Training time: 39.32\n",
      "ES_tanh_medium\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 9999.993 Test MSE 3003.2242444360672 Test RE 0.4796112090047399\n",
      "1 Train Loss 9999.993 Test MSE 3003.224619410666 Test RE 0.47961123894622953\n",
      "2 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "3 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "4 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "5 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "6 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "7 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "8 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "9 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "10 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "11 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "12 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "13 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "14 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "15 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "16 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "17 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "18 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "19 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "20 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "21 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "22 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "23 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "24 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "25 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "26 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "27 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "28 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "29 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "30 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "31 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "32 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "33 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "34 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "35 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "36 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "37 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "38 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "39 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "40 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "41 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "42 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "43 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "44 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "45 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "46 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "47 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "48 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "49 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "50 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "51 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "52 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "53 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "54 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "55 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "56 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "57 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "58 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "59 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "60 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "61 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "62 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "63 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "64 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "65 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "66 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "67 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "68 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "69 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "70 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "71 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "72 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "73 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "74 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "75 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "76 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "77 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "78 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "79 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "80 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "81 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "82 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "83 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "84 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "85 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "86 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "87 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "88 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "89 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "90 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "91 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "92 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "93 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "94 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "95 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "96 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "97 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "98 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "99 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "100 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "101 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "102 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "103 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "104 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "105 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "106 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "107 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "108 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "109 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "110 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "111 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "112 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "113 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "114 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "115 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "116 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "117 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "118 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "119 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "120 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "121 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "122 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "123 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "124 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "125 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "126 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "127 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "128 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "129 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "130 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "131 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "132 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "133 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "134 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "135 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "136 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "137 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "138 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "139 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "140 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "141 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "142 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "143 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "144 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "145 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "146 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "147 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "148 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "149 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "150 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "151 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "152 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "153 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "154 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "155 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "156 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "157 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "158 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "159 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "160 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "161 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "162 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "163 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "164 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "165 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "166 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "167 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "168 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "169 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "170 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "171 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "172 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "173 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "174 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "175 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "176 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "177 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "178 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "179 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "180 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "181 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "182 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "183 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "184 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "185 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "186 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "187 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "188 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "189 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "190 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "191 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "192 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "193 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "194 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "195 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "196 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "197 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "198 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "199 Train Loss 9999.993 Test MSE 3003.2270567066435 Test RE 0.47961143356275915\n",
      "Training time: 19.70\n",
      "Training time: 19.70\n",
      "ES_tanh_medium\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 9999.993 Test MSE 3003.22325784653 Test RE 0.4796111302261671\n",
      "1 Train Loss 9999.993 Test MSE 3003.2232550785798 Test RE 0.479611130005148\n",
      "2 Train Loss 9999.993 Test MSE 3003.223270005108 Test RE 0.4796111311970224\n",
      "3 Train Loss 9999.993 Test MSE 3003.2232532877033 Test RE 0.47961112986214754\n",
      "4 Train Loss 9999.993 Test MSE 3003.2232215020017 Test RE 0.4796111273240785\n",
      "5 Train Loss 9999.993 Test MSE 3003.2232541541853 Test RE 0.47961112993133576\n",
      "6 Train Loss 9999.993 Test MSE 3003.223182372071 Test RE 0.4796111241995771\n",
      "7 Train Loss 9999.993 Test MSE 3003.223280065834 Test RE 0.47961113200036515\n",
      "8 Train Loss 9999.993 Test MSE 3003.2231930529865 Test RE 0.4796111250524417\n",
      "9 Train Loss 9999.993 Test MSE 3003.2232181222366 Test RE 0.4796111270542062\n",
      "10 Train Loss 9999.993 Test MSE 3003.223307156073 Test RE 0.47961113416350426\n",
      "11 Train Loss 9999.993 Test MSE 3003.2232073410846 Test RE 0.47961112619333773\n",
      "12 Train Loss 9999.993 Test MSE 3003.223226336628 Test RE 0.47961112771012054\n",
      "13 Train Loss 9999.993 Test MSE 3003.2232813168057 Test RE 0.47961113210025447\n",
      "14 Train Loss 9999.993 Test MSE 3003.2232293592456 Test RE 0.47961112795147454\n",
      "15 Train Loss 9999.993 Test MSE 3003.2232461810286 Test RE 0.4796111292946838\n",
      "16 Train Loss 9999.993 Test MSE 3003.223270152714 Test RE 0.4796111312088085\n",
      "17 Train Loss 9999.993 Test MSE 3003.223188560638 Test RE 0.47961112469373035\n",
      "18 Train Loss 9999.993 Test MSE 3003.223271263425 Test RE 0.47961113129749816\n",
      "19 Train Loss 9999.993 Test MSE 3003.2231668177537 Test RE 0.47961112295757413\n",
      "20 Train Loss 9999.993 Test MSE 3003.22323486722 Test RE 0.47961112839128317\n",
      "21 Train Loss 9999.993 Test MSE 3003.2232574662726 Test RE 0.47961113019580387\n",
      "22 Train Loss 9999.993 Test MSE 3003.2232598858077 Test RE 0.47961113038900216\n",
      "23 Train Loss 9999.993 Test MSE 3003.2232643353864 Test RE 0.4796111307442984\n",
      "24 Train Loss 9999.993 Test MSE 3003.2232144165546 Test RE 0.47961112675830975\n",
      "25 Train Loss 9999.993 Test MSE 3003.223247536502 Test RE 0.4796111294029176\n",
      "26 Train Loss 9999.993 Test MSE 3003.223230775338 Test RE 0.4796111280645487\n",
      "27 Train Loss 9999.993 Test MSE 3003.2232666431933 Test RE 0.4796111309285753\n",
      "28 Train Loss 9999.993 Test MSE 3003.223257805004 Test RE 0.47961113022285135\n",
      "29 Train Loss 9999.993 Test MSE 3003.223215665822 Test RE 0.479611126858063\n",
      "30 Train Loss 9999.993 Test MSE 3003.2231607114886 Test RE 0.4796111224699925\n",
      "31 Train Loss 9999.993 Test MSE 3003.2232304818017 Test RE 0.47961112804111\n",
      "32 Train Loss 9999.993 Test MSE 3003.223236325819 Test RE 0.47961112850775134\n",
      "33 Train Loss 9999.993 Test MSE 3003.2233275976346 Test RE 0.4796111357957507\n",
      "34 Train Loss 9999.993 Test MSE 3003.22318133981 Test RE 0.4796111241171515\n",
      "35 Train Loss 9999.993 Test MSE 3003.2232756210356 Test RE 0.4796111316454507\n",
      "36 Train Loss 9999.993 Test MSE 3003.2232252813774 Test RE 0.47961112762585933\n",
      "37 Train Loss 9999.993 Test MSE 3003.223224702264 Test RE 0.4796111275796173\n",
      "38 Train Loss 9999.993 Test MSE 3003.2231603385158 Test RE 0.47961112244021087\n",
      "39 Train Loss 9999.993 Test MSE 3003.223216141064 Test RE 0.47961112689601093\n",
      "40 Train Loss 9999.993 Test MSE 3003.223190391205 Test RE 0.4796111248399001\n",
      "41 Train Loss 9999.993 Test MSE 3003.223275808783 Test RE 0.4796111316604422\n",
      "42 Train Loss 9999.993 Test MSE 3003.223219973333 Test RE 0.47961112720201526\n",
      "43 Train Loss 9999.993 Test MSE 3003.223242350821 Test RE 0.4796111289888441\n",
      "44 Train Loss 9999.993 Test MSE 3003.223218437433 Test RE 0.4796111270793745\n",
      "45 Train Loss 9999.993 Test MSE 3003.2232685202443 Test RE 0.4796111310784568\n",
      "46 Train Loss 9999.993 Test MSE 3003.223231727695 Test RE 0.4796111281405938\n",
      "47 Train Loss 9999.993 Test MSE 3003.2232332379954 Test RE 0.4796111282611906\n",
      "48 Train Loss 9999.993 Test MSE 3003.2232075815323 Test RE 0.4796111262125373\n",
      "49 Train Loss 9999.993 Test MSE 3003.2232979324144 Test RE 0.4796111334270008\n",
      "50 Train Loss 9999.993 Test MSE 3003.223168194943 Test RE 0.47961112306754194\n",
      "51 Train Loss 9999.993 Test MSE 3003.223212180534 Test RE 0.4796111265797649\n",
      "52 Train Loss 9999.993 Test MSE 3003.2231940350975 Test RE 0.4796111251308627\n",
      "53 Train Loss 9999.993 Test MSE 3003.22322549596 Test RE 0.47961112764299363\n",
      "54 Train Loss 9999.993 Test MSE 3003.223232375418 Test RE 0.47961112819231416\n",
      "55 Train Loss 9999.993 Test MSE 3003.2231862132803 Test RE 0.47961112450629534\n",
      "56 Train Loss 9999.993 Test MSE 3003.22326040411 Test RE 0.4796111304303883\n",
      "57 Train Loss 9999.993 Test MSE 3003.2232340915753 Test RE 0.4796111283293483\n",
      "58 Train Loss 9999.993 Test MSE 3003.22320954044 Test RE 0.479611126368955\n",
      "59 Train Loss 9999.993 Test MSE 3003.2232073538457 Test RE 0.47961112619435675\n",
      "60 Train Loss 9999.993 Test MSE 3003.2232365324708 Test RE 0.4796111285242524\n",
      "61 Train Loss 9999.993 Test MSE 3003.223237865336 Test RE 0.4796111286306807\n",
      "62 Train Loss 9999.993 Test MSE 3003.2232163110393 Test RE 0.47961112690958324\n",
      "63 Train Loss 9999.993 Test MSE 3003.2232126082927 Test RE 0.4796111266139211\n",
      "64 Train Loss 9999.993 Test MSE 3003.223254263113 Test RE 0.47961112994003346\n",
      "65 Train Loss 9999.993 Test MSE 3003.223273775256 Test RE 0.47961113149806617\n",
      "66 Train Loss 9999.993 Test MSE 3003.2232406168987 Test RE 0.47961112885039137\n",
      "67 Train Loss 9999.993 Test MSE 3003.2231708601767 Test RE 0.47961112328035926\n",
      "68 Train Loss 9999.993 Test MSE 3003.2232153533623 Test RE 0.47961112683311324\n",
      "69 Train Loss 9999.993 Test MSE 3003.223181003016 Test RE 0.4796111240902588\n",
      "70 Train Loss 9999.993 Test MSE 3003.223201222079 Test RE 0.47961112570473885\n",
      "71 Train Loss 9999.993 Test MSE 3003.2232233172053 Test RE 0.47961112746902146\n",
      "72 Train Loss 9999.993 Test MSE 3003.2231780872908 Test RE 0.4796111238574399\n",
      "73 Train Loss 9999.993 Test MSE 3003.223208758894 Test RE 0.4796111263065489\n",
      "74 Train Loss 9999.993 Test MSE 3003.22320666524 Test RE 0.4796111261393719\n",
      "75 Train Loss 9999.993 Test MSE 3003.2232755468335 Test RE 0.47961113163952573\n",
      "76 Train Loss 9999.993 Test MSE 3003.2232252302724 Test RE 0.4796111276217787\n",
      "77 Train Loss 9999.993 Test MSE 3003.223142804827 Test RE 0.4796111210401564\n",
      "78 Train Loss 9999.993 Test MSE 3003.223154018815 Test RE 0.4796111219355866\n",
      "79 Train Loss 9999.993 Test MSE 3003.22322198951 Test RE 0.47961112736300554\n",
      "80 Train Loss 9999.993 Test MSE 3003.2232271660264 Test RE 0.4796111277763473\n",
      "81 Train Loss 9999.993 Test MSE 3003.223253474053 Test RE 0.47961112987702753\n",
      "82 Train Loss 9999.993 Test MSE 3003.223186569004 Test RE 0.4796111245346997\n",
      "83 Train Loss 9999.993 Test MSE 3003.223189233122 Test RE 0.47961112474742784\n",
      "84 Train Loss 9999.993 Test MSE 3003.2232389437604 Test RE 0.47961112871679246\n",
      "85 Train Loss 9999.993 Test MSE 3003.223228694965 Test RE 0.4796111278984321\n",
      "86 Train Loss 9999.993 Test MSE 3003.223191686202 Test RE 0.4796111249433048\n",
      "87 Train Loss 9999.993 Test MSE 3003.223257907396 Test RE 0.4796111302310272\n",
      "88 Train Loss 9999.993 Test MSE 3003.2231378460206 Test RE 0.4796111206441988\n",
      "89 Train Loss 9999.993 Test MSE 3003.223250979532 Test RE 0.47961112967784153\n",
      "90 Train Loss 9999.993 Test MSE 3003.223124468418 Test RE 0.47961111957600533\n",
      "91 Train Loss 9999.993 Test MSE 3003.223177911116 Test RE 0.47961112384337246\n",
      "92 Train Loss 9999.993 Test MSE 3003.223196289319 Test RE 0.47961112531086086\n",
      "93 Train Loss 9999.993 Test MSE 3003.223179489982 Test RE 0.479611123969444\n",
      "94 Train Loss 9999.993 Test MSE 3003.2231974941574 Test RE 0.47961112540706635\n",
      "95 Train Loss 9999.993 Test MSE 3003.223165708596 Test RE 0.47961112286900875\n",
      "96 Train Loss 9999.993 Test MSE 3003.223230530157 Test RE 0.4796111280449712\n",
      "97 Train Loss 9999.993 Test MSE 3003.223206823421 Test RE 0.4796111261520026\n",
      "98 Train Loss 9999.993 Test MSE 3003.2232120957547 Test RE 0.47961112657299526\n",
      "99 Train Loss 9999.993 Test MSE 3003.2231624603314 Test RE 0.4796111226096367\n",
      "100 Train Loss 9999.993 Test MSE 3003.2231941342566 Test RE 0.47961112513878046\n",
      "101 Train Loss 9999.993 Test MSE 3003.223225843481 Test RE 0.4796111276707428\n",
      "102 Train Loss 9999.993 Test MSE 3003.223215687021 Test RE 0.4796111268597558\n",
      "103 Train Loss 9999.993 Test MSE 3003.2232294145506 Test RE 0.4796111279558908\n",
      "104 Train Loss 9999.993 Test MSE 3003.2231849252944 Test RE 0.4796111244034503\n",
      "105 Train Loss 9999.993 Test MSE 3003.2231726361492 Test RE 0.47961112342216955\n",
      "106 Train Loss 9999.993 Test MSE 3003.2231924357775 Test RE 0.47961112500315795\n",
      "107 Train Loss 9999.993 Test MSE 3003.223161448 Test RE 0.47961112252880256\n",
      "108 Train Loss 9999.993 Test MSE 3003.2231989957645 Test RE 0.47961112552696905\n",
      "109 Train Loss 9999.993 Test MSE 3003.2231382221867 Test RE 0.4796111206742354\n",
      "110 Train Loss 9999.993 Test MSE 3003.2231922819487 Test RE 0.4796111249908748\n",
      "111 Train Loss 9999.993 Test MSE 3003.2231905765393 Test RE 0.479611124854699\n",
      "112 Train Loss 9999.993 Test MSE 3003.223162189619 Test RE 0.4796111225880204\n",
      "113 Train Loss 9999.993 Test MSE 3003.223168058258 Test RE 0.4796111230566279\n",
      "114 Train Loss 9999.993 Test MSE 3003.223202827739 Test RE 0.47961112583294985\n",
      "115 Train Loss 9999.993 Test MSE 3003.2232076711507 Test RE 0.47961112621969343\n",
      "116 Train Loss 9999.993 Test MSE 3003.2231866810635 Test RE 0.4796111245436475\n",
      "117 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "118 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "119 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "120 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "121 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "122 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "123 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "124 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "125 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "126 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "127 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "128 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "129 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "130 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "131 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "132 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "133 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "134 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "135 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "136 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "137 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "138 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "139 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "140 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "141 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "142 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "143 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "144 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "145 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "146 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "147 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "148 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "149 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "150 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "151 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "152 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "153 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "154 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "155 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "156 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "157 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "158 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "159 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "160 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "161 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "162 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "163 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "164 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "165 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "166 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "167 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "168 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "169 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "170 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "171 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "172 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "173 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "174 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "175 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "176 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "177 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "178 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "179 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "180 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "181 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "182 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "183 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "184 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "185 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "186 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "187 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "188 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "189 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "190 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "191 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "192 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "193 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "194 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "195 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "196 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "197 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "198 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "199 Train Loss 9999.992 Test MSE 3003.2231087089895 Test RE 0.47961111831762443\n",
      "Training time: 16.01\n",
      "Training time: 16.01\n",
      "ES_tanh_medium\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 9999.993 Test MSE 3003.22336982204 Test RE 0.47961113916734394\n",
      "1 Train Loss 9999.993 Test MSE 3003.223320746635 Test RE 0.47961113524870247\n",
      "2 Train Loss 9999.993 Test MSE 3003.223252167374 Test RE 0.47961112977269\n",
      "3 Train Loss 9999.993 Test MSE 3003.223482364497 Test RE 0.4796111481537911\n",
      "4 Train Loss 9999.993 Test MSE 3003.2233398435415 Test RE 0.4796111367735789\n",
      "5 Train Loss 9999.993 Test MSE 3003.2233861694663 Test RE 0.47961114047267595\n",
      "6 Train Loss 9999.993 Test MSE 3003.223313125091 Test RE 0.47961113464012683\n",
      "7 Train Loss 9999.993 Test MSE 3003.2234304040644 Test RE 0.4796111440047819\n",
      "8 Train Loss 9999.993 Test MSE 3003.2233655469777 Test RE 0.4796111388259829\n",
      "9 Train Loss 9999.993 Test MSE 3003.223373402357 Test RE 0.4796111394532301\n",
      "10 Train Loss 9999.993 Test MSE 3003.223358340139 Test RE 0.479611138250521\n",
      "11 Train Loss 9999.993 Test MSE 3003.2233719135843 Test RE 0.47961113933435245\n",
      "12 Train Loss 9999.993 Test MSE 3003.223445976983 Test RE 0.47961114524827\n",
      "13 Train Loss 9999.993 Test MSE 3003.223316796186 Test RE 0.47961113493326163\n",
      "14 Train Loss 9999.993 Test MSE 3003.2233342135823 Test RE 0.47961113632403\n",
      "15 Train Loss 9999.993 Test MSE 3003.2232968274066 Test RE 0.4796111333387666\n",
      "16 Train Loss 9999.993 Test MSE 3003.223408498642 Test RE 0.47961114225564727\n",
      "17 Train Loss 9999.993 Test MSE 3003.2232888366284 Test RE 0.47961113270070777\n",
      "18 Train Loss 9999.993 Test MSE 3003.2232806719476 Test RE 0.4796111320487629\n",
      "19 Train Loss 9999.993 Test MSE 3003.223438416046 Test RE 0.47961114464453386\n",
      "20 Train Loss 9999.993 Test MSE 3003.2233651060983 Test RE 0.4796111387907788\n",
      "21 Train Loss 9999.993 Test MSE 3003.2233081821473 Test RE 0.4796111342454358\n",
      "22 Train Loss 9999.993 Test MSE 3003.223245796404 Test RE 0.47961112926397187\n",
      "23 Train Loss 9999.993 Test MSE 3003.2233756448045 Test RE 0.47961113963228813\n",
      "24 Train Loss 9999.993 Test MSE 3003.223327796566 Test RE 0.47961113581163534\n",
      "25 Train Loss 9999.993 Test MSE 3003.223356331155 Test RE 0.479611138090105\n",
      "26 Train Loss 9999.993 Test MSE 3003.2232766946836 Test RE 0.47961113173118086\n",
      "27 Train Loss 9999.993 Test MSE 3003.2234724304344 Test RE 0.4796111473605621\n",
      "28 Train Loss 9999.993 Test MSE 3003.223319486713 Test RE 0.4796111351480984\n",
      "29 Train Loss 9999.993 Test MSE 3003.223227109266 Test RE 0.4796111277718152\n",
      "30 Train Loss 9999.993 Test MSE 3003.223443969408 Test RE 0.4796111450879663\n",
      "31 Train Loss 9999.993 Test MSE 3003.223371795343 Test RE 0.47961113932491095\n",
      "32 Train Loss 9999.993 Test MSE 3003.223402731326 Test RE 0.4796111417951305\n",
      "33 Train Loss 9999.993 Test MSE 3003.2232460122627 Test RE 0.47961112928120797\n",
      "34 Train Loss 9999.993 Test MSE 3003.223562826492 Test RE 0.4796111545786323\n",
      "35 Train Loss 9999.993 Test MSE 3003.2233709204233 Test RE 0.4796111392550491\n",
      "36 Train Loss 9999.993 Test MSE 3003.2232913029693 Test RE 0.4796111328976436\n",
      "37 Train Loss 9999.993 Test MSE 3003.2233788001554 Test RE 0.47961113988424103\n",
      "38 Train Loss 9999.993 Test MSE 3003.2233151716773 Test RE 0.47961113480354556\n",
      "39 Train Loss 9999.993 Test MSE 3003.223387078814 Test RE 0.4796111405452868\n",
      "40 Train Loss 9999.993 Test MSE 3003.2232459196453 Test RE 0.4796111292738124\n",
      "41 Train Loss 9999.993 Test MSE 3003.2234436659232 Test RE 0.4796111450637333\n",
      "42 Train Loss 9999.993 Test MSE 3003.2234310736912 Test RE 0.47961114405825117\n",
      "43 Train Loss 9999.993 Test MSE 3003.223256881013 Test RE 0.47961113014907103\n",
      "44 Train Loss 9999.993 Test MSE 3003.223376266086 Test RE 0.47961113968189706\n",
      "45 Train Loss 9999.993 Test MSE 3003.223318705618 Test RE 0.4796111350857286\n",
      "46 Train Loss 9999.993 Test MSE 3003.2234446189773 Test RE 0.4796111451398341\n",
      "47 Train Loss 9999.993 Test MSE 3003.2233745821045 Test RE 0.47961113954743223\n",
      "48 Train Loss 9999.993 Test MSE 3003.2233499799836 Test RE 0.47961113758296775\n",
      "49 Train Loss 9999.993 Test MSE 3003.2233459490953 Test RE 0.47961113726110377\n",
      "50 Train Loss 9999.993 Test MSE 3003.2233813395987 Test RE 0.47961114008701405\n",
      "51 Train Loss 9999.993 Test MSE 3003.223304028817 Test RE 0.4796111339137949\n",
      "52 Train Loss 9999.993 Test MSE 3003.2233725033875 Test RE 0.479611139381448\n",
      "53 Train Loss 9999.993 Test MSE 3003.223226683831 Test RE 0.47961112773784437\n",
      "54 Train Loss 9999.993 Test MSE 3003.223459581309 Test RE 0.4796111463345672\n",
      "55 Train Loss 9999.993 Test MSE 3003.2233448922066 Test RE 0.47961113717671183\n",
      "56 Train Loss 9999.993 Test MSE 3003.2233274635687 Test RE 0.47961113578504566\n",
      "57 Train Loss 9999.993 Test MSE 3003.2234574754725 Test RE 0.4796111461664174\n",
      "58 Train Loss 9999.993 Test MSE 3003.2233616189524 Test RE 0.47961113851233234\n",
      "59 Train Loss 9999.993 Test MSE 3003.2233339671943 Test RE 0.4796111363043563\n",
      "60 Train Loss 9999.993 Test MSE 3003.2234372058906 Test RE 0.4796111445479036\n",
      "61 Train Loss 9999.993 Test MSE 3003.22337176406 Test RE 0.4796111393224131\n",
      "62 Train Loss 9999.993 Test MSE 3003.2232256361053 Test RE 0.4796111276541842\n",
      "63 Train Loss 9999.993 Test MSE 3003.2234466637874 Test RE 0.4796111453031109\n",
      "64 Train Loss 9999.993 Test MSE 3003.2233496963213 Test RE 0.4796111375603174\n",
      "65 Train Loss 9999.993 Test MSE 3003.223298427042 Test RE 0.4796111334664965\n",
      "66 Train Loss 9999.993 Test MSE 3003.223409679318 Test RE 0.47961114234992336\n",
      "67 Train Loss 9999.993 Test MSE 3003.2233364345866 Test RE 0.47961113650137593\n",
      "68 Train Loss 9999.993 Test MSE 3003.223229826999 Test RE 0.4796111279888244\n",
      "69 Train Loss 9999.993 Test MSE 3003.2233801629322 Test RE 0.4796111399930578\n",
      "70 Train Loss 9999.993 Test MSE 3003.2233778717355 Test RE 0.4796111398101073\n",
      "71 Train Loss 9999.993 Test MSE 3003.223214978808 Test RE 0.4796111268032053\n",
      "72 Train Loss 9999.993 Test MSE 3003.2232849604693 Test RE 0.4796111323911988\n",
      "73 Train Loss 9999.993 Test MSE 3003.223353966719 Test RE 0.4796111379013061\n",
      "74 Train Loss 9999.993 Test MSE 3003.2232215717713 Test RE 0.4796111273296494\n",
      "75 Train Loss 9999.993 Test MSE 3003.2233317545088 Test RE 0.47961113612767453\n",
      "76 Train Loss 9999.993 Test MSE 3003.223342793588 Test RE 0.47961113700913843\n",
      "77 Train Loss 9999.993 Test MSE 3003.22329843423 Test RE 0.4796111334670704\n",
      "78 Train Loss 9999.993 Test MSE 3003.2233520625987 Test RE 0.4796111377492632\n",
      "79 Train Loss 9999.993 Test MSE 3003.2232438785577 Test RE 0.47961112911083303\n",
      "80 Train Loss 9999.993 Test MSE 3003.223332266052 Test RE 0.4796111361685211\n",
      "81 Train Loss 9999.993 Test MSE 3003.2233413477124 Test RE 0.479611136893686\n",
      "82 Train Loss 9999.993 Test MSE 3003.223226647164 Test RE 0.4796111277349166\n",
      "83 Train Loss 9999.993 Test MSE 3003.2233998342745 Test RE 0.4796111415638027\n",
      "84 Train Loss 9999.993 Test MSE 3003.2233485885085 Test RE 0.4796111374718593\n",
      "85 Train Loss 9999.993 Test MSE 3003.2233879394826 Test RE 0.4796111406140108\n",
      "86 Train Loss 9999.993 Test MSE 3003.2233297284292 Test RE 0.47961113596589344\n",
      "87 Train Loss 9999.993 Test MSE 3003.223342434727 Test RE 0.4796111369804836\n",
      "88 Train Loss 9999.993 Test MSE 3003.2233916344358 Test RE 0.47961114090905055\n",
      "89 Train Loss 9999.993 Test MSE 3003.2233411192774 Test RE 0.47961113687544565\n",
      "90 Train Loss 9999.993 Test MSE 3003.2232638575406 Test RE 0.4796111307061427\n",
      "91 Train Loss 9999.993 Test MSE 3003.223329579107 Test RE 0.47961113595397015\n",
      "92 Train Loss 9999.993 Test MSE 3003.2232454758814 Test RE 0.4796111292383782\n",
      "93 Train Loss 9999.993 Test MSE 3003.223374853485 Test RE 0.4796111395691018\n",
      "94 Train Loss 9999.993 Test MSE 3003.22338369894 Test RE 0.479611140275406\n",
      "95 Train Loss 9999.993 Test MSE 3003.2232855301577 Test RE 0.47961113243668807\n",
      "96 Train Loss 9999.993 Test MSE 3003.2233319398315 Test RE 0.47961113614247247\n",
      "97 Train Loss 9999.993 Test MSE 3003.223237296835 Test RE 0.4796111285852863\n",
      "98 Train Loss 9999.993 Test MSE 3003.223339460043 Test RE 0.47961113674295686\n",
      "99 Train Loss 9999.993 Test MSE 3003.2233200782885 Test RE 0.4796111351953354\n",
      "100 Train Loss 9999.993 Test MSE 3003.223437229522 Test RE 0.47961114454979054\n",
      "101 Train Loss 9999.993 Test MSE 3003.223295008426 Test RE 0.47961113319352205\n",
      "102 Train Loss 9999.993 Test MSE 3003.223197788896 Test RE 0.47961112543060125\n",
      "103 Train Loss 9999.993 Test MSE 3003.2233874756894 Test RE 0.4796111405769772\n",
      "104 Train Loss 9999.993 Test MSE 3003.223291375575 Test RE 0.4796111329034411\n",
      "105 Train Loss 9999.993 Test MSE 3003.2231898734735 Test RE 0.47961112479855955\n",
      "106 Train Loss 9999.993 Test MSE 3003.2233372622254 Test RE 0.4796111365674624\n",
      "107 Train Loss 9999.993 Test MSE 3003.22334467194 Test RE 0.4796111371591236\n",
      "108 Train Loss 9999.993 Test MSE 3003.223321102732 Test RE 0.4796111352771366\n",
      "109 Train Loss 9999.993 Test MSE 3003.2232790220496 Test RE 0.4796111319170196\n",
      "110 Train Loss 9999.993 Test MSE 3003.2233506022203 Test RE 0.47961113763265284\n",
      "111 Train Loss 9999.993 Test MSE 3003.223295880821 Test RE 0.47961113326318217\n",
      "112 Train Loss 9999.993 Test MSE 3003.22343988877 Test RE 0.4796111447621299\n",
      "113 Train Loss 9999.993 Test MSE 3003.223338872112 Test RE 0.47961113669601096\n",
      "114 Train Loss 9999.993 Test MSE 3003.223319706143 Test RE 0.4796111351656199\n",
      "115 Train Loss 9999.993 Test MSE 3003.2233348716077 Test RE 0.479611136376573\n",
      "116 Train Loss 9999.993 Test MSE 3003.2232469407586 Test RE 0.4796111293553479\n",
      "117 Train Loss 9999.993 Test MSE 3003.2233734251595 Test RE 0.4796111394550508\n",
      "118 Train Loss 9999.993 Test MSE 3003.2233108226987 Test RE 0.4796111344562822\n",
      "119 Train Loss 9999.993 Test MSE 3003.2232920251276 Test RE 0.47961113295530755\n",
      "120 Train Loss 9999.993 Test MSE 3003.2233438525045 Test RE 0.4796111370936922\n",
      "121 Train Loss 9999.993 Test MSE 3003.223366901297 Test RE 0.47961113893412444\n",
      "122 Train Loss 9999.993 Test MSE 3003.2232609520242 Test RE 0.4796111304741389\n",
      "123 Train Loss 9999.993 Test MSE 3003.2233306052694 Test RE 0.4796111360359085\n",
      "124 Train Loss 9999.993 Test MSE 3003.22330608458 Test RE 0.4796111340779464\n",
      "125 Train Loss 9999.993 Test MSE 3003.223408902252 Test RE 0.47961114228787516\n",
      "126 Train Loss 9999.993 Test MSE 3003.2232897139857 Test RE 0.4796111327707643\n",
      "127 Train Loss 9999.993 Test MSE 3003.223352132167 Test RE 0.4796111377548183\n",
      "128 Train Loss 9999.993 Test MSE 3003.2233548070485 Test RE 0.4796111379684059\n",
      "129 Train Loss 9999.993 Test MSE 3003.2233631394456 Test RE 0.4796111386337427\n",
      "130 Train Loss 9999.993 Test MSE 3003.223281005597 Test RE 0.4796111320754047\n",
      "131 Train Loss 9999.993 Test MSE 3003.223400971792 Test RE 0.47961114165463287\n",
      "132 Train Loss 9999.993 Test MSE 3003.223255054967 Test RE 0.4796111300032625\n",
      "133 Train Loss 9999.993 Test MSE 3003.223197530913 Test RE 0.4796111254100014\n",
      "134 Train Loss 9999.993 Test MSE 3003.223271790626 Test RE 0.4796111313395946\n",
      "135 Train Loss 9999.993 Test MSE 3003.223219765783 Test RE 0.4796111271854424\n",
      "136 Train Loss 9999.993 Test MSE 3003.2232677345564 Test RE 0.47961113101572017\n",
      "137 Train Loss 9999.993 Test MSE 3003.2231164347177 Test RE 0.47961111893451913\n",
      "138 Train Loss 9999.993 Test MSE 3003.223293993083 Test RE 0.4796111331124475\n",
      "139 Train Loss 9999.993 Test MSE 3003.223198369042 Test RE 0.4796111254769256\n",
      "140 Train Loss 9999.993 Test MSE 3003.2232626316427 Test RE 0.47961113060825533\n",
      "141 Train Loss 9999.993 Test MSE 3003.22329798924 Test RE 0.4796111334315383\n",
      "142 Train Loss 9999.993 Test MSE 3003.223317057107 Test RE 0.4796111349540959\n",
      "143 Train Loss 9999.993 Test MSE 3003.2233771407814 Test RE 0.4796111397517411\n",
      "144 Train Loss 9999.993 Test MSE 3003.2232822033716 Test RE 0.4796111321710462\n",
      "145 Train Loss 9999.993 Test MSE 3003.223369525456 Test RE 0.4796111391436618\n",
      "146 Train Loss 9999.993 Test MSE 3003.2232800267634 Test RE 0.4796111319972453\n",
      "147 Train Loss 9999.993 Test MSE 3003.223289186067 Test RE 0.4796111327286102\n",
      "148 Train Loss 9999.993 Test MSE 3003.2232917670735 Test RE 0.479611132934702\n",
      "149 Train Loss 9999.993 Test MSE 3003.2233302699074 Test RE 0.47961113600912997\n",
      "150 Train Loss 9999.993 Test MSE 3003.2232837228516 Test RE 0.47961113229237573\n",
      "151 Train Loss 9999.993 Test MSE 3003.223344621376 Test RE 0.4796111371550862\n",
      "152 Train Loss 9999.993 Test MSE 3003.2232722935696 Test RE 0.4796111313797546\n",
      "153 Train Loss 9999.993 Test MSE 3003.223382025528 Test RE 0.47961114014178496\n",
      "154 Train Loss 9999.993 Test MSE 3003.2231631522923 Test RE 0.47961112266488926\n",
      "155 Train Loss 9999.993 Test MSE 3003.223390797045 Test RE 0.4796111408421854\n",
      "156 Train Loss 9999.993 Test MSE 3003.2232678440955 Test RE 0.4796111310244667\n",
      "157 Train Loss 9999.993 Test MSE 3003.2233202624693 Test RE 0.4796111352100423\n",
      "158 Train Loss 9999.993 Test MSE 3003.22336727948 Test RE 0.47961113896432206\n",
      "159 Train Loss 9999.993 Test MSE 3003.223322204521 Test RE 0.47961113536511385\n",
      "160 Train Loss 9999.993 Test MSE 3003.2233000448414 Test RE 0.4796111335956767\n",
      "161 Train Loss 9999.993 Test MSE 3003.2231658025053 Test RE 0.47961112287650726\n",
      "162 Train Loss 9999.993 Test MSE 3003.2232880069946 Test RE 0.479611132634462\n",
      "163 Train Loss 9999.993 Test MSE 3003.2232373613056 Test RE 0.4796111285904343\n",
      "164 Train Loss 9999.993 Test MSE 3003.22326691539 Test RE 0.47961113095031\n",
      "165 Train Loss 9999.993 Test MSE 3003.2233617960715 Test RE 0.47961113852647536\n",
      "166 Train Loss 9999.993 Test MSE 3003.2232808831336 Test RE 0.479611132065626\n",
      "167 Train Loss 9999.993 Test MSE 3003.2232730357837 Test RE 0.47961113143901984\n",
      "168 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "169 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "170 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "171 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "172 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "173 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "174 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "175 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "176 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "177 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "178 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "179 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "180 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "181 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "182 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "183 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "184 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "185 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "186 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "187 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "188 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "189 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "190 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "191 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "192 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "193 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "194 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "195 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "196 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "197 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "198 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "199 Train Loss 9999.992 Test MSE 3003.2231692575115 Test RE 0.47961112315238746\n",
      "Training time: 16.29\n",
      "Training time: 16.29\n",
      "ES_tanh_medium\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 9999.993 Test MSE 3003.2274159754515 Test RE 0.4796114622501377\n",
      "1 Train Loss 9999.993 Test MSE 3003.223347159777 Test RE 0.47961113735777594\n",
      "2 Train Loss 9999.993 Test MSE 3003.223214082713 Test RE 0.4796111267316527\n",
      "3 Train Loss 9968.8 Test MSE 2988.0594337036177 Test RE 0.4783987757310004\n",
      "4 Train Loss 9882.299 Test MSE 2950.2416212927233 Test RE 0.4753617536790984\n",
      "5 Train Loss 9797.665 Test MSE 2910.262811907099 Test RE 0.47212994733519387\n",
      "6 Train Loss 9735.457 Test MSE 2887.1202727925565 Test RE 0.47024900137679243\n",
      "7 Train Loss 9683.641 Test MSE 2870.8037412134154 Test RE 0.4689183148394735\n",
      "8 Train Loss 9614.009 Test MSE 2843.6144806753696 Test RE 0.46669247936214403\n",
      "9 Train Loss 9486.955 Test MSE 2787.507671670049 Test RE 0.4620654321495324\n",
      "10 Train Loss 9372.558 Test MSE 2734.1743437102855 Test RE 0.45762373954988994\n",
      "11 Train Loss 9286.133 Test MSE 2704.7191580600306 Test RE 0.4551520807121043\n",
      "12 Train Loss 9176.961 Test MSE 2653.3527748023507 Test RE 0.4508093774658653\n",
      "13 Train Loss 9071.64 Test MSE 2617.1829830481256 Test RE 0.4477261779509388\n",
      "14 Train Loss 8970.552 Test MSE 2551.0443649014574 Test RE 0.44203275236321377\n",
      "15 Train Loss 8896.826 Test MSE 2536.4626696963737 Test RE 0.4407676187439135\n",
      "16 Train Loss 8811.046 Test MSE 2507.177705992735 Test RE 0.43821577011094215\n",
      "17 Train Loss 8742.127 Test MSE 2464.0488080537093 Test RE 0.43443028870828077\n",
      "18 Train Loss 8658.109 Test MSE 2428.728023333279 Test RE 0.43130539021081943\n",
      "19 Train Loss 8576.501 Test MSE 2414.8465164721247 Test RE 0.43007105104307325\n",
      "20 Train Loss 8512.0625 Test MSE 2383.349767374085 Test RE 0.4272571455251991\n",
      "21 Train Loss 8378.18 Test MSE 2325.73203021451 Test RE 0.4220610556483236\n",
      "22 Train Loss 8316.605 Test MSE 2326.5334935582237 Test RE 0.42213377196372365\n",
      "23 Train Loss 8259.796 Test MSE 2300.1387963049115 Test RE 0.4197323718425132\n",
      "24 Train Loss 8131.2026 Test MSE 2263.732790271428 Test RE 0.4163974149155519\n",
      "25 Train Loss 8018.2344 Test MSE 2222.9221673205625 Test RE 0.4126269333146884\n",
      "26 Train Loss 7941.662 Test MSE 2185.4996630612864 Test RE 0.4091389400923477\n",
      "27 Train Loss 7897.137 Test MSE 2155.8041996599586 Test RE 0.4063498470609382\n",
      "28 Train Loss 7837.7583 Test MSE 2155.841592770123 Test RE 0.40635337117938786\n",
      "29 Train Loss 7778.976 Test MSE 2137.2144949265085 Test RE 0.40459405708253904\n",
      "30 Train Loss 7726.868 Test MSE 2125.297886108478 Test RE 0.4034645193929756\n",
      "31 Train Loss 7686.0913 Test MSE 2100.261822619792 Test RE 0.40108106813736655\n",
      "32 Train Loss 7623.814 Test MSE 2095.583307926511 Test RE 0.4006340977139575\n",
      "33 Train Loss 7598.1875 Test MSE 2073.885440987566 Test RE 0.39855459928676706\n",
      "34 Train Loss 7475.8335 Test MSE 2050.548464790547 Test RE 0.39630583159517097\n",
      "35 Train Loss 7438.799 Test MSE 2053.9701657440955 Test RE 0.39663634678141824\n",
      "36 Train Loss 7415.247 Test MSE 2032.2793248112541 Test RE 0.3945364597788055\n",
      "37 Train Loss 7354.9062 Test MSE 2021.6087278896293 Test RE 0.39349932866985254\n",
      "38 Train Loss 7330.291 Test MSE 2022.3600930633863 Test RE 0.39357244722651596\n",
      "39 Train Loss 7303.268 Test MSE 2004.5302580761647 Test RE 0.3918336700458547\n",
      "40 Train Loss 7246.9985 Test MSE 1976.0090056606887 Test RE 0.3890361006442329\n",
      "41 Train Loss 7164.485 Test MSE 1942.3982925656721 Test RE 0.38571327633786595\n",
      "42 Train Loss 7122.7744 Test MSE 1913.1497349849246 Test RE 0.3827982333420727\n",
      "43 Train Loss 7078.1484 Test MSE 1896.9329316399821 Test RE 0.38117238706687856\n",
      "44 Train Loss 6970.4185 Test MSE 1847.6816064719635 Test RE 0.3761915286330637\n",
      "45 Train Loss 6919.092 Test MSE 1835.8126850992724 Test RE 0.37498131438443427\n",
      "46 Train Loss 6832.735 Test MSE 1813.5543467836494 Test RE 0.3727011485577121\n",
      "47 Train Loss 6772.621 Test MSE 1786.5618617079954 Test RE 0.36991715575685685\n",
      "48 Train Loss 6675.1846 Test MSE 1748.8199597456155 Test RE 0.365988967861559\n",
      "49 Train Loss 6580.916 Test MSE 1722.0840285438064 Test RE 0.3631805761546282\n",
      "50 Train Loss 6516.8994 Test MSE 1705.420861105263 Test RE 0.3614192075708797\n",
      "51 Train Loss 6410.6143 Test MSE 1667.9582661394086 Test RE 0.3574275578688645\n",
      "52 Train Loss 6348.873 Test MSE 1651.330769296807 Test RE 0.3556415385730131\n",
      "53 Train Loss 6307.864 Test MSE 1634.2676741771927 Test RE 0.35379935680465247\n",
      "54 Train Loss 6288.7803 Test MSE 1626.750055665137 Test RE 0.35298468171370145\n",
      "55 Train Loss 6260.7007 Test MSE 1608.6853779266926 Test RE 0.351019304176508\n",
      "56 Train Loss 6202.931 Test MSE 1601.017325299543 Test RE 0.3501817104098534\n",
      "57 Train Loss 6169.891 Test MSE 1590.8957049541416 Test RE 0.34907303220427355\n",
      "58 Train Loss 6133.863 Test MSE 1568.4950290423274 Test RE 0.34660675080294057\n",
      "59 Train Loss 6071.809 Test MSE 1546.7500934584511 Test RE 0.3441957624957147\n",
      "60 Train Loss 6041.2983 Test MSE 1531.6567045058698 Test RE 0.34251229199707356\n",
      "61 Train Loss 6015.298 Test MSE 1517.4761783142649 Test RE 0.34092306552444995\n",
      "62 Train Loss 5974.2725 Test MSE 1500.6890305502704 Test RE 0.33903208291717557\n",
      "63 Train Loss 5910.2163 Test MSE 1501.5201546565543 Test RE 0.3391259527089367\n",
      "64 Train Loss 5877.514 Test MSE 1480.94330270557 Test RE 0.3367942434493028\n",
      "65 Train Loss 5839.628 Test MSE 1457.7444965749698 Test RE 0.3341459095488532\n",
      "66 Train Loss 5801.0103 Test MSE 1438.3220323192186 Test RE 0.3319124250050993\n",
      "67 Train Loss 5747.829 Test MSE 1446.5949429767418 Test RE 0.33286559983823527\n",
      "68 Train Loss 5715.7188 Test MSE 1441.198353936093 Test RE 0.33224413447217815\n",
      "69 Train Loss 5685.086 Test MSE 1428.4594064934238 Test RE 0.3307724998080602\n",
      "70 Train Loss 5639.04 Test MSE 1405.5235076426213 Test RE 0.32810624806302635\n",
      "71 Train Loss 5617.9927 Test MSE 1389.3244489545552 Test RE 0.3262100095837138\n",
      "72 Train Loss 5602.5273 Test MSE 1383.5990301905617 Test RE 0.32553715844476777\n",
      "73 Train Loss 5583.828 Test MSE 1363.0110073718693 Test RE 0.32310607628812416\n",
      "74 Train Loss 5551.107 Test MSE 1340.4916614286496 Test RE 0.32042581839273304\n",
      "75 Train Loss 5492.0166 Test MSE 1327.8523996547829 Test RE 0.31891162112247284\n",
      "76 Train Loss 5450.0815 Test MSE 1318.5897499563978 Test RE 0.31779736469365905\n",
      "77 Train Loss 5368.738 Test MSE 1294.391308289626 Test RE 0.31486779138335275\n",
      "78 Train Loss 5333.7915 Test MSE 1276.0021789071434 Test RE 0.31262316229364645\n",
      "79 Train Loss 5311.0137 Test MSE 1264.470983865081 Test RE 0.31120737315360186\n",
      "80 Train Loss 5272.659 Test MSE 1254.518843785802 Test RE 0.3099802601262278\n",
      "81 Train Loss 5215.7793 Test MSE 1248.2607389919845 Test RE 0.30920613294813576\n",
      "82 Train Loss 5181.9165 Test MSE 1213.4220660831395 Test RE 0.30486066173604703\n",
      "83 Train Loss 5144.572 Test MSE 1198.1127894470226 Test RE 0.30293140274501984\n",
      "84 Train Loss 5131.152 Test MSE 1194.088609297375 Test RE 0.3024222370398623\n",
      "85 Train Loss 5083.88 Test MSE 1190.5661970251292 Test RE 0.30197585368749513\n",
      "86 Train Loss 4987.215 Test MSE 1158.7038452307997 Test RE 0.2979076584169827\n",
      "87 Train Loss 4947.19 Test MSE 1148.0458500199136 Test RE 0.2965343853909164\n",
      "88 Train Loss 4928.5557 Test MSE 1137.938308324397 Test RE 0.29522613630300754\n",
      "89 Train Loss 4896.0063 Test MSE 1120.3972680212678 Test RE 0.29294188001278726\n",
      "90 Train Loss 4862.112 Test MSE 1109.6538328973672 Test RE 0.29153399409779734\n",
      "91 Train Loss 4794.8667 Test MSE 1095.9119183557057 Test RE 0.2897231969898538\n",
      "92 Train Loss 4762.484 Test MSE 1097.6809485338204 Test RE 0.28995693950363627\n",
      "93 Train Loss 4700.3237 Test MSE 1075.726396718901 Test RE 0.2870426009869487\n",
      "94 Train Loss 4641.832 Test MSE 1036.6832738926428 Test RE 0.28178540137860314\n",
      "95 Train Loss 4508.6045 Test MSE 977.9298586584626 Test RE 0.2736839296889422\n",
      "96 Train Loss 4445.6177 Test MSE 957.4616623265161 Test RE 0.27080466444337326\n",
      "97 Train Loss 4399.2173 Test MSE 946.7344260447599 Test RE 0.2692833668397583\n",
      "98 Train Loss 4348.7754 Test MSE 945.2337410523706 Test RE 0.269069859353672\n",
      "99 Train Loss 4264.349 Test MSE 930.1403675058285 Test RE 0.2669129776569259\n",
      "100 Train Loss 4205.7515 Test MSE 906.7303446741137 Test RE 0.2635327044243599\n",
      "101 Train Loss 4192.2783 Test MSE 909.1380522914689 Test RE 0.2638823613244864\n",
      "102 Train Loss 4135.5195 Test MSE 890.1230288996051 Test RE 0.26110817082327703\n",
      "103 Train Loss 4062.7427 Test MSE 869.3636973731462 Test RE 0.2580454432347798\n",
      "104 Train Loss 4014.1265 Test MSE 867.4737054480499 Test RE 0.2577647959289598\n",
      "105 Train Loss 3963.059 Test MSE 863.4987234308069 Test RE 0.257173546376108\n",
      "106 Train Loss 3919.2222 Test MSE 847.623764611444 Test RE 0.25479858157929774\n",
      "107 Train Loss 3864.0981 Test MSE 823.5354358524729 Test RE 0.2511519701938701\n",
      "108 Train Loss 3824.002 Test MSE 800.0760011827148 Test RE 0.2475489369299174\n",
      "109 Train Loss 3804.696 Test MSE 799.0936281930874 Test RE 0.2473969138199095\n",
      "110 Train Loss 3785.262 Test MSE 792.7326196128543 Test RE 0.24641027212744102\n",
      "111 Train Loss 3756.4512 Test MSE 795.6376602924374 Test RE 0.2468613556566614\n",
      "112 Train Loss 3713.581 Test MSE 771.571379334824 Test RE 0.24309918261557809\n",
      "113 Train Loss 3654.518 Test MSE 754.6110861954637 Test RE 0.24041249437167056\n",
      "114 Train Loss 3618.0664 Test MSE 763.5484648523955 Test RE 0.24183198907957254\n",
      "115 Train Loss 3595.6602 Test MSE 756.1149193874934 Test RE 0.2406519291944655\n",
      "116 Train Loss 3567.084 Test MSE 744.185098383297 Test RE 0.23874590350899783\n",
      "117 Train Loss 3526.544 Test MSE 736.4753806190932 Test RE 0.2375059863923761\n",
      "118 Train Loss 3515.4597 Test MSE 722.561637543668 Test RE 0.23525176686683444\n",
      "119 Train Loss 3481.492 Test MSE 719.6776087473254 Test RE 0.2347818061032684\n",
      "120 Train Loss 3451.675 Test MSE 692.913978674597 Test RE 0.23037487108689197\n",
      "121 Train Loss 3427.5115 Test MSE 685.0891389016239 Test RE 0.229070405730374\n",
      "122 Train Loss 3376.3506 Test MSE 653.9100408509212 Test RE 0.22379709601878778\n",
      "123 Train Loss 3329.871 Test MSE 639.381663504143 Test RE 0.22129700302882538\n",
      "124 Train Loss 3303.9136 Test MSE 631.1103840119092 Test RE 0.21986095333869618\n",
      "125 Train Loss 3276.3708 Test MSE 637.2559956731262 Test RE 0.22092883830732157\n",
      "126 Train Loss 3225.662 Test MSE 638.0048973417704 Test RE 0.22105861770135615\n",
      "127 Train Loss 3174.3218 Test MSE 631.1861990565923 Test RE 0.21987415884747138\n",
      "128 Train Loss 3122.6558 Test MSE 589.776303143381 Test RE 0.21253923019573515\n",
      "129 Train Loss 3098.1934 Test MSE 581.3839071966183 Test RE 0.21102161717333523\n",
      "130 Train Loss 3069.4048 Test MSE 572.2418681619126 Test RE 0.20935592612755738\n",
      "131 Train Loss 3030.1252 Test MSE 559.8770687844258 Test RE 0.2070817297224608\n",
      "132 Train Loss 2960.9424 Test MSE 554.3330564041635 Test RE 0.20605389702091084\n",
      "133 Train Loss 2924.931 Test MSE 551.9945908786576 Test RE 0.20561881636208695\n",
      "134 Train Loss 2908.7573 Test MSE 552.7456378014175 Test RE 0.20575865186788525\n",
      "135 Train Loss 2886.5488 Test MSE 545.6293621925211 Test RE 0.2044298501993602\n",
      "136 Train Loss 2878.478 Test MSE 538.9848188362349 Test RE 0.20318128857097156\n",
      "137 Train Loss 2867.1636 Test MSE 538.203368211147 Test RE 0.2030339432916407\n",
      "138 Train Loss 2840.0957 Test MSE 545.9279162877168 Test RE 0.204485771880362\n",
      "139 Train Loss 2807.4714 Test MSE 520.8523539141066 Test RE 0.1997343494745727\n",
      "140 Train Loss 2790.567 Test MSE 509.30758560408816 Test RE 0.19750837511629074\n",
      "141 Train Loss 2762.797 Test MSE 503.19456006176114 Test RE 0.19631948789472162\n",
      "142 Train Loss 2735.0344 Test MSE 487.00136184122044 Test RE 0.19313479886989143\n",
      "143 Train Loss 2661.2673 Test MSE 468.2512503951017 Test RE 0.18938035080784602\n",
      "144 Train Loss 2582.555 Test MSE 453.64890788334424 Test RE 0.186404064863788\n",
      "145 Train Loss 2534.0854 Test MSE 446.6271330482024 Test RE 0.18495581731773653\n",
      "146 Train Loss 2522.1753 Test MSE 444.16628660533223 Test RE 0.18444557453000063\n",
      "147 Train Loss 2477.5342 Test MSE 446.8071838991624 Test RE 0.18499309460595825\n",
      "148 Train Loss 2430.1008 Test MSE 427.4390783814339 Test RE 0.18093915433805902\n",
      "149 Train Loss 2398.71 Test MSE 419.063780501776 Test RE 0.17915771184219087\n",
      "150 Train Loss 2375.4685 Test MSE 414.70736504989685 Test RE 0.17822405391881901\n",
      "151 Train Loss 2355.3757 Test MSE 419.5155921315737 Test RE 0.17925426484382795\n",
      "152 Train Loss 2331.9946 Test MSE 416.97132437332317 Test RE 0.17870986977034203\n",
      "153 Train Loss 2274.2295 Test MSE 415.56683035265564 Test RE 0.1784086396314333\n",
      "154 Train Loss 2233.4375 Test MSE 399.1349745705426 Test RE 0.17484585304697098\n",
      "155 Train Loss 2223.6863 Test MSE 399.68440228444746 Test RE 0.17496615335469567\n",
      "156 Train Loss 2202.8557 Test MSE 388.8399369214572 Test RE 0.17257618963119492\n",
      "157 Train Loss 2179.5315 Test MSE 380.2425383392653 Test RE 0.17065766299137602\n",
      "158 Train Loss 2140.7703 Test MSE 375.2662203535954 Test RE 0.1695372679620857\n",
      "159 Train Loss 2078.563 Test MSE 360.0455524137731 Test RE 0.16606349314973318\n",
      "160 Train Loss 2038.6785 Test MSE 362.2439515557747 Test RE 0.16656970445820393\n",
      "161 Train Loss 2003.6685 Test MSE 364.07429432277183 Test RE 0.16698999512021734\n",
      "162 Train Loss 1994.3175 Test MSE 369.8381562820714 Test RE 0.16830665995876254\n",
      "163 Train Loss 1986.6606 Test MSE 372.61335657007106 Test RE 0.16893695151358012\n",
      "164 Train Loss 1974.1008 Test MSE 373.6767370313615 Test RE 0.1691778396401717\n",
      "165 Train Loss 1965.3528 Test MSE 368.3650765437357 Test RE 0.16797113954648918\n",
      "166 Train Loss 1957.4406 Test MSE 363.1392895023286 Test RE 0.16677542789036462\n",
      "167 Train Loss 1942.3567 Test MSE 361.06070520326443 Test RE 0.16629743737733058\n",
      "168 Train Loss 1919.3739 Test MSE 340.99043375692776 Test RE 0.16160937157285027\n",
      "169 Train Loss 1892.988 Test MSE 332.3110466598442 Test RE 0.1595393553884851\n",
      "170 Train Loss 1885.0323 Test MSE 328.67056856874706 Test RE 0.15866306948680436\n",
      "171 Train Loss 1875.7505 Test MSE 329.2845472524933 Test RE 0.1588111969730047\n",
      "172 Train Loss 1866.1571 Test MSE 331.28595492732643 Test RE 0.15929309696269475\n",
      "173 Train Loss 1827.3271 Test MSE 332.1722407513557 Test RE 0.15950603221377374\n",
      "174 Train Loss 1794.0035 Test MSE 331.08453535276135 Test RE 0.15924466504813037\n",
      "175 Train Loss 1777.8708 Test MSE 325.54821307276734 Test RE 0.15790762505100914\n",
      "176 Train Loss 1768.7054 Test MSE 328.436957446691 Test RE 0.15860667251992128\n",
      "177 Train Loss 1757.5002 Test MSE 330.1774231387322 Test RE 0.1590263645165442\n",
      "178 Train Loss 1753.1023 Test MSE 332.14639207095 Test RE 0.1594998259446201\n",
      "179 Train Loss 1730.6234 Test MSE 329.04981224453854 Test RE 0.1587545815109431\n",
      "180 Train Loss 1710.1615 Test MSE 329.4229781685108 Test RE 0.1588445755047132\n",
      "181 Train Loss 1693.7295 Test MSE 324.708256465048 Test RE 0.15770378240570812\n",
      "182 Train Loss 1680.5171 Test MSE 322.8330742583133 Test RE 0.1572477553309114\n",
      "183 Train Loss 1673.8562 Test MSE 317.50565566198554 Test RE 0.1559449001602749\n",
      "184 Train Loss 1656.7753 Test MSE 316.2686013861364 Test RE 0.15564081018019926\n",
      "185 Train Loss 1633.6738 Test MSE 317.55845900047046 Test RE 0.1559578669671179\n",
      "186 Train Loss 1586.5277 Test MSE 310.26612258755085 Test RE 0.15415677741084322\n",
      "187 Train Loss 1563.1593 Test MSE 312.35864123675964 Test RE 0.15467574137389917\n",
      "188 Train Loss 1550.0676 Test MSE 312.76122135025594 Test RE 0.15477538537027427\n",
      "189 Train Loss 1536.2394 Test MSE 306.8809971225314 Test RE 0.15331351547720048\n",
      "190 Train Loss 1492.8981 Test MSE 304.2907638225632 Test RE 0.15266512196052284\n",
      "191 Train Loss 1412.5363 Test MSE 291.9598108532709 Test RE 0.1495398637556937\n",
      "192 Train Loss 1313.642 Test MSE 284.57556689170434 Test RE 0.14763667261445\n",
      "193 Train Loss 1275.9507 Test MSE 303.7052586089989 Test RE 0.15251817490310662\n",
      "194 Train Loss 1267.477 Test MSE 308.9626067150348 Test RE 0.1538326084254879\n",
      "195 Train Loss 1264.8483 Test MSE 307.6861158266224 Test RE 0.15351449684477392\n",
      "196 Train Loss 1261.7556 Test MSE 309.3309373110403 Test RE 0.15392427709016912\n",
      "197 Train Loss 1257.4263 Test MSE 315.0200484323349 Test RE 0.15533328999024656\n",
      "198 Train Loss 1257.4263 Test MSE 315.0200484323349 Test RE 0.15533328999024656\n",
      "199 Train Loss 1257.4263 Test MSE 315.0200484323349 Test RE 0.15533328999024656\n",
      "Training time: 126.39\n",
      "Training time: 126.39\n",
      "ES_tanh_medium\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 9999.995 Test MSE 3003.223950162487 Test RE 0.4796111855071753\n",
      "1 Train Loss 9999.995 Test MSE 3003.225502458235 Test RE 0.479611309457024\n",
      "2 Train Loss 9999.995 Test MSE 3003.2273144175438 Test RE 0.4796114541408055\n",
      "3 Train Loss 9987.431 Test MSE 2998.53481442128 Test RE 0.4792366146228341\n",
      "4 Train Loss 9878.863 Test MSE 2945.595836914517 Test RE 0.47498732700693036\n",
      "5 Train Loss 9719.27 Test MSE 2897.909597296981 Test RE 0.4711268549622612\n",
      "6 Train Loss 9496.915 Test MSE 2804.541231518283 Test RE 0.46347504837506986\n",
      "7 Train Loss 9303.985 Test MSE 2716.6018051839205 Test RE 0.4561507951929908\n",
      "8 Train Loss 9147.355 Test MSE 2660.507472539336 Test RE 0.4514167662542244\n",
      "9 Train Loss 8907.957 Test MSE 2546.111758700453 Test RE 0.44160519639472534\n",
      "10 Train Loss 8739.629 Test MSE 2488.690126121021 Test RE 0.43659710955991604\n",
      "11 Train Loss 8449.353 Test MSE 2395.789689723604 Test RE 0.4283707311896598\n",
      "12 Train Loss 8261.696 Test MSE 2322.1435851122524 Test RE 0.42173532431547356\n",
      "13 Train Loss 8063.182 Test MSE 2258.6948418201328 Test RE 0.4159338095861246\n",
      "14 Train Loss 7778.654 Test MSE 2169.374103053868 Test RE 0.40762674365450313\n",
      "15 Train Loss 7610.0137 Test MSE 2101.209508122543 Test RE 0.401171546343941\n",
      "16 Train Loss 7480.738 Test MSE 2078.6978311805055 Test RE 0.3990167484562351\n",
      "17 Train Loss 7272.2563 Test MSE 2033.5806918542223 Test RE 0.394662759980611\n",
      "18 Train Loss 7161.8022 Test MSE 2002.1311434691008 Test RE 0.39159911750642407\n",
      "19 Train Loss 6962.5225 Test MSE 1971.8699620166283 Test RE 0.3886284401782245\n",
      "20 Train Loss 6888.6177 Test MSE 2004.9195593525424 Test RE 0.39187171734937876\n",
      "21 Train Loss 6771.8105 Test MSE 1963.6726577446593 Test RE 0.3878198109643765\n",
      "22 Train Loss 6707.1484 Test MSE 1943.3936788180977 Test RE 0.3858120934856667\n",
      "23 Train Loss 6633.7524 Test MSE 1998.5506738227073 Test RE 0.3912488067444342\n",
      "24 Train Loss 6573.1084 Test MSE 2013.7330722493605 Test RE 0.3927320957865298\n",
      "25 Train Loss 6491.5996 Test MSE 1923.0737109742067 Test RE 0.3837897832224446\n",
      "26 Train Loss 6453.0186 Test MSE 1880.4532100559254 Test RE 0.37951304601320585\n",
      "27 Train Loss 6371.133 Test MSE 1834.5942452420525 Test RE 0.37485685505953864\n",
      "28 Train Loss 6320.2446 Test MSE 1815.948015877468 Test RE 0.3729470273324345\n",
      "29 Train Loss 6270.535 Test MSE 1856.616057561166 Test RE 0.3770999674825324\n",
      "30 Train Loss 6173.816 Test MSE 1854.978090535005 Test RE 0.37693358585406794\n",
      "31 Train Loss 6075.465 Test MSE 1846.525976774075 Test RE 0.37607386601768134\n",
      "32 Train Loss 6015.8667 Test MSE 1840.8379869618238 Test RE 0.37549419527444505\n",
      "33 Train Loss 5993.781 Test MSE 1810.3606759439126 Test RE 0.372372840426981\n",
      "34 Train Loss 5969.6943 Test MSE 1746.283292721629 Test RE 0.3657234376553721\n",
      "35 Train Loss 5946.2285 Test MSE 1797.4650758023022 Test RE 0.37104422307275287\n",
      "36 Train Loss 5921.3936 Test MSE 1830.5064970695707 Test RE 0.3744390038262873\n",
      "37 Train Loss 5883.6714 Test MSE 1777.7537682739562 Test RE 0.36900414769397116\n",
      "38 Train Loss 5861.398 Test MSE 1828.671655512821 Test RE 0.37425129389519585\n",
      "39 Train Loss 5827.6567 Test MSE 1847.940356323436 Test RE 0.3762178686946289\n",
      "40 Train Loss 5799.0786 Test MSE 1838.5845949931208 Test RE 0.37526430141367983\n",
      "41 Train Loss 5743.6626 Test MSE 1802.1585736368947 Test RE 0.3715283381537875\n",
      "42 Train Loss 5681.9272 Test MSE 1766.4675505580346 Test RE 0.36783095593555604\n",
      "43 Train Loss 5646.7827 Test MSE 1748.8332938920876 Test RE 0.3659903631284574\n",
      "44 Train Loss 5596.9854 Test MSE 1736.4497362966547 Test RE 0.3646922649698688\n",
      "45 Train Loss 5481.351 Test MSE 1637.267001031788 Test RE 0.3541238671329093\n",
      "46 Train Loss 5306.9355 Test MSE 1481.3578618821737 Test RE 0.3368413794113464\n",
      "47 Train Loss 5237.0654 Test MSE 1418.9866666098721 Test RE 0.3296739268489813\n",
      "48 Train Loss 5204.822 Test MSE 1393.1204780768417 Test RE 0.32665535480245517\n",
      "49 Train Loss 5148.828 Test MSE 1402.6064206076724 Test RE 0.327765587945005\n",
      "50 Train Loss 5088.4634 Test MSE 1390.3701173143268 Test RE 0.3263327466905266\n",
      "51 Train Loss 5054.4116 Test MSE 1408.909179483946 Test RE 0.32850118700012193\n",
      "52 Train Loss 4995.346 Test MSE 1458.0137430273244 Test RE 0.3341767666184699\n",
      "53 Train Loss 4947.041 Test MSE 1438.4057566752288 Test RE 0.3319220851330201\n",
      "54 Train Loss 4852.938 Test MSE 1414.4732215235413 Test RE 0.3291492037145356\n",
      "55 Train Loss 4811.523 Test MSE 1366.1493107705473 Test RE 0.3234778347998919\n",
      "56 Train Loss 4745.598 Test MSE 1317.314466786883 Test RE 0.31764364756114305\n",
      "57 Train Loss 4709.718 Test MSE 1266.9396288894823 Test RE 0.3115110123581124\n",
      "58 Train Loss 4650.9136 Test MSE 1246.8453598745525 Test RE 0.30903078174974763\n",
      "59 Train Loss 4602.9297 Test MSE 1193.3472161469133 Test RE 0.3023283375641612\n",
      "60 Train Loss 4544.929 Test MSE 1179.3194276067527 Test RE 0.3005461508910569\n",
      "61 Train Loss 4479.089 Test MSE 1146.9964016459332 Test RE 0.2963988208231583\n",
      "62 Train Loss 4444.52 Test MSE 1127.6548049426415 Test RE 0.2938891353965219\n",
      "63 Train Loss 4415.798 Test MSE 1119.1793510161829 Test RE 0.2927826169021248\n",
      "64 Train Loss 4377.785 Test MSE 1096.6495483115243 Test RE 0.2898206831824467\n",
      "65 Train Loss 4314.744 Test MSE 1099.7635085020231 Test RE 0.29023186755722735\n",
      "66 Train Loss 4273.0464 Test MSE 1107.0888372716136 Test RE 0.29119685469984624\n",
      "67 Train Loss 4251.471 Test MSE 1118.1111455825376 Test RE 0.29264285974682\n",
      "68 Train Loss 4224.723 Test MSE 1124.6152260677354 Test RE 0.29349278095127473\n",
      "69 Train Loss 4206.846 Test MSE 1115.3846041572938 Test RE 0.2922858335676815\n",
      "70 Train Loss 4188.529 Test MSE 1098.4137566923332 Test RE 0.2900537105006173\n",
      "71 Train Loss 4176.316 Test MSE 1082.5898472173526 Test RE 0.28795685307531665\n",
      "72 Train Loss 4145.5957 Test MSE 1119.1339580702413 Test RE 0.2927766793371345\n",
      "73 Train Loss 4110.646 Test MSE 1130.6125732633843 Test RE 0.29427430943911176\n",
      "74 Train Loss 4084.9653 Test MSE 1138.7739072959932 Test RE 0.2953345100979102\n",
      "75 Train Loss 4068.0356 Test MSE 1176.557174877011 Test RE 0.30019396847981356\n",
      "76 Train Loss 4047.183 Test MSE 1155.5938960110873 Test RE 0.2975075992502338\n",
      "77 Train Loss 4026.1902 Test MSE 1168.5225543042122 Test RE 0.29916721153423337\n",
      "78 Train Loss 4011.6213 Test MSE 1174.4401156339907 Test RE 0.2999237671780387\n",
      "79 Train Loss 4005.3445 Test MSE 1193.4932450108145 Test RE 0.3023468348265407\n",
      "80 Train Loss 3961.2224 Test MSE 1180.378099894104 Test RE 0.3006810204176125\n",
      "81 Train Loss 3919.75 Test MSE 1141.3900767419823 Test RE 0.29567355978346815\n",
      "82 Train Loss 3887.6953 Test MSE 1111.8909928917476 Test RE 0.29182772524751194\n",
      "83 Train Loss 3862.678 Test MSE 1061.3932230929986 Test RE 0.28512388438231967\n",
      "84 Train Loss 3834.7954 Test MSE 1030.271171405552 Test RE 0.2809125988995698\n",
      "85 Train Loss 3825.9878 Test MSE 1028.0478455383986 Test RE 0.2806093304109896\n",
      "86 Train Loss 3801.4602 Test MSE 970.7923596138988 Test RE 0.27268334864940375\n",
      "87 Train Loss 3763.88 Test MSE 928.7855220971164 Test RE 0.26671851367209803\n",
      "88 Train Loss 3726.8728 Test MSE 903.9108357562466 Test RE 0.2631226534450796\n",
      "89 Train Loss 3691.7163 Test MSE 911.4250946867236 Test RE 0.2642140662140064\n",
      "90 Train Loss 3668.8452 Test MSE 918.1746063877026 Test RE 0.2651905735247663\n",
      "91 Train Loss 3645.8145 Test MSE 956.3475521915105 Test RE 0.2706470633345309\n",
      "92 Train Loss 3619.8652 Test MSE 931.0896246954707 Test RE 0.2670491422944089\n",
      "93 Train Loss 3591.7534 Test MSE 922.6437013653506 Test RE 0.26583518033266146\n",
      "94 Train Loss 3518.8945 Test MSE 907.6491124800748 Test RE 0.26366618625949634\n",
      "95 Train Loss 3435.0405 Test MSE 840.6122049146977 Test RE 0.2537425438276006\n",
      "96 Train Loss 3412.1392 Test MSE 810.9412276484042 Test RE 0.24922415599015552\n",
      "97 Train Loss 3388.4849 Test MSE 815.1110900387145 Test RE 0.2498640901133455\n",
      "98 Train Loss 3362.355 Test MSE 808.2856705086217 Test RE 0.24881575913628282\n",
      "99 Train Loss 3329.7546 Test MSE 782.0095034272271 Test RE 0.24473802964399186\n",
      "100 Train Loss 3292.7156 Test MSE 760.0372314686729 Test RE 0.2412753073243326\n",
      "101 Train Loss 3279.969 Test MSE 746.8127068352892 Test RE 0.2391670204982621\n",
      "102 Train Loss 3268.049 Test MSE 737.3998087585161 Test RE 0.2376549990876501\n",
      "103 Train Loss 3249.2625 Test MSE 753.2227266860333 Test RE 0.24019123295319597\n",
      "104 Train Loss 3240.106 Test MSE 769.202078783422 Test RE 0.24272564758598716\n",
      "105 Train Loss 3231.0537 Test MSE 770.0647565061787 Test RE 0.24286172062683362\n",
      "106 Train Loss 3210.5547 Test MSE 781.4656990140217 Test RE 0.2446529202140664\n",
      "107 Train Loss 3175.0576 Test MSE 793.646348820508 Test RE 0.24655224144664303\n",
      "108 Train Loss 3150.75 Test MSE 798.8747371667703 Test RE 0.24736302750707836\n",
      "109 Train Loss 3130.9482 Test MSE 776.5802013828525 Test RE 0.24388697155034905\n",
      "110 Train Loss 3115.8452 Test MSE 769.4483668302558 Test RE 0.24276450320199186\n",
      "111 Train Loss 3103.9182 Test MSE 749.6591204062963 Test RE 0.23962236948149745\n",
      "112 Train Loss 3100.2175 Test MSE 739.6417901200458 Test RE 0.23801600657179472\n",
      "113 Train Loss 3096.9478 Test MSE 732.2454619798433 Test RE 0.2368229508844814\n",
      "114 Train Loss 3090.0298 Test MSE 737.6571574760305 Test RE 0.23769646565251856\n",
      "115 Train Loss 3071.9749 Test MSE 732.0392189725368 Test RE 0.2367895969615999\n",
      "116 Train Loss 3051.629 Test MSE 729.3735126736453 Test RE 0.23635807144461476\n",
      "117 Train Loss 3031.125 Test MSE 710.4174200767396 Test RE 0.23326643113545142\n",
      "118 Train Loss 3011.3804 Test MSE 700.1347065128581 Test RE 0.23157210699295303\n",
      "119 Train Loss 2968.9478 Test MSE 676.4708034596673 Test RE 0.22762500712347208\n",
      "120 Train Loss 2943.5671 Test MSE 673.2594333327754 Test RE 0.2270840689529723\n",
      "121 Train Loss 2923.302 Test MSE 669.3087121233617 Test RE 0.2264168181107384\n",
      "122 Train Loss 2893.8613 Test MSE 664.696118244752 Test RE 0.22563528458604787\n",
      "123 Train Loss 2855.642 Test MSE 642.0978921176585 Test RE 0.22176656310974094\n",
      "124 Train Loss 2815.0957 Test MSE 636.7237103074118 Test RE 0.22083655062771115\n",
      "125 Train Loss 2802.2449 Test MSE 633.1105450967491 Test RE 0.2202090774207631\n",
      "126 Train Loss 2778.7483 Test MSE 609.3049550973724 Test RE 0.21602936984557927\n",
      "127 Train Loss 2749.4084 Test MSE 580.5424964223669 Test RE 0.21086886083731232\n",
      "128 Train Loss 2740.829 Test MSE 565.1010839909 Test RE 0.20804558982747143\n",
      "129 Train Loss 2730.34 Test MSE 544.9639964607611 Test RE 0.2043051665596375\n",
      "130 Train Loss 2719.057 Test MSE 536.2795774065584 Test RE 0.20267074926162254\n",
      "131 Train Loss 2699.1074 Test MSE 538.3026439089003 Test RE 0.20305266800442295\n",
      "132 Train Loss 2677.0786 Test MSE 525.5176855125158 Test RE 0.20062687653995248\n",
      "133 Train Loss 2660.8276 Test MSE 515.3921127933388 Test RE 0.19868465560145387\n",
      "134 Train Loss 2642.7676 Test MSE 508.82166403183777 Test RE 0.19741413296725038\n",
      "135 Train Loss 2622.8772 Test MSE 499.15830965620063 Test RE 0.19553053856985256\n",
      "136 Train Loss 2597.2976 Test MSE 497.40074121476636 Test RE 0.19518599722719288\n",
      "137 Train Loss 2578.096 Test MSE 494.1553753744517 Test RE 0.1945481949886386\n",
      "138 Train Loss 2570.8154 Test MSE 497.15433059130993 Test RE 0.1951376440007164\n",
      "139 Train Loss 2548.0925 Test MSE 492.14614143654325 Test RE 0.19415227600496235\n",
      "140 Train Loss 2519.9136 Test MSE 492.1012050235487 Test RE 0.19414341206670785\n",
      "141 Train Loss 2502.9575 Test MSE 491.50669439917925 Test RE 0.1940261036746258\n",
      "142 Train Loss 2497.8777 Test MSE 490.7590089277683 Test RE 0.19387847017017473\n",
      "143 Train Loss 2476.7231 Test MSE 484.97871481679783 Test RE 0.19273331130417617\n",
      "144 Train Loss 2459.7502 Test MSE 482.08957732821335 Test RE 0.1921583738943596\n",
      "145 Train Loss 2453.8584 Test MSE 480.6048833457057 Test RE 0.19186225011265332\n",
      "146 Train Loss 2447.7246 Test MSE 487.907419058236 Test RE 0.19331437728149795\n",
      "147 Train Loss 2442.8516 Test MSE 493.0232333807609 Test RE 0.19432520593262004\n",
      "148 Train Loss 2437.739 Test MSE 499.0909659699 Test RE 0.19551734817398334\n",
      "149 Train Loss 2430.9773 Test MSE 509.32823872657434 Test RE 0.19751237969370677\n",
      "150 Train Loss 2416.0198 Test MSE 493.2101252014079 Test RE 0.19436203416702544\n",
      "151 Train Loss 2398.7695 Test MSE 477.16587197712704 Test RE 0.19117457394848544\n",
      "152 Train Loss 2387.9043 Test MSE 464.45149010026284 Test RE 0.18861039478433608\n",
      "153 Train Loss 2380.6868 Test MSE 465.279648792732 Test RE 0.18877847452345575\n",
      "154 Train Loss 2378.7253 Test MSE 465.83496015802297 Test RE 0.18889109450634492\n",
      "155 Train Loss 2374.2295 Test MSE 464.0847498559945 Test RE 0.1885359147968337\n",
      "156 Train Loss 2367.2412 Test MSE 469.8846376781622 Test RE 0.18971036825882975\n",
      "157 Train Loss 2362.8965 Test MSE 473.7528215738919 Test RE 0.19048963453944912\n",
      "158 Train Loss 2360.9426 Test MSE 480.6218769995373 Test RE 0.19186564210049395\n",
      "159 Train Loss 2359.3315 Test MSE 480.75596797788774 Test RE 0.19189240498696092\n",
      "160 Train Loss 2355.1614 Test MSE 472.2843367777146 Test RE 0.19019417641692885\n",
      "161 Train Loss 2347.1611 Test MSE 473.7562398109828 Test RE 0.19049032175177807\n",
      "162 Train Loss 2340.809 Test MSE 466.33310757318856 Test RE 0.1889920642449159\n",
      "163 Train Loss 2334.936 Test MSE 461.17541154661404 Test RE 0.18794402169748547\n",
      "164 Train Loss 2333.6133 Test MSE 457.28339265450415 Test RE 0.18714927904824494\n",
      "165 Train Loss 2332.6135 Test MSE 453.2711994880013 Test RE 0.18632644862774542\n",
      "166 Train Loss 2328.3137 Test MSE 454.962962204046 Test RE 0.18667384171107368\n",
      "167 Train Loss 2324.9253 Test MSE 457.00345404984597 Test RE 0.18709198598952217\n",
      "168 Train Loss 2321.9 Test MSE 458.51743025705684 Test RE 0.18740163201986215\n",
      "169 Train Loss 2317.3862 Test MSE 455.52562873961506 Test RE 0.1867892386527511\n",
      "170 Train Loss 2309.292 Test MSE 452.74628820405405 Test RE 0.18621852958539348\n",
      "171 Train Loss 2295.3394 Test MSE 459.22772063253615 Test RE 0.18754672799287958\n",
      "172 Train Loss 2285.8772 Test MSE 463.5722917585066 Test RE 0.18843179217392417\n",
      "173 Train Loss 2268.4138 Test MSE 450.263255864515 Test RE 0.1857071809961075\n",
      "174 Train Loss 2258.5757 Test MSE 444.1589842967102 Test RE 0.1844440583365325\n",
      "175 Train Loss 2248.4558 Test MSE 445.54232823856756 Test RE 0.18473106278889986\n",
      "176 Train Loss 2243.2578 Test MSE 436.9629085703624 Test RE 0.1829438146914565\n",
      "177 Train Loss 2240.233 Test MSE 433.86397705298486 Test RE 0.1822939436306012\n",
      "178 Train Loss 2229.5588 Test MSE 432.19293714302137 Test RE 0.18194254970167106\n",
      "179 Train Loss 2211.399 Test MSE 427.3136314208354 Test RE 0.18091260092523626\n",
      "180 Train Loss 2206.5876 Test MSE 423.53947382275686 Test RE 0.18011189277126502\n",
      "181 Train Loss 2200.736 Test MSE 417.5099840952356 Test RE 0.17882526468344923\n",
      "182 Train Loss 2197.0315 Test MSE 419.50398903812254 Test RE 0.17925178589142737\n",
      "183 Train Loss 2194.0427 Test MSE 417.34093027163794 Test RE 0.17878905697975636\n",
      "184 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "185 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "186 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "187 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "188 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "189 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "190 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "191 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "192 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "193 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "194 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "195 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "196 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "197 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "198 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "199 Train Loss 2193.3245 Test MSE 414.80992189214146 Test RE 0.17824608989867116\n",
      "Training time: 121.07\n",
      "Training time: 121.07\n",
      "ES_tanh_medium\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 9999.993 Test MSE 3003.2234268042207 Test RE 0.4796111437173365\n",
      "1 Train Loss 9999.993 Test MSE 3003.2237206353825 Test RE 0.47961116717957647\n",
      "2 Train Loss 9999.993 Test MSE 3003.2257208071737 Test RE 0.4796113268920481\n",
      "3 Train Loss 9999.993 Test MSE 3003.2284649989056 Test RE 0.4796115460139624\n",
      "4 Train Loss 9986.316 Test MSE 2993.047376947577 Test RE 0.4787979028229589\n",
      "5 Train Loss 9911.209 Test MSE 2959.277343581812 Test RE 0.4760891437726821\n",
      "6 Train Loss 9648.885 Test MSE 2841.082113583067 Test RE 0.46648462771383675\n",
      "7 Train Loss 9226.491 Test MSE 2664.051044902412 Test RE 0.4517172908168403\n",
      "8 Train Loss 8835.847 Test MSE 2500.0437903816396 Test RE 0.437591877097437\n",
      "9 Train Loss 8392.221 Test MSE 2295.7859816153814 Test RE 0.41933503007691686\n",
      "10 Train Loss 8006.373 Test MSE 2157.077566609814 Test RE 0.4064698384961813\n",
      "11 Train Loss 7696.1865 Test MSE 2041.1613729570522 Test RE 0.3953976778377583\n",
      "12 Train Loss 7455.114 Test MSE 1977.8659210149315 Test RE 0.3892188522079464\n",
      "13 Train Loss 7076.2344 Test MSE 1866.6984487904122 Test RE 0.3781225056518245\n",
      "14 Train Loss 6744.0503 Test MSE 1735.9403135993505 Test RE 0.3646387661149385\n",
      "15 Train Loss 6453.841 Test MSE 1592.9096630725808 Test RE 0.34929391284186617\n",
      "16 Train Loss 6190.19 Test MSE 1492.1400335675273 Test RE 0.3380650191846956\n",
      "17 Train Loss 6041.4097 Test MSE 1441.0784667799985 Test RE 0.33223031519716434\n",
      "18 Train Loss 5735.2227 Test MSE 1372.2045199716758 Test RE 0.3241939206327102\n",
      "19 Train Loss 5527.128 Test MSE 1325.2978913065913 Test RE 0.3186047140499111\n",
      "20 Train Loss 5295.8276 Test MSE 1223.329870701404 Test RE 0.3061027518845344\n",
      "21 Train Loss 5039.538 Test MSE 1100.4610382701603 Test RE 0.2903238933770656\n",
      "22 Train Loss 4813.828 Test MSE 1023.6701512814898 Test RE 0.2800112393853798\n",
      "23 Train Loss 4678.1943 Test MSE 1012.5172826237911 Test RE 0.27848170309405884\n",
      "24 Train Loss 4475.4326 Test MSE 997.5407457688461 Test RE 0.27641446470329556\n",
      "25 Train Loss 4314.3657 Test MSE 923.5751877677378 Test RE 0.2659693379647719\n",
      "26 Train Loss 4116.4097 Test MSE 888.0003903872046 Test RE 0.26079665822729914\n",
      "27 Train Loss 3957.7637 Test MSE 824.6033712805291 Test RE 0.2513147605113911\n",
      "28 Train Loss 3868.107 Test MSE 814.8390342919031 Test RE 0.24982238865970235\n",
      "29 Train Loss 3714.8538 Test MSE 728.924898235327 Test RE 0.23628537209982325\n",
      "30 Train Loss 3670.4421 Test MSE 714.2256002791842 Test RE 0.23389080583626412\n",
      "31 Train Loss 3585.2974 Test MSE 658.4865813523139 Test RE 0.22457887837415616\n",
      "32 Train Loss 3501.9512 Test MSE 609.7653716548682 Test RE 0.2161109748902626\n",
      "33 Train Loss 3404.1628 Test MSE 605.3056099545852 Test RE 0.2153192177177962\n",
      "34 Train Loss 3340.981 Test MSE 592.6978877115457 Test RE 0.21306500939913187\n",
      "35 Train Loss 3298.6748 Test MSE 576.9437355422881 Test RE 0.21021426077140307\n",
      "36 Train Loss 3245.0369 Test MSE 569.0131068010473 Test RE 0.20876446598182805\n",
      "37 Train Loss 3182.5354 Test MSE 559.4639866505813 Test RE 0.207005322282551\n",
      "38 Train Loss 3124.2605 Test MSE 552.7671229554959 Test RE 0.20576265073560876\n",
      "39 Train Loss 2974.0264 Test MSE 496.6676790548972 Test RE 0.19504211301641086\n",
      "40 Train Loss 2895.1768 Test MSE 490.9685507634415 Test RE 0.1939198563843746\n",
      "41 Train Loss 2836.0513 Test MSE 488.92349223762534 Test RE 0.19351556237322584\n",
      "42 Train Loss 2772.0146 Test MSE 459.9226910010947 Test RE 0.1876885858750854\n",
      "43 Train Loss 2666.9204 Test MSE 436.5935738177963 Test RE 0.1828664834228426\n",
      "44 Train Loss 2602.5642 Test MSE 401.01507867352177 Test RE 0.1752571702971025\n",
      "45 Train Loss 2555.8347 Test MSE 378.7811112880428 Test RE 0.1703293937925217\n",
      "46 Train Loss 2503.5396 Test MSE 365.98074718133984 Test RE 0.16742664071679292\n",
      "47 Train Loss 2464.5674 Test MSE 361.6082054644646 Test RE 0.16642347352547282\n",
      "48 Train Loss 2402.71 Test MSE 343.0510462618685 Test RE 0.16209694053424625\n",
      "49 Train Loss 2293.2854 Test MSE 333.99885647604935 Test RE 0.15994399292564607\n",
      "50 Train Loss 2234.3274 Test MSE 319.03278506338086 Test RE 0.15631947989613135\n",
      "51 Train Loss 2122.158 Test MSE 300.2813566198107 Test RE 0.15165601095697082\n",
      "52 Train Loss 2044.1923 Test MSE 279.6955289259865 Test RE 0.1463653264857931\n",
      "53 Train Loss 2018.925 Test MSE 285.6943323812081 Test RE 0.14792659349285245\n",
      "54 Train Loss 1960.5476 Test MSE 282.7828942140837 Test RE 0.14717092223286535\n",
      "55 Train Loss 1909.5314 Test MSE 283.2657274675208 Test RE 0.14729651099788846\n",
      "56 Train Loss 1888.0757 Test MSE 287.6203439626328 Test RE 0.14842438034687355\n",
      "57 Train Loss 1857.1389 Test MSE 275.1566798555283 Test RE 0.14517287378751118\n",
      "58 Train Loss 1834.6089 Test MSE 265.18979892660656 Test RE 0.14251935586399533\n",
      "59 Train Loss 1802.7765 Test MSE 259.2827252540462 Test RE 0.14092311527660287\n",
      "60 Train Loss 1786.3744 Test MSE 254.69020666842292 Test RE 0.13966949623812938\n",
      "61 Train Loss 1745.7178 Test MSE 253.59864091986458 Test RE 0.13936987312940843\n",
      "62 Train Loss 1705.4258 Test MSE 251.20776918004645 Test RE 0.1387113432090977\n",
      "63 Train Loss 1679.9108 Test MSE 258.1376421863652 Test RE 0.1406115880959872\n",
      "64 Train Loss 1662.8154 Test MSE 253.72551650215647 Test RE 0.13940473219378985\n",
      "65 Train Loss 1641.5479 Test MSE 259.9430022516903 Test RE 0.14110243522278487\n",
      "66 Train Loss 1626.1991 Test MSE 259.48311335760127 Test RE 0.140977561367581\n",
      "67 Train Loss 1611.5172 Test MSE 267.4395450232468 Test RE 0.14312261287355352\n",
      "68 Train Loss 1597.1606 Test MSE 279.9793962131422 Test RE 0.14643958185851905\n",
      "69 Train Loss 1571.3588 Test MSE 284.74887967075256 Test RE 0.14768162276191893\n",
      "70 Train Loss 1540.3721 Test MSE 271.0980805924652 Test RE 0.14409823627209772\n",
      "71 Train Loss 1525.1833 Test MSE 275.1772436723071 Test RE 0.14517829842885507\n",
      "72 Train Loss 1509.9739 Test MSE 290.2869307795657 Test RE 0.14911082930280978\n",
      "73 Train Loss 1502.0286 Test MSE 295.69468508697923 Test RE 0.15049331302323424\n",
      "74 Train Loss 1478.6476 Test MSE 281.91457131683427 Test RE 0.14694479445844102\n",
      "75 Train Loss 1442.5825 Test MSE 282.254127059242 Test RE 0.1470332626300656\n",
      "76 Train Loss 1414.5135 Test MSE 264.15277378329097 Test RE 0.14224042181652988\n",
      "77 Train Loss 1384.2958 Test MSE 263.2608364278528 Test RE 0.1420000744942861\n",
      "78 Train Loss 1378.524 Test MSE 268.2363791817424 Test RE 0.1433356706770438\n",
      "79 Train Loss 1368.3745 Test MSE 250.1256645095797 Test RE 0.13841226371581591\n",
      "80 Train Loss 1340.5702 Test MSE 237.68100746251886 Test RE 0.1349250798151184\n",
      "81 Train Loss 1331.7261 Test MSE 230.74169399052076 Test RE 0.13294085946207723\n",
      "82 Train Loss 1325.7504 Test MSE 233.99518813884424 Test RE 0.1338748222364397\n",
      "83 Train Loss 1319.921 Test MSE 234.74220941556715 Test RE 0.1340883472475973\n",
      "84 Train Loss 1313.326 Test MSE 234.75628963069303 Test RE 0.1340923686046201\n",
      "85 Train Loss 1304.0735 Test MSE 229.64748180647283 Test RE 0.1326252719956998\n",
      "86 Train Loss 1299.2493 Test MSE 227.25936734065866 Test RE 0.13193388177213877\n",
      "87 Train Loss 1297.0321 Test MSE 227.8151567929462 Test RE 0.13209511315009462\n",
      "88 Train Loss 1287.0953 Test MSE 228.27746783489457 Test RE 0.13222907719230842\n",
      "89 Train Loss 1274.3284 Test MSE 219.24133102892688 Test RE 0.12958557461603556\n",
      "90 Train Loss 1264.0253 Test MSE 225.34361166988222 Test RE 0.1313766154029863\n",
      "91 Train Loss 1249.6805 Test MSE 218.38958218585873 Test RE 0.12933361078213287\n",
      "92 Train Loss 1246.6593 Test MSE 218.96296919020196 Test RE 0.12950328370944694\n",
      "93 Train Loss 1242.7107 Test MSE 220.63419404722006 Test RE 0.1299965582224774\n",
      "94 Train Loss 1231.9518 Test MSE 231.17682517845404 Test RE 0.13306614992659488\n",
      "95 Train Loss 1229.6445 Test MSE 234.01313917323668 Test RE 0.13387995726820828\n",
      "96 Train Loss 1221.2648 Test MSE 229.7399636035738 Test RE 0.13265197420203137\n",
      "97 Train Loss 1204.2928 Test MSE 235.80823833163913 Test RE 0.13439246839070787\n",
      "98 Train Loss 1193.6692 Test MSE 237.85866603706572 Test RE 0.1349754963796885\n",
      "99 Train Loss 1189.8536 Test MSE 239.34765671880356 Test RE 0.13539730928209442\n",
      "100 Train Loss 1184.0392 Test MSE 235.34537807627848 Test RE 0.1342605063191567\n",
      "101 Train Loss 1176.5225 Test MSE 240.27185160573035 Test RE 0.13565846274517404\n",
      "102 Train Loss 1171.012 Test MSE 238.37468293803795 Test RE 0.13512182677093623\n",
      "103 Train Loss 1162.5497 Test MSE 243.41042132735222 Test RE 0.13654161265145845\n",
      "104 Train Loss 1150.1715 Test MSE 246.94357143335145 Test RE 0.13752900667745474\n",
      "105 Train Loss 1145.0758 Test MSE 245.7805106784603 Test RE 0.13720475572870489\n",
      "106 Train Loss 1139.8335 Test MSE 236.10322927493692 Test RE 0.13447650313527995\n",
      "107 Train Loss 1137.576 Test MSE 234.73072297877022 Test RE 0.13408506659310518\n",
      "108 Train Loss 1135.8174 Test MSE 233.68971923304582 Test RE 0.13378741028800592\n",
      "109 Train Loss 1132.9591 Test MSE 236.94965027207132 Test RE 0.13471733403209493\n",
      "110 Train Loss 1129.5935 Test MSE 242.04370664003397 Test RE 0.13615774223960955\n",
      "111 Train Loss 1127.0724 Test MSE 244.8752658994483 Test RE 0.1369518502710957\n",
      "112 Train Loss 1117.6239 Test MSE 241.08086260790125 Test RE 0.13588665626888288\n",
      "113 Train Loss 1110.2822 Test MSE 240.76781847553397 Test RE 0.13579840302053373\n",
      "114 Train Loss 1104.4889 Test MSE 228.06959676353162 Test RE 0.13216885911554074\n",
      "115 Train Loss 1094.6997 Test MSE 221.73314955892147 Test RE 0.13031990561491066\n",
      "116 Train Loss 1090.5078 Test MSE 225.2736057729408 Test RE 0.13135620689851712\n",
      "117 Train Loss 1085.6583 Test MSE 221.7157534372985 Test RE 0.13031479337661903\n",
      "118 Train Loss 1080.4087 Test MSE 222.2413954065949 Test RE 0.13046917657319898\n",
      "119 Train Loss 1074.3875 Test MSE 225.63720820073635 Test RE 0.1314621717735295\n",
      "120 Train Loss 1072.7952 Test MSE 225.89104325498343 Test RE 0.13153609647785053\n",
      "121 Train Loss 1069.7201 Test MSE 223.17505621392309 Test RE 0.13074294709658213\n",
      "122 Train Loss 1065.5356 Test MSE 221.5482300114395 Test RE 0.13026555261325848\n",
      "123 Train Loss 1061.5969 Test MSE 224.76082791172837 Test RE 0.13120662228942248\n",
      "124 Train Loss 1052.4734 Test MSE 229.52844887169167 Test RE 0.1325908957825501\n",
      "125 Train Loss 1041.3328 Test MSE 235.99850252664638 Test RE 0.13444667540062305\n",
      "126 Train Loss 1036.8365 Test MSE 242.3343744586933 Test RE 0.13623947293156308\n",
      "127 Train Loss 1035.1261 Test MSE 245.97700623411905 Test RE 0.13725959070789628\n",
      "128 Train Loss 1034.1836 Test MSE 244.8598125479709 Test RE 0.13694752889045247\n",
      "129 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "130 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "131 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "132 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "133 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "134 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "135 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "136 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "137 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "138 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "139 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "140 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "141 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "142 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "143 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "144 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "145 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "146 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "147 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "148 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "149 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "150 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "151 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "152 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "153 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "154 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "155 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "156 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "157 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "158 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "159 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "160 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "161 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "162 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "163 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "164 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "165 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "166 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "167 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "168 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "169 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "170 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "171 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "172 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "173 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "174 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "175 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "176 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "177 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "178 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "179 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "180 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "181 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "182 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "183 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "184 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "185 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "186 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "187 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "188 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "189 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "190 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "191 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "192 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "193 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "194 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "195 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "196 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "197 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "198 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "199 Train Loss 1033.8962 Test MSE 245.02127653702257 Test RE 0.13699267400842952\n",
      "Training time: 90.10\n",
      "Training time: 90.10\n",
      "ES_tanh_medium\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 9999.993 Test MSE 3003.2234960431356 Test RE 0.4796111492460219\n",
      "1 Train Loss 9999.993 Test MSE 3003.2231603616656 Test RE 0.4796111224420593\n",
      "2 Train Loss 9999.993 Test MSE 3003.2226650609678 Test RE 0.4796110828925953\n",
      "3 Train Loss 9999.993 Test MSE 3003.222214481001 Test RE 0.47961104691405193\n",
      "4 Train Loss 9999.993 Test MSE 3003.221757267909 Test RE 0.47961101040585463\n",
      "5 Train Loss 9999.993 Test MSE 3003.2218579541013 Test RE 0.4796110184455883\n",
      "6 Train Loss 9999.993 Test MSE 3003.2231676692195 Test RE 0.4796111230255632\n",
      "7 Train Loss 9999.993 Test MSE 3003.223393017187 Test RE 0.4796111410194623\n",
      "8 Train Loss 9999.993 Test MSE 3003.223314721663 Test RE 0.4796111347676121\n",
      "9 Train Loss 9999.993 Test MSE 3003.2234277079892 Test RE 0.4796111437895019\n",
      "10 Train Loss 9999.993 Test MSE 3003.223528722527 Test RE 0.47961115185545156\n",
      "11 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "12 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "13 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "14 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "15 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "16 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "17 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "18 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "19 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "20 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "21 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "22 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "23 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "24 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "25 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "26 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "27 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "28 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "29 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "30 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "31 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "32 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "33 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "34 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "35 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "36 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "37 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "38 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "39 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "40 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "41 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "42 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "43 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "44 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "45 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "46 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "47 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "48 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "49 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "50 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "51 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "52 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "53 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "54 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "55 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "56 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "57 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "58 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "59 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "60 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "61 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "62 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "63 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "64 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "65 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "66 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "67 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "68 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "69 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "70 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "71 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "72 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "73 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "74 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "75 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "76 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "77 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "78 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "79 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "80 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "81 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "82 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "83 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "84 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "85 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "86 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "87 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "88 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "89 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "90 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "91 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "92 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "93 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "94 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "95 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "96 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "97 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "98 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "99 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "100 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "101 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "102 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "103 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "104 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "105 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "106 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "107 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "108 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "109 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "110 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "111 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "112 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "113 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "114 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "115 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "116 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "117 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "118 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "119 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "120 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "121 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "122 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "123 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "124 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "125 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "126 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "127 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "128 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "129 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "130 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "131 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "132 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "133 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "134 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "135 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "136 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "137 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "138 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "139 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "140 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "141 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "142 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "143 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "144 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "145 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "146 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "147 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "148 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "149 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "150 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "151 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "152 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "153 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "154 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "155 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "156 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "157 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "158 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "159 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "160 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "161 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "162 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "163 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "164 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "165 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "166 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "167 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "168 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "169 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "170 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "171 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "172 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "173 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "174 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "175 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "176 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "177 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "178 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "179 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "180 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "181 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "182 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "183 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "184 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "185 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "186 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "187 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "188 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "189 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "190 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "191 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "192 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "193 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "194 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "195 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "196 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "197 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "198 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "199 Train Loss 9999.993 Test MSE 3003.2234909523377 Test RE 0.47961114883952477\n",
      "Training time: 44.93\n",
      "Training time: 44.93\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "\n",
    "N_T = 5000 #Total number of data points for 'y'\n",
    "N_f = 10000 #Total number of collocation points \n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    " \n",
    "    \n",
    "    torch.manual_seed(reps*36)\n",
    "    \n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "   \n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-08, \n",
    "                              tolerance_change = 1e-08, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "    \n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "    \n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = PINN.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1541 into shape (500,500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16644/2850883497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1541 into shape (500,500)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGiCAYAAADA0E3hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcu0lEQVR4nO3db2yV5f348U9paaturRG0FkEEpxMl6mgDo6wandag0ZBskcVF1GliszmETqeMRYYxaXTRfXUKbgoaE3REReeDztEHG1Zxf2DFGCFxEWZBW0kxtqhbGXD/Hhj6W9fiOLV/uNrXK7kfnMv7Puc6uazn7X2fP3lZlmUBAJCAMcM9AQCAIyVcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGTkHC6vvPJKXHnllTFhwoTIy8uLF1988X8es2HDhqioqIji4uKYOnVqPProo/2ZKwAwyuUcLp988kmcd9558fDDDx/R/jt27IjLL788qquro7m5OX7yk5/EwoUL4/nnn895sgDA6Jb3RX5kMS8vL1544YWYN2/eYfe544474qWXXopt27Z1j9XW1sYbb7wRr7/+en8fGgAYhQoG+wFef/31qKmp6TF22WWXxapVq+Lf//53jB07ttcxXV1d0dXV1X374MGD8eGHH8a4ceMiLy9vsKcMAAyALMti7969MWHChBgzZmDeVjvo4dLW1hZlZWU9xsrKymL//v3R3t4e5eXlvY6pr6+P5cuXD/bUAIAhsHPnzpg4ceKA3Negh0tE9DpLcujq1OHOnixZsiTq6uq6b3d0dMSpp54aO3fujJKSksGbKAAwYDo7O2PSpEnx5S9/ecDuc9DD5eSTT462trYeY7t3746CgoIYN25cn8cUFRVFUVFRr/GSkhLhAgCJGci3eQz697jMnj07Ghsbe4ytX78+Kisr+3x/CwDA4eQcLh9//HFs2bIltmzZEhGffdx5y5Yt0dLSEhGfXeZZsGBB9/61tbXx7rvvRl1dXWzbti1Wr14dq1atittuu21gngEAMGrkfKlo06ZNcdFFF3XfPvRelOuuuy6efPLJaG1t7Y6YiIgpU6ZEQ0NDLF68OB555JGYMGFCPPTQQ/Gtb31rAKYPAIwmX+h7XIZKZ2dnlJaWRkdHh/e4AEAiBuP1228VAQDJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQjH6Fy4oVK2LKlClRXFwcFRUV0dTU9Ln7r1mzJs4777w49thjo7y8PG644YbYs2dPvyYMAIxeOYfL2rVrY9GiRbF06dJobm6O6urqmDt3brS0tPS5/6uvvhoLFiyIG2+8Md5666149tln469//WvcdNNNX3jyAMDoknO4PPDAA3HjjTfGTTfdFNOmTYv/+7//i0mTJsXKlSv73P9Pf/pTnHbaabFw4cKYMmVKfOMb34ibb745Nm3a9IUnDwCMLjmFy759+2Lz5s1RU1PTY7ympiY2btzY5zFVVVWxa9euaGhoiCzL4oMPPojnnnsurrjiisM+TldXV3R2dvbYAAByCpf29vY4cOBAlJWV9RgvKyuLtra2Po+pqqqKNWvWxPz586OwsDBOPvnkOP744+OXv/zlYR+nvr4+SktLu7dJkyblMk0AYITq15tz8/LyetzOsqzX2CFbt26NhQsXxl133RWbN2+Ol19+OXbs2BG1tbWHvf8lS5ZER0dH97Zz587+TBMAGGEKctl5/PjxkZ+f3+vsyu7du3udhTmkvr4+5syZE7fffntERJx77rlx3HHHRXV1ddxzzz1RXl7e65iioqIoKirKZWoAwCiQ0xmXwsLCqKioiMbGxh7jjY2NUVVV1ecxn376aYwZ0/Nh8vPzI+KzMzUAAEcq50tFdXV18fjjj8fq1atj27ZtsXjx4mhpaem+9LNkyZJYsGBB9/5XXnllrFu3LlauXBnbt2+P1157LRYuXBgzZ86MCRMmDNwzAQBGvJwuFUVEzJ8/P/bs2RN33313tLa2xvTp06OhoSEmT54cERGtra09vtPl+uuvj71798bDDz8cP/rRj+L444+Piy++OO69996BexYAwKiQlyVwvaazszNKS0ujo6MjSkpKhns6AMARGIzXb79VBAAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMvoVLitWrIgpU6ZEcXFxVFRURFNT0+fu39XVFUuXLo3JkydHUVFRnH766bF69ep+TRgAGL0Kcj1g7dq1sWjRolixYkXMmTMnfvWrX8XcuXNj69atceqpp/Z5zNVXXx0ffPBBrFq1Kr7yla/E7t27Y//+/V948gDA6JKXZVmWywGzZs2KGTNmxMqVK7vHpk2bFvPmzYv6+vpe+7/88svxne98J7Zv3x4nnHBCvybZ2dkZpaWl0dHRESUlJf26DwBgaA3G63dOl4r27dsXmzdvjpqamh7jNTU1sXHjxj6Peemll6KysjLuu+++OOWUU+LMM8+M2267Lf75z38e9nG6urqis7OzxwYAkNOlovb29jhw4ECUlZX1GC8rK4u2trY+j9m+fXu8+uqrUVxcHC+88EK0t7fH97///fjwww8P+z6X+vr6WL58eS5TAwBGgX69OTcvL6/H7SzLeo0dcvDgwcjLy4s1a9bEzJkz4/LLL48HHnggnnzyycOedVmyZEl0dHR0bzt37uzPNAGAESanMy7jx4+P/Pz8XmdXdu/e3esszCHl5eVxyimnRGlpaffYtGnTIsuy2LVrV5xxxhm9jikqKoqioqJcpgYAjAI5nXEpLCyMioqKaGxs7DHe2NgYVVVVfR4zZ86ceP/99+Pjjz/uHnv77bdjzJgxMXHixH5MGQAYrXK+VFRXVxePP/54rF69OrZt2xaLFy+OlpaWqK2tjYjPLvMsWLCge/9rrrkmxo0bFzfccENs3bo1Xnnllbj99tvje9/7XhxzzDED90wAgBEv5+9xmT9/fuzZsyfuvvvuaG1tjenTp0dDQ0NMnjw5IiJaW1ujpaWle/8vfelL0djYGD/84Q+jsrIyxo0bF1dffXXcc889A/csAIBRIefvcRkOvscFANIz7N/jAgAwnIQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJKNf4bJixYqYMmVKFBcXR0VFRTQ1NR3Rca+99loUFBTE+eef35+HBQBGuZzDZe3atbFo0aJYunRpNDc3R3V1dcydOzdaWlo+97iOjo5YsGBBfPOb3+z3ZAGA0S0vy7IslwNmzZoVM2bMiJUrV3aPTZs2LebNmxf19fWHPe473/lOnHHGGZGfnx8vvvhibNmy5bD7dnV1RVdXV/ftzs7OmDRpUnR0dERJSUku0wUAhklnZ2eUlpYO6Ot3Tmdc9u3bF5s3b46ampoe4zU1NbFx48bDHvfEE0/EO++8E8uWLTuix6mvr4/S0tLubdKkSblMEwAYoXIKl/b29jhw4ECUlZX1GC8rK4u2trY+j/n73/8ed955Z6xZsyYKCgqO6HGWLFkSHR0d3dvOnTtzmSYAMEIdWUn8l7y8vB63syzrNRYRceDAgbjmmmti+fLlceaZZx7x/RcVFUVRUVF/pgYAjGA5hcv48eMjPz+/19mV3bt39zoLExGxd+/e2LRpUzQ3N8ctt9wSEREHDx6MLMuioKAg1q9fHxdffPEXmD4AMJrkdKmosLAwKioqorGxscd4Y2NjVFVV9dq/pKQk3nzzzdiyZUv3VltbG1/96ldjy5YtMWvWrC82ewBgVMn5UlFdXV1ce+21UVlZGbNnz45f//rX0dLSErW1tRHx2ftT3nvvvXjqqadizJgxMX369B7Hn3TSSVFcXNxrHADgf8k5XObPnx979uyJu+++O1pbW2P69OnR0NAQkydPjoiI1tbW//mdLgAA/ZHz97gMh8H4HDgAMLiG/XtcAACGk3ABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZPQrXFasWBFTpkyJ4uLiqKioiKampsPuu27durj00kvjxBNPjJKSkpg9e3b8/ve/7/eEAYDRK+dwWbt2bSxatCiWLl0azc3NUV1dHXPnzo2WlpY+93/llVfi0ksvjYaGhti8eXNcdNFFceWVV0Zzc/MXnjwAMLrkZVmW5XLArFmzYsaMGbFy5crusWnTpsW8efOivr7+iO7jnHPOifnz58ddd93V5z/v6uqKrq6u7tudnZ0xadKk6OjoiJKSklymCwAMk87OzigtLR3Q1++czrjs27cvNm/eHDU1NT3Ga2pqYuPGjUd0HwcPHoy9e/fGCSeccNh96uvro7S0tHubNGlSLtMEAEaonMKlvb09Dhw4EGVlZT3Gy8rKoq2t7Yju4/77749PPvkkrr766sPus2TJkujo6Ojedu7cmcs0AYARqqA/B+Xl5fW4nWVZr7G+PPPMM/Gzn/0sfvvb38ZJJ5102P2KioqiqKioP1MDAEawnMJl/PjxkZ+f3+vsyu7du3udhflva9eujRtvvDGeffbZuOSSS3KfKQAw6uV0qaiwsDAqKiqisbGxx3hjY2NUVVUd9rhnnnkmrr/++nj66afjiiuu6N9MAYBRL+dLRXV1dXHttddGZWVlzJ49O379619HS0tL1NbWRsRn709577334qmnnoqIz6JlwYIF8eCDD8bXv/717rM1xxxzTJSWlg7gUwEARrqcw2X+/PmxZ8+euPvuu6O1tTWmT58eDQ0NMXny5IiIaG1t7fGdLr/61a9i//798YMf/CB+8IMfdI9fd9118eSTT37xZwAAjBo5f4/LcBiMz4EDAINr2L/HBQBgOAkXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASEa/wmXFihUxZcqUKC4ujoqKimhqavrc/Tds2BAVFRVRXFwcU6dOjUcffbRfkwUARrecw2Xt2rWxaNGiWLp0aTQ3N0d1dXXMnTs3Wlpa+tx/x44dcfnll0d1dXU0NzfHT37yk1i4cGE8//zzX3jyAMDokpdlWZbLAbNmzYoZM2bEypUru8emTZsW8+bNi/r6+l7733HHHfHSSy/Ftm3busdqa2vjjTfeiNdff73Px+jq6oqurq7u2x0dHXHqqafGzp07o6SkJJfpAgDDpLOzMyZNmhQfffRRlJaWDsydZjno6urK8vPzs3Xr1vUYX7hwYXbBBRf0eUx1dXW2cOHCHmPr1q3LCgoKsn379vV5zLJly7KIsNlsNpvNNgK2d955J5fc+FwFkYP29vY4cOBAlJWV9RgvKyuLtra2Po9pa2vrc//9+/dHe3t7lJeX9zpmyZIlUVdX1337o48+ismTJ0dLS8vAFRv9cqienf0aftbi6GEtji7W4+hx6IrJCSecMGD3mVO4HJKXl9fjdpZlvcb+1/59jR9SVFQURUVFvcZLS0v9S3iUKCkpsRZHCWtx9LAWRxfrcfQYM2bgPsSc0z2NHz8+8vPze51d2b17d6+zKoecfPLJfe5fUFAQ48aNy3G6AMBollO4FBYWRkVFRTQ2NvYYb2xsjKqqqj6PmT17dq/9169fH5WVlTF27NgcpwsAjGY5n7upq6uLxx9/PFavXh3btm2LxYsXR0tLS9TW1kbEZ+9PWbBgQff+tbW18e6770ZdXV1s27YtVq9eHatWrYrbbrvtiB+zqKgoli1b1uflI4aWtTh6WIujh7U4uliPo8dgrEXOH4eO+OwL6O67775obW2N6dOnxy9+8Yu44IILIiLi+uuvj3/84x/xxz/+sXv/DRs2xOLFi+Ott96KCRMmxB133NEdOgAAR6pf4QIAMBz8VhEAkAzhAgAkQ7gAAMkQLgBAMo6acFmxYkVMmTIliouLo6KiIpqamj53/w0bNkRFRUUUFxfH1KlT49FHHx2imY58uazFunXr4tJLL40TTzwxSkpKYvbs2fH73/9+CGc7suX6d3HIa6+9FgUFBXH++ecP7gRHkVzXoqurK5YuXRqTJ0+OoqKiOP3002P16tVDNNuRLde1WLNmTZx33nlx7LHHRnl5edxwww2xZ8+eIZrtyPXKK6/ElVdeGRMmTIi8vLx48cUX/+cxA/LaPWC/evQF/OY3v8nGjh2bPfbYY9nWrVuzW2+9NTvuuOOyd999t8/9t2/fnh177LHZrbfemm3dujV77LHHsrFjx2bPPffcEM985Ml1LW699dbs3nvvzf7yl79kb7/9drZkyZJs7Nix2d/+9rchnvnIk+taHPLRRx9lU6dOzWpqarLzzjtvaCY7wvVnLa666qps1qxZWWNjY7Zjx47sz3/+c/baa68N4axHplzXoqmpKRszZkz24IMPZtu3b8+ampqyc845J5s3b94Qz3zkaWhoyJYuXZo9//zzWURkL7zwwufuP1Cv3UdFuMycOTOrra3tMXbWWWdld955Z5/7//jHP87OOuusHmM333xz9vWvf33Q5jha5LoWfTn77LOz5cuXD/TURp3+rsX8+fOzn/70p9myZcuEywDJdS1+97vfZaWlpdmePXuGYnqjSq5r8fOf/zybOnVqj7GHHnoomzhx4qDNcTQ6knAZqNfuYb9UtG/fvti8eXPU1NT0GK+pqYmNGzf2eczrr7/ea//LLrssNm3aFP/+978Hba4jXX/W4r8dPHgw9u7dO6C/BDoa9XctnnjiiXjnnXdi2bJlgz3FUaM/a/HSSy9FZWVl3HfffXHKKafEmWeeGbfddlv885//HIopj1j9WYuqqqrYtWtXNDQ0RJZl8cEHH8Rzzz0XV1xxxVBMmf8wUK/d/fp16IHU3t4eBw4c6PUjjWVlZb1+nPGQtra2Pvffv39/tLe3R3l5+aDNdyTrz1r8t/vvvz8++eSTuPrqqwdjiqNGf9bi73//e9x5553R1NQUBQXD/qc9YvRnLbZv3x6vvvpqFBcXxwsvvBDt7e3x/e9/Pz788EPvc/kC+rMWVVVVsWbNmpg/f37861//iv3798dVV10Vv/zlL4diyvyHgXrtHvYzLofk5eX1uJ1lWa+x/7V/X+PkLte1OOSZZ56Jn/3sZ7F27do46aSTBmt6o8qRrsWBAwfimmuuieXLl8eZZ545VNMbVXL5uzh48GDk5eXFmjVrYubMmXH55ZfHAw88EE8++aSzLgMgl7XYunVrLFy4MO66667YvHlzvPzyy7Fjxw4/OzNMBuK1e9j/t2z8+PGRn5/fq5Z3797dq8wOOfnkk/vcv6CgIMaNGzdocx3p+rMWh6xduzZuvPHGePbZZ+OSSy4ZzGmOCrmuxd69e2PTpk3R3Nwct9xyS0R89uKZZVkUFBTE+vXr4+KLLx6SuY80/fm7KC8vj1NOOSVKS0u7x6ZNmxZZlsWuXbvijDPOGNQ5j1T9WYv6+vqYM2dO3H777RERce6558Zxxx0X1dXVcc899zhDP4QG6rV72M+4FBYWRkVFRTQ2NvYYb2xsjKqqqj6PmT17dq/9169fH5WVlTF27NhBm+tI15+1iPjsTMv1118fTz/9tOvGAyTXtSgpKYk333wztmzZ0r3V1tbGV7/61diyZUvMmjVrqKY+4vTn72LOnDnx/vvvx8cff9w99vbbb8eYMWNi4sSJgzrfkaw/a/Hpp5/GmDE9X+ry8/Mj4v//3z5DY8Beu3N6K+8gOfTxtlWrVmVbt27NFi1alB133HHZP/7xjyzLsuzOO+/Mrr322u79D32kavHixdnWrVuzVatW+Tj0AMl1LZ5++umsoKAge+SRR7LW1tbu7aOPPhqupzBi5LoW/82nigZOrmuxd+/ebOLEidm3v/3t7K233so2bNiQnXHGGdlNN900XE9hxMh1LZ544omsoKAgW7FiRfbOO+9kr776alZZWZnNnDlzuJ7CiLF3796subk5a25uziIie+CBB7Lm5ubuj6YP1mv3UREuWZZljzzySDZ58uSssLAwmzFjRrZhw4buf3bddddlF154YY/9//jHP2Zf+9rXssLCwuy0007LVq5cOcQzHrlyWYsLL7wwi4he23XXXTf0Ex+Bcv27+E/CZWDluhbbtm3LLrnkkuyYY47JJk6cmNXV1WWffvrpEM96ZMp1LR566KHs7LPPzo455pisvLw8++53v5vt2rVriGc98vzhD3/43P/+D9Zrd16WOVcGAKRh2N/jAgBwpIQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAk4/8BrQWhjBP+6s8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "img3 = ax.imshow(np.transpose(u_pred.reshape(500,500)),vmin = 0,vmax = 500,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + train_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
