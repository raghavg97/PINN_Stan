{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "#     y = xt[:,0]*np.cos(xt[:,1])\n",
    "#     return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 25000\n",
    "label = \"ES_stan_high\"\n",
    "ES_val = 1000.0\n",
    "\n",
    "x = np.linspace(0,1,500).reshape(-1,1)\n",
    "y = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xy = np.hstack((X,Y))\n",
    "\n",
    "# bound_pts_1 = (X == 0).reshape(-1,)\n",
    "# bound_pts_2 = np.logical_and(Y == 0,X != 0).reshape(-1,)\n",
    "# bound_pts_3 = np.logical_and(X == 1,Y != 0).reshape(-1,) \n",
    "# bound_pts_4 = np.logical_and(Y == 1,X != 1).reshape(-1,) \n",
    "\n",
    "# xy_bound_1 = xy[bound_pts_1,:]\n",
    "# xy_bound_2 = xy[bound_pts_2,:]\n",
    "# xy_bound_3 = xy[bound_pts_3,:]\n",
    "# xy_bound_4 = xy[bound_pts_4,:]\n",
    "\n",
    "# u_bound_1 = 1000*np.ones((np.shape(xy_bound_1)[0],1))\n",
    "# u_bound_2 = 800*np.ones((np.shape(xy_bound_2)[0],1))\n",
    "# u_bound_3 = 500*np.ones((np.shape(xy_bound_3)[0],1))\n",
    "# u_bound_4 = np.zeros((np.shape(xy_bound_4)[0],1))\n",
    "\n",
    "# xy_bound = np.vstack((xy_bound_1,xy_bound_2,xy_bound_3,xy_bound_4))\n",
    "# u_bound = np.vstack((u_bound_1,u_bound_2,u_bound_3,u_bound_4))\n",
    "\n",
    "# xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "\n",
    "lb_xy = xy[0]\n",
    "ub_xy = xy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_data = scipy.io.loadmat('./../ES_FEA_high.mat')\n",
    "\n",
    "xy = np.array(fea_data['xy'])\n",
    "u_true = np.array(fea_data['u'])\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "u_true_norm = np.linalg.norm(u_true,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_T,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    N_t = int(N_T/4)\n",
    "    \n",
    "    x_BC1 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC1 = np.zeros((N_t,1))\n",
    "    u_BC1 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC2 = np.ones((N_t,1))\n",
    "    y_BC2 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC2 = ES_val*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC3 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC3 = np.ones((N_t,1)) \n",
    "    u_BC3 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC4 = np.zeros((N_t,1))\n",
    "    y_BC4 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC4 = ES_val*np.ones((N_t,1))\n",
    "    \n",
    "    XY_corners = np.array([[0,0],[1,0],[0,1],[1,1]]).reshape(-1,2)\n",
    "    U_corners = ES_val*np.ones((4,1))\n",
    "    \n",
    "    XY_1 = np.hstack((x_BC1,y_BC1))\n",
    "    XY_2 = np.hstack((x_BC2,y_BC2))\n",
    "    XY_3 = np.hstack((x_BC3,y_BC3))\n",
    "    XY_4 = np.hstack((x_BC4,y_BC4))\n",
    "    \n",
    "    xy_BC = np.vstack((XY_1,XY_2,XY_3,XY_4,XY_corners)) #choose indices from  set 'idx' (x,t)\n",
    "    u_BC = np.vstack((u_BC1,u_BC2,u_BC3,u_BC4,U_corners))\n",
    "    \n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xy_coll = lb_xy + (ub_xy - lb_xy)*samples\n",
    "    \n",
    "    xy_coll = np.vstack((xy_coll, xy_BC)) # append training points to collocation points \n",
    "\n",
    "    return xy_coll, xy_BC, u_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "            \n",
    "        beta_mean = beta_init*torch.ones((50,len(layers)-2))\n",
    "        beta_std = 0.1*torch.ones((50,len(layers)-2))\n",
    "        \n",
    "        self.beta = Parameter(torch.normal(beta_mean,beta_std))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xy):\n",
    "        if torch.is_tensor(xy) != True:         \n",
    "            xy = torch.from_numpy(xy)                \n",
    "        \n",
    "        ubxy = torch.from_numpy(ub_xy).float().to(device)\n",
    "        lbxy = torch.from_numpy(lb_xy).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xy = 2.0*(xy - lbxy)/(ubxy - lbxy) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xy.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            z1 =self.activation(z)\n",
    "            a = z1 + self.beta[:,i]*z*z1\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xy,u):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xy), u)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xy_coll, f_hat):\n",
    "        \n",
    "        g = xy_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy = autograd.grad(u_x_y,g,torch.ones(xy_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2u_dx2 + d2u_dy2\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xy_BC,u_BC,xy_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xy_BC,u_BC)\n",
    "        loss_f = self.loss_PDE(xy_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    'callable for optimizer'  \n",
    "    def closure(self):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = self.loss(xy_BC, u_BC, xy_coll,f_hat)\n",
    "        self.train_loss.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        u_pred = self.test(xy_test_tensor)\n",
    "        #self.test_loss.append(np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))) #Commented because no true values yet\n",
    "        self.beta_val.append(self.beta.cpu().detach().numpy())\n",
    "        \n",
    "        #print(self.iter,\"Train Loss\",self.train_loss[-1],\"Test Loss\",self.test_loss[-1])\n",
    "        print(self.iter,\"Train Loss\",self.train_loss[-1])\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        self.iter += 1\n",
    "  \n",
    "\n",
    "        return loss        \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        u_pred = self.forward(xy_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "        \n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xy_BC,u_BC,xy_coll,f_hat,seed):\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xy_BC,u_BC,xy_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xy_coll_np_array, xy_BC_np_array, u_BC_np_array = trainingdata(N_T,N_f,rep*22)\n",
    "        \n",
    "    xy_coll = torch.from_numpy(xy_coll_np_array).float().to(device)\n",
    "    xy_BC = torch.from_numpy(xy_BC_np_array).float().to(device)\n",
    "    u_BC = torch.from_numpy(u_BC_np_array).float().to(device)\n",
    "        \n",
    "    f_hat = torch.zeros(xy_coll.shape[0],1).to(device)\n",
    "    \n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(xy_BC,u_BC,xy_coll,f_hat,i)\n",
    "        loss_np = PINN.loss(xy_BC,u_BC,xy_coll,f_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES_stan_high\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 243416.56 Test MSE 71842.30012549386 Test RE 0.4689495851887354\n",
      "1 Train Loss 193995.98 Test MSE 50701.26868501582 Test RE 0.39395394626770325\n",
      "2 Train Loss 141886.45 Test MSE 31977.19641607907 Test RE 0.31286446149212616\n",
      "3 Train Loss 112557.64 Test MSE 27115.272473332567 Test RE 0.28809984742949724\n",
      "4 Train Loss 96664.63 Test MSE 26137.956771344325 Test RE 0.2828602100392478\n",
      "5 Train Loss 86264.18 Test MSE 23971.0097121029 Test RE 0.2708814127466509\n",
      "6 Train Loss 77025.97 Test MSE 18398.152307842643 Test RE 0.23731388371635206\n",
      "7 Train Loss 71032.27 Test MSE 17502.842938718743 Test RE 0.23146766984588282\n",
      "8 Train Loss 65906.63 Test MSE 16049.199120881254 Test RE 0.22164744249763796\n",
      "9 Train Loss 62730.863 Test MSE 14449.57430641563 Test RE 0.2103117650292211\n",
      "10 Train Loss 60086.7 Test MSE 13670.612271466443 Test RE 0.20456438511564823\n",
      "11 Train Loss 57514.316 Test MSE 12253.516883013384 Test RE 0.19367181322287533\n",
      "12 Train Loss 55922.504 Test MSE 11660.480135568801 Test RE 0.1889271001258421\n",
      "13 Train Loss 54596.04 Test MSE 10878.179653746805 Test RE 0.18247953068257447\n",
      "14 Train Loss 53745.062 Test MSE 10739.961250249875 Test RE 0.18131653001524978\n",
      "15 Train Loss 52643.266 Test MSE 10264.77943234864 Test RE 0.17726004398293263\n",
      "16 Train Loss 51871.145 Test MSE 10542.337017504324 Test RE 0.17964059698927012\n",
      "17 Train Loss 51258.875 Test MSE 10526.675863066348 Test RE 0.1795071149749025\n",
      "18 Train Loss 50718.86 Test MSE 10166.536514231897 Test RE 0.1764097377095675\n",
      "19 Train Loss 50154.086 Test MSE 10065.312318526956 Test RE 0.17552931963076526\n",
      "20 Train Loss 49710.723 Test MSE 9708.957689011744 Test RE 0.17239407919514887\n",
      "21 Train Loss 49172.13 Test MSE 9675.13910375642 Test RE 0.17209357270225248\n",
      "22 Train Loss 48728.582 Test MSE 9409.074543335288 Test RE 0.16971080616579054\n",
      "23 Train Loss 48312.43 Test MSE 9292.342390870168 Test RE 0.16865477582392746\n",
      "24 Train Loss 47891.414 Test MSE 9293.358806443044 Test RE 0.168663999475294\n",
      "25 Train Loss 47398.05 Test MSE 9089.353221178959 Test RE 0.16680249109379416\n",
      "26 Train Loss 47009.12 Test MSE 9181.726477984703 Test RE 0.16764793847145656\n",
      "27 Train Loss 46594.42 Test MSE 9250.81632753392 Test RE 0.16827750760613894\n",
      "28 Train Loss 46104.137 Test MSE 9067.019824158124 Test RE 0.16659744034292512\n",
      "29 Train Loss 45733.68 Test MSE 9077.72164428645 Test RE 0.16669572898111007\n",
      "30 Train Loss 45364.277 Test MSE 9099.760276425768 Test RE 0.16689795586925196\n",
      "31 Train Loss 45029.656 Test MSE 9140.256764673502 Test RE 0.16726891499184113\n",
      "32 Train Loss 44750.188 Test MSE 8991.460594437365 Test RE 0.16590182538035936\n",
      "33 Train Loss 44508.566 Test MSE 9075.616472194697 Test RE 0.16667639904581258\n",
      "34 Train Loss 44036.188 Test MSE 8891.570794962743 Test RE 0.16497771614679121\n",
      "35 Train Loss 43723.18 Test MSE 8786.785643209801 Test RE 0.16400272256921097\n",
      "36 Train Loss 43347.082 Test MSE 8810.669668249107 Test RE 0.16422546539570135\n",
      "37 Train Loss 43087.434 Test MSE 8700.288230191414 Test RE 0.16319350199030588\n",
      "38 Train Loss 42760.35 Test MSE 8699.342209979523 Test RE 0.16318462937918107\n",
      "39 Train Loss 42493.07 Test MSE 8319.473500000004 Test RE 0.15958202187581655\n",
      "40 Train Loss 42201.414 Test MSE 8110.209231587351 Test RE 0.1575622126922615\n",
      "41 Train Loss 41947.395 Test MSE 8012.029170687835 Test RE 0.15660560540487992\n",
      "42 Train Loss 41715.496 Test MSE 7791.798822979554 Test RE 0.1544382626209948\n",
      "43 Train Loss 41482.39 Test MSE 7766.731132026996 Test RE 0.15418963393391924\n",
      "44 Train Loss 41261.25 Test MSE 7719.880477679856 Test RE 0.15372387735473092\n",
      "45 Train Loss 41070.996 Test MSE 7574.146002919555 Test RE 0.15226597863515673\n",
      "46 Train Loss 40814.375 Test MSE 7492.062774858179 Test RE 0.15143865564637993\n",
      "47 Train Loss 40543.094 Test MSE 7349.205583783134 Test RE 0.14998790533781467\n",
      "48 Train Loss 40318.3 Test MSE 7310.771362699231 Test RE 0.1495951945265802\n",
      "49 Train Loss 40142.496 Test MSE 7361.456290185388 Test RE 0.15011286392513895\n",
      "50 Train Loss 39987.28 Test MSE 7290.032091134562 Test RE 0.1493828572345085\n",
      "51 Train Loss 39886.766 Test MSE 7249.4706598625535 Test RE 0.14896669759287873\n",
      "52 Train Loss 39753.15 Test MSE 7207.773609567768 Test RE 0.1485376711410709\n",
      "53 Train Loss 39628.145 Test MSE 7263.924885297966 Test RE 0.14911513091444056\n",
      "54 Train Loss 39466.285 Test MSE 7234.770795204855 Test RE 0.14881558990579566\n",
      "55 Train Loss 39294.33 Test MSE 7218.382626479255 Test RE 0.14864694616227167\n",
      "56 Train Loss 39048.047 Test MSE 7010.565788592441 Test RE 0.14649155074619535\n",
      "57 Train Loss 38845.883 Test MSE 7030.6295603941535 Test RE 0.14670102550245281\n",
      "58 Train Loss 38639.51 Test MSE 6888.567208999354 Test RE 0.14521132621258445\n",
      "59 Train Loss 38424.38 Test MSE 6851.267441551829 Test RE 0.14481765213818362\n",
      "60 Train Loss 38220.777 Test MSE 6670.344747318959 Test RE 0.1428927459341467\n",
      "61 Train Loss 37952.13 Test MSE 6578.6306921078685 Test RE 0.14190699228269701\n",
      "62 Train Loss 37750.83 Test MSE 6580.419457882172 Test RE 0.14192628361626955\n",
      "63 Train Loss 37555.824 Test MSE 6534.626877361468 Test RE 0.14143159500864502\n",
      "64 Train Loss 37343.26 Test MSE 6578.164927674034 Test RE 0.1419019687145009\n",
      "65 Train Loss 37142.805 Test MSE 6660.81077192129 Test RE 0.1427905905641177\n",
      "66 Train Loss 37007.86 Test MSE 6719.128486156106 Test RE 0.14341431893364784\n",
      "67 Train Loss 36825.81 Test MSE 6612.030312863864 Test RE 0.14226676617768513\n",
      "68 Train Loss 36665.914 Test MSE 6542.705015542743 Test RE 0.14151898722819506\n",
      "69 Train Loss 36445.383 Test MSE 6423.8194626690865 Test RE 0.14022734303035392\n",
      "70 Train Loss 36224.023 Test MSE 6414.766850912915 Test RE 0.14012850220497197\n",
      "71 Train Loss 36014.508 Test MSE 6328.927315584334 Test RE 0.13918777610176714\n",
      "72 Train Loss 35816.336 Test MSE 6242.86894811633 Test RE 0.13823822569543298\n",
      "73 Train Loss 35635.22 Test MSE 6220.126141147041 Test RE 0.1379861946284023\n",
      "74 Train Loss 35469.477 Test MSE 6257.192568707935 Test RE 0.1383967215285052\n",
      "75 Train Loss 35290.85 Test MSE 6145.592524078005 Test RE 0.1371569827145401\n",
      "76 Train Loss 35116.3 Test MSE 6083.167509759509 Test RE 0.13645860576314756\n",
      "77 Train Loss 34904.996 Test MSE 6059.916418576517 Test RE 0.13619756995661864\n",
      "78 Train Loss 34644.395 Test MSE 6080.424966326557 Test RE 0.1364278417045264\n",
      "79 Train Loss 34375.54 Test MSE 6032.879442334764 Test RE 0.135893400169379\n",
      "80 Train Loss 34197.57 Test MSE 6084.618485804828 Test RE 0.1364748790584699\n",
      "81 Train Loss 34046.832 Test MSE 6062.747770183405 Test RE 0.13622938377624277\n",
      "82 Train Loss 33849.746 Test MSE 5954.6700016868945 Test RE 0.13500967478720305\n",
      "83 Train Loss 33689.043 Test MSE 5878.375309001059 Test RE 0.1341419752514177\n",
      "84 Train Loss 33524.223 Test MSE 5756.72497856345 Test RE 0.1327467150512464\n",
      "85 Train Loss 33397.945 Test MSE 5790.568605747763 Test RE 0.1331363503627179\n",
      "86 Train Loss 33219.586 Test MSE 5822.139545979224 Test RE 0.13349879543996446\n",
      "87 Train Loss 33050.96 Test MSE 5819.776904278055 Test RE 0.13347170558547639\n",
      "88 Train Loss 32879.293 Test MSE 5837.7155740453 Test RE 0.1336772514936374\n",
      "89 Train Loss 32651.232 Test MSE 5782.387283229374 Test RE 0.13304226491937515\n",
      "90 Train Loss 32487.133 Test MSE 5744.302213607201 Test RE 0.1326034068448649\n",
      "91 Train Loss 32226.545 Test MSE 5708.158564371882 Test RE 0.13218557245949608\n",
      "92 Train Loss 32055.797 Test MSE 5722.723412772361 Test RE 0.13235410634381123\n",
      "93 Train Loss 31847.814 Test MSE 5753.256578131758 Test RE 0.13270671938214182\n",
      "94 Train Loss 31621.584 Test MSE 5702.6105878143235 Test RE 0.13212131874865823\n",
      "95 Train Loss 31458.146 Test MSE 5718.521792943689 Test RE 0.13230551027273144\n",
      "96 Train Loss 31257.977 Test MSE 5717.248723880857 Test RE 0.1322907823908245\n",
      "97 Train Loss 31063.717 Test MSE 5824.669426554105 Test RE 0.13352779674831058\n",
      "98 Train Loss 30900.482 Test MSE 5808.846965065638 Test RE 0.133346312185884\n",
      "99 Train Loss 30765.39 Test MSE 5816.556121280395 Test RE 0.13343476749488378\n",
      "100 Train Loss 30539.732 Test MSE 5746.606622617855 Test RE 0.13263000205470651\n",
      "101 Train Loss 30320.648 Test MSE 5727.169457516996 Test RE 0.13240551001887738\n",
      "102 Train Loss 30105.105 Test MSE 5613.3048118846 Test RE 0.1310826928983367\n",
      "103 Train Loss 29849.297 Test MSE 5533.079025803205 Test RE 0.13014259985203852\n",
      "104 Train Loss 29629.5 Test MSE 5663.289326811137 Test RE 0.13166502216526682\n",
      "105 Train Loss 29442.814 Test MSE 5816.268501192996 Test RE 0.13343146837826386\n",
      "106 Train Loss 29309.0 Test MSE 5837.334186850167 Test RE 0.1336728847491397\n",
      "107 Train Loss 29136.377 Test MSE 5766.490284492227 Test RE 0.1328592584687911\n",
      "108 Train Loss 28981.418 Test MSE 5818.430711083245 Test RE 0.13345626778636097\n",
      "109 Train Loss 28819.92 Test MSE 5777.774469326435 Test RE 0.13298918808272955\n",
      "110 Train Loss 28620.467 Test MSE 5750.233882873211 Test RE 0.1326718535051042\n",
      "111 Train Loss 28447.424 Test MSE 5596.4635927438685 Test RE 0.1308859059126095\n",
      "112 Train Loss 28306.14 Test MSE 5592.185962994777 Test RE 0.13083587534757854\n",
      "113 Train Loss 28170.871 Test MSE 5496.037730589884 Test RE 0.12970624736728428\n",
      "114 Train Loss 28038.523 Test MSE 5462.444192250554 Test RE 0.12930923676397169\n",
      "115 Train Loss 27964.13 Test MSE 5439.147820211356 Test RE 0.129033201464786\n",
      "116 Train Loss 27869.736 Test MSE 5458.294954021063 Test RE 0.12926011619307387\n",
      "117 Train Loss 27773.18 Test MSE 5378.460644896577 Test RE 0.12831133968646288\n",
      "118 Train Loss 27613.943 Test MSE 5482.8119688085635 Test RE 0.12955008966899095\n",
      "119 Train Loss 27429.89 Test MSE 5587.064251139819 Test RE 0.13077594733727876\n",
      "120 Train Loss 27273.613 Test MSE 5596.884874620414 Test RE 0.13089083213266778\n",
      "121 Train Loss 27012.785 Test MSE 5641.150391076635 Test RE 0.13140741765020492\n",
      "122 Train Loss 26829.11 Test MSE 5621.920625005504 Test RE 0.13118325317299367\n",
      "123 Train Loss 26592.799 Test MSE 5503.214503403247 Test RE 0.1297909054999663\n",
      "124 Train Loss 26384.162 Test MSE 5395.703122435594 Test RE 0.12851684784402928\n",
      "125 Train Loss 26199.74 Test MSE 5290.768187974303 Test RE 0.12726102259040542\n",
      "126 Train Loss 26003.363 Test MSE 5330.943399160969 Test RE 0.12774328425033357\n",
      "127 Train Loss 25782.756 Test MSE 5492.346078885295 Test RE 0.12966267864137168\n",
      "128 Train Loss 25571.566 Test MSE 5537.556319695408 Test RE 0.13019524403413046\n",
      "129 Train Loss 25447.121 Test MSE 5539.245423554382 Test RE 0.13021509904860895\n",
      "130 Train Loss 25308.629 Test MSE 5509.2534094034345 Test RE 0.1298620984520742\n",
      "131 Train Loss 25147.814 Test MSE 5592.986655764336 Test RE 0.13084524159455907\n",
      "132 Train Loss 24986.113 Test MSE 5620.412531628201 Test RE 0.13116565688536952\n",
      "133 Train Loss 24856.023 Test MSE 5588.0929586588045 Test RE 0.1307879862187309\n",
      "134 Train Loss 24713.469 Test MSE 5534.367963532422 Test RE 0.13015775741063654\n",
      "135 Train Loss 24570.783 Test MSE 5505.145589424498 Test RE 0.12981367541196412\n",
      "136 Train Loss 24441.8 Test MSE 5625.399277022972 Test RE 0.13122383274966723\n",
      "137 Train Loss 24314.947 Test MSE 5649.507232284787 Test RE 0.13150471558108343\n",
      "138 Train Loss 24222.414 Test MSE 5666.210596849514 Test RE 0.13169897588673143\n",
      "139 Train Loss 24115.215 Test MSE 5761.425994871086 Test RE 0.13280090533529273\n",
      "140 Train Loss 24024.486 Test MSE 5724.542857696374 Test RE 0.1323751445674128\n",
      "141 Train Loss 23906.352 Test MSE 5720.608836764669 Test RE 0.13232965131986563\n",
      "142 Train Loss 23775.299 Test MSE 5703.387067581327 Test RE 0.13213031340446132\n",
      "143 Train Loss 23676.273 Test MSE 5758.896217993498 Test RE 0.1327717464476555\n",
      "144 Train Loss 23573.758 Test MSE 5759.221344852826 Test RE 0.13277549430575536\n",
      "145 Train Loss 23453.582 Test MSE 5706.18383236904 Test RE 0.132162705745382\n",
      "146 Train Loss 23330.363 Test MSE 5658.2177823198745 Test RE 0.13160605514630191\n",
      "147 Train Loss 23253.453 Test MSE 5737.028471327116 Test RE 0.13251942549281578\n",
      "148 Train Loss 23170.281 Test MSE 5811.903717623203 Test RE 0.1333813925619297\n",
      "149 Train Loss 23039.7 Test MSE 5945.731237838 Test RE 0.13490830285223873\n",
      "150 Train Loss 22957.428 Test MSE 5989.469996373609 Test RE 0.13540360858222308\n",
      "151 Train Loss 22875.414 Test MSE 6000.7179154179385 Test RE 0.13553068948136435\n",
      "152 Train Loss 22808.291 Test MSE 6064.034176898772 Test RE 0.1362438357298545\n",
      "153 Train Loss 22731.607 Test MSE 6126.536957686882 Test RE 0.136944177104687\n",
      "154 Train Loss 22664.47 Test MSE 6220.038222770631 Test RE 0.1379852194419839\n",
      "155 Train Loss 22604.04 Test MSE 6223.925094227661 Test RE 0.13802832585309258\n",
      "156 Train Loss 22513.932 Test MSE 6064.540807262573 Test RE 0.13624952697601161\n",
      "157 Train Loss 22443.133 Test MSE 6033.595690974503 Test RE 0.13590146684592738\n",
      "158 Train Loss 22356.955 Test MSE 6047.56256688413 Test RE 0.13605867175527148\n",
      "159 Train Loss 22277.445 Test MSE 6123.91608370557 Test RE 0.13691488226599657\n",
      "160 Train Loss 22174.463 Test MSE 6070.896743426439 Test RE 0.13632090637152525\n",
      "161 Train Loss 22076.645 Test MSE 6089.618993081104 Test RE 0.13653094695099185\n",
      "162 Train Loss 21965.21 Test MSE 6047.2861190777785 Test RE 0.13605556194443605\n",
      "163 Train Loss 21834.73 Test MSE 5893.382640141539 Test RE 0.1343130964982383\n",
      "164 Train Loss 21687.502 Test MSE 5795.244411747803 Test RE 0.13319009241897042\n",
      "165 Train Loss 21541.209 Test MSE 5786.943438344618 Test RE 0.13309466903976933\n",
      "166 Train Loss 21472.979 Test MSE 5742.214663362108 Test RE 0.1325793097989273\n",
      "167 Train Loss 21381.123 Test MSE 5741.608507874507 Test RE 0.13257231199391448\n",
      "168 Train Loss 21297.836 Test MSE 5854.9151815854975 Test RE 0.133874032683012\n",
      "169 Train Loss 21181.389 Test MSE 5924.45599430423 Test RE 0.1346667195163822\n",
      "170 Train Loss 21110.656 Test MSE 6003.483388318447 Test RE 0.1355619160180166\n",
      "171 Train Loss 21035.42 Test MSE 6060.510558427343 Test RE 0.1362042464860425\n",
      "172 Train Loss 20963.475 Test MSE 5928.1139028109865 Test RE 0.1347082864152792\n",
      "173 Train Loss 20882.21 Test MSE 5880.38457579222 Test RE 0.13416489859115205\n",
      "174 Train Loss 20806.78 Test MSE 5926.232887188196 Test RE 0.1346869129650628\n",
      "175 Train Loss 20717.059 Test MSE 5915.17448284144 Test RE 0.1345611907870723\n",
      "176 Train Loss 20646.47 Test MSE 5878.189901392787 Test RE 0.13413985977412957\n",
      "177 Train Loss 20558.768 Test MSE 5915.3097430477865 Test RE 0.13456272925989657\n",
      "178 Train Loss 20476.047 Test MSE 5796.4512234454205 Test RE 0.13320395956442946\n",
      "179 Train Loss 20422.713 Test MSE 5810.641194780461 Test RE 0.13336690452071925\n",
      "180 Train Loss 20363.648 Test MSE 5789.185064417174 Test RE 0.13312044426956032\n",
      "181 Train Loss 20270.762 Test MSE 5820.293262039408 Test RE 0.13347762657038648\n",
      "182 Train Loss 20204.791 Test MSE 5774.431835259065 Test RE 0.13295071319018364\n",
      "183 Train Loss 20142.977 Test MSE 5759.8997320792405 Test RE 0.1327833139867172\n",
      "184 Train Loss 20084.799 Test MSE 5691.871723546139 Test RE 0.13199685807532527\n",
      "185 Train Loss 20023.148 Test MSE 5749.191932885457 Test RE 0.13265983280284066\n",
      "186 Train Loss 19953.074 Test MSE 5877.962783700509 Test RE 0.13413726834460896\n",
      "187 Train Loss 19840.81 Test MSE 5974.61837119569 Test RE 0.13523562946225903\n",
      "188 Train Loss 19767.83 Test MSE 5920.721397729653 Test RE 0.13462426792655047\n",
      "189 Train Loss 19664.416 Test MSE 5979.79781794362 Test RE 0.13529423521394968\n",
      "190 Train Loss 19567.117 Test MSE 5948.612698185887 Test RE 0.13494098897809423\n",
      "191 Train Loss 19472.404 Test MSE 5849.491586497988 Test RE 0.1338120124189392\n",
      "192 Train Loss 19373.186 Test MSE 5857.380798212603 Test RE 0.1339022181722152\n",
      "193 Train Loss 19315.326 Test MSE 5920.141150280402 Test RE 0.1346176709853333\n",
      "194 Train Loss 19253.71 Test MSE 5954.245611278711 Test RE 0.13500486361950612\n",
      "195 Train Loss 19175.307 Test MSE 6033.889288862123 Test RE 0.13590477332354473\n",
      "196 Train Loss 19075.377 Test MSE 6016.485109685563 Test RE 0.1357086295922402\n",
      "197 Train Loss 19018.83 Test MSE 6057.79793149996 Test RE 0.13617376121130403\n",
      "198 Train Loss 18931.822 Test MSE 6115.5176101276365 Test RE 0.13682096601066945\n",
      "199 Train Loss 18840.357 Test MSE 6186.487776235658 Test RE 0.1376125749977165\n",
      "Training time: 187.51\n",
      "Training time: 187.51\n",
      "ES_stan_high\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 242937.73 Test MSE 72206.23289899739 Test RE 0.47013586772709953\n",
      "1 Train Loss 196029.6 Test MSE 53717.095034513884 Test RE 0.405501346873433\n",
      "2 Train Loss 140055.94 Test MSE 32017.585194768446 Test RE 0.3130619807775565\n",
      "3 Train Loss 94150.04 Test MSE 23313.398246800916 Test RE 0.26713994553574066\n",
      "4 Train Loss 80638.37 Test MSE 21601.529826352053 Test RE 0.25714512564174347\n",
      "5 Train Loss 70956.59 Test MSE 16361.770162884888 Test RE 0.22379541552802606\n",
      "6 Train Loss 64854.438 Test MSE 13861.12282332367 Test RE 0.20598483490716052\n",
      "7 Train Loss 60217.69 Test MSE 13901.577425878266 Test RE 0.20628520607705264\n",
      "8 Train Loss 57109.062 Test MSE 11862.951752750843 Test RE 0.19056029826519397\n",
      "9 Train Loss 55284.42 Test MSE 10998.960307927673 Test RE 0.1834897712487149\n",
      "10 Train Loss 53739.816 Test MSE 10492.802940431779 Test RE 0.17921807169039763\n",
      "11 Train Loss 52760.727 Test MSE 10558.547715212297 Test RE 0.1797786584457868\n",
      "12 Train Loss 51785.65 Test MSE 9842.312670827056 Test RE 0.17357397952762957\n",
      "13 Train Loss 51108.47 Test MSE 9798.488857825165 Test RE 0.17318712126908342\n",
      "14 Train Loss 50333.73 Test MSE 9744.667755963048 Test RE 0.17271082554327447\n",
      "15 Train Loss 49694.453 Test MSE 9539.052848991558 Test RE 0.17087899034957174\n",
      "16 Train Loss 49157.195 Test MSE 9341.84617981672 Test RE 0.1691034226756916\n",
      "17 Train Loss 48619.65 Test MSE 9261.002753334344 Test RE 0.16837013049833144\n",
      "18 Train Loss 48334.766 Test MSE 9087.82033147737 Test RE 0.16678842515335826\n",
      "19 Train Loss 47780.1 Test MSE 8858.510275154114 Test RE 0.16467072154453988\n",
      "20 Train Loss 47309.13 Test MSE 8951.091236649761 Test RE 0.16552897803558397\n",
      "21 Train Loss 46888.047 Test MSE 8682.255358721743 Test RE 0.16302429070429775\n",
      "22 Train Loss 46287.02 Test MSE 8464.558033906198 Test RE 0.16096749490554702\n",
      "23 Train Loss 45830.043 Test MSE 8516.663179854377 Test RE 0.1614621673422936\n",
      "24 Train Loss 45392.734 Test MSE 8400.678742084732 Test RE 0.1603589597199525\n",
      "25 Train Loss 44998.203 Test MSE 8437.905501055242 Test RE 0.16071387422563788\n",
      "26 Train Loss 44728.254 Test MSE 8593.723445476086 Test RE 0.1621909914596331\n",
      "27 Train Loss 44432.71 Test MSE 8570.438032297407 Test RE 0.16197110737467393\n",
      "28 Train Loss 44164.125 Test MSE 8571.223375509659 Test RE 0.16197852823200853\n",
      "29 Train Loss 43772.023 Test MSE 8542.40743990217 Test RE 0.16170601798118672\n",
      "30 Train Loss 43407.52 Test MSE 8461.823867169114 Test RE 0.16094149546677947\n",
      "31 Train Loss 43169.51 Test MSE 8389.795389039808 Test RE 0.16025505092594625\n",
      "32 Train Loss 42817.184 Test MSE 8305.017671307385 Test RE 0.15944331758465707\n",
      "33 Train Loss 42515.66 Test MSE 8142.533457886747 Test RE 0.1578758921419963\n",
      "34 Train Loss 42257.36 Test MSE 8083.081719752409 Test RE 0.1572984802245447\n",
      "35 Train Loss 41870.273 Test MSE 8092.346658273138 Test RE 0.1573886032386791\n",
      "36 Train Loss 41535.008 Test MSE 7791.947772537872 Test RE 0.15443973875003722\n",
      "37 Train Loss 41245.21 Test MSE 7708.590975639955 Test RE 0.15361143384088005\n",
      "38 Train Loss 41011.29 Test MSE 7517.666044336451 Test RE 0.1516971971119153\n",
      "39 Train Loss 40857.816 Test MSE 7528.201445343325 Test RE 0.15180345557378283\n",
      "40 Train Loss 40648.71 Test MSE 7470.664017587772 Test RE 0.15122223218709155\n",
      "41 Train Loss 40386.332 Test MSE 7309.692179019639 Test RE 0.14958415282915197\n",
      "42 Train Loss 40225.03 Test MSE 7292.799711031324 Test RE 0.14941121072668986\n",
      "43 Train Loss 40031.68 Test MSE 7217.694839718764 Test RE 0.14863986425470824\n",
      "44 Train Loss 39797.03 Test MSE 7138.4172688823855 Test RE 0.14782129653672163\n",
      "45 Train Loss 39570.523 Test MSE 7184.590475756092 Test RE 0.14829859994276917\n",
      "46 Train Loss 39330.875 Test MSE 7118.204618430303 Test RE 0.14761186788201144\n",
      "47 Train Loss 39091.27 Test MSE 7142.966959360962 Test RE 0.1478683961942991\n",
      "48 Train Loss 38881.848 Test MSE 7165.50531544524 Test RE 0.14810149861393854\n",
      "49 Train Loss 38726.152 Test MSE 7234.832280754452 Test RE 0.14881622226783953\n",
      "50 Train Loss 38526.195 Test MSE 7339.642851158329 Test RE 0.14989029199060067\n",
      "51 Train Loss 38337.992 Test MSE 7399.008256974864 Test RE 0.1504952517628237\n",
      "52 Train Loss 38161.93 Test MSE 7491.618554224773 Test RE 0.1514341660168371\n",
      "53 Train Loss 37998.816 Test MSE 7506.185346423855 Test RE 0.15158131971627195\n",
      "54 Train Loss 37696.38 Test MSE 7531.732525299229 Test RE 0.15183905287428118\n",
      "55 Train Loss 37500.23 Test MSE 7322.101764051846 Test RE 0.14971107268030115\n",
      "56 Train Loss 37316.945 Test MSE 7289.45612410199 Test RE 0.14937695593672043\n",
      "57 Train Loss 37139.285 Test MSE 7300.552440717883 Test RE 0.14949060664382735\n",
      "58 Train Loss 36990.4 Test MSE 7318.866104074883 Test RE 0.1496779901263123\n",
      "59 Train Loss 36862.055 Test MSE 7250.00563801102 Test RE 0.14897219402576276\n",
      "60 Train Loss 36713.13 Test MSE 7202.8103102600535 Test RE 0.148486520541731\n",
      "61 Train Loss 36586.613 Test MSE 7078.391558489354 Test RE 0.14719848269129313\n",
      "62 Train Loss 36431.082 Test MSE 7025.1670650007245 Test RE 0.14664402424929857\n",
      "63 Train Loss 36181.98 Test MSE 7039.063684982557 Test RE 0.1467889922958565\n",
      "64 Train Loss 36060.008 Test MSE 6885.864682515528 Test RE 0.14518283872448973\n",
      "65 Train Loss 35927.547 Test MSE 6910.41243003337 Test RE 0.14544139311035786\n",
      "66 Train Loss 35767.734 Test MSE 6857.92506576608 Test RE 0.14488799732662455\n",
      "67 Train Loss 35651.137 Test MSE 6833.988096867458 Test RE 0.14463491705179207\n",
      "68 Train Loss 35465.96 Test MSE 6774.938454890381 Test RE 0.1440086963799279\n",
      "69 Train Loss 35294.21 Test MSE 6880.5571993736185 Test RE 0.14512687596281093\n",
      "70 Train Loss 35114.637 Test MSE 7021.048473910005 Test RE 0.14660103201061606\n",
      "71 Train Loss 34944.77 Test MSE 6950.4263507195865 Test RE 0.1458618658526408\n",
      "72 Train Loss 34800.09 Test MSE 6980.046139738477 Test RE 0.14617233634234833\n",
      "73 Train Loss 34604.164 Test MSE 7030.83804960576 Test RE 0.14670320065292408\n",
      "74 Train Loss 34393.7 Test MSE 7050.163145928132 Test RE 0.1469046779174808\n",
      "75 Train Loss 34271.31 Test MSE 6977.316178963207 Test RE 0.14614374886872628\n",
      "76 Train Loss 34037.78 Test MSE 6951.463143430657 Test RE 0.14587274452917456\n",
      "77 Train Loss 33850.062 Test MSE 6839.088287103266 Test RE 0.1446888773457692\n",
      "78 Train Loss 33737.22 Test MSE 6854.907164257864 Test RE 0.14485611408081756\n",
      "79 Train Loss 33601.566 Test MSE 6844.429710971582 Test RE 0.14474536833906929\n",
      "80 Train Loss 33477.92 Test MSE 6875.884193801387 Test RE 0.1450775853408717\n",
      "81 Train Loss 33350.7 Test MSE 6905.211292291942 Test RE 0.14538664940887144\n",
      "82 Train Loss 33202.92 Test MSE 6884.541652677489 Test RE 0.14516889055212298\n",
      "83 Train Loss 33058.67 Test MSE 6814.3148559568335 Test RE 0.1444265842090246\n",
      "84 Train Loss 32905.703 Test MSE 6758.610212264359 Test RE 0.14383505440223507\n",
      "85 Train Loss 32789.633 Test MSE 6723.74339798267 Test RE 0.14346356124483076\n",
      "86 Train Loss 32681.184 Test MSE 6709.069007929661 Test RE 0.1433069230416585\n",
      "87 Train Loss 32594.682 Test MSE 6696.331286057738 Test RE 0.14317081839216983\n",
      "88 Train Loss 32468.377 Test MSE 6632.852085364019 Test RE 0.142490594387875\n",
      "89 Train Loss 32339.309 Test MSE 6529.90617110922 Test RE 0.1413804996934777\n",
      "90 Train Loss 32171.736 Test MSE 6415.3670506154385 Test RE 0.14013505763559445\n",
      "91 Train Loss 32011.31 Test MSE 6320.764964970541 Test RE 0.13909799264295314\n",
      "92 Train Loss 31789.031 Test MSE 6239.651991493342 Test RE 0.13820260395776932\n",
      "93 Train Loss 31511.805 Test MSE 6079.833117820404 Test RE 0.13642120182493686\n",
      "94 Train Loss 31310.367 Test MSE 5889.157659890102 Test RE 0.13426494317471174\n",
      "95 Train Loss 31191.05 Test MSE 5714.67311251076 Test RE 0.13226098064151043\n",
      "96 Train Loss 31043.697 Test MSE 5582.787267465707 Test RE 0.13072588225382428\n",
      "97 Train Loss 30890.594 Test MSE 5523.068917528861 Test RE 0.13002482354221134\n",
      "98 Train Loss 30741.121 Test MSE 5355.9798678492425 Test RE 0.12804290236674357\n",
      "99 Train Loss 30598.098 Test MSE 5180.373932916453 Test RE 0.1259263445215204\n",
      "100 Train Loss 30489.877 Test MSE 5056.67804851384 Test RE 0.12441383970522434\n",
      "101 Train Loss 30391.832 Test MSE 4961.245620887487 Test RE 0.12323424427052125\n",
      "102 Train Loss 30283.865 Test MSE 4956.287683320381 Test RE 0.123172652841945\n",
      "103 Train Loss 30151.787 Test MSE 5073.746691867981 Test RE 0.12462364013565827\n",
      "104 Train Loss 29987.215 Test MSE 5112.234719030531 Test RE 0.1250954272008717\n",
      "105 Train Loss 29821.049 Test MSE 5114.918873371871 Test RE 0.1251282632686289\n",
      "106 Train Loss 29613.195 Test MSE 5015.68579381472 Test RE 0.12390852952596579\n",
      "107 Train Loss 29442.088 Test MSE 4973.929012015571 Test RE 0.1233916674810398\n",
      "108 Train Loss 29268.783 Test MSE 4991.318238429581 Test RE 0.1236071725214316\n",
      "109 Train Loss 29105.75 Test MSE 5050.442072997658 Test RE 0.12433710147970438\n",
      "110 Train Loss 28960.086 Test MSE 5031.197542304968 Test RE 0.12409998432115571\n",
      "111 Train Loss 28836.645 Test MSE 4921.705589659219 Test RE 0.12274218706567337\n",
      "112 Train Loss 28652.38 Test MSE 4814.189854326781 Test RE 0.12139411923956475\n",
      "113 Train Loss 28445.545 Test MSE 4727.890734486584 Test RE 0.12030114403175665\n",
      "114 Train Loss 28300.025 Test MSE 4666.857425156117 Test RE 0.11952212569082478\n",
      "115 Train Loss 28143.85 Test MSE 4722.105173159478 Test RE 0.1202275147175156\n",
      "116 Train Loss 28028.865 Test MSE 4779.319488093441 Test RE 0.12095367643590618\n",
      "117 Train Loss 27832.613 Test MSE 4830.866538790569 Test RE 0.12160419625188405\n",
      "118 Train Loss 27675.53 Test MSE 4860.2985105155485 Test RE 0.12197406948818391\n",
      "119 Train Loss 27526.562 Test MSE 4812.660910368012 Test RE 0.12137484086149825\n",
      "120 Train Loss 27416.146 Test MSE 4742.442046580812 Test RE 0.12048613081805312\n",
      "121 Train Loss 27290.453 Test MSE 4578.193698638257 Test RE 0.11838130507860367\n",
      "122 Train Loss 27143.559 Test MSE 4593.554797709398 Test RE 0.11857973968671985\n",
      "123 Train Loss 26986.016 Test MSE 4518.837592245916 Test RE 0.11761139693115001\n",
      "124 Train Loss 26851.898 Test MSE 4510.716223173085 Test RE 0.11750566231576001\n",
      "125 Train Loss 26713.846 Test MSE 4419.72896777784 Test RE 0.1163145007016196\n",
      "126 Train Loss 26599.824 Test MSE 4344.646633233349 Test RE 0.11532229365889074\n",
      "127 Train Loss 26406.672 Test MSE 4281.697766909826 Test RE 0.11448380257007174\n",
      "128 Train Loss 26306.79 Test MSE 4281.130133526249 Test RE 0.11447621364323816\n",
      "129 Train Loss 26185.477 Test MSE 4273.452342460343 Test RE 0.11437351659326447\n",
      "130 Train Loss 26065.307 Test MSE 4257.4442141228965 Test RE 0.11415909700652951\n",
      "131 Train Loss 25927.08 Test MSE 4273.119349464663 Test RE 0.1143690604394557\n",
      "132 Train Loss 25736.438 Test MSE 4189.4319823126725 Test RE 0.11324358609356569\n",
      "133 Train Loss 25587.215 Test MSE 4195.9446347931425 Test RE 0.11333157292834503\n",
      "134 Train Loss 25428.678 Test MSE 4163.297962268596 Test RE 0.11288982214297465\n",
      "135 Train Loss 25316.332 Test MSE 4127.419689348719 Test RE 0.11240234132938698\n",
      "136 Train Loss 25110.73 Test MSE 4069.8944055725765 Test RE 0.11161629761510392\n",
      "137 Train Loss 24961.11 Test MSE 4137.811812046788 Test RE 0.11254375711302009\n",
      "138 Train Loss 24821.768 Test MSE 4197.597087629653 Test RE 0.11335388693160843\n",
      "139 Train Loss 24654.945 Test MSE 4271.618509006517 Test RE 0.11434897385004225\n",
      "140 Train Loss 24479.143 Test MSE 4363.870681515033 Test RE 0.11557714918047932\n",
      "141 Train Loss 24368.404 Test MSE 4306.9109326155285 Test RE 0.11482038193114433\n",
      "142 Train Loss 24214.502 Test MSE 4229.277718747823 Test RE 0.11378084218836333\n",
      "143 Train Loss 24030.385 Test MSE 4255.382455270006 Test RE 0.11413145166116255\n",
      "144 Train Loss 23863.977 Test MSE 4297.781906786453 Test RE 0.1146986294402777\n",
      "145 Train Loss 23649.074 Test MSE 4188.797781890463 Test RE 0.11323501430523795\n",
      "146 Train Loss 23485.361 Test MSE 4206.650719239511 Test RE 0.11347606535072774\n",
      "147 Train Loss 23368.879 Test MSE 4218.6022906379185 Test RE 0.11363715019728741\n",
      "148 Train Loss 23222.074 Test MSE 4265.710809316667 Test RE 0.11426987348944674\n",
      "149 Train Loss 23085.643 Test MSE 4366.641130927785 Test RE 0.1156138310466338\n",
      "150 Train Loss 22991.906 Test MSE 4376.185695021046 Test RE 0.11574011590145067\n",
      "151 Train Loss 22886.053 Test MSE 4403.815706151048 Test RE 0.11610491633758775\n",
      "152 Train Loss 22738.2 Test MSE 4404.574203161976 Test RE 0.11611491464884677\n",
      "153 Train Loss 22638.729 Test MSE 4384.867819410049 Test RE 0.1158548701925581\n",
      "154 Train Loss 22556.455 Test MSE 4368.232327316711 Test RE 0.11563489386688172\n",
      "155 Train Loss 22456.908 Test MSE 4313.578364210822 Test RE 0.11490922298195372\n",
      "156 Train Loss 22355.35 Test MSE 4281.772631349698 Test RE 0.11448480342636243\n",
      "157 Train Loss 22270.258 Test MSE 4311.214019313712 Test RE 0.11487772682597402\n",
      "158 Train Loss 22158.717 Test MSE 4291.850955736578 Test RE 0.11461945990261413\n",
      "159 Train Loss 22055.887 Test MSE 4290.194645227184 Test RE 0.1145973408055404\n",
      "160 Train Loss 21968.508 Test MSE 4279.362079637452 Test RE 0.11445257257068292\n",
      "161 Train Loss 21833.861 Test MSE 4320.013318110767 Test RE 0.11499490126631365\n",
      "162 Train Loss 21724.342 Test MSE 4342.067804241592 Test RE 0.11528806295573939\n",
      "163 Train Loss 21615.992 Test MSE 4392.3588759780405 Test RE 0.11595379051025959\n",
      "164 Train Loss 21534.652 Test MSE 4430.3002843251315 Test RE 0.11645352088143353\n",
      "165 Train Loss 21450.838 Test MSE 4524.623028401041 Test RE 0.11768666137305618\n",
      "166 Train Loss 21361.143 Test MSE 4526.674633038233 Test RE 0.11771333974328292\n",
      "167 Train Loss 21267.812 Test MSE 4431.918918778231 Test RE 0.11647479240425929\n",
      "168 Train Loss 21192.285 Test MSE 4370.533781194655 Test RE 0.11566535164831397\n",
      "169 Train Loss 21122.031 Test MSE 4400.120510250637 Test RE 0.11605619490190362\n",
      "170 Train Loss 21043.91 Test MSE 4451.433128103725 Test RE 0.11673093619265225\n",
      "171 Train Loss 20981.242 Test MSE 4501.469688672458 Test RE 0.11738516287689701\n",
      "172 Train Loss 20914.293 Test MSE 4466.3503787611435 Test RE 0.11692636182268493\n",
      "173 Train Loss 20856.271 Test MSE 4461.262398591844 Test RE 0.11685974271688314\n",
      "174 Train Loss 20810.3 Test MSE 4479.0161854175385 Test RE 0.11709203604328351\n",
      "175 Train Loss 20739.627 Test MSE 4526.61378651917 Test RE 0.11771254860280778\n",
      "176 Train Loss 20687.504 Test MSE 4574.648691062028 Test RE 0.11833546342999189\n",
      "177 Train Loss 20628.836 Test MSE 4565.29844091727 Test RE 0.11821446701895288\n",
      "178 Train Loss 20561.375 Test MSE 4534.378685129143 Test RE 0.11781346668491673\n",
      "179 Train Loss 20487.363 Test MSE 4532.365368377789 Test RE 0.11778730850782608\n",
      "180 Train Loss 20419.42 Test MSE 4542.311420077158 Test RE 0.11791647689552996\n",
      "181 Train Loss 20366.277 Test MSE 4556.346359889148 Test RE 0.11809850693464685\n",
      "182 Train Loss 20302.379 Test MSE 4579.89168582669 Test RE 0.11840325601800514\n",
      "183 Train Loss 20267.04 Test MSE 4546.296046768133 Test RE 0.11796818516706883\n",
      "184 Train Loss 20216.084 Test MSE 4507.568996039449 Test RE 0.11746466200445689\n",
      "185 Train Loss 20164.215 Test MSE 4499.292607197625 Test RE 0.11735677348543791\n",
      "186 Train Loss 20115.537 Test MSE 4534.117988328877 Test RE 0.11781007988846727\n",
      "187 Train Loss 20064.727 Test MSE 4537.8988669970995 Test RE 0.11785918897657345\n",
      "188 Train Loss 20007.898 Test MSE 4537.551874334884 Test RE 0.11785468281008908\n",
      "189 Train Loss 19961.219 Test MSE 4594.965470394396 Test RE 0.11859794610489419\n",
      "190 Train Loss 19903.365 Test MSE 4660.868946340902 Test RE 0.1194454160966544\n",
      "191 Train Loss 19855.092 Test MSE 4705.756785911489 Test RE 0.12001921459944365\n",
      "192 Train Loss 19829.557 Test MSE 4701.701683340265 Test RE 0.11996749123779998\n",
      "193 Train Loss 19777.824 Test MSE 4747.589665512146 Test RE 0.12055150309584986\n",
      "194 Train Loss 19710.408 Test MSE 4700.812624881493 Test RE 0.1199561482004705\n",
      "195 Train Loss 19647.928 Test MSE 4694.886196166474 Test RE 0.11988050853716009\n",
      "196 Train Loss 19610.21 Test MSE 4701.851469372459 Test RE 0.11996940217479689\n",
      "197 Train Loss 19577.379 Test MSE 4663.661158996081 Test RE 0.11948118915429161\n",
      "198 Train Loss 19528.309 Test MSE 4622.201176241569 Test RE 0.11894890918531578\n",
      "199 Train Loss 19489.09 Test MSE 4605.177134498978 Test RE 0.11872965659091511\n",
      "Training time: 165.89\n",
      "Training time: 165.89\n",
      "ES_stan_high\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 220299.2 Test MSE 60528.89043550649 Test RE 0.43044473319504734\n",
      "1 Train Loss 172014.8 Test MSE 46468.11134025346 Test RE 0.3771495140606635\n",
      "2 Train Loss 127249.59 Test MSE 30405.76744934815 Test RE 0.30508020296039795\n",
      "3 Train Loss 101438.45 Test MSE 26437.006565542866 Test RE 0.2844737392014513\n",
      "4 Train Loss 88584.73 Test MSE 23484.85914620932 Test RE 0.2681205006956591\n",
      "5 Train Loss 78907.914 Test MSE 21272.322343568092 Test RE 0.25517815585188913\n",
      "6 Train Loss 72738.88 Test MSE 19240.165437022617 Test RE 0.24268360790600865\n",
      "7 Train Loss 67896.74 Test MSE 17233.683356414618 Test RE 0.22968101378857791\n",
      "8 Train Loss 64549.695 Test MSE 16400.17454796564 Test RE 0.22405790814808382\n",
      "9 Train Loss 61951.977 Test MSE 16602.048650449313 Test RE 0.22543268460295582\n",
      "10 Train Loss 59928.508 Test MSE 16048.764965345721 Test RE 0.22164444452514817\n",
      "11 Train Loss 58344.816 Test MSE 15111.848980437708 Test RE 0.21507743291686288\n",
      "12 Train Loss 56885.676 Test MSE 14742.46584278653 Test RE 0.2124325718300544\n",
      "13 Train Loss 55114.62 Test MSE 13723.957352293342 Test RE 0.20496311922298632\n",
      "14 Train Loss 53687.453 Test MSE 14108.011371838225 Test RE 0.20781119626257366\n",
      "15 Train Loss 52548.01 Test MSE 13449.095569891982 Test RE 0.20290024979371396\n",
      "16 Train Loss 51523.395 Test MSE 13664.832153591262 Test RE 0.20452113426315247\n",
      "17 Train Loss 50628.336 Test MSE 12858.25473483325 Test RE 0.19839332426918746\n",
      "18 Train Loss 49808.53 Test MSE 12951.75161087316 Test RE 0.19911331151135409\n",
      "19 Train Loss 49101.637 Test MSE 12422.332008521058 Test RE 0.19500134551415516\n",
      "20 Train Loss 48317.96 Test MSE 12085.507294872828 Test RE 0.1923395006786832\n",
      "21 Train Loss 47576.062 Test MSE 11434.391759225142 Test RE 0.18708655401183008\n",
      "22 Train Loss 46823.73 Test MSE 11044.095191571765 Test RE 0.18386586637171698\n",
      "23 Train Loss 45968.492 Test MSE 10674.052192738125 Test RE 0.18075932165465727\n",
      "24 Train Loss 45245.13 Test MSE 10790.360028456822 Test RE 0.18174145874437522\n",
      "25 Train Loss 44585.18 Test MSE 10352.645085077213 Test RE 0.17801709293565005\n",
      "26 Train Loss 43883.01 Test MSE 10218.008360476942 Test RE 0.17685574363303894\n",
      "27 Train Loss 43414.293 Test MSE 10112.364566619432 Test RE 0.17593911414076213\n",
      "28 Train Loss 42846.953 Test MSE 10032.771230866103 Test RE 0.17524534736443506\n",
      "29 Train Loss 42209.754 Test MSE 9885.475147772653 Test RE 0.17395415882976215\n",
      "30 Train Loss 41709.633 Test MSE 9600.127993247115 Test RE 0.17142515605322384\n",
      "31 Train Loss 41170.32 Test MSE 9416.609200688537 Test RE 0.169778743606198\n",
      "32 Train Loss 40620.477 Test MSE 9315.62830970265 Test RE 0.1688659617641676\n",
      "33 Train Loss 40203.4 Test MSE 9257.990815198851 Test RE 0.16834274892478102\n",
      "34 Train Loss 39879.375 Test MSE 9004.63090992445 Test RE 0.16602328394796625\n",
      "35 Train Loss 39466.344 Test MSE 8549.050754796717 Test RE 0.16176888405415105\n",
      "36 Train Loss 39142.434 Test MSE 8756.614190704655 Test RE 0.16372090988134955\n",
      "37 Train Loss 38793.223 Test MSE 8496.618682034532 Test RE 0.16127204977389095\n",
      "38 Train Loss 38422.395 Test MSE 8173.647199845848 Test RE 0.15817723731158956\n",
      "39 Train Loss 37991.8 Test MSE 8077.023559719938 Test RE 0.15723952263758506\n",
      "40 Train Loss 37564.203 Test MSE 8051.243482808805 Test RE 0.15698838515382582\n",
      "41 Train Loss 37220.55 Test MSE 7795.904021649223 Test RE 0.15447894104963103\n",
      "42 Train Loss 36913.633 Test MSE 7802.216700647019 Test RE 0.15454147251701802\n",
      "43 Train Loss 36564.074 Test MSE 7757.8701072901595 Test RE 0.15410165174072493\n",
      "44 Train Loss 36212.316 Test MSE 7577.859071506256 Test RE 0.1523032966871273\n",
      "45 Train Loss 35940.617 Test MSE 7658.833196912215 Test RE 0.15311486203450322\n",
      "46 Train Loss 35601.844 Test MSE 7609.608998469984 Test RE 0.15262202549833825\n",
      "47 Train Loss 35212.55 Test MSE 7522.793406663473 Test RE 0.15174892020722686\n",
      "48 Train Loss 34669.473 Test MSE 7078.320602948433 Test RE 0.14719774491251592\n",
      "49 Train Loss 34330.5 Test MSE 7121.341806291325 Test RE 0.14764439259662931\n",
      "50 Train Loss 34024.934 Test MSE 7253.906435612981 Test RE 0.14901226518308303\n",
      "51 Train Loss 33649.473 Test MSE 7034.668647727248 Test RE 0.14674315922391384\n",
      "52 Train Loss 32957.27 Test MSE 6670.468789652321 Test RE 0.14289407455117445\n",
      "53 Train Loss 32611.611 Test MSE 6550.620852635703 Test RE 0.14160457129575002\n",
      "54 Train Loss 32189.363 Test MSE 6390.280291921578 Test RE 0.13986079601619397\n",
      "55 Train Loss 31820.617 Test MSE 6469.846532865544 Test RE 0.14072881522685665\n",
      "56 Train Loss 31501.873 Test MSE 6340.456912370505 Test RE 0.13931449968797013\n",
      "57 Train Loss 31180.656 Test MSE 6217.1857919320755 Test RE 0.13795357667584007\n",
      "58 Train Loss 30852.803 Test MSE 6243.368654674732 Test RE 0.1382437581810813\n",
      "59 Train Loss 30447.5 Test MSE 6216.990956279254 Test RE 0.13795141504784206\n",
      "60 Train Loss 30103.307 Test MSE 6081.248981699461 Test RE 0.13643708569906718\n",
      "61 Train Loss 29625.043 Test MSE 6391.605655728613 Test RE 0.13987529904408938\n",
      "62 Train Loss 29272.95 Test MSE 6526.564547455115 Test RE 0.1413443199332384\n",
      "63 Train Loss 28922.02 Test MSE 6461.004461308188 Test RE 0.14063261822404588\n",
      "64 Train Loss 28495.771 Test MSE 6434.818000130601 Test RE 0.14034733675829583\n",
      "65 Train Loss 28168.326 Test MSE 6358.4731839946435 Test RE 0.1395122888579304\n",
      "66 Train Loss 27801.158 Test MSE 6215.709626752324 Test RE 0.13793719833663554\n",
      "67 Train Loss 27350.914 Test MSE 6181.668954950708 Test RE 0.13755896949389124\n",
      "68 Train Loss 27099.375 Test MSE 6174.022970673591 Test RE 0.13747387118497004\n",
      "69 Train Loss 26799.254 Test MSE 6099.363493113894 Test RE 0.13664014048288808\n",
      "70 Train Loss 26455.584 Test MSE 6141.747575213307 Test RE 0.1371140703270215\n",
      "71 Train Loss 26181.5 Test MSE 5969.499162634195 Test RE 0.135177680342521\n",
      "72 Train Loss 25774.826 Test MSE 6010.815184900636 Test RE 0.13564466873488012\n",
      "73 Train Loss 25484.332 Test MSE 6059.861815616305 Test RE 0.136196956350198\n",
      "74 Train Loss 25171.062 Test MSE 6126.699388383811 Test RE 0.13694599246880268\n",
      "75 Train Loss 24833.006 Test MSE 6149.629628230929 Test RE 0.13720202524840294\n",
      "76 Train Loss 24646.127 Test MSE 6297.373495144749 Test RE 0.13884037173991504\n",
      "77 Train Loss 24346.186 Test MSE 6338.2961072254 Test RE 0.1392907587223063\n",
      "78 Train Loss 24138.92 Test MSE 6152.796800353534 Test RE 0.13723735148110874\n",
      "79 Train Loss 23941.938 Test MSE 6167.283802653206 Test RE 0.13739882186341992\n",
      "80 Train Loss 23700.316 Test MSE 6170.371410107261 Test RE 0.13743321143880072\n",
      "81 Train Loss 23478.56 Test MSE 6066.997978055597 Test RE 0.13627712630003264\n",
      "82 Train Loss 23272.836 Test MSE 5902.773695557576 Test RE 0.13442006729284894\n",
      "83 Train Loss 23066.29 Test MSE 5930.495933174565 Test RE 0.13473534788932795\n",
      "84 Train Loss 22906.236 Test MSE 6064.059020891318 Test RE 0.13624411482107274\n",
      "85 Train Loss 22792.398 Test MSE 6104.280157352847 Test RE 0.13669520183160597\n",
      "86 Train Loss 22666.137 Test MSE 6110.0475649867285 Test RE 0.13675976233676138\n",
      "87 Train Loss 22505.346 Test MSE 6139.812502872252 Test RE 0.13709246845035258\n",
      "88 Train Loss 22398.941 Test MSE 6100.855395396868 Test RE 0.13665685052760404\n",
      "89 Train Loss 22224.572 Test MSE 6131.965404705954 Test RE 0.1370048336889892\n",
      "90 Train Loss 22078.682 Test MSE 6127.541631748323 Test RE 0.13695540519516441\n",
      "91 Train Loss 21898.904 Test MSE 6136.364980176018 Test RE 0.13705397413472203\n",
      "92 Train Loss 21722.988 Test MSE 6020.714088368835 Test RE 0.13575631591379794\n",
      "93 Train Loss 21545.516 Test MSE 6049.172447468306 Test RE 0.13607678017798858\n",
      "94 Train Loss 21334.488 Test MSE 6041.088360228498 Test RE 0.13598582357646236\n",
      "95 Train Loss 21122.379 Test MSE 6042.079491086752 Test RE 0.1359969783726092\n",
      "96 Train Loss 20913.64 Test MSE 6148.041479576193 Test RE 0.13718430781704002\n",
      "97 Train Loss 20707.553 Test MSE 6107.919711854055 Test RE 0.13673594664416888\n",
      "98 Train Loss 20501.312 Test MSE 6314.415178177511 Test RE 0.1390281067559196\n",
      "99 Train Loss 20232.871 Test MSE 6164.292324519494 Test RE 0.1373654947587289\n",
      "100 Train Loss 19994.408 Test MSE 6140.492081976619 Test RE 0.1371000552129003\n",
      "101 Train Loss 19718.969 Test MSE 6213.070578165106 Test RE 0.13790791273310637\n",
      "102 Train Loss 19482.05 Test MSE 6284.0974354194495 Test RE 0.1386939435840956\n",
      "103 Train Loss 19270.824 Test MSE 6270.568862814152 Test RE 0.13854457113662996\n",
      "104 Train Loss 19107.504 Test MSE 6270.19551875782 Test RE 0.13854044666537083\n",
      "105 Train Loss 18869.174 Test MSE 6235.3616118939435 Test RE 0.13815508178866315\n",
      "106 Train Loss 18679.102 Test MSE 6214.636914485539 Test RE 0.13792529516562202\n",
      "107 Train Loss 18561.074 Test MSE 6290.113303268729 Test RE 0.13876031467815966\n",
      "108 Train Loss 18377.547 Test MSE 6446.889242043998 Test RE 0.1404789156829413\n",
      "109 Train Loss 18208.791 Test MSE 6568.169705091374 Test RE 0.14179412093597984\n",
      "110 Train Loss 18048.766 Test MSE 6638.117264861991 Test RE 0.1425471379169772\n",
      "111 Train Loss 17887.621 Test MSE 6772.909724405039 Test RE 0.1439871333274445\n",
      "112 Train Loss 17682.576 Test MSE 6750.375855523792 Test RE 0.14374740693605706\n",
      "113 Train Loss 17515.781 Test MSE 6682.497761643204 Test RE 0.14302285819862537\n",
      "114 Train Loss 17279.812 Test MSE 6662.822900832574 Test RE 0.14281215636071717\n",
      "115 Train Loss 17129.088 Test MSE 6721.2419813854585 Test RE 0.14343687257642138\n",
      "116 Train Loss 16985.56 Test MSE 6678.929507874928 Test RE 0.14298466813736868\n",
      "117 Train Loss 16807.086 Test MSE 6740.791068061312 Test RE 0.14364531797111846\n",
      "118 Train Loss 16629.633 Test MSE 6657.134831848699 Test RE 0.14275118379290921\n",
      "119 Train Loss 16451.291 Test MSE 6805.997555884872 Test RE 0.1443384164302\n",
      "120 Train Loss 16324.929 Test MSE 6877.014119169427 Test RE 0.14508950527039285\n",
      "121 Train Loss 16170.388 Test MSE 6994.162373069083 Test RE 0.1463200689344964\n",
      "122 Train Loss 15997.137 Test MSE 7028.730600506 Test RE 0.14668121232825065\n",
      "123 Train Loss 15869.652 Test MSE 7079.641975240378 Test RE 0.14721148361947234\n",
      "124 Train Loss 15707.206 Test MSE 7176.947443904311 Test RE 0.14821969826208004\n",
      "125 Train Loss 15488.163 Test MSE 7459.812554268968 Test RE 0.15111236385179797\n",
      "126 Train Loss 15328.003 Test MSE 7536.557387587014 Test RE 0.15188767948363033\n",
      "127 Train Loss 15141.979 Test MSE 7631.936255878353 Test RE 0.1528457646772184\n",
      "128 Train Loss 15005.099 Test MSE 7724.092125165818 Test RE 0.15376580433175344\n",
      "129 Train Loss 14851.452 Test MSE 7642.930011437354 Test RE 0.15295581173613154\n",
      "130 Train Loss 14680.24 Test MSE 7717.344941842789 Test RE 0.153698630564261\n",
      "131 Train Loss 14557.482 Test MSE 7769.563727297027 Test RE 0.15421774852970863\n",
      "132 Train Loss 14440.467 Test MSE 7801.973703889315 Test RE 0.15453906593369746\n",
      "133 Train Loss 14268.522 Test MSE 7872.193406332491 Test RE 0.1552329531429664\n",
      "134 Train Loss 14118.512 Test MSE 7747.69743098966 Test RE 0.15400058402290662\n",
      "135 Train Loss 13954.232 Test MSE 7694.951657312295 Test RE 0.15347547625495803\n",
      "136 Train Loss 13806.481 Test MSE 7764.633675399378 Test RE 0.1541688125676625\n",
      "137 Train Loss 13660.895 Test MSE 7747.479525072728 Test RE 0.15399841835531786\n",
      "138 Train Loss 13559.3 Test MSE 7705.292566019152 Test RE 0.1535785661193826\n",
      "139 Train Loss 13470.346 Test MSE 7762.351855872398 Test RE 0.15414615784429953\n",
      "140 Train Loss 13376.505 Test MSE 7879.485634083067 Test RE 0.15530483476238258\n",
      "141 Train Loss 13289.632 Test MSE 7928.723709622133 Test RE 0.15578932084019803\n",
      "142 Train Loss 13218.007 Test MSE 7877.823640614712 Test RE 0.15528845493473475\n",
      "143 Train Loss 13130.647 Test MSE 7783.289989021263 Test RE 0.1543539144163139\n",
      "144 Train Loss 13049.297 Test MSE 7776.631547861533 Test RE 0.1542878770234857\n",
      "145 Train Loss 12984.201 Test MSE 7760.983770620832 Test RE 0.15413257340611683\n",
      "146 Train Loss 12875.898 Test MSE 7710.609603995549 Test RE 0.15363154543452193\n",
      "147 Train Loss 12730.327 Test MSE 7650.408948933604 Test RE 0.15303063037508288\n",
      "148 Train Loss 12619.023 Test MSE 7598.747057804527 Test RE 0.1525130604133377\n",
      "149 Train Loss 12547.892 Test MSE 7632.57936108669 Test RE 0.15285220431674115\n",
      "150 Train Loss 12465.41 Test MSE 7730.15225679423 Test RE 0.15382611292827936\n",
      "151 Train Loss 12393.928 Test MSE 7777.012798203311 Test RE 0.1542916589684422\n",
      "152 Train Loss 12341.611 Test MSE 7781.874205320078 Test RE 0.15433987525708878\n",
      "153 Train Loss 12258.447 Test MSE 7763.378937930835 Test RE 0.15415635549568782\n",
      "154 Train Loss 12178.543 Test MSE 7689.472484068107 Test RE 0.15342082558868442\n",
      "155 Train Loss 12074.628 Test MSE 7653.66440919558 Test RE 0.1530631862915552\n",
      "156 Train Loss 11951.1455 Test MSE 7655.220322790957 Test RE 0.15307874361008028\n",
      "157 Train Loss 11860.595 Test MSE 7677.78141995471 Test RE 0.15330415081043425\n",
      "158 Train Loss 11760.118 Test MSE 7589.480402878558 Test RE 0.15242003737746948\n",
      "159 Train Loss 11688.715 Test MSE 7584.457784143004 Test RE 0.15236959423814672\n",
      "160 Train Loss 11597.856 Test MSE 7543.290167155355 Test RE 0.15195550872739716\n",
      "161 Train Loss 11517.842 Test MSE 7574.484944748722 Test RE 0.1522693855362076\n",
      "162 Train Loss 11414.967 Test MSE 7596.324299375143 Test RE 0.15248874510468852\n",
      "163 Train Loss 11346.359 Test MSE 7623.31586574959 Test RE 0.1527594194597834\n",
      "164 Train Loss 11275.836 Test MSE 7580.249677499849 Test RE 0.15232731854206932\n",
      "165 Train Loss 11189.131 Test MSE 7617.124793819878 Test RE 0.1526973771238914\n",
      "166 Train Loss 11119.853 Test MSE 7642.7441005023475 Test RE 0.15295395143315488\n",
      "167 Train Loss 11046.344 Test MSE 7683.4704149726385 Test RE 0.15336093707485202\n",
      "168 Train Loss 10958.624 Test MSE 7757.8678981399435 Test RE 0.15410162979954029\n",
      "169 Train Loss 10878.975 Test MSE 7746.096013947459 Test RE 0.15398466755823645\n",
      "170 Train Loss 10808.223 Test MSE 7733.75308933198 Test RE 0.15386193612845872\n",
      "171 Train Loss 10674.461 Test MSE 7608.871938845574 Test RE 0.1526146339058858\n",
      "172 Train Loss 10572.685 Test MSE 7553.132156629932 Test RE 0.15205460719638675\n",
      "173 Train Loss 10460.917 Test MSE 7447.662470477227 Test RE 0.1509892524410777\n",
      "174 Train Loss 10371.15 Test MSE 7373.050106903899 Test RE 0.15023102643640696\n",
      "175 Train Loss 10277.258 Test MSE 7260.1512981244205 Test RE 0.14907639345133494\n",
      "176 Train Loss 10168.926 Test MSE 7203.481147243787 Test RE 0.14849343506023638\n",
      "177 Train Loss 10086.42 Test MSE 7160.269605471917 Test RE 0.14804738113325713\n",
      "178 Train Loss 10012.911 Test MSE 7180.599163124559 Test RE 0.14825740147038566\n",
      "179 Train Loss 9957.183 Test MSE 7163.384592082557 Test RE 0.1480795807214143\n",
      "180 Train Loss 9919.717 Test MSE 7176.04047006692 Test RE 0.14821033246715395\n",
      "181 Train Loss 9841.305 Test MSE 7201.715772107328 Test RE 0.1484752381165626\n",
      "182 Train Loss 9752.3955 Test MSE 7097.234639071131 Test RE 0.1473942778364297\n",
      "183 Train Loss 9677.853 Test MSE 7074.079272409641 Test RE 0.14715363785124438\n",
      "184 Train Loss 9610.899 Test MSE 7026.155687278989 Test RE 0.14665434218536436\n",
      "185 Train Loss 9527.738 Test MSE 7116.289056528717 Test RE 0.1475920048188348\n",
      "186 Train Loss 9458.758 Test MSE 7139.192177904183 Test RE 0.14782931967010474\n",
      "187 Train Loss 9375.62 Test MSE 7192.043036917731 Test RE 0.14837549492599547\n",
      "188 Train Loss 9294.937 Test MSE 7196.571511837864 Test RE 0.1484221999421835\n",
      "189 Train Loss 9194.562 Test MSE 7236.322811394531 Test RE 0.14883155114534014\n",
      "190 Train Loss 9112.566 Test MSE 7224.999193165132 Test RE 0.14871505748324762\n",
      "191 Train Loss 9033.167 Test MSE 7266.295970373873 Test RE 0.14913946595501526\n",
      "192 Train Loss 8934.657 Test MSE 7249.833450634579 Test RE 0.14897042497310006\n",
      "193 Train Loss 8868.485 Test MSE 7240.868421437766 Test RE 0.14887828924709093\n",
      "194 Train Loss 8806.776 Test MSE 7228.533806752589 Test RE 0.14875143022010634\n",
      "195 Train Loss 8741.135 Test MSE 7275.0373547927165 Test RE 0.14922914669195214\n",
      "196 Train Loss 8674.901 Test MSE 7288.234724570322 Test RE 0.14936444083379594\n",
      "197 Train Loss 8598.499 Test MSE 7369.84710352732 Test RE 0.1501983911803691\n",
      "198 Train Loss 8548.543 Test MSE 7397.62363818096 Test RE 0.15048116958475147\n",
      "199 Train Loss 8465.127 Test MSE 7437.9864853169465 Test RE 0.1508911381265276\n",
      "Training time: 164.34\n",
      "Training time: 164.34\n",
      "ES_stan_high\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 251765.66 Test MSE 76538.30084484411 Test RE 0.48403353334252386\n",
      "1 Train Loss 204421.88 Test MSE 55236.33311241186 Test RE 0.41119560286025014\n",
      "2 Train Loss 159510.5 Test MSE 40400.861567419124 Test RE 0.35166678837252424\n",
      "3 Train Loss 126988.086 Test MSE 34871.360534968895 Test RE 0.3267160635879696\n",
      "4 Train Loss 107796.805 Test MSE 29024.00557508163 Test RE 0.29806756261743755\n",
      "5 Train Loss 94992.89 Test MSE 25608.66171192626 Test RE 0.2799815950886171\n",
      "6 Train Loss 87443.21 Test MSE 23958.790370269475 Test RE 0.2708123623698148\n",
      "7 Train Loss 80853.16 Test MSE 19480.014901245428 Test RE 0.24419157961586482\n",
      "8 Train Loss 73749.24 Test MSE 17914.06682067364 Test RE 0.23417101413198377\n",
      "9 Train Loss 67923.0 Test MSE 15023.311381251326 Test RE 0.21444645741096224\n",
      "10 Train Loss 63421.406 Test MSE 15046.120334010917 Test RE 0.21460918598198725\n",
      "11 Train Loss 61534.586 Test MSE 14780.952059941861 Test RE 0.21270967598981952\n",
      "12 Train Loss 59277.715 Test MSE 14071.137392483623 Test RE 0.20753944147102343\n",
      "13 Train Loss 58003.383 Test MSE 13691.10654750152 Test RE 0.20471766387200305\n",
      "14 Train Loss 56658.57 Test MSE 13398.860593983893 Test RE 0.20252095942280315\n",
      "15 Train Loss 55129.297 Test MSE 13054.467895138861 Test RE 0.19990130491041044\n",
      "16 Train Loss 54248.086 Test MSE 13037.262374449529 Test RE 0.19976952856842697\n",
      "17 Train Loss 53563.223 Test MSE 13182.613057655984 Test RE 0.20088004369293416\n",
      "18 Train Loss 53030.07 Test MSE 12554.72030558237 Test RE 0.19603768387268788\n",
      "19 Train Loss 52332.348 Test MSE 12645.565598962927 Test RE 0.19674566461927456\n",
      "20 Train Loss 51709.293 Test MSE 12327.883874419113 Test RE 0.1942586244836264\n",
      "21 Train Loss 51206.316 Test MSE 12302.365928662432 Test RE 0.1940574687555687\n",
      "22 Train Loss 50575.156 Test MSE 12013.419910803324 Test RE 0.19176501138320798\n",
      "23 Train Loss 50128.926 Test MSE 11872.86292642252 Test RE 0.1906398856196183\n",
      "24 Train Loss 49613.93 Test MSE 11991.248568375875 Test RE 0.1915879739013658\n",
      "25 Train Loss 49300.11 Test MSE 11769.391355390711 Test RE 0.18980735793377598\n",
      "26 Train Loss 49017.785 Test MSE 11565.817765243602 Test RE 0.18815866125587097\n",
      "27 Train Loss 48628.66 Test MSE 11250.71287359699 Test RE 0.18557781734324938\n",
      "28 Train Loss 48304.992 Test MSE 11317.483342127989 Test RE 0.1861276841683786\n",
      "29 Train Loss 47810.33 Test MSE 11241.463366728018 Test RE 0.18550151745646645\n",
      "30 Train Loss 47539.418 Test MSE 11030.012731790586 Test RE 0.18374860418061836\n",
      "31 Train Loss 47239.875 Test MSE 10807.060912367591 Test RE 0.18188205041358763\n",
      "32 Train Loss 46842.523 Test MSE 10708.96308646214 Test RE 0.18105467893647262\n",
      "33 Train Loss 46485.965 Test MSE 10699.937955314286 Test RE 0.18097836965085945\n",
      "34 Train Loss 46159.645 Test MSE 10310.789785489616 Test RE 0.17765687074440753\n",
      "35 Train Loss 45939.445 Test MSE 10038.504573643326 Test RE 0.175295413199768\n",
      "36 Train Loss 45553.773 Test MSE 9999.425653380897 Test RE 0.1749538765010174\n",
      "37 Train Loss 45254.93 Test MSE 10028.171457116456 Test RE 0.17520516996259486\n",
      "38 Train Loss 44973.613 Test MSE 10056.097627846226 Test RE 0.17544895358282164\n",
      "39 Train Loss 44690.38 Test MSE 9805.117873713869 Test RE 0.17324569489637115\n",
      "40 Train Loss 44339.902 Test MSE 9536.91723759352 Test RE 0.1708598610107991\n",
      "41 Train Loss 44067.504 Test MSE 9292.427260217068 Test RE 0.16865554600583596\n",
      "42 Train Loss 43818.1 Test MSE 9249.202351662658 Test RE 0.16826282740524653\n",
      "43 Train Loss 43496.46 Test MSE 9232.097447834816 Test RE 0.1681071679625699\n",
      "44 Train Loss 43222.145 Test MSE 9215.37682163275 Test RE 0.16795486611559216\n",
      "45 Train Loss 42969.61 Test MSE 9088.9600943042 Test RE 0.16679888383761804\n",
      "46 Train Loss 42731.74 Test MSE 8903.99836737892 Test RE 0.16509296893258274\n",
      "47 Train Loss 42546.297 Test MSE 8840.54142114638 Test RE 0.1645036253800498\n",
      "48 Train Loss 42265.1 Test MSE 8520.28326319525 Test RE 0.1614964791608199\n",
      "49 Train Loss 42075.22 Test MSE 8474.290221694073 Test RE 0.16106000510205756\n",
      "50 Train Loss 41851.555 Test MSE 8484.139521586581 Test RE 0.1611535744504618\n",
      "51 Train Loss 41594.66 Test MSE 8483.556028862387 Test RE 0.16114803272435413\n",
      "52 Train Loss 41190.816 Test MSE 8216.368641877532 Test RE 0.15859007337647316\n",
      "53 Train Loss 40989.426 Test MSE 8051.91529592505 Test RE 0.156994934741878\n",
      "54 Train Loss 40753.75 Test MSE 8031.181367155757 Test RE 0.15679267106383835\n",
      "55 Train Loss 40444.906 Test MSE 8090.229228652142 Test RE 0.15736801087484167\n",
      "56 Train Loss 40242.484 Test MSE 8013.5639994243675 Test RE 0.15662060480566548\n",
      "57 Train Loss 40126.305 Test MSE 7946.83325831754 Test RE 0.15596713414623542\n",
      "58 Train Loss 39978.727 Test MSE 8006.169037198114 Test RE 0.1565483229358876\n",
      "59 Train Loss 39798.734 Test MSE 7946.078785581066 Test RE 0.15595973020684378\n",
      "60 Train Loss 39623.25 Test MSE 7868.385142639283 Test RE 0.1551954007416025\n",
      "61 Train Loss 39414.46 Test MSE 7814.993798721218 Test RE 0.15466796117262663\n",
      "62 Train Loss 39239.207 Test MSE 7671.097304336668 Test RE 0.1532374045896849\n",
      "63 Train Loss 39091.492 Test MSE 7628.2978046699445 Test RE 0.15280932646968065\n",
      "64 Train Loss 38932.8 Test MSE 7547.032862468585 Test RE 0.15199320134099786\n",
      "65 Train Loss 38747.016 Test MSE 7491.631079445902 Test RE 0.1514342926080143\n",
      "66 Train Loss 38593.086 Test MSE 7516.067660752926 Test RE 0.15168106955332208\n",
      "67 Train Loss 38439.117 Test MSE 7556.519850130496 Test RE 0.15208870276413647\n",
      "68 Train Loss 38291.305 Test MSE 7561.3432331075555 Test RE 0.15213723469742613\n",
      "69 Train Loss 38139.53 Test MSE 7494.561009162196 Test RE 0.15146390221215014\n",
      "70 Train Loss 37952.562 Test MSE 7330.8436795776215 Test RE 0.14980041664127144\n",
      "71 Train Loss 37753.945 Test MSE 7222.367008151734 Test RE 0.14868796535533857\n",
      "72 Train Loss 37587.15 Test MSE 7231.863764530059 Test RE 0.1487856888237131\n",
      "73 Train Loss 37435.895 Test MSE 7292.481443868879 Test RE 0.149407950442383\n",
      "74 Train Loss 37290.21 Test MSE 7278.658313978068 Test RE 0.1492662795205015\n",
      "75 Train Loss 37144.656 Test MSE 7279.600136693761 Test RE 0.1492759363706586\n",
      "76 Train Loss 36981.094 Test MSE 7296.279824396118 Test RE 0.14944685588045184\n",
      "77 Train Loss 36767.69 Test MSE 7187.512941599605 Test RE 0.14832875848348653\n",
      "78 Train Loss 36620.832 Test MSE 7035.069046591461 Test RE 0.14674733532382597\n",
      "79 Train Loss 36474.25 Test MSE 7022.449868582361 Test RE 0.14661566199467793\n",
      "80 Train Loss 36347.387 Test MSE 6939.433368849167 Test RE 0.1457464706750286\n",
      "81 Train Loss 36198.19 Test MSE 6827.078625719671 Test RE 0.14456178233915049\n",
      "82 Train Loss 36048.74 Test MSE 6768.691170637611 Test RE 0.1439422846507685\n",
      "83 Train Loss 35813.133 Test MSE 6806.4723329115395 Test RE 0.1443434507670883\n",
      "84 Train Loss 35571.117 Test MSE 6745.4013519171685 Test RE 0.1436944318279838\n",
      "85 Train Loss 35416.887 Test MSE 6592.784983789103 Test RE 0.14205957066982897\n",
      "86 Train Loss 35287.95 Test MSE 6498.464500561473 Test RE 0.1410397135562828\n",
      "87 Train Loss 35164.023 Test MSE 6443.05766043247 Test RE 0.14043716404046475\n",
      "88 Train Loss 34996.85 Test MSE 6318.292114461018 Test RE 0.13907078057345929\n",
      "89 Train Loss 34844.26 Test MSE 6251.067572413964 Test RE 0.13832896854333307\n",
      "90 Train Loss 34665.344 Test MSE 6164.854553811489 Test RE 0.13737175899311857\n",
      "91 Train Loss 34459.758 Test MSE 6142.039290169604 Test RE 0.13711732654600522\n",
      "92 Train Loss 34312.29 Test MSE 6171.686996681912 Test RE 0.13744786174422846\n",
      "93 Train Loss 34188.598 Test MSE 6162.2814935441265 Test RE 0.13734308818656965\n",
      "94 Train Loss 34049.57 Test MSE 6119.530714130404 Test RE 0.13686585074100494\n",
      "95 Train Loss 33899.99 Test MSE 6101.059392322743 Test RE 0.13665913523544962\n",
      "96 Train Loss 33748.492 Test MSE 6079.3818135077245 Test RE 0.13641613847713532\n",
      "97 Train Loss 33606.375 Test MSE 6110.763571280028 Test RE 0.13676777520252997\n",
      "98 Train Loss 33477.32 Test MSE 6120.677153489356 Test RE 0.13687867043726576\n",
      "99 Train Loss 33357.93 Test MSE 6160.87199627442 Test RE 0.13732738006134623\n",
      "100 Train Loss 33253.355 Test MSE 6169.490837543783 Test RE 0.13742340455480215\n",
      "101 Train Loss 33089.246 Test MSE 6248.877361119701 Test RE 0.13830473298608326\n",
      "102 Train Loss 32899.445 Test MSE 6391.117858306352 Test RE 0.1398699614093968\n",
      "103 Train Loss 32775.09 Test MSE 6392.239317977015 Test RE 0.1398822324740122\n",
      "104 Train Loss 32595.121 Test MSE 6387.504128372678 Test RE 0.13983041248014424\n",
      "105 Train Loss 32336.633 Test MSE 6382.392977742602 Test RE 0.13977445656100362\n",
      "106 Train Loss 32150.363 Test MSE 6340.34118785234 Test RE 0.13931322831453938\n",
      "107 Train Loss 31925.785 Test MSE 6313.890564536514 Test RE 0.13902233127598937\n",
      "108 Train Loss 31762.115 Test MSE 6170.475877079465 Test RE 0.1374343748347908\n",
      "109 Train Loss 31623.357 Test MSE 6100.497040457596 Test RE 0.1366528369611983\n",
      "110 Train Loss 31466.04 Test MSE 6009.883027840063 Test RE 0.1356341504412426\n",
      "111 Train Loss 31344.371 Test MSE 6003.37702236513 Test RE 0.13556071511219522\n",
      "112 Train Loss 31167.66 Test MSE 5941.8721180336115 Test RE 0.1348645141415538\n",
      "113 Train Loss 30982.262 Test MSE 5798.038756251845 Test RE 0.1332221992744283\n",
      "114 Train Loss 30828.57 Test MSE 5803.796382111682 Test RE 0.1332883296749027\n",
      "115 Train Loss 30663.62 Test MSE 5838.150169352676 Test RE 0.13368222727776555\n",
      "116 Train Loss 30464.1 Test MSE 5911.507364970024 Test RE 0.13451947365331332\n",
      "117 Train Loss 30264.201 Test MSE 5906.909491356487 Test RE 0.13446714995543915\n",
      "118 Train Loss 30119.809 Test MSE 5833.955607882733 Test RE 0.13363419501936882\n",
      "119 Train Loss 29980.674 Test MSE 5799.915217500055 Test RE 0.1332437553627801\n",
      "120 Train Loss 29846.705 Test MSE 5823.5948932275915 Test RE 0.1335154795956093\n",
      "121 Train Loss 29686.361 Test MSE 5758.664415173116 Test RE 0.13276907430582166\n",
      "122 Train Loss 29521.42 Test MSE 5764.882196557331 Test RE 0.13284073209858177\n",
      "123 Train Loss 29369.535 Test MSE 5708.046428172722 Test RE 0.1321842740670013\n",
      "124 Train Loss 29272.967 Test MSE 5666.474514583507 Test RE 0.1317020429533335\n",
      "125 Train Loss 29171.832 Test MSE 5617.544730705931 Test RE 0.1311321891474413\n",
      "126 Train Loss 29071.365 Test MSE 5646.569943623485 Test RE 0.13147052520711563\n",
      "127 Train Loss 28964.893 Test MSE 5618.071861215848 Test RE 0.13113834149330936\n",
      "128 Train Loss 28862.97 Test MSE 5626.002408822918 Test RE 0.13123086719657953\n",
      "129 Train Loss 28696.832 Test MSE 5597.529675923831 Test RE 0.1308983716971188\n",
      "130 Train Loss 28554.457 Test MSE 5530.237867188765 Test RE 0.13010918236014624\n",
      "131 Train Loss 28442.908 Test MSE 5484.319216631375 Test RE 0.12956789537469687\n",
      "132 Train Loss 28298.566 Test MSE 5514.544984317104 Test RE 0.12992444901435637\n",
      "133 Train Loss 28098.875 Test MSE 5424.0182963692605 Test RE 0.12885361723389785\n",
      "134 Train Loss 27885.496 Test MSE 5474.70285415199 Test RE 0.12945425150583806\n",
      "135 Train Loss 27735.043 Test MSE 5586.723888353464 Test RE 0.13077196385492135\n",
      "136 Train Loss 27540.59 Test MSE 5577.968920122769 Test RE 0.13066945715248693\n",
      "137 Train Loss 27392.254 Test MSE 5613.102756530204 Test RE 0.13108033366440883\n",
      "138 Train Loss 27216.844 Test MSE 5629.740157295378 Test RE 0.13127445289874376\n",
      "139 Train Loss 27079.68 Test MSE 5665.814858539177 Test RE 0.13169437676008933\n",
      "140 Train Loss 26922.541 Test MSE 5690.741395414628 Test RE 0.13198375103627058\n",
      "141 Train Loss 26806.5 Test MSE 5646.747810063585 Test RE 0.13147259584560791\n",
      "142 Train Loss 26610.082 Test MSE 5655.696437546262 Test RE 0.13157672955066615\n",
      "143 Train Loss 26470.17 Test MSE 5670.356920610124 Test RE 0.13174715329933598\n",
      "144 Train Loss 26314.352 Test MSE 5679.423536926501 Test RE 0.13185243977433764\n",
      "145 Train Loss 26132.049 Test MSE 5700.400793362817 Test RE 0.1320957173822121\n",
      "146 Train Loss 26012.988 Test MSE 5689.165627770842 Test RE 0.13196547660513222\n",
      "147 Train Loss 25929.857 Test MSE 5664.319655242109 Test RE 0.13167699860142626\n",
      "148 Train Loss 25798.537 Test MSE 5716.285519905728 Test RE 0.13227963818659946\n",
      "149 Train Loss 25677.9 Test MSE 5719.141309185449 Test RE 0.1323126767394902\n",
      "150 Train Loss 25553.105 Test MSE 5710.3279890284475 Test RE 0.13221068908819286\n",
      "151 Train Loss 25397.285 Test MSE 5764.538623838368 Test RE 0.13283677355008114\n",
      "152 Train Loss 25230.996 Test MSE 5827.3998214821695 Test RE 0.13355908958884796\n",
      "153 Train Loss 25114.242 Test MSE 5837.4249464068525 Test RE 0.13367392392594668\n",
      "154 Train Loss 24941.387 Test MSE 5920.555192128982 Test RE 0.13462237833718763\n",
      "155 Train Loss 24747.344 Test MSE 5963.483201642147 Test RE 0.13510954827470711\n",
      "156 Train Loss 24599.682 Test MSE 5975.673475674487 Test RE 0.135247570092643\n",
      "157 Train Loss 24410.203 Test MSE 5888.827329135387 Test RE 0.13426117757150258\n",
      "158 Train Loss 24298.041 Test MSE 5895.452387654018 Test RE 0.13433667971104135\n",
      "159 Train Loss 24127.621 Test MSE 5668.8402214359485 Test RE 0.13172953234838516\n",
      "160 Train Loss 23955.572 Test MSE 5598.164703190126 Test RE 0.13090579655080675\n",
      "161 Train Loss 23822.46 Test MSE 5602.034904320143 Test RE 0.13095103854134452\n",
      "162 Train Loss 23739.74 Test MSE 5609.039990045986 Test RE 0.13103288707300365\n",
      "163 Train Loss 23647.76 Test MSE 5641.2144532171715 Test RE 0.13140816379380804\n",
      "164 Train Loss 23528.04 Test MSE 5791.060140715382 Test RE 0.13314200091169057\n",
      "165 Train Loss 23384.049 Test MSE 5771.180596830655 Test RE 0.13291327960871108\n",
      "166 Train Loss 23277.654 Test MSE 5865.986672063493 Test RE 0.1340005490372739\n",
      "167 Train Loss 23139.545 Test MSE 6040.4191120605265 Test RE 0.13597829092849006\n",
      "168 Train Loss 23031.87 Test MSE 6050.433420219122 Test RE 0.13609096229729054\n",
      "169 Train Loss 22908.133 Test MSE 6071.685824252286 Test RE 0.13632976541844918\n",
      "170 Train Loss 22755.283 Test MSE 6064.752180369442 Test RE 0.1362519013713535\n",
      "171 Train Loss 22653.746 Test MSE 6148.022136175339 Test RE 0.13718409200740755\n",
      "172 Train Loss 22561.902 Test MSE 6155.451217759468 Test RE 0.13726695151058754\n",
      "173 Train Loss 22441.459 Test MSE 6159.692613846911 Test RE 0.13731423506735702\n",
      "174 Train Loss 22316.248 Test MSE 6126.507423535428 Test RE 0.1369438470213977\n",
      "175 Train Loss 22225.812 Test MSE 6168.064158595394 Test RE 0.13740751423100497\n",
      "176 Train Loss 22078.264 Test MSE 6169.350638186715 Test RE 0.13742184309836025\n",
      "177 Train Loss 21956.863 Test MSE 6149.919247505385 Test RE 0.1372052560025759\n",
      "178 Train Loss 21850.766 Test MSE 6203.113256212979 Test RE 0.13779735998025053\n",
      "179 Train Loss 21706.314 Test MSE 6087.33850698799 Test RE 0.13650537999175902\n",
      "180 Train Loss 21606.705 Test MSE 6005.579833465126 Test RE 0.13558558338711083\n",
      "181 Train Loss 21432.938 Test MSE 5926.709834499767 Test RE 0.1346923327038603\n",
      "182 Train Loss 21320.04 Test MSE 5852.381326448753 Test RE 0.13384506094696355\n",
      "183 Train Loss 21204.309 Test MSE 5799.939664410957 Test RE 0.13324403617678005\n",
      "184 Train Loss 21053.707 Test MSE 5810.295326255016 Test RE 0.1333629352426742\n",
      "185 Train Loss 20907.08 Test MSE 5757.697171388452 Test RE 0.13275792367734485\n",
      "186 Train Loss 20782.479 Test MSE 5785.418955227168 Test RE 0.13307713699174853\n",
      "187 Train Loss 20698.805 Test MSE 5793.084098495687 Test RE 0.13316526523990774\n",
      "188 Train Loss 20556.17 Test MSE 5801.729853100156 Test RE 0.13326459790474632\n",
      "189 Train Loss 20449.625 Test MSE 5881.984677818336 Test RE 0.13418315104738174\n",
      "190 Train Loss 20365.834 Test MSE 5861.0039305464015 Test RE 0.1339436249437252\n",
      "191 Train Loss 20269.602 Test MSE 5816.053963754899 Test RE 0.13342900749553815\n",
      "192 Train Loss 20197.438 Test MSE 5784.6126908773595 Test RE 0.13306786375755142\n",
      "193 Train Loss 20125.174 Test MSE 5837.410807796222 Test RE 0.13367376204252004\n",
      "194 Train Loss 20032.543 Test MSE 5835.171173879076 Test RE 0.13364811633910714\n",
      "195 Train Loss 19979.705 Test MSE 5778.791948042672 Test RE 0.13300089741063328\n",
      "196 Train Loss 19887.637 Test MSE 5720.857228560807 Test RE 0.13233252419965133\n",
      "197 Train Loss 19794.537 Test MSE 5686.3126230446815 Test RE 0.13193238340952831\n",
      "198 Train Loss 19696.61 Test MSE 5731.136234443681 Test RE 0.13245135572083427\n",
      "199 Train Loss 19600.338 Test MSE 5732.813496665482 Test RE 0.13247073576996996\n",
      "Training time: 165.51\n",
      "Training time: 165.51\n",
      "ES_stan_high\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 243540.38 Test MSE 72015.97151158228 Test RE 0.46951606178836625\n",
      "1 Train Loss 194335.72 Test MSE 51045.7666680697 Test RE 0.3952900724303656\n",
      "2 Train Loss 122696.266 Test MSE 28333.304531060017 Test RE 0.29449956429812535\n",
      "3 Train Loss 93747.805 Test MSE 24483.626355692366 Test RE 0.2737624717647964\n",
      "4 Train Loss 81423.38 Test MSE 20526.649810502935 Test RE 0.25066579661230415\n",
      "5 Train Loss 74273.22 Test MSE 17568.68428399584 Test RE 0.2319026231077896\n",
      "6 Train Loss 69774.445 Test MSE 16182.810583939448 Test RE 0.22256815068236543\n",
      "7 Train Loss 66406.29 Test MSE 14157.823170286987 Test RE 0.2081777372357264\n",
      "8 Train Loss 63484.875 Test MSE 13603.444531133022 Test RE 0.20406122380365302\n",
      "9 Train Loss 60952.09 Test MSE 13607.682991076921 Test RE 0.20409301126606813\n",
      "10 Train Loss 58582.883 Test MSE 12225.276395754843 Test RE 0.19344850829888213\n",
      "11 Train Loss 56859.992 Test MSE 11406.14881818478 Test RE 0.1868553593207061\n",
      "12 Train Loss 55349.723 Test MSE 11077.95183515126 Test RE 0.18414747918887842\n",
      "13 Train Loss 54290.598 Test MSE 10419.103416118547 Test RE 0.17858756515822696\n",
      "14 Train Loss 53032.383 Test MSE 10017.046724961507 Test RE 0.1751079612413006\n",
      "15 Train Loss 52313.582 Test MSE 10013.497141636819 Test RE 0.17507693336506092\n",
      "16 Train Loss 51846.375 Test MSE 9960.53613119681 Test RE 0.17461333189591513\n",
      "17 Train Loss 51219.043 Test MSE 9885.916195920114 Test RE 0.17395803933639503\n",
      "18 Train Loss 50663.05 Test MSE 9380.651142039616 Test RE 0.1694542768545993\n",
      "19 Train Loss 50163.26 Test MSE 9470.05925804914 Test RE 0.1702599063315226\n",
      "20 Train Loss 49703.9 Test MSE 9183.670926095163 Test RE 0.1676656892431198\n",
      "21 Train Loss 49153.58 Test MSE 9215.391735431142 Test RE 0.1679550020212663\n",
      "22 Train Loss 48865.19 Test MSE 9137.609856741112 Test RE 0.16724469370969292\n",
      "23 Train Loss 48400.746 Test MSE 8960.21505783795 Test RE 0.16561331815139044\n",
      "24 Train Loss 47979.273 Test MSE 8861.384873759765 Test RE 0.1646974373136929\n",
      "25 Train Loss 47448.367 Test MSE 8465.49607457059 Test RE 0.1609764138515931\n",
      "26 Train Loss 46745.47 Test MSE 8446.072496638571 Test RE 0.1607916323880354\n",
      "27 Train Loss 46322.055 Test MSE 8427.431192760068 Test RE 0.16061409298266452\n",
      "28 Train Loss 46041.383 Test MSE 8376.837147943745 Test RE 0.1601312442084368\n",
      "29 Train Loss 45765.16 Test MSE 8354.543478689895 Test RE 0.1599180198558225\n",
      "30 Train Loss 45551.285 Test MSE 8312.049976525772 Test RE 0.15951080791776395\n",
      "31 Train Loss 45320.8 Test MSE 8312.711537412746 Test RE 0.1595171555704025\n",
      "32 Train Loss 45092.953 Test MSE 8341.018909076301 Test RE 0.15978852753729306\n",
      "33 Train Loss 44886.887 Test MSE 8291.631323475021 Test RE 0.15931476731844935\n",
      "34 Train Loss 44719.938 Test MSE 8341.56528360471 Test RE 0.15979376088783867\n",
      "35 Train Loss 44592.816 Test MSE 8275.580390520965 Test RE 0.15916049192433276\n",
      "36 Train Loss 44495.133 Test MSE 8232.319517439671 Test RE 0.1587439384286559\n",
      "37 Train Loss 44385.25 Test MSE 8221.720284607778 Test RE 0.15864171293249404\n",
      "38 Train Loss 44264.59 Test MSE 8178.9917638170955 Test RE 0.15822894312864996\n",
      "39 Train Loss 44175.465 Test MSE 8104.909101499975 Test RE 0.15751071977252526\n",
      "40 Train Loss 44063.88 Test MSE 8107.733509668528 Test RE 0.15753816214153518\n",
      "41 Train Loss 43985.516 Test MSE 8024.593334470981 Test RE 0.15672834882303402\n",
      "42 Train Loss 43883.812 Test MSE 7979.686659317706 Test RE 0.15628919739172453\n",
      "43 Train Loss 43749.504 Test MSE 7884.405664797986 Test RE 0.15535331415248826\n",
      "44 Train Loss 43652.812 Test MSE 7913.936372456675 Test RE 0.1556439768715401\n",
      "45 Train Loss 43545.27 Test MSE 7906.3561214760775 Test RE 0.15556941833286334\n",
      "46 Train Loss 43338.996 Test MSE 7883.979850559872 Test RE 0.15534911900138193\n",
      "47 Train Loss 43221.445 Test MSE 7861.206813664534 Test RE 0.1551245921942828\n",
      "48 Train Loss 43103.938 Test MSE 7792.7732031887 Test RE 0.15444791872774494\n",
      "49 Train Loss 42912.406 Test MSE 7731.6443833808435 Test RE 0.15384095849341145\n",
      "50 Train Loss 42783.332 Test MSE 7702.424178032634 Test RE 0.15354997772281023\n",
      "51 Train Loss 42629.496 Test MSE 7743.86031801157 Test RE 0.15396244425123767\n",
      "52 Train Loss 42467.516 Test MSE 7719.5898984117985 Test RE 0.15372098421459482\n",
      "53 Train Loss 42323.39 Test MSE 7754.391155000575 Test RE 0.15406709506447283\n",
      "54 Train Loss 42178.188 Test MSE 7810.093759297378 Test RE 0.15461946478461855\n",
      "55 Train Loss 41976.695 Test MSE 7906.07787059335 Test RE 0.15556668080699337\n",
      "56 Train Loss 41890.594 Test MSE 7943.893188592477 Test RE 0.15593828009489916\n",
      "57 Train Loss 41682.49 Test MSE 8028.959759127881 Test RE 0.1567709833485889\n",
      "58 Train Loss 41460.254 Test MSE 7875.265392034949 Test RE 0.15526323866024172\n",
      "59 Train Loss 41189.332 Test MSE 7881.973842313473 Test RE 0.15532935414624613\n",
      "60 Train Loss 41023.297 Test MSE 7775.48677569555 Test RE 0.15427652050192284\n",
      "61 Train Loss 40839.28 Test MSE 7648.041446779231 Test RE 0.15300695004744944\n",
      "62 Train Loss 40616.188 Test MSE 7640.348649292703 Test RE 0.15292997951696946\n",
      "63 Train Loss 40357.7 Test MSE 7645.700457735399 Test RE 0.15298353130620768\n",
      "64 Train Loss 40173.01 Test MSE 7591.211634985629 Test RE 0.1524374206107157\n",
      "65 Train Loss 39941.094 Test MSE 7590.636699659587 Test RE 0.15243164792765626\n",
      "66 Train Loss 39679.504 Test MSE 7608.726473098719 Test RE 0.1526131750623156\n",
      "67 Train Loss 39553.977 Test MSE 7484.904446029704 Test RE 0.15136629194692114\n",
      "68 Train Loss 39345.79 Test MSE 7404.10412977036 Test RE 0.15054706767056197\n",
      "69 Train Loss 39225.688 Test MSE 7404.303160259879 Test RE 0.1505490910926188\n",
      "70 Train Loss 39064.72 Test MSE 7292.4083867005875 Test RE 0.14940720204492725\n",
      "71 Train Loss 38889.473 Test MSE 7346.511805063228 Test RE 0.14996041452581388\n",
      "72 Train Loss 38459.625 Test MSE 7356.48835188675 Test RE 0.15006220293647168\n",
      "73 Train Loss 38201.883 Test MSE 7132.83178595286 Test RE 0.14776345353949488\n",
      "74 Train Loss 37898.2 Test MSE 7084.808209386336 Test RE 0.14726518621497203\n",
      "75 Train Loss 37660.61 Test MSE 7132.355168590319 Test RE 0.1477585166640617\n",
      "76 Train Loss 37253.062 Test MSE 7140.004951782426 Test RE 0.14783773437494416\n",
      "77 Train Loss 36991.13 Test MSE 7030.299371515256 Test RE 0.14669758060356664\n",
      "78 Train Loss 36747.98 Test MSE 6977.854987527885 Test RE 0.14614939158158344\n",
      "79 Train Loss 36515.297 Test MSE 6903.53046284432 Test RE 0.14536895371326558\n",
      "80 Train Loss 36213.44 Test MSE 6833.282146531167 Test RE 0.14462744647210407\n",
      "81 Train Loss 36025.71 Test MSE 6809.079126172401 Test RE 0.14437108898378825\n",
      "82 Train Loss 35834.395 Test MSE 6824.248460748293 Test RE 0.14453181519468175\n",
      "83 Train Loss 35606.16 Test MSE 6650.289674224598 Test RE 0.14267777340719306\n",
      "84 Train Loss 35217.168 Test MSE 6594.736593008361 Test RE 0.14208059549119698\n",
      "85 Train Loss 34846.812 Test MSE 6410.446270410909 Test RE 0.14008130341593303\n",
      "86 Train Loss 34541.883 Test MSE 6293.936740659297 Test RE 0.13880248091206998\n",
      "87 Train Loss 34302.414 Test MSE 6266.396085055522 Test RE 0.13849846591658574\n",
      "88 Train Loss 33867.99 Test MSE 6174.700360842663 Test RE 0.1374814125316042\n",
      "89 Train Loss 33544.113 Test MSE 6266.492459974685 Test RE 0.13849953094080025\n",
      "90 Train Loss 33220.445 Test MSE 6089.439387793574 Test RE 0.13652893353596346\n",
      "91 Train Loss 33002.746 Test MSE 6092.182987380812 Test RE 0.1365596866578412\n",
      "92 Train Loss 32768.48 Test MSE 6112.856981773899 Test RE 0.13679119998208109\n",
      "93 Train Loss 32485.656 Test MSE 6150.662149816389 Test RE 0.13721354286128037\n",
      "94 Train Loss 32199.682 Test MSE 6001.238836027863 Test RE 0.1355365720439412\n",
      "95 Train Loss 31879.65 Test MSE 6011.906142923236 Test RE 0.13565697787440234\n",
      "96 Train Loss 31517.045 Test MSE 5817.848610677611 Test RE 0.13344959185477817\n",
      "97 Train Loss 31077.23 Test MSE 5636.939359778723 Test RE 0.13135836169375095\n",
      "98 Train Loss 30746.58 Test MSE 5710.260659248191 Test RE 0.13220990964584725\n",
      "99 Train Loss 30514.94 Test MSE 5800.585635531643 Test RE 0.13325145603008154\n",
      "100 Train Loss 30215.643 Test MSE 5881.645163579235 Test RE 0.13417927839636823\n",
      "101 Train Loss 29990.002 Test MSE 5907.169366771933 Test RE 0.1344701078746496\n",
      "102 Train Loss 29777.03 Test MSE 5861.146289334095 Test RE 0.13394525162206453\n",
      "103 Train Loss 29562.758 Test MSE 5799.86041571906 Test RE 0.1332431258697552\n",
      "104 Train Loss 29366.03 Test MSE 5767.201851725709 Test RE 0.13286745542864645\n",
      "105 Train Loss 29040.318 Test MSE 5573.1864885930045 Test RE 0.13061342853830415\n",
      "106 Train Loss 28766.81 Test MSE 5347.656059854159 Test RE 0.12794336698960426\n",
      "107 Train Loss 28599.312 Test MSE 5262.502908496933 Test RE 0.12692062915960697\n",
      "108 Train Loss 28381.176 Test MSE 5207.6064990303885 Test RE 0.12625690004792853\n",
      "109 Train Loss 28213.84 Test MSE 5226.552114913643 Test RE 0.12648635700699387\n",
      "110 Train Loss 28111.547 Test MSE 5116.930895917406 Test RE 0.12515287129658517\n",
      "111 Train Loss 27978.648 Test MSE 5200.199408266384 Test RE 0.1261670767191534\n",
      "112 Train Loss 27800.494 Test MSE 5144.739277056423 Test RE 0.1254924872821473\n",
      "113 Train Loss 27666.445 Test MSE 5110.713217977239 Test RE 0.1250768103925178\n",
      "114 Train Loss 27552.365 Test MSE 5086.379921788593 Test RE 0.12477869520449382\n",
      "115 Train Loss 27423.324 Test MSE 5139.895210591741 Test RE 0.12543339418961053\n",
      "116 Train Loss 27272.816 Test MSE 5218.539191675436 Test RE 0.12638936053505706\n",
      "117 Train Loss 27164.951 Test MSE 5210.1059205125175 Test RE 0.1262871952855356\n",
      "118 Train Loss 27005.055 Test MSE 5222.463386915754 Test RE 0.12643687223361416\n",
      "119 Train Loss 26773.105 Test MSE 5227.884404818071 Test RE 0.12650247717140645\n",
      "120 Train Loss 26485.447 Test MSE 5071.2472918061385 Test RE 0.12459294066220797\n",
      "121 Train Loss 26230.084 Test MSE 5065.601868277195 Test RE 0.1245235715561689\n",
      "122 Train Loss 26080.414 Test MSE 4980.3295830519155 Test RE 0.12347103363387466\n",
      "123 Train Loss 25918.717 Test MSE 5022.046154692592 Test RE 0.1239870684643239\n",
      "124 Train Loss 25779.86 Test MSE 4958.853433429968 Test RE 0.12320453046669147\n",
      "125 Train Loss 25635.182 Test MSE 4891.185883874732 Test RE 0.12236103049236058\n",
      "126 Train Loss 25451.693 Test MSE 4928.899187999139 Test RE 0.12283185472033606\n",
      "127 Train Loss 25301.623 Test MSE 4921.427510197148 Test RE 0.12273871951129964\n",
      "128 Train Loss 25115.441 Test MSE 4896.849205946994 Test RE 0.12243184864017213\n",
      "129 Train Loss 24958.516 Test MSE 5036.058513115401 Test RE 0.1241599204255952\n",
      "130 Train Loss 24840.703 Test MSE 5089.858904855046 Test RE 0.12482136098745367\n",
      "131 Train Loss 24734.85 Test MSE 5118.489835214416 Test RE 0.12517193456664466\n",
      "132 Train Loss 24605.094 Test MSE 5064.515225381403 Test RE 0.12451021481048452\n",
      "133 Train Loss 24491.111 Test MSE 5045.7843588230135 Test RE 0.1242797539983831\n",
      "134 Train Loss 24369.0 Test MSE 5116.525095424566 Test RE 0.12514790854597857\n",
      "135 Train Loss 24268.701 Test MSE 5272.966653256487 Test RE 0.1270467483826576\n",
      "136 Train Loss 24138.0 Test MSE 5309.144698468337 Test RE 0.1274818398958566\n",
      "137 Train Loss 24010.031 Test MSE 5411.84153451758 Test RE 0.12870889967251534\n",
      "138 Train Loss 23848.865 Test MSE 5397.970008470269 Test RE 0.12854384177309844\n",
      "139 Train Loss 23694.25 Test MSE 5286.134620861021 Test RE 0.1272052838365008\n",
      "140 Train Loss 23532.918 Test MSE 5310.810356151442 Test RE 0.12750183600314968\n",
      "141 Train Loss 23412.51 Test MSE 5393.637534660737 Test RE 0.12849224602339648\n",
      "142 Train Loss 23234.588 Test MSE 5372.75434661539 Test RE 0.1282432554211333\n",
      "143 Train Loss 23106.898 Test MSE 5305.583654645246 Test RE 0.12743907928249185\n",
      "144 Train Loss 22890.742 Test MSE 5280.918530677534 Test RE 0.12714250847782357\n",
      "145 Train Loss 22724.79 Test MSE 5322.165681008293 Test RE 0.12763807243216813\n",
      "146 Train Loss 22555.111 Test MSE 5352.551354513361 Test RE 0.128001913874889\n",
      "147 Train Loss 22436.996 Test MSE 5385.3181148662115 Test RE 0.1283931113059686\n",
      "148 Train Loss 22287.664 Test MSE 5558.033548197642 Test RE 0.1304357452120549\n",
      "149 Train Loss 22159.068 Test MSE 5582.219085505155 Test RE 0.13071922984397474\n",
      "150 Train Loss 22024.363 Test MSE 5550.662761271165 Test RE 0.1303492278283799\n",
      "151 Train Loss 21881.076 Test MSE 5640.639330804974 Test RE 0.13140146508494774\n",
      "152 Train Loss 21770.383 Test MSE 5714.461703026398 Test RE 0.13225853417748937\n",
      "153 Train Loss 21666.143 Test MSE 5713.804255270464 Test RE 0.1322509257987702\n",
      "154 Train Loss 21562.004 Test MSE 5655.360213462957 Test RE 0.1315728184564908\n",
      "155 Train Loss 21471.926 Test MSE 5507.840338387283 Test RE 0.12984544318845936\n",
      "156 Train Loss 21349.652 Test MSE 5426.177914881945 Test RE 0.12887926675683134\n",
      "157 Train Loss 21261.625 Test MSE 5394.660555620538 Test RE 0.12850443112366491\n",
      "158 Train Loss 21169.633 Test MSE 5391.575364596325 Test RE 0.1284676802091922\n",
      "159 Train Loss 21059.428 Test MSE 5362.546745620366 Test RE 0.12812137395665812\n",
      "160 Train Loss 20972.281 Test MSE 5383.612486653062 Test RE 0.12837277747882098\n",
      "161 Train Loss 20902.807 Test MSE 5387.748180053995 Test RE 0.12842207602396433\n",
      "162 Train Loss 20826.924 Test MSE 5382.753582725628 Test RE 0.12836253674538187\n",
      "163 Train Loss 20762.932 Test MSE 5365.640429357572 Test RE 0.12815832560292675\n",
      "164 Train Loss 20727.59 Test MSE 5318.970477548103 Test RE 0.12759975242632526\n",
      "165 Train Loss 20661.03 Test MSE 5271.550323116491 Test RE 0.12702968472234488\n",
      "166 Train Loss 20613.252 Test MSE 5236.13578167638 Test RE 0.1266022697434225\n",
      "167 Train Loss 20570.695 Test MSE 5218.9077155509385 Test RE 0.12639382315122036\n",
      "168 Train Loss 20535.488 Test MSE 5213.8049493723165 Test RE 0.1263320175120377\n",
      "169 Train Loss 20492.469 Test MSE 5218.771450192369 Test RE 0.12639217307298592\n",
      "170 Train Loss 20432.062 Test MSE 5242.7662297637935 Test RE 0.12668240175687095\n",
      "171 Train Loss 20392.674 Test MSE 5159.957003938389 Test RE 0.1256779486035612\n",
      "172 Train Loss 20360.15 Test MSE 5128.499437013646 Test RE 0.12529426647644115\n",
      "173 Train Loss 20319.467 Test MSE 5162.640992895488 Test RE 0.1257106305011741\n",
      "174 Train Loss 20278.605 Test MSE 5167.902507585111 Test RE 0.12577467329359296\n",
      "175 Train Loss 20244.914 Test MSE 5173.824997744366 Test RE 0.12584672244406273\n",
      "176 Train Loss 20189.902 Test MSE 5117.9307860973795 Test RE 0.12516509864700723\n",
      "177 Train Loss 20146.453 Test MSE 5084.011398628092 Test RE 0.12474963960429179\n",
      "178 Train Loss 20099.697 Test MSE 5103.483539603366 Test RE 0.1249883114790449\n",
      "179 Train Loss 20056.594 Test MSE 5120.768074980752 Test RE 0.12519978848085772\n",
      "180 Train Loss 20004.814 Test MSE 5131.046852469789 Test RE 0.1253253805410523\n",
      "181 Train Loss 19944.246 Test MSE 5169.608806451773 Test RE 0.12579543524397768\n",
      "182 Train Loss 19874.475 Test MSE 5145.834625252597 Test RE 0.12550584565139908\n",
      "183 Train Loss 19825.8 Test MSE 5151.066944685462 Test RE 0.1255696370357811\n",
      "184 Train Loss 19775.803 Test MSE 5104.765475952469 Test RE 0.12500400830631198\n",
      "185 Train Loss 19727.88 Test MSE 5130.305559753902 Test RE 0.12531632720845878\n",
      "186 Train Loss 19688.854 Test MSE 5153.961142398095 Test RE 0.12560490859465642\n",
      "187 Train Loss 19640.053 Test MSE 5192.767784660146 Test RE 0.12607689157596277\n",
      "188 Train Loss 19593.516 Test MSE 5214.777192113149 Test RE 0.12634379582583447\n",
      "189 Train Loss 19564.652 Test MSE 5228.602363748954 Test RE 0.12651116332991588\n",
      "190 Train Loss 19527.23 Test MSE 5208.530468356172 Test RE 0.12626810023449692\n",
      "191 Train Loss 19475.918 Test MSE 5190.463858289026 Test RE 0.12604891958553152\n",
      "192 Train Loss 19438.057 Test MSE 5216.189621232833 Test RE 0.12636090485733406\n",
      "193 Train Loss 19405.902 Test MSE 5255.678998693614 Test RE 0.12683831320747802\n",
      "194 Train Loss 19371.672 Test MSE 5316.841531788126 Test RE 0.1275742136363358\n",
      "195 Train Loss 19326.283 Test MSE 5354.683846185663 Test RE 0.12802740973799695\n",
      "196 Train Loss 19265.984 Test MSE 5379.156901564803 Test RE 0.12831964454734224\n",
      "197 Train Loss 19224.365 Test MSE 5379.622513257686 Test RE 0.12832519800443334\n",
      "198 Train Loss 19186.787 Test MSE 5377.722259212459 Test RE 0.12830253172870915\n",
      "199 Train Loss 19132.158 Test MSE 5408.552725752368 Test RE 0.12866978514148325\n",
      "Training time: 171.22\n",
      "Training time: 171.22\n",
      "ES_stan_high\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 233782.16 Test MSE 68226.90567361467 Test RE 0.4569975579331742\n",
      "1 Train Loss 161797.52 Test MSE 37801.74725910005 Test RE 0.34016684256068314\n",
      "2 Train Loss 115859.99 Test MSE 27707.022848558423 Test RE 0.29122655527826363\n",
      "3 Train Loss 94227.77 Test MSE 22132.369685933165 Test RE 0.2602855147813731\n",
      "4 Train Loss 83047.06 Test MSE 18421.70748752157 Test RE 0.23746575176837834\n",
      "5 Train Loss 75404.305 Test MSE 15304.248431290593 Test RE 0.21644225266908462\n",
      "6 Train Loss 70357.09 Test MSE 15668.817064273424 Test RE 0.21900505889223923\n",
      "7 Train Loss 65697.8 Test MSE 14780.857454547397 Test RE 0.21270899526523152\n",
      "8 Train Loss 62172.32 Test MSE 13696.656766324506 Test RE 0.2047591547733175\n",
      "9 Train Loss 60097.883 Test MSE 12408.662002030107 Test RE 0.19489402253277216\n",
      "10 Train Loss 58672.637 Test MSE 12434.414743428892 Test RE 0.19509615770025932\n",
      "11 Train Loss 57358.64 Test MSE 12178.724026731183 Test RE 0.19307984278307963\n",
      "12 Train Loss 55649.543 Test MSE 11556.31616078929 Test RE 0.18808135688607056\n",
      "13 Train Loss 53920.3 Test MSE 11604.299465454525 Test RE 0.18847142134636438\n",
      "14 Train Loss 52627.027 Test MSE 11250.261746923034 Test RE 0.18557409669266972\n",
      "15 Train Loss 51511.68 Test MSE 10893.64033902216 Test RE 0.18260915976397554\n",
      "16 Train Loss 50505.9 Test MSE 10791.59767734404 Test RE 0.1817518812726344\n",
      "17 Train Loss 49760.89 Test MSE 10628.274077803791 Test RE 0.1803712913150756\n",
      "18 Train Loss 48819.28 Test MSE 10297.741368474824 Test RE 0.1775444218022868\n",
      "19 Train Loss 47875.113 Test MSE 10328.382956905196 Test RE 0.17780837299160032\n",
      "20 Train Loss 47003.188 Test MSE 10035.022533626729 Test RE 0.17526500834319483\n",
      "21 Train Loss 46241.42 Test MSE 9736.899887446025 Test RE 0.17264197442980384\n",
      "22 Train Loss 45566.805 Test MSE 9490.18823561804 Test RE 0.17044075729220898\n",
      "23 Train Loss 44723.242 Test MSE 9414.745621445214 Test RE 0.1697619428772244\n",
      "24 Train Loss 43992.305 Test MSE 9449.976536437185 Test RE 0.1700792793200697\n",
      "25 Train Loss 43196.383 Test MSE 9277.430782358431 Test RE 0.16851939963843604\n",
      "26 Train Loss 42521.79 Test MSE 8877.423823203217 Test RE 0.16484641965043864\n",
      "27 Train Loss 41944.395 Test MSE 8755.152881238708 Test RE 0.16370724838545475\n",
      "28 Train Loss 41383.4 Test MSE 8722.95436072637 Test RE 0.1634059408833032\n",
      "29 Train Loss 40717.895 Test MSE 8683.511614872923 Test RE 0.1630360844636267\n",
      "30 Train Loss 40188.94 Test MSE 8720.894803943776 Test RE 0.16338664904320882\n",
      "31 Train Loss 39803.03 Test MSE 8498.738701395825 Test RE 0.16129216827963241\n",
      "32 Train Loss 39392.023 Test MSE 8168.551517119503 Test RE 0.15812792354385496\n",
      "33 Train Loss 38929.027 Test MSE 8041.976843244622 Test RE 0.15689801565901373\n",
      "34 Train Loss 38439.023 Test MSE 7562.827647709878 Test RE 0.15215216747081772\n",
      "35 Train Loss 37967.96 Test MSE 7512.465035661505 Test RE 0.15164471307351332\n",
      "36 Train Loss 37562.11 Test MSE 7364.992707766549 Test RE 0.1501489164403954\n",
      "37 Train Loss 37196.586 Test MSE 7288.189507226504 Test RE 0.14936397749294547\n",
      "38 Train Loss 36701.715 Test MSE 7266.70084630956 Test RE 0.14914362090135697\n",
      "39 Train Loss 36210.844 Test MSE 6877.234562786311 Test RE 0.14509183068360637\n",
      "40 Train Loss 35641.594 Test MSE 6737.363849900358 Test RE 0.1436087965577637\n",
      "41 Train Loss 35154.38 Test MSE 6716.785622725441 Test RE 0.14338931349889025\n",
      "42 Train Loss 34685.785 Test MSE 6882.7632130597885 Test RE 0.14515013906549462\n",
      "43 Train Loss 34200.938 Test MSE 6656.634494032296 Test RE 0.14274581923597426\n",
      "44 Train Loss 33689.777 Test MSE 6796.814519759998 Test RE 0.1442410087922092\n",
      "45 Train Loss 33170.117 Test MSE 6641.349660075155 Test RE 0.1425818399709873\n",
      "46 Train Loss 32688.611 Test MSE 6837.849175575574 Test RE 0.14467576932830864\n",
      "47 Train Loss 32156.758 Test MSE 6674.065479091164 Test RE 0.14293259330932664\n",
      "48 Train Loss 31794.928 Test MSE 6575.9089073868145 Test RE 0.14187763357116084\n",
      "49 Train Loss 31312.402 Test MSE 6834.1721022543115 Test RE 0.1446368641889795\n",
      "50 Train Loss 30706.969 Test MSE 6494.1010938248755 Test RE 0.14099235490901496\n",
      "51 Train Loss 30304.715 Test MSE 6538.801839312671 Test RE 0.14147676799680808\n",
      "52 Train Loss 29818.834 Test MSE 6437.918086671776 Test RE 0.14038114008415967\n",
      "53 Train Loss 29417.686 Test MSE 6412.612034778296 Test RE 0.14010496459821034\n",
      "54 Train Loss 29012.168 Test MSE 6376.662551461031 Test RE 0.13971169427968855\n",
      "55 Train Loss 28635.523 Test MSE 6455.596319174244 Test RE 0.14057374808899684\n",
      "56 Train Loss 28287.764 Test MSE 6524.39836146683 Test RE 0.1413208616886516\n",
      "57 Train Loss 28021.0 Test MSE 6413.067563623938 Test RE 0.14010994078568806\n",
      "58 Train Loss 27781.434 Test MSE 6377.699197661169 Test RE 0.139723050197461\n",
      "59 Train Loss 27504.799 Test MSE 6354.213375324744 Test RE 0.1394655484526707\n",
      "60 Train Loss 27207.729 Test MSE 6187.14491858408 Test RE 0.13761988355894367\n",
      "61 Train Loss 26993.383 Test MSE 6091.577869373963 Test RE 0.13655290446025758\n",
      "62 Train Loss 26777.97 Test MSE 6160.525375642905 Test RE 0.1373235168766567\n",
      "63 Train Loss 26523.47 Test MSE 6168.336935532888 Test RE 0.13741055255758267\n",
      "64 Train Loss 26345.125 Test MSE 6151.76537688682 Test RE 0.13722584811425864\n",
      "65 Train Loss 26102.232 Test MSE 6128.123044513592 Test RE 0.13696190255877758\n",
      "66 Train Loss 25925.928 Test MSE 6051.45621351904 Test RE 0.13610246453463395\n",
      "67 Train Loss 25755.324 Test MSE 6030.7238548535715 Test RE 0.1358691201977567\n",
      "68 Train Loss 25597.604 Test MSE 5938.709234060359 Test RE 0.13482861488438247\n",
      "69 Train Loss 25481.834 Test MSE 5961.786537024235 Test RE 0.13509032696649134\n",
      "70 Train Loss 25358.955 Test MSE 5949.501089005773 Test RE 0.1349510649291094\n",
      "71 Train Loss 25213.648 Test MSE 5849.840015224907 Test RE 0.13381599765886718\n",
      "72 Train Loss 25072.08 Test MSE 5848.508844926208 Test RE 0.13380077142908658\n",
      "73 Train Loss 24972.998 Test MSE 5843.982230549762 Test RE 0.13374898201150653\n",
      "74 Train Loss 24835.95 Test MSE 5736.667266954713 Test RE 0.13251525370339534\n",
      "75 Train Loss 24583.852 Test MSE 5550.830008359678 Test RE 0.1303511915906878\n",
      "76 Train Loss 24454.781 Test MSE 5453.185698564886 Test RE 0.12919960484478193\n",
      "77 Train Loss 24284.201 Test MSE 5322.978235815098 Test RE 0.12764781554965493\n",
      "78 Train Loss 24105.234 Test MSE 5326.331851230302 Test RE 0.1276880199482597\n",
      "79 Train Loss 23953.182 Test MSE 5385.891808719221 Test RE 0.12839994993421366\n",
      "80 Train Loss 23852.695 Test MSE 5368.877463591369 Test RE 0.1281969780566793\n",
      "81 Train Loss 23694.47 Test MSE 5456.896739712283 Test RE 0.12924355929010972\n",
      "82 Train Loss 23569.043 Test MSE 5502.721551836714 Test RE 0.12978509234631017\n",
      "83 Train Loss 23446.172 Test MSE 5458.183947109149 Test RE 0.12925880178633994\n",
      "84 Train Loss 23299.832 Test MSE 5396.679301712355 Test RE 0.12852847281736093\n",
      "85 Train Loss 23163.654 Test MSE 5340.857727826924 Test RE 0.12786201563730779\n",
      "86 Train Loss 23041.688 Test MSE 5283.243992004239 Test RE 0.12717049910509323\n",
      "87 Train Loss 22895.93 Test MSE 5260.706002839554 Test RE 0.1268989584952603\n",
      "88 Train Loss 22685.29 Test MSE 5224.270518622454 Test RE 0.12645874584968758\n",
      "89 Train Loss 22569.945 Test MSE 5230.5796863573205 Test RE 0.12653508269881625\n",
      "90 Train Loss 22445.318 Test MSE 5306.530362904085 Test RE 0.12745044864873054\n",
      "91 Train Loss 22352.117 Test MSE 5240.461629641714 Test RE 0.12665455535320755\n",
      "92 Train Loss 22259.996 Test MSE 5230.714621479706 Test RE 0.12653671482353082\n",
      "93 Train Loss 22101.445 Test MSE 5258.056691154018 Test RE 0.12686700107059498\n",
      "94 Train Loss 21976.154 Test MSE 5235.009351503355 Test RE 0.12658865127618846\n",
      "95 Train Loss 21842.477 Test MSE 5281.842375696122 Test RE 0.12715362916031062\n",
      "96 Train Loss 21709.453 Test MSE 5279.334350579417 Test RE 0.12712343682030905\n",
      "97 Train Loss 21602.729 Test MSE 5195.30502236893 Test RE 0.12610768902265465\n",
      "98 Train Loss 21450.152 Test MSE 5169.38571061418 Test RE 0.12579272084702517\n",
      "99 Train Loss 21326.973 Test MSE 5133.001794720121 Test RE 0.12534925291604393\n",
      "100 Train Loss 21194.988 Test MSE 5197.161982231217 Test RE 0.1261302243689034\n",
      "101 Train Loss 21096.367 Test MSE 5235.854734537173 Test RE 0.1265988720390202\n",
      "102 Train Loss 20979.176 Test MSE 5205.12241454857 Test RE 0.1262267835043042\n",
      "103 Train Loss 20884.232 Test MSE 5135.595602150034 Test RE 0.12538091964567277\n",
      "104 Train Loss 20797.611 Test MSE 5113.471165050831 Test RE 0.12511055408768312\n",
      "105 Train Loss 20681.22 Test MSE 5017.418840906775 Test RE 0.12392993445236385\n",
      "106 Train Loss 20583.791 Test MSE 5037.481185813777 Test RE 0.12417745660545897\n",
      "107 Train Loss 20466.248 Test MSE 5030.182637201072 Test RE 0.1240874668182371\n",
      "108 Train Loss 20352.572 Test MSE 4980.613868351156 Test RE 0.12347455754712855\n",
      "109 Train Loss 20242.322 Test MSE 5021.898747190613 Test RE 0.1239852488117766\n",
      "110 Train Loss 20113.025 Test MSE 5056.638560324948 Test RE 0.1244133539231805\n",
      "111 Train Loss 19952.846 Test MSE 5126.159886653128 Test RE 0.1252656844625157\n",
      "112 Train Loss 19856.88 Test MSE 5137.216539262303 Test RE 0.12540070494103797\n",
      "113 Train Loss 19758.102 Test MSE 5184.114311245878 Test RE 0.1259717975318495\n",
      "114 Train Loss 19673.785 Test MSE 5271.665565749319 Test RE 0.12703107322804155\n",
      "115 Train Loss 19511.873 Test MSE 5369.0774977429755 Test RE 0.12819936622208844\n",
      "116 Train Loss 19385.598 Test MSE 5500.11809325625 Test RE 0.12975438662329933\n",
      "117 Train Loss 19284.244 Test MSE 5576.2555218088855 Test RE 0.13064938658320552\n",
      "118 Train Loss 19171.324 Test MSE 5630.124307914402 Test RE 0.13127893164027477\n",
      "119 Train Loss 19059.58 Test MSE 5682.388870362915 Test RE 0.1318868565970817\n",
      "120 Train Loss 18960.102 Test MSE 5586.5152384441035 Test RE 0.13076952183221566\n",
      "121 Train Loss 18860.475 Test MSE 5633.732969910381 Test RE 0.13132099691077898\n",
      "122 Train Loss 18758.623 Test MSE 5566.318172977808 Test RE 0.1305329206623695\n",
      "123 Train Loss 18648.932 Test MSE 5511.07538227709 Test RE 0.12988357011477855\n",
      "124 Train Loss 18550.793 Test MSE 5545.2137409284205 Test RE 0.1302852309664223\n",
      "125 Train Loss 18411.576 Test MSE 5547.579133550359 Test RE 0.13031301554617483\n",
      "126 Train Loss 18316.6 Test MSE 5628.8834986962565 Test RE 0.13126446472307585\n",
      "127 Train Loss 18227.496 Test MSE 5714.874029707146 Test RE 0.13226330564517505\n",
      "128 Train Loss 18142.047 Test MSE 5789.48521105767 Test RE 0.13312389511245198\n",
      "129 Train Loss 18080.27 Test MSE 5798.957780170403 Test RE 0.13323275711488966\n",
      "130 Train Loss 17964.023 Test MSE 5839.114971043107 Test RE 0.13369327285786708\n",
      "131 Train Loss 17847.326 Test MSE 6014.5730882783355 Test RE 0.1356870639755393\n",
      "132 Train Loss 17741.643 Test MSE 6109.391638701329 Test RE 0.13675242141759805\n",
      "133 Train Loss 17646.295 Test MSE 6239.482202240985 Test RE 0.13820072360639196\n",
      "134 Train Loss 17542.648 Test MSE 6286.921111865326 Test RE 0.13872510023328033\n",
      "135 Train Loss 17452.654 Test MSE 6502.016489466538 Test RE 0.14107825366525878\n",
      "136 Train Loss 17349.643 Test MSE 6573.818970158157 Test RE 0.14185508620047357\n",
      "137 Train Loss 17272.172 Test MSE 6635.862166826225 Test RE 0.1425229228373166\n",
      "138 Train Loss 17199.822 Test MSE 6707.895941914855 Test RE 0.1432943940432312\n",
      "139 Train Loss 17147.209 Test MSE 6720.856279110653 Test RE 0.1434327569143221\n",
      "140 Train Loss 17077.695 Test MSE 6782.902667023639 Test RE 0.14409331552084068\n",
      "141 Train Loss 16994.412 Test MSE 6790.100374323684 Test RE 0.14416974788055223\n",
      "142 Train Loss 16928.074 Test MSE 6825.385916845204 Test RE 0.14454385987223675\n",
      "143 Train Loss 16837.217 Test MSE 6862.4693526842875 Test RE 0.14493599315547911\n",
      "144 Train Loss 16793.95 Test MSE 6914.513011229891 Test RE 0.1454845385665964\n",
      "145 Train Loss 16732.213 Test MSE 6871.016028537239 Test RE 0.14502621836789417\n",
      "146 Train Loss 16658.15 Test MSE 6851.713633242602 Test RE 0.14482236771684143\n",
      "147 Train Loss 16594.973 Test MSE 6905.37984603201 Test RE 0.1453884238161224\n",
      "148 Train Loss 16546.19 Test MSE 6980.366507067454 Test RE 0.14617569078318626\n",
      "149 Train Loss 16496.914 Test MSE 6973.728424220143 Test RE 0.14610617028300898\n",
      "150 Train Loss 16418.21 Test MSE 7014.0946924536765 Test RE 0.14652841578507012\n",
      "151 Train Loss 16341.256 Test MSE 7036.253986396751 Test RE 0.14675969337151043\n",
      "152 Train Loss 16310.132 Test MSE 7062.498895881837 Test RE 0.14703314213393895\n",
      "153 Train Loss 16264.295 Test MSE 7035.998810722102 Test RE 0.14675703216546385\n",
      "154 Train Loss 16216.54 Test MSE 7053.569595547875 Test RE 0.14694016383040834\n",
      "155 Train Loss 16157.145 Test MSE 7027.983142439606 Test RE 0.1466734128423586\n",
      "156 Train Loss 16118.316 Test MSE 7018.762872776825 Test RE 0.14657716814185084\n",
      "157 Train Loss 16080.511 Test MSE 6995.140632192263 Test RE 0.14633030132044328\n",
      "158 Train Loss 16034.157 Test MSE 6962.814163324454 Test RE 0.14599179349792796\n",
      "159 Train Loss 15998.494 Test MSE 6976.511600815867 Test RE 0.1461353224585103\n",
      "160 Train Loss 15912.396 Test MSE 7020.542080312476 Test RE 0.14659574511059484\n",
      "161 Train Loss 15860.781 Test MSE 7009.134668746413 Test RE 0.1464765977686349\n",
      "162 Train Loss 15811.186 Test MSE 7043.043231520797 Test RE 0.14683048013518796\n",
      "163 Train Loss 15771.275 Test MSE 7050.438906463887 Test RE 0.14690755090890836\n",
      "164 Train Loss 15704.521 Test MSE 7167.366578563458 Test RE 0.14812073228600273\n",
      "165 Train Loss 15648.029 Test MSE 7143.649847225101 Test RE 0.1478754643440264\n",
      "166 Train Loss 15597.556 Test MSE 7151.49628522229 Test RE 0.1479566537395543\n",
      "167 Train Loss 15547.487 Test MSE 7183.726167457413 Test RE 0.148289679492385\n",
      "168 Train Loss 15505.44 Test MSE 7207.61210770933 Test RE 0.14853600701802697\n",
      "169 Train Loss 15458.619 Test MSE 7268.983479356989 Test RE 0.14916704373341763\n",
      "170 Train Loss 15402.165 Test MSE 7313.745634781722 Test RE 0.1496256216555386\n",
      "171 Train Loss 15353.749 Test MSE 7316.89968568968 Test RE 0.14965788118319975\n",
      "172 Train Loss 15263.509 Test MSE 7323.646387159616 Test RE 0.14972686288613868\n",
      "173 Train Loss 15202.326 Test MSE 7274.6470606061375 Test RE 0.14922514368504186\n",
      "174 Train Loss 15138.643 Test MSE 7267.176269542974 Test RE 0.1491484996753886\n",
      "175 Train Loss 15076.105 Test MSE 7246.378581229825 Test RE 0.14893492521315502\n",
      "176 Train Loss 14973.988 Test MSE 7263.142875183741 Test RE 0.14910710407763958\n",
      "177 Train Loss 14868.891 Test MSE 7202.462668184947 Test RE 0.1484829371636621\n",
      "178 Train Loss 14745.389 Test MSE 7108.513429901639 Test RE 0.14751134943986874\n",
      "179 Train Loss 14595.671 Test MSE 7066.514011234243 Test RE 0.14707493124802307\n",
      "180 Train Loss 14519.986 Test MSE 7076.026947443499 Test RE 0.14717389403799822\n",
      "181 Train Loss 14449.35 Test MSE 7037.70970920628 Test RE 0.14677487406174036\n",
      "182 Train Loss 14397.204 Test MSE 7116.921448012638 Test RE 0.14759856258038093\n",
      "183 Train Loss 14313.101 Test MSE 7236.895719735242 Test RE 0.14883744261478063\n",
      "184 Train Loss 14230.568 Test MSE 7257.618309147776 Test RE 0.149050385604704\n",
      "185 Train Loss 14174.07 Test MSE 7266.31810099032 Test RE 0.14913969306837663\n",
      "186 Train Loss 14111.701 Test MSE 7284.341143955957 Test RE 0.14932453815462782\n",
      "187 Train Loss 14021.319 Test MSE 7231.645622389005 Test RE 0.14878344481894942\n",
      "188 Train Loss 13936.105 Test MSE 7222.927137729259 Test RE 0.14869373097984961\n",
      "189 Train Loss 13875.215 Test MSE 7184.526991747416 Test RE 0.14829794474812483\n",
      "190 Train Loss 13823.324 Test MSE 7171.203619845281 Test RE 0.1481603751110797\n",
      "191 Train Loss 13656.927 Test MSE 7054.198215584661 Test RE 0.14694671139983545\n",
      "192 Train Loss 13580.558 Test MSE 7031.469512335599 Test RE 0.14670978845390725\n",
      "193 Train Loss 13526.143 Test MSE 6992.954544738996 Test RE 0.14630743431539212\n",
      "194 Train Loss 13465.576 Test MSE 6957.322835311686 Test RE 0.14593421283192087\n",
      "195 Train Loss 13415.969 Test MSE 6869.15553864798 Test RE 0.14500658240144285\n",
      "196 Train Loss 13340.95 Test MSE 6787.0987475414495 Test RE 0.14413787857172466\n",
      "197 Train Loss 13287.959 Test MSE 6765.365074439416 Test RE 0.14390691409656337\n",
      "198 Train Loss 13237.623 Test MSE 6726.8949680074475 Test RE 0.1434971796076535\n",
      "199 Train Loss 13205.943 Test MSE 6695.6328147429695 Test RE 0.1431633513693102\n",
      "Training time: 175.11\n",
      "Training time: 175.11\n",
      "ES_stan_high\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 220865.72 Test MSE 61326.87712144916 Test RE 0.4332728410803701\n",
      "1 Train Loss 124116.26 Test MSE 28576.230287077025 Test RE 0.29575936857484814\n",
      "2 Train Loss 80268.29 Test MSE 18900.02746809349 Test RE 0.2405288968843964\n",
      "3 Train Loss 66770.766 Test MSE 16531.795758301825 Test RE 0.22495521076369024\n",
      "4 Train Loss 59089.676 Test MSE 13198.624246432802 Test RE 0.20100199797721516\n",
      "5 Train Loss 54207.684 Test MSE 10867.253322437033 Test RE 0.18238786402560994\n",
      "6 Train Loss 51705.344 Test MSE 10198.386960951742 Test RE 0.17668585608752718\n",
      "7 Train Loss 49652.215 Test MSE 9386.513129564655 Test RE 0.16950721474268188\n",
      "8 Train Loss 47882.465 Test MSE 8812.75105402923 Test RE 0.16424486212582698\n",
      "9 Train Loss 46513.36 Test MSE 8873.872299014989 Test RE 0.1648134419181113\n",
      "10 Train Loss 45531.03 Test MSE 8782.628329509955 Test RE 0.16396392047144584\n",
      "11 Train Loss 44758.723 Test MSE 8595.840326822601 Test RE 0.16221096638351803\n",
      "12 Train Loss 44135.1 Test MSE 8714.922575051967 Test RE 0.16333069437321474\n",
      "13 Train Loss 43498.203 Test MSE 8288.047843998847 Test RE 0.15928033724835497\n",
      "14 Train Loss 42990.637 Test MSE 7875.341538272505 Test RE 0.1552639892814772\n",
      "15 Train Loss 42410.367 Test MSE 7896.011140006219 Test RE 0.15546760850365976\n",
      "16 Train Loss 41781.754 Test MSE 7579.129639475605 Test RE 0.15231606438165676\n",
      "17 Train Loss 41126.44 Test MSE 7563.616229257078 Test RE 0.15216009977270736\n",
      "18 Train Loss 40260.12 Test MSE 7112.750928201692 Test RE 0.14755530982423762\n",
      "19 Train Loss 39515.773 Test MSE 7212.796696176609 Test RE 0.14858941996674477\n",
      "20 Train Loss 38509.043 Test MSE 6995.484856150716 Test RE 0.14633390166091934\n",
      "21 Train Loss 37985.668 Test MSE 6839.977643826871 Test RE 0.14469828472854984\n",
      "22 Train Loss 37185.008 Test MSE 7011.585251399915 Test RE 0.14650220161683922\n",
      "23 Train Loss 36552.395 Test MSE 6863.096148465538 Test RE 0.14494261199704397\n",
      "24 Train Loss 36097.645 Test MSE 6828.56614874885 Test RE 0.1445775304563139\n",
      "25 Train Loss 35502.805 Test MSE 6886.318910333478 Test RE 0.1451876271569943\n",
      "26 Train Loss 34957.527 Test MSE 6638.763706327109 Test RE 0.14255407860013236\n",
      "27 Train Loss 34334.438 Test MSE 6489.3417319964965 Test RE 0.14094068058078218\n",
      "28 Train Loss 33947.7 Test MSE 6474.561373811157 Test RE 0.14078008330087455\n",
      "29 Train Loss 33456.125 Test MSE 6566.572769131846 Test RE 0.1417768825038204\n",
      "30 Train Loss 32890.457 Test MSE 6600.512948371579 Test RE 0.14214280634386212\n",
      "31 Train Loss 32292.86 Test MSE 6389.966467491741 Test RE 0.13985736171664437\n",
      "32 Train Loss 31715.805 Test MSE 5935.407685629668 Test RE 0.13479113156355982\n",
      "33 Train Loss 31166.258 Test MSE 5770.18171954063 Test RE 0.13290177678017176\n",
      "34 Train Loss 30713.592 Test MSE 5698.8543851663935 Test RE 0.13207779866357774\n",
      "35 Train Loss 30351.35 Test MSE 5535.827583737147 Test RE 0.13017492001792536\n",
      "36 Train Loss 29836.66 Test MSE 5424.312523819878 Test RE 0.12885711203748287\n",
      "37 Train Loss 29146.834 Test MSE 5235.0205444645435 Test RE 0.12658878660556502\n",
      "38 Train Loss 28482.32 Test MSE 5086.767382300498 Test RE 0.12478344769026754\n",
      "39 Train Loss 27989.186 Test MSE 5057.207258247905 Test RE 0.1244203498381441\n",
      "40 Train Loss 27486.676 Test MSE 5048.776683618896 Test RE 0.12431659963467953\n",
      "41 Train Loss 27052.848 Test MSE 4866.875592470721 Test RE 0.12205657082348216\n",
      "42 Train Loss 26604.256 Test MSE 4978.651325730046 Test RE 0.12345022842184006\n",
      "43 Train Loss 26197.066 Test MSE 4974.4958276970065 Test RE 0.12339869797338077\n",
      "44 Train Loss 25739.428 Test MSE 4800.909368649258 Test RE 0.12122656392007201\n",
      "45 Train Loss 25262.754 Test MSE 4635.281885831434 Test RE 0.11911710144025538\n",
      "46 Train Loss 24915.547 Test MSE 4689.590867497091 Test RE 0.11981288327781105\n",
      "47 Train Loss 24450.266 Test MSE 4797.524783609034 Test RE 0.1211838247301422\n",
      "48 Train Loss 24033.707 Test MSE 4907.563174608247 Test RE 0.12256571168392932\n",
      "49 Train Loss 23766.26 Test MSE 5023.580410617475 Test RE 0.12400600629981043\n",
      "50 Train Loss 23442.414 Test MSE 5236.816657978779 Test RE 0.12661050078314562\n",
      "51 Train Loss 23048.795 Test MSE 5115.318008846534 Test RE 0.12513314527709443\n",
      "52 Train Loss 22718.78 Test MSE 5097.109366786541 Test RE 0.12491023284781586\n",
      "53 Train Loss 22292.797 Test MSE 5075.517992594492 Test RE 0.12464539197851436\n",
      "54 Train Loss 21880.066 Test MSE 5242.50348886847 Test RE 0.12667922737685616\n",
      "55 Train Loss 21409.396 Test MSE 5335.256890715807 Test RE 0.12779495504462995\n",
      "56 Train Loss 21056.34 Test MSE 5419.682445780557 Test RE 0.1288021054489411\n",
      "57 Train Loss 20751.738 Test MSE 5553.016695133626 Test RE 0.13037686425224645\n",
      "58 Train Loss 20425.977 Test MSE 5196.143886848887 Test RE 0.1261178696559959\n",
      "59 Train Loss 20234.791 Test MSE 5261.473380576317 Test RE 0.12690821351584083\n",
      "60 Train Loss 20027.809 Test MSE 5347.0192147439575 Test RE 0.12793574846171824\n",
      "61 Train Loss 19830.41 Test MSE 5227.601952160214 Test RE 0.1264990597810466\n",
      "62 Train Loss 19574.154 Test MSE 5279.223285110066 Test RE 0.1271220996158911\n",
      "63 Train Loss 19369.982 Test MSE 5192.576734159728 Test RE 0.12607457226612837\n",
      "64 Train Loss 19101.756 Test MSE 5362.660476387024 Test RE 0.12812273257090606\n",
      "65 Train Loss 18894.879 Test MSE 5495.13257735346 Test RE 0.12969556613931452\n",
      "66 Train Loss 18687.639 Test MSE 5480.2761877667635 Test RE 0.12952012797636364\n",
      "67 Train Loss 18469.086 Test MSE 5576.225243124878 Test RE 0.1306490318741318\n",
      "68 Train Loss 18315.145 Test MSE 5534.435414319475 Test RE 0.1301585505650208\n",
      "69 Train Loss 18147.686 Test MSE 5553.440424737725 Test RE 0.13038183843891574\n",
      "70 Train Loss 18024.793 Test MSE 5555.610630620494 Test RE 0.13040731163866248\n",
      "71 Train Loss 17866.467 Test MSE 5617.8523355730285 Test RE 0.13113577935894585\n",
      "72 Train Loss 17733.424 Test MSE 5594.036222083367 Test RE 0.13085751806908424\n",
      "73 Train Loss 17663.652 Test MSE 5667.57676852801 Test RE 0.1317148518027346\n",
      "74 Train Loss 17592.326 Test MSE 5596.918496405098 Test RE 0.13089122527786057\n",
      "75 Train Loss 17491.854 Test MSE 5637.302352608714 Test RE 0.13136259106121512\n",
      "76 Train Loss 17384.99 Test MSE 5733.66794608456 Test RE 0.13248060747833867\n",
      "77 Train Loss 17222.05 Test MSE 5773.750790853769 Test RE 0.13294287276432884\n",
      "78 Train Loss 17115.58 Test MSE 5918.30174111702 Test RE 0.13459675626318923\n",
      "79 Train Loss 16966.67 Test MSE 5914.71400318865 Test RE 0.13455595308051396\n",
      "80 Train Loss 16863.729 Test MSE 5936.796525594711 Test RE 0.13480690068765452\n",
      "81 Train Loss 16763.072 Test MSE 5979.415865491406 Test RE 0.13528991426601006\n",
      "82 Train Loss 16644.326 Test MSE 5998.941918945258 Test RE 0.1355106318947329\n",
      "83 Train Loss 16509.986 Test MSE 5881.89307783043 Test RE 0.1341821062280274\n",
      "84 Train Loss 16373.714 Test MSE 5860.054490836904 Test RE 0.13393277556122274\n",
      "85 Train Loss 16262.025 Test MSE 5930.853618841987 Test RE 0.13473941097079162\n",
      "86 Train Loss 16122.484 Test MSE 5831.814800958215 Test RE 0.13360967381289476\n",
      "87 Train Loss 15990.85 Test MSE 5902.750810598181 Test RE 0.1344198067203688\n",
      "88 Train Loss 15881.538 Test MSE 5995.094144913073 Test RE 0.13546716606906842\n",
      "89 Train Loss 15768.549 Test MSE 5960.999241116245 Test RE 0.13508140685735393\n",
      "90 Train Loss 15661.126 Test MSE 5923.508277599811 Test RE 0.13465594797852917\n",
      "91 Train Loss 15550.037 Test MSE 5812.382524845777 Test RE 0.1333868866876011\n",
      "92 Train Loss 15451.884 Test MSE 5723.588049385259 Test RE 0.1323641045453419\n",
      "93 Train Loss 15345.631 Test MSE 5753.694264426957 Test RE 0.13271176720218128\n",
      "94 Train Loss 15266.375 Test MSE 5784.388938234299 Test RE 0.13306529015619373\n",
      "95 Train Loss 15198.339 Test MSE 5768.483352217599 Test RE 0.13288221650830218\n",
      "96 Train Loss 15126.534 Test MSE 5696.8211101232355 Test RE 0.13205423476531802\n",
      "97 Train Loss 15027.921 Test MSE 5727.335938635075 Test RE 0.13240743442999556\n",
      "98 Train Loss 14918.663 Test MSE 5681.155441993604 Test RE 0.1318725420347866\n",
      "99 Train Loss 14838.369 Test MSE 5615.089352676433 Test RE 0.13110352766783953\n",
      "100 Train Loss 14725.82 Test MSE 5683.744138097896 Test RE 0.1319025833758299\n",
      "101 Train Loss 14619.901 Test MSE 5723.517437723332 Test RE 0.13236328805766426\n",
      "102 Train Loss 14530.09 Test MSE 5759.233732142343 Test RE 0.1327756370965517\n",
      "103 Train Loss 14437.102 Test MSE 5685.525482961798 Test RE 0.1319232515812034\n",
      "104 Train Loss 14368.654 Test MSE 5685.273460957644 Test RE 0.13192032767110867\n",
      "105 Train Loss 14267.1045 Test MSE 5725.382024468967 Test RE 0.13238484671786285\n",
      "106 Train Loss 14198.182 Test MSE 5734.525037159973 Test RE 0.13249050896760545\n",
      "107 Train Loss 14097.572 Test MSE 5747.043787257626 Test RE 0.13263504677485294\n",
      "108 Train Loss 14016.02 Test MSE 5782.101117748047 Test RE 0.1330389728037693\n",
      "109 Train Loss 13950.611 Test MSE 5749.974822540199 Test RE 0.13266886489608679\n",
      "110 Train Loss 13862.674 Test MSE 5763.250163793871 Test RE 0.1328219272240079\n",
      "111 Train Loss 13789.188 Test MSE 5811.317504802605 Test RE 0.13337466569084866\n",
      "112 Train Loss 13698.369 Test MSE 5850.531834397914 Test RE 0.13382391016037712\n",
      "113 Train Loss 13589.902 Test MSE 5802.416904826907 Test RE 0.1332724883929211\n",
      "114 Train Loss 13515.038 Test MSE 5723.058426771552 Test RE 0.13235798035853832\n",
      "115 Train Loss 13432.251 Test MSE 5661.77593511457 Test RE 0.13164742867378282\n",
      "116 Train Loss 13371.029 Test MSE 5779.251969014693 Test RE 0.13300619107625425\n",
      "117 Train Loss 13324.312 Test MSE 5673.622441871528 Test RE 0.13178508399870928\n",
      "118 Train Loss 13256.69 Test MSE 5538.677305253306 Test RE 0.1302084212908896\n",
      "119 Train Loss 13195.565 Test MSE 5475.304146057248 Test RE 0.12946136035342462\n",
      "120 Train Loss 13127.377 Test MSE 5451.9625675616535 Test RE 0.12918511451625575\n",
      "121 Train Loss 13059.355 Test MSE 5398.0741717140745 Test RE 0.12854508200590042\n",
      "122 Train Loss 12988.393 Test MSE 5381.701421123375 Test RE 0.12834999068221725\n",
      "123 Train Loss 12939.077 Test MSE 5422.901846580876 Test RE 0.12884035529511392\n",
      "124 Train Loss 12882.825 Test MSE 5345.113626518917 Test RE 0.12791294934964906\n",
      "125 Train Loss 12822.735 Test MSE 5271.533926935564 Test RE 0.12702948717103782\n",
      "126 Train Loss 12752.061 Test MSE 5145.267709012739 Test RE 0.12549893197586634\n",
      "127 Train Loss 12673.38 Test MSE 5085.492329319441 Test RE 0.12476780755315962\n",
      "128 Train Loss 12602.28 Test MSE 5216.697752206341 Test RE 0.12636705938110016\n",
      "129 Train Loss 12518.867 Test MSE 5136.106479605158 Test RE 0.12538715579598494\n",
      "130 Train Loss 12455.9 Test MSE 5008.350573674462 Test RE 0.12381789098448197\n",
      "131 Train Loss 12382.614 Test MSE 5021.718919966331 Test RE 0.12398302892206274\n",
      "132 Train Loss 12266.6 Test MSE 5058.0052632356765 Test RE 0.12443016594199209\n",
      "133 Train Loss 12193.588 Test MSE 5101.281338808326 Test RE 0.12496134175764294\n",
      "134 Train Loss 12096.96 Test MSE 5102.097928395303 Test RE 0.12497134297502298\n",
      "135 Train Loss 12006.626 Test MSE 5134.98148420415 Test RE 0.1253734228545684\n",
      "136 Train Loss 11917.188 Test MSE 5173.250227431292 Test RE 0.1258397319709501\n",
      "137 Train Loss 11827.739 Test MSE 5304.5811511219335 Test RE 0.1274270387446424\n",
      "138 Train Loss 11736.94 Test MSE 5300.743804614555 Test RE 0.1273809398960464\n",
      "139 Train Loss 11685.978 Test MSE 5351.715214840207 Test RE 0.12799191568417148\n",
      "140 Train Loss 11635.835 Test MSE 5359.024233606603 Test RE 0.12807928731033785\n",
      "141 Train Loss 11561.764 Test MSE 5386.692854660658 Test RE 0.1284094980683318\n",
      "142 Train Loss 11474.648 Test MSE 5361.028183647674 Test RE 0.12810323201483304\n",
      "143 Train Loss 11425.083 Test MSE 5365.448451309537 Test RE 0.12815603288450939\n",
      "144 Train Loss 11358.305 Test MSE 5362.198964729292 Test RE 0.1281172193179969\n",
      "145 Train Loss 11244.446 Test MSE 5367.097225808503 Test RE 0.1281757222143427\n",
      "146 Train Loss 11168.166 Test MSE 5509.157436121563 Test RE 0.12986096732366784\n",
      "147 Train Loss 11072.562 Test MSE 5385.812496933771 Test RE 0.1283990045321212\n",
      "148 Train Loss 11014.865 Test MSE 5367.658255297168 Test RE 0.12818242122478965\n",
      "149 Train Loss 10935.284 Test MSE 5563.019878738403 Test RE 0.13049424161422804\n",
      "150 Train Loss 10879.917 Test MSE 5553.642469282036 Test RE 0.13038421018485358\n",
      "151 Train Loss 10830.413 Test MSE 5517.512407855551 Test RE 0.12995940103828282\n",
      "152 Train Loss 10765.01 Test MSE 5464.278356081845 Test RE 0.12933094448405916\n",
      "153 Train Loss 10709.928 Test MSE 5492.6800821809165 Test RE 0.1296666211372532\n",
      "154 Train Loss 10631.51 Test MSE 5570.546902951684 Test RE 0.1305824941560571\n",
      "155 Train Loss 10583.127 Test MSE 5556.445906345031 Test RE 0.13041711451858481\n",
      "156 Train Loss 10538.581 Test MSE 5619.1206662433015 Test RE 0.1311505816476523\n",
      "157 Train Loss 10475.494 Test MSE 5594.992306759864 Test RE 0.1308687001134616\n",
      "158 Train Loss 10435.311 Test MSE 5618.171867015826 Test RE 0.13113950866744944\n",
      "159 Train Loss 10392.122 Test MSE 5604.359756553177 Test RE 0.1309782081538317\n",
      "160 Train Loss 10346.719 Test MSE 5658.494073928541 Test RE 0.13160926827861766\n",
      "161 Train Loss 10309.69 Test MSE 5713.999804534914 Test RE 0.13225318885756948\n",
      "162 Train Loss 10260.482 Test MSE 5655.144703042406 Test RE 0.13157031149119505\n",
      "163 Train Loss 10216.022 Test MSE 5653.680649222191 Test RE 0.13155327934647756\n",
      "164 Train Loss 10160.119 Test MSE 5726.797999198818 Test RE 0.13240121610667943\n",
      "165 Train Loss 10096.68 Test MSE 5744.285358922081 Test RE 0.13260321230510846\n",
      "166 Train Loss 10049.394 Test MSE 5795.344196464817 Test RE 0.13319123907280656\n",
      "167 Train Loss 10014.762 Test MSE 5793.704661313763 Test RE 0.13317239746843434\n",
      "168 Train Loss 9962.376 Test MSE 5826.341307839602 Test RE 0.13354695891794138\n",
      "169 Train Loss 9914.7 Test MSE 5794.9855739738105 Test RE 0.13318711799636274\n",
      "170 Train Loss 9868.014 Test MSE 5863.383073794378 Test RE 0.13397080789240487\n",
      "171 Train Loss 9827.117 Test MSE 5917.862124212171 Test RE 0.1345917571848354\n",
      "172 Train Loss 9782.65 Test MSE 5896.148834613612 Test RE 0.1343446142683134\n",
      "173 Train Loss 9739.154 Test MSE 5845.986587033767 Test RE 0.1337719165145782\n",
      "174 Train Loss 9682.974 Test MSE 5760.953947925731 Test RE 0.1327954648813269\n",
      "175 Train Loss 9645.938 Test MSE 5744.450068341557 Test RE 0.1326051133981245\n",
      "176 Train Loss 9599.835 Test MSE 5801.240492658426 Test RE 0.1332589775294985\n",
      "177 Train Loss 9566.639 Test MSE 5853.282134830827 Test RE 0.13385536137912066\n",
      "178 Train Loss 9535.374 Test MSE 5860.679089594187 Test RE 0.1339399130388977\n",
      "179 Train Loss 9497.067 Test MSE 5888.4143323446 Test RE 0.1342564694688025\n",
      "180 Train Loss 9454.583 Test MSE 5884.910122984417 Test RE 0.13421651535173174\n",
      "181 Train Loss 9411.486 Test MSE 5860.392584979905 Test RE 0.13393663911180337\n",
      "182 Train Loss 9367.402 Test MSE 5833.826214382773 Test RE 0.13363271304956573\n",
      "183 Train Loss 9340.387 Test MSE 5882.604700279222 Test RE 0.1341902230120117\n",
      "184 Train Loss 9290.959 Test MSE 5843.002424444152 Test RE 0.13373776931805653\n",
      "185 Train Loss 9256.559 Test MSE 5772.7638548503 Test RE 0.13293150998476866\n",
      "186 Train Loss 9211.927 Test MSE 5830.427911922189 Test RE 0.1335937857217767\n",
      "187 Train Loss 9162.606 Test MSE 5892.763993217035 Test RE 0.1343060466789855\n",
      "188 Train Loss 9131.724 Test MSE 5940.822061556933 Test RE 0.13485259688627568\n",
      "189 Train Loss 9103.608 Test MSE 5918.164685756636 Test RE 0.13459519776595946\n",
      "190 Train Loss 9051.95 Test MSE 5896.166589131431 Test RE 0.13434481653780483\n",
      "191 Train Loss 9002.809 Test MSE 5911.293795328278 Test RE 0.13451704368634312\n",
      "192 Train Loss 8958.307 Test MSE 5951.880506012137 Test RE 0.1349780480958676\n",
      "193 Train Loss 8902.729 Test MSE 5963.475049251995 Test RE 0.1351094559238033\n",
      "194 Train Loss 8854.144 Test MSE 5986.839336919684 Test RE 0.13537386973188095\n",
      "195 Train Loss 8810.433 Test MSE 6002.513284529164 Test RE 0.13555096284025467\n",
      "196 Train Loss 8778.21 Test MSE 6070.924243923672 Test RE 0.1363212151305621\n",
      "197 Train Loss 8748.831 Test MSE 6096.67978445294 Test RE 0.13661007647089532\n",
      "198 Train Loss 8706.942 Test MSE 6073.622915086647 Test RE 0.13635151078596242\n",
      "199 Train Loss 8681.32 Test MSE 6123.310721382619 Test RE 0.13690811493293412\n",
      "Training time: 186.14\n",
      "Training time: 186.14\n",
      "ES_stan_high\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 306.46\n",
      "Training time: 306.46\n",
      "ES_stan_high\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 208465.28 Test MSE 56590.960698988194 Test RE 0.41620718691106373\n",
      "1 Train Loss 138591.08 Test MSE 34652.73401823214 Test RE 0.3256902776398814\n",
      "2 Train Loss 103794.1 Test MSE 24525.010065229937 Test RE 0.2739937390436045\n",
      "3 Train Loss 82204.12 Test MSE 19260.075268562665 Test RE 0.24280914062095002\n",
      "4 Train Loss 72090.44 Test MSE 17581.494913866354 Test RE 0.2319871563960814\n",
      "5 Train Loss 65373.246 Test MSE 16408.869578082882 Test RE 0.22411729568995536\n",
      "6 Train Loss 61804.004 Test MSE 14882.524857097018 Test RE 0.21343928143376356\n",
      "7 Train Loss 59189.676 Test MSE 14001.613304665994 Test RE 0.20702609073149889\n",
      "8 Train Loss 57238.992 Test MSE 12484.24059421761 Test RE 0.1954866510864344\n",
      "9 Train Loss 55424.9 Test MSE 12181.198948964573 Test RE 0.19309946032757605\n",
      "10 Train Loss 54426.36 Test MSE 11748.608547956854 Test RE 0.18963969961460841\n",
      "11 Train Loss 53048.516 Test MSE 10988.163031999493 Test RE 0.18339968654576105\n",
      "12 Train Loss 52228.844 Test MSE 10540.494209143488 Test RE 0.17962489564802853\n",
      "13 Train Loss 51556.867 Test MSE 10384.380459662165 Test RE 0.17828973418842384\n",
      "14 Train Loss 50579.67 Test MSE 10176.845112835754 Test RE 0.1764991524487835\n",
      "15 Train Loss 50063.36 Test MSE 10062.658113339841 Test RE 0.1755061747181382\n",
      "16 Train Loss 49422.426 Test MSE 9440.726258641063 Test RE 0.1699960163737552\n",
      "17 Train Loss 48889.64 Test MSE 9273.592301465167 Test RE 0.16848453409035888\n",
      "18 Train Loss 48479.867 Test MSE 8963.534242029742 Test RE 0.16564398985994871\n",
      "19 Train Loss 48037.152 Test MSE 8741.038760758602 Test RE 0.1635752395085746\n",
      "20 Train Loss 47760.77 Test MSE 8559.774223995915 Test RE 0.16187030934978866\n",
      "21 Train Loss 47484.816 Test MSE 8644.893892130256 Test RE 0.16267314961342313\n",
      "22 Train Loss 47294.67 Test MSE 8603.26231363082 Test RE 0.16228098093936066\n",
      "23 Train Loss 46955.27 Test MSE 8448.356619002874 Test RE 0.16081337284411265\n",
      "24 Train Loss 46710.023 Test MSE 8588.525316326093 Test RE 0.16214193139530325\n",
      "25 Train Loss 46439.152 Test MSE 8305.545812299719 Test RE 0.1594483872435414\n",
      "26 Train Loss 46218.156 Test MSE 8331.510065646062 Test RE 0.15969742131946948\n",
      "27 Train Loss 45972.793 Test MSE 7988.608345035835 Test RE 0.15637654252416627\n",
      "28 Train Loss 45727.043 Test MSE 8075.953732433709 Test RE 0.15722910885698851\n",
      "29 Train Loss 45528.58 Test MSE 8051.725047973674 Test RE 0.15699308001911683\n",
      "30 Train Loss 45322.395 Test MSE 8004.616395044355 Test RE 0.15653314243509658\n",
      "31 Train Loss 45163.92 Test MSE 8214.989741714673 Test RE 0.15857676524345135\n",
      "32 Train Loss 44985.9 Test MSE 7984.268167916804 Test RE 0.15633405739587392\n",
      "33 Train Loss 44784.35 Test MSE 7941.504011112297 Test RE 0.1559148286061111\n",
      "34 Train Loss 44645.24 Test MSE 7818.716421616735 Test RE 0.15470479433964243\n",
      "35 Train Loss 44485.773 Test MSE 7813.330192542384 Test RE 0.1546514979304664\n",
      "36 Train Loss 44338.902 Test MSE 7825.47393502519 Test RE 0.15477163356753015\n",
      "37 Train Loss 44225.344 Test MSE 7870.937385509015 Test RE 0.15522056881820656\n",
      "38 Train Loss 44075.84 Test MSE 7661.858793612004 Test RE 0.15314510280784796\n",
      "39 Train Loss 43984.688 Test MSE 7652.49642868432 Test RE 0.1530515068116365\n",
      "40 Train Loss 43880.96 Test MSE 7659.667681284533 Test RE 0.15312320328414442\n",
      "41 Train Loss 43777.664 Test MSE 7674.348511893856 Test RE 0.15326987411855972\n",
      "42 Train Loss 43703.44 Test MSE 7714.396588558283 Test RE 0.15366926805971334\n",
      "43 Train Loss 43630.89 Test MSE 7622.11408469786 Test RE 0.1527473780715703\n",
      "44 Train Loss 43519.234 Test MSE 7691.283841834089 Test RE 0.15343889468514285\n",
      "45 Train Loss 43398.734 Test MSE 7663.926295724884 Test RE 0.15316576401259338\n",
      "46 Train Loss 43258.086 Test MSE 7630.494459678764 Test RE 0.15283132647672712\n",
      "47 Train Loss 43187.684 Test MSE 7621.458922624592 Test RE 0.1527408131974182\n",
      "48 Train Loss 43085.695 Test MSE 7613.060489599503 Test RE 0.15265663396827672\n",
      "49 Train Loss 42984.94 Test MSE 7681.013332661312 Test RE 0.15333641361371583\n",
      "50 Train Loss 42837.64 Test MSE 7620.401214649957 Test RE 0.15273021412554968\n",
      "51 Train Loss 42687.996 Test MSE 7597.376625295724 Test RE 0.15249930694326272\n",
      "52 Train Loss 42590.297 Test MSE 7558.8151242416025 Test RE 0.15211179929299823\n",
      "53 Train Loss 42484.965 Test MSE 7588.496980619403 Test RE 0.15241016199038526\n",
      "54 Train Loss 42349.242 Test MSE 7617.345719000222 Test RE 0.15269959150608203\n",
      "55 Train Loss 42252.42 Test MSE 7593.466465657015 Test RE 0.15246005830465684\n",
      "56 Train Loss 42147.543 Test MSE 7511.010737282057 Test RE 0.15163003431403874\n",
      "57 Train Loss 42019.016 Test MSE 7553.344499715433 Test RE 0.15205674455588625\n",
      "58 Train Loss 41892.89 Test MSE 7510.787067169956 Test RE 0.1516277766046271\n",
      "59 Train Loss 41764.67 Test MSE 7474.66583315951 Test RE 0.1512627294214573\n",
      "60 Train Loss 41652.4 Test MSE 7550.228900384912 Test RE 0.15202538118073158\n",
      "61 Train Loss 41529.68 Test MSE 7560.582055622626 Test RE 0.1521295769077555\n",
      "62 Train Loss 41389.066 Test MSE 7521.858932630695 Test RE 0.1517394948633568\n",
      "63 Train Loss 41234.59 Test MSE 7583.510257982369 Test RE 0.15236007617567063\n",
      "64 Train Loss 41084.332 Test MSE 7595.9800152741855 Test RE 0.1524852894830411\n",
      "65 Train Loss 40876.49 Test MSE 7601.478483871293 Test RE 0.15254046892666007\n",
      "66 Train Loss 40667.797 Test MSE 7595.487556965979 Test RE 0.15248034648262088\n",
      "67 Train Loss 40492.727 Test MSE 7515.957259168845 Test RE 0.1516799555471287\n",
      "68 Train Loss 40346.613 Test MSE 7554.150583182971 Test RE 0.15206485799212316\n",
      "69 Train Loss 40150.375 Test MSE 7545.243444115384 Test RE 0.1519751813089772\n",
      "70 Train Loss 39929.902 Test MSE 7567.521132562062 Test RE 0.15219937290539173\n",
      "71 Train Loss 39776.465 Test MSE 7388.235624263654 Test RE 0.1503856546008995\n",
      "72 Train Loss 39578.58 Test MSE 7316.212179429285 Test RE 0.1496508499847616\n",
      "73 Train Loss 39454.523 Test MSE 7321.47021037579 Test RE 0.149704616022073\n",
      "74 Train Loss 39299.83 Test MSE 7282.931394479197 Test RE 0.1493100879544351\n",
      "75 Train Loss 39112.812 Test MSE 7308.816417049911 Test RE 0.14957519184741191\n",
      "76 Train Loss 38987.9 Test MSE 7294.023924760227 Test RE 0.14942375073787664\n",
      "77 Train Loss 38845.668 Test MSE 7295.7390871670705 Test RE 0.14944131792288984\n",
      "78 Train Loss 38702.14 Test MSE 7145.712271144842 Test RE 0.14789680916718256\n",
      "79 Train Loss 38556.06 Test MSE 7108.686055036637 Test RE 0.14751314053249795\n",
      "80 Train Loss 38410.902 Test MSE 7090.753098193842 Test RE 0.14732695864090065\n",
      "81 Train Loss 38240.125 Test MSE 7011.733735815704 Test RE 0.14650375284797112\n",
      "82 Train Loss 38033.32 Test MSE 6920.929320593047 Test RE 0.14555202396665884\n",
      "83 Train Loss 37799.168 Test MSE 6791.442360848959 Test RE 0.14418399393656078\n",
      "84 Train Loss 37634.67 Test MSE 6775.522333246392 Test RE 0.14401490173145304\n",
      "85 Train Loss 37443.81 Test MSE 6755.014336462413 Test RE 0.14379678604612098\n",
      "86 Train Loss 37204.06 Test MSE 6727.997933647445 Test RE 0.14350894327960761\n",
      "87 Train Loss 36994.914 Test MSE 6694.816383661126 Test RE 0.14315462280127794\n",
      "88 Train Loss 36718.96 Test MSE 6612.026821398757 Test RE 0.1422667286158855\n",
      "89 Train Loss 36518.773 Test MSE 6515.529496267121 Test RE 0.14122477758816263\n",
      "90 Train Loss 36325.82 Test MSE 6490.9483008782445 Test RE 0.14095812587094267\n",
      "91 Train Loss 36101.195 Test MSE 6424.360377285879 Test RE 0.14023324679393864\n",
      "92 Train Loss 35892.56 Test MSE 6420.182945394287 Test RE 0.14018764613758403\n",
      "93 Train Loss 35720.895 Test MSE 6414.401694050951 Test RE 0.14012451378157822\n",
      "94 Train Loss 35534.992 Test MSE 6330.820495871282 Test RE 0.13920859225574303\n",
      "95 Train Loss 35387.203 Test MSE 6258.522789445447 Test RE 0.1384114316723605\n",
      "96 Train Loss 35099.105 Test MSE 6381.290055511066 Test RE 0.13976237903642524\n",
      "97 Train Loss 34838.77 Test MSE 6329.616270858084 Test RE 0.1391953517570111\n",
      "98 Train Loss 34600.094 Test MSE 6180.650876899672 Test RE 0.13754764152282045\n",
      "99 Train Loss 34333.168 Test MSE 6140.103013785054 Test RE 0.13709571174052057\n",
      "100 Train Loss 33997.64 Test MSE 5993.91284856823 Test RE 0.1354538189265458\n",
      "101 Train Loss 33805.24 Test MSE 5989.977438309328 Test RE 0.13540934431627294\n",
      "102 Train Loss 33519.44 Test MSE 5952.602156503199 Test RE 0.13498623072169352\n",
      "103 Train Loss 33293.96 Test MSE 5943.623775896383 Test RE 0.13488439163756089\n",
      "104 Train Loss 33015.19 Test MSE 6010.942753266031 Test RE 0.1356461081300638\n",
      "105 Train Loss 32695.838 Test MSE 5962.140175671638 Test RE 0.13509433352155525\n",
      "106 Train Loss 32412.354 Test MSE 5834.4079749222765 Test RE 0.13363937594097922\n",
      "107 Train Loss 32006.299 Test MSE 5806.242494853662 Test RE 0.13331641507915343\n",
      "108 Train Loss 31716.87 Test MSE 5624.238434550197 Test RE 0.13121029255008146\n",
      "109 Train Loss 31519.36 Test MSE 5644.9257941249825 Test RE 0.1314513832379626\n",
      "110 Train Loss 31339.912 Test MSE 5553.244723152565 Test RE 0.13037954111011554\n",
      "111 Train Loss 31173.896 Test MSE 5510.370228436314 Test RE 0.12987526040915204\n",
      "112 Train Loss 30912.615 Test MSE 5427.216947274905 Test RE 0.12889160539788075\n",
      "113 Train Loss 30594.865 Test MSE 5457.262922612818 Test RE 0.12924789563636468\n",
      "114 Train Loss 30329.396 Test MSE 5298.506050330076 Test RE 0.12735404958171925\n",
      "115 Train Loss 30170.145 Test MSE 5128.987420109757 Test RE 0.12530022728724724\n",
      "116 Train Loss 29976.094 Test MSE 5194.0972802465485 Test RE 0.1260930301701037\n",
      "117 Train Loss 29712.168 Test MSE 5048.0892367863835 Test RE 0.12430813580598217\n",
      "118 Train Loss 29410.234 Test MSE 4917.223007122919 Test RE 0.12268627887396329\n",
      "119 Train Loss 29168.71 Test MSE 5003.450336766621 Test RE 0.1237573036241461\n",
      "120 Train Loss 28835.033 Test MSE 5004.899297889776 Test RE 0.12377522191343414\n",
      "121 Train Loss 28505.686 Test MSE 4753.048055966467 Test RE 0.1206207833196222\n",
      "122 Train Loss 28289.611 Test MSE 4844.083604452026 Test RE 0.12177043483361141\n",
      "123 Train Loss 28015.955 Test MSE 4681.945805271095 Test RE 0.11971518279716317\n",
      "124 Train Loss 27795.275 Test MSE 4605.5865182035095 Test RE 0.11873493379362166\n",
      "125 Train Loss 27557.1 Test MSE 4723.257209310801 Test RE 0.12024217957477229\n",
      "126 Train Loss 27359.25 Test MSE 4786.115367104753 Test RE 0.12103963998760986\n",
      "127 Train Loss 27110.71 Test MSE 4646.498282164739 Test RE 0.1192611333870795\n",
      "128 Train Loss 26976.775 Test MSE 4609.927362039355 Test RE 0.11879087546521837\n",
      "129 Train Loss 26839.467 Test MSE 4647.045251823771 Test RE 0.11926815268396597\n",
      "130 Train Loss 26734.914 Test MSE 4629.071654370899 Test RE 0.11903727968098037\n",
      "131 Train Loss 26585.436 Test MSE 4610.125713544797 Test RE 0.11879343104730046\n",
      "132 Train Loss 26416.375 Test MSE 4628.726422968365 Test RE 0.1190328407592776\n",
      "133 Train Loss 26318.354 Test MSE 4711.433633850222 Test RE 0.12009158611192029\n",
      "134 Train Loss 26175.504 Test MSE 4598.419782610188 Test RE 0.11864251633848438\n",
      "135 Train Loss 26036.873 Test MSE 4501.039562772574 Test RE 0.11737955453023648\n",
      "136 Train Loss 25906.555 Test MSE 4504.929798834277 Test RE 0.11743026898689418\n",
      "137 Train Loss 25776.752 Test MSE 4589.936438738545 Test RE 0.1185330276509587\n",
      "138 Train Loss 25656.404 Test MSE 4689.9946390233 Test RE 0.11981804108270734\n",
      "139 Train Loss 25574.672 Test MSE 4699.469245262635 Test RE 0.11993900667919351\n",
      "140 Train Loss 25457.195 Test MSE 4623.763059696859 Test RE 0.11896900444234797\n",
      "141 Train Loss 25322.377 Test MSE 4600.726770985944 Test RE 0.11867227358102626\n",
      "142 Train Loss 25159.201 Test MSE 4640.237981576571 Test RE 0.11918076510243418\n",
      "143 Train Loss 24968.26 Test MSE 4676.2585501907915 Test RE 0.11964245046573668\n",
      "144 Train Loss 24834.441 Test MSE 4674.772014302645 Test RE 0.11962343238417553\n",
      "145 Train Loss 24660.402 Test MSE 4746.739524784011 Test RE 0.12054070916269354\n",
      "146 Train Loss 24542.027 Test MSE 4678.68798254973 Test RE 0.11967352504123936\n",
      "147 Train Loss 24429.527 Test MSE 4647.1498866924985 Test RE 0.11926949542290813\n",
      "148 Train Loss 24297.12 Test MSE 4731.427733845345 Test RE 0.12034613507971138\n",
      "149 Train Loss 24196.44 Test MSE 4699.71440395821 Test RE 0.1199421350864049\n",
      "150 Train Loss 24072.922 Test MSE 4702.344124568121 Test RE 0.11997568714589453\n",
      "151 Train Loss 23937.879 Test MSE 4760.957552565277 Test RE 0.120721103481349\n",
      "152 Train Loss 23791.0 Test MSE 4615.549964573297 Test RE 0.11886329638316198\n",
      "153 Train Loss 23655.791 Test MSE 4659.977927385543 Test RE 0.11943399835266134\n",
      "154 Train Loss 23461.336 Test MSE 4683.994755197063 Test RE 0.11974137528149778\n",
      "155 Train Loss 23284.943 Test MSE 4686.28476314203 Test RE 0.11977064252111422\n",
      "156 Train Loss 23053.398 Test MSE 4699.879487477895 Test RE 0.11994424162887113\n",
      "157 Train Loss 22890.805 Test MSE 4710.987915025873 Test RE 0.12008590542629884\n",
      "158 Train Loss 22726.111 Test MSE 4781.597089560013 Test RE 0.12098249345249118\n",
      "159 Train Loss 22487.242 Test MSE 4827.461522001072 Test RE 0.12156133258392673\n",
      "160 Train Loss 22290.947 Test MSE 4829.853027955292 Test RE 0.12159143936505146\n",
      "161 Train Loss 22164.816 Test MSE 4871.161822948255 Test RE 0.12211030626914957\n",
      "162 Train Loss 22023.586 Test MSE 5006.069714980594 Test RE 0.12378969374972673\n",
      "163 Train Loss 21875.83 Test MSE 5038.137387407736 Test RE 0.12418554425764804\n",
      "164 Train Loss 21748.191 Test MSE 4927.877272765207 Test RE 0.12281912061423156\n",
      "165 Train Loss 21600.785 Test MSE 4879.197816468776 Test RE 0.12221098792311277\n",
      "166 Train Loss 21459.854 Test MSE 4818.6742215414315 Test RE 0.12145064475203528\n",
      "167 Train Loss 21329.777 Test MSE 4895.542954208352 Test RE 0.12241551798804179\n",
      "168 Train Loss 21203.127 Test MSE 4867.220423901772 Test RE 0.12206089476763113\n",
      "169 Train Loss 21009.275 Test MSE 4847.198577164418 Test RE 0.12180958058887387\n",
      "170 Train Loss 20830.854 Test MSE 4830.461105683538 Test RE 0.12159909329559306\n",
      "171 Train Loss 20595.908 Test MSE 4876.754093535022 Test RE 0.1221803796951952\n",
      "172 Train Loss 20366.633 Test MSE 4887.249979184783 Test RE 0.12231178903133563\n",
      "173 Train Loss 20246.219 Test MSE 5017.108556458756 Test RE 0.12392610238979865\n",
      "174 Train Loss 20031.316 Test MSE 5075.543642608415 Test RE 0.12464570693671223\n",
      "175 Train Loss 19858.742 Test MSE 5077.775377967381 Test RE 0.1246731075147626\n",
      "176 Train Loss 19723.816 Test MSE 5042.253008141562 Test RE 0.12423625707326227\n",
      "177 Train Loss 19582.342 Test MSE 5074.747979056401 Test RE 0.12463593656135678\n",
      "178 Train Loss 19454.674 Test MSE 5188.188066347957 Test RE 0.1260212830799973\n",
      "179 Train Loss 19286.082 Test MSE 5303.445237614409 Test RE 0.12741339451523417\n",
      "180 Train Loss 19081.586 Test MSE 5279.859805764581 Test RE 0.127129762997302\n",
      "181 Train Loss 18890.496 Test MSE 5389.694507695272 Test RE 0.12844527020994506\n",
      "182 Train Loss 18736.195 Test MSE 5392.903445888005 Test RE 0.12848350165336198\n",
      "183 Train Loss 18572.408 Test MSE 5417.616578799062 Test RE 0.1287775548058864\n",
      "184 Train Loss 18345.902 Test MSE 5467.93046574706 Test RE 0.1293741571341201\n",
      "185 Train Loss 18135.625 Test MSE 5415.103909933883 Test RE 0.1287476880854634\n",
      "186 Train Loss 17988.365 Test MSE 5463.895108822781 Test RE 0.12932640897215053\n",
      "187 Train Loss 17759.543 Test MSE 5655.9457637965315 Test RE 0.13157962973912402\n",
      "188 Train Loss 17575.963 Test MSE 5781.072182367943 Test RE 0.13302713501386437\n",
      "189 Train Loss 17381.963 Test MSE 5985.686543387599 Test RE 0.1353608356728551\n",
      "190 Train Loss 17229.04 Test MSE 6028.6793115998125 Test RE 0.13584608698914255\n",
      "191 Train Loss 17074.277 Test MSE 6195.225686656433 Test RE 0.13770972398650985\n",
      "192 Train Loss 16887.676 Test MSE 6357.799895037524 Test RE 0.13950490229141785\n",
      "193 Train Loss 16711.898 Test MSE 6407.189813322217 Test RE 0.14004571878722502\n",
      "194 Train Loss 16550.05 Test MSE 6604.576322791694 Test RE 0.1421865522302451\n",
      "195 Train Loss 16421.691 Test MSE 6835.573240037026 Test RE 0.14465169010981604\n",
      "196 Train Loss 16261.824 Test MSE 6882.19150563788 Test RE 0.14514411059026425\n",
      "197 Train Loss 16094.841 Test MSE 6853.106966178063 Test RE 0.1448370921732343\n",
      "198 Train Loss 15937.268 Test MSE 6965.699577724583 Test RE 0.14602204011810785\n",
      "199 Train Loss 15774.005 Test MSE 7082.742088141905 Test RE 0.14724371139820808\n",
      "Training time: 190.86\n",
      "Training time: 190.86\n",
      "ES_stan_high\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 244262.89 Test MSE 72436.05235534978 Test RE 0.4708834523101981\n",
      "1 Train Loss 204856.48 Test MSE 57647.08108758319 Test RE 0.4200729366549689\n",
      "2 Train Loss 147878.05 Test MSE 36040.95566626596 Test RE 0.3321499496746594\n",
      "3 Train Loss 111727.05 Test MSE 22870.79855193541 Test RE 0.26459199822721574\n",
      "4 Train Loss 86782.29 Test MSE 19127.00907610973 Test RE 0.24196891317610714\n",
      "5 Train Loss 77442.914 Test MSE 17733.651244112658 Test RE 0.23298884232484143\n",
      "6 Train Loss 70437.46 Test MSE 16085.070162894142 Test RE 0.22189500273470716\n",
      "7 Train Loss 66594.11 Test MSE 15085.70381371169 Test RE 0.21489129852455188\n",
      "8 Train Loss 62415.688 Test MSE 12997.784960347328 Test RE 0.19946684372114645\n",
      "9 Train Loss 59724.504 Test MSE 12550.777910338365 Test RE 0.19600690187612027\n",
      "10 Train Loss 57095.1 Test MSE 12084.038557573354 Test RE 0.19232781292841775\n",
      "11 Train Loss 55176.71 Test MSE 11538.390193673134 Test RE 0.18793542592259474\n",
      "12 Train Loss 54083.848 Test MSE 11097.350755835552 Test RE 0.18430864164431354\n",
      "13 Train Loss 52916.977 Test MSE 11257.796739913418 Test RE 0.18563623148987618\n",
      "14 Train Loss 51815.34 Test MSE 11072.872750871104 Test RE 0.18410525984134907\n",
      "15 Train Loss 51142.164 Test MSE 11112.55612256779 Test RE 0.18443486641774254\n",
      "16 Train Loss 50520.234 Test MSE 10926.502269692995 Test RE 0.1828843832236995\n",
      "17 Train Loss 49909.66 Test MSE 10917.471326098803 Test RE 0.18280878904349768\n",
      "18 Train Loss 49273.89 Test MSE 10867.299642931557 Test RE 0.18238825272948955\n",
      "19 Train Loss 48810.07 Test MSE 10821.902124008358 Test RE 0.182006895823223\n",
      "20 Train Loss 48173.527 Test MSE 10635.909178789037 Test RE 0.18043606692088884\n",
      "21 Train Loss 47854.43 Test MSE 10647.654290147877 Test RE 0.18053566616166936\n",
      "22 Train Loss 47453.465 Test MSE 10301.195405231356 Test RE 0.1775741950079986\n",
      "23 Train Loss 47068.395 Test MSE 10026.717815482256 Test RE 0.17519247099943497\n",
      "24 Train Loss 46717.0 Test MSE 9750.831152645249 Test RE 0.17276543577166495\n",
      "25 Train Loss 46403.312 Test MSE 9594.955028550208 Test RE 0.1713789641810108\n",
      "26 Train Loss 46049.312 Test MSE 9267.997285360612 Test RE 0.1684337007196879\n",
      "27 Train Loss 45639.652 Test MSE 9037.573712781157 Test RE 0.1663266988941515\n",
      "28 Train Loss 45273.023 Test MSE 8926.570724167437 Test RE 0.16530209849801825\n",
      "29 Train Loss 44912.24 Test MSE 8854.019620749852 Test RE 0.16462897789814726\n",
      "30 Train Loss 44580.074 Test MSE 8645.754420766652 Test RE 0.16268124580418883\n",
      "31 Train Loss 44204.793 Test MSE 8450.476745511729 Test RE 0.16083354974493907\n",
      "32 Train Loss 43767.938 Test MSE 8272.396555438705 Test RE 0.15912987234948053\n",
      "33 Train Loss 43430.54 Test MSE 8316.269733501485 Test RE 0.1595512920005508\n",
      "34 Train Loss 42983.984 Test MSE 8249.736850485482 Test RE 0.1589117790441178\n",
      "35 Train Loss 42691.44 Test MSE 8114.735375759084 Test RE 0.15760617270608468\n",
      "36 Train Loss 42344.125 Test MSE 8041.995517027372 Test RE 0.15689819782055278\n",
      "37 Train Loss 42054.293 Test MSE 7884.714003932299 Test RE 0.15535635186009214\n",
      "38 Train Loss 41692.227 Test MSE 7897.985874144022 Test RE 0.1554870479393275\n",
      "39 Train Loss 41340.766 Test MSE 7824.841751132419 Test RE 0.15476538179857752\n",
      "40 Train Loss 41044.49 Test MSE 7801.5398752335905 Test RE 0.15453476930249943\n",
      "41 Train Loss 40775.934 Test MSE 7761.426358425792 Test RE 0.15413696822427525\n",
      "42 Train Loss 40406.617 Test MSE 7774.323215982398 Test RE 0.1542649767449018\n",
      "43 Train Loss 39983.92 Test MSE 7881.424655927558 Test RE 0.15532394266846675\n",
      "44 Train Loss 39672.57 Test MSE 7801.447412589641 Test RE 0.15453385353869398\n",
      "45 Train Loss 39297.41 Test MSE 7628.802997920292 Test RE 0.15281438637715966\n",
      "46 Train Loss 38867.86 Test MSE 7572.836433761819 Test RE 0.1522528146791646\n",
      "47 Train Loss 38569.47 Test MSE 7473.640982470257 Test RE 0.15125235925708583\n",
      "48 Train Loss 38302.12 Test MSE 7324.344614205352 Test RE 0.14973400009948676\n",
      "49 Train Loss 37767.973 Test MSE 7105.178665647633 Test RE 0.1474767449275655\n",
      "50 Train Loss 37408.93 Test MSE 6911.1905926414765 Test RE 0.14544958175821177\n",
      "51 Train Loss 37137.24 Test MSE 6732.765699289524 Test RE 0.14355978275978779\n",
      "52 Train Loss 36678.832 Test MSE 6586.999507424832 Test RE 0.14199722503899004\n",
      "53 Train Loss 36248.6 Test MSE 6389.39478092412 Test RE 0.13985110531734454\n",
      "54 Train Loss 35923.58 Test MSE 6276.9919176636595 Test RE 0.13861550980549764\n",
      "55 Train Loss 35602.043 Test MSE 6254.5020568814625 Test RE 0.13836696392972442\n",
      "56 Train Loss 35223.37 Test MSE 6248.193026521693 Test RE 0.1382971596813287\n",
      "57 Train Loss 34909.34 Test MSE 6314.824981104164 Test RE 0.1390326181159631\n",
      "58 Train Loss 34527.03 Test MSE 6189.235796645685 Test RE 0.1376431351631229\n",
      "59 Train Loss 34222.77 Test MSE 5998.1991625801475 Test RE 0.13550224254028842\n",
      "60 Train Loss 33795.21 Test MSE 5867.892793971732 Test RE 0.1340223186602224\n",
      "61 Train Loss 33433.965 Test MSE 5894.033685169228 Test RE 0.13432051511197077\n",
      "62 Train Loss 32958.203 Test MSE 5821.086579932195 Test RE 0.1334867228973808\n",
      "63 Train Loss 32473.598 Test MSE 5825.690020278731 Test RE 0.13353949455056804\n",
      "64 Train Loss 31713.582 Test MSE 5868.6112554824485 Test RE 0.13403052321794665\n",
      "65 Train Loss 30891.193 Test MSE 5895.903689879493 Test RE 0.13434182140995796\n",
      "66 Train Loss 30134.635 Test MSE 5827.335663944563 Test RE 0.13355835436849575\n",
      "67 Train Loss 29018.982 Test MSE 5889.769307259352 Test RE 0.13427191536596658\n",
      "68 Train Loss 27791.576 Test MSE 6018.451960619686 Test RE 0.13573081005383597\n",
      "69 Train Loss 26345.191 Test MSE 6645.388822774724 Test RE 0.14262519137851237\n",
      "70 Train Loss 25010.8 Test MSE 6745.999397718643 Test RE 0.1437008016451739\n",
      "71 Train Loss 23494.49 Test MSE 6436.506190795969 Test RE 0.14036574578912323\n",
      "72 Train Loss 22234.145 Test MSE 6856.192238398628 Test RE 0.1448696913706607\n",
      "73 Train Loss 21518.348 Test MSE 7084.526071621661 Test RE 0.14726225392076697\n",
      "74 Train Loss 20022.37 Test MSE 6764.810712270897 Test RE 0.14390101802278174\n",
      "75 Train Loss 19068.533 Test MSE 6488.869512582925 Test RE 0.1409355524692495\n",
      "76 Train Loss 18212.105 Test MSE 6521.659732786965 Test RE 0.14129119872467968\n",
      "77 Train Loss 17421.701 Test MSE 6896.670632232213 Test RE 0.14529671138372435\n",
      "78 Train Loss 16756.94 Test MSE 7469.8823335832085 Test RE 0.1512143205013259\n",
      "79 Train Loss 16453.496 Test MSE 7545.197138704458 Test RE 0.15197471496988088\n",
      "80 Train Loss 16079.524 Test MSE 7943.9758101151765 Test RE 0.15593909102125117\n",
      "81 Train Loss 15728.832 Test MSE 8024.383215396073 Test RE 0.15672629689156092\n",
      "82 Train Loss 15476.248 Test MSE 8212.76612028914 Test RE 0.15855530212734217\n",
      "83 Train Loss 15213.373 Test MSE 7909.216680020592 Test RE 0.1555975586782467\n",
      "84 Train Loss 14954.317 Test MSE 8070.603200224396 Test RE 0.15717701601295\n",
      "85 Train Loss 14724.073 Test MSE 7968.96882228961 Test RE 0.15618420298129312\n",
      "86 Train Loss 14532.123 Test MSE 7850.049272872554 Test RE 0.15501446765590404\n",
      "87 Train Loss 14335.444 Test MSE 7678.282665822169 Test RE 0.1533091549785471\n",
      "88 Train Loss 14151.776 Test MSE 7658.076544654318 Test RE 0.15310729837795814\n",
      "89 Train Loss 13983.55 Test MSE 7603.855971096158 Test RE 0.15256432183002278\n",
      "90 Train Loss 13698.962 Test MSE 7564.580360606099 Test RE 0.15216979735935704\n",
      "91 Train Loss 13466.739 Test MSE 7354.271523352654 Test RE 0.15003959111255505\n",
      "92 Train Loss 13274.946 Test MSE 7516.1567996428985 Test RE 0.15168196900252165\n",
      "93 Train Loss 13031.447 Test MSE 7569.222626076497 Test RE 0.15221648231852744\n",
      "94 Train Loss 12724.886 Test MSE 8188.385221962589 Test RE 0.15831977892411814\n",
      "95 Train Loss 12391.002 Test MSE 8203.702772950946 Test RE 0.15846778968380318\n",
      "96 Train Loss 12178.859 Test MSE 7926.578322455354 Test RE 0.155768242351769\n",
      "97 Train Loss 11865.479 Test MSE 7793.272223564371 Test RE 0.15445286378533823\n",
      "98 Train Loss 11592.556 Test MSE 7659.584887581059 Test RE 0.1531223757240025\n",
      "99 Train Loss 11280.251 Test MSE 7487.486420689258 Test RE 0.1513923971720664\n",
      "100 Train Loss 11053.236 Test MSE 7697.399210731044 Test RE 0.15349988248763663\n",
      "101 Train Loss 10839.716 Test MSE 7684.807448725473 Test RE 0.15337427999273837\n",
      "102 Train Loss 10609.965 Test MSE 7602.016996811894 Test RE 0.1525458720572389\n",
      "103 Train Loss 10450.189 Test MSE 7750.133762689027 Test RE 0.15402479553972132\n",
      "104 Train Loss 10254.366 Test MSE 7825.2695867890625 Test RE 0.15476961276233292\n",
      "105 Train Loss 10092.467 Test MSE 7685.176458063432 Test RE 0.1533779623141563\n",
      "106 Train Loss 9947.361 Test MSE 7901.042085609964 Test RE 0.15551712873107015\n",
      "107 Train Loss 9790.953 Test MSE 8072.910777608098 Test RE 0.157199484730349\n",
      "108 Train Loss 9703.849 Test MSE 8003.779707671278 Test RE 0.15652496136058472\n",
      "109 Train Loss 9594.223 Test MSE 8185.580661542588 Test RE 0.15829266396801508\n",
      "110 Train Loss 9454.0 Test MSE 7963.35306293239 Test RE 0.15612916151382344\n",
      "111 Train Loss 9322.134 Test MSE 7889.772824648418 Test RE 0.15540618207016318\n",
      "112 Train Loss 9223.78 Test MSE 7961.003778480791 Test RE 0.15610612982951463\n",
      "113 Train Loss 9116.803 Test MSE 8002.944634783271 Test RE 0.15651679564601767\n",
      "114 Train Loss 8987.107 Test MSE 8140.048442745207 Test RE 0.1578517992768986\n",
      "115 Train Loss 8895.93 Test MSE 8093.684464698021 Test RE 0.15740161224534308\n",
      "116 Train Loss 8812.318 Test MSE 8020.822021848743 Test RE 0.15669151573765247\n",
      "117 Train Loss 8712.386 Test MSE 8343.05114948864 Test RE 0.15980799212126515\n",
      "118 Train Loss 8581.674 Test MSE 8223.55003928496 Test RE 0.15865936491150143\n",
      "119 Train Loss 8438.281 Test MSE 8359.671243007235 Test RE 0.15996708873256532\n",
      "120 Train Loss 8361.562 Test MSE 8303.173155532999 Test RE 0.15942561069604644\n",
      "121 Train Loss 8288.018 Test MSE 8405.810490096397 Test RE 0.16040793172335543\n",
      "122 Train Loss 8195.245 Test MSE 8270.464756454518 Test RE 0.15911129098237128\n",
      "123 Train Loss 8110.5957 Test MSE 8124.918900213764 Test RE 0.1577050350234666\n",
      "124 Train Loss 8073.4824 Test MSE 8224.064643684958 Test RE 0.15866432904071767\n",
      "125 Train Loss 7994.549 Test MSE 8347.078942333172 Test RE 0.15984656289156668\n",
      "126 Train Loss 7911.434 Test MSE 8189.289634952439 Test RE 0.15832852194897498\n",
      "127 Train Loss 7828.3774 Test MSE 8299.189452026889 Test RE 0.15938736142986815\n",
      "128 Train Loss 7730.1196 Test MSE 8215.948579105228 Test RE 0.1585860193569745\n",
      "129 Train Loss 7676.1943 Test MSE 8185.588921303149 Test RE 0.15829274383157194\n",
      "130 Train Loss 7547.4653 Test MSE 8130.010730141766 Test RE 0.15775444360567173\n",
      "131 Train Loss 7487.8555 Test MSE 7983.472529441511 Test RE 0.156326267797167\n",
      "132 Train Loss 7407.11 Test MSE 8165.062350617612 Test RE 0.15809414805849956\n",
      "133 Train Loss 7304.85 Test MSE 8101.823889239443 Test RE 0.15748073792742984\n",
      "134 Train Loss 7185.515 Test MSE 7928.56760282671 Test RE 0.1557877871828128\n",
      "135 Train Loss 7078.15 Test MSE 8097.67309932368 Test RE 0.15744039187618436\n",
      "136 Train Loss 6971.1626 Test MSE 8266.850169404483 Test RE 0.15907651757595112\n",
      "137 Train Loss 6892.1724 Test MSE 8275.404532361263 Test RE 0.1591588008151546\n",
      "138 Train Loss 6814.3125 Test MSE 8368.099179013716 Test RE 0.16004770510601837\n",
      "139 Train Loss 6731.488 Test MSE 8267.62465358093 Test RE 0.15908396898475566\n",
      "140 Train Loss 6688.2705 Test MSE 8164.958645811366 Test RE 0.15809314407504244\n",
      "141 Train Loss 6647.271 Test MSE 8237.47862919859 Test RE 0.15879367225194754\n",
      "142 Train Loss 6593.4453 Test MSE 8381.79553586859 Test RE 0.16017862935834806\n",
      "143 Train Loss 6556.284 Test MSE 8225.354093715829 Test RE 0.1586767670330045\n",
      "144 Train Loss 6490.756 Test MSE 8194.98657108013 Test RE 0.1583835835418001\n",
      "145 Train Loss 6444.813 Test MSE 8280.2337918085 Test RE 0.15920523401590075\n",
      "146 Train Loss 6407.446 Test MSE 8410.456368910995 Test RE 0.16045225421125436\n",
      "147 Train Loss 6353.785 Test MSE 8397.39236885434 Test RE 0.16032759017472184\n",
      "148 Train Loss 6290.779 Test MSE 8271.792963172908 Test RE 0.15912406681829724\n",
      "149 Train Loss 6230.8096 Test MSE 8385.784817402922 Test RE 0.16021674300783784\n",
      "150 Train Loss 6176.3433 Test MSE 8626.868808802306 Test RE 0.16250346984884015\n",
      "151 Train Loss 6100.5396 Test MSE 8478.465308917806 Test RE 0.16109967549028464\n",
      "152 Train Loss 6063.2656 Test MSE 8427.033781365973 Test RE 0.16061030590795183\n",
      "153 Train Loss 6015.597 Test MSE 8445.809084286831 Test RE 0.16078912501953463\n",
      "154 Train Loss 5972.8457 Test MSE 8390.345280481974 Test RE 0.16026030262953808\n",
      "155 Train Loss 5930.7153 Test MSE 8534.7752535391 Test RE 0.1616337639788128\n",
      "156 Train Loss 5845.3994 Test MSE 8352.842957236076 Test RE 0.15990174381010575\n",
      "157 Train Loss 5780.797 Test MSE 8473.451952468109 Test RE 0.16105203894906706\n",
      "158 Train Loss 5739.6113 Test MSE 8425.939176373016 Test RE 0.16059987456540514\n",
      "159 Train Loss 5679.288 Test MSE 8463.21673434124 Test RE 0.16095474089146616\n",
      "160 Train Loss 5632.368 Test MSE 8593.590977322017 Test RE 0.16218974140637163\n",
      "161 Train Loss 5587.336 Test MSE 8608.615356100008 Test RE 0.16233145957555206\n",
      "162 Train Loss 5562.7607 Test MSE 8715.391844675398 Test RE 0.1633350917216149\n",
      "163 Train Loss 5512.174 Test MSE 8617.696387945725 Test RE 0.16241705688356894\n",
      "164 Train Loss 5469.1816 Test MSE 8570.745102095252 Test RE 0.16197400897605757\n",
      "165 Train Loss 5425.8877 Test MSE 8574.51647399527 Test RE 0.16200964164475076\n",
      "166 Train Loss 5385.9116 Test MSE 8609.600543527704 Test RE 0.16234074808079652\n",
      "167 Train Loss 5357.5947 Test MSE 8486.9197293016 Test RE 0.16117997687528898\n",
      "168 Train Loss 5324.711 Test MSE 8553.095073402279 Test RE 0.1618071437141042\n",
      "169 Train Loss 5289.421 Test MSE 8544.403173998568 Test RE 0.16172490629627945\n",
      "170 Train Loss 5257.462 Test MSE 8482.769881060374 Test RE 0.16114056597890303\n",
      "171 Train Loss 5231.4673 Test MSE 8613.66162821035 Test RE 0.16237903102993465\n",
      "172 Train Loss 5205.5493 Test MSE 8551.68483376821 Test RE 0.16179380373297134\n",
      "173 Train Loss 5174.9966 Test MSE 8659.026588983694 Test RE 0.16280606457446703\n",
      "174 Train Loss 5143.5005 Test MSE 8666.94336911052 Test RE 0.16288047278501344\n",
      "175 Train Loss 5116.3813 Test MSE 8624.383270399905 Test RE 0.16248005824254913\n",
      "176 Train Loss 5076.781 Test MSE 8540.582707873175 Test RE 0.16168874615755655\n",
      "177 Train Loss 5039.373 Test MSE 8443.224746371761 Test RE 0.16076452315959655\n",
      "178 Train Loss 4999.1387 Test MSE 8346.104262474688 Test RE 0.15983723005940054\n",
      "179 Train Loss 4963.338 Test MSE 8400.899238400443 Test RE 0.16036106421227275\n",
      "180 Train Loss 4938.74 Test MSE 8451.308474697047 Test RE 0.1608414644857253\n",
      "181 Train Loss 4892.0337 Test MSE 8442.00630741576 Test RE 0.16075292280362696\n",
      "182 Train Loss 4848.232 Test MSE 8367.312689350545 Test RE 0.1600401837549451\n",
      "183 Train Loss 4822.101 Test MSE 8539.628006929615 Test RE 0.16167970879336777\n",
      "184 Train Loss 4793.2646 Test MSE 8559.73431419709 Test RE 0.1618699319905942\n",
      "185 Train Loss 4773.894 Test MSE 8495.195587937742 Test RE 0.1612585435238558\n",
      "186 Train Loss 4751.884 Test MSE 8498.406791251637 Test RE 0.16128901869288748\n",
      "187 Train Loss 4733.8936 Test MSE 8644.673360528128 Test RE 0.16267107470078984\n",
      "188 Train Loss 4715.773 Test MSE 8671.34820731198 Test RE 0.16292185825170447\n",
      "189 Train Loss 4693.68 Test MSE 8657.976019508356 Test RE 0.162796187929079\n",
      "190 Train Loss 4666.3145 Test MSE 8591.476288176298 Test RE 0.16216978455776387\n",
      "191 Train Loss 4649.178 Test MSE 8485.583101302142 Test RE 0.16116728403972266\n",
      "192 Train Loss 4622.5054 Test MSE 8537.254323224746 Test RE 0.16165723690335732\n",
      "193 Train Loss 4599.4663 Test MSE 8577.496779001403 Test RE 0.16203779461401305\n",
      "194 Train Loss 4585.303 Test MSE 8451.376441472967 Test RE 0.16084211124083014\n",
      "195 Train Loss 4569.921 Test MSE 8624.435876633133 Test RE 0.16248055378237714\n",
      "196 Train Loss 4550.5957 Test MSE 8652.034955293375 Test RE 0.16274032333784536\n",
      "197 Train Loss 4531.1206 Test MSE 8578.49386188969 Test RE 0.16204721230436345\n",
      "198 Train Loss 4516.3228 Test MSE 8630.019172391223 Test RE 0.16253313868328564\n",
      "199 Train Loss 4491.136 Test MSE 8694.396071033401 Test RE 0.16313823227288973\n",
      "Training time: 192.01\n",
      "Training time: 192.01\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init =1.0\n",
    "\n",
    "N_T = 5000 #Total number of data points for 'y'\n",
    "N_f = 10000 #Total number of collocation points \n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "    \n",
    "    torch.manual_seed(reps*36)\n",
    "    \n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "   \n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.5, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-08, \n",
    "                              tolerance_change = 1e-08, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "    \n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "    \n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = PINN.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1541 into shape (500,500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15048/2850883497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1541 into shape (500,500)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "img3 = ax.imshow(np.transpose(u_pred.reshape(500,500)),vmin = 0,vmax = 500,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_loss[-1]\n",
    "print(a/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + train_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
