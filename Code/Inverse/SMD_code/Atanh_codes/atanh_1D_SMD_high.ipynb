{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "510f67c6-b225-41ba-e78a-d0a6e54ded85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "tstart= 0 \n",
    "tstop= 60 \n",
    "\n",
    "increment = 0.1 \n",
    "# Initial condition\n",
    "x_init= [0,0] \n",
    "\n",
    "t = np.arange(tstart,tstop+1,increment)\n",
    "\n",
    "c = 1 # Damping constant \n",
    "k = 0.01 # Stiffness of the spring\n",
    "m = 5 # Mass \n",
    "F0 = 100\n",
    "\n",
    "def mydiff(x, t):    \n",
    "    F =F0\n",
    "    \n",
    "    dx1dt = x[1] \n",
    "    dx2dt = (F -c*x[1] -k*x[0])/m\n",
    "    dxdt= [dx1dt, dx2dt] \n",
    "    \n",
    "    return dxdt \n",
    "\n",
    "x_full_sol = odeint(mydiff, x_init, t) \n",
    "\n",
    "x_sol = x_full_sol[:,0]\n",
    "v_sol = x_full_sol[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "level = \"high\"\n",
    "label = \"1D_SMD_atanh_\" + level\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "\n",
    "# bc1_t = t[0].reshape(-1,1)\n",
    "# bc1_x = x_sol[0].reshape(-1,1)\n",
    "# t_bc1_train = torch.from_numpy(bc1_t).float().to(device)\n",
    "# x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "\n",
    "bc1_t = t.reshape(-1,1)\n",
    "bc1_x = x_sol.reshape(-1,1)\n",
    "t_bc1_train = torch.from_numpy(bc1_t).float().to(device)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "\n",
    "\n",
    "bc2_t = t[0].reshape(-1,1)\n",
    "t_bc2_train = torch.from_numpy(bc2_t).float().to(device)\n",
    "bc2_val = v_sol[0].reshape(-1,1)\n",
    "bc2_val =torch.from_numpy(bc2_val).float().to(device)\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "x_true = x_sol\n",
    "x_true_norm = np.linalg.norm(x_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(t[0]) \n",
    "ub = np.array(t[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    \n",
    "    t01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=t01,random_state =seed)\n",
    "\n",
    "    t_coll = lb + (ub-lb)*sampling(N_f)\n",
    "    # t_coll = np.vstack((t_coll,)) # append training points to collocation points \n",
    "\n",
    "    return t_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        \n",
    "        self.k = Parameter(torch.tensor(0.0))\n",
    "        self.k.requiresGrad = True\n",
    "        self.c = Parameter(torch.tensor(0.0))\n",
    "        self.c.requiresGrad = True\n",
    "        self.m = Parameter(torch.tensor(0.0))\n",
    "        self.m.requiresGrad = True\n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(1.0)\n",
    "        \n",
    "    'forward pass'\n",
    "    def forward(self,t):\n",
    "        if torch.is_tensor(t) != True:         \n",
    "            t = torch.from_numpy(t)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        t = 2.0*(t - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = t.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,t,x):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(t), x)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,t_bc2,bc2_val):\n",
    "        g = t_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        x = self.forward(g)    \n",
    "            \n",
    "        x_t = autograd.grad(x,g,torch.ones([t_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        bc2 = dx_dt\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self,t_coll,f_hat):\n",
    "             \n",
    "        g = t_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        x = self.forward(g) \n",
    "\n",
    "        x_t = autograd.grad(x,g,torch.ones([t_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        x_tt = autograd.grad(x_t,g,torch.ones(t_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        dx2_d2t = x_tt[:,[0]]\n",
    "        \n",
    "        f = self.m*dx2_d2t + self.c*dx_dt + self.k*x - F0\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,t_bc1,x_bc1,t_bc2,bc2_val,t_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(t_bc1,x_bc1)\n",
    "        loss_bc2 = self.loss_BC2(t_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(t_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        x_pred = self.forward(t_test_tensor)\n",
    "        x_pred = x_pred.cpu().detach().numpy()\n",
    "\n",
    "        return x_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        x_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(x_pred.reshape(-1,1) - x_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(x_pred.reshape(-1,1) - x_true.reshape(-1,1),2)/x_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    m_val.append(PINN.m.cpu().detach().numpy())\n",
    "    k_val.append(PINN.k.cpu().detach().numpy())\n",
    "    c_val.append(PINN.c.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    t_coll = colloc_pts(N_f,rep*11)\n",
    "    t_coll =  torch.from_numpy(t_coll).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(t_coll.shape[0],1).to(device)\n",
    "    for i in range(max_iter):      \n",
    "        train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "         \n",
    "        loss_np = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test RE\",test_re_loss[-1],\"c\",PINN.c.cpu().detach().numpy(),\"k\",PINN.k.cpu().detach().numpy(),\"m\",PINN.m.cpu().detach().numpy())\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "42720d97-b37a-4c42-b7e5-b77a0ef391f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 3115652.2 Test RE 0.6605576940457089 c -0.039822 k 0.3642053 m -0.0007811197\n",
      "1 Train Loss 1878125.2 Test RE 0.5219799287045468 c -0.07437731 k 0.044515554 m -0.0014648192\n",
      "2 Train Loss 1878123.5 Test RE 0.5219796758520977 c -0.07441682 k 0.044634648 m -0.0014656006\n",
      "3 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "4 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "5 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "6 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "7 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "8 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "9 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "10 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "11 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "12 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "13 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "14 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "15 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "16 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "17 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "18 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "19 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "20 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "21 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "22 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "23 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "24 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "25 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "26 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "27 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "28 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "29 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "30 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "31 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "32 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "33 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "34 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "35 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "36 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "37 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "38 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "39 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "40 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "41 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "42 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "43 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "44 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "45 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "46 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "47 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "48 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "49 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "50 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "51 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "52 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "53 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "54 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "55 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "56 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "57 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "58 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "59 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "60 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "61 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "62 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "63 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "64 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "65 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "66 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "67 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "68 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "69 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "70 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "71 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "72 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "73 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "74 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "75 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "76 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "77 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "78 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "79 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "80 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "81 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "82 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "83 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "84 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "85 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "86 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "87 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "88 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "89 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "90 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "91 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "92 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "93 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "94 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "95 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "96 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "97 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "98 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "99 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "100 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "101 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "102 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "103 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "104 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "105 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "106 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "107 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "108 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "109 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "110 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "111 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "112 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "113 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "114 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "115 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "116 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "117 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "118 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "119 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "120 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "121 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "122 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "123 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "124 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "125 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "126 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "127 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "128 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "129 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "130 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "131 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "132 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "133 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "134 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "135 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "136 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "137 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "138 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "139 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "140 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "141 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "142 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "143 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "144 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "145 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "146 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "147 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "148 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "149 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "150 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "151 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "152 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "153 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "154 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "155 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "156 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "157 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "158 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "159 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "160 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "161 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "162 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "163 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "164 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "165 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "166 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "167 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "168 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "169 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "170 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "171 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "172 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "173 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "174 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "175 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "176 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "177 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "178 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "179 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "180 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "181 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "182 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "183 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "184 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "185 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "186 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "187 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "188 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "189 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "190 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "191 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "192 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "193 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "194 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "195 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "196 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "197 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "198 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "199 Train Loss 1878123.2 Test RE 0.5219796722284865 c -0.074420966 k 0.04464951 m -0.0014656824\n",
      "Training time: 24.90\n",
      "Training time: 24.90\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 1950978.6 Test RE 0.5318263875557447 c -0.093678035 k 0.025350297 m -0.005512239\n",
      "1 Train Loss 1878123.5 Test RE 0.5219796719875563 c -0.08423749 k 0.04444805 m -0.0049563595\n",
      "2 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "3 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "4 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "5 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "6 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "7 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "8 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "9 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "10 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "11 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "12 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "13 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "14 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "15 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "16 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "17 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "18 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "19 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "20 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "21 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "22 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "23 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "24 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "25 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "26 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "27 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "28 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "29 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "30 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "31 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "32 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "33 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "34 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "35 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "36 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "37 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "38 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "39 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "40 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "41 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "42 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "43 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "44 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "45 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "46 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "47 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "48 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "49 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "50 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "51 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "52 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "53 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "54 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "55 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "56 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "57 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "58 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "59 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "60 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "61 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "62 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "63 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "64 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "65 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "66 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "67 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "68 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "69 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "70 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "71 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "72 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "73 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "74 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "75 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "76 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "77 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "78 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "79 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "80 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "81 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "82 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "83 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "84 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "85 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "86 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "87 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "88 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "89 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "90 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "91 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "92 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "93 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "94 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "95 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "96 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "97 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "98 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "99 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "100 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "101 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "102 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "103 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "104 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "105 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "106 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "107 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "108 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "109 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "110 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "111 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "112 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "113 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "114 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "115 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "116 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "117 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "118 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "119 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "120 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "121 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "122 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "123 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "124 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "125 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "126 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "127 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "128 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "129 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "130 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "131 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "132 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "133 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "134 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "135 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "136 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "137 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "138 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "139 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "140 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "141 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "142 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "143 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "144 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "145 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "146 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "147 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "148 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "149 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "150 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "151 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "152 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "153 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "154 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "155 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "156 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "157 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "158 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "159 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "160 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "161 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "162 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "163 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "164 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "165 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "166 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "167 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "168 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "169 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "170 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "171 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "172 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "173 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "174 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "175 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "176 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "177 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "178 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "179 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "180 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "181 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "182 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "183 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "184 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "185 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "186 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "187 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "188 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "189 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "190 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "191 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "192 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "193 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "194 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "195 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "196 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "197 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "198 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "199 Train Loss 1878123.2 Test RE 0.5219796719901048 c -0.08423881 k 0.0445514 m -0.0049564494\n",
      "Training time: 30.40\n",
      "Training time: 30.40\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 1929609.0 Test RE 0.5281321446522852 c 0.099713765 k 0.008199096 m -0.0020907097\n",
      "1 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "2 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "3 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "4 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "5 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "6 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "7 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "8 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "9 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "10 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "11 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "12 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "13 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "14 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "15 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "16 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "17 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "18 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "19 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "20 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "21 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "22 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "23 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "24 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "25 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "26 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "27 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "28 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "29 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "30 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "31 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "32 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "33 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "34 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "35 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "36 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "37 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "38 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "39 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "40 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "41 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "42 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "43 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "44 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "45 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "46 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "47 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "48 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "49 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "50 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "51 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "52 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "53 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "54 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "55 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "56 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "57 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "58 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "59 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "60 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "61 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "62 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "63 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "64 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "65 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "66 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "67 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "68 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "69 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "70 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "71 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "72 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "73 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "74 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "75 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "76 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "77 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "78 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "79 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "80 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "81 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "82 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "83 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "84 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "85 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "86 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "87 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "88 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "89 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "90 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "91 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "92 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "93 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "94 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "95 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "96 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "97 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "98 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "99 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "100 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "101 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "102 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "103 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "104 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "105 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "106 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "107 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "108 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "109 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "110 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "111 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "112 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "113 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "114 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "115 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "116 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "117 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "118 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "119 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "120 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "121 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "122 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "123 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "124 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "125 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "126 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "127 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "128 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "129 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "130 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "131 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "132 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "133 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "134 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "135 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "136 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "137 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "138 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "139 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "140 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "141 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "142 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "143 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "144 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "145 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "146 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "147 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "148 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "149 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "150 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "151 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "152 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "153 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "154 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "155 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "156 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "157 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "158 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "159 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "160 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "161 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "162 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "163 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "164 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "165 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "166 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "167 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "168 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "169 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "170 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "171 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "172 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "173 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "174 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "175 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "176 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "177 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "178 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "179 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "180 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "181 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "182 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "183 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "184 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "185 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "186 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "187 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "188 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "189 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "190 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "191 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "192 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "193 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "194 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "195 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "196 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "197 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "198 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "199 Train Loss 1878123.0 Test RE 0.5219796521747467 c 0.11007431 k 0.04462452 m -0.0023083773\n",
      "Training time: 15.24\n",
      "Training time: 15.24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 3841659.5 Test RE 0.7223492281306383 c 0.023058299 k 0.64072317 m -0.0010356046\n",
      "1 Train Loss 1878229.0 Test RE 0.5219909188578332 c 0.068966255 k 0.042589962 m -0.002903006\n",
      "2 Train Loss 1878123.5 Test RE 0.5219796746978325 c 0.069243245 k 0.04462272 m -0.002914549\n",
      "3 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "4 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "5 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "6 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "7 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "8 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "9 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "10 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "11 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "12 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "13 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "14 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "15 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "16 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "17 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "18 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "19 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "20 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "21 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "22 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "23 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "24 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "25 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "26 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "27 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "28 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "29 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "30 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "31 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "32 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "33 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "34 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "35 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "36 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "37 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "38 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "39 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "40 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "41 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "42 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "43 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "44 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "45 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "46 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "47 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "48 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "49 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "50 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "51 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "52 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "53 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "54 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "55 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "56 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "57 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "58 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "59 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "60 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "61 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "62 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "63 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "64 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "65 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "66 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "67 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "68 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "69 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "70 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "71 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "72 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "73 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "74 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "75 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "76 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "77 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "78 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "79 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "80 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "81 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "82 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "83 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "84 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "85 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "86 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "87 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "88 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "89 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "90 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "91 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "92 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "93 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "94 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "95 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "96 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "97 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "98 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "99 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "100 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "101 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "102 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "103 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "104 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "105 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "106 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "107 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "108 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "109 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "110 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "111 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "112 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "113 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "114 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "115 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "116 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "117 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "118 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "119 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "120 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "121 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "122 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "123 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "124 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "125 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "126 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "127 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "128 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "129 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "130 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "131 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "132 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "133 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "134 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "135 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "136 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "137 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "138 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "139 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "140 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "141 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "142 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "143 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "144 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "145 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "146 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "147 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "148 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "149 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "150 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "151 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "152 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "153 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "154 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "155 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "156 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "157 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "158 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "159 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "160 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "161 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "162 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "163 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "164 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "165 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "166 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "167 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "168 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "169 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "170 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "171 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "172 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "173 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "174 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "175 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "176 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "177 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "178 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "179 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "180 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "181 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "182 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "183 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "184 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "185 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "186 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "187 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "188 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "189 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "190 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "191 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "192 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "193 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "194 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "195 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "196 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "197 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "198 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "199 Train Loss 1878123.2 Test RE 0.521979672659497 c 0.069245435 k 0.04463853 m -0.0029146404\n",
      "Training time: 26.12\n",
      "Training time: 26.12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 3569261.2 Test RE 0.7194194753060846 c 0.065687336 k 0.1492474 m -0.0020870317\n",
      "1 Train Loss 1878043.5 Test RE 0.5219685501079226 c 0.20245437 k 0.04494585 m -0.006459667\n",
      "2 Train Loss 1878001.8 Test RE 0.5219627737928006 c 0.20304257 k 0.044578705 m -0.006478917\n",
      "3 Train Loss 1877823.1 Test RE 0.5219378840945683 c 0.2038999 k 0.044235624 m -0.0065077166\n",
      "4 Train Loss 1875362.5 Test RE 0.5215822605325109 c 0.20710279 k 0.049136046 m -0.0066217296\n",
      "5 Train Loss 1855571.5 Test RE 0.5179909307859503 c 0.22014582 k 0.009608591 m -0.007029042\n",
      "6 Train Loss 1774321.0 Test RE 0.5070015630714867 c 0.22491907 k 0.063891456 m -0.007161486\n",
      "7 Train Loss 1741378.4 Test RE 0.5025964641058145 c 0.21942708 k 0.050110105 m -0.006921495\n",
      "8 Train Loss 1729758.0 Test RE 0.5007163883846205 c 0.22551925 k 0.026452845 m -0.004892814\n",
      "9 Train Loss 1712975.2 Test RE 0.49809329337569624 c 0.2179665 k 0.021012297 m -0.0008727659\n",
      "10 Train Loss 1698177.5 Test RE 0.4962406487563063 c 0.20987517 k 0.039168034 m 0.0004168555\n",
      "11 Train Loss 1694014.6 Test RE 0.4956224858251851 c 0.2133259 k 0.046652954 m -0.0012925029\n",
      "12 Train Loss 1692195.0 Test RE 0.49534839855759966 c 0.20959443 k 0.039145663 m 0.0010194338\n",
      "13 Train Loss 1688312.2 Test RE 0.49488840206971657 c 0.18704529 k 0.04172915 m -0.0005882304\n",
      "14 Train Loss 1687993.9 Test RE 0.4948241710079945 c 0.1871936 k 0.048728257 m -0.0009553135\n",
      "15 Train Loss 1679457.4 Test RE 0.4935976256475352 c 0.18020652 k 0.04390343 m -0.0016239653\n",
      "16 Train Loss 1677665.9 Test RE 0.4933130018302131 c 0.17278028 k 0.038213175 m -0.0015648258\n",
      "17 Train Loss 1673343.4 Test RE 0.4926967012160634 c 0.14021164 k 0.04426993 m -0.0016129891\n",
      "18 Train Loss 1672869.5 Test RE 0.49262624561452245 c 0.12875825 k 0.04427459 m -0.0017597129\n",
      "19 Train Loss 1670900.5 Test RE 0.4923317178922409 c 0.105490625 k 0.041651487 m 0.0012713263\n",
      "20 Train Loss 1670404.1 Test RE 0.4922548088310686 c 0.09339173 k 0.045107648 m 0.0014495105\n",
      "21 Train Loss 1669899.9 Test RE 0.4921786667237074 c 0.08250636 k 0.042846926 m -0.0011506816\n",
      "22 Train Loss 1668987.5 Test RE 0.49205087965695593 c 0.05080101 k 0.043262694 m -0.0001371351\n",
      "23 Train Loss 1668214.8 Test RE 0.49193837720104916 c 0.008481806 k 0.046487853 m 2.8147304e-05\n",
      "24 Train Loss 1667198.9 Test RE 0.4917925770772833 c -0.0054999907 k 0.042776402 m 0.00013506754\n",
      "25 Train Loss 1666890.1 Test RE 0.49174827593141324 c -0.02075396 k 0.04419826 m -0.00012436892\n",
      "26 Train Loss 1666591.5 Test RE 0.4917035768678706 c -0.03321807 k 0.043892752 m -0.00047314045\n",
      "27 Train Loss 1666433.4 Test RE 0.491678282707321 c -0.03947436 k 0.044041663 m -0.00069557823\n",
      "28 Train Loss 1666252.4 Test RE 0.4916472184439919 c -0.05274855 k 0.0427064 m -0.001107631\n",
      "29 Train Loss 1665341.1 Test RE 0.491508254249449 c -0.076570764 k 0.04377905 m -0.0014005144\n",
      "30 Train Loss 1665058.4 Test RE 0.4914443952781215 c -0.08509143 k 0.04388343 m -0.0012555888\n",
      "31 Train Loss 1664642.4 Test RE 0.4914165160645248 c -0.09402379 k 0.043713875 m 8.5958156e-05\n",
      "32 Train Loss 1664296.5 Test RE 0.4913616571433181 c -0.09963123 k 0.041765805 m 0.00034362776\n",
      "33 Train Loss 1663727.5 Test RE 0.4912805581723775 c -0.11042382 k 0.043402083 m 0.001315525\n",
      "34 Train Loss 1663334.9 Test RE 0.49121830983413217 c -0.12503628 k 0.044453025 m 0.002308861\n",
      "35 Train Loss 1663007.5 Test RE 0.4911727847963388 c -0.1363922 k 0.043579914 m 0.003100805\n",
      "36 Train Loss 1662629.4 Test RE 0.49111635192225767 c -0.14727248 k 0.043672394 m 0.004395446\n",
      "37 Train Loss 1662278.6 Test RE 0.491064225883498 c -0.15968432 k 0.043823477 m 0.005943879\n",
      "38 Train Loss 1661828.9 Test RE 0.49099600959493045 c -0.17642444 k 0.043481424 m 0.008312906\n",
      "39 Train Loss 1661429.6 Test RE 0.4909197201492353 c -0.19596155 k 0.04309039 m 0.012005202\n",
      "40 Train Loss 1661126.5 Test RE 0.49085313792556057 c -0.20746507 k 0.04330585 m 0.014916918\n",
      "41 Train Loss 1660782.1 Test RE 0.4907824146844929 c -0.22534381 k 0.043862358 m 0.019252544\n",
      "42 Train Loss 1660229.6 Test RE 0.49070931728851014 c -0.2473339 k 0.043561377 m 0.024652287\n",
      "43 Train Loss 1659581.8 Test RE 0.4906314746107112 c -0.27007404 k 0.04358994 m 0.029991105\n",
      "44 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "45 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "46 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "47 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "48 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "49 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "50 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "51 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "52 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "53 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "54 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "55 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "56 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "57 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "58 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "59 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "60 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "61 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "62 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "63 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "64 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "65 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "66 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "67 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "68 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "69 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "70 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "71 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "72 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "73 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "74 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "75 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "76 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "77 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "78 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "79 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "80 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "81 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "82 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "83 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "84 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "85 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "86 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "87 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "88 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "89 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "90 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "91 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "92 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "93 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "94 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "95 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "96 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "97 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "98 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "99 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "100 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "101 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "102 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "103 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "104 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "105 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "106 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "107 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "108 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "109 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "110 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "111 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "112 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "113 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "114 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "115 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "116 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "117 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "118 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "119 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "120 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "121 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "122 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "123 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "124 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "125 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "126 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "127 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "128 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "129 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "130 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "131 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "132 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "133 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "134 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "135 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "136 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "137 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "138 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "139 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "140 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "141 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "142 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "143 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "144 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "145 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "146 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "147 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "148 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "149 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "150 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "151 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "152 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "153 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "154 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "155 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "156 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "157 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "158 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "159 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "160 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "161 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "162 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "163 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "164 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "165 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "166 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "167 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "168 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "169 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "170 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "171 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "172 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "173 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "174 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "175 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "176 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "177 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "178 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "179 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "180 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "181 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "182 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "183 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "184 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "185 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "186 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "187 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "188 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "189 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "190 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "191 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "192 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "193 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "194 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "195 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "196 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "197 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "198 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "199 Train Loss 1659140.9 Test RE 0.49057622368388404 c -0.29052594 k 0.043532673 m 0.03456603\n",
      "Training time: 29.63\n",
      "Training time: 29.63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 2516810.0 Test RE 0.5934544377518772 c -0.09569736 k 0.2660332 m -0.0010815164\n",
      "1 Train Loss 1878123.8 Test RE 0.5219797037151506 c -0.14379287 k 0.044551976 m -0.0016263435\n",
      "2 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "3 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "4 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "5 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "6 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "7 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "8 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "9 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "10 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "11 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "12 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "13 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "14 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "15 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "16 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "17 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "18 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "19 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "20 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "21 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "22 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "23 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "24 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "25 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "26 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "27 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "28 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "29 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "30 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "31 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "32 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "33 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "34 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "35 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "36 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "37 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "38 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "39 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "40 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "41 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "42 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "43 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "44 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "45 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "46 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "47 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "48 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "49 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "50 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "51 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "52 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "53 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "54 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "55 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "56 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "57 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "58 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "59 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "60 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "61 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "62 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "63 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "64 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "65 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "66 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "67 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "68 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "69 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "70 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "71 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "72 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "73 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "74 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "75 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "76 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "77 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "78 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "79 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "80 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "81 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "82 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "83 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "84 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "85 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "86 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "87 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "88 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "89 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "90 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "91 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "92 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "93 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "94 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "95 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "96 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "97 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "98 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "99 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "100 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "101 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "102 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "103 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "104 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "105 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "106 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "107 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "108 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "109 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "110 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "111 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "112 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "113 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "114 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "115 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "116 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "117 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "118 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "119 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "120 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "121 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "122 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "123 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "124 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "125 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "126 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "127 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "128 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "129 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "130 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "131 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "132 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "133 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "134 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "135 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "136 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "137 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "138 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "139 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "140 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "141 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "142 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "143 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "144 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "145 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "146 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "147 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "148 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "149 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "150 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "151 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "152 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "153 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "154 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "155 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "156 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "157 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "158 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "159 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "160 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "161 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "162 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "163 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "164 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "165 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "166 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "167 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "168 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "169 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "170 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "171 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "172 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "173 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "174 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "175 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "176 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "177 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "178 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "179 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "180 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "181 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "182 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "183 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "184 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "185 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "186 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "187 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "188 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "189 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "190 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "191 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "192 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "193 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "194 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "195 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "196 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "197 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "198 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "199 Train Loss 1878123.2 Test RE 0.5219796739519278 c -0.1438159 k 0.044628795 m -0.0016266044\n",
      "Training time: 42.29\n",
      "Training time: 42.29\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 2307521.5 Test RE 0.5522593785198342 c 0.2234028 k 0.31313506 m -0.0023948974\n",
      "1 Train Loss 1878268.0 Test RE 0.5219997412462642 c 0.29708573 k 0.044857226 m -0.0031852212\n",
      "2 Train Loss 1878133.5 Test RE 0.5219810896948163 c 0.29659262 k 0.04463302 m -0.00317965\n",
      "3 Train Loss 1878122.8 Test RE 0.5219796286102802 c 0.29618734 k 0.04471658 m -0.0031748791\n",
      "4 Train Loss 1878114.8 Test RE 0.5219784597958845 c 0.29477024 k 0.044564016 m -0.00315894\n",
      "5 Train Loss 1878034.2 Test RE 0.5219653107030998 c 0.2957467 k 0.042924274 m -0.003170655\n",
      "6 Train Loss 1878006.2 Test RE 0.5219633812005677 c 0.29563913 k 0.044949647 m -0.0031695124\n",
      "7 Train Loss 1875293.4 Test RE 0.5214366711013703 c 0.3000168 k 0.029768467 m -0.0032179581\n",
      "8 Train Loss 1865617.5 Test RE 0.520157773812748 c 0.29876703 k 0.054956988 m -0.003205125\n",
      "9 Train Loss 1794563.8 Test RE 0.5102259466096779 c 0.29029784 k 0.048191696 m -0.003120688\n",
      "10 Train Loss 1793113.8 Test RE 0.510028767428609 c 0.2915997 k 0.044251468 m -0.0031356665\n",
      "11 Train Loss 1792919.0 Test RE 0.5100004282167488 c 0.2887627 k 0.044153605 m -0.003022995\n",
      "12 Train Loss 1789117.2 Test RE 0.5094396340195317 c 0.26155874 k 0.043905787 m 0.00592182\n",
      "13 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "14 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "15 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "16 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "17 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "18 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "19 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "20 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "21 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "22 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "23 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "24 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "25 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "26 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "27 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "28 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "29 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "30 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "31 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "32 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "33 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "34 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "35 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "36 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "37 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "38 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "39 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "40 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "41 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "42 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "43 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "44 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "45 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "46 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "47 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "48 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "49 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "50 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "51 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "52 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "53 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "54 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "55 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "56 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "57 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "58 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "59 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "60 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "61 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "62 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "63 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "64 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "65 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "66 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "67 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "68 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "69 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "70 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "71 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "72 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "73 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "74 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "75 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "76 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "77 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "78 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "79 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "80 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "81 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "82 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "83 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "84 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "85 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "86 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "87 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "88 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "89 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "90 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "91 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "92 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "93 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "94 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "95 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "96 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "97 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "98 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "99 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "100 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "101 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "102 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "103 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "104 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "105 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "106 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "107 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "108 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "109 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "110 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "111 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "112 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "113 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "114 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "115 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "116 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "117 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "118 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "119 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "120 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "121 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "122 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "123 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "124 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "125 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "126 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "127 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "128 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "129 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "130 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "131 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "132 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "133 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "134 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "135 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "136 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "137 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "138 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "139 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "140 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "141 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "142 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "143 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "144 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "145 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "146 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "147 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "148 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "149 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "150 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "151 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "152 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "153 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "154 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "155 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "156 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "157 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "158 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "159 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "160 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "161 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "162 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "163 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "164 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "165 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "166 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "167 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "168 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "169 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "170 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "171 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "172 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "173 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "174 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "175 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "176 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "177 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "178 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "179 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "180 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "181 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "182 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "183 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "184 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "185 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "186 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "187 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "188 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "189 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "190 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "191 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "192 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "193 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "194 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "195 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "196 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "197 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "198 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "199 Train Loss 1788727.2 Test RE 0.5093748103950217 c 0.2566245 k 0.043201927 m 0.00028799934\n",
      "Training time: 37.55\n",
      "Training time: 37.55\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 4033433.0 Test RE 0.7648278718750317 c 0.115404546 k 0.084459946 m -0.00019720622\n",
      "1 Train Loss 1878137.1 Test RE 0.5219814132662633 c 0.33483428 k 0.044214647 m -0.00057956745\n",
      "2 Train Loss 1878123.5 Test RE 0.5219796776399738 c 0.33533493 k 0.044635125 m -0.0005804394\n",
      "3 Train Loss 1878123.5 Test RE 0.5219796734137319 c 0.33535 k 0.044646714 m -0.0005804657\n",
      "4 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "5 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "6 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "7 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "8 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "9 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "10 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "11 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "12 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "13 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "14 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "15 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "16 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "17 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "18 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "19 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "20 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "21 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "22 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "23 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "24 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "25 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "26 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "27 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "28 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "29 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "30 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "31 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "32 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "33 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "34 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "35 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "36 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "37 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "38 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "39 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "40 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "41 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "42 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "43 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "44 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "45 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "46 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "47 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "48 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "49 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "50 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "51 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "52 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "53 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "54 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "55 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "56 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "57 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "58 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "59 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "60 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "61 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "62 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "63 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "64 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "65 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "66 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "67 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "68 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "69 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "70 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "71 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "72 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "73 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "74 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "75 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "76 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "77 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "78 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "79 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "80 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "81 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "82 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "83 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "84 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "85 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "86 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "87 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "88 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "89 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "90 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "91 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "92 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "93 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "94 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "95 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "96 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "97 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "98 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "99 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "100 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "101 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "102 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "103 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "104 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "105 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "106 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "107 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "108 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "109 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "110 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "111 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "112 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "113 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "114 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "115 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "116 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "117 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "118 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "119 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "120 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "121 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "122 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "123 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "124 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "125 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "126 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "127 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "128 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "129 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "130 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "131 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "132 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "133 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "134 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "135 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "136 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "137 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "138 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "139 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "140 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "141 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "142 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "143 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "144 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "145 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "146 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "147 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "148 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "149 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "150 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "151 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "152 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "153 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "154 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "155 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "156 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "157 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "158 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "159 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "160 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "161 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "162 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "163 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "164 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "165 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "166 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "167 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "168 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "169 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "170 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "171 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "172 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "173 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "174 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "175 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "176 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "177 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "178 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "179 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "180 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "181 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "182 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "183 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "184 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "185 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "186 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "187 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "188 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "189 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "190 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "191 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "192 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "193 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "194 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "195 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "196 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "197 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "198 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "199 Train Loss 1878123.2 Test RE 0.5219796723345043 c 0.33535767 k 0.044649974 m -0.0005804791\n",
      "Training time: 31.35\n",
      "Training time: 31.35\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 2296270.8 Test RE 0.5704992026766732 c 0.11323185 k 0.2016618 m -0.0010589568\n",
      "1 Train Loss 1878123.5 Test RE 0.5219796776610637 c 0.15090775 k 0.044673324 m -0.0014115814\n",
      "2 Train Loss 1878123.5 Test RE 0.521979673403703 c 0.15090093 k 0.04466385 m -0.0014115176\n",
      "3 Train Loss 1878123.2 Test RE 0.521979672074826 c 0.15089582 k 0.04465674 m -0.0014114698\n",
      "4 Train Loss 1878123.2 Test RE 0.5219796720087 c 0.15089497 k 0.04465555 m -0.0014114617\n",
      "5 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "6 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "7 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "8 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "9 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "10 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "11 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "12 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "13 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "14 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "15 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "16 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "17 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "18 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "19 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "20 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "21 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "22 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "23 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "24 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "25 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "26 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "27 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "28 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "29 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "30 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "31 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "32 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "33 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "34 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "35 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "36 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "37 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "38 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "39 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "40 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "41 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "42 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "43 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "44 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "45 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "46 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "47 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "48 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "49 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "50 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "51 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "52 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "53 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "54 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "55 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "56 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "57 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "58 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "59 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "60 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "61 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "62 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "63 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "64 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "65 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "66 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "67 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "68 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "69 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "70 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "71 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "72 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "73 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "74 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "75 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "76 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "77 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "78 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "79 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "80 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "81 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "82 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "83 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "84 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "85 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "86 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "87 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "88 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "89 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "90 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "91 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "92 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "93 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "94 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "95 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "96 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "97 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "98 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "99 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "100 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "101 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "102 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "103 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "104 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "105 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "106 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "107 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "108 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "109 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "110 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "111 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "112 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "113 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "114 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "115 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "116 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "117 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "118 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "119 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "120 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "121 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "122 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "123 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "124 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "125 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "126 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "127 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "128 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "129 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "130 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "131 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "132 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "133 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "134 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "135 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "136 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "137 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "138 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "139 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "140 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "141 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "142 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "143 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "144 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "145 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "146 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "147 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "148 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "149 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "150 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "151 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "152 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "153 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "154 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "155 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "156 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "157 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "158 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "159 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "160 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "161 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "162 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "163 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "164 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "165 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "166 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "167 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "168 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "169 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "170 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "171 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "172 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "173 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "174 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "175 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "176 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "177 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "178 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "179 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "180 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "181 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "182 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "183 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "184 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "185 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "186 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "187 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "188 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "189 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "190 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "191 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "192 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "193 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "194 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "195 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "196 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "197 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "198 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "199 Train Loss 1878123.2 Test RE 0.5219796719911355 c 0.15089452 k 0.044654958 m -0.0014114575\n",
      "Training time: 19.85\n",
      "Training time: 19.85\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 2566302.0 Test RE 0.5652278375214429 c 0.12456925 k 0.4211561 m -0.00083932636\n",
      "1 Train Loss 1878125.5 Test RE 0.521979973879965 c 0.16681015 k 0.04458419 m -0.0011241054\n",
      "2 Train Loss 1878123.5 Test RE 0.5219796768358826 c 0.16690612 k 0.044645518 m -0.0011247528\n",
      "3 Train Loss 1878123.5 Test RE 0.5219796732020991 c 0.16691306 k 0.044649854 m -0.0011247996\n",
      "4 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "5 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "6 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "7 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "8 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "9 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "10 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "11 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "12 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "13 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "14 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "15 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "16 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "17 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "18 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "19 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "20 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "21 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "22 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "23 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "24 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "25 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "26 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "27 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "28 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "29 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "30 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "31 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "32 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "33 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "34 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "35 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "36 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "37 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "38 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "39 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "40 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "41 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "42 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "43 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "44 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "45 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "46 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "47 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "48 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "49 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "50 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "51 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "52 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "53 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "54 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "55 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "56 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "57 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "58 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "59 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "60 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "61 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "62 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "63 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "64 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "65 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "66 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "67 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "68 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "69 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "70 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "71 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "72 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "73 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "74 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "75 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "76 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "77 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "78 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "79 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "80 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "81 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "82 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "83 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "84 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "85 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "86 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "87 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "88 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "89 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "90 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "91 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "92 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "93 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "94 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "95 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "96 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "97 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "98 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "99 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "100 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "101 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "102 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "103 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "104 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "105 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "106 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "107 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "108 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "109 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "110 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "111 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "112 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "113 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "114 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "115 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "116 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "117 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "118 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "119 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "120 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "121 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "122 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "123 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "124 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "125 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "126 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "127 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "128 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "129 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "130 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "131 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "132 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "133 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "134 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "135 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "136 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "137 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "138 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "139 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "140 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "141 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "142 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "143 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "144 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "145 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "146 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "147 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "148 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "149 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "150 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "151 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "152 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "153 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "154 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "155 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "156 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "157 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "158 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "159 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "160 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "161 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "162 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "163 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "164 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "165 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "166 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "167 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "168 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "169 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "170 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "171 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "172 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "173 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "174 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "175 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "176 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "177 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "178 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "179 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "180 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "181 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "182 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "183 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "184 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "185 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "186 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "187 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "188 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "189 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "190 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "191 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "192 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "193 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "194 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "195 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "196 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "197 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "198 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "199 Train Loss 1878123.2 Test RE 0.5219796720376302 c 0.1669186 k 0.04465335 m -0.0011248369\n",
      "Training time: 32.89\n",
      "Training time: 32.89\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "m_full = []\n",
    "k_full = []\n",
    "c_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []   \n",
    "    beta_val = []\n",
    "    m_val = []\n",
    "    k_val = []\n",
    "    c_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "    N_f = 10000 #Total number of collocation points\n",
    "\n",
    "    layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.5, \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-6, \n",
    "                                tolerance_change = 1e-6, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    beta_full.append(beta_val)\n",
    "    m_full.append(m_val)\n",
    "    k_full.append(k_val)\n",
    "    c_full.append(c_val)\n",
    "    \n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full,\"m\": m_full,\"k\": k_full,\"c\": c_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "990b2054-f35e-4c8e-c378-69ff2eb19f4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f55d05ed4d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_pred = PINN.test()\n",
    "plt.plot(t,x_true,'b')\n",
    "plt.plot(t,x_pred,'r--')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
