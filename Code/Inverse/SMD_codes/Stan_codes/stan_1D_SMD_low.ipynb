{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "510f67c6-b225-41ba-e78a-d0a6e54ded85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "tstart= 0 \n",
    "tstop= 60 \n",
    "\n",
    "increment = 0.1 \n",
    "# Initial condition\n",
    "x_init= [0,0] \n",
    "\n",
    "t = np.arange(tstart,tstop+1,increment)\n",
    "\n",
    "c = 1 # Damping constant \n",
    "k = 1 # Stiffness of the spring\n",
    "m = 5 # Mass \n",
    "F0 = 100\n",
    "\n",
    "def mydiff(x, t):    \n",
    "    F =F0\n",
    "    \n",
    "    dx1dt = x[1] \n",
    "    dx2dt = (F -c*x[1] -k*x[0])/m\n",
    "    dxdt= [dx1dt, dx2dt] \n",
    "    \n",
    "    return dxdt \n",
    "\n",
    "x_full_sol = odeint(mydiff, x_init, t) \n",
    "\n",
    "x_sol = x_full_sol[:,0]\n",
    "v_sol = x_full_sol[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "level = \"low\"\n",
    "label = \"1D_SMD_stan_\" + level\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "\n",
    "# bc1_t = t[0].reshape(-1,1)\n",
    "# bc1_x = x_sol[0].reshape(-1,1)\n",
    "# t_bc1_train = torch.from_numpy(bc1_t).float().to(device)\n",
    "# x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "\n",
    "bc1_t = t.reshape(-1,1)\n",
    "bc1_x = x_sol.reshape(-1,1)\n",
    "t_bc1_train = torch.from_numpy(bc1_t).float().to(device)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "\n",
    "\n",
    "bc2_t = t[0].reshape(-1,1)\n",
    "t_bc2_train = torch.from_numpy(bc2_t).float().to(device)\n",
    "bc2_val = v_sol[0].reshape(-1,1)\n",
    "bc2_val =torch.from_numpy(bc2_val).float().to(device)\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "x_true = x_sol\n",
    "x_true_norm = np.linalg.norm(x_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(t[0]) \n",
    "ub = np.array(t[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    \n",
    "    t01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=t01,random_state =seed)\n",
    "\n",
    "    t_coll = lb + (ub-lb)*sampling(N_f)\n",
    "    # t_coll = np.vstack((t_coll,)) # append training points to collocation points \n",
    "\n",
    "    return t_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(1.0*torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "        self.k = Parameter(torch.tensor(0.0))\n",
    "        self.k.requiresGrad = True\n",
    "        self.c = Parameter(torch.tensor(0.0))\n",
    "        self.c.requiresGrad = True\n",
    "        self.m = Parameter(torch.tensor(0.0))\n",
    "        self.m.requiresGrad = True\n",
    "        \n",
    "    'forward pass'\n",
    "    def forward(self,t):\n",
    "        if torch.is_tensor(t) != True:         \n",
    "            t = torch.from_numpy(t)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        t = 2.0*(t - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = t.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) + self.beta[:,i]*z*self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,t,x):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(t), x)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,t_bc2,bc2_val):\n",
    "        g = t_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        x = self.forward(g)    \n",
    "            \n",
    "        x_t = autograd.grad(x,g,torch.ones([t_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        bc2 = dx_dt\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self,t_coll,f_hat):\n",
    "             \n",
    "        g = t_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        x = self.forward(g) \n",
    "\n",
    "        x_t = autograd.grad(x,g,torch.ones([t_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        x_tt = autograd.grad(x_t,g,torch.ones(t_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        dx2_d2t = x_tt[:,[0]]\n",
    "        \n",
    "        f = self.m*dx2_d2t + self.c*dx_dt + self.k*x - F0\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,t_bc1,x_bc1,t_bc2,bc2_val,t_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(t_bc1,x_bc1)\n",
    "        loss_bc2 = self.loss_BC2(t_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(t_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        x_pred = self.forward(t_test_tensor)\n",
    "        x_pred = x_pred.cpu().detach().numpy()\n",
    "\n",
    "        return x_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        x_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(x_pred.reshape(-1,1) - x_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(x_pred.reshape(-1,1) - x_true.reshape(-1,1),2)/x_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    m_val.append(PINN.m.cpu().detach().numpy())\n",
    "    k_val.append(PINN.k.cpu().detach().numpy())\n",
    "    c_val.append(PINN.c.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    t_coll = colloc_pts(N_f,rep*11)\n",
    "    t_coll =  torch.from_numpy(t_coll).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(t_coll.shape[0],1).to(device)\n",
    "    for i in range(max_iter):      \n",
    "        train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "         \n",
    "        loss_np = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test RE\",test_re_loss[-1],\"c\",PINN.c.cpu().detach().numpy(),\"k\",PINN.k.cpu().detach().numpy(),\"m\",PINN.m.cpu().detach().numpy())\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "42720d97-b37a-4c42-b7e5-b77a0ef391f3",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 1006.4357 Test RE 0.28542956899338595 c -0.04146331 k 1.0886124 m -0.0030952275\n",
      "1 Train Loss 492.4157 Test RE 0.21863194430400207 c -0.04444852 k 1.0182047 m -0.0033220658\n",
      "2 Train Loss 490.8372 Test RE 0.21867577613441608 c -0.044570554 k 1.0161611 m -0.00333563\n",
      "3 Train Loss 489.05215 Test RE 0.2188495599012086 c -0.044300336 k 1.0175235 m -0.0033444401\n",
      "4 Train Loss 484.39124 Test RE 0.2176275353873896 c -0.042951584 k 1.017721 m -0.0034244827\n",
      "5 Train Loss 471.86365 Test RE 0.21289579746679022 c -0.034016177 k 1.0129243 m -0.0037355116\n",
      "6 Train Loss 451.1824 Test RE 0.20384659410328104 c -0.01525415 k 1.0163141 m -0.004240655\n",
      "7 Train Loss 414.9341 Test RE 0.19111342331174222 c 0.021506153 k 1.0069366 m -0.005290111\n",
      "8 Train Loss 361.06796 Test RE 0.16313073536751316 c 0.15566729 k 1.00595 m -0.0060789804\n",
      "9 Train Loss 344.9805 Test RE 0.15432214536510627 c 0.33710814 k 1.001939 m 0.017089799\n",
      "10 Train Loss 317.3897 Test RE 0.15755661546746522 c 0.68448794 k 0.9972451 m 0.11875591\n",
      "11 Train Loss 275.16513 Test RE 0.13008189991464192 c 0.9518686 k 0.99405986 m 0.18833269\n",
      "12 Train Loss 261.8946 Test RE 0.12005794436750065 c 1.0333852 k 0.9885319 m 0.23273142\n",
      "13 Train Loss 250.54779 Test RE 0.1217863806562362 c 1.2040056 k 0.989608 m 0.36877608\n",
      "14 Train Loss 236.14291 Test RE 0.10812820685677223 c 1.3307469 k 0.9816837 m 0.5939116\n",
      "15 Train Loss 229.68874 Test RE 0.1052610491626464 c 1.3103186 k 0.984964 m 0.6461766\n",
      "16 Train Loss 213.77666 Test RE 0.10831567581373278 c 1.318097 k 0.98440474 m 1.0922848\n",
      "17 Train Loss 185.2214 Test RE 0.09866979461915457 c 1.198967 k 0.98243004 m 1.6963549\n",
      "18 Train Loss 170.10101 Test RE 0.09567762695850818 c 1.1182346 k 0.9902771 m 2.007442\n",
      "19 Train Loss 158.36134 Test RE 0.09553842769743653 c 1.0848981 k 0.9816863 m 2.4012513\n",
      "20 Train Loss 138.93065 Test RE 0.0891173882797184 c 1.3708683 k 0.9954462 m 3.1123269\n",
      "21 Train Loss 108.02822 Test RE 0.0641138083465822 c 1.8122997 k 0.9887002 m 4.282563\n",
      "22 Train Loss 97.126175 Test RE 0.06839075811242201 c 1.7204539 k 0.9937551 m 4.408643\n",
      "23 Train Loss 81.13376 Test RE 0.06161463037382195 c 1.6637173 k 0.9949867 m 5.299312\n",
      "24 Train Loss 63.377365 Test RE 0.05717556108971142 c 1.528373 k 0.9997984 m 5.7624593\n",
      "25 Train Loss 60.2659 Test RE 0.054592920483615706 c 1.4728664 k 1.0034732 m 5.9295115\n",
      "26 Train Loss 57.36145 Test RE 0.04945312659892684 c 1.411864 k 1.0061011 m 6.166784\n",
      "27 Train Loss 52.163376 Test RE 0.047168511518116296 c 1.2148033 k 1.0099101 m 6.213589\n",
      "28 Train Loss 48.681328 Test RE 0.04232935487892883 c 1.0952394 k 1.0034257 m 6.0331216\n",
      "29 Train Loss 47.283405 Test RE 0.03924011633892028 c 1.1132528 k 1.0086442 m 5.9813175\n",
      "30 Train Loss 45.76982 Test RE 0.040418562234113366 c 1.081657 k 1.0053694 m 5.8042192\n",
      "31 Train Loss 37.0164 Test RE 0.0319769082015485 c 0.93612486 k 0.9995462 m 5.052599\n",
      "32 Train Loss 34.51885 Test RE 0.026844442263450115 c 0.91137695 k 1.00396 m 4.9984035\n",
      "33 Train Loss 34.022926 Test RE 0.026939433427535516 c 0.8642987 k 1.001234 m 5.015994\n",
      "34 Train Loss 33.201134 Test RE 0.02714421438940899 c 0.89253217 k 1.0012295 m 5.14139\n",
      "35 Train Loss 32.448235 Test RE 0.026764367605929127 c 0.96278656 k 1.0007938 m 5.128066\n",
      "36 Train Loss 30.89148 Test RE 0.02563673763447936 c 0.99017996 k 0.99843824 m 4.902762\n",
      "37 Train Loss 28.122372 Test RE 0.0234168065421092 c 1.0372307 k 0.99668247 m 4.823424\n",
      "38 Train Loss 27.137901 Test RE 0.02247436434797396 c 1.0150985 k 0.99893713 m 4.992891\n",
      "39 Train Loss 26.769201 Test RE 0.021666857587550808 c 0.9879577 k 1.0000819 m 5.048614\n",
      "40 Train Loss 26.23522 Test RE 0.02142884241751168 c 1.020803 k 0.9986 m 5.127404\n",
      "41 Train Loss 25.543407 Test RE 0.02279488034736912 c 1.0540922 k 1.0031952 m 5.139848\n",
      "42 Train Loss 24.621637 Test RE 0.022314530759114562 c 0.9786122 k 1.0032656 m 5.086561\n",
      "43 Train Loss 23.876945 Test RE 0.01994803526396169 c 0.9912991 k 0.995514 m 5.02903\n",
      "44 Train Loss 22.866526 Test RE 0.020731429197215826 c 1.0044049 k 0.9988156 m 5.0067477\n",
      "45 Train Loss 20.827349 Test RE 0.01809532158269707 c 0.96862894 k 1.0012192 m 5.144233\n",
      "46 Train Loss 18.915434 Test RE 0.018905359039366385 c 1.0725747 k 1.0005972 m 5.1206856\n",
      "47 Train Loss 17.61818 Test RE 0.019317356348776793 c 1.1186936 k 0.99576175 m 4.946862\n",
      "48 Train Loss 16.345432 Test RE 0.020026347581596108 c 1.1221008 k 0.9948296 m 4.7825937\n",
      "49 Train Loss 15.032027 Test RE 0.017945206784491463 c 1.0417217 k 1.0000132 m 4.7512474\n",
      "50 Train Loss 14.204438 Test RE 0.017914831634338893 c 0.9901837 k 0.9947708 m 4.689576\n",
      "51 Train Loss 12.760804 Test RE 0.01876550445033333 c 1.0331038 k 0.997281 m 4.557939\n",
      "52 Train Loss 11.778415 Test RE 0.017696636741190645 c 1.0695229 k 0.9942002 m 4.4876885\n",
      "53 Train Loss 11.308189 Test RE 0.017591276621879266 c 1.0787591 k 0.99182427 m 4.438618\n",
      "54 Train Loss 9.440371 Test RE 0.017213454729704904 c 0.9921644 k 0.997965 m 4.4956393\n",
      "55 Train Loss 4.864769 Test RE 0.012711066150406163 c 0.9108398 k 0.9979671 m 4.727752\n",
      "56 Train Loss 3.7774305 Test RE 0.011371697809736214 c 0.9499177 k 0.99480414 m 4.781924\n",
      "57 Train Loss 3.3259625 Test RE 0.01108371386984717 c 1.0110432 k 0.9997154 m 4.7799287\n",
      "58 Train Loss 3.0255718 Test RE 0.01075162381832435 c 1.0308794 k 0.9996053 m 4.7996297\n",
      "59 Train Loss 2.8365445 Test RE 0.010542228070138354 c 1.009181 k 0.9980466 m 4.837395\n",
      "60 Train Loss 2.7426314 Test RE 0.010427758444771375 c 1.0105197 k 0.9992182 m 4.8539243\n",
      "61 Train Loss 2.675036 Test RE 0.010559228853883737 c 1.0323421 k 0.9994721 m 4.8674507\n",
      "62 Train Loss 2.3166547 Test RE 0.01051762501375111 c 1.0363578 k 0.9996569 m 4.989361\n",
      "63 Train Loss 2.232613 Test RE 0.010239691491429222 c 1.0140853 k 1.0009172 m 5.0312386\n",
      "64 Train Loss 2.201007 Test RE 0.010233549286500112 c 1.0210829 k 1.0008558 m 5.034098\n",
      "65 Train Loss 2.132715 Test RE 0.0103306640010212 c 1.0259768 k 1.000495 m 5.020954\n",
      "66 Train Loss 2.0565505 Test RE 0.010646352552751969 c 1.0284852 k 1.0004739 m 4.989138\n",
      "67 Train Loss 2.0309718 Test RE 0.010611803308494566 c 1.0190591 k 0.99994576 m 4.9748535\n",
      "68 Train Loss 2.0033598 Test RE 0.010615101567683683 c 1.0161556 k 0.99963164 m 4.9513483\n",
      "69 Train Loss 1.9960172 Test RE 0.010712144512322622 c 1.015976 k 0.9995799 m 4.9328437\n",
      "70 Train Loss 1.9826233 Test RE 0.01087974669442897 c 1.0135 k 0.9995613 m 4.921138\n",
      "71 Train Loss 1.9625815 Test RE 0.010944292155100548 c 1.0100973 k 0.99953556 m 4.9326463\n",
      "72 Train Loss 1.9373922 Test RE 0.010854342629668407 c 1.0113809 k 0.99921453 m 4.944814\n",
      "73 Train Loss 1.9095285 Test RE 0.01085604546271415 c 1.0089525 k 0.9995063 m 4.9467177\n",
      "74 Train Loss 1.8994367 Test RE 0.010785852408914757 c 1.0074197 k 1.0003479 m 4.957284\n",
      "75 Train Loss 1.872969 Test RE 0.010630679866737231 c 1.0061998 k 0.99988574 m 4.964962\n",
      "76 Train Loss 1.8252892 Test RE 0.010423737385347293 c 0.9952461 k 0.9990093 m 4.9258122\n",
      "77 Train Loss 1.7842145 Test RE 0.010319560669369916 c 0.9955595 k 0.99968183 m 4.9147415\n",
      "78 Train Loss 1.7671728 Test RE 0.01022951105578342 c 0.99986184 k 0.99964154 m 4.92977\n",
      "79 Train Loss 1.7387352 Test RE 0.00989766605884711 c 0.9963912 k 0.9994758 m 4.946998\n",
      "80 Train Loss 1.6891024 Test RE 0.009445331406474213 c 0.98986423 k 1.0000075 m 4.9656363\n",
      "81 Train Loss 1.6108279 Test RE 0.00929490959651225 c 1.0110956 k 1.0001416 m 4.9733086\n",
      "82 Train Loss 1.5452635 Test RE 0.009040528774905472 c 1.0201197 k 1.0001029 m 4.9792657\n",
      "83 Train Loss 1.5064911 Test RE 0.008688683595161279 c 1.0117211 k 1.0008577 m 5.001546\n",
      "84 Train Loss 1.4910604 Test RE 0.008780768999852105 c 1.0096618 k 1.0003816 m 4.9982524\n",
      "85 Train Loss 1.478223 Test RE 0.008909043441134483 c 1.0118777 k 1.0001903 m 4.9871616\n",
      "86 Train Loss 1.4749775 Test RE 0.008874787678040187 c 1.0097139 k 1.0004009 m 4.990594\n",
      "87 Train Loss 1.4548092 Test RE 0.00879271387254091 c 1.0095929 k 0.99997264 m 5.0006514\n",
      "88 Train Loss 1.2863731 Test RE 0.007959070162447788 c 1.0137236 k 0.99932843 m 4.989354\n",
      "89 Train Loss 1.1339946 Test RE 0.006765736626215744 c 1.0091126 k 1.0000063 m 4.9803867\n",
      "90 Train Loss 1.064471 Test RE 0.006515256625071276 c 1.0082927 k 0.9999365 m 5.0058465\n",
      "91 Train Loss 1.0356437 Test RE 0.0068371898162127714 c 1.0042248 k 1.0005608 m 5.0027165\n",
      "92 Train Loss 0.9708518 Test RE 0.006384766732076279 c 1.0009271 k 1.0010138 m 4.991374\n",
      "93 Train Loss 0.91196257 Test RE 0.00594159154343148 c 1.0019506 k 1.0002612 m 5.0092106\n",
      "94 Train Loss 0.86400235 Test RE 0.0061696592484859515 c 1.0095011 k 1.0004494 m 5.0055547\n",
      "95 Train Loss 0.8419473 Test RE 0.006053250125165615 c 1.0063803 k 1.0007217 m 5.0075865\n",
      "96 Train Loss 0.8353586 Test RE 0.00594581004995621 c 1.0041605 k 1.000571 m 5.003893\n",
      "97 Train Loss 0.8292484 Test RE 0.0058821781213303 c 1.006914 k 1.0005536 m 4.984766\n",
      "98 Train Loss 0.827993 Test RE 0.005826905505504993 c 1.0061108 k 1.0004349 m 4.989039\n",
      "99 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "100 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "101 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "102 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "103 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "104 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "105 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "106 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "107 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "108 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "109 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "110 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "111 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "112 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "113 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "114 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "115 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "116 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "117 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "118 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "119 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "120 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "121 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "122 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "123 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "124 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "125 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "126 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "127 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "128 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "129 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "130 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "131 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "132 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "133 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "134 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "135 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "136 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "137 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "138 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "139 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "140 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "141 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "142 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "143 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "144 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "145 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "146 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "147 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "148 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "149 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "150 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "151 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "152 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "153 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "154 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "155 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "156 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "157 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "158 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "159 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "160 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "161 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "162 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "163 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "164 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "165 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "166 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "167 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "168 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "169 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "170 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "171 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "172 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "173 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "174 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "175 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "176 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "177 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "178 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "179 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "180 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "181 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "182 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "183 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "184 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "185 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "186 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "187 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "188 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "189 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "190 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "191 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "192 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "193 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "194 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "195 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "196 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "197 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "198 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "199 Train Loss 0.827485 Test RE 0.005801816979583996 c 1.0064995 k 1.000427 m 4.9904637\n",
      "Training time: 56.48\n",
      "Training time: 56.48\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 2966.0776 Test RE 0.5359642542326952 c -0.08513117 k 2.180388 m -0.0052973526\n",
      "1 Train Loss 486.95654 Test RE 0.21820752687117972 c -0.086077295 k 1.0166155 m -0.0054266183\n",
      "2 Train Loss 486.55585 Test RE 0.21822072092262812 c -0.08613503 k 1.0172032 m -0.0054362295\n",
      "3 Train Loss 483.17996 Test RE 0.21719883610461901 c -0.08442456 k 1.0155118 m -0.00543653\n",
      "4 Train Loss 471.85648 Test RE 0.2128894508667046 c -0.07057342 k 1.0161254 m -0.0054831444\n",
      "5 Train Loss 450.58554 Test RE 0.2003034612379589 c -0.017213454 k 1.010656 m -0.0066499435\n",
      "6 Train Loss 376.44208 Test RE 0.16499183451354277 c 0.124176994 k 1.0076978 m -0.010309156\n",
      "7 Train Loss 357.20306 Test RE 0.16110810586342503 c 0.18727708 k 1.0047557 m -0.0060705487\n",
      "8 Train Loss 324.63498 Test RE 0.1531234387911616 c 0.48481348 k 1.002119 m 0.03604088\n",
      "9 Train Loss 297.18915 Test RE 0.13367626573694089 c 0.7235327 k 0.9970614 m 0.0817273\n",
      "10 Train Loss 256.79526 Test RE 0.1195609012929991 c 1.1940022 k 0.9875125 m 0.20844746\n",
      "11 Train Loss 221.81856 Test RE 0.10531400100013673 c 1.5810728 k 0.97922844 m 0.35548973\n",
      "12 Train Loss 196.65324 Test RE 0.11328963082649329 c 2.1286802 k 0.97413677 m 0.6273608\n",
      "13 Train Loss 171.99216 Test RE 0.10644766963336792 c 2.298049 k 0.97740424 m 0.7399811\n",
      "14 Train Loss 161.05121 Test RE 0.09807355033700708 c 2.2288506 k 0.9709514 m 0.73607224\n",
      "15 Train Loss 150.30646 Test RE 0.09179958721785947 c 2.0365412 k 0.9712984 m 0.7169988\n",
      "16 Train Loss 145.8663 Test RE 0.09035340546875584 c 1.9373363 k 0.975382 m 0.76897895\n",
      "17 Train Loss 140.94223 Test RE 0.08703961349558566 c 1.8454508 k 0.971826 m 0.84085935\n",
      "18 Train Loss 137.42096 Test RE 0.08421870635923552 c 1.7160054 k 0.97555315 m 0.9001676\n",
      "19 Train Loss 131.91013 Test RE 0.08217307151138914 c 1.6122903 k 0.97326124 m 1.0139828\n",
      "20 Train Loss 128.8694 Test RE 0.07877910602997527 c 1.5473125 k 0.971991 m 1.1182685\n",
      "21 Train Loss 126.58917 Test RE 0.07536363301986447 c 1.3652084 k 0.9795906 m 1.2323474\n",
      "22 Train Loss 123.252884 Test RE 0.07262117053229902 c 1.3167495 k 0.96945214 m 1.3563807\n",
      "23 Train Loss 112.98105 Test RE 0.06577258423093542 c 1.4324884 k 0.9640466 m 1.7044687\n",
      "24 Train Loss 103.70375 Test RE 0.057277509012053966 c 1.2626199 k 0.9952592 m 2.0332766\n",
      "25 Train Loss 97.492645 Test RE 0.05644324403395123 c 1.2837793 k 0.9731789 m 2.0625525\n",
      "26 Train Loss 93.400894 Test RE 0.05608162774442584 c 1.266211 k 0.9793021 m 2.1448555\n",
      "27 Train Loss 85.522545 Test RE 0.04906632297527178 c 1.1928293 k 0.98134947 m 2.3410664\n",
      "28 Train Loss 73.34552 Test RE 0.0464697384377668 c 1.0114691 k 0.96923065 m 2.720349\n",
      "29 Train Loss 58.293682 Test RE 0.04408977872327086 c 1.0357702 k 0.98662996 m 3.0816724\n",
      "30 Train Loss 49.120926 Test RE 0.039814920948040254 c 1.0149182 k 0.9826927 m 3.3474636\n",
      "31 Train Loss 40.930595 Test RE 0.036129520917675566 c 1.0585326 k 0.9866872 m 3.4842432\n",
      "32 Train Loss 35.530342 Test RE 0.032428203565997106 c 1.041243 k 0.99171597 m 3.9238243\n",
      "33 Train Loss 25.643482 Test RE 0.032408881346062866 c 0.93094563 k 0.9934618 m 4.261807\n",
      "34 Train Loss 12.722452 Test RE 0.01899250339843388 c 0.92833084 k 0.9979774 m 4.7553782\n",
      "35 Train Loss 8.98196 Test RE 0.016132849752839542 c 0.95658207 k 0.9995374 m 4.9064484\n",
      "36 Train Loss 6.6817894 Test RE 0.01230221023911097 c 1.0164784 k 0.99937147 m 4.9044456\n",
      "37 Train Loss 5.203831 Test RE 0.011488609973236278 c 1.0683216 k 1.0005443 m 4.9484687\n",
      "38 Train Loss 4.1483607 Test RE 0.010346453234813266 c 1.0248986 k 0.99958676 m 4.9470997\n",
      "39 Train Loss 3.4483712 Test RE 0.0073953151351695 c 0.9685856 k 0.99908847 m 4.968555\n",
      "40 Train Loss 2.3875256 Test RE 0.006274334958951274 c 1.0098386 k 0.9995428 m 4.9137645\n",
      "41 Train Loss 1.6416852 Test RE 0.004513695539051254 c 0.99800843 k 0.99962777 m 4.962977\n",
      "42 Train Loss 1.3101647 Test RE 0.0038353999702552093 c 1.0129511 k 0.9996416 m 4.986533\n",
      "43 Train Loss 1.2512138 Test RE 0.003953912714943138 c 1.0153705 k 1.0003388 m 5.0044637\n",
      "44 Train Loss 1.131658 Test RE 0.004235522157575378 c 1.013877 k 1.0001117 m 5.0031037\n",
      "45 Train Loss 1.0586953 Test RE 0.003891523849048357 c 1.0256346 k 0.9997596 m 4.985299\n",
      "46 Train Loss 0.9799108 Test RE 0.0035299239975780405 c 1.0145023 k 1.0003072 m 4.9930406\n",
      "47 Train Loss 0.90180874 Test RE 0.0031389897419642223 c 0.9945954 k 1.0002339 m 5.012558\n",
      "48 Train Loss 0.87373513 Test RE 0.0031703398681000128 c 1.000882 k 1.0002443 m 5.013\n",
      "49 Train Loss 0.7710824 Test RE 0.00330520033424262 c 1.0083662 k 1.0002477 m 5.0159464\n",
      "50 Train Loss 0.7056802 Test RE 0.003168286044716587 c 0.9988184 k 0.9996939 m 4.996236\n",
      "51 Train Loss 0.63755846 Test RE 0.002989409965894619 c 1.0111085 k 1.0000639 m 4.9893622\n",
      "52 Train Loss 0.59665143 Test RE 0.0028130786438001487 c 1.0017785 k 1.0002134 m 5.0156097\n",
      "53 Train Loss 0.572466 Test RE 0.0027155623930504515 c 0.9986561 k 1.0002804 m 5.006432\n",
      "54 Train Loss 0.5476106 Test RE 0.002715940688527312 c 1.0043418 k 1.0000919 m 4.999494\n",
      "55 Train Loss 0.5107155 Test RE 0.002739884996651355 c 1.0031089 k 1.0003488 m 5.0128646\n",
      "56 Train Loss 0.45971113 Test RE 0.0029337881806212746 c 1.000027 k 1.0003605 m 5.028452\n",
      "57 Train Loss 0.43684298 Test RE 0.0030101542353355277 c 1.0019214 k 1.0003669 m 5.012061\n",
      "58 Train Loss 0.3938663 Test RE 0.003069826502040953 c 1.0079517 k 0.99983853 m 4.9812374\n",
      "59 Train Loss 0.3641196 Test RE 0.002980124686698291 c 1.0029819 k 0.999736 m 4.961814\n",
      "60 Train Loss 0.32467645 Test RE 0.0028436669608118944 c 1.0003132 k 0.99948883 m 4.9501834\n",
      "61 Train Loss 0.27131063 Test RE 0.002749134502100817 c 1.0012715 k 0.9998788 m 4.9896693\n",
      "62 Train Loss 0.25951833 Test RE 0.002671520665220441 c 1.0045245 k 0.99983317 m 4.9926066\n",
      "63 Train Loss 0.24838853 Test RE 0.0026029124881472585 c 1.0038056 k 0.99996644 m 4.9891562\n",
      "64 Train Loss 0.24063355 Test RE 0.0026215315121261747 c 1.0039686 k 0.99986446 m 4.9978886\n",
      "65 Train Loss 0.22777118 Test RE 0.0025609754652645535 c 1.0042243 k 0.9998952 m 4.992529\n",
      "66 Train Loss 0.22298473 Test RE 0.002535184817340262 c 1.0027808 k 1.0000895 m 4.9921775\n",
      "67 Train Loss 0.21460238 Test RE 0.002559157485372351 c 1.0005453 k 0.9999143 m 4.9981513\n",
      "68 Train Loss 0.2069825 Test RE 0.0025787144097675946 c 1.0017648 k 1.0001137 m 4.996465\n",
      "69 Train Loss 0.19744274 Test RE 0.002491519614077788 c 1.0025084 k 1.0000057 m 4.993837\n",
      "70 Train Loss 0.19310322 Test RE 0.002448881404556205 c 1.0005178 k 1.0000393 m 4.9999213\n",
      "71 Train Loss 0.18296054 Test RE 0.0023850845867037012 c 1.0021049 k 1.0000613 m 4.994293\n",
      "72 Train Loss 0.17932847 Test RE 0.0023094220855035927 c 1.0021755 k 1.0000074 m 4.9955926\n",
      "73 Train Loss 0.17312774 Test RE 0.002210815892264117 c 0.9974317 k 1.00027 m 5.0082808\n",
      "74 Train Loss 0.15439928 Test RE 0.0019392429904727137 c 0.9943819 k 1.0003209 m 5.0072107\n",
      "75 Train Loss 0.14290546 Test RE 0.0018140035305042016 c 0.99983525 k 1.000128 m 5.0004067\n",
      "76 Train Loss 0.14204271 Test RE 0.0018213476702732964 c 1.0005126 k 1.0002874 m 5.0041127\n",
      "77 Train Loss 0.14114581 Test RE 0.0018104125145464445 c 1.0010052 k 1.0003011 m 5.0055857\n",
      "78 Train Loss 0.1381465 Test RE 0.001798661242611729 c 1.0000547 k 1.0002054 m 4.998713\n",
      "79 Train Loss 0.1364368 Test RE 0.0017718009473129835 c 0.99944335 k 1.0002489 m 4.9949055\n",
      "80 Train Loss 0.13171345 Test RE 0.0017812973974747355 c 1.0011276 k 1.0002091 m 4.993896\n",
      "81 Train Loss 0.12455273 Test RE 0.0018302273643761842 c 0.99993813 k 1.000178 m 4.9914927\n",
      "82 Train Loss 0.11803244 Test RE 0.0018294923549643104 c 0.99979645 k 1.0001597 m 4.9925356\n",
      "83 Train Loss 0.11636908 Test RE 0.0018545029402315947 c 1.001621 k 1.0001849 m 4.994987\n",
      "84 Train Loss 0.115504526 Test RE 0.0018720877899017707 c 1.0017095 k 1.0002065 m 4.997632\n",
      "85 Train Loss 0.114777535 Test RE 0.0018711586573183156 c 1.0024812 k 1.0001706 m 4.997463\n",
      "86 Train Loss 0.11339444 Test RE 0.0019084682981313245 c 1.0041592 k 1.000221 m 4.9945307\n",
      "87 Train Loss 0.108497605 Test RE 0.0019144637175693637 c 1.0031483 k 1.000232 m 4.997772\n",
      "88 Train Loss 0.09676912 Test RE 0.0018053395966668682 c 1.0002096 k 1.0002701 m 5.0046225\n",
      "89 Train Loss 0.091911614 Test RE 0.0018655759176414782 c 0.9994626 k 1.0003695 m 5.007259\n",
      "90 Train Loss 0.09018351 Test RE 0.001883904076804793 c 1.0003521 k 1.0002555 m 5.004794\n",
      "91 Train Loss 0.08978213 Test RE 0.0018638021596959766 c 0.99925905 k 1.000293 m 5.0034213\n",
      "92 Train Loss 0.088443674 Test RE 0.001845575455213527 c 0.9993833 k 1.0003142 m 5.004769\n",
      "93 Train Loss 0.08569651 Test RE 0.0018093183293084606 c 1.002441 k 1.0002816 m 5.003504\n",
      "94 Train Loss 0.082469374 Test RE 0.0017922733730045303 c 1.0004715 k 1.0003037 m 5.0000167\n",
      "95 Train Loss 0.0806195 Test RE 0.0017801382394479343 c 1.000029 k 1.0003098 m 5.0024385\n",
      "96 Train Loss 0.078948036 Test RE 0.0017658440967495686 c 1.0009433 k 1.0002841 m 5.003686\n",
      "97 Train Loss 0.078077495 Test RE 0.0017505706085221278 c 0.9991188 k 1.0003055 m 5.0019717\n",
      "98 Train Loss 0.07740825 Test RE 0.0017442502165827749 c 0.99950284 k 1.000294 m 5.0030327\n",
      "99 Train Loss 0.07709675 Test RE 0.0017478016472067214 c 1.0005993 k 1.0002844 m 5.002577\n",
      "100 Train Loss 0.07618832 Test RE 0.001752205304309078 c 1.0014608 k 1.0002773 m 4.9996543\n",
      "101 Train Loss 0.07439754 Test RE 0.0017490639429800234 c 1.0002187 k 1.0002488 m 4.999978\n",
      "102 Train Loss 0.07189986 Test RE 0.0017760600582761765 c 0.9999088 k 1.0002377 m 5.0006595\n",
      "103 Train Loss 0.06798991 Test RE 0.0017512598678941747 c 1.0007817 k 1.0002639 m 4.9988604\n",
      "104 Train Loss 0.065891474 Test RE 0.001715178164808224 c 1.0007802 k 1.000241 m 4.999895\n",
      "105 Train Loss 0.064982936 Test RE 0.0017212716184078396 c 1.0005388 k 1.0002564 m 5.0002937\n",
      "106 Train Loss 0.06474274 Test RE 0.0017143336298733004 c 1.0004262 k 1.0002462 m 5.0004764\n",
      "107 Train Loss 0.0645444 Test RE 0.0017021379534238926 c 1.0007092 k 1.0002521 m 5.000322\n",
      "108 Train Loss 0.06389518 Test RE 0.0016867392192412873 c 0.999879 k 1.0002726 m 5.0028687\n",
      "109 Train Loss 0.06365408 Test RE 0.001682159927446599 c 0.9993496 k 1.000308 m 5.0037055\n",
      "110 Train Loss 0.06282848 Test RE 0.0016602344919630918 c 0.998743 k 1.0002593 m 5.0008283\n",
      "111 Train Loss 0.059625793 Test RE 0.0015926500271740557 c 0.99924374 k 1.0001012 m 4.9991183\n",
      "112 Train Loss 0.055783223 Test RE 0.0015335225355849887 c 1.0014259 k 1.0003194 m 5.00099\n",
      "113 Train Loss 0.054985736 Test RE 0.0015104206900489428 c 1.0003872 k 1.000209 m 5.000468\n",
      "114 Train Loss 0.054819845 Test RE 0.0015016831608517629 c 0.9998406 k 1.0002056 m 5.0001135\n",
      "115 Train Loss 0.054731455 Test RE 0.0014912912733011637 c 1.0001599 k 1.0002556 m 5.0000496\n",
      "116 Train Loss 0.054592725 Test RE 0.0014812856980086263 c 1.0000998 k 1.0002213 m 5.0010257\n",
      "117 Train Loss 0.054461326 Test RE 0.0014896749839099607 c 0.9996646 k 1.0002152 m 5.0013466\n",
      "118 Train Loss 0.054311223 Test RE 0.0014966342472465962 c 1.0000029 k 1.0002428 m 5.001398\n",
      "119 Train Loss 0.054059245 Test RE 0.0015133863021651577 c 0.9998785 k 1.0001787 m 5.0022306\n",
      "120 Train Loss 0.053177588 Test RE 0.0014978600124774478 c 0.99930924 k 1.0002062 m 5.003228\n",
      "121 Train Loss 0.0515936 Test RE 0.0014645694122065933 c 0.99951315 k 1.0003021 m 5.000902\n",
      "122 Train Loss 0.05038321 Test RE 0.001480558014507389 c 1.0000792 k 1.0001606 m 5.0013657\n",
      "123 Train Loss 0.049803138 Test RE 0.0014618407984910093 c 1.0005126 k 1.000202 m 5.0023127\n",
      "124 Train Loss 0.049395286 Test RE 0.0014338133876143503 c 1.0005724 k 1.0001793 m 5.0003114\n",
      "125 Train Loss 0.049115278 Test RE 0.0014478534452395373 c 0.99994475 k 1.0001872 m 4.999619\n",
      "126 Train Loss 0.048229665 Test RE 0.0014553300168540996 c 1.0007603 k 1.0002314 m 5.0008354\n",
      "127 Train Loss 0.04627829 Test RE 0.0014290833849446268 c 1.0020593 k 1.0000381 m 4.997233\n",
      "128 Train Loss 0.044975195 Test RE 0.0014230830536294914 c 1.0009142 k 1.0001429 m 4.9957013\n",
      "129 Train Loss 0.04449907 Test RE 0.0013932766198789847 c 1.00055 k 1.0001153 m 4.9969916\n",
      "130 Train Loss 0.044113703 Test RE 0.0013928359927462865 c 1.0008819 k 1.0001097 m 4.9983635\n",
      "131 Train Loss 0.043785144 Test RE 0.0013910349185067398 c 1.000859 k 1.0001696 m 4.9996085\n",
      "132 Train Loss 0.04338251 Test RE 0.0013733789103825438 c 1.0004537 k 1.0001476 m 5.00011\n",
      "133 Train Loss 0.043141007 Test RE 0.0013899102217001431 c 1.0005219 k 1.0001245 m 4.998274\n",
      "134 Train Loss 0.042876005 Test RE 0.00138393731178182 c 1.000912 k 1.0001208 m 4.996239\n",
      "135 Train Loss 0.042523015 Test RE 0.0013412060388361883 c 1.001531 k 1.0000632 m 4.99609\n",
      "136 Train Loss 0.041640252 Test RE 0.0012775117236591541 c 1.0012789 k 1.0000688 m 4.993711\n",
      "137 Train Loss 0.04066959 Test RE 0.001274370455899965 c 1.0014199 k 1.0001017 m 4.9917336\n",
      "138 Train Loss 0.039498977 Test RE 0.0012578649339797018 c 1.0024934 k 0.99997073 m 4.9928107\n",
      "139 Train Loss 0.038520355 Test RE 0.0011916087547420517 c 1.001576 k 1.0000781 m 4.994408\n",
      "140 Train Loss 0.037556008 Test RE 0.0011903560328452975 c 1.00102 k 1.0001945 m 4.99483\n",
      "141 Train Loss 0.035077985 Test RE 0.0011034944415331956 c 0.99918556 k 0.9999696 m 4.996034\n",
      "142 Train Loss 0.033380486 Test RE 0.0010413913970263855 c 0.9996327 k 1.0001279 m 4.998334\n",
      "143 Train Loss 0.03259982 Test RE 0.0010386801526808234 c 0.9998445 k 1.0000945 m 5.0002084\n",
      "144 Train Loss 0.031950913 Test RE 0.001036946553170521 c 0.9996796 k 1.0001159 m 5.001815\n",
      "145 Train Loss 0.031566788 Test RE 0.001035109361634901 c 1.0008321 k 1.0002242 m 5.0025287\n",
      "146 Train Loss 0.030801255 Test RE 0.001053141968272012 c 1.0011798 k 1.0000889 m 5.0020857\n",
      "147 Train Loss 0.030300207 Test RE 0.0010615290519761203 c 1.0008903 k 1.000091 m 5.001391\n",
      "148 Train Loss 0.02984687 Test RE 0.0010753731557547278 c 1.0020162 k 1.000155 m 4.999295\n",
      "149 Train Loss 0.029008282 Test RE 0.001073883145929715 c 1.001251 k 0.9999938 m 4.9977903\n",
      "150 Train Loss 0.027814236 Test RE 0.0010471754474675736 c 0.9995567 k 1.000028 m 5.0011744\n",
      "151 Train Loss 0.026383413 Test RE 0.0010285338525493554 c 1.0002102 k 1.000133 m 5.0004826\n",
      "152 Train Loss 0.025591306 Test RE 0.001026759420379693 c 0.9997821 k 1.0000219 m 4.998653\n",
      "153 Train Loss 0.023603965 Test RE 0.0009677550075381414 c 0.9992132 k 1.0000678 m 4.996814\n",
      "154 Train Loss 0.022358779 Test RE 0.000882251510754296 c 1.0006363 k 1.0000244 m 4.9957767\n",
      "155 Train Loss 0.021531545 Test RE 0.0008745023949773199 c 1.0006942 k 1.0000296 m 4.9983964\n",
      "156 Train Loss 0.021276306 Test RE 0.0008692318670756577 c 1.0001833 k 1.000028 m 5.000576\n",
      "157 Train Loss 0.021078553 Test RE 0.0008640829823218061 c 0.99978447 k 1.0000472 m 5.000931\n",
      "158 Train Loss 0.020905813 Test RE 0.0008724493523298869 c 0.99981564 k 1.0000448 m 5.000661\n",
      "159 Train Loss 0.020521203 Test RE 0.0008529346595523843 c 1.0005548 k 0.9999996 m 5.0013328\n",
      "160 Train Loss 0.020204235 Test RE 0.0008227869826038174 c 1.0008854 k 1.0000405 m 5.00238\n",
      "161 Train Loss 0.019889839 Test RE 0.0008126150103783821 c 1.0004681 k 1.000059 m 5.0009656\n",
      "162 Train Loss 0.019711565 Test RE 0.0007993467627295823 c 1.0004671 k 1.0000337 m 5.000127\n",
      "163 Train Loss 0.01953099 Test RE 0.0007795652407100052 c 1.0005757 k 1.000033 m 5.0002403\n",
      "164 Train Loss 0.019248528 Test RE 0.000758211965939811 c 1.0005529 k 1.0000395 m 4.9994235\n",
      "165 Train Loss 0.018689306 Test RE 0.0007024395915524888 c 1.0007744 k 0.9999831 m 4.9994903\n",
      "166 Train Loss 0.01835117 Test RE 0.0006758882084214577 c 1.0005114 k 0.9999986 m 5.000783\n",
      "167 Train Loss 0.018016811 Test RE 0.0006868099172989779 c 1.0008036 k 0.9999869 m 5.002769\n",
      "168 Train Loss 0.017372616 Test RE 0.0007063506900539524 c 1.001125 k 1.0000736 m 5.0019283\n",
      "169 Train Loss 0.016776 Test RE 0.0006878903006211267 c 1.0001664 k 1.000026 m 5.000231\n",
      "170 Train Loss 0.016606007 Test RE 0.0006879453793132713 c 0.9996454 k 0.99999636 m 5.0009575\n",
      "171 Train Loss 0.016367547 Test RE 0.0006863236750679735 c 0.99952334 k 1.0000117 m 5.001358\n",
      "172 Train Loss 0.016274028 Test RE 0.000671192370519511 c 0.99996924 k 1.000013 m 5.0015073\n",
      "173 Train Loss 0.01617908 Test RE 0.0006689562292047627 c 1.0002738 k 1.0000206 m 5.001921\n",
      "174 Train Loss 0.015982658 Test RE 0.0006537393337910409 c 1.0003972 k 1.000011 m 5.0007615\n",
      "175 Train Loss 0.01590931 Test RE 0.0006387362245358001 c 1.000201 k 0.99998105 m 4.9994845\n",
      "176 Train Loss 0.015849784 Test RE 0.000638455147914741 c 1.0000097 k 0.99997693 m 4.9993777\n",
      "177 Train Loss 0.015807997 Test RE 0.0006388036038188344 c 1.0001502 k 0.9999951 m 4.9993896\n",
      "178 Train Loss 0.015730646 Test RE 0.0006268439645746702 c 1.000211 k 0.99997675 m 4.999584\n",
      "179 Train Loss 0.01561292 Test RE 0.0006340023138806569 c 1.0000243 k 1.0000029 m 5.0000834\n",
      "180 Train Loss 0.015521396 Test RE 0.0006417304136892803 c 0.99991935 k 0.9999866 m 4.999424\n",
      "181 Train Loss 0.015449762 Test RE 0.0006452300058775252 c 0.999649 k 0.99997526 m 4.9989166\n",
      "182 Train Loss 0.01530875 Test RE 0.000652755022014852 c 0.999556 k 0.9999855 m 4.9984217\n",
      "183 Train Loss 0.015101418 Test RE 0.0006514913210570659 c 0.9999043 k 0.9999366 m 4.9980803\n",
      "184 Train Loss 0.014878254 Test RE 0.0006460716540901212 c 0.99976295 k 0.9999854 m 4.998012\n",
      "185 Train Loss 0.01468891 Test RE 0.0006377926819214348 c 0.9994582 k 0.9999997 m 4.9992604\n",
      "186 Train Loss 0.01456015 Test RE 0.0006247049991803873 c 0.99915785 k 0.99995196 m 5.0000973\n",
      "187 Train Loss 0.014483576 Test RE 0.0006244093915120777 c 0.9992319 k 0.99999696 m 5.0007086\n",
      "188 Train Loss 0.014392997 Test RE 0.0006193933973548216 c 0.9999137 k 0.99998784 m 5.000079\n",
      "189 Train Loss 0.014323435 Test RE 0.0006180130118436507 c 1.0003211 k 0.99997455 m 4.9998875\n",
      "190 Train Loss 0.014299153 Test RE 0.0006240331855708676 c 1.0002635 k 0.99997246 m 4.9995623\n",
      "191 Train Loss 0.014274595 Test RE 0.0006300871399277932 c 1.0002416 k 0.9999743 m 4.998986\n",
      "192 Train Loss 0.014216868 Test RE 0.0006335008699089427 c 1.0003556 k 0.99997497 m 4.9995713\n",
      "193 Train Loss 0.014174163 Test RE 0.000635685301631961 c 1.000268 k 0.9999731 m 5.000279\n",
      "194 Train Loss 0.0141261 Test RE 0.000635494318002474 c 1.0000095 k 0.9999973 m 5.0001497\n",
      "195 Train Loss 0.01411788 Test RE 0.0006342261920780552 c 1.0000337 k 0.999998 m 5.0001884\n",
      "196 Train Loss 0.014110459 Test RE 0.000633464640187423 c 1.0000471 k 0.9999953 m 5.000408\n",
      "197 Train Loss 0.01410502 Test RE 0.0006335349571920287 c 1.0000635 k 0.99999034 m 5.000586\n",
      "198 Train Loss 0.014097605 Test RE 0.0006344889248017724 c 1.0000836 k 0.9999853 m 5.000698\n",
      "199 Train Loss 0.014094252 Test RE 0.0006349451208819245 c 1.0000961 k 0.9999854 m 5.0006595\n",
      "Training time: 68.46\n",
      "Training time: 68.46\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 623.89716 Test RE 0.24175521495638624 c 0.01730347 k 0.88304603 m -0.0014089189\n",
      "1 Train Loss 495.929 Test RE 0.21889077875094443 c 0.016296938 k 1.0107776 m -0.0013018036\n",
      "2 Train Loss 490.80496 Test RE 0.21924378138152284 c 0.01641645 k 1.0178812 m -0.0012784912\n",
      "3 Train Loss 488.83362 Test RE 0.2189503195113763 c 0.017336905 k 1.0151583 m -0.0012623146\n",
      "4 Train Loss 486.63397 Test RE 0.21795109456270978 c 0.021339351 k 1.0200975 m -0.0012662353\n",
      "5 Train Loss 476.36276 Test RE 0.21549575535706866 c 0.03148018 k 1.005122 m -0.0012502727\n",
      "6 Train Loss 441.01434 Test RE 0.19915164303214627 c 0.0602149 k 1.0298048 m -0.0013768541\n",
      "7 Train Loss 417.16248 Test RE 0.19056237906440215 c 0.08881197 k 1.0151864 m -0.0019516515\n",
      "8 Train Loss 353.50427 Test RE 0.15341639531997078 c 0.19844532 k 1.002487 m -0.0028967753\n",
      "9 Train Loss 281.258 Test RE 0.11670876034210609 c 0.33282256 k 0.988821 m 0.0023265718\n",
      "10 Train Loss 255.83624 Test RE 0.11916583005740422 c 0.46168438 k 0.9920414 m 0.08217332\n",
      "11 Train Loss 233.0084 Test RE 0.11553230657530941 c 0.6950606 k 0.98603225 m 0.23352686\n",
      "12 Train Loss 206.39008 Test RE 0.10444118731649968 c 1.0134811 k 0.98463523 m 0.4474741\n",
      "13 Train Loss 197.98175 Test RE 0.09497898610935422 c 1.1379505 k 0.9701299 m 0.55245286\n",
      "14 Train Loss 192.9166 Test RE 0.09856426149793583 c 1.2090545 k 0.9820643 m 0.6317802\n",
      "15 Train Loss 184.08354 Test RE 0.09700876571145818 c 1.3408748 k 0.98898834 m 0.79445404\n",
      "16 Train Loss 168.2539 Test RE 0.09037740429186533 c 1.5741136 k 0.97336775 m 1.0398608\n",
      "17 Train Loss 155.99007 Test RE 0.09335731238051985 c 1.773977 k 0.9784585 m 1.2997882\n",
      "18 Train Loss 147.71523 Test RE 0.09290799964893619 c 1.9032756 k 0.973268 m 1.4696656\n",
      "19 Train Loss 142.4467 Test RE 0.0901895370778457 c 1.8060921 k 0.9811825 m 1.3848747\n",
      "20 Train Loss 137.28113 Test RE 0.08912996198297492 c 1.6385232 k 0.97407645 m 1.2378886\n",
      "21 Train Loss 133.54851 Test RE 0.09469154047579072 c 1.6400391 k 0.973193 m 1.2996254\n",
      "22 Train Loss 129.66997 Test RE 0.0910752671262595 c 1.7144407 k 0.9800346 m 1.3791203\n",
      "23 Train Loss 120.945755 Test RE 0.08325318888322983 c 1.8389992 k 0.9823474 m 1.5425872\n",
      "24 Train Loss 117.452965 Test RE 0.08211960164259961 c 1.8310338 k 0.96803045 m 1.5702899\n",
      "25 Train Loss 111.91168 Test RE 0.07884002867800718 c 1.7868956 k 0.9691082 m 1.6230202\n",
      "26 Train Loss 106.7518 Test RE 0.0795679428417373 c 1.8352596 k 0.9770462 m 1.6608135\n",
      "27 Train Loss 105.24179 Test RE 0.08004316562917524 c 1.873149 k 0.97082084 m 1.7441185\n",
      "28 Train Loss 103.36191 Test RE 0.07980778901409429 c 1.9421625 k 0.97761685 m 1.9496931\n",
      "29 Train Loss 98.63441 Test RE 0.07669246515969196 c 2.0423992 k 0.98311734 m 2.2162766\n",
      "30 Train Loss 94.66112 Test RE 0.0743115336509841 c 2.024522 k 0.9678262 m 2.3091247\n",
      "31 Train Loss 88.74002 Test RE 0.0730003135573988 c 2.0071805 k 0.97608113 m 2.6016848\n",
      "32 Train Loss 76.98426 Test RE 0.06731392081357626 c 1.9872527 k 0.9949012 m 3.034437\n",
      "33 Train Loss 67.93173 Test RE 0.05994004995128111 c 1.9579724 k 0.9802368 m 3.3765507\n",
      "34 Train Loss 60.072212 Test RE 0.05320324694416478 c 1.7966037 k 0.98692006 m 3.4069543\n",
      "35 Train Loss 55.80867 Test RE 0.0551882268288519 c 1.7481608 k 0.98631734 m 3.4300745\n",
      "36 Train Loss 47.449883 Test RE 0.05178615093616761 c 1.6217743 k 0.98202026 m 3.6162844\n",
      "37 Train Loss 43.969414 Test RE 0.05243018425912762 c 1.6006724 k 0.99008465 m 3.5818174\n",
      "38 Train Loss 38.00548 Test RE 0.04752687629617114 c 1.3950021 k 0.9875813 m 3.6270432\n",
      "39 Train Loss 33.62328 Test RE 0.04541359423864467 c 1.1978315 k 0.98455596 m 3.7296307\n",
      "40 Train Loss 27.636639 Test RE 0.04136506473433384 c 1.1622815 k 0.9905057 m 3.9493449\n",
      "41 Train Loss 25.533726 Test RE 0.039449574165775776 c 1.1264515 k 0.99516636 m 4.15996\n",
      "42 Train Loss 22.176666 Test RE 0.03577933766800605 c 1.1615363 k 0.9904463 m 4.417574\n",
      "43 Train Loss 20.26456 Test RE 0.035491620415715096 c 1.1069756 k 0.99345016 m 4.5763965\n",
      "44 Train Loss 19.735039 Test RE 0.03564188070387088 c 1.1347924 k 0.99739337 m 4.5813985\n",
      "45 Train Loss 18.828796 Test RE 0.035633682078364405 c 1.1612542 k 0.995869 m 4.6203747\n",
      "46 Train Loss 17.485275 Test RE 0.03444590316749623 c 1.1252356 k 0.99519527 m 4.793834\n",
      "47 Train Loss 16.825329 Test RE 0.03293389666934761 c 1.1393429 k 0.9991245 m 4.933886\n",
      "48 Train Loss 16.37564 Test RE 0.03292058809198858 c 1.148801 k 0.9984722 m 4.979461\n",
      "49 Train Loss 14.940361 Test RE 0.03145249150267813 c 1.0859041 k 0.99734026 m 4.8681846\n",
      "50 Train Loss 14.655823 Test RE 0.030622524474875876 c 1.0747281 k 0.9988325 m 4.849281\n",
      "51 Train Loss 14.495812 Test RE 0.030312305572193065 c 1.0917313 k 0.99766576 m 4.8723054\n",
      "52 Train Loss 13.749223 Test RE 0.02962390464575405 c 1.0781859 k 0.9977914 m 4.877717\n",
      "53 Train Loss 13.256945 Test RE 0.029702487705026835 c 1.0874915 k 0.99765027 m 4.768432\n",
      "54 Train Loss 12.991477 Test RE 0.02889944578681401 c 1.064835 k 0.997347 m 4.7324905\n",
      "55 Train Loss 11.451512 Test RE 0.025863147004908008 c 1.0339683 k 0.9984302 m 4.840832\n",
      "56 Train Loss 8.659576 Test RE 0.021260876357559536 c 1.0485452 k 0.9994107 m 5.0408764\n",
      "57 Train Loss 7.7137136 Test RE 0.019769433578680197 c 1.0814452 k 1.0004977 m 5.0325494\n",
      "58 Train Loss 7.2256193 Test RE 0.01960383428878484 c 1.1011084 k 0.9994113 m 4.9848027\n",
      "59 Train Loss 6.695939 Test RE 0.017682548598522155 c 1.0851251 k 0.99940735 m 5.013276\n",
      "60 Train Loss 6.440618 Test RE 0.01674631292378214 c 1.0588415 k 1.0002952 m 4.993139\n",
      "61 Train Loss 5.7311363 Test RE 0.014008266825572291 c 0.9945442 k 1.0006938 m 4.807356\n",
      "62 Train Loss 4.8772345 Test RE 0.012910123137674064 c 1.0106452 k 0.9988486 m 4.778267\n",
      "63 Train Loss 4.741086 Test RE 0.012966606208680571 c 1.0259813 k 0.99716896 m 4.783612\n",
      "64 Train Loss 3.9739056 Test RE 0.0122384432933987 c 1.0370957 k 0.9983067 m 4.874563\n",
      "65 Train Loss 2.8628411 Test RE 0.0099173708770061 c 1.0336126 k 0.9990812 m 5.007637\n",
      "66 Train Loss 2.3498042 Test RE 0.008684370049556507 c 0.9913038 k 1.0003213 m 5.02777\n",
      "67 Train Loss 2.070456 Test RE 0.008019816820027023 c 1.0223469 k 0.99903923 m 4.994166\n",
      "68 Train Loss 1.8275115 Test RE 0.008140114146483564 c 1.0241796 k 0.9993884 m 4.914305\n",
      "69 Train Loss 1.7041216 Test RE 0.007914389050397465 c 1.02354 k 0.9991505 m 4.8870335\n",
      "70 Train Loss 1.6632885 Test RE 0.00788794912659286 c 1.0301963 k 0.9988032 m 4.8969245\n",
      "71 Train Loss 1.5878322 Test RE 0.007843856345431345 c 1.0158149 k 0.99925804 m 4.915521\n",
      "72 Train Loss 1.5224755 Test RE 0.007557644646837324 c 1.0129919 k 0.99808323 m 4.913537\n",
      "73 Train Loss 1.4639146 Test RE 0.007373410225103822 c 1.0243983 k 0.9980546 m 4.9384713\n",
      "74 Train Loss 1.3984461 Test RE 0.007157332804146307 c 1.0255374 k 1.0005649 m 4.9553523\n",
      "75 Train Loss 1.3418909 Test RE 0.006998132984929016 c 1.0207546 k 1.0013243 m 4.9689093\n",
      "76 Train Loss 1.2570273 Test RE 0.006901422838228215 c 1.0153128 k 1.0002443 m 5.0037\n",
      "77 Train Loss 1.1727543 Test RE 0.0065786051393821625 c 1.0015469 k 0.9997858 m 5.0074325\n",
      "78 Train Loss 1.1179948 Test RE 0.006685672239101379 c 1.0074885 k 1.0001103 m 4.96263\n",
      "79 Train Loss 1.1044207 Test RE 0.006586720021794943 c 1.0103108 k 0.99992585 m 4.954328\n",
      "80 Train Loss 1.0835391 Test RE 0.006384889254134563 c 1.0025562 k 0.99974376 m 4.950639\n",
      "81 Train Loss 1.0343866 Test RE 0.006056529545677992 c 1.0018843 k 0.9998343 m 4.9560223\n",
      "82 Train Loss 1.0130646 Test RE 0.00590799014527814 c 1.0046003 k 0.99974555 m 4.9723225\n",
      "83 Train Loss 0.985589 Test RE 0.005838711619461195 c 1.0040514 k 0.9999724 m 4.9809966\n",
      "84 Train Loss 0.98014194 Test RE 0.005873829242861917 c 1.0038611 k 1.0001936 m 4.978888\n",
      "85 Train Loss 0.9717188 Test RE 0.005767471511831823 c 1.0007349 k 1.0003251 m 4.9919915\n",
      "86 Train Loss 0.96610487 Test RE 0.005721260943040679 c 0.99817294 k 1.0005764 m 4.9947233\n",
      "87 Train Loss 0.9399884 Test RE 0.005619002835738705 c 1.0031047 k 1.0011466 m 4.9853725\n",
      "88 Train Loss 0.91263753 Test RE 0.005589020374764903 c 1.00757 k 1.000376 m 4.981117\n",
      "89 Train Loss 0.8986912 Test RE 0.0056012046256327845 c 1.0062416 k 1.0004147 m 4.9924407\n",
      "90 Train Loss 0.8515214 Test RE 0.0052602349635851075 c 1.0112065 k 1.0017081 m 5.00815\n",
      "91 Train Loss 0.7618241 Test RE 0.0050167810565335804 c 1.0095291 k 1.000233 m 4.973392\n",
      "92 Train Loss 0.7190745 Test RE 0.0050939880857035335 c 1.0046887 k 0.9994629 m 4.9721646\n",
      "93 Train Loss 0.67973876 Test RE 0.004959443880902113 c 1.0139285 k 1.000802 m 4.9751444\n",
      "94 Train Loss 0.6036272 Test RE 0.004733983921566072 c 1.0093683 k 1.001273 m 4.9798017\n",
      "95 Train Loss 0.53916615 Test RE 0.004500555625690747 c 0.9962227 k 1.000173 m 4.9862905\n",
      "96 Train Loss 0.4745924 Test RE 0.004327260086725879 c 1.0038427 k 1.0010259 m 4.989243\n",
      "97 Train Loss 0.4278249 Test RE 0.003841918461392699 c 1.0003322 k 1.0000995 m 4.979154\n",
      "98 Train Loss 0.41943616 Test RE 0.0037966209865157464 c 1.0031135 k 0.99972683 m 4.981161\n",
      "99 Train Loss 0.40486616 Test RE 0.0037584827327210796 c 1.0085713 k 0.999459 m 4.9813495\n",
      "100 Train Loss 0.39817038 Test RE 0.00371655668589263 c 1.0048182 k 0.9997922 m 4.9793544\n",
      "101 Train Loss 0.39486444 Test RE 0.0037304214714815255 c 1.0043805 k 0.9998044 m 4.9862604\n",
      "102 Train Loss 0.39258394 Test RE 0.003737630683230389 c 1.0048094 k 0.99989516 m 4.9939995\n",
      "103 Train Loss 0.3899362 Test RE 0.003719480362509151 c 1.0033195 k 1.0000478 m 4.9957685\n",
      "104 Train Loss 0.38020414 Test RE 0.0038032804531487603 c 1.0007434 k 1.000045 m 4.9888687\n",
      "105 Train Loss 0.3683933 Test RE 0.00380089621746102 c 1.0060843 k 0.9998888 m 4.978951\n",
      "106 Train Loss 0.35519177 Test RE 0.003831130432997192 c 1.0059364 k 0.99955636 m 4.9760795\n",
      "107 Train Loss 0.3508973 Test RE 0.003851394296833221 c 1.0048168 k 0.9995142 m 4.982956\n",
      "108 Train Loss 0.34193498 Test RE 0.003896860004562363 c 1.0045973 k 0.99972785 m 4.9923906\n",
      "109 Train Loss 0.32232136 Test RE 0.003787075462953326 c 1.0037978 k 1.0001085 m 4.999582\n",
      "110 Train Loss 0.3119742 Test RE 0.0037192687346024 c 1.0024892 k 0.9998101 m 5.0006638\n",
      "111 Train Loss 0.3019095 Test RE 0.0036309027473142093 c 0.99815524 k 0.9997012 m 4.9973025\n",
      "112 Train Loss 0.29366562 Test RE 0.003625586011837143 c 1.0006157 k 0.9996525 m 4.97951\n",
      "113 Train Loss 0.29000312 Test RE 0.00363140599919014 c 1.004804 k 0.99972296 m 4.9771185\n",
      "114 Train Loss 0.28262725 Test RE 0.0035889003299711996 c 1.0018338 k 1.0000141 m 4.9884424\n",
      "115 Train Loss 0.27212623 Test RE 0.0035995269773700027 c 1.0008296 k 0.99941486 m 4.986193\n",
      "116 Train Loss 0.26235205 Test RE 0.003640897323968782 c 1.0020986 k 0.9996049 m 4.9860954\n",
      "117 Train Loss 0.25925112 Test RE 0.003632874564771204 c 1.0018151 k 0.9999864 m 4.994095\n",
      "118 Train Loss 0.25621003 Test RE 0.0035814786920259174 c 1.002943 k 0.9998519 m 4.994579\n",
      "119 Train Loss 0.25325742 Test RE 0.00349145821502496 c 1.0029298 k 0.99999297 m 4.997717\n",
      "120 Train Loss 0.25172642 Test RE 0.0034483943870591586 c 1.0029023 k 1.0001136 m 5.0015297\n",
      "121 Train Loss 0.24938542 Test RE 0.0034543468705791583 c 1.002491 k 1.0000011 m 5.00092\n",
      "122 Train Loss 0.24530952 Test RE 0.003393110116463167 c 0.99878454 k 1.0003253 m 5.0017347\n",
      "123 Train Loss 0.24081895 Test RE 0.003287119775663214 c 0.99661714 k 1.000325 m 4.996687\n",
      "124 Train Loss 0.23610038 Test RE 0.0032065670691766323 c 0.9992754 k 0.9999907 m 4.9963903\n",
      "125 Train Loss 0.23186913 Test RE 0.0030908548849533845 c 0.9992809 k 1.0000925 m 5.004295\n",
      "126 Train Loss 0.23103642 Test RE 0.0030620388541842875 c 0.9994571 k 1.0001515 m 5.0063295\n",
      "127 Train Loss 0.23054384 Test RE 0.0030735555186404456 c 1.0004169 k 1.0001028 m 5.0055656\n",
      "128 Train Loss 0.22975954 Test RE 0.00303562966559734 c 1.0002964 k 1.0001538 m 5.0083966\n",
      "129 Train Loss 0.22924756 Test RE 0.0030205409203657723 c 1.0004541 k 1.0001682 m 5.0090194\n",
      "130 Train Loss 0.22791865 Test RE 0.003009575736303798 c 1.0004877 k 0.9999945 m 5.007116\n",
      "131 Train Loss 0.2266759 Test RE 0.0029723905097107607 c 1.0002141 k 1.0000966 m 5.009074\n",
      "132 Train Loss 0.2240632 Test RE 0.0029035108125891147 c 0.99919534 k 1.0001814 m 5.006316\n",
      "133 Train Loss 0.21947178 Test RE 0.0027896137412087374 c 0.9992721 k 0.99998033 m 5.0038986\n",
      "134 Train Loss 0.21392843 Test RE 0.002635482899974003 c 1.0014892 k 1.0001242 m 5.007656\n",
      "135 Train Loss 0.20953317 Test RE 0.002460542864266867 c 1.0015148 k 1.0000621 m 5.008604\n",
      "136 Train Loss 0.20606819 Test RE 0.002303689570976288 c 0.9989364 k 1.0000255 m 5.010078\n",
      "137 Train Loss 0.20371348 Test RE 0.0022423430434772977 c 0.9984031 k 1.0001138 m 5.009283\n",
      "138 Train Loss 0.19389267 Test RE 0.00209541225827739 c 0.9956132 k 0.99990714 m 5.0190253\n",
      "139 Train Loss 0.18383536 Test RE 0.0018030981001994956 c 0.99048835 k 1.0000451 m 5.030921\n",
      "140 Train Loss 0.17415054 Test RE 0.0016319744655365542 c 0.9896106 k 1.0005594 m 5.026154\n",
      "141 Train Loss 0.1611432 Test RE 0.0014406960768456611 c 0.9952945 k 1.000487 m 5.011481\n",
      "142 Train Loss 0.15626895 Test RE 0.0013608457927617055 c 0.9985139 k 1.0005748 m 5.0117855\n",
      "143 Train Loss 0.14577825 Test RE 0.0012147282313382539 c 1.001848 k 1.000447 m 5.011906\n",
      "144 Train Loss 0.13632709 Test RE 0.0011765192941942232 c 0.9999943 k 0.99995273 m 5.0087566\n",
      "145 Train Loss 0.12267612 Test RE 0.0012822700419602255 c 1.0007262 k 1.0000778 m 4.9994526\n",
      "146 Train Loss 0.117201544 Test RE 0.00132241271927299 c 1.0013 k 1.0001496 m 5.005907\n",
      "147 Train Loss 0.113361254 Test RE 0.0012664792696732707 c 0.9998343 k 1.0001389 m 5.009336\n",
      "148 Train Loss 0.11112392 Test RE 0.0012846205000003675 c 0.99853736 k 1.0002149 m 5.0053306\n",
      "149 Train Loss 0.11065417 Test RE 0.00126792133994315 c 0.999048 k 1.0002334 m 5.0046854\n",
      "150 Train Loss 0.11021709 Test RE 0.0012820111993846887 c 0.9985839 k 1.0002158 m 5.0041656\n",
      "151 Train Loss 0.10957846 Test RE 0.00130617532727862 c 0.99822366 k 1.0001607 m 5.0044055\n",
      "152 Train Loss 0.10924888 Test RE 0.001307085370951348 c 0.99872375 k 1.0002126 m 5.0058827\n",
      "153 Train Loss 0.10815857 Test RE 0.0013478345237702234 c 0.9977788 k 1.0003575 m 5.0060987\n",
      "154 Train Loss 0.10712955 Test RE 0.001415432916767996 c 0.9974194 k 1.0002755 m 5.0022454\n",
      "155 Train Loss 0.106085315 Test RE 0.0014575644622092383 c 0.9981632 k 1.0001638 m 5.0016375\n",
      "156 Train Loss 0.1048975 Test RE 0.0014609936448995461 c 0.9981696 k 1.0001906 m 5.000807\n",
      "157 Train Loss 0.103977926 Test RE 0.0014722694260428505 c 0.9980035 k 1.000098 m 4.9990907\n",
      "158 Train Loss 0.1030609 Test RE 0.0015206641717892425 c 0.9986256 k 1.0000235 m 5.000294\n",
      "159 Train Loss 0.101763666 Test RE 0.0015488550962789998 c 1.0001271 k 1.0001018 m 4.998958\n",
      "160 Train Loss 0.10006544 Test RE 0.0015503143832001282 c 1.001073 k 1.0000076 m 4.9981084\n",
      "161 Train Loss 0.09812969 Test RE 0.0015728003668874706 c 1.0000983 k 0.9999941 m 5.003882\n",
      "162 Train Loss 0.0968965 Test RE 0.0016087945552754862 c 1.0008295 k 1.0001925 m 5.004811\n",
      "163 Train Loss 0.09533908 Test RE 0.0015888168644556913 c 1.0001011 k 1.00036 m 5.0049534\n",
      "164 Train Loss 0.09318344 Test RE 0.001502594245299183 c 0.9990196 k 1.0001487 m 5.002017\n",
      "165 Train Loss 0.08971306 Test RE 0.001544513040885316 c 0.9993089 k 1.0000764 m 4.996732\n",
      "166 Train Loss 0.08752749 Test RE 0.00151396845076176 c 0.9993084 k 1.0002598 m 4.9986744\n",
      "167 Train Loss 0.08310334 Test RE 0.0014355811294137922 c 1.0013995 k 1.0003389 m 5.0004897\n",
      "168 Train Loss 0.07397694 Test RE 0.0014317065689429052 c 1.0055053 k 1.0001384 m 4.998541\n",
      "169 Train Loss 0.062395457 Test RE 0.0012595518094387322 c 1.0025411 k 1.0001656 m 4.9958954\n",
      "170 Train Loss 0.05750981 Test RE 0.001134303128932172 c 0.99953955 k 1.0000622 m 4.9968066\n",
      "171 Train Loss 0.053666472 Test RE 0.001072394676796529 c 0.9999534 k 0.99997467 m 4.994959\n",
      "172 Train Loss 0.047928393 Test RE 0.0009528457664951293 c 0.9989401 k 1.0001795 m 4.9949846\n",
      "173 Train Loss 0.041922133 Test RE 0.0008529184671687605 c 0.9965925 k 1.0002844 m 4.9976654\n",
      "174 Train Loss 0.03763966 Test RE 0.0008411527373171201 c 0.9997139 k 1.0001436 m 4.992861\n",
      "175 Train Loss 0.033790696 Test RE 0.0007430259786683689 c 1.0002882 k 1.0000333 m 4.996664\n",
      "176 Train Loss 0.031926867 Test RE 0.0006085775619069009 c 1.0000571 k 0.99984217 m 4.9964314\n",
      "177 Train Loss 0.030292727 Test RE 0.0005343874380431625 c 1.0017135 k 0.99992526 m 4.99739\n",
      "178 Train Loss 0.02877957 Test RE 0.0004670995486429097 c 1.0015988 k 0.9999642 m 5.003654\n",
      "179 Train Loss 0.027691204 Test RE 0.0004295156850967726 c 1.0022625 k 0.99984646 m 5.001513\n",
      "180 Train Loss 0.027123759 Test RE 0.00042354405354375784 c 1.0018193 k 0.9998655 m 5.000562\n",
      "181 Train Loss 0.026226783 Test RE 0.0003912944419198043 c 1.0006018 k 1.0000257 m 5.00299\n",
      "182 Train Loss 0.025645785 Test RE 0.00034586291469886906 c 1.0007257 k 1.0000035 m 5.0015507\n",
      "183 Train Loss 0.025532426 Test RE 0.00034083540476785665 c 1.0009192 k 0.9999818 m 5.000818\n",
      "184 Train Loss 0.025362832 Test RE 0.000338103256770365 c 1.0009998 k 1.0000014 m 5.001726\n",
      "185 Train Loss 0.025300773 Test RE 0.00033095357708354007 c 1.0007899 k 1.0000134 m 5.0009604\n",
      "186 Train Loss 0.02523659 Test RE 0.00033474306926279236 c 1.0002513 k 1.0000185 m 4.999934\n",
      "187 Train Loss 0.025208972 Test RE 0.00033547981458837816 c 1.0002341 k 0.99999815 m 4.999797\n",
      "188 Train Loss 0.025204413 Test RE 0.0003350453892789581 c 1.0002851 k 0.9999969 m 4.999783\n",
      "189 Train Loss 0.025202176 Test RE 0.0003349043509854613 c 1.0003134 k 0.99999815 m 4.9997706\n",
      "190 Train Loss 0.025201347 Test RE 0.0003349043246909996 c 1.0003229 k 0.99999946 m 4.9997683\n",
      "191 Train Loss 0.025200572 Test RE 0.0003351471012031876 c 1.000333 k 1.0000012 m 4.9997573\n",
      "192 Train Loss 0.025195368 Test RE 0.00033644913624976137 c 1.0003443 k 1.00001 m 4.9997306\n",
      "193 Train Loss 0.025192503 Test RE 0.0003376173956192324 c 1.0003335 k 1.0000153 m 4.999742\n",
      "194 Train Loss 0.025189547 Test RE 0.00033860406038927024 c 1.0003214 k 1.0000184 m 4.999755\n",
      "195 Train Loss 0.025187273 Test RE 0.00033919992126218334 c 1.0003113 k 1.0000199 m 4.999768\n",
      "196 Train Loss 0.025187273 Test RE 0.00033919992126218334 c 1.0003113 k 1.0000199 m 4.999768\n",
      "197 Train Loss 0.025187273 Test RE 0.00033919992126218334 c 1.0003113 k 1.0000199 m 4.999768\n",
      "198 Train Loss 0.025187273 Test RE 0.00033919992126218334 c 1.0003113 k 1.0000199 m 4.999768\n",
      "199 Train Loss 0.025187273 Test RE 0.00033919992126218334 c 1.0003113 k 1.0000199 m 4.999768\n",
      "Training time: 60.24\n",
      "Training time: 60.24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 624.18066 Test RE 0.2395972046917694 c -0.008185014 k 0.9447468 m 0.0039730016\n",
      "1 Train Loss 493.04114 Test RE 0.22019361590837314 c -0.0077232835 k 1.0164475 m 0.0035794429\n",
      "2 Train Loss 485.11313 Test RE 0.2176853588528206 c -0.006343199 k 1.018108 m 0.0034307006\n",
      "3 Train Loss 473.60504 Test RE 0.2143184506674651 c 0.0005523118 k 1.0139766 m 0.0034588194\n",
      "4 Train Loss 416.5069 Test RE 0.1869813019499385 c 0.027050741 k 1.0137789 m 0.003246116\n",
      "5 Train Loss 402.33694 Test RE 0.1811530823793263 c 0.05936101 k 1.0030566 m 0.0028873235\n",
      "6 Train Loss 322.9378 Test RE 0.15068430644417571 c 0.5414977 k 1.0069482 m 0.0031148621\n",
      "7 Train Loss 279.11108 Test RE 0.12716124000840262 c 0.8607981 k 0.98861176 m 0.009722416\n",
      "8 Train Loss 266.87326 Test RE 0.12433055721104426 c 0.9450636 k 0.9938909 m 0.021376055\n",
      "9 Train Loss 250.91934 Test RE 0.11085384315757374 c 1.2021996 k 0.97581834 m 0.11016926\n",
      "10 Train Loss 227.0003 Test RE 0.10779201162266358 c 1.3614141 k 0.9796763 m 0.18426232\n",
      "11 Train Loss 216.40378 Test RE 0.09759526791335002 c 1.4765053 k 0.99198914 m 0.29077864\n",
      "12 Train Loss 208.43658 Test RE 0.09313073804735734 c 1.4667262 k 0.9679702 m 0.39002514\n",
      "13 Train Loss 168.943 Test RE 0.08339096414922449 c 1.4304954 k 0.9555119 m 0.98495543\n",
      "14 Train Loss 149.80777 Test RE 0.08343263148333938 c 1.4982792 k 0.9891297 m 1.3764681\n",
      "15 Train Loss 142.30183 Test RE 0.0791045184146067 c 1.5448574 k 0.96619606 m 1.5384315\n",
      "16 Train Loss 134.60516 Test RE 0.08015266809122355 c 1.5065672 k 0.9781465 m 1.6765668\n",
      "17 Train Loss 130.93689 Test RE 0.08477505250597485 c 1.4197601 k 0.9853859 m 1.793974\n",
      "18 Train Loss 125.51999 Test RE 0.08180879587760961 c 1.2899816 k 0.9778948 m 1.7375154\n",
      "19 Train Loss 124.31422 Test RE 0.08043406244187722 c 1.2712468 k 0.98038924 m 1.6826704\n",
      "20 Train Loss 103.07009 Test RE 0.07626253338683033 c 1.3176228 k 0.99909544 m 2.3580794\n",
      "21 Train Loss 72.56813 Test RE 0.05972996339349114 c 1.5651703 k 0.9794926 m 3.2033799\n",
      "22 Train Loss 67.60603 Test RE 0.05798999750459224 c 1.5734757 k 0.98583674 m 3.5232105\n",
      "23 Train Loss 64.72549 Test RE 0.059051146205438644 c 1.5192164 k 0.9827132 m 3.4884102\n",
      "24 Train Loss 59.96376 Test RE 0.056969579104151485 c 1.4255046 k 0.9828284 m 3.4785795\n",
      "25 Train Loss 48.356705 Test RE 0.05545094064041005 c 1.3589635 k 0.9877529 m 3.8552382\n",
      "26 Train Loss 42.43388 Test RE 0.05376963782072121 c 1.433463 k 0.98820883 m 4.135508\n",
      "27 Train Loss 39.833946 Test RE 0.05086827377760602 c 1.5000597 k 0.9928767 m 4.360889\n",
      "28 Train Loss 38.570423 Test RE 0.049961172062396336 c 1.4386495 k 0.99154735 m 4.3303943\n",
      "29 Train Loss 36.225155 Test RE 0.04821284457299088 c 1.3067558 k 0.9924532 m 4.424707\n",
      "30 Train Loss 32.13697 Test RE 0.04011560360811608 c 1.0723841 k 0.99688953 m 4.6680293\n",
      "31 Train Loss 30.960163 Test RE 0.039737213308209486 c 1.1030846 k 0.99650365 m 4.721878\n",
      "32 Train Loss 29.906452 Test RE 0.04068759030103958 c 1.1376193 k 0.99515015 m 4.88031\n",
      "33 Train Loss 27.915936 Test RE 0.03843934995095467 c 1.1415714 k 0.99938923 m 5.142223\n",
      "34 Train Loss 27.31709 Test RE 0.03655040539837792 c 1.1134629 k 0.9998792 m 5.1721344\n",
      "35 Train Loss 22.444426 Test RE 0.03569955380578816 c 1.1547624 k 0.9949456 m 5.0826936\n",
      "36 Train Loss 20.350037 Test RE 0.03631012709922479 c 1.2226309 k 0.99717504 m 5.0296454\n",
      "37 Train Loss 18.855072 Test RE 0.03553861796965473 c 1.1988031 k 1.0029761 m 4.8848624\n",
      "38 Train Loss 17.814047 Test RE 0.03486178094090904 c 1.1355791 k 0.99384296 m 4.814257\n",
      "39 Train Loss 15.932687 Test RE 0.03210691430590862 c 1.1011477 k 0.99302 m 5.0087476\n",
      "40 Train Loss 14.315744 Test RE 0.029989384690631515 c 1.1012844 k 1.0023417 m 5.095054\n",
      "41 Train Loss 13.528422 Test RE 0.028997466174091865 c 1.0935065 k 0.99641746 m 5.0432816\n",
      "42 Train Loss 12.88146 Test RE 0.02709688050527607 c 1.0636706 k 1.0001904 m 5.0423903\n",
      "43 Train Loss 12.623577 Test RE 0.027449834894738612 c 1.0755221 k 0.9993495 m 4.9926925\n",
      "44 Train Loss 12.448944 Test RE 0.027386586907026684 c 1.0840553 k 0.9986388 m 4.930617\n",
      "45 Train Loss 12.088411 Test RE 0.027495227749613594 c 1.0853891 k 0.99786323 m 4.7786164\n",
      "46 Train Loss 11.999924 Test RE 0.027489994485543005 c 1.1007608 k 0.9965165 m 4.7698174\n",
      "47 Train Loss 11.722769 Test RE 0.026503307350384364 c 1.103263 k 0.9965555 m 4.799534\n",
      "48 Train Loss 11.099976 Test RE 0.02595152865070444 c 1.0782402 k 0.9986381 m 4.8124194\n",
      "49 Train Loss 10.824816 Test RE 0.025279823212859723 c 1.0694067 k 0.99676996 m 4.8286085\n",
      "50 Train Loss 10.709044 Test RE 0.025102157619524067 c 1.0753495 k 0.9986895 m 4.8008285\n",
      "51 Train Loss 10.606155 Test RE 0.0252643322791808 c 1.085471 k 0.9968579 m 4.751565\n",
      "52 Train Loss 10.406321 Test RE 0.024802543936725138 c 1.0738043 k 0.9966453 m 4.745849\n",
      "53 Train Loss 10.068447 Test RE 0.024027048474441474 c 1.0728297 k 0.998103 m 4.820881\n",
      "54 Train Loss 9.532928 Test RE 0.023570442342807786 c 1.0838615 k 0.9974879 m 4.9196477\n",
      "55 Train Loss 8.705599 Test RE 0.022420506832509332 c 1.0352806 k 0.99804974 m 4.899291\n",
      "56 Train Loss 8.268969 Test RE 0.02301661364081527 c 1.0783215 k 0.99972606 m 4.88422\n",
      "57 Train Loss 7.9061604 Test RE 0.02237632965363573 c 1.0578054 k 0.9979309 m 4.8715777\n",
      "58 Train Loss 7.6005845 Test RE 0.021352036660022704 c 1.0189725 k 0.9990549 m 4.922482\n",
      "59 Train Loss 6.760874 Test RE 0.019879228736598545 c 1.0383453 k 0.9986439 m 5.0040464\n",
      "60 Train Loss 6.3828654 Test RE 0.018799091451312453 c 1.0276583 k 0.9992759 m 4.9740205\n",
      "61 Train Loss 6.0645695 Test RE 0.01752119216400357 c 1.0263652 k 1.0004385 m 4.9936438\n",
      "62 Train Loss 5.994833 Test RE 0.017156419521696147 c 1.0482372 k 0.99956745 m 5.0002093\n",
      "63 Train Loss 5.3638678 Test RE 0.016041300096785678 c 1.0920478 k 0.9978156 m 4.910722\n",
      "64 Train Loss 4.521552 Test RE 0.014743301134804335 c 1.0118151 k 0.9979341 m 4.8141108\n",
      "65 Train Loss 4.0390706 Test RE 0.01314952509641543 c 1.0216597 k 0.9960537 m 4.8208117\n",
      "66 Train Loss 3.72432 Test RE 0.01328066415858041 c 1.0423042 k 0.99450505 m 4.7697625\n",
      "67 Train Loss 3.6617892 Test RE 0.01309674981601092 c 1.0244406 k 0.99662083 m 4.7750454\n",
      "68 Train Loss 3.6084101 Test RE 0.013023485370170809 c 1.0362452 k 0.99821436 m 4.8074093\n",
      "69 Train Loss 3.5234356 Test RE 0.01301590748937763 c 1.0363443 k 0.9969365 m 4.829064\n",
      "70 Train Loss 3.4733834 Test RE 0.012851629207279941 c 1.008347 k 0.9967183 m 4.8657165\n",
      "71 Train Loss 3.3591752 Test RE 0.012711281166716727 c 1.019856 k 0.998044 m 4.934213\n",
      "72 Train Loss 3.1732044 Test RE 0.01293155792683936 c 1.0117183 k 0.99843687 m 4.934555\n",
      "73 Train Loss 3.0209935 Test RE 0.013286979632093687 c 1.0211389 k 0.99699926 m 4.9219656\n",
      "74 Train Loss 3.000801 Test RE 0.013313849639866565 c 1.0269625 k 0.9982837 m 4.9177227\n",
      "75 Train Loss 2.946576 Test RE 0.013177457880138866 c 1.0098773 k 0.99775785 m 4.914183\n",
      "76 Train Loss 2.7828166 Test RE 0.012411578118891677 c 1.0085974 k 0.99745697 m 4.9421077\n",
      "77 Train Loss 2.7334404 Test RE 0.012194837920806056 c 1.0108505 k 0.998281 m 4.932611\n",
      "78 Train Loss 2.7187166 Test RE 0.012270633726917876 c 1.0101516 k 0.9981804 m 4.9297104\n",
      "79 Train Loss 2.6958237 Test RE 0.012240298138862633 c 1.0140625 k 0.997885 m 4.923258\n",
      "80 Train Loss 2.6435008 Test RE 0.011820798684619925 c 1.0101943 k 0.99790764 m 4.928588\n",
      "81 Train Loss 2.3929389 Test RE 0.011177664468698846 c 0.99624294 k 0.9989719 m 4.9175625\n",
      "82 Train Loss 2.1492112 Test RE 0.01082989646933528 c 1.0039052 k 0.99792254 m 4.949464\n",
      "83 Train Loss 1.8193536 Test RE 0.009766022514012327 c 1.005059 k 0.9998111 m 5.0527453\n",
      "84 Train Loss 1.679482 Test RE 0.009262701468888756 c 0.99879295 k 0.99995697 m 5.0643706\n",
      "85 Train Loss 1.562148 Test RE 0.00875263950751498 c 1.0187011 k 0.99916446 m 5.0208483\n",
      "86 Train Loss 1.4635222 Test RE 0.008605904834035782 c 1.0158533 k 0.9987235 m 4.974057\n",
      "87 Train Loss 1.4104179 Test RE 0.00860895392992356 c 0.99522626 k 0.99889463 m 4.9738445\n",
      "88 Train Loss 1.387756 Test RE 0.008514525497478038 c 1.0007168 k 0.9990832 m 4.976892\n",
      "89 Train Loss 1.3573418 Test RE 0.008402357102020013 c 1.000893 k 0.99940133 m 4.9570637\n",
      "90 Train Loss 1.3240254 Test RE 0.00831719394828709 c 0.9948344 k 0.99890256 m 4.951624\n",
      "91 Train Loss 1.2238061 Test RE 0.007792942282881972 c 0.9995574 k 0.9993217 m 4.9775\n",
      "92 Train Loss 1.1604156 Test RE 0.007643335489338588 c 1.0046983 k 0.99983144 m 4.971036\n",
      "93 Train Loss 1.0852365 Test RE 0.007341906539935431 c 0.9992772 k 0.99871415 m 4.964035\n",
      "94 Train Loss 1.0074555 Test RE 0.006998682338806131 c 1.0017052 k 0.99830014 m 4.98469\n",
      "95 Train Loss 0.9349593 Test RE 0.0069532989182855675 c 1.0082083 k 1.0000643 m 5.000894\n",
      "96 Train Loss 0.86970603 Test RE 0.007163797000716455 c 1.0021974 k 1.0011721 m 4.997732\n",
      "97 Train Loss 0.83194387 Test RE 0.007129967525217539 c 1.0059156 k 0.99983174 m 4.9704885\n",
      "98 Train Loss 0.82306576 Test RE 0.007166375582032974 c 1.0055168 k 0.999564 m 4.977297\n",
      "99 Train Loss 0.82185465 Test RE 0.007181591584018678 c 1.0055789 k 0.9996022 m 4.9732146\n",
      "100 Train Loss 0.8205318 Test RE 0.007149574916269544 c 1.0060213 k 0.9997348 m 4.9697433\n",
      "101 Train Loss 0.8122864 Test RE 0.007027412729642781 c 1.0050948 k 0.9998827 m 4.976593\n",
      "102 Train Loss 0.8044392 Test RE 0.006996632353560931 c 1.0045962 k 0.9997409 m 4.984527\n",
      "103 Train Loss 0.802284 Test RE 0.0069491384688052295 c 1.005292 k 0.9999606 m 4.9844546\n",
      "104 Train Loss 0.79768753 Test RE 0.006876302139985807 c 1.0051693 k 0.99994296 m 4.9844203\n",
      "105 Train Loss 0.7962117 Test RE 0.006896520941012255 c 1.0043449 k 0.9997994 m 4.9855733\n",
      "106 Train Loss 0.7936317 Test RE 0.006920852203161052 c 1.0051712 k 0.9998372 m 4.9855957\n",
      "107 Train Loss 0.7917349 Test RE 0.006872068492515259 c 1.0053539 k 0.99981064 m 4.9846234\n",
      "108 Train Loss 0.79123247 Test RE 0.006862430073416787 c 1.005535 k 0.9998141 m 4.9851193\n",
      "109 Train Loss 0.791227 Test RE 0.006862412446496119 c 1.005535 k 0.9998141 m 4.9851193\n",
      "110 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "111 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "112 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "113 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "114 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "115 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "116 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "117 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "118 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "119 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "120 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "121 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "122 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "123 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "124 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "125 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "126 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "127 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "128 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "129 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "130 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "131 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "132 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "133 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "134 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "135 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "136 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "137 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "138 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "139 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "140 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "141 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "142 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "143 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "144 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "145 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "146 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "147 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "148 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "149 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "150 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "151 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "152 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "153 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "154 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "155 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "156 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "157 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "158 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "159 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "160 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "161 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "162 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "163 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "164 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "165 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "166 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "167 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "168 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "169 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "170 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "171 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "172 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "173 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "174 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "175 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "176 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "177 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "178 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "179 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "180 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "181 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "182 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "183 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "184 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "185 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "186 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "187 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "188 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "189 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "190 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "191 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "192 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "193 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "194 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "195 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "196 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "197 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "198 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "199 Train Loss 0.7912227 Test RE 0.006862324673166181 c 1.0055351 k 0.9998141 m 4.9851193\n",
      "Training time: 45.44\n",
      "Training time: 45.44\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 494.95923 Test RE 0.21931537795020975 c 0.015928343 k 1.0128936 m -0.00044196655\n",
      "1 Train Loss 490.00647 Test RE 0.21906979861841025 c 0.015814487 k 1.0201907 m -0.00043274413\n",
      "2 Train Loss 484.5329 Test RE 0.2179799804674583 c 0.016013939 k 1.0115767 m -0.00045719964\n",
      "3 Train Loss 479.57443 Test RE 0.21612248912274845 c 0.017759146 k 1.0277348 m -0.00050489086\n",
      "4 Train Loss 467.53348 Test RE 0.21199436377389938 c 0.02692543 k 1.0087581 m -0.000730826\n",
      "5 Train Loss 432.15625 Test RE 0.1969718581158294 c 0.056544576 k 0.986782 m -0.0017763131\n",
      "6 Train Loss 386.8529 Test RE 0.16579371636732443 c 0.12498164 k 1.0446181 m -0.003457095\n",
      "7 Train Loss 327.05383 Test RE 0.14231278739219244 c 0.19802165 k 1.0005605 m 5.6895515e-06\n",
      "8 Train Loss 309.21893 Test RE 0.13715194413183407 c 0.2365117 k 1.0018014 m 0.010056808\n",
      "9 Train Loss 281.36755 Test RE 0.13233161581543504 c 0.50849575 k 0.99017215 m 0.1335711\n",
      "10 Train Loss 259.01584 Test RE 0.12351171480752673 c 0.68821526 k 0.98982733 m 0.2523702\n",
      "11 Train Loss 241.89807 Test RE 0.11333884807450657 c 0.8895648 k 0.9851788 m 0.41367966\n",
      "12 Train Loss 228.62463 Test RE 0.10479391014489241 c 1.0516373 k 0.98708975 m 0.6591571\n",
      "13 Train Loss 207.68634 Test RE 0.10082285296271684 c 1.1812972 k 0.98711616 m 0.9054835\n",
      "14 Train Loss 195.70792 Test RE 0.08744697975081556 c 1.22737 k 0.9813698 m 1.0526146\n",
      "15 Train Loss 157.68579 Test RE 0.07749488863944845 c 1.2603464 k 0.9802049 m 1.602957\n",
      "16 Train Loss 133.62851 Test RE 0.07030799478282838 c 1.2626238 k 0.96940935 m 1.8550107\n",
      "17 Train Loss 108.44878 Test RE 0.06913067393935247 c 1.2351973 k 0.9821918 m 2.296497\n",
      "18 Train Loss 92.04103 Test RE 0.07062924007731808 c 1.3361794 k 0.97975963 m 2.7645626\n",
      "19 Train Loss 82.88722 Test RE 0.06547606242964127 c 1.4164879 k 0.98379916 m 3.0313933\n",
      "20 Train Loss 74.79718 Test RE 0.06312546733549042 c 1.4472893 k 0.9854764 m 3.3917303\n",
      "21 Train Loss 66.33664 Test RE 0.056346773292347614 c 1.4445262 k 0.9861466 m 3.7797887\n",
      "22 Train Loss 56.863297 Test RE 0.055201415147002574 c 1.3768528 k 0.9918257 m 3.9751863\n",
      "23 Train Loss 51.791977 Test RE 0.05347535675488075 c 1.3603896 k 0.98793113 m 4.024326\n",
      "24 Train Loss 46.51045 Test RE 0.05168541350928675 c 1.3833727 k 0.9918794 m 4.222538\n",
      "25 Train Loss 35.128937 Test RE 0.04850786551211021 c 1.3855522 k 0.99115694 m 4.5652084\n",
      "26 Train Loss 29.731796 Test RE 0.04603331988540087 c 1.421193 k 0.99840015 m 4.9517007\n",
      "27 Train Loss 25.316456 Test RE 0.04357406788479007 c 1.3319345 k 0.99366295 m 4.7838855\n",
      "28 Train Loss 20.632376 Test RE 0.03793321276511102 c 1.2116628 k 0.9951195 m 4.606725\n",
      "29 Train Loss 17.318123 Test RE 0.034026261957668405 c 1.1255549 k 0.99648434 m 4.7142596\n",
      "30 Train Loss 14.318854 Test RE 0.029714782235405326 c 1.0977064 k 0.9971491 m 4.85861\n",
      "31 Train Loss 12.071612 Test RE 0.02598725011997294 c 1.0150728 k 0.9994192 m 4.8748913\n",
      "32 Train Loss 9.881074 Test RE 0.021771803081923908 c 0.9180912 k 0.99819744 m 4.916956\n",
      "33 Train Loss 7.8485355 Test RE 0.019644112622716915 c 0.98674214 k 1.0007195 m 4.9999957\n",
      "34 Train Loss 6.898535 Test RE 0.018344418607589123 c 1.010447 k 0.99998677 m 4.9787703\n",
      "35 Train Loss 6.238474 Test RE 0.017496788514050704 c 1.0041139 k 0.99883723 m 4.92015\n",
      "36 Train Loss 5.743579 Test RE 0.016646081857432413 c 1.0383426 k 1.0006133 m 4.929048\n",
      "37 Train Loss 5.2288675 Test RE 0.015854640088290628 c 1.041176 k 0.9993929 m 4.9639516\n",
      "38 Train Loss 4.926304 Test RE 0.015328477051901816 c 1.0194689 k 0.9989964 m 4.9771276\n",
      "39 Train Loss 4.3628864 Test RE 0.014015881634358771 c 1.0043489 k 1.0006356 m 5.02186\n",
      "40 Train Loss 3.8162584 Test RE 0.01350724088870085 c 1.0305316 k 1.0003868 m 5.0237117\n",
      "41 Train Loss 3.3704002 Test RE 0.01315307278631824 c 1.0124904 k 1.0010798 m 5.0135474\n",
      "42 Train Loss 3.1793923 Test RE 0.012709456359114168 c 1.0029614 k 1.0002981 m 5.023459\n",
      "43 Train Loss 2.8519835 Test RE 0.012472734619576542 c 0.998312 k 1.0005137 m 5.0329046\n",
      "44 Train Loss 2.7166119 Test RE 0.012471871024362605 c 0.9973045 k 1.0004274 m 4.990731\n",
      "45 Train Loss 2.6544366 Test RE 0.01227695341167452 c 1.0001417 k 1.0003036 m 4.9949045\n",
      "46 Train Loss 2.5992165 Test RE 0.01202162572553668 c 1.0053663 k 1.0007167 m 5.013444\n",
      "47 Train Loss 2.512752 Test RE 0.011897363245287002 c 1.0193803 k 1.000021 m 4.970951\n",
      "48 Train Loss 2.4330807 Test RE 0.011800654837348278 c 1.0336717 k 0.9992731 m 4.932023\n",
      "49 Train Loss 2.335112 Test RE 0.011362313548949655 c 1.0281093 k 0.9996218 m 4.9195466\n",
      "50 Train Loss 2.074356 Test RE 0.010854397887106881 c 1.0237502 k 0.9996267 m 4.9488244\n",
      "51 Train Loss 1.9382815 Test RE 0.010774988008105713 c 1.0265445 k 0.9997681 m 4.994824\n",
      "52 Train Loss 1.8763885 Test RE 0.010727450227472542 c 1.0135446 k 1.0008777 m 5.0056963\n",
      "53 Train Loss 1.8492754 Test RE 0.010613384434441406 c 1.0145721 k 0.99992275 m 5.003158\n",
      "54 Train Loss 1.8258209 Test RE 0.010549280570730008 c 1.0148498 k 1.0000871 m 4.97804\n",
      "55 Train Loss 1.7392321 Test RE 0.010289401217740109 c 1.0070269 k 1.0008023 m 4.9503646\n",
      "56 Train Loss 1.5828354 Test RE 0.00981344899485151 c 1.0125967 k 0.9993017 m 4.9696727\n",
      "57 Train Loss 1.4123856 Test RE 0.009407549356712112 c 1.0041194 k 1.0000613 m 4.9981103\n",
      "58 Train Loss 1.3132184 Test RE 0.009028291603380338 c 1.0033605 k 1.0000211 m 5.0003867\n",
      "59 Train Loss 1.2557855 Test RE 0.008856259479898787 c 1.0065985 k 0.9998532 m 5.008287\n",
      "60 Train Loss 1.2250481 Test RE 0.00875454410360875 c 1.0031974 k 1.0000907 m 5.0052795\n",
      "61 Train Loss 1.209122 Test RE 0.008658967919358888 c 1.0059857 k 1.0001894 m 5.0049996\n",
      "62 Train Loss 1.1727494 Test RE 0.008450228106060413 c 1.0058281 k 1.0001769 m 4.9957843\n",
      "63 Train Loss 1.15193 Test RE 0.008439613373468317 c 1.003196 k 0.9997852 m 4.989658\n",
      "64 Train Loss 1.1338072 Test RE 0.008441909361950179 c 1.0109202 k 0.9999146 m 4.982065\n",
      "65 Train Loss 1.1067722 Test RE 0.008244556797936056 c 1.0120331 k 0.9997314 m 4.971255\n",
      "66 Train Loss 1.0782223 Test RE 0.008086946430131841 c 1.0032505 k 0.99974597 m 4.983536\n",
      "67 Train Loss 1.0350816 Test RE 0.007749965525764516 c 0.99253523 k 1.0001339 m 5.0013013\n",
      "68 Train Loss 0.9771168 Test RE 0.007459877406147088 c 1.0013434 k 1.0000881 m 5.0085435\n",
      "69 Train Loss 0.9545944 Test RE 0.0074540788018120085 c 1.0042039 k 1.0001051 m 4.9975057\n",
      "70 Train Loss 0.94298685 Test RE 0.007374992009744351 c 1.0033164 k 0.9998324 m 4.982053\n",
      "71 Train Loss 0.9199748 Test RE 0.007202100776572535 c 1.0087208 k 0.9996579 m 4.970607\n",
      "72 Train Loss 0.88944995 Test RE 0.007017086820267845 c 1.0079324 k 1.0000476 m 4.980258\n",
      "73 Train Loss 0.84769535 Test RE 0.006697097812905319 c 1.0030015 k 0.99984163 m 4.9867992\n",
      "74 Train Loss 0.8052617 Test RE 0.006598774347843148 c 1.0082564 k 1.0000075 m 4.9999657\n",
      "75 Train Loss 0.7493301 Test RE 0.006595906029227905 c 1.0109947 k 1.0000657 m 4.9904876\n",
      "76 Train Loss 0.6958419 Test RE 0.006576612340926397 c 1.0119362 k 0.99946785 m 4.9544106\n",
      "77 Train Loss 0.6573546 Test RE 0.0063682065376415836 c 1.0163866 k 0.9994641 m 4.9538016\n",
      "78 Train Loss 0.6087288 Test RE 0.0060989520465874435 c 1.0119658 k 0.9999327 m 4.9877357\n",
      "79 Train Loss 0.58033717 Test RE 0.0059004489297756245 c 1.0046556 k 0.9997108 m 4.989118\n",
      "80 Train Loss 0.5510306 Test RE 0.005651216802663837 c 0.9996254 k 0.9999073 m 4.9893684\n",
      "81 Train Loss 0.52585906 Test RE 0.005317950754027125 c 1.0043395 k 0.99965703 m 4.998998\n",
      "82 Train Loss 0.47459733 Test RE 0.004663100943254128 c 1.0062805 k 1.0007422 m 5.0107703\n",
      "83 Train Loss 0.42889762 Test RE 0.004357951221291065 c 0.992022 k 1.0005304 m 5.0196457\n",
      "84 Train Loss 0.3998685 Test RE 0.004187077998706981 c 0.9966546 k 0.9998628 m 5.006689\n",
      "85 Train Loss 0.37584007 Test RE 0.004040967164489603 c 0.99857795 k 1.0000217 m 4.9862423\n",
      "86 Train Loss 0.33906782 Test RE 0.0038256343602297085 c 1.0027355 k 0.99962336 m 4.9691925\n",
      "87 Train Loss 0.3036366 Test RE 0.0036129402632199166 c 1.0074826 k 0.9994154 m 4.975055\n",
      "88 Train Loss 0.2917362 Test RE 0.00353955637974656 c 1.0020272 k 0.9995444 m 4.9768167\n",
      "89 Train Loss 0.28326797 Test RE 0.003495911452644327 c 1.0023794 k 0.9996257 m 4.9788637\n",
      "90 Train Loss 0.27576533 Test RE 0.003483233006388669 c 1.0039448 k 0.99986315 m 4.9859557\n",
      "91 Train Loss 0.2687586 Test RE 0.0034146101913542673 c 1.0029753 k 0.99971676 m 4.987289\n",
      "92 Train Loss 0.26094356 Test RE 0.003315212173599698 c 1.001725 k 0.9995992 m 4.9933352\n",
      "93 Train Loss 0.25540912 Test RE 0.0032706413112074686 c 1.0006238 k 1.0000238 m 4.998565\n",
      "94 Train Loss 0.24992463 Test RE 0.003195506057352117 c 0.9998516 k 0.9998445 m 4.996106\n",
      "95 Train Loss 0.24588403 Test RE 0.003162030290695563 c 1.0010297 k 0.9997823 m 4.9913373\n",
      "96 Train Loss 0.24125251 Test RE 0.003089013035640884 c 0.99959046 k 0.9999542 m 4.990565\n",
      "97 Train Loss 0.23659298 Test RE 0.0030682453281121345 c 1.0009537 k 0.99966514 m 4.9931107\n",
      "98 Train Loss 0.22943702 Test RE 0.0030708256210304702 c 1.0028685 k 0.9997764 m 4.9907274\n",
      "99 Train Loss 0.22658056 Test RE 0.003026596739450927 c 1.0000896 k 0.99993366 m 4.9858027\n",
      "100 Train Loss 0.2165017 Test RE 0.0029682053893904247 c 1.0008498 k 0.9996541 m 4.9814587\n",
      "101 Train Loss 0.20083266 Test RE 0.0029432145086278503 c 1.0025868 k 0.99998915 m 4.9916677\n",
      "102 Train Loss 0.18694647 Test RE 0.0027057875513769865 c 1.0015475 k 0.99991226 m 4.992764\n",
      "103 Train Loss 0.18068531 Test RE 0.0026637868147785272 c 1.0024621 k 0.99964195 m 4.9937115\n",
      "104 Train Loss 0.17956226 Test RE 0.002670832423907242 c 1.0007206 k 0.999843 m 4.9942284\n",
      "105 Train Loss 0.17806453 Test RE 0.0026401189256080593 c 0.999008 k 0.99978006 m 4.9957485\n",
      "106 Train Loss 0.17616239 Test RE 0.002600250741025897 c 1.0010096 k 0.9997605 m 4.999606\n",
      "107 Train Loss 0.17405757 Test RE 0.002550384394101839 c 1.0018711 k 0.99994785 m 4.9983325\n",
      "108 Train Loss 0.16796273 Test RE 0.002400459646097018 c 1.0009613 k 0.99982405 m 4.998184\n",
      "109 Train Loss 0.16492924 Test RE 0.002373503220773491 c 1.0001241 k 0.999731 m 5.0011234\n",
      "110 Train Loss 0.16250491 Test RE 0.0024262589510021942 c 1.0007848 k 0.99970025 m 4.9979753\n",
      "111 Train Loss 0.16067818 Test RE 0.0024058532090437 c 1.0023329 k 0.9998071 m 4.997766\n",
      "112 Train Loss 0.15788066 Test RE 0.0023555485052393055 c 1.0015112 k 0.99975055 m 4.997106\n",
      "113 Train Loss 0.15394351 Test RE 0.0023656986502197663 c 0.9996752 k 0.9997616 m 5.000849\n",
      "114 Train Loss 0.13795973 Test RE 0.0023574828862820696 c 1.0016285 k 1.0001581 m 5.012469\n",
      "115 Train Loss 0.11846712 Test RE 0.002087868379877522 c 0.9988238 k 0.99999195 m 5.0059366\n",
      "116 Train Loss 0.11256239 Test RE 0.0019137174645925063 c 1.0011673 k 0.9997258 m 5.0014367\n",
      "117 Train Loss 0.109939255 Test RE 0.001881702811824539 c 1.0000812 k 0.9998094 m 5.00218\n",
      "118 Train Loss 0.108827755 Test RE 0.0018598584240275063 c 1.0008844 k 0.9997628 m 4.9973807\n",
      "119 Train Loss 0.108211786 Test RE 0.00184000501152065 c 1.0007291 k 0.99978447 m 4.998083\n",
      "120 Train Loss 0.10766094 Test RE 0.0018224737990649368 c 1.0004377 k 0.9997437 m 4.998633\n",
      "121 Train Loss 0.106815785 Test RE 0.0018133250730169063 c 1.0004787 k 0.99972284 m 4.9924555\n",
      "122 Train Loss 0.103040315 Test RE 0.0017626885828476286 c 0.9976779 k 0.9996248 m 4.9864216\n",
      "123 Train Loss 0.091568135 Test RE 0.0016623285768588567 c 0.993373 k 0.9996339 m 4.999046\n",
      "124 Train Loss 0.07915595 Test RE 0.0015745338518649214 c 0.99871075 k 0.9999757 m 5.0032806\n",
      "125 Train Loss 0.074268185 Test RE 0.0015134057713196794 c 0.998934 k 0.9999142 m 4.99658\n",
      "126 Train Loss 0.07229903 Test RE 0.0015000064953913366 c 0.99992585 k 0.9996919 m 4.99788\n",
      "127 Train Loss 0.069411896 Test RE 0.0014494729397688405 c 1.0027285 k 0.9996227 m 4.996443\n",
      "128 Train Loss 0.06770283 Test RE 0.0014063158262420487 c 1.0019218 k 0.9998877 m 4.996204\n",
      "129 Train Loss 0.06590181 Test RE 0.001378595661973161 c 0.99968517 k 0.99980885 m 4.999127\n",
      "130 Train Loss 0.06440124 Test RE 0.001295313937813858 c 1.0006826 k 0.99974525 m 4.997712\n",
      "131 Train Loss 0.06243275 Test RE 0.0012191383624487924 c 1.000246 k 0.99979866 m 4.9956665\n",
      "132 Train Loss 0.061853312 Test RE 0.0011838873351980364 c 1.0000066 k 0.9998124 m 4.998087\n",
      "133 Train Loss 0.0610886 Test RE 0.0011632809653561655 c 1.0005362 k 0.9997748 m 4.997906\n",
      "134 Train Loss 0.05851994 Test RE 0.001091408709029657 c 1.0006462 k 0.99981076 m 4.9941063\n",
      "135 Train Loss 0.05689173 Test RE 0.00100441845262464 c 1.0015218 k 0.9998278 m 4.9967256\n",
      "136 Train Loss 0.054972295 Test RE 0.0009055375552182306 c 1.0015038 k 0.9997562 m 4.999034\n",
      "137 Train Loss 0.05438725 Test RE 0.0008763104471342943 c 1.0005169 k 0.9998057 m 4.997321\n",
      "138 Train Loss 0.05269008 Test RE 0.0008859455112966476 c 1.0010979 k 0.9998661 m 4.9955683\n",
      "139 Train Loss 0.050707452 Test RE 0.0009047850924035393 c 1.0018958 k 0.9997755 m 4.9942107\n",
      "140 Train Loss 0.050018355 Test RE 0.0008648154021530184 c 1.0011873 k 0.9997766 m 4.9928765\n",
      "141 Train Loss 0.049682774 Test RE 0.0008613725307523987 c 1.0014111 k 0.999768 m 4.9934793\n",
      "142 Train Loss 0.049375113 Test RE 0.0008882520587617034 c 1.0017437 k 0.99979496 m 4.9947376\n",
      "143 Train Loss 0.04836728 Test RE 0.0008755864917223704 c 1.0002787 k 0.99981207 m 4.9963307\n",
      "144 Train Loss 0.045284625 Test RE 0.000834573835004338 c 0.99937457 k 0.9997127 m 4.996555\n",
      "145 Train Loss 0.043637164 Test RE 0.0008356528285074395 c 1.0009059 k 0.99982685 m 4.998051\n",
      "146 Train Loss 0.042304542 Test RE 0.0008346827759204538 c 1.0014175 k 0.999908 m 4.997101\n",
      "147 Train Loss 0.041498452 Test RE 0.0007747862887151302 c 1.0013816 k 0.9997978 m 4.996305\n",
      "148 Train Loss 0.040543146 Test RE 0.0007271071948712634 c 1.0009493 k 0.9998823 m 4.997949\n",
      "149 Train Loss 0.03991749 Test RE 0.0007208130880723855 c 1.0008161 k 0.99991447 m 4.998093\n",
      "150 Train Loss 0.039521173 Test RE 0.000719075749261727 c 1.0010645 k 0.999802 m 4.997762\n",
      "151 Train Loss 0.03908288 Test RE 0.0007402126755412346 c 1.001585 k 0.9998607 m 4.999559\n",
      "152 Train Loss 0.038616177 Test RE 0.0007693648017629681 c 1.0013032 k 0.99989593 m 5.000628\n",
      "153 Train Loss 0.038208462 Test RE 0.0007566880852949161 c 1.0003982 k 0.99983525 m 5.0009375\n",
      "154 Train Loss 0.037091367 Test RE 0.0007134427139414029 c 0.99933815 k 0.9998969 m 5.0001717\n",
      "155 Train Loss 0.035995293 Test RE 0.0007056766717981898 c 0.99968207 k 0.9999055 m 4.997303\n",
      "156 Train Loss 0.035148397 Test RE 0.000674267143831978 c 1.0004535 k 0.99975604 m 4.9947085\n",
      "157 Train Loss 0.0339461 Test RE 0.0006265613083898179 c 1.0016367 k 0.99973416 m 4.993902\n",
      "158 Train Loss 0.033318214 Test RE 0.0006050145702149347 c 1.0020715 k 0.9998145 m 4.991627\n",
      "159 Train Loss 0.032209918 Test RE 0.0005456995673277684 c 1.0010722 k 0.9997756 m 4.9906354\n",
      "160 Train Loss 0.03013549 Test RE 0.0005785596698815761 c 1.0004932 k 0.99978346 m 5.000094\n",
      "161 Train Loss 0.028288785 Test RE 0.0005886219966856705 c 1.0019007 k 1.0000038 m 5.0025525\n",
      "162 Train Loss 0.02613973 Test RE 0.0005307435572948325 c 1.0022469 k 0.99994993 m 5.000784\n",
      "163 Train Loss 0.024231022 Test RE 0.0004328074971846374 c 1.0029819 k 0.99975944 m 5.004577\n",
      "164 Train Loss 0.023226727 Test RE 0.00039933147936720294 c 1.0038308 k 0.99987215 m 5.0048194\n",
      "165 Train Loss 0.022071224 Test RE 0.00043553992365405936 c 1.0026467 k 0.99997973 m 5.0039277\n",
      "166 Train Loss 0.019843759 Test RE 0.0004206168268823304 c 1.0019543 k 1.000017 m 5.002176\n",
      "167 Train Loss 0.01764504 Test RE 0.00032311991597502377 c 1.0027534 k 0.99991196 m 5.0000434\n",
      "168 Train Loss 0.016953468 Test RE 0.0003238591669995064 c 1.0023252 k 0.9999059 m 4.9996514\n",
      "169 Train Loss 0.015909325 Test RE 0.00027421889410732183 c 1.0001574 k 0.99994975 m 4.998503\n",
      "170 Train Loss 0.015124355 Test RE 0.00022158097597358833 c 0.9994111 k 0.9999068 m 4.997651\n",
      "171 Train Loss 0.0147858765 Test RE 0.0002199878718886664 c 0.9995922 k 0.99992585 m 4.998866\n",
      "172 Train Loss 0.014461 Test RE 0.00022038015699451743 c 0.9995899 k 0.9999831 m 4.9995713\n",
      "173 Train Loss 0.014216468 Test RE 0.0002256473948658502 c 0.99951917 k 0.999969 m 4.999756\n",
      "174 Train Loss 0.014095305 Test RE 0.00022964163697539722 c 0.9995487 k 0.999962 m 5.000313\n",
      "175 Train Loss 0.013969909 Test RE 0.0002344057595047846 c 0.9997661 k 0.9999805 m 4.999955\n",
      "176 Train Loss 0.013808993 Test RE 0.000238360458339416 c 1.0001528 k 0.9999453 m 4.9991965\n",
      "177 Train Loss 0.013572072 Test RE 0.0002408773983416038 c 1.0006251 k 0.9999722 m 5.000577\n",
      "178 Train Loss 0.013382155 Test RE 0.00024249577413091547 c 1.0007114 k 0.9999685 m 5.0007925\n",
      "179 Train Loss 0.013112607 Test RE 0.00023296947969503334 c 1.0006343 k 0.99994856 m 4.9993324\n",
      "180 Train Loss 0.012930529 Test RE 0.00022654526238135783 c 1.000851 k 1.0000129 m 4.9994564\n",
      "181 Train Loss 0.012603824 Test RE 0.0002177549187440093 c 1.0005392 k 0.99999046 m 5.0013466\n",
      "182 Train Loss 0.012349869 Test RE 0.00021363749637698045 c 0.99944025 k 0.99996495 m 5.002252\n",
      "183 Train Loss 0.011882674 Test RE 0.0002212860001159126 c 0.9988694 k 0.99999815 m 5.0002394\n",
      "184 Train Loss 0.0114335315 Test RE 0.00022546742750405386 c 0.9992113 k 0.9999698 m 5.0001\n",
      "185 Train Loss 0.011166948 Test RE 0.00022614484796800526 c 0.9998787 k 0.9999719 m 5.0010533\n",
      "186 Train Loss 0.011048671 Test RE 0.00022625738458043697 c 0.9998607 k 0.99998045 m 5.0007224\n",
      "187 Train Loss 0.01069905 Test RE 0.00021975087398178929 c 0.99903506 k 0.99996704 m 5.0020323\n",
      "188 Train Loss 0.010543205 Test RE 0.00021894867556203045 c 0.99905825 k 0.99998415 m 5.002055\n",
      "189 Train Loss 0.010371372 Test RE 0.00020390925479107843 c 0.9995982 k 1.0000094 m 5.0013843\n",
      "190 Train Loss 0.010290327 Test RE 0.00019569142126380477 c 0.99988073 k 0.99997526 m 5.001495\n",
      "191 Train Loss 0.0102437 Test RE 0.0001965554484522657 c 1.0000648 k 0.99998486 m 5.001767\n",
      "192 Train Loss 0.010217949 Test RE 0.0001990120192470498 c 1.0001622 k 0.99998 m 5.0018125\n",
      "193 Train Loss 0.010166188 Test RE 0.0002073857213119987 c 1.0002737 k 0.9999732 m 5.0015416\n",
      "194 Train Loss 0.010100961 Test RE 0.0002205124946276436 c 1.0002729 k 1.000002 m 5.000971\n",
      "195 Train Loss 0.009971967 Test RE 0.00023478959465011146 c 1.0002668 k 0.99997723 m 4.99974\n",
      "196 Train Loss 0.009794019 Test RE 0.00024063271797167998 c 1.0002908 k 0.9999481 m 4.999456\n",
      "197 Train Loss 0.00967454 Test RE 0.00024776487009871674 c 1.000276 k 0.9999779 m 4.999376\n",
      "198 Train Loss 0.009664576 Test RE 0.0002490813404650982 c 1.0002649 k 0.99997735 m 4.999355\n",
      "199 Train Loss 0.009660024 Test RE 0.00024908570117198665 c 1.0002486 k 0.9999724 m 4.9993844\n",
      "Training time: 62.88\n",
      "Training time: 62.88\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 726.80365 Test RE 0.2566081253185594 c -0.12000634 k 1.125208 m 0.0038920501\n",
      "1 Train Loss 512.60333 Test RE 0.22423380967080897 c -0.12367759 k 1.0261683 m 0.003975741\n",
      "2 Train Loss 492.61008 Test RE 0.21950563735659898 c -0.12508231 k 1.0162417 m 0.004021193\n",
      "3 Train Loss 482.07626 Test RE 0.21686586128429902 c -0.12300469 k 1.016455 m 0.0043019354\n",
      "4 Train Loss 454.2896 Test RE 0.20629630141202243 c -0.10839483 k 1.017442 m 0.0057053654\n",
      "5 Train Loss 364.7265 Test RE 0.16103704362431648 c -0.055496745 k 0.9997134 m 0.00920482\n",
      "6 Train Loss 316.7318 Test RE 0.14039180613279054 c -0.02088229 k 1.0022657 m 0.016134534\n",
      "7 Train Loss 289.8325 Test RE 0.13855139613662093 c 0.067831665 k 0.9952898 m 0.05286914\n",
      "8 Train Loss 261.737 Test RE 0.12531858779462257 c 0.16914664 k 0.99650496 m 0.09485707\n",
      "9 Train Loss 255.60428 Test RE 0.11830157338158166 c 0.2035397 k 0.9924312 m 0.11766682\n",
      "10 Train Loss 247.19536 Test RE 0.11981039429980984 c 0.28683946 k 0.99253696 m 0.21007125\n",
      "11 Train Loss 236.9302 Test RE 0.10839928935198755 c 0.3493424 k 0.9887752 m 0.29977491\n",
      "12 Train Loss 229.01924 Test RE 0.10770646280282965 c 0.43744144 k 0.98621094 m 0.42061782\n",
      "13 Train Loss 219.24539 Test RE 0.1042097556035829 c 0.63108873 k 0.9851336 m 0.6713159\n",
      "14 Train Loss 203.23051 Test RE 0.10173072959209357 c 0.845733 k 0.99549586 m 0.9797837\n",
      "15 Train Loss 191.11972 Test RE 0.1035497293877986 c 0.9752097 k 0.98073673 m 1.1278671\n",
      "16 Train Loss 182.03354 Test RE 0.10465051102111714 c 1.0744662 k 0.98954153 m 1.2526774\n",
      "17 Train Loss 173.7345 Test RE 0.10226777901683527 c 1.2486176 k 0.99017423 m 1.4870303\n",
      "18 Train Loss 164.6253 Test RE 0.09957843513820203 c 1.4342542 k 0.9731766 m 1.7374736\n",
      "19 Train Loss 155.40282 Test RE 0.09778683138851935 c 1.6437213 k 0.9835605 m 2.0113688\n",
      "20 Train Loss 145.70166 Test RE 0.09350256803542265 c 1.6328324 k 0.9938541 m 2.0078568\n",
      "21 Train Loss 138.01111 Test RE 0.08446194545389678 c 1.6835884 k 0.98035735 m 2.0895815\n",
      "22 Train Loss 134.74475 Test RE 0.08072909989311931 c 1.6223719 k 0.9838475 m 2.024397\n",
      "23 Train Loss 129.37047 Test RE 0.0752210941361148 c 1.5526786 k 0.98012626 m 1.9831283\n",
      "24 Train Loss 128.03351 Test RE 0.0732826002308374 c 1.5545077 k 0.9791066 m 2.0025005\n",
      "25 Train Loss 123.61282 Test RE 0.07431533794222894 c 1.551695 k 0.97683465 m 2.0676193\n",
      "26 Train Loss 118.06543 Test RE 0.06859292191638036 c 1.5459132 k 0.9819361 m 2.1583884\n",
      "27 Train Loss 110.02533 Test RE 0.06746184774362088 c 1.4768156 k 0.9877819 m 2.264917\n",
      "28 Train Loss 91.942345 Test RE 0.0644595485472048 c 1.5227103 k 0.965706 m 2.7093294\n",
      "29 Train Loss 71.188286 Test RE 0.053196908256889414 c 1.5007008 k 0.97369164 m 3.1186538\n",
      "30 Train Loss 65.48059 Test RE 0.047785098790646664 c 1.4264734 k 0.98633564 m 3.1988096\n",
      "31 Train Loss 55.27585 Test RE 0.04491066234356361 c 1.3079123 k 0.97315586 m 3.594791\n",
      "32 Train Loss 45.18615 Test RE 0.03808745446190327 c 1.2528225 k 0.9821349 m 3.6787906\n",
      "33 Train Loss 41.084686 Test RE 0.03776181585985303 c 1.2913017 k 0.98649704 m 3.8510475\n",
      "34 Train Loss 37.178432 Test RE 0.03419042323095775 c 1.3283972 k 0.9892521 m 4.0255384\n",
      "35 Train Loss 35.34471 Test RE 0.03582829997862022 c 1.2666684 k 0.98868436 m 4.076469\n",
      "36 Train Loss 31.926884 Test RE 0.030110862064706492 c 1.1070569 k 0.9911994 m 4.204014\n",
      "37 Train Loss 26.550915 Test RE 0.02962800956972277 c 1.0984795 k 0.9926395 m 4.1109457\n",
      "38 Train Loss 21.743874 Test RE 0.0287057281576351 c 1.123965 k 0.989273 m 4.1966414\n",
      "39 Train Loss 19.507076 Test RE 0.027018187003425363 c 1.1009674 k 0.99312806 m 4.4196124\n",
      "40 Train Loss 18.474953 Test RE 0.026524201575363348 c 1.1186725 k 0.99561536 m 4.4662714\n",
      "41 Train Loss 15.675295 Test RE 0.023807906808852593 c 1.1619556 k 0.9968472 m 4.492597\n",
      "42 Train Loss 14.611218 Test RE 0.022343783263054175 c 1.115741 k 0.9945531 m 4.4673\n",
      "43 Train Loss 13.592169 Test RE 0.02257582388410734 c 1.14749 k 0.9951714 m 4.413464\n",
      "44 Train Loss 12.443531 Test RE 0.020159217760019457 c 1.1265668 k 0.9958959 m 4.5214295\n",
      "45 Train Loss 10.832136 Test RE 0.01961156379150211 c 1.0955759 k 0.9967101 m 4.565261\n",
      "46 Train Loss 9.487116 Test RE 0.019156772246029224 c 1.1444012 k 0.994886 m 4.593829\n",
      "47 Train Loss 8.539297 Test RE 0.019201921680475735 c 1.1234881 k 0.9960744 m 4.6105676\n",
      "48 Train Loss 8.181311 Test RE 0.018718319667544756 c 1.1141238 k 0.9969266 m 4.6678267\n",
      "49 Train Loss 7.4863977 Test RE 0.01738625896267817 c 1.046981 k 0.9974226 m 4.715779\n",
      "50 Train Loss 6.988013 Test RE 0.01703605662256773 c 1.0390068 k 0.99641067 m 4.694255\n",
      "51 Train Loss 6.533287 Test RE 0.01642741947937238 c 1.0835352 k 0.9972609 m 4.7023115\n",
      "52 Train Loss 6.3657722 Test RE 0.015155371183834076 c 1.0685037 k 0.99645686 m 4.7377114\n",
      "53 Train Loss 6.2144833 Test RE 0.01490796115177627 c 1.0704155 k 0.9980009 m 4.7723837\n",
      "54 Train Loss 6.1151214 Test RE 0.014706778927061383 c 1.0656925 k 0.9979619 m 4.7911696\n",
      "55 Train Loss 5.7345066 Test RE 0.014174964365548142 c 1.0377709 k 0.9991536 m 4.830643\n",
      "56 Train Loss 5.088496 Test RE 0.013674488755682316 c 1.0290025 k 0.99933887 m 4.956674\n",
      "57 Train Loss 4.9453773 Test RE 0.013584825342146167 c 1.0538483 k 0.9996644 m 4.972989\n",
      "58 Train Loss 4.619535 Test RE 0.013450577452214325 c 1.0254339 k 1.0013895 m 4.999172\n",
      "59 Train Loss 3.9622412 Test RE 0.01211969787730155 c 1.0133466 k 0.9968657 m 5.059737\n",
      "60 Train Loss 3.335107 Test RE 0.010839916340316528 c 1.0288346 k 1.0008827 m 5.0620546\n",
      "61 Train Loss 3.171612 Test RE 0.010850402091278698 c 1.0157995 k 1.0021528 m 5.1026955\n",
      "62 Train Loss 2.9791508 Test RE 0.010088522056525025 c 1.0035394 k 1.0010315 m 5.143407\n",
      "63 Train Loss 2.8287768 Test RE 0.008871287563840452 c 1.0027039 k 1.0026386 m 5.1381164\n",
      "64 Train Loss 2.7388375 Test RE 0.00847072000038362 c 0.98156935 k 1.0022833 m 5.11357\n",
      "65 Train Loss 2.6518536 Test RE 0.007746900662104607 c 0.98001176 k 1.0004214 m 5.0911865\n",
      "66 Train Loss 2.552049 Test RE 0.006842948315113946 c 0.9856055 k 1.0013297 m 5.0824547\n",
      "67 Train Loss 2.4453235 Test RE 0.006521874622100405 c 0.97532296 k 1.0027776 m 5.0854764\n",
      "68 Train Loss 2.295015 Test RE 0.006652073983052466 c 0.9794608 k 1.0017989 m 5.094845\n",
      "69 Train Loss 2.0689147 Test RE 0.006233853173527511 c 0.9854002 k 1.0010622 m 5.103625\n",
      "70 Train Loss 1.9712774 Test RE 0.005934721399928487 c 0.97316724 k 1.0016673 m 5.0887012\n",
      "71 Train Loss 1.9488058 Test RE 0.006032261489719235 c 0.9720947 k 1.0013471 m 5.1029315\n",
      "72 Train Loss 1.925667 Test RE 0.006115062490360018 c 0.9709341 k 1.0010978 m 5.114143\n",
      "73 Train Loss 1.8761909 Test RE 0.006065915231149317 c 0.9789189 k 1.001514 m 5.1009235\n",
      "74 Train Loss 1.745462 Test RE 0.005793272759085502 c 0.9990411 k 1.0006057 m 5.0400352\n",
      "75 Train Loss 1.6153485 Test RE 0.0055614118880063295 c 1.0081096 k 1.0001053 m 5.030259\n",
      "76 Train Loss 1.5308747 Test RE 0.005487484590634161 c 1.0021137 k 1.0014027 m 5.0439215\n",
      "77 Train Loss 1.4996763 Test RE 0.005662805383527793 c 1.0029113 k 1.0008824 m 5.049027\n",
      "78 Train Loss 1.4769053 Test RE 0.005712022174709599 c 1.0039611 k 1.0008346 m 5.0478406\n",
      "79 Train Loss 1.4514996 Test RE 0.005630140928680773 c 1.004263 k 1.0004622 m 5.0208673\n",
      "80 Train Loss 1.4348139 Test RE 0.005574695253412402 c 1.0019399 k 1.000078 m 5.005199\n",
      "81 Train Loss 1.4139953 Test RE 0.00569017066834112 c 1.0039073 k 1.000546 m 5.0102873\n",
      "82 Train Loss 1.3945336 Test RE 0.005725486372225318 c 1.0092663 k 1.0005354 m 5.013383\n",
      "83 Train Loss 1.3433137 Test RE 0.005700472567537993 c 1.0061038 k 0.9992112 m 5.014883\n",
      "84 Train Loss 1.1764724 Test RE 0.0059736120386396354 c 0.9956457 k 0.99873406 m 4.984854\n",
      "85 Train Loss 1.1108716 Test RE 0.006022012550959238 c 1.0015451 k 1.0000788 m 4.975554\n",
      "86 Train Loss 1.1014771 Test RE 0.005958036449371669 c 1.003352 k 1.000207 m 4.978243\n",
      "87 Train Loss 1.0833503 Test RE 0.0060058352248729425 c 1.0108563 k 1.0006534 m 4.98737\n",
      "88 Train Loss 1.0390589 Test RE 0.0061735071712552035 c 1.0069851 k 0.9999765 m 4.991192\n",
      "89 Train Loss 1.0176117 Test RE 0.006177467822205702 c 1.0031439 k 1.0001705 m 4.9949956\n",
      "90 Train Loss 1.0101278 Test RE 0.006214684379200478 c 1.0058035 k 1.0002978 m 4.9962664\n",
      "91 Train Loss 1.0053333 Test RE 0.006289862924772002 c 1.0039893 k 1.0001793 m 4.992475\n",
      "92 Train Loss 1.0031669 Test RE 0.006313519344773623 c 1.0030153 k 1.0002604 m 4.993103\n",
      "93 Train Loss 0.9924269 Test RE 0.006257351477404257 c 1.0021949 k 1.0006256 m 4.991969\n",
      "94 Train Loss 0.9674993 Test RE 0.006242581006534904 c 1.004893 k 1.0003046 m 5.001446\n",
      "95 Train Loss 0.9427228 Test RE 0.006190109959591537 c 1.0032026 k 0.99988765 m 5.0058556\n",
      "96 Train Loss 0.9152589 Test RE 0.006042616054014018 c 1.0003481 k 1.0003248 m 4.9964037\n",
      "97 Train Loss 0.90470433 Test RE 0.006060258242411889 c 1.0007993 k 1.0002768 m 4.9839444\n",
      "98 Train Loss 0.89639825 Test RE 0.006101322625174779 c 1.0033188 k 1.0000343 m 4.9688096\n",
      "99 Train Loss 0.89247227 Test RE 0.0061535530347157285 c 1.0077071 k 0.9999239 m 4.9663444\n",
      "100 Train Loss 0.89001334 Test RE 0.006189170370320666 c 1.0085753 k 0.9998995 m 4.9631586\n",
      "101 Train Loss 0.88336 Test RE 0.006217955147802021 c 1.0102624 k 0.99972206 m 4.9553022\n",
      "102 Train Loss 0.8748654 Test RE 0.006221599312442439 c 1.0119361 k 0.9996747 m 4.952891\n",
      "103 Train Loss 0.86783683 Test RE 0.006173995140553957 c 1.012524 k 0.9996567 m 4.9532857\n",
      "104 Train Loss 0.8581388 Test RE 0.006067683843805354 c 1.0123888 k 0.99968696 m 4.949718\n",
      "105 Train Loss 0.8417045 Test RE 0.006026354153005169 c 1.0128192 k 0.9999638 m 4.9665904\n",
      "106 Train Loss 0.8243683 Test RE 0.006032578049770197 c 1.0045099 k 1.0004174 m 4.989949\n",
      "107 Train Loss 0.80844474 Test RE 0.006088379513406838 c 1.0008332 k 1.0003829 m 4.9885573\n",
      "108 Train Loss 0.8028945 Test RE 0.006123709822592603 c 1.0043769 k 0.9999036 m 4.991981\n",
      "109 Train Loss 0.7945807 Test RE 0.006072246814623396 c 1.0074201 k 1.0000532 m 4.9923997\n",
      "110 Train Loss 0.78604156 Test RE 0.00600996763752378 c 1.0061944 k 1.0008504 m 5.000855\n",
      "111 Train Loss 0.77430594 Test RE 0.0058943143674532565 c 1.0073174 k 1.0007452 m 5.016364\n",
      "112 Train Loss 0.7657803 Test RE 0.005772677079255402 c 1.0062392 k 1.0007514 m 5.0125866\n",
      "113 Train Loss 0.74679464 Test RE 0.0055645374166660815 c 1.0037389 k 1.000194 m 4.993039\n",
      "114 Train Loss 0.7166153 Test RE 0.005247385949223308 c 0.9998971 k 1.0000875 m 4.9936147\n",
      "115 Train Loss 0.6719161 Test RE 0.005006101398498034 c 1.0029495 k 1.0004082 m 4.9865017\n",
      "116 Train Loss 0.6497749 Test RE 0.004761529163741179 c 1.01037 k 0.9999349 m 4.9871626\n",
      "117 Train Loss 0.63326806 Test RE 0.004320108293355906 c 1.006168 k 1.0004 m 4.997782\n",
      "118 Train Loss 0.62917113 Test RE 0.004273544930221065 c 1.0045681 k 1.0003417 m 4.989453\n",
      "119 Train Loss 0.6261371 Test RE 0.004186417494816747 c 1.0065645 k 1.0003673 m 4.9850793\n",
      "120 Train Loss 0.6180591 Test RE 0.004072788081078866 c 1.0049638 k 1.0001988 m 4.9862323\n",
      "121 Train Loss 0.6104271 Test RE 0.004053909009504578 c 1.0038198 k 1.0003271 m 4.990656\n",
      "122 Train Loss 0.6086355 Test RE 0.004108285275732118 c 1.0062683 k 1.0003793 m 4.9904113\n",
      "123 Train Loss 0.6061635 Test RE 0.004150919947288447 c 1.0068035 k 1.0002757 m 4.992471\n",
      "124 Train Loss 0.60111177 Test RE 0.004073325693823844 c 1.0054445 k 1.0002333 m 4.9948993\n",
      "125 Train Loss 0.5957614 Test RE 0.003969414096246396 c 1.0066466 k 1.0001842 m 4.997893\n",
      "126 Train Loss 0.5874252 Test RE 0.0038576049454629264 c 1.0026413 k 1.0000795 m 4.98844\n",
      "127 Train Loss 0.5783966 Test RE 0.0038626919288190092 c 1.0014391 k 1.000495 m 4.988264\n",
      "128 Train Loss 0.5731331 Test RE 0.0037491180703907796 c 1.0039072 k 1.000473 m 4.9964857\n",
      "129 Train Loss 0.5676173 Test RE 0.0036297006039769865 c 1.005525 k 0.9999856 m 4.9971867\n",
      "130 Train Loss 0.5624057 Test RE 0.003593646384180214 c 1.005878 k 1.0001285 m 4.9985027\n",
      "131 Train Loss 0.55854815 Test RE 0.0034992977946658893 c 1.003359 k 1.0003508 m 5.001895\n",
      "132 Train Loss 0.5559339 Test RE 0.003513677585017444 c 1.0033321 k 1.0003673 m 5.002209\n",
      "133 Train Loss 0.5519712 Test RE 0.0034711962941939324 c 1.001599 k 1.0001396 m 4.9993525\n",
      "134 Train Loss 0.5498463 Test RE 0.0033855564478949504 c 0.99822885 k 1.0000894 m 5.0010366\n",
      "135 Train Loss 0.5443391 Test RE 0.003361198479124247 c 0.9991207 k 1.0004128 m 4.9997573\n",
      "136 Train Loss 0.53761065 Test RE 0.003370365799543015 c 1.0039372 k 1.0005028 m 4.990322\n",
      "137 Train Loss 0.5278667 Test RE 0.0034766927438881204 c 1.0032724 k 1.0002037 m 4.989686\n",
      "138 Train Loss 0.522498 Test RE 0.003523494235914295 c 1.0027604 k 1.0002041 m 4.995942\n",
      "139 Train Loss 0.5188994 Test RE 0.0034191427777580056 c 1.0041727 k 1.0001711 m 4.99915\n",
      "140 Train Loss 0.51599675 Test RE 0.0033211338426883874 c 1.0033494 k 1.0001943 m 4.9968653\n",
      "141 Train Loss 0.5116733 Test RE 0.0033619431805103715 c 1.0034212 k 1.0001014 m 4.9889755\n",
      "142 Train Loss 0.5104121 Test RE 0.0033450195048404133 c 1.0029137 k 0.9999869 m 4.990158\n",
      "143 Train Loss 0.50121456 Test RE 0.003372375744083805 c 1.0034832 k 1.0000715 m 4.984569\n",
      "144 Train Loss 0.49007723 Test RE 0.0035039461193427527 c 1.006997 k 1.0001851 m 4.98464\n",
      "145 Train Loss 0.48596457 Test RE 0.0034643979748656168 c 1.0062014 k 1.0000074 m 4.991312\n",
      "146 Train Loss 0.4771637 Test RE 0.0032530432144130404 c 1.0058604 k 0.99990225 m 4.9898295\n",
      "147 Train Loss 0.45890355 Test RE 0.0029934046095649834 c 1.0079937 k 0.9998131 m 4.9870596\n",
      "148 Train Loss 0.4409297 Test RE 0.00294558438024943 c 1.0031449 k 0.99972963 m 4.9732747\n",
      "149 Train Loss 0.42629308 Test RE 0.0030907098198014074 c 1.0043743 k 0.9997551 m 4.9683733\n",
      "150 Train Loss 0.41487265 Test RE 0.003190833270175694 c 1.0077477 k 0.9993153 m 4.9764495\n",
      "151 Train Loss 0.40540162 Test RE 0.0030764491365494148 c 1.006615 k 0.99943244 m 4.9738054\n",
      "152 Train Loss 0.39990336 Test RE 0.0029904833289057173 c 1.006698 k 0.9998158 m 4.9807353\n",
      "153 Train Loss 0.39587492 Test RE 0.0028959882481219557 c 1.0060681 k 0.9999753 m 4.9886723\n",
      "154 Train Loss 0.3911964 Test RE 0.002778729963794254 c 1.004519 k 0.99975634 m 4.9853916\n",
      "155 Train Loss 0.38645285 Test RE 0.0027479201636181286 c 1.00443 k 0.99961805 m 4.9789515\n",
      "156 Train Loss 0.38101554 Test RE 0.0027165807803315634 c 1.0052254 k 0.9997213 m 4.983568\n",
      "157 Train Loss 0.37882274 Test RE 0.002622468941334615 c 1.0050802 k 0.99959964 m 4.9864306\n",
      "158 Train Loss 0.37727287 Test RE 0.0026353593610122026 c 1.0049703 k 0.9996196 m 4.988283\n",
      "159 Train Loss 0.3741557 Test RE 0.0027307560180267463 c 1.0057552 k 0.9995153 m 4.98761\n",
      "160 Train Loss 0.3700603 Test RE 0.0026551920567964545 c 1.0066445 k 0.99946874 m 4.9812574\n",
      "161 Train Loss 0.3654133 Test RE 0.0025807746085218988 c 1.0059296 k 0.9997613 m 4.987293\n",
      "162 Train Loss 0.36065182 Test RE 0.0025734014558630794 c 1.0046709 k 0.99965453 m 4.986461\n",
      "163 Train Loss 0.3557094 Test RE 0.00242253941330084 c 1.0053047 k 0.99956083 m 4.984283\n",
      "164 Train Loss 0.35186183 Test RE 0.002383309224413864 c 1.005372 k 0.99960583 m 4.994177\n",
      "165 Train Loss 0.3487258 Test RE 0.0024420980902094373 c 1.0049592 k 0.9997089 m 4.9948835\n",
      "166 Train Loss 0.34729216 Test RE 0.0024417582358633822 c 1.0042708 k 0.9996587 m 4.9939957\n",
      "167 Train Loss 0.3451221 Test RE 0.0024302270509449207 c 1.0007986 k 0.99943274 m 4.9942513\n",
      "168 Train Loss 0.34013447 Test RE 0.0024009532939334253 c 1.0034652 k 0.9995983 m 4.9912534\n",
      "169 Train Loss 0.33673638 Test RE 0.002458734622314524 c 1.0061425 k 0.99981934 m 4.9929724\n",
      "170 Train Loss 0.33387378 Test RE 0.0024503616472172874 c 1.0051825 k 0.9996656 m 4.9953375\n",
      "171 Train Loss 0.32818025 Test RE 0.002368220188944589 c 1.004257 k 0.99945134 m 4.9973207\n",
      "172 Train Loss 0.31782758 Test RE 0.0023525239503342245 c 1.001653 k 0.9994785 m 4.994784\n",
      "173 Train Loss 0.30148318 Test RE 0.002267566269126188 c 1.0014669 k 0.9996215 m 4.9903784\n",
      "174 Train Loss 0.29329374 Test RE 0.002176728230839317 c 1.001308 k 0.99972963 m 5.001246\n",
      "175 Train Loss 0.2889606 Test RE 0.002182508025018139 c 1.0026149 k 0.99946624 m 4.9942203\n",
      "176 Train Loss 0.28240943 Test RE 0.0021505151105294445 c 1.0008091 k 0.999818 m 4.986297\n",
      "177 Train Loss 0.27555633 Test RE 0.0021263020933332114 c 1.0012426 k 0.99991095 m 4.9870677\n",
      "178 Train Loss 0.26943454 Test RE 0.002158019057316316 c 1.0023888 k 0.9995217 m 4.982689\n",
      "179 Train Loss 0.26246184 Test RE 0.002146695572328388 c 1.0004936 k 0.9997529 m 4.986874\n",
      "180 Train Loss 0.25037095 Test RE 0.002278022979242177 c 1.0014018 k 1.0000386 m 4.9987373\n",
      "181 Train Loss 0.24422175 Test RE 0.0021950371683587856 c 0.9996341 k 0.9998185 m 4.9946713\n",
      "182 Train Loss 0.24013093 Test RE 0.0020990989955258035 c 1.0000701 k 0.9999286 m 4.9912786\n",
      "183 Train Loss 0.23797221 Test RE 0.0021515186806028838 c 1.000225 k 0.9998517 m 4.992794\n",
      "184 Train Loss 0.23607847 Test RE 0.002183698897786657 c 1.0006068 k 0.99976677 m 4.996492\n",
      "185 Train Loss 0.2352249 Test RE 0.002152214924129886 c 1.002846 k 0.9998386 m 4.9963565\n",
      "186 Train Loss 0.23386243 Test RE 0.0022218077472611953 c 1.004746 k 0.9996884 m 4.9945135\n",
      "187 Train Loss 0.23133129 Test RE 0.002218151352165976 c 1.0025733 k 0.9997711 m 4.997782\n",
      "188 Train Loss 0.22785035 Test RE 0.002158454506271204 c 1.0016142 k 1.0001631 m 4.995255\n",
      "189 Train Loss 0.22612993 Test RE 0.002188284620302599 c 1.0014385 k 0.99985814 m 4.990448\n",
      "190 Train Loss 0.2242715 Test RE 0.0020898988653590797 c 1.0005627 k 0.99968916 m 4.98828\n",
      "191 Train Loss 0.22317916 Test RE 0.0020145080985818384 c 1.0003002 k 0.999859 m 4.992263\n",
      "192 Train Loss 0.22273932 Test RE 0.002021044887603767 c 1.000381 k 0.9998489 m 4.9945655\n",
      "193 Train Loss 0.22126852 Test RE 0.0020238102331916123 c 1.0008018 k 0.9999503 m 4.995002\n",
      "194 Train Loss 0.21826977 Test RE 0.0019702320609607956 c 1.0002795 k 0.99986255 m 4.9901886\n",
      "195 Train Loss 0.21639496 Test RE 0.0018965160930074368 c 1.0000461 k 0.999841 m 4.9958377\n",
      "196 Train Loss 0.2141814 Test RE 0.0018620685378617507 c 0.9988416 k 0.9999992 m 4.996172\n",
      "197 Train Loss 0.21288215 Test RE 0.0018766199528189255 c 0.99918073 k 0.99997514 m 4.9919333\n",
      "198 Train Loss 0.2116265 Test RE 0.0018012840552007303 c 1.000235 k 0.99991167 m 4.9912105\n",
      "199 Train Loss 0.21011457 Test RE 0.0017944308683889758 c 1.0004284 k 0.9997732 m 4.9893317\n",
      "Training time: 62.25\n",
      "Training time: 62.25\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 2385.2078 Test RE 0.3830745545553225 c 0.1252643 k 0.55365163 m -0.0010968492\n",
      "1 Train Loss 504.70825 Test RE 0.21786603759966192 c 0.13115665 k 0.9704952 m -0.0011896666\n",
      "2 Train Loss 474.06924 Test RE 0.21531179711493661 c 0.13362883 k 1.0223716 m -0.0012867311\n",
      "3 Train Loss 454.51804 Test RE 0.2073607517943307 c 0.16177867 k 0.9926182 m -0.001755037\n",
      "4 Train Loss 386.76508 Test RE 0.18048244935923533 c 0.2259835 k 1.0140461 m -0.0024916257\n",
      "5 Train Loss 364.6525 Test RE 0.16205823029471333 c 0.3101654 k 0.9945955 m 0.002615291\n",
      "6 Train Loss 337.32755 Test RE 0.15218145639859207 c 0.57176936 k 1.0234053 m 0.04682612\n",
      "7 Train Loss 290.09286 Test RE 0.12179900958412838 c 1.0120267 k 0.996012 m 0.12257416\n",
      "8 Train Loss 250.74402 Test RE 0.10979351831926842 c 1.4299185 k 0.9666948 m 0.24723414\n",
      "9 Train Loss 230.97147 Test RE 0.11028075668117117 c 1.6659518 k 0.98360944 m 0.36981714\n",
      "10 Train Loss 215.30704 Test RE 0.09806946144671197 c 1.7611732 k 0.98723686 m 0.51892895\n",
      "11 Train Loss 201.4502 Test RE 0.09539549686330749 c 1.6989123 k 0.96716917 m 0.7734867\n",
      "12 Train Loss 183.35172 Test RE 0.09286947928221956 c 1.4739722 k 0.97676235 m 1.0749112\n",
      "13 Train Loss 180.02411 Test RE 0.09303114845600673 c 1.4911151 k 0.9823644 m 1.101249\n",
      "14 Train Loss 173.18208 Test RE 0.08690068170463267 c 1.5208651 k 0.97217584 m 1.1686465\n",
      "15 Train Loss 166.76282 Test RE 0.08453858077773073 c 1.4804085 k 0.9795117 m 1.3070477\n",
      "16 Train Loss 151.02115 Test RE 0.08839188094145117 c 1.1751388 k 0.98206884 m 1.4330144\n",
      "17 Train Loss 137.65565 Test RE 0.0734064511500753 c 1.1535499 k 0.97902495 m 1.5625782\n",
      "18 Train Loss 132.76965 Test RE 0.07420617397136002 c 1.1355768 k 0.9843597 m 1.6726664\n",
      "19 Train Loss 128.49292 Test RE 0.06706898860434798 c 1.0967816 k 0.97703576 m 1.8681732\n",
      "20 Train Loss 123.225006 Test RE 0.06872787649270415 c 1.0975866 k 0.9853701 m 1.996389\n",
      "21 Train Loss 112.2269 Test RE 0.06379958708402818 c 1.1742185 k 0.98243237 m 1.9826174\n",
      "22 Train Loss 98.3207 Test RE 0.06647363050253952 c 1.3654934 k 0.9683091 m 2.0308201\n",
      "23 Train Loss 88.75244 Test RE 0.06600254859609367 c 1.5496873 k 0.9853401 m 2.021152\n",
      "24 Train Loss 85.83637 Test RE 0.06634504581238873 c 1.6493715 k 0.9773695 m 1.9953315\n",
      "25 Train Loss 79.360596 Test RE 0.06111221699245331 c 1.5977592 k 0.9677101 m 2.1609073\n",
      "26 Train Loss 68.55458 Test RE 0.06007725186733393 c 1.4722499 k 0.9805374 m 2.391192\n",
      "27 Train Loss 62.583088 Test RE 0.060429075761503595 c 1.4549978 k 0.97940737 m 2.5048313\n",
      "28 Train Loss 57.434258 Test RE 0.05550575828136211 c 1.4004176 k 0.9809867 m 2.6842382\n",
      "29 Train Loss 54.061974 Test RE 0.05093642495892727 c 1.2664613 k 0.979976 m 2.8321989\n",
      "30 Train Loss 53.086082 Test RE 0.04974833345606663 c 1.2273043 k 0.9800396 m 2.872604\n",
      "31 Train Loss 49.43711 Test RE 0.048185609165694025 c 1.1849029 k 0.9816349 m 3.1333127\n",
      "32 Train Loss 46.89058 Test RE 0.045872082510466226 c 1.2343605 k 0.9804651 m 3.1401634\n",
      "33 Train Loss 43.02484 Test RE 0.03976063993554595 c 1.1843293 k 0.9871794 m 3.3403904\n",
      "34 Train Loss 39.635384 Test RE 0.04099398771859412 c 1.2129354 k 0.98473865 m 3.4253154\n",
      "35 Train Loss 32.757797 Test RE 0.03938088048826351 c 1.2159564 k 0.98889554 m 3.7247548\n",
      "36 Train Loss 29.389637 Test RE 0.030659232763401472 c 1.2173877 k 0.9934117 m 3.9258714\n",
      "37 Train Loss 26.5189 Test RE 0.02940863481723444 c 1.0645279 k 0.9882393 m 4.092865\n",
      "38 Train Loss 23.820145 Test RE 0.025278390975449233 c 1.0162426 k 0.9866827 m 4.119493\n",
      "39 Train Loss 18.988876 Test RE 0.02384531707408698 c 0.9629912 k 0.99582237 m 4.306582\n",
      "40 Train Loss 16.52481 Test RE 0.021638755731129028 c 1.0189626 k 0.99081504 m 4.3727036\n",
      "41 Train Loss 15.438141 Test RE 0.020826521390373814 c 1.0726001 k 0.99335235 m 4.455619\n",
      "42 Train Loss 13.617205 Test RE 0.021187786991898494 c 1.0549684 k 0.99620277 m 4.3972883\n",
      "43 Train Loss 11.511946 Test RE 0.020418369000325027 c 0.99835575 k 0.9909532 m 4.415894\n",
      "44 Train Loss 9.468563 Test RE 0.019100149487652922 c 1.0560496 k 0.9931974 m 4.512675\n",
      "45 Train Loss 7.7738028 Test RE 0.017401530648004863 c 1.0421634 k 0.99706376 m 4.672522\n",
      "46 Train Loss 6.9363375 Test RE 0.01768328141566891 c 1.0210724 k 0.99510926 m 4.7022057\n",
      "47 Train Loss 6.206552 Test RE 0.01777029074756832 c 1.0808307 k 0.99610716 m 4.759318\n",
      "48 Train Loss 5.7002954 Test RE 0.017304034579475203 c 1.0759478 k 0.99790174 m 4.8945646\n",
      "49 Train Loss 5.5540433 Test RE 0.016975734492797826 c 1.0490619 k 0.9989573 m 4.978745\n",
      "50 Train Loss 5.32793 Test RE 0.016251227490884698 c 1.0362483 k 0.99898064 m 4.9976006\n",
      "51 Train Loss 5.285925 Test RE 0.016189494334917977 c 1.0347971 k 0.99874353 m 4.966623\n",
      "52 Train Loss 5.2358446 Test RE 0.016172409198145398 c 1.0286647 k 0.9989893 m 4.962465\n",
      "53 Train Loss 5.1459093 Test RE 0.01610057891906929 c 1.0292648 k 0.998534 m 4.9638\n",
      "54 Train Loss 4.986059 Test RE 0.016443043510858846 c 1.053472 k 0.9979653 m 4.940558\n",
      "55 Train Loss 4.784465 Test RE 0.016886831148758063 c 1.0626063 k 0.99876535 m 4.920925\n",
      "56 Train Loss 4.5763254 Test RE 0.0167449356404551 c 1.0508468 k 0.9980414 m 4.9195704\n",
      "57 Train Loss 4.4185457 Test RE 0.016736259445644424 c 1.0619903 k 0.9977691 m 4.9444056\n",
      "58 Train Loss 4.208832 Test RE 0.01652758892459405 c 1.0398285 k 0.9993383 m 5.0217066\n",
      "59 Train Loss 4.120615 Test RE 0.01639576355348764 c 1.0317298 k 0.9998457 m 5.0015564\n",
      "60 Train Loss 4.016058 Test RE 0.016312404996222853 c 1.037708 k 0.9987457 m 4.953449\n",
      "61 Train Loss 3.9134474 Test RE 0.016014368050870635 c 1.0374283 k 0.99881107 m 4.994216\n",
      "62 Train Loss 3.7972395 Test RE 0.01596253295930056 c 1.0255742 k 0.99882835 m 4.9661503\n",
      "63 Train Loss 3.7707763 Test RE 0.015896746743060332 c 1.0270712 k 0.99911183 m 4.9475627\n",
      "64 Train Loss 3.7533832 Test RE 0.015799784278495963 c 1.0242152 k 0.9993823 m 4.9533305\n",
      "65 Train Loss 3.6924348 Test RE 0.01567698981103548 c 1.019314 k 0.9983427 m 4.954838\n",
      "66 Train Loss 3.6072316 Test RE 0.015512074893851034 c 1.0267098 k 0.99884266 m 4.9467587\n",
      "67 Train Loss 3.5623944 Test RE 0.01522956413770739 c 1.0197585 k 0.9998957 m 4.9623938\n",
      "68 Train Loss 3.4933848 Test RE 0.01486189210763432 c 0.99677604 k 0.999607 m 4.99674\n",
      "69 Train Loss 3.418951 Test RE 0.014637823623414231 c 1.0083592 k 0.99952734 m 4.9900417\n",
      "70 Train Loss 3.3591266 Test RE 0.014404999879218339 c 1.0234702 k 0.9989835 m 4.977418\n",
      "71 Train Loss 3.2762098 Test RE 0.014221943783482044 c 1.0148445 k 0.9981863 m 4.947533\n",
      "72 Train Loss 3.2448134 Test RE 0.014252587860037866 c 1.009393 k 0.9988879 m 4.9475794\n",
      "73 Train Loss 3.2397027 Test RE 0.014283253094603803 c 1.0124887 k 0.9990781 m 4.9502554\n",
      "74 Train Loss 3.2274795 Test RE 0.014374894657647373 c 1.019551 k 0.9986842 m 4.9440947\n",
      "75 Train Loss 3.1967254 Test RE 0.01434632740946185 c 1.0226222 k 0.9991563 m 4.957491\n",
      "76 Train Loss 3.1658356 Test RE 0.014051042582090187 c 1.0196073 k 0.99953926 m 4.9721093\n",
      "77 Train Loss 3.1353712 Test RE 0.013807241398399605 c 1.0200176 k 0.998603 m 4.975452\n",
      "78 Train Loss 3.0281892 Test RE 0.013271099011323754 c 1.019355 k 0.9983879 m 4.9510646\n",
      "79 Train Loss 2.8867004 Test RE 0.013060237069054561 c 1.0230465 k 0.9999846 m 4.9595118\n",
      "80 Train Loss 2.7392411 Test RE 0.01219939802354289 c 1.018975 k 0.99889576 m 5.0114136\n",
      "81 Train Loss 2.593868 Test RE 0.011682530303375483 c 1.004217 k 0.9997906 m 5.0112724\n",
      "82 Train Loss 2.5195618 Test RE 0.011648109120937469 c 1.0142882 k 1.0003731 m 4.9734473\n",
      "83 Train Loss 2.365471 Test RE 0.011215840314811291 c 1.0244647 k 0.9999622 m 4.95333\n",
      "84 Train Loss 2.134252 Test RE 0.010652494631435392 c 1.0022885 k 1.0007195 m 4.9918346\n",
      "85 Train Loss 2.0587766 Test RE 0.01043779064423643 c 1.0024366 k 1.0000829 m 4.995095\n",
      "86 Train Loss 2.0139253 Test RE 0.010369960737465057 c 1.0098165 k 1.0003133 m 4.9863825\n",
      "87 Train Loss 1.9850147 Test RE 0.010496001656663305 c 1.01021 k 1.0003521 m 4.999096\n",
      "88 Train Loss 1.9756155 Test RE 0.01050742124326705 c 1.0113921 k 1.0000961 m 4.9959273\n",
      "89 Train Loss 1.9575057 Test RE 0.010606218373073942 c 1.0134252 k 1.0002395 m 4.974479\n",
      "90 Train Loss 1.9399936 Test RE 0.010587046094499588 c 1.0077664 k 1.0001357 m 4.9761124\n",
      "91 Train Loss 1.9153142 Test RE 0.010680253992690274 c 1.013223 k 1.0000387 m 4.9760957\n",
      "92 Train Loss 1.8819373 Test RE 0.010755570494799178 c 1.0146521 k 1.0003021 m 4.977316\n",
      "93 Train Loss 1.7999372 Test RE 0.010330159228818254 c 1.0028471 k 0.99967736 m 4.984438\n",
      "94 Train Loss 1.5936143 Test RE 0.009092907761333386 c 1.011999 k 1.0007246 m 5.0105176\n",
      "95 Train Loss 1.4927232 Test RE 0.008402376788757764 c 1.0341945 k 1.0013847 m 4.981923\n",
      "96 Train Loss 1.3428524 Test RE 0.007661612647470371 c 1.00678 k 1.0000312 m 4.9733844\n",
      "97 Train Loss 1.3190777 Test RE 0.007661294344456987 c 1.0017442 k 1.0004578 m 4.967618\n",
      "98 Train Loss 1.1444888 Test RE 0.007765650542832083 c 1.0016923 k 1.0005357 m 4.9811897\n",
      "99 Train Loss 1.0561516 Test RE 0.007481482055147258 c 1.0144206 k 1.0002874 m 4.9853888\n",
      "100 Train Loss 1.0442829 Test RE 0.0074452687455326665 c 1.0147816 k 1.0005087 m 4.9748344\n",
      "101 Train Loss 1.0237606 Test RE 0.007482183352354823 c 1.0133505 k 1.0004022 m 4.9832554\n",
      "102 Train Loss 0.977743 Test RE 0.007067902917888732 c 1.0101523 k 1.0006578 m 4.994025\n",
      "103 Train Loss 0.93771994 Test RE 0.006821308338433371 c 1.0135382 k 1.0003961 m 4.976703\n",
      "104 Train Loss 0.9227966 Test RE 0.006738334145027087 c 1.0151455 k 1.0003818 m 4.977919\n",
      "105 Train Loss 0.9148318 Test RE 0.006595363782050465 c 1.0126587 k 1.0004677 m 4.9757266\n",
      "106 Train Loss 0.8913496 Test RE 0.006534851750445677 c 1.0113031 k 1.0004073 m 4.9679008\n",
      "107 Train Loss 0.8051523 Test RE 0.005737717406541305 c 1.0075796 k 1.0011406 m 4.9943633\n",
      "108 Train Loss 0.78176266 Test RE 0.0054408905913644464 c 1.0070847 k 1.0007522 m 5.0015616\n",
      "109 Train Loss 0.77230716 Test RE 0.005428530845755028 c 1.0050362 k 1.0004016 m 4.9901547\n",
      "110 Train Loss 0.75610405 Test RE 0.005430066869873789 c 1.0058373 k 1.0008107 m 4.9957933\n",
      "111 Train Loss 0.743368 Test RE 0.005401284540745864 c 1.0063484 k 1.0010134 m 5.011044\n",
      "112 Train Loss 0.7235882 Test RE 0.005362730907484705 c 1.002011 k 1.0006518 m 5.00843\n",
      "113 Train Loss 0.720466 Test RE 0.00535633067112199 c 1.0029991 k 1.0008478 m 5.002604\n",
      "114 Train Loss 0.715081 Test RE 0.005337542825202881 c 1.0035884 k 1.0006183 m 5.0030656\n",
      "115 Train Loss 0.7057635 Test RE 0.005354785345869616 c 1.003195 k 1.0006088 m 5.000174\n",
      "116 Train Loss 0.68914104 Test RE 0.005328432493919662 c 1.0037184 k 1.0011741 m 5.0017633\n",
      "117 Train Loss 0.63168967 Test RE 0.00518333792656821 c 0.99410045 k 1.0005462 m 5.0290723\n",
      "118 Train Loss 0.46880665 Test RE 0.0044627494170779375 c 0.9852717 k 1.0017402 m 5.0051837\n",
      "119 Train Loss 0.33226505 Test RE 0.0034252377274047695 c 0.9869054 k 1.001749 m 5.002104\n",
      "120 Train Loss 0.24863017 Test RE 0.0027955296235444853 c 0.9966511 k 0.9998619 m 5.0077796\n",
      "121 Train Loss 0.20727172 Test RE 0.002199505117440886 c 1.0048718 k 1.0003349 m 4.989393\n",
      "122 Train Loss 0.1730237 Test RE 0.0020555063021735816 c 0.9991399 k 1.0004853 m 4.9932384\n",
      "123 Train Loss 0.15200928 Test RE 0.001976069132017596 c 0.99885815 k 1.0003734 m 5.0051346\n",
      "124 Train Loss 0.1429911 Test RE 0.0019193724744789266 c 1.0015615 k 0.99986136 m 4.9960966\n",
      "125 Train Loss 0.1371223 Test RE 0.0019169652693697189 c 1.001049 k 0.99999475 m 4.9976177\n",
      "126 Train Loss 0.13240767 Test RE 0.001864828322660184 c 0.997891 k 1.0001771 m 5.002936\n",
      "127 Train Loss 0.1292941 Test RE 0.0017320950797479597 c 0.99957424 k 1.0001277 m 5.0024104\n",
      "128 Train Loss 0.122298345 Test RE 0.0014946812583666734 c 1.0016478 k 1.0003006 m 5.006503\n",
      "129 Train Loss 0.113299176 Test RE 0.001402053403919796 c 1.000128 k 1.0002835 m 5.0033474\n",
      "130 Train Loss 0.10788961 Test RE 0.0014893950548404192 c 1.0026611 k 1.000261 m 5.0002513\n",
      "131 Train Loss 0.10691342 Test RE 0.0015003591964340892 c 1.0025212 k 1.00009 m 5.000193\n",
      "132 Train Loss 0.10629697 Test RE 0.0014610017408004108 c 1.0006043 k 1.0000947 m 5.0011616\n",
      "133 Train Loss 0.10511474 Test RE 0.0014057077523957873 c 1.0000839 k 1.0000412 m 5.000178\n",
      "134 Train Loss 0.10095305 Test RE 0.0013462760268377438 c 1.0017569 k 0.9999453 m 4.9990287\n",
      "135 Train Loss 0.096481726 Test RE 0.0013550837319710669 c 0.9996172 k 1.0002873 m 5.005576\n",
      "136 Train Loss 0.09319477 Test RE 0.0014070634716462362 c 0.9992125 k 1.0001117 m 5.0022817\n",
      "137 Train Loss 0.09176877 Test RE 0.0014194696070153581 c 0.9999887 k 1.0001035 m 5.0000777\n",
      "138 Train Loss 0.09165823 Test RE 0.0014240141922589955 c 0.9997599 k 1.0001205 m 5.0003223\n",
      "139 Train Loss 0.091505475 Test RE 0.0014369868885012948 c 0.9998333 k 1.0001178 m 5.000903\n",
      "140 Train Loss 0.09102196 Test RE 0.001462963424404808 c 1.0000691 k 1.0001003 m 5.0004478\n",
      "141 Train Loss 0.090459235 Test RE 0.0014475368993844345 c 1.0005527 k 1.0000927 m 4.9996247\n",
      "142 Train Loss 0.09003351 Test RE 0.0014194121664873524 c 1.0009264 k 1.0001143 m 5.001141\n",
      "143 Train Loss 0.08652085 Test RE 0.0013466251961809488 c 1.0003527 k 1.0001708 m 5.004567\n",
      "144 Train Loss 0.07582366 Test RE 0.001168625246432395 c 1.0015492 k 1.0000132 m 4.996791\n",
      "145 Train Loss 0.06444374 Test RE 0.0010622764260307554 c 1.0019819 k 0.9998078 m 4.995718\n",
      "146 Train Loss 0.057552136 Test RE 0.001024524140529808 c 1.001375 k 0.999983 m 4.9983735\n",
      "147 Train Loss 0.05536086 Test RE 0.000959352511913592 c 1.0010364 k 0.9999692 m 4.9960885\n",
      "148 Train Loss 0.054887764 Test RE 0.000943547382830259 c 1.0007571 k 1.0000079 m 4.997649\n",
      "149 Train Loss 0.054518815 Test RE 0.0009426227726779542 c 1.000582 k 0.9999849 m 4.9977846\n",
      "150 Train Loss 0.05431577 Test RE 0.0009359608165744423 c 1.0004663 k 0.99998295 m 4.9973493\n",
      "151 Train Loss 0.054220892 Test RE 0.0009315091233088494 c 1.0005534 k 1.0000038 m 4.9984894\n",
      "152 Train Loss 0.05386521 Test RE 0.000938824352666014 c 1.0002986 k 0.9999826 m 4.9994497\n",
      "153 Train Loss 0.052689824 Test RE 0.0009292237057290935 c 0.999725 k 1.0000027 m 4.99781\n",
      "154 Train Loss 0.051029302 Test RE 0.0009227891106963618 c 1.0000925 k 1.0001587 m 4.9994164\n",
      "155 Train Loss 0.050211184 Test RE 0.0009106643326030509 c 1.0000538 k 1.0000334 m 4.998631\n",
      "156 Train Loss 0.050001632 Test RE 0.0009015332483486536 c 1.000415 k 0.99993527 m 4.9987435\n",
      "157 Train Loss 0.049707968 Test RE 0.0008936681635002889 c 1.0010207 k 0.99998444 m 5.0012627\n",
      "158 Train Loss 0.04925955 Test RE 0.0008688967783087878 c 1.0009328 k 1.0000471 m 5.000164\n",
      "159 Train Loss 0.04888712 Test RE 0.0008528214780598268 c 1.0004046 k 0.9999979 m 4.999017\n",
      "160 Train Loss 0.04877787 Test RE 0.0008545693213829946 c 1.0002197 k 0.99997413 m 4.999618\n",
      "161 Train Loss 0.04871312 Test RE 0.0008570813199849026 c 0.9999533 k 0.99998695 m 4.9993234\n",
      "162 Train Loss 0.04863707 Test RE 0.0008542038327600007 c 1.0001086 k 0.99999124 m 4.9992704\n",
      "163 Train Loss 0.048561353 Test RE 0.0008500581066978401 c 1.0003443 k 0.9999694 m 4.9996753\n",
      "164 Train Loss 0.04838431 Test RE 0.0008464931568490336 c 1.0000982 k 0.9999784 m 5.0003233\n",
      "165 Train Loss 0.04738871 Test RE 0.0008468430242108524 c 0.9994513 k 0.99992704 m 5.0008187\n",
      "166 Train Loss 0.04630032 Test RE 0.0008681941887874725 c 1.0004305 k 0.9998805 m 4.9995365\n",
      "167 Train Loss 0.045571677 Test RE 0.0008796885199397748 c 1.0009464 k 1.0000077 m 5.0008826\n",
      "168 Train Loss 0.04483486 Test RE 0.0009067415977842707 c 1.0010918 k 0.99999994 m 4.998025\n",
      "169 Train Loss 0.044442095 Test RE 0.0009187653504616676 c 1.0011115 k 1.000014 m 4.9982467\n",
      "170 Train Loss 0.04397104 Test RE 0.0009340807463592589 c 1.0005642 k 0.99994254 m 4.9990788\n",
      "171 Train Loss 0.043571185 Test RE 0.0009792478462952359 c 1.0007032 k 0.9999743 m 4.998332\n",
      "172 Train Loss 0.043398134 Test RE 0.000998144954640625 c 1.0008055 k 1.0000323 m 4.9990706\n",
      "173 Train Loss 0.043284778 Test RE 0.0009962563154047657 c 1.0008211 k 1.0000188 m 4.9992323\n",
      "174 Train Loss 0.043189026 Test RE 0.001015748800305779 c 1.0007613 k 1.0000283 m 4.9997554\n",
      "175 Train Loss 0.04305175 Test RE 0.0010384357650974115 c 1.0005677 k 1.0000411 m 4.9997087\n",
      "176 Train Loss 0.04267932 Test RE 0.0010190495434815343 c 1.0003208 k 1.000022 m 4.998694\n",
      "177 Train Loss 0.041404337 Test RE 0.0009620817165781304 c 1.0011029 k 0.9999971 m 4.9996758\n",
      "178 Train Loss 0.04083625 Test RE 0.0009397484851903366 c 1.0008103 k 1.0000141 m 5.0000753\n",
      "179 Train Loss 0.04043059 Test RE 0.000928693265675372 c 1.0000356 k 0.99998087 m 5.000862\n",
      "180 Train Loss 0.040217526 Test RE 0.0009166945210023441 c 0.99995357 k 0.99999964 m 5.0004025\n",
      "181 Train Loss 0.040136337 Test RE 0.000913719967983258 c 1.0004443 k 1.0000187 m 4.999523\n",
      "182 Train Loss 0.040081155 Test RE 0.0009219985593698255 c 1.0005977 k 1.0000021 m 4.9987264\n",
      "183 Train Loss 0.0400033 Test RE 0.0009198373748906916 c 0.99990106 k 0.9999741 m 4.9988227\n",
      "184 Train Loss 0.03988721 Test RE 0.000913241078719254 c 0.9995915 k 1.0000029 m 4.998733\n",
      "185 Train Loss 0.039626766 Test RE 0.0009161301251954699 c 1.0000803 k 1.0000473 m 4.9976106\n",
      "186 Train Loss 0.039413355 Test RE 0.0009100103297268699 c 1.0004078 k 0.99993885 m 4.997966\n",
      "187 Train Loss 0.03916666 Test RE 0.0009036048786632147 c 1.0004183 k 0.99992067 m 4.998901\n",
      "188 Train Loss 0.038880408 Test RE 0.0008961282600824813 c 1.0000116 k 1.0000169 m 4.999577\n",
      "189 Train Loss 0.038218938 Test RE 0.000865094556331393 c 1.0005921 k 1.000051 m 5.001346\n",
      "190 Train Loss 0.03756291 Test RE 0.0008648652214242002 c 1.0011673 k 1.0000818 m 5.0040736\n",
      "191 Train Loss 0.037154295 Test RE 0.0008761172382321218 c 1.0007217 k 1.0000746 m 5.003324\n",
      "192 Train Loss 0.036884725 Test RE 0.0008724972243519371 c 1.0007459 k 1.0000466 m 5.0019217\n",
      "193 Train Loss 0.036735427 Test RE 0.0008557445151756519 c 1.0007625 k 1.000022 m 5.0007105\n",
      "194 Train Loss 0.03663775 Test RE 0.0008524137290284682 c 1.0004743 k 0.9999946 m 4.9995565\n",
      "195 Train Loss 0.036584884 Test RE 0.0008581488476033471 c 1.0006597 k 0.9999797 m 4.9992414\n",
      "196 Train Loss 0.03643894 Test RE 0.0008479453807985375 c 1.0005316 k 0.99995446 m 4.998753\n",
      "197 Train Loss 0.036275513 Test RE 0.00083987465457702 c 1.000015 k 0.99999666 m 4.999525\n",
      "198 Train Loss 0.036101766 Test RE 0.0008532716361506383 c 1.0005625 k 1.0000367 m 4.9988785\n",
      "199 Train Loss 0.03595117 Test RE 0.0008470291307798184 c 1.0002939 k 0.9999689 m 4.9977293\n",
      "Training time: 53.72\n",
      "Training time: 53.72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 752.5333 Test RE 0.23899864732519432 c 0.13697153 k 1.0547489 m 0.0033110126\n",
      "1 Train Loss 489.94916 Test RE 0.21727627842672184 c 0.13494873 k 1.0147638 m 0.003152717\n",
      "2 Train Loss 478.06757 Test RE 0.21591372752711743 c 0.13973804 k 1.0163968 m 0.002996819\n",
      "3 Train Loss 469.2147 Test RE 0.21046459029906087 c 0.16371176 k 1.0126618 m 0.0027713473\n",
      "4 Train Loss 455.3517 Test RE 0.20807371128601418 c 0.1842131 k 1.0157597 m 0.0025612994\n",
      "5 Train Loss 416.59882 Test RE 0.18528135277673008 c 0.2756759 k 1.0028359 m 0.00036007632\n",
      "6 Train Loss 354.28983 Test RE 0.15996259796625611 c 0.3988012 k 1.0061318 m -0.0013998197\n",
      "7 Train Loss 315.90485 Test RE 0.1508562217742671 c 0.44011033 k 1.0000205 m 0.0043653743\n",
      "8 Train Loss 262.59406 Test RE 0.11385128901756639 c 0.7223089 k 0.99303997 m 0.107378736\n",
      "9 Train Loss 236.0469 Test RE 0.10672336854870021 c 0.8379837 k 0.98316157 m 0.16815625\n",
      "10 Train Loss 215.45499 Test RE 0.0969901592222746 c 0.9605016 k 0.9807272 m 0.2469978\n",
      "11 Train Loss 190.13022 Test RE 0.09531782204992431 c 1.1870837 k 0.9729538 m 0.4600391\n",
      "12 Train Loss 172.69078 Test RE 0.08430630884849503 c 1.3228303 k 0.9763884 m 0.663522\n",
      "13 Train Loss 156.96777 Test RE 0.08211998013255693 c 1.3901702 k 0.9670953 m 0.8838366\n",
      "14 Train Loss 124.62602 Test RE 0.08267932782587105 c 1.6470882 k 0.98239136 m 1.5311593\n",
      "15 Train Loss 117.19362 Test RE 0.07954150367444655 c 1.7175751 k 0.9721442 m 1.637113\n",
      "16 Train Loss 111.87362 Test RE 0.08132896627033642 c 1.7764975 k 0.9738134 m 1.786799\n",
      "17 Train Loss 107.644516 Test RE 0.07915301526481533 c 1.7721026 k 0.9820421 m 1.8245689\n",
      "18 Train Loss 105.7664 Test RE 0.07789066547176808 c 1.8 k 0.9746759 m 1.9096432\n",
      "19 Train Loss 101.64264 Test RE 0.07688752277053282 c 1.8410295 k 0.9734095 m 2.2406747\n",
      "20 Train Loss 94.48753 Test RE 0.07553830237471279 c 1.7561553 k 0.9827882 m 2.5526235\n",
      "21 Train Loss 79.27243 Test RE 0.0646753263420497 c 1.6811736 k 0.9762148 m 3.2051113\n",
      "22 Train Loss 72.97258 Test RE 0.0621887689162147 c 1.6898677 k 0.9830183 m 3.3231199\n",
      "23 Train Loss 66.82202 Test RE 0.06364246013399673 c 1.6320626 k 0.9856722 m 3.511764\n",
      "24 Train Loss 56.787434 Test RE 0.06141390259730633 c 1.4953072 k 0.9871259 m 3.9236615\n",
      "25 Train Loss 42.929787 Test RE 0.05323931480881392 c 1.4530948 k 0.99108565 m 4.5158734\n",
      "26 Train Loss 41.70397 Test RE 0.053036324193498546 c 1.4297608 k 0.9934695 m 4.5445776\n",
      "27 Train Loss 37.406292 Test RE 0.050787480620803245 c 1.3563263 k 0.99929994 m 4.575824\n",
      "28 Train Loss 30.52253 Test RE 0.04482208979816535 c 1.206597 k 0.98651284 m 4.5404367\n",
      "29 Train Loss 24.828114 Test RE 0.04047949627017568 c 1.1761367 k 0.99540144 m 4.657799\n",
      "30 Train Loss 20.419102 Test RE 0.03564074795591042 c 1.1102264 k 0.99865174 m 4.588147\n",
      "31 Train Loss 16.955965 Test RE 0.032438423420842855 c 1.0640864 k 0.99405295 m 4.775967\n",
      "32 Train Loss 15.134348 Test RE 0.030634703991119203 c 1.0900387 k 0.999412 m 4.9445004\n",
      "33 Train Loss 14.285162 Test RE 0.028805999939097892 c 1.0874186 k 0.9996042 m 5.0223513\n",
      "34 Train Loss 13.430472 Test RE 0.027753928104215665 c 1.0625508 k 0.9977504 m 5.086603\n",
      "35 Train Loss 12.481258 Test RE 0.026587666493440187 c 1.0649331 k 0.99901116 m 5.053604\n",
      "36 Train Loss 11.996725 Test RE 0.02636976376858243 c 1.0861923 k 0.99990433 m 5.0221667\n",
      "37 Train Loss 11.548006 Test RE 0.025367931096390132 c 1.0851117 k 0.99925816 m 4.993465\n",
      "38 Train Loss 11.393221 Test RE 0.025302695324190053 c 1.0695719 k 0.9988045 m 4.9153533\n",
      "39 Train Loss 11.333927 Test RE 0.025301675880149983 c 1.0656546 k 0.99760514 m 4.8787684\n",
      "40 Train Loss 10.890003 Test RE 0.0251353722956329 c 1.0662385 k 0.997833 m 4.798909\n",
      "41 Train Loss 10.323847 Test RE 0.02532284405316484 c 1.043061 k 0.9981949 m 4.8486934\n",
      "42 Train Loss 9.978715 Test RE 0.024745261855101494 c 1.0201085 k 0.9975873 m 4.863784\n",
      "43 Train Loss 9.856329 Test RE 0.024690310957723744 c 1.0321513 k 0.9998473 m 4.8854685\n",
      "44 Train Loss 9.655351 Test RE 0.024704759474949215 c 1.0311096 k 0.99940836 m 4.9219785\n",
      "45 Train Loss 9.559881 Test RE 0.024499384373830133 c 1.020013 k 0.9985766 m 4.9221654\n",
      "46 Train Loss 9.458868 Test RE 0.024240346714543254 c 1.0310041 k 0.9992896 m 4.9177437\n",
      "47 Train Loss 9.354994 Test RE 0.024373110877660368 c 1.0669607 k 0.9989213 m 4.88878\n",
      "48 Train Loss 9.171791 Test RE 0.024510901275622957 c 1.0749387 k 0.99771273 m 4.8286314\n",
      "49 Train Loss 8.927992 Test RE 0.024055740156163654 c 1.0667182 k 0.9979616 m 4.812553\n",
      "50 Train Loss 8.711883 Test RE 0.024052603975354157 c 1.0997086 k 0.99823004 m 4.827187\n",
      "51 Train Loss 8.585735 Test RE 0.023834410590148243 c 1.0993581 k 0.99653053 m 4.809242\n",
      "52 Train Loss 8.092142 Test RE 0.02276757700548274 c 1.0684351 k 0.9966273 m 4.8251667\n",
      "53 Train Loss 7.6743603 Test RE 0.02252859113818276 c 1.0662025 k 0.99875814 m 4.936879\n",
      "54 Train Loss 7.5958967 Test RE 0.022515488708755825 c 1.0595196 k 0.99856526 m 4.9460955\n",
      "55 Train Loss 7.3577623 Test RE 0.021880962702935356 c 1.0240763 k 0.99805564 m 4.9121156\n",
      "56 Train Loss 6.820389 Test RE 0.021630296253800134 c 1.0487938 k 0.99794376 m 4.872324\n",
      "57 Train Loss 6.497024 Test RE 0.02150878766116536 c 1.0453465 k 0.9972675 m 4.8678584\n",
      "58 Train Loss 6.4523625 Test RE 0.021425323565768182 c 1.0504388 k 0.9975754 m 4.8644986\n",
      "59 Train Loss 6.3673663 Test RE 0.02121466192592225 c 1.0509177 k 0.99901384 m 4.890161\n",
      "60 Train Loss 6.1071177 Test RE 0.02081105127814673 c 1.0453188 k 0.99777234 m 4.908389\n",
      "61 Train Loss 6.0528054 Test RE 0.020650182194087444 c 1.043826 k 0.9982522 m 4.9000254\n",
      "62 Train Loss 6.014148 Test RE 0.020599481275830927 c 1.0460546 k 0.9986158 m 4.8957148\n",
      "63 Train Loss 5.951231 Test RE 0.02053001684886741 c 1.0398948 k 0.9978407 m 4.910722\n",
      "64 Train Loss 5.74249 Test RE 0.020054850748579833 c 1.0308377 k 0.9984934 m 4.934019\n",
      "65 Train Loss 5.552572 Test RE 0.01985793366450539 c 1.0408285 k 0.9991824 m 4.8987927\n",
      "66 Train Loss 5.493621 Test RE 0.019788055563933017 c 1.0323981 k 0.99839634 m 4.881725\n",
      "67 Train Loss 5.421841 Test RE 0.019549486573388758 c 1.0295274 k 0.9979426 m 4.9107814\n",
      "68 Train Loss 5.1408257 Test RE 0.018872325485895868 c 1.0291413 k 0.99751854 m 4.9152184\n",
      "69 Train Loss 4.894652 Test RE 0.01849577291772535 c 1.0463151 k 0.9986814 m 4.9412208\n",
      "70 Train Loss 4.449114 Test RE 0.017603396653895403 c 1.0297612 k 0.9999184 m 4.9551673\n",
      "71 Train Loss 4.0219555 Test RE 0.01675930338572483 c 1.013831 k 1.0005342 m 4.9845357\n",
      "72 Train Loss 3.9086258 Test RE 0.016588208425858373 c 1.0223172 k 0.99924856 m 4.97872\n",
      "73 Train Loss 3.7492537 Test RE 0.016038593989918346 c 1.0115137 k 0.998093 m 4.9463177\n",
      "74 Train Loss 3.6736724 Test RE 0.015793803969964253 c 1.0138769 k 0.9996325 m 4.966029\n",
      "75 Train Loss 3.5580862 Test RE 0.015437353362602456 c 1.015036 k 0.99993694 m 4.965196\n",
      "76 Train Loss 3.4949708 Test RE 0.015169299785854412 c 1.0219051 k 0.9986012 m 4.9440427\n",
      "77 Train Loss 3.4705849 Test RE 0.015009305005579001 c 1.0197556 k 0.9985242 m 4.947631\n",
      "78 Train Loss 3.424086 Test RE 0.014928490997999776 c 1.0129937 k 0.9995093 m 4.9606996\n",
      "79 Train Loss 3.3416772 Test RE 0.014706700357966928 c 1.0150536 k 0.9989282 m 4.955977\n",
      "80 Train Loss 3.2757015 Test RE 0.01446254825851986 c 1.009155 k 0.9996126 m 4.9919243\n",
      "81 Train Loss 3.1912546 Test RE 0.014365818119713207 c 1.0104969 k 0.9999281 m 4.9845667\n",
      "82 Train Loss 3.1293817 Test RE 0.014154978402639141 c 1.0040885 k 0.9992162 m 4.953289\n",
      "83 Train Loss 2.9210968 Test RE 0.013414036396326125 c 0.9925098 k 1.001232 m 4.990649\n",
      "84 Train Loss 2.857314 Test RE 0.013286526447086514 c 0.9960075 k 0.99986213 m 4.9791656\n",
      "85 Train Loss 2.6775637 Test RE 0.01263566685023447 c 1.012749 k 0.9989388 m 4.941824\n",
      "86 Train Loss 2.3908262 Test RE 0.010622133684033643 c 1.0081419 k 0.9989426 m 4.9300666\n",
      "87 Train Loss 2.213345 Test RE 0.009585642291007137 c 1.0113916 k 0.9988725 m 4.905798\n",
      "88 Train Loss 2.1464062 Test RE 0.009745153617225102 c 1.0111135 k 0.999515 m 4.929374\n",
      "89 Train Loss 2.0727198 Test RE 0.009554631789937255 c 1.0278349 k 0.99830973 m 4.9109344\n",
      "90 Train Loss 2.0115278 Test RE 0.008921583459825584 c 1.0388799 k 0.99921024 m 4.8808546\n",
      "91 Train Loss 1.7848303 Test RE 0.006585898390727964 c 1.0203496 k 0.9997607 m 4.887279\n",
      "92 Train Loss 1.6508248 Test RE 0.006104553477432821 c 1.007225 k 0.99846005 m 4.915803\n",
      "93 Train Loss 1.6163512 Test RE 0.006088806089751879 c 1.00636 k 1.0003332 m 4.940001\n",
      "94 Train Loss 1.4995984 Test RE 0.0060060771765790225 c 1.0218036 k 1.0008764 m 4.9627028\n",
      "95 Train Loss 1.3785877 Test RE 0.005644249844792205 c 1.0211791 k 0.9989275 m 4.987653\n",
      "96 Train Loss 1.2741315 Test RE 0.005341705418063371 c 1.0074607 k 0.99982876 m 4.9816713\n",
      "97 Train Loss 1.1927395 Test RE 0.005046117798073455 c 1.0044659 k 1.0001726 m 4.9417515\n",
      "98 Train Loss 1.1458629 Test RE 0.004930519125938009 c 1.0103024 k 1.0001439 m 4.9636736\n",
      "99 Train Loss 1.1139203 Test RE 0.0046947291075147704 c 1.0047568 k 1.0002601 m 4.988504\n",
      "100 Train Loss 1.0775743 Test RE 0.004404051998026208 c 0.99258524 k 0.99924296 m 4.9929276\n",
      "101 Train Loss 0.95830697 Test RE 0.004055221121176907 c 0.988221 k 1.0008132 m 5.0342574\n",
      "102 Train Loss 0.8150187 Test RE 0.004720409084709116 c 1.0017239 k 1.0007144 m 5.0232563\n",
      "103 Train Loss 0.74265885 Test RE 0.00449045019478309 c 0.99075407 k 1.0000156 m 4.990951\n",
      "104 Train Loss 0.70374817 Test RE 0.0038821398462768222 c 0.98999834 k 0.9999109 m 4.9699483\n",
      "105 Train Loss 0.6857129 Test RE 0.0034739914581798873 c 0.9936061 k 1.0000385 m 4.977875\n",
      "106 Train Loss 0.65070677 Test RE 0.0035015341306190227 c 0.996584 k 1.0008919 m 4.9806623\n",
      "107 Train Loss 0.5770863 Test RE 0.00350075907377131 c 1.0004431 k 1.000433 m 4.9830647\n",
      "108 Train Loss 0.5599035 Test RE 0.0033213528838322566 c 1.0059214 k 0.9999524 m 4.984412\n",
      "109 Train Loss 0.55086976 Test RE 0.003438579662831816 c 1.0057555 k 1.0003507 m 4.984748\n",
      "110 Train Loss 0.545945 Test RE 0.003534051163791819 c 1.0055463 k 1.0001276 m 4.986386\n",
      "111 Train Loss 0.5388131 Test RE 0.003634707120399263 c 1.0067585 k 0.99960965 m 4.9749703\n",
      "112 Train Loss 0.5170275 Test RE 0.0037640370878291884 c 1.0000902 k 1.0000805 m 4.9725647\n",
      "113 Train Loss 0.4695173 Test RE 0.0036434923806871267 c 1.0041745 k 1.000167 m 4.975488\n",
      "114 Train Loss 0.460001 Test RE 0.00355139441776838 c 1.0094196 k 0.9999039 m 4.9646072\n",
      "115 Train Loss 0.45422268 Test RE 0.0034507737043727427 c 1.0053481 k 1.0002508 m 4.9717264\n",
      "116 Train Loss 0.44096848 Test RE 0.0031745287387639825 c 1.0019473 k 1.0005201 m 4.983121\n",
      "117 Train Loss 0.42874184 Test RE 0.0029119067226644818 c 1.0030185 k 1.000048 m 4.980789\n",
      "118 Train Loss 0.41611832 Test RE 0.0028581797764312407 c 1.0011545 k 1.0002497 m 4.987659\n",
      "119 Train Loss 0.39314568 Test RE 0.00290516838104497 c 0.9989416 k 1.0004401 m 4.9894905\n",
      "120 Train Loss 0.37411162 Test RE 0.002885084203895147 c 0.99991345 k 1.000035 m 4.982977\n",
      "121 Train Loss 0.36312044 Test RE 0.002721374784054786 c 0.998596 k 1.0002565 m 4.9867463\n",
      "122 Train Loss 0.3545833 Test RE 0.002703473826153923 c 1.000617 k 1.0005357 m 4.984907\n",
      "123 Train Loss 0.34218115 Test RE 0.002690717585077893 c 1.0019943 k 0.9998736 m 4.9896145\n",
      "124 Train Loss 0.32708812 Test RE 0.002603533501027447 c 0.99715656 k 0.9996723 m 5.004098\n",
      "125 Train Loss 0.3059823 Test RE 0.0024525484761953424 c 0.99877673 k 1.0007313 m 5.0015397\n",
      "126 Train Loss 0.297065 Test RE 0.002416018421876376 c 1.0045637 k 1.0005604 m 4.9981318\n",
      "127 Train Loss 0.2932048 Test RE 0.0023680473182068743 c 1.0012931 k 1.0004176 m 5.0016212\n",
      "128 Train Loss 0.29029104 Test RE 0.0023045658661472704 c 1.0003382 k 1.0004178 m 4.9967084\n",
      "129 Train Loss 0.28924063 Test RE 0.0022783090657480195 c 1.0005352 k 1.0002258 m 4.9964886\n",
      "130 Train Loss 0.28739953 Test RE 0.002299098924381128 c 1.0005697 k 1.0003 m 4.9988675\n",
      "131 Train Loss 0.28559172 Test RE 0.0023185658572691375 c 1.0026472 k 1.0003197 m 4.992681\n",
      "132 Train Loss 0.28464508 Test RE 0.0023282246195390367 c 1.0036665 k 1.0001795 m 4.9927487\n",
      "133 Train Loss 0.28411055 Test RE 0.0023580162530091203 c 1.0034288 k 1.0002065 m 4.9940596\n",
      "134 Train Loss 0.28338867 Test RE 0.0023761037917604294 c 1.0038117 k 1.0002804 m 4.994381\n",
      "135 Train Loss 0.28122342 Test RE 0.0024434821917533457 c 1.0055623 k 1.000175 m 4.9930906\n",
      "136 Train Loss 0.2776596 Test RE 0.0024388107453465913 c 1.005509 k 0.9999308 m 4.9901166\n",
      "137 Train Loss 0.27293873 Test RE 0.002448715108305138 c 1.0063287 k 1.000046 m 4.9871793\n",
      "138 Train Loss 0.2632213 Test RE 0.0023299957426660563 c 1.0081342 k 1.0003955 m 4.9926953\n",
      "139 Train Loss 0.25355142 Test RE 0.0020747234049377566 c 1.0031377 k 1.0002571 m 4.995516\n",
      "140 Train Loss 0.25039458 Test RE 0.0019715970296067696 c 1.0011092 k 1.0000471 m 4.997984\n",
      "141 Train Loss 0.24856605 Test RE 0.0019860598965930534 c 1.0022327 k 1.0000358 m 4.995241\n",
      "142 Train Loss 0.2469455 Test RE 0.001980683797701655 c 1.0031677 k 1.0000632 m 4.989396\n",
      "143 Train Loss 0.24250396 Test RE 0.001962571433687001 c 1.0051686 k 1.0000024 m 4.9835706\n",
      "144 Train Loss 0.23524696 Test RE 0.0018122471859925542 c 1.0010997 k 0.99991155 m 4.9948926\n",
      "145 Train Loss 0.23341489 Test RE 0.0017377121417716055 c 1.0002359 k 1.0000013 m 4.998811\n",
      "146 Train Loss 0.23135349 Test RE 0.0017498221066130437 c 1.0008942 k 0.9999068 m 4.9975348\n",
      "147 Train Loss 0.2291183 Test RE 0.0017591292556578804 c 0.9995016 k 0.99990934 m 4.9986353\n",
      "148 Train Loss 0.22700363 Test RE 0.0017984049699308273 c 0.9990372 k 1.0000973 m 4.997071\n",
      "149 Train Loss 0.22379507 Test RE 0.0018627176342843569 c 1.0000317 k 1.0000437 m 4.994298\n",
      "150 Train Loss 0.22213548 Test RE 0.0018203244476865746 c 0.9980607 k 0.99980915 m 4.9957933\n",
      "151 Train Loss 0.21889837 Test RE 0.0017779698801470723 c 0.9973521 k 0.99957424 m 4.99474\n",
      "152 Train Loss 0.21397331 Test RE 0.0017359927640833385 c 0.9996009 k 0.9998216 m 4.990684\n",
      "153 Train Loss 0.20771463 Test RE 0.0016082970859504064 c 0.99728745 k 1.000109 m 4.9917884\n",
      "154 Train Loss 0.20338582 Test RE 0.0016236298298379706 c 1.000912 k 0.9999478 m 4.990447\n",
      "155 Train Loss 0.20217252 Test RE 0.001620237255253931 c 1.0025904 k 0.99993277 m 4.992643\n",
      "156 Train Loss 0.20189553 Test RE 0.0015928329036768957 c 1.002456 k 0.999919 m 4.9949074\n",
      "157 Train Loss 0.2017233 Test RE 0.0015922349737778922 c 1.0026684 k 0.9998983 m 4.994858\n",
      "158 Train Loss 0.20145199 Test RE 0.0015860517956444013 c 1.0025569 k 0.9998416 m 4.9946074\n",
      "159 Train Loss 0.20075898 Test RE 0.001533661084189914 c 1.0028844 k 0.9998429 m 4.994816\n",
      "160 Train Loss 0.19965856 Test RE 0.0015123448508338997 c 1.0020524 k 0.99990517 m 4.9936585\n",
      "161 Train Loss 0.19829756 Test RE 0.0015696779333606514 c 1.0003358 k 0.9999719 m 4.996019\n",
      "162 Train Loss 0.1961206 Test RE 0.0015946632845488236 c 1.0013734 k 1.0000117 m 5.0007553\n",
      "163 Train Loss 0.19241783 Test RE 0.0015499222144092796 c 1.0014389 k 0.9999316 m 4.995991\n",
      "164 Train Loss 0.18250023 Test RE 0.0015740379343534858 c 1.0013803 k 0.9996178 m 4.98989\n",
      "165 Train Loss 0.17455368 Test RE 0.0014589660697183955 c 0.99971735 k 0.99981236 m 4.987523\n",
      "166 Train Loss 0.17091003 Test RE 0.0014897105792769883 c 0.99769646 k 1.0002445 m 4.991006\n",
      "167 Train Loss 0.16501048 Test RE 0.0015082975892806675 c 0.99743026 k 1.0003383 m 5.0012374\n",
      "168 Train Loss 0.15784797 Test RE 0.001447430929795148 c 1.0002877 k 0.99980754 m 4.998241\n",
      "169 Train Loss 0.14003006 Test RE 0.0014348084697472865 c 1.0009266 k 0.9998508 m 4.9863763\n",
      "170 Train Loss 0.12994112 Test RE 0.001431289955356128 c 1.0035661 k 0.99974847 m 4.986619\n",
      "171 Train Loss 0.11998371 Test RE 0.0013264717445532102 c 1.0014 k 0.99987835 m 4.9938874\n",
      "172 Train Loss 0.11355826 Test RE 0.0012878575186838167 c 0.995489 k 1.0000967 m 4.995581\n",
      "173 Train Loss 0.107234724 Test RE 0.0013330843194686204 c 0.99927205 k 0.99977916 m 4.9922943\n",
      "174 Train Loss 0.104569554 Test RE 0.0013858605840165216 c 1.0011199 k 1.0000668 m 4.9980016\n",
      "175 Train Loss 0.10393332 Test RE 0.0013974414363820734 c 1.000891 k 1.0000591 m 5.0005856\n",
      "176 Train Loss 0.10249905 Test RE 0.0014308851705760028 c 1.0014385 k 1.0000378 m 4.9977684\n",
      "177 Train Loss 0.10197323 Test RE 0.0014642783402188067 c 1.0009131 k 1.0001019 m 4.9977612\n",
      "178 Train Loss 0.10134126 Test RE 0.0014994803850514097 c 1.0006921 k 1.0000147 m 4.9971294\n",
      "179 Train Loss 0.10073224 Test RE 0.0015176459759032482 c 1.0004728 k 1.0000255 m 4.9959693\n",
      "180 Train Loss 0.099987224 Test RE 0.0015517850884264983 c 0.99993986 k 1.0001088 m 4.997182\n",
      "181 Train Loss 0.098922625 Test RE 0.0015839597747624153 c 1.0004927 k 1.0000563 m 4.9972386\n",
      "182 Train Loss 0.09813364 Test RE 0.0016280220970467374 c 1.0007612 k 1.0000154 m 4.995561\n",
      "183 Train Loss 0.096396424 Test RE 0.0016628066471474985 c 1.0014461 k 1.0001398 m 4.9962277\n",
      "184 Train Loss 0.09486753 Test RE 0.001676079394688206 c 1.0006096 k 1.0002092 m 4.99769\n",
      "185 Train Loss 0.09145941 Test RE 0.0017163868508838628 c 0.9996389 k 1.000051 m 4.995901\n",
      "186 Train Loss 0.08876339 Test RE 0.0016900587465635151 c 1.0011934 k 1.0000762 m 4.9933133\n",
      "187 Train Loss 0.08801877 Test RE 0.001666790653328388 c 1.0019488 k 1.0000602 m 4.9934163\n",
      "188 Train Loss 0.08748326 Test RE 0.0016577445196266658 c 1.000677 k 1.0000656 m 4.9952188\n",
      "189 Train Loss 0.087216556 Test RE 0.0016308272017135266 c 1.0004907 k 1.0000662 m 4.995815\n",
      "190 Train Loss 0.08574231 Test RE 0.0015621955472664832 c 1.0022602 k 0.99997795 m 4.9957476\n",
      "191 Train Loss 0.083306015 Test RE 0.0014945628876973328 c 1.0012268 k 0.9999855 m 4.9919415\n",
      "192 Train Loss 0.081627406 Test RE 0.0014556348007935562 c 0.99975944 k 1.0000178 m 4.9939127\n",
      "193 Train Loss 0.081241935 Test RE 0.0014562407145855788 c 1.0009342 k 0.99996215 m 4.994813\n",
      "194 Train Loss 0.08113251 Test RE 0.0014456599754364573 c 1.0010144 k 1.0000104 m 4.996119\n",
      "195 Train Loss 0.08100805 Test RE 0.0014403993713434883 c 1.0008329 k 1.0000418 m 4.9963646\n",
      "196 Train Loss 0.08071388 Test RE 0.0014547764975364399 c 1.0008053 k 1.0000043 m 4.9963164\n",
      "197 Train Loss 0.080646515 Test RE 0.0014559765606865932 c 1.0008454 k 1.0000051 m 4.9976625\n",
      "198 Train Loss 0.080422044 Test RE 0.0014541009837037242 c 1.0008428 k 1.0000778 m 5.0005183\n",
      "199 Train Loss 0.07998115 Test RE 0.00146677531633976 c 1.0008485 k 1.0000515 m 4.998536\n",
      "Training time: 53.09\n",
      "Training time: 53.09\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 593.47565 Test RE 0.23524168822241961 c 0.06558466 k 0.9560231 m -0.0018421046\n",
      "1 Train Loss 491.7363 Test RE 0.21992709589198725 c 0.059212714 k 1.0187474 m -0.0016679149\n",
      "2 Train Loss 487.2103 Test RE 0.21778297476884373 c 0.05882637 k 1.0162854 m -0.0016401224\n",
      "3 Train Loss 445.5115 Test RE 0.20403360828112266 c 0.10912165 k 1.0125144 m -0.0024765276\n",
      "4 Train Loss 382.7941 Test RE 0.17988666565553052 c 0.14373752 k 1.0065507 m -0.0027139154\n",
      "5 Train Loss 331.87607 Test RE 0.14950716402989075 c 0.19940718 k 1.004028 m -0.0002718169\n",
      "6 Train Loss 312.17825 Test RE 0.1452902520489066 c 0.2605725 k 0.99582624 m 0.017642103\n",
      "7 Train Loss 253.35617 Test RE 0.11072807786857708 c 0.6922556 k 0.996027 m 0.16441056\n",
      "8 Train Loss 219.6886 Test RE 0.10513747936453734 c 0.9562706 k 0.9710458 m 0.2780558\n",
      "9 Train Loss 211.16162 Test RE 0.10304846418767602 c 1.0871025 k 0.97678834 m 0.35028347\n",
      "10 Train Loss 197.42116 Test RE 0.10126321001237447 c 1.3636153 k 0.9809706 m 0.5648663\n",
      "11 Train Loss 186.75142 Test RE 0.10179748476280992 c 1.6688887 k 0.9740421 m 0.87511706\n",
      "12 Train Loss 176.79575 Test RE 0.09677270903539036 c 1.799257 k 0.9875346 m 1.0835968\n",
      "13 Train Loss 164.20755 Test RE 0.09562704700688238 c 1.870186 k 0.9757209 m 1.2292581\n",
      "14 Train Loss 160.3013 Test RE 0.09211583859165622 c 1.9324287 k 0.96718293 m 1.2948564\n",
      "15 Train Loss 151.77948 Test RE 0.09078579677167353 c 2.0657682 k 0.98828846 m 1.5279012\n",
      "16 Train Loss 142.12714 Test RE 0.08765167149337395 c 2.1418178 k 0.9772722 m 1.7366425\n",
      "17 Train Loss 134.45798 Test RE 0.08170356034988395 c 2.2103508 k 0.9679808 m 1.9979633\n",
      "18 Train Loss 124.08048 Test RE 0.08220063167632356 c 2.1773133 k 0.97940814 m 2.300161\n",
      "19 Train Loss 103.67206 Test RE 0.0850063166493043 c 1.8838568 k 0.9820415 m 2.5091662\n",
      "20 Train Loss 91.29982 Test RE 0.0775790744125864 c 1.7671694 k 0.9782636 m 2.7872906\n",
      "21 Train Loss 88.57647 Test RE 0.07628985310349395 c 1.7272668 k 0.9875918 m 2.9589987\n",
      "22 Train Loss 83.78737 Test RE 0.07279719439830924 c 1.7933317 k 0.988744 m 3.203926\n",
      "23 Train Loss 80.251495 Test RE 0.06841263949928356 c 1.8512249 k 0.9753599 m 3.3478782\n",
      "24 Train Loss 72.16777 Test RE 0.06418124323814627 c 1.6263393 k 0.9864756 m 3.581356\n",
      "25 Train Loss 69.19792 Test RE 0.06102090841026382 c 1.5615481 k 0.986117 m 3.564762\n",
      "26 Train Loss 63.765038 Test RE 0.05406338015365126 c 1.4902877 k 0.98133725 m 3.4426947\n",
      "27 Train Loss 60.155952 Test RE 0.05378217081984219 c 1.3375055 k 0.9889911 m 3.3918238\n",
      "28 Train Loss 55.280632 Test RE 0.05160116868328612 c 1.1823964 k 0.98355365 m 3.579536\n",
      "29 Train Loss 45.924343 Test RE 0.04554755257064405 c 1.2370167 k 0.9873157 m 3.858317\n",
      "30 Train Loss 41.288788 Test RE 0.04627641685374156 c 1.2705449 k 0.9957321 m 3.9349446\n",
      "31 Train Loss 39.64781 Test RE 0.04755178970167266 c 1.3050731 k 0.9885191 m 3.9255464\n",
      "32 Train Loss 38.99813 Test RE 0.046931234032662056 c 1.3347291 k 0.9887885 m 3.9380383\n",
      "33 Train Loss 38.310207 Test RE 0.045081893855639196 c 1.3078314 k 0.9912909 m 4.050498\n",
      "34 Train Loss 38.148056 Test RE 0.044526199549928556 c 1.3011127 k 0.9894174 m 4.0660753\n",
      "35 Train Loss 37.76982 Test RE 0.04330634971342686 c 1.2611449 k 0.9905759 m 4.0532284\n",
      "36 Train Loss 37.66284 Test RE 0.043175424097144706 c 1.2384315 k 0.9912939 m 4.0541716\n",
      "37 Train Loss 37.325813 Test RE 0.042446219747702754 c 1.2372221 k 0.99082285 m 4.0665307\n",
      "38 Train Loss 37.169792 Test RE 0.042146466583589046 c 1.2425983 k 0.99162936 m 4.050389\n",
      "39 Train Loss 36.77067 Test RE 0.041953296386406984 c 1.2124008 k 0.9939261 m 4.041412\n",
      "40 Train Loss 34.213303 Test RE 0.03952993396447728 c 1.1653599 k 0.98794514 m 4.064999\n",
      "41 Train Loss 32.876854 Test RE 0.03669899424623392 c 1.1579454 k 0.9932218 m 4.0947075\n",
      "42 Train Loss 32.350212 Test RE 0.03749158697358822 c 1.1495174 k 0.99479884 m 4.1106515\n",
      "43 Train Loss 31.753962 Test RE 0.037083123750716145 c 1.1647999 k 0.9920867 m 4.1192613\n",
      "44 Train Loss 31.431002 Test RE 0.03610575800974571 c 1.1671336 k 0.9927483 m 4.1460915\n",
      "45 Train Loss 30.936142 Test RE 0.03578054649443357 c 1.1528329 k 0.9911419 m 4.1662245\n",
      "46 Train Loss 29.40403 Test RE 0.03450645341459721 c 1.1704398 k 0.99166167 m 4.177808\n",
      "47 Train Loss 27.69693 Test RE 0.032632085727732116 c 1.2057384 k 0.9956132 m 4.2044396\n",
      "48 Train Loss 25.02369 Test RE 0.03191832970265669 c 1.2136697 k 0.99180704 m 4.1981077\n",
      "49 Train Loss 23.678787 Test RE 0.03403515453008426 c 1.2346559 k 0.9926737 m 4.1582484\n",
      "50 Train Loss 22.618427 Test RE 0.03290137109552347 c 1.1993127 k 0.9930639 m 4.2346783\n",
      "51 Train Loss 22.15949 Test RE 0.03132566811749926 c 1.2302103 k 0.9916352 m 4.241231\n",
      "52 Train Loss 21.751324 Test RE 0.030712424155285443 c 1.2500595 k 0.9937383 m 4.2374015\n",
      "53 Train Loss 20.54752 Test RE 0.02894295793131336 c 1.2181501 k 0.9961379 m 4.294664\n",
      "54 Train Loss 19.384886 Test RE 0.027720912206678865 c 1.2178037 k 0.988624 m 4.3806853\n",
      "55 Train Loss 18.584623 Test RE 0.026506100601506478 c 1.2634969 k 0.99284434 m 4.4423237\n",
      "56 Train Loss 18.053959 Test RE 0.026629995349440716 c 1.2291565 k 0.99531066 m 4.476886\n",
      "57 Train Loss 17.448105 Test RE 0.026571588127215544 c 1.1946514 k 0.9937126 m 4.4673877\n",
      "58 Train Loss 17.0287 Test RE 0.024635953663503102 c 1.1967437 k 0.99562126 m 4.5330815\n",
      "59 Train Loss 16.077856 Test RE 0.022537543752127808 c 1.1526679 k 0.99252784 m 4.6545706\n",
      "60 Train Loss 15.190112 Test RE 0.02090935387256028 c 1.108154 k 0.99538714 m 4.7703924\n",
      "61 Train Loss 14.832891 Test RE 0.019478030401176596 c 1.0812774 k 0.9988983 m 4.7865696\n",
      "62 Train Loss 14.408576 Test RE 0.019156338349395806 c 1.0801016 k 0.9973251 m 4.8066077\n",
      "63 Train Loss 14.132084 Test RE 0.01866137883604889 c 1.0876237 k 0.9978517 m 4.8522058\n",
      "64 Train Loss 14.003226 Test RE 0.01888531856278903 c 1.0908399 k 0.99728864 m 4.836361\n",
      "65 Train Loss 13.754028 Test RE 0.018497614113770055 c 1.1152991 k 0.99818796 m 4.81082\n",
      "66 Train Loss 13.543751 Test RE 0.017739705080520956 c 1.0811013 k 0.9985613 m 4.84086\n",
      "67 Train Loss 13.482776 Test RE 0.01747051609526687 c 1.0670544 k 0.99827087 m 4.8574114\n",
      "68 Train Loss 13.427589 Test RE 0.017874829970358476 c 1.0777092 k 0.9978072 m 4.8443437\n",
      "69 Train Loss 13.3968525 Test RE 0.017863571720739903 c 1.0753244 k 0.99848914 m 4.8457594\n",
      "70 Train Loss 13.371776 Test RE 0.01763459293475879 c 1.0666366 k 0.9987108 m 4.8726716\n",
      "71 Train Loss 13.291697 Test RE 0.018236173850766063 c 1.0901778 k 0.99811524 m 4.9056115\n",
      "72 Train Loss 13.26684 Test RE 0.018338885981128743 c 1.0969793 k 0.9986149 m 4.9003215\n",
      "73 Train Loss 13.09598 Test RE 0.017255747333845148 c 1.0747817 k 1.0003986 m 4.902211\n",
      "74 Train Loss 12.757405 Test RE 0.017328724411204564 c 1.0375491 k 0.9998693 m 4.9340563\n",
      "75 Train Loss 12.51526 Test RE 0.01761396283776258 c 1.0372859 k 0.9980689 m 4.875441\n",
      "76 Train Loss 12.215253 Test RE 0.017551801334822904 c 1.0645956 k 0.99722075 m 4.8142953\n",
      "77 Train Loss 11.509242 Test RE 0.01841079675003193 c 1.0998058 k 0.99705464 m 4.8307047\n",
      "78 Train Loss 10.859507 Test RE 0.01923740930177191 c 1.1477675 k 0.99598414 m 4.811004\n",
      "79 Train Loss 10.625075 Test RE 0.01977067535744463 c 1.1398588 k 0.99603564 m 4.786551\n",
      "80 Train Loss 10.364655 Test RE 0.019444441975117886 c 1.1089956 k 0.99872917 m 4.837653\n",
      "81 Train Loss 9.485751 Test RE 0.01853013439042286 c 1.0357493 k 0.9996838 m 4.9552107\n",
      "82 Train Loss 8.645203 Test RE 0.01742058220362875 c 1.0706848 k 0.9971868 m 4.943717\n",
      "83 Train Loss 8.515807 Test RE 0.017572245036753604 c 1.0676962 k 0.99892765 m 4.9249635\n",
      "84 Train Loss 8.465969 Test RE 0.017859314615217583 c 1.0624232 k 0.9983038 m 4.902683\n",
      "85 Train Loss 8.434691 Test RE 0.017805014731864504 c 1.065385 k 0.99757314 m 4.89666\n",
      "86 Train Loss 8.38657 Test RE 0.01731635693554551 c 1.0511831 k 0.99765134 m 4.882701\n",
      "87 Train Loss 8.346356 Test RE 0.01738076152261559 c 1.0565473 k 0.9981348 m 4.84256\n",
      "88 Train Loss 8.298534 Test RE 0.017148355797589238 c 1.061455 k 0.99749583 m 4.8179097\n",
      "89 Train Loss 8.24382 Test RE 0.016969496226348496 c 1.042208 k 0.9969782 m 4.8009677\n",
      "90 Train Loss 8.237141 Test RE 0.01704402168557547 c 1.0429717 k 0.997193 m 4.7935095\n",
      "91 Train Loss 8.208853 Test RE 0.016790031418156836 c 1.0449861 k 0.9980302 m 4.801652\n",
      "92 Train Loss 8.156086 Test RE 0.016735107969886226 c 1.0430408 k 0.99735045 m 4.7956004\n",
      "93 Train Loss 8.081341 Test RE 0.016802413035271125 c 1.0411186 k 0.9970907 m 4.802683\n",
      "94 Train Loss 8.05357 Test RE 0.01642762896456903 c 1.0423319 k 0.99741924 m 4.8132668\n",
      "95 Train Loss 8.046945 Test RE 0.016396436892963998 c 1.0421036 k 0.99748737 m 4.8229947\n",
      "96 Train Loss 8.0363245 Test RE 0.01651450569563764 c 1.0385221 k 0.9978992 m 4.831351\n",
      "97 Train Loss 7.9467826 Test RE 0.016246866634571665 c 1.0434462 k 0.9982078 m 4.8693595\n",
      "98 Train Loss 7.884042 Test RE 0.01627050806178383 c 1.0510635 k 0.99772394 m 4.900927\n",
      "99 Train Loss 7.852584 Test RE 0.01633382981487399 c 1.0483996 k 0.9978657 m 4.9044676\n",
      "100 Train Loss 7.8070216 Test RE 0.01675977160165909 c 1.0588124 k 0.99854803 m 4.9030867\n",
      "101 Train Loss 7.7239447 Test RE 0.016597305222849367 c 1.0686398 k 0.9983637 m 4.9243064\n",
      "102 Train Loss 7.541092 Test RE 0.016043260549497486 c 1.0536168 k 0.998418 m 4.902795\n",
      "103 Train Loss 7.299274 Test RE 0.014476606309237005 c 1.0296377 k 0.9992245 m 4.883407\n",
      "104 Train Loss 6.9315987 Test RE 0.01297044620665754 c 1.0092223 k 0.9983803 m 4.805083\n",
      "105 Train Loss 6.795352 Test RE 0.012840357192374384 c 1.0069498 k 0.996893 m 4.7791862\n",
      "106 Train Loss 6.718382 Test RE 0.012532929474094361 c 1.0132421 k 0.9976923 m 4.771217\n",
      "107 Train Loss 6.6855235 Test RE 0.012349152926317 c 1.0108085 k 0.9973651 m 4.7825055\n",
      "108 Train Loss 6.662656 Test RE 0.012341431513652986 c 1.002886 k 0.99714375 m 4.7851386\n",
      "109 Train Loss 6.596653 Test RE 0.012521621701585646 c 1.0065036 k 0.99785215 m 4.797504\n",
      "110 Train Loss 6.5087895 Test RE 0.012847887390994297 c 1.0245129 k 0.9979377 m 4.8426843\n",
      "111 Train Loss 6.454373 Test RE 0.01293116633074519 c 1.0214998 k 0.9981624 m 4.8395567\n",
      "112 Train Loss 6.380144 Test RE 0.012202135955819558 c 1.0328876 k 0.99747384 m 4.840805\n",
      "113 Train Loss 6.3352327 Test RE 0.012132809692305839 c 1.026472 k 0.9977526 m 4.825981\n",
      "114 Train Loss 6.284064 Test RE 0.011871644751687234 c 1.0101819 k 0.99755263 m 4.808348\n",
      "115 Train Loss 6.216863 Test RE 0.011887290580953362 c 1.0052108 k 0.99773026 m 4.798504\n",
      "116 Train Loss 5.917784 Test RE 0.012105991775883323 c 1.0192217 k 0.998678 m 4.838622\n",
      "117 Train Loss 5.7086577 Test RE 0.012503600994512582 c 1.0355477 k 0.99786127 m 4.867408\n",
      "118 Train Loss 5.6944833 Test RE 0.012477699992194072 c 1.0357717 k 0.99795884 m 4.8732934\n",
      "119 Train Loss 5.6917186 Test RE 0.012461800211166704 c 1.0361168 k 0.99814117 m 4.871502\n",
      "120 Train Loss 5.678109 Test RE 0.012536131102841016 c 1.037958 k 0.9984399 m 4.8648252\n",
      "121 Train Loss 5.657092 Test RE 0.012790106660605743 c 1.0462149 k 0.997702 m 4.8606853\n",
      "122 Train Loss 5.601658 Test RE 0.012650476136198806 c 1.0517048 k 0.99740475 m 4.849866\n",
      "123 Train Loss 5.5161734 Test RE 0.01253960577055919 c 1.0540576 k 0.99731237 m 4.844209\n",
      "124 Train Loss 5.4618645 Test RE 0.01285265955590182 c 1.0515164 k 0.9974522 m 4.8737507\n",
      "125 Train Loss 5.43433 Test RE 0.012936361506655048 c 1.0544274 k 0.997728 m 4.9037766\n",
      "126 Train Loss 5.411139 Test RE 0.012949571439527767 c 1.0594709 k 0.9981978 m 4.928563\n",
      "127 Train Loss 5.292179 Test RE 0.012974617777514042 c 1.0540563 k 0.9970807 m 4.968922\n",
      "128 Train Loss 5.04336 Test RE 0.012210932492001312 c 1.0338625 k 0.9974828 m 4.9794874\n",
      "129 Train Loss 4.8822117 Test RE 0.01162043057747923 c 1.0337582 k 0.9988434 m 4.970618\n",
      "130 Train Loss 4.7599273 Test RE 0.01183569621785707 c 1.0370148 k 0.99852633 m 4.95478\n",
      "131 Train Loss 4.7034698 Test RE 0.012251571824722151 c 1.0400672 k 0.9981992 m 4.9320264\n",
      "132 Train Loss 4.6780434 Test RE 0.012278235975501798 c 1.0474113 k 0.9984801 m 4.9223895\n",
      "133 Train Loss 4.6635385 Test RE 0.012310801517295451 c 1.0541846 k 0.9984178 m 4.92808\n",
      "134 Train Loss 4.652313 Test RE 0.012427871414580976 c 1.0582625 k 0.9984615 m 4.9327374\n",
      "135 Train Loss 4.6407566 Test RE 0.01248937222579802 c 1.0627009 k 0.9989734 m 4.9185724\n",
      "136 Train Loss 4.626975 Test RE 0.01243144367562325 c 1.0691015 k 0.9983836 m 4.898563\n",
      "137 Train Loss 4.62032 Test RE 0.012322562501871923 c 1.0672709 k 0.99778026 m 4.9035234\n",
      "138 Train Loss 4.5919 Test RE 0.012265844940449659 c 1.063512 k 0.9980492 m 4.918296\n",
      "139 Train Loss 4.5527353 Test RE 0.012388825368068275 c 1.0630769 k 0.9978563 m 4.8931513\n",
      "140 Train Loss 4.4703865 Test RE 0.01235356977902617 c 1.0533094 k 0.9980464 m 4.8757358\n",
      "141 Train Loss 4.3187466 Test RE 0.011935367017277914 c 1.0516603 k 0.9991047 m 4.9267464\n",
      "142 Train Loss 4.1968164 Test RE 0.011685640060342214 c 1.044851 k 0.9997854 m 4.9463925\n",
      "143 Train Loss 4.069266 Test RE 0.011171025948939177 c 1.0516655 k 0.9987479 m 4.9424434\n",
      "144 Train Loss 4.024537 Test RE 0.011004628418632527 c 1.0413488 k 0.99881166 m 4.948714\n",
      "145 Train Loss 3.9974732 Test RE 0.01074760475853152 c 1.034742 k 0.9996838 m 4.941136\n",
      "146 Train Loss 3.9466748 Test RE 0.010693958675016844 c 1.0276092 k 0.99891704 m 4.9224124\n",
      "147 Train Loss 3.8938866 Test RE 0.010412675083425037 c 1.0165873 k 0.99947155 m 4.928838\n",
      "148 Train Loss 3.8541877 Test RE 0.010320125254362877 c 1.0274246 k 0.99949235 m 4.933609\n",
      "149 Train Loss 3.766767 Test RE 0.010403174121979445 c 1.0225905 k 0.998909 m 4.9460287\n",
      "150 Train Loss 3.7046745 Test RE 0.010282963617048014 c 1.015118 k 0.9986301 m 4.9287434\n",
      "151 Train Loss 3.6469822 Test RE 0.010001763618817005 c 1.015751 k 0.9979654 m 4.9367514\n",
      "152 Train Loss 3.5792356 Test RE 0.009757885614576179 c 1.0087317 k 0.9981677 m 4.9504485\n",
      "153 Train Loss 3.5274763 Test RE 0.009660388833367122 c 1.0149883 k 0.99879164 m 4.9284883\n",
      "154 Train Loss 3.4994993 Test RE 0.009945650647688797 c 1.0198308 k 0.9985091 m 4.90927\n",
      "155 Train Loss 3.4821372 Test RE 0.009851616980913228 c 1.0125685 k 0.9980823 m 4.908728\n",
      "156 Train Loss 3.4633205 Test RE 0.009666291670895374 c 1.0152456 k 0.9977211 m 4.8947377\n",
      "157 Train Loss 3.4447346 Test RE 0.009756218497134778 c 1.0200635 k 0.99799275 m 4.8771305\n",
      "158 Train Loss 3.4353094 Test RE 0.009872263346108332 c 1.0191948 k 0.997907 m 4.87621\n",
      "159 Train Loss 3.4271238 Test RE 0.009873771719871704 c 1.0200603 k 0.9980691 m 4.879287\n",
      "160 Train Loss 3.4017372 Test RE 0.009800481859456254 c 1.0201466 k 0.9983988 m 4.8894153\n",
      "161 Train Loss 3.383024 Test RE 0.00960656165615698 c 1.0170538 k 0.99852383 m 4.8971105\n",
      "162 Train Loss 3.3591828 Test RE 0.009417172839041905 c 1.0127203 k 0.99821377 m 4.9046884\n",
      "163 Train Loss 3.3089907 Test RE 0.009565635573623915 c 1.0213786 k 0.9976641 m 4.9092975\n",
      "164 Train Loss 3.281167 Test RE 0.009793664762298262 c 1.026041 k 0.9985641 m 4.9144306\n",
      "165 Train Loss 3.251249 Test RE 0.009634998406053462 c 1.0151798 k 0.99857557 m 4.928451\n",
      "166 Train Loss 3.2046473 Test RE 0.009516408583520656 c 1.0171987 k 0.9986438 m 4.9155545\n",
      "167 Train Loss 3.1831465 Test RE 0.009654867486664956 c 1.0170583 k 0.9989172 m 4.918217\n",
      "168 Train Loss 3.1502843 Test RE 0.009612052421840947 c 1.0161071 k 0.9985314 m 4.928582\n",
      "169 Train Loss 3.1311808 Test RE 0.009705460353881345 c 1.0222952 k 0.9986868 m 4.927722\n",
      "170 Train Loss 3.1210852 Test RE 0.009675587900624148 c 1.0203344 k 0.9987562 m 4.934681\n",
      "171 Train Loss 3.1176527 Test RE 0.009743774184828122 c 1.0210013 k 0.9986749 m 4.9293118\n",
      "172 Train Loss 3.1105464 Test RE 0.009827249702942716 c 1.021873 k 0.9985682 m 4.916238\n",
      "173 Train Loss 3.1034007 Test RE 0.009757209549034467 c 1.0193167 k 0.99872977 m 4.9115148\n",
      "174 Train Loss 3.0890896 Test RE 0.009812454305595467 c 1.0226251 k 0.9984537 m 4.9049854\n",
      "175 Train Loss 3.085209 Test RE 0.00984927628512649 c 1.02578 k 0.9981104 m 4.9048743\n",
      "176 Train Loss 3.0801563 Test RE 0.00990397876426512 c 1.0267109 k 0.9982335 m 4.9040265\n",
      "177 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "178 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "179 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "180 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "181 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "182 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "183 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "184 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "185 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "186 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "187 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "188 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "189 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "190 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "191 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "192 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "193 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "194 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "195 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "196 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "197 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "198 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "199 Train Loss 3.0796618 Test RE 0.009902628507206657 c 1.0260943 k 0.99826634 m 4.9039516\n",
      "Training time: 50.89\n",
      "Training time: 50.89\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 509.0187 Test RE 0.22060033372628474 c 0.07228131 k 1.0245079 m -6.151849e-05\n",
      "1 Train Loss 483.34943 Test RE 0.21739285549055878 c 0.07209759 k 1.0161103 m -9.252921e-05\n",
      "2 Train Loss 471.55142 Test RE 0.2138237768812207 c 0.084324405 k 1.0188792 m -0.0005636867\n",
      "3 Train Loss 430.60962 Test RE 0.20235797019144786 c 0.15123382 k 1.013001 m -0.0029161202\n",
      "4 Train Loss 296.2188 Test RE 0.15265253060489092 c 0.24323756 k 1.002375 m -0.0036184755\n",
      "5 Train Loss 255.48361 Test RE 0.12065737938178345 c 0.2994138 k 0.9919882 m 0.018059656\n",
      "6 Train Loss 234.00337 Test RE 0.1020274182763283 c 0.46214548 k 0.98485893 m 0.22046681\n",
      "7 Train Loss 181.46283 Test RE 0.09789640009668503 c 1.2376978 k 0.97364753 m 1.27355\n",
      "8 Train Loss 144.51605 Test RE 0.0776148317584246 c 1.773784 k 0.98536307 m 2.0444045\n",
      "9 Train Loss 129.25621 Test RE 0.07657702303741365 c 1.7685735 k 0.9767113 m 2.118679\n",
      "10 Train Loss 110.68561 Test RE 0.07896393016162509 c 1.856874 k 0.9815538 m 2.7030768\n",
      "11 Train Loss 107.71947 Test RE 0.07766899521091626 c 1.8175687 k 0.98157537 m 2.6872287\n",
      "12 Train Loss 95.19025 Test RE 0.07287555907143482 c 1.5240685 k 0.9819502 m 2.5876303\n",
      "13 Train Loss 80.51747 Test RE 0.0621339303353411 c 1.2773621 k 0.9776966 m 2.6772652\n",
      "14 Train Loss 69.29482 Test RE 0.05704997313637351 c 1.3791995 k 0.9837522 m 3.0106542\n",
      "15 Train Loss 55.970535 Test RE 0.056117792914976254 c 1.4281521 k 0.99317086 m 3.5728135\n",
      "16 Train Loss 50.253685 Test RE 0.05479926385765081 c 1.3517727 k 0.97737986 m 3.7414436\n",
      "17 Train Loss 42.100876 Test RE 0.04841281641837573 c 1.2549789 k 0.9915828 m 3.8588305\n",
      "18 Train Loss 38.995323 Test RE 0.04539962118327991 c 1.293621 k 0.9906653 m 3.9985454\n",
      "19 Train Loss 37.0691 Test RE 0.04486017436807395 c 1.3078749 k 0.98705614 m 4.1439157\n",
      "20 Train Loss 34.10573 Test RE 0.04491343328502671 c 1.3454112 k 0.9947971 m 4.2645745\n",
      "21 Train Loss 31.243221 Test RE 0.04355078343814223 c 1.3546953 k 0.99274695 m 4.269612\n",
      "22 Train Loss 29.994135 Test RE 0.04178932528409757 c 1.2569683 k 0.99004877 m 4.188097\n",
      "23 Train Loss 29.16447 Test RE 0.041832839481707344 c 1.2580723 k 0.9924249 m 4.2099595\n",
      "24 Train Loss 28.014381 Test RE 0.04248587859793148 c 1.2608973 k 0.9912034 m 4.326339\n",
      "25 Train Loss 27.291039 Test RE 0.041018896123703574 c 1.1934346 k 0.99383557 m 4.355973\n",
      "26 Train Loss 24.754498 Test RE 0.038167368758467206 c 1.1493177 k 0.998217 m 4.3570766\n",
      "27 Train Loss 23.862694 Test RE 0.037960735726374685 c 1.2184008 k 0.99239933 m 4.37788\n",
      "28 Train Loss 22.606413 Test RE 0.03692867635727591 c 1.1960835 k 0.9900308 m 4.4411507\n",
      "29 Train Loss 21.638893 Test RE 0.03624244559410469 c 1.1782037 k 0.9967671 m 4.4443507\n",
      "30 Train Loss 19.15997 Test RE 0.033396266876098465 c 1.2067822 k 0.99745905 m 4.5379314\n",
      "31 Train Loss 17.427505 Test RE 0.030251389971525124 c 1.1398164 k 0.9930614 m 4.609349\n",
      "32 Train Loss 15.568933 Test RE 0.025643383044251483 c 1.0799549 k 1.0016999 m 4.8686714\n",
      "33 Train Loss 13.491926 Test RE 0.02557272098810951 c 1.0907451 k 1.0017632 m 4.953526\n",
      "34 Train Loss 12.438156 Test RE 0.024918352550310167 c 1.0624993 k 0.9982445 m 4.875704\n",
      "35 Train Loss 11.830755 Test RE 0.023447676298366103 c 1.035183 k 1.0007592 m 4.911381\n",
      "36 Train Loss 11.471022 Test RE 0.023380781613159984 c 1.0326977 k 0.99817055 m 4.9433317\n",
      "37 Train Loss 11.294731 Test RE 0.023719562995575365 c 1.0584944 k 0.99925774 m 4.9298997\n",
      "38 Train Loss 10.784346 Test RE 0.022539434574351334 c 1.0773497 k 1.0037239 m 4.974288\n",
      "39 Train Loss 10.163083 Test RE 0.020873744924074716 c 1.0531096 k 0.9987047 m 4.971221\n",
      "40 Train Loss 9.04405 Test RE 0.01979710573170539 c 1.0490195 k 0.9957064 m 4.7811155\n",
      "41 Train Loss 8.189329 Test RE 0.017387820941346492 c 1.069926 k 0.9992279 m 4.802651\n",
      "42 Train Loss 8.025505 Test RE 0.01697292165720719 c 1.054547 k 0.99727595 m 4.8130994\n",
      "43 Train Loss 7.3701525 Test RE 0.0172233817284603 c 1.0809028 k 0.99484897 m 4.68965\n",
      "44 Train Loss 6.2252817 Test RE 0.014791112608153932 c 1.0735198 k 0.9968211 m 4.766496\n",
      "45 Train Loss 5.571327 Test RE 0.013716602688715064 c 1.0448135 k 0.99895066 m 4.829259\n",
      "46 Train Loss 4.3577456 Test RE 0.011280472104003143 c 1.0352409 k 0.9977186 m 4.8370214\n",
      "47 Train Loss 3.0082176 Test RE 0.008387050585205634 c 1.0290619 k 0.99957514 m 4.874554\n",
      "48 Train Loss 2.6212025 Test RE 0.007528256563037024 c 1.03214 k 0.9980592 m 4.8655076\n",
      "49 Train Loss 2.3198798 Test RE 0.00652114807797887 c 1.0188861 k 0.996386 m 4.890298\n",
      "50 Train Loss 1.947332 Test RE 0.0063364442281045215 c 1.0300316 k 1.0010377 m 4.8934827\n",
      "51 Train Loss 1.6637042 Test RE 0.006364954269482062 c 1.037142 k 0.99792284 m 4.8915753\n",
      "52 Train Loss 1.3352653 Test RE 0.004616146948184073 c 1.0301903 k 0.9964083 m 4.996338\n",
      "53 Train Loss 1.1355001 Test RE 0.003423456051582068 c 1.0253891 k 1.0008636 m 5.0113196\n",
      "54 Train Loss 1.0679697 Test RE 0.0029725888686291083 c 1.0044098 k 1.0000293 m 5.0051174\n",
      "55 Train Loss 1.0386952 Test RE 0.002591340771960242 c 1.0018262 k 0.9991672 m 4.985571\n",
      "56 Train Loss 1.0047154 Test RE 0.002830954012441414 c 1.0064638 k 0.99990344 m 4.964347\n",
      "57 Train Loss 0.95967966 Test RE 0.0027114138562099903 c 1.0082903 k 0.9996445 m 4.980557\n",
      "58 Train Loss 0.93935174 Test RE 0.0026546420453298324 c 1.0126368 k 0.9992469 m 4.9722123\n",
      "59 Train Loss 0.9099111 Test RE 0.002740693226453512 c 1.0169771 k 0.9995005 m 4.9546857\n",
      "60 Train Loss 0.8423803 Test RE 0.0027521037914350357 c 1.0094837 k 0.9993658 m 4.940024\n",
      "61 Train Loss 0.794659 Test RE 0.0027855660789503833 c 1.0023466 k 0.9996605 m 4.9595194\n",
      "62 Train Loss 0.7443384 Test RE 0.002691992618759201 c 1.0002015 k 1.0004468 m 4.993385\n",
      "63 Train Loss 0.70490736 Test RE 0.0028230567113095013 c 1.0012605 k 1.0004556 m 4.9856496\n",
      "64 Train Loss 0.6429616 Test RE 0.0025575357766203506 c 1.0084167 k 0.9996984 m 4.9544463\n",
      "65 Train Loss 0.5825587 Test RE 0.0022688018337170034 c 1.005452 k 0.9995605 m 4.9625835\n",
      "66 Train Loss 0.5655492 Test RE 0.0023328180083507935 c 1.0001158 k 0.99994147 m 4.973833\n",
      "67 Train Loss 0.5566621 Test RE 0.0022766378466530556 c 0.9977954 k 1.0000464 m 4.9781146\n",
      "68 Train Loss 0.5509498 Test RE 0.00211288617974284 c 0.99823445 k 1.0001159 m 4.9831133\n",
      "69 Train Loss 0.54618937 Test RE 0.002159159829058557 c 1.0007063 k 0.9998659 m 4.987781\n",
      "70 Train Loss 0.5405901 Test RE 0.0022655539372321686 c 1.0056871 k 0.9998301 m 4.9878187\n",
      "71 Train Loss 0.5345671 Test RE 0.0022009208534693467 c 1.0061475 k 0.9999304 m 4.9826317\n",
      "72 Train Loss 0.5105156 Test RE 0.002184954719372158 c 1.0080212 k 0.99973 m 4.995019\n",
      "73 Train Loss 0.4819425 Test RE 0.00233672182923028 c 1.0046687 k 0.9999536 m 4.992852\n",
      "74 Train Loss 0.47659189 Test RE 0.002261854033321946 c 1.0036416 k 1.0000925 m 4.9861183\n",
      "75 Train Loss 0.47578254 Test RE 0.0022461032784596613 c 1.0036908 k 1.0000474 m 4.989412\n",
      "76 Train Loss 0.4747114 Test RE 0.0023216121350360165 c 1.0035927 k 0.9999425 m 4.9891825\n",
      "77 Train Loss 0.47231737 Test RE 0.0023795610208701976 c 1.0032641 k 1.0002629 m 4.9908447\n",
      "78 Train Loss 0.464348 Test RE 0.002447849304607962 c 1.0037577 k 1.0005411 m 4.9950128\n",
      "79 Train Loss 0.44415888 Test RE 0.0027184999917796962 c 1.0046155 k 1.0002726 m 5.008751\n",
      "80 Train Loss 0.4336698 Test RE 0.0026998318159266355 c 1.003814 k 1.0003074 m 5.0101266\n",
      "81 Train Loss 0.4230825 Test RE 0.0025317130449122225 c 1.0019835 k 1.0000967 m 5.010868\n",
      "82 Train Loss 0.4216243 Test RE 0.0024640529095364505 c 1.0019717 k 1.0002798 m 5.015422\n",
      "83 Train Loss 0.41996643 Test RE 0.0024956386372353844 c 1.0031742 k 1.0004815 m 5.020457\n",
      "84 Train Loss 0.4099515 Test RE 0.0025850083100775684 c 1.0058342 k 1.0004355 m 5.025342\n",
      "85 Train Loss 0.3594987 Test RE 0.002409653319274762 c 0.9986588 k 1.0005887 m 5.00786\n",
      "86 Train Loss 0.30663878 Test RE 0.0024483210166210798 c 1.001607 k 1.0008441 m 4.9857106\n",
      "87 Train Loss 0.28223225 Test RE 0.002583923001857451 c 1.0053817 k 0.9999087 m 4.9929237\n",
      "88 Train Loss 0.27807778 Test RE 0.0025635577822286718 c 1.005488 k 0.99983877 m 4.9945917\n",
      "89 Train Loss 0.27636844 Test RE 0.002545985040927031 c 1.004823 k 0.99998957 m 4.995154\n",
      "90 Train Loss 0.27360046 Test RE 0.0025392492654884424 c 1.0038899 k 1.0000318 m 4.9947443\n",
      "91 Train Loss 0.26205286 Test RE 0.002634182761335237 c 1.0069304 k 1.0000856 m 4.9972153\n",
      "92 Train Loss 0.23066296 Test RE 0.00204616152288676 c 1.0037669 k 1.0000615 m 4.998467\n",
      "93 Train Loss 0.21450427 Test RE 0.0018253407977046896 c 1.0020255 k 0.99986935 m 4.9963913\n",
      "94 Train Loss 0.1975871 Test RE 0.0017703793809867433 c 1.0000993 k 0.9995274 m 4.988859\n",
      "95 Train Loss 0.1657172 Test RE 0.001355023273361766 c 0.9995185 k 0.99970984 m 4.990807\n",
      "96 Train Loss 0.14345966 Test RE 0.0012990811805225866 c 1.0008233 k 1.0003899 m 4.999778\n",
      "97 Train Loss 0.127473 Test RE 0.0010305971289664524 c 1.001627 k 0.99991494 m 4.991841\n",
      "98 Train Loss 0.122899406 Test RE 0.0009454565436126159 c 1.0030501 k 0.99980426 m 4.99328\n",
      "99 Train Loss 0.12046336 Test RE 0.0009402569829285257 c 1.0022206 k 0.9999539 m 4.9949775\n",
      "100 Train Loss 0.11980577 Test RE 0.0009147496160794211 c 1.0012445 k 0.99995345 m 4.9967403\n",
      "101 Train Loss 0.11961023 Test RE 0.0009058610240531902 c 1.0016791 k 0.9999481 m 4.9979854\n",
      "102 Train Loss 0.11832844 Test RE 0.00091297382302256 c 1.0021739 k 1.0000378 m 4.999045\n",
      "103 Train Loss 0.11675374 Test RE 0.0009024442054797899 c 1.0001601 k 1.0000807 m 4.9971313\n",
      "104 Train Loss 0.11507465 Test RE 0.000833695622672919 c 1.0003176 k 0.99995136 m 4.996883\n",
      "105 Train Loss 0.113847904 Test RE 0.0008169311005995823 c 1.0014943 k 0.99990225 m 4.9972725\n",
      "106 Train Loss 0.113647595 Test RE 0.0008248396990499679 c 1.0011691 k 0.9999229 m 4.9988246\n",
      "107 Train Loss 0.11339537 Test RE 0.0008103319274782102 c 1.0009559 k 0.9999342 m 4.99982\n",
      "108 Train Loss 0.11317866 Test RE 0.0007863130791876089 c 1.0007228 k 0.9999086 m 4.9986053\n",
      "109 Train Loss 0.11307288 Test RE 0.0007795418839876663 c 1.0008733 k 0.9999031 m 4.998184\n",
      "110 Train Loss 0.112778455 Test RE 0.0007733822432212694 c 1.0018499 k 0.99988496 m 4.9979467\n",
      "111 Train Loss 0.11203071 Test RE 0.0007919137356301384 c 1.00262 k 0.9998418 m 4.999068\n",
      "112 Train Loss 0.11015763 Test RE 0.0008028280964828893 c 1.0037907 k 0.99970627 m 4.999869\n",
      "113 Train Loss 0.10793706 Test RE 0.000752010604925795 c 1.0032188 k 0.99979424 m 4.9973783\n",
      "114 Train Loss 0.10656403 Test RE 0.0007231810124159409 c 1.0011786 k 0.9999888 m 4.996374\n",
      "115 Train Loss 0.10286905 Test RE 0.000753086246954941 c 0.9995086 k 1.0000871 m 4.9997253\n",
      "116 Train Loss 0.099764355 Test RE 0.0007395181817696827 c 1.0018768 k 0.9998932 m 4.9980035\n",
      "117 Train Loss 0.097567886 Test RE 0.0006790006257322258 c 1.0011283 k 0.9999261 m 4.999336\n",
      "118 Train Loss 0.09702416 Test RE 0.0006893707011731543 c 1.0002272 k 0.9999755 m 5.0000477\n",
      "119 Train Loss 0.096489534 Test RE 0.0007245291202495457 c 1.0010574 k 0.99983317 m 4.995556\n",
      "120 Train Loss 0.09567101 Test RE 0.0007184040927449688 c 1.0002463 k 0.9997506 m 4.995369\n",
      "121 Train Loss 0.09379206 Test RE 0.0007512794430793274 c 0.9993256 k 0.9999223 m 5.001479\n",
      "122 Train Loss 0.091618925 Test RE 0.0007940724878129703 c 1.0002985 k 0.9998424 m 4.9990625\n",
      "123 Train Loss 0.09001637 Test RE 0.00083344632823945 c 1.000547 k 0.99985737 m 5.000881\n",
      "124 Train Loss 0.08918638 Test RE 0.0008760407247415638 c 1.0007143 k 1.000044 m 5.001191\n",
      "125 Train Loss 0.08582835 Test RE 0.0010193395725716533 c 1.0025988 k 1.0001527 m 4.996448\n",
      "126 Train Loss 0.081971176 Test RE 0.0010756539494256674 c 1.0008417 k 1.0001202 m 4.999542\n",
      "127 Train Loss 0.079344876 Test RE 0.001110785060135923 c 0.99901223 k 1.0000602 m 5.00057\n",
      "128 Train Loss 0.07610551 Test RE 0.0010852232653399188 c 0.9984901 k 0.9998159 m 4.9995565\n",
      "129 Train Loss 0.071370326 Test RE 0.0011870044560820668 c 1.001294 k 0.9999023 m 4.999961\n",
      "130 Train Loss 0.06702104 Test RE 0.001202036102059337 c 1.0001422 k 1.0001981 m 4.995874\n",
      "131 Train Loss 0.06471134 Test RE 0.0012178825561743258 c 0.9999635 k 1.0001749 m 5.000968\n",
      "132 Train Loss 0.06349148 Test RE 0.001197829176275593 c 1.0003226 k 1.0001898 m 5.0046153\n",
      "133 Train Loss 0.061107807 Test RE 0.0011786287273537995 c 1.0005162 k 0.9999755 m 5.0008473\n",
      "134 Train Loss 0.05836332 Test RE 0.0012808427686405918 c 1.0014337 k 0.9999421 m 4.9975066\n",
      "135 Train Loss 0.055616863 Test RE 0.0013638277387641863 c 0.99896556 k 1.0001785 m 4.9975266\n",
      "136 Train Loss 0.053179547 Test RE 0.0013358322599795452 c 1.0004485 k 1.0001434 m 4.9974256\n",
      "137 Train Loss 0.052050553 Test RE 0.001308080533449987 c 1.0008719 k 1.0001897 m 4.997871\n",
      "138 Train Loss 0.05163054 Test RE 0.0012970413740907036 c 0.9992014 k 1.0002035 m 5.000373\n",
      "139 Train Loss 0.050234865 Test RE 0.0013090679324115086 c 0.9990979 k 1.0001849 m 5.005608\n",
      "140 Train Loss 0.048840344 Test RE 0.0012936475551838177 c 1.0010446 k 1.0002093 m 5.004022\n",
      "141 Train Loss 0.047929134 Test RE 0.0012497887668918362 c 0.99979204 k 1.0001504 m 5.0032306\n",
      "142 Train Loss 0.04692883 Test RE 0.0012179211830638072 c 0.99873966 k 1.0001968 m 5.009439\n",
      "143 Train Loss 0.044578288 Test RE 0.0011935360512708344 c 0.9989727 k 1.0002906 m 5.006149\n",
      "144 Train Loss 0.04076671 Test RE 0.0011417673392227717 c 1.0003811 k 1.0000498 m 5.0000405\n",
      "145 Train Loss 0.03796705 Test RE 0.0011209259965677752 c 1.0013382 k 1.0001874 m 5.0039287\n",
      "146 Train Loss 0.036824167 Test RE 0.0011432734430342558 c 1.0013757 k 1.0001136 m 5.00123\n",
      "147 Train Loss 0.03610763 Test RE 0.0011192629590637121 c 1.0003263 k 1.0000336 m 4.9998207\n",
      "148 Train Loss 0.03586332 Test RE 0.0011022428272826179 c 1.0003414 k 1.0001153 m 5.002021\n",
      "149 Train Loss 0.03553 Test RE 0.0010850635472938767 c 1.0005873 k 1.0001358 m 5.001147\n",
      "150 Train Loss 0.035185892 Test RE 0.0010662982231677367 c 1.0003407 k 1.0000634 m 4.9987197\n",
      "151 Train Loss 0.03503942 Test RE 0.001051028708404836 c 1.0007544 k 1.0000718 m 4.9986253\n",
      "152 Train Loss 0.03486038 Test RE 0.0010350768387336394 c 1.000468 k 1.0000731 m 4.999723\n",
      "153 Train Loss 0.03450329 Test RE 0.0010314640943644524 c 0.99974114 k 1.0000728 m 5.001515\n",
      "154 Train Loss 0.0342208 Test RE 0.0010156867533860177 c 1.0007098 k 1.0000765 m 5.001326\n",
      "155 Train Loss 0.034036767 Test RE 0.000997156395543061 c 1.0007418 k 1.0001312 m 5.001653\n",
      "156 Train Loss 0.03374909 Test RE 0.0009651955589440359 c 1.0002083 k 1.0000817 m 5.0021996\n",
      "157 Train Loss 0.03360714 Test RE 0.000956078707541121 c 1.0004523 k 1.0000726 m 5.0009236\n",
      "158 Train Loss 0.03332732 Test RE 0.0009625286645212546 c 1.0010105 k 1.0001137 m 5.000236\n",
      "159 Train Loss 0.032677803 Test RE 0.0009535526621704081 c 1.0001209 k 1.0000579 m 5.000081\n",
      "160 Train Loss 0.03250113 Test RE 0.0009435012642006983 c 1.0003372 k 1.0000484 m 4.999456\n",
      "161 Train Loss 0.032445066 Test RE 0.0009477566605868921 c 1.000429 k 1.0000687 m 4.9993696\n",
      "162 Train Loss 0.032358903 Test RE 0.0009416276095618493 c 1.0002012 k 1.0000432 m 4.999483\n",
      "163 Train Loss 0.03217808 Test RE 0.0009244319202343963 c 1.0004729 k 1.0000405 m 5.000812\n",
      "164 Train Loss 0.031926036 Test RE 0.0009232022676136463 c 1.0005622 k 1.0000836 m 5.0004187\n",
      "165 Train Loss 0.031714816 Test RE 0.0009126631767963325 c 1.0001441 k 1.000071 m 4.9996104\n",
      "166 Train Loss 0.031488262 Test RE 0.0009129932839660078 c 1.0006022 k 1.0000663 m 5.0001554\n",
      "167 Train Loss 0.031443365 Test RE 0.0009207823616780597 c 1.0007043 k 1.0000672 m 5.000148\n",
      "168 Train Loss 0.03138542 Test RE 0.0009093774495518164 c 1.0005063 k 1.0000792 m 5.000429\n",
      "169 Train Loss 0.031354953 Test RE 0.0009011727375662986 c 1.000705 k 1.0000747 m 5.0008006\n",
      "170 Train Loss 0.031213548 Test RE 0.0008988074921244204 c 1.0005573 k 1.0000238 m 5.0006638\n",
      "171 Train Loss 0.031099513 Test RE 0.000896218632574382 c 1.0004574 k 1.0000023 m 4.9990973\n",
      "172 Train Loss 0.030986581 Test RE 0.0008880588568397307 c 1.0005174 k 1.0000288 m 4.999963\n",
      "173 Train Loss 0.030691044 Test RE 0.0008757075364463501 c 1.0002022 k 1.0000387 m 5.002934\n",
      "174 Train Loss 0.030383343 Test RE 0.0008586508974339147 c 1.0002 k 1.0000464 m 5.0019507\n",
      "175 Train Loss 0.030039437 Test RE 0.0008592605206375999 c 0.9997215 k 1.0001258 m 5.0005126\n",
      "176 Train Loss 0.029488957 Test RE 0.000855795197386529 c 1.000801 k 1.000108 m 4.999971\n",
      "177 Train Loss 0.028423276 Test RE 0.0008319789407883427 c 1.0011914 k 0.9999101 m 4.998938\n",
      "178 Train Loss 0.027001448 Test RE 0.0008542406267321673 c 0.99906933 k 1.0000017 m 5.0017786\n",
      "179 Train Loss 0.026160635 Test RE 0.0008646214554158762 c 1.0007285 k 1.0000117 m 4.9999547\n",
      "180 Train Loss 0.025567345 Test RE 0.000880531213048884 c 1.0011263 k 0.9999566 m 4.9981213\n",
      "181 Train Loss 0.025206506 Test RE 0.0008884161980114575 c 1.0008376 k 1.0000035 m 4.9992676\n",
      "182 Train Loss 0.025048185 Test RE 0.0008873428134056116 c 1.0006126 k 1.0000615 m 5.000784\n",
      "183 Train Loss 0.024921097 Test RE 0.0008738731129679082 c 1.0004536 k 1.0000762 m 5.000337\n",
      "184 Train Loss 0.024842579 Test RE 0.0008647329699337535 c 1.0002358 k 1.0000504 m 4.9998446\n",
      "185 Train Loss 0.0247448 Test RE 0.0008587466059659071 c 1.0000373 k 1.0000199 m 4.999138\n",
      "186 Train Loss 0.024639064 Test RE 0.0008529973773110059 c 1.0001729 k 1.0000541 m 4.999274\n",
      "187 Train Loss 0.024480509 Test RE 0.0008596087783566472 c 1.0000863 k 1.000008 m 4.997595\n",
      "188 Train Loss 0.024265807 Test RE 0.0008634255490016428 c 1.0005159 k 0.9999487 m 4.9981227\n",
      "189 Train Loss 0.0240135 Test RE 0.0008637126193187498 c 1.0003418 k 0.999984 m 5.000494\n",
      "190 Train Loss 0.02367886 Test RE 0.0008569911804114746 c 1.0001574 k 0.99998456 m 4.9998217\n",
      "191 Train Loss 0.023329312 Test RE 0.0008303204750881647 c 1.0006903 k 1.0000151 m 4.99936\n",
      "192 Train Loss 0.023149647 Test RE 0.0008307727186009084 c 1.000746 k 1.0000536 m 5.0001864\n",
      "193 Train Loss 0.023046264 Test RE 0.0008290431504780777 c 1.000429 k 1.0000575 m 4.9999375\n",
      "194 Train Loss 0.022978581 Test RE 0.0008198383450231131 c 1.0007598 k 1.0000354 m 4.9994903\n",
      "195 Train Loss 0.022941664 Test RE 0.0008234625196429366 c 1.0008138 k 1.0000321 m 5.0001802\n",
      "196 Train Loss 0.022843275 Test RE 0.0008232623442408007 c 1.0003824 k 1.0000126 m 4.999468\n",
      "197 Train Loss 0.022546139 Test RE 0.0007982708816618262 c 1.0004443 k 1.0000439 m 4.9986043\n",
      "198 Train Loss 0.022327282 Test RE 0.0007877506198722107 c 1.0005765 k 1.0000305 m 4.999603\n",
      "199 Train Loss 0.022233557 Test RE 0.0007791701678153832 c 1.0001907 k 0.99999714 m 4.999137\n",
      "Training time: 60.82\n",
      "Training time: 60.82\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "m_full = []\n",
    "k_full = []\n",
    "c_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []   \n",
    "    beta_val = []\n",
    "    m_val = []\n",
    "    k_val = []\n",
    "    c_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "    N_f = 10000 #Total number of collocation points\n",
    "\n",
    "    layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-6, \n",
    "                                tolerance_change = 1e-6, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    beta_full.append(beta_val)\n",
    "    m_full.append(m_val)\n",
    "    k_full.append(k_val)\n",
    "    c_full.append(c_val)\n",
    "    \n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full,\"m\": m_full,\"k\": k_full,\"c\": c_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "990b2054-f35e-4c8e-c378-69ff2eb19f4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fde3074d950>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_pred = PINN.test()\n",
    "plt.plot(t,x_true,'b')\n",
    "plt.plot(t,x_pred,'r--')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
