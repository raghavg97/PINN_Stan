{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "510f67c6-b225-41ba-e78a-d0a6e54ded85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "tstart= 0 \n",
    "tstop= 60 \n",
    "\n",
    "increment = 0.1 \n",
    "# Initial condition\n",
    "x_init= [0,0] \n",
    "\n",
    "t = np.arange(tstart,tstop+1,increment)\n",
    "\n",
    "c = 1 # Damping constant \n",
    "k = 1.0 # Stiffness of the spring\n",
    "m = 5 # Mass \n",
    "F0 = 100\n",
    "\n",
    "def mydiff(x, t):    \n",
    "    F =F0\n",
    "    \n",
    "    dx1dt = x[1] \n",
    "    dx2dt = (F -c*x[1] -k*x[0])/m\n",
    "    dxdt= [dx1dt, dx2dt] \n",
    "    \n",
    "    return dxdt \n",
    "\n",
    "x_full_sol = odeint(mydiff, x_init, t) \n",
    "\n",
    "x_sol = x_full_sol[:,0]\n",
    "v_sol = x_full_sol[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "level = \"low\"\n",
    "label = \"1D_SMD_swish_\" + level\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "\n",
    "# bc1_t = t[0].reshape(-1,1)\n",
    "# bc1_x = x_sol[0].reshape(-1,1)\n",
    "# t_bc1_train = torch.from_numpy(bc1_t).float().to(device)\n",
    "# x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "\n",
    "bc1_t = t.reshape(-1,1)\n",
    "bc1_x = x_sol.reshape(-1,1)\n",
    "t_bc1_train = torch.from_numpy(bc1_t).float().to(device)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "\n",
    "\n",
    "bc2_t = t[0].reshape(-1,1)\n",
    "t_bc2_train = torch.from_numpy(bc2_t).float().to(device)\n",
    "bc2_val = v_sol[0].reshape(-1,1)\n",
    "bc2_val =torch.from_numpy(bc2_val).float().to(device)\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "x_true = x_sol\n",
    "x_true_norm = np.linalg.norm(x_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(t[0]) \n",
    "ub = np.array(t[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    \n",
    "    t01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=t01,random_state =seed)\n",
    "\n",
    "    t_coll = lb + (ub-lb)*sampling(N_f)\n",
    "    # t_coll = np.vstack((t_coll,)) # append training points to collocation points \n",
    "\n",
    "    return t_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((layers[1],len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "        self.k = Parameter(torch.tensor(0.0))\n",
    "        self.k.requiresGrad = True\n",
    "        self.c = Parameter(torch.tensor(0.0))\n",
    "        self.c.requiresGrad = True\n",
    "        self.m = Parameter(torch.tensor(0.0))\n",
    "        self.m.requiresGrad = True\n",
    "        \n",
    "    'forward pass'\n",
    "    def forward(self,t):\n",
    "        if torch.is_tensor(t) != True:         \n",
    "            t = torch.from_numpy(t)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        t = 2.0*(t - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = t.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,t,x):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(t), x)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,t_bc2,bc2_val):\n",
    "        g = t_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        x = self.forward(g)    \n",
    "            \n",
    "        x_t = autograd.grad(x,g,torch.ones([t_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        bc2 = dx_dt\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self,t_coll,f_hat):\n",
    "             \n",
    "        g = t_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        x = self.forward(g) \n",
    "\n",
    "        x_t = autograd.grad(x,g,torch.ones([t_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        x_tt = autograd.grad(x_t,g,torch.ones(t_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        dx2_d2t = x_tt[:,[0]]\n",
    "        \n",
    "        f = self.m*dx2_d2t + self.c*dx_dt + self.k*x - F0\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,t_bc1,x_bc1,t_bc2,bc2_val,t_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(t_bc1,x_bc1)\n",
    "        loss_bc2 = self.loss_BC2(t_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(t_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        x_pred = self.forward(t_test_tensor)\n",
    "        x_pred = x_pred.cpu().detach().numpy()\n",
    "\n",
    "        return x_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        x_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(x_pred.reshape(-1,1) - x_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(x_pred.reshape(-1,1) - x_true.reshape(-1,1),2)/x_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    m_val.append(PINN.m.cpu().detach().numpy())\n",
    "    k_val.append(PINN.k.cpu().detach().numpy())\n",
    "    c_val.append(PINN.c.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    t_coll = colloc_pts(N_f,rep*11)\n",
    "    t_coll =  torch.from_numpy(t_coll).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(t_coll.shape[0],1).to(device)\n",
    "    for i in range(max_iter):      \n",
    "        train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "         \n",
    "        loss_np = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test RE\",test_re_loss[-1],\"c\",PINN.c.cpu().detach().numpy(),\"k\",PINN.k.cpu().detach().numpy(),\"m\",PINN.m.cpu().detach().numpy())\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "42720d97-b37a-4c42-b7e5-b77a0ef391f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 496.20892 Test RE 0.22104789710628678 c -0.0830726 k 1.0177325 m -0.0007073963\n",
      "1 Train Loss 496.1078 Test RE 0.22102973595546352 c -0.083090305 k 1.0173746 m -0.00070754223\n",
      "2 Train Loss 495.5614 Test RE 0.2208487248701311 c -0.082858175 k 1.0164444 m -0.00070551614\n",
      "3 Train Loss 491.8608 Test RE 0.21927486952914754 c -0.08112184 k 1.0164287 m -0.0006837183\n",
      "4 Train Loss 491.64578 Test RE 0.21940414438952313 c -0.08151146 k 1.0170289 m -0.00068552967\n",
      "5 Train Loss 491.64346 Test RE 0.21941397687250666 c -0.0815377 k 1.0170794 m -0.0006856021\n",
      "6 Train Loss 491.64194 Test RE 0.21942035916604608 c -0.081555404 k 1.017113 m -0.00068559736\n",
      "7 Train Loss 491.62943 Test RE 0.21944843536599346 c -0.08164924 k 1.0172726 m -0.0006845071\n",
      "8 Train Loss 489.60022 Test RE 0.21860964341394393 c -0.085071206 k 1.0187232 m -0.000500595\n",
      "9 Train Loss 489.31653 Test RE 0.2185203046512259 c -0.08530442 k 1.01497 m -0.00047907585\n",
      "10 Train Loss 487.28415 Test RE 0.21822631398553718 c -0.08203485 k 1.0033826 m -0.00026056767\n",
      "11 Train Loss 485.43585 Test RE 0.21756288190541456 c -0.078780085 k 1.0202115 m -0.00018022167\n",
      "12 Train Loss 474.49124 Test RE 0.2133850378697003 c 0.0009839758 k 1.0184373 m 0.00031847498\n",
      "13 Train Loss 463.5574 Test RE 0.2086763356932471 c 0.039183028 k 1.0182434 m 0.00056168914\n",
      "14 Train Loss 432.43893 Test RE 0.20051584175158507 c 0.16399917 k 1.0246004 m 0.0014677659\n",
      "15 Train Loss 366.87665 Test RE 0.1656795973512212 c 0.5809401 k 1.0041142 m 0.007033352\n",
      "16 Train Loss 353.70786 Test RE 0.1652335528555579 c 0.62800795 k 1.003118 m 0.011871605\n",
      "17 Train Loss 321.29846 Test RE 0.15114223047644204 c 1.2074128 k 0.98539263 m 0.11356096\n",
      "18 Train Loss 277.79727 Test RE 0.1346415973632633 c 1.8237883 k 0.9914063 m 0.23545127\n",
      "19 Train Loss 225.55591 Test RE 0.12977470339831973 c 2.8373656 k 0.96873915 m 0.48428926\n",
      "20 Train Loss 220.21379 Test RE 0.12705173208755796 c 2.9362285 k 0.97994006 m 0.51485795\n",
      "21 Train Loss 205.70615 Test RE 0.12395204950888312 c 2.7696333 k 0.9648067 m 0.69760823\n",
      "22 Train Loss 196.77429 Test RE 0.12004166178184932 c 2.708727 k 0.9713295 m 0.86891854\n",
      "23 Train Loss 193.97757 Test RE 0.12209311224043136 c 2.6560094 k 0.96753347 m 0.86850274\n",
      "24 Train Loss 184.78587 Test RE 0.11643031395731208 c 2.4226584 k 0.9695292 m 0.9934069\n",
      "25 Train Loss 177.14716 Test RE 0.11304368965261033 c 2.0694916 k 0.9745517 m 1.0773348\n",
      "26 Train Loss 175.73338 Test RE 0.11163193857512976 c 1.9336603 k 0.97289956 m 1.117141\n",
      "27 Train Loss 174.38013 Test RE 0.11081091533674536 c 1.9357215 k 0.9738219 m 1.1185399\n",
      "28 Train Loss 173.17851 Test RE 0.1109757016044098 c 1.9110557 k 0.9760487 m 1.0929403\n",
      "29 Train Loss 168.0555 Test RE 0.10749134828816548 c 1.8431793 k 0.97416884 m 1.1331275\n",
      "30 Train Loss 162.29997 Test RE 0.10339603933489133 c 1.8909824 k 0.9770512 m 1.3057785\n",
      "31 Train Loss 154.86696 Test RE 0.1000183234124761 c 1.827201 k 0.98666143 m 1.5957719\n",
      "32 Train Loss 150.89108 Test RE 0.09603472486636311 c 1.7827388 k 0.9752141 m 1.6719698\n",
      "33 Train Loss 145.24757 Test RE 0.0918375042193017 c 1.4942851 k 0.9786146 m 1.6802614\n",
      "34 Train Loss 134.1329 Test RE 0.09002303120469905 c 1.4900194 k 0.9891105 m 1.6849279\n",
      "35 Train Loss 128.80638 Test RE 0.08430550614803756 c 1.51678 k 0.97468287 m 1.7241812\n",
      "36 Train Loss 125.46118 Test RE 0.07805128746588504 c 1.3588352 k 0.97617877 m 1.760909\n",
      "37 Train Loss 117.38318 Test RE 0.07616555843602432 c 1.5290157 k 0.9806912 m 1.9425411\n",
      "38 Train Loss 109.50007 Test RE 0.07700483476753552 c 1.3598672 k 0.97519654 m 2.184133\n",
      "39 Train Loss 95.248535 Test RE 0.06937556473578381 c 1.2932832 k 0.98148465 m 2.604366\n",
      "40 Train Loss 89.301865 Test RE 0.06639175695158012 c 1.4292747 k 0.9799801 m 2.6448421\n",
      "41 Train Loss 83.1531 Test RE 0.06587924147942005 c 1.4015361 k 0.9770068 m 2.7165377\n",
      "42 Train Loss 71.57977 Test RE 0.06138975447522848 c 1.4087824 k 0.9808677 m 2.9123242\n",
      "43 Train Loss 56.91474 Test RE 0.0607748237651152 c 1.1382295 k 0.9850056 m 3.276348\n",
      "44 Train Loss 51.188046 Test RE 0.056881686607432286 c 1.2922208 k 0.9843736 m 3.3569944\n",
      "45 Train Loss 46.902813 Test RE 0.060175906078135485 c 1.2648284 k 0.98538005 m 3.5268028\n",
      "46 Train Loss 43.88562 Test RE 0.05693343776168281 c 1.2269756 k 0.9866193 m 3.7448657\n",
      "47 Train Loss 40.60393 Test RE 0.053266972636185385 c 1.2333282 k 0.9892478 m 3.900038\n",
      "48 Train Loss 37.903767 Test RE 0.0524095462990694 c 1.2605118 k 0.9875776 m 4.020617\n",
      "49 Train Loss 35.44209 Test RE 0.049404689949537964 c 1.1693918 k 0.99119115 m 4.284445\n",
      "50 Train Loss 33.778862 Test RE 0.04775143091594971 c 1.1501336 k 0.9922066 m 4.3001246\n",
      "51 Train Loss 32.660454 Test RE 0.04701386250498243 c 1.1884496 k 0.99248195 m 4.3349576\n",
      "52 Train Loss 30.647072 Test RE 0.04638060290083493 c 1.1847565 k 0.9914574 m 4.3366127\n",
      "53 Train Loss 28.276201 Test RE 0.04516533297096564 c 1.1817036 k 0.99489367 m 4.5201616\n",
      "54 Train Loss 27.11692 Test RE 0.04433247963300794 c 1.126505 k 0.9941555 m 4.664026\n",
      "55 Train Loss 26.334747 Test RE 0.04370157625456919 c 1.154416 k 0.9959869 m 4.7358603\n",
      "56 Train Loss 25.844374 Test RE 0.04297846745044349 c 1.1906679 k 0.9947892 m 4.8062477\n",
      "57 Train Loss 25.104538 Test RE 0.04184598664014422 c 1.1467221 k 0.99586165 m 4.8390727\n",
      "58 Train Loss 24.350853 Test RE 0.04097688953304372 c 1.1138557 k 0.9983949 m 4.8417354\n",
      "59 Train Loss 23.166203 Test RE 0.039065841392934335 c 1.1523212 k 0.9942338 m 4.8728833\n",
      "60 Train Loss 21.918127 Test RE 0.03690428713866395 c 1.1268497 k 0.99601716 m 4.800849\n",
      "61 Train Loss 20.923996 Test RE 0.03522381943840358 c 1.0866281 k 0.9979682 m 4.7668624\n",
      "62 Train Loss 19.330675 Test RE 0.03544546544330948 c 1.1536884 k 0.99507 m 4.663071\n",
      "63 Train Loss 15.663559 Test RE 0.03227149909084749 c 1.065579 k 0.99761873 m 4.6185985\n",
      "64 Train Loss 13.991956 Test RE 0.03175879953249692 c 1.1042699 k 0.9978788 m 4.6674848\n",
      "65 Train Loss 12.962217 Test RE 0.030740448366381904 c 1.1182082 k 0.9939849 m 4.666023\n",
      "66 Train Loss 11.782595 Test RE 0.02956962007409029 c 1.0866464 k 0.99774754 m 4.7050614\n",
      "67 Train Loss 10.837949 Test RE 0.028093764745872978 c 1.0991114 k 0.998474 m 4.69487\n",
      "68 Train Loss 10.48207 Test RE 0.027474055741347397 c 1.0818037 k 0.99656355 m 4.6620812\n",
      "69 Train Loss 10.285738 Test RE 0.027054771952485325 c 1.0769864 k 0.9954781 m 4.655858\n",
      "70 Train Loss 9.794223 Test RE 0.026608899894759785 c 1.0826349 k 0.9976432 m 4.730203\n",
      "71 Train Loss 8.996423 Test RE 0.02502375002893365 c 1.0538037 k 0.99728656 m 4.874191\n",
      "72 Train Loss 8.510487 Test RE 0.024143043709710106 c 1.0668988 k 1.0002749 m 4.9371448\n",
      "73 Train Loss 8.155371 Test RE 0.023536119615461447 c 1.0653428 k 0.9995246 m 4.9280686\n",
      "74 Train Loss 8.0769825 Test RE 0.023077434717472294 c 1.0596226 k 0.9998865 m 4.965891\n",
      "75 Train Loss 7.7378645 Test RE 0.02207954771806058 c 1.0464066 k 1.0001796 m 5.0159554\n",
      "76 Train Loss 7.5041256 Test RE 0.022117472143714626 c 1.0411936 k 0.999594 m 4.962223\n",
      "77 Train Loss 7.4145055 Test RE 0.022082157542782796 c 1.0419774 k 0.9990288 m 4.936137\n",
      "78 Train Loss 7.1655226 Test RE 0.021276426784237783 c 1.0442771 k 0.99872476 m 4.8652105\n",
      "79 Train Loss 6.9026785 Test RE 0.020927017029907305 c 1.0636537 k 0.99929065 m 4.8745394\n",
      "80 Train Loss 6.8398256 Test RE 0.020668748486827933 c 1.0549824 k 0.9989025 m 4.908897\n",
      "81 Train Loss 6.5375957 Test RE 0.0196388289534399 c 1.0211415 k 0.9994493 m 4.990213\n",
      "82 Train Loss 6.070035 Test RE 0.019019978018707934 c 1.0404139 k 1.0001752 m 5.0500703\n",
      "83 Train Loss 5.303955 Test RE 0.01736520508788464 c 1.0795666 k 0.99972373 m 5.04926\n",
      "84 Train Loss 3.841228 Test RE 0.01284949007615436 c 0.99091214 k 1.0007439 m 5.045999\n",
      "85 Train Loss 3.1046634 Test RE 0.010139365670751225 c 1.0020779 k 0.99979234 m 5.068601\n",
      "86 Train Loss 2.889346 Test RE 0.00864886416805775 c 1.0114874 k 1.0011793 m 5.0642858\n",
      "87 Train Loss 2.4267473 Test RE 0.00679002156905194 c 1.0110288 k 0.9994584 m 4.9494176\n",
      "88 Train Loss 2.1374135 Test RE 0.006421955457371559 c 1.0108931 k 0.99931204 m 4.917544\n",
      "89 Train Loss 1.9683015 Test RE 0.006137433099181814 c 1.013818 k 0.9997483 m 4.9553065\n",
      "90 Train Loss 1.6981432 Test RE 0.006095492530259899 c 1.0128224 k 0.99918187 m 4.948752\n",
      "91 Train Loss 1.5484722 Test RE 0.0055523308626381105 c 1.0094211 k 0.9991123 m 4.983718\n",
      "92 Train Loss 1.452513 Test RE 0.0055081609450779384 c 1.004666 k 0.9998533 m 5.018393\n",
      "93 Train Loss 1.350122 Test RE 0.004989308836083188 c 1.0016754 k 1.000625 m 4.990154\n",
      "94 Train Loss 1.2326117 Test RE 0.004105224973067696 c 1.0007421 k 0.9985793 m 4.936246\n",
      "95 Train Loss 0.87393355 Test RE 0.003599109522425459 c 1.0002085 k 0.99973446 m 4.9874334\n",
      "96 Train Loss 0.7192943 Test RE 0.002760190768251172 c 0.9972869 k 1.0015116 m 5.0193524\n",
      "97 Train Loss 0.6513787 Test RE 0.002655368839625207 c 0.9993301 k 1.0003077 m 5.0212297\n",
      "98 Train Loss 0.6245872 Test RE 0.0025679590171128926 c 0.9995646 k 1.000302 m 5.0239463\n",
      "99 Train Loss 0.5513044 Test RE 0.002675125388911452 c 1.0013821 k 1.0002077 m 4.9967837\n",
      "100 Train Loss 0.5042187 Test RE 0.0023879502072543996 c 1.0059308 k 1.0001802 m 4.9870567\n",
      "101 Train Loss 0.46403623 Test RE 0.0024048687889218524 c 1.0042456 k 1.0003844 m 5.0164886\n",
      "102 Train Loss 0.4335645 Test RE 0.0024451547621265226 c 0.99831617 k 1.0007923 m 5.0307016\n",
      "103 Train Loss 0.39956158 Test RE 0.0023246439509074343 c 0.99930346 k 1.0003626 m 5.00318\n",
      "104 Train Loss 0.3822293 Test RE 0.0021860200398348927 c 1.0020897 k 0.9998379 m 4.993979\n",
      "105 Train Loss 0.3672381 Test RE 0.0021633487521364996 c 0.99998444 k 1.0000564 m 5.005966\n",
      "106 Train Loss 0.36007187 Test RE 0.0021972004905827444 c 0.99965566 k 1.0004563 m 5.006891\n",
      "107 Train Loss 0.3118009 Test RE 0.002434650814795493 c 1.0019513 k 1.0013138 m 5.006309\n",
      "108 Train Loss 0.23010981 Test RE 0.0022393227850913897 c 1.0023236 k 1.0003529 m 5.0333333\n",
      "109 Train Loss 0.20634453 Test RE 0.0023244754399229252 c 1.0028102 k 1.0004767 m 5.0372596\n",
      "110 Train Loss 0.17061648 Test RE 0.002473226726757412 c 1.0052749 k 1.0004704 m 5.017022\n",
      "111 Train Loss 0.12616555 Test RE 0.001998250969307734 c 0.9985671 k 1.0001522 m 5.003362\n",
      "112 Train Loss 0.1210134 Test RE 0.0019003252713325528 c 0.99855554 k 1.0001768 m 5.004214\n",
      "113 Train Loss 0.11332539 Test RE 0.0018907233911119984 c 1.000295 k 1.0003853 m 5.0115623\n",
      "114 Train Loss 0.10450295 Test RE 0.0019056771177204264 c 0.99979895 k 1.0003192 m 5.011469\n",
      "115 Train Loss 0.09677874 Test RE 0.0018543261922888254 c 1.0000536 k 1.0003055 m 4.9981694\n",
      "116 Train Loss 0.093249165 Test RE 0.0018108244677199443 c 1.000166 k 1.000234 m 4.9966855\n",
      "117 Train Loss 0.09177707 Test RE 0.0017895358021739686 c 0.9996218 k 1.0002238 m 5.0005975\n",
      "118 Train Loss 0.090542704 Test RE 0.0017731820361501596 c 0.9990889 k 1.0003053 m 5.0007095\n",
      "119 Train Loss 0.08673671 Test RE 0.0017727766813212633 c 0.99883056 k 1.0002975 m 4.997398\n",
      "120 Train Loss 0.08227577 Test RE 0.0017908918287217873 c 0.9995911 k 1.0003213 m 5.000941\n",
      "121 Train Loss 0.08066869 Test RE 0.0018141728419972995 c 1.0011613 k 1.0002587 m 5.002377\n",
      "122 Train Loss 0.08027877 Test RE 0.0018176315793501491 c 1.0014193 k 1.0001968 m 5.0011716\n",
      "123 Train Loss 0.07940406 Test RE 0.0018159138988259008 c 1.0008013 k 1.0001318 m 4.9978213\n",
      "124 Train Loss 0.07633872 Test RE 0.0017837018697199293 c 0.99854046 k 1.0001764 m 4.995993\n",
      "125 Train Loss 0.06879737 Test RE 0.0016720004837292991 c 0.99991196 k 1.0002851 m 5.0004473\n",
      "126 Train Loss 0.064932674 Test RE 0.0016090943502365552 c 1.0034729 k 1.0000961 m 4.996858\n",
      "127 Train Loss 0.06146133 Test RE 0.0015339197229879153 c 1.0029632 k 1.0000161 m 4.992245\n",
      "128 Train Loss 0.058649674 Test RE 0.0014950080218480908 c 1.0004119 k 1.0000802 m 4.9949284\n",
      "129 Train Loss 0.05660828 Test RE 0.0014801369375168222 c 1.000205 k 1.0001669 m 5.0004444\n",
      "130 Train Loss 0.055257343 Test RE 0.00146571868676552 c 1.0007926 k 1.0001662 m 4.9999595\n",
      "131 Train Loss 0.05351608 Test RE 0.001424730845805634 c 1.0002128 k 1.0001473 m 4.996611\n",
      "132 Train Loss 0.05216419 Test RE 0.0013827668353325296 c 0.99942327 k 1.0001773 m 4.9995584\n",
      "133 Train Loss 0.051605992 Test RE 0.001362044820069837 c 1.0004869 k 1.0001295 m 5.000935\n",
      "134 Train Loss 0.050827987 Test RE 0.001343219581876829 c 1.0011296 k 1.000114 m 4.9994926\n",
      "135 Train Loss 0.050066996 Test RE 0.001328824084803676 c 1.0004233 k 1.0001047 m 4.9980226\n",
      "136 Train Loss 0.049937613 Test RE 0.0013247171957257392 c 1.0001723 k 1.0000889 m 4.9980817\n",
      "137 Train Loss 0.049775854 Test RE 0.0013182181249968695 c 1.0000129 k 1.0000713 m 4.999115\n",
      "138 Train Loss 0.049744114 Test RE 0.0013166303543947968 c 1.0000155 k 1.0000694 m 4.999322\n",
      "139 Train Loss 0.0496014 Test RE 0.0013074240199870638 c 1.0000796 k 1.0000594 m 4.999769\n",
      "140 Train Loss 0.049322177 Test RE 0.001280561815401173 c 1.0001905 k 1.0000784 m 4.9994545\n",
      "141 Train Loss 0.049159504 Test RE 0.0012718151081881684 c 1.000182 k 1.0000925 m 4.999074\n",
      "142 Train Loss 0.049062803 Test RE 0.0012726048012453616 c 1.0001348 k 1.0000893 m 4.9991245\n",
      "143 Train Loss 0.04890077 Test RE 0.0012743156491937342 c 1.0001281 k 1.0000659 m 4.9998164\n",
      "144 Train Loss 0.048719026 Test RE 0.0012732131930125088 c 1.0003102 k 1.0000429 m 5.000183\n",
      "145 Train Loss 0.048219875 Test RE 0.0012593523541579762 c 1.0006938 k 1.0000348 m 4.999553\n",
      "146 Train Loss 0.04741849 Test RE 0.001234654129144646 c 1.0004102 k 1.000109 m 4.9986477\n",
      "147 Train Loss 0.046045467 Test RE 0.0012461600224655705 c 0.9997203 k 1.0001107 m 4.999754\n",
      "148 Train Loss 0.04474144 Test RE 0.0012603122084095502 c 1.0002089 k 1.0000346 m 5.0017514\n",
      "149 Train Loss 0.042965453 Test RE 0.0012359871038643414 c 1.0011156 k 0.99998564 m 5.0015264\n",
      "150 Train Loss 0.042440306 Test RE 0.001219895966251665 c 1.0009807 k 1.0000242 m 5.0016685\n",
      "151 Train Loss 0.041947365 Test RE 0.0012159350028934147 c 1.0009327 k 1.0000685 m 5.0017786\n",
      "152 Train Loss 0.041536838 Test RE 0.0012183142155114254 c 1.001002 k 1.0000657 m 5.001438\n",
      "153 Train Loss 0.040969778 Test RE 0.0012104100265674686 c 1.0007075 k 1.0000408 m 5.001852\n",
      "154 Train Loss 0.040500246 Test RE 0.0011789453025717377 c 1.0002106 k 1.0000731 m 5.0028267\n",
      "155 Train Loss 0.039850578 Test RE 0.0011601011788932537 c 1.000469 k 1.0000452 m 4.9982157\n",
      "156 Train Loss 0.03938158 Test RE 0.0011605358869332465 c 1.0015892 k 1.0000182 m 4.9955425\n",
      "157 Train Loss 0.0381272 Test RE 0.0011430046020403152 c 1.002538 k 1.0000619 m 4.9976606\n",
      "158 Train Loss 0.03680188 Test RE 0.0011089370084395981 c 1.0015664 k 1.0001377 m 5.000425\n",
      "159 Train Loss 0.03602937 Test RE 0.0011013670187546975 c 1.00024 k 1.0000749 m 4.999395\n",
      "160 Train Loss 0.035645545 Test RE 0.001099951453112727 c 1.0000895 k 1.0000521 m 4.9986486\n",
      "161 Train Loss 0.035393808 Test RE 0.001090636987945852 c 1.0005608 k 1.0000792 m 4.999544\n",
      "162 Train Loss 0.03503392 Test RE 0.0010802890874391463 c 1.0010515 k 1.0001153 m 5.0006065\n",
      "163 Train Loss 0.03442311 Test RE 0.001083873572150051 c 1.0008093 k 1.0000582 m 4.999988\n",
      "164 Train Loss 0.033971503 Test RE 0.0010781041238021516 c 1.0008577 k 1.0000433 m 5.000424\n",
      "165 Train Loss 0.033823464 Test RE 0.0010663635435673067 c 1.0009658 k 1.000071 m 5.000818\n",
      "166 Train Loss 0.033612072 Test RE 0.001041295910415424 c 1.0007879 k 1.0000671 m 5.000566\n",
      "167 Train Loss 0.033518586 Test RE 0.001026517658999618 c 1.0004556 k 1.0000572 m 5.0000596\n",
      "168 Train Loss 0.033484995 Test RE 0.0010229850949682719 c 1.000377 k 1.0000571 m 4.999685\n",
      "169 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "170 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "171 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "172 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "173 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "174 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "175 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "176 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "177 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "178 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "179 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "180 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "181 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "182 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "183 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "184 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "185 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "186 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "187 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "188 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "189 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "190 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "191 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "192 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "193 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "194 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "195 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "196 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "197 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "198 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "199 Train Loss 0.0334355 Test RE 0.0010219228790792198 c 1.0003474 k 1.0000614 m 4.9996486\n",
      "Training time: 93.99\n",
      "Training time: 93.99\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 913.81573 Test RE 0.2999850366546704 c -0.11281633 k 1.2861142 m -0.0025319532\n",
      "1 Train Loss 497.38455 Test RE 0.22125794562587434 c -0.124827944 k 1.0162328 m -0.0028008563\n",
      "2 Train Loss 496.95172 Test RE 0.22122348783572646 c -0.124898605 k 1.0175773 m -0.0028024153\n",
      "3 Train Loss 496.90848 Test RE 0.2212108986986129 c -0.12497691 k 1.0179514 m -0.0028041636\n",
      "4 Train Loss 496.35657 Test RE 0.22101303746648665 c -0.12607807 k 1.019038 m -0.002828778\n",
      "5 Train Loss 492.15137 Test RE 0.2195616852599781 c -0.13547274 k 1.0169487 m -0.0030356387\n",
      "6 Train Loss 492.0771 Test RE 0.21963505938243863 c -0.13477145 k 1.0171661 m -0.003018674\n",
      "7 Train Loss 492.05856 Test RE 0.21965978989196322 c -0.13441524 k 1.017242 m -0.003006311\n",
      "8 Train Loss 491.79395 Test RE 0.21954829103399276 c -0.13357712 k 1.0172657 m -0.0029252835\n",
      "9 Train Loss 491.09445 Test RE 0.21936833625852697 c -0.13083667 k 1.0178088 m -0.002526571\n",
      "10 Train Loss 485.84213 Test RE 0.21699472796831368 c -0.1276929 k 1.0109235 m -0.00065256073\n",
      "11 Train Loss 468.4361 Test RE 0.21067173035766465 c -0.09141876 k 1.0190737 m 0.0015361141\n",
      "12 Train Loss 440.07056 Test RE 0.20205769452127118 c -0.03470965 k 1.0092943 m 0.003928209\n",
      "13 Train Loss 341.63483 Test RE 0.16512921923326132 c 0.10914092 k 1.0310495 m 0.008693133\n",
      "14 Train Loss 294.54388 Test RE 0.13696083175370546 c 0.26199242 k 0.99631995 m 0.039810613\n",
      "15 Train Loss 262.8899 Test RE 0.12848190976326998 c 0.6988243 k 1.0071478 m 0.3553577\n",
      "16 Train Loss 206.18602 Test RE 0.09162845747051884 c 1.8656608 k 0.96906865 m 1.3143893\n",
      "17 Train Loss 170.53452 Test RE 0.1051123996208775 c 2.5193772 k 0.98227644 m 2.0545614\n",
      "18 Train Loss 145.98111 Test RE 0.09505770418974326 c 2.2603824 k 0.97741103 m 1.9574909\n",
      "19 Train Loss 125.25209 Test RE 0.0851311197453186 c 1.8363132 k 0.97347 m 1.9568715\n",
      "20 Train Loss 106.877686 Test RE 0.07632638717971782 c 1.9436094 k 0.9759668 m 2.3289785\n",
      "21 Train Loss 93.995476 Test RE 0.06980092453229747 c 1.7035965 k 0.9769546 m 2.5181122\n",
      "22 Train Loss 67.514206 Test RE 0.058896063748541526 c 1.1588533 k 0.98895055 m 3.4183245\n",
      "23 Train Loss 42.80989 Test RE 0.049278616206041834 c 1.1190448 k 0.9976845 m 4.2017565\n",
      "24 Train Loss 37.448547 Test RE 0.047768009137360734 c 1.2021848 k 0.98911864 m 4.1592894\n",
      "25 Train Loss 34.13366 Test RE 0.04681265625027637 c 1.1901984 k 0.9943676 m 4.189112\n",
      "26 Train Loss 31.2218 Test RE 0.04603438609186502 c 1.1135538 k 0.9917931 m 4.2677736\n",
      "27 Train Loss 25.45816 Test RE 0.043503387213951944 c 1.2186484 k 0.9930507 m 4.419685\n",
      "28 Train Loss 22.671812 Test RE 0.04133539701351639 c 1.2292944 k 0.99434173 m 4.5297446\n",
      "29 Train Loss 20.272379 Test RE 0.039477360994868635 c 1.1434083 k 0.99564 m 4.668077\n",
      "30 Train Loss 19.368202 Test RE 0.03839988646076122 c 1.136793 k 0.9971311 m 4.801087\n",
      "31 Train Loss 18.42682 Test RE 0.037140923634581074 c 1.1510415 k 0.9984339 m 4.836462\n",
      "32 Train Loss 15.577734 Test RE 0.0333994092317308 c 1.0968187 k 0.99621844 m 4.604539\n",
      "33 Train Loss 14.329296 Test RE 0.032436712724330616 c 1.121483 k 0.9941384 m 4.5487847\n",
      "34 Train Loss 11.647115 Test RE 0.026655437263595056 c 1.0982826 k 0.9965035 m 4.633425\n",
      "35 Train Loss 9.40327 Test RE 0.024595046903296783 c 1.143432 k 0.9986747 m 4.8475666\n",
      "36 Train Loss 7.5415983 Test RE 0.01988834405028044 c 1.0618414 k 0.99807423 m 5.021406\n",
      "37 Train Loss 6.5858574 Test RE 0.017036654421476886 c 1.0425131 k 1.0004423 m 5.030704\n",
      "38 Train Loss 6.036461 Test RE 0.016511480296298828 c 1.0307385 k 0.9979915 m 5.0404468\n",
      "39 Train Loss 3.9650414 Test RE 0.012134072046796016 c 0.96475345 k 1.0027803 m 5.0204754\n",
      "40 Train Loss 2.0973692 Test RE 0.007905946683244373 c 1.0328547 k 0.9993724 m 4.9405527\n",
      "41 Train Loss 1.6320972 Test RE 0.006633604668746512 c 1.0149834 k 0.9992255 m 4.9287715\n",
      "42 Train Loss 1.3280771 Test RE 0.005723219173092418 c 1.005123 k 1.0002381 m 4.952347\n",
      "43 Train Loss 1.2126077 Test RE 0.005815755898957801 c 1.0074208 k 0.9992157 m 4.964601\n",
      "44 Train Loss 1.049102 Test RE 0.005639444791639178 c 1.011429 k 0.9999108 m 4.9694986\n",
      "45 Train Loss 0.9743675 Test RE 0.0055728082651891496 c 1.0159701 k 1.000047 m 4.975128\n",
      "46 Train Loss 0.926273 Test RE 0.005359034961403389 c 1.0116751 k 0.99968404 m 4.9718523\n",
      "47 Train Loss 0.8740457 Test RE 0.005286750725192633 c 1.0077952 k 0.99978036 m 4.948454\n",
      "48 Train Loss 0.8447546 Test RE 0.00533166366893031 c 1.0126345 k 0.9996649 m 4.955105\n",
      "49 Train Loss 0.781884 Test RE 0.0053583676441983225 c 1.0154941 k 0.9997809 m 4.9853954\n",
      "50 Train Loss 0.71930146 Test RE 0.005232571849521797 c 1.0019473 k 1.0001073 m 4.986113\n",
      "51 Train Loss 0.6588644 Test RE 0.005292941150472594 c 1.0092502 k 0.99983364 m 4.9783854\n",
      "52 Train Loss 0.59874594 Test RE 0.005311333161975102 c 1.0142303 k 1.0001574 m 4.996274\n",
      "53 Train Loss 0.5346502 Test RE 0.004956946906449202 c 1.0021977 k 1.0004238 m 5.0071163\n",
      "54 Train Loss 0.52110255 Test RE 0.004799786658082836 c 1.0026945 k 1.0002856 m 5.012912\n",
      "55 Train Loss 0.5051501 Test RE 0.004727258178161884 c 1.0014809 k 1.0005933 m 5.022329\n",
      "56 Train Loss 0.4501474 Test RE 0.00479569629260106 c 1.0031796 k 1.0002618 m 4.999955\n",
      "57 Train Loss 0.4358706 Test RE 0.004777528638010636 c 1.0002023 k 1.0001303 m 4.9926963\n",
      "58 Train Loss 0.41490376 Test RE 0.004584198093787844 c 0.99728274 k 1.0002936 m 4.9935637\n",
      "59 Train Loss 0.3905631 Test RE 0.004371924241469239 c 1.0007724 k 1.00025 m 4.9888954\n",
      "60 Train Loss 0.3781057 Test RE 0.004398865925559685 c 0.99874836 k 1.0002651 m 4.998928\n",
      "61 Train Loss 0.3733369 Test RE 0.004416676025063979 c 0.9983267 k 1.0003978 m 5.0088825\n",
      "62 Train Loss 0.36196303 Test RE 0.004342296902814009 c 0.99646395 k 1.0005406 m 5.0151978\n",
      "63 Train Loss 0.3353996 Test RE 0.004285202536246003 c 1.0011047 k 1.0004057 m 5.009205\n",
      "64 Train Loss 0.32021108 Test RE 0.00425524300830774 c 0.9979158 k 1.0003184 m 5.010736\n",
      "65 Train Loss 0.29561377 Test RE 0.004031283595930585 c 0.9950531 k 1.0005196 m 5.007078\n",
      "66 Train Loss 0.2793008 Test RE 0.0038499001138559046 c 0.9992897 k 1.0002629 m 4.9950767\n",
      "67 Train Loss 0.26260442 Test RE 0.0037241259137132175 c 1.0016419 k 1.0000184 m 4.989387\n",
      "68 Train Loss 0.2572857 Test RE 0.0036349285465714313 c 1.001208 k 1.0002766 m 4.989121\n",
      "69 Train Loss 0.2466276 Test RE 0.0034075199114057737 c 1.0017244 k 1.0003891 m 4.9907575\n",
      "70 Train Loss 0.23806562 Test RE 0.0033386803405930183 c 1.0006121 k 1.0002635 m 5.000452\n",
      "71 Train Loss 0.23018083 Test RE 0.0033232218503352704 c 0.99651474 k 1.0005444 m 5.0120606\n",
      "72 Train Loss 0.22607979 Test RE 0.003286988750043458 c 0.997802 k 1.0005299 m 5.013805\n",
      "73 Train Loss 0.21976526 Test RE 0.0032375351108708747 c 1.0014801 k 1.0004828 m 5.0184226\n",
      "74 Train Loss 0.19535732 Test RE 0.003147577831050568 c 1.0027725 k 1.0004053 m 5.020498\n",
      "75 Train Loss 0.17956886 Test RE 0.002957959408347244 c 0.9994713 k 1.0004679 m 5.012401\n",
      "76 Train Loss 0.1742276 Test RE 0.0028701889961652268 c 0.9987423 k 1.0003892 m 5.0073667\n",
      "77 Train Loss 0.16959038 Test RE 0.002802351237138747 c 0.99749756 k 1.0004102 m 5.0045695\n",
      "78 Train Loss 0.15966105 Test RE 0.002636917458164874 c 0.99689674 k 1.0004059 m 4.9998646\n",
      "79 Train Loss 0.14562517 Test RE 0.0025320734123033014 c 1.001698 k 1.0004702 m 5.0070243\n",
      "80 Train Loss 0.13818747 Test RE 0.002482456356502508 c 1.003403 k 1.0003563 m 5.003238\n",
      "81 Train Loss 0.12888648 Test RE 0.0024209856786690325 c 1.001946 k 1.0001893 m 4.986727\n",
      "82 Train Loss 0.12041703 Test RE 0.002312326933153806 c 0.99985296 k 1.0002564 m 4.99325\n",
      "83 Train Loss 0.11773397 Test RE 0.0023257198081705565 c 1.0016551 k 1.000266 m 4.999619\n",
      "84 Train Loss 0.11304527 Test RE 0.0022848947551501425 c 1.000975 k 1.0002589 m 4.9984183\n",
      "85 Train Loss 0.10363643 Test RE 0.002251883107577803 c 0.99849284 k 1.0002006 m 4.993666\n",
      "86 Train Loss 0.095559314 Test RE 0.0022527899480247514 c 1.0012534 k 1.0001805 m 4.99949\n",
      "87 Train Loss 0.092797354 Test RE 0.0022516683724175895 c 1.001977 k 1.0001667 m 5.000482\n",
      "88 Train Loss 0.09147425 Test RE 0.0022375804275765374 c 1.0009229 k 1.0001649 m 4.9988985\n",
      "89 Train Loss 0.0904563 Test RE 0.0022402485078754798 c 0.99986464 k 1.0001696 m 4.999385\n",
      "90 Train Loss 0.086796984 Test RE 0.0021957979314515034 c 0.9987556 k 1.0002078 m 5.0004272\n",
      "91 Train Loss 0.08126977 Test RE 0.0020586749463762663 c 1.0007726 k 1.0001812 m 4.9993997\n",
      "92 Train Loss 0.074538216 Test RE 0.0019085423937445845 c 1.0014353 k 1.0002036 m 5.0021896\n",
      "93 Train Loss 0.07071926 Test RE 0.0018700762724392424 c 1.0003663 k 1.0001668 m 5.001213\n",
      "94 Train Loss 0.06692658 Test RE 0.001855551046237796 c 1.0007082 k 1.000089 m 4.99619\n",
      "95 Train Loss 0.0640766 Test RE 0.001822812024960046 c 0.99998873 k 1.000229 m 4.9994426\n",
      "96 Train Loss 0.06265012 Test RE 0.0018147959377388526 c 0.99957305 k 1.000177 m 5.000279\n",
      "97 Train Loss 0.061878115 Test RE 0.001798043044055042 c 0.9997852 k 1.0001272 m 4.995922\n",
      "98 Train Loss 0.060787775 Test RE 0.0017476142432841187 c 1.0006905 k 1.0001287 m 4.992592\n",
      "99 Train Loss 0.05855603 Test RE 0.001690530871503609 c 1.0007213 k 1.0001875 m 4.997731\n",
      "100 Train Loss 0.05675432 Test RE 0.0016666652725043155 c 0.99918914 k 1.0001633 m 5.0014033\n",
      "101 Train Loss 0.05500991 Test RE 0.0016209587361060236 c 0.9995449 k 1.0000929 m 4.9971824\n",
      "102 Train Loss 0.054216832 Test RE 0.0015845634527676506 c 1.0009366 k 1.0001316 m 4.997185\n",
      "103 Train Loss 0.053527795 Test RE 0.0015656940575526778 c 1.0018145 k 1.0001615 m 4.9997425\n",
      "104 Train Loss 0.052785188 Test RE 0.0015521871647397535 c 1.0007619 k 1.0001595 m 4.998731\n",
      "105 Train Loss 0.052480374 Test RE 0.0015380157938711008 c 0.99981755 k 1.0001675 m 4.998014\n",
      "106 Train Loss 0.052188594 Test RE 0.0015240041945440966 c 0.9993984 k 1.0001942 m 4.998738\n",
      "107 Train Loss 0.051492598 Test RE 0.0015096826060834636 c 0.9996733 k 1.0001836 m 4.9999237\n",
      "108 Train Loss 0.05004744 Test RE 0.0014876121943130406 c 1.0000104 k 1.0001626 m 5.0026746\n",
      "109 Train Loss 0.04761999 Test RE 0.0013749135523292396 c 0.9987289 k 1.0001817 m 5.00355\n",
      "110 Train Loss 0.045144416 Test RE 0.001259478537527807 c 0.9972298 k 1.0001315 m 5.0022087\n",
      "111 Train Loss 0.04364835 Test RE 0.0011941130967819476 c 0.99795336 k 1.0002054 m 5.005495\n",
      "112 Train Loss 0.04225353 Test RE 0.0011274549659439068 c 0.9991115 k 1.0002209 m 5.006648\n",
      "113 Train Loss 0.039257463 Test RE 0.0010551626920956608 c 1.0009727 k 1.0000826 m 4.998383\n",
      "114 Train Loss 0.034990236 Test RE 0.001036767829875682 c 1.0008107 k 1.0000196 m 4.9960465\n",
      "115 Train Loss 0.031797525 Test RE 0.0009981824050169397 c 0.99991894 k 1.0000682 m 5.0000296\n",
      "116 Train Loss 0.028932316 Test RE 0.000981557758096616 c 1.0003054 k 1.0001185 m 5.0001817\n",
      "117 Train Loss 0.026413277 Test RE 0.0009938646191643564 c 0.9991929 k 1.0001059 m 5.0009303\n",
      "118 Train Loss 0.025217377 Test RE 0.000978251076425369 c 0.9994908 k 1.0000544 m 4.999574\n",
      "119 Train Loss 0.024850432 Test RE 0.0009724780162504951 c 1.0003089 k 1.0000399 m 4.9979415\n",
      "120 Train Loss 0.024669811 Test RE 0.0009697158967255205 c 1.0009192 k 1.00003 m 4.9976788\n",
      "121 Train Loss 0.02437029 Test RE 0.0009588340553333139 c 1.0013063 k 1.0000353 m 4.9982905\n",
      "122 Train Loss 0.023748681 Test RE 0.0009205701717093507 c 1.0009731 k 1.000041 m 4.9999332\n",
      "123 Train Loss 0.023090221 Test RE 0.0008934004289059278 c 1.0002702 k 1.0000693 m 5.000017\n",
      "124 Train Loss 0.022108376 Test RE 0.0008752644232463037 c 0.9996643 k 1.0000848 m 4.998411\n",
      "125 Train Loss 0.021653058 Test RE 0.000863839290886076 c 0.9995485 k 1.0000321 m 4.997967\n",
      "126 Train Loss 0.021366991 Test RE 0.0008506308641141607 c 0.9998735 k 1.0000103 m 4.9982266\n",
      "127 Train Loss 0.02103312 Test RE 0.0008323602051801427 c 1.0004103 k 1.000024 m 4.998368\n",
      "128 Train Loss 0.02073197 Test RE 0.0008038915662801336 c 1.0007955 k 1.0000257 m 4.998374\n",
      "129 Train Loss 0.020417906 Test RE 0.0007734405350458855 c 1.0001669 k 1.000009 m 4.9986243\n",
      "130 Train Loss 0.020233102 Test RE 0.0007565648483918128 c 0.9996471 k 1.0000349 m 4.9999757\n",
      "131 Train Loss 0.019832416 Test RE 0.0007343960364108636 c 0.9995255 k 1.0000257 m 5.001924\n",
      "132 Train Loss 0.019498901 Test RE 0.0007187255688579742 c 0.9997731 k 1.000005 m 5.001406\n",
      "133 Train Loss 0.019152302 Test RE 0.0006820626627891876 c 0.99959755 k 1.0000081 m 4.9997125\n",
      "134 Train Loss 0.018634096 Test RE 0.0006317604513317119 c 0.9991871 k 0.9999847 m 4.997092\n",
      "135 Train Loss 0.017956145 Test RE 0.0005771276202119602 c 0.9993983 k 0.99993736 m 4.9957213\n",
      "136 Train Loss 0.017631758 Test RE 0.0005480310879351956 c 1.0002393 k 0.9999471 m 4.9970064\n",
      "137 Train Loss 0.017293893 Test RE 0.0005172938443773194 c 1.000658 k 0.99995035 m 4.9982486\n",
      "138 Train Loss 0.017099757 Test RE 0.0004962060119190337 c 1.0006348 k 0.9999593 m 4.998791\n",
      "139 Train Loss 0.016964 Test RE 0.0004796961842114896 c 1.000523 k 0.99995875 m 4.9995246\n",
      "140 Train Loss 0.016815767 Test RE 0.00047054440330887955 c 1.0001955 k 0.99994385 m 4.999449\n",
      "141 Train Loss 0.016576406 Test RE 0.0004684638982658214 c 0.9997664 k 0.9999541 m 4.9990387\n",
      "142 Train Loss 0.016109345 Test RE 0.0004794806832829379 c 0.99893117 k 0.9999893 m 4.9995766\n",
      "143 Train Loss 0.015480256 Test RE 0.0004915324225371931 c 0.9988949 k 0.9999897 m 5.0008283\n",
      "144 Train Loss 0.014941484 Test RE 0.0005006192149712866 c 0.99983823 k 0.9999736 m 5.000957\n",
      "145 Train Loss 0.014786969 Test RE 0.0005075335129616477 c 1.000125 k 0.999981 m 4.999854\n",
      "146 Train Loss 0.014727013 Test RE 0.0005149978491018197 c 0.99999225 k 0.9999888 m 4.9994407\n",
      "147 Train Loss 0.014615262 Test RE 0.0005236791872954827 c 0.99988025 k 0.9999922 m 4.999185\n",
      "148 Train Loss 0.01443901 Test RE 0.000543433986111578 c 1.0001277 k 0.9999892 m 4.998911\n",
      "149 Train Loss 0.014015373 Test RE 0.0005488479653251895 c 1.0006272 k 1.0000031 m 4.999558\n",
      "150 Train Loss 0.013732174 Test RE 0.0005276152431761688 c 1.0001886 k 0.9999916 m 5.0012407\n",
      "151 Train Loss 0.013493129 Test RE 0.0005262673927377627 c 1.000077 k 1.0000095 m 5.001003\n",
      "152 Train Loss 0.0133327525 Test RE 0.00053549786285909 c 1.000144 k 1.0000033 m 5.000665\n",
      "153 Train Loss 0.013177682 Test RE 0.0005453743501292397 c 1.0001171 k 0.99998957 m 5.0008106\n",
      "154 Train Loss 0.012842291 Test RE 0.0005611190708729569 c 0.99966085 k 1.0000081 m 5.0012355\n",
      "155 Train Loss 0.012420417 Test RE 0.0005627408173426077 c 0.9993527 k 1.0000185 m 4.9998655\n",
      "156 Train Loss 0.012214519 Test RE 0.000561083171081812 c 0.99937487 k 0.99998605 m 4.9983983\n",
      "157 Train Loss 0.012093733 Test RE 0.000560073719008098 c 0.999649 k 0.99996763 m 4.9980273\n",
      "158 Train Loss 0.011817167 Test RE 0.0005571924714436825 c 1.0002536 k 0.99997586 m 4.9984407\n",
      "159 Train Loss 0.01131608 Test RE 0.0005512878644686421 c 1.0006086 k 0.99998903 m 4.9990253\n",
      "160 Train Loss 0.0110255685 Test RE 0.0005323038096488773 c 1.0005865 k 0.99998236 m 4.999393\n",
      "161 Train Loss 0.01085579 Test RE 0.0005114518315258361 c 1.0001785 k 0.99998665 m 4.999841\n",
      "162 Train Loss 0.010732248 Test RE 0.000496555858790462 c 0.99990946 k 0.99998504 m 5.000606\n",
      "163 Train Loss 0.010660991 Test RE 0.0004997817701128317 c 0.9999403 k 0.99998635 m 5.0007815\n",
      "164 Train Loss 0.010600814 Test RE 0.0005056379683526105 c 0.99995285 k 0.9999883 m 5.000792\n",
      "165 Train Loss 0.01049938 Test RE 0.0004995587231864791 c 0.9998666 k 0.99998754 m 5.000742\n",
      "166 Train Loss 0.01043015 Test RE 0.00048804932540751636 c 0.99988115 k 0.99998546 m 5.0003333\n",
      "167 Train Loss 0.01040674 Test RE 0.00048506983597051566 c 0.99999285 k 0.9999757 m 4.9998746\n",
      "168 Train Loss 0.010402682 Test RE 0.00048522271165724485 c 1.0000175 k 0.9999738 m 4.9997864\n",
      "169 Train Loss 0.010388864 Test RE 0.00048661714349730156 c 1.000073 k 0.9999703 m 4.999625\n",
      "170 Train Loss 0.010368818 Test RE 0.0004888946009262806 c 1.0001047 k 0.99997157 m 4.9996247\n",
      "171 Train Loss 0.010333757 Test RE 0.0004926994004016191 c 1.0000272 k 0.9999769 m 4.999943\n",
      "172 Train Loss 0.0102846995 Test RE 0.0004980918640915443 c 0.99997 k 0.99998206 m 5.0001926\n",
      "173 Train Loss 0.01024745 Test RE 0.0005017979630924593 c 1.0000533 k 0.9999822 m 5.0001216\n",
      "174 Train Loss 0.010209192 Test RE 0.0005005517504978454 c 1.0003295 k 0.9999801 m 4.9999747\n",
      "175 Train Loss 0.010136532 Test RE 0.0004892248456065107 c 1.0002596 k 0.9999813 m 5.0001717\n",
      "176 Train Loss 0.010034413 Test RE 0.0004760850385437223 c 0.9997635 k 0.9999793 m 5.0002875\n",
      "177 Train Loss 0.009976011 Test RE 0.00047869368872771703 c 0.9997144 k 0.9999734 m 4.9996963\n",
      "178 Train Loss 0.009897565 Test RE 0.0004743149991874717 c 0.99996364 k 0.9999606 m 4.9989247\n",
      "179 Train Loss 0.009872665 Test RE 0.0004690710596101651 c 0.99997663 k 0.9999663 m 4.999258\n",
      "180 Train Loss 0.009807248 Test RE 0.0004648460839051277 c 0.9998808 k 0.9999785 m 5.0003333\n",
      "181 Train Loss 0.009639513 Test RE 0.0004643524136528259 c 0.9998039 k 0.99998766 m 5.0010047\n",
      "182 Train Loss 0.009438286 Test RE 0.00045455816709783696 c 0.9999124 k 0.999978 m 5.0006614\n",
      "183 Train Loss 0.0092606675 Test RE 0.0004533639914440453 c 1.0001786 k 0.99997663 m 5.000516\n",
      "184 Train Loss 0.009144681 Test RE 0.00046990552092315634 c 1.0002288 k 0.99998105 m 5.0005546\n",
      "185 Train Loss 0.009060444 Test RE 0.00048092659266163283 c 1.0000659 k 0.999981 m 5.000393\n",
      "186 Train Loss 0.009023299 Test RE 0.00048406405678506215 c 0.9998775 k 0.9999829 m 5.0002403\n",
      "187 Train Loss 0.009015583 Test RE 0.0004823919743006061 c 0.9998798 k 0.9999822 m 5.000224\n",
      "188 Train Loss 0.009009426 Test RE 0.000481175875580866 c 0.99989563 k 0.9999818 m 5.0002255\n",
      "189 Train Loss 0.009006633 Test RE 0.00048093297612903285 c 0.9999028 k 0.99998164 m 5.000228\n",
      "190 Train Loss 0.009006632 Test RE 0.00048097622162888607 c 0.9999034 k 0.9999816 m 5.000229\n",
      "191 Train Loss 0.008999107 Test RE 0.00048205307654894934 c 0.99991924 k 0.99998116 m 5.000259\n",
      "192 Train Loss 0.008996573 Test RE 0.0004827147140578513 c 0.99993426 k 0.9999811 m 5.0002723\n",
      "193 Train Loss 0.008992197 Test RE 0.00048398941911550233 c 0.99996084 k 0.99998057 m 5.000281\n",
      "194 Train Loss 0.008992106 Test RE 0.0004839794110493483 c 0.9999609 k 0.99998057 m 5.000281\n",
      "195 Train Loss 0.008992106 Test RE 0.0004839794110493483 c 0.9999609 k 0.99998057 m 5.000281\n",
      "196 Train Loss 0.008992106 Test RE 0.0004839794110493483 c 0.9999609 k 0.99998057 m 5.000281\n",
      "197 Train Loss 0.008992106 Test RE 0.0004839794110493483 c 0.9999609 k 0.99998057 m 5.000281\n",
      "198 Train Loss 0.008992106 Test RE 0.0004839794110493483 c 0.9999609 k 0.99998057 m 5.000281\n",
      "199 Train Loss 0.008992106 Test RE 0.0004839794110493483 c 0.9999609 k 0.99998057 m 5.000281\n",
      "Training time: 102.44\n",
      "Training time: 102.44\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 1167.3516 Test RE 0.3060822201956104 c 0.015009705 k 0.7131275 m -0.0011766272\n",
      "1 Train Loss 497.62634 Test RE 0.22129400486910195 c 0.015231194 k 1.0024776 m -0.001195256\n",
      "2 Train Loss 496.4993 Test RE 0.22112068162734366 c 0.015248407 k 1.0167091 m -0.0011968267\n",
      "3 Train Loss 496.43228 Test RE 0.22110356481098015 c 0.0152360145 k 1.0197031 m -0.0011959858\n",
      "4 Train Loss 495.5206 Test RE 0.22081688645520967 c 0.014883359 k 1.029614 m -0.0011712897\n",
      "5 Train Loss 492.26672 Test RE 0.21961441896112385 c 0.013126712 k 1.0211557 m -0.0010680512\n",
      "6 Train Loss 492.18002 Test RE 0.21963682738128198 c 0.013135931 k 1.0171916 m -0.0010709629\n",
      "7 Train Loss 492.1776 Test RE 0.21964211847226678 c 0.013127234 k 1.0167736 m -0.0010711652\n",
      "8 Train Loss 492.14166 Test RE 0.2196476640389475 c 0.012784441 k 1.0149636 m -0.0010630129\n",
      "9 Train Loss 491.6124 Test RE 0.21942103255820528 c 0.00609346 k 1.0122943 m -0.0008680058\n",
      "10 Train Loss 491.17218 Test RE 0.21921673551715637 c -0.0036886723 k 1.0173541 m -0.0005769231\n",
      "11 Train Loss 491.01263 Test RE 0.2192333847436932 c -0.0153698735 k 1.0190756 m -0.00021826674\n",
      "12 Train Loss 490.8794 Test RE 0.21916677804028858 c -0.02126265 k 1.015115 m -1.7986047e-05\n",
      "13 Train Loss 488.53635 Test RE 0.2183891077476498 c -0.041703332 k 1.0088539 m 0.00074507657\n",
      "14 Train Loss 480.59543 Test RE 0.21618522849955746 c -0.053144522 k 1.0327876 m 0.002181049\n",
      "15 Train Loss 462.05203 Test RE 0.20965762041164132 c -0.07520282 k 1.0037403 m 0.003989066\n",
      "16 Train Loss 425.91187 Test RE 0.19725784897636905 c -0.05637504 k 1.0140426 m 0.005750585\n",
      "17 Train Loss 393.86884 Test RE 0.17562911176369905 c 0.0040496225 k 1.0048825 m 0.009326377\n",
      "18 Train Loss 376.02725 Test RE 0.1738120674742169 c 0.03277682 k 1.0126008 m 0.010890652\n",
      "19 Train Loss 327.99725 Test RE 0.14470936185102118 c 0.3552037 k 1.0148194 m 0.050236225\n",
      "20 Train Loss 276.42322 Test RE 0.12521006110219274 c 0.7870065 k 0.99276155 m 0.1119496\n",
      "21 Train Loss 258.4414 Test RE 0.1247608147242306 c 0.9942882 k 0.9906924 m 0.14887172\n",
      "22 Train Loss 238.54596 Test RE 0.1162472395003679 c 1.1323991 k 0.97368795 m 0.18684237\n",
      "23 Train Loss 224.19238 Test RE 0.10668034197244396 c 1.3695426 k 0.99730736 m 0.2684645\n",
      "24 Train Loss 210.64908 Test RE 0.11013164589767997 c 1.5912226 k 0.98177403 m 0.33414003\n",
      "25 Train Loss 208.14337 Test RE 0.10508329292968814 c 1.6488403 k 0.9812045 m 0.347923\n",
      "26 Train Loss 197.081 Test RE 0.09909686645689653 c 1.7686472 k 0.9764458 m 0.43545374\n",
      "27 Train Loss 178.46205 Test RE 0.09222363798918047 c 1.8004802 k 0.96594495 m 0.6121299\n",
      "28 Train Loss 172.41846 Test RE 0.09604085623410442 c 1.8102875 k 0.978736 m 0.6369466\n",
      "29 Train Loss 161.936 Test RE 0.0921073759406253 c 1.7394387 k 0.9865778 m 0.82377607\n",
      "30 Train Loss 155.84909 Test RE 0.08838141002478739 c 1.7422462 k 0.97190183 m 0.94703555\n",
      "31 Train Loss 150.83188 Test RE 0.08694785424385244 c 1.669993 k 0.9716725 m 1.0371823\n",
      "32 Train Loss 147.70862 Test RE 0.08832310641918964 c 1.6118311 k 0.97361326 m 1.0986017\n",
      "33 Train Loss 146.81949 Test RE 0.08892939540977272 c 1.621258 k 0.976967 m 1.1133898\n",
      "34 Train Loss 137.01877 Test RE 0.08532881126773165 c 1.8330864 k 0.9741258 m 1.3459079\n",
      "35 Train Loss 130.0105 Test RE 0.08888881540886126 c 1.8549244 k 0.97255087 m 1.5167259\n",
      "36 Train Loss 123.63628 Test RE 0.09285994498071905 c 1.8399035 k 0.9734127 m 1.7724714\n",
      "37 Train Loss 120.27479 Test RE 0.09448321391032204 c 1.878939 k 0.9810864 m 1.8480793\n",
      "38 Train Loss 98.000916 Test RE 0.08543536625685093 c 1.8942481 k 0.9804429 m 2.5667205\n",
      "39 Train Loss 73.579926 Test RE 0.06269743145068532 c 1.827491 k 0.97021693 m 3.149044\n",
      "40 Train Loss 64.54863 Test RE 0.06129935456044677 c 1.7603939 k 0.98636514 m 3.3819163\n",
      "41 Train Loss 56.040802 Test RE 0.06331945561016691 c 1.6379563 k 0.98639077 m 3.628652\n",
      "42 Train Loss 51.870518 Test RE 0.06082999538644759 c 1.568141 k 0.98633206 m 3.6157424\n",
      "43 Train Loss 47.491745 Test RE 0.05716428180691582 c 1.4510524 k 0.9847279 m 3.662266\n",
      "44 Train Loss 45.224285 Test RE 0.05406553355216025 c 1.3920026 k 0.9824036 m 3.7255516\n",
      "45 Train Loss 37.794178 Test RE 0.048832195072681744 c 1.3005596 k 0.9893303 m 4.016079\n",
      "46 Train Loss 30.475842 Test RE 0.042032107999293675 c 1.1385213 k 0.98884654 m 4.4255357\n",
      "47 Train Loss 24.140648 Test RE 0.032763780009850516 c 1.0719222 k 1.0002809 m 4.6965322\n",
      "48 Train Loss 20.018045 Test RE 0.026270494282655956 c 1.1055051 k 0.99817693 m 4.862377\n",
      "49 Train Loss 15.566425 Test RE 0.025814477849907702 c 1.111733 k 1.0006417 m 4.820892\n",
      "50 Train Loss 12.382572 Test RE 0.02506585306276998 c 1.1261969 k 0.99603015 m 4.712088\n",
      "51 Train Loss 11.033501 Test RE 0.02421406216421467 c 1.0652512 k 0.9983651 m 4.7043996\n",
      "52 Train Loss 10.094131 Test RE 0.023341188036058585 c 1.0943589 k 0.99806154 m 4.7793403\n",
      "53 Train Loss 9.697294 Test RE 0.02317157938461291 c 1.1217827 k 0.99649453 m 4.8029556\n",
      "54 Train Loss 8.648602 Test RE 0.02376768238194726 c 1.1064222 k 0.9966879 m 4.854638\n",
      "55 Train Loss 7.0559797 Test RE 0.021835099146005125 c 1.0879868 k 0.99931955 m 4.999211\n",
      "56 Train Loss 6.810785 Test RE 0.021252095240983385 c 1.0828724 k 1.0007381 m 5.0630994\n",
      "57 Train Loss 6.63164 Test RE 0.021076211993895123 c 1.073284 k 1.0006914 m 5.1137\n",
      "58 Train Loss 6.342058 Test RE 0.020211748745234622 c 1.0611887 k 1.0009166 m 5.1425676\n",
      "59 Train Loss 5.653603 Test RE 0.018926674207146672 c 1.0341392 k 1.0017139 m 5.073131\n",
      "60 Train Loss 5.3827357 Test RE 0.01856419031954836 c 1.0490065 k 1.0004956 m 5.052573\n",
      "61 Train Loss 5.238593 Test RE 0.018448518479181407 c 1.0549145 k 0.9994741 m 5.007776\n",
      "62 Train Loss 5.001047 Test RE 0.018260109306370304 c 1.0376687 k 0.9990232 m 4.9103346\n",
      "63 Train Loss 4.852877 Test RE 0.01803626524268679 c 1.0424423 k 0.99869126 m 4.8905416\n",
      "64 Train Loss 4.687584 Test RE 0.01792395787844692 c 1.0429353 k 0.9988799 m 4.937227\n",
      "65 Train Loss 4.523229 Test RE 0.017528795346133687 c 1.0124422 k 0.999537 m 4.9391713\n",
      "66 Train Loss 4.362205 Test RE 0.016987643866690116 c 0.98695123 k 1.0001233 m 4.9707313\n",
      "67 Train Loss 4.212017 Test RE 0.016708379576082073 c 1.0002648 k 1.0002254 m 5.010842\n",
      "68 Train Loss 4.0671487 Test RE 0.01643085599864419 c 1.0202396 k 1.0001876 m 4.995378\n",
      "69 Train Loss 3.9317646 Test RE 0.01597372282600051 c 1.0245001 k 0.99949455 m 4.939684\n",
      "70 Train Loss 3.859678 Test RE 0.015908952199188704 c 1.0267136 k 0.99931335 m 4.914612\n",
      "71 Train Loss 3.7163527 Test RE 0.015960398851588085 c 1.0364845 k 0.99983567 m 4.9185853\n",
      "72 Train Loss 3.5581012 Test RE 0.01585687312260734 c 1.0381904 k 0.99928975 m 4.943879\n",
      "73 Train Loss 3.3952641 Test RE 0.015698199055991787 c 1.0400257 k 0.99889946 m 4.9845166\n",
      "74 Train Loss 3.1277382 Test RE 0.014968798733688537 c 1.0428972 k 1.0006752 m 5.0377626\n",
      "75 Train Loss 2.8955045 Test RE 0.014053761654903822 c 1.0396731 k 1.0010263 m 5.077054\n",
      "76 Train Loss 2.6204777 Test RE 0.012672287206356117 c 1.0023221 k 1.0005968 m 5.0382047\n",
      "77 Train Loss 2.4565465 Test RE 0.01214534931604853 c 1.0064529 k 1.0007914 m 5.025934\n",
      "78 Train Loss 2.3823264 Test RE 0.011732487858987617 c 1.0051378 k 1.0007113 m 5.030208\n",
      "79 Train Loss 2.3028626 Test RE 0.011375483307295497 c 1.0006758 k 1.0002332 m 5.012819\n",
      "80 Train Loss 2.1411576 Test RE 0.01096647606415034 c 1.002466 k 1.0010417 m 4.98916\n",
      "81 Train Loss 1.9482058 Test RE 0.010927394797628425 c 1.0027174 k 1.000319 m 4.970436\n",
      "82 Train Loss 1.8133023 Test RE 0.010684741545161767 c 1.0191375 k 0.99843115 m 4.937306\n",
      "83 Train Loss 1.7523263 Test RE 0.01023894017224161 c 1.0253423 k 0.9994323 m 4.925269\n",
      "84 Train Loss 1.7006309 Test RE 0.009831616191017219 c 1.0106709 k 0.9999745 m 4.9319434\n",
      "85 Train Loss 1.6331573 Test RE 0.00931487885725124 c 1.0092881 k 0.9991041 m 4.948962\n",
      "86 Train Loss 1.5053738 Test RE 0.008320850796078565 c 1.0219742 k 0.9994389 m 4.959539\n",
      "87 Train Loss 1.4220083 Test RE 0.008191306956002176 c 1.0100236 k 0.9997519 m 4.949451\n",
      "88 Train Loss 1.3130767 Test RE 0.008073963062007937 c 1.0027626 k 0.9989425 m 4.92421\n",
      "89 Train Loss 1.2193557 Test RE 0.00778914772444446 c 1.0144185 k 0.9995705 m 4.9290233\n",
      "90 Train Loss 1.1434953 Test RE 0.007708104783336839 c 1.0179355 k 1.0000254 m 4.9446907\n",
      "91 Train Loss 1.0656784 Test RE 0.0071295956585963926 c 0.9983738 k 1.0000203 m 4.9657464\n",
      "92 Train Loss 0.9265928 Test RE 0.006344383295694472 c 0.9920513 k 1.0000219 m 4.9658566\n",
      "93 Train Loss 0.63248795 Test RE 0.005096592566805889 c 1.0119853 k 0.99995756 m 4.9624777\n",
      "94 Train Loss 0.5928059 Test RE 0.005079932001315136 c 1.002323 k 0.99968195 m 4.9699554\n",
      "95 Train Loss 0.56812185 Test RE 0.004852644265409134 c 0.99926704 k 1.0000007 m 4.98749\n",
      "96 Train Loss 0.55567527 Test RE 0.004750891966428315 c 1.0049123 k 1.0002316 m 4.9986\n",
      "97 Train Loss 0.5321547 Test RE 0.004691718253319438 c 1.0086745 k 1.000125 m 5.014132\n",
      "98 Train Loss 0.5174416 Test RE 0.004614187202341498 c 1.0031713 k 1.0001267 m 5.0185046\n",
      "99 Train Loss 0.50193965 Test RE 0.004494624188880973 c 1.0009327 k 1.0002904 m 5.0182295\n",
      "100 Train Loss 0.4983629 Test RE 0.004496149030271935 c 1.0036016 k 1.0003237 m 5.0146813\n",
      "101 Train Loss 0.4981076 Test RE 0.00449957265791708 c 1.0039663 k 1.0003288 m 5.014156\n",
      "102 Train Loss 0.4936123 Test RE 0.004526943775061089 c 1.0070652 k 1.0003625 m 5.006985\n",
      "103 Train Loss 0.4733495 Test RE 0.004425588019217485 c 1.0078847 k 1.000215 m 5.003469\n",
      "104 Train Loss 0.4610081 Test RE 0.004223210491903765 c 1.0055252 k 1.0002289 m 5.0070777\n",
      "105 Train Loss 0.44008905 Test RE 0.0037898650309453282 c 1.0033555 k 1.000244 m 4.995801\n",
      "106 Train Loss 0.42572004 Test RE 0.0036257677830383926 c 1.0074155 k 0.99991757 m 4.9795055\n",
      "107 Train Loss 0.4164736 Test RE 0.0036032113736847895 c 1.0085711 k 0.99959713 m 4.973639\n",
      "108 Train Loss 0.41085184 Test RE 0.003552307658757907 c 1.0062182 k 0.99957436 m 4.9682655\n",
      "109 Train Loss 0.40647292 Test RE 0.003521517040672111 c 1.0057063 k 0.9997534 m 4.960088\n",
      "110 Train Loss 0.4036978 Test RE 0.0035185298095384877 c 1.00718 k 0.99987876 m 4.9540925\n",
      "111 Train Loss 0.38649705 Test RE 0.0035246007567901996 c 1.0131954 k 0.99923927 m 4.9502487\n",
      "112 Train Loss 0.3618465 Test RE 0.0034408029863251598 c 1.0129256 k 0.99888027 m 4.9591074\n",
      "113 Train Loss 0.29982376 Test RE 0.003158214859224583 c 1.0019192 k 0.9996924 m 4.9816074\n",
      "114 Train Loss 0.2534141 Test RE 0.002558363616128735 c 0.99677384 k 1.0002321 m 4.999242\n",
      "115 Train Loss 0.24544388 Test RE 0.002527554481587848 c 1.0003154 k 1.0000604 m 4.9982023\n",
      "116 Train Loss 0.23583627 Test RE 0.0024781413521443372 c 1.0034838 k 1.0001234 m 4.9946046\n",
      "117 Train Loss 0.22177085 Test RE 0.002278479657665113 c 1.0020179 k 1.0002389 m 5.0016737\n",
      "118 Train Loss 0.2138584 Test RE 0.002117074713635881 c 1.0011382 k 1.0000684 m 5.003947\n",
      "119 Train Loss 0.20469877 Test RE 0.0020256944352211384 c 1.0010922 k 0.9998936 m 4.995857\n",
      "120 Train Loss 0.19805837 Test RE 0.001998984209750882 c 1.0005778 k 0.99999255 m 4.9960504\n",
      "121 Train Loss 0.19692075 Test RE 0.0020011815721185434 c 1.0004425 k 1.0000697 m 5.001891\n",
      "122 Train Loss 0.19629827 Test RE 0.0020055487489469945 c 1.0009931 k 1.0001444 m 5.005049\n",
      "123 Train Loss 0.19575413 Test RE 0.001976495865176783 c 1.0016426 k 1.0001191 m 5.0023704\n",
      "124 Train Loss 0.19555508 Test RE 0.0019658954442540303 c 1.0017902 k 1.0000921 m 5.0009604\n",
      "125 Train Loss 0.19398199 Test RE 0.0019356957992045006 c 1.00162 k 0.99998003 m 4.998857\n",
      "126 Train Loss 0.19033346 Test RE 0.0018908071283722184 c 1.0004946 k 0.9998254 m 5.0017176\n",
      "127 Train Loss 0.18698293 Test RE 0.0018681664728806473 c 1.0001049 k 0.9998791 m 5.006265\n",
      "128 Train Loss 0.18305463 Test RE 0.0018592990800367405 c 1.0000315 k 1.0001627 m 5.0068636\n",
      "129 Train Loss 0.17767087 Test RE 0.0018504916167107258 c 0.999599 k 1.0002995 m 5.0006375\n",
      "130 Train Loss 0.17161661 Test RE 0.0018200656501474062 c 0.9995317 k 1.0000241 m 4.996246\n",
      "131 Train Loss 0.16315612 Test RE 0.0017596065391099923 c 1.0012186 k 0.99980974 m 4.9959517\n",
      "132 Train Loss 0.15311244 Test RE 0.001824908010529639 c 1.0031636 k 1.0002279 m 4.9947553\n",
      "133 Train Loss 0.1451622 Test RE 0.0018486355413395129 c 1.0042311 k 1.000133 m 4.9930964\n",
      "134 Train Loss 0.13889796 Test RE 0.001750406640954738 c 1.0024011 k 0.99992275 m 4.9933786\n",
      "135 Train Loss 0.13486813 Test RE 0.0015728081860672972 c 0.9993434 k 1.000001 m 4.993018\n",
      "136 Train Loss 0.13052697 Test RE 0.0014666278067428612 c 1.000844 k 1.0000871 m 4.9888988\n",
      "137 Train Loss 0.12574331 Test RE 0.001449573653897809 c 1.0030988 k 1.00001 m 4.9915214\n",
      "138 Train Loss 0.122551806 Test RE 0.0014395141530889736 c 1.001619 k 1.0000076 m 4.9941506\n",
      "139 Train Loss 0.12177788 Test RE 0.0014256366871041254 c 1.0004679 k 1.0000988 m 4.99257\n",
      "140 Train Loss 0.12106883 Test RE 0.0013806125349744107 c 1.0001968 k 1.0001347 m 4.9896326\n",
      "141 Train Loss 0.11960161 Test RE 0.0013611128781824983 c 1.0009676 k 0.9999856 m 4.9896946\n",
      "142 Train Loss 0.11654092 Test RE 0.0013641973872777677 c 1.0012317 k 0.99993855 m 4.990329\n",
      "143 Train Loss 0.11425039 Test RE 0.0013772469223581757 c 1.0008613 k 1.0000798 m 4.9882097\n",
      "144 Train Loss 0.111937284 Test RE 0.001374200437496873 c 1.0002866 k 1.0001194 m 4.9863205\n",
      "145 Train Loss 0.10547087 Test RE 0.0013497025677283205 c 1.0018299 k 1.000046 m 4.991831\n",
      "146 Train Loss 0.09694306 Test RE 0.0012998892054922823 c 1.003343 k 0.9999345 m 4.996165\n",
      "147 Train Loss 0.08952805 Test RE 0.0012946813417351879 c 1.0027533 k 0.9999798 m 4.994218\n",
      "148 Train Loss 0.08648791 Test RE 0.0012601005775956214 c 1.0013845 k 1.0000626 m 4.9907656\n",
      "149 Train Loss 0.0859932 Test RE 0.0012455357195794575 c 1.0008795 k 1.0000805 m 4.9905105\n",
      "150 Train Loss 0.08579239 Test RE 0.0012341794005998586 c 1.0004876 k 1.0000803 m 4.990998\n",
      "151 Train Loss 0.085544325 Test RE 0.001216078568757611 c 1.000026 k 1.00007 m 4.9922667\n",
      "152 Train Loss 0.08538565 Test RE 0.001203409989313845 c 0.9998391 k 1.0000556 m 4.992976\n",
      "153 Train Loss 0.08516443 Test RE 0.0011887641005663865 c 0.9996594 k 1.0000439 m 4.993141\n",
      "154 Train Loss 0.08460216 Test RE 0.001172052874184274 c 0.999274 k 1.0001503 m 4.9934273\n",
      "155 Train Loss 0.08330757 Test RE 0.001165860958097187 c 0.9986286 k 1.0003481 m 4.994429\n",
      "156 Train Loss 0.08082347 Test RE 0.001179826988228376 c 0.99795395 k 1.0003289 m 4.9941463\n",
      "157 Train Loss 0.07796414 Test RE 0.0011882277037402128 c 0.9982751 k 0.9999657 m 4.9913583\n",
      "158 Train Loss 0.07639524 Test RE 0.0011856104477004246 c 0.99793065 k 0.9998966 m 4.9896765\n",
      "159 Train Loss 0.07364938 Test RE 0.001150058498082554 c 0.9962893 k 1.0001159 m 4.9922943\n",
      "160 Train Loss 0.06930771 Test RE 0.0011142227905168542 c 0.9984717 k 1.0000168 m 4.9964037\n",
      "161 Train Loss 0.06731199 Test RE 0.0011092111756418328 c 1.0020953 k 1.0000209 m 4.993806\n",
      "162 Train Loss 0.066087715 Test RE 0.0010947997086140225 c 1.0031279 k 1.0001266 m 4.991402\n",
      "163 Train Loss 0.064878 Test RE 0.0010896328073413686 c 1.0020387 k 1.0000898 m 4.992713\n",
      "164 Train Loss 0.06290951 Test RE 0.0010737364747376744 c 1.0009941 k 0.99996555 m 4.9952326\n",
      "165 Train Loss 0.061185203 Test RE 0.001088662448552001 c 1.0008818 k 0.9999432 m 4.9949007\n",
      "166 Train Loss 0.059351005 Test RE 0.0010930506107051886 c 1.0007658 k 1.0000087 m 4.993283\n",
      "167 Train Loss 0.05812798 Test RE 0.001080559710253274 c 1.000573 k 1.0000342 m 4.9928236\n",
      "168 Train Loss 0.057738625 Test RE 0.0010693482244979267 c 1.0006496 k 1.000044 m 4.9938602\n",
      "169 Train Loss 0.057610296 Test RE 0.0010671266393953809 c 1.0008581 k 1.0000563 m 4.995439\n",
      "170 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "171 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "172 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "173 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "174 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "175 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "176 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "177 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "178 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "179 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "180 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "181 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "182 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "183 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "184 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "185 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "186 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "187 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "188 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "189 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "190 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "191 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "192 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "193 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "194 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "195 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "196 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "197 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "198 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "199 Train Loss 0.05760379 Test RE 0.001067021294869465 c 1.0008641 k 1.0000565 m 4.9954934\n",
      "Training time: 98.34\n",
      "Training time: 98.34\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 539.0541 Test RE 0.2282635486561414 c -0.012311119 k 0.93157953 m 0.0017945715\n",
      "1 Train Loss 496.5523 Test RE 0.2211306102283551 c -0.012539494 k 1.0148032 m 0.001831028\n",
      "2 Train Loss 496.3849 Test RE 0.2210929921746967 c -0.012563898 k 1.0200384 m 0.001834751\n",
      "3 Train Loss 494.68665 Test RE 0.22052088530228278 c -0.012832045 k 1.033981 m 0.0018686844\n",
      "4 Train Loss 491.53937 Test RE 0.21932377341258344 c -0.01372156 k 1.0204388 m 0.0019060357\n",
      "5 Train Loss 491.47165 Test RE 0.21936187891869088 c -0.013760229 k 1.0171986 m 0.0019034904\n",
      "6 Train Loss 491.4714 Test RE 0.21936257977115595 c -0.01376029 k 1.0171537 m 0.0019034572\n",
      "7 Train Loss 491.4689 Test RE 0.21937035502676563 c -0.013752798 k 1.0166414 m 0.001903217\n",
      "8 Train Loss 491.44852 Test RE 0.21938759218703746 c -0.0135904 k 1.0150172 m 0.0019050166\n",
      "9 Train Loss 491.28525 Test RE 0.21935244591143627 c -0.012462552 k 1.0123159 m 0.0019286413\n",
      "10 Train Loss 491.10605 Test RE 0.21925615517322541 c -0.011612838 k 1.0165867 m 0.0019486962\n",
      "11 Train Loss 491.09357 Test RE 0.2192183593167591 c -0.01165427 k 1.0176123 m 0.0019476046\n",
      "12 Train Loss 487.50314 Test RE 0.21583905048567012 c 0.0071829185 k 1.0267324 m 0.0020430873\n",
      "13 Train Loss 458.72235 Test RE 0.2085441002835859 c 0.031112056 k 1.031 m 0.0021916234\n",
      "14 Train Loss 436.2659 Test RE 0.19735656708395577 c 0.04523448 k 0.98640114 m 0.0022568898\n",
      "15 Train Loss 425.04254 Test RE 0.1910337089865425 c 0.068212986 k 1.0272126 m 0.0012827942\n",
      "16 Train Loss 399.85822 Test RE 0.1798772240689029 c 0.21076354 k 0.987456 m -0.0061351554\n",
      "17 Train Loss 375.47464 Test RE 0.17076904272937313 c 0.65852404 k 1.0118679 m -0.024731643\n",
      "18 Train Loss 366.69962 Test RE 0.16871124122434253 c 1.3988284 k 0.99442756 m -0.03911351\n",
      "19 Train Loss 360.6887 Test RE 0.16800565624426764 c 1.9470049 k 0.9973345 m -0.041537955\n",
      "20 Train Loss 356.10022 Test RE 0.16526050839785975 c 2.518973 k 0.98545164 m -0.039326202\n",
      "21 Train Loss 352.24728 Test RE 0.16499657200878656 c 2.976921 k 0.9908607 m -0.018548677\n",
      "22 Train Loss 351.11612 Test RE 0.16593023728462095 c 3.2688146 k 0.988335 m -0.00066857773\n",
      "23 Train Loss 350.80725 Test RE 0.16587665212414635 c 3.3177767 k 0.9857092 m 0.010820369\n",
      "24 Train Loss 349.74103 Test RE 0.1655913736760318 c 3.462971 k 0.9850769 m 0.07021338\n",
      "25 Train Loss 348.14926 Test RE 0.164990754143058 c 3.3128643 k 0.9870836 m 0.12778045\n",
      "26 Train Loss 335.9196 Test RE 0.16260219061434286 c 2.849796 k 0.97618353 m 0.44075072\n",
      "27 Train Loss 324.92438 Test RE 0.1574413543764373 c 2.8393836 k 0.98783857 m 0.53285384\n",
      "28 Train Loss 308.85986 Test RE 0.1523316589117563 c 2.44482 k 0.99202853 m 0.75606805\n",
      "29 Train Loss 301.39374 Test RE 0.1465055902603284 c 2.091769 k 0.9905199 m 0.79299617\n",
      "30 Train Loss 297.59033 Test RE 0.14279202737761573 c 1.8664329 k 0.98993087 m 0.8552017\n",
      "31 Train Loss 292.29343 Test RE 0.14370210466839722 c 1.9078985 k 0.9895162 m 0.9155824\n",
      "32 Train Loss 269.69968 Test RE 0.13755928974173123 c 2.2933729 k 0.9774941 m 1.1971126\n",
      "33 Train Loss 231.23595 Test RE 0.12525129818141206 c 2.150094 k 0.98890626 m 2.0875351\n",
      "34 Train Loss 194.09183 Test RE 0.10650716249352118 c 1.8868164 k 0.9705961 m 2.4602828\n",
      "35 Train Loss 179.0954 Test RE 0.10540679656265771 c 1.543508 k 0.9763765 m 2.5764909\n",
      "36 Train Loss 149.09857 Test RE 0.09989196963176968 c 0.8959792 k 0.98348546 m 2.9289823\n",
      "37 Train Loss 124.18068 Test RE 0.08575003275166632 c 1.2607569 k 0.98096704 m 2.9991534\n",
      "38 Train Loss 100.13073 Test RE 0.07503224997680026 c 1.474481 k 0.973271 m 3.3589647\n",
      "39 Train Loss 83.647194 Test RE 0.07296540632786423 c 1.5783864 k 0.9888783 m 3.5470178\n",
      "40 Train Loss 77.91295 Test RE 0.07374218329539105 c 1.6275034 k 0.9854411 m 3.569289\n",
      "41 Train Loss 74.41701 Test RE 0.07184484626471213 c 1.5391294 k 0.98284954 m 3.626956\n",
      "42 Train Loss 69.99037 Test RE 0.06974254870069878 c 1.6246121 k 0.99450505 m 3.6881886\n",
      "43 Train Loss 65.36551 Test RE 0.06392585680732166 c 1.5024599 k 0.9831143 m 3.7191565\n",
      "44 Train Loss 62.460762 Test RE 0.06477171333126806 c 1.4551069 k 0.9903662 m 3.6190996\n",
      "45 Train Loss 56.910057 Test RE 0.06117444873278418 c 1.4518225 k 0.98242337 m 3.5983038\n",
      "46 Train Loss 53.613472 Test RE 0.05469047634732633 c 1.3042681 k 0.98988473 m 3.5894988\n",
      "47 Train Loss 50.86315 Test RE 0.050056560292977746 c 1.3369706 k 0.9864184 m 3.5293043\n",
      "48 Train Loss 41.873665 Test RE 0.043514624498556455 c 1.2794598 k 0.98546994 m 3.7978902\n",
      "49 Train Loss 37.291725 Test RE 0.0419880811193316 c 1.1638191 k 0.99102646 m 3.7353594\n",
      "50 Train Loss 33.16909 Test RE 0.04065482734326953 c 1.1667084 k 0.98188496 m 3.6329944\n",
      "51 Train Loss 30.285282 Test RE 0.036561315426855596 c 1.2027055 k 0.98773646 m 3.6854372\n",
      "52 Train Loss 27.518442 Test RE 0.03471076300232606 c 1.0836712 k 0.9864336 m 3.7483923\n",
      "53 Train Loss 24.876106 Test RE 0.03529672367830599 c 1.174902 k 0.9905345 m 3.830922\n",
      "54 Train Loss 21.97925 Test RE 0.03434525842968455 c 1.1785613 k 0.99043876 m 4.0954127\n",
      "55 Train Loss 20.67424 Test RE 0.035472718020153136 c 1.2049153 k 0.9910662 m 4.209131\n",
      "56 Train Loss 16.594936 Test RE 0.03200809925287097 c 1.2130871 k 0.9934951 m 4.4868603\n",
      "57 Train Loss 15.248254 Test RE 0.030777322634040902 c 1.0902963 k 0.9954059 m 4.565722\n",
      "58 Train Loss 14.405619 Test RE 0.03045149530317792 c 1.1041783 k 0.99576724 m 4.5886855\n",
      "59 Train Loss 14.116129 Test RE 0.030394237526517643 c 1.110957 k 0.9959677 m 4.6262374\n",
      "60 Train Loss 13.554263 Test RE 0.0297150315373625 c 1.0799948 k 0.9978855 m 4.7504873\n",
      "61 Train Loss 12.688528 Test RE 0.028703790563289977 c 1.0924482 k 0.99820703 m 4.91684\n",
      "62 Train Loss 11.4383745 Test RE 0.02706228433053845 c 1.0817108 k 0.9989535 m 4.9577017\n",
      "63 Train Loss 10.787464 Test RE 0.025851521140227835 c 1.0638903 k 0.999686 m 5.0327234\n",
      "64 Train Loss 10.140489 Test RE 0.024721491624931938 c 1.052394 k 1.000052 m 5.0479326\n",
      "65 Train Loss 9.743526 Test RE 0.024242152269345764 c 1.0312816 k 0.99951595 m 5.00075\n",
      "66 Train Loss 9.503098 Test RE 0.02395759688764629 c 1.0292673 k 0.9994003 m 4.9731355\n",
      "67 Train Loss 9.154419 Test RE 0.023498333782221673 c 1.0312932 k 0.99931 m 4.9867744\n",
      "68 Train Loss 8.946371 Test RE 0.023362410354960218 c 1.0249491 k 0.99968207 m 4.960293\n",
      "69 Train Loss 8.3119755 Test RE 0.02319560812735044 c 1.0510429 k 0.99799263 m 4.8475456\n",
      "70 Train Loss 7.921806 Test RE 0.02306900411899509 c 1.0466888 k 0.9991004 m 4.9457965\n",
      "71 Train Loss 7.854744 Test RE 0.02283024859821014 c 1.0413347 k 0.9991502 m 4.942376\n",
      "72 Train Loss 7.34006 Test RE 0.02194806534369174 c 1.058374 k 0.9987046 m 4.8851724\n",
      "73 Train Loss 6.6430273 Test RE 0.02075327583787178 c 1.0550951 k 0.9984798 m 4.8184557\n",
      "74 Train Loss 6.2499156 Test RE 0.019643245362291024 c 1.0181508 k 0.99840546 m 4.8431873\n",
      "75 Train Loss 5.6360373 Test RE 0.01844566530617716 c 1.047666 k 0.99828476 m 4.879284\n",
      "76 Train Loss 5.0812774 Test RE 0.01687244755475365 c 1.0219449 k 1.0001732 m 4.93322\n",
      "77 Train Loss 4.390854 Test RE 0.014472377276031513 c 1.0506064 k 0.99896973 m 5.0341806\n",
      "78 Train Loss 4.077661 Test RE 0.013164383037668677 c 1.0121619 k 1.0003179 m 5.0128284\n",
      "79 Train Loss 3.9079065 Test RE 0.0128478095279403 c 1.029735 k 1.0005063 m 5.0142546\n",
      "80 Train Loss 3.7136664 Test RE 0.01287454829480079 c 1.0374306 k 0.9990126 m 4.9329453\n",
      "81 Train Loss 3.598312 Test RE 0.012487863284471455 c 1.0365762 k 0.99876916 m 4.8764606\n",
      "82 Train Loss 3.5261984 Test RE 0.012375481378753786 c 1.03471 k 0.99875504 m 4.8937726\n",
      "83 Train Loss 3.390892 Test RE 0.011952048541123377 c 1.0318601 k 0.99888235 m 4.905986\n",
      "84 Train Loss 3.1192577 Test RE 0.010926435789370751 c 1.0351429 k 0.9982306 m 4.848259\n",
      "85 Train Loss 2.8732257 Test RE 0.01091661659600109 c 1.0020239 k 0.99993336 m 4.9211383\n",
      "86 Train Loss 2.1488042 Test RE 0.010778101041027928 c 1.0205424 k 0.99748236 m 4.8888903\n",
      "87 Train Loss 1.8403852 Test RE 0.010680806145629888 c 1.0270711 k 0.99957955 m 4.924639\n",
      "88 Train Loss 1.653519 Test RE 0.009500638117861632 c 1.0166783 k 0.9995014 m 4.9602075\n",
      "89 Train Loss 1.4656364 Test RE 0.00845515433987329 c 1.016297 k 0.9992719 m 4.9608746\n",
      "90 Train Loss 1.3917092 Test RE 0.008224596341336602 c 1.018238 k 0.99936 m 4.9385853\n",
      "91 Train Loss 1.3465546 Test RE 0.008134435917570406 c 1.0257065 k 0.9991611 m 4.9297705\n",
      "92 Train Loss 1.2121356 Test RE 0.007808700924977392 c 1.0206338 k 0.998831 m 4.9065933\n",
      "93 Train Loss 1.0824134 Test RE 0.007679300057347483 c 1.0209262 k 0.9987172 m 4.902453\n",
      "94 Train Loss 0.9841639 Test RE 0.0072886798580158695 c 1.0120523 k 0.9998737 m 4.9706964\n",
      "95 Train Loss 0.95520437 Test RE 0.0073113434342465975 c 1.0101868 k 1.0002064 m 4.99624\n",
      "96 Train Loss 0.9291376 Test RE 0.0071914666549088135 c 1.0109661 k 1.0000436 m 5.000501\n",
      "97 Train Loss 0.9080136 Test RE 0.006995804287333666 c 1.0079973 k 0.999939 m 4.9913507\n",
      "98 Train Loss 0.89557815 Test RE 0.006983200656172843 c 1.0048963 k 1.0001446 m 4.9854183\n",
      "99 Train Loss 0.8652499 Test RE 0.0070542241503517905 c 1.007557 k 1.0001279 m 4.9785366\n",
      "100 Train Loss 0.8498933 Test RE 0.006972712176596726 c 1.010614 k 0.99997514 m 4.982273\n",
      "101 Train Loss 0.8437141 Test RE 0.0069040199236943735 c 1.0084488 k 1.0000117 m 4.9850063\n",
      "102 Train Loss 0.8301077 Test RE 0.00687429701673298 c 1.0030295 k 1.0000093 m 4.9827394\n",
      "103 Train Loss 0.8109334 Test RE 0.00684907468470477 c 1.00332 k 1.0000427 m 4.98626\n",
      "104 Train Loss 0.7990089 Test RE 0.006832100230619448 c 1.0047488 k 1.0001941 m 4.993975\n",
      "105 Train Loss 0.77831566 Test RE 0.006798123643229909 c 1.0046065 k 1.0004379 m 4.9982476\n",
      "106 Train Loss 0.71246904 Test RE 0.006626786370893972 c 1.0051124 k 0.999741 m 5.0031834\n",
      "107 Train Loss 0.6367794 Test RE 0.00630853382695229 c 1.0064683 k 0.99954665 m 5.005807\n",
      "108 Train Loss 0.54858506 Test RE 0.005673011746447074 c 0.9989677 k 1.0002095 m 4.9876165\n",
      "109 Train Loss 0.4879564 Test RE 0.0052796935633063116 c 1.003475 k 1.0000775 m 4.9839783\n",
      "110 Train Loss 0.47339207 Test RE 0.0052478512103016845 c 1.0043485 k 1.0000327 m 4.9808755\n",
      "111 Train Loss 0.45484543 Test RE 0.005212283415854355 c 1.0032905 k 0.99976367 m 4.977736\n",
      "112 Train Loss 0.4477995 Test RE 0.005092347821767529 c 1.004048 k 0.9999644 m 4.9893665\n",
      "113 Train Loss 0.44473803 Test RE 0.005046991030353735 c 1.0053699 k 0.99998116 m 4.99307\n",
      "114 Train Loss 0.44308415 Test RE 0.005037599890939018 c 1.0040559 k 1.0000043 m 4.991942\n",
      "115 Train Loss 0.4401916 Test RE 0.005044829838579223 c 1.0044066 k 0.9999846 m 4.993727\n",
      "116 Train Loss 0.43418255 Test RE 0.00504771331082312 c 1.0058777 k 0.9999247 m 4.994005\n",
      "117 Train Loss 0.43066144 Test RE 0.004984957486250649 c 1.0031058 k 0.9999293 m 4.993467\n",
      "118 Train Loss 0.4245809 Test RE 0.004909609327171714 c 1.0007285 k 1.000063 m 4.9939017\n",
      "119 Train Loss 0.4188162 Test RE 0.004911556050612578 c 1.0028155 k 1.0001651 m 4.998555\n",
      "120 Train Loss 0.4155022 Test RE 0.004929152277846182 c 1.0042394 k 1.0000215 m 4.9964414\n",
      "121 Train Loss 0.41402406 Test RE 0.004934759989455482 c 1.0049311 k 0.99990225 m 4.989738\n",
      "122 Train Loss 0.41042197 Test RE 0.004910506652715338 c 1.0053399 k 0.99993396 m 4.98642\n",
      "123 Train Loss 0.4066729 Test RE 0.004866260535756472 c 1.0036696 k 1.0000222 m 4.991436\n",
      "124 Train Loss 0.4049018 Test RE 0.004849823591674864 c 1.0027754 k 1.0000485 m 4.9940486\n",
      "125 Train Loss 0.40355405 Test RE 0.004825748567102228 c 1.003026 k 0.99999034 m 4.994636\n",
      "126 Train Loss 0.40167624 Test RE 0.0048014421677384286 c 1.0041418 k 0.9999976 m 4.992818\n",
      "127 Train Loss 0.3991955 Test RE 0.00479310125830217 c 1.0054656 k 1.0000103 m 4.991048\n",
      "128 Train Loss 0.39526266 Test RE 0.004818785380337357 c 1.0043778 k 0.99999416 m 4.989971\n",
      "129 Train Loss 0.3840182 Test RE 0.004802039700571908 c 1.004 k 0.9999222 m 4.9937205\n",
      "130 Train Loss 0.37891448 Test RE 0.00475463884180542 c 1.0047612 k 1.0000387 m 4.9982047\n",
      "131 Train Loss 0.37191215 Test RE 0.004666930623946903 c 1.0052841 k 1.0000973 m 4.9994483\n",
      "132 Train Loss 0.36065555 Test RE 0.004601989676135536 c 1.0044066 k 0.9999071 m 4.992323\n",
      "133 Train Loss 0.3561031 Test RE 0.004576600119320956 c 1.0031111 k 0.99999416 m 4.990859\n",
      "134 Train Loss 0.35100353 Test RE 0.004496074074060449 c 1.0026686 k 1.0000628 m 4.9910765\n",
      "135 Train Loss 0.34645736 Test RE 0.004413233976858251 c 1.0019029 k 0.99998915 m 4.992256\n",
      "136 Train Loss 0.34164572 Test RE 0.004358906947195447 c 1.0014675 k 0.9999321 m 4.995835\n",
      "137 Train Loss 0.33698708 Test RE 0.004352546582498215 c 1.0034302 k 1.000104 m 5.0000587\n",
      "138 Train Loss 0.33045954 Test RE 0.004382520767452022 c 1.0062153 k 1.0004349 m 4.999027\n",
      "139 Train Loss 0.32098916 Test RE 0.004357099761357329 c 1.0058553 k 1.0002636 m 4.9980145\n",
      "140 Train Loss 0.31363297 Test RE 0.004318852753319722 c 1.0043231 k 0.99983054 m 4.998358\n",
      "141 Train Loss 0.30816376 Test RE 0.004300107834759065 c 1.0028741 k 0.9999809 m 4.9951735\n",
      "142 Train Loss 0.30224985 Test RE 0.004253894760639898 c 1.0015684 k 1.0002724 m 4.992831\n",
      "143 Train Loss 0.29884666 Test RE 0.004238034785725678 c 1.0013362 k 0.9999834 m 4.997124\n",
      "144 Train Loss 0.296665 Test RE 0.004226160912720272 c 1.0010381 k 1.0000116 m 5.0018034\n",
      "145 Train Loss 0.2951563 Test RE 0.004204952155106795 c 1.0010608 k 1.000298 m 5.002627\n",
      "146 Train Loss 0.29430357 Test RE 0.004190916707989106 c 1.001026 k 1.0001767 m 4.99997\n",
      "147 Train Loss 0.2939077 Test RE 0.004181690525130485 c 1.0008792 k 1.0000094 m 4.997965\n",
      "148 Train Loss 0.29275405 Test RE 0.004147013414501395 c 1.0014188 k 0.99999964 m 4.9969735\n",
      "149 Train Loss 0.29131553 Test RE 0.004113385882251736 c 1.0025587 k 1.0002178 m 4.9997635\n",
      "150 Train Loss 0.28886324 Test RE 0.004069032787242229 c 1.0029165 k 1.0003641 m 5.003532\n",
      "151 Train Loss 0.2875136 Test RE 0.004055737688289736 c 1.0018398 k 1.0002402 m 5.003112\n",
      "152 Train Loss 0.28660354 Test RE 0.004049800150366377 c 1.0013436 k 1.0001261 m 5.0009584\n",
      "153 Train Loss 0.2842713 Test RE 0.004017760389624367 c 1.0028887 k 1.0001522 m 4.999177\n",
      "154 Train Loss 0.2816695 Test RE 0.003981714685459212 c 1.0024043 k 1.0001646 m 4.9989724\n",
      "155 Train Loss 0.27826804 Test RE 0.003929365351359653 c 0.99945354 k 1.0000267 m 4.996854\n",
      "156 Train Loss 0.2758547 Test RE 0.0038975705324418852 c 0.99875563 k 1.0000294 m 4.9934254\n",
      "157 Train Loss 0.27363783 Test RE 0.003883794414737245 c 1.0012326 k 1.0002627 m 4.9934373\n",
      "158 Train Loss 0.26708305 Test RE 0.0038612721228214937 c 1.0038661 k 1.0003675 m 4.997649\n",
      "159 Train Loss 0.26097554 Test RE 0.0038084767658303066 c 1.000835 k 0.99999964 m 4.9987345\n",
      "160 Train Loss 0.2578329 Test RE 0.0037722738233714748 c 0.99953413 k 1.000023 m 5.0014086\n",
      "161 Train Loss 0.25583655 Test RE 0.0037481315719047202 c 1.000061 k 1.0002942 m 5.0055842\n",
      "162 Train Loss 0.2537876 Test RE 0.0037499120418864637 c 1.0007594 k 1.0004569 m 5.0090356\n",
      "163 Train Loss 0.24961737 Test RE 0.0037737739980580887 c 1.0001262 k 1.0002166 m 5.0038943\n",
      "164 Train Loss 0.24778365 Test RE 0.003797117902092197 c 1.000621 k 1.0001032 m 4.9978814\n",
      "165 Train Loss 0.24680117 Test RE 0.0037908964952916555 c 1.0022062 k 1.0001397 m 4.995709\n",
      "166 Train Loss 0.2449207 Test RE 0.0037735341152419066 c 1.0020686 k 1.0000763 m 4.9953923\n",
      "167 Train Loss 0.24293399 Test RE 0.0037593418241015984 c 0.9994723 k 0.999923 m 4.994805\n",
      "168 Train Loss 0.24052459 Test RE 0.0037195263527622516 c 0.9987296 k 0.99993384 m 4.9947343\n",
      "169 Train Loss 0.238877 Test RE 0.0037043389769148356 c 0.9997434 k 0.9999746 m 4.9961467\n",
      "170 Train Loss 0.23631102 Test RE 0.003719313472209737 c 0.99998236 k 0.99996495 m 4.998306\n",
      "171 Train Loss 0.23348534 Test RE 0.0037222475481760334 c 0.99788684 k 0.9999751 m 4.9989896\n",
      "172 Train Loss 0.23054203 Test RE 0.003663517902775659 c 0.99630594 k 1.0000882 m 4.9966197\n",
      "173 Train Loss 0.22757003 Test RE 0.003596263814177826 c 0.9968249 k 1.0001605 m 4.9938593\n",
      "174 Train Loss 0.22499062 Test RE 0.003557450871524258 c 0.99728423 k 1.0000615 m 4.99236\n",
      "175 Train Loss 0.22202986 Test RE 0.003536608343205518 c 0.9975249 k 0.9999147 m 4.9925003\n",
      "176 Train Loss 0.21841481 Test RE 0.003536597153560418 c 1.0000318 k 1.0000097 m 4.991996\n",
      "177 Train Loss 0.21656366 Test RE 0.0035362439631968705 c 1.0020257 k 1.0000871 m 4.989857\n",
      "178 Train Loss 0.21461195 Test RE 0.0035165303969679103 c 1.0038368 k 0.99976164 m 4.9889264\n",
      "179 Train Loss 0.21245566 Test RE 0.0035326928381134307 c 1.0040289 k 0.9998825 m 4.990324\n",
      "180 Train Loss 0.21117423 Test RE 0.0035479723264189304 c 1.0038869 k 0.99998707 m 4.987145\n",
      "181 Train Loss 0.2101596 Test RE 0.0035458107046275845 c 1.0045154 k 0.99987864 m 4.983335\n",
      "182 Train Loss 0.2072157 Test RE 0.003529340719093157 c 1.0060314 k 0.9996058 m 4.9756927\n",
      "183 Train Loss 0.19175012 Test RE 0.003442389345414659 c 1.0051184 k 0.9998575 m 4.975232\n",
      "184 Train Loss 0.17917398 Test RE 0.0033455199775026282 c 0.9984684 k 1.0005155 m 4.9932632\n",
      "185 Train Loss 0.17082825 Test RE 0.0032566051168017333 c 0.9996487 k 0.99986684 m 4.9985466\n",
      "186 Train Loss 0.16708528 Test RE 0.003238950152326301 c 1.0036817 k 0.9999465 m 4.9990506\n",
      "187 Train Loss 0.16448095 Test RE 0.0032158529109822484 c 1.0052556 k 1.0002229 m 4.997764\n",
      "188 Train Loss 0.16127343 Test RE 0.003202393113606014 c 1.0033741 k 1.0001479 m 4.988111\n",
      "189 Train Loss 0.1598946 Test RE 0.0032119251090644415 c 1.0029 k 0.99988425 m 4.9846377\n",
      "190 Train Loss 0.15618369 Test RE 0.003189867412713321 c 1.0047516 k 0.9997183 m 4.9839425\n",
      "191 Train Loss 0.15116236 Test RE 0.0031289576968620398 c 1.0051576 k 1.0000081 m 4.989845\n",
      "192 Train Loss 0.14699242 Test RE 0.0030461434647595757 c 1.0038689 k 1.0001425 m 4.995355\n",
      "193 Train Loss 0.141405 Test RE 0.0029415623065449257 c 1.0003588 k 0.9998746 m 4.9968333\n",
      "194 Train Loss 0.13734855 Test RE 0.002875260227109616 c 0.99754614 k 0.9999902 m 5.0004425\n",
      "195 Train Loss 0.1356588 Test RE 0.0028826716534650822 c 0.9979844 k 1.0001657 m 5.000394\n",
      "196 Train Loss 0.13360411 Test RE 0.002862863425747437 c 0.9991703 k 1.0001136 m 4.999103\n",
      "197 Train Loss 0.1310231 Test RE 0.002768030557986172 c 0.9993598 k 0.9999441 m 4.997902\n",
      "198 Train Loss 0.12918836 Test RE 0.002667663954274696 c 0.9994679 k 1.0000225 m 4.995477\n",
      "199 Train Loss 0.12839867 Test RE 0.0026425698201304093 c 1.0006444 k 1.0000923 m 4.992625\n",
      "Training time: 106.03\n",
      "Training time: 106.03\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 498.85266 Test RE 0.22140346637969363 c 0.012751613 k 1.0409782 m -0.00024126371\n",
      "1 Train Loss 496.01883 Test RE 0.2209997801230818 c 0.012626593 k 1.0158354 m -0.00023919756\n",
      "2 Train Loss 493.50668 Test RE 0.22008285646824507 c 0.012277232 k 1.0023962 m -0.00023368986\n",
      "3 Train Loss 491.6587 Test RE 0.21938309138517487 c 0.013284778 k 1.0152954 m -0.0002344559\n",
      "4 Train Loss 491.63748 Test RE 0.2193674665358575 c 0.013430624 k 1.0171247 m -0.00023474636\n",
      "5 Train Loss 491.62726 Test RE 0.2193571271080425 c 0.013639442 k 1.0182604 m -0.00023463015\n",
      "6 Train Loss 491.30374 Test RE 0.21922541096427708 c 0.019457858 k 1.0239253 m -0.0002217408\n",
      "7 Train Loss 489.47995 Test RE 0.21886729115047837 c 0.03758389 k 1.0170974 m -0.00017219824\n",
      "8 Train Loss 487.41116 Test RE 0.21781265112922127 c 0.059621967 k 1.0121616 m -0.00013767245\n",
      "9 Train Loss 478.21616 Test RE 0.21479656763193103 c 0.11167857 k 1.0297037 m -0.00016830872\n",
      "10 Train Loss 475.5006 Test RE 0.2142545514433851 c 0.12284188 k 1.0112103 m -0.00012369065\n",
      "11 Train Loss 472.35577 Test RE 0.2119734329647673 c 0.15744466 k 1.0069337 m 5.3693606e-05\n",
      "12 Train Loss 462.97263 Test RE 0.21012328177357625 c 0.23986095 k 1.0265179 m 0.00010714255\n",
      "13 Train Loss 450.27094 Test RE 0.20656399394490346 c 0.29495937 k 1.0113273 m -0.00021806646\n",
      "14 Train Loss 440.96124 Test RE 0.20127868358892095 c 0.30872923 k 1.0128819 m -0.0006625221\n",
      "15 Train Loss 428.6755 Test RE 0.1960191405880342 c 0.35607508 k 1.0115358 m -0.0012315442\n",
      "16 Train Loss 369.09943 Test RE 0.17496848633286455 c 0.479029 k 1.0022106 m -0.003097127\n",
      "17 Train Loss 336.43353 Test RE 0.16129269496230136 c 0.54865474 k 1.006314 m -0.0025921245\n",
      "18 Train Loss 311.3269 Test RE 0.1349809264065317 c 0.7005048 k 0.99250233 m 0.004454813\n",
      "19 Train Loss 282.90298 Test RE 0.12456218077775115 c 0.76406497 k 0.99933845 m 0.017654343\n",
      "20 Train Loss 272.05328 Test RE 0.12343069929630816 c 0.8040545 k 0.9873344 m 0.037929542\n",
      "21 Train Loss 246.4823 Test RE 0.11590430409250944 c 1.0358387 k 0.97811246 m 0.18910024\n",
      "22 Train Loss 226.15479 Test RE 0.11244320618882139 c 1.3095583 k 0.98522574 m 0.34243277\n",
      "23 Train Loss 204.19482 Test RE 0.10357972360527468 c 1.5334957 k 0.96585596 m 0.49741715\n",
      "24 Train Loss 193.71658 Test RE 0.09997563081753569 c 1.5896528 k 0.9796761 m 0.5536626\n",
      "25 Train Loss 188.88306 Test RE 0.09495820059593882 c 1.6473609 k 0.9688898 m 0.62400556\n",
      "26 Train Loss 174.68274 Test RE 0.09400328985746953 c 1.7603298 k 0.96985996 m 0.8440365\n",
      "27 Train Loss 166.85721 Test RE 0.09756579340723137 c 1.8070949 k 0.97781193 m 0.96843857\n",
      "28 Train Loss 163.53745 Test RE 0.09521286154797215 c 1.8734924 k 0.97277415 m 1.106737\n",
      "29 Train Loss 162.6603 Test RE 0.09213423801528954 c 1.8701112 k 0.9785246 m 1.1020473\n",
      "30 Train Loss 161.66922 Test RE 0.09229038843325257 c 1.8165052 k 0.97488666 m 1.0538509\n",
      "31 Train Loss 159.04066 Test RE 0.09205202058968126 c 1.7013413 k 0.97215575 m 1.0478877\n",
      "32 Train Loss 156.46045 Test RE 0.0880702947415469 c 1.6160808 k 0.9812855 m 1.1448385\n",
      "33 Train Loss 145.995 Test RE 0.08719634816799327 c 1.4787159 k 0.97061145 m 1.4587806\n",
      "34 Train Loss 126.24107 Test RE 0.08511491229093092 c 1.1581126 k 0.9637355 m 1.8156457\n",
      "35 Train Loss 109.110306 Test RE 0.07368336131261166 c 1.0063336 k 0.9814335 m 1.8486631\n",
      "36 Train Loss 105.32892 Test RE 0.07203884429235488 c 1.0234157 k 0.9741782 m 1.8732084\n",
      "37 Train Loss 93.00177 Test RE 0.06549182099278322 c 1.3973355 k 0.9758768 m 2.1357462\n",
      "38 Train Loss 80.9823 Test RE 0.062394472267495636 c 1.496005 k 0.9812729 m 2.2218692\n",
      "39 Train Loss 77.318695 Test RE 0.0634655881564407 c 1.601725 k 0.9736918 m 2.2758698\n",
      "40 Train Loss 72.7439 Test RE 0.06410059810445014 c 1.7053621 k 0.98048383 m 2.4300694\n",
      "41 Train Loss 68.862076 Test RE 0.06282288815207762 c 1.7211708 k 0.9805414 m 2.607934\n",
      "42 Train Loss 66.48576 Test RE 0.06128677227284136 c 1.749763 k 0.97700787 m 2.6801813\n",
      "43 Train Loss 56.495968 Test RE 0.059081452589189384 c 1.5253594 k 0.9769834 m 2.9843864\n",
      "44 Train Loss 48.107548 Test RE 0.05224623414400342 c 1.3610783 k 0.99158245 m 3.1925395\n",
      "45 Train Loss 44.134384 Test RE 0.04760243037550716 c 1.3579199 k 0.9800379 m 3.4813032\n",
      "46 Train Loss 39.49814 Test RE 0.042898691806000276 c 1.3226779 k 0.9921862 m 3.6967268\n",
      "47 Train Loss 34.606407 Test RE 0.039338003921173655 c 1.1896588 k 0.9883871 m 3.9432015\n",
      "48 Train Loss 34.24196 Test RE 0.038684592056861894 c 1.1912507 k 0.988102 m 3.952732\n",
      "49 Train Loss 33.283234 Test RE 0.03922503999558142 c 1.2557495 k 0.9914605 m 4.0258794\n",
      "50 Train Loss 30.15061 Test RE 0.04069988287300431 c 1.3120328 k 0.9928282 m 4.352604\n",
      "51 Train Loss 28.282038 Test RE 0.03728463580083086 c 1.1924745 k 0.9917602 m 4.367974\n",
      "52 Train Loss 27.034634 Test RE 0.03803394797236353 c 1.2611709 k 0.9941664 m 4.444849\n",
      "53 Train Loss 24.367506 Test RE 0.03897220859119975 c 1.3099513 k 0.99650264 m 4.777863\n",
      "54 Train Loss 22.95847 Test RE 0.03750357271623056 c 1.1849605 k 0.9956916 m 4.979281\n",
      "55 Train Loss 21.767963 Test RE 0.036757117831850844 c 1.1684778 k 1.0021613 m 5.162738\n",
      "56 Train Loss 19.991426 Test RE 0.035096477344472604 c 1.1901257 k 1.0002114 m 5.122829\n",
      "57 Train Loss 18.941343 Test RE 0.03446177377214773 c 1.1280003 k 0.9969293 m 4.9935684\n",
      "58 Train Loss 17.318642 Test RE 0.03379475623607098 c 1.1385261 k 1.0009158 m 4.802223\n",
      "59 Train Loss 16.287004 Test RE 0.03307426792179935 c 1.2061436 k 0.99700177 m 4.8261595\n",
      "60 Train Loss 15.69672 Test RE 0.03304481123335705 c 1.210915 k 0.99549735 m 4.886981\n",
      "61 Train Loss 14.841 Test RE 0.03172271038029621 c 1.1979293 k 0.99782366 m 4.9947033\n",
      "62 Train Loss 14.530985 Test RE 0.030677199693459896 c 1.179075 k 1.0000252 m 5.09313\n",
      "63 Train Loss 13.59244 Test RE 0.028337739216478735 c 1.1173161 k 0.99807787 m 5.1931043\n",
      "64 Train Loss 9.788063 Test RE 0.02187598625442571 c 0.9940399 k 1.0012785 m 5.1593084\n",
      "65 Train Loss 5.9549537 Test RE 0.015320326424155178 c 0.99479127 k 1.0030395 m 5.2326007\n",
      "66 Train Loss 5.1223927 Test RE 0.013697642992006504 c 0.9938074 k 1.0006449 m 5.229095\n",
      "67 Train Loss 4.0126553 Test RE 0.011686135531981745 c 1.0071918 k 1.0003209 m 5.0761037\n",
      "68 Train Loss 3.6397395 Test RE 0.010561762762800766 c 1.0166651 k 0.99890083 m 4.9743075\n",
      "69 Train Loss 3.4172125 Test RE 0.010537647751245093 c 1.0110697 k 0.9988782 m 4.933719\n",
      "70 Train Loss 3.2475536 Test RE 0.010074307159211758 c 1.0329794 k 0.99868315 m 4.9071107\n",
      "71 Train Loss 2.9093075 Test RE 0.009006273589514375 c 1.0517793 k 0.99740183 m 4.863194\n",
      "72 Train Loss 2.5362754 Test RE 0.008557865482413557 c 1.0247227 k 0.998192 m 4.9006405\n",
      "73 Train Loss 2.4205172 Test RE 0.00832539929219661 c 1.0341907 k 0.99844056 m 4.909985\n",
      "74 Train Loss 2.3174553 Test RE 0.00793150425583876 c 1.0350283 k 0.9979529 m 4.877838\n",
      "75 Train Loss 1.681698 Test RE 0.007531422839799872 c 0.98138887 k 0.99882793 m 4.9312444\n",
      "76 Train Loss 1.2976298 Test RE 0.006960085069584375 c 0.98332655 k 1.0004215 m 5.0282264\n",
      "77 Train Loss 1.211808 Test RE 0.0067036097099969095 c 1.0085845 k 1.0001247 m 5.0295887\n",
      "78 Train Loss 1.1976196 Test RE 0.006669648162643907 c 1.0122092 k 0.99960613 m 5.013281\n",
      "79 Train Loss 1.1021765 Test RE 0.006585363397703501 c 1.012071 k 0.9987503 m 4.968987\n",
      "80 Train Loss 0.81750613 Test RE 0.005805908162345776 c 1.0031853 k 0.9998892 m 4.968685\n",
      "81 Train Loss 0.7588842 Test RE 0.005314643385517875 c 1.0048755 k 1.0000882 m 4.974091\n",
      "82 Train Loss 0.7526369 Test RE 0.00527039532295184 c 1.0051492 k 0.9998023 m 4.979202\n",
      "83 Train Loss 0.7463727 Test RE 0.005286427146732868 c 1.0049326 k 0.99975765 m 4.984911\n",
      "84 Train Loss 0.74271715 Test RE 0.005272009555611546 c 1.0047562 k 1.0000161 m 4.9872584\n",
      "85 Train Loss 0.7324071 Test RE 0.005219091685101388 c 1.0040272 k 1.0004797 m 4.987393\n",
      "86 Train Loss 0.6928968 Test RE 0.004916739179840685 c 0.9995866 k 1.0005776 m 4.977711\n",
      "87 Train Loss 0.66008496 Test RE 0.00459151590875226 c 0.99623996 k 0.99988055 m 4.9701195\n",
      "88 Train Loss 0.65028644 Test RE 0.004516613279921657 c 0.9953139 k 0.99987525 m 4.961957\n",
      "89 Train Loss 0.633167 Test RE 0.0045633835782144805 c 0.9994354 k 0.9998705 m 4.9533777\n",
      "90 Train Loss 0.5794717 Test RE 0.004500123275929353 c 1.0076747 k 0.9998482 m 4.9656234\n",
      "91 Train Loss 0.5272764 Test RE 0.003933325428674927 c 1.0015124 k 0.9999384 m 4.9759016\n",
      "92 Train Loss 0.51482284 Test RE 0.003669428901529157 c 1.0016099 k 1.0000883 m 4.9770555\n",
      "93 Train Loss 0.49946937 Test RE 0.0034435780283476216 c 1.0042703 k 1.0001808 m 4.983123\n",
      "94 Train Loss 0.47358787 Test RE 0.003346094291084038 c 1.0024025 k 1.0003453 m 4.9911866\n",
      "95 Train Loss 0.458374 Test RE 0.0034289415379774686 c 0.99875516 k 1.0003151 m 4.998787\n",
      "96 Train Loss 0.45180413 Test RE 0.00347230074293644 c 1.0000712 k 1.0003449 m 5.0069237\n",
      "97 Train Loss 0.42634028 Test RE 0.0032646029137812257 c 1.0010904 k 1.0007643 m 5.0199366\n",
      "98 Train Loss 0.39498132 Test RE 0.0029782510760937874 c 0.99944097 k 1.0007424 m 5.017337\n",
      "99 Train Loss 0.38707387 Test RE 0.0029240502954928516 c 0.99937737 k 1.000501 m 5.011139\n",
      "100 Train Loss 0.38471997 Test RE 0.0029008253842056062 c 0.9985598 k 1.0004134 m 5.0100775\n",
      "101 Train Loss 0.38372937 Test RE 0.0028965637302936684 c 0.9982684 k 1.0004733 m 5.011394\n",
      "102 Train Loss 0.382367 Test RE 0.002888577133911273 c 0.99768066 k 1.0005229 m 5.01185\n",
      "103 Train Loss 0.37908307 Test RE 0.0028617510074337603 c 0.9961831 k 1.0004061 m 5.0096416\n",
      "104 Train Loss 0.3727064 Test RE 0.0027600007626340864 c 0.9953834 k 1.0002829 m 5.003832\n",
      "105 Train Loss 0.36400026 Test RE 0.0026092572758740656 c 0.99570256 k 1.0004292 m 4.9964056\n",
      "106 Train Loss 0.3472084 Test RE 0.002582310875963614 c 0.9948461 k 1.0007627 m 4.9920015\n",
      "107 Train Loss 0.3070808 Test RE 0.002852168423731338 c 0.9982824 k 1.0004058 m 4.9966083\n",
      "108 Train Loss 0.28227955 Test RE 0.0027618717969557336 c 1.00359 k 0.99996257 m 4.9907036\n",
      "109 Train Loss 0.2693076 Test RE 0.002544058316572413 c 0.999375 k 1.000203 m 4.989841\n",
      "110 Train Loss 0.26325655 Test RE 0.002461119826789131 c 0.9984718 k 1.0004153 m 4.997849\n",
      "111 Train Loss 0.25744677 Test RE 0.0024415047919552407 c 1.0021338 k 1.0005237 m 5.006087\n",
      "112 Train Loss 0.25387558 Test RE 0.0024328380099089032 c 1.004343 k 1.0003365 m 5.004576\n",
      "113 Train Loss 0.2455207 Test RE 0.0023318131703341186 c 1.0047369 k 1.0000753 m 5.001351\n",
      "114 Train Loss 0.23371701 Test RE 0.002299192730947258 c 1.0004573 k 1.000333 m 5.0005407\n",
      "115 Train Loss 0.2299693 Test RE 0.0023708153737300856 c 0.9985076 k 1.0005033 m 5.0000553\n",
      "116 Train Loss 0.22771174 Test RE 0.0024285457856556983 c 0.9992526 k 1.0002732 m 4.9975553\n",
      "117 Train Loss 0.22647679 Test RE 0.00243156209374971 c 1.0005896 k 1.000321 m 4.99935\n",
      "118 Train Loss 0.22274749 Test RE 0.0024407670025744102 c 1.0005262 k 1.0004656 m 5.001095\n",
      "119 Train Loss 0.21720019 Test RE 0.002408897953037712 c 1.0000952 k 1.0003586 m 4.9980593\n",
      "120 Train Loss 0.21403094 Test RE 0.0023950188328888716 c 1.0005646 k 1.0003188 m 4.9942484\n",
      "121 Train Loss 0.21138266 Test RE 0.002390902517936401 c 1.0009226 k 1.0003651 m 4.9941998\n",
      "122 Train Loss 0.19983011 Test RE 0.0023418694109708068 c 1.0004275 k 1.0003365 m 4.995512\n",
      "123 Train Loss 0.17904118 Test RE 0.00229017533840992 c 0.99762136 k 0.999781 m 4.992205\n",
      "124 Train Loss 0.15282598 Test RE 0.0021672001993841197 c 0.9949067 k 0.9997662 m 4.9970036\n",
      "125 Train Loss 0.116963014 Test RE 0.0018528654534524485 c 1.000558 k 1.0003572 m 4.9983144\n",
      "126 Train Loss 0.114523314 Test RE 0.0018463926593493371 c 1.0006913 k 1.0002644 m 4.996274\n",
      "127 Train Loss 0.11371712 Test RE 0.0018555555247491261 c 1.0005963 k 1.0001367 m 4.9960217\n",
      "128 Train Loss 0.11223541 Test RE 0.0018453175478022636 c 1.000338 k 1.000136 m 4.999212\n",
      "129 Train Loss 0.11119865 Test RE 0.0018251227502691489 c 0.999894 k 1.0002538 m 5.0012474\n",
      "130 Train Loss 0.110800385 Test RE 0.0018180688960344614 c 0.9997025 k 1.0002549 m 4.9998775\n",
      "131 Train Loss 0.11007114 Test RE 0.0018064525717627826 c 0.99994403 k 1.0001704 m 4.996837\n",
      "132 Train Loss 0.109884396 Test RE 0.0018086594568275146 c 1.0004466 k 1.0001453 m 4.996859\n",
      "133 Train Loss 0.10971043 Test RE 0.001812148433804654 c 1.0007703 k 1.0001742 m 4.997655\n",
      "134 Train Loss 0.109474845 Test RE 0.0018143321618499348 c 1.0010246 k 1.0002395 m 4.998644\n",
      "135 Train Loss 0.1087458 Test RE 0.001802002266473539 c 1.0006429 k 1.0002725 m 4.999246\n",
      "136 Train Loss 0.10769431 Test RE 0.0017830815996842469 c 0.99968106 k 1.0001634 m 4.9990764\n",
      "137 Train Loss 0.10732317 Test RE 0.001778629374254782 c 0.9995103 k 1.0001354 m 4.999557\n",
      "138 Train Loss 0.106831096 Test RE 0.001771390552069253 c 0.999554 k 1.0001915 m 5.000388\n",
      "139 Train Loss 0.105933756 Test RE 0.001757490743610962 c 1.0005941 k 1.0003235 m 4.9989758\n",
      "140 Train Loss 0.10484169 Test RE 0.001721697601043626 c 1.0017513 k 1.000296 m 4.9961963\n",
      "141 Train Loss 0.10374546 Test RE 0.0016852272532454596 c 1.0011494 k 1.0001682 m 4.9974766\n",
      "142 Train Loss 0.10276286 Test RE 0.0016520021170079112 c 1.0003109 k 1.0002009 m 5.000462\n",
      "143 Train Loss 0.10235981 Test RE 0.0016277254730568695 c 1.000145 k 1.0002346 m 5.0002313\n",
      "144 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "145 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "146 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "147 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "148 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "149 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "150 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "151 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "152 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "153 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "154 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "155 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "156 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "157 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "158 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "159 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "160 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "161 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "162 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "163 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "164 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "165 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "166 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "167 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "168 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "169 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "170 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "171 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "172 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "173 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "174 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "175 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "176 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "177 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "178 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "179 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "180 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "181 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "182 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "183 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "184 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "185 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "186 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "187 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "188 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "189 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "190 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "191 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "192 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "193 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "194 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "195 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "196 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "197 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "198 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "199 Train Loss 0.10231424 Test RE 0.001623079150473482 c 1.0002184 k 1.0002322 m 5.000071\n",
      "Training time: 86.62\n",
      "Training time: 86.62\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 924.60706 Test RE 0.28503466677426686 c -0.16701207 k 0.77406853 m 0.0017914576\n",
      "1 Train Loss 497.64706 Test RE 0.2213637464763885 c -0.17633563 k 1.0116315 m 0.0018931056\n",
      "2 Train Loss 497.0734 Test RE 0.22123964194258383 c -0.17721619 k 1.0231105 m 0.0019026317\n",
      "3 Train Loss 492.20407 Test RE 0.21980045210642535 c -0.1836003 k 1.0143721 m 0.0019689302\n",
      "4 Train Loss 491.84824 Test RE 0.21950678472623034 c -0.18547778 k 1.0182701 m 0.0019903705\n",
      "5 Train Loss 491.67734 Test RE 0.2194162990990073 c -0.18588465 k 1.0182134 m 0.0019984695\n",
      "6 Train Loss 491.62515 Test RE 0.21940559569598772 c -0.1859945 k 1.0167985 m 0.0020056248\n",
      "7 Train Loss 490.92746 Test RE 0.219297755349708 c -0.19436829 k 1.0133566 m 0.002401103\n",
      "8 Train Loss 490.44705 Test RE 0.21900762318951805 c -0.1998991 k 1.0236051 m 0.0026654704\n",
      "9 Train Loss 487.84674 Test RE 0.2179519913531716 c -0.21191342 k 1.0148096 m 0.003618515\n",
      "10 Train Loss 486.27634 Test RE 0.2174115486034951 c -0.21853623 k 1.0062499 m 0.0044419495\n",
      "11 Train Loss 482.12848 Test RE 0.21617005558122487 c -0.22998151 k 1.0271354 m 0.0054122275\n",
      "12 Train Loss 479.12985 Test RE 0.21559716257684894 c -0.23383605 k 1.0142441 m 0.005804906\n",
      "13 Train Loss 476.82507 Test RE 0.21369386051225106 c -0.24475458 k 1.0105045 m 0.006402409\n",
      "14 Train Loss 476.44748 Test RE 0.21376818475522805 c -0.24525793 k 1.0176654 m 0.0064090043\n",
      "15 Train Loss 474.09772 Test RE 0.21330974112424492 c -0.24546757 k 1.0239457 m 0.006548431\n",
      "16 Train Loss 466.14935 Test RE 0.20828867335620516 c -0.2225627 k 0.9821323 m 0.007165876\n",
      "17 Train Loss 445.33398 Test RE 0.2041389325105707 c -0.19702429 k 0.9734709 m 0.00737594\n",
      "18 Train Loss 388.7156 Test RE 0.18773886088992073 c -0.16484019 k 1.0269469 m 0.007403293\n",
      "19 Train Loss 346.625 Test RE 0.16170405251034672 c -0.12414252 k 0.9982189 m 0.008082654\n",
      "20 Train Loss 336.1859 Test RE 0.15904302682394675 c -0.15595971 k 1.0312153 m 0.008794819\n",
      "21 Train Loss 330.19904 Test RE 0.15832710055224775 c -0.15977237 k 1.0053774 m 0.008953877\n",
      "22 Train Loss 328.99927 Test RE 0.15752671611970337 c -0.16208412 k 0.999061 m 0.00916618\n",
      "23 Train Loss 326.09753 Test RE 0.1561679840455665 c -0.16573888 k 1.0072304 m 0.009783375\n",
      "24 Train Loss 322.86578 Test RE 0.15451764860689554 c -0.16890629 k 1.0079436 m 0.01082198\n",
      "25 Train Loss 318.18768 Test RE 0.1508042164807918 c -0.1726062 k 1.0009342 m 0.012854276\n",
      "26 Train Loss 311.8607 Test RE 0.14643877417116422 c -0.176096 k 0.9992943 m 0.017128129\n",
      "27 Train Loss 303.95718 Test RE 0.14365954950514045 c -0.17006037 k 1.0040512 m 0.024144476\n",
      "28 Train Loss 294.45447 Test RE 0.13905753325058853 c -0.14914536 k 1.0036098 m 0.031703167\n",
      "29 Train Loss 291.71854 Test RE 0.13617420172620517 c -0.14257056 k 0.9940454 m 0.035583284\n",
      "30 Train Loss 290.65646 Test RE 0.13607460702245064 c -0.14081411 k 0.9988227 m 0.038430557\n",
      "31 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "32 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "33 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "34 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "35 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "36 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "37 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "38 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "39 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "40 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "41 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "42 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "43 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "44 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "45 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "46 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "47 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "48 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "49 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "50 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "51 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "52 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "53 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "54 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "55 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "56 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "57 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "58 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "59 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "60 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "61 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "62 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "63 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "64 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "65 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "66 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "67 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "68 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "69 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "70 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "71 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "72 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "73 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "74 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "75 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "76 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "77 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "78 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "79 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "80 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "81 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "82 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "83 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "84 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "85 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "86 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "87 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "88 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "89 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "90 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "91 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "92 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "93 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "94 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "95 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "96 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "97 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "98 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "99 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "100 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "101 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "102 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "103 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "104 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "105 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "106 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "107 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "108 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "109 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "110 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "111 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "112 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "113 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "114 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "115 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "116 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "117 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "118 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "119 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "120 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "121 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "122 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "123 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "124 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "125 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "126 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "127 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "128 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "129 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "130 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "131 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "132 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "133 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "134 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "135 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "136 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "137 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "138 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "139 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "140 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "141 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "142 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "143 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "144 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "145 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "146 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "147 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "148 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "149 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "150 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "151 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "152 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "153 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "154 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "155 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "156 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "157 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "158 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "159 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "160 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "161 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "162 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "163 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "164 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "165 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "166 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "167 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "168 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "169 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "170 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "171 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "172 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "173 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "174 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "175 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "176 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "177 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "178 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "179 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "180 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "181 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "182 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "183 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "184 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "185 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "186 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "187 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "188 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "189 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "190 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "191 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "192 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "193 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "194 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "195 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "196 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "197 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "198 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "199 Train Loss 290.56244 Test RE 0.1356821110858671 c -0.1413666 k 0.99876475 m 0.03814712\n",
      "Training time: 49.64\n",
      "Training time: 49.64\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 999.2743 Test RE 0.27893059254314634 c 0.12955554 k 0.740379 m -0.00034595875\n",
      "1 Train Loss 493.92526 Test RE 0.220429792043497 c 0.13209368 k 1.0105633 m -0.00035203478\n",
      "2 Train Loss 493.67374 Test RE 0.22038709252210706 c 0.13213299 k 1.0179845 m -0.00035205847\n",
      "3 Train Loss 493.0813 Test RE 0.2201059046225073 c 0.13092875 k 1.0259664 m -0.00034717412\n",
      "4 Train Loss 491.96204 Test RE 0.21948363288284675 c 0.12840678 k 1.0193763 m -0.00033607916\n",
      "5 Train Loss 491.9234 Test RE 0.21950117326710417 c 0.12851939 k 1.0171912 m -0.00033604706\n",
      "6 Train Loss 491.91992 Test RE 0.21950793760074946 c 0.12855625 k 1.016679 m -0.00033569627\n",
      "7 Train Loss 491.8918 Test RE 0.21952311925803572 c 0.12869239 k 1.0149872 m -0.00032729763\n",
      "8 Train Loss 491.4245 Test RE 0.21939686856060545 c 0.12918164 k 1.0095369 m -0.00019021954\n",
      "9 Train Loss 491.01666 Test RE 0.21926903589245847 c 0.1293485 k 1.0151061 m -0.000114329196\n",
      "10 Train Loss 490.98627 Test RE 0.21924234080842947 c 0.12933797 k 1.0171384 m -0.000115270755\n",
      "11 Train Loss 490.9279 Test RE 0.2191361318986043 c 0.12911937 k 1.0179899 m -0.00013063378\n",
      "12 Train Loss 490.68103 Test RE 0.21881424887470532 c 0.12969135 k 1.0139165 m -0.00011224446\n",
      "13 Train Loss 488.77762 Test RE 0.21784772730164562 c 0.13536963 k 1.005014 m 1.5963882e-05\n",
      "14 Train Loss 473.9324 Test RE 0.2149691906184894 c 0.15412177 k 1.0234573 m 0.00019527834\n",
      "15 Train Loss 423.70413 Test RE 0.19671951632725954 c 0.15777338 k 1.0589185 m 0.0008312437\n",
      "16 Train Loss 381.81488 Test RE 0.17475667384694954 c 0.16397578 k 1.0079762 m 0.0009815434\n",
      "17 Train Loss 380.70224 Test RE 0.17299305155692132 c 0.16703497 k 1.0048772 m 0.0012422821\n",
      "18 Train Loss 379.7009 Test RE 0.1730099938612878 c 0.19276336 k 1.0097061 m 0.0027296115\n",
      "19 Train Loss 374.7637 Test RE 0.17091668840173366 c 0.4221023 k 1.0008056 m 0.016706808\n",
      "20 Train Loss 367.26227 Test RE 0.167687732420915 c 0.9279348 k 1.0045923 m 0.04822113\n",
      "21 Train Loss 352.6723 Test RE 0.17037124242092208 c 2.3270562 k 0.9797659 m 0.13600503\n",
      "22 Train Loss 347.70972 Test RE 0.16499963298106515 c 2.6035104 k 0.9939847 m 0.15335564\n",
      "23 Train Loss 346.8118 Test RE 0.1643654204413385 c 2.9051998 k 0.99020547 m 0.17291145\n",
      "24 Train Loss 346.6786 Test RE 0.16399464551398396 c 2.9155486 k 0.99013335 m 0.17437048\n",
      "25 Train Loss 346.41153 Test RE 0.16360107088556652 c 2.8597794 k 0.9915066 m 0.17442527\n",
      "26 Train Loss 345.52142 Test RE 0.1636670780964543 c 2.9469616 k 0.9920754 m 0.19755103\n",
      "27 Train Loss 343.24 Test RE 0.16311168472045554 c 3.0616663 k 0.98827267 m 0.26296014\n",
      "28 Train Loss 341.96783 Test RE 0.16061138279953063 c 3.0992966 k 0.99043626 m 0.301805\n",
      "29 Train Loss 340.7003 Test RE 0.15865482528963812 c 2.9124503 k 0.9910202 m 0.3460287\n",
      "30 Train Loss 340.32233 Test RE 0.1598436659280799 c 2.8140783 k 0.9891742 m 0.3465011\n",
      "31 Train Loss 339.692 Test RE 0.15949079052817436 c 2.71183 k 0.9886135 m 0.37843478\n",
      "32 Train Loss 339.3904 Test RE 0.15835181998093822 c 2.7637758 k 0.9897041 m 0.3911639\n",
      "33 Train Loss 339.19193 Test RE 0.15818397470718468 c 2.8 k 0.9898835 m 0.39725256\n",
      "34 Train Loss 338.47067 Test RE 0.15796068612707564 c 2.8300076 k 0.98853624 m 0.4537539\n",
      "35 Train Loss 337.9992 Test RE 0.15834910441827074 c 2.9033253 k 0.9898549 m 0.50034404\n",
      "36 Train Loss 336.84723 Test RE 0.15899641222948047 c 3.196938 k 0.98765683 m 0.665343\n",
      "37 Train Loss 336.2738 Test RE 0.1589790479709485 c 3.317143 k 0.98678714 m 0.78443617\n",
      "38 Train Loss 335.2143 Test RE 0.1583907431842532 c 3.6621914 k 0.9865249 m 1.0488238\n",
      "39 Train Loss 332.42795 Test RE 0.1589116447297013 c 3.2786953 k 0.98763674 m 1.0244879\n",
      "40 Train Loss 331.52823 Test RE 0.15832111230224105 c 2.9480793 k 0.9895216 m 1.0146853\n",
      "41 Train Loss 331.28668 Test RE 0.157794764063605 c 2.8962777 k 0.989562 m 1.0266112\n",
      "42 Train Loss 329.4673 Test RE 0.1577709262102424 c 3.0125623 k 0.9859981 m 1.246794\n",
      "43 Train Loss 325.88342 Test RE 0.15705870362041524 c 2.9606054 k 0.985679 m 1.4534954\n",
      "44 Train Loss 309.94025 Test RE 0.15164969788197702 c 3.2532148 k 0.9979832 m 2.169412\n",
      "45 Train Loss 283.44443 Test RE 0.14927231592828177 c 3.803919 k 0.9646114 m 2.8349333\n",
      "46 Train Loss 271.72528 Test RE 0.14448620221640762 c 3.8481784 k 0.984198 m 2.996618\n",
      "47 Train Loss 268.3469 Test RE 0.14474948062052445 c 3.6445193 k 0.9789116 m 2.9867096\n",
      "48 Train Loss 266.3981 Test RE 0.14262252554868227 c 3.5369618 k 0.9813009 m 2.967874\n",
      "49 Train Loss 264.9331 Test RE 0.14318590511007576 c 3.4708195 k 0.98009694 m 2.9512703\n",
      "50 Train Loss 264.2799 Test RE 0.14327160685832674 c 3.451413 k 0.9782325 m 2.9437578\n",
      "51 Train Loss 263.78656 Test RE 0.14228074985054515 c 3.4324222 k 0.9807521 m 2.9488103\n",
      "52 Train Loss 262.15924 Test RE 0.13937459477196687 c 3.4273453 k 0.9843196 m 3.02508\n",
      "53 Train Loss 246.57039 Test RE 0.12982396711299754 c 2.5366397 k 0.9817541 m 3.1340892\n",
      "54 Train Loss 238.95369 Test RE 0.12908195518731186 c 2.0812216 k 0.9893745 m 3.0492313\n",
      "55 Train Loss 237.95198 Test RE 0.12871158485214165 c 2.105842 k 0.98956275 m 3.0064871\n",
      "56 Train Loss 237.66801 Test RE 0.1292637187871661 c 2.131765 k 0.98841155 m 3.0070786\n",
      "57 Train Loss 236.99493 Test RE 0.1283300828338087 c 2.1964025 k 0.9860841 m 3.047927\n",
      "58 Train Loss 236.50854 Test RE 0.12668436505830144 c 2.1652977 k 0.9874219 m 3.042145\n",
      "59 Train Loss 236.43097 Test RE 0.1267436745661309 c 2.1327286 k 0.98851407 m 3.0274768\n",
      "60 Train Loss 236.3232 Test RE 0.126934654571035 c 2.0932312 k 0.9884524 m 3.012343\n",
      "61 Train Loss 235.7587 Test RE 0.12741667805749646 c 2.0748422 k 0.98723763 m 2.966258\n",
      "62 Train Loss 234.57327 Test RE 0.1256828614550494 c 2.1462147 k 0.9863524 m 2.9136438\n",
      "63 Train Loss 227.78673 Test RE 0.12205407333787079 c 2.306311 k 0.9919306 m 2.868977\n",
      "64 Train Loss 220.59227 Test RE 0.12213467666832258 c 2.1874297 k 0.97848296 m 2.8899174\n",
      "65 Train Loss 213.28004 Test RE 0.12027156614182145 c 2.1067889 k 0.98247904 m 2.85813\n",
      "66 Train Loss 210.46237 Test RE 0.11895010149454249 c 2.1983938 k 0.9843355 m 2.8497713\n",
      "67 Train Loss 207.48503 Test RE 0.11633222753428413 c 2.245467 k 0.9856829 m 2.8827364\n",
      "68 Train Loss 206.35571 Test RE 0.11520451440522197 c 2.206428 k 0.9853763 m 2.9286764\n",
      "69 Train Loss 206.1354 Test RE 0.11543687744408139 c 2.2223299 k 0.9861794 m 2.931269\n",
      "70 Train Loss 206.03175 Test RE 0.11577902296626051 c 2.2093778 k 0.98697126 m 2.9334626\n",
      "71 Train Loss 205.64308 Test RE 0.11645590519351537 c 2.138859 k 0.98834103 m 2.940984\n",
      "72 Train Loss 203.83989 Test RE 0.11595885571826754 c 1.9413545 k 0.9906206 m 2.89405\n",
      "73 Train Loss 201.95155 Test RE 0.11571862141599726 c 1.9237463 k 0.991652 m 2.802585\n",
      "74 Train Loss 195.62976 Test RE 0.11391414108742012 c 1.8517905 k 0.9830628 m 2.6010916\n",
      "75 Train Loss 191.66672 Test RE 0.10910484675136044 c 1.7121911 k 0.9860226 m 2.5499315\n",
      "76 Train Loss 187.57904 Test RE 0.11108477881176336 c 1.7326447 k 0.9755244 m 2.3832598\n",
      "77 Train Loss 181.02419 Test RE 0.1066096023473776 c 1.6591944 k 0.9843494 m 2.325045\n",
      "78 Train Loss 175.69797 Test RE 0.10454994360191505 c 1.5876786 k 0.98202866 m 2.324709\n",
      "79 Train Loss 172.07729 Test RE 0.10414386381244467 c 1.6352215 k 0.9872369 m 2.2688835\n",
      "80 Train Loss 160.25162 Test RE 0.10256554317772541 c 1.5136702 k 0.9809241 m 2.0290263\n",
      "81 Train Loss 152.858 Test RE 0.09893565662469854 c 1.4549073 k 0.98010206 m 2.0151749\n",
      "82 Train Loss 145.01558 Test RE 0.09247383565094638 c 1.5196784 k 0.9824206 m 1.9863245\n",
      "83 Train Loss 132.32703 Test RE 0.08359463975741736 c 1.7540816 k 0.96811265 m 2.005366\n",
      "84 Train Loss 116.57359 Test RE 0.08291267514580213 c 1.9411924 k 0.9750644 m 2.0063603\n",
      "85 Train Loss 111.28265 Test RE 0.08003250732763936 c 1.9206717 k 0.9776721 m 2.0034451\n",
      "86 Train Loss 108.39035 Test RE 0.07578722726364678 c 1.9604995 k 0.9729581 m 2.0453837\n",
      "87 Train Loss 106.82819 Test RE 0.07316615870378766 c 1.9630193 k 0.9765289 m 2.0905187\n",
      "88 Train Loss 104.94864 Test RE 0.07135030392338272 c 1.8436167 k 0.9771853 m 2.1045384\n",
      "89 Train Loss 101.57443 Test RE 0.06863456719732225 c 1.7364756 k 0.9740422 m 2.0759256\n",
      "90 Train Loss 98.337875 Test RE 0.06443336575628342 c 1.6680304 k 0.97643393 m 2.0330536\n",
      "91 Train Loss 92.128586 Test RE 0.05666239719670442 c 1.5213424 k 0.9707649 m 2.0751176\n",
      "92 Train Loss 86.87396 Test RE 0.05419703867421079 c 1.3428681 k 0.97048557 m 2.1660857\n",
      "93 Train Loss 84.841545 Test RE 0.05299673410482321 c 1.3655734 k 0.97398514 m 2.2105947\n",
      "94 Train Loss 84.40182 Test RE 0.054887917095305286 c 1.4149876 k 0.97366554 m 2.2113695\n",
      "95 Train Loss 83.44144 Test RE 0.055696202589774924 c 1.401399 k 0.97294307 m 2.2276857\n",
      "96 Train Loss 82.895935 Test RE 0.05514144191949582 c 1.3627803 k 0.9735949 m 2.260816\n",
      "97 Train Loss 82.53099 Test RE 0.05546687926705646 c 1.3703933 k 0.97388965 m 2.2994068\n",
      "98 Train Loss 82.31578 Test RE 0.05692983116979259 c 1.4020731 k 0.97384286 m 2.3143048\n",
      "99 Train Loss 81.1879 Test RE 0.05805591773374399 c 1.4470274 k 0.9746396 m 2.3105664\n",
      "100 Train Loss 79.835144 Test RE 0.05565118091682871 c 1.4436963 k 0.97323877 m 2.2703445\n",
      "101 Train Loss 78.871414 Test RE 0.053885668562701036 c 1.3946503 k 0.9758721 m 2.2765615\n",
      "102 Train Loss 78.08565 Test RE 0.054106027705107 c 1.3321524 k 0.97571075 m 2.2840796\n",
      "103 Train Loss 77.14751 Test RE 0.05473860759201028 c 1.285429 k 0.9757527 m 2.2918189\n",
      "104 Train Loss 75.782455 Test RE 0.05455285215675748 c 1.3113874 k 0.9753956 m 2.3072243\n",
      "105 Train Loss 74.45563 Test RE 0.053731763447041954 c 1.3858529 k 0.97427815 m 2.3582437\n",
      "106 Train Loss 73.2229 Test RE 0.053904270857415705 c 1.4012781 k 0.97524565 m 2.4472668\n",
      "107 Train Loss 72.11429 Test RE 0.05381350849534515 c 1.358199 k 0.9764164 m 2.4748652\n",
      "108 Train Loss 70.92069 Test RE 0.052166395293833774 c 1.29732 k 0.97750056 m 2.4702816\n",
      "109 Train Loss 70.33566 Test RE 0.049456887475894315 c 1.2767023 k 0.97805935 m 2.4792788\n",
      "110 Train Loss 70.03921 Test RE 0.04776992540808322 c 1.2640604 k 0.9780431 m 2.4936357\n",
      "111 Train Loss 69.68682 Test RE 0.046347303056305404 c 1.2445493 k 0.97555727 m 2.5087266\n",
      "112 Train Loss 69.46019 Test RE 0.04520149365486386 c 1.2238107 k 0.97341925 m 2.5294726\n",
      "113 Train Loss 69.05394 Test RE 0.04441170223792301 c 1.1752278 k 0.97669387 m 2.552294\n",
      "114 Train Loss 68.56327 Test RE 0.04360193833443904 c 1.118572 k 0.9801596 m 2.5809615\n",
      "115 Train Loss 68.110085 Test RE 0.042725519780565456 c 1.0867501 k 0.9785278 m 2.616577\n",
      "116 Train Loss 67.523026 Test RE 0.04206940730468486 c 1.0402029 k 0.97376734 m 2.660797\n",
      "117 Train Loss 66.30832 Test RE 0.04195318011477173 c 1.0167106 k 0.9705972 m 2.7098699\n",
      "118 Train Loss 62.69218 Test RE 0.04464794429384626 c 1.1743984 k 0.97654754 m 2.8787012\n",
      "119 Train Loss 55.85727 Test RE 0.039749413034812296 c 1.240254 k 0.98344 m 3.1663384\n",
      "120 Train Loss 48.894775 Test RE 0.04023613558281789 c 1.2616658 k 0.980246 m 3.264793\n",
      "121 Train Loss 47.10505 Test RE 0.036810286037922746 c 1.2401975 k 0.98081017 m 3.2747967\n",
      "122 Train Loss 43.533863 Test RE 0.03662206839289267 c 1.2901716 k 0.9904068 m 3.3676283\n",
      "123 Train Loss 40.645947 Test RE 0.043119386304444854 c 1.3361471 k 0.9849715 m 3.458999\n",
      "124 Train Loss 39.013397 Test RE 0.043798667658839524 c 1.3839742 k 0.983994 m 3.5311642\n",
      "125 Train Loss 38.706482 Test RE 0.0439810905455049 c 1.4069105 k 0.98611856 m 3.5631733\n",
      "126 Train Loss 38.42354 Test RE 0.04310826919524307 c 1.3929775 k 0.9865701 m 3.5892801\n",
      "127 Train Loss 37.124054 Test RE 0.04129120940874357 c 1.3783214 k 0.983305 m 3.7111437\n",
      "128 Train Loss 34.652782 Test RE 0.04284278171564941 c 1.4564 k 0.990643 m 3.8436399\n",
      "129 Train Loss 25.730537 Test RE 0.030199199105846376 c 1.3308835 k 0.9949069 m 4.1994195\n",
      "130 Train Loss 22.645548 Test RE 0.031000970596402506 c 1.2667726 k 0.989775 m 4.281319\n",
      "131 Train Loss 21.509167 Test RE 0.030481983741516266 c 1.2437806 k 0.9915184 m 4.3074846\n",
      "132 Train Loss 20.248444 Test RE 0.027135435305737907 c 1.2234074 k 0.9923754 m 4.3404875\n",
      "133 Train Loss 17.540731 Test RE 0.022351977650267436 c 1.1583687 k 0.9933827 m 4.436303\n",
      "134 Train Loss 16.264694 Test RE 0.02357619569975173 c 1.1474297 k 0.9931856 m 4.4812455\n",
      "135 Train Loss 15.559162 Test RE 0.022795221758768282 c 1.1369455 k 0.9925865 m 4.561701\n",
      "136 Train Loss 14.722725 Test RE 0.020533285696336608 c 1.1080382 k 0.99537396 m 4.6774883\n",
      "137 Train Loss 14.512745 Test RE 0.02060197718939447 c 1.0939012 k 0.99691683 m 4.7374806\n",
      "138 Train Loss 14.139992 Test RE 0.02099734510326133 c 1.0926353 k 0.9971919 m 4.825953\n",
      "139 Train Loss 13.881131 Test RE 0.020634517050029083 c 1.1010556 k 0.99753666 m 4.88157\n",
      "140 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "141 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "142 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "143 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "144 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "145 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "146 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "147 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "148 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "149 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "150 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "151 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "152 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "153 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "154 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "155 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "156 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "157 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "158 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "159 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "160 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "161 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "162 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "163 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "164 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "165 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "166 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "167 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "168 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "169 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "170 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "171 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "172 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "173 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "174 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "175 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "176 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "177 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "178 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "179 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "180 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "181 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "182 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "183 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "184 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "185 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "186 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "187 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "188 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "189 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "190 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "191 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "192 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "193 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "194 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "195 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "196 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "197 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "198 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "199 Train Loss 13.856243 Test RE 0.020364998253813566 c 1.1021242 k 0.99769443 m 4.883813\n",
      "Training time: 84.64\n",
      "Training time: 84.64\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 1078.4066 Test RE 0.300122587452422 c 0.1670129 k 0.7339202 m 0.0009832847\n",
      "1 Train Loss 495.0954 Test RE 0.22070048667449396 c 0.18550952 k 1.0055094 m 0.0010929042\n",
      "2 Train Loss 494.39062 Test RE 0.2206019854571446 c 0.18641508 k 1.0175481 m 0.0010982966\n",
      "3 Train Loss 493.97058 Test RE 0.22044588742556148 c 0.18650098 k 1.0245383 m 0.0010990476\n",
      "4 Train Loss 491.80475 Test RE 0.21940895047759473 c 0.1834024 k 1.0252427 m 0.0010832251\n",
      "5 Train Loss 491.47943 Test RE 0.21933987020172685 c 0.1828331 k 1.0180386 m 0.0010802939\n",
      "6 Train Loss 491.4692 Test RE 0.21935375666737508 c 0.1828257 k 1.0169346 m 0.0010802799\n",
      "7 Train Loss 491.46817 Test RE 0.2193562379273415 c 0.18283108 k 1.0167618 m 0.0010803344\n",
      "8 Train Loss 491.46643 Test RE 0.21936037891015325 c 0.18284681 k 1.0164655 m 0.0010804886\n",
      "9 Train Loss 491.44272 Test RE 0.21937719933300004 c 0.18318838 k 1.0148314 m 0.0010836892\n",
      "10 Train Loss 491.17453 Test RE 0.21929005072009564 c 0.18625478 k 1.0141935 m 0.0011116384\n",
      "11 Train Loss 491.09747 Test RE 0.21922587954572836 c 0.1878759 k 1.017097 m 0.0011242533\n",
      "12 Train Loss 491.0634 Test RE 0.21924143056697706 c 0.19009148 k 1.0181061 m 0.0011377579\n",
      "13 Train Loss 490.3907 Test RE 0.21896117405400908 c 0.20546478 k 1.0151222 m 0.0011808932\n",
      "14 Train Loss 444.8859 Test RE 0.20602864884694588 c 0.31542814 k 1.0138426 m 0.0014393578\n",
      "15 Train Loss 376.06363 Test RE 0.1691984158643561 c 0.38508904 k 1.00296 m 0.0016237501\n",
      "16 Train Loss 360.21695 Test RE 0.15839173969492032 c 0.4055023 k 1.0050768 m 0.002442465\n",
      "17 Train Loss 348.40802 Test RE 0.15934357942894303 c 0.44992602 k 0.9877035 m 0.0117446855\n",
      "18 Train Loss 332.76523 Test RE 0.15842359762873487 c 0.49882194 k 1.0136359 m 0.02527519\n",
      "19 Train Loss 320.86533 Test RE 0.14916873257270497 c 0.5582361 k 0.99390125 m 0.04218215\n",
      "20 Train Loss 302.1766 Test RE 0.13870243989988904 c 0.69668823 k 1.0009979 m 0.08990515\n",
      "21 Train Loss 277.79413 Test RE 0.1292940619966927 c 0.9035389 k 0.9987565 m 0.16540255\n",
      "22 Train Loss 272.9275 Test RE 0.13049265224307602 c 1.0067531 k 0.9948007 m 0.20773435\n",
      "23 Train Loss 250.98598 Test RE 0.11615949119869966 c 1.2530435 k 0.9845625 m 0.34194207\n",
      "24 Train Loss 236.31668 Test RE 0.10457913712219605 c 1.2879276 k 0.99554515 m 0.35871875\n",
      "25 Train Loss 231.39584 Test RE 0.10429199383056618 c 1.3378978 k 0.97409475 m 0.38983345\n",
      "26 Train Loss 224.21056 Test RE 0.11125365784755534 c 1.4224112 k 0.98423654 m 0.46145913\n",
      "27 Train Loss 211.3901 Test RE 0.11076129694192151 c 1.6225724 k 0.97467446 m 0.6607429\n",
      "28 Train Loss 208.52316 Test RE 0.11132941624321159 c 1.663524 k 0.9803602 m 0.72808594\n",
      "29 Train Loss 199.57083 Test RE 0.1142635440957411 c 1.7659696 k 0.97442013 m 0.8322519\n",
      "30 Train Loss 192.21918 Test RE 0.1105766444887987 c 1.7232372 k 0.9852495 m 0.80828965\n",
      "31 Train Loss 187.49025 Test RE 0.10753275666288922 c 1.7416077 k 0.97912115 m 0.8177231\n",
      "32 Train Loss 177.0398 Test RE 0.09639054341419376 c 1.7950147 k 0.9781088 m 0.83614695\n",
      "33 Train Loss 169.38048 Test RE 0.09329915480904666 c 1.8778526 k 0.97295135 m 0.8976303\n",
      "34 Train Loss 167.00797 Test RE 0.09372520079859613 c 1.9241908 k 0.97272736 m 0.9355241\n",
      "35 Train Loss 163.61781 Test RE 0.08975381205834201 c 2.018174 k 0.9757316 m 1.0183221\n",
      "36 Train Loss 144.91945 Test RE 0.08903015999545706 c 2.082452 k 0.978557 m 1.0995886\n",
      "37 Train Loss 139.02646 Test RE 0.09024689339103403 c 2.08007 k 0.97811955 m 1.1017671\n",
      "38 Train Loss 136.90218 Test RE 0.08839543210092628 c 2.0938525 k 0.9803151 m 1.1234004\n",
      "39 Train Loss 133.52196 Test RE 0.08519752259721569 c 2.1171532 k 0.9759233 m 1.1641613\n",
      "40 Train Loss 130.85504 Test RE 0.08456584762374308 c 2.1402707 k 0.9720211 m 1.203803\n",
      "41 Train Loss 129.26244 Test RE 0.08339957543001006 c 2.1800663 k 0.9744657 m 1.2598588\n",
      "42 Train Loss 128.65665 Test RE 0.08159315125589704 c 2.1895602 k 0.97284764 m 1.2824441\n",
      "43 Train Loss 127.10428 Test RE 0.08310446230566394 c 2.1632469 k 0.97085625 m 1.3012836\n",
      "44 Train Loss 124.98319 Test RE 0.08541648935758735 c 2.158645 k 0.9736683 m 1.3586699\n",
      "45 Train Loss 123.774475 Test RE 0.08536834306668165 c 2.1602535 k 0.9737219 m 1.389986\n",
      "46 Train Loss 120.99778 Test RE 0.08601265023207492 c 2.067969 k 0.97126067 m 1.3830457\n",
      "47 Train Loss 117.464905 Test RE 0.08742638796025709 c 1.9043229 k 0.9797227 m 1.4653187\n",
      "48 Train Loss 111.47443 Test RE 0.0838455065639756 c 1.5583434 k 0.96743387 m 1.6090336\n",
      "49 Train Loss 105.01613 Test RE 0.07966180676978014 c 1.5375025 k 0.98278904 m 1.6553744\n",
      "50 Train Loss 103.26224 Test RE 0.08027532264744786 c 1.5314239 k 0.97534823 m 1.6992483\n",
      "51 Train Loss 102.2014 Test RE 0.08070188358360585 c 1.5194306 k 0.9747081 m 1.718889\n",
      "52 Train Loss 100.9924 Test RE 0.07925666096623742 c 1.4972508 k 0.97581446 m 1.759432\n",
      "53 Train Loss 100.09584 Test RE 0.07929448588384401 c 1.4573115 k 0.9772661 m 1.8139683\n",
      "54 Train Loss 98.847015 Test RE 0.07994470349027709 c 1.3730338 k 0.9786723 m 1.9043535\n",
      "55 Train Loss 95.76559 Test RE 0.0751481909144641 c 1.2411299 k 0.9778589 m 2.014943\n",
      "56 Train Loss 91.92928 Test RE 0.06927158843121808 c 1.0861181 k 0.97651756 m 2.0991163\n",
      "57 Train Loss 86.975296 Test RE 0.0653001924825676 c 1.1026069 k 0.979011 m 2.214403\n",
      "58 Train Loss 83.45029 Test RE 0.05926787352811975 c 1.1661739 k 0.9799014 m 2.3229992\n",
      "59 Train Loss 82.46647 Test RE 0.05922524085608693 c 1.1910555 k 0.9788543 m 2.363483\n",
      "60 Train Loss 81.34859 Test RE 0.058848934166562714 c 1.22952 k 0.97905606 m 2.383629\n",
      "61 Train Loss 80.45442 Test RE 0.059343958528424404 c 1.2332898 k 0.9787673 m 2.3624628\n",
      "62 Train Loss 79.1259 Test RE 0.060799157911288884 c 1.3013073 k 0.97693306 m 2.3375268\n",
      "63 Train Loss 77.63092 Test RE 0.059686779215481586 c 1.3381083 k 0.976776 m 2.3423638\n",
      "64 Train Loss 76.5264 Test RE 0.05972651941109624 c 1.2974601 k 0.9773468 m 2.3332148\n",
      "65 Train Loss 73.67368 Test RE 0.057151323095272835 c 1.3234493 k 0.97610754 m 2.283357\n",
      "66 Train Loss 70.090675 Test RE 0.049786738489160445 c 1.3108189 k 0.9760268 m 2.3354049\n",
      "67 Train Loss 66.33028 Test RE 0.0496139105397229 c 1.1890717 k 0.9756127 m 2.4386559\n",
      "68 Train Loss 64.60394 Test RE 0.047669003976869344 c 1.1908785 k 0.9751543 m 2.506497\n",
      "69 Train Loss 61.99928 Test RE 0.04702050389092395 c 1.1523911 k 0.97787946 m 2.602607\n",
      "70 Train Loss 58.45652 Test RE 0.04251183428471497 c 1.0611666 k 0.9789625 m 2.8018205\n",
      "71 Train Loss 56.086163 Test RE 0.041305035152926724 c 1.0467465 k 0.9782254 m 2.9254932\n",
      "72 Train Loss 53.50717 Test RE 0.04068255089862114 c 1.0623273 k 0.981462 m 2.9872613\n",
      "73 Train Loss 51.003178 Test RE 0.04036896141846443 c 1.0506338 k 0.98551905 m 3.0880787\n",
      "74 Train Loss 47.781155 Test RE 0.04152302096901995 c 1.0335022 k 0.98450947 m 3.2229216\n",
      "75 Train Loss 44.560013 Test RE 0.0408986802291047 c 1.0775726 k 0.98166287 m 3.216996\n",
      "76 Train Loss 41.646408 Test RE 0.03936790368595882 c 1.1297734 k 0.9837076 m 3.2633862\n",
      "77 Train Loss 38.10594 Test RE 0.038098951245703436 c 1.0780044 k 0.98592436 m 3.427616\n",
      "78 Train Loss 37.19055 Test RE 0.036688581869459426 c 1.0841616 k 0.9836392 m 3.446411\n",
      "79 Train Loss 36.510914 Test RE 0.03694574311725835 c 1.0742182 k 0.9864208 m 3.509979\n",
      "80 Train Loss 32.54729 Test RE 0.03312490694660433 c 1.1271464 k 0.99485284 m 3.8520694\n",
      "81 Train Loss 27.913141 Test RE 0.03323132189782832 c 1.1402906 k 0.9904658 m 4.0688357\n",
      "82 Train Loss 25.81007 Test RE 0.03010444097990313 c 1.1539567 k 0.9946328 m 4.3065414\n",
      "83 Train Loss 24.389133 Test RE 0.026429094972480093 c 1.1538912 k 0.991039 m 4.311325\n",
      "84 Train Loss 13.906439 Test RE 0.02771215196619143 c 1.2210245 k 0.99329484 m 4.377856\n",
      "85 Train Loss 11.508936 Test RE 0.022206504429751212 c 1.2593106 k 0.9911632 m 4.320295\n",
      "86 Train Loss 9.988005 Test RE 0.02060954055582956 c 1.2057751 k 0.9929063 m 4.2810454\n",
      "87 Train Loss 8.567322 Test RE 0.018838026433226147 c 1.1797812 k 0.9916264 m 4.4121757\n",
      "88 Train Loss 7.508111 Test RE 0.017375149076926343 c 1.1381065 k 0.9943183 m 4.5113907\n",
      "89 Train Loss 5.8741674 Test RE 0.01564638041605118 c 1.0638361 k 0.99554086 m 4.570737\n",
      "90 Train Loss 5.3479953 Test RE 0.013714873691643611 c 1.0673853 k 0.9948862 m 4.6197395\n",
      "91 Train Loss 5.1951337 Test RE 0.012762524514934197 c 1.0445689 k 0.9960642 m 4.680756\n",
      "92 Train Loss 5.0257845 Test RE 0.012150549385637007 c 1.0358558 k 0.997793 m 4.72202\n",
      "93 Train Loss 4.1551204 Test RE 0.011543151352002044 c 1.0689839 k 0.9969254 m 4.740099\n",
      "94 Train Loss 3.8676875 Test RE 0.010365642185157077 c 1.0438915 k 0.9975872 m 4.7869797\n",
      "95 Train Loss 3.5623796 Test RE 0.009314658751017094 c 1.041895 k 0.9976508 m 4.7914953\n",
      "96 Train Loss 2.6848783 Test RE 0.007282621870422061 c 1.0494151 k 0.9983456 m 4.9048676\n",
      "97 Train Loss 2.3643932 Test RE 0.00809494959883945 c 1.0483316 k 0.9989898 m 4.9590573\n",
      "98 Train Loss 2.241558 Test RE 0.007595256529937377 c 1.0353311 k 1.000303 m 4.972004\n",
      "99 Train Loss 2.0836246 Test RE 0.007651482240602189 c 1.0244235 k 0.99939305 m 4.913426\n",
      "100 Train Loss 2.0215125 Test RE 0.007783002703525547 c 1.0224857 k 0.9987892 m 4.8922615\n",
      "101 Train Loss 1.6063809 Test RE 0.007231749455721686 c 0.98643255 k 0.99865013 m 4.8708653\n",
      "102 Train Loss 1.2382469 Test RE 0.006352476018985368 c 0.9832771 k 0.9996516 m 4.9258647\n",
      "103 Train Loss 1.1655225 Test RE 0.006429031072259963 c 0.98235923 k 0.99950284 m 4.9465823\n",
      "104 Train Loss 1.1443417 Test RE 0.006582929577467274 c 0.9839201 k 0.9994638 m 4.942754\n",
      "105 Train Loss 1.0547782 Test RE 0.006656710832813794 c 0.9974612 k 1.0002059 m 4.9587865\n",
      "106 Train Loss 0.9274323 Test RE 0.006171793027225954 c 1.0093486 k 0.99993783 m 4.9878154\n",
      "107 Train Loss 0.91447276 Test RE 0.0061004489999892195 c 1.0092087 k 0.9997914 m 4.9761777\n",
      "108 Train Loss 0.9096205 Test RE 0.006097169270900848 c 1.0120627 k 0.99971503 m 4.96957\n",
      "109 Train Loss 0.87568533 Test RE 0.006029536016341502 c 1.0105406 k 1.0001469 m 4.987241\n",
      "110 Train Loss 0.786604 Test RE 0.006112402931027451 c 1.0059232 k 0.99983406 m 4.9818645\n",
      "111 Train Loss 0.7350378 Test RE 0.005956100738739577 c 1.0070974 k 0.9996635 m 4.9706593\n",
      "112 Train Loss 0.7112369 Test RE 0.005808763079072322 c 1.0047064 k 0.9998663 m 4.9793215\n",
      "113 Train Loss 0.6695906 Test RE 0.0056266928218330365 c 1.0031377 k 1.0000885 m 4.9920316\n",
      "114 Train Loss 0.5798228 Test RE 0.0054941170671387604 c 1.0045953 k 1.0001024 m 4.988339\n",
      "115 Train Loss 0.55432856 Test RE 0.005441172120853864 c 1.0035785 k 1.0000585 m 4.994762\n",
      "116 Train Loss 0.53835547 Test RE 0.005403296889683499 c 1.0057161 k 1.0000838 m 4.994867\n",
      "117 Train Loss 0.52990496 Test RE 0.005316496271717099 c 1.007092 k 1.000094 m 4.996501\n",
      "118 Train Loss 0.5140997 Test RE 0.005059861991353318 c 1.0070971 k 1.0001067 m 4.9970264\n",
      "119 Train Loss 0.49866924 Test RE 0.004878107457157446 c 1.0067819 k 1.0000104 m 4.9906573\n",
      "120 Train Loss 0.49059224 Test RE 0.004808038062851752 c 1.0074174 k 0.9999854 m 4.992334\n",
      "121 Train Loss 0.4878427 Test RE 0.004797770002107278 c 1.0070133 k 1.0001105 m 4.9967957\n",
      "122 Train Loss 0.48151243 Test RE 0.004727492190056279 c 1.0049452 k 1.0001901 m 5.00481\n",
      "123 Train Loss 0.47277904 Test RE 0.004628765805575299 c 1.0057123 k 1.0001112 m 5.001776\n",
      "124 Train Loss 0.46238762 Test RE 0.004579566470904376 c 1.0085742 k 0.99995136 m 4.98727\n",
      "125 Train Loss 0.4554429 Test RE 0.004567173023135833 c 1.0070268 k 0.9998845 m 4.9833493\n",
      "126 Train Loss 0.4463314 Test RE 0.004552538498537057 c 1.002997 k 0.99996305 m 4.987374\n",
      "127 Train Loss 0.4188547 Test RE 0.004423825243817517 c 1.0019749 k 1.0005412 m 5.0030365\n",
      "128 Train Loss 0.39836663 Test RE 0.004379032446446051 c 1.0061185 k 1.0002741 m 4.988265\n",
      "129 Train Loss 0.38930482 Test RE 0.004360449600677837 c 1.0082587 k 0.9997891 m 4.981577\n",
      "130 Train Loss 0.38720027 Test RE 0.004384531197149784 c 1.0084498 k 0.99979 m 4.983504\n",
      "131 Train Loss 0.38530654 Test RE 0.0044187827175864065 c 1.0086377 k 0.99992406 m 4.985597\n",
      "132 Train Loss 0.3820783 Test RE 0.00444495337154507 c 1.0094575 k 1.0000483 m 4.9865932\n",
      "133 Train Loss 0.37395954 Test RE 0.004370813652225042 c 1.0108365 k 0.9997844 m 4.9867043\n",
      "134 Train Loss 0.3693571 Test RE 0.004342677470464065 c 1.0105705 k 0.9995969 m 4.9894547\n",
      "135 Train Loss 0.35922077 Test RE 0.004318405450979219 c 1.0101756 k 0.9994231 m 4.986833\n",
      "136 Train Loss 0.31475568 Test RE 0.004039879931018737 c 1.0081398 k 1.000328 m 4.978246\n",
      "137 Train Loss 0.26605615 Test RE 0.0034536408302441074 c 1.0068341 k 1.000316 m 4.9902205\n",
      "138 Train Loss 0.24046546 Test RE 0.002992661355291751 c 1.0084049 k 0.9997371 m 4.9960265\n",
      "139 Train Loss 0.21815099 Test RE 0.0025299447730314636 c 1.004411 k 0.9997569 m 4.9925\n",
      "140 Train Loss 0.21048442 Test RE 0.0024294809131034977 c 1.0031518 k 1.0001013 m 4.993591\n",
      "141 Train Loss 0.20283906 Test RE 0.002477918966691446 c 1.0043945 k 1.000147 m 4.9963126\n",
      "142 Train Loss 0.19821593 Test RE 0.002530695844230922 c 1.0048606 k 1.0000507 m 4.9967756\n",
      "143 Train Loss 0.1964229 Test RE 0.0025019894208236975 c 1.0034312 k 0.9999802 m 4.9980335\n",
      "144 Train Loss 0.19581974 Test RE 0.0024594115498100125 c 1.0023226 k 1.0000052 m 4.9988737\n",
      "145 Train Loss 0.1950655 Test RE 0.0024515438773523926 c 1.0020723 k 0.9999769 m 4.997982\n",
      "146 Train Loss 0.19338667 Test RE 0.0024822677935979675 c 1.0026665 k 0.99992645 m 4.996613\n",
      "147 Train Loss 0.18968351 Test RE 0.002445497962051112 c 1.002995 k 1.0000794 m 4.996214\n",
      "148 Train Loss 0.18413317 Test RE 0.0023128655265432425 c 1.0046012 k 1.0000206 m 4.995704\n",
      "149 Train Loss 0.17136669 Test RE 0.002226291493092952 c 1.0087302 k 0.9994657 m 4.9932156\n",
      "150 Train Loss 0.151992 Test RE 0.0021686313946881943 c 1.004824 k 0.9996259 m 4.995276\n",
      "151 Train Loss 0.14489609 Test RE 0.0020386627002116973 c 1.0013821 k 0.99992245 m 4.9948397\n",
      "152 Train Loss 0.14266582 Test RE 0.0020013420832425475 c 1.0004122 k 0.99995095 m 4.992197\n",
      "153 Train Loss 0.14134422 Test RE 0.0019907964034934817 c 0.9992081 k 0.9999255 m 4.9916797\n",
      "154 Train Loss 0.14026655 Test RE 0.00199430027216298 c 0.99835116 k 1.0000068 m 4.9928365\n",
      "155 Train Loss 0.13734402 Test RE 0.001971530174654997 c 0.99727046 k 1.0001086 m 4.9937673\n",
      "156 Train Loss 0.1338011 Test RE 0.0019119962924912229 c 0.99599797 k 0.99987197 m 4.992964\n",
      "157 Train Loss 0.12880625 Test RE 0.0018489768601478713 c 0.99610513 k 0.9996884 m 4.9905834\n",
      "158 Train Loss 0.10828293 Test RE 0.0016557569910660662 c 1.0011629 k 1.0000445 m 4.990162\n",
      "159 Train Loss 0.09224699 Test RE 0.0014190555074962963 c 1.0042554 k 0.9998859 m 4.99408\n",
      "160 Train Loss 0.07951174 Test RE 0.0013227755344363064 c 1.001062 k 0.9994924 m 4.9936366\n",
      "161 Train Loss 0.07266968 Test RE 0.0012891939744481367 c 0.99721324 k 0.9997114 m 4.989182\n",
      "162 Train Loss 0.06759193 Test RE 0.0012365240476831711 c 0.99797225 k 1.0001886 m 4.995305\n",
      "163 Train Loss 0.06357679 Test RE 0.001110751356629037 c 1.0001314 k 1.0000138 m 5.0029984\n",
      "164 Train Loss 0.061484296 Test RE 0.0010736319727544916 c 1.0010461 k 0.99973255 m 5.0011864\n",
      "165 Train Loss 0.060023613 Test RE 0.0010828853548070167 c 1.0015609 k 0.9998581 m 4.997702\n",
      "166 Train Loss 0.058678128 Test RE 0.0010791152400566571 c 1.0025625 k 0.9999291 m 4.997229\n",
      "167 Train Loss 0.05652799 Test RE 0.0010297340294595936 c 1.0018843 k 0.9997435 m 4.9995985\n",
      "168 Train Loss 0.05506834 Test RE 0.000994201662832581 c 1.0003126 k 0.9997576 m 5.0013175\n",
      "169 Train Loss 0.054010294 Test RE 0.0009894910257979036 c 1.0010952 k 0.99986225 m 4.9997063\n",
      "170 Train Loss 0.05080581 Test RE 0.0009563362155647619 c 1.0031518 k 0.9997875 m 4.99766\n",
      "171 Train Loss 0.044521328 Test RE 0.0008283586744049367 c 1.0000122 k 0.9997833 m 5.0024486\n",
      "172 Train Loss 0.041500784 Test RE 0.0007477620556605439 c 0.9975341 k 0.9999163 m 5.0031652\n",
      "173 Train Loss 0.03915758 Test RE 0.0007083462433973564 c 0.9992467 k 0.9998926 m 4.9988728\n",
      "174 Train Loss 0.037737086 Test RE 0.0007368220364771973 c 1.0014246 k 0.99981534 m 5.0000877\n",
      "175 Train Loss 0.0367605 Test RE 0.000728084345209823 c 1.0008099 k 0.9998292 m 5.000767\n",
      "176 Train Loss 0.036477976 Test RE 0.0007125575137368384 c 0.99987113 k 0.999861 m 4.9999895\n",
      "177 Train Loss 0.036013413 Test RE 0.0007000160306936445 c 1.0001154 k 0.99987686 m 4.9987106\n",
      "178 Train Loss 0.03465685 Test RE 0.000692773046495035 c 1.0020837 k 0.99980104 m 4.9972663\n",
      "179 Train Loss 0.031636547 Test RE 0.0006860693653079909 c 1.0012251 k 0.9998635 m 4.998998\n",
      "180 Train Loss 0.029967586 Test RE 0.0006268426407320069 c 0.9997706 k 0.9999044 m 5.000337\n",
      "181 Train Loss 0.028469956 Test RE 0.0005768703399468331 c 1.0001205 k 0.99985766 m 5.0010495\n",
      "182 Train Loss 0.025075084 Test RE 0.0004846805914241951 c 1.0017107 k 0.99985206 m 4.999701\n",
      "183 Train Loss 0.023060039 Test RE 0.0004405996768158359 c 1.0014106 k 0.999983 m 4.997258\n",
      "184 Train Loss 0.021057868 Test RE 0.00044363317990098904 c 1.0005068 k 0.9999193 m 4.9951\n",
      "185 Train Loss 0.020435488 Test RE 0.0004327414563144582 c 1.0007882 k 0.9998691 m 4.9962473\n",
      "186 Train Loss 0.020234756 Test RE 0.00042890216449194984 c 1.0008833 k 0.99992114 m 4.997805\n",
      "187 Train Loss 0.02018471 Test RE 0.0004280703441805195 c 1.0007743 k 0.9999512 m 4.998313\n",
      "188 Train Loss 0.02016119 Test RE 0.0004281895444883301 c 1.0007013 k 0.9999645 m 4.998485\n",
      "189 Train Loss 0.020108454 Test RE 0.000431981805536869 c 1.0004593 k 0.99995697 m 4.998549\n",
      "190 Train Loss 0.020058883 Test RE 0.00043599965088256444 c 1.0003784 k 0.99992424 m 4.9983606\n",
      "191 Train Loss 0.01992799 Test RE 0.00044100883353388417 c 1.0002912 k 0.9998917 m 4.998048\n",
      "192 Train Loss 0.01961759 Test RE 0.00043708750509835557 c 1.0003315 k 0.9999256 m 4.99814\n",
      "193 Train Loss 0.019041603 Test RE 0.00042894548430674203 c 1.0006331 k 1.0000029 m 4.998621\n",
      "194 Train Loss 0.018748306 Test RE 0.00043456391393120926 c 1.000851 k 0.99995697 m 4.9977574\n",
      "195 Train Loss 0.018535057 Test RE 0.0004349210629317356 c 1.000709 k 0.99991155 m 4.9972763\n",
      "196 Train Loss 0.018267978 Test RE 0.00043885734704972784 c 1.0002948 k 0.9999477 m 4.9986176\n",
      "197 Train Loss 0.018188342 Test RE 0.00044034596223856766 c 1.0002573 k 0.99998754 m 4.9995136\n",
      "198 Train Loss 0.018147705 Test RE 0.00044112499694951376 c 1.0002942 k 1.0000045 m 4.9998994\n",
      "199 Train Loss 0.018019522 Test RE 0.00044222420901110466 c 1.0002191 k 1.0000033 m 5.0001817\n",
      "Training time: 89.17\n",
      "Training time: 89.17\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 645.31537 Test RE 0.2389469983300114 c 0.040717334 k 0.8559421 m 3.4997567e-05\n",
      "1 Train Loss 497.07452 Test RE 0.22124697043609062 c 0.040318385 k 1.0143518 m 3.4450095e-05\n",
      "2 Train Loss 496.99707 Test RE 0.22123365328161892 c 0.040301926 k 1.0179954 m 3.443039e-05\n",
      "3 Train Loss 496.78354 Test RE 0.22117209345209396 c 0.04020567 k 1.0233814 m 3.4338824e-05\n",
      "4 Train Loss 493.36768 Test RE 0.219880305571753 c 0.03841572 k 1.0348274 m 3.3606633e-05\n",
      "5 Train Loss 491.44226 Test RE 0.2193525097305103 c 0.037341654 k 1.0187247 m 3.4436092e-05\n",
      "6 Train Loss 491.4234 Test RE 0.219363065641585 c 0.037357826 k 1.0169566 m 3.4849345e-05\n",
      "7 Train Loss 491.39487 Test RE 0.2193643459012073 c 0.037567884 k 1.0150772 m 3.971e-05\n",
      "8 Train Loss 491.02567 Test RE 0.21916540527468734 c 0.040604856 k 1.0130941 m 0.0001095194\n",
      "9 Train Loss 482.9699 Test RE 0.21759685004061693 c 0.059193432 k 1.0176526 m 0.00056106324\n",
      "10 Train Loss 421.87964 Test RE 0.1992791564234801 c 0.084486134 k 1.0058967 m 0.0013591066\n",
      "11 Train Loss 392.87427 Test RE 0.17836256274772247 c 0.1046057 k 1.0032866 m 0.0020161378\n",
      "12 Train Loss 385.39124 Test RE 0.17800772004265727 c 0.105893925 k 1.0109392 m 0.00229854\n",
      "13 Train Loss 372.94696 Test RE 0.1724325292599483 c 0.13223904 k 1.0026911 m 0.0040515335\n",
      "14 Train Loss 358.20157 Test RE 0.15584609021927331 c 0.22970986 k 1.0062623 m 0.011705686\n",
      "15 Train Loss 332.13953 Test RE 0.13344819535595082 c 0.32731855 k 0.9963732 m 0.02146266\n",
      "16 Train Loss 293.32697 Test RE 0.12904838545581065 c 0.40864047 k 0.99252164 m 0.040990647\n",
      "17 Train Loss 282.561 Test RE 0.12760196949332295 c 0.4938296 k 0.9916895 m 0.064782746\n",
      "18 Train Loss 277.21674 Test RE 0.12537383349882888 c 0.51804173 k 1.0002861 m 0.097564876\n",
      "19 Train Loss 263.12744 Test RE 0.13116177903746756 c 0.64290065 k 0.99451214 m 0.28065175\n",
      "20 Train Loss 245.8078 Test RE 0.12217242585072317 c 0.87929827 k 0.9705975 m 0.6423439\n",
      "21 Train Loss 236.23822 Test RE 0.10942847748038019 c 0.8224778 k 0.98949087 m 0.5788385\n",
      "22 Train Loss 234.14221 Test RE 0.1068120420769145 c 0.7844435 k 0.9851797 m 0.5591212\n",
      "23 Train Loss 223.59119 Test RE 0.10819843179007414 c 0.8486243 k 0.97721523 m 0.8362688\n",
      "24 Train Loss 213.36072 Test RE 0.11528891712497599 c 1.2078009 k 1.007926 m 1.5196232\n",
      "25 Train Loss 197.97871 Test RE 0.10657625242682751 c 1.6250112 k 0.9891474 m 2.188463\n",
      "26 Train Loss 195.31544 Test RE 0.10472999798517484 c 1.5856787 k 0.97579265 m 2.1586797\n",
      "27 Train Loss 169.33423 Test RE 0.09637043726877538 c 1.8603743 k 0.9839527 m 2.6440678\n",
      "28 Train Loss 164.61923 Test RE 0.10004062500534885 c 1.8375664 k 0.9863359 m 2.587132\n",
      "29 Train Loss 149.52225 Test RE 0.09936955760344741 c 1.9034774 k 0.9819257 m 2.8437548\n",
      "30 Train Loss 140.51555 Test RE 0.10383650951694978 c 2.0735266 k 0.97681314 m 3.2363136\n",
      "31 Train Loss 127.51361 Test RE 0.09718339330126019 c 2.3200626 k 0.9694373 m 3.4670951\n",
      "32 Train Loss 103.52782 Test RE 0.07708403011743321 c 2.2120063 k 0.9839567 m 3.1502728\n",
      "33 Train Loss 80.37206 Test RE 0.0739262147228448 c 2.0094304 k 0.9738822 m 2.9125285\n",
      "34 Train Loss 76.259186 Test RE 0.07303671003595227 c 1.9135164 k 0.98175174 m 2.8395374\n",
      "35 Train Loss 75.28621 Test RE 0.07135448114342255 c 1.9178108 k 0.97904396 m 2.8509152\n",
      "36 Train Loss 72.54634 Test RE 0.06769732824727699 c 1.9074119 k 0.97566384 m 2.8479674\n",
      "37 Train Loss 66.77867 Test RE 0.05845505323266811 c 1.7052965 k 0.97758514 m 2.6017306\n",
      "38 Train Loss 65.80095 Test RE 0.05965205034160676 c 1.6617941 k 0.9754903 m 2.5467885\n",
      "39 Train Loss 63.578518 Test RE 0.06208988778565924 c 1.6698722 k 0.9787084 m 2.5983226\n",
      "40 Train Loss 59.8468 Test RE 0.05629618082933425 c 1.7696859 k 0.98028487 m 2.8592284\n",
      "41 Train Loss 56.06036 Test RE 0.05769493419833266 c 1.778016 k 0.9778139 m 3.0338974\n",
      "42 Train Loss 53.06893 Test RE 0.05318078876975471 c 1.6868122 k 0.9828218 m 3.0536485\n",
      "43 Train Loss 46.642876 Test RE 0.05051552389426385 c 1.3920621 k 0.9811326 m 3.2663217\n",
      "44 Train Loss 38.636684 Test RE 0.05038417165920125 c 1.271022 k 0.9851813 m 3.4767783\n",
      "45 Train Loss 38.252666 Test RE 0.05053231818195475 c 1.2496456 k 0.98540866 m 3.524878\n",
      "46 Train Loss 37.23667 Test RE 0.04998474693780961 c 1.158408 k 0.9852375 m 3.6083148\n",
      "47 Train Loss 33.99323 Test RE 0.043050104305590926 c 1.0381488 k 0.9896613 m 3.6904073\n",
      "48 Train Loss 32.97873 Test RE 0.043252714707513795 c 1.0673965 k 0.9877011 m 3.7202518\n",
      "49 Train Loss 30.921375 Test RE 0.0420344039258952 c 1.1194438 k 0.989922 m 3.9077685\n",
      "50 Train Loss 25.766724 Test RE 0.037743842365497854 c 1.1576935 k 0.992347 m 4.2477484\n",
      "51 Train Loss 22.928658 Test RE 0.03826242815073761 c 1.1754662 k 0.99244803 m 4.51325\n",
      "52 Train Loss 22.223034 Test RE 0.037379960841087446 c 1.1435332 k 0.996166 m 4.6053433\n",
      "53 Train Loss 21.338383 Test RE 0.035290266842868956 c 1.0775691 k 0.9970371 m 4.770331\n",
      "54 Train Loss 20.777 Test RE 0.03522560467688451 c 1.0871576 k 0.9972878 m 4.898376\n",
      "55 Train Loss 20.36155 Test RE 0.034818772860724885 c 1.0554491 k 1.0001696 m 5.0405593\n",
      "56 Train Loss 19.828876 Test RE 0.033574046199169906 c 1.0032085 k 1.0024651 m 5.169994\n",
      "57 Train Loss 18.631784 Test RE 0.032662069379001596 c 1.0228287 k 1.0012002 m 5.2034197\n",
      "58 Train Loss 17.225754 Test RE 0.03290483931529771 c 1.0812291 k 1.0014547 m 5.184428\n",
      "59 Train Loss 16.85103 Test RE 0.032396409907015304 c 1.0520006 k 1.002565 m 5.179571\n",
      "60 Train Loss 16.385492 Test RE 0.03211654873445537 c 1.034859 k 1.0009838 m 5.069753\n",
      "61 Train Loss 15.94734 Test RE 0.03237727152183092 c 1.0497545 k 0.9995872 m 4.9612417\n",
      "62 Train Loss 14.177446 Test RE 0.030939406816669516 c 1.1143337 k 0.9973145 m 4.6488943\n",
      "63 Train Loss 12.927624 Test RE 0.029122030028702083 c 1.1286027 k 0.9971125 m 4.7591543\n",
      "64 Train Loss 10.041981 Test RE 0.02534036661663063 c 1.0300733 k 0.99978125 m 4.8596888\n",
      "65 Train Loss 8.003771 Test RE 0.02274074004769016 c 1.0510784 k 0.99940187 m 4.90425\n",
      "66 Train Loss 6.2904005 Test RE 0.020356527986081428 c 1.0747651 k 1.0014304 m 5.050328\n",
      "67 Train Loss 5.643302 Test RE 0.018539972318050713 c 1.0263355 k 1.0018766 m 5.0632105\n",
      "68 Train Loss 4.460691 Test RE 0.016574805991676288 c 1.0672475 k 0.9994119 m 4.950819\n",
      "69 Train Loss 3.6813617 Test RE 0.01494767234230751 c 1.0798687 k 0.9988947 m 4.9284625\n",
      "70 Train Loss 3.3312373 Test RE 0.0138904017631357 c 1.041275 k 0.99852747 m 4.9234433\n",
      "71 Train Loss 3.061503 Test RE 0.01360676220205558 c 1.0508175 k 0.9989416 m 4.911635\n",
      "72 Train Loss 2.7660983 Test RE 0.012498796416439516 c 1.033888 k 0.99879766 m 4.9094105\n",
      "73 Train Loss 2.5998404 Test RE 0.012126385438769923 c 1.0101719 k 0.99873036 m 4.884487\n",
      "74 Train Loss 2.427174 Test RE 0.011641484369346387 c 1.0269493 k 0.9984689 m 4.8706613\n",
      "75 Train Loss 2.0988073 Test RE 0.009721086616701909 c 1.0243521 k 0.99803585 m 4.8519306\n",
      "76 Train Loss 1.7411897 Test RE 0.007521577685689908 c 0.99534696 k 0.9980447 m 4.8359795\n",
      "77 Train Loss 1.6297156 Test RE 0.0064053802667891615 c 0.99816054 k 0.9986991 m 4.823754\n",
      "78 Train Loss 1.6122417 Test RE 0.006154833064131592 c 0.9971626 k 0.9985223 m 4.819011\n",
      "79 Train Loss 1.5485927 Test RE 0.006000009329199049 c 1.0022733 k 0.99862283 m 4.825845\n",
      "80 Train Loss 1.4176869 Test RE 0.006015783704968134 c 1.0192456 k 0.9998064 m 4.8795133\n",
      "81 Train Loss 1.2949193 Test RE 0.005565394925255942 c 1.0073221 k 0.99978596 m 4.9347687\n",
      "82 Train Loss 1.2553844 Test RE 0.005206934818628018 c 0.99516696 k 0.99994355 m 4.974237\n",
      "83 Train Loss 1.239624 Test RE 0.005080368594132323 c 0.99784166 k 1.0003852 m 4.9919405\n",
      "84 Train Loss 1.2369905 Test RE 0.005079801431625729 c 1.0005375 k 1.0005395 m 4.991073\n",
      "85 Train Loss 1.2260036 Test RE 0.0051207912427605915 c 1.0038248 k 1.0007213 m 4.9778223\n",
      "86 Train Loss 1.1653464 Test RE 0.005263210150124248 c 1.0126029 k 1.0002156 m 4.954221\n",
      "87 Train Loss 1.1358824 Test RE 0.0051221771482030075 c 1.0118058 k 1.0001992 m 4.9632387\n",
      "88 Train Loss 1.1199715 Test RE 0.004958539336330769 c 1.012186 k 1.0004566 m 4.9771357\n",
      "89 Train Loss 1.117111 Test RE 0.004955716374786938 c 1.0124028 k 1.0004733 m 4.9765167\n",
      "90 Train Loss 1.1141812 Test RE 0.004906558185104228 c 1.0121492 k 1.0003425 m 4.971461\n",
      "91 Train Loss 1.108456 Test RE 0.004699966135812658 c 1.0123285 k 1.0002526 m 4.9630766\n",
      "92 Train Loss 1.0880567 Test RE 0.004554722679253555 c 1.0096749 k 1.0002 m 4.951682\n",
      "93 Train Loss 0.94275635 Test RE 0.004151267942905007 c 0.9936882 k 1.0003453 m 4.9310665\n",
      "94 Train Loss 0.6591023 Test RE 0.003345875040082466 c 0.9995697 k 0.9999512 m 4.9719863\n",
      "95 Train Loss 0.59300417 Test RE 0.003253987319622579 c 1.0054721 k 1.0001523 m 4.9878206\n",
      "96 Train Loss 0.5775238 Test RE 0.0032409722569776405 c 1.0084939 k 1.0002737 m 4.987615\n",
      "97 Train Loss 0.56829125 Test RE 0.003085455880142135 c 1.0102509 k 1.0002067 m 4.98272\n",
      "98 Train Loss 0.5607363 Test RE 0.002961303045943359 c 1.0071257 k 1.0001146 m 4.9852743\n",
      "99 Train Loss 0.5584911 Test RE 0.002903710434643036 c 1.0053926 k 1.0002052 m 4.9901457\n",
      "100 Train Loss 0.5580947 Test RE 0.002894440469585747 c 1.0053824 k 1.0002427 m 4.9910097\n",
      "101 Train Loss 0.5573427 Test RE 0.0028955152203095167 c 1.0058388 k 1.0002794 m 4.992208\n",
      "102 Train Loss 0.55308384 Test RE 0.0029065543805358043 c 1.0074344 k 1.0005894 m 4.9991117\n",
      "103 Train Loss 0.5440931 Test RE 0.002989832521878336 c 1.0090898 k 1.0006394 m 5.0099354\n",
      "104 Train Loss 0.53983086 Test RE 0.003070370078501466 c 1.0071172 k 1.0003952 m 5.0167313\n",
      "105 Train Loss 0.52857906 Test RE 0.0031134643761062514 c 1.0040653 k 1.0002208 m 5.013856\n",
      "106 Train Loss 0.506157 Test RE 0.002974293084491456 c 1.0026406 k 1.0002533 m 5.0092688\n",
      "107 Train Loss 0.4968632 Test RE 0.0029330311455632815 c 1.0027869 k 1.0004735 m 5.015374\n",
      "108 Train Loss 0.49211335 Test RE 0.0029166525527262294 c 1.0029229 k 1.0005645 m 5.011527\n",
      "109 Train Loss 0.4874306 Test RE 0.0028703845370305074 c 1.002953 k 1.0004102 m 5.0028296\n",
      "110 Train Loss 0.48493135 Test RE 0.002819172503978329 c 1.002775 k 1.00032 m 4.99819\n",
      "111 Train Loss 0.48337 Test RE 0.002796317970611165 c 1.0024152 k 1.0002693 m 4.9944544\n",
      "112 Train Loss 0.48196647 Test RE 0.002804297234609741 c 1.0016553 k 1.0002117 m 4.990136\n",
      "113 Train Loss 0.47966644 Test RE 0.002881821150987755 c 0.9999226 k 1.0001289 m 4.987125\n",
      "114 Train Loss 0.47407407 Test RE 0.0029889110760300676 c 1.0005575 k 1.0000879 m 4.986964\n",
      "115 Train Loss 0.45683587 Test RE 0.0029089131437765522 c 1.0045063 k 1.0000386 m 4.977758\n",
      "116 Train Loss 0.44101197 Test RE 0.0027419965112014254 c 1.0040874 k 0.9999981 m 4.9778376\n",
      "117 Train Loss 0.42977884 Test RE 0.0026533490112298345 c 0.99864113 k 1.0002346 m 4.9901686\n",
      "118 Train Loss 0.41853887 Test RE 0.002689174750218436 c 0.9952713 k 1.0004773 m 5.0064483\n",
      "119 Train Loss 0.40116367 Test RE 0.0027171667465964427 c 1.0018426 k 1.0003636 m 5.010258\n",
      "120 Train Loss 0.38980088 Test RE 0.00272109663139593 c 1.0025576 k 1.0004181 m 5.0134697\n",
      "121 Train Loss 0.38394415 Test RE 0.002721920260117621 c 1.0001184 k 1.0006996 m 5.0219097\n",
      "122 Train Loss 0.37928176 Test RE 0.0027703931877764393 c 0.9999321 k 1.0006974 m 5.0311146\n",
      "123 Train Loss 0.37660807 Test RE 0.002813363524057676 c 1.0018996 k 1.0005436 m 5.0302415\n",
      "124 Train Loss 0.37458146 Test RE 0.002811143780842242 c 1.0024321 k 1.0006007 m 5.024879\n",
      "125 Train Loss 0.3676138 Test RE 0.0027797118045653135 c 1.0002643 k 1.0005318 m 5.014766\n",
      "126 Train Loss 0.3611763 Test RE 0.0027951284532283017 c 0.99951386 k 1.0003028 m 5.0164614\n",
      "127 Train Loss 0.34763426 Test RE 0.0027683393172569758 c 0.99987894 k 1.0001073 m 5.015193\n",
      "128 Train Loss 0.3326046 Test RE 0.0026811782988799882 c 0.99786234 k 1.0004954 m 5.0143743\n",
      "129 Train Loss 0.3227175 Test RE 0.0026573977624347895 c 0.998767 k 1.0003444 m 5.015777\n",
      "130 Train Loss 0.31122455 Test RE 0.0027611409506022974 c 1.0015875 k 1.000258 m 5.0137053\n",
      "131 Train Loss 0.29476166 Test RE 0.002879497027930239 c 0.99946094 k 1.0003806 m 5.010357\n",
      "132 Train Loss 0.28862667 Test RE 0.002941471440456557 c 0.99686885 k 1.0003892 m 5.0032625\n",
      "133 Train Loss 0.28156018 Test RE 0.003035334769767393 c 0.9975322 k 1.0002292 m 4.993604\n",
      "134 Train Loss 0.27934396 Test RE 0.0030870764528375134 c 0.99899644 k 1.0001316 m 4.993468\n",
      "135 Train Loss 0.2781527 Test RE 0.003138888043931484 c 0.99957347 k 1.0000658 m 4.99492\n",
      "136 Train Loss 0.27683443 Test RE 0.003175063860823274 c 0.99928087 k 1.0000796 m 4.998927\n",
      "137 Train Loss 0.2757874 Test RE 0.0031741024020333986 c 0.9985178 k 1.0001807 m 5.0009894\n",
      "138 Train Loss 0.2744555 Test RE 0.003137377922062864 c 0.99820185 k 1.0002308 m 5.0015626\n",
      "139 Train Loss 0.27265173 Test RE 0.0030795107755751216 c 0.9982786 k 1.000225 m 5.0037875\n",
      "140 Train Loss 0.27192843 Test RE 0.003060766152297137 c 0.99867916 k 1.0001425 m 5.0045033\n",
      "141 Train Loss 0.2715403 Test RE 0.0030592635515596335 c 0.99908787 k 1.0000992 m 5.0046043\n",
      "142 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "143 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "144 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "145 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "146 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "147 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "148 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "149 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "150 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "151 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "152 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "153 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "154 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "155 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "156 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "157 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "158 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "159 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "160 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "161 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "162 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "163 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "164 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "165 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "166 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "167 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "168 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "169 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "170 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "171 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "172 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "173 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "174 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "175 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "176 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "177 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "178 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "179 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "180 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "181 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "182 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "183 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "184 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "185 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "186 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "187 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "188 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "189 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "190 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "191 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "192 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "193 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "194 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "195 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "196 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "197 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "198 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "199 Train Loss 0.27140316 Test RE 0.0030602606621894595 c 0.9992523 k 1.0000974 m 5.004626\n",
      "Training time: 70.89\n",
      "Training time: 70.89\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 1013.7474 Test RE 0.277703461538388 c 0.06845999 k 0.73623914 m -0.0004691181\n",
      "1 Train Loss 497.51984 Test RE 0.2213170263733571 c 0.06759013 k 1.0082668 m -0.00046347734\n",
      "2 Train Loss 497.08154 Test RE 0.2212523602357371 c 0.06755683 k 1.016831 m -0.00046326502\n",
      "3 Train Loss 496.94763 Test RE 0.2212174599610216 c 0.067448825 k 1.0211542 m -0.00046253664\n",
      "4 Train Loss 495.08893 Test RE 0.22065336479451644 c 0.065503664 k 1.032359 m -0.00044953622\n",
      "5 Train Loss 491.69016 Test RE 0.21939905181642436 c 0.06042498 k 1.0202243 m -0.00041952296\n",
      "6 Train Loss 491.636 Test RE 0.21940312573937473 c 0.0604957 k 1.0172106 m -0.0004199339\n",
      "7 Train Loss 491.63495 Test RE 0.2194066480925616 c 0.060519103 k 1.0169923 m -0.0004199529\n",
      "8 Train Loss 491.62805 Test RE 0.2194212363535569 c 0.060634535 k 1.016043 m -0.00041795173\n",
      "9 Train Loss 491.494 Test RE 0.219427547952388 c 0.061181974 k 1.0126787 m -0.00036189563\n",
      "10 Train Loss 490.69052 Test RE 0.2193753153556508 c 0.061965488 k 1.0161355 m -9.983464e-05\n",
      "11 Train Loss 488.96143 Test RE 0.21860760841933954 c 0.056496385 k 1.0205522 m 4.790887e-06\n",
      "12 Train Loss 486.24466 Test RE 0.21792291422362872 c 0.052243043 k 1.0108842 m 0.00027635854\n",
      "13 Train Loss 479.30612 Test RE 0.2154989163349953 c 0.03652105 k 1.0258262 m 0.0006204698\n",
      "14 Train Loss 476.2961 Test RE 0.21386858885511578 c 0.033038937 k 1.0009444 m 0.0006145943\n",
      "15 Train Loss 459.80518 Test RE 0.20825263954883252 c 0.051509775 k 1.0110713 m 0.0002650022\n",
      "16 Train Loss 448.88232 Test RE 0.20546549283117818 c 0.07044464 k 1.0325278 m -9.2582115e-05\n",
      "17 Train Loss 424.3059 Test RE 0.19609638661888848 c 0.10044422 k 1.0185819 m -0.00070761476\n",
      "18 Train Loss 401.37256 Test RE 0.17178752235063705 c 0.20031668 k 1.0077946 m -0.0043711015\n",
      "19 Train Loss 358.48395 Test RE 0.16142789174637975 c 0.42849773 k 1.0073469 m -0.009761263\n",
      "20 Train Loss 338.15564 Test RE 0.14536494993072183 c 0.931888 k 0.9997964 m -0.017924005\n",
      "21 Train Loss 323.25586 Test RE 0.14752798189168276 c 1.2395381 k 0.9984695 m -0.011346674\n",
      "22 Train Loss 314.99768 Test RE 0.15123401705168615 c 1.3061343 k 0.9972926 m 0.048425913\n",
      "23 Train Loss 292.53262 Test RE 0.1301404951184267 c 1.6256399 k 0.9901019 m 0.22968504\n",
      "24 Train Loss 270.80185 Test RE 0.11903453007511583 c 1.821813 k 0.987838 m 0.5524716\n",
      "25 Train Loss 232.94797 Test RE 0.12251393372560654 c 1.6824225 k 0.98718256 m 1.1467712\n",
      "26 Train Loss 189.96054 Test RE 0.09826459391757797 c 1.3661333 k 0.99134994 m 1.3296008\n",
      "27 Train Loss 145.85045 Test RE 0.07507318897859597 c 1.4574388 k 0.9731243 m 1.65802\n",
      "28 Train Loss 134.95938 Test RE 0.0783688085025939 c 1.2247235 k 0.9819728 m 1.7757853\n",
      "29 Train Loss 125.396454 Test RE 0.07540632321667248 c 1.0474838 k 0.97948 m 1.93703\n",
      "30 Train Loss 121.24638 Test RE 0.07868713712349433 c 0.97724575 k 0.97895944 m 2.09531\n",
      "31 Train Loss 103.01279 Test RE 0.08252593100178834 c 1.3640733 k 0.984241 m 2.428631\n",
      "32 Train Loss 89.02916 Test RE 0.0783580067227243 c 1.7098767 k 0.98361236 m 2.7917585\n",
      "33 Train Loss 82.38872 Test RE 0.07152580095805444 c 1.6469073 k 0.97374076 m 2.791579\n",
      "34 Train Loss 75.7269 Test RE 0.0654045351789531 c 1.6384181 k 0.9823622 m 2.9078195\n",
      "35 Train Loss 71.20963 Test RE 0.06998972696816329 c 1.5613812 k 0.9784788 m 2.9922483\n",
      "36 Train Loss 69.188 Test RE 0.07011357535357754 c 1.5681154 k 0.9823905 m 3.0578685\n",
      "37 Train Loss 67.81801 Test RE 0.06842243631747882 c 1.5663126 k 0.98079854 m 3.0893738\n",
      "38 Train Loss 56.840733 Test RE 0.05828185720030408 c 1.4037776 k 0.9778083 m 3.1346083\n",
      "39 Train Loss 54.56115 Test RE 0.058493034970769194 c 1.3940078 k 0.9815074 m 3.212378\n",
      "40 Train Loss 51.180916 Test RE 0.05779063275536593 c 1.318177 k 0.9862651 m 3.4006457\n",
      "41 Train Loss 45.10374 Test RE 0.04717956472719961 c 1.1998419 k 0.9854624 m 3.7297695\n",
      "42 Train Loss 43.26175 Test RE 0.04543082386362233 c 1.12659 k 0.9890986 m 3.9481683\n",
      "43 Train Loss 37.65647 Test RE 0.04302711321854094 c 0.9056505 k 0.9905499 m 4.2507877\n",
      "44 Train Loss 25.178879 Test RE 0.03902120878050545 c 1.1218548 k 0.99757135 m 4.5104938\n",
      "45 Train Loss 20.739294 Test RE 0.03500908034488648 c 1.0738658 k 0.9958284 m 4.844212\n",
      "46 Train Loss 18.669569 Test RE 0.03390983466906853 c 1.0568115 k 0.99465406 m 5.145851\n",
      "47 Train Loss 16.227444 Test RE 0.03129877986819122 c 1.1002576 k 1.0045475 m 5.2321315\n",
      "48 Train Loss 14.300604 Test RE 0.03086192867948527 c 1.0815389 k 0.9994348 m 5.15574\n",
      "49 Train Loss 10.010903 Test RE 0.02663341326847869 c 1.0901624 k 0.99249244 m 4.959534\n",
      "50 Train Loss 8.889172 Test RE 0.02457478432733521 c 1.050772 k 1.0029895 m 5.102825\n",
      "51 Train Loss 8.521907 Test RE 0.02368232259560879 c 1.0424187 k 1.0014929 m 5.2194223\n",
      "52 Train Loss 7.917599 Test RE 0.02263102186560161 c 1.0081917 k 1.0003524 m 5.3206224\n",
      "53 Train Loss 7.006851 Test RE 0.020262332698238936 c 0.9514223 k 1.0035697 m 5.354457\n",
      "54 Train Loss 5.86123 Test RE 0.01799955612782231 c 0.95706624 k 1.0043474 m 5.336559\n",
      "55 Train Loss 5.1823745 Test RE 0.0177924337232548 c 1.0049801 k 1.0005302 m 5.28589\n",
      "56 Train Loss 4.8019915 Test RE 0.017609510136126095 c 1.0157373 k 1.002433 m 5.2776694\n",
      "57 Train Loss 4.4667826 Test RE 0.017580943254428837 c 1.0372548 k 1.0028465 m 5.24336\n",
      "58 Train Loss 3.3068557 Test RE 0.015661940522825057 c 1.0809791 k 0.99953735 m 5.127144\n",
      "59 Train Loss 2.5292792 Test RE 0.012855097558141794 c 1.0548092 k 1.0001919 m 5.0436826\n",
      "60 Train Loss 2.3225384 Test RE 0.011299535058804414 c 1.0264356 k 1.0002822 m 5.06771\n",
      "61 Train Loss 2.2182417 Test RE 0.01062611146040477 c 1.0244062 k 1.0001605 m 5.057311\n",
      "62 Train Loss 1.9893875 Test RE 0.010266882800122312 c 1.0168668 k 1.0007629 m 5.03881\n",
      "63 Train Loss 1.7703404 Test RE 0.009676531657925461 c 0.99938667 k 1.0004804 m 5.0164876\n",
      "64 Train Loss 1.6065955 Test RE 0.008971222426886624 c 1.0086664 k 1.0004579 m 4.986378\n",
      "65 Train Loss 1.3518479 Test RE 0.007497203566394702 c 1.0213121 k 0.9987985 m 4.929671\n",
      "66 Train Loss 1.0159458 Test RE 0.005953336414727807 c 1.0060852 k 0.99938226 m 4.9081774\n",
      "67 Train Loss 0.8041561 Test RE 0.004873230938596816 c 1.0112967 k 0.9993525 m 4.9367104\n",
      "68 Train Loss 0.75428027 Test RE 0.004553992144267961 c 1.0171046 k 0.9997346 m 4.9518414\n",
      "69 Train Loss 0.729786 Test RE 0.004493840503666354 c 1.0115395 k 1.0001287 m 4.9741554\n",
      "70 Train Loss 0.7149785 Test RE 0.004629466205542236 c 1.0103893 k 1.000283 m 4.9905977\n",
      "71 Train Loss 0.7000423 Test RE 0.004803997573446679 c 1.0135806 k 1.0001872 m 4.994118\n",
      "72 Train Loss 0.685458 Test RE 0.004752514320784706 c 1.0099654 k 1.0001005 m 4.9828234\n",
      "73 Train Loss 0.6455093 Test RE 0.004431721881561155 c 0.9975175 k 1.0001729 m 4.9726834\n",
      "74 Train Loss 0.5264689 Test RE 0.0038130269771190204 c 0.9928355 k 1.000199 m 5.0079675\n",
      "75 Train Loss 0.4736542 Test RE 0.0037346661939807453 c 0.9999208 k 1.0006706 m 5.019511\n",
      "76 Train Loss 0.45047504 Test RE 0.003509162960220032 c 0.9983012 k 1.0006723 m 5.0267043\n",
      "77 Train Loss 0.44529837 Test RE 0.003472686499990487 c 0.9958652 k 1.0008141 m 5.0290904\n",
      "78 Train Loss 0.4396626 Test RE 0.003457526596234304 c 0.9927315 k 1.0009216 m 5.0261817\n",
      "79 Train Loss 0.4255029 Test RE 0.003382955185498176 c 0.9887679 k 1.0005997 m 5.014841\n",
      "80 Train Loss 0.39911142 Test RE 0.003296648097992484 c 0.98953265 k 1.0001459 m 5.007164\n",
      "81 Train Loss 0.34411114 Test RE 0.0032239726184953837 c 0.99391186 k 1.0005777 m 5.03504\n",
      "82 Train Loss 0.32611486 Test RE 0.003128281255129858 c 0.99855095 k 1.0008104 m 5.0365934\n",
      "83 Train Loss 0.31748796 Test RE 0.0030634630467994183 c 1.0011466 k 1.0005721 m 5.029561\n",
      "84 Train Loss 0.29748097 Test RE 0.0027884292192803532 c 1.0003347 k 1.0003722 m 5.014855\n",
      "85 Train Loss 0.28282258 Test RE 0.002652087228423884 c 0.9965102 k 1.0005364 m 5.0153418\n",
      "86 Train Loss 0.2817151 Test RE 0.0026500051389006006 c 0.9955445 k 1.0005243 m 5.0155406\n",
      "87 Train Loss 0.28148603 Test RE 0.0026485874100543056 c 0.99541944 k 1.000515 m 5.015389\n",
      "88 Train Loss 0.27885357 Test RE 0.0026309789412263256 c 0.99515486 k 1.0005178 m 5.0147977\n",
      "89 Train Loss 0.27622458 Test RE 0.0025823556818539476 c 0.9972513 k 1.0005052 m 5.013536\n",
      "90 Train Loss 0.27305108 Test RE 0.0025331603599372554 c 1.0005838 k 1.000471 m 5.01044\n",
      "91 Train Loss 0.26113284 Test RE 0.002497106564795693 c 1.0039282 k 1.0005109 m 5.0034943\n",
      "92 Train Loss 0.24859244 Test RE 0.0024905139626252154 c 1.0000782 k 1.0003982 m 4.9999027\n",
      "93 Train Loss 0.21859998 Test RE 0.002328270887868917 c 0.9943529 k 1.0001848 m 4.9903483\n",
      "94 Train Loss 0.16703548 Test RE 0.0023504165062354075 c 1.0005518 k 1.000016 m 4.9833255\n",
      "95 Train Loss 0.15271945 Test RE 0.0023967753874061973 c 1.0023974 k 1.0001321 m 4.9871254\n",
      "96 Train Loss 0.14765148 Test RE 0.0024256689954606893 c 1.0026002 k 1.00019 m 4.991531\n",
      "97 Train Loss 0.14069104 Test RE 0.002383738886436766 c 1.0045481 k 1.0000889 m 4.995338\n",
      "98 Train Loss 0.1370545 Test RE 0.0022805337888134746 c 1.0025744 k 1.000128 m 4.9950747\n",
      "99 Train Loss 0.13652325 Test RE 0.002275789276388733 c 1.0012859 k 1.0002007 m 4.994498\n",
      "100 Train Loss 0.13643035 Test RE 0.002278063798837047 c 1.0010772 k 1.0002005 m 4.9942346\n",
      "101 Train Loss 0.13631356 Test RE 0.0022827641826710337 c 1.0009946 k 1.0001796 m 4.993891\n",
      "102 Train Loss 0.13622756 Test RE 0.002285730298010483 c 1.0012522 k 1.0001693 m 4.9936934\n",
      "103 Train Loss 0.13459705 Test RE 0.0022997740611408173 c 1.0023617 k 1.000147 m 4.9933968\n",
      "104 Train Loss 0.1335265 Test RE 0.0023140218125648065 c 1.0022193 k 1.0001701 m 4.995681\n",
      "105 Train Loss 0.13329187 Test RE 0.0023150513696669024 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "106 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "107 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "108 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "109 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "110 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "111 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "112 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "113 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "114 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "115 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "116 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "117 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "118 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "119 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "120 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "121 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "122 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "123 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "124 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "125 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "126 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "127 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "128 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "129 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "130 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "131 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "132 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "133 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "134 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "135 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "136 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "137 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "138 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "139 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "140 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "141 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "142 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "143 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "144 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "145 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "146 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "147 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "148 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "149 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "150 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "151 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "152 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "153 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "154 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "155 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "156 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "157 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "158 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "159 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "160 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "161 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "162 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "163 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "164 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "165 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "166 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "167 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "168 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "169 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "170 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "171 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "172 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "173 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "174 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "175 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "176 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "177 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "178 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "179 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "180 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "181 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "182 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "183 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "184 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "185 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "186 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "187 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "188 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "189 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "190 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "191 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "192 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "193 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "194 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "195 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "196 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "197 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "198 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "199 Train Loss 0.13329163 Test RE 0.002315045579990197 c 1.0020719 k 1.0002052 m 4.9972653\n",
      "Training time: 65.12\n",
      "Training time: 65.12\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "m_full = []\n",
    "k_full = []\n",
    "c_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []   \n",
    "    beta_val = []\n",
    "    m_val = []\n",
    "    k_val = []\n",
    "    c_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "    N_f = 10000 #Total number of collocation points\n",
    "\n",
    "    layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.05, \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-6, \n",
    "                                tolerance_change = 1e-6, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    beta_full.append(beta_val)\n",
    "    m_full.append(m_val)\n",
    "    k_full.append(k_val)\n",
    "    c_full.append(c_val)\n",
    "    \n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full,\"m\": m_full,\"k\": k_full,\"c\": c_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "990b2054-f35e-4c8e-c378-69ff2eb19f4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc18050b410>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRmUlEQVR4nO3dd3wUdeLG8c+mbXpIAqRACAFCDU2aIAqKgCjYRQXbWQ4LamwolhO9E5SfIio2PA+xHZ4KWBFio4ggVXoPJJCEUEJ6z/z+GAhEWgK7md3keb9e8wrZncw8jMA+fmfmOzbDMAxEREREXIiH1QFERERE/koFRURERFyOCoqIiIi4HBUUERERcTkqKCIiIuJyVFBERETE5aigiIiIiMtRQRERERGX42V1gDNRUVFBWloaQUFB2Gw2q+OIiIhINRiGQW5uLtHR0Xh4nHqMxC0LSlpaGjExMVbHEBERkTOQmppK06ZNT7mOWxaUoKAgwPwNBgcHW5xGREREqiMnJ4eYmJjKz/FTccuCcuS0TnBwsAqKiIiIm6nO5Rm6SFZERERcjgqKiIiIuBwVFBEREXE5KigiIiLiclRQRERExOWooIiIiIjLUUERERERl6OCIiIiIi5HBUVERERcjgqKiIiIuBwVFBEREXE5KigiIiLictzyYYFSfSm7DP54bg4V+w4QOrgnF97dBi/9VxcRERenEZQ67N13Ib61jaBprzH821sYeH9bkhqPZNfaHKujiYiInJIKSh313ntw991QUgLfdHqarZF9KceDIVmfcqD7INK35lkdUURE5KRUUOqgTfNSWHrPB4DBE0/AG6vPJz59IQdmLyLLI4xzSpayvs9dVFRYnVREROTEVFDqoL03PcK/y//Gx62fZ/x4sNnM1xtf0ZuC/35NKV5cvH8G8+7/xtqgIiIiJ6GCUsf88eYy+u37ggpsXPjGNZXl5Igmw8/jz4seBsBr6lvs22dBSBERkdNQQalDDAOMJ58EYFm7W4gelHDC9brM/AcTm0zm0rKveOml2kwoIiJSPSoodciaj/6kV86PlOBNyw/HnXQ9r5AAEqY+SCk+vPsuHDxYaxFFRESqRQWlDtn/4nsArI69kobdm59y3SFDoFMnKMwr47//3FYL6URERKpPBaWOyMkooNvGjwHwf/Cu065vs8H4m9azmTYMfX0QJUW6pUdERFyHCkod8cN7qewillTvODo8MKBaPzN4VBwNbQeIrUhm6YSfnZxQRESk+lRQ6oj3F7WhC6uZNWYJNs/q/Wf1CvZnQ5cRAFS8929nxhMREakRFZQ64NAh+PlnABuX3NK4Rj8b/cydAJybPov0dQccnk1ERORMqKDUAb9+moZ3WQHt2kHr1jX72dirzmFLQFfslLDu6RnOCSgiIlJDKih1QPhLY9hPQ55vMe2Mfn7/JSMBCPvpc0fGEhEROWMqKG6utLCMhJTv8KeQdpfXcPjksNZjrwWga94CUpamOzKeiIjIGVFBcXMbP15BKIc4ZGtAu7+de0bbaNgtlnda/h8XsIDPfo1wcEIREZGaq3FBWbBgAcOGDSM6Ohqbzcbs2bNPuu6oUaOw2WxMnjy5yuvFxcXcf//9NGzYkICAAC6//HJ2795d0ygC7P/sJwA2R12Ih7fnGW/HeORRfqMvn3+pzioiItar8adRfn4+nTt3ZsqUKadcb/bs2SxdupTo6Ojj3ktMTGTWrFnMmDGDRYsWkZeXx9ChQykvL69pnHovZIU5f0nJ+Red1Xauusr8umwZpOssj4iIWMyrpj8wZMgQhgwZcsp19uzZw+jRo5k7dy6XXXZZlfeys7N5//33+eijj7j44osB+Pjjj4mJieHHH39k8ODBNY1UbxVmFdH+0G8AxNxavcnZTiYyEu5o+xtdNv2XdRMGE/X6MEdEFBEROSMOH8+vqKjg5ptv5rHHHqNDhw7Hvb9ixQpKS0sZNGhQ5WvR0dEkJCSwePHiE26zuLiYnJycKovAhvd/x48iMjyiiB3c9qy3d1uj7xjNm/jO+tQB6URERM6cwwvKSy+9hJeXFw888MAJ38/IyMDHx4fQ0NAqr0dERJCRkXHCn5kwYQIhISGVS0xMjKNju6Vfd8XxGBP5sesYbB62s95ew9uGApCw+weK80rPensiIiJnyqEFZcWKFbz22mt88MEH2Gw1+8A0DOOkPzN27Fiys7Mrl9TUVEfEdXtzNjbnZR4j785Eh2yv9c29OGgLJ5RDrHn7N4dsU0RE5Ew4tKAsXLiQzMxMmjVrhpeXF15eXuzatYtHHnmE5s2bAxAZGUlJSQlZWVlVfjYzM5OIiBPf4mq32wkODq6y1Hfl5bB0qfnr3r0ds00Pb082x10CQM6XSY7ZqIiIyBlwaEG5+eabWbNmDatXr65coqOjeeyxx5g7dy4A3bp1w9vbm6Skox+A6enprFu3jj59+jgyTp225efdXJ73Ce39kklIcOCGD1+43Hjtjw7cqIiISM3U+C6evLw8tm3bVvl9cnIyq1evJiwsjGbNmhEeHl5lfW9vbyIjI2nTpg0AISEh3HHHHTzyyCOEh4cTFhbGo48+SseOHSvv6pHT2/fhHD7h76yy98fT8xeHbbfVqAEwFdoXLOfA9kOEt2zgsG2LiIhUV40LyvLly7nwwgsrv3/44YcBuPXWW/nggw+qtY1XX30VLy8vhg8fTmFhIQMGDOCDDz7A0/PMJxqrb2xLfgcgu72Dzu8c1uicGJJ92mArKWLrl8kMHNPVodsXERGpjhoXlP79+2MYRrXX37lz53Gv+fr68sYbb/DGG2/UdPdyWHSKWVD8Bzi2oAD8+/bFjH8nlL9vtzHQ4VsXERE5Pc1r7oZydufQsmQTAHHX93L49ntfFgbY+Oknh29aRESkWlRQ3FDy7D8BSPNsSqMOjR2+/X79wNMTkreXs3NzscO3LyIicjoqKG7o0M8rAUhtdI5Tth8UBP+JfJL9NGTXSzOcsg8REZFTUUFxQ55rVgFQ0MY5BQWgeXMI5RC2+Y67Q0hERKS6VFDc0HPe/+JKZmFcN9xp+wi67AIAYlMWOm0fIiIiJ6OC4mYKC+GXrU35iitpfUU7p+0n/tY+lONBbNkO9vyxx2n7EREROREVFDezbp05zX3DhtCkifP2ExgdzFb/zgAkf6hRFBERqV0qKG4m85Mknuaf3NhiKTV8HmPN99XmfADKflFBERGR2qWC4mYCf/6af/IPrja+dPq+fC82C0rUdhUUERGpXSoobiY4dR0Anp06OH1fLW87n/lcwIziqziwv/qzB4uIiJytGk91L9aKyV4PQNj5zi8o4e0juKfdfDZuhC6/wRVXOH2XIiIigEZQ3MqBTftoaOwDIPYS593Bc6zzzbM8LNRZHhERqUUqKG4k9Qdz9CTFK47AiIBa2ef550MYB8ies7hW9iciIgI6xeNWcn43C0p6WALNammfFzTbyQHiKNpgpygnB99gn1ras4iI1GcaQXEn682CUtDC+defHBHTN5b9tob4UszWz1fX2n5FRKR+U0FxI8+FTqYD68gafnet7dPmYWNH43MB2P/tklrbr4iI1G8qKG7CMODPjT5soAPN+8XW6r4LO5kFxWfF77W6XxERqb9UUNxEZiYcOAA2G7RtW7v7DhlsFpSYNI2giIhI7VBBcRMpXy5jGrfxWMNp+PvX7r5b3diDCmw0K99J+qqM2t25iIjUSyoobqLwp8XcxnSu8vy61vcdGB3Mdl/zwtydMzSKIiIizqeC4iZsG8w7eApr8Q6eYy3qM4bbeZ8fc3pasn8REalfVFDcRHD6ZgC8O9XODLJ/5XHLzUzjduati7Zk/yIiUr+ooLiJiNytADTo2dqS/Z9rXifL8uVQWmpJBBERqUdUUNxAXnoukRXpADTpH29Jhtat4fyg1dxRNIVN3223JIOIiNQfKihuYM/8bQDsszUiNK6BJRlsNnjV/jhTuJ8Dn861JIOIiNQfKihuYP/KFADSA60ZPTkiL6E3AF7LNGGbiIg4lwqKG/g15Ar8yec/g/9naY6gi3sBELVnmaU5RESk7lNBcQNbt0Ih/jTq0sTSHHHDewDQsnQzWbuyLc0iIiJ1mwqKG9iyxfwab+0ZHkLjG5Lq1RyA7Z+tsDaMiIjUaSoobmDc8qG8y99p12i/1VHYE2WOouT8rNM8IiLiPF5WB5BTO7T9AINKvwMgr/2rFqeBks49IPVzfNeqoIiIiPNoBMXF7fnVnKAtzaMpgREBFqcB31uG049f+ZsxzeooIiJSh2kExcUdWmZegJIRHI8rTDLf4dJYFnnEUpEO6ekQFWV1IhERqYs0guLiyjaYIyi5kdZMcf9XAQHQvr3562U6yyMiIk5S44KyYMEChg0bRnR0NDabjdmzZ1e+V1payuOPP07Hjh0JCAggOjqaW265hbS0tCrbKC4u5v7776dhw4YEBARw+eWXs3v37rP+zdRFPjvNEZSKlhbfwnOMG2J/ZxIPUfbvD6yOIiIidVSNC0p+fj6dO3dmypQpx71XUFDAypUreeaZZ1i5ciUzZ85ky5YtXH755VXWS0xMZNasWcyYMYNFixaRl5fH0KFDKS8vP/PfSR0Vut8cQfHr7BojKAAXBKzgISbT9PfPrY4iIiJ1VI2vQRkyZAhDhgw54XshISEkJSVVee2NN96gZ8+epKSk0KxZM7Kzs3n//ff56KOPuPjiiwH4+OOPiYmJ4ccff2Tw4MFn8NuouzyL8wEI79XK4iRHNRzSA/4HcQeWYVQY2DxsVkcSEZE6xunXoGRnZ2Oz2WjQoAEAK1asoLS0lEGDBlWuEx0dTUJCAosXLz7hNoqLi8nJyamy1AdZWdC6YjMB5NHkQtcZQWl5dWdK8aKRsY/U31KsjiMiInWQUwtKUVERTzzxBCNGjCA4OBiAjIwMfHx8CA0NrbJuREQEGRkZJ9zOhAkTCAkJqVxiYmKcGdtlJCebX4MiAvAP8rQ2zDF8gn3Z5t8JgNSZulJWREQcz2kFpbS0lBtuuIGKigreeuut065vGAY224lPFYwdO5bs7OzKJTU11dFxXdKOHebXFi2szXEi+5ubM8qW/KaCIiIijueUglJaWsrw4cNJTk4mKSmpcvQEIDIykpKSErKysqr8TGZmJhERESfcnt1uJzg4uMpSHwTNeI8kLua2iv9YHeU4Hr3MghKyRQVFREQcz+EF5Ug52bp1Kz/++CPh4eFV3u/WrRve3t5VLqZNT09n3bp19OnTx9Fx3Jr/huVczE/E++yyOspxIoaaBSUwJ43yMsPiNCIiUtfU+C6evLw8tm3bVvl9cnIyq1evJiwsjOjoaK699lpWrlzJt99+S3l5eeV1JWFhYfj4+BASEsIdd9zBI488Qnh4OGFhYTz66KN07Nix8q4eMQVkmud4PFvFWZzkeHFDO9DaL5WthU1Yu8lGQoLViUREpC6pcUFZvnw5F154YeX3Dz/8MAC33nor48aN4+uvvwagS5cuVX7ul19+oX///gC8+uqreHl5MXz4cAoLCxkwYAAffPABnp6ucyGoKwjPMa+SDersehehePp4EtWjKVsXmDPKqqCIiIgj2QzDcLvx+ZycHEJCQsjOzq6z16OUl5RTYffFmzJ2L06haW/Xu3Pp0UfhlVfgnnugGtdBi4hIPVeTz289i8dF7V2xG2/KKMaHqG6u8JjA4w2IXM9XXM7w/15pdRQREalj9DRjF7Vv6Q6igTTvWOJ8XPPUV4euPjTjGwoP+VKcV4o90NvqSCIiUkdoBMVF7duZRwYR7A92vetPjoi5sBWHbA3wo4hts9dZHUdEROoQFRQXtTBkGFFk8J+rvrU6yknZPGzsCOsOwL7vNR+KiIg4jgqKizoyi2zzVq59Fi63jTkfim25CoqIiDiOCoqLOvIcnjjXmwKlCr8LzIISkaqCIiIijqOC4qIm/9GbeQykjb9rP3eo+XVmQWlVtI7cvQUWpxERkbrCtc8f1FOFBwroXroEgIPtAi1Oc2qNuzZhp1dLUsui8P4lk3NvaG51JBERqQM0guKCMpaaz97JJpjQFqEWpzkNm41Hhm3lAhayMLW51WlERKSOUEFxQVl/pgCw1x6LzWZxmGro2csMuUyXoYiIiIOooLiggk1mQTkU3MziJNXTs6f5dd2SPGuDiIhInaFrUFxQ2Q6zoBQ2co+C0i2hmLV0o13qRjI3ZtK4XbjVkdxK+q4Skn7xYt0GD/btg7DsZM7Ln4dvtw50+FtPYuN9rI4oIlLrVFBckFe6WVAqYtyjoAQ3shPoU4JnSQXJny+n8T8GWx3J5RkGLPz3ZnKffZm+6f/jTebxB70AuJmFXM3dMA9yJwTybcNrqPj7PVzybC981FVEpJ7QKR4XdLDQj700xrtlrNVRqi2tqXmeJ+/nPyxO4vp2rMrmq9j76fv3dlyW/m9CyOHO6DmMHg0vvgjD/taIdc0vI8urEUHkMXT/dC4ffy6LQ4Yw55UNuN/zx0VEak4jKC7oYb932M47LLjefT6Jys/pCTs+IXCDCsqpJL24gtZPXsOVhnmn1voWw2g44RHuuvb8Y/53YYi5VFRw8PslpD37Lm1XfkL/oh8oevQXbv1uG//6oCnN3GOATUTkjGgExcVUVEDq4bnZmsW6wS08hzW81BxBidv/B0aF+xSr2mIY8PmNMzl/7HnEGrvY49uCPdN/pMP2r4kY3g88TvBX0cODsKF9SFgxnbJ1m9nceigfe9zKR780pUsX+P77Wv9tiIjUGhUUF7N3L5SUmJ9XTZpYnab6Wl7ThVK8aGxkkrIoxeo4LsUw4LHHYM2M9fhSzMYWlxGRuoImtwyo9jZ8O7Skzaav6bvqDXr0gKwsuP2yDD647Ved8hGROkkFxcUcmPMHm2nN57434eVGJ+B8gn3Z7t8JgNSZmhDlWBMnwiuvwL94mjm3fUa7LV/h1bBBzTdks9G2kw8LF8LoUaV8znWMnD6Qqf0+obTU4bFFRCylguJictcm05qttPTaZXWUGtva6Wo+4FZWpEdbHcVlfPXiRp59ogiASZNsDJk2HDw9z2qbdju8Mbmc6J5N8aaMUQtv4j+dJlOgRyGJSB2iguJiSraap0fyQt3vCshD9z7F3/iAz/f0sTqKS1j97W76jL2AH7iEp+47xEMPOXDjvr60/P0TdlyRCMCoTQ/xaacXVVJEpM5QQXE1qWZBKYl2n1uMjzgyo+zKldT7Uw6H9pdRcu0IGrGfZiHZPD/eCefrPDxoMWsSu/7+LwDu3D6WjztPVEkRkTpBBcXF+GaaBcUj1v1GUOLjITSojFaFa9j02wGr41jGMODHvuPoWbyQXFsQDX/+HI9gJz2V2mYj9t2n2HWXWVL+vu1x3j/nTYqKnLM7EZHaooLiYkKyzYLi18b9CoqHB8zzvpQ1dObAtK+tjmOZH55cwNWbxwOQ+a/3CD6nldP3GTv1KXbd/hwZtkje3DyAkSOhvNzpuxURcRoVFBcTUWReHNugk/sVFICC+C7mL/6onxO27d1ZSPzEO/HA4M/ud9Dyyetrbd+x7/+DbTPXkuzTlpkz4b770C3IIuK2VFBcSH5WCduMluylMRHdY6yOc0Z8z+8BQOOd9bOg/D7keVpVbCXTO5oOP7xS6/vve2VDPvkEbDbY+O58Prjt11rPICLiCCooLiQlw4eeLKNNyF5CmoVYHeeMNLvWvFI2vmgN+Qfq14UQ334Lz266gWV0J3fi23iFW/Pf8Npr4ctHFjOXwVz94RV8Nna1JTlERM6GCooLSTk8Aas7P2Mlsmcz9nk0xpsytn6+2uo4taa4GBITYQ2d+eLRpbRMvNzSPFf98xwyYs8lhBz6vXgJc9/abmkeEZGaUkFxIXWhoGCzsbOROYpy8If6c5rnrcklbN8OkZHw9D9c4K+Vry+xq78iNbwzkeyl1ejB/PHNXqtTiYhUmwv8SypHtPj4eTbTmlsPvWZ1lLNS2NEsKN6r6kdB2bergMuf7MCLPM7EZ/MJCrI6kcnWIISo1T+Q4R9HS2M7PlddypYVuVbHEhGpFhUUF+KbupXWbKVRkHtfu2G/6lKe4XleL7nb6ii1Yul1L9OyYhs3+3zGyJtd66+UV9NIQn6fy0GvRnQpX8nevleTvqvE6lgiIqflWv+a1nMBB81zPN6t3G8W2WO1GdGNf/EMX2T0JTPT6jTOtWvFfi5Y9jIAWY+/hEeAn8WJjufXKR6POd+TbwtgT1E4V1xukJNjdSoRkVNzo+fl1n3h+WZBCergzhehQIMG0K4dbNwIS5bA5dZeL+pU6277Py4jl61BXekw7jqr45xUg4u7kzrnDxJvbsveNR5ce61515GPj9XJXFdxMWz4I4+9S3eyuiyBnTvhwAHosG02DQ9uxTCgwDuYQp8GlIeEUd6kGcTGEt7El5YtoXVraNnSfLijiNScCoqLKC8pJ7JsNwANz3HvggIw6Jz9tNm4kH0f+8Plg62O4xRbF6Rz4bo3ADCe+6c5la4Lixncnm+/h/794cekCiYN/ZXH516EzWZ1MteQvb+U1f9ezqHZvxK26TdistfRlV0UYWcIhYB5oEYwnauYfdLthHGALMIA6MYKmjctI+DcjnQ6158ePaBrV1zmOiURV6aC4iL2rdtLJGWU4UnjzlFWxzlr13l8yXnczfKkAUDdLCjb7pxAPIVsCj2XtomXWh2nWrp3h89nlHPo8pu5Mem/fH7FdK77+harY1kmMxO++AIavPgEw1LfpB95x61T6B3MHdcUEB0fQOPG0HTphaTsCcFGBV75OXjmZ+OVtZ+A/TsxDBh8dShbt8GWLfB07j+5cvdXlH/hwbovEvid3vyH3mS3703LS+Lpf6GN88+HEPec9kjEuYwamj9/vjF06FAjKirKAIxZs2ZVeb+iosJ49tlnjaioKMPX19fo16+fsW7duirrFBUVGaNHjzbCw8MNf39/Y9iwYUZqamq1M2RnZxuAkZ2dXdP4Lmv9tKWGAcYez6ZWR3GIHV+tMQwwcgg0ivNLrY7jcBuX5RpZhBgGGNun/mh1nBpbc8mjhgFGKZ7Gt/d+Z3WcWlVWZhi/vLrSuHRQqeHpaRhgGOP4h2GAcdAj3FjZ8hpj5W2vGXtmLDAq9u2v/oYrKgzj0KEq3+bf8DejKDTC3MlfllSaGB6UGR4ehtG9u2E8/kipMWeOYeTlOeE3LeIiavL5XeMx6fz8fDp37syUKVNO+P7EiROZNGkSU6ZMYdmyZURGRjJw4EByc4/e3piYmMisWbOYMWMGixYtIi8vj6FDh1Jej59ulplRwXK6sSOoi9VRHCJ2SHtybMEEkceWmeusjuNwL04JpAPrmZbwCi3uvMjqODXW8buXWNPpJrwo58K3ruW3f/1idSSn259eytfDP+ZP/3Pp/9A5eM/7lvJyc1Qp6pm72DPrD0JLM+m67Qu6TnuA6OvPx9YwvPo7sNmqDIXYbOD/3/9gP5gBaWkwcyY8+ijFPc6j3NtOUeNY4lp6UlEBy5fD8Fd6EjWkM58E3834NtN5Y/RmFi4wKNFNV9VmGFBWBgUFcOiQOUKWlgYZGbBvHxw8CNnZkJcHhYV6oKarsxnGmT9OzGazMWvWLK688koADMMgOjqaxMREHn/8cQCKi4uJiIjgpZdeYtSoUWRnZ9OoUSM++ugjrr/efJBaWloaMTExfP/99wwefPrTATk5OYSEhJCdnU1wcPCZxncpb7wBDzwA11xjDjnXBSsaX0K3fXP5+ZopXPTFfVbHcZiUFPPix7IyWLoUeva0OtGZMUpKWdvqKjqlfkcBfiRP+Z4O9/W3OpbDpSUX89vfp9P9pxeJM5IBKMGbpAv+Ret/jyE+3oJQJSXmp2fTpqSmwm9z8xj+9xA8jIoqqx0gjOUevdjY9ipKb7uLAQOgc2fw9LQgcy0qL4f9+2HvXrNc7N179Nf79pnlIzsbcnKOfs3NNQ/r6T7RbFTgQwm+FGGnmGCfYrz9vckNjCIgAAICIMFYS5C9hCD/coL9ywgOML8G+ZdjbxhEefdeNGhg3hDQeNMCAr2K8PO3YfOwmc30yBIYCD16HN35ihVmMzryvpcXeHubV6v7+UGLFkfXzcsz1/HxMderIxeL1eTz26HXoCQnJ5ORkcGgQYMqX7Pb7fTr14/FixczatQoVqxYQWlpaZV1oqOjSUhIYPHixScsKMXFxRQXF1d+n1MH75Hcs8f82rSptTkcKb9TH/hpLt7LFgN1p6C883wmZWWNGTDAfcsJgM3Hm/YbvmB5i6vpvm8OzUdfxnb/ObT82wVWR3OI3bvKWXjLe5y/4AWuw7wA/YBXY3Ze8SDtX7mTy2IbWxfOx6fyL3tMDNxwZyBcmorx+xKyf/idwl+XEJ68nPDygwyumEPGhkbcNuYuABo2KGOBZ3+MNu0IP789jXu3xNayhfnh5u9v3e+pBsrKzH/zdu2CnTuPWZINDu44RPaePHzL8wggn0DyKpc0olmI+efTi1Je4ZEq7/tTgJ1i7BSziL48yOt4ekJFBewzwgkiFx9Kq4YpgZ9KLuLiQz9VvpREP8LIOmH2JfSiN0sqv09hJI0P//n6q11BHXj6inUEBZldZcy0kTTcv/mE65ZEx7Lr153Y7eadX+FDLsRr1fKjK3h7H12ioszbJI8YNQr+/BP8/TH8/DDsflQcXsoCgsl++mVKSqC0FHx+/B5bRjql3v4UeQZQ6BFAoWcgBZ6BFBDAgcBYioptFBdDcDDceedJ/zM6nUMLSkZGBgARERFVXo+IiGDXrl2V6/j4+BAaGnrcOkd+/q8mTJjAc88958ioLmf34T/fTZpYm8ORQob0gZ8gds9iDKNu/A/Avi1ZPPF+K/rSl4DRnwChp/0ZV+YV6Eu7jTP5veWVnJP9C88k5vJkD0hIsDrZmcvOhpdegtcmwW/F79CU3ezziWb/38bQ9pW7CA9w0Q/x6Ghs11xNg2uupgFASQkVq9eQPvN3grPiGZoG8+dDo0NbaMdvsPg3WFx1E0WhkRSPepDg8U+Yf98KCuDDD6FxY/P0U3Dw0SUoCHx9zf87r45j/xKXl5vDGQUFkJ9fdSkooCwmjj2xfdi5E3ZvzKXVB09TfDCfskN5GHn5eBbmEUAejchjKUN5lv8DIJA8cg/fAXUif7a+jrl3XECDBhAS5Mn1I9446bpdBkdw/5yjkY3AYmz5pcetZ/j40KunN8terYyP56gm5OcHUI4XZXhShhdlFZ6UGF7k+7WiR4w5inPoEGzY34EDRjg2jOOWrbmt+Pjjo/u6iOa0oKLyfS/K8KYUb0pJTQune+uj666ilC7HBi0tNRcgLdufFr7myzYb/FK8lnONpeb3h5cj128UEkz0Wy9XbuYHXmMw8054zCqw4cnR815t29ahgnKE7S+fRIZhHPfaX51qnbFjx/Lwww9Xfp+Tk0NMTMzZB3Uho+dcyrNsJfXQO8AAq+M4RKsRPSl/1INm5TvZszyNJj2irY501lbf9SYDySXebw+tLm9gdRyHCAj3pe3G2dx94Sr+u7k3P14EP//sfiWlpARmjl3GYx90YPdBf8CT9xMm88BFa2n14l008vO1OmLN+Pjg0bM7TXp25yrgKsyRh1W/RDPz/c8oWLIG39QtNK/YQUu2E8ohfLMyeOnFQl6fCm3awAWRu3lx1j0n38cjj8DLhz+8UlKgfXuzsHh4mDs7dhk9Gl5/naIi2L8qjaZ9Tj4dwnTbndxp9AEgmAqyef2k6+5t3Ik7hkHz5hDXzB9uNUsDgYHYAgPNcy6BgRAYSOd+Heg85shPesCWceZww5H1/P3N0mW34xERceTOcABsa9aYI1dHhih8fcHbG5vNRiDQ/dhQKWtPmrc5cOxDPAzjBwoLzWJ8pLQcWXJz4eVc82tuLszM/aHy18cuhYXmvDvBJebX4mLowTJ8KMGHErwprfLVhsExJxVIZBIR7MWPwsrFnwL8KKQCDzw8jp5J+rP0XDwqvPG3FRJgyyfQyMPfyMe/Ig/DZmPoYBu+vubhsfp/mB1aUCIjIwFzlCQq6uitspmZmZWjKpGRkZSUlJCVlVVlFCUzM5M+ffqccLt2ux17HZ/tKCpnC7FspyCq7sycFRAVzCMtZzJ7ewIvbIvihh6n/xlXlpdZQNeF5nOSDt3zhHm+uY4IjfJl0u+9WXMxrFwJoy7YyCcPLKX5uNusjnZahgHfvb4d21NPckP+/1jDC8xq+yQvvQTDhvXHZutvdUSH8fKCHgMb0GPgcGA4xcWwdi18thw2/JbF/qXbWbY9jIMH4fffYR82zuUKGrGPYHKqLJ5UMO0jL/6z1Px8b15eytv5+Sfd9/T3yxg9zbw0IpQAMvEknwDyCaAA/8pf5xPABqMt3t4QGwstYwP4/sCT+Df0JygqkOAmgYQ3C6RB00A8ggLoHx1N/8qRA0+4oRhbdWcQfPbZ6h+8Y6/vcCCbzexF/v7mmRdHMC/29aa42JuSkgCKi49e0HvsNTZHf30uhnH0kpa/Li9UuR3m1GcjvnHMb8EhHFpQ4uLiiIyMJCkpia5duwJQUlLC/PnzeemllwDo1q0b3t7eJCUlMXz4cADS09NZt24dEydOdGQct2FUGDQuMy9CCetUhy5CAUovvYIdb8DvS+CGG61Oc3ZWjX6f8439pHi1oNsE15019kyFhkJSElx34X4+WDOImOd2s2PbDlp8OM5lJ6Fb9NUBUkf9k2v2voUPpVRgY8SFGTw/r/pnLtyZ3W7ehdS9O3B3KNCdwkJzDpbNm2Hz5ni+2Dyb7dshPd1czLuCDPwpoDzTk+LDj6Pwohlz2X74pEY5pXibpzYOL/kFAZWzxOR7h9IqqpTIKBuRkRARYT6FvXlzc3m4Ofxf1JE/Nl7AC9X/TWl6Y2y2o+WiPqvxX+G8vDy2bdtW+X1ycjKrV68mLCyMZs2akZiYyPjx44mPjyc+Pp7x48fj7+/PiBEjAAgJCeGOO+7gkUceITw8nLCwMB599FE6duzIxRdf7LjfmRvJ2n6QMMwHBDbu4v6nQY7Vp495h9Lixadf15UZZeXEzp4MwParHqWZT9389AsLg1kLwvm2882M2DWBFp/8kz0bVtHk54/MWxZcxIYVhSy96XWu2jSBvmQDsK3VYKI/nkhCr04Wp7OWn595p0/nzse/Zxjmrbbp6TayswPIy6NyKSz0xmZrUeUmFH//o5erHPkaHg4NGtjqxDVl4uJqOsnKL7/8YgDHLbfeeqthGEcnaouMjDTsdrtxwQUXGGvXrq2yjcLCQmP06NFGWFiY4efnZwwdOtRISUmpdoa6NlHbps9WGwYYmbZGVkdxuF3bSoyHedn4nGuNvH0FVsc5Y6ue+8owwDhAqJGdnm91HKcrKjKMN3t+YBRiNwww9oXGG2Wr1lgdy9i92zDuuMMw3uXvRyc8C+9sHJwx1+poIlINNfn8rnFBcQV1raD8Me47wwBjg19Xq6M4XEV5hZHhEWUYYCx7+Ver45yx3yKvNgwwks4ZY3WUWlNebhiv3rTc2EkzwwCj2OZj5P5jovlGLcvOKjeeezTH8PMze0krthhpAS2NtJc+tCSPiJwZp84kK45XuNW8xzg3qA7dY3yYzcNGcow5b0H21/MtTnNmtm2DizM+5nbep+WkujOfy+l4eEDiR91Y8c5yvvMYho9RwsIXf+Prb2pvbP/QwQq+uOELUhp2pcXL91BYCOedBx8ujicqZwtRY2522etjROTs6G+2C9ibH8gyunOwSUerozhFed9+ADRY454F5c03oRA/9l56O3H93P9J0zV19ahGNFv1FU83ncatJVO54kobN9wAaYt3mjNtOcH+5Fy+vfQtMholcO1n15FQvoZhHt/x7SfZLFwIvXujYiJSx+lvuAv4IWwEPVnGimvGWx3FKZqMMAtKu0O/U5TjXg8Wyd1fzLT3zenHH3jA4jAW6tjJxjPbbuO2xxpjs8Fnn8FvFzxBeYtWFI6807w3+SwZBqz/ZDU/tb0XnxZNGDrnPtpWbCTHI4R11zxLYMZ2LhsRooszReoJFRQXcGQW2bo0zf2xYi9px36PRvhTyMYPl1kdp0bW3v4qS3Pb8UD0FwwcaHUaa9ntMHGi2UX6n1dKSPlBPCvK8Pv0fejWjbw252D86wVYtcqcW7wajINZbPnjEM89Bx06wJs3LWbA5rcJJpdd9tasuv11Ag+kkPDFODwbnXyGURGpe+rmvZJuZneqAdgsn7XPWWweNrZHX0DD3V+SNXs+jD7P6kjVUlFcStycN4liN8MuytcZhcO6dIGfF3rz9dfzuHPsYgZsfIOrmUngllXwzCp45ml2dB9O2qufERcHwT5F+L37KmUlBoWHiinYuZfSHbsJ3LmOhvm7eJPJvM6DAOR4X8uNMX/Q8MGRtL1vALGeOugi9ZUKigv4aVM0uQRi8/gJqJvXOJT07kfx599wYOsBq6NU25/Pz6Zr2W4ybY3p9eoNVsdxKTYbXHEFXH55H+bP78Mj7+zHY/aXDCj+ngH8xAfLO/DP881140hjB0/iBfhy/NOLOtg2MuQSuP56uOKKxjRo8EHt/mZExCXZDON0D6d2PTV5XLOry03LJaiJ+XvI3ZNDUHSQxYmcY+OyPM7p6YnNz49Dh9xjssj1YX3pkPUbc3v9g8FL6vbDKh2hoAAWLoRFv5axakkxG3YFkJICTcp38Q+eNx+P5ulNYXAEXjFReHduT8srEuh1SSgBAVanF5HaUJPPb42gWGzf6j0EAdkEE1JHywlA2+6BBDaE/fth2TLzVlFXtmvmCjpk/UYJ3rR59W6r47gFf38YPBgGD/biyD8t5eVQXBxLcfH7+Pqas5yKiFSHTvBa7NA68wrZffY6eoXsYTYb9O9v/vqXecc/8tzV7H3SfCjg4ibDad7bQU8Aq4c8Pc3iEhqqciIiNaOCYrGCreZDAg8F1u2CAjCy5RJW0pVLXxtsdZRTyt2eSZfNMwDwH/ugxWlEROonFRSLle00R1CKwuroLTzHOGdQQ7qymoTsReSm553+Bywy7dtGDGIe74U/QY97e1gdR0SkXlJBsZhHmllQyiLr/ghKswtbkurVHB9K2fjuAqvjnFBFBbwxxcZ8+lP+rwmaFExExCIqKBbbWdGMP+hBRXwbq6M4n83GzlbmbGcFXyVZHObE5nxvsG0bhITAzTdbnUZEpP5SQbHYZL+x9OIPiq4ZaXWUWuF1qVlQmmx0wYJiGETfOpBXeJgHR+zTra8iIhZSQbFYXZ/m/q/a3nMRFdiIL15P+oo0q+NUsfPTxXQ9+BP38DZ33KlzOyIiVlJBsVBxkcG+feY8eXV1mvu/Cm0Vzib/bgBse/dHi9NUdfBZ89biRbEjaXZOQ4vTiIjUbyooFtq3IoUC/Nloa0dYqNtN6HvGUnpdxyeMIGlHK6ujVDq0NoVO22cCEPxUPX5ssYiIi9BMshbKWp9GU4oI9CjE5lF/TimEvDCGIX0gZDk8Uwre3lYngi0PvElPylkaeBE97+xkdRwRkXpPIygWyttqXoOR5R9tcZLa1bMnNGoE2dnms1usVpadT5v5UwHI+Vuibi0WEXEBKigWKkk2C0p+cP0qKJ6ecNmlBh1Zw+Yp1t/Ns/axDwkxDpHs0ZLzX7zM6jgiIoJO8VjK2GMWlOKG9augANwV/R3TGEbKNy0wKrZZeopr/Koh9OIRWg5pR5y/OruIiCvQv8YW8so0C4oRVf8KSsf7+1OMD83KdrDju42W5Vi+HL5Y3pwnvV+m19Q7LMshIiJVqaBYyO+QWVC8m9W/ghIUFcia8IsA2P3W15bleM28s5jrr4fo+vefQUTEZamgWGgj7VlKT+ztWlgdxRL5Ay4HoOGiWZbsf9/8DVz3yZVcwHwSEy2JICIiJ6GCYqEHjNc4l6UEDO5rdRRLtHniKsrxoEPeH+xZlFzr+0958BUuN77i+bDX6Nat1ncvIiKnoIJikcJCyMoyf11fTy1EdY1kdYP+AGx/YUat7jt34246/vkRAMZjY2p13yIicnoqKBZJ31MBGPj7Q3Cw1Wmskzf0RgACFv1Qq/vdNOpVfCjlD/9+XDDm3Frdt4iInJ4KikXy5i2mAH9+rLioXk8MljDuWoZ6fM+5eT+yeXPt7LNozwHaL3oXgOx7xuKhvwUiIi5H/zRbJG9rGn4U4e9TZnUUS4W3bEDF4CGU4c1nn9XOPtfe8yYBRj7rvLvQf/yg2tmpiIjUiAqKRUp3Hp5FNqSeXoByjBtuML9+9kkZRoVzH5pYlp1Py+9eByB1xBN4+9Tj4SsRERemgmKRI7PIljRSQbnySnjKeyJztzRn/VvznbqvL2Z7MbbiBX7xHkS/169x6r5EROTMqaBYxHufWVCoh7PI/lVwMFwct52m7CFv0lSn7ae0FJ75l52pjOL3cXPxD9aTHkREXJUKikX8DqUD4B2rggIQ9sTfAeia/CXZ2/c7ZR8fTDPYts18kvIDDzhlFyIi4iAqKBYJKTBHUALiVVAAOt7WjfW+52CnhLUP/8fh2y9Kz+Lc0d24hek8PbacwECH70JERBzI4QWlrKyMp59+mri4OPz8/GjRogXPP/88FRUVlesYhsG4ceOIjo7Gz8+P/v37s379ekdHcWl/GD1YQi9CEmKsjuISbDbYe91oAFp+9zrlhSUO3f6amybSsXQVY71f5u+jdGGsiIirc3hBeemll3jnnXeYMmUKGzduZOLEifzf//0fb7zxRuU6EydOZNKkSUyZMoVly5YRGRnJwIEDyc3NdXQcl5SXByNKP6Q3S2jYq6XVcVzGua+NYK8tkqjyPawY47h7jvcv3U7nnycBkDrqBXz9NXAoIuLqHP4v9e+//84VV1zBZZddRvPmzbn22msZNGgQy5cvB8zRk8mTJ/PUU09x9dVXk5CQwPTp0ykoKODTTz91dByXlG5efkJQkLmIyT/UztoLzYtDQv4zyWG3HKde9xB2SlgSNJCLXh3mkG2KiIhzObyg9O3bl59++oktW7YA8Oeff7Jo0SIuvfRSAJKTk8nIyGDQoKMTZNntdvr168fixYsdHcclpaWWA0a9fQbPqXR++24+9byJKwr+yzffnv2pmI2T5tA19RtK8cJ36ut4eun0joiIO3D4fZaPP/442dnZtG3bFk9PT8rLy3nhhRe48UbzmSsZGRkAREREVPm5iIgIdu3adcJtFhcXU1xcXPl9Tk6Oo2PXKu9Z/6OQv7H44JVA7T4kz9U1ah3KujEfsXkCPPkkXHYZeHqe2bZKsvIJGGuOyPzU4UEuuaGtA5OKiIgzOXwE5bPPPuPjjz/m008/ZeXKlUyfPp2XX36Z6dOnV1nP9pcH0BiGcdxrR0yYMIGQkJDKJSbGvS8sLdmZhi/FuhbiJB57DBo0gPXr4b+T957xdmbeNYdmJdtIszXhnNn/cFxAERFxOod/Qj722GM88cQT3HDDDXTs2JGbb76Zhx56iAkTJgAQGRkJHB1JOSIzM/O4UZUjxo4dS3Z2duWSmprq6Ni1K928xbhUs8ieUGgoPPdEIe/yd654tBWZy048snYqixfDTbOvZQA/suWZj2jcqh4/MlpExA05vKAUFBTg8ZfHw3p6elbeZhwXF0dkZCRJSUmV75eUlDB//nz69Olzwm3a7XaCg4OrLO7M58gssroI5aTufchO98BNBJFH2tC/Y5RXnP6HDktLg2uugfJyiBo5gP7PXejEpCIi4gwOLyjDhg3jhRde4LvvvmPnzp3MmjWLSZMmcdVVVwHmqZ3ExETGjx/PrFmzWLduHbfddhv+/v6MGDHC0XFckn+2WVC8m6ugnIyXjwe+06dSiC9dMuex5JJx1fq5nOQDrOk4Ar+MHSQkwDvvODeniIg4h8Mvkn3jjTd45plnuPfee8nMzCQ6OppRo0bxj38cvQZgzJgxFBYWcu+995KVlUWvXr2YN28eQfXkntuQAvM+44BWKiin0v7qtiTdMpWBH95C7x//ybJ7Yunx9h0nXT97xwHSOw3mkvwVfOe5Bu8v/iQw8AyvsBUREUvZDMNw7vPtnSAnJ4eQkBCys7Pd7nSPUWGQ7xlEIPns+nErsQNaWR3JpRkG/NjpYQauexWAxUP+ybmzn8DDp2q33vzRHwTcPpymZbvYZ2vEvs/n0/6adlZEFhGRk6jJ57ce51rLcg+WksRgokmjc6coq+O4PJsNLlr1CvO6eTJozct0mvMil/e4lcvvi6FNq3LsX32GbdYseqV+AcBOr5YUzfhK5URExM1pBKWWbdoE7dqZt9FmZVmdxn0YFQY/3jKdb74o4Y1i88nHgeSSy9H//gtib6LDj68T3irUqpgiInIKGkFxYWm6geeM2DxsDPz4NjpMhKjp8N13UJJZzto9PdnX5nwiHrmJC0Z2sTqmiIg4iApKLUtPKQW8iI7WlOtnIjoaxo41F2gALLU2kIiIOIWmMq1lTf73KkX48ujuRKujiIiIuCwVlFpmS0/DTgn2ELvVUURERFyWCkot89lvXoRi00UoIiIiJ6WCUssCDs8i6xOngiIiInIyKii1LKTQnEU2MF4FRURE5GRUUGqRUWHQuMwcQQntoIIiIiJyMiootSh71yH8KAKgkWaRFREROSnNg1KL9qYU8xNXE+6dQ/8QX6vjiIiIuCwVlFqUUhLJtXxJx7awxuowIiIiLkyneGqRprkXERGpHhWUWrQ3pRgwVFBEREROQwWlFvX84jGK8OX65BetjiIiIuLSVFBqkX2/Oc29X6NAq6OIiIi4NBWUWhSYY16EYtcssiIiIqekglKLGhSaBSWwtQqKiIjIqaig1JKKcoOIcs0iKyIiUh0qKLXk4NYD+FAKQKOOkRanERERcW0qKLXk4Dpz9GS/rRHeAT4WpxEREXFtmkm2luw96M0arsG3gT9DrQ4jIiLi4lRQaslWr3bcwRdc2hsVFBERkdPQKZ5aomnuRUREqk8FpZbs21WAprkXERGpHhWUWnLjtyMpwpd+uz60OoqIiIjLU0GpJYG55jT3gU1CrI4iIiLi8lRQaklYkWaRFRERqS4VlFpQXlpB4/J0AELbR1mcRkRExPWpoNSCA5v24UU5Fdg0i6yIiEg1qKDUggNrzdM7+zwi8PLV1DMiIiKno4JSC3I3mwXloK+uPxEREakO/e98LUgvCuVzrsUzKo52VocRERFxAxpBqQWr/PownM+Zd/FEq6OIiIi4BacUlD179nDTTTcRHh6Ov78/Xbp0YcWKFZXvG4bBuHHjiI6Oxs/Pj/79+7N+/XpnRHEJmuZeRESkZhxeULKysjjvvPPw9vZmzpw5bNiwgVdeeYUGDRpUrjNx4kQmTZrElClTWLZsGZGRkQwcOJDc3FxHx3EJWbtysFGhgiIiIlJNNsMwDEdu8IknnuC3335j4cKFJ3zfMAyio6NJTEzk8ccfB6C4uJiIiAheeuklRo0addp95OTkEBISQnZ2NsHBwY6M7xQb/bvRsnAtq/71Pb2eutjqOCIiIpaoyee3w0dQvv76a7p37851111H48aN6dq1K++9917l+8nJyWRkZDBo0KDK1+x2O/369WPx4sUn3GZxcTE5OTlVFncSVpyGD6U0aBludRQRERG34PCCsmPHDt5++23i4+OZO3cud999Nw888AAffmg+JC8jIwOAiIiIKj8XERFR+d5fTZgwgZCQkMolJibG0bGdprSwjEYVewEIS9A5HhERkepweEGpqKjgnHPOYfz48XTt2pVRo0Zx11138fbbb1dZz2azVfneMIzjXjti7NixZGdnVy6pqamOju00+9dl4IFBGZ6Et21kdRwRERG34PCCEhUVRfv27au81q5dO1JSUgCIjDSnev/raElmZuZxoypH2O12goODqyzu4uA68xaeTM8oPLx0V7eIiEh1OPwT87zzzmPz5s1VXtuyZQuxsbEAxMXFERkZSVJSUuX7JSUlzJ8/nz59+jg6juXytpgFJUuzyIqIiFSbw2eSfeihh+jTpw/jx49n+PDh/PHHH0ydOpWpU6cC5qmdxMRExo8fT3x8PPHx8YwfPx5/f39GjBjh6DiWK0o2C0pesAqKiIhIdTm8oPTo0YNZs2YxduxYnn/+eeLi4pg8eTIjR46sXGfMmDEUFhZy7733kpWVRa9evZg3bx5BQUGOjmO5XUYs/+M6vFqca3UUERERt+HweVBqgzvNg3L77TBtGrzwAjz5pNVpRERErGPpPChSlaa5FxERqTkVFCfLSzmoae5FRERqSAXFyb7a1Jpi7MQVbbQ6ioiIiNtw+EWyclRRdjHhxgEAGrZvbHEaERER96ERFCfatyYdgGJ8aNAizOI0IiIi7kMFxYmy1h+eRdYrGpvHiafxFxERkeOpoDhR3tbDs8j66QpZERGRmlBBcaKSw7PI5oc0sTiJiIiIe1FBcSLj8CQoJQ01giIiIlITuovHiTZ5dSST4fi37Wl1FBEREbeiguJEX9hH8jMj+Xio1UlERETci07xOJGmuRcRETkzKihOVLp7r6a5FxEROQM6xeMkeXvz2ZYXSSleFAUdBIKsjiQiIuI2NILiJPvXHplF1k5QVKDFaURERNyLCoqTHNpgXoCyzzsabJpFVkREpCZUUJwk//Asstn+ugBFRESkplRQnKR0l1lQChqooIiIiNSUCoqzHL7HuLSRCoqIiEhNqaA4ifc+TYIiIiJypnSbsZP84XMeuymnccfOVkcRERFxOyooTvIW97GN+1gw2OokIiIi7keneJzAMDTNvYiIyNlQQXGCnINlBBVk4EE5UVFWpxEREXE/KihOsH/JNjKIItMWgb+/1WlERETcjwqKE2Rv2APAIe/GFicRERFxTyooTlCw7fAssgE6vyMiInImVFCcoHSXOYJSENbU4iQiIiLuSQXFCTz27AagLEIFRURE5EyooDiBfb9ZUDyaqaCIiIicCRUUJwjOMQuKb7wKioiIyJnQTLJO8I3tctbSko5dW1sdRURExC2poDhYSQk8kf8PADL7WhxGRETETekUj4MdmeLexwcaNrQ2i4iIiLtyekGZMGECNpuNxMTEytcMw2DcuHFER0fj5+dH//79Wb9+vbOj1Iq0LXlEkk6zJuXYbFanERERcU9OLSjLli1j6tSpdOrUqcrrEydOZNKkSUyZMoVly5YRGRnJwIEDyc3NdWacWmF89x3pRPO/gwOsjiIiIuK2nFZQ8vLyGDlyJO+99x6hoaGVrxuGweTJk3nqqae4+uqrSUhIYPr06RQUFPDpp586K06tKd1h3sFT2ECPMRYRETlTTiso9913H5dddhkXX3xxldeTk5PJyMhg0KBBla/Z7Xb69evH4sWLT7it4uJicnJyqiwua7dZUEo0SZuIiMgZc8pdPDNmzGDlypUsW7bsuPcyMjIAiIiIqPJ6REQEu3btOuH2JkyYwHPPPef4oE5g32cWFFuMCoqIiMiZcvgISmpqKg8++CAff/wxvr6+J13P9pcrSA3DOO61I8aOHUt2dnblkpqa6tDMjhSYfXiStpYqKCIiImfK4SMoK1asIDMzk27dulW+Vl5ezoIFC5gyZQqbN28GzJGUqKijT/vNzMw8blTlCLvdjt1ud3RUpwgrNB8UGNhWBUVERORMOXwEZcCAAaxdu5bVq1dXLt27d2fkyJGsXr2aFi1aEBkZSVJSUuXPlJSUMH/+fPr06ePoOLWqrLiciHJzIpTwziooIiIiZ8rhIyhBQUEkJCRUeS0gIIDw8PDK1xMTExk/fjzx8fHEx8czfvx4/P39GTFihKPj1KrM1GI+JZEY226uTTjxaJCIiIicniVT3Y8ZM4bCwkLuvfdesrKy6NWrF/PmzSMoKMiKOA6TesCfx3iZmKZwvY/VaURERNyXzTAMw+oQNZWTk0NISAjZ2dkEBwdbHafSl1/CtddC795wkjumRURE6q2afH7rWTwOdGBjJlGkEdOk3OooIiIibk0FxYFaf/0yaTTh3u2PWh1FRETEramgOJD3XnMOFJrqDh4REZGzoYLiQIGHzILi00IFRURE5GyooDhQaIFZUDRJm4iIyNlRQXGQinKDiDJzFtnQhCYWpxEREXFvKigOcmDzfuyUANC4S7TFaURERNybCoqD7F9tnt7J9IjAJ1CztImIiJwNS2aSrYv25DfgOx6hYWNvbrM6jIiIiJtTQXGQTcVxPMbLXHkuKigiIiJnSad4HCQlxfwaG2ttDhERkbpABcVBitZtI4o0YmMqrI4iIiLi9lRQHOSuhbeQRhN6p8+0OoqIiIjbU0FxkIYFuwAI7qhzPCIiImdLBcUBinNLiKhIB6BRt2YWpxEREXF/KigOkLF8Nx4YFOJLw/aNrY4jIiLi9lRQHODgavMWngzvZtg8bBanERERcX8qKA6Qt8EsKFlBOr0jIiLiCCooDlC23bxANr+hLpAVERFxBM0k6wArfM9jOY/SvOu5VkcRERGpE1RQHGBu6UX8yEV8MMTqJCIiInWDTvE4gKa5FxERcSwVlLNkVBhE7lxCJOk0izGsjiMiIlIn6BTPWdq/cR/zS3pTgY2yiCLAx+pIIiIibk8jKGcpc7l5fmevRxQ+gSonIiIijqCCcpZy1pm3GB/w1xwoIiIijqKCcpaKt5gjKDmhukJWRETEUVRQzlaKOYJSEqURFBEREUdRQTlLfuk7APBo1cLiJCIiInWHCspZCjtkFpSABBUUERERR9FtxmfBMGBSeSKt2Mg1F3SwOo6IiEidoYJyFjIy4J2yO/HwgAd6Wp1GRESk7tApnrOwwzy7Q7Nm4O1tbRYREZG6RCMoZyFzaTLnkkFk03igodVxRERE6gyHj6BMmDCBHj16EBQUROPGjbnyyivZvHlzlXUMw2DcuHFER0fj5+dH//79Wb9+vaOjOF2Dbz7id/rw0L6xVkcRERGpUxxeUObPn899993HkiVLSEpKoqysjEGDBpGfn1+5zsSJE5k0aRJTpkxh2bJlREZGMnDgQHJzcx0dx6m8UsxzPBXNdQePiIiIIzn8FM8PP/xQ5ftp06bRuHFjVqxYwQUXXIBhGEyePJmnnnqKq6++GoDp06cTERHBp59+yqhRoxwdyWmC9psFxd5WBUVERMSRnH6RbHZ2NgBhYWEAJCcnk5GRwaBBgyrXsdvt9OvXj8WLF59wG8XFxeTk5FRZXEFE3nYAQrqqoIiIiDiSUwuKYRg8/PDD9O3bl4SEBAAyMjIAiIiIqLJuRERE5Xt/NWHCBEJCQiqXmJgYZ8auloIDhURVpAEQdZ4KioiIiCM5taCMHj2aNWvW8N///ve492w2W5XvDcM47rUjxo4dS3Z2duWSmprqlLw1kbZ4JwDZBNOgRZi1YUREROoYp91mfP/99/P111+zYMECmjZtWvl6ZGQkYI6kREVFVb6emZl53KjKEXa7Hbvd7qyoZ+TAsh20AtL9WhDiceJiJSIiImfG4SMohmEwevRoZs6cyc8//0xcXFyV9+Pi4oiMjCQpKanytZKSEubPn0+fPn0cHcdpNtCe0bzBTx0esDqKiIhInePwEZT77ruPTz/9lK+++oqgoKDK60pCQkLw8/PDZrORmJjI+PHjiY+PJz4+nvHjx+Pv78+IESMcHcdpVmfH8SajGXOR1UlERETqHocXlLfffhuA/v37V3l92rRp3HbbbQCMGTOGwsJC7r33XrKysujVqxfz5s0jKCjI0XGc5sg09y10fayIiIjD2QzDMKwOUVM5OTmEhISQnZ1NcHCwJRnubfIVy9OiGP9tZy6+zLWujxEREXFFNfn81rN4zkBZcTmvpg3HTgl7GiQDza2OJCIiUqfoacZnYPeindgpoRBfono1szqOiIhInaOCcgYyF5oPP0z1jcfDS4dQRETE0fTpegbyV20B4GDD1hYnERERqZtUUM6Ax1ZzBKU4to3FSUREROomFZQzEJRuFhSvBBUUERERZ1BBOQOROeYpntBeKigiIiLOoNuMaygnB26v+Ddt2cTzA9tZHUdERKRO0ghKDW3eDHO5hM8iEwluas0kcSIiInWdCkoNbdhgfm3b1tocIiIidZlO8dRQybfzuJ6DtI7rCzS1Oo6IiEidpBGUGuo0/3VmcCMDi7+xOoqIiEidpYJSQ9EH1wHQ4LwEi5OIiIjUXSooNZC1K4eY8l0AxF7aweI0IiIidZcKSg2k/GBeIZvhGU1w8zCL04iIiNRdKig1kLXQPL2zJ1Snd0RERJxJBaUGKtaaBSW/uQqKiIiIM6mg1EDIrjUAeHVRQREREXEmFZRqKi+HG0s+5Epm0fDGgVbHERERqdM0UVs1bdoEWwubkhbQlJb9rE4jIiJSt2kEpZqWLze/nnMOeHpam0VERKSu0whKNXl+OI2n2U1Q3NWA5kARERFxJhWUauqwbBo3sZDf/WNRQREREXEuneKphtKicuJzVwIQfXl3i9OIiIjUfSoo1bD1m00Ekk8eATQb2MbqOCIiInWeCko1pH+2AIDtYT2xeekKWREREWdTQakG++KfAcjtcZHFSUREROoHFZTTKCupoG3GrwA0vO5Ca8OIiIjUEyoop7FuTireRgn5+BM/oofVcUREROoFFZTTmLsplnAO8NhFK/H087E6joiISL2ggnIaSUlQjhdtLtfdOyIiIrVFBeUUDu4r59dfDAAuu8ziMCIiIvWICsoprHluFskVzZgcMYFWraxOIyIiUn+ooJyCz4wPiWE3PeIPWR1FRESkXrG0oLz11lvExcXh6+tLt27dWLhwoZVxqtixcA89D3wPQPPn/mZxGhERkfrFsoLy2WefkZiYyFNPPcWqVas4//zzGTJkCCkpKVZFqmLr3S/jRTnrwi4g+qK2VscRERGpVywrKJMmTeKOO+7gzjvvpF27dkyePJmYmBjefvttqyJVWj5tLf03vAWA1z+etDiNiIhI/WNJQSkpKWHFihUMGjSoyuuDBg1i8eLFx61fXFxMTk5OlcUZtm6Ff161gtjbL8JOCatjhtH2gUGn/0ERERFxKEsKyv79+ykvLyciIqLK6xEREWRkZBy3/oQJEwgJCalcYmJinJKrvBzenR1BI/azI6Aj8fP/DTabU/YlIiIiJ2fpRbK2v3z4G4Zx3GsAY8eOJTs7u3JJTU11Sp42beD2Z5qy+ukviE37nYC4xk7Zj4iIiJyalxU7bdiwIZ6enseNlmRmZh43qgJgt9ux2+1Oz2WzwfPPA1zj9H2JiIjIyVkyguLj40O3bt1ISkqq8npSUhJ9+vSxIpKIiIi4EEtGUAAefvhhbr75Zrp3707v3r2ZOnUqKSkp3H333VZFEhERERdhWUG5/vrrOXDgAM8//zzp6ekkJCTw/fffExsba1UkERERcRE2wzAMq0PUVE5ODiEhIWRnZxMcHGx1HBEREamGmnx+61k8IiIi4nJUUERERMTlqKCIiIiIy1FBEREREZejgiIiIiIuRwVFREREXI4KioiIiLgcFRQRERFxOSooIiIi4nIsm+r+bByZ/DYnJ8fiJCIiIlJdRz63qzOJvVsWlNzcXABiYmIsTiIiIiI1lZubS0hIyCnXcctn8VRUVJCWlkZQUBA2m82h287JySEmJobU1FQ95+cUdJyqR8epenScqkfHqXp0nKrHiuNkGAa5ublER0fj4XHqq0zccgTFw8ODpk2bOnUfwcHB+oNdDTpO1aPjVD06TtWj41Q9Ok7VU9vH6XQjJ0foIlkRERFxOSooIiIi4nJUUP7Cbrfz7LPPYrfbrY7i0nScqkfHqXp0nKpHx6l6dJyqx9WPk1teJCsiIiJ1m0ZQRERExOWooIiIiIjLUUERERERl6OCIiIiIi5HBeUYb731FnFxcfj6+tKtWzcWLlxodSTLLViwgGHDhhEdHY3NZmP27NlV3jcMg3HjxhEdHY2fnx/9+/dn/fr11oS1yIQJE+jRowdBQUE0btyYK6+8ks2bN1dZR8cJ3n77bTp16lQ5KVTv3r2ZM2dO5fs6Ric2YcIEbDYbiYmJla/pWMG4ceOw2WxVlsjIyMr3dYyO2rNnDzfddBPh4eH4+/vTpUsXVqxYUfm+qx4rFZTDPvvsMxITE3nqqadYtWoV559/PkOGDCElJcXqaJbKz8+nc+fOTJky5YTvT5w4kUmTJjFlyhSWLVtGZGQkAwcOrHxeUn0wf/587rvvPpYsWUJSUhJlZWUMGjSI/Pz8ynV0nKBp06a8+OKLLF++nOXLl3PRRRdxxRVXVP5DqGN0vGXLljF16lQ6depU5XUdK1OHDh1IT0+vXNauXVv5no6RKSsri/POOw9vb2/mzJnDhg0beOWVV2jQoEHlOi57rAwxDMMwevbsadx9991VXmvbtq3xxBNPWJTI9QDGrFmzKr+vqKgwIiMjjRdffLHytaKiIiMkJMR45513LEjoGjIzMw3AmD9/vmEYOk6nEhoaavz73//WMTqB3NxcIz4+3khKSjL69etnPPjgg4Zh6M/TEc8++6zRuXPnE76nY3TU448/bvTt2/ek77vysdIIClBSUsKKFSsYNGhQldcHDRrE4sWLLUrl+pKTk8nIyKhy3Ox2O/369avXxy07OxuAsLAwQMfpRMrLy5kxYwb5+fn07t1bx+gE7rvvPi677DIuvvjiKq/rWB21detWoqOjiYuL44YbbmDHjh2AjtGxvv76a7p37851111H48aN6dq1K++9917l+658rFRQgP3791NeXk5ERESV1yMiIsjIyLAoles7cmx03I4yDIOHH36Yvn37kpCQAOg4HWvt2rUEBgZit9u5++67mTVrFu3bt9cx+osZM2awcuVKJkyYcNx7OlamXr168eGHHzJ37lzee+89MjIy6NOnDwcOHNAxOsaOHTt4++23iY+PZ+7cudx999088MADfPjhh4Br/3lyy6cZO4vNZqvyvWEYx70mx9NxO2r06NGsWbOGRYsWHfeejhO0adOG1atXc+jQIb788ktuvfVW5s+fX/m+jhGkpqby4IMPMm/ePHx9fU+6Xn0/VkOGDKn8dceOHenduzctW7Zk+vTpnHvuuYCOEUBFRQXdu3dn/PjxAHTt2pX169fz9ttvc8stt1Su54rHSiMoQMOGDfH09DyuLWZmZh7XKuWoI1fM67iZ7r//fr7++mt++eUXmjZtWvm6jtNRPj4+tGrViu7duzNhwgQ6d+7Ma6+9pmN0jBUrVpCZmUm3bt3w8vLCy8uL+fPn8/rrr+Pl5VV5PHSsqgoICKBjx45s3bpVf56OERUVRfv27au81q5du8obQFz5WKmgYP6j2a1bN5KSkqq8npSURJ8+fSxK5fri4uKIjIysctxKSkqYP39+vTpuhmEwevRoZs6cyc8//0xcXFyV93WcTs4wDIqLi3WMjjFgwADWrl3L6tWrK5fu3bszcuRIVq9eTYsWLXSsTqC4uJiNGzcSFRWlP0/HOO+8846b9mDLli3ExsYCLv7vk1VX57qaGTNmGN7e3sb7779vbNiwwUhMTDQCAgKMnTt3Wh3NUrm5ucaqVauMVatWGYAxadIkY9WqVcauXbsMwzCMF1980QgJCTFmzpxprF271rjxxhuNqKgoIycnx+Lkteeee+4xQkJCjF9//dVIT0+vXAoKCirX0XEyjLFjxxoLFiwwkpOTjTVr1hhPPvmk4eHhYcybN88wDB2jUzn2Lh7D0LEyDMN45JFHjF9//dXYsWOHsWTJEmPo0KFGUFBQ5b/ZOkamP/74w/Dy8jJeeOEFY+vWrcYnn3xi+Pv7Gx9//HHlOq56rFRQjvHmm28asbGxho+Pj3HOOedU3iZan/3yyy8GcNxy6623GoZh3qL27LPPGpGRkYbdbjcuuOACY+3atdaGrmUnOj6AMW3atMp1dJwM4/bbb6/8+9WoUSNjwIABleXEMHSMTuWvBUXHyjCuv/56IyoqyvD29jaio6ONq6++2li/fn3l+zpGR33zzTdGQkKCYbfbjbZt2xpTp06t8r6rHiubYRiGNWM3IiIiIiema1BERETE5aigiIiIiMtRQRERERGXo4IiIiIiLkcFRURERFyOCoqIiIi4HBUUERERcTkqKCIiIuJyVFBERETE5aigiIiIiMtRQRERERGXo4IiIiIiLuf/AWBX24fGN7JJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_pred = PINN.test()\n",
    "plt.plot(t,x_true,'b')\n",
    "plt.plot(t,x_pred,'r--')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
