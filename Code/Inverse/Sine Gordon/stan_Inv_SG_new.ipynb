{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013bdb71-0590-4e91-b8fe-31fcfbef22d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31422d3-999f-419c-9844-4eb0c19aa035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_SG(xy): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    term1 = np.exp(xy[:,0]+xy[:,1]-t_val).reshape(-1,1)\n",
    "    u = 4.0*np.arctan(term1)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "180d56a4-349d-4dfd-8536-3fd2cbcdab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BC_func(xy):\n",
    "    x = xy[:,0].reshape(-1,1)\n",
    "    y = xy[:,1].reshape(-1,1)\n",
    "    t = torch.tensor(t_val).float().to(device)\n",
    "    num = 4.0*torch.exp(x+y+t)\n",
    "    den = torch.exp(2.0*t) + torch.exp(2.0*x + 2.0*y)\n",
    "    \n",
    "    return torch.div(num,den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8586107c-57a3-49ac-94ad-af3c91197276",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 0\n",
    "level = \"_low\"\n",
    "label = \"inv_SG_stan\" + level\n",
    "\n",
    "l_limit = -2.0\n",
    "u_limit = 2.0\n",
    "\n",
    "x = np.linspace(l_limit,u_limit,100).reshape(-1,1)\n",
    "y = np.linspace(l_limit,u_limit,100).reshape(-1,1)\n",
    "\n",
    "t_val = 2\n",
    "\n",
    "# t = 3.0*np.ones((1,1))\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xy = np.hstack((X,Y))\n",
    "\n",
    "xy_test_tensor = torch.tensor(xy).float().to(device)\n",
    "\n",
    "u_true = true_SG(xy)\n",
    "u_true_norm = np.linalg.norm(u_true,2)\n",
    "\n",
    "lb_xy = xy[0]\n",
    "ub_xy = xy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e37ff74-08a9-4c09-a03d-05e04b14e804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5d58196650>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(u_true.reshape(100,100),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b516da21-7949-4319-a9b8-dad9a1e90180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_T,N_f,N_N,seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #-------------------------------------------------------------------------\n",
    "    x_NBC_1 = np.vstack((l_limit*np.ones((N_N,1)),u_limit*np.ones((N_N,1))))\n",
    "    y_NBC_1 = np.random.uniform(l_limit,u_limit,size = (2*N_N,1))\n",
    "\n",
    "    x_NBC_2 = np.random.uniform(l_limit,u_limit,size = (2*N_N,1))\n",
    "    y_NBC_2 = np.vstack((l_limit*np.ones((N_N,1)),u_limit*np.ones((N_N,1))))\n",
    "\n",
    "    xy_NBC1 = np.hstack((x_NBC_1,y_NBC_1))\n",
    "    xy_NBC2 = np.hstack((x_NBC_2,y_NBC_2))\n",
    "    \n",
    "    #----------------------------------------------------------------------------\n",
    "    xy_d = np.random.uniform(l_limit,u_limit,size = (N_T,2))\n",
    "    \n",
    "    xy_D = np.vstack((xy_d,xy_NBC1,xy_NBC2))\n",
    "    # xy_D = np.vstack((xy_NBC1,xy_NBC2))\n",
    "    u_D = true_SG(xy_D)\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    \n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xy_coll = lb_xy + (ub_xy - lb_xy)*samples\n",
    "    \n",
    "    xy_coll = np.vstack((xy_coll, xy_D,xy_NBC1,xy_NBC2)) # append training points to collocation points \n",
    "    \n",
    "    return xy_D,u_D,xy_NBC1,xy_NBC2,xy_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb478c40-2ba6-4fe5-96d8-f86f1b79cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "        \n",
    "        beta_mean = 1.0*torch.ones((50,len(layers)-2))\n",
    "        beta_std = 0.1*torch.ones((50,len(layers)-2))\n",
    "        \n",
    "        self.beta = Parameter(torch.normal(beta_mean,beta_std))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "        # self.lambdas = torch.tensor([1.0,1.0,1.0,4.0])\n",
    "        \n",
    "        self.lambdas = Parameter(torch.tensor([-1.0,-1.0]))\n",
    "        self.lambdas.requiresGrad = True\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xy):\n",
    "        if torch.is_tensor(xy) != True:         \n",
    "            xy = torch.from_numpy(xy)                \n",
    "        \n",
    "        ubxy = torch.from_numpy(ub_xy).float().to(device)\n",
    "        lbxy = torch.from_numpy(lb_xy).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xyt = 2.0*(xy - lbxy)/(ubxy - lbxy) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xy.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            z1 =self.activation(z)\n",
    "            a = z1 + self.beta[:,i]*z*z1\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xy,u):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xy), u)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC1(self,xy_NBC1,N_hat):\n",
    "        g = xy_NBC1.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_NBC1.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0] \n",
    "            \n",
    "        du_dx = u_x_y[:,[0]]\n",
    "        \n",
    "        f = du_dx - BC_func(g)\n",
    "        \n",
    "        loss_NBC1 = self.loss_function(f,N_hat)\n",
    "        \n",
    "        return loss_NBC1\n",
    "    \n",
    "    def loss_NBC2(self,xy_NBC2,N_hat):\n",
    "        g = xy_NBC2.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_NBC2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0] \n",
    "            \n",
    "        du_dy = u_x_y[:,[1]]\n",
    "\n",
    "        f = du_dy - BC_func(g)\n",
    "        \n",
    "        loss_NBC2 = self.loss_function(f,N_hat)\n",
    "        \n",
    "        return loss_NBC2\n",
    "    \n",
    "    def s_func(self,xy):\n",
    "        x = xy[:,0].reshape(-1,1)\n",
    "        y = xy[:,1].reshape(-1,1)\n",
    "        \n",
    "        num = torch.exp(3*t_val+x+y) - torch.exp(t_val+3.0*x + 3.0*y)\n",
    "        den = torch.square(torch.exp(torch.tensor(2.0*t_val).float().to(device)) + torch.exp(2.0*x + 2.0*y))\n",
    "        \n",
    "        return torch.div(num,den)\n",
    "    \n",
    "    def loss_PDE(self, xy_coll, f_hat):\n",
    "        \n",
    "        g = xy_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy = autograd.grad(u_x_y,g,torch.ones(xy_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy[:,[1]]\n",
    "        \n",
    "        #f = self.lambdas[2]*(self.s_func(g.detach())) - self.lambdas[0]*d2u_dx2 - self.lambdas[0]*d2u_dy2 + self.lambdas[2]*torch.sin(u.detach())\n",
    "        f1 = d2u_dx2 - self.lambdas[0]*d2u_dy2\n",
    "        f2 = torch.sin(u) - self.lambdas[1]*self.s_func(g)\n",
    "        \n",
    "        loss_f = self.loss_function(f1,f_hat) + self.loss_function(f2,f_hat) \n",
    "        # print(torch.mean(torch.abs(d2u_dx2)).cpu().detach().numpy())\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xy_D,u_D,xy_NBC1,xy_NBC2,xy_coll,f_hat,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xy_D,u_D)\n",
    "        loss_NBC1 = self.loss_NBC1(xy_NBC1,N_hat)\n",
    "        loss_NBC2 = self.loss_NBC2(xy_NBC2,N_hat)\n",
    "        loss_f = self.loss_PDE(xy_coll,f_hat)\n",
    "        \n",
    "        # loss_val = loss_BC + loss_NBC1 + loss_NBC2 + loss_f\n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        u_pred = self.forward(xy_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "        \n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "        \n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d42f591-390e-4a45-bf60-6a5caa47faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fa190bd-2ac3-4d40-86c5-4d2f37ce5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xy_D,u_D,xy_NBC1,xy_NBC2,xy_coll,f_hat,N_hat,seed):\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xy_D,u_D,xy_NBC1,xy_NBC2,xy_coll,f_hat,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "      # optimizer.zero_grad()\n",
    "      # loss = PINN.loss(xy_D,u_D,xy_NBC1,xy_NBC2,xy_coll,f_hat,N_hat)\n",
    "      # loss.backward()\n",
    "      # optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b53252-e28c-4862-8f2b-0f43fb2af4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xy_D,u_D,xy_NBC1,xy_NBC2,xy_coll = trainingdata(N_T,N_f,N_N,rep*22)\n",
    "        \n",
    "    xy_coll = torch.from_numpy(xy_coll).float().to(device)\n",
    "    xy_NBC1 = torch.from_numpy(xy_NBC1).float().to(device)\n",
    "    xy_NBC2 = torch.from_numpy(xy_NBC2).float().to(device)\n",
    "    xy_D = torch.from_numpy(xy_D).float().to(device)\n",
    "    u_D = torch.from_numpy(u_D).float().to(device)\n",
    "        \n",
    "    f_hat = torch.zeros(xy_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xy_NBC1.shape[0],1).to(device)\n",
    "\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(xy_D,u_D,xy_NBC1,xy_NBC2,xy_coll,f_hat,N_hat,i)\n",
    "        loss_np = PINN.loss(xy_D,u_D,xy_NBC1,xy_NBC2,xy_coll,f_hat,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"RE Loss\",test_re_loss[-1],\"Lamdas:\",np.transpose(PINN.lambdas.cpu().detach().numpy()))\n",
    "        #print(i,\"Train Loss\",train_loss[-1],\"RE Loss\",test_re_loss[-1])\n",
    "      \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648172a4-1635-404f-aae9-24f70904153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_SG_stan_low\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 0.62660444 RE Loss 0.6222404057060053 Lamdas: [-0.8795485  -0.85063285]\n",
      "1 Train Loss 0.29266524 RE Loss 0.5172694484682844 Lamdas: [-0.47592232  3.0989037 ]\n",
      "2 Train Loss 0.1792836 RE Loss 0.2700970655543002 Lamdas: [-0.06575897  4.591478  ]\n",
      "3 Train Loss 0.021445395 RE Loss 0.05115247970193005 Lamdas: [0.9584356 3.6835396]\n",
      "4 Train Loss 0.0027115631 RE Loss 0.020412391908782777 Lamdas: [1.0031388 3.8447409]\n",
      "5 Train Loss 0.00050724257 RE Loss 0.010213446920537073 Lamdas: [0.9982313 3.9469602]\n",
      "6 Train Loss 0.00013034377 RE Loss 0.00433683922399134 Lamdas: [1.001589  3.9872158]\n",
      "7 Train Loss 5.2649088e-05 RE Loss 0.0029847325043473602 Lamdas: [0.9999543 3.9857635]\n",
      "8 Train Loss 2.7771624e-05 RE Loss 0.0020926123097253463 Lamdas: [1.0000497 3.9902024]\n",
      "9 Train Loss 1.4319611e-05 RE Loss 0.0013312319525481421 Lamdas: [0.99979067 3.9929585 ]\n",
      "10 Train Loss 8.485469e-06 RE Loss 0.0006867424620486096 Lamdas: [1.0002733 3.9963713]\n",
      "11 Train Loss 5.8061614e-06 RE Loss 0.0006924078132171177 Lamdas: [1.0000575 3.9962697]\n",
      "12 Train Loss 3.3347503e-06 RE Loss 0.0004466907144707945 Lamdas: [0.99990875 3.9987602 ]\n",
      "13 Train Loss 2.633858e-06 RE Loss 0.0004409727614254296 Lamdas: [0.999983 3.998668]\n",
      "14 Train Loss 2.2819097e-06 RE Loss 0.00040800583188416834 Lamdas: [1.0000713 3.998926 ]\n",
      "15 Train Loss 1.8168832e-06 RE Loss 0.00039460066034051105 Lamdas: [1.0001456 3.9987223]\n",
      "16 Train Loss 1.6075827e-06 RE Loss 0.000354707414084623 Lamdas: [0.99995923 3.9997723 ]\n",
      "17 Train Loss 1.3993813e-06 RE Loss 0.00032694416367130195 Lamdas: [1.0000347 4.000113 ]\n",
      "18 Train Loss 1.3894695e-06 RE Loss 0.00032330017802704357 Lamdas: [1.0000345 4.00005  ]\n",
      "19 Train Loss 1.3681814e-06 RE Loss 0.00031625967739427196 Lamdas: [1.0000311 3.9998825]\n",
      "20 Train Loss 1.3593879e-06 RE Loss 0.00031404303864422466 Lamdas: [1.0000275 3.999796 ]\n",
      "21 Train Loss 1.3404142e-06 RE Loss 0.000310441595264898 Lamdas: [1.0000129 3.9996064]\n",
      "22 Train Loss 1.3202158e-06 RE Loss 0.000309703536129667 Lamdas: [1.0000229 3.9993913]\n",
      "23 Train Loss 1.3008664e-06 RE Loss 0.0003125478726373354 Lamdas: [1.0000241 3.999221 ]\n",
      "24 Train Loss 1.2916674e-06 RE Loss 0.0003128107692352872 Lamdas: [1.000018  3.9991355]\n",
      "25 Train Loss 1.2825137e-06 RE Loss 0.0003144976044236156 Lamdas: [1.0000161 3.999069 ]\n",
      "26 Train Loss 1.2750033e-06 RE Loss 0.00031530921142882665 Lamdas: [1.0000101 3.9990005]\n",
      "27 Train Loss 1.2683887e-06 RE Loss 0.000316211281128265 Lamdas: [1.0000058 3.9989626]\n",
      "28 Train Loss 1.2625361e-06 RE Loss 0.00031709020763417685 Lamdas: [1.0000007 3.9989228]\n",
      "29 Train Loss 1.2567789e-06 RE Loss 0.0003172894993017483 Lamdas: [0.999995  3.9989033]\n",
      "30 Train Loss 1.2511629e-06 RE Loss 0.0003178153446146538 Lamdas: [0.99998796 3.998884  ]\n",
      "31 Train Loss 1.2451524e-06 RE Loss 0.0003174636970536703 Lamdas: [0.99998313 3.998874  ]\n",
      "32 Train Loss 1.2380189e-06 RE Loss 0.00031732432585895653 Lamdas: [0.9999757 3.9988723]\n",
      "33 Train Loss 1.2301261e-06 RE Loss 0.000316278625316344 Lamdas: [0.99996954 3.9988759 ]\n",
      "34 Train Loss 1.220935e-06 RE Loss 0.0003152343398302097 Lamdas: [0.99996173 3.9989002 ]\n",
      "35 Train Loss 1.2113919e-06 RE Loss 0.00031364096528081693 Lamdas: [0.99995583 3.9989278 ]\n",
      "36 Train Loss 1.1915764e-06 RE Loss 0.0003097096882461057 Lamdas: [0.9999504 3.9990306]\n",
      "37 Train Loss 1.1713782e-06 RE Loss 0.00030523020244153996 Lamdas: [0.9999613 3.9991457]\n",
      "38 Train Loss 1.1623896e-06 RE Loss 0.00030224387476232453 Lamdas: [0.99995935 3.999191  ]\n",
      "39 Train Loss 1.1548319e-06 RE Loss 0.0003009673841854031 Lamdas: [0.99996865 3.99926   ]\n",
      "40 Train Loss 1.1489412e-06 RE Loss 0.00029969292775924394 Lamdas: [0.99997413 3.9993095 ]\n",
      "41 Train Loss 1.1434181e-06 RE Loss 0.00029946760982264435 Lamdas: [0.9999859 3.9993598]\n",
      "42 Train Loss 1.1387046e-06 RE Loss 0.00029894849415398146 Lamdas: [0.9999959 3.9993987]\n",
      "43 Train Loss 1.134788e-06 RE Loss 0.00029837128355264536 Lamdas: [0.99999833 3.9994426 ]\n",
      "44 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "45 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "46 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "47 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "48 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "49 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "50 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "51 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "52 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "53 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "54 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "55 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "56 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "57 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "58 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "59 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "60 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "61 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "62 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "63 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "64 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "65 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "66 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "67 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "68 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "69 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "70 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "71 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "72 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "73 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "74 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "75 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "76 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "77 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "78 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "79 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "80 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "81 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "82 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "83 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "84 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "85 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "86 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "87 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "88 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "89 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "90 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "91 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "92 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "93 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "94 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "95 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "96 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "97 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "98 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "99 Train Loss 1.1322848e-06 RE Loss 0.00029819174134341705 Lamdas: [1.0000045 3.9994621]\n",
      "Training time: 17.43\n",
      "Training time: 17.43\n"
     ]
    }
   ],
   "source": [
    "max_reps = 1\n",
    "max_iter = 100 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "N_T = 10 #Total number of data points for 'y'\n",
    "N_N = 1000\n",
    "N_f = 50000 #Total number of collocation points \n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    " \n",
    "    \n",
    "    torch.manual_seed(reps*36)\n",
    "    \n",
    "    layers = np.array([2,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "   \n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-08, \n",
    "                              tolerance_change = 1e-08, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "    # optimizer = torch.optim.Adam(PINN.parameters(),lr = 0.008)\n",
    "    \n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "    \n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "    \n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10c2f464-5f53-4a4e-8f27-68428df82337",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = PINN.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "395f67fd-dfd0-4131-9c5e-8458e68f5d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5d507e42d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(u_pred.reshape(100,100),cmap = 'jet',vmax = 6, vmin = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "650a9b0e-5403-4859-96cb-10a9e72e7e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012150146"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(u_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c3a46-9810-4c38-896c-cf69cbb56460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
