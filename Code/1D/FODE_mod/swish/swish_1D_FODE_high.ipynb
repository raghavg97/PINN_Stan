{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "12aa433d-9505-4460-d56f-b6a376e9ccb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "4778640e-2987-401e-f7cb-585a0f18a01a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "63653bcd-0776-4d8a-c31d-d2238f724ffe"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/swish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "d48278bc-c428-4c93-93f7-f711d3b81f62"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "level = \"high\"\n",
    "label = \"1D_FODE_swish_\"+level\n",
    "\n",
    "extent = 100.0\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(extent,-1.0*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "              \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "       \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "      \n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "  print(rep) \n",
    "  torch.manual_seed(rep*11)\n",
    "  start_time = time.time() \n",
    "  thresh_flag = 0\n",
    "  x_coll = torch.from_numpy(colloc_pts(N_f,123)).float().to(device)\n",
    "  f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "  loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "  data_update(loss_np)\n",
    "\n",
    "  for i in range(max_iter):\n",
    "    \n",
    "    train_step(i)\n",
    "\n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    if(thresh_flag == 0):\n",
    "        if(loss_np < loss_thresh):\n",
    "            time_threshold[rep] = time.time() - start_time\n",
    "            epoch_threshold[rep] = i+1            \n",
    "            thresh_flag = 1       \n",
    "    data_update(loss_np)\n",
    "    print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "\n",
    "  elapsed_time[rep] = time.time() - start_time  \n",
    "  print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "2bf8b190-81d6-4793-b63a-bc5565d05793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 457586.0 Test MSE 5043811.776421945 Test RE 1.003844073431476\n",
      "1 Train Loss 455600.72 Test MSE 5023643.857380131 Test RE 1.0018351042671596\n",
      "2 Train Loss 442041.22 Test MSE 4823098.440417994 Test RE 0.9816346654808731\n",
      "3 Train Loss 337228.62 Test MSE 4261208.888083082 Test RE 0.9226845227659841\n",
      "4 Train Loss 280372.16 Test MSE 3699577.9362934623 Test RE 0.8597316479117979\n",
      "5 Train Loss 241273.39 Test MSE 2850855.842508385 Test RE 0.7547001776747043\n",
      "6 Train Loss 211317.03 Test MSE 2882544.6485630143 Test RE 0.7588830366349468\n",
      "7 Train Loss 195295.89 Test MSE 2715840.814582823 Test RE 0.7366123213317677\n",
      "8 Train Loss 189847.98 Test MSE 2584094.4848305434 Test RE 0.7185235686820765\n",
      "9 Train Loss 181235.52 Test MSE 2248086.9416386187 Test RE 0.6701829504614442\n",
      "10 Train Loss 175415.5 Test MSE 2005129.349500209 Test RE 0.6329334095189786\n",
      "11 Train Loss 169542.2 Test MSE 1654012.3917753098 Test RE 0.5748522070806464\n",
      "12 Train Loss 159098.39 Test MSE 1208105.4606516308 Test RE 0.49129149661120314\n",
      "13 Train Loss 141411.95 Test MSE 818648.6049727522 Test RE 0.40442275812162554\n",
      "14 Train Loss 137613.12 Test MSE 665213.4641072141 Test RE 0.36455859271420504\n",
      "15 Train Loss 129704.48 Test MSE 470656.1485846419 Test RE 0.3066469800370185\n",
      "16 Train Loss 126554.11 Test MSE 474088.30203799676 Test RE 0.3077630259583642\n",
      "17 Train Loss 123445.26 Test MSE 333712.3346164921 Test RE 0.2582099379308898\n",
      "18 Train Loss 121067.67 Test MSE 264616.3657704229 Test RE 0.22992975361113765\n",
      "19 Train Loss 119219.664 Test MSE 199991.3145291161 Test RE 0.19989060900536026\n",
      "20 Train Loss 117295.75 Test MSE 145537.21899448268 Test RE 0.17051942504041134\n",
      "21 Train Loss 115862.98 Test MSE 116463.76758177383 Test RE 0.1525394728920002\n",
      "22 Train Loss 114209.516 Test MSE 73138.65022136841 Test RE 0.12088162630184406\n",
      "23 Train Loss 113539.04 Test MSE 68621.02828888991 Test RE 0.11708882140679719\n",
      "24 Train Loss 112662.79 Test MSE 61889.4583143562 Test RE 0.11119753613089513\n",
      "25 Train Loss 111687.86 Test MSE 52235.79473724356 Test RE 0.10215765775372478\n",
      "26 Train Loss 110972.234 Test MSE 39872.25576660355 Test RE 0.0892528775622065\n",
      "27 Train Loss 110677.164 Test MSE 32773.31004442811 Test RE 0.08091834225001512\n",
      "28 Train Loss 110054.65 Test MSE 18057.837066471093 Test RE 0.060064752062366784\n",
      "29 Train Loss 109546.1 Test MSE 17937.636055504416 Test RE 0.05986450940113642\n",
      "30 Train Loss 109096.875 Test MSE 17635.764913679464 Test RE 0.05935864439356505\n",
      "31 Train Loss 108904.38 Test MSE 22669.58137700212 Test RE 0.06729899423363599\n",
      "32 Train Loss 108362.67 Test MSE 20131.85861713616 Test RE 0.06342036826535948\n",
      "33 Train Loss 107855.29 Test MSE 17027.981140300417 Test RE 0.05832683406460341\n",
      "34 Train Loss 107564.664 Test MSE 15335.411528253895 Test RE 0.05535215593581284\n",
      "35 Train Loss 107429.76 Test MSE 15652.095001873666 Test RE 0.055920759503339565\n",
      "36 Train Loss 107195.266 Test MSE 16554.63274312467 Test RE 0.05751042790147947\n",
      "37 Train Loss 106954.11 Test MSE 17968.218020885153 Test RE 0.05991551931929876\n",
      "38 Train Loss 106648.88 Test MSE 20413.55387042919 Test RE 0.06386253199384817\n",
      "39 Train Loss 106293.914 Test MSE 16482.981068105422 Test RE 0.05738583477254125\n",
      "40 Train Loss 106196.12 Test MSE 20495.62698621504 Test RE 0.06399078352941551\n",
      "41 Train Loss 105905.945 Test MSE 20600.281779497433 Test RE 0.06415395040887474\n",
      "42 Train Loss 105794.56 Test MSE 21594.224812482917 Test RE 0.06568340114590449\n",
      "43 Train Loss 105665.99 Test MSE 18328.62324111434 Test RE 0.06051342659064471\n",
      "44 Train Loss 105531.61 Test MSE 16484.25596044011 Test RE 0.05738805401146263\n",
      "45 Train Loss 105425.48 Test MSE 15597.552332178691 Test RE 0.05582324127055399\n",
      "46 Train Loss 105207.0 Test MSE 15345.23806159352 Test RE 0.05536988720765404\n",
      "47 Train Loss 105022.24 Test MSE 10051.746950861563 Test RE 0.04481336924245253\n",
      "48 Train Loss 104717.82 Test MSE 9010.920879081663 Test RE 0.04242984173500807\n",
      "49 Train Loss 104103.18 Test MSE 5539.897008574687 Test RE 0.03326884082096239\n",
      "50 Train Loss 103880.52 Test MSE 5994.820638299127 Test RE 0.03460787396986349\n",
      "51 Train Loss 103746.414 Test MSE 6540.525007335826 Test RE 0.03614873706792635\n",
      "52 Train Loss 103593.53 Test MSE 4624.024272952922 Test RE 0.030394631066606545\n",
      "53 Train Loss 103430.164 Test MSE 5377.5361039158615 Test RE 0.03277770113760579\n",
      "54 Train Loss 103168.79 Test MSE 8770.464414518274 Test RE 0.04185989349744676\n",
      "55 Train Loss 102950.37 Test MSE 7854.311295991731 Test RE 0.039613286837050975\n",
      "56 Train Loss 102619.64 Test MSE 7381.908534294076 Test RE 0.038403530669911236\n",
      "57 Train Loss 102466.49 Test MSE 4451.526861806361 Test RE 0.029822312918416402\n",
      "58 Train Loss 102339.72 Test MSE 5727.307470099548 Test RE 0.03382689014812997\n",
      "59 Train Loss 102096.734 Test MSE 4260.6480389297485 Test RE 0.029175926318203482\n",
      "60 Train Loss 101996.445 Test MSE 4619.341243763673 Test RE 0.030379235926664205\n",
      "61 Train Loss 101794.79 Test MSE 2843.5102235951726 Test RE 0.023834948653522394\n",
      "62 Train Loss 101692.914 Test MSE 3373.5311153213324 Test RE 0.025961464269080147\n",
      "63 Train Loss 101501.99 Test MSE 3967.9814226935014 Test RE 0.028156044229861635\n",
      "64 Train Loss 101398.77 Test MSE 2925.8567674434057 Test RE 0.02417760926020896\n",
      "65 Train Loss 101095.04 Test MSE 2804.071812250754 Test RE 0.023669080652195806\n",
      "66 Train Loss 100816.85 Test MSE 3262.1743789787242 Test RE 0.02552938835424549\n",
      "67 Train Loss 100551.71 Test MSE 4537.002277692478 Test RE 0.030107266186559675\n",
      "68 Train Loss 100331.164 Test MSE 7156.3280377644405 Test RE 0.03781219976206872\n",
      "69 Train Loss 100219.22 Test MSE 6745.273217191637 Test RE 0.03671018696593661\n",
      "70 Train Loss 100013.52 Test MSE 6648.84161602422 Test RE 0.036446834730798496\n",
      "71 Train Loss 99616.4 Test MSE 6950.369237144431 Test RE 0.03726411077035537\n",
      "72 Train Loss 99160.914 Test MSE 3549.641230218068 Test RE 0.026630483637791122\n",
      "73 Train Loss 98955.14 Test MSE 3535.665821063945 Test RE 0.02657800805982168\n",
      "74 Train Loss 98848.79 Test MSE 3293.2536762254385 Test RE 0.025650711512843472\n",
      "75 Train Loss 98643.57 Test MSE 3631.5368993460415 Test RE 0.026935934933954804\n",
      "76 Train Loss 98444.22 Test MSE 2811.1260180078825 Test RE 0.02369883411404928\n",
      "77 Train Loss 98231.58 Test MSE 3298.199225827544 Test RE 0.02566996439895425\n",
      "78 Train Loss 98024.99 Test MSE 4368.582584392747 Test RE 0.02954317035152128\n",
      "79 Train Loss 97785.24 Test MSE 2922.8062695746335 Test RE 0.024165002187251667\n",
      "80 Train Loss 97708.68 Test MSE 2836.858003808509 Test RE 0.02380705211968919\n",
      "81 Train Loss 97618.95 Test MSE 2768.6642705695654 Test RE 0.023519168943430372\n",
      "82 Train Loss 97572.42 Test MSE 2817.0722466386387 Test RE 0.02372388532915675\n",
      "83 Train Loss 97488.34 Test MSE 2877.8345692086614 Test RE 0.02397837435594482\n",
      "84 Train Loss 97442.695 Test MSE 2685.822560442551 Test RE 0.023164636114521027\n",
      "85 Train Loss 97332.125 Test MSE 2530.79785837623 Test RE 0.02248617326700435\n",
      "86 Train Loss 97296.38 Test MSE 2617.2039170683993 Test RE 0.022866811117900662\n",
      "87 Train Loss 97241.06 Test MSE 2638.2433807509415 Test RE 0.022958539243320794\n",
      "88 Train Loss 97193.11 Test MSE 2803.231193728044 Test RE 0.023665532569202927\n",
      "89 Train Loss 97124.11 Test MSE 3094.0945570355807 Test RE 0.024863004842844236\n",
      "90 Train Loss 97073.18 Test MSE 3084.5213311521784 Test RE 0.024824511585418613\n",
      "91 Train Loss 97034.98 Test MSE 3067.787362272187 Test RE 0.024757081746009605\n",
      "92 Train Loss 96836.94 Test MSE 3286.3261753003894 Test RE 0.02562371862206267\n",
      "93 Train Loss 96758.76 Test MSE 3561.4716122290342 Test RE 0.026674824278009837\n",
      "94 Train Loss 96644.445 Test MSE 3466.4265832661877 Test RE 0.026316481685059193\n",
      "95 Train Loss 96613.02 Test MSE 3453.673341834996 Test RE 0.026268026929305535\n",
      "96 Train Loss 96577.0 Test MSE 3287.544802487561 Test RE 0.025628469043088447\n",
      "97 Train Loss 96500.78 Test MSE 3585.6855298298105 Test RE 0.02676534975954857\n",
      "98 Train Loss 96458.81 Test MSE 3917.802710752903 Test RE 0.027977448491846205\n",
      "99 Train Loss 96441.78 Test MSE 3595.3479133906485 Test RE 0.026801387928985506\n",
      "100 Train Loss 96383.61 Test MSE 3597.7349847030328 Test RE 0.026810283620061243\n",
      "101 Train Loss 96242.21 Test MSE 3489.0821204332083 Test RE 0.0264023399912365\n",
      "102 Train Loss 96090.72 Test MSE 3823.5324416418857 Test RE 0.0276388019162656\n",
      "103 Train Loss 96044.45 Test MSE 3043.623262563705 Test RE 0.02465938669563292\n",
      "104 Train Loss 96022.86 Test MSE 2872.072254998731 Test RE 0.023954356268991898\n",
      "105 Train Loss 95990.875 Test MSE 3094.903042355691 Test RE 0.024866252975878075\n",
      "106 Train Loss 95891.42 Test MSE 3580.9773220850734 Test RE 0.026747771778997217\n",
      "107 Train Loss 95802.57 Test MSE 3515.6353981304364 Test RE 0.02650261562841709\n",
      "108 Train Loss 95773.586 Test MSE 3254.2678435844364 Test RE 0.025498431783104715\n",
      "109 Train Loss 95747.61 Test MSE 3217.5996972651365 Test RE 0.025354370355507014\n",
      "110 Train Loss 95695.18 Test MSE 3149.46777760195 Test RE 0.025084497663212312\n",
      "111 Train Loss 95569.41 Test MSE 2883.100579726364 Test RE 0.02400030276379732\n",
      "112 Train Loss 95515.99 Test MSE 2623.957017116201 Test RE 0.022896293417296792\n",
      "113 Train Loss 95490.72 Test MSE 2628.119981927248 Test RE 0.022914448952568105\n",
      "114 Train Loss 95459.95 Test MSE 2620.224105520985 Test RE 0.022880001180383233\n",
      "115 Train Loss 95380.625 Test MSE 2670.898540463286 Test RE 0.023100188247071853\n",
      "116 Train Loss 95288.97 Test MSE 2763.327428627064 Test RE 0.02349649038436163\n",
      "117 Train Loss 95263.14 Test MSE 2713.8502263404416 Test RE 0.023285188691612845\n",
      "118 Train Loss 95209.664 Test MSE 2863.9263232668327 Test RE 0.02392036180608951\n",
      "119 Train Loss 95180.305 Test MSE 2991.433859975602 Test RE 0.02444705368449095\n",
      "120 Train Loss 95134.17 Test MSE 3401.9479289353644 Test RE 0.026070577686061174\n",
      "121 Train Loss 94887.46 Test MSE 4948.650637257984 Test RE 0.03144345216621562\n",
      "122 Train Loss 94805.13 Test MSE 5593.036371387618 Test RE 0.03342801939141341\n",
      "123 Train Loss 94720.664 Test MSE 4562.954822840578 Test RE 0.03019325313765742\n",
      "124 Train Loss 94567.59 Test MSE 3059.2180023635105 Test RE 0.02472248014570938\n",
      "125 Train Loss 94371.11 Test MSE 2738.9376670234883 Test RE 0.02339256785880658\n",
      "126 Train Loss 94000.516 Test MSE 2804.7314618356963 Test RE 0.02367186452902491\n",
      "127 Train Loss 93872.836 Test MSE 2496.6934493224257 Test RE 0.022334150305555443\n",
      "128 Train Loss 93767.1 Test MSE 2914.9793428708567 Test RE 0.024132624999826848\n",
      "129 Train Loss 93697.586 Test MSE 2811.908368287702 Test RE 0.023702131636032086\n",
      "130 Train Loss 93590.94 Test MSE 2861.878320590936 Test RE 0.02391180751372475\n",
      "131 Train Loss 93549.62 Test MSE 2477.175952716247 Test RE 0.02224668222720536\n",
      "132 Train Loss 93522.76 Test MSE 2513.8710858523127 Test RE 0.022410849807327087\n",
      "133 Train Loss 93494.15 Test MSE 2459.3361704305134 Test RE 0.022166430944845324\n",
      "134 Train Loss 93416.86 Test MSE 2354.071411184505 Test RE 0.021686858218857415\n",
      "135 Train Loss 93196.45 Test MSE 2377.908057361429 Test RE 0.021796379099579766\n",
      "136 Train Loss 92938.555 Test MSE 2331.3617606345833 Test RE 0.021581998502496064\n",
      "137 Train Loss 92652.43 Test MSE 2798.428579569227 Test RE 0.023645251483568823\n",
      "138 Train Loss 92440.055 Test MSE 3201.179112346215 Test RE 0.02528959130186684\n",
      "139 Train Loss 92298.766 Test MSE 3323.672823607721 Test RE 0.025768904539719594\n",
      "140 Train Loss 92171.74 Test MSE 4314.791749440757 Test RE 0.029360722844780373\n",
      "141 Train Loss 92096.95 Test MSE 3950.5952440603733 Test RE 0.02809429199750798\n",
      "142 Train Loss 92033.71 Test MSE 4104.430430124601 Test RE 0.028636060616259753\n",
      "143 Train Loss 91968.12 Test MSE 4716.224180046355 Test RE 0.03069615957884327\n",
      "144 Train Loss 91830.22 Test MSE 5099.5926787921535 Test RE 0.03191938889911304\n",
      "145 Train Loss 91623.61 Test MSE 7901.002258024639 Test RE 0.03973085550551614\n",
      "146 Train Loss 91473.016 Test MSE 6872.4471276935865 Test RE 0.037054633945400144\n",
      "147 Train Loss 91344.875 Test MSE 6164.008824800851 Test RE 0.03509283460686713\n",
      "148 Train Loss 91187.62 Test MSE 5092.579994306791 Test RE 0.03189743443884992\n",
      "149 Train Loss 91021.055 Test MSE 4903.117170373529 Test RE 0.03129845930498895\n",
      "150 Train Loss 90956.62 Test MSE 4604.985331176251 Test RE 0.03033199314864921\n",
      "151 Train Loss 90894.73 Test MSE 4236.759586193853 Test RE 0.029094020066801028\n",
      "152 Train Loss 90846.74 Test MSE 3788.4982096334843 Test RE 0.02751188622683772\n",
      "153 Train Loss 90754.2 Test MSE 4045.2788655099234 Test RE 0.028428965497065868\n",
      "154 Train Loss 90708.58 Test MSE 3833.1960410316974 Test RE 0.02767370704199178\n",
      "155 Train Loss 90618.7 Test MSE 3662.9974071490055 Test RE 0.027052358199962014\n",
      "156 Train Loss 90458.99 Test MSE 3777.76207328361 Test RE 0.02747287592460834\n",
      "157 Train Loss 90318.22 Test MSE 3477.4942143106864 Test RE 0.02635845992806575\n",
      "158 Train Loss 90231.195 Test MSE 2598.3107849921103 Test RE 0.02278412589303534\n",
      "159 Train Loss 90091.78 Test MSE 2352.22088924679 Test RE 0.02167833258605598\n",
      "160 Train Loss 89893.96 Test MSE 2869.894582593393 Test RE 0.02394527317012032\n",
      "161 Train Loss 89788.44 Test MSE 3670.761412827806 Test RE 0.027081012804508708\n",
      "162 Train Loss 89636.77 Test MSE 3607.27271193175 Test RE 0.026845797620377084\n",
      "163 Train Loss 89513.87 Test MSE 2610.558118281981 Test RE 0.022837760110541457\n",
      "164 Train Loss 89333.06 Test MSE 3256.6169327104753 Test RE 0.025507633128272183\n",
      "165 Train Loss 89110.914 Test MSE 4077.6029475031232 Test RE 0.028542321315794834\n",
      "166 Train Loss 88867.88 Test MSE 4027.0193689059884 Test RE 0.028364731890911574\n",
      "167 Train Loss 88720.43 Test MSE 4499.056638667803 Test RE 0.029981099375203716\n",
      "168 Train Loss 88592.266 Test MSE 5169.716212019752 Test RE 0.03213809834424139\n",
      "169 Train Loss 88389.586 Test MSE 3722.556395804402 Test RE 0.027271402087062288\n",
      "170 Train Loss 88185.695 Test MSE 3229.0229075925545 Test RE 0.025399337369156925\n",
      "171 Train Loss 87909.56 Test MSE 4160.833864141183 Test RE 0.028832148846670045\n",
      "172 Train Loss 87629.54 Test MSE 4843.006229391157 Test RE 0.031106012163579475\n",
      "173 Train Loss 87415.28 Test MSE 4481.903664205163 Test RE 0.029923892256250622\n",
      "174 Train Loss 87195.69 Test MSE 4845.1181484353765 Test RE 0.031112793717855934\n",
      "175 Train Loss 87069.26 Test MSE 5277.783364930098 Test RE 0.032472266578015926\n",
      "176 Train Loss 86828.82 Test MSE 5812.077432223066 Test RE 0.03407630678261881\n",
      "177 Train Loss 86729.45 Test MSE 5890.606380499514 Test RE 0.03430574265224462\n",
      "178 Train Loss 86510.17 Test MSE 4812.780960275188 Test RE 0.031008793713858653\n",
      "179 Train Loss 86330.17 Test MSE 4489.543927019464 Test RE 0.029949386897253485\n",
      "180 Train Loss 86225.2 Test MSE 3275.2287827620135 Test RE 0.02558041845779209\n",
      "181 Train Loss 86107.58 Test MSE 3732.4305681697115 Test RE 0.02730754716628303\n",
      "182 Train Loss 86045.3 Test MSE 3792.4139791905277 Test RE 0.02752610061703056\n",
      "183 Train Loss 85853.05 Test MSE 3805.0538377479447 Test RE 0.027571933772245063\n",
      "184 Train Loss 85760.01 Test MSE 3403.6853875605734 Test RE 0.026077234279426407\n",
      "185 Train Loss 85677.9 Test MSE 4180.328143964097 Test RE 0.028899611907244695\n",
      "186 Train Loss 85583.125 Test MSE 4711.851591360625 Test RE 0.030681926497477127\n",
      "187 Train Loss 85452.46 Test MSE 3540.891715833044 Test RE 0.026597642634347808\n",
      "188 Train Loss 85348.02 Test MSE 3309.8103003469814 Test RE 0.025715109338479095\n",
      "189 Train Loss 85239.766 Test MSE 3423.86463553734 Test RE 0.026154421398551238\n",
      "190 Train Loss 85083.36 Test MSE 3648.050295896009 Test RE 0.026997107280346093\n",
      "191 Train Loss 84977.9 Test MSE 3705.1366604223954 Test RE 0.027207518881004575\n",
      "192 Train Loss 84784.41 Test MSE 2908.0994819064294 Test RE 0.024104129568921145\n",
      "193 Train Loss 84694.25 Test MSE 2329.1178148018257 Test RE 0.0215716096183527\n",
      "194 Train Loss 84594.73 Test MSE 3822.0305629244044 Test RE 0.02763337313985391\n",
      "195 Train Loss 84487.69 Test MSE 3343.5649040409176 Test RE 0.025845902557575916\n",
      "196 Train Loss 84427.84 Test MSE 3398.0642038240803 Test RE 0.026055692115598727\n",
      "197 Train Loss 84336.88 Test MSE 3401.483902020444 Test RE 0.026068799607363496\n",
      "198 Train Loss 84262.15 Test MSE 2768.2438818742135 Test RE 0.023517383322798326\n",
      "199 Train Loss 84191.71 Test MSE 3203.117397099211 Test RE 0.025297246451688578\n",
      "Training time: 42.62\n",
      "Training time: 42.62\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 457334.22 Test MSE 4963740.725012114 Test RE 0.9958441304090905\n",
      "1 Train Loss 443659.5 Test MSE 4642501.426904531 Test RE 0.9630810700126503\n",
      "2 Train Loss 428029.94 Test MSE 4285520.211926704 Test RE 0.9253128588909546\n",
      "3 Train Loss 309793.56 Test MSE 2891371.002570144 Test RE 0.7600439988283857\n",
      "4 Train Loss 259235.47 Test MSE 3450268.353066085 Test RE 0.8302583671415522\n",
      "5 Train Loss 226659.42 Test MSE 3255851.2779373955 Test RE 0.8065273570527465\n",
      "6 Train Loss 207808.11 Test MSE 2803720.0971808257 Test RE 0.748435107262106\n",
      "7 Train Loss 196076.4 Test MSE 2465753.500300839 Test RE 0.7018780370359387\n",
      "8 Train Loss 187109.89 Test MSE 2058491.1196785576 Test RE 0.6413001220215425\n",
      "9 Train Loss 179814.11 Test MSE 1966180.170327009 Test RE 0.6267559701849647\n",
      "10 Train Loss 172099.69 Test MSE 1563006.3301940786 Test RE 0.5588138895115246\n",
      "11 Train Loss 154802.17 Test MSE 1028342.2029889639 Test RE 0.45326861972640414\n",
      "12 Train Loss 140023.88 Test MSE 436425.1967010659 Test RE 0.2952852350813729\n",
      "13 Train Loss 136011.39 Test MSE 360411.25351534714 Test RE 0.2683403581834967\n",
      "14 Train Loss 128650.61 Test MSE 128273.63880616598 Test RE 0.16008680276994064\n",
      "15 Train Loss 122419.13 Test MSE 42178.662834297356 Test RE 0.09179800169685862\n",
      "16 Train Loss 118631.53 Test MSE 20849.977001736264 Test RE 0.06454158310792642\n",
      "17 Train Loss 116100.95 Test MSE 17815.0606360043 Test RE 0.059659619076824315\n",
      "18 Train Loss 114604.03 Test MSE 9065.923402843053 Test RE 0.0425591402798571\n",
      "19 Train Loss 114162.84 Test MSE 8994.585687436653 Test RE 0.042391365423484074\n",
      "20 Train Loss 113987.445 Test MSE 5816.036764930177 Test RE 0.034087911623379576\n",
      "21 Train Loss 113378.07 Test MSE 8381.51310165237 Test RE 0.04092116956585258\n",
      "22 Train Loss 112643.62 Test MSE 9000.826678666175 Test RE 0.0424060697285096\n",
      "23 Train Loss 111843.49 Test MSE 6474.246618905885 Test RE 0.035965114144372555\n",
      "24 Train Loss 111478.38 Test MSE 4631.913805997023 Test RE 0.030420549750466378\n",
      "25 Train Loss 110748.67 Test MSE 3778.33100725162 Test RE 0.027474944565191235\n",
      "26 Train Loss 109984.31 Test MSE 7868.204669331503 Test RE 0.03964830703141811\n",
      "27 Train Loss 109519.39 Test MSE 4658.288821143824 Test RE 0.030507037060137254\n",
      "28 Train Loss 109284.1 Test MSE 5606.496596797529 Test RE 0.033468219227362074\n",
      "29 Train Loss 108886.56 Test MSE 10936.381254428285 Test RE 0.046743760116688265\n",
      "30 Train Loss 108489.25 Test MSE 9208.60470871567 Test RE 0.04289273496671522\n",
      "31 Train Loss 108241.734 Test MSE 8394.316174995198 Test RE 0.04095241194452332\n",
      "32 Train Loss 107995.67 Test MSE 10062.602101940378 Test RE 0.04483756029265166\n",
      "33 Train Loss 107888.65 Test MSE 10784.943761275865 Test RE 0.04641899848151241\n",
      "34 Train Loss 107674.63 Test MSE 9193.238394168355 Test RE 0.04285693266725197\n",
      "35 Train Loss 107362.65 Test MSE 12235.917655454026 Test RE 0.04944303214688631\n",
      "36 Train Loss 107329.53 Test MSE 12632.783184529571 Test RE 0.05023846309106546\n",
      "37 Train Loss 107209.66 Test MSE 12724.231997806104 Test RE 0.05041997350225168\n",
      "38 Train Loss 107151.25 Test MSE 12738.425447424122 Test RE 0.050448086550599416\n",
      "39 Train Loss 107034.875 Test MSE 15777.917891837371 Test RE 0.056145075410515506\n",
      "40 Train Loss 106919.07 Test MSE 19276.06900900595 Test RE 0.062057754908694876\n",
      "41 Train Loss 106695.586 Test MSE 15039.603502477044 Test RE 0.05481570664347047\n",
      "42 Train Loss 106650.35 Test MSE 14621.33910667902 Test RE 0.05404809589936037\n",
      "43 Train Loss 106367.18 Test MSE 18059.13442943434 Test RE 0.060066909695776716\n",
      "44 Train Loss 106170.87 Test MSE 12647.227874817865 Test RE 0.05026717694244783\n",
      "45 Train Loss 106022.37 Test MSE 14290.195659145405 Test RE 0.05343255127853052\n",
      "46 Train Loss 105867.945 Test MSE 12657.824889287067 Test RE 0.050288231772440864\n",
      "47 Train Loss 105670.56 Test MSE 13591.37302265121 Test RE 0.05210969001634353\n",
      "48 Train Loss 105534.4 Test MSE 13390.267739086912 Test RE 0.05172273173575008\n",
      "49 Train Loss 105236.305 Test MSE 8669.816363350565 Test RE 0.041619012651494924\n",
      "50 Train Loss 104804.13 Test MSE 9540.337066743086 Test RE 0.04365848721084041\n",
      "51 Train Loss 104710.695 Test MSE 8505.122505487567 Test RE 0.041221815046976897\n",
      "52 Train Loss 103529.14 Test MSE 6858.765375262833 Test RE 0.037017731158678506\n",
      "53 Train Loss 103032.64 Test MSE 8404.688102418844 Test RE 0.04097770431562496\n",
      "54 Train Loss 102725.266 Test MSE 7270.532349045074 Test RE 0.038112718677179865\n",
      "55 Train Loss 102637.49 Test MSE 7460.823777694461 Test RE 0.03860825871207884\n",
      "56 Train Loss 102413.516 Test MSE 8775.583228378713 Test RE 0.04187210731745274\n",
      "57 Train Loss 102253.61 Test MSE 7603.026379345952 Test RE 0.038974456917944614\n",
      "58 Train Loss 101984.85 Test MSE 7656.46357852337 Test RE 0.03911118136319225\n",
      "59 Train Loss 101768.945 Test MSE 10250.574488244241 Test RE 0.045254412021880776\n",
      "60 Train Loss 101634.52 Test MSE 9204.524393383974 Test RE 0.042883231068934935\n",
      "61 Train Loss 101518.5 Test MSE 9097.980563950674 Test RE 0.0426343185721288\n",
      "62 Train Loss 101419.48 Test MSE 6639.84122158358 Test RE 0.036422157727146486\n",
      "63 Train Loss 101318.77 Test MSE 8946.463238722423 Test RE 0.04227781310147378\n",
      "64 Train Loss 101146.96 Test MSE 7492.059833808186 Test RE 0.038688994442850365\n",
      "65 Train Loss 100941.305 Test MSE 7649.549534423674 Test RE 0.03909351801859943\n",
      "66 Train Loss 100840.516 Test MSE 8739.390773972253 Test RE 0.04178567317151087\n",
      "67 Train Loss 100358.14 Test MSE 10571.241571713103 Test RE 0.0459568043858928\n",
      "68 Train Loss 99869.71 Test MSE 13668.559683353273 Test RE 0.05225744839738443\n",
      "69 Train Loss 99764.64 Test MSE 16394.558776247322 Test RE 0.057231705783608616\n",
      "70 Train Loss 99697.98 Test MSE 14451.727091865288 Test RE 0.053733694212071796\n",
      "71 Train Loss 99628.2 Test MSE 15787.04983975158 Test RE 0.0561613208917662\n",
      "72 Train Loss 99425.53 Test MSE 6574.335401115632 Test RE 0.03624204972998281\n",
      "73 Train Loss 97818.37 Test MSE 9137.695108752747 Test RE 0.04272727100104243\n",
      "74 Train Loss 97231.2 Test MSE 10385.825217003965 Test RE 0.04555198727113301\n",
      "75 Train Loss 97014.19 Test MSE 10127.36169781022 Test RE 0.04498160879392253\n",
      "76 Train Loss 96610.914 Test MSE 11488.694902931134 Test RE 0.04790955884142952\n",
      "77 Train Loss 96361.445 Test MSE 10280.709524812997 Test RE 0.045320883541936696\n",
      "78 Train Loss 95934.28 Test MSE 7954.08929509754 Test RE 0.03986410836711611\n",
      "79 Train Loss 95462.586 Test MSE 4216.828015894421 Test RE 0.029025503891066666\n",
      "80 Train Loss 95311.67 Test MSE 5554.618079416323 Test RE 0.033313013848038996\n",
      "81 Train Loss 95056.48 Test MSE 4376.6146833290395 Test RE 0.029570316993524977\n",
      "82 Train Loss 94822.734 Test MSE 4329.456695162384 Test RE 0.029410575560535328\n",
      "83 Train Loss 94644.055 Test MSE 5228.505297061032 Test RE 0.03232031611527814\n",
      "84 Train Loss 94548.125 Test MSE 5283.017931598002 Test RE 0.03248836577220412\n",
      "85 Train Loss 94473.84 Test MSE 5261.462650076047 Test RE 0.032422020014808775\n",
      "86 Train Loss 94357.42 Test MSE 5140.082480328758 Test RE 0.032045855321508505\n",
      "87 Train Loss 93763.3 Test MSE 6229.244262301022 Test RE 0.0352780445293496\n",
      "88 Train Loss 93542.914 Test MSE 4934.253685182771 Test RE 0.031397680132988826\n",
      "89 Train Loss 93493.0 Test MSE 5733.086220755455 Test RE 0.03384395120878297\n",
      "90 Train Loss 93265.77 Test MSE 8101.602186671659 Test RE 0.04023206096828092\n",
      "91 Train Loss 93145.85 Test MSE 5681.029796345267 Test RE 0.033689949284232835\n",
      "92 Train Loss 92794.71 Test MSE 7744.748575998497 Test RE 0.039336026276505065\n",
      "93 Train Loss 92429.81 Test MSE 10055.458184331637 Test RE 0.04482164131338088\n",
      "94 Train Loss 92302.87 Test MSE 10578.432920527453 Test RE 0.045972433355364294\n",
      "95 Train Loss 92154.99 Test MSE 7358.8824579353 Test RE 0.03834358863191961\n",
      "96 Train Loss 91349.89 Test MSE 4265.456945570995 Test RE 0.029192386811680987\n",
      "97 Train Loss 91075.305 Test MSE 6482.3180751687905 Test RE 0.03598752605132471\n",
      "98 Train Loss 91019.2 Test MSE 6084.643319674936 Test RE 0.034866181467310325\n",
      "99 Train Loss 90924.71 Test MSE 7842.467331056432 Test RE 0.03958340799909228\n",
      "100 Train Loss 90770.71 Test MSE 6653.641885655848 Test RE 0.036459989132526516\n",
      "101 Train Loss 90514.875 Test MSE 5186.571891770269 Test RE 0.032190448283137635\n",
      "102 Train Loss 90382.73 Test MSE 5681.9564401048765 Test RE 0.03369269678859894\n",
      "103 Train Loss 90321.9 Test MSE 4666.627993300213 Test RE 0.030534331383079445\n",
      "104 Train Loss 90134.13 Test MSE 4865.230744106756 Test RE 0.031177303082494473\n",
      "105 Train Loss 89908.164 Test MSE 3157.968512250536 Test RE 0.025118327659335565\n",
      "106 Train Loss 89720.08 Test MSE 2985.9925458139523 Test RE 0.024424809394246728\n",
      "107 Train Loss 89563.24 Test MSE 3193.397810432222 Test RE 0.02525883612248413\n",
      "108 Train Loss 89236.18 Test MSE 3790.4008677651464 Test RE 0.027518793864183627\n",
      "109 Train Loss 89048.47 Test MSE 3565.9570438614314 Test RE 0.026691616557321336\n",
      "110 Train Loss 88926.83 Test MSE 3478.062700812085 Test RE 0.026360614326519816\n",
      "111 Train Loss 88813.78 Test MSE 2792.2096740672505 Test RE 0.023618963628318876\n",
      "112 Train Loss 88639.98 Test MSE 3104.6284091023394 Test RE 0.024905291960488574\n",
      "113 Train Loss 88496.0 Test MSE 4104.848917562554 Test RE 0.0286375204444128\n",
      "114 Train Loss 88362.23 Test MSE 3641.817019372448 Test RE 0.026974032984991497\n",
      "115 Train Loss 88279.98 Test MSE 4036.265349364841 Test RE 0.02839727573651439\n",
      "116 Train Loss 88188.89 Test MSE 3675.9009494842767 Test RE 0.027099964618263403\n",
      "117 Train Loss 88046.1 Test MSE 3068.5734709091007 Test RE 0.024760253496019805\n",
      "118 Train Loss 87852.234 Test MSE 2198.3689291334294 Test RE 0.020957385992730258\n",
      "119 Train Loss 87804.02 Test MSE 2424.160827660948 Test RE 0.022007339246532805\n",
      "120 Train Loss 87716.28 Test MSE 2978.538893038994 Test RE 0.024394305667487497\n",
      "121 Train Loss 87699.336 Test MSE 3011.014344981142 Test RE 0.024526932503978006\n",
      "122 Train Loss 87647.1 Test MSE 3137.0737481914143 Test RE 0.025035091780289544\n",
      "123 Train Loss 87478.47 Test MSE 2149.2147874021134 Test RE 0.020721764498310674\n",
      "124 Train Loss 87290.06 Test MSE 3850.7286826288373 Test RE 0.02773692317304751\n",
      "125 Train Loss 87251.27 Test MSE 3678.3408408724167 Test RE 0.02710895697181649\n",
      "126 Train Loss 87151.7 Test MSE 4373.366172130498 Test RE 0.02955934077739225\n",
      "127 Train Loss 87127.12 Test MSE 4309.846932289073 Test RE 0.02934389410381292\n",
      "128 Train Loss 87047.8 Test MSE 3310.7474667277 Test RE 0.025718749672528966\n",
      "129 Train Loss 86936.65 Test MSE 3295.990393688887 Test RE 0.025661367262322148\n",
      "130 Train Loss 86869.34 Test MSE 3982.4137884299025 Test RE 0.02820720242000754\n",
      "131 Train Loss 86786.53 Test MSE 4701.117974195705 Test RE 0.03064695979562895\n",
      "132 Train Loss 86756.695 Test MSE 4370.5684868120325 Test RE 0.029549884564451078\n",
      "133 Train Loss 86730.69 Test MSE 4987.914034820106 Test RE 0.0315679444457418\n",
      "134 Train Loss 86675.01 Test MSE 3796.866612119969 Test RE 0.027542254927799506\n",
      "135 Train Loss 86557.42 Test MSE 2739.717638411214 Test RE 0.023395898390031863\n",
      "136 Train Loss 86397.484 Test MSE 2291.7379661953055 Test RE 0.021397808843099164\n",
      "137 Train Loss 86315.05 Test MSE 2928.3053372067543 Test RE 0.024187723935504907\n",
      "138 Train Loss 85997.7 Test MSE 2998.2122276770992 Test RE 0.024474735619102406\n",
      "139 Train Loss 85593.74 Test MSE 4166.935227316166 Test RE 0.028853280544606615\n",
      "140 Train Loss 85393.414 Test MSE 3214.6823531178547 Test RE 0.025342873555906517\n",
      "141 Train Loss 85340.336 Test MSE 2470.1293973257034 Test RE 0.02221501832408806\n",
      "142 Train Loss 85254.46 Test MSE 2571.537274986412 Test RE 0.022666435855071936\n",
      "143 Train Loss 85227.71 Test MSE 2587.8388334242504 Test RE 0.022738166196631642\n",
      "144 Train Loss 85151.19 Test MSE 2406.396804832041 Test RE 0.02192655712611384\n",
      "145 Train Loss 85014.54 Test MSE 1953.3247562541117 Test RE 0.01975486430157786\n",
      "146 Train Loss 84870.5 Test MSE 2565.749951546304 Test RE 0.02264091573428731\n",
      "147 Train Loss 84752.7 Test MSE 2296.030472577565 Test RE 0.02141783889516617\n",
      "148 Train Loss 84646.055 Test MSE 1970.3748790322195 Test RE 0.019840894809019034\n",
      "149 Train Loss 84574.125 Test MSE 2187.059785899536 Test RE 0.02090341059348063\n",
      "150 Train Loss 84498.164 Test MSE 2259.049636020252 Test RE 0.021244656346891846\n",
      "151 Train Loss 84419.96 Test MSE 2095.6454384278422 Test RE 0.020461889114785897\n",
      "152 Train Loss 84386.51 Test MSE 2285.6015854925204 Test RE 0.021369142146242085\n",
      "153 Train Loss 84304.6 Test MSE 2287.8541206014847 Test RE 0.02137966954731844\n",
      "154 Train Loss 84224.71 Test MSE 2327.0487371932395 Test RE 0.021562025892897168\n",
      "155 Train Loss 84124.63 Test MSE 2061.409307213222 Test RE 0.020294059994459445\n",
      "156 Train Loss 84068.49 Test MSE 1861.6792281253554 Test RE 0.019285870675368175\n",
      "157 Train Loss 83932.11 Test MSE 1770.7188965724774 Test RE 0.01880882365361545\n",
      "158 Train Loss 83867.734 Test MSE 1690.7844269369873 Test RE 0.018379383645976327\n",
      "159 Train Loss 83794.305 Test MSE 1656.4844015368487 Test RE 0.018192002163107557\n",
      "160 Train Loss 83725.14 Test MSE 1825.8788149377317 Test RE 0.01909953519843408\n",
      "161 Train Loss 83645.07 Test MSE 1963.898132880872 Test RE 0.019808258833266208\n",
      "162 Train Loss 83572.836 Test MSE 1918.7462288686604 Test RE 0.019579229330374457\n",
      "163 Train Loss 83488.48 Test MSE 2391.945262578129 Test RE 0.021860618345321874\n",
      "164 Train Loss 83450.836 Test MSE 2611.2348889106115 Test RE 0.022840720190911917\n",
      "165 Train Loss 83405.72 Test MSE 2010.593976193776 Test RE 0.02004236708580356\n",
      "166 Train Loss 83370.25 Test MSE 1962.3907061710559 Test RE 0.019800655274317742\n",
      "167 Train Loss 83355.516 Test MSE 2112.015182400793 Test RE 0.020541650774567294\n",
      "168 Train Loss 83306.02 Test MSE 2340.547339751012 Test RE 0.021624473306710593\n",
      "169 Train Loss 83143.95 Test MSE 2666.121166509026 Test RE 0.02307951961646251\n",
      "170 Train Loss 83069.65 Test MSE 2733.134232776222 Test RE 0.023367771891356144\n",
      "171 Train Loss 83021.41 Test MSE 2346.971388681935 Test RE 0.021654129080484256\n",
      "172 Train Loss 82815.79 Test MSE 2102.9317177288526 Test RE 0.02049742987678141\n",
      "173 Train Loss 82179.34 Test MSE 4818.04007457824 Test RE 0.03102573134987047\n",
      "174 Train Loss 81940.12 Test MSE 6774.934268985464 Test RE 0.03679081145140987\n",
      "175 Train Loss 81794.4 Test MSE 3506.297770516047 Test RE 0.026467396376566366\n",
      "176 Train Loss 81587.02 Test MSE 2583.365742967402 Test RE 0.0227185061887478\n",
      "177 Train Loss 81315.21 Test MSE 4059.2043929883093 Test RE 0.028477855602737457\n",
      "178 Train Loss 81182.6 Test MSE 4054.3086765932903 Test RE 0.02846067716650587\n",
      "179 Train Loss 81019.26 Test MSE 4883.0993695642055 Test RE 0.031234503347409473\n",
      "180 Train Loss 80597.95 Test MSE 2427.565146801915 Test RE 0.022022786596550662\n",
      "181 Train Loss 80425.02 Test MSE 4427.999639734084 Test RE 0.029743400027297896\n",
      "182 Train Loss 80322.57 Test MSE 3996.5515312477482 Test RE 0.028257226462503927\n",
      "183 Train Loss 80280.2 Test MSE 3762.2402563432984 Test RE 0.027416378471151977\n",
      "184 Train Loss 80254.65 Test MSE 3852.0497901609274 Test RE 0.02774168075515358\n",
      "185 Train Loss 80213.58 Test MSE 3439.2877819268188 Test RE 0.026213262833986208\n",
      "186 Train Loss 80186.21 Test MSE 3455.556110116306 Test RE 0.026275185954573146\n",
      "187 Train Loss 80142.95 Test MSE 3164.2562741087627 Test RE 0.025143321500059736\n",
      "188 Train Loss 79902.41 Test MSE 3726.2550142007635 Test RE 0.027284946739808878\n",
      "189 Train Loss 79647.17 Test MSE 3385.1688853057212 Test RE 0.02600620573107123\n",
      "190 Train Loss 79577.7 Test MSE 3030.2452228948014 Test RE 0.024605132681457573\n",
      "191 Train Loss 79396.14 Test MSE 2673.884510041998 Test RE 0.0231130972345877\n",
      "192 Train Loss 79326.81 Test MSE 2429.5613827000707 Test RE 0.022031839627136448\n",
      "193 Train Loss 79286.22 Test MSE 3104.655889854139 Test RE 0.02490540218537577\n",
      "194 Train Loss 79215.36 Test MSE 3049.653582144377 Test RE 0.024683803383545706\n",
      "195 Train Loss 79168.21 Test MSE 2917.732424109314 Test RE 0.024144018459170902\n",
      "196 Train Loss 79089.836 Test MSE 3000.950328406619 Test RE 0.02448590877717801\n",
      "197 Train Loss 79020.82 Test MSE 3332.9124716639817 Test RE 0.025804697828866158\n",
      "198 Train Loss 78879.88 Test MSE 2586.0373415151926 Test RE 0.02273025037256858\n",
      "199 Train Loss 78713.89 Test MSE 3241.4413000434733 Test RE 0.0254481317359675\n",
      "Training time: 30.70\n",
      "Training time: 30.70\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 452557.16 Test MSE 4626537.719713863 Test RE 0.9614238186608214\n",
      "1 Train Loss 452557.16 Test MSE 4626537.719713863 Test RE 0.9614238186608214\n",
      "2 Train Loss 452557.16 Test MSE 4626537.719713863 Test RE 0.9614238186608214\n",
      "3 Train Loss 437340.9 Test MSE 4294277.8003686955 Test RE 0.9262578285891072\n",
      "4 Train Loss 311483.25 Test MSE 1259076.2911732646 Test RE 0.5015483970042296\n",
      "5 Train Loss 226021.27 Test MSE 1204444.2665891945 Test RE 0.4905464961127074\n",
      "6 Train Loss 178521.44 Test MSE 316093.3668227696 Test RE 0.2513011724561965\n",
      "7 Train Loss 162232.5 Test MSE 222258.2608044807 Test RE 0.2107248626642822\n",
      "8 Train Loss 147026.92 Test MSE 85891.50948109556 Test RE 0.1309971783844762\n",
      "9 Train Loss 137732.34 Test MSE 124793.57581231439 Test RE 0.15790029384068796\n",
      "10 Train Loss 132006.94 Test MSE 49256.73680131811 Test RE 0.09920182049324416\n",
      "11 Train Loss 124991.37 Test MSE 49071.99215222188 Test RE 0.09901561020462238\n",
      "12 Train Loss 122468.4 Test MSE 78310.21819017368 Test RE 0.12508235249213284\n",
      "13 Train Loss 119746.305 Test MSE 76333.07112060685 Test RE 0.12349324184953168\n",
      "14 Train Loss 118155.01 Test MSE 70487.68862425463 Test RE 0.11867068754046656\n",
      "15 Train Loss 115919.98 Test MSE 59726.21690722673 Test RE 0.10923689001406751\n",
      "16 Train Loss 114577.68 Test MSE 51388.30877561934 Test RE 0.10132555381677442\n",
      "17 Train Loss 113815.43 Test MSE 50023.23540844423 Test RE 0.09997069526005938\n",
      "18 Train Loss 113224.16 Test MSE 45689.280050553396 Test RE 0.09554192361658448\n",
      "19 Train Loss 112910.664 Test MSE 41155.85446715097 Test RE 0.09067814664359475\n",
      "20 Train Loss 112310.16 Test MSE 30992.62331161146 Test RE 0.07868935627968474\n",
      "21 Train Loss 112118.9 Test MSE 29333.702975222932 Test RE 0.07655441968754136\n",
      "22 Train Loss 111747.49 Test MSE 19760.882336235514 Test RE 0.06283331741000489\n",
      "23 Train Loss 111532.96 Test MSE 19702.994840762687 Test RE 0.06274121800441579\n",
      "24 Train Loss 111227.836 Test MSE 15341.412830256188 Test RE 0.05536298552819087\n",
      "25 Train Loss 110821.12 Test MSE 14676.47304932359 Test RE 0.05414990192255041\n",
      "26 Train Loss 110538.836 Test MSE 16356.432842720684 Test RE 0.05716512020794439\n",
      "27 Train Loss 110295.28 Test MSE 16280.835610430015 Test RE 0.05703286246377916\n",
      "28 Train Loss 110095.414 Test MSE 19397.91790323695 Test RE 0.06225358728060882\n",
      "29 Train Loss 109122.766 Test MSE 19842.455118306596 Test RE 0.06296287159223048\n",
      "30 Train Loss 108189.85 Test MSE 15779.138781570959 Test RE 0.056147247611583066\n",
      "31 Train Loss 107823.53 Test MSE 14559.89943883217 Test RE 0.05393441982557867\n",
      "32 Train Loss 107361.26 Test MSE 9957.370551555032 Test RE 0.044602495517248236\n",
      "33 Train Loss 107121.09 Test MSE 9901.023755764849 Test RE 0.04447611811541529\n",
      "34 Train Loss 106628.12 Test MSE 13732.717125928155 Test RE 0.05237994774260849\n",
      "35 Train Loss 106171.695 Test MSE 16701.839506191973 Test RE 0.057765558509039014\n",
      "36 Train Loss 105943.55 Test MSE 17630.973357419545 Test RE 0.05935058011035811\n",
      "37 Train Loss 105860.72 Test MSE 21445.91026322936 Test RE 0.0654574474685078\n",
      "38 Train Loss 105665.61 Test MSE 24184.9406737765 Test RE 0.06951192839610819\n",
      "39 Train Loss 105532.4 Test MSE 24921.984124808954 Test RE 0.0705631778384791\n",
      "40 Train Loss 105418.3 Test MSE 27594.569216107528 Test RE 0.07425037184842313\n",
      "41 Train Loss 105373.0 Test MSE 25423.7487724185 Test RE 0.07126997686702173\n",
      "42 Train Loss 105340.32 Test MSE 25093.87062423326 Test RE 0.07080609622420234\n",
      "43 Train Loss 105231.58 Test MSE 25138.995959886564 Test RE 0.07086973155906594\n",
      "44 Train Loss 105156.58 Test MSE 24552.120000525756 Test RE 0.07003761082602039\n",
      "45 Train Loss 105125.49 Test MSE 21673.461756344343 Test RE 0.0658037987617598\n",
      "46 Train Loss 105063.29 Test MSE 18367.62662661418 Test RE 0.06057777878350846\n",
      "47 Train Loss 104965.164 Test MSE 18184.768792831183 Test RE 0.06027548526647102\n",
      "48 Train Loss 104854.234 Test MSE 14432.40783101596 Test RE 0.05369776624252011\n",
      "49 Train Loss 104715.125 Test MSE 15389.83184549845 Test RE 0.05545028223040831\n",
      "50 Train Loss 104512.875 Test MSE 13925.957287475854 Test RE 0.05274719299206385\n",
      "51 Train Loss 104210.18 Test MSE 11294.618167952967 Test RE 0.04750317090878683\n",
      "52 Train Loss 103847.984 Test MSE 11523.937274132153 Test RE 0.04798298552724978\n",
      "53 Train Loss 103765.19 Test MSE 10854.654588427204 Test RE 0.04656877648156424\n",
      "54 Train Loss 103716.88 Test MSE 10746.13188000707 Test RE 0.04633539895205243\n",
      "55 Train Loss 103616.164 Test MSE 12017.034379708948 Test RE 0.04899880353889845\n",
      "56 Train Loss 103532.8 Test MSE 15247.948601259912 Test RE 0.055194084398284306\n",
      "57 Train Loss 103410.836 Test MSE 17388.709526138056 Test RE 0.05894140717426055\n",
      "58 Train Loss 103295.21 Test MSE 16562.15006904909 Test RE 0.05752348393146361\n",
      "59 Train Loss 102257.65 Test MSE 6811.392062282073 Test RE 0.036889669395453475\n",
      "60 Train Loss 102049.086 Test MSE 6303.04393757015 Test RE 0.03548640386903361\n",
      "61 Train Loss 101875.04 Test MSE 5957.446208547892 Test RE 0.034499824711236\n",
      "62 Train Loss 101630.17 Test MSE 4980.879468085748 Test RE 0.03154567610249976\n",
      "63 Train Loss 101430.875 Test MSE 5129.195708952742 Test RE 0.03201190053296654\n",
      "64 Train Loss 101319.91 Test MSE 4850.716210034097 Test RE 0.031130762428829575\n",
      "65 Train Loss 101288.586 Test MSE 4815.271617224059 Test RE 0.03101681633930797\n",
      "66 Train Loss 101228.47 Test MSE 4778.785779614966 Test RE 0.030899083999396986\n",
      "67 Train Loss 100880.55 Test MSE 5251.953946653366 Test RE 0.03239270964923157\n",
      "68 Train Loss 100357.18 Test MSE 5450.654864563084 Test RE 0.0329997891766974\n",
      "69 Train Loss 99978.59 Test MSE 6033.625439149465 Test RE 0.034719702621109336\n",
      "70 Train Loss 99769.92 Test MSE 6197.823297341676 Test RE 0.03518895895966352\n",
      "71 Train Loss 99648.48 Test MSE 4807.445262774607 Test RE 0.030991599972079797\n",
      "72 Train Loss 99558.945 Test MSE 4488.244100372758 Test RE 0.029945051063826496\n",
      "73 Train Loss 99432.445 Test MSE 4895.630041318078 Test RE 0.03127455358106703\n",
      "74 Train Loss 99176.01 Test MSE 4168.481684000906 Test RE 0.02885863414467113\n",
      "75 Train Loss 98647.82 Test MSE 4181.78728602091 Test RE 0.02890465516684206\n",
      "76 Train Loss 98211.6 Test MSE 3892.4641209541246 Test RE 0.027886828941611926\n",
      "77 Train Loss 98054.16 Test MSE 3994.793206692219 Test RE 0.028251009747809534\n",
      "78 Train Loss 97902.45 Test MSE 4391.025608551742 Test RE 0.029618960231373035\n",
      "79 Train Loss 96311.02 Test MSE 5599.805333799569 Test RE 0.033448241375637684\n",
      "80 Train Loss 95998.375 Test MSE 3980.2074515489867 Test RE 0.02819938766035372\n",
      "81 Train Loss 95918.81 Test MSE 4002.889095827406 Test RE 0.028279622152537508\n",
      "82 Train Loss 95737.21 Test MSE 4172.885499731042 Test RE 0.02887387405318121\n",
      "83 Train Loss 95494.68 Test MSE 4319.881720124434 Test RE 0.029378035519376334\n",
      "84 Train Loss 95221.67 Test MSE 4156.010220555997 Test RE 0.028815431483592523\n",
      "85 Train Loss 94925.61 Test MSE 5697.099995108469 Test RE 0.033737565813925195\n",
      "86 Train Loss 94819.58 Test MSE 5993.485502184203 Test RE 0.0346040199099861\n",
      "87 Train Loss 94754.42 Test MSE 6446.899491427716 Test RE 0.03588907569263391\n",
      "88 Train Loss 94704.75 Test MSE 9263.85008148186 Test RE 0.04302120620599963\n",
      "89 Train Loss 94597.74 Test MSE 11840.286450633776 Test RE 0.048637128693932365\n",
      "90 Train Loss 94186.7 Test MSE 9204.689234359515 Test RE 0.04288361505846515\n",
      "91 Train Loss 93718.45 Test MSE 6863.915102700472 Test RE 0.03703162545642662\n",
      "92 Train Loss 93538.15 Test MSE 5544.037502765852 Test RE 0.033281270990082656\n",
      "93 Train Loss 93419.22 Test MSE 4633.8547890412565 Test RE 0.0304269228814564\n",
      "94 Train Loss 93319.555 Test MSE 6041.18512887689 Test RE 0.03474144643164146\n",
      "95 Train Loss 93012.2 Test MSE 4027.612669391185 Test RE 0.028366821300950442\n",
      "96 Train Loss 92872.32 Test MSE 4282.170724258393 Test RE 0.02924952466008864\n",
      "97 Train Loss 92775.75 Test MSE 5836.328557992565 Test RE 0.034147325155123656\n",
      "98 Train Loss 92711.48 Test MSE 5518.792123336224 Test RE 0.0332054095821075\n",
      "99 Train Loss 92667.61 Test MSE 4592.982239180247 Test RE 0.030292436534053526\n",
      "100 Train Loss 92636.7 Test MSE 3947.5407036224747 Test RE 0.028083428856659858\n",
      "101 Train Loss 92585.45 Test MSE 4201.355285849539 Test RE 0.028972203576936237\n",
      "102 Train Loss 92517.31 Test MSE 5129.723899539037 Test RE 0.03201354873964435\n",
      "103 Train Loss 92425.67 Test MSE 4065.861390120387 Test RE 0.028501197534181583\n",
      "104 Train Loss 92333.67 Test MSE 3263.648365162091 Test RE 0.02553515532308233\n",
      "105 Train Loss 92197.94 Test MSE 3403.176393259339 Test RE 0.02607528438418196\n",
      "106 Train Loss 92122.07 Test MSE 3774.4163633816347 Test RE 0.02746070779023857\n",
      "107 Train Loss 92001.86 Test MSE 3808.772187194681 Test RE 0.027585402313664024\n",
      "108 Train Loss 91899.484 Test MSE 3460.564569597304 Test RE 0.026294220597646127\n",
      "109 Train Loss 91818.4 Test MSE 3419.2550453380495 Test RE 0.026136809462484804\n",
      "110 Train Loss 91769.055 Test MSE 3477.672408105075 Test RE 0.026359135249652377\n",
      "111 Train Loss 91700.34 Test MSE 3523.212255432356 Test RE 0.026531159324855863\n",
      "112 Train Loss 91509.33 Test MSE 4063.104715598174 Test RE 0.028491533918094395\n",
      "113 Train Loss 91225.73 Test MSE 4469.528630590243 Test RE 0.029882552105947195\n",
      "114 Train Loss 91024.234 Test MSE 3632.713741609947 Test RE 0.026940299033756922\n",
      "115 Train Loss 90959.555 Test MSE 3872.403490868377 Test RE 0.027814875805094542\n",
      "116 Train Loss 90879.65 Test MSE 4242.24357054546 Test RE 0.02911284336216264\n",
      "117 Train Loss 90655.89 Test MSE 3201.807780179548 Test RE 0.02529207444503282\n",
      "118 Train Loss 90328.89 Test MSE 3188.7328523905953 Test RE 0.025240380157776268\n",
      "119 Train Loss 90251.16 Test MSE 3524.434625874103 Test RE 0.026535761388274657\n",
      "120 Train Loss 90220.99 Test MSE 3189.0128465725934 Test RE 0.025241488278900298\n",
      "121 Train Loss 90168.875 Test MSE 2973.8493043665076 Test RE 0.02437509418018232\n",
      "122 Train Loss 90071.97 Test MSE 2883.1111248524157 Test RE 0.024000346655083726\n",
      "123 Train Loss 89984.42 Test MSE 3427.710598967141 Test RE 0.026169106663209925\n",
      "124 Train Loss 89912.17 Test MSE 3165.1932868360304 Test RE 0.025147043996963624\n",
      "125 Train Loss 89752.02 Test MSE 2669.7055888723007 Test RE 0.023095028844027032\n",
      "126 Train Loss 89553.836 Test MSE 2847.478602263198 Test RE 0.023851574780469943\n",
      "127 Train Loss 89373.625 Test MSE 2847.2488715219774 Test RE 0.023850612604587006\n",
      "128 Train Loss 89246.414 Test MSE 3130.016883398929 Test RE 0.02500691763800354\n",
      "129 Train Loss 89147.17 Test MSE 3083.0770481991553 Test RE 0.024818699043857202\n",
      "130 Train Loss 89081.86 Test MSE 2547.2595839895444 Test RE 0.02255918605801068\n",
      "131 Train Loss 89045.92 Test MSE 2791.531713344201 Test RE 0.02361609606040017\n",
      "132 Train Loss 89036.805 Test MSE 2835.301975096961 Test RE 0.023800522089328136\n",
      "133 Train Loss 89017.64 Test MSE 2764.378030163415 Test RE 0.0235009565765996\n",
      "134 Train Loss 89005.24 Test MSE 2730.944365879083 Test RE 0.023358408545091178\n",
      "135 Train Loss 88988.11 Test MSE 2701.965149770208 Test RE 0.02323414499181069\n",
      "136 Train Loss 88973.336 Test MSE 2718.8745675521686 Test RE 0.023306733475640683\n",
      "137 Train Loss 88956.305 Test MSE 2586.1666795376327 Test RE 0.02273081878061661\n",
      "138 Train Loss 88940.18 Test MSE 2736.6902893002434 Test RE 0.02338296874942299\n",
      "139 Train Loss 88932.17 Test MSE 2803.780637254192 Test RE 0.02366785172086653\n",
      "140 Train Loss 88912.96 Test MSE 2636.819418622668 Test RE 0.022952342600674164\n",
      "141 Train Loss 88884.36 Test MSE 2756.7291055379023 Test RE 0.02346842094634133\n",
      "142 Train Loss 88849.43 Test MSE 2851.4829057252355 Test RE 0.023868339680706747\n",
      "143 Train Loss 88831.58 Test MSE 2797.735858852724 Test RE 0.023642324739352422\n",
      "144 Train Loss 88812.08 Test MSE 2717.723244229894 Test RE 0.023301798266887747\n",
      "145 Train Loss 88794.64 Test MSE 2764.278446364809 Test RE 0.02350053327421866\n",
      "146 Train Loss 88770.16 Test MSE 2696.2655893311976 Test RE 0.023209626851404964\n",
      "147 Train Loss 88752.5 Test MSE 2609.2772502686394 Test RE 0.022832156759818537\n",
      "148 Train Loss 88723.18 Test MSE 2701.337595496931 Test RE 0.023231446671720012\n",
      "149 Train Loss 88701.45 Test MSE 2660.4670287170293 Test RE 0.02305503384938353\n",
      "150 Train Loss 88668.73 Test MSE 2524.811347513852 Test RE 0.022459562405861284\n",
      "151 Train Loss 88632.81 Test MSE 2349.966263243748 Test RE 0.021667940651704513\n",
      "152 Train Loss 88547.82 Test MSE 2577.7898834212283 Test RE 0.022693975472024775\n",
      "153 Train Loss 88423.0 Test MSE 2838.072855218149 Test RE 0.023812149120503164\n",
      "154 Train Loss 88327.59 Test MSE 3507.500815917082 Test RE 0.02647193659972466\n",
      "155 Train Loss 88211.14 Test MSE 3275.60850147583 Test RE 0.0255819012675014\n",
      "156 Train Loss 88177.195 Test MSE 3654.098667849037 Test RE 0.027019478260357773\n",
      "157 Train Loss 88145.64 Test MSE 3545.850488180858 Test RE 0.02661626019193331\n",
      "158 Train Loss 88129.4 Test MSE 3415.045921255349 Test RE 0.026120717221595684\n",
      "159 Train Loss 88101.97 Test MSE 3133.3845475645335 Test RE 0.02502036680832781\n",
      "160 Train Loss 88045.16 Test MSE 2901.598404305544 Test RE 0.024077172015817397\n",
      "161 Train Loss 87994.34 Test MSE 2803.9231963576553 Test RE 0.023668453412880094\n",
      "162 Train Loss 87936.3 Test MSE 2588.1629799130505 Test RE 0.02273959021613606\n",
      "163 Train Loss 87882.51 Test MSE 2391.9402926933585 Test RE 0.021860595634766507\n",
      "164 Train Loss 87863.555 Test MSE 2600.8291804060095 Test RE 0.02279516489990944\n",
      "165 Train Loss 87807.516 Test MSE 2518.8836159397697 Test RE 0.02243318172357926\n",
      "166 Train Loss 87787.54 Test MSE 2466.7191348753727 Test RE 0.022199677992278056\n",
      "167 Train Loss 87771.29 Test MSE 2360.3222662712174 Test RE 0.02171563209893411\n",
      "168 Train Loss 87750.4 Test MSE 2508.373261649105 Test RE 0.02238633018252118\n",
      "169 Train Loss 87739.48 Test MSE 2550.297461605259 Test RE 0.02257263416240177\n",
      "170 Train Loss 87736.47 Test MSE 2522.663995983416 Test RE 0.0224500094476345\n",
      "171 Train Loss 87719.89 Test MSE 2619.9039649441884 Test RE 0.022878603391447757\n",
      "172 Train Loss 87690.984 Test MSE 2482.356921705437 Test RE 0.02226993434375761\n",
      "173 Train Loss 87683.91 Test MSE 2549.0877151882173 Test RE 0.022567279806134873\n",
      "174 Train Loss 87669.0 Test MSE 2684.8365546952173 Test RE 0.023160383681517006\n",
      "175 Train Loss 87623.086 Test MSE 2426.5415984757847 Test RE 0.022018143309643995\n",
      "176 Train Loss 87559.77 Test MSE 2286.996818915156 Test RE 0.021375663491173678\n",
      "177 Train Loss 87474.4 Test MSE 2379.7763255002465 Test RE 0.021804939877433052\n",
      "178 Train Loss 87393.52 Test MSE 2289.684468028052 Test RE 0.021388220004971068\n",
      "179 Train Loss 87367.54 Test MSE 2257.3230879070843 Test RE 0.02123653635433736\n",
      "180 Train Loss 87313.17 Test MSE 2308.317367714175 Test RE 0.021475069759043758\n",
      "181 Train Loss 87244.26 Test MSE 2811.2366047601063 Test RE 0.023699300253116902\n",
      "182 Train Loss 87200.87 Test MSE 2675.773537018494 Test RE 0.02312126018167278\n",
      "183 Train Loss 87171.99 Test MSE 2946.776528703155 Test RE 0.02426388978880202\n",
      "184 Train Loss 87151.61 Test MSE 2870.264005031811 Test RE 0.023946814278390627\n",
      "185 Train Loss 87133.47 Test MSE 2907.7165073832753 Test RE 0.02410254235164625\n",
      "186 Train Loss 87111.5 Test MSE 2764.585475056578 Test RE 0.02350183834130689\n",
      "187 Train Loss 87092.91 Test MSE 2795.5957825518635 Test RE 0.02363328062996925\n",
      "188 Train Loss 87084.555 Test MSE 2821.111504264589 Test RE 0.02374088747724137\n",
      "189 Train Loss 87080.61 Test MSE 2856.072689433149 Test RE 0.023887541350887383\n",
      "190 Train Loss 87072.32 Test MSE 2827.752066305688 Test RE 0.023768812671082995\n",
      "191 Train Loss 87065.92 Test MSE 2881.4321945973466 Test RE 0.02399335754256659\n",
      "192 Train Loss 87053.305 Test MSE 2840.676634901832 Test RE 0.023823069801367076\n",
      "193 Train Loss 87038.52 Test MSE 2918.181877180542 Test RE 0.024145877982904188\n",
      "194 Train Loss 87024.14 Test MSE 3010.7863875897883 Test RE 0.024526004045867654\n",
      "195 Train Loss 87020.65 Test MSE 3034.5031487886868 Test RE 0.024622413470076873\n",
      "196 Train Loss 87012.38 Test MSE 2851.936312094614 Test RE 0.02387023722444686\n",
      "197 Train Loss 86994.77 Test MSE 3056.39182962394 Test RE 0.024711057922169526\n",
      "198 Train Loss 86969.86 Test MSE 2891.7839542306497 Test RE 0.0240364178643237\n",
      "199 Train Loss 86950.17 Test MSE 2741.649630313375 Test RE 0.023404146086758365\n",
      "Training time: 40.99\n",
      "Training time: 40.99\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 456769.47 Test MSE 4925444.70539642 Test RE 0.9919951471985581\n",
      "1 Train Loss 451856.12 Test MSE 4502708.463271079 Test RE 0.9484703040243513\n",
      "2 Train Loss 219352.45 Test MSE 668618.5247920826 Test RE 0.36549044370545714\n",
      "3 Train Loss 125135.92 Test MSE 4347.416006512982 Test RE 0.02947151242800427\n",
      "4 Train Loss 123423.38 Test MSE 3871.5690236546 Test RE 0.027811878719108833\n",
      "5 Train Loss 122170.04 Test MSE 3816.671653913206 Test RE 0.027613993823794022\n",
      "6 Train Loss 120846.29 Test MSE 7423.980388535884 Test RE 0.03851281217655429\n",
      "7 Train Loss 119878.9 Test MSE 8284.891195349053 Test RE 0.040684616655475486\n",
      "8 Train Loss 118295.305 Test MSE 12671.040683954843 Test RE 0.05031447741763811\n",
      "9 Train Loss 116735.95 Test MSE 19388.848404111242 Test RE 0.06223903224255269\n",
      "10 Train Loss 115459.92 Test MSE 26093.302245430685 Test RE 0.07220235218002173\n",
      "11 Train Loss 113622.27 Test MSE 12959.509182600044 Test RE 0.05088398319648456\n",
      "12 Train Loss 112363.42 Test MSE 7942.933500747362 Test RE 0.039836143390933075\n",
      "13 Train Loss 111153.36 Test MSE 9372.720853483808 Test RE 0.04327326507175347\n",
      "14 Train Loss 110113.78 Test MSE 10679.528052110732 Test RE 0.04619158386894144\n",
      "15 Train Loss 107961.03 Test MSE 4552.242907763527 Test RE 0.030157791729702444\n",
      "16 Train Loss 106559.01 Test MSE 3407.048720976652 Test RE 0.026090115137599935\n",
      "17 Train Loss 105026.836 Test MSE 4934.922840004789 Test RE 0.031399809046309804\n",
      "18 Train Loss 103846.71 Test MSE 4650.70541048925 Test RE 0.030482195146040465\n",
      "19 Train Loss 102701.875 Test MSE 3240.359645410645 Test RE 0.025443885417160885\n",
      "20 Train Loss 100901.96 Test MSE 2080.306674417231 Test RE 0.020386867713966122\n",
      "21 Train Loss 99891.8 Test MSE 1671.658485920908 Test RE 0.018275135357269014\n",
      "22 Train Loss 98896.77 Test MSE 1463.678928243689 Test RE 0.017100536425075606\n",
      "23 Train Loss 98314.055 Test MSE 1407.0066368382766 Test RE 0.01676620981383404\n",
      "24 Train Loss 97458.32 Test MSE 1406.7640027660343 Test RE 0.016764764110220168\n",
      "25 Train Loss 96325.31 Test MSE 2154.34165920569 Test RE 0.020746465274986785\n",
      "26 Train Loss 95641.09 Test MSE 2053.375756982929 Test RE 0.020254477243962912\n",
      "27 Train Loss 95018.71 Test MSE 2869.6735434283078 Test RE 0.02394435102037675\n",
      "28 Train Loss 94599.7 Test MSE 3992.2550935273744 Test RE 0.028242033606981826\n",
      "29 Train Loss 93845.25 Test MSE 1911.9253182449615 Test RE 0.01954439745170826\n",
      "30 Train Loss 92770.47 Test MSE 5477.413756009123 Test RE 0.03308069290995433\n",
      "31 Train Loss 91556.11 Test MSE 5102.143178909303 Test RE 0.031927369951099835\n",
      "32 Train Loss 90312.055 Test MSE 3631.468967190449 Test RE 0.026935682998654273\n",
      "33 Train Loss 89726.03 Test MSE 4044.299098050845 Test RE 0.02842552253763497\n",
      "34 Train Loss 89070.71 Test MSE 2767.8362148107813 Test RE 0.023515651608397\n",
      "35 Train Loss 88513.27 Test MSE 1560.4206118625693 Test RE 0.01765662375891816\n",
      "36 Train Loss 87709.96 Test MSE 1800.1463214083835 Test RE 0.018964470756990627\n",
      "37 Train Loss 86979.984 Test MSE 1637.7616678251889 Test RE 0.018088900701588025\n",
      "38 Train Loss 86417.95 Test MSE 1359.2673771680957 Test RE 0.016479319373652785\n",
      "39 Train Loss 86042.24 Test MSE 1685.9146937433138 Test RE 0.018352896758667053\n",
      "40 Train Loss 85726.336 Test MSE 1388.4490019896623 Test RE 0.01665527431491873\n",
      "41 Train Loss 85451.15 Test MSE 1280.2801753665037 Test RE 0.015993346041062454\n",
      "42 Train Loss 84896.22 Test MSE 1062.0847602354015 Test RE 0.014566875629154666\n",
      "43 Train Loss 84744.03 Test MSE 1087.4875384366896 Test RE 0.014740050389616734\n",
      "44 Train Loss 84276.37 Test MSE 1701.0029787404426 Test RE 0.018434839494899356\n",
      "45 Train Loss 83896.84 Test MSE 1622.4056783462831 Test RE 0.018003898360003903\n",
      "46 Train Loss 83692.93 Test MSE 1960.157752111766 Test RE 0.019789386738935315\n",
      "47 Train Loss 83400.0 Test MSE 1287.564988523131 Test RE 0.01603878268685085\n",
      "48 Train Loss 83138.625 Test MSE 1276.2838701281735 Test RE 0.01596836547517201\n",
      "49 Train Loss 82851.78 Test MSE 1168.735157010944 Test RE 0.015280757294112915\n",
      "50 Train Loss 82666.07 Test MSE 1093.787262361876 Test RE 0.01478268267409114\n",
      "51 Train Loss 82399.266 Test MSE 1026.6578022746949 Test RE 0.014321868428635106\n",
      "52 Train Loss 82152.03 Test MSE 1126.9138066331395 Test RE 0.0150048678036617\n",
      "53 Train Loss 81991.99 Test MSE 1225.6306376285731 Test RE 0.01564828070261723\n",
      "54 Train Loss 81658.57 Test MSE 1219.2678840287804 Test RE 0.015607609512595655\n",
      "55 Train Loss 80819.41 Test MSE 1096.3782227723113 Test RE 0.014800180907833131\n",
      "56 Train Loss 80418.44 Test MSE 1052.4377492360318 Test RE 0.014500568599527676\n",
      "57 Train Loss 80104.555 Test MSE 1202.2991319505174 Test RE 0.015498622148347825\n",
      "58 Train Loss 79486.945 Test MSE 1116.2231795944947 Test RE 0.014933525301114631\n",
      "59 Train Loss 79245.18 Test MSE 1108.7089606631903 Test RE 0.014883175483174223\n",
      "60 Train Loss 79066.27 Test MSE 1191.0993661406867 Test RE 0.015426266165185687\n",
      "61 Train Loss 78847.12 Test MSE 1666.8902170733609 Test RE 0.018249052581213038\n",
      "62 Train Loss 78515.875 Test MSE 1574.8805451953992 Test RE 0.01773824433201257\n",
      "63 Train Loss 78256.234 Test MSE 1651.5427111976173 Test RE 0.018164846341656868\n",
      "64 Train Loss 77908.13 Test MSE 1969.6766903276928 Test RE 0.01983737925566943\n",
      "65 Train Loss 77418.47 Test MSE 1811.7884022613678 Test RE 0.01902569635763874\n",
      "66 Train Loss 76918.69 Test MSE 1900.2251389347282 Test RE 0.01948450393163533\n",
      "67 Train Loss 76158.45 Test MSE 3131.9084189965724 Test RE 0.0250144726021617\n",
      "68 Train Loss 75958.625 Test MSE 3074.8535123583392 Test RE 0.02478557730577658\n",
      "69 Train Loss 75685.76 Test MSE 2752.8195439094707 Test RE 0.023451773719188444\n",
      "70 Train Loss 75230.76 Test MSE 2446.046709942147 Test RE 0.022106459692370274\n",
      "71 Train Loss 74772.086 Test MSE 1845.0433602502617 Test RE 0.019199508546478998\n",
      "72 Train Loss 74662.55 Test MSE 2078.6443196728965 Test RE 0.020378720602837984\n",
      "73 Train Loss 74076.85 Test MSE 1621.6365665906008 Test RE 0.017999630422731325\n",
      "74 Train Loss 73823.02 Test MSE 1521.2168827117719 Test RE 0.017433411924027004\n",
      "75 Train Loss 73540.43 Test MSE 1693.9370259224254 Test RE 0.018396510560779396\n",
      "76 Train Loss 72731.63 Test MSE 1735.9384871153734 Test RE 0.018623186376680985\n",
      "77 Train Loss 72430.91 Test MSE 3540.638204472731 Test RE 0.026596690483618672\n",
      "78 Train Loss 72071.74 Test MSE 2522.704826604186 Test RE 0.02245019112940314\n",
      "79 Train Loss 71530.75 Test MSE 2126.8494259833624 Test RE 0.020613664142750385\n",
      "80 Train Loss 71210.89 Test MSE 1161.9694294541566 Test RE 0.015236463470337865\n",
      "81 Train Loss 70831.2 Test MSE 1456.350672139089 Test RE 0.01705767375915877\n",
      "82 Train Loss 70720.984 Test MSE 2227.48452899347 Test RE 0.021095711223151292\n",
      "83 Train Loss 70613.836 Test MSE 2183.7408480791764 Test RE 0.02088754375230709\n",
      "84 Train Loss 70254.164 Test MSE 2559.8622207390213 Test RE 0.022614923298981526\n",
      "85 Train Loss 69962.21 Test MSE 1527.725172207513 Test RE 0.017470665189769623\n",
      "86 Train Loss 69608.56 Test MSE 1297.3285966302317 Test RE 0.016099478901271655\n",
      "87 Train Loss 69252.7 Test MSE 1841.5413951747182 Test RE 0.019181279180083267\n",
      "88 Train Loss 69087.33 Test MSE 1927.3684703806884 Test RE 0.019623171466613503\n",
      "89 Train Loss 68893.57 Test MSE 1867.2381042564145 Test RE 0.01931464251066036\n",
      "90 Train Loss 68650.81 Test MSE 1820.388288358465 Test RE 0.019070796856514985\n",
      "91 Train Loss 68569.19 Test MSE 1237.7998426419847 Test RE 0.01572577418952985\n",
      "92 Train Loss 68408.69 Test MSE 1389.423199155322 Test RE 0.016661116328514507\n",
      "93 Train Loss 68204.99 Test MSE 1884.8654808263823 Test RE 0.019405596823392067\n",
      "94 Train Loss 67986.95 Test MSE 1318.6996002586513 Test RE 0.016231541292448057\n",
      "95 Train Loss 67747.53 Test MSE 1223.508427570057 Test RE 0.015634727138569657\n",
      "96 Train Loss 67532.57 Test MSE 1106.0093382694806 Test RE 0.014865044736851072\n",
      "97 Train Loss 67308.58 Test MSE 1605.6262453739405 Test RE 0.017910555379787706\n",
      "98 Train Loss 67234.01 Test MSE 1542.317210127725 Test RE 0.01755390226589725\n",
      "99 Train Loss 67079.46 Test MSE 1270.6119098225242 Test RE 0.01593284328859799\n",
      "100 Train Loss 66922.12 Test MSE 1574.7871779221953 Test RE 0.017737718515607907\n",
      "101 Train Loss 66841.305 Test MSE 1918.792976133873 Test RE 0.019579467837644894\n",
      "102 Train Loss 66588.85 Test MSE 1301.9733433804442 Test RE 0.01612827314478982\n",
      "103 Train Loss 66449.61 Test MSE 1247.2774158965312 Test RE 0.015785863859366665\n",
      "104 Train Loss 65911.73 Test MSE 2197.728347720337 Test RE 0.020954332390155227\n",
      "105 Train Loss 65675.875 Test MSE 2782.615591426484 Test RE 0.023578351120138553\n",
      "106 Train Loss 65458.457 Test MSE 1759.6384767237566 Test RE 0.018749882417199364\n",
      "107 Train Loss 65325.32 Test MSE 1591.2363145868842 Test RE 0.017830115826872037\n",
      "108 Train Loss 65231.27 Test MSE 1660.2096375395827 Test RE 0.01821244649773473\n",
      "109 Train Loss 65110.812 Test MSE 1683.5481621183362 Test RE 0.018340011182912175\n",
      "110 Train Loss 65026.258 Test MSE 1689.2261232101441 Test RE 0.018370912056176712\n",
      "111 Train Loss 64908.348 Test MSE 2251.2609676938155 Test RE 0.021208001452503202\n",
      "112 Train Loss 64825.324 Test MSE 2560.900911319897 Test RE 0.022619510953210072\n",
      "113 Train Loss 64762.414 Test MSE 2286.778035630409 Test RE 0.021374641025885266\n",
      "114 Train Loss 64654.066 Test MSE 2697.234937313467 Test RE 0.02321379858124111\n",
      "115 Train Loss 64479.777 Test MSE 3453.152970860991 Test RE 0.02626604793008765\n",
      "116 Train Loss 64363.85 Test MSE 2727.5307851158736 Test RE 0.023343805401328147\n",
      "117 Train Loss 64203.855 Test MSE 2537.6979873442015 Test RE 0.022516806270965025\n",
      "118 Train Loss 64140.37 Test MSE 2214.8706948081635 Test RE 0.021035895860564764\n",
      "119 Train Loss 64020.336 Test MSE 1868.5361947369315 Test RE 0.019321355044412587\n",
      "120 Train Loss 63902.273 Test MSE 1467.1946695733939 Test RE 0.01712106176101674\n",
      "121 Train Loss 63757.016 Test MSE 1685.5117428932526 Test RE 0.018350703362607555\n",
      "122 Train Loss 63637.812 Test MSE 1741.9533205498722 Test RE 0.018655422110393168\n",
      "123 Train Loss 63583.61 Test MSE 1723.7232502966187 Test RE 0.018557548038901455\n",
      "124 Train Loss 63541.793 Test MSE 1667.3032804545167 Test RE 0.018251313542479004\n",
      "125 Train Loss 63444.402 Test MSE 1767.055974271865 Test RE 0.018789359546140902\n",
      "126 Train Loss 63337.992 Test MSE 1157.2735955114947 Test RE 0.015205644959509065\n",
      "127 Train Loss 63211.31 Test MSE 1315.7191880327027 Test RE 0.01621318834487379\n",
      "128 Train Loss 63085.76 Test MSE 1072.1220071044945 Test RE 0.014635545998952284\n",
      "129 Train Loss 63008.875 Test MSE 914.9138888662193 Test RE 0.013520007542381075\n",
      "130 Train Loss 62959.184 Test MSE 824.5813637448921 Test RE 0.012835227808263468\n",
      "131 Train Loss 62891.477 Test MSE 828.1990980626832 Test RE 0.012863353367751715\n",
      "132 Train Loss 62760.066 Test MSE 860.9743233307817 Test RE 0.013115411568783852\n",
      "133 Train Loss 62725.277 Test MSE 876.9040321564418 Test RE 0.013236185871132098\n",
      "134 Train Loss 62642.316 Test MSE 979.3352009673048 Test RE 0.013987899589991838\n",
      "135 Train Loss 62528.12 Test MSE 973.9016638100294 Test RE 0.013949041859566637\n",
      "136 Train Loss 62482.81 Test MSE 959.2695272043468 Test RE 0.013843858381887777\n",
      "137 Train Loss 62419.305 Test MSE 1110.594785292588 Test RE 0.014895827646669366\n",
      "138 Train Loss 62344.992 Test MSE 1174.3080603824153 Test RE 0.015317145739036597\n",
      "139 Train Loss 62298.6 Test MSE 1425.1667847838773 Test RE 0.016874063133924592\n",
      "140 Train Loss 62179.074 Test MSE 1483.9982938494481 Test RE 0.01721882548691748\n",
      "141 Train Loss 62073.19 Test MSE 1262.5928381173426 Test RE 0.015882486118060445\n",
      "142 Train Loss 61916.69 Test MSE 1711.9137125530708 Test RE 0.018493868232777187\n",
      "143 Train Loss 61848.6 Test MSE 1595.5437629886578 Test RE 0.017854232420312748\n",
      "144 Train Loss 61771.73 Test MSE 1504.6247670062219 Test RE 0.01733807697745196\n",
      "145 Train Loss 61709.88 Test MSE 1351.1235940623837 Test RE 0.01642987890902455\n",
      "146 Train Loss 61646.945 Test MSE 1135.2697001522656 Test RE 0.015060394463252996\n",
      "147 Train Loss 61578.945 Test MSE 1145.870711721389 Test RE 0.015130547148221825\n",
      "148 Train Loss 61524.01 Test MSE 1189.8538923642293 Test RE 0.015418198813428473\n",
      "149 Train Loss 61492.824 Test MSE 1098.9102557569079 Test RE 0.014817261206396848\n",
      "150 Train Loss 61468.785 Test MSE 1241.1555394613194 Test RE 0.015747076184927145\n",
      "151 Train Loss 61440.754 Test MSE 1007.0224059379341 Test RE 0.014184250433226124\n",
      "152 Train Loss 61395.31 Test MSE 1070.3685004552156 Test RE 0.014623572534586536\n",
      "153 Train Loss 61359.664 Test MSE 946.6795070077967 Test RE 0.013752710836028716\n",
      "154 Train Loss 61324.926 Test MSE 990.7800888113148 Test RE 0.014069396168911412\n",
      "155 Train Loss 61253.31 Test MSE 966.2655814661969 Test RE 0.013894249035419765\n",
      "156 Train Loss 61189.207 Test MSE 1039.3090253247674 Test RE 0.01440984047659028\n",
      "157 Train Loss 61134.527 Test MSE 1196.402789470815 Test RE 0.01546057109240596\n",
      "158 Train Loss 60939.43 Test MSE 838.9951390181219 Test RE 0.012946922429349358\n",
      "159 Train Loss 60798.77 Test MSE 775.3813676641008 Test RE 0.012446421490806134\n",
      "160 Train Loss 60729.85 Test MSE 737.5019615853954 Test RE 0.012138594775406375\n",
      "161 Train Loss 60593.69 Test MSE 796.837845936532 Test RE 0.012617456032733681\n",
      "162 Train Loss 60478.23 Test MSE 1386.2344180957657 Test RE 0.01664198638656083\n",
      "163 Train Loss 60383.594 Test MSE 2350.3645579782865 Test RE 0.021669776818706677\n",
      "164 Train Loss 60304.582 Test MSE 1930.3747550836508 Test RE 0.019638469489530155\n",
      "165 Train Loss 60241.25 Test MSE 2139.4889121397437 Test RE 0.02067482507181873\n",
      "166 Train Loss 60014.676 Test MSE 1710.1302857363269 Test RE 0.018484232509068464\n",
      "167 Train Loss 59968.48 Test MSE 1482.0626919419315 Test RE 0.01720759243277463\n",
      "168 Train Loss 59886.625 Test MSE 1557.81942349403 Test RE 0.017641901010350285\n",
      "169 Train Loss 59838.117 Test MSE 1714.9364469950997 Test RE 0.01851018838875046\n",
      "170 Train Loss 59779.066 Test MSE 1708.210783094041 Test RE 0.01847385596198937\n",
      "171 Train Loss 59641.016 Test MSE 1653.2202049011246 Test RE 0.01817406913726768\n",
      "172 Train Loss 59553.11 Test MSE 1301.7791240674912 Test RE 0.01612707014821076\n",
      "173 Train Loss 59477.17 Test MSE 1507.6458328064214 Test RE 0.01735547440647711\n",
      "174 Train Loss 59390.54 Test MSE 1786.7121834510326 Test RE 0.018893574179748174\n",
      "175 Train Loss 59319.734 Test MSE 1927.8674553895623 Test RE 0.0196257114673629\n",
      "176 Train Loss 59190.117 Test MSE 1954.170912661365 Test RE 0.01975914262116653\n",
      "177 Train Loss 59111.844 Test MSE 2026.8705648180157 Test RE 0.020123329180275765\n",
      "178 Train Loss 58902.71 Test MSE 1756.3688367462728 Test RE 0.018732454442423628\n",
      "179 Train Loss 58740.555 Test MSE 1725.2861131711736 Test RE 0.018565958998076306\n",
      "180 Train Loss 58648.047 Test MSE 1730.661422003315 Test RE 0.018594858596493572\n",
      "181 Train Loss 58424.36 Test MSE 1983.244221323302 Test RE 0.019905583943440913\n",
      "182 Train Loss 58296.375 Test MSE 1841.1790923497251 Test RE 0.019179392235404304\n",
      "183 Train Loss 58093.996 Test MSE 2807.5644603923806 Test RE 0.023683816730678636\n",
      "184 Train Loss 57992.555 Test MSE 2850.6665782843806 Test RE 0.02386492290143814\n",
      "185 Train Loss 57885.027 Test MSE 3104.2794552192227 Test RE 0.02490389226921876\n",
      "186 Train Loss 57698.766 Test MSE 3695.682602801002 Test RE 0.02717278524408412\n",
      "187 Train Loss 57548.43 Test MSE 3076.9078229512984 Test RE 0.024793855549306767\n",
      "188 Train Loss 57415.367 Test MSE 2260.6351703505575 Test RE 0.02125211041587996\n",
      "189 Train Loss 57349.945 Test MSE 2343.8767709408694 Test RE 0.02163984825957764\n",
      "190 Train Loss 57247.44 Test MSE 2849.5259545472986 Test RE 0.02386014794437379\n",
      "191 Train Loss 57147.96 Test MSE 1843.7090562400886 Test RE 0.01919256491168519\n",
      "192 Train Loss 57020.96 Test MSE 2328.7490089789057 Test RE 0.02156990166477677\n",
      "193 Train Loss 56937.05 Test MSE 1539.1014090986866 Test RE 0.017535592377230687\n",
      "194 Train Loss 56860.207 Test MSE 1440.3571507167649 Test RE 0.016963752213515784\n",
      "195 Train Loss 56664.96 Test MSE 808.6612333954938 Test RE 0.012710719522386832\n",
      "196 Train Loss 56607.824 Test MSE 929.3325977116353 Test RE 0.013626126269992217\n",
      "197 Train Loss 56536.15 Test MSE 899.2502234332917 Test RE 0.013403774130696194\n",
      "198 Train Loss 56341.832 Test MSE 992.4213848384466 Test RE 0.01408104481264991\n",
      "199 Train Loss 56227.984 Test MSE 1496.1796682025051 Test RE 0.01728935127102546\n",
      "Training time: 40.56\n",
      "Training time: 40.56\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "1 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "2 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "3 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "4 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "5 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "6 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "7 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "8 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "9 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "10 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "11 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "12 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "13 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "14 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "15 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "16 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "17 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "18 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "19 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "20 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "21 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "22 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "23 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "24 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "25 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "26 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "27 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "28 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "29 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "30 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "31 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "32 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "33 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "34 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "35 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "36 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "37 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "38 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "39 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "40 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "41 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "42 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "43 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "44 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "45 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "46 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "47 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "48 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "49 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "50 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "51 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "52 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "53 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "54 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "55 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "56 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "57 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "58 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "59 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "60 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "61 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "62 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "63 Train Loss 455489.06 Test MSE 4851829.974051992 Test RE 0.9845541570997214\n",
      "64 Train Loss 291762.88 Test MSE 2527438.1478030877 Test RE 0.7106030901792049\n",
      "65 Train Loss 254625.28 Test MSE 1984008.404084222 Test RE 0.6295910960045186\n",
      "66 Train Loss 171667.92 Test MSE 243969.63783128024 Test RE 0.22077745076548513\n",
      "67 Train Loss 145154.81 Test MSE 60083.24997028865 Test RE 0.1095629032075163\n",
      "68 Train Loss 123834.016 Test MSE 15608.11397589472 Test RE 0.05584213799868965\n",
      "69 Train Loss 118381.49 Test MSE 12565.980954646113 Test RE 0.05010545638255398\n",
      "70 Train Loss 117444.22 Test MSE 12040.285090936819 Test RE 0.04904618238736538\n",
      "71 Train Loss 115423.25 Test MSE 10549.991392468157 Test RE 0.04591059024914949\n",
      "72 Train Loss 114134.47 Test MSE 10477.99267706918 Test RE 0.04575366298968716\n",
      "73 Train Loss 112009.625 Test MSE 12100.968008704547 Test RE 0.04916962318480539\n",
      "74 Train Loss 110923.44 Test MSE 9443.572208200256 Test RE 0.043436515270949924\n",
      "75 Train Loss 109897.98 Test MSE 5790.470204675217 Test RE 0.03401290603493262\n",
      "76 Train Loss 108690.02 Test MSE 5203.90796171657 Test RE 0.03224420154523596\n",
      "77 Train Loss 107904.42 Test MSE 4782.667479246491 Test RE 0.030911630765673947\n",
      "78 Train Loss 107404.83 Test MSE 4150.142035704234 Test RE 0.02879508095496334\n",
      "79 Train Loss 106880.42 Test MSE 4337.994947247733 Test RE 0.029439562017716355\n",
      "80 Train Loss 106468.45 Test MSE 4927.926932025519 Test RE 0.03137754445475315\n",
      "81 Train Loss 106055.07 Test MSE 6507.305788303657 Test RE 0.036056820788269\n",
      "82 Train Loss 105557.18 Test MSE 6831.116141687016 Test RE 0.03694304238996357\n",
      "83 Train Loss 105288.71 Test MSE 8180.709517990677 Test RE 0.040428004895813704\n",
      "84 Train Loss 105038.52 Test MSE 11845.124856305165 Test RE 0.048647065198607696\n",
      "85 Train Loss 104754.24 Test MSE 11298.80500644155 Test RE 0.0475119746449172\n",
      "86 Train Loss 104295.75 Test MSE 5135.433685263116 Test RE 0.03203136058199594\n",
      "87 Train Loss 103858.94 Test MSE 4663.5092827283415 Test RE 0.03052412662091119\n",
      "88 Train Loss 103678.36 Test MSE 4215.185799686589 Test RE 0.02901985144395799\n",
      "89 Train Loss 103582.08 Test MSE 3832.118284792498 Test RE 0.027669816345186064\n",
      "90 Train Loss 103450.86 Test MSE 4067.0896292857246 Test RE 0.02850550211325908\n",
      "91 Train Loss 103227.695 Test MSE 4344.823074342823 Test RE 0.029462722260417688\n",
      "92 Train Loss 103107.98 Test MSE 3867.9035797195675 Test RE 0.02779871002421777\n",
      "93 Train Loss 102995.984 Test MSE 4123.120430431743 Test RE 0.028701185374881505\n",
      "94 Train Loss 102906.09 Test MSE 4773.866811918984 Test RE 0.030883177162836402\n",
      "95 Train Loss 102190.08 Test MSE 5551.3612797068 Test RE 0.03330324632486839\n",
      "96 Train Loss 102009.27 Test MSE 5802.456997619272 Test RE 0.03404809271830589\n",
      "97 Train Loss 101768.73 Test MSE 7441.285023619358 Test RE 0.0385576710136541\n",
      "98 Train Loss 101510.18 Test MSE 7684.5878346378695 Test RE 0.039182948478455666\n",
      "99 Train Loss 101292.66 Test MSE 6903.3497903784855 Test RE 0.0371378504815481\n",
      "100 Train Loss 100903.32 Test MSE 6202.3200273578095 Test RE 0.03520172203385539\n",
      "101 Train Loss 100606.445 Test MSE 4919.135692151703 Test RE 0.031349543770178394\n",
      "102 Train Loss 100058.13 Test MSE 4576.373885122908 Test RE 0.030237617777750674\n",
      "103 Train Loss 99715.04 Test MSE 4830.058322825344 Test RE 0.031064402956778203\n",
      "104 Train Loss 99347.35 Test MSE 3977.649646975238 Test RE 0.028190325304265094\n",
      "105 Train Loss 99086.02 Test MSE 4662.055217886115 Test RE 0.030519367595368007\n",
      "106 Train Loss 98899.55 Test MSE 5385.649225826683 Test RE 0.032802417778589416\n",
      "107 Train Loss 98803.19 Test MSE 5700.202516968706 Test RE 0.033746750951006675\n",
      "108 Train Loss 98311.5 Test MSE 4214.963117353977 Test RE 0.029019084894881832\n",
      "109 Train Loss 98117.64 Test MSE 4640.656897590677 Test RE 0.030449246772122147\n",
      "110 Train Loss 97957.37 Test MSE 3731.5730385336533 Test RE 0.027304410018018446\n",
      "111 Train Loss 97789.28 Test MSE 4102.9495188175515 Test RE 0.028630894090403553\n",
      "112 Train Loss 97539.266 Test MSE 3973.0273709436774 Test RE 0.028173941088241117\n",
      "113 Train Loss 97448.44 Test MSE 3796.801241103302 Test RE 0.02754201782795646\n",
      "114 Train Loss 97056.02 Test MSE 5661.1262716657275 Test RE 0.033630881024591074\n",
      "115 Train Loss 96996.35 Test MSE 6117.489849435504 Test RE 0.03496016328319474\n",
      "116 Train Loss 96609.3 Test MSE 4510.871759845595 Test RE 0.030020440740680717\n",
      "117 Train Loss 96478.24 Test MSE 4014.4921809088014 Test RE 0.02832057924773407\n",
      "118 Train Loss 96026.0 Test MSE 4157.255979204849 Test RE 0.02881974985403244\n",
      "119 Train Loss 95777.05 Test MSE 4963.474602957261 Test RE 0.031490512278416316\n",
      "120 Train Loss 95528.18 Test MSE 5793.456391482159 Test RE 0.03402167525367502\n",
      "121 Train Loss 95272.69 Test MSE 4045.391077508654 Test RE 0.028429359789897628\n",
      "122 Train Loss 95155.164 Test MSE 4798.793505587825 Test RE 0.030963700273988426\n",
      "123 Train Loss 94931.71 Test MSE 3154.577772982539 Test RE 0.025104839150225846\n",
      "124 Train Loss 94796.055 Test MSE 3058.7829815721834 Test RE 0.024720722314912697\n",
      "125 Train Loss 94717.055 Test MSE 2474.681769150992 Test RE 0.022235479695702692\n",
      "126 Train Loss 94643.03 Test MSE 2452.9771626530655 Test RE 0.02213775496657316\n",
      "127 Train Loss 94454.83 Test MSE 2165.7498146110556 Test RE 0.020801323425495878\n",
      "128 Train Loss 94284.87 Test MSE 2218.003742258816 Test RE 0.02105076877606071\n",
      "129 Train Loss 94188.0 Test MSE 2267.7739872512166 Test RE 0.021285639784378568\n",
      "130 Train Loss 94077.13 Test MSE 2275.789015180403 Test RE 0.0213232216865355\n",
      "131 Train Loss 93684.35 Test MSE 2619.787602808753 Test RE 0.02287809531314739\n",
      "132 Train Loss 93232.945 Test MSE 3723.3990777393014 Test RE 0.027274488651107594\n",
      "133 Train Loss 93102.92 Test MSE 3394.212742932854 Test RE 0.026040921804495392\n",
      "134 Train Loss 92989.805 Test MSE 3992.70837819238 Test RE 0.028243636875946915\n",
      "135 Train Loss 92719.54 Test MSE 4826.860450871275 Test RE 0.031054117736137282\n",
      "136 Train Loss 92504.766 Test MSE 3619.839723627773 Test RE 0.02689251963958231\n",
      "137 Train Loss 92322.39 Test MSE 3199.1486340653864 Test RE 0.025281569552793683\n",
      "138 Train Loss 92179.805 Test MSE 2391.5213503372556 Test RE 0.021858681136624824\n",
      "139 Train Loss 92120.516 Test MSE 2593.014217145143 Test RE 0.02276089171500458\n",
      "140 Train Loss 92010.54 Test MSE 3109.509992899392 Test RE 0.02492486427325881\n",
      "141 Train Loss 91929.08 Test MSE 3660.424321230817 Test RE 0.0270428550168307\n",
      "142 Train Loss 91847.42 Test MSE 3409.7620288700914 Test RE 0.026100501902319044\n",
      "143 Train Loss 91763.86 Test MSE 2783.7460516448546 Test RE 0.02358314008226604\n",
      "144 Train Loss 91669.04 Test MSE 3089.5387831900994 Test RE 0.024844693839276802\n",
      "145 Train Loss 91375.05 Test MSE 3605.6077505889693 Test RE 0.02683960147475812\n",
      "146 Train Loss 91239.47 Test MSE 4295.106739558585 Test RE 0.029293671308755133\n",
      "147 Train Loss 91200.02 Test MSE 3820.328960947354 Test RE 0.02762722114338234\n",
      "148 Train Loss 91035.66 Test MSE 3023.7806194160357 Test RE 0.024578872867551116\n",
      "149 Train Loss 90892.664 Test MSE 3516.1094281069995 Test RE 0.026504402305558988\n",
      "150 Train Loss 90831.875 Test MSE 3958.1471889859317 Test RE 0.02812113165525131\n",
      "151 Train Loss 90726.34 Test MSE 4613.472488841076 Test RE 0.030359931772169328\n",
      "152 Train Loss 90505.38 Test MSE 4280.951033182105 Test RE 0.02924535879104364\n",
      "153 Train Loss 90345.22 Test MSE 4318.4994786288125 Test RE 0.02937333506792591\n",
      "154 Train Loss 90133.44 Test MSE 3849.6809310994445 Test RE 0.0277331494222614\n",
      "155 Train Loss 90052.47 Test MSE 4685.485803499688 Test RE 0.030595963688820494\n",
      "156 Train Loss 89819.9 Test MSE 4355.351542035881 Test RE 0.029498398008580354\n",
      "157 Train Loss 89563.04 Test MSE 5226.829645156092 Test RE 0.03231513662935959\n",
      "158 Train Loss 89429.27 Test MSE 3342.9424952114828 Test RE 0.02584349682191224\n",
      "159 Train Loss 89265.22 Test MSE 3324.8416732770265 Test RE 0.025773435269654463\n",
      "160 Train Loss 89131.19 Test MSE 2636.2689121688636 Test RE 0.022949946518446056\n",
      "161 Train Loss 88700.54 Test MSE 1528.1025801106168 Test RE 0.017472823025507383\n",
      "162 Train Loss 88360.47 Test MSE 1551.5596559264548 Test RE 0.01760642020921406\n",
      "163 Train Loss 88127.33 Test MSE 1661.9229155515216 Test RE 0.018221841376995163\n",
      "164 Train Loss 87946.29 Test MSE 1686.5689522264931 Test RE 0.018356457547867876\n",
      "165 Train Loss 87805.445 Test MSE 1657.4203048857612 Test RE 0.01819714062125468\n",
      "166 Train Loss 87732.336 Test MSE 1620.8625260862584 Test RE 0.017995334112986344\n",
      "167 Train Loss 87687.96 Test MSE 1707.4350879501733 Test RE 0.018469661014947455\n",
      "168 Train Loss 87485.36 Test MSE 1741.2064917611574 Test RE 0.018651422605996035\n",
      "169 Train Loss 87255.38 Test MSE 1811.9082863172657 Test RE 0.01902632580198037\n",
      "170 Train Loss 87116.31 Test MSE 2059.708174666256 Test RE 0.020285684653594687\n",
      "171 Train Loss 86994.125 Test MSE 2001.2066170258722 Test RE 0.01999552395772525\n",
      "172 Train Loss 86905.26 Test MSE 1991.819615374963 Test RE 0.01994857262347687\n",
      "173 Train Loss 86828.016 Test MSE 2428.1820524892955 Test RE 0.02202558469226717\n",
      "174 Train Loss 86704.06 Test MSE 2284.6943400037057 Test RE 0.02136490059727985\n",
      "175 Train Loss 86579.01 Test MSE 2788.0728058806994 Test RE 0.023601460509264295\n",
      "176 Train Loss 86508.28 Test MSE 3197.4737629935853 Test RE 0.025274950774196028\n",
      "177 Train Loss 86420.9 Test MSE 3039.5812139057316 Test RE 0.02464300694900158\n",
      "178 Train Loss 86317.34 Test MSE 2060.7427326814504 Test RE 0.02029077859924432\n",
      "179 Train Loss 86289.31 Test MSE 2025.470201485797 Test RE 0.020116376382732108\n",
      "180 Train Loss 86264.555 Test MSE 1754.4232040865277 Test RE 0.018722076048812323\n",
      "181 Train Loss 86243.195 Test MSE 1741.9804071227848 Test RE 0.01865556715144591\n",
      "182 Train Loss 86158.76 Test MSE 1672.4709737174287 Test RE 0.01827957601330382\n",
      "183 Train Loss 86038.016 Test MSE 1699.949881398803 Test RE 0.018429132072158346\n",
      "184 Train Loss 85915.1 Test MSE 1746.2054663991087 Test RE 0.018678177377393707\n",
      "185 Train Loss 85821.08 Test MSE 1673.398718592226 Test RE 0.018284645288662013\n",
      "186 Train Loss 85775.29 Test MSE 1718.137930845355 Test RE 0.018527457961059323\n",
      "187 Train Loss 85706.625 Test MSE 1801.4861286333914 Test RE 0.01897152685254571\n",
      "188 Train Loss 85671.95 Test MSE 1918.0053080988675 Test RE 0.01957544872141476\n",
      "189 Train Loss 85660.54 Test MSE 2063.8396329752622 Test RE 0.020306019445755205\n",
      "190 Train Loss 85632.68 Test MSE 2272.3286650786363 Test RE 0.02130700447986104\n",
      "191 Train Loss 85587.6 Test MSE 2330.587228428679 Test RE 0.021578413185584445\n",
      "192 Train Loss 85554.445 Test MSE 2294.637866836059 Test RE 0.02141134265528414\n",
      "193 Train Loss 85519.13 Test MSE 2164.920421649852 Test RE 0.0207973400191072\n",
      "194 Train Loss 85484.414 Test MSE 2364.837618852088 Test RE 0.02173639343455002\n",
      "195 Train Loss 85427.85 Test MSE 2685.788427008128 Test RE 0.023164488917324984\n",
      "196 Train Loss 85340.53 Test MSE 2065.2579489246164 Test RE 0.020312995618813577\n",
      "197 Train Loss 85299.3 Test MSE 1753.4348356193289 Test RE 0.018716801689570944\n",
      "198 Train Loss 85261.61 Test MSE 1782.496436679358 Test RE 0.018871271325251248\n",
      "199 Train Loss 85193.61 Test MSE 1611.3479509834788 Test RE 0.017942439447134022\n",
      "Training time: 33.49\n",
      "Training time: 33.49\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 455636.88 Test MSE 4839659.507666974 Test RE 0.9833185401185044\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 46.93\n",
      "Training time: 46.93\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 456974.84 Test MSE 4822998.191944189 Test RE 0.9816244637516713\n",
      "1 Train Loss 426061.56 Test MSE 2621323.0883368566 Test RE 0.7236808825309529\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 47.26\n",
      "Training time: 47.26\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 457466.75 Test MSE 4964194.440087171 Test RE 0.9958896423722354\n",
      "1 Train Loss 449205.78 Test MSE 4215330.142620806 Test RE 0.9177039915449887\n",
      "2 Train Loss 294699.03 Test MSE 2474950.097166432 Test RE 0.7031857269170927\n",
      "3 Train Loss 285806.25 Test MSE 2354783.196046863 Test RE 0.6859023449951666\n",
      "4 Train Loss 268953.38 Test MSE 1729355.5154907973 Test RE 0.5877991657201259\n",
      "5 Train Loss 242634.5 Test MSE 1185430.0095103043 Test RE 0.48665902570246383\n",
      "6 Train Loss 174391.78 Test MSE 514358.3333415674 Test RE 0.3205676650201829\n",
      "7 Train Loss 153974.64 Test MSE 190273.3244017959 Test RE 0.19497358479076068\n",
      "8 Train Loss 143766.86 Test MSE 41611.77463553692 Test RE 0.09117902471662126\n",
      "9 Train Loss 134878.12 Test MSE 29574.84946212477 Test RE 0.0768684448864933\n",
      "10 Train Loss 133012.19 Test MSE 39908.43657994356 Test RE 0.08929336322579662\n",
      "11 Train Loss 130216.18 Test MSE 26405.344940701347 Test RE 0.07263279325567693\n",
      "12 Train Loss 127152.75 Test MSE 24703.534482694457 Test RE 0.0702532420794482\n",
      "13 Train Loss 125553.74 Test MSE 21635.232729050527 Test RE 0.06574573868979153\n",
      "14 Train Loss 123894.98 Test MSE 7851.304332009059 Test RE 0.03960570328675053\n",
      "15 Train Loss 122225.66 Test MSE 7472.417227118131 Test RE 0.03863824394959082\n",
      "16 Train Loss 121796.84 Test MSE 10576.563753742314 Test RE 0.045968371603386515\n",
      "17 Train Loss 121609.77 Test MSE 10534.02742695519 Test RE 0.04587584175889032\n",
      "18 Train Loss 121419.56 Test MSE 9036.816371280453 Test RE 0.04249076521855077\n",
      "19 Train Loss 121130.45 Test MSE 7028.62525373774 Test RE 0.0374733067326027\n",
      "20 Train Loss 120859.66 Test MSE 7858.388039305228 Test RE 0.03962356604843047\n",
      "21 Train Loss 120356.7 Test MSE 5276.996379593385 Test RE 0.03246984547159653\n",
      "22 Train Loss 119937.76 Test MSE 3176.966335373089 Test RE 0.02519376824957198\n",
      "23 Train Loss 119716.62 Test MSE 1867.644512178622 Test RE 0.019316744330625937\n",
      "24 Train Loss 119516.234 Test MSE 2391.3384753050736 Test RE 0.021857845375021192\n",
      "25 Train Loss 119420.305 Test MSE 2117.762565697839 Test RE 0.0205695815706086\n",
      "26 Train Loss 119312.11 Test MSE 2597.471587335804 Test RE 0.022780446208280732\n",
      "27 Train Loss 119256.76 Test MSE 2656.0603801513894 Test RE 0.023035932403120823\n",
      "28 Train Loss 119187.59 Test MSE 3251.0695469253883 Test RE 0.02548589876489824\n",
      "29 Train Loss 119061.24 Test MSE 4585.524659852437 Test RE 0.030267833780060566\n",
      "30 Train Loss 119013.45 Test MSE 5604.361777938242 Test RE 0.03346184667481255\n",
      "31 Train Loss 118895.78 Test MSE 5438.839823076981 Test RE 0.032964003990856326\n",
      "32 Train Loss 118807.16 Test MSE 8972.658717843138 Test RE 0.042339663133009305\n",
      "33 Train Loss 118732.85 Test MSE 11066.755034211952 Test RE 0.04702155337010136\n",
      "34 Train Loss 118579.33 Test MSE 8574.618508466485 Test RE 0.04138988570917833\n",
      "35 Train Loss 118342.84 Test MSE 8955.581300355441 Test RE 0.042299351978004655\n",
      "36 Train Loss 118306.56 Test MSE 6227.946512810884 Test RE 0.03527436956918701\n",
      "37 Train Loss 118281.72 Test MSE 4898.386529264746 Test RE 0.03128335692178235\n",
      "38 Train Loss 118044.16 Test MSE 3761.9826845170423 Test RE 0.02741543996017713\n",
      "39 Train Loss 117726.164 Test MSE 6177.397173329033 Test RE 0.03513092509860907\n",
      "40 Train Loss 117498.805 Test MSE 5852.357259261049 Test RE 0.03419418355132822\n",
      "41 Train Loss 117136.69 Test MSE 5217.917145624355 Test RE 0.03228757388688406\n",
      "42 Train Loss 116977.03 Test MSE 4694.413267195277 Test RE 0.030625097740422193\n",
      "43 Train Loss 116936.37 Test MSE 3267.360037656131 Test RE 0.02554967147051991\n",
      "44 Train Loss 116781.82 Test MSE 5109.0389905620505 Test RE 0.03194893841567527\n",
      "45 Train Loss 116621.64 Test MSE 5984.335248524776 Test RE 0.03457759484364483\n",
      "46 Train Loss 116568.586 Test MSE 6514.75574329728 Test RE 0.036077454892553804\n",
      "47 Train Loss 116504.555 Test MSE 5686.400601791005 Test RE 0.03370587064219167\n",
      "48 Train Loss 116359.086 Test MSE 5472.3076794921835 Test RE 0.03306527030903095\n",
      "49 Train Loss 115999.555 Test MSE 4147.422217277698 Test RE 0.028785643901154\n",
      "50 Train Loss 115944.72 Test MSE 3444.7236450739047 Test RE 0.026233969948385467\n",
      "51 Train Loss 115933.96 Test MSE 3353.335439136708 Test RE 0.025883638341139884\n",
      "52 Train Loss 115801.04 Test MSE 3349.197177821602 Test RE 0.02586766225881937\n",
      "53 Train Loss 115550.12 Test MSE 2336.161719831249 Test RE 0.021604204289669332\n",
      "54 Train Loss 115456.06 Test MSE 2645.4278790903195 Test RE 0.022989778484822695\n",
      "55 Train Loss 115405.24 Test MSE 2501.48151275818 Test RE 0.022355555838440688\n",
      "56 Train Loss 115329.82 Test MSE 2386.2847762443935 Test RE 0.02183473668571487\n",
      "57 Train Loss 115325.11 Test MSE 2655.8698469242395 Test RE 0.023035106143806407\n",
      "58 Train Loss 115177.984 Test MSE 2244.4146680796457 Test RE 0.021175729119042856\n",
      "59 Train Loss 115102.234 Test MSE 1981.5198535070372 Test RE 0.019896928425321106\n",
      "60 Train Loss 115084.11 Test MSE 1890.1203435099662 Test RE 0.019432628665388575\n",
      "61 Train Loss 115071.15 Test MSE 1887.3751817737113 Test RE 0.01941851181500133\n",
      "62 Train Loss 115032.07 Test MSE 1853.4064293365166 Test RE 0.019242972369568217\n",
      "63 Train Loss 115002.266 Test MSE 2734.6477756946724 Test RE 0.023374241246226557\n",
      "64 Train Loss 114697.84 Test MSE 3075.8913502499854 Test RE 0.024789759820648877\n",
      "65 Train Loss 114206.06 Test MSE 3881.043176198759 Test RE 0.027845887279618557\n",
      "66 Train Loss 114017.625 Test MSE 3462.208401563358 Test RE 0.02630046497594434\n",
      "67 Train Loss 113970.88 Test MSE 3455.690355259335 Test RE 0.02627569633289238\n",
      "68 Train Loss 113804.875 Test MSE 4923.0386060358505 Test RE 0.031361977896562275\n",
      "69 Train Loss 113700.57 Test MSE 4634.643389319554 Test RE 0.03042951183386897\n",
      "70 Train Loss 113622.25 Test MSE 3573.379071679641 Test RE 0.026719379503290886\n",
      "71 Train Loss 113548.914 Test MSE 4240.096443536971 Test RE 0.029105474987073263\n",
      "72 Train Loss 113477.734 Test MSE 3484.6255334591774 Test RE 0.02638547281565089\n",
      "73 Train Loss 113311.63 Test MSE 3836.931650796569 Test RE 0.02768718835038668\n",
      "74 Train Loss 113011.32 Test MSE 3679.359352207954 Test RE 0.027112709868857977\n",
      "75 Train Loss 112849.06 Test MSE 4711.438094663909 Test RE 0.03068058019514127\n",
      "76 Train Loss 112629.83 Test MSE 7221.000688695893 Test RE 0.037982672323227176\n",
      "77 Train Loss 112397.72 Test MSE 6536.7584096470955 Test RE 0.03613832679063022\n",
      "78 Train Loss 112289.805 Test MSE 6798.154405563853 Test RE 0.03685380519398934\n",
      "79 Train Loss 111832.26 Test MSE 3093.434551300467 Test RE 0.024860352919854358\n",
      "80 Train Loss 111651.17 Test MSE 2081.494007464127 Test RE 0.020392684776698828\n",
      "81 Train Loss 111242.52 Test MSE 2267.806244147672 Test RE 0.021285791167682373\n",
      "82 Train Loss 110874.84 Test MSE 2156.2796646192137 Test RE 0.020755794743131953\n",
      "83 Train Loss 110623.11 Test MSE 2677.951249364996 Test RE 0.023130667034016932\n",
      "84 Train Loss 110304.516 Test MSE 1986.6519949347758 Test RE 0.0199226783104859\n",
      "85 Train Loss 110123.98 Test MSE 2473.188243752668 Test RE 0.02222876888014924\n",
      "86 Train Loss 109856.12 Test MSE 2845.041650296545 Test RE 0.023841366172821652\n",
      "87 Train Loss 109436.14 Test MSE 2491.7878038237304 Test RE 0.022312197811548664\n",
      "88 Train Loss 109323.2 Test MSE 3811.5910061183604 Test RE 0.027595608210552944\n",
      "89 Train Loss 109105.555 Test MSE 3465.3647187238985 Test RE 0.026312450634857144\n",
      "90 Train Loss 108969.9 Test MSE 3584.72282333724 Test RE 0.026761756457021203\n",
      "91 Train Loss 108628.336 Test MSE 2492.117501307595 Test RE 0.022313673866642292\n",
      "92 Train Loss 108217.53 Test MSE 2836.4805180252665 Test RE 0.023805468127349558\n",
      "93 Train Loss 107883.39 Test MSE 3210.570113386669 Test RE 0.025326658995673837\n",
      "94 Train Loss 107533.664 Test MSE 3735.9474329628424 Test RE 0.02732040933980841\n",
      "95 Train Loss 107272.56 Test MSE 2840.6699820517642 Test RE 0.02382304190459728\n",
      "96 Train Loss 107193.86 Test MSE 2994.869164871194 Test RE 0.02446108691902524\n",
      "97 Train Loss 107108.3 Test MSE 3081.5022229981246 Test RE 0.024812359580958527\n",
      "98 Train Loss 106979.13 Test MSE 2772.3418799559668 Test RE 0.023534783984571952\n",
      "99 Train Loss 106931.95 Test MSE 2863.5188486267334 Test RE 0.023918660071052183\n",
      "100 Train Loss 106907.51 Test MSE 2871.177115393024 Test RE 0.023950623047448508\n",
      "101 Train Loss 106863.45 Test MSE 2855.280944663443 Test RE 0.023884230134946435\n",
      "102 Train Loss 106782.98 Test MSE 2933.4992672431713 Test RE 0.02420916529383548\n",
      "103 Train Loss 106713.52 Test MSE 2880.537759401015 Test RE 0.023989633323553198\n",
      "104 Train Loss 106646.484 Test MSE 2908.1863699065248 Test RE 0.024104489657009905\n",
      "105 Train Loss 106624.484 Test MSE 3275.537590574396 Test RE 0.025581624365439357\n",
      "106 Train Loss 106612.336 Test MSE 3330.663374300781 Test RE 0.0257959896685497\n",
      "107 Train Loss 106602.14 Test MSE 3440.8158114683033 Test RE 0.02621908528831125\n",
      "108 Train Loss 106600.22 Test MSE 3408.732725320371 Test RE 0.026096562130746497\n",
      "109 Train Loss 106589.47 Test MSE 3385.7717125756653 Test RE 0.02600852120670164\n",
      "110 Train Loss 106571.4 Test MSE 3229.9270925674505 Test RE 0.025402893257795787\n",
      "111 Train Loss 106513.31 Test MSE 3662.1459015493137 Test RE 0.027049213702329607\n",
      "112 Train Loss 106484.62 Test MSE 3654.5789374535143 Test RE 0.027021253829240144\n",
      "113 Train Loss 106467.04 Test MSE 3939.225389593242 Test RE 0.02805383503441347\n",
      "114 Train Loss 106439.51 Test MSE 3159.3146792464595 Test RE 0.025123680762264754\n",
      "115 Train Loss 106421.484 Test MSE 3115.26221804089 Test RE 0.024947907644487833\n",
      "116 Train Loss 106414.336 Test MSE 3076.806358848543 Test RE 0.024793446744884994\n",
      "117 Train Loss 106405.51 Test MSE 2922.621082477567 Test RE 0.02416423663574412\n",
      "118 Train Loss 106381.234 Test MSE 2539.04769839086 Test RE 0.022522793418054386\n",
      "119 Train Loss 106331.39 Test MSE 2641.931594349285 Test RE 0.022974581437165804\n",
      "120 Train Loss 106275.49 Test MSE 2577.268766298891 Test RE 0.02269168148813264\n",
      "121 Train Loss 106187.55 Test MSE 2447.8040467414 Test RE 0.022114399344522424\n",
      "122 Train Loss 106163.22 Test MSE 2454.298825742306 Test RE 0.022143718070100397\n",
      "123 Train Loss 106139.94 Test MSE 2459.375366558761 Test RE 0.02216660758495227\n",
      "124 Train Loss 106127.95 Test MSE 2449.1892439731905 Test RE 0.02212065566072805\n",
      "125 Train Loss 106113.586 Test MSE 2473.279672467379 Test RE 0.022229179752429353\n",
      "126 Train Loss 106100.12 Test MSE 2502.8737548565596 Test RE 0.022361776155544945\n",
      "127 Train Loss 106091.84 Test MSE 2565.7142921258614 Test RE 0.022640758399248062\n",
      "128 Train Loss 106026.164 Test MSE 2306.430181145189 Test RE 0.021466289391453442\n",
      "129 Train Loss 105944.75 Test MSE 2693.4138940291464 Test RE 0.02319734981647025\n",
      "130 Train Loss 105887.445 Test MSE 2738.7115654843406 Test RE 0.023391602301097752\n",
      "131 Train Loss 105881.22 Test MSE 2624.064082618942 Test RE 0.022896760532067333\n",
      "132 Train Loss 105873.3 Test MSE 2536.9364365794786 Test RE 0.022513427425689122\n",
      "133 Train Loss 105862.5 Test MSE 2385.451861665351 Test RE 0.021830925728628874\n",
      "134 Train Loss 105802.42 Test MSE 2422.9409691928477 Test RE 0.022001801409078325\n",
      "135 Train Loss 105789.555 Test MSE 2528.94524398688 Test RE 0.022477941508282244\n",
      "136 Train Loss 105777.664 Test MSE 2430.552811984497 Test RE 0.022036334426741213\n",
      "137 Train Loss 105746.69 Test MSE 2562.2235122702773 Test RE 0.022625351227012605\n",
      "138 Train Loss 105711.18 Test MSE 2928.0465891706067 Test RE 0.02418665528596105\n",
      "139 Train Loss 105680.17 Test MSE 3167.302817635381 Test RE 0.02515542257341332\n",
      "140 Train Loss 105613.77 Test MSE 3008.066722836635 Test RE 0.024514924286268298\n",
      "141 Train Loss 105497.47 Test MSE 2986.923151133301 Test RE 0.024428615178503393\n",
      "142 Train Loss 105392.336 Test MSE 3867.086836003781 Test RE 0.02779577489153671\n",
      "143 Train Loss 105293.91 Test MSE 3677.627388789007 Test RE 0.027106327813644086\n",
      "144 Train Loss 105089.78 Test MSE 3504.841648701911 Test RE 0.0264619000157535\n",
      "145 Train Loss 104958.66 Test MSE 4400.109051372775 Test RE 0.029649579858958806\n",
      "146 Train Loss 104905.97 Test MSE 4471.743061237689 Test RE 0.029889953853464938\n",
      "147 Train Loss 104850.234 Test MSE 3968.8754599335693 Test RE 0.0281592160106272\n",
      "148 Train Loss 104793.83 Test MSE 3184.136753850361 Test RE 0.02522218341445188\n",
      "149 Train Loss 104617.76 Test MSE 3770.849057361163 Test RE 0.02744772778272277\n",
      "150 Train Loss 104306.086 Test MSE 2285.7194882142007 Test RE 0.021369693302564347\n",
      "151 Train Loss 104116.84 Test MSE 3284.079422603848 Test RE 0.025614958079300434\n",
      "152 Train Loss 103926.11 Test MSE 3562.9781393924804 Test RE 0.026680465499231403\n",
      "153 Train Loss 103742.29 Test MSE 4448.258488111179 Test RE 0.029811362927130707\n",
      "154 Train Loss 103598.59 Test MSE 3591.916050113558 Test RE 0.02678859352622022\n",
      "155 Train Loss 103449.49 Test MSE 4644.396302548261 Test RE 0.030461512183980154\n",
      "156 Train Loss 103395.08 Test MSE 4745.098226372268 Test RE 0.030789981443362348\n",
      "157 Train Loss 103328.93 Test MSE 3717.712326360237 Test RE 0.02725365251451396\n",
      "158 Train Loss 103260.03 Test MSE 4525.933015326378 Test RE 0.03007051628767453\n",
      "159 Train Loss 103180.31 Test MSE 3375.8729997433365 Test RE 0.02597047384966475\n",
      "160 Train Loss 102957.516 Test MSE 3943.4201810580803 Test RE 0.028068768005252542\n",
      "161 Train Loss 102864.36 Test MSE 3907.0644568074777 Test RE 0.027939080672957917\n",
      "162 Train Loss 102804.086 Test MSE 4100.195791485666 Test RE 0.02862128455115896\n",
      "163 Train Loss 102735.016 Test MSE 3481.640906782216 Test RE 0.026374170646266445\n",
      "164 Train Loss 102686.516 Test MSE 4152.374353281966 Test RE 0.02880282419884357\n",
      "165 Train Loss 102673.914 Test MSE 4393.423076804486 Test RE 0.02962704499709766\n",
      "166 Train Loss 102667.875 Test MSE 4120.230092520741 Test RE 0.028691123739659867\n",
      "167 Train Loss 102610.55 Test MSE 3499.1885809247897 Test RE 0.026440550794026598\n",
      "168 Train Loss 102455.17 Test MSE 4125.688384544165 Test RE 0.028710121792806787\n",
      "169 Train Loss 102207.38 Test MSE 5144.069413764921 Test RE 0.03205828118498607\n",
      "170 Train Loss 101934.164 Test MSE 5398.6269134882305 Test RE 0.03284191565278335\n",
      "171 Train Loss 101446.87 Test MSE 4197.828633230901 Test RE 0.02896004126962372\n",
      "172 Train Loss 100891.96 Test MSE 3269.8154338082395 Test RE 0.025559269859216475\n",
      "173 Train Loss 100186.555 Test MSE 3075.6491693441294 Test RE 0.024788783888149302\n",
      "174 Train Loss 99990.3 Test MSE 2585.0000848180043 Test RE 0.02272569137631764\n",
      "175 Train Loss 99300.24 Test MSE 2334.503470438341 Test RE 0.02159653540315018\n",
      "176 Train Loss 98932.875 Test MSE 3186.0546850948117 Test RE 0.025229778429223738\n",
      "177 Train Loss 98887.945 Test MSE 3547.526222142111 Test RE 0.026622548740044587\n",
      "178 Train Loss 98682.01 Test MSE 5834.37196907419 Test RE 0.03414160084763698\n",
      "179 Train Loss 98389.32 Test MSE 3704.8721601810157 Test RE 0.027206547726036676\n",
      "180 Train Loss 98103.51 Test MSE 2264.8042005537977 Test RE 0.02127169780440863\n",
      "181 Train Loss 97966.03 Test MSE 2382.293188542782 Test RE 0.021816467335717883\n",
      "182 Train Loss 97862.65 Test MSE 2180.8339212726173 Test RE 0.020873636703531602\n",
      "183 Train Loss 97710.63 Test MSE 1975.4116020736217 Test RE 0.01986623752722888\n",
      "184 Train Loss 97466.49 Test MSE 1978.9177945661158 Test RE 0.01988386017667948\n",
      "185 Train Loss 97334.09 Test MSE 2176.740052020663 Test RE 0.020854035467522982\n",
      "186 Train Loss 97068.36 Test MSE 2285.667709792066 Test RE 0.021369451257275587\n",
      "187 Train Loss 96996.85 Test MSE 1928.904483154426 Test RE 0.0196309892346213\n",
      "188 Train Loss 96977.71 Test MSE 1910.726925840027 Test RE 0.01953827128961655\n",
      "189 Train Loss 96925.586 Test MSE 2234.733592077378 Test RE 0.021130009985611913\n",
      "190 Train Loss 96533.04 Test MSE 2061.641631181947 Test RE 0.02029520354797627\n",
      "191 Train Loss 96255.586 Test MSE 1738.3539249824576 Test RE 0.018636138308174642\n",
      "192 Train Loss 95860.22 Test MSE 1784.235836747083 Test RE 0.018880476585380515\n",
      "193 Train Loss 95806.914 Test MSE 1656.3823312054162 Test RE 0.01819144167117243\n",
      "194 Train Loss 95773.664 Test MSE 1836.8685859544896 Test RE 0.019156928006448196\n",
      "195 Train Loss 95633.81 Test MSE 1735.4532569452274 Test RE 0.018620583414789407\n",
      "196 Train Loss 95521.695 Test MSE 1670.4715615464816 Test RE 0.01826864627606841\n",
      "197 Train Loss 95234.914 Test MSE 1831.985663391023 Test RE 0.019131448762939048\n",
      "198 Train Loss 94791.06 Test MSE 1887.2789775736749 Test RE 0.019418016903809406\n",
      "199 Train Loss 94412.52 Test MSE 2154.603688612914 Test RE 0.0207477269176529\n",
      "Training time: 40.93\n",
      "Training time: 40.93\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 457660.4 Test MSE 4996599.918442167 Test RE 0.9991348601767474\n",
      "1 Train Loss 456956.44 Test MSE 4898129.892246831 Test RE 0.9892406920449517\n",
      "2 Train Loss 385668.8 Test MSE 3493182.612132039 Test RE 0.8354057661169926\n",
      "3 Train Loss 302374.88 Test MSE 3883862.5263173156 Test RE 0.8808840537892937\n",
      "4 Train Loss 211148.11 Test MSE 2515499.301796585 Test RE 0.7089227674969206\n",
      "5 Train Loss 152286.0 Test MSE 468048.9121527667 Test RE 0.30579645308363546\n",
      "6 Train Loss 141805.55 Test MSE 446679.0553914037 Test RE 0.2987339753277045\n",
      "7 Train Loss 129524.766 Test MSE 176227.07574728294 Test RE 0.18763901350973874\n",
      "8 Train Loss 123351.15 Test MSE 73143.04144840947 Test RE 0.1208852550993216\n",
      "9 Train Loss 117691.74 Test MSE 46543.19807675116 Test RE 0.09643061449402303\n",
      "10 Train Loss 114457.6 Test MSE 21094.77257021326 Test RE 0.06491936263927543\n",
      "11 Train Loss 111249.97 Test MSE 11468.499846962144 Test RE 0.04786743213369036\n",
      "12 Train Loss 110320.42 Test MSE 13218.780117506143 Test RE 0.0513904609256259\n",
      "13 Train Loss 109416.34 Test MSE 7761.069102522149 Test RE 0.03937745091384717\n",
      "14 Train Loss 107673.96 Test MSE 7816.842528013118 Test RE 0.03951868685313829\n",
      "15 Train Loss 106428.03 Test MSE 4102.083727614608 Test RE 0.028627873131462794\n",
      "16 Train Loss 105230.77 Test MSE 7637.701739563975 Test RE 0.0390632318258265\n",
      "17 Train Loss 103809.48 Test MSE 6753.120719976709 Test RE 0.036731535215615084\n",
      "18 Train Loss 102464.84 Test MSE 5071.536424282843 Test RE 0.03183146289270432\n",
      "19 Train Loss 101434.78 Test MSE 4359.517065378341 Test RE 0.029512500991789786\n",
      "20 Train Loss 100900.19 Test MSE 4372.2231257617395 Test RE 0.029555477631267448\n",
      "21 Train Loss 100262.164 Test MSE 5410.251994696486 Test RE 0.03287725654896724\n",
      "22 Train Loss 98789.56 Test MSE 5936.619920137876 Test RE 0.03443946895494452\n",
      "23 Train Loss 97829.81 Test MSE 5132.386455391888 Test RE 0.03202185589277203\n",
      "24 Train Loss 96986.92 Test MSE 3508.174138781652 Test RE 0.026474477341094208\n",
      "25 Train Loss 96152.37 Test MSE 2527.953906477567 Test RE 0.022473535440027757\n",
      "26 Train Loss 95638.34 Test MSE 3293.9542787889377 Test RE 0.025653439817482346\n",
      "27 Train Loss 94536.9 Test MSE 11163.160413343507 Test RE 0.047225917753049844\n",
      "28 Train Loss 93947.79 Test MSE 5220.74896576548 Test RE 0.03229633410647828\n",
      "29 Train Loss 93682.234 Test MSE 3737.153106879724 Test RE 0.02732481743820651\n",
      "30 Train Loss 92495.086 Test MSE 4538.883413311411 Test RE 0.030113507089468916\n",
      "31 Train Loss 92123.875 Test MSE 6252.127432144658 Test RE 0.03534278219480743\n",
      "32 Train Loss 91340.04 Test MSE 1579.2746079340736 Test RE 0.017762972768527563\n",
      "33 Train Loss 91217.49 Test MSE 1519.846229932212 Test RE 0.01742555619361304\n",
      "34 Train Loss 90750.18 Test MSE 1730.1227625579659 Test RE 0.01859196459435311\n",
      "35 Train Loss 90378.92 Test MSE 1829.354159247988 Test RE 0.01911770341010576\n",
      "36 Train Loss 89581.37 Test MSE 1947.4767500674895 Test RE 0.0197252703577319\n",
      "37 Train Loss 89288.36 Test MSE 1674.604187459724 Test RE 0.018291229972366724\n",
      "38 Train Loss 88960.81 Test MSE 2749.724975634957 Test RE 0.023438588415734624\n",
      "39 Train Loss 88728.82 Test MSE 2213.8399017117135 Test RE 0.021031000274618534\n",
      "40 Train Loss 88441.45 Test MSE 1991.7801337814738 Test RE 0.019948374913470422\n",
      "41 Train Loss 88128.51 Test MSE 1572.6682994282558 Test RE 0.017725781435572803\n",
      "42 Train Loss 87699.83 Test MSE 2019.2430006772943 Test RE 0.020085429211432554\n",
      "43 Train Loss 87492.8 Test MSE 1451.125065942188 Test RE 0.01702704350294526\n",
      "44 Train Loss 87328.914 Test MSE 1416.0883859162418 Test RE 0.016820232868595287\n",
      "45 Train Loss 87058.23 Test MSE 1659.2972721836015 Test RE 0.018207441500665937\n",
      "46 Train Loss 86842.195 Test MSE 2058.5330323639278 Test RE 0.0202798969484151\n",
      "47 Train Loss 86721.84 Test MSE 2425.67857822723 Test RE 0.022014227491058944\n",
      "48 Train Loss 86524.45 Test MSE 2565.3153959797905 Test RE 0.022638998331427355\n",
      "49 Train Loss 86467.586 Test MSE 2263.6297771529717 Test RE 0.021266181826661554\n",
      "50 Train Loss 86255.63 Test MSE 2357.3551639715774 Test RE 0.02170197871678364\n",
      "51 Train Loss 86040.16 Test MSE 2750.0275864711534 Test RE 0.02343987810393456\n",
      "52 Train Loss 85980.516 Test MSE 2638.582572072895 Test RE 0.022960015052385662\n",
      "53 Train Loss 85835.91 Test MSE 3046.466176510352 Test RE 0.02467090062912033\n",
      "54 Train Loss 85790.64 Test MSE 3153.820551261008 Test RE 0.0251018258990388\n",
      "55 Train Loss 85458.87 Test MSE 4188.230163969449 Test RE 0.028926913292023602\n",
      "56 Train Loss 85320.445 Test MSE 4843.1016227780265 Test RE 0.031106318511857793\n",
      "57 Train Loss 85293.6 Test MSE 4543.315246729423 Test RE 0.030128205141081093\n",
      "58 Train Loss 85024.53 Test MSE 4162.56281817214 Test RE 0.02883813854539127\n",
      "59 Train Loss 84883.26 Test MSE 4076.299099695493 Test RE 0.028537757627401576\n",
      "60 Train Loss 84820.875 Test MSE 4356.576733873029 Test RE 0.029502546773009918\n",
      "61 Train Loss 84711.12 Test MSE 3479.522733340634 Test RE 0.02636614661841049\n",
      "62 Train Loss 84080.15 Test MSE 1273.5535311293706 Test RE 0.01595127586261258\n",
      "63 Train Loss 83908.03 Test MSE 1379.0999990552978 Test RE 0.01659910616982721\n",
      "64 Train Loss 83856.02 Test MSE 1398.6424314662397 Test RE 0.016716300646775133\n",
      "65 Train Loss 83718.875 Test MSE 1372.1428630800297 Test RE 0.016557184536007043\n",
      "66 Train Loss 83521.81 Test MSE 1309.1874732442225 Test RE 0.016172894153736572\n",
      "67 Train Loss 83487.71 Test MSE 1409.4360532782775 Test RE 0.01678067830931651\n",
      "68 Train Loss 83449.03 Test MSE 1549.9701896238814 Test RE 0.01759739961425098\n",
      "69 Train Loss 83298.53 Test MSE 1333.5475703007996 Test RE 0.01632266546808482\n",
      "70 Train Loss 83166.305 Test MSE 1542.9632338667345 Test RE 0.017557578244561407\n",
      "71 Train Loss 83113.0 Test MSE 1654.3185961979711 Test RE 0.018180105515454723\n",
      "72 Train Loss 82807.74 Test MSE 1497.830865879794 Test RE 0.01729888898401331\n",
      "73 Train Loss 82754.43 Test MSE 1503.3699178985112 Test RE 0.017330845537085096\n",
      "74 Train Loss 82536.8 Test MSE 1170.0378399619658 Test RE 0.015289270958704873\n",
      "75 Train Loss 82403.664 Test MSE 1206.3639641027733 Test RE 0.015524799551902578\n",
      "76 Train Loss 82330.56 Test MSE 1197.8987844402855 Test RE 0.015470234105202176\n",
      "77 Train Loss 82266.77 Test MSE 1213.6211224640167 Test RE 0.015571426025361648\n",
      "78 Train Loss 82222.84 Test MSE 1298.9062662167837 Test RE 0.01610926514236196\n",
      "79 Train Loss 82176.836 Test MSE 1477.4979718164564 Test RE 0.01718107249585181\n",
      "80 Train Loss 82141.66 Test MSE 1531.6793966703895 Test RE 0.017493260316399868\n",
      "81 Train Loss 82120.73 Test MSE 1508.3645974398084 Test RE 0.017359610992964705\n",
      "82 Train Loss 82091.81 Test MSE 1446.281751477537 Test RE 0.016998604792045763\n",
      "83 Train Loss 81995.02 Test MSE 1211.411424316026 Test RE 0.015557243745970725\n",
      "84 Train Loss 81854.766 Test MSE 1325.893721835267 Test RE 0.016275756386376905\n",
      "85 Train Loss 81801.086 Test MSE 1207.1618269240582 Test RE 0.01552993258527771\n",
      "86 Train Loss 81753.67 Test MSE 1226.923107575606 Test RE 0.015656529355493023\n",
      "87 Train Loss 81726.836 Test MSE 1290.9472185272753 Test RE 0.016059834546271665\n",
      "88 Train Loss 81699.73 Test MSE 1321.9923169002934 Test RE 0.016251793268296472\n",
      "89 Train Loss 81607.04 Test MSE 1218.507393727938 Test RE 0.015602741309632025\n",
      "90 Train Loss 81456.78 Test MSE 1275.6048656078883 Test RE 0.01596411719033225\n",
      "91 Train Loss 81209.51 Test MSE 1382.0350715312284 Test RE 0.016616760323020598\n",
      "92 Train Loss 80735.8 Test MSE 1229.849123388384 Test RE 0.015675187399983904\n",
      "93 Train Loss 80444.96 Test MSE 1817.1972944165866 Test RE 0.019054074740301286\n",
      "94 Train Loss 80063.73 Test MSE 1729.8536512277697 Test RE 0.01859051859785916\n",
      "95 Train Loss 79948.055 Test MSE 2083.765630587586 Test RE 0.020403809445335964\n",
      "96 Train Loss 79873.875 Test MSE 1888.2305355671115 Test RE 0.019422911527485966\n",
      "97 Train Loss 79829.36 Test MSE 2055.1304121786834 Test RE 0.020263129346361927\n",
      "98 Train Loss 79729.805 Test MSE 1525.2994583516297 Test RE 0.01745678976538581\n",
      "99 Train Loss 79581.41 Test MSE 1247.6304409014976 Test RE 0.01578809768895637\n",
      "100 Train Loss 79486.05 Test MSE 1463.962176632322 Test RE 0.01710219097682889\n",
      "101 Train Loss 79350.195 Test MSE 1405.4893102621377 Test RE 0.016757166971608416\n",
      "102 Train Loss 79148.45 Test MSE 1344.4412648656573 Test RE 0.016389199453332098\n",
      "103 Train Loss 78982.516 Test MSE 1640.7158007495802 Test RE 0.018105207391067153\n",
      "104 Train Loss 78886.46 Test MSE 1582.8134127100875 Test RE 0.017782863077118526\n",
      "105 Train Loss 78715.52 Test MSE 1556.8313207262659 Test RE 0.017636305119051725\n",
      "106 Train Loss 78625.78 Test MSE 1432.2948031961205 Test RE 0.01691620859175405\n",
      "107 Train Loss 78557.9 Test MSE 1389.611021777137 Test RE 0.016662242417672994\n",
      "108 Train Loss 78452.15 Test MSE 1531.5961661391714 Test RE 0.01749278502335494\n",
      "109 Train Loss 78289.66 Test MSE 2071.843885423661 Test RE 0.020345358069136895\n",
      "110 Train Loss 78199.65 Test MSE 1977.1452656034946 Test RE 0.019874953133164727\n",
      "111 Train Loss 77978.05 Test MSE 1678.648462189456 Test RE 0.01831330388993202\n",
      "112 Train Loss 77812.99 Test MSE 1540.921086486444 Test RE 0.01754595546792294\n",
      "113 Train Loss 77750.27 Test MSE 1575.503839926122 Test RE 0.017741754141230658\n",
      "114 Train Loss 77695.49 Test MSE 1487.3768558792901 Test RE 0.01723841506351716\n",
      "115 Train Loss 77669.164 Test MSE 1429.6792401434177 Test RE 0.01690075589721502\n",
      "116 Train Loss 77632.336 Test MSE 1396.2428339010603 Test RE 0.016701954730681933\n",
      "117 Train Loss 77594.555 Test MSE 1396.1668081095872 Test RE 0.01670150001156641\n",
      "118 Train Loss 77504.77 Test MSE 1382.7226798155916 Test RE 0.016620893503670207\n",
      "119 Train Loss 77414.88 Test MSE 1478.998874943479 Test RE 0.017189796900333343\n",
      "120 Train Loss 77359.234 Test MSE 1521.4535410535384 Test RE 0.01743476794431367\n",
      "121 Train Loss 77311.28 Test MSE 1472.9094322962633 Test RE 0.017154372853799373\n",
      "122 Train Loss 77288.555 Test MSE 1531.7171166439894 Test RE 0.01749347571436643\n",
      "123 Train Loss 77261.95 Test MSE 1532.4907579277576 Test RE 0.017497892968176852\n",
      "124 Train Loss 77234.66 Test MSE 1817.3233972035907 Test RE 0.01905473584910131\n",
      "125 Train Loss 77211.74 Test MSE 1941.815967413208 Test RE 0.019696581509958216\n",
      "126 Train Loss 77174.81 Test MSE 1719.505981754364 Test RE 0.018534832649022313\n",
      "127 Train Loss 77140.46 Test MSE 1879.8106293117419 Test RE 0.019379558290102683\n",
      "128 Train Loss 77050.96 Test MSE 1886.0874677963798 Test RE 0.01941188627601148\n",
      "129 Train Loss 76940.22 Test MSE 1768.3118005166725 Test RE 0.0187960350505653\n",
      "130 Train Loss 76869.19 Test MSE 1804.2244879727684 Test RE 0.01898594026651927\n",
      "131 Train Loss 76838.664 Test MSE 1886.1445890797115 Test RE 0.019412180224059924\n",
      "132 Train Loss 76807.375 Test MSE 1962.4357515601016 Test RE 0.01980088252852839\n",
      "133 Train Loss 76755.85 Test MSE 1730.1377675182332 Test RE 0.018592045216113372\n",
      "134 Train Loss 76677.36 Test MSE 1897.040869438055 Test RE 0.019468171675969936\n",
      "135 Train Loss 76620.48 Test MSE 1817.1453324576805 Test RE 0.01905380231690247\n",
      "136 Train Loss 76547.92 Test MSE 2118.6448460004353 Test RE 0.02057386586743388\n",
      "137 Train Loss 76459.09 Test MSE 2190.024361107933 Test RE 0.02091757315715\n",
      "138 Train Loss 76298.34 Test MSE 2647.7447990142705 Test RE 0.022999843740918947\n",
      "139 Train Loss 76069.695 Test MSE 2202.12547610991 Test RE 0.02097528421730292\n",
      "140 Train Loss 75867.27 Test MSE 2101.6523750272027 Test RE 0.02049119400459165\n",
      "141 Train Loss 75723.41 Test MSE 2782.3642445684286 Test RE 0.023577286208706933\n",
      "142 Train Loss 75657.734 Test MSE 2688.7514221623464 Test RE 0.02317726307110061\n",
      "143 Train Loss 75551.65 Test MSE 2254.62377895545 Test RE 0.021223835221686384\n",
      "144 Train Loss 75460.06 Test MSE 2140.4893603222395 Test RE 0.020679658392895577\n",
      "145 Train Loss 75380.805 Test MSE 2049.158537325503 Test RE 0.020233667248030877\n",
      "146 Train Loss 75295.93 Test MSE 1939.7536315195366 Test RE 0.019686119200713566\n",
      "147 Train Loss 75190.61 Test MSE 1910.2061155818544 Test RE 0.019535608317353\n",
      "148 Train Loss 74994.12 Test MSE 2036.6056893678478 Test RE 0.020171597789605086\n",
      "149 Train Loss 74802.9 Test MSE 3071.407339670857 Test RE 0.02477168407067347\n",
      "150 Train Loss 74726.53 Test MSE 3610.7219072484986 Test RE 0.02685862923621709\n",
      "151 Train Loss 74679.65 Test MSE 2629.1717153680033 Test RE 0.0229190335000366\n",
      "152 Train Loss 74508.95 Test MSE 3354.8155662547 Test RE 0.02588935009427677\n",
      "153 Train Loss 74464.305 Test MSE 3044.74866640027 Test RE 0.02466394527616603\n",
      "154 Train Loss 74411.67 Test MSE 2956.2069743970665 Test RE 0.024302684131517788\n",
      "155 Train Loss 74381.586 Test MSE 3074.551361264051 Test RE 0.02478435949600756\n",
      "156 Train Loss 74355.94 Test MSE 3197.2724758413246 Test RE 0.025274155208178623\n",
      "157 Train Loss 74284.51 Test MSE 3101.9105335505856 Test RE 0.024894388191019932\n",
      "158 Train Loss 74139.72 Test MSE 3050.8767528577946 Test RE 0.024688753040571835\n",
      "159 Train Loss 74043.99 Test MSE 2390.6330095655835 Test RE 0.021854621009538437\n",
      "160 Train Loss 73994.97 Test MSE 2450.194463204771 Test RE 0.022125194678572442\n",
      "161 Train Loss 73927.555 Test MSE 2343.2870965592792 Test RE 0.021637126003234797\n",
      "162 Train Loss 73874.96 Test MSE 2140.0625526906633 Test RE 0.0206775965568945\n",
      "163 Train Loss 73852.234 Test MSE 1807.0419605457935 Test RE 0.019000758682751046\n",
      "164 Train Loss 73804.44 Test MSE 1650.2837798521618 Test RE 0.01815792170872442\n",
      "165 Train Loss 73749.66 Test MSE 1555.6027086765403 Test RE 0.01762934468172756\n",
      "166 Train Loss 73655.32 Test MSE 1689.5789734852285 Test RE 0.01837283063972655\n",
      "167 Train Loss 73627.43 Test MSE 1676.6753676897463 Test RE 0.0183025379361794\n",
      "168 Train Loss 73570.44 Test MSE 1677.4409916484817 Test RE 0.01830671622331351\n",
      "169 Train Loss 73519.71 Test MSE 1473.9765722482923 Test RE 0.017160585999589317\n",
      "170 Train Loss 73428.836 Test MSE 1746.657421543856 Test RE 0.018680594375957312\n",
      "171 Train Loss 73359.89 Test MSE 1416.6560648533662 Test RE 0.01682360396296278\n",
      "172 Train Loss 73338.65 Test MSE 1486.6188215134152 Test RE 0.017234021766577335\n",
      "173 Train Loss 73274.445 Test MSE 1338.5758012758572 Test RE 0.01635340936988924\n",
      "174 Train Loss 73218.61 Test MSE 1451.6509555246305 Test RE 0.017030128534652238\n",
      "175 Train Loss 73181.91 Test MSE 1466.0814224697285 Test RE 0.017114565148922255\n",
      "176 Train Loss 73144.63 Test MSE 1363.0893613886471 Test RE 0.01650247136253216\n",
      "177 Train Loss 73111.5 Test MSE 1215.658406911423 Test RE 0.015584490284566033\n",
      "178 Train Loss 73084.61 Test MSE 1204.5159110982727 Test RE 0.015512903619298397\n",
      "179 Train Loss 73048.03 Test MSE 1208.1137129376714 Test RE 0.015536054304949054\n",
      "180 Train Loss 73027.375 Test MSE 1205.1048986435148 Test RE 0.015516695927172279\n",
      "181 Train Loss 73011.24 Test MSE 1222.157661547323 Test RE 0.015626094304582977\n",
      "182 Train Loss 72984.836 Test MSE 1181.8916218770942 Test RE 0.015366524427941388\n",
      "183 Train Loss 72938.74 Test MSE 1124.906561295498 Test RE 0.01499149860258488\n",
      "184 Train Loss 72874.95 Test MSE 1092.198004001505 Test RE 0.01477193924939637\n",
      "185 Train Loss 72825.76 Test MSE 1084.2745221432053 Test RE 0.014718259309794337\n",
      "186 Train Loss 72790.78 Test MSE 1120.1070827164726 Test RE 0.014959483371622706\n",
      "187 Train Loss 72772.64 Test MSE 1111.808399055941 Test RE 0.014903964208138257\n",
      "188 Train Loss 72734.266 Test MSE 1078.2381066881187 Test RE 0.01467723209406641\n",
      "189 Train Loss 72716.79 Test MSE 1086.4559780853342 Test RE 0.014733057730596763\n",
      "190 Train Loss 72699.62 Test MSE 1081.622296774512 Test RE 0.014700247247084996\n",
      "191 Train Loss 72688.11 Test MSE 1082.8420970416757 Test RE 0.014708534018213025\n",
      "192 Train Loss 72636.42 Test MSE 1110.1009908622711 Test RE 0.014892515775135723\n",
      "193 Train Loss 72548.32 Test MSE 1118.9134227172967 Test RE 0.014951510340741513\n",
      "194 Train Loss 72502.31 Test MSE 1109.8618745571632 Test RE 0.014890911761105232\n",
      "195 Train Loss 72475.97 Test MSE 1102.0013510691506 Test RE 0.014838086111403602\n",
      "196 Train Loss 72423.82 Test MSE 1162.2539560562411 Test RE 0.015238328800749022\n",
      "197 Train Loss 72397.64 Test MSE 1188.3978080316174 Test RE 0.015408761910948431\n",
      "198 Train Loss 72387.64 Test MSE 1163.5013298392362 Test RE 0.015246503775971126\n",
      "199 Train Loss 72374.11 Test MSE 1153.5005259706645 Test RE 0.015180837172037593\n",
      "Training time: 40.24\n",
      "Training time: 40.24\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 457766.75 Test MSE 5005214.89841692 Test RE 0.9999958276287594\n",
      "1 Train Loss 453137.5 Test MSE 4821373.092602051 Test RE 0.9814590716441687\n",
      "2 Train Loss 431920.03 Test MSE 4057498.277247912 Test RE 0.900359592021291\n",
      "3 Train Loss 299118.12 Test MSE 507623.4097138513 Test RE 0.3184620193577649\n",
      "4 Train Loss 161541.95 Test MSE 794694.2276057159 Test RE 0.3984619471541154\n",
      "5 Train Loss 143951.42 Test MSE 327856.06838610757 Test RE 0.2559342667255996\n",
      "6 Train Loss 130130.234 Test MSE 20820.158801424368 Test RE 0.06449541513319358\n",
      "7 Train Loss 120429.625 Test MSE 25384.20328945079 Test RE 0.07121452669501636\n",
      "8 Train Loss 117780.39 Test MSE 26466.89393376611 Test RE 0.07271739493839742\n",
      "9 Train Loss 115754.31 Test MSE 31750.23031469549 Test RE 0.07964532039079711\n",
      "10 Train Loss 114853.01 Test MSE 33205.35632135865 Test RE 0.08144996389420488\n",
      "11 Train Loss 114019.984 Test MSE 23429.939207110023 Test RE 0.06841831977552226\n",
      "12 Train Loss 112966.945 Test MSE 19221.784901908202 Test RE 0.061970311642247235\n",
      "13 Train Loss 111996.37 Test MSE 18212.71679104051 Test RE 0.06032178589357712\n",
      "14 Train Loss 111005.42 Test MSE 13093.074465617072 Test RE 0.05114552519737882\n",
      "15 Train Loss 109203.16 Test MSE 14267.655236258375 Test RE 0.05339039413674271\n",
      "16 Train Loss 108453.83 Test MSE 7914.633025613046 Test RE 0.03976511246849794\n",
      "17 Train Loss 107020.44 Test MSE 5710.978161243112 Test RE 0.03377863326461331\n",
      "18 Train Loss 106495.055 Test MSE 3857.4366547495492 Test RE 0.02776107153101725\n",
      "19 Train Loss 105580.33 Test MSE 2888.647471637614 Test RE 0.02402337915520615\n",
      "20 Train Loss 105114.5 Test MSE 2710.5856719360927 Test RE 0.023271179326134574\n",
      "21 Train Loss 104321.89 Test MSE 3279.942119279063 Test RE 0.02559881805401535\n",
      "22 Train Loss 103458.375 Test MSE 4933.691204264979 Test RE 0.03139589049058302\n",
      "23 Train Loss 102469.02 Test MSE 4274.119012795239 Test RE 0.029222012965857497\n",
      "24 Train Loss 101725.82 Test MSE 8648.258540268493 Test RE 0.041567236829012956\n",
      "25 Train Loss 101235.08 Test MSE 7117.489687690483 Test RE 0.03770945423450765\n",
      "26 Train Loss 100325.21 Test MSE 10055.297067766514 Test RE 0.04482128222791274\n",
      "27 Train Loss 99224.44 Test MSE 4953.6444448326665 Test RE 0.03145931335416713\n",
      "28 Train Loss 98324.83 Test MSE 12913.21577031831 Test RE 0.05079301907960357\n",
      "29 Train Loss 97515.3 Test MSE 9809.43775574033 Test RE 0.044269934717219336\n",
      "30 Train Loss 96875.99 Test MSE 7959.1426417781695 Test RE 0.03987676947556078\n",
      "31 Train Loss 96071.43 Test MSE 2154.0696622734367 Test RE 0.02074515555862615\n",
      "32 Train Loss 95513.04 Test MSE 6205.450307159521 Test RE 0.03521060397958278\n",
      "33 Train Loss 94260.82 Test MSE 2625.252396796097 Test RE 0.022901944373739446\n",
      "34 Train Loss 92594.97 Test MSE 5533.5189530424195 Test RE 0.033249684181175444\n",
      "35 Train Loss 91862.22 Test MSE 1849.6798677122003 Test RE 0.019223617142456587\n",
      "36 Train Loss 90705.93 Test MSE 3017.2196978617953 Test RE 0.02455219308376469\n",
      "37 Train Loss 89374.2 Test MSE 3342.9234269141266 Test RE 0.025843423115561384\n",
      "38 Train Loss 88165.74 Test MSE 3960.092666540081 Test RE 0.02812804174562107\n",
      "39 Train Loss 87433.32 Test MSE 3267.223589723633 Test RE 0.0255491379761689\n",
      "40 Train Loss 86909.445 Test MSE 6388.662515915058 Test RE 0.03572660901067525\n",
      "41 Train Loss 86071.82 Test MSE 10072.956199536451 Test RE 0.04486062257349521\n",
      "42 Train Loss 85401.35 Test MSE 6412.676472777937 Test RE 0.03579369132603204\n",
      "43 Train Loss 85065.91 Test MSE 4270.977198902216 Test RE 0.0292112707515948\n",
      "44 Train Loss 84752.77 Test MSE 4410.394775132231 Test RE 0.02968421415654299\n",
      "45 Train Loss 84560.16 Test MSE 3674.1549502505904 Test RE 0.027093527810239316\n",
      "46 Train Loss 83942.03 Test MSE 2186.0694139424913 Test RE 0.020898677184733663\n",
      "47 Train Loss 82813.53 Test MSE 1884.4215806393236 Test RE 0.01940331160585754\n",
      "48 Train Loss 82604.5 Test MSE 2897.3195036250445 Test RE 0.02405941252209438\n",
      "49 Train Loss 82148.8 Test MSE 2746.080618831034 Test RE 0.02342305106179156\n",
      "50 Train Loss 81664.04 Test MSE 1599.430425686564 Test RE 0.017875965190191002\n",
      "51 Train Loss 81580.08 Test MSE 1969.5999304242498 Test RE 0.019836992712497305\n",
      "52 Train Loss 81353.99 Test MSE 1942.0716456086134 Test RE 0.01969787818810381\n",
      "53 Train Loss 80782.11 Test MSE 5352.043805029847 Test RE 0.032699917226799255\n",
      "54 Train Loss 80128.836 Test MSE 4491.773715561876 Test RE 0.029956823344141893\n",
      "55 Train Loss 79532.24 Test MSE 5857.456337306247 Test RE 0.034209076767884226\n",
      "56 Train Loss 78360.48 Test MSE 1551.3732977951006 Test RE 0.01760536282218843\n",
      "57 Train Loss 78176.9 Test MSE 1644.5991737342608 Test RE 0.01812662112982647\n",
      "58 Train Loss 77929.41 Test MSE 1912.4852367074564 Test RE 0.019547259087511815\n",
      "59 Train Loss 77772.13 Test MSE 3308.2457352597585 Test RE 0.025709030784975703\n",
      "60 Train Loss 77606.42 Test MSE 4022.923655965629 Test RE 0.028350303930338366\n",
      "61 Train Loss 77512.836 Test MSE 2929.018024128672 Test RE 0.024190667143914827\n",
      "62 Train Loss 77335.55 Test MSE 1885.3184888105422 Test RE 0.019407928650849064\n",
      "63 Train Loss 77063.66 Test MSE 1751.6777809975474 Test RE 0.018707421618820903\n",
      "64 Train Loss 76806.93 Test MSE 1581.7700907380981 Test RE 0.01777700126485213\n",
      "65 Train Loss 76628.84 Test MSE 1489.1193461652301 Test RE 0.017248509673490724\n",
      "66 Train Loss 76519.99 Test MSE 1477.493148150365 Test RE 0.017181044449849033\n",
      "67 Train Loss 76256.53 Test MSE 1884.5792784018397 Test RE 0.0194041234716427\n",
      "68 Train Loss 76097.08 Test MSE 1615.4707350492795 Test RE 0.017965378486236243\n",
      "69 Train Loss 76049.195 Test MSE 1542.350614119776 Test RE 0.01755409235884084\n",
      "70 Train Loss 75700.03 Test MSE 1719.6239365983747 Test RE 0.01853546836527594\n",
      "71 Train Loss 75646.75 Test MSE 1467.638240478683 Test RE 0.01712364963538434\n",
      "72 Train Loss 75390.516 Test MSE 1308.9602061154014 Test RE 0.01617149033387802\n",
      "73 Train Loss 74999.734 Test MSE 1234.163442331075 Test RE 0.015702657660680987\n",
      "74 Train Loss 74924.05 Test MSE 1427.2251241687661 Test RE 0.016886244170302978\n",
      "75 Train Loss 74627.91 Test MSE 1077.7654871504894 Test RE 0.014674015037041497\n",
      "76 Train Loss 74274.555 Test MSE 1222.6268179331353 Test RE 0.015629093254202267\n",
      "77 Train Loss 74122.555 Test MSE 1968.7242697801173 Test RE 0.019832582577054673\n",
      "78 Train Loss 73655.625 Test MSE 4251.841889743081 Test RE 0.029145759492293692\n",
      "79 Train Loss 73413.56 Test MSE 4196.23954530304 Test RE 0.0289545593393164\n",
      "80 Train Loss 73325.83 Test MSE 2752.567235898272 Test RE 0.02345069896548967\n",
      "81 Train Loss 73009.47 Test MSE 3359.4355582695043 Test RE 0.025907170364534857\n",
      "82 Train Loss 72685.8 Test MSE 2088.1293216632716 Test RE 0.020425162460105416\n",
      "83 Train Loss 72517.88 Test MSE 1432.6924582562647 Test RE 0.016918556693937697\n",
      "84 Train Loss 72410.87 Test MSE 1177.2016994875187 Test RE 0.015336005790789958\n",
      "85 Train Loss 72166.38 Test MSE 1180.6520304942928 Test RE 0.015358463956038479\n",
      "86 Train Loss 71866.17 Test MSE 1189.6349157095765 Test RE 0.015416779991768872\n",
      "87 Train Loss 71820.63 Test MSE 1186.8615092324867 Test RE 0.015398798867495862\n",
      "88 Train Loss 71654.2 Test MSE 1643.2216125441573 Test RE 0.018119027862918153\n",
      "89 Train Loss 71232.9 Test MSE 1189.0705369704287 Test RE 0.015413122594470072\n",
      "90 Train Loss 70836.62 Test MSE 1259.4947009009502 Test RE 0.015862988009761582\n",
      "91 Train Loss 70692.35 Test MSE 1368.2596290927115 Test RE 0.016533739099760473\n",
      "92 Train Loss 70570.55 Test MSE 1306.1919197536547 Test RE 0.016154380948006242\n",
      "93 Train Loss 70332.11 Test MSE 1066.4359469046829 Test RE 0.014596684177599921\n",
      "94 Train Loss 69936.65 Test MSE 1258.6123905454715 Test RE 0.015857430808688268\n",
      "95 Train Loss 69569.695 Test MSE 1218.9923213581953 Test RE 0.01560584570102925\n",
      "96 Train Loss 69427.81 Test MSE 1080.1874048907132 Test RE 0.014690493257263201\n",
      "97 Train Loss 69151.49 Test MSE 1215.5039261345937 Test RE 0.015583500047242495\n",
      "98 Train Loss 68320.836 Test MSE 2676.553888077359 Test RE 0.02312463142821764\n",
      "99 Train Loss 67889.305 Test MSE 1952.725150359316 Test RE 0.01975183202489078\n",
      "100 Train Loss 67623.09 Test MSE 1332.126998915793 Test RE 0.01631396923164537\n",
      "101 Train Loss 67044.6 Test MSE 1402.287587981322 Test RE 0.016738069571086894\n",
      "102 Train Loss 66456.34 Test MSE 1975.213793321003 Test RE 0.019865242844895013\n",
      "103 Train Loss 66171.67 Test MSE 2314.3318187796144 Test RE 0.021503028811277934\n",
      "104 Train Loss 65568.23 Test MSE 2112.3570735124476 Test RE 0.020543313339230772\n",
      "105 Train Loss 65091.504 Test MSE 1193.2373175420103 Test RE 0.015440104566086573\n",
      "106 Train Loss 64414.35 Test MSE 1795.39814373736 Test RE 0.01893944331001744\n",
      "107 Train Loss 63849.844 Test MSE 1508.674769442495 Test RE 0.017361395769847236\n",
      "108 Train Loss 63460.97 Test MSE 1335.902076764645 Test RE 0.016337068731004486\n",
      "109 Train Loss 63152.23 Test MSE 1846.906391550693 Test RE 0.019209199446215637\n",
      "110 Train Loss 62707.54 Test MSE 965.6093043944238 Test RE 0.013889529822573415\n",
      "111 Train Loss 62231.35 Test MSE 1035.6735199868435 Test RE 0.01438461557066617\n",
      "112 Train Loss 61892.52 Test MSE 1330.1675756838704 Test RE 0.0163019667222493\n",
      "113 Train Loss 61683.42 Test MSE 1318.7557474745622 Test RE 0.016231886839740507\n",
      "114 Train Loss 61409.96 Test MSE 1205.8143280600204 Test RE 0.01552126249268888\n",
      "115 Train Loss 61109.41 Test MSE 1284.5555408345551 Test RE 0.016020027860780495\n",
      "116 Train Loss 60882.84 Test MSE 1394.7396149224353 Test RE 0.016692961504025248\n",
      "117 Train Loss 60657.89 Test MSE 936.5026879065138 Test RE 0.013678590172870812\n",
      "118 Train Loss 60526.41 Test MSE 1049.7730528876432 Test RE 0.014482199768965637\n",
      "119 Train Loss 60312.15 Test MSE 1556.9862428299202 Test RE 0.017637182601886348\n",
      "120 Train Loss 60164.03 Test MSE 1286.6396130238313 Test RE 0.01603301809851817\n",
      "121 Train Loss 60004.05 Test MSE 914.7612947099793 Test RE 0.013518880026339315\n",
      "122 Train Loss 59827.633 Test MSE 979.5979676943973 Test RE 0.013989776020082055\n",
      "123 Train Loss 59668.23 Test MSE 1194.951738133464 Test RE 0.01545119260844028\n",
      "124 Train Loss 59467.355 Test MSE 996.3096589990988 Test RE 0.014108602380544184\n",
      "125 Train Loss 59235.62 Test MSE 943.9897530201713 Test RE 0.013733159487657846\n",
      "126 Train Loss 59036.176 Test MSE 896.6124092121092 Test RE 0.013384100723033431\n",
      "127 Train Loss 58854.375 Test MSE 925.8587708638847 Test RE 0.013600635331446455\n",
      "128 Train Loss 58604.76 Test MSE 1032.6188432757358 Test RE 0.014363386487721782\n",
      "129 Train Loss 58367.793 Test MSE 2185.164010566184 Test RE 0.020894348938711393\n",
      "130 Train Loss 58191.117 Test MSE 2539.3649583137044 Test RE 0.02252420051184516\n",
      "131 Train Loss 58063.094 Test MSE 2488.1793816732948 Test RE 0.02229603652413443\n",
      "132 Train Loss 57680.105 Test MSE 819.038092577648 Test RE 0.012792012468624445\n",
      "133 Train Loss 57028.73 Test MSE 2097.9722176955975 Test RE 0.020473245303788867\n",
      "134 Train Loss 56542.598 Test MSE 3391.724639538903 Test RE 0.0260313754989002\n",
      "135 Train Loss 56056.055 Test MSE 1556.833141144489 Test RE 0.017636315430201496\n",
      "136 Train Loss 55797.22 Test MSE 1086.3070379081637 Test RE 0.014732047832596892\n",
      "137 Train Loss 55629.527 Test MSE 950.9191692823043 Test RE 0.013783471887410456\n",
      "138 Train Loss 55458.18 Test MSE 810.6651540835037 Test RE 0.012726458816153348\n",
      "139 Train Loss 55194.777 Test MSE 824.4749179962141 Test RE 0.012834399327540323\n",
      "140 Train Loss 55011.746 Test MSE 775.6227424722133 Test RE 0.012448358614237327\n",
      "141 Train Loss 54835.293 Test MSE 789.8151368049694 Test RE 0.012561732762731034\n",
      "142 Train Loss 54657.152 Test MSE 824.2204861925571 Test RE 0.01283241883591593\n",
      "143 Train Loss 54418.254 Test MSE 1079.736488446871 Test RE 0.014687426716958833\n",
      "144 Train Loss 54310.016 Test MSE 792.1491291675338 Test RE 0.012580279735740022\n",
      "145 Train Loss 54197.984 Test MSE 806.0161687150523 Test RE 0.012689914634285208\n",
      "146 Train Loss 54085.547 Test MSE 891.5115385699604 Test RE 0.013345975028163759\n",
      "147 Train Loss 53905.64 Test MSE 745.4509378167369 Test RE 0.0122038358198828\n",
      "148 Train Loss 53737.516 Test MSE 832.0151282004053 Test RE 0.012892954058324241\n",
      "149 Train Loss 53576.656 Test MSE 880.5072174866574 Test RE 0.013263351637019409\n",
      "150 Train Loss 53401.19 Test MSE 896.0182040191625 Test RE 0.01337966501583745\n",
      "151 Train Loss 53272.688 Test MSE 847.2899318086814 Test RE 0.013010765414196282\n",
      "152 Train Loss 53097.168 Test MSE 807.903340213241 Test RE 0.012704761758200001\n",
      "153 Train Loss 52977.89 Test MSE 708.6864098568725 Test RE 0.011899093468061733\n",
      "154 Train Loss 52877.043 Test MSE 711.4221344370382 Test RE 0.011922038233885263\n",
      "155 Train Loss 52803.89 Test MSE 704.4895974181885 Test RE 0.011863808174308661\n",
      "156 Train Loss 52699.35 Test MSE 704.8787529184422 Test RE 0.011867084467398138\n",
      "157 Train Loss 52621.64 Test MSE 770.8510959133396 Test RE 0.01241000826515598\n",
      "158 Train Loss 52514.67 Test MSE 1049.9899407509902 Test RE 0.014483695735706107\n",
      "159 Train Loss 52442.074 Test MSE 827.8631294668197 Test RE 0.012860744018651176\n",
      "160 Train Loss 52344.336 Test MSE 774.6474054716808 Test RE 0.012440529315668152\n",
      "161 Train Loss 52252.863 Test MSE 830.4879821640128 Test RE 0.012881116252615862\n",
      "162 Train Loss 52178.63 Test MSE 674.2078476332256 Test RE 0.011606030975075293\n",
      "163 Train Loss 52123.785 Test MSE 674.4889421850434 Test RE 0.011608450149009486\n",
      "164 Train Loss 52028.223 Test MSE 687.8510262568774 Test RE 0.011722871876236529\n",
      "165 Train Loss 51874.895 Test MSE 974.7284226520507 Test RE 0.013954961372612873\n",
      "166 Train Loss 51743.51 Test MSE 698.5609876230219 Test RE 0.01181378295540406\n",
      "167 Train Loss 51676.605 Test MSE 800.5391686625168 Test RE 0.012646726210203225\n",
      "168 Train Loss 51541.92 Test MSE 666.7082554137613 Test RE 0.011541300265066456\n",
      "169 Train Loss 51374.004 Test MSE 1032.8247754502381 Test RE 0.014364818640532115\n",
      "170 Train Loss 51224.66 Test MSE 828.4151196869581 Test RE 0.012865030851656276\n",
      "171 Train Loss 51150.637 Test MSE 742.0204424751716 Test RE 0.01217572298516634\n",
      "172 Train Loss 51063.305 Test MSE 697.6361245864464 Test RE 0.011805959909032573\n",
      "173 Train Loss 50936.645 Test MSE 1083.750473396163 Test RE 0.014714702084486178\n",
      "174 Train Loss 50712.984 Test MSE 2057.6945421887494 Test RE 0.02027576628205816\n",
      "175 Train Loss 50545.26 Test MSE 1319.9938740536584 Test RE 0.01623950478403398\n",
      "176 Train Loss 50326.035 Test MSE 802.8361799587766 Test RE 0.012664857031072204\n",
      "177 Train Loss 50139.2 Test MSE 972.23722221766 Test RE 0.013937116993497896\n",
      "178 Train Loss 49938.812 Test MSE 1001.1587549661614 Test RE 0.014142894392359296\n",
      "179 Train Loss 49803.633 Test MSE 971.408394634396 Test RE 0.013931175064062417\n",
      "180 Train Loss 49616.3 Test MSE 1200.7938329977474 Test RE 0.01548891684038748\n",
      "181 Train Loss 49424.625 Test MSE 1144.3226296737078 Test RE 0.015120322938455125\n",
      "182 Train Loss 49120.484 Test MSE 708.8424573928447 Test RE 0.01190040344239358\n",
      "183 Train Loss 48941.45 Test MSE 720.7447140906169 Test RE 0.011999898058407003\n",
      "184 Train Loss 48717.074 Test MSE 775.6708643141284 Test RE 0.012448744774042425\n",
      "185 Train Loss 48565.305 Test MSE 777.226847645906 Test RE 0.012461224509968016\n",
      "186 Train Loss 48428.83 Test MSE 855.7471049475856 Test RE 0.013075537269927382\n",
      "187 Train Loss 48360.31 Test MSE 830.47919363693 Test RE 0.012881048096097662\n",
      "188 Train Loss 48237.03 Test MSE 1695.4567098900304 Test RE 0.018404760753759925\n",
      "189 Train Loss 48153.094 Test MSE 1439.2144597408776 Test RE 0.01695702187837929\n",
      "190 Train Loss 48079.816 Test MSE 1042.9656255590648 Test RE 0.014435167285282416\n",
      "191 Train Loss 48030.03 Test MSE 1295.987016550275 Test RE 0.016091152434483114\n",
      "192 Train Loss 47943.195 Test MSE 800.0599107674594 Test RE 0.012642940042685548\n",
      "193 Train Loss 47843.258 Test MSE 761.0372447325351 Test RE 0.012330758138224165\n",
      "194 Train Loss 47726.207 Test MSE 762.4837594725603 Test RE 0.012342471202195648\n",
      "195 Train Loss 47597.438 Test MSE 806.8348881226173 Test RE 0.012696357955665052\n",
      "196 Train Loss 47512.582 Test MSE 760.4105036519005 Test RE 0.012325679684771603\n",
      "197 Train Loss 47380.164 Test MSE 743.250266009389 Test RE 0.01218580882006087\n",
      "198 Train Loss 47291.97 Test MSE 707.5790150751634 Test RE 0.011889793059972046\n",
      "199 Train Loss 47194.492 Test MSE 708.2200144191195 Test RE 0.011895177352125749\n",
      "Training time: 40.09\n",
      "Training time: 40.09\n"
     ]
    }
   ],
   "source": [
    " \n",
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  beta_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers)\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "7ef8bb86-89cf-4917-9bf1-6cda3bafbc51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1D_FODE_swish_high'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "bb023909-b810-4d9b-857a-cc29fc84d142"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_swish_tune4.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_swish_tune4.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8052/2114102953.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_swish_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_swish_tune4.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(4,5):\n",
    "    label = \"1D_FODE_swish_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(i,' ',np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "swish_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
