{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "12aa433d-9505-4460-d56f-b6a376e9ccb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "4778640e-2987-401e-f7cb-585a0f18a01a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "63653bcd-0776-4d8a-c31d-d2238f724ffe"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/swish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "d48278bc-c428-4c93-93f7-f711d3b81f62"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "level = \"low\"\n",
    "label = \"1D_FODE_swish_\"+level\n",
    "\n",
    "extent = 1.0\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(extent,-1.0*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "              \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "       \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "      \n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "  print(rep) \n",
    "  torch.manual_seed(rep*11)\n",
    "  start_time = time.time() \n",
    "  thresh_flag = 0\n",
    "  x_coll = torch.from_numpy(colloc_pts(N_f,123)).float().to(device)\n",
    "  f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "  loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "  data_update(loss_np)\n",
    "\n",
    "  for i in range(max_iter):\n",
    "    \n",
    "    train_step(i)\n",
    "\n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    if(thresh_flag == 0):\n",
    "        if(loss_np < loss_thresh):\n",
    "            time_threshold[rep] = time.time() - start_time\n",
    "            epoch_threshold[rep] = i+1            \n",
    "            thresh_flag = 1       \n",
    "    data_update(loss_np)\n",
    "    print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "\n",
    "  elapsed_time[rep] = time.time() - start_time  \n",
    "  print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "2bf8b190-81d6-4793-b63a-bc5565d05793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 1.5424484 Test MSE 0.1261984870432898 Test RE 1.0331465958775419\n",
      "1 Train Loss 0.039824057 Test MSE 1.787296122383171e-05 Test RE 0.0122951301831731\n",
      "2 Train Loss 0.014418521 Test MSE 0.00014684250411762089 Test RE 0.035242017774775564\n",
      "3 Train Loss 0.0005473235 Test MSE 1.021828149414484e-06 Test RE 0.002939840754574591\n",
      "4 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "5 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "6 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "7 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "8 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "9 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "10 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "11 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "12 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "13 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "14 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "15 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "16 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "17 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "18 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "19 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "20 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "21 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "22 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "23 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "24 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "25 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "26 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "27 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "28 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "29 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "30 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "31 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "32 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "33 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "34 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "35 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "36 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "37 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "38 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "39 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "40 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "41 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "42 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "43 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "44 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "45 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "46 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "47 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "48 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "49 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "50 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "51 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "52 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "53 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "54 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "55 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "56 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "57 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "58 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "59 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "60 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "61 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "62 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "63 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "64 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "65 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "66 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "67 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "68 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "69 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "70 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "71 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "72 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "73 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "74 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "75 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "76 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "77 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "78 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "79 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "80 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "81 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "82 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "83 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "84 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "85 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "86 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "87 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "88 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "89 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "90 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "91 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "92 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "93 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "94 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "95 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "96 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "97 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "98 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "99 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "100 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "101 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "102 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "103 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "104 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "105 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "106 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "107 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "108 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "109 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "110 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "111 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "112 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "113 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "114 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "115 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "116 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "117 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "118 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "119 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "120 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "121 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "122 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "123 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "124 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "125 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "126 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "127 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "128 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "129 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "130 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "131 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "132 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "133 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "134 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "135 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "136 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "137 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "138 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "139 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "140 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "141 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "142 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "143 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "144 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "145 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "146 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "147 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "148 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "149 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "150 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "151 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "152 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "153 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "154 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "155 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "156 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "157 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "158 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "159 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "160 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "161 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "162 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "163 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "164 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "165 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "166 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "167 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "168 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "169 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "170 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "171 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "172 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "173 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "174 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "175 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "176 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "177 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "178 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "179 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "180 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "181 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "182 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "183 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "184 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "185 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "186 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "187 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "188 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "189 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "190 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "191 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "192 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "193 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "194 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "195 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "196 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "197 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "198 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "199 Train Loss 7.4702286e-05 Test MSE 2.14658791685725e-08 Test RE 0.0004260977246761896\n",
      "Training time: 3.01\n",
      "Training time: 3.01\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 6.653305 Test MSE 2.0559015709045356 Test RE 4.169999799658644\n",
      "1 Train Loss 0.043994177 Test MSE 0.0027234179847994843 Test RE 0.15177212871741103\n",
      "2 Train Loss 0.012319084 Test MSE 1.2219272861449734e-05 Test RE 0.010166174415043286\n",
      "3 Train Loss 0.0004044373 Test MSE 9.542783132235981e-06 Test RE 0.008984055000854675\n",
      "4 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "5 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "6 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "7 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "8 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "9 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "10 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "11 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "12 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "13 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "14 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "15 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "16 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "17 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "18 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "19 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "20 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "21 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "22 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "23 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "24 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "25 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "26 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "27 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "28 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "29 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "30 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "31 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "32 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "33 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "34 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "35 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "36 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "37 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "38 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "39 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "40 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "41 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "42 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "43 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "44 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "45 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "46 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "47 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "48 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "49 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "50 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "51 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "52 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "53 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "54 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "55 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "56 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "57 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "58 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "59 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "60 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "61 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "62 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "63 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "64 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "65 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "66 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "67 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "68 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "69 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "70 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "71 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "72 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "73 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "74 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "75 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "76 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "77 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "78 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "79 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "80 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "81 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "82 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "83 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "84 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "85 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "86 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "87 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "88 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "89 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "90 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "91 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "92 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "93 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "94 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "95 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "96 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "97 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "98 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "99 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "100 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "101 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "102 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "103 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "104 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "105 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "106 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "107 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "108 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "109 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "110 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "111 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "112 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "113 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "114 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "115 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "116 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "117 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "118 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "119 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "120 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "121 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "122 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "123 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "124 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "125 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "126 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "127 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "128 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "129 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "130 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "131 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "132 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "133 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "134 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "135 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "136 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "137 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "138 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "139 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "140 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "141 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "142 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "143 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "144 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "145 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "146 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "147 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "148 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "149 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "150 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "151 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "152 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "153 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "154 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "155 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "156 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "157 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "158 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "159 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "160 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "161 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "162 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "163 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "164 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "165 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "166 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "167 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "168 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "169 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "170 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "171 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "172 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "173 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "174 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "175 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "176 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "177 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "178 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "179 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "180 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "181 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "182 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "183 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "184 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "185 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "186 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "187 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "188 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "189 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "190 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "191 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "192 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "193 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "194 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "195 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "196 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "197 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "198 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "199 Train Loss 7.751223e-06 Test MSE 3.019956813253475e-09 Test RE 0.0001598215142447796\n",
      "Training time: 3.02\n",
      "Training time: 3.02\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 2.236677 Test MSE 0.015461366609086357 Test RE 0.36162530579950214\n",
      "1 Train Loss 0.026382625 Test MSE 4.191815896409031e-05 Test RE 0.018829378046239964\n",
      "2 Train Loss 0.0006028397 Test MSE 1.2872854271943086e-06 Test RE 0.003299683623365443\n",
      "3 Train Loss 6.965771e-05 Test MSE 1.1769053533299721e-07 Test RE 0.0009977130299741728\n",
      "4 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "5 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "6 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "7 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "8 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "9 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "10 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "11 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "12 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "13 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "14 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "15 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "16 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "17 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "18 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "19 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "20 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "21 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "22 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "23 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "24 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "25 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "26 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "27 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "28 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "29 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "30 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "31 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "32 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "33 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "34 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "35 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "36 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "37 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "38 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "39 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "40 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "41 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "42 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "43 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "44 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "45 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "46 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "47 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "48 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "49 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "50 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "51 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "52 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "53 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "54 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "55 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "56 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "57 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "58 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "59 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "60 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "61 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "62 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "63 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "64 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "65 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "66 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "67 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "68 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "69 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "70 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "71 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "72 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "73 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "74 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "75 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "76 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "77 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "78 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "79 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "80 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "81 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "82 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "83 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "84 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "85 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "86 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "87 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "88 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "89 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "90 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "91 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "92 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "93 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "94 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "95 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "96 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "97 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "98 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "99 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "100 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "101 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "102 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "103 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "104 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "105 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "106 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "107 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "108 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "109 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "110 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "111 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "112 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "113 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "114 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "115 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "116 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "117 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "118 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "119 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "120 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "121 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "122 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "123 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "124 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "125 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "126 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "127 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "128 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "129 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "130 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "131 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "132 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "133 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "134 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "135 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "136 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "137 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "138 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "139 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "140 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "141 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "142 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "143 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "144 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "145 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "146 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "147 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "148 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "149 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "150 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "151 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "152 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "153 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "154 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "155 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "156 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "157 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "158 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "159 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "160 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "161 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "162 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "163 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "164 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "165 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "166 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "167 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "168 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "169 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "170 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "171 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "172 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "173 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "174 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "175 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "176 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "177 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "178 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "179 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "180 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "181 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "182 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "183 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "184 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "185 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "186 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "187 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "188 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "189 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "190 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "191 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "192 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "193 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "194 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "195 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "196 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "197 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "198 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "199 Train Loss 6.905438e-05 Test MSE 9.495405101679708e-08 Test RE 0.0008961725222681279\n",
      "Training time: 2.89\n",
      "Training time: 2.89\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 5.846744 Test MSE 0.18921555875693943 Test RE 1.265066330433664\n",
      "1 Train Loss 0.022588765 Test MSE 0.009152005043404344 Test RE 0.27822298150343727\n",
      "2 Train Loss 0.003497466 Test MSE 0.00026581521608546785 Test RE 0.04741598684684984\n",
      "3 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "4 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "5 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "6 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "7 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "8 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "9 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "10 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "11 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "12 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "13 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "14 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "15 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "16 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "17 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "18 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "19 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "20 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "21 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "22 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "23 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "24 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "25 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "26 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "27 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "28 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "29 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "30 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "31 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "32 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "33 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "34 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "35 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "36 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "37 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "38 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "39 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "40 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "41 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "42 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "43 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "44 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "45 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "46 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "47 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "48 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "49 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "50 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "51 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "52 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "53 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "54 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "55 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "56 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "57 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "58 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "59 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "60 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "61 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "62 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "63 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "64 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "65 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "66 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "67 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "68 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "69 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "70 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "71 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "72 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "73 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "74 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "75 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "76 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "77 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "78 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "79 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "80 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "81 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "82 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "83 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "84 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "85 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "86 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "87 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "88 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "89 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "90 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "91 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "92 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "93 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "94 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "95 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "96 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "97 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "98 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "99 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "100 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "101 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "102 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "103 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "104 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "105 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "106 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "107 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "108 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "109 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "110 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "111 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "112 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "113 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "114 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "115 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "116 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "117 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "118 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "119 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "120 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "121 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "122 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "123 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "124 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "125 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "126 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "127 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "128 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "129 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "130 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "131 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "132 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "133 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "134 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "135 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "136 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "137 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "138 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "139 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "140 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "141 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "142 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "143 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "144 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "145 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "146 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "147 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "148 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "149 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "150 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "151 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "152 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "153 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "154 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "155 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "156 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "157 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "158 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "159 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "160 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "161 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "162 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "163 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "164 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "165 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "166 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "167 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "168 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "169 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "170 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "171 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "172 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "173 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "174 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "175 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "176 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "177 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "178 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "179 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "180 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "181 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "182 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "183 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "184 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "185 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "186 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "187 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "188 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "189 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "190 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "191 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "192 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "193 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "194 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "195 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "196 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "197 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "198 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "199 Train Loss 9.706189e-06 Test MSE 6.480544676459465e-09 Test RE 0.00023412113959805353\n",
      "Training time: 2.85\n",
      "Training time: 2.85\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 3.0386283 Test MSE 0.23633390505267698 Test RE 1.4138322715221416\n",
      "1 Train Loss 0.02560405 Test MSE 0.0023794465599843244 Test RE 0.1418642128375505\n",
      "2 Train Loss 0.013359037 Test MSE 6.338906227324353e-05 Test RE 0.02315485355094971\n",
      "3 Train Loss 0.0001776391 Test MSE 4.772103245858645e-06 Test RE 0.006353159965333356\n",
      "4 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "5 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "6 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "7 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "8 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "9 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "10 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "11 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "12 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "13 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "14 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "15 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "16 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "17 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "18 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "19 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "20 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "21 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "22 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "23 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "24 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "25 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "26 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "27 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "28 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "29 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "30 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "31 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "32 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "33 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "34 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "35 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "36 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "37 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "38 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "39 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "40 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "41 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "42 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "43 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "44 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "45 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "46 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "47 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "48 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "49 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "50 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "51 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "52 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "53 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "54 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "55 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "56 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "57 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "58 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "59 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "60 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "61 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "62 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "63 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "64 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "65 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "66 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "67 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "68 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "69 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "70 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "71 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "72 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "73 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "74 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "75 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "76 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "77 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "78 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "79 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "80 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "81 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "82 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "83 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "84 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "85 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "86 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "87 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "88 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "89 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "90 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "91 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "92 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "93 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "94 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "95 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "96 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "97 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "98 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "99 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "100 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "101 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "102 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "103 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "104 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "105 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "106 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "107 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "108 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "109 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "110 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "111 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "112 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "113 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "114 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "115 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "116 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "117 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "118 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "119 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "120 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "121 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "122 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "123 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "124 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "125 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "126 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "127 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "128 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "129 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "130 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "131 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "132 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "133 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "134 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "135 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "136 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "137 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "138 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "139 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "140 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "141 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "142 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "143 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "144 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "145 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "146 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "147 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "148 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "149 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "150 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "151 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "152 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "153 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "154 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "155 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "156 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "157 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "158 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "159 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "160 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "161 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "162 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "163 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "164 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "165 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "166 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "167 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "168 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "169 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "170 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "171 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "172 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "173 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "174 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "175 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "176 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "177 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "178 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "179 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "180 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "181 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "182 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "183 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "184 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "185 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "186 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "187 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "188 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "189 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "190 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "191 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "192 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "193 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "194 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "195 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "196 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "197 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "198 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "199 Train Loss 0.00012069102 Test MSE 3.492858649941031e-08 Test RE 0.0005435323284382592\n",
      "Training time: 3.25\n",
      "Training time: 3.25\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 5.291438 Test MSE 0.06353867014163898 Test RE 0.733084328263303\n",
      "1 Train Loss 0.0544358 Test MSE 0.0001501720422362252 Test RE 0.035639320762443125\n",
      "2 Train Loss 0.018404346 Test MSE 0.0004931195693968274 Test RE 0.06458192617276706\n",
      "3 Train Loss 0.0037580132 Test MSE 7.463377348412212e-05 Test RE 0.025124797780132872\n",
      "4 Train Loss 0.0016497344 Test MSE 3.2941039944753724e-05 Test RE 0.016691813658501864\n",
      "5 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "6 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "7 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "8 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "9 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "10 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "11 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "12 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "13 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "14 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "15 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "16 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "17 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "18 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "19 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "20 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "21 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "22 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "23 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "24 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "25 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "26 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "27 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "28 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "29 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "30 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "31 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "32 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "33 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "34 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "35 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "36 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "37 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "38 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "39 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "40 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "41 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "42 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "43 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "44 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "45 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "46 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "47 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "48 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "49 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "50 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "51 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "52 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "53 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "54 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "55 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "56 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "57 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "58 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "59 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "60 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "61 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "62 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "63 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "64 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "65 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "66 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "67 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "68 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "69 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "70 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "71 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "72 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "73 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "74 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "75 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "76 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "77 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "78 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "79 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "80 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "81 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "82 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "83 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "84 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "85 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "86 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "87 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "88 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "89 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "90 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "91 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "92 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "93 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "94 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "95 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "96 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "97 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "98 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "99 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "100 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "101 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "102 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "103 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "104 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "105 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "106 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "107 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "108 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "109 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "110 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "111 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "112 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "113 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "114 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "115 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "116 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "117 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "118 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "119 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "120 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "121 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "122 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "123 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "124 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "125 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "126 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "127 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "128 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "129 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "130 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "131 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "132 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "133 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "134 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "135 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "136 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "137 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "138 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "139 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "140 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "141 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "142 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "143 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "144 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "145 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "146 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "147 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "148 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "149 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "150 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "151 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "152 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "153 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "154 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "155 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "156 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "157 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "158 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "159 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "160 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "161 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "162 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "163 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "164 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "165 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "166 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "167 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "168 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "169 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "170 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "171 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "172 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "173 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "174 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "175 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "176 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "177 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "178 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "179 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "180 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "181 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "182 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "183 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "184 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "185 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "186 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "187 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "188 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "189 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "190 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "191 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "192 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "193 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "194 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "195 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "196 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "197 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "198 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "199 Train Loss 1.7101738e-05 Test MSE 6.03680867116089e-08 Test RE 0.0007145598015110955\n",
      "Training time: 3.77\n",
      "Training time: 3.77\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 2.100875 Test MSE 0.005893842371286261 Test RE 0.22327193345424923\n",
      "1 Train Loss 0.004212166 Test MSE 2.4905421786627485e-05 Test RE 0.01451382310192317\n",
      "2 Train Loss 4.8670856e-05 Test MSE 2.2379002380123712e-08 Test RE 0.0004350660914065546\n",
      "3 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "4 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "5 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "6 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "7 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "8 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "9 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "10 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "11 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "12 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "13 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "14 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "15 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "16 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "17 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "18 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "19 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "20 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "21 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "22 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "23 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "24 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "25 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "26 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "27 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "28 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "29 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "30 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "31 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "32 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "33 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "34 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "35 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "36 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "37 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "38 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "39 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "40 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "41 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "42 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "43 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "44 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "45 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "46 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "47 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "48 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "49 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "50 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "51 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "52 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "53 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "54 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "55 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "56 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "57 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "58 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "59 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "60 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "61 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "62 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "63 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "64 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "65 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "66 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "67 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "68 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "69 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "70 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "71 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "72 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "73 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "74 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "75 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "76 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "77 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "78 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "79 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "80 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "81 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "82 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "83 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "84 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "85 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "86 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "87 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "88 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "89 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "90 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "91 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "92 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "93 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "94 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "95 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "96 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "97 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "98 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "99 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "100 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "101 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "102 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "103 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "104 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "105 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "106 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "107 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "108 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "109 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "110 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "111 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "112 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "113 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "114 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "115 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "116 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "117 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "118 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "119 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "120 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "121 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "122 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "123 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "124 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "125 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "126 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "127 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "128 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "129 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "130 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "131 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "132 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "133 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "134 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "135 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "136 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "137 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "138 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "139 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "140 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "141 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "142 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "143 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "144 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "145 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "146 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "147 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "148 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "149 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "150 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "151 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "152 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "153 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "154 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "155 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "156 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "157 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "158 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "159 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "160 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "161 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "162 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "163 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "164 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "165 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "166 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "167 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "168 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "169 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "170 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "171 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "172 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "173 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "174 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "175 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "176 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "177 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "178 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "179 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "180 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "181 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "182 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "183 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "184 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "185 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "186 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "187 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "188 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "189 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "190 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "191 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "192 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "193 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "194 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "195 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "196 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "197 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "198 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "199 Train Loss 4.3380565e-05 Test MSE 1.1535916290683398e-08 Test RE 0.0003123639621110652\n",
      "Training time: 2.90\n",
      "Training time: 2.90\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 4.649429 Test MSE 0.025481100982835785 Test RE 0.4642415092087421\n",
      "1 Train Loss 0.0057581295 Test MSE 0.00036272819877586576 Test RE 0.05538925637124421\n",
      "2 Train Loss 0.00068046176 Test MSE 0.00023521382017098577 Test RE 0.04460322823444908\n",
      "3 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "4 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "5 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "6 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "7 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "8 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "9 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "10 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "11 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "12 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "13 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "14 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "15 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "16 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "17 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "18 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "19 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "20 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "21 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "22 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "23 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "24 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "25 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "26 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "27 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "28 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "29 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "30 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "31 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "32 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "33 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "34 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "35 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "36 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "37 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "38 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "39 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "40 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "41 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "42 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "43 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "44 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "45 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "46 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "47 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "48 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "49 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "50 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "51 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "52 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "53 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "54 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "55 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "56 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "57 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "58 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "59 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "60 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "61 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "62 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "63 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "64 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "65 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "66 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "67 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "68 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "69 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "70 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "71 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "72 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "73 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "74 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "75 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "76 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "77 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "78 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "79 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "80 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "81 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "82 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "83 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "84 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "85 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "86 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "87 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "88 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "89 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "90 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "91 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "92 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "93 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "94 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "95 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "96 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "97 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "98 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "99 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "100 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "101 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "102 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "103 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "104 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "105 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "106 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "107 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "108 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "109 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "110 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "111 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "112 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "113 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "114 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "115 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "116 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "117 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "118 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "119 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "120 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "121 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "122 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "123 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "124 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "125 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "126 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "127 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "128 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "129 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "130 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "131 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "132 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "133 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "134 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "135 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "136 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "137 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "138 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "139 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "140 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "141 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "142 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "143 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "144 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "145 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "146 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "147 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "148 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "149 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "150 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "151 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "152 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "153 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "154 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "155 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "156 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "157 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "158 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "159 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "160 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "161 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "162 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "163 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "164 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "165 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "166 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "167 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "168 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "169 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "170 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "171 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "172 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "173 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "174 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "175 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "176 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "177 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "178 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "179 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "180 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "181 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "182 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "183 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "184 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "185 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "186 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "187 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "188 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "189 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "190 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "191 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "192 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "193 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "194 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "195 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "196 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "197 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "198 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "199 Train Loss 7.861406e-06 Test MSE 2.574238597185083e-08 Test RE 0.0004666156210822397\n",
      "Training time: 3.02\n",
      "Training time: 3.02\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 3.0588655 Test MSE 0.41636973328064814 Test RE 1.876611835645187\n",
      "1 Train Loss 0.19756863 Test MSE 0.02101363581019942 Test RE 0.42158531571436964\n",
      "2 Train Loss 0.017178174 Test MSE 4.141429149813962e-06 Test RE 0.005918477391001002\n",
      "3 Train Loss 3.8477898e-05 Test MSE 2.7222608054869166e-08 Test RE 0.0004798436368876867\n",
      "4 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "5 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "6 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "7 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "8 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "9 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "10 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "11 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "12 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "13 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "14 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "15 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "16 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "17 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "18 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "19 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "20 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "21 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "22 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "23 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "24 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "25 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "26 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "27 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "28 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "29 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "30 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "31 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "32 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "33 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "34 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "35 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "36 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "37 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "38 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "39 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "40 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "41 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "42 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "43 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "44 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "45 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "46 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "47 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "48 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "49 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "50 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "51 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "52 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "53 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "54 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "55 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "56 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "57 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "58 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "59 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "60 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "61 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "62 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "63 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "64 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "65 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "66 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "67 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "68 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "69 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "70 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "71 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "72 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "73 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "74 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "75 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "76 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "77 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "78 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "79 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "80 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "81 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "82 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "83 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "84 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "85 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "86 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "87 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "88 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "89 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "90 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "91 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "92 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "93 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "94 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "95 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "96 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "97 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "98 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "99 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "100 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "101 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "102 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "103 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "104 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "105 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "106 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "107 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "108 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "109 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "110 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "111 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "112 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "113 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "114 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "115 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "116 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "117 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "118 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "119 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "120 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "121 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "122 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "123 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "124 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "125 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "126 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "127 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "128 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "129 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "130 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "131 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "132 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "133 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "134 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "135 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "136 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "137 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "138 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "139 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "140 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "141 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "142 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "143 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "144 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "145 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "146 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "147 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "148 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "149 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "150 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "151 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "152 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "153 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "154 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "155 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "156 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "157 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "158 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "159 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "160 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "161 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "162 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "163 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "164 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "165 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "166 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "167 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "168 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "169 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "170 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "171 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "172 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "173 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "174 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "175 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "176 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "177 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "178 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "179 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "180 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "181 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "182 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "183 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "184 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "185 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "186 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "187 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "188 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "189 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "190 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "191 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "192 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "193 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "194 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "195 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "196 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "197 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "198 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "199 Train Loss 3.5242094e-05 Test MSE 3.2471626731740984e-08 Test RE 0.0005240671019435465\n",
      "Training time: 3.09\n",
      "Training time: 3.09\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 6.0696383 Test MSE 0.05478597768018908 Test RE 0.680721680877762\n",
      "1 Train Loss 0.022344436 Test MSE 0.00027752646792308304 Test RE 0.048449252301841\n",
      "2 Train Loss 0.0074826526 Test MSE 7.82338526840286e-06 Test RE 0.008134525667980742\n",
      "3 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "4 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "5 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "6 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "7 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "8 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "9 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "10 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "11 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "12 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "13 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "14 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "15 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "16 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "17 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "18 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "19 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "20 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "21 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "22 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "23 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "24 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "25 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "26 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "27 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "28 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "29 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "30 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "31 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "32 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "33 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "34 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "35 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "36 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "37 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "38 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "39 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "40 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "41 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "42 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "43 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "44 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "45 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "46 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "47 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "48 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "49 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "50 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "51 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "52 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "53 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "54 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "55 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "56 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "57 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "58 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "59 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "60 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "61 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "62 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "63 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "64 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "65 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "66 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "67 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "68 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "69 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "70 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "71 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "72 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "73 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "74 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "75 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "76 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "77 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "78 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "79 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "80 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "81 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "82 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "83 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "84 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "85 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "86 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "87 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "88 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "89 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "90 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "91 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "92 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "93 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "94 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "95 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "96 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "97 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "98 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "99 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "100 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "101 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "102 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "103 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "104 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "105 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "106 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "107 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "108 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "109 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "110 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "111 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "112 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "113 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "114 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "115 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "116 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "117 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "118 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "119 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "120 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "121 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "122 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "123 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "124 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "125 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "126 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "127 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "128 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "129 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "130 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "131 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "132 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "133 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "134 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "135 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "136 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "137 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "138 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "139 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "140 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "141 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "142 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "143 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "144 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "145 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "146 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "147 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "148 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "149 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "150 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "151 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "152 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "153 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "154 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "155 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "156 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "157 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "158 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "159 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "160 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "161 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "162 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "163 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "164 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "165 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "166 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "167 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "168 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "169 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "170 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "171 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "172 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "173 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "174 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "175 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "176 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "177 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "178 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "179 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "180 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "181 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "182 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "183 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "184 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "185 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "186 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "187 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "188 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "189 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "190 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "191 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "192 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "193 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "194 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "195 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "196 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "197 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "198 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "199 Train Loss 0.00010193895 Test MSE 4.777160882475959e-08 Test RE 0.0006356525720818013\n",
      "Training time: 3.14\n",
      "Training time: 3.14\n"
     ]
    }
   ],
   "source": [
    " \n",
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  beta_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers)\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "7ef8bb86-89cf-4917-9bf1-6cda3bafbc51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1D_FODE_swish_low'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "bb023909-b810-4d9b-857a-cc29fc84d142"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_swish_tune4.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_swish_tune4.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9991/2114102953.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_swish_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_swish_tune4.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(4,5):\n",
    "    label = \"1D_FODE_swish_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(i,' ',np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "swish_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
