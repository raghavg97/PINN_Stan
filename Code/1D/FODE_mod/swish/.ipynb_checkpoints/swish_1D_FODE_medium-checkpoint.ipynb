{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "12aa433d-9505-4460-d56f-b6a376e9ccb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "4778640e-2987-401e-f7cb-585a0f18a01a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "63653bcd-0776-4d8a-c31d-d2238f724ffe"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/swish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "d48278bc-c428-4c93-93f7-f711d3b81f62"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "level = \"medium\"\n",
    "label = \"1D_FODE_swish_\"+level\n",
    "\n",
    "extent = 20.0\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(extent,-1.0*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "              \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "       \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "      \n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "  print(rep) \n",
    "  torch.manual_seed(rep*11)\n",
    "  start_time = time.time() \n",
    "  thresh_flag = 0\n",
    "  x_coll = torch.from_numpy(colloc_pts(N_f,123)).float().to(device)\n",
    "  f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "  loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "  data_update(loss_np)\n",
    "\n",
    "  for i in range(max_iter):\n",
    "    \n",
    "    train_step(i)\n",
    "\n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    if(thresh_flag == 0):\n",
    "        if(loss_np < loss_thresh):\n",
    "            time_threshold[rep] = time.time() - start_time\n",
    "            epoch_threshold[rep] = i+1            \n",
    "            thresh_flag = 1       \n",
    "    data_update(loss_np)\n",
    "    print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "\n",
    "  elapsed_time[rep] = time.time() - start_time  \n",
    "  print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "2bf8b190-81d6-4793-b63a-bc5565d05793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 15555.671 Test MSE 10311.517834277074 Test RE 1.1313986363853175\n",
      "1 Train Loss 9016.923 Test MSE 3610.0840060645887 Test RE 0.6694420776009953\n",
      "2 Train Loss 4320.0093 Test MSE 166.1901341869061 Test RE 0.1436339062299193\n",
      "3 Train Loss 3915.0967 Test MSE 77.26669684250228 Test RE 0.09793784092482395\n",
      "4 Train Loss 3573.233 Test MSE 40.73464164104517 Test RE 0.07111092081436594\n",
      "5 Train Loss 3465.417 Test MSE 70.57787273520846 Test RE 0.09360275565214397\n",
      "6 Train Loss 3141.775 Test MSE 52.71097666763002 Test RE 0.08089187162387196\n",
      "7 Train Loss 2962.9756 Test MSE 48.219800444249266 Test RE 0.077369013024639\n",
      "8 Train Loss 2896.4329 Test MSE 60.90039265697711 Test RE 0.08694896139692719\n",
      "9 Train Loss 2847.7979 Test MSE 60.69888290420209 Test RE 0.0868049920349539\n",
      "10 Train Loss 2772.8975 Test MSE 37.24547179983569 Test RE 0.06799720981985986\n",
      "11 Train Loss 2642.3335 Test MSE 55.97198491315271 Test RE 0.08335654520270457\n",
      "12 Train Loss 2570.172 Test MSE 50.42730591223853 Test RE 0.07912017435062535\n",
      "13 Train Loss 2517.5784 Test MSE 54.66925032622795 Test RE 0.08238078226852452\n",
      "14 Train Loss 2392.978 Test MSE 68.03721494185908 Test RE 0.09190256151101799\n",
      "15 Train Loss 2255.373 Test MSE 38.05161617906157 Test RE 0.06872913943050242\n",
      "16 Train Loss 2134.993 Test MSE 80.18120078973982 Test RE 0.09976785391839006\n",
      "17 Train Loss 1971.388 Test MSE 29.708557200993 Test RE 0.06072886057218123\n",
      "18 Train Loss 1838.6577 Test MSE 38.96977652548805 Test RE 0.06955339125719648\n",
      "19 Train Loss 1734.8722 Test MSE 25.519447400477798 Test RE 0.056284652007056214\n",
      "20 Train Loss 1593.0483 Test MSE 28.551745236460008 Test RE 0.05953477028706888\n",
      "21 Train Loss 1459.3939 Test MSE 81.13610912925127 Test RE 0.10036018218381146\n",
      "22 Train Loss 1358.3029 Test MSE 32.51237396637222 Test RE 0.06352997628027122\n",
      "23 Train Loss 1322.8835 Test MSE 40.51864199158428 Test RE 0.07092213371051755\n",
      "24 Train Loss 1304.354 Test MSE 44.56594531716504 Test RE 0.07437995544614358\n",
      "25 Train Loss 1286.2565 Test MSE 37.69133984751413 Test RE 0.06840299858740684\n",
      "26 Train Loss 1272.2369 Test MSE 36.17947953197662 Test RE 0.06701708131772004\n",
      "27 Train Loss 1255.4198 Test MSE 41.35409844801978 Test RE 0.07164957703607398\n",
      "28 Train Loss 1201.9775 Test MSE 32.54383408731036 Test RE 0.06356070577235857\n",
      "29 Train Loss 1186.2126 Test MSE 35.804606376537535 Test RE 0.066668978994643\n",
      "30 Train Loss 1151.9607 Test MSE 30.705884023440827 Test RE 0.06173979099849684\n",
      "31 Train Loss 1083.9495 Test MSE 32.65105045386599 Test RE 0.06366532074033507\n",
      "32 Train Loss 1042.7643 Test MSE 24.658267398329226 Test RE 0.055326810079026824\n",
      "33 Train Loss 1011.29297 Test MSE 14.625094694167233 Test RE 0.04260923094798129\n",
      "34 Train Loss 972.8591 Test MSE 12.977230092687105 Test RE 0.04013704125317314\n",
      "35 Train Loss 945.7399 Test MSE 10.917119088879772 Test RE 0.03681360738300229\n",
      "36 Train Loss 885.51154 Test MSE 14.125919342221302 Test RE 0.04187576109195123\n",
      "37 Train Loss 844.0789 Test MSE 8.477062999414454 Test RE 0.03243971706670145\n",
      "38 Train Loss 783.15924 Test MSE 7.351019960460168 Test RE 0.03020842991323394\n",
      "39 Train Loss 707.49316 Test MSE 17.36571330983669 Test RE 0.04643021191315547\n",
      "40 Train Loss 652.7511 Test MSE 7.946959791130423 Test RE 0.031409054286564944\n",
      "41 Train Loss 577.61035 Test MSE 12.02333290257899 Test RE 0.03863374316943227\n",
      "42 Train Loss 529.64886 Test MSE 18.161548235931374 Test RE 0.04748219492934119\n",
      "43 Train Loss 466.08792 Test MSE 29.433038739925298 Test RE 0.06044660357510087\n",
      "44 Train Loss 432.9021 Test MSE 15.47923368293512 Test RE 0.043835814521040344\n",
      "45 Train Loss 409.35764 Test MSE 16.103881011288962 Test RE 0.04471154003077291\n",
      "46 Train Loss 199.68826 Test MSE 49.01364545797577 Test RE 0.07800327818380377\n",
      "47 Train Loss 81.74348 Test MSE 8.165702212228766 Test RE 0.03183839169118719\n",
      "48 Train Loss 56.416077 Test MSE 2.295432794191978 Test RE 0.01688055197047349\n",
      "49 Train Loss 43.279312 Test MSE 0.48557406431918987 Test RE 0.007763938620766134\n",
      "50 Train Loss 38.75587 Test MSE 0.9972790522540989 Test RE 0.011126605771404561\n",
      "51 Train Loss 29.791998 Test MSE 0.33608074901599 Test RE 0.00645916190329238\n",
      "52 Train Loss 27.935686 Test MSE 0.41142561825451573 Test RE 0.007146608927819355\n",
      "53 Train Loss 25.39916 Test MSE 0.29130685961262603 Test RE 0.006013533131395439\n",
      "54 Train Loss 22.793905 Test MSE 0.1661667861572992 Test RE 0.004541783858214082\n",
      "55 Train Loss 20.962093 Test MSE 0.12062856253485418 Test RE 0.00386971898948777\n",
      "56 Train Loss 20.113482 Test MSE 0.1796480816445328 Test RE 0.004722431252637294\n",
      "57 Train Loss 19.54448 Test MSE 0.06288296363997622 Test RE 0.0027939643034814387\n",
      "58 Train Loss 18.126282 Test MSE 0.042712508952006026 Test RE 0.0023026710122001307\n",
      "59 Train Loss 17.848166 Test MSE 0.04098613546253137 Test RE 0.002255655843383644\n",
      "60 Train Loss 17.467514 Test MSE 0.09045314228771614 Test RE 0.0033509363732927453\n",
      "61 Train Loss 17.331842 Test MSE 0.06896032726224338 Test RE 0.0029258631503463867\n",
      "62 Train Loss 16.792006 Test MSE 0.1381545217234273 Test RE 0.00414130201992189\n",
      "63 Train Loss 16.445032 Test MSE 0.08646683012423591 Test RE 0.003276265747106989\n",
      "64 Train Loss 16.10439 Test MSE 0.05086864252863018 Test RE 0.0025129244186383815\n",
      "65 Train Loss 15.941347 Test MSE 0.05227721472206475 Test RE 0.002547478766027206\n",
      "66 Train Loss 15.466562 Test MSE 0.05739341771219665 Test RE 0.002669226304028828\n",
      "67 Train Loss 14.669914 Test MSE 0.03340886243775522 Test RE 0.0020365036673015125\n",
      "68 Train Loss 14.088373 Test MSE 0.05311220312924282 Test RE 0.0025677427440315512\n",
      "69 Train Loss 13.971755 Test MSE 0.05966890897907733 Test RE 0.0027216257224413503\n",
      "70 Train Loss 13.660104 Test MSE 0.032708457459608715 Test RE 0.0020150433049535626\n",
      "71 Train Loss 13.182423 Test MSE 0.0452295794750406 Test RE 0.0023695486364601575\n",
      "72 Train Loss 13.020371 Test MSE 0.04583507164789544 Test RE 0.002385356579920908\n",
      "73 Train Loss 12.71755 Test MSE 0.047755904202325554 Test RE 0.0024348257636959115\n",
      "74 Train Loss 12.330326 Test MSE 0.05002974350440167 Test RE 0.0024921173602010216\n",
      "75 Train Loss 11.921946 Test MSE 0.028646451360458836 Test RE 0.001885774538265458\n",
      "76 Train Loss 11.703158 Test MSE 0.023313230898374088 Test RE 0.0017012008258271974\n",
      "77 Train Loss 11.47441 Test MSE 0.03497261782412186 Test RE 0.0020836195486190726\n",
      "78 Train Loss 10.596764 Test MSE 0.05554222073906351 Test RE 0.002625826170285907\n",
      "79 Train Loss 10.086091 Test MSE 0.023482656524478982 Test RE 0.001707371254289051\n",
      "80 Train Loss 9.301421 Test MSE 0.035794050365634496 Test RE 0.0021079474249032816\n",
      "81 Train Loss 8.566305 Test MSE 0.021952016407275624 Test RE 0.0016507889823627311\n",
      "82 Train Loss 7.7828894 Test MSE 0.01726175440681519 Test RE 0.0014638508155912075\n",
      "83 Train Loss 7.4109874 Test MSE 0.01428140706935789 Test RE 0.0013314959551296453\n",
      "84 Train Loss 6.917422 Test MSE 0.04056994539423283 Test RE 0.0022441741933126023\n",
      "85 Train Loss 6.5753894 Test MSE 0.01134112588186219 Test RE 0.0011865401484266534\n",
      "86 Train Loss 6.4181414 Test MSE 0.015544087447831487 Test RE 0.001389111055607023\n",
      "87 Train Loss 6.215454 Test MSE 0.010310512093283977 Test RE 0.0011313434591672727\n",
      "88 Train Loss 6.070968 Test MSE 0.012866348458854761 Test RE 0.0012638106388106307\n",
      "89 Train Loss 5.5516214 Test MSE 0.018031057643007796 Test RE 0.0014961149174970855\n",
      "90 Train Loss 5.32827 Test MSE 0.013256348299990554 Test RE 0.0012828217228291624\n",
      "91 Train Loss 5.200746 Test MSE 0.009813650411394315 Test RE 0.0011037472739015277\n",
      "92 Train Loss 4.9268355 Test MSE 0.044432641262233265 Test RE 0.002348580320637941\n",
      "93 Train Loss 4.730978 Test MSE 0.011851459779640363 Test RE 0.001212942674231354\n",
      "94 Train Loss 4.692078 Test MSE 0.011068299053701434 Test RE 0.0011721813162524268\n",
      "95 Train Loss 3.973185 Test MSE 0.05352481432668967 Test RE 0.002577697421239704\n",
      "96 Train Loss 3.6622884 Test MSE 0.0048116531242586615 Test RE 0.0007728612053494058\n",
      "97 Train Loss 3.5928845 Test MSE 0.005197104024244618 Test RE 0.0008032210050287165\n",
      "98 Train Loss 3.534966 Test MSE 0.01110667336358194 Test RE 0.0011742115617273386\n",
      "99 Train Loss 3.395083 Test MSE 0.005633344488297957 Test RE 0.0008362526505230281\n",
      "100 Train Loss 3.147079 Test MSE 0.010556430479630235 Test RE 0.0011447559205547105\n",
      "101 Train Loss 2.99659 Test MSE 0.00891458102043362 Test RE 0.0010519735504127539\n",
      "102 Train Loss 2.911225 Test MSE 0.015771311803421163 Test RE 0.0013992272721401902\n",
      "103 Train Loss 2.8384664 Test MSE 0.011986946991313092 Test RE 0.0012198562193295672\n",
      "104 Train Loss 2.800849 Test MSE 0.012596743335665425 Test RE 0.0012504994141433426\n",
      "105 Train Loss 2.758521 Test MSE 0.013604038313935876 Test RE 0.0012995358822009428\n",
      "106 Train Loss 2.6766312 Test MSE 0.010492981162989249 Test RE 0.0011413104636977336\n",
      "107 Train Loss 2.6351383 Test MSE 0.009812547467053356 Test RE 0.0011036852477458554\n",
      "108 Train Loss 2.5614917 Test MSE 0.003287758197630175 Test RE 0.0006388579256418875\n",
      "109 Train Loss 2.4276383 Test MSE 0.024405108491528698 Test RE 0.0017405829444617639\n",
      "110 Train Loss 2.3482883 Test MSE 0.0030261314277413675 Test RE 0.0006129121707157978\n",
      "111 Train Loss 2.2945638 Test MSE 0.004857654109884355 Test RE 0.0007765468209739272\n",
      "112 Train Loss 2.2720544 Test MSE 0.005247025783424724 Test RE 0.0008070695303231686\n",
      "113 Train Loss 2.125833 Test MSE 0.005156701105471676 Test RE 0.0008000927444048053\n",
      "114 Train Loss 2.0217338 Test MSE 0.0026983049407158346 Test RE 0.0005787618106251446\n",
      "115 Train Loss 1.9372029 Test MSE 0.002531879895524973 Test RE 0.0005606294433679722\n",
      "116 Train Loss 1.8587837 Test MSE 0.003036373132608688 Test RE 0.0006139484712619125\n",
      "117 Train Loss 1.83109 Test MSE 0.0021758593630800635 Test RE 0.0005197203987427587\n",
      "118 Train Loss 1.8183146 Test MSE 0.0024244951755186678 Test RE 0.0005486116357045572\n",
      "119 Train Loss 1.7225369 Test MSE 0.0035795107607335796 Test RE 0.0006666013494753504\n",
      "120 Train Loss 1.7007682 Test MSE 0.003508339958377912 Test RE 0.000659941116682551\n",
      "121 Train Loss 1.6674644 Test MSE 0.0049211354326870495 Test RE 0.0007816044277516442\n",
      "122 Train Loss 1.637797 Test MSE 0.005319521010977638 Test RE 0.0008126258188149707\n",
      "123 Train Loss 1.6201332 Test MSE 0.005478320347275242 Test RE 0.0008246659524851148\n",
      "124 Train Loss 1.6107066 Test MSE 0.005432988783007072 Test RE 0.0008212469251960258\n",
      "125 Train Loss 1.5692651 Test MSE 0.0018387999251206725 Test RE 0.00047777298665828183\n",
      "126 Train Loss 1.5162649 Test MSE 0.004684521198035343 Test RE 0.0007625827140400063\n",
      "127 Train Loss 1.4975137 Test MSE 0.0047921108626294735 Test RE 0.0007712901421232692\n",
      "128 Train Loss 1.4612706 Test MSE 0.0041123478780683495 Test RE 0.0007144951339305051\n",
      "129 Train Loss 1.4494352 Test MSE 0.0018797196209004838 Test RE 0.0004830597916403483\n",
      "130 Train Loss 1.4332273 Test MSE 0.00177721737310686 Test RE 0.0004697043987678527\n",
      "131 Train Loss 1.4174706 Test MSE 0.0016166045307508346 Test RE 0.0004479775478417068\n",
      "132 Train Loss 1.3220026 Test MSE 0.004820178322146565 Test RE 0.000773545572930764\n",
      "133 Train Loss 1.2476046 Test MSE 0.0011525025630687272 Test RE 0.00037824683462494863\n",
      "134 Train Loss 1.2370361 Test MSE 0.0011964726017303382 Test RE 0.0003853946942303956\n",
      "135 Train Loss 1.2219652 Test MSE 0.002187317308403567 Test RE 0.0005210870102557312\n",
      "136 Train Loss 1.1742519 Test MSE 0.0011542201296176656 Test RE 0.00037852857900622886\n",
      "137 Train Loss 1.1634858 Test MSE 0.001283440466985096 Test RE 0.00039915559078240807\n",
      "138 Train Loss 1.1566203 Test MSE 0.0011458005136169827 Test RE 0.000377145437864056\n",
      "139 Train Loss 1.1526941 Test MSE 0.0010483248572552156 Test RE 0.0003607466395153456\n",
      "140 Train Loss 1.1359904 Test MSE 0.0016195377602708178 Test RE 0.00044838377751328423\n",
      "141 Train Loss 1.1187898 Test MSE 0.001048529287402618 Test RE 0.000360781811768117\n",
      "142 Train Loss 1.0931727 Test MSE 0.0013383443343577843 Test RE 0.00040760385682246295\n",
      "143 Train Loss 1.0792881 Test MSE 0.0015734037523638506 Test RE 0.00044195132790383234\n",
      "144 Train Loss 1.0684175 Test MSE 0.0011106622486501722 Test RE 0.000371317448533943\n",
      "145 Train Loss 1.0547528 Test MSE 0.0014671640885488152 Test RE 0.00042676981685339414\n",
      "146 Train Loss 1.0472008 Test MSE 0.0016333131797297937 Test RE 0.0004502866648622973\n",
      "147 Train Loss 1.0445234 Test MSE 0.0015063605585229189 Test RE 0.00043243299173446106\n",
      "148 Train Loss 1.0202982 Test MSE 0.004437324063865808 Test RE 0.000742189704902456\n",
      "149 Train Loss 0.9380626 Test MSE 0.0034397075275789794 Test RE 0.0006534541354188724\n",
      "150 Train Loss 0.8968996 Test MSE 0.00106188541549172 Test RE 0.00036307235346645054\n",
      "151 Train Loss 0.8594926 Test MSE 0.001635355548561766 Test RE 0.00045056810633577584\n",
      "152 Train Loss 0.8251356 Test MSE 0.0011190331274573324 Test RE 0.0003727141011763005\n",
      "153 Train Loss 0.7736176 Test MSE 0.0014812153301486668 Test RE 0.0004288085651126688\n",
      "154 Train Loss 0.75298786 Test MSE 0.0011707578344879864 Test RE 0.0003812307194517983\n",
      "155 Train Loss 0.7429259 Test MSE 0.0009553007126592263 Test RE 0.00034436928049497053\n",
      "156 Train Loss 0.73616195 Test MSE 0.000960836501311385 Test RE 0.0003453656169153241\n",
      "157 Train Loss 0.7262847 Test MSE 0.0020016197069143084 Test RE 0.0004984770136910253\n",
      "158 Train Loss 0.71707886 Test MSE 0.0010366815355060688 Test RE 0.00035873771207541353\n",
      "159 Train Loss 0.7100185 Test MSE 0.0007862380475445547 Test RE 0.0003124146424761515\n",
      "160 Train Loss 0.70038664 Test MSE 0.000943093452473273 Test RE 0.00034216195385229116\n",
      "161 Train Loss 0.6887985 Test MSE 0.0011380615695297518 Test RE 0.00037586962566751257\n",
      "162 Train Loss 0.679218 Test MSE 0.0010527317664801449 Test RE 0.00036150409099755683\n",
      "163 Train Loss 0.6723381 Test MSE 0.0006673827189511707 Test RE 0.0002878338261886102\n",
      "164 Train Loss 0.6601637 Test MSE 0.0006443392206902583 Test RE 0.0002828209886555259\n",
      "165 Train Loss 0.6557121 Test MSE 0.000828065676855209 Test RE 0.00032061714619348135\n",
      "166 Train Loss 0.6516692 Test MSE 0.0009600599571845189 Test RE 0.0003452260271667947\n",
      "167 Train Loss 0.64902693 Test MSE 0.0009166200152586271 Test RE 0.0003373253817086913\n",
      "168 Train Loss 0.6436258 Test MSE 0.0010212310801855664 Test RE 0.0003560544058866769\n",
      "169 Train Loss 0.6392531 Test MSE 0.001052399203007376 Test RE 0.0003614469859704152\n",
      "170 Train Loss 0.6104368 Test MSE 0.0011101870209039558 Test RE 0.00037123800078359435\n",
      "171 Train Loss 0.60180604 Test MSE 0.0006345783060668137 Test RE 0.0002806706257419716\n",
      "172 Train Loss 0.59959686 Test MSE 0.0005540764957936126 Test RE 0.00026226432333791407\n",
      "173 Train Loss 0.5980134 Test MSE 0.0006207029234047511 Test RE 0.0002775851620555209\n",
      "174 Train Loss 0.59274733 Test MSE 0.0011197098589711873 Test RE 0.00037282678294141015\n",
      "175 Train Loss 0.58761364 Test MSE 0.0006399736459067039 Test RE 0.0002818612654470483\n",
      "176 Train Loss 0.5848949 Test MSE 0.0005865234165258576 Test RE 0.0002698342229488119\n",
      "177 Train Loss 0.57784635 Test MSE 0.0006689310774633353 Test RE 0.00028816752658866653\n",
      "178 Train Loss 0.5735815 Test MSE 0.0009183126526965701 Test RE 0.00033763669185589597\n",
      "179 Train Loss 0.5507516 Test MSE 0.001690088169154256 Test RE 0.0004580459348843028\n",
      "180 Train Loss 0.52731365 Test MSE 0.00113630586581728 Test RE 0.0003755795840622509\n",
      "181 Train Loss 0.5134591 Test MSE 0.0005868738485367759 Test RE 0.000269914820267578\n",
      "182 Train Loss 0.49780244 Test MSE 0.0008010063955690108 Test RE 0.00031533512132264955\n",
      "183 Train Loss 0.48955688 Test MSE 0.0009370797061049579 Test RE 0.0003410692912140907\n",
      "184 Train Loss 0.4802712 Test MSE 0.0005413249455257388 Test RE 0.0002592288736096274\n",
      "185 Train Loss 0.4739848 Test MSE 0.0005085857580364029 Test RE 0.0002512675756894605\n",
      "186 Train Loss 0.4725489 Test MSE 0.0007316208419735529 Test RE 0.0003013681740613478\n",
      "187 Train Loss 0.47134638 Test MSE 0.0004796320542229932 Test RE 0.00024401046479782066\n",
      "188 Train Loss 0.46808475 Test MSE 0.0007886033662997595 Test RE 0.0003128842237168157\n",
      "189 Train Loss 0.46347976 Test MSE 0.0006797922210333827 Test RE 0.0002904975323758429\n",
      "190 Train Loss 0.45830205 Test MSE 0.0008064143251520946 Test RE 0.0003163978103975829\n",
      "191 Train Loss 0.45511535 Test MSE 0.0004171835687750992 Test RE 0.00022757154072377859\n",
      "192 Train Loss 0.45245805 Test MSE 0.0005480278009696611 Test RE 0.0002608288626095823\n",
      "193 Train Loss 0.45065188 Test MSE 0.0005297517338511002 Test RE 0.0002564428210346384\n",
      "194 Train Loss 0.44896013 Test MSE 0.0006439790502470938 Test RE 0.0002827419324717726\n",
      "195 Train Loss 0.44577423 Test MSE 0.0007280218421168102 Test RE 0.00030062601287727034\n",
      "196 Train Loss 0.4428599 Test MSE 0.000603899722704253 Test RE 0.00027380209539409813\n",
      "197 Train Loss 0.44002518 Test MSE 0.0006786691342831576 Test RE 0.0002902574672631629\n",
      "198 Train Loss 0.43116835 Test MSE 0.000940437342259259 Test RE 0.00034167978495563733\n",
      "199 Train Loss 0.41859376 Test MSE 0.0013427198080750054 Test RE 0.00040826960651787255\n",
      "Training time: 43.66\n",
      "Training time: 43.66\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 13667.289 Test MSE 11430.577720533882 Test RE 1.1912103078148526\n",
      "1 Train Loss 5063.278 Test MSE 119.73486202666002 Test RE 0.12191711057998425\n",
      "2 Train Loss 3801.545 Test MSE 66.11753919041587 Test RE 0.09059676556378721\n",
      "3 Train Loss 3621.9038 Test MSE 91.41858950734294 Test RE 0.10652992235880772\n",
      "4 Train Loss 3447.228 Test MSE 45.092500704170405 Test RE 0.07481807202078412\n",
      "5 Train Loss 3149.4539 Test MSE 47.97851876498888 Test RE 0.07717520118636319\n",
      "6 Train Loss 2925.2214 Test MSE 63.7716889574364 Test RE 0.08897506458946236\n",
      "7 Train Loss 2794.7832 Test MSE 58.41225547325618 Test RE 0.08515425237480277\n",
      "8 Train Loss 2701.2832 Test MSE 55.070244395190244 Test RE 0.08268235811142424\n",
      "9 Train Loss 2562.8708 Test MSE 42.00660364384519 Test RE 0.07221262575296848\n",
      "10 Train Loss 2423.915 Test MSE 30.47580552047768 Test RE 0.06150804863486621\n",
      "11 Train Loss 2285.9648 Test MSE 51.60417080934144 Test RE 0.08003809702997497\n",
      "12 Train Loss 2114.9783 Test MSE 26.70319885464874 Test RE 0.05757527185936009\n",
      "13 Train Loss 1840.1837 Test MSE 34.504299231013306 Test RE 0.06544718297757597\n",
      "14 Train Loss 1617.1721 Test MSE 36.830960639369714 Test RE 0.06761777493815307\n",
      "15 Train Loss 1463.6559 Test MSE 42.52416658192087 Test RE 0.07265612934962735\n",
      "16 Train Loss 1300.2175 Test MSE 23.689790484083233 Test RE 0.05422942033567145\n",
      "17 Train Loss 1158.8375 Test MSE 18.40612562125765 Test RE 0.04780084162072568\n",
      "18 Train Loss 1029.2715 Test MSE 17.119977592486357 Test RE 0.04610053318158745\n",
      "19 Train Loss 856.46277 Test MSE 12.616508160035545 Test RE 0.03957527476740926\n",
      "20 Train Loss 692.83594 Test MSE 13.379311191123136 Test RE 0.04075409279012481\n",
      "21 Train Loss 568.4926 Test MSE 5.107624920034912 Test RE 0.025180471095337074\n",
      "22 Train Loss 440.29504 Test MSE 3.532408364199646 Test RE 0.02094063295360398\n",
      "23 Train Loss 347.06946 Test MSE 5.991780222834587 Test RE 0.027272960904529842\n",
      "24 Train Loss 252.25014 Test MSE 2.7244816267628744 Test RE 0.018390616752159434\n",
      "25 Train Loss 175.79303 Test MSE 2.0491424332206623 Test RE 0.015949255881584346\n",
      "26 Train Loss 139.61931 Test MSE 0.8994524096023675 Test RE 0.010566799017620618\n",
      "27 Train Loss 121.12718 Test MSE 0.40528403337370283 Test RE 0.007093067612145238\n",
      "28 Train Loss 109.40607 Test MSE 0.28768001110622543 Test RE 0.005975980831345293\n",
      "29 Train Loss 97.93931 Test MSE 0.391807867580583 Test RE 0.006974144293394524\n",
      "30 Train Loss 88.42247 Test MSE 0.37284112530115054 Test RE 0.0068032472908207695\n",
      "31 Train Loss 83.590904 Test MSE 0.5339572590947195 Test RE 0.008141559476777364\n",
      "32 Train Loss 75.94176 Test MSE 0.49133360856748115 Test RE 0.007809848124720835\n",
      "33 Train Loss 67.23318 Test MSE 0.765019636324445 Test RE 0.00974519746749333\n",
      "34 Train Loss 61.44521 Test MSE 0.21233694584308477 Test RE 0.0051341332439177444\n",
      "35 Train Loss 55.029495 Test MSE 0.162031207042631 Test RE 0.004484909521135836\n",
      "36 Train Loss 49.418545 Test MSE 0.36860917949211447 Test RE 0.006764526858568929\n",
      "37 Train Loss 42.950077 Test MSE 0.24308772624599642 Test RE 0.005493332263428148\n",
      "38 Train Loss 37.39621 Test MSE 0.10815103693781157 Test RE 0.0036641200661865665\n",
      "39 Train Loss 34.141857 Test MSE 0.05846801542517869 Test RE 0.00269409886410063\n",
      "40 Train Loss 32.02216 Test MSE 0.05953106180715711 Test RE 0.0027184801534629616\n",
      "41 Train Loss 30.646393 Test MSE 0.05418690462186502 Test RE 0.002593591199489627\n",
      "42 Train Loss 27.782852 Test MSE 0.1158505788776299 Test RE 0.0037923067272154407\n",
      "43 Train Loss 24.230001 Test MSE 0.04732370154715019 Test RE 0.002423782836200381\n",
      "44 Train Loss 22.645853 Test MSE 0.11345479405235967 Test RE 0.0037528895086872357\n",
      "45 Train Loss 20.425379 Test MSE 0.06454121870365481 Test RE 0.002830563702428772\n",
      "46 Train Loss 17.455864 Test MSE 0.16034893287982782 Test RE 0.004461566693245475\n",
      "47 Train Loss 11.757323 Test MSE 0.09157850339110972 Test RE 0.0033717170593797717\n",
      "48 Train Loss 10.119691 Test MSE 0.06459829934181799 Test RE 0.002831815109499143\n",
      "49 Train Loss 9.044164 Test MSE 0.11836234759800696 Test RE 0.003833196981923381\n",
      "50 Train Loss 7.0892653 Test MSE 0.059324059876968475 Test RE 0.002713749676152667\n",
      "51 Train Loss 5.846036 Test MSE 0.014933282566313965 Test RE 0.0013615449816093035\n",
      "52 Train Loss 4.860308 Test MSE 0.008187801293621552 Test RE 0.0010081798184180288\n",
      "53 Train Loss 4.599053 Test MSE 0.010987027155047279 Test RE 0.001167869862274704\n",
      "54 Train Loss 4.4411182 Test MSE 0.012057229573095126 Test RE 0.0012234271594745887\n",
      "55 Train Loss 4.215687 Test MSE 0.025190935281947033 Test RE 0.001768383680732768\n",
      "56 Train Loss 4.0949316 Test MSE 0.012119073081771237 Test RE 0.0012265607257825168\n",
      "57 Train Loss 3.9367769 Test MSE 0.012318767977800835 Test RE 0.0012366249088170706\n",
      "58 Train Loss 3.7081952 Test MSE 0.004371205674146638 Test RE 0.0007366394494925409\n",
      "59 Train Loss 3.3700747 Test MSE 0.016254138043152875 Test RE 0.0014204839279092513\n",
      "60 Train Loss 2.9824572 Test MSE 0.003918269132427535 Test RE 0.0006974313796859103\n",
      "61 Train Loss 2.9177692 Test MSE 0.004020343878614623 Test RE 0.0007064573587768333\n",
      "62 Train Loss 2.8305476 Test MSE 0.004641006175147253 Test RE 0.000759032593884271\n",
      "63 Train Loss 2.7476292 Test MSE 0.004530448337762538 Test RE 0.0007499372804446224\n",
      "64 Train Loss 2.5123384 Test MSE 0.0033542917661103823 Test RE 0.0006452897555370235\n",
      "65 Train Loss 2.4398308 Test MSE 0.006463598699076637 Test RE 0.0008957597516308923\n",
      "66 Train Loss 2.2845511 Test MSE 0.002978345785191774 Test RE 0.0006080536660685257\n",
      "67 Train Loss 2.177157 Test MSE 0.009970099309738356 Test RE 0.001112510438198654\n",
      "68 Train Loss 2.0045187 Test MSE 0.005002047684856555 Test RE 0.0007880037171487514\n",
      "69 Train Loss 1.9263742 Test MSE 0.0073640862839208805 Test RE 0.0009561230464101924\n",
      "70 Train Loss 1.861912 Test MSE 0.006899903937513332 Test RE 0.0009254988310446521\n",
      "71 Train Loss 1.8162487 Test MSE 0.007852372676682607 Test RE 0.0009873128829720162\n",
      "72 Train Loss 1.7714461 Test MSE 0.005101194688346255 Test RE 0.0007957750192122002\n",
      "73 Train Loss 1.6762143 Test MSE 0.0026778378462016215 Test RE 0.0005765626298060105\n",
      "74 Train Loss 1.6161237 Test MSE 0.007330673445677644 Test RE 0.000953951486783648\n",
      "75 Train Loss 1.6014795 Test MSE 0.0055781116585803935 Test RE 0.0008321429804805873\n",
      "76 Train Loss 1.5672699 Test MSE 0.010809489928248673 Test RE 0.001158395743242429\n",
      "77 Train Loss 1.5432768 Test MSE 0.005779888071102533 Test RE 0.0008470597905039592\n",
      "78 Train Loss 1.5292194 Test MSE 0.006411278153740043 Test RE 0.000892126955961761\n",
      "79 Train Loss 1.5005091 Test MSE 0.004637077106450467 Test RE 0.0007587112279390414\n",
      "80 Train Loss 1.482448 Test MSE 0.003957243113782384 Test RE 0.0007008913793091169\n",
      "81 Train Loss 1.4600387 Test MSE 0.0036034856043080893 Test RE 0.0006688300048559008\n",
      "82 Train Loss 1.4186682 Test MSE 0.00451758331353083 Test RE 0.0007488717324470952\n",
      "83 Train Loss 1.3797003 Test MSE 0.0037115440512060743 Test RE 0.0006787841020588149\n",
      "84 Train Loss 1.346668 Test MSE 0.0035975116011317657 Test RE 0.0006682753682623424\n",
      "85 Train Loss 1.3125606 Test MSE 0.0023596001341443327 Test RE 0.0005412196529300028\n",
      "86 Train Loss 1.2463441 Test MSE 0.0022912127107036447 Test RE 0.0005333190014675018\n",
      "87 Train Loss 1.2104523 Test MSE 0.0014710836264958472 Test RE 0.0004273394957361114\n",
      "88 Train Loss 1.1743236 Test MSE 0.0027113414615284135 Test RE 0.0005801582334304692\n",
      "89 Train Loss 1.1365458 Test MSE 0.0032409892238587056 Test RE 0.0006342977134934443\n",
      "90 Train Loss 1.071295 Test MSE 0.003251331730380934 Test RE 0.0006353089792583233\n",
      "91 Train Loss 1.0596198 Test MSE 0.0014816022097787244 Test RE 0.0004288645618554677\n",
      "92 Train Loss 1.0559896 Test MSE 0.001991292811481821 Test RE 0.0004971894622195978\n",
      "93 Train Loss 1.0018868 Test MSE 0.001802250478112461 Test RE 0.0004730008563952394\n",
      "94 Train Loss 0.9191774 Test MSE 0.0036339139767747547 Test RE 0.0006716479190351749\n",
      "95 Train Loss 0.8643447 Test MSE 0.005627534195419458 Test RE 0.000835821279216855\n",
      "96 Train Loss 0.80263335 Test MSE 0.0016995214076360376 Test RE 0.00045932244937723585\n",
      "97 Train Loss 0.78706163 Test MSE 0.0018795188006091187 Test RE 0.0004830339870474352\n",
      "98 Train Loss 0.7824296 Test MSE 0.0022701762009774596 Test RE 0.0005308650518416246\n",
      "99 Train Loss 0.7775031 Test MSE 0.0023550182584219505 Test RE 0.00054069392695145\n",
      "100 Train Loss 0.7658241 Test MSE 0.002414384587395905 Test RE 0.0005474665352293348\n",
      "101 Train Loss 0.66163 Test MSE 0.0011415264947740576 Test RE 0.00037644137433603096\n",
      "102 Train Loss 0.6196435 Test MSE 0.0030904724194129444 Test RE 0.0006193937066802314\n",
      "103 Train Loss 0.610464 Test MSE 0.0034881265861300553 Test RE 0.00065803723830865\n",
      "104 Train Loss 0.539544 Test MSE 0.001403261505030521 Test RE 0.0004173723341588433\n",
      "105 Train Loss 0.47864023 Test MSE 0.0017202085302916487 Test RE 0.0004621095042884139\n",
      "106 Train Loss 0.4228145 Test MSE 0.0019022779762926448 Test RE 0.0004859497267817312\n",
      "107 Train Loss 0.41072407 Test MSE 0.001207421978667281 Test RE 0.00038715412498222386\n",
      "108 Train Loss 0.40821412 Test MSE 0.0011512981474908464 Test RE 0.000378049140720207\n",
      "109 Train Loss 0.40222207 Test MSE 0.0014147113148230653 Test RE 0.0004190716344151356\n",
      "110 Train Loss 0.39599055 Test MSE 0.0011934996011093903 Test RE 0.0003849155811657549\n",
      "111 Train Loss 0.37965447 Test MSE 0.0013784928725955733 Test RE 0.0004136724655906195\n",
      "112 Train Loss 0.34905207 Test MSE 0.0024095990844158477 Test RE 0.000546923704925544\n",
      "113 Train Loss 0.32001686 Test MSE 0.0011704416183251308 Test RE 0.0003811792316663224\n",
      "114 Train Loss 0.29805824 Test MSE 0.004261932990644987 Test RE 0.0007273738120514805\n",
      "115 Train Loss 0.28062347 Test MSE 0.002088448145243307 Test RE 0.0005091739782752873\n",
      "116 Train Loss 0.27205527 Test MSE 0.0012911596989351377 Test RE 0.0004003541487327007\n",
      "117 Train Loss 0.27115998 Test MSE 0.0012938028921107613 Test RE 0.0004007637310364267\n",
      "118 Train Loss 0.26900253 Test MSE 0.0009246923515987237 Test RE 0.00033880747626353083\n",
      "119 Train Loss 0.2639139 Test MSE 0.001422058314612227 Test RE 0.00042015840459119704\n",
      "120 Train Loss 0.2604141 Test MSE 0.0010536578847686695 Test RE 0.00036166306879264614\n",
      "121 Train Loss 0.25686994 Test MSE 0.0017181812196283743 Test RE 0.0004618371199540812\n",
      "122 Train Loss 0.25260782 Test MSE 0.0009735046124121418 Test RE 0.00034763489132204854\n",
      "123 Train Loss 0.24291722 Test MSE 0.0004983731114853581 Test RE 0.00024873199535591046\n",
      "124 Train Loss 0.23846331 Test MSE 0.00087099434766999 Test RE 0.00032882287385416713\n",
      "125 Train Loss 0.23464954 Test MSE 0.0010130489648583158 Test RE 0.0003546251813619267\n",
      "126 Train Loss 0.22861391 Test MSE 0.0008731140629755889 Test RE 0.00032922275435943885\n",
      "127 Train Loss 0.2264948 Test MSE 0.0009202648659181079 Test RE 0.0003379953871613599\n",
      "128 Train Loss 0.22170608 Test MSE 0.0007441887905058668 Test RE 0.0003039456375076751\n",
      "129 Train Loss 0.21739265 Test MSE 0.0006208596984533368 Test RE 0.0002776202156037157\n",
      "130 Train Loss 0.1991456 Test MSE 0.00047931824746126226 Test RE 0.00024393062790843865\n",
      "131 Train Loss 0.18813811 Test MSE 0.0002466181261214706 Test RE 0.00017497131231396479\n",
      "132 Train Loss 0.17326023 Test MSE 0.0008650390443398127 Test RE 0.00032769680526823733\n",
      "133 Train Loss 0.16360703 Test MSE 0.0007706834243502383 Test RE 0.0003093088608660725\n",
      "134 Train Loss 0.14954375 Test MSE 0.0005341252837346418 Test RE 0.00025749922164323513\n",
      "135 Train Loss 0.144108 Test MSE 0.0001842396675695862 Test RE 0.00015123277563911232\n",
      "136 Train Loss 0.14158867 Test MSE 0.00020711119834450548 Test RE 0.00016034526624549359\n",
      "137 Train Loss 0.14039722 Test MSE 0.00012026515807294094 Test RE 0.00012218679283418864\n",
      "138 Train Loss 0.13877374 Test MSE 8.610147209115785e-05 Test RE 0.00010338550196492893\n",
      "139 Train Loss 0.13780737 Test MSE 0.00010126376231988502 Test RE 0.00011211955924787761\n",
      "140 Train Loss 0.1373441 Test MSE 9.19589000885143e-05 Test RE 0.00010684427005869781\n",
      "141 Train Loss 0.1368984 Test MSE 9.77914436593988e-05 Test RE 0.00011018051071358737\n",
      "142 Train Loss 0.13528316 Test MSE 0.00010488567612767315 Test RE 0.00011410704098573303\n",
      "143 Train Loss 0.1351432 Test MSE 8.621154537203608e-05 Test RE 0.0001034515655661826\n",
      "144 Train Loss 0.13490735 Test MSE 8.122128876631032e-05 Test RE 0.00010041284924840824\n",
      "145 Train Loss 0.13399386 Test MSE 8.952270928709987e-05 Test RE 0.00010541950214593903\n",
      "146 Train Loss 0.13289502 Test MSE 0.00010778100603247918 Test RE 0.00011567126066572833\n",
      "147 Train Loss 0.13241626 Test MSE 8.616492336339837e-05 Test RE 0.00010342358919707767\n",
      "148 Train Loss 0.13175443 Test MSE 8.41896115855197e-05 Test RE 0.00010223123452597532\n",
      "149 Train Loss 0.13043624 Test MSE 8.898044435113472e-05 Test RE 0.00010509973898248942\n",
      "150 Train Loss 0.12902702 Test MSE 0.00011182650525771918 Test RE 0.00011782209175984848\n",
      "151 Train Loss 0.12641722 Test MSE 0.00011466069879136302 Test RE 0.00011930582396551491\n",
      "152 Train Loss 0.122633144 Test MSE 0.00010002147286823786 Test RE 0.00011142970354269954\n",
      "153 Train Loss 0.120346606 Test MSE 0.0001507118468843768 Test RE 0.00013678171612823263\n",
      "154 Train Loss 0.119051024 Test MSE 8.464610801446742e-05 Test RE 0.00010250802106759221\n",
      "155 Train Loss 0.11860945 Test MSE 7.427544291582294e-05 Test RE 9.602337745942739e-05\n",
      "156 Train Loss 0.11716868 Test MSE 0.00010951077177975534 Test RE 0.00011659576391350653\n",
      "157 Train Loss 0.11644473 Test MSE 7.926277001527256e-05 Test RE 9.919481577310244e-05\n",
      "158 Train Loss 0.115780674 Test MSE 7.516690638721584e-05 Test RE 9.659790122119042e-05\n",
      "159 Train Loss 0.11300385 Test MSE 7.20825034329974e-05 Test RE 9.459523991515243e-05\n",
      "160 Train Loss 0.11029089 Test MSE 8.02785616727869e-05 Test RE 9.982840763530991e-05\n",
      "161 Train Loss 0.10637032 Test MSE 8.14524287811393e-05 Test RE 0.00010055562547671949\n",
      "162 Train Loss 0.10356095 Test MSE 9.962228314645514e-05 Test RE 0.00011120712102205954\n",
      "163 Train Loss 0.10101408 Test MSE 0.00013547048392886397 Test RE 0.00012968110231607272\n",
      "164 Train Loss 0.09913259 Test MSE 0.0001362513562595593 Test RE 0.00013005431600417015\n",
      "165 Train Loss 0.0976537 Test MSE 0.00013588218901167446 Test RE 0.00012987800818293425\n",
      "166 Train Loss 0.096927844 Test MSE 7.547275764984061e-05 Test RE 9.679422829191756e-05\n",
      "167 Train Loss 0.09572725 Test MSE 0.00014758155113480566 Test RE 0.00013535377966450294\n",
      "168 Train Loss 0.095119536 Test MSE 0.0002567469141903218 Test RE 0.00017852825852732586\n",
      "169 Train Loss 0.09477244 Test MSE 9.280009218163741e-05 Test RE 0.00010733183544844498\n",
      "170 Train Loss 0.0945422 Test MSE 9.243788749386333e-05 Test RE 0.00010712216915818633\n",
      "171 Train Loss 0.094299704 Test MSE 0.00010015274965552971 Test RE 0.00011150280452998066\n",
      "172 Train Loss 0.093778744 Test MSE 0.00014848532659448424 Test RE 0.00013576759396347128\n",
      "173 Train Loss 0.09302184 Test MSE 0.00020987783721429328 Test RE 0.00016141267780265332\n",
      "174 Train Loss 0.092578895 Test MSE 8.748526992148032e-05 Test RE 0.00010421298133234702\n",
      "175 Train Loss 0.092539154 Test MSE 0.00010036821730426455 Test RE 0.00011162268311126182\n",
      "176 Train Loss 0.092485316 Test MSE 0.00012064119245461655 Test RE 0.00012237766513902706\n",
      "177 Train Loss 0.091989405 Test MSE 0.00013535937102614418 Test RE 0.00012962790918087343\n",
      "178 Train Loss 0.09094878 Test MSE 8.460763912789405e-05 Test RE 0.00010248472514966548\n",
      "179 Train Loss 0.09049829 Test MSE 0.00012684912747935604 Test RE 0.00012548681441045545\n",
      "180 Train Loss 0.0903029 Test MSE 0.00012063301996897074 Test RE 0.00012237352000986487\n",
      "181 Train Loss 0.08972235 Test MSE 0.00011584390516462097 Test RE 0.00011991981422743609\n",
      "182 Train Loss 0.08893297 Test MSE 7.54840145688673e-05 Test RE 9.680144655316761e-05\n",
      "183 Train Loss 0.08876629 Test MSE 9.384709426281902e-05 Test RE 0.0001079356142817558\n",
      "184 Train Loss 0.08793576 Test MSE 9.542225048906538e-05 Test RE 0.00010883765597072873\n",
      "185 Train Loss 0.08680571 Test MSE 0.00010493418208762644 Test RE 0.00011413342319535173\n",
      "186 Train Loss 0.0853033 Test MSE 0.00013622833124023382 Test RE 0.000130043326646919\n",
      "187 Train Loss 0.083659634 Test MSE 6.88336353538142e-05 Test RE 9.243888657378146e-05\n",
      "188 Train Loss 0.082331076 Test MSE 0.00011265867089428268 Test RE 0.00011825967032991073\n",
      "189 Train Loss 0.08145019 Test MSE 8.99462924664657e-05 Test RE 0.00010566860783103677\n",
      "190 Train Loss 0.080742575 Test MSE 0.00019910517765683628 Test RE 0.0001572155970243583\n",
      "191 Train Loss 0.08019369 Test MSE 0.000293626835294935 Test RE 0.00019092035116783168\n",
      "192 Train Loss 0.07969603 Test MSE 0.0003113139079540595 Test RE 0.00019658646529976658\n",
      "193 Train Loss 0.078746766 Test MSE 0.0002504591158130196 Test RE 0.00017632860590251093\n",
      "194 Train Loss 0.07700847 Test MSE 0.00015200634279517535 Test RE 0.00013736788367677891\n",
      "195 Train Loss 0.07502421 Test MSE 0.00035273131534035594 Test RE 0.00020925524926547354\n",
      "196 Train Loss 0.073542506 Test MSE 0.00013732193889705858 Test RE 0.00013056426123084284\n",
      "197 Train Loss 0.07245491 Test MSE 0.00013255594141633442 Test RE 0.00012827852322187352\n",
      "198 Train Loss 0.0714776 Test MSE 0.00015888667421603013 Test RE 0.00014044235058155145\n",
      "199 Train Loss 0.07069237 Test MSE 0.00015412337135439137 Test RE 0.00013832115367424797\n",
      "Training time: 43.18\n",
      "Training time: 43.18\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 18029.098 Test MSE 6560.109399521975 Test RE 0.9024224549688075\n",
      "1 Train Loss 12029.34 Test MSE 6684.270121002988 Test RE 0.9109223300784155\n",
      "2 Train Loss 5131.201 Test MSE 767.2389109745043 Test RE 0.30861687009843203\n",
      "3 Train Loss 4271.8687 Test MSE 183.09451754193694 Test RE 0.15076204594317463\n",
      "4 Train Loss 3273.5117 Test MSE 43.23159092131384 Test RE 0.0732579836985501\n",
      "5 Train Loss 2425.844 Test MSE 138.73895235876174 Test RE 0.13123617310803745\n",
      "6 Train Loss 1835.0752 Test MSE 102.23948490572727 Test RE 0.11265842587618304\n",
      "7 Train Loss 1327.4691 Test MSE 15.867751763813242 Test RE 0.04438252958183155\n",
      "8 Train Loss 972.9543 Test MSE 10.28530030051236 Test RE 0.035732453771433394\n",
      "9 Train Loss 701.3872 Test MSE 17.459478615515632 Test RE 0.04655539197522761\n",
      "10 Train Loss 590.5101 Test MSE 15.137319088510889 Test RE 0.043348975232690524\n",
      "11 Train Loss 479.37943 Test MSE 5.382870157091215 Test RE 0.02585004505646936\n",
      "12 Train Loss 388.12488 Test MSE 4.322599179047729 Test RE 0.02316470829588528\n",
      "13 Train Loss 300.9658 Test MSE 6.941062609478374 Test RE 0.029354002931124792\n",
      "14 Train Loss 251.9911 Test MSE 3.1429487497390567 Test RE 0.019752542367419614\n",
      "15 Train Loss 201.50195 Test MSE 0.6772357986328614 Test RE 0.009169049255970512\n",
      "16 Train Loss 166.88814 Test MSE 1.478074605418219 Test RE 0.013545733596665548\n",
      "17 Train Loss 143.20717 Test MSE 0.5364107719704098 Test RE 0.008160243113587248\n",
      "18 Train Loss 109.32604 Test MSE 0.4992386732810098 Test RE 0.007872423743918376\n",
      "19 Train Loss 92.78707 Test MSE 0.8584748610167778 Test RE 0.010323290374800472\n",
      "20 Train Loss 77.639984 Test MSE 0.15763793339879487 Test RE 0.004423690341289962\n",
      "21 Train Loss 67.33737 Test MSE 0.1975367193917411 Test RE 0.004951973031023767\n",
      "22 Train Loss 62.09927 Test MSE 0.1496284935060575 Test RE 0.004309843537631004\n",
      "23 Train Loss 53.687016 Test MSE 0.19463907046943346 Test RE 0.004915518820804949\n",
      "24 Train Loss 46.154263 Test MSE 0.09834664394679186 Test RE 0.0034940902997656815\n",
      "25 Train Loss 41.033985 Test MSE 0.10920526529407644 Test RE 0.0036819352048339977\n",
      "26 Train Loss 34.0902 Test MSE 0.19226437635710203 Test RE 0.004885440902479343\n",
      "27 Train Loss 30.943672 Test MSE 0.11886376858064379 Test RE 0.00384130772886262\n",
      "28 Train Loss 29.420464 Test MSE 0.05245607774555132 Test RE 0.0025518330595587584\n",
      "29 Train Loss 27.4971 Test MSE 0.09592333334292794 Test RE 0.0034507737317568815\n",
      "30 Train Loss 25.77441 Test MSE 0.0714125720551133 Test RE 0.0029774308916915198\n",
      "31 Train Loss 23.321323 Test MSE 0.05206157243772859 Test RE 0.002542219191443063\n",
      "32 Train Loss 22.649035 Test MSE 0.05109776326132113 Test RE 0.002518577372781651\n",
      "33 Train Loss 21.9104 Test MSE 0.04875461030995438 Test RE 0.002460153452320665\n",
      "34 Train Loss 21.4102 Test MSE 0.047570037193444395 Test RE 0.0024300829472246096\n",
      "35 Train Loss 21.119816 Test MSE 0.041001273291637434 Test RE 0.002256072357163582\n",
      "36 Train Loss 20.778158 Test MSE 0.0361008813988458 Test RE 0.0021169629388148553\n",
      "37 Train Loss 19.858477 Test MSE 0.04994605599238085 Test RE 0.00249003213672169\n",
      "38 Train Loss 19.358992 Test MSE 0.05495895928648265 Test RE 0.002612002585384819\n",
      "39 Train Loss 17.137949 Test MSE 0.03956848956675101 Test RE 0.002216302766475361\n",
      "40 Train Loss 15.630095 Test MSE 0.043092724419151775 Test RE 0.0023128971893543195\n",
      "41 Train Loss 15.309335 Test MSE 0.036559665210284725 Test RE 0.002130372058698149\n",
      "42 Train Loss 14.682911 Test MSE 0.03626037071069336 Test RE 0.0021216340280701186\n",
      "43 Train Loss 14.256747 Test MSE 0.03390274053838426 Test RE 0.00205150110545908\n",
      "44 Train Loss 14.053443 Test MSE 0.033953115735084756 Test RE 0.002053024675666804\n",
      "45 Train Loss 13.756788 Test MSE 0.028292735966828984 Test RE 0.001874095965312445\n",
      "46 Train Loss 13.460154 Test MSE 0.043260894195156406 Test RE 0.002317405846751722\n",
      "47 Train Loss 12.798083 Test MSE 0.06100630053037081 Test RE 0.0027519573396926557\n",
      "48 Train Loss 12.476868 Test MSE 0.041836357215177464 Test RE 0.0022789315641859667\n",
      "49 Train Loss 12.138459 Test MSE 0.023837306015699236 Test RE 0.0017202158236705757\n",
      "50 Train Loss 11.99964 Test MSE 0.0409049825034575 Test RE 0.0022534216263019463\n",
      "51 Train Loss 11.597152 Test MSE 0.021315029640990267 Test RE 0.0016266620054499964\n",
      "52 Train Loss 11.170981 Test MSE 0.02308882123421406 Test RE 0.0016929932748995429\n",
      "53 Train Loss 11.073991 Test MSE 0.029835840185731585 Test RE 0.0019245246960353408\n",
      "54 Train Loss 10.521913 Test MSE 0.056397056696416335 Test RE 0.002645955719655606\n",
      "55 Train Loss 9.966371 Test MSE 0.041728613240605845 Test RE 0.0022759951297734596\n",
      "56 Train Loss 9.786743 Test MSE 0.01866241738711582 Test RE 0.0015220828811282178\n",
      "57 Train Loss 9.538389 Test MSE 0.017153359211968963 Test RE 0.0014592474515642544\n",
      "58 Train Loss 9.272593 Test MSE 0.02788052776893508 Test RE 0.0018603936463221914\n",
      "59 Train Loss 9.070178 Test MSE 0.019036009532413512 Test RE 0.0015372422391068319\n",
      "60 Train Loss 8.993765 Test MSE 0.01349901629774397 Test RE 0.0012945100104626542\n",
      "61 Train Loss 8.833663 Test MSE 0.014277938974365407 Test RE 0.0013313342751631746\n",
      "62 Train Loss 8.396119 Test MSE 0.02153900930184897 Test RE 0.001635186203671632\n",
      "63 Train Loss 8.134886 Test MSE 0.021244083432152762 Test RE 0.0016239526098950285\n",
      "64 Train Loss 7.9328737 Test MSE 0.0168039486323713 Test RE 0.0014443086923523632\n",
      "65 Train Loss 7.7746396 Test MSE 0.013669200131324381 Test RE 0.0013026444797347434\n",
      "66 Train Loss 7.6720433 Test MSE 0.010579042278025854 Test RE 0.0011459812942071742\n",
      "67 Train Loss 7.582235 Test MSE 0.012216105225502028 Test RE 0.0012314612052919543\n",
      "68 Train Loss 7.4350348 Test MSE 0.012269436742453189 Test RE 0.001234146356136964\n",
      "69 Train Loss 7.3049927 Test MSE 0.01147133010378855 Test RE 0.0011933318745981519\n",
      "70 Train Loss 7.144267 Test MSE 0.009739206557897475 Test RE 0.0010995529315512632\n",
      "71 Train Loss 6.979577 Test MSE 0.009401365756143814 Test RE 0.0010803135588201957\n",
      "72 Train Loss 6.8353987 Test MSE 0.010737007354479312 Test RE 0.0011545054240510288\n",
      "73 Train Loss 6.6342545 Test MSE 0.0100154575219214 Test RE 0.0011150382075042276\n",
      "74 Train Loss 6.0969214 Test MSE 0.008429593345709717 Test RE 0.0010229576734921214\n",
      "75 Train Loss 5.74549 Test MSE 0.010139106202861342 Test RE 0.0011219001043450535\n",
      "76 Train Loss 5.5150857 Test MSE 0.013706499616161022 Test RE 0.0013044205480818658\n",
      "77 Train Loss 5.2277074 Test MSE 0.04109374687567407 Test RE 0.002258615078144267\n",
      "78 Train Loss 4.9173126 Test MSE 0.03296694868578819 Test RE 0.002022989964707535\n",
      "79 Train Loss 4.3571205 Test MSE 0.037826575542039796 Test RE 0.002166969833083506\n",
      "80 Train Loss 3.758811 Test MSE 0.006293588553064579 Test RE 0.000883900797980434\n",
      "81 Train Loss 3.5018854 Test MSE 0.010243679829202016 Test RE 0.0011276708399804596\n",
      "82 Train Loss 3.1476731 Test MSE 0.024406246054054195 Test RE 0.0017406235097159259\n",
      "83 Train Loss 2.871984 Test MSE 0.03610057350972879 Test RE 0.0021169539114557654\n",
      "84 Train Loss 2.1519992 Test MSE 0.03190029226023143 Test RE 0.00198999361667496\n",
      "85 Train Loss 1.7136759 Test MSE 0.03734075814381507 Test RE 0.0021530093607151583\n",
      "86 Train Loss 1.4373682 Test MSE 0.0037033732674652447 Test RE 0.0006780365353030469\n",
      "87 Train Loss 1.3523607 Test MSE 0.0013972629893971467 Test RE 0.00041647930896586275\n",
      "88 Train Loss 1.2840009 Test MSE 0.0013232000743443515 Test RE 0.000405291140789466\n",
      "89 Train Loss 1.1772486 Test MSE 0.0036456128581700154 Test RE 0.0006727281888898672\n",
      "90 Train Loss 0.92180634 Test MSE 0.002336597398404578 Test RE 0.0005385751322400476\n",
      "91 Train Loss 0.8279521 Test MSE 0.0021963557383642566 Test RE 0.0005221625179079569\n",
      "92 Train Loss 0.77923965 Test MSE 0.0013293830319967511 Test RE 0.0004062369453891498\n",
      "93 Train Loss 0.73756415 Test MSE 0.001715136483144445 Test RE 0.00046142773477863386\n",
      "94 Train Loss 0.6570105 Test MSE 0.0023452488562398692 Test RE 0.0005395712719690681\n",
      "95 Train Loss 0.63201725 Test MSE 0.0009873619408811564 Test RE 0.00035010034903386935\n",
      "96 Train Loss 0.6078581 Test MSE 0.0005982927196290786 Test RE 0.0002725280516696493\n",
      "97 Train Loss 0.56758314 Test MSE 0.0012011463452951659 Test RE 0.00038614668820366753\n",
      "98 Train Loss 0.5231971 Test MSE 0.0012999585596930655 Test RE 0.0004017159784540584\n",
      "99 Train Loss 0.5034493 Test MSE 0.001984411550632641 Test RE 0.0004963296561689144\n",
      "100 Train Loss 0.4872047 Test MSE 0.0007435250320671442 Test RE 0.0003038100593519751\n",
      "101 Train Loss 0.47811493 Test MSE 0.0009911542728051129 Test RE 0.0003507720501796731\n",
      "102 Train Loss 0.46272364 Test MSE 0.0005030300598175921 Test RE 0.0002498914064906107\n",
      "103 Train Loss 0.4504998 Test MSE 0.0005667440623493781 Test RE 0.00026524538829872493\n",
      "104 Train Loss 0.43946192 Test MSE 0.0007992653372868398 Test RE 0.00031499223050023624\n",
      "105 Train Loss 0.3867696 Test MSE 0.0026199042654392367 Test RE 0.0005702917162772656\n",
      "106 Train Loss 0.32833636 Test MSE 0.001581801437430082 Test RE 0.0004431291657875799\n",
      "107 Train Loss 0.26931056 Test MSE 0.0004890759710062559 Test RE 0.00024640102792763486\n",
      "108 Train Loss 0.25163776 Test MSE 0.0008817123630040524 Test RE 0.00033083985172730574\n",
      "109 Train Loss 0.23793346 Test MSE 0.0007838179975480821 Test RE 0.0003119334639427772\n",
      "110 Train Loss 0.22402163 Test MSE 0.0006125209520090074 Test RE 0.00027574955913942475\n",
      "111 Train Loss 0.22038169 Test MSE 0.000716462085878149 Test RE 0.0002982297461889344\n",
      "112 Train Loss 0.21253225 Test MSE 0.000835437547409383 Test RE 0.00032204113408954775\n",
      "113 Train Loss 0.20072843 Test MSE 0.00023959672740871552 Test RE 0.00017246254605175803\n",
      "114 Train Loss 0.19455294 Test MSE 0.0005153294443965052 Test RE 0.00025292795409888503\n",
      "115 Train Loss 0.18750864 Test MSE 0.0004075325002465845 Test RE 0.00022492383350054883\n",
      "116 Train Loss 0.1842764 Test MSE 0.0001964787862946839 Test RE 0.00015617524132689926\n",
      "117 Train Loss 0.18187688 Test MSE 0.0002773262678881947 Test RE 0.00018554525647318697\n",
      "118 Train Loss 0.17304704 Test MSE 0.0005576012622709182 Test RE 0.0002630972001887991\n",
      "119 Train Loss 0.16315491 Test MSE 0.00018838295172336696 Test RE 0.0001529238245870712\n",
      "120 Train Loss 0.15194312 Test MSE 0.0003569599881497471 Test RE 0.0002105058268019675\n",
      "121 Train Loss 0.14173992 Test MSE 0.0010505324265386552 Test RE 0.0003611262710693808\n",
      "122 Train Loss 0.13550155 Test MSE 0.0006112152154084091 Test RE 0.0002754554888856976\n",
      "123 Train Loss 0.13104656 Test MSE 0.0003329218892274248 Test RE 0.0002032944524093476\n",
      "124 Train Loss 0.12826873 Test MSE 0.00014781404116187834 Test RE 0.00013546035131966017\n",
      "125 Train Loss 0.124839514 Test MSE 0.00012520047975001013 Test RE 0.00012466867646947663\n",
      "126 Train Loss 0.1224651 Test MSE 0.00010349421007912198 Test RE 0.00011334761318584722\n",
      "127 Train Loss 0.11986059 Test MSE 0.00021039753121877304 Test RE 0.0001616123971670753\n",
      "128 Train Loss 0.11543286 Test MSE 6.623927560384147e-05 Test RE 9.068013113866501e-05\n",
      "129 Train Loss 0.114103965 Test MSE 0.00036747314439551643 Test RE 0.00021358323250993255\n",
      "130 Train Loss 0.1083628 Test MSE 0.0008322548994030147 Test RE 0.0003214271315313052\n",
      "131 Train Loss 0.09283074 Test MSE 0.0007412971366436631 Test RE 0.00030335455025301024\n",
      "132 Train Loss 0.08259148 Test MSE 0.00041276125906248255 Test RE 0.00022636215332485268\n",
      "133 Train Loss 0.07764583 Test MSE 0.00011966450739590497 Test RE 0.00012188128687116863\n",
      "134 Train Loss 0.074583314 Test MSE 0.00011825530546280177 Test RE 0.00012116150784991799\n",
      "135 Train Loss 0.06901176 Test MSE 0.0001446237885096928 Test RE 0.00013399056528082555\n",
      "136 Train Loss 0.0619271 Test MSE 0.00028473202837121065 Test RE 0.00018800634797390054\n",
      "137 Train Loss 0.060389906 Test MSE 6.28952795161603e-05 Test RE 8.836156071114218e-05\n",
      "138 Train Loss 0.060181905 Test MSE 5.0804296975589855e-05 Test RE 7.941537214344061e-05\n",
      "139 Train Loss 0.059447043 Test MSE 4.079533356909137e-05 Test RE 7.11638763864025e-05\n",
      "140 Train Loss 0.057755627 Test MSE 6.001725921926983e-05 Test RE 8.631622367511862e-05\n",
      "141 Train Loss 0.0530779 Test MSE 6.614390245808532e-05 Test RE 9.061482573942966e-05\n",
      "142 Train Loss 0.048743166 Test MSE 4.205099577565118e-05 Test RE 7.22507724446738e-05\n",
      "143 Train Loss 0.0464606 Test MSE 4.766196865656349e-05 Test RE 7.692018865314001e-05\n",
      "144 Train Loss 0.04542976 Test MSE 2.6803445696456508e-05 Test RE 5.768324267597469e-05\n",
      "145 Train Loss 0.04261399 Test MSE 5.9534336331714875e-05 Test RE 8.59682548468247e-05\n",
      "146 Train Loss 0.040319264 Test MSE 0.00012024885245936456 Test RE 0.00012217850947849818\n",
      "147 Train Loss 0.03709813 Test MSE 4.485905191989657e-05 Test RE 7.462415005506897e-05\n",
      "148 Train Loss 0.034524858 Test MSE 1.7828037451218524e-05 Test RE 4.7044203638207004e-05\n",
      "149 Train Loss 0.034036603 Test MSE 1.4188647952133878e-05 Test RE 4.1968636411272065e-05\n",
      "150 Train Loss 0.033898816 Test MSE 1.512396777444603e-05 Test RE 4.332985383294324e-05\n",
      "151 Train Loss 0.033505585 Test MSE 1.2006274079751553e-05 Test RE 3.860632647405713e-05\n",
      "152 Train Loss 0.031720635 Test MSE 0.0002112047072496713 Test RE 0.00016192210797171314\n",
      "153 Train Loss 0.02657949 Test MSE 1.935891052402813e-05 Test RE 4.902242701603265e-05\n",
      "154 Train Loss 0.02592487 Test MSE 1.462923066989846e-05 Test RE 4.261525546580709e-05\n",
      "155 Train Loss 0.025593756 Test MSE 2.68929188014291e-05 Test RE 5.777943924279237e-05\n",
      "156 Train Loss 0.025260337 Test MSE 1.0408214757858592e-05 Test RE 3.594532996903973e-05\n",
      "157 Train Loss 0.024986029 Test MSE 3.474900205267e-05 Test RE 6.567884709401687e-05\n",
      "158 Train Loss 0.024833014 Test MSE 1.1422537811152197e-05 Test RE 3.765612739079366e-05\n",
      "159 Train Loss 0.024699012 Test MSE 1.3764825587519548e-05 Test RE 4.133707176035323e-05\n",
      "160 Train Loss 0.024552971 Test MSE 1.14947118296498e-05 Test RE 3.777490635444353e-05\n",
      "161 Train Loss 0.024436375 Test MSE 3.494309955650356e-05 Test RE 6.586202283004062e-05\n",
      "162 Train Loss 0.02415676 Test MSE 1.2242603421939924e-05 Test RE 3.898443488428044e-05\n",
      "163 Train Loss 0.023548512 Test MSE 1.616042752400004e-05 Test RE 4.478997038326473e-05\n",
      "164 Train Loss 0.022819966 Test MSE 5.034358608666079e-05 Test RE 7.9054469088015e-05\n",
      "165 Train Loss 0.021822713 Test MSE 6.302330114353874e-05 Test RE 8.845144377012506e-05\n",
      "166 Train Loss 0.021333702 Test MSE 2.0656152959389366e-05 Test RE 5.06382948031464e-05\n",
      "167 Train Loss 0.0210377 Test MSE 1.7731264963645995e-05 Test RE 4.691634942465404e-05\n",
      "168 Train Loss 0.02088758 Test MSE 2.7830933439621408e-05 Test RE 5.877846478327499e-05\n",
      "169 Train Loss 0.020662002 Test MSE 8.97344945573052e-06 Test RE 3.337598279051732e-05\n",
      "170 Train Loss 0.020417934 Test MSE 2.6333461458509446e-05 Test RE 5.717528356049962e-05\n",
      "171 Train Loss 0.02033146 Test MSE 1.3284615335881667e-05 Test RE 4.060961238259345e-05\n",
      "172 Train Loss 0.020263089 Test MSE 1.1240334756933723e-05 Test RE 3.7354590093561026e-05\n",
      "173 Train Loss 0.020074608 Test MSE 2.0319422291410048e-05 Test RE 5.022385337368476e-05\n",
      "174 Train Loss 0.019744083 Test MSE 2.047636777391715e-05 Test RE 5.041744265315631e-05\n",
      "175 Train Loss 0.018122638 Test MSE 1.727121272903569e-05 Test RE 4.630370782365562e-05\n",
      "176 Train Loss 0.01675985 Test MSE 3.0224436518912644e-05 Test RE 6.125385961049308e-05\n",
      "177 Train Loss 0.016037399 Test MSE 1.7199832638275164e-05 Test RE 4.620792459852949e-05\n",
      "178 Train Loss 0.015806317 Test MSE 2.6353943656786714e-05 Test RE 5.7197514740947e-05\n",
      "179 Train Loss 0.015688576 Test MSE 3.811299612106646e-05 Test RE 6.87845495702726e-05\n",
      "180 Train Loss 0.0156199895 Test MSE 2.4242986472554216e-05 Test RE 5.4858940017320835e-05\n",
      "181 Train Loss 0.01557161 Test MSE 2.2272057606933044e-05 Test RE 5.258168788700812e-05\n",
      "182 Train Loss 0.015498383 Test MSE 1.8013589681433906e-05 Test RE 4.728838534744291e-05\n",
      "183 Train Loss 0.015385206 Test MSE 2.4145955310093374e-05 Test RE 5.474904506501485e-05\n",
      "184 Train Loss 0.015329112 Test MSE 2.530880974961141e-05 Test RE 5.6051883789866305e-05\n",
      "185 Train Loss 0.015230298 Test MSE 3.0236200592474295e-05 Test RE 6.12657791843351e-05\n",
      "186 Train Loss 0.015136027 Test MSE 2.9173738575701757e-05 Test RE 6.0179752296179176e-05\n",
      "187 Train Loss 0.014973083 Test MSE 2.7987649750841033e-05 Test RE 5.8943723577128113e-05\n",
      "188 Train Loss 0.014840445 Test MSE 2.7495981281583744e-05 Test RE 5.842368742291333e-05\n",
      "189 Train Loss 0.014681391 Test MSE 3.1752137377130556e-05 Test RE 6.278282229881798e-05\n",
      "190 Train Loss 0.014386254 Test MSE 1.7227789419973848e-05 Test RE 4.624546276467907e-05\n",
      "191 Train Loss 0.0138344625 Test MSE 2.8088589317633073e-05 Test RE 5.904992040088941e-05\n",
      "192 Train Loss 0.0127756735 Test MSE 0.00011726272327537086 Test RE 0.00012065194856775484\n",
      "193 Train Loss 0.011516488 Test MSE 1.0170552121414464e-05 Test RE 3.553256975179541e-05\n",
      "194 Train Loss 0.010780319 Test MSE 1.0100030554053702e-05 Test RE 3.5409165861410035e-05\n",
      "195 Train Loss 0.010323787 Test MSE 1.8226246617238226e-05 Test RE 4.756669461094199e-05\n",
      "196 Train Loss 0.010106514 Test MSE 8.757584471149302e-06 Test RE 3.297209328204226e-05\n",
      "197 Train Loss 0.00994643 Test MSE 1.841535217031042e-05 Test RE 4.7812820827067316e-05\n",
      "198 Train Loss 0.009812772 Test MSE 1.7737465916535184e-05 Test RE 4.692455246718922e-05\n",
      "199 Train Loss 0.009656691 Test MSE 6.475085780749384e-06 Test RE 2.8351570132725797e-05\n",
      "Training time: 38.88\n",
      "Training time: 38.88\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 8193.036 Test MSE 1687.8190890971762 Test RE 0.45773834975356836\n",
      "1 Train Loss 4842.8438 Test MSE 59.64027810736436 Test RE 0.08604471140918045\n",
      "2 Train Loss 4609.9355 Test MSE 173.7300101016372 Test RE 0.1468560270160544\n",
      "3 Train Loss 3888.9116 Test MSE 116.06940543046984 Test RE 0.12003647467178442\n",
      "4 Train Loss 3335.469 Test MSE 46.84390293793387 Test RE 0.07625720591613881\n",
      "5 Train Loss 2817.1643 Test MSE 111.4082022871892 Test RE 0.11760152013879945\n",
      "6 Train Loss 2199.0544 Test MSE 60.21618809114525 Test RE 0.08645915409622135\n",
      "7 Train Loss 1608.6948 Test MSE 39.94698796027488 Test RE 0.07042005690677572\n",
      "8 Train Loss 1409.6624 Test MSE 54.30036622196606 Test RE 0.08210237715578907\n",
      "9 Train Loss 1229.938 Test MSE 23.22536315488657 Test RE 0.05369521789117193\n",
      "10 Train Loss 970.661 Test MSE 22.105842656287532 Test RE 0.052385113547020565\n",
      "11 Train Loss 711.49603 Test MSE 6.741957749073481 Test RE 0.028929928854322096\n",
      "12 Train Loss 528.49255 Test MSE 11.538964542272193 Test RE 0.037847550031993867\n",
      "13 Train Loss 313.12622 Test MSE 2.2913327641350696 Test RE 0.01686546947627234\n",
      "14 Train Loss 238.86171 Test MSE 2.8665463476017967 Test RE 0.018864002111680572\n",
      "15 Train Loss 202.7391 Test MSE 2.33680763907504 Test RE 0.01703200728516004\n",
      "16 Train Loss 173.45816 Test MSE 0.32689740368399073 Test RE 0.006370302973470161\n",
      "17 Train Loss 130.81703 Test MSE 0.7668543654559409 Test RE 0.009756876311731704\n",
      "18 Train Loss 107.36408 Test MSE 0.3196738516071793 Test RE 0.006299526528908717\n",
      "19 Train Loss 92.219505 Test MSE 0.26900651272540743 Test RE 0.005778774525333375\n",
      "20 Train Loss 79.67231 Test MSE 0.3189110350502571 Test RE 0.006292005968139984\n",
      "21 Train Loss 69.66637 Test MSE 0.45717091991437503 Test RE 0.007533445507346376\n",
      "22 Train Loss 56.815067 Test MSE 0.3291458470807291 Test RE 0.006392173322557327\n",
      "23 Train Loss 47.28554 Test MSE 0.08291538343997963 Test RE 0.0032082773783824836\n",
      "24 Train Loss 38.4804 Test MSE 0.22941358986462837 Test RE 0.005336591040546487\n",
      "25 Train Loss 27.396702 Test MSE 0.07156066525291123 Test RE 0.0029805165451379594\n",
      "26 Train Loss 20.800463 Test MSE 0.04374345508824873 Test RE 0.0023302949489292482\n",
      "27 Train Loss 17.041042 Test MSE 0.1089798633588218 Test RE 0.003678133446734014\n",
      "28 Train Loss 14.007382 Test MSE 0.10442268717491889 Test RE 0.0036004085540061177\n",
      "29 Train Loss 9.957414 Test MSE 0.025197587369051436 Test RE 0.0017686171509407173\n",
      "30 Train Loss 9.1653385 Test MSE 0.013296019257907661 Test RE 0.0012847397755371107\n",
      "31 Train Loss 6.75065 Test MSE 0.0551354771317212 Test RE 0.0026161938533224576\n",
      "32 Train Loss 5.877503 Test MSE 0.010719879202326515 Test RE 0.0011535841972828845\n",
      "33 Train Loss 5.1395235 Test MSE 0.009513427968551766 Test RE 0.0010867330358273273\n",
      "34 Train Loss 4.603149 Test MSE 0.005426583598794249 Test RE 0.000820762680764001\n",
      "35 Train Loss 4.171624 Test MSE 0.007440757535139369 Test RE 0.0009610874998972542\n",
      "36 Train Loss 3.6429667 Test MSE 0.022762934725440623 Test RE 0.0016810029626678532\n",
      "37 Train Loss 2.8261302 Test MSE 0.004965689849577758 Test RE 0.0007851346560458854\n",
      "38 Train Loss 2.619543 Test MSE 0.002174954958696922 Test RE 0.0005196123756168209\n",
      "39 Train Loss 2.334424 Test MSE 0.009356976501934065 Test RE 0.0010777601504413257\n",
      "40 Train Loss 1.9646544 Test MSE 0.0032666361484996434 Test RE 0.0006368024625490689\n",
      "41 Train Loss 1.8066096 Test MSE 0.0014245311967796318 Test RE 0.0004205235622347782\n",
      "42 Train Loss 1.7557523 Test MSE 0.0013167237593075158 Test RE 0.0004042980888832549\n",
      "43 Train Loss 1.6543729 Test MSE 0.00169268405567625 Test RE 0.00045839756714435495\n",
      "44 Train Loss 1.5746195 Test MSE 0.0015382921886648393 Test RE 0.00043699228504889847\n",
      "45 Train Loss 1.4734774 Test MSE 0.0009122027262928144 Test RE 0.0003365115967192433\n",
      "46 Train Loss 1.4275551 Test MSE 0.0012088439497940553 Test RE 0.0003873820320462443\n",
      "47 Train Loss 1.3962073 Test MSE 0.0025703106165547935 Test RE 0.0005648682404995716\n",
      "48 Train Loss 1.3179032 Test MSE 0.001644400671894498 Test RE 0.00045181243033710786\n",
      "49 Train Loss 1.24955 Test MSE 0.002016789820171388 Test RE 0.0005003624065331754\n",
      "50 Train Loss 1.172207 Test MSE 0.0008034164222983364 Test RE 0.00031580914705886466\n",
      "51 Train Loss 1.0995339 Test MSE 0.0014729720430687457 Test RE 0.00042761369366563364\n",
      "52 Train Loss 0.91127235 Test MSE 0.003666721635741524 Test RE 0.0006746729885315697\n",
      "53 Train Loss 0.8559956 Test MSE 0.002808932172681344 Test RE 0.0005905069025838189\n",
      "54 Train Loss 0.82052344 Test MSE 0.0013414650339543862 Test RE 0.00040807879758199083\n",
      "55 Train Loss 0.77975893 Test MSE 0.0009714459642805114 Test RE 0.00034726712898310106\n",
      "56 Train Loss 0.709685 Test MSE 0.001243332973302843 Test RE 0.00039286928640080624\n",
      "57 Train Loss 0.6595784 Test MSE 0.0012813059214422853 Test RE 0.00039882352616385996\n",
      "58 Train Loss 0.62407 Test MSE 0.00102078811233614 Test RE 0.0003559771766657879\n",
      "59 Train Loss 0.57494384 Test MSE 0.0029026862453569707 Test RE 0.0006002807270023055\n",
      "60 Train Loss 0.5109265 Test MSE 0.0006056210160827369 Test RE 0.00027419202633969045\n",
      "61 Train Loss 0.48764104 Test MSE 0.0006030250561358609 Test RE 0.00027360374100793256\n",
      "62 Train Loss 0.4619184 Test MSE 0.0006243728521180545 Test RE 0.00027840456885379767\n",
      "63 Train Loss 0.44742456 Test MSE 0.000286474273286651 Test RE 0.00018858066616215909\n",
      "64 Train Loss 0.39906138 Test MSE 0.0011852154190041802 Test RE 0.0003835773891245485\n",
      "65 Train Loss 0.36966977 Test MSE 0.0005304619404679141 Test RE 0.0002566146622724724\n",
      "66 Train Loss 0.35677466 Test MSE 0.0002644184178932941 Test RE 0.00018117580661960612\n",
      "67 Train Loss 0.32990822 Test MSE 0.001074954412375537 Test RE 0.00036529975059125216\n",
      "68 Train Loss 0.3147918 Test MSE 0.0004568645102444682 Test RE 0.0002381486170055853\n",
      "69 Train Loss 0.29881608 Test MSE 0.0001802218917798316 Test RE 0.0001495746944775832\n",
      "70 Train Loss 0.29080427 Test MSE 0.00016482214312694732 Test RE 0.00014304152472615595\n",
      "71 Train Loss 0.2805097 Test MSE 0.00013546100846773072 Test RE 0.00012967656697488003\n",
      "72 Train Loss 0.27096882 Test MSE 0.00018917470996949478 Test RE 0.00015324485083627402\n",
      "73 Train Loss 0.25232002 Test MSE 0.0001659748727289027 Test RE 0.00014354085358634876\n",
      "74 Train Loss 0.24579982 Test MSE 0.0002683129573936317 Test RE 0.00018250517159166534\n",
      "75 Train Loss 0.22765364 Test MSE 0.0004017432292119202 Test RE 0.00022332052255657353\n",
      "76 Train Loss 0.21339822 Test MSE 0.0003421761574988035 Test RE 0.00020610058518038415\n",
      "77 Train Loss 0.20753738 Test MSE 8.840252355615177e-05 Test RE 0.00010475787582938573\n",
      "78 Train Loss 0.19704013 Test MSE 0.00028238855897425827 Test RE 0.0001872310621170552\n",
      "79 Train Loss 0.18642315 Test MSE 9.712362463293371e-05 Test RE 0.00010980365415946987\n",
      "80 Train Loss 0.1841452 Test MSE 0.0001685676987769087 Test RE 0.00014465769189207168\n",
      "81 Train Loss 0.17704292 Test MSE 0.00010406100150692405 Test RE 0.0001136575664478541\n",
      "82 Train Loss 0.1719558 Test MSE 0.00010194473712241416 Test RE 0.0001124959163120835\n",
      "83 Train Loss 0.16208468 Test MSE 0.00016916621752946653 Test RE 0.0001449142761152951\n",
      "84 Train Loss 0.15527026 Test MSE 0.00021586578187865482 Test RE 0.00016369908615818018\n",
      "85 Train Loss 0.14530426 Test MSE 9.300894071060926e-05 Test RE 0.00010745254383147768\n",
      "86 Train Loss 0.14136545 Test MSE 0.00012029337042730663 Test RE 0.00012220112356394248\n",
      "87 Train Loss 0.13939637 Test MSE 0.0001288859456233027 Test RE 0.0001264902740430517\n",
      "88 Train Loss 0.13770445 Test MSE 0.00021618924621585726 Test RE 0.0001638216877922569\n",
      "89 Train Loss 0.12696454 Test MSE 0.0003238664932950105 Test RE 0.00020051061166105583\n",
      "90 Train Loss 0.11720987 Test MSE 0.00043266658974885035 Test RE 0.00023175602458860116\n",
      "91 Train Loss 0.11364858 Test MSE 9.040126400367251e-05 Test RE 0.00010593552025973706\n",
      "92 Train Loss 0.11119617 Test MSE 8.159650908049354e-05 Test RE 0.00010064452204827892\n",
      "93 Train Loss 0.10908182 Test MSE 0.00010034866899886566 Test RE 0.00011161181243618996\n",
      "94 Train Loss 0.10498977 Test MSE 5.899322781890409e-05 Test RE 8.55766796520236e-05\n",
      "95 Train Loss 0.1013678 Test MSE 0.00019001575908503593 Test RE 0.00015358512758426536\n",
      "96 Train Loss 0.094565466 Test MSE 0.00022439825569881445 Test RE 0.00016690297991224214\n",
      "97 Train Loss 0.08794033 Test MSE 6.737290253495873e-05 Test RE 9.145279463560031e-05\n",
      "98 Train Loss 0.08514771 Test MSE 6.467214300067949e-05 Test RE 8.960102511750974e-05\n",
      "99 Train Loss 0.08471117 Test MSE 5.0207103973473164e-05 Test RE 7.894723751792606e-05\n",
      "100 Train Loss 0.083946906 Test MSE 4.1316464516411754e-05 Test RE 7.161696758339867e-05\n",
      "101 Train Loss 0.07866483 Test MSE 7.871775779610772e-05 Test RE 9.885319485174723e-05\n",
      "102 Train Loss 0.074813545 Test MSE 3.594132765036261e-05 Test RE 6.67961467485827e-05\n",
      "103 Train Loss 0.071500115 Test MSE 0.00010328226270121487 Test RE 0.00011323149054652419\n",
      "104 Train Loss 0.06960218 Test MSE 4.129862454772978e-05 Test RE 7.160150422730651e-05\n",
      "105 Train Loss 0.06742373 Test MSE 6.996093321255187e-05 Test RE 9.319275470112549e-05\n",
      "106 Train Loss 0.06455359 Test MSE 3.4487267719315145e-05 Test RE 6.543102843926592e-05\n",
      "107 Train Loss 0.062176988 Test MSE 0.00011556070149822641 Test RE 0.00011977314050735078\n",
      "108 Train Loss 0.05999426 Test MSE 0.00010466105429090755 Test RE 0.00011398479040054682\n",
      "109 Train Loss 0.058479533 Test MSE 8.075467997268454e-05 Test RE 0.00010012400253445797\n",
      "110 Train Loss 0.055791907 Test MSE 5.01454041423141e-05 Test RE 7.889871322285319e-05\n",
      "111 Train Loss 0.053922262 Test MSE 5.032796756956731e-05 Test RE 7.904220526801804e-05\n",
      "112 Train Loss 0.051530354 Test MSE 3.827459624369041e-05 Test RE 6.893021948719206e-05\n",
      "113 Train Loss 0.047974594 Test MSE 5.2481796260048485e-05 Test RE 8.071582644020429e-05\n",
      "114 Train Loss 0.04446369 Test MSE 0.0001747485476687672 Test RE 0.00014728588880309762\n",
      "115 Train Loss 0.03835284 Test MSE 0.00022816904209748326 Test RE 0.00016829945589451776\n",
      "116 Train Loss 0.036092866 Test MSE 5.1811372423764803e-05 Test RE 8.019862096545415e-05\n",
      "117 Train Loss 0.034027293 Test MSE 1.5944490967030318e-05 Test RE 4.448972094952192e-05\n",
      "118 Train Loss 0.033569075 Test MSE 3.194412228266782e-05 Test RE 6.297234008159104e-05\n",
      "119 Train Loss 0.03292285 Test MSE 2.566721173809516e-05 Test RE 5.644736830163284e-05\n",
      "120 Train Loss 0.032775626 Test MSE 1.2584418524598123e-05 Test RE 3.952491357895487e-05\n",
      "121 Train Loss 0.03258793 Test MSE 1.4441197189639032e-05 Test RE 4.234049699016161e-05\n",
      "122 Train Loss 0.03196622 Test MSE 2.913612178068283e-05 Test RE 6.0140941713146255e-05\n",
      "123 Train Loss 0.030764665 Test MSE 1.432926433195354e-05 Test RE 4.217608845743214e-05\n",
      "124 Train Loss 0.02995386 Test MSE 1.3996173313604932e-05 Test RE 4.1683003822258415e-05\n",
      "125 Train Loss 0.029214598 Test MSE 2.182760194070062e-05 Test RE 5.2054390404565135e-05\n",
      "126 Train Loss 0.028301738 Test MSE 1.1849136920217161e-05 Test RE 3.835285612856961e-05\n",
      "127 Train Loss 0.027404785 Test MSE 9.320245604228446e-06 Test RE 3.4014808541537776e-05\n",
      "128 Train Loss 0.027176833 Test MSE 1.0916244441678621e-05 Test RE 3.681213265494693e-05\n",
      "129 Train Loss 0.026820898 Test MSE 5.4511819009611975e-05 Test RE 8.226208057280409e-05\n",
      "130 Train Loss 0.026094131 Test MSE 1.2074458920199273e-05 Test RE 3.8715795881473774e-05\n",
      "131 Train Loss 0.02442985 Test MSE 9.543675368688425e-06 Test RE 3.442010425840163e-05\n",
      "132 Train Loss 0.02402137 Test MSE 1.2733291956676354e-05 Test RE 3.975801569586176e-05\n",
      "133 Train Loss 0.023752606 Test MSE 9.026941640286432e-06 Test RE 3.347531479459079e-05\n",
      "134 Train Loss 0.023521164 Test MSE 1.2199658800683348e-05 Test RE 3.891599999018706e-05\n",
      "135 Train Loss 0.023302464 Test MSE 1.1861491776010123e-05 Test RE 3.837284579352851e-05\n",
      "136 Train Loss 0.022574786 Test MSE 1.1951620480599714e-05 Test RE 3.851835657783849e-05\n",
      "137 Train Loss 0.02194185 Test MSE 7.334758934608203e-06 Test RE 3.0174999721403655e-05\n",
      "138 Train Loss 0.021793757 Test MSE 7.173739147064175e-06 Test RE 2.984194617501789e-05\n",
      "139 Train Loss 0.021692598 Test MSE 6.440459928560785e-06 Test RE 2.8275662781843188e-05\n",
      "140 Train Loss 0.021648314 Test MSE 6.320456998457549e-06 Test RE 2.801099866413146e-05\n",
      "141 Train Loss 0.021318268 Test MSE 1.1704459905254513e-05 Test RE 3.8117994361571674e-05\n",
      "142 Train Loss 0.019857114 Test MSE 6.348424589465025e-05 Test RE 8.8774316028687e-05\n",
      "143 Train Loss 0.01797786 Test MSE 2.8688829825525857e-05 Test RE 5.967752034931385e-05\n",
      "144 Train Loss 0.017633222 Test MSE 1.1490116913651283e-05 Test RE 3.7767355496551826e-05\n",
      "145 Train Loss 0.01717937 Test MSE 2.7118744469245308e-05 Test RE 5.802152532997129e-05\n",
      "146 Train Loss 0.016762633 Test MSE 2.4936440708466624e-05 Test RE 5.563800955111585e-05\n",
      "147 Train Loss 0.016458906 Test MSE 3.8853746694315905e-05 Test RE 6.944976884654914e-05\n",
      "148 Train Loss 0.016371923 Test MSE 4.368080203323113e-05 Test RE 7.36376048845485e-05\n",
      "149 Train Loss 0.016317533 Test MSE 2.580104534054602e-05 Test RE 5.659434048941725e-05\n",
      "150 Train Loss 0.016221803 Test MSE 2.5139718227865332e-05 Test RE 5.5864324945714466e-05\n",
      "151 Train Loss 0.01605742 Test MSE 2.6864419325091443e-05 Test RE 5.774881556321422e-05\n",
      "152 Train Loss 0.0158982 Test MSE 2.6678333159026406e-05 Test RE 5.7548458917733e-05\n",
      "153 Train Loss 0.01562064 Test MSE 2.9856998731017003e-05 Test RE 6.0880390185163984e-05\n",
      "154 Train Loss 0.015480287 Test MSE 3.115927713327983e-05 Test RE 6.219393555392916e-05\n",
      "155 Train Loss 0.015261487 Test MSE 2.5969305317211717e-05 Test RE 5.677857890877354e-05\n",
      "156 Train Loss 0.015071537 Test MSE 1.7120454776058404e-05 Test RE 4.6101175655086327e-05\n",
      "157 Train Loss 0.014929446 Test MSE 1.4317004296928268e-05 Test RE 4.215804178874756e-05\n",
      "158 Train Loss 0.014789253 Test MSE 9.967086333639332e-06 Test RE 3.5175352832104456e-05\n",
      "159 Train Loss 0.01464614 Test MSE 7.423210137223046e-06 Test RE 3.03563974099545e-05\n",
      "160 Train Loss 0.014408679 Test MSE 6.479196960370659e-06 Test RE 2.8360569233724755e-05\n",
      "161 Train Loss 0.014121586 Test MSE 9.40139858724978e-06 Test RE 3.416257398083108e-05\n",
      "162 Train Loss 0.013963049 Test MSE 5.356533798527822e-06 Test RE 2.578673024497651e-05\n",
      "163 Train Loss 0.013808246 Test MSE 5.240080261655777e-06 Test RE 2.5504882194038715e-05\n",
      "164 Train Loss 0.013573555 Test MSE 6.664847889354743e-06 Test RE 2.8764012801685802e-05\n",
      "165 Train Loss 0.013459952 Test MSE 4.569327871387373e-06 Test RE 2.3816641160346038e-05\n",
      "166 Train Loss 0.013309019 Test MSE 8.166149894022646e-06 Test RE 3.183926444362055e-05\n",
      "167 Train Loss 0.01307519 Test MSE 1.0358609079561221e-05 Test RE 3.585956972319772e-05\n",
      "168 Train Loss 0.012990851 Test MSE 8.015957034709884e-06 Test RE 3.154510974953991e-05\n",
      "169 Train Loss 0.012901021 Test MSE 7.33076938101781e-06 Test RE 3.0166792147435848e-05\n",
      "170 Train Loss 0.012846857 Test MSE 7.362096701621756e-06 Test RE 3.023118083795081e-05\n",
      "171 Train Loss 0.012632271 Test MSE 1.2683851916552253e-05 Test RE 3.968075564302161e-05\n",
      "172 Train Loss 0.012378193 Test MSE 2.067794571848801e-05 Test RE 5.066500009642338e-05\n",
      "173 Train Loss 0.012076121 Test MSE 2.9108120687933314e-05 Test RE 6.0112035723245396e-05\n",
      "174 Train Loss 0.011592276 Test MSE 2.446336280551097e-05 Test RE 5.5107718393425456e-05\n",
      "175 Train Loss 0.011373947 Test MSE 2.0300261570587464e-05 Test RE 5.0200167852790803e-05\n",
      "176 Train Loss 0.011349003 Test MSE 1.350874461535405e-05 Test RE 4.095074885875438e-05\n",
      "177 Train Loss 0.011254385 Test MSE 1.158890729028172e-05 Test RE 3.792936715549134e-05\n",
      "178 Train Loss 0.011104786 Test MSE 1.6550006090040753e-05 Test RE 4.532663005343003e-05\n",
      "179 Train Loss 0.010939289 Test MSE 1.520074361515965e-05 Test RE 4.343969520398854e-05\n",
      "180 Train Loss 0.010818513 Test MSE 6.466878414666054e-06 Test RE 2.8333596201128263e-05\n",
      "181 Train Loss 0.010775982 Test MSE 1.3110666932164866e-05 Test RE 4.034286571377532e-05\n",
      "182 Train Loss 0.010775185 Test MSE 1.4512478276222606e-05 Test RE 4.244486373633877e-05\n",
      "183 Train Loss 0.010697969 Test MSE 6.03406006267013e-06 Test RE 2.736901494613649e-05\n",
      "184 Train Loss 0.010573195 Test MSE 6.7843787411430466e-06 Test RE 2.9020800965062813e-05\n",
      "185 Train Loss 0.010388506 Test MSE 1.1562084848091954e-05 Test RE 3.788544810507403e-05\n",
      "186 Train Loss 0.010174988 Test MSE 1.1800398170655886e-05 Test RE 3.827389694229435e-05\n",
      "187 Train Loss 0.009912149 Test MSE 4.206052727151903e-06 Test RE 2.2850289605334397e-05\n",
      "188 Train Loss 0.009766156 Test MSE 3.88323579742835e-06 Test RE 2.1955899470752497e-05\n",
      "189 Train Loss 0.009656139 Test MSE 1.5768561179435456e-05 Test RE 4.424359274546545e-05\n",
      "190 Train Loss 0.00957277 Test MSE 6.350357345447686e-06 Test RE 2.807717666159361e-05\n",
      "191 Train Loss 0.00940754 Test MSE 3.4685811297871725e-06 Test RE 2.0750581943991032e-05\n",
      "192 Train Loss 0.008994867 Test MSE 3.477002480743939e-06 Test RE 2.0775756790380302e-05\n",
      "193 Train Loss 0.008773729 Test MSE 1.2089915570331319e-05 Test RE 3.874056821819032e-05\n",
      "194 Train Loss 0.00861747 Test MSE 1.358514808286195e-05 Test RE 4.1066391273612065e-05\n",
      "195 Train Loss 0.008533082 Test MSE 5.676812506808567e-06 Test RE 2.6546460735813782e-05\n",
      "196 Train Loss 0.008426329 Test MSE 4.740287934621557e-06 Test RE 2.4258096174918287e-05\n",
      "197 Train Loss 0.008325532 Test MSE 5.147106470157116e-06 Test RE 2.5277605304866243e-05\n",
      "198 Train Loss 0.008158146 Test MSE 1.5119433493156175e-05 Test RE 4.3323358035132485e-05\n",
      "199 Train Loss 0.008001793 Test MSE 6.3597318625593814e-06 Test RE 2.8097893047420616e-05\n",
      "Training time: 37.80\n",
      "Training time: 37.80\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 13330.0205 Test MSE 3285.2549561856777 Test RE 0.638614671719292\n",
      "1 Train Loss 4839.534 Test MSE 146.57993753666926 Test RE 0.13489368490300332\n",
      "2 Train Loss 3898.8435 Test MSE 149.40960266065184 Test RE 0.13618949445272918\n",
      "3 Train Loss 2992.0422 Test MSE 81.71274657703063 Test RE 0.10071618261363076\n",
      "4 Train Loss 2322.866 Test MSE 75.38082074564474 Test RE 0.09673525553351532\n",
      "5 Train Loss 1937.8693 Test MSE 140.596526525127 Test RE 0.1321118116476978\n",
      "6 Train Loss 1681.1475 Test MSE 235.6635835557946 Test RE 0.17104114337314316\n",
      "7 Train Loss 1485.5938 Test MSE 145.15023953760019 Test RE 0.13423421604778812\n",
      "8 Train Loss 1306.3389 Test MSE 57.1963674585132 Test RE 0.08426332188236009\n",
      "9 Train Loss 1033.0525 Test MSE 53.07555689830813 Test RE 0.08117113753191033\n",
      "10 Train Loss 772.45654 Test MSE 11.616852240712316 Test RE 0.03797507017384755\n",
      "11 Train Loss 602.95483 Test MSE 11.51397465012708 Test RE 0.03780654467023553\n",
      "12 Train Loss 398.59332 Test MSE 7.132212805164803 Test RE 0.029755448366150676\n",
      "13 Train Loss 292.6919 Test MSE 3.9524084837774454 Test RE 0.022150588227337818\n",
      "14 Train Loss 206.41772 Test MSE 3.36158197966355 Test RE 0.020428016775600803\n",
      "15 Train Loss 137.06697 Test MSE 0.5983896671547765 Test RE 0.008618791906558183\n",
      "16 Train Loss 75.79864 Test MSE 1.031372213305474 Test RE 0.011315195597742305\n",
      "17 Train Loss 47.199436 Test MSE 4.650442710983562 Test RE 0.024027108064585776\n",
      "18 Train Loss 24.769104 Test MSE 0.6903401661338225 Test RE 0.00925733379902069\n",
      "19 Train Loss 13.904559 Test MSE 0.18034508501441882 Test RE 0.004731583490680748\n",
      "20 Train Loss 10.009954 Test MSE 0.0657026511212901 Test RE 0.002855918431224287\n",
      "21 Train Loss 8.853618 Test MSE 0.04010019407183196 Test RE 0.002231143941674802\n",
      "22 Train Loss 6.5389047 Test MSE 0.06632854857070057 Test RE 0.002869489231893007\n",
      "23 Train Loss 4.8700967 Test MSE 0.03590295497879075 Test RE 0.0021111517402388506\n",
      "24 Train Loss 3.496675 Test MSE 0.04409300316466942 Test RE 0.002339586960092234\n",
      "25 Train Loss 2.8282623 Test MSE 0.01419347811757086 Test RE 0.0013273906940937622\n",
      "26 Train Loss 2.3182368 Test MSE 0.004768523599941704 Test RE 0.0007693896158762728\n",
      "27 Train Loss 1.9900107 Test MSE 0.005598562562276145 Test RE 0.0008336670182982151\n",
      "28 Train Loss 1.5490912 Test MSE 0.005397712555131629 Test RE 0.0008185764178329817\n",
      "29 Train Loss 1.1860678 Test MSE 0.00166803328861739 Test RE 0.00045504747525502726\n",
      "30 Train Loss 1.0888168 Test MSE 0.001994341047034167 Test RE 0.000497569861082912\n",
      "31 Train Loss 0.9035606 Test MSE 0.0012181016724147774 Test RE 0.0003888625520714063\n",
      "32 Train Loss 0.8203071 Test MSE 0.004261315293828554 Test RE 0.0007273210997294248\n",
      "33 Train Loss 0.7451018 Test MSE 0.004965909548118625 Test RE 0.0007851520243306226\n",
      "34 Train Loss 0.6863728 Test MSE 0.0039256877317469414 Test RE 0.0006980913033775608\n",
      "35 Train Loss 0.54100406 Test MSE 0.0038054790767706563 Test RE 0.0006873200635465662\n",
      "36 Train Loss 0.518615 Test MSE 0.0027151044328774846 Test RE 0.0005805606840068425\n",
      "37 Train Loss 0.48547968 Test MSE 0.0017950199117476504 Test RE 0.00047205107130227693\n",
      "38 Train Loss 0.4322108 Test MSE 0.0014660428624535037 Test RE 0.00042660671413227637\n",
      "39 Train Loss 0.39436224 Test MSE 0.0017360058602915937 Test RE 0.00046422651883441487\n",
      "40 Train Loss 0.35866648 Test MSE 0.0015767523550804935 Test RE 0.0004424213702692248\n",
      "41 Train Loss 0.34302825 Test MSE 0.0014310793283176405 Test RE 0.0004214889627979916\n",
      "42 Train Loss 0.30552468 Test MSE 0.0009022072744851571 Test RE 0.000334662857237468\n",
      "43 Train Loss 0.26278552 Test MSE 0.0011375155159207677 Test RE 0.00037577944179843775\n",
      "44 Train Loss 0.2538135 Test MSE 0.0006837162837748012 Test RE 0.00029133476630744965\n",
      "45 Train Loss 0.2489924 Test MSE 0.0005725363984327268 Test RE 0.00026659739606355195\n",
      "46 Train Loss 0.22531329 Test MSE 0.0009113470902690187 Test RE 0.00033635373762329584\n",
      "47 Train Loss 0.21151137 Test MSE 0.0007540704219644673 Test RE 0.00030595693767716803\n",
      "48 Train Loss 0.20684399 Test MSE 0.00044029671672493186 Test RE 0.00023379061630786823\n",
      "49 Train Loss 0.19661501 Test MSE 0.0003781615732057191 Test RE 0.00021666713983719535\n",
      "50 Train Loss 0.17363326 Test MSE 0.0011826237016066658 Test RE 0.00038315777416003346\n",
      "51 Train Loss 0.16594873 Test MSE 0.0005616932982258515 Test RE 0.00026406082355981246\n",
      "52 Train Loss 0.16376282 Test MSE 0.0006102332363388886 Test RE 0.0002752341263866889\n",
      "53 Train Loss 0.16225085 Test MSE 0.0004913508710810651 Test RE 0.00024697342100853565\n",
      "54 Train Loss 0.15339589 Test MSE 0.0001604209652394957 Test RE 0.000141118813036705\n",
      "55 Train Loss 0.13617912 Test MSE 0.00027428418908450957 Test RE 0.00018452479827188675\n",
      "56 Train Loss 0.1322356 Test MSE 0.00032038576375877613 Test RE 0.00019943021497517344\n",
      "57 Train Loss 0.13030681 Test MSE 0.00033823043024067763 Test RE 0.0002049088383999904\n",
      "58 Train Loss 0.12034147 Test MSE 0.00044684499017234945 Test RE 0.0002355227149470368\n",
      "59 Train Loss 0.11579384 Test MSE 0.00016703988979717204 Test RE 0.00014400064910550606\n",
      "60 Train Loss 0.11281908 Test MSE 0.00027552072125859367 Test RE 0.00018494026929840102\n",
      "61 Train Loss 0.11133385 Test MSE 0.00021396016263698522 Test RE 0.00016297493331883923\n",
      "62 Train Loss 0.11096588 Test MSE 0.00026736058372290407 Test RE 0.00018218098368600255\n",
      "63 Train Loss 0.10973598 Test MSE 0.0002450013744180851 Test RE 0.00017439684050927527\n",
      "64 Train Loss 0.10521611 Test MSE 0.00023964126105173485 Test RE 0.00017247857304154537\n",
      "65 Train Loss 0.09461086 Test MSE 0.00010776922287571795 Test RE 0.00011566493761354527\n",
      "66 Train Loss 0.0878749 Test MSE 9.301852263021173e-05 Test RE 0.0001074580786494844\n",
      "67 Train Loss 0.08575522 Test MSE 0.00018162603856040132 Test RE 0.00015015624792435593\n",
      "68 Train Loss 0.08495118 Test MSE 0.00013423902764758596 Test RE 0.00012909034194684988\n",
      "69 Train Loss 0.083916694 Test MSE 0.00018316845430009723 Test RE 0.00015079248304195741\n",
      "70 Train Loss 0.08185493 Test MSE 0.00022136720339387876 Test RE 0.00016577192917122834\n",
      "71 Train Loss 0.07982891 Test MSE 0.0001379489670105443 Test RE 0.0001308620076131957\n",
      "72 Train Loss 0.07848009 Test MSE 0.00018920363407446138 Test RE 0.00015325656567050802\n",
      "73 Train Loss 0.077314936 Test MSE 0.0002568863038548259 Test RE 0.00017857671406085594\n",
      "74 Train Loss 0.075709246 Test MSE 0.00026084893037058325 Test RE 0.00017994876999082648\n",
      "75 Train Loss 0.07443631 Test MSE 0.00017623279932742414 Test RE 0.0001479100630559603\n",
      "76 Train Loss 0.07402451 Test MSE 0.0001879269175106051 Test RE 0.00015273861474743219\n",
      "77 Train Loss 0.073841386 Test MSE 0.00022899820893229218 Test RE 0.00016860497888738826\n",
      "78 Train Loss 0.07325249 Test MSE 0.00019191568064033898 Test RE 0.0001543510480300598\n",
      "79 Train Loss 0.0682968 Test MSE 0.0002207851427112082 Test RE 0.00016555384620474354\n",
      "80 Train Loss 0.065427914 Test MSE 0.00015443208449324365 Test RE 0.00013845961481563835\n",
      "81 Train Loss 0.0639717 Test MSE 0.0001830844129003503 Test RE 0.0001507578857490888\n",
      "82 Train Loss 0.06361585 Test MSE 0.00016951028321809855 Test RE 0.00014506157119646338\n",
      "83 Train Loss 0.06324475 Test MSE 0.0001759570887317486 Test RE 0.00014779431747927478\n",
      "84 Train Loss 0.061710324 Test MSE 0.0001680264185249255 Test RE 0.00014442525320333075\n",
      "85 Train Loss 0.060393814 Test MSE 9.511744390398522e-05 Test RE 0.00010866368727536075\n",
      "86 Train Loss 0.057530735 Test MSE 0.00020111581915399984 Test RE 0.00015800741513649012\n",
      "87 Train Loss 0.051955204 Test MSE 8.701519329452185e-05 Test RE 0.00010393262516502013\n",
      "88 Train Loss 0.04922675 Test MSE 0.0001563629511082029 Test RE 0.00013932250730103052\n",
      "89 Train Loss 0.04806811 Test MSE 0.00013202051387173883 Test RE 0.00012801918609843155\n",
      "90 Train Loss 0.046911154 Test MSE 0.0002597990476291713 Test RE 0.00017958626976721426\n",
      "91 Train Loss 0.0451241 Test MSE 0.00014167120846759457 Test RE 0.0001326157639967471\n",
      "92 Train Loss 0.042330496 Test MSE 0.000128552579977214 Test RE 0.00012632658352664447\n",
      "93 Train Loss 0.04072258 Test MSE 6.609384908055943e-05 Test RE 9.058053356512797e-05\n",
      "94 Train Loss 0.040127546 Test MSE 8.193545487067735e-05 Test RE 0.0001008533403241727\n",
      "95 Train Loss 0.039824307 Test MSE 6.643405756523954e-05 Test RE 9.081335940795843e-05\n",
      "96 Train Loss 0.039484918 Test MSE 6.239933770673018e-05 Test RE 8.801249698492883e-05\n",
      "97 Train Loss 0.039041016 Test MSE 2.7095259403251026e-05 Test RE 5.79963963182803e-05\n",
      "98 Train Loss 0.038697124 Test MSE 4.5765797465473254e-05 Test RE 7.537457380635901e-05\n",
      "99 Train Loss 0.038309477 Test MSE 6.056254106443635e-05 Test RE 8.670744653449999e-05\n",
      "100 Train Loss 0.037103634 Test MSE 2.5381516438511686e-05 Test RE 5.613233846589192e-05\n",
      "101 Train Loss 0.03573814 Test MSE 2.3843965148386188e-05 Test RE 5.440559841559348e-05\n",
      "102 Train Loss 0.035091896 Test MSE 2.5917005905012996e-05 Test RE 5.6721377092424135e-05\n",
      "103 Train Loss 0.034023862 Test MSE 4.7553777621740204e-05 Test RE 7.683283595750211e-05\n",
      "104 Train Loss 0.03319565 Test MSE 2.562264632502962e-05 Test RE 5.639834285226178e-05\n",
      "105 Train Loss 0.032153744 Test MSE 1.8961001568016526e-05 Test RE 4.851600022770391e-05\n",
      "106 Train Loss 0.031553272 Test MSE 2.2137806144589052e-05 Test RE 5.242297245512087e-05\n",
      "107 Train Loss 0.031053131 Test MSE 1.8494251301117542e-05 Test RE 4.7915136492154647e-05\n",
      "108 Train Loss 0.030428985 Test MSE 3.7332249451914224e-05 Test RE 6.807637656117835e-05\n",
      "109 Train Loss 0.029849216 Test MSE 1.8712442263724056e-05 Test RE 4.819695365672323e-05\n",
      "110 Train Loss 0.029041776 Test MSE 1.3789044915094928e-05 Test RE 4.137342224212852e-05\n",
      "111 Train Loss 0.028452957 Test MSE 5.352489030662556e-05 Test RE 8.151400755421804e-05\n",
      "112 Train Loss 0.027592558 Test MSE 3.481987955865702e-05 Test RE 6.574579551330066e-05\n",
      "113 Train Loss 0.026455324 Test MSE 6.507311080123581e-05 Test RE 8.98783594468838e-05\n",
      "114 Train Loss 0.025381513 Test MSE 2.650245541152541e-05 Test RE 5.735845023079305e-05\n",
      "115 Train Loss 0.024477825 Test MSE 3.711859488187381e-05 Test RE 6.788129457228098e-05\n",
      "116 Train Loss 0.02400462 Test MSE 4.26930081972217e-05 Test RE 7.280022653572492e-05\n",
      "117 Train Loss 0.023578247 Test MSE 7.743002876707428e-05 Test RE 9.804130031968202e-05\n",
      "118 Train Loss 0.023096425 Test MSE 3.83855909250878e-05 Test RE 6.903009446587098e-05\n",
      "119 Train Loss 0.022914764 Test MSE 2.9910447974142675e-05 Test RE 6.093485908533777e-05\n",
      "120 Train Loss 0.022699628 Test MSE 3.2437472421964336e-05 Test RE 6.345675435646931e-05\n",
      "121 Train Loss 0.022059595 Test MSE 1.722488706315862e-05 Test RE 4.624156712594502e-05\n",
      "122 Train Loss 0.021696154 Test MSE 3.6334789351014085e-05 Test RE 6.71607713958477e-05\n",
      "123 Train Loss 0.021356447 Test MSE 4.64005537912321e-05 Test RE 7.589548389630777e-05\n",
      "124 Train Loss 0.021151675 Test MSE 4.367000141414258e-05 Test RE 7.362850041698023e-05\n",
      "125 Train Loss 0.021110471 Test MSE 4.3211098315022434e-05 Test RE 7.324061879324807e-05\n",
      "126 Train Loss 0.020760745 Test MSE 4.306560955687315e-05 Test RE 7.311721680324866e-05\n",
      "127 Train Loss 0.019618621 Test MSE 9.530091860040722e-05 Test RE 0.00010876843899702973\n",
      "128 Train Loss 0.018913489 Test MSE 4.7276485225304915e-05 Test RE 7.66084972039362e-05\n",
      "129 Train Loss 0.018494846 Test MSE 8.407860702636185e-05 Test RE 0.00010216381601660034\n",
      "130 Train Loss 0.017836874 Test MSE 9.52251355734865e-05 Test RE 0.00010872518421535074\n",
      "131 Train Loss 0.016822636 Test MSE 2.6852010426028862e-05 Test RE 5.7735476693228993e-05\n",
      "132 Train Loss 0.016181095 Test MSE 2.3200496910518732e-05 Test RE 5.366646578997373e-05\n",
      "133 Train Loss 0.0147843165 Test MSE 1.9608937933371208e-05 Test RE 4.9337982692194435e-05\n",
      "134 Train Loss 0.013503221 Test MSE 2.422169529180892e-05 Test RE 5.483484504514664e-05\n",
      "135 Train Loss 0.012743469 Test MSE 2.4400676502612867e-05 Test RE 5.503706753901197e-05\n",
      "136 Train Loss 0.012341379 Test MSE 3.067204336700427e-05 Test RE 6.170576020777061e-05\n",
      "137 Train Loss 0.012118338 Test MSE 3.543942541042035e-05 Test RE 6.63281200698528e-05\n",
      "138 Train Loss 0.012056105 Test MSE 2.660079949808331e-05 Test RE 5.746477323046913e-05\n",
      "139 Train Loss 0.011964673 Test MSE 2.6576666412371468e-05 Test RE 5.7438700386711994e-05\n",
      "140 Train Loss 0.011781758 Test MSE 3.575940741341449e-05 Test RE 6.662688496496713e-05\n",
      "141 Train Loss 0.011335421 Test MSE 8.910237201419084e-05 Test RE 0.00010517172209513454\n",
      "142 Train Loss 0.010753219 Test MSE 2.6889392295726895e-05 Test RE 5.7775650769631076e-05\n",
      "143 Train Loss 0.010149716 Test MSE 3.077858688721247e-05 Test RE 6.181283898145023e-05\n",
      "144 Train Loss 0.009866292 Test MSE 2.804931070431535e-05 Test RE 5.900861874662594e-05\n",
      "145 Train Loss 0.009487165 Test MSE 3.70081895088652e-05 Test RE 6.778026649125908e-05\n",
      "146 Train Loss 0.009121221 Test MSE 2.567790824631926e-05 Test RE 5.645912896447705e-05\n",
      "147 Train Loss 0.008750308 Test MSE 2.3727093556886053e-05 Test RE 5.4272099655575694e-05\n",
      "148 Train Loss 0.008638027 Test MSE 1.7387531533056008e-05 Test RE 4.645937013772982e-05\n",
      "149 Train Loss 0.008579998 Test MSE 1.8185496892807197e-05 Test RE 4.7513490724078496e-05\n",
      "150 Train Loss 0.008515955 Test MSE 2.232001543893892e-05 Test RE 5.263826882305849e-05\n",
      "151 Train Loss 0.008357743 Test MSE 3.7347493349339605e-05 Test RE 6.809027397430058e-05\n",
      "152 Train Loss 0.00820006 Test MSE 1.635274397476618e-05 Test RE 4.5055692694900295e-05\n",
      "153 Train Loss 0.008110718 Test MSE 1.2772839731415619e-05 Test RE 3.981970917151922e-05\n",
      "154 Train Loss 0.008066089 Test MSE 1.3049935433011634e-05 Test RE 4.024931873218071e-05\n",
      "155 Train Loss 0.008053524 Test MSE 1.546514366180908e-05 Test RE 4.3815859134900246e-05\n",
      "156 Train Loss 0.008052869 Test MSE 1.6011685405351232e-05 Test RE 4.4583368305012034e-05\n",
      "157 Train Loss 0.007994468 Test MSE 2.1742460184081853e-05 Test RE 5.195276832489422e-05\n",
      "158 Train Loss 0.007720863 Test MSE 1.579858729729848e-05 Test RE 4.428569650844353e-05\n",
      "159 Train Loss 0.0074619083 Test MSE 7.95116923513477e-06 Test RE 3.141737175356397e-05\n",
      "160 Train Loss 0.0071717505 Test MSE 1.793522945594521e-05 Test RE 4.718541955293171e-05\n",
      "161 Train Loss 0.006811203 Test MSE 4.388052261525713e-06 Test RE 2.3339430140525867e-05\n",
      "162 Train Loss 0.0065585165 Test MSE 2.1535853418719936e-05 Test RE 5.1705339686394546e-05\n",
      "163 Train Loss 0.006198217 Test MSE 1.4485827198233684e-05 Test RE 4.2405872422410096e-05\n",
      "164 Train Loss 0.0058688708 Test MSE 8.317798215411601e-06 Test RE 3.213353779635851e-05\n",
      "165 Train Loss 0.0055576204 Test MSE 1.0808639942361202e-05 Test RE 3.663024954121696e-05\n",
      "166 Train Loss 0.005415835 Test MSE 1.6065807268983166e-05 Test RE 4.465865392730037e-05\n",
      "167 Train Loss 0.005292248 Test MSE 7.074614247483994e-06 Test RE 2.9635054791764435e-05\n",
      "168 Train Loss 0.0051393975 Test MSE 9.401319414476499e-06 Test RE 3.4162430132477354e-05\n",
      "169 Train Loss 0.0051157856 Test MSE 9.477692791538307e-06 Test RE 3.4300911901860054e-05\n",
      "170 Train Loss 0.005085329 Test MSE 1.27430922739287e-05 Test RE 3.9773312848570245e-05\n",
      "171 Train Loss 0.005082507 Test MSE 1.3383049852476367e-05 Test RE 4.0759786472964364e-05\n",
      "172 Train Loss 0.0050818627 Test MSE 1.3100581010588328e-05 Test RE 4.032734502107633e-05\n",
      "173 Train Loss 0.005043354 Test MSE 2.4578687226336687e-05 Test RE 5.5237459210561666e-05\n",
      "174 Train Loss 0.0048887553 Test MSE 1.4529769730094815e-05 Test RE 4.24701424964943e-05\n",
      "175 Train Loss 0.0046756314 Test MSE 2.053062977256441e-05 Test RE 5.04842011039247e-05\n",
      "176 Train Loss 0.004363501 Test MSE 6.767915258590296e-06 Test RE 2.8985567550396777e-05\n",
      "177 Train Loss 0.00416238 Test MSE 1.731299626036592e-05 Test RE 4.635968431226857e-05\n",
      "178 Train Loss 0.004080732 Test MSE 9.49222317048798e-06 Test RE 3.4327195427690075e-05\n",
      "179 Train Loss 0.0039936434 Test MSE 7.868060119995286e-06 Test RE 3.1252746351000335e-05\n",
      "180 Train Loss 0.0038624906 Test MSE 8.353577738609306e-06 Test RE 3.2202575832782994e-05\n",
      "181 Train Loss 0.003828507 Test MSE 9.2015327690957e-06 Test RE 3.379748943038338e-05\n",
      "182 Train Loss 0.0038279942 Test MSE 7.816770279711163e-06 Test RE 3.1150715533072e-05\n",
      "183 Train Loss 0.0038270997 Test MSE 7.571307937194408e-06 Test RE 3.0657716745756985e-05\n",
      "184 Train Loss 0.0038253504 Test MSE 8.418591527438165e-06 Test RE 3.232764522177324e-05\n",
      "185 Train Loss 0.0037859164 Test MSE 1.349255521392092e-05 Test RE 4.092620302263462e-05\n",
      "186 Train Loss 0.0037106322 Test MSE 8.202697301663649e-06 Test RE 3.1910432835912285e-05\n",
      "187 Train Loss 0.0036252507 Test MSE 1.3096726045631454e-05 Test RE 4.0321411240741183e-05\n",
      "188 Train Loss 0.0035557398 Test MSE 1.3208410594350745e-05 Test RE 4.0492970098403034e-05\n",
      "189 Train Loss 0.0033764073 Test MSE 6.675736104234556e-06 Test RE 2.8787498779863932e-05\n",
      "190 Train Loss 0.0031735352 Test MSE 1.4875530911851361e-05 Test RE 4.297249697986007e-05\n",
      "191 Train Loss 0.0030158656 Test MSE 1.3836364958415512e-05 Test RE 4.144435229477526e-05\n",
      "192 Train Loss 0.00296271 Test MSE 1.3901982427379117e-05 Test RE 4.1542508744418984e-05\n",
      "193 Train Loss 0.002899438 Test MSE 1.1999610805898773e-05 Test RE 3.859561206651039e-05\n",
      "194 Train Loss 0.002845962 Test MSE 9.612484377672051e-06 Test RE 3.454396427473281e-05\n",
      "195 Train Loss 0.002798799 Test MSE 1.3719796432103671e-05 Test RE 4.126940296937668e-05\n",
      "196 Train Loss 0.0027070374 Test MSE 1.0432799373868881e-05 Test RE 3.5987757077612914e-05\n",
      "197 Train Loss 0.0026028513 Test MSE 9.111540168829354e-06 Test RE 3.3631810663504875e-05\n",
      "198 Train Loss 0.0025229699 Test MSE 1.1719921778585858e-05 Test RE 3.814316344621345e-05\n",
      "199 Train Loss 0.002468979 Test MSE 9.9253627480566e-06 Test RE 3.510165120277636e-05\n",
      "Training time: 38.09\n",
      "Training time: 38.09\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 11196.711 Test MSE 3444.5614930567363 Test RE 0.653915035885856\n",
      "1 Train Loss 4936.9316 Test MSE 73.52401714971941 Test RE 0.09553642067968693\n",
      "2 Train Loss 4769.254 Test MSE 81.92189897618175 Test RE 0.10084499708744156\n",
      "3 Train Loss 4425.886 Test MSE 61.02070471995922 Test RE 0.08703480523952563\n",
      "4 Train Loss 4028.8242 Test MSE 74.38711417339307 Test RE 0.09609553471264488\n",
      "5 Train Loss 3354.7146 Test MSE 63.442261760293015 Test RE 0.08874495654605274\n",
      "6 Train Loss 2742.7605 Test MSE 113.64707238424575 Test RE 0.11877730814281655\n",
      "7 Train Loss 2085.35 Test MSE 32.60234115682005 Test RE 0.06361781460495199\n",
      "8 Train Loss 1806.4419 Test MSE 28.09589047860631 Test RE 0.05905759442389943\n",
      "9 Train Loss 1675.3405 Test MSE 27.18071499633299 Test RE 0.058087781581533514\n",
      "10 Train Loss 1520.213 Test MSE 34.91396728598053 Test RE 0.06583456232471231\n",
      "11 Train Loss 1378.6852 Test MSE 22.33575819083876 Test RE 0.0526568289611711\n",
      "12 Train Loss 1214.6097 Test MSE 27.487310151048582 Test RE 0.05841447445172694\n",
      "13 Train Loss 1053.0819 Test MSE 15.741581713980768 Test RE 0.04420572690954161\n",
      "14 Train Loss 926.63995 Test MSE 13.585836870797852 Test RE 0.04106743232506696\n",
      "15 Train Loss 820.4077 Test MSE 12.759477821962419 Test RE 0.039798875645699686\n",
      "16 Train Loss 685.9416 Test MSE 12.444077287770172 Test RE 0.03930390507428557\n",
      "17 Train Loss 561.74854 Test MSE 9.117066881010173 Test RE 0.0336420090030195\n",
      "18 Train Loss 469.76978 Test MSE 5.188344076661392 Test RE 0.02537866290073729\n",
      "19 Train Loss 402.2925 Test MSE 3.8689044990669754 Test RE 0.021915347285169216\n",
      "20 Train Loss 330.71243 Test MSE 6.159065511720533 Test RE 0.0276510586971406\n",
      "21 Train Loss 301.31757 Test MSE 2.727765796741336 Test RE 0.018401697707971117\n",
      "22 Train Loss 253.4131 Test MSE 1.7680429786637981 Test RE 0.014814969485568073\n",
      "23 Train Loss 210.91977 Test MSE 7.520831824338609 Test RE 0.030555351989826306\n",
      "24 Train Loss 178.64026 Test MSE 0.928229274391802 Test RE 0.010734504017319263\n",
      "25 Train Loss 157.36273 Test MSE 0.5722657157868007 Test RE 0.008428556773204473\n",
      "26 Train Loss 118.86405 Test MSE 1.0051326017585374 Test RE 0.01117033073868057\n",
      "27 Train Loss 108.45763 Test MSE 1.0398609964044059 Test RE 0.011361665440485232\n",
      "28 Train Loss 83.820244 Test MSE 1.4608467266490621 Test RE 0.013466560242087974\n",
      "29 Train Loss 74.82865 Test MSE 0.21645868705145627 Test RE 0.00518372390686299\n",
      "30 Train Loss 65.10311 Test MSE 0.18898358457962952 Test RE 0.004843579065919624\n",
      "31 Train Loss 57.658157 Test MSE 0.17697905258981322 Test RE 0.004687219430059351\n",
      "32 Train Loss 51.191868 Test MSE 0.11757643438993941 Test RE 0.0038204497796311574\n",
      "33 Train Loss 45.669525 Test MSE 0.16822394435354263 Test RE 0.004569811204828366\n",
      "34 Train Loss 38.1911 Test MSE 0.5276533786158427 Test RE 0.008093357304758946\n",
      "35 Train Loss 35.5222 Test MSE 0.1313686741861874 Test RE 0.004038315638540734\n",
      "36 Train Loss 32.27714 Test MSE 0.09970747824323001 Test RE 0.003518181321561813\n",
      "37 Train Loss 29.492834 Test MSE 0.26144551787268455 Test RE 0.005696983383856259\n",
      "38 Train Loss 25.728617 Test MSE 0.14337894131961543 Test RE 0.004218878682128927\n",
      "39 Train Loss 23.23526 Test MSE 0.38396629508988417 Test RE 0.0069040019280066315\n",
      "40 Train Loss 20.476072 Test MSE 0.0465947866592207 Test RE 0.00240504394461078\n",
      "41 Train Loss 19.030188 Test MSE 0.3517916480988725 Test RE 0.006608412053538282\n",
      "42 Train Loss 15.238138 Test MSE 0.0475400686526436 Test RE 0.002429317365382097\n",
      "43 Train Loss 14.171781 Test MSE 0.030517450631377795 Test RE 0.0019463837840445922\n",
      "44 Train Loss 12.705798 Test MSE 0.038131904939637556 Test RE 0.0021756979532810694\n",
      "45 Train Loss 11.092835 Test MSE 0.028243932122588904 Test RE 0.0018724788971665523\n",
      "46 Train Loss 9.418949 Test MSE 0.023726148431901885 Test RE 0.0017162003012555073\n",
      "47 Train Loss 8.955564 Test MSE 0.0181356825358341 Test RE 0.0015004492293133865\n",
      "48 Train Loss 8.013651 Test MSE 0.016701206148902727 Test RE 0.001439886535834912\n",
      "49 Train Loss 7.2849984 Test MSE 0.03301354678775563 Test RE 0.002024419187135507\n",
      "50 Train Loss 6.7999177 Test MSE 0.010981417882873235 Test RE 0.0011675717044491224\n",
      "51 Train Loss 6.5649524 Test MSE 0.007905236576793973 Test RE 0.0009906307120016557\n",
      "52 Train Loss 6.3646393 Test MSE 0.007367725668851388 Test RE 0.0009563592787040335\n",
      "53 Train Loss 6.3162813 Test MSE 0.007421661978951815 Test RE 0.0009598534662577268\n",
      "54 Train Loss 6.15929 Test MSE 0.008643825970805557 Test RE 0.001035875018474652\n",
      "55 Train Loss 6.0873904 Test MSE 0.007205641084830445 Test RE 0.0009457811746798326\n",
      "56 Train Loss 6.0219197 Test MSE 0.0061238322321201235 Test RE 0.000871898628467009\n",
      "57 Train Loss 5.8412066 Test MSE 0.006759054654157301 Test RE 0.0009160039183729312\n",
      "58 Train Loss 5.7932634 Test MSE 0.006649919729569696 Test RE 0.0009085787052623561\n",
      "59 Train Loss 4.975799 Test MSE 0.0101803738381806 Test RE 0.0011241809340854024\n",
      "60 Train Loss 4.46993 Test MSE 0.010616257742009463 Test RE 0.0011479952186624184\n",
      "61 Train Loss 4.1870747 Test MSE 0.006930276141521157 Test RE 0.000927533538644303\n",
      "62 Train Loss 3.9522324 Test MSE 0.005208126714146471 Test RE 0.0008040723413207214\n",
      "63 Train Loss 3.752739 Test MSE 0.005593816525919923 Test RE 0.0008333135835711165\n",
      "64 Train Loss 3.6151152 Test MSE 0.009366908953942118 Test RE 0.0010783320211563098\n",
      "65 Train Loss 3.396694 Test MSE 0.006828404436279375 Test RE 0.0009206911535566115\n",
      "66 Train Loss 3.287414 Test MSE 0.003632171955003864 Test RE 0.0006714869128088586\n",
      "67 Train Loss 3.038059 Test MSE 0.004707747514582401 Test RE 0.0007644708565604572\n",
      "68 Train Loss 2.864556 Test MSE 0.0022243066056156016 Test RE 0.0005254745393542404\n",
      "69 Train Loss 2.7247536 Test MSE 0.0026681753031211216 Test RE 0.0005755214734283044\n",
      "70 Train Loss 2.5904765 Test MSE 0.0074352368952171274 Test RE 0.0009607308962504852\n",
      "71 Train Loss 2.429953 Test MSE 0.008990218815045279 Test RE 0.001056426978519502\n",
      "72 Train Loss 2.2775676 Test MSE 0.0033995427069937476 Test RE 0.0006496278019976294\n",
      "73 Train Loss 2.10004 Test MSE 0.020885645887338794 Test RE 0.0016101943837516614\n",
      "74 Train Loss 1.7457261 Test MSE 0.00581702752439745 Test RE 0.0008497768814145932\n",
      "75 Train Loss 1.4694973 Test MSE 0.002990680891902538 Test RE 0.0006093115215229485\n",
      "76 Train Loss 1.3683177 Test MSE 0.0031406078092913146 Test RE 0.0006243975717932159\n",
      "77 Train Loss 1.2240713 Test MSE 0.0030389095291831762 Test RE 0.0006142048448475614\n",
      "78 Train Loss 1.0344926 Test MSE 0.010391887699951419 Test RE 0.0011357992427295707\n",
      "79 Train Loss 0.925524 Test MSE 0.000941914329474669 Test RE 0.00034194798925911305\n",
      "80 Train Loss 0.8673992 Test MSE 0.002593901919728291 Test RE 0.0005674546087800922\n",
      "81 Train Loss 0.8340543 Test MSE 0.0039514250243922215 Test RE 0.0007003759512023205\n",
      "82 Train Loss 0.7569147 Test MSE 0.0005471553490975714 Test RE 0.0002606211621338954\n",
      "83 Train Loss 0.72455513 Test MSE 0.002156154242039752 Test RE 0.0005173616880343772\n",
      "84 Train Loss 0.6972214 Test MSE 0.0007150777143489933 Test RE 0.0002979414822273078\n",
      "85 Train Loss 0.6602761 Test MSE 0.00048628569480022585 Test RE 0.0002456971389684955\n",
      "86 Train Loss 0.62842375 Test MSE 0.0007255628188801936 Test RE 0.0003001178745228566\n",
      "87 Train Loss 0.58152694 Test MSE 0.0009485826031152907 Test RE 0.0003431562633270666\n",
      "88 Train Loss 0.5169623 Test MSE 0.0004056509961159211 Test RE 0.00022440401642303517\n",
      "89 Train Loss 0.5006459 Test MSE 0.0007291646618781891 Test RE 0.00030086187573667527\n",
      "90 Train Loss 0.49177542 Test MSE 0.0010162741145800073 Test RE 0.0003551892263896397\n",
      "91 Train Loss 0.42860648 Test MSE 0.0014498763937236502 Test RE 0.00042424803729157386\n",
      "92 Train Loss 0.41679972 Test MSE 0.0003108293575811132 Test RE 0.0001964334153760705\n",
      "93 Train Loss 0.384089 Test MSE 0.004538767481335063 Test RE 0.0007506255097340155\n",
      "94 Train Loss 0.34359294 Test MSE 0.0003020456920395234 Test RE 0.00019363803877198263\n",
      "95 Train Loss 0.33523658 Test MSE 0.00022116924565513676 Test RE 0.00016569779177549125\n",
      "96 Train Loss 0.31560394 Test MSE 0.00017173526606880008 Test RE 0.00014601050262900338\n",
      "97 Train Loss 0.2919045 Test MSE 0.00038794099320401255 Test RE 0.00021945081042480248\n",
      "98 Train Loss 0.27168652 Test MSE 0.0004243340431165702 Test RE 0.0002295135286342238\n",
      "99 Train Loss 0.25907925 Test MSE 0.0001369540413661046 Test RE 0.00013038924737326826\n",
      "100 Train Loss 0.25062424 Test MSE 0.0003841387134375422 Test RE 0.0002183727237682236\n",
      "101 Train Loss 0.23664051 Test MSE 0.0003081848220956654 Test RE 0.00019559600286401396\n",
      "102 Train Loss 0.22626963 Test MSE 0.0001381749127527806 Test RE 0.00013096913279431665\n",
      "103 Train Loss 0.21369238 Test MSE 0.00011565012121594146 Test RE 0.000119819471177025\n",
      "104 Train Loss 0.20436887 Test MSE 0.00024962470913897795 Test RE 0.00017603464073642577\n",
      "105 Train Loss 0.19221197 Test MSE 0.0002135508577727387 Test RE 0.0001628189735248163\n",
      "106 Train Loss 0.1847662 Test MSE 0.0002836513071972571 Test RE 0.00018764921286785119\n",
      "107 Train Loss 0.18184495 Test MSE 8.315456360770355e-05 Test RE 0.0001016008629642175\n",
      "108 Train Loss 0.17537649 Test MSE 0.00011457015702791451 Test RE 0.00011925870977064356\n",
      "109 Train Loss 0.17186464 Test MSE 0.0001411129549050618 Test RE 0.0001323542207400481\n",
      "110 Train Loss 0.16548485 Test MSE 0.00017672540859737742 Test RE 0.0001481166393098582\n",
      "111 Train Loss 0.15712155 Test MSE 0.00011070918684567599 Test RE 0.00011723200232331518\n",
      "112 Train Loss 0.15432808 Test MSE 0.0001117155676079711 Test RE 0.00011776363446799271\n",
      "113 Train Loss 0.1435436 Test MSE 0.00019238647480754895 Test RE 0.0001545402536793745\n",
      "114 Train Loss 0.13726816 Test MSE 0.0001884553672981897 Test RE 0.00015295321419618862\n",
      "115 Train Loss 0.1319454 Test MSE 9.156571904353239e-05 Test RE 0.00010661561279052925\n",
      "116 Train Loss 0.13023834 Test MSE 0.0001377590864556762 Test RE 0.0001307719137631439\n",
      "117 Train Loss 0.12585561 Test MSE 9.549938267826852e-05 Test RE 0.00010888163518346933\n",
      "118 Train Loss 0.11629384 Test MSE 0.00024595108795804916 Test RE 0.0001747345260507981\n",
      "119 Train Loss 0.10904252 Test MSE 7.298169787421778e-05 Test RE 9.51834262469732e-05\n",
      "120 Train Loss 0.10727099 Test MSE 4.8276622320794984e-05 Test RE 7.741458515579941e-05\n",
      "121 Train Loss 0.106824145 Test MSE 4.153288790011389e-05 Test RE 7.180429413939682e-05\n",
      "122 Train Loss 0.10481047 Test MSE 9.048159523049627e-05 Test RE 0.00010598257734872416\n",
      "123 Train Loss 0.10368839 Test MSE 4.488800595470329e-05 Test RE 7.46482290492727e-05\n",
      "124 Train Loss 0.10208089 Test MSE 6.805035593122423e-05 Test RE 9.191143630311172e-05\n",
      "125 Train Loss 0.09913022 Test MSE 5.278937683709115e-05 Test RE 8.09520069164756e-05\n",
      "126 Train Loss 0.09860941 Test MSE 6.789586806837676e-05 Test RE 9.180704839003145e-05\n",
      "127 Train Loss 0.09674284 Test MSE 0.00016429928470134856 Test RE 0.0001428144621697218\n",
      "128 Train Loss 0.09538908 Test MSE 5.8653840944945145e-05 Test RE 8.533016411733395e-05\n",
      "129 Train Loss 0.09326526 Test MSE 0.0002716721448536565 Test RE 0.0001836440695298863\n",
      "130 Train Loss 0.0866812 Test MSE 0.00022047714395603482 Test RE 0.0001654383307913669\n",
      "131 Train Loss 0.08318081 Test MSE 0.00010944793715742756 Test RE 0.00011656230920453474\n",
      "132 Train Loss 0.08115089 Test MSE 6.88667489305423e-05 Test RE 9.246111854004176e-05\n",
      "133 Train Loss 0.07960717 Test MSE 4.2919470728078695e-05 Test RE 7.299305340703986e-05\n",
      "134 Train Loss 0.07800934 Test MSE 5.963700946418076e-05 Test RE 8.60423534950157e-05\n",
      "135 Train Loss 0.07703048 Test MSE 5.525429732240991e-05 Test RE 8.282041121310825e-05\n",
      "136 Train Loss 0.07495004 Test MSE 5.8295690091780103e-05 Test RE 8.50692445730191e-05\n",
      "137 Train Loss 0.069665916 Test MSE 6.592923879271588e-05 Test RE 9.0467665398629e-05\n",
      "138 Train Loss 0.066950835 Test MSE 4.961690606645997e-05 Test RE 7.848184284137e-05\n",
      "139 Train Loss 0.06502712 Test MSE 5.3353901847583e-05 Test RE 8.13837027214123e-05\n",
      "140 Train Loss 0.061081618 Test MSE 3.938100702041535e-05 Test RE 6.991941098223981e-05\n",
      "141 Train Loss 0.060030937 Test MSE 3.565583926459233e-05 Test RE 6.653033097789794e-05\n",
      "142 Train Loss 0.05900658 Test MSE 5.4187674824055476e-05 Test RE 8.201713797921441e-05\n",
      "143 Train Loss 0.057591125 Test MSE 3.045303072300063e-05 Test RE 6.148506162700727e-05\n",
      "144 Train Loss 0.055079196 Test MSE 5.754180509407394e-05 Test RE 8.451739313844128e-05\n",
      "145 Train Loss 0.05311509 Test MSE 2.579815461968339e-05 Test RE 5.659117001664754e-05\n",
      "146 Train Loss 0.049097247 Test MSE 3.62595594507951e-05 Test RE 6.709120836566721e-05\n",
      "147 Train Loss 0.0479286 Test MSE 2.4320486174525373e-05 Test RE 5.494655626664389e-05\n",
      "148 Train Loss 0.047062177 Test MSE 2.8353483387600297e-05 Test RE 5.932770701191199e-05\n",
      "149 Train Loss 0.046108764 Test MSE 4.218213347138811e-05 Test RE 7.236334319656809e-05\n",
      "150 Train Loss 0.045665484 Test MSE 2.1279868205193788e-05 Test RE 5.139712413989721e-05\n",
      "151 Train Loss 0.044617843 Test MSE 5.6050929282035634e-05 Test RE 8.341530862837207e-05\n",
      "152 Train Loss 0.04156074 Test MSE 2.4620384632023275e-05 Test RE 5.528429415114699e-05\n",
      "153 Train Loss 0.040049005 Test MSE 3.4916730310977074e-05 Test RE 6.583716728422804e-05\n",
      "154 Train Loss 0.03902249 Test MSE 1.546100132994592e-05 Test RE 4.380999071270301e-05\n",
      "155 Train Loss 0.03888967 Test MSE 1.7717540515554058e-05 Test RE 4.689818868849599e-05\n",
      "156 Train Loss 0.038658272 Test MSE 2.1361311354279304e-05 Test RE 5.149538476109931e-05\n",
      "157 Train Loss 0.037846852 Test MSE 1.5059989725965894e-05 Test RE 4.323810881356263e-05\n",
      "158 Train Loss 0.037227225 Test MSE 6.619266693794077e-05 Test RE 9.064822239841761e-05\n",
      "159 Train Loss 0.035730824 Test MSE 4.553586952790213e-05 Test RE 7.518499399400354e-05\n",
      "160 Train Loss 0.03439451 Test MSE 2.333276168126533e-05 Test RE 5.381922318495666e-05\n",
      "161 Train Loss 0.034010753 Test MSE 1.4057408794631815e-05 Test RE 4.177408918353368e-05\n",
      "162 Train Loss 0.03311521 Test MSE 1.8940859214121738e-05 Test RE 4.8490224001997986e-05\n",
      "163 Train Loss 0.032652743 Test MSE 1.4314424887702076e-05 Test RE 4.215424393627712e-05\n",
      "164 Train Loss 0.0318934 Test MSE 7.873255969211617e-05 Test RE 9.886248847222686e-05\n",
      "165 Train Loss 0.031439256 Test MSE 1.254385720146401e-05 Test RE 3.946116503568803e-05\n",
      "166 Train Loss 0.030987537 Test MSE 1.6685540290167312e-05 Test RE 4.551184999504963e-05\n",
      "167 Train Loss 0.030488266 Test MSE 1.6912710980796576e-05 Test RE 4.5820620492759704e-05\n",
      "168 Train Loss 0.030310092 Test MSE 2.160961107955028e-05 Test RE 5.17938062328447e-05\n",
      "169 Train Loss 0.030097555 Test MSE 1.3782764464673358e-05 Test RE 4.136399906151514e-05\n",
      "170 Train Loss 0.030040722 Test MSE 1.0958725866198363e-05 Test RE 3.688369175902782e-05\n",
      "171 Train Loss 0.029896405 Test MSE 1.2010052164446726e-05 Test RE 3.8612400235889016e-05\n",
      "172 Train Loss 0.029183958 Test MSE 1.1959407398191107e-05 Test RE 3.853090259322922e-05\n",
      "173 Train Loss 0.02873882 Test MSE 1.1231147401953483e-05 Test RE 3.7339320973801516e-05\n",
      "174 Train Loss 0.028186487 Test MSE 6.890191898624063e-05 Test RE 9.24847253435149e-05\n",
      "175 Train Loss 0.026945585 Test MSE 1.8326796609121702e-05 Test RE 4.769772138094306e-05\n",
      "176 Train Loss 0.026389217 Test MSE 1.7848935926243254e-05 Test RE 4.707176876328884e-05\n",
      "177 Train Loss 0.026099965 Test MSE 1.9149999587080245e-05 Test RE 4.875719770604856e-05\n",
      "178 Train Loss 0.025950456 Test MSE 9.724465593000284e-06 Test RE 3.474459265403123e-05\n",
      "179 Train Loss 0.025857208 Test MSE 1.5095656913062077e-05 Test RE 4.328927982103047e-05\n",
      "180 Train Loss 0.025697578 Test MSE 1.0326188427704933e-05 Test RE 3.5803408624736345e-05\n",
      "181 Train Loss 0.02554442 Test MSE 2.0899071905920397e-05 Test RE 5.093518084545744e-05\n",
      "182 Train Loss 0.025337724 Test MSE 1.0153324646644046e-05 Test RE 3.5502463427207545e-05\n",
      "183 Train Loss 0.025013443 Test MSE 1.8649162585906666e-05 Test RE 4.811539106674214e-05\n",
      "184 Train Loss 0.024652176 Test MSE 2.13305622774271e-05 Test RE 5.145830825028011e-05\n",
      "185 Train Loss 0.02430335 Test MSE 2.1198861479326375e-05 Test RE 5.1299203358433044e-05\n",
      "186 Train Loss 0.023941008 Test MSE 1.9859857353386213e-05 Test RE 4.965264801759247e-05\n",
      "187 Train Loss 0.023639789 Test MSE 1.6992488656901793e-05 Test RE 4.592856185221654e-05\n",
      "188 Train Loss 0.022680683 Test MSE 1.8640624502210986e-05 Test RE 4.8104375551563784e-05\n",
      "189 Train Loss 0.020913638 Test MSE 5.02521175573036e-05 Test RE 7.898261998022431e-05\n",
      "190 Train Loss 0.019229889 Test MSE 1.3710029739147728e-05 Test RE 4.125471115717471e-05\n",
      "191 Train Loss 0.018165106 Test MSE 3.5624682138350786e-05 Test RE 6.650125654014963e-05\n",
      "192 Train Loss 0.016827494 Test MSE 1.3552609484509637e-05 Test RE 4.101718150822554e-05\n",
      "193 Train Loss 0.015811143 Test MSE 1.050720073346661e-05 Test RE 3.611585219378882e-05\n",
      "194 Train Loss 0.015278235 Test MSE 4.168571028893451e-05 Test RE 7.193627663125325e-05\n",
      "195 Train Loss 0.014773654 Test MSE 3.548832175621099e-05 Test RE 6.637386128536846e-05\n",
      "196 Train Loss 0.013918076 Test MSE 6.154026935043635e-05 Test RE 8.740455151404338e-05\n",
      "197 Train Loss 0.012847397 Test MSE 1.1151895622035925e-05 Test RE 3.720734663489868e-05\n",
      "198 Train Loss 0.0121196415 Test MSE 1.4473812507398226e-05 Test RE 4.238828284577179e-05\n",
      "199 Train Loss 0.011566097 Test MSE 9.046778859444012e-06 Test RE 3.351207656601019e-05\n",
      "Training time: 39.10\n",
      "Training time: 39.10\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 17082.975 Test MSE 4881.832749350488 Test RE 0.7784770263039283\n",
      "1 Train Loss 10165.788 Test MSE 1317.632550211327 Test RE 0.40443758627098086\n",
      "2 Train Loss 5199.896 Test MSE 81.2211983471562 Test RE 0.1004127933563659\n",
      "3 Train Loss 4842.647 Test MSE 63.93107885565283 Test RE 0.08908618659661284\n",
      "4 Train Loss 4315.4023 Test MSE 149.90350184727197 Test RE 0.13641440765422808\n",
      "5 Train Loss 3371.116 Test MSE 58.80126366490454 Test RE 0.08543733280478942\n",
      "6 Train Loss 2938.3816 Test MSE 76.34117767152857 Test RE 0.09734951226587867\n",
      "7 Train Loss 2625.211 Test MSE 60.45091905912763 Test RE 0.08662750501816778\n",
      "8 Train Loss 2137.1223 Test MSE 109.76836743126644 Test RE 0.11673281399495736\n",
      "9 Train Loss 1623.7438 Test MSE 38.60478525712481 Test RE 0.06922690615724388\n",
      "10 Train Loss 1346.8336 Test MSE 71.5485686032359 Test RE 0.09424424230821372\n",
      "11 Train Loss 1068.5408 Test MSE 27.601177003729937 Test RE 0.058535341100368135\n",
      "12 Train Loss 852.4993 Test MSE 34.814042275871444 Test RE 0.06574028439593198\n",
      "13 Train Loss 627.718 Test MSE 10.884041158414732 Test RE 0.03675779404385931\n",
      "14 Train Loss 529.2555 Test MSE 8.594760817344065 Test RE 0.03266414162860535\n",
      "15 Train Loss 338.53232 Test MSE 6.244444084013552 Test RE 0.027842052168181326\n",
      "16 Train Loss 278.22403 Test MSE 1.7303108252556096 Test RE 0.014656032344484132\n",
      "17 Train Loss 190.08366 Test MSE 3.377397279314915 Test RE 0.0204760144304646\n",
      "18 Train Loss 103.650635 Test MSE 1.3839608700059176 Test RE 0.01310739109207394\n",
      "19 Train Loss 60.794838 Test MSE 2.1101287962615274 Test RE 0.016184855802666213\n",
      "20 Train Loss 42.57301 Test MSE 0.14190109857947986 Test RE 0.004197079844297107\n",
      "21 Train Loss 35.745564 Test MSE 0.08829936657997943 Test RE 0.0033108015239205406\n",
      "22 Train Loss 31.810997 Test MSE 0.056875005464032756 Test RE 0.002657143920748494\n",
      "23 Train Loss 27.97168 Test MSE 0.0609748011064597 Test RE 0.002751246787975011\n",
      "24 Train Loss 24.113272 Test MSE 0.058855605632932725 Test RE 0.0027030138367280135\n",
      "25 Train Loss 22.002455 Test MSE 0.15862015977102042 Test RE 0.0044374507281749135\n",
      "26 Train Loss 20.236128 Test MSE 0.1415553871182125 Test RE 0.004191964086040319\n",
      "27 Train Loss 18.461176 Test MSE 0.12681411415079213 Test RE 0.003967693796988976\n",
      "28 Train Loss 16.979366 Test MSE 0.0353294603441904 Test RE 0.0020942226586777917\n",
      "29 Train Loss 15.997246 Test MSE 0.026206752491699608 Test RE 0.0018036860893893153\n",
      "30 Train Loss 15.746117 Test MSE 0.028963276119182136 Test RE 0.0018961740320289425\n",
      "31 Train Loss 15.353879 Test MSE 0.036012105446110936 Test RE 0.002114358416776399\n",
      "32 Train Loss 14.611018 Test MSE 0.045774778679938365 Test RE 0.002383787175202312\n",
      "33 Train Loss 13.704301 Test MSE 0.050544542585713885 Test RE 0.0025049063152475346\n",
      "34 Train Loss 13.256711 Test MSE 0.02532671093622752 Test RE 0.0017731429480339342\n",
      "35 Train Loss 12.226354 Test MSE 0.0326933829255537 Test RE 0.002014578909167873\n",
      "36 Train Loss 11.5004425 Test MSE 0.019627342500400265 Test RE 0.0015609360214668133\n",
      "37 Train Loss 11.346831 Test MSE 0.02501831275341399 Test RE 0.001762314282814435\n",
      "38 Train Loss 10.675098 Test MSE 0.02036693810821321 Test RE 0.0015900735894793009\n",
      "39 Train Loss 10.485149 Test MSE 0.022198922677638788 Test RE 0.0016600466844035233\n",
      "40 Train Loss 9.61211 Test MSE 0.024464451696532472 Test RE 0.0017426978511823061\n",
      "41 Train Loss 9.133299 Test MSE 0.02335282147691899 Test RE 0.0017026447045271661\n",
      "42 Train Loss 8.878201 Test MSE 0.019266064391341153 Test RE 0.0015465033178797716\n",
      "43 Train Loss 8.724232 Test MSE 0.03199637457095995 Test RE 0.0019929882511117666\n",
      "44 Train Loss 8.27132 Test MSE 0.013051072505172652 Test RE 0.0012728506642791437\n",
      "45 Train Loss 7.999785 Test MSE 0.02604585358957793 Test RE 0.0017981406115746027\n",
      "46 Train Loss 7.5879116 Test MSE 0.015776313911188576 Test RE 0.0013994491474925823\n",
      "47 Train Loss 7.250461 Test MSE 0.011935326379212274 Test RE 0.0012172267898190505\n",
      "48 Train Loss 6.9181776 Test MSE 0.012971197687315708 Test RE 0.0012689496534503406\n",
      "49 Train Loss 6.543774 Test MSE 0.012246651455858478 Test RE 0.0012329998713154827\n",
      "50 Train Loss 6.395305 Test MSE 0.008632420564769695 Test RE 0.001035191381674666\n",
      "51 Train Loss 6.284284 Test MSE 0.008157408963384677 Test RE 0.001006306945602482\n",
      "52 Train Loss 6.0878296 Test MSE 0.012892745888508441 Test RE 0.0012651064321935075\n",
      "53 Train Loss 5.5466266 Test MSE 0.012654991758491798 Test RE 0.0012533872878834234\n",
      "54 Train Loss 5.4042974 Test MSE 0.007287863127253861 Test RE 0.0009511619227888436\n",
      "55 Train Loss 4.893981 Test MSE 0.024730036731779773 Test RE 0.0017521316435375205\n",
      "56 Train Loss 4.3942695 Test MSE 0.011700576703800347 Test RE 0.001205196845702221\n",
      "57 Train Loss 3.8797154 Test MSE 0.008376710432978232 Test RE 0.0010197438712087753\n",
      "58 Train Loss 3.6927485 Test MSE 0.005345213554317806 Test RE 0.0008145858895389594\n",
      "59 Train Loss 3.3343217 Test MSE 0.0338553096421454 Test RE 0.002050065549051244\n",
      "60 Train Loss 3.0505977 Test MSE 0.011418979026389785 Test RE 0.0011906057893442316\n",
      "61 Train Loss 2.7000573 Test MSE 0.009934301279628605 Test RE 0.0011105113861248001\n",
      "62 Train Loss 2.3292735 Test MSE 0.0025612965106422843 Test RE 0.0005638768711701083\n",
      "63 Train Loss 2.120141 Test MSE 0.002370754002987283 Test RE 0.0005424973219428956\n",
      "64 Train Loss 2.0039048 Test MSE 0.0049273969906076555 Test RE 0.000782101518887882\n",
      "65 Train Loss 1.7599564 Test MSE 0.005965653874144004 Test RE 0.0008605644044747862\n",
      "66 Train Loss 1.5401917 Test MSE 0.0037390702011891046 Test RE 0.0006812965063584985\n",
      "67 Train Loss 1.3845434 Test MSE 0.001958581298710908 Test RE 0.0004930888181024602\n",
      "68 Train Loss 1.3333361 Test MSE 0.0025975048024356345 Test RE 0.0005678485641067143\n",
      "69 Train Loss 1.2701885 Test MSE 0.0015827620513970586 Test RE 0.00044326369956914426\n",
      "70 Train Loss 1.1686573 Test MSE 0.0019000128755924408 Test RE 0.00048566032298740793\n",
      "71 Train Loss 1.1050556 Test MSE 0.0013701615775967243 Test RE 0.000412420500287668\n",
      "72 Train Loss 1.0227159 Test MSE 0.005430422999269262 Test RE 0.0008210529812244761\n",
      "73 Train Loss 0.9262858 Test MSE 0.002168353338596738 Test RE 0.0005188231890582495\n",
      "74 Train Loss 0.8496437 Test MSE 0.0007284498061328891 Test RE 0.0003007143606481139\n",
      "75 Train Loss 0.76966363 Test MSE 0.0009355508466739971 Test RE 0.0003407909478352448\n",
      "76 Train Loss 0.7340533 Test MSE 0.0005655958273142639 Test RE 0.0002649765557800426\n",
      "77 Train Loss 0.68989116 Test MSE 0.0012857736749738748 Test RE 0.00039951824497455845\n",
      "78 Train Loss 0.61998516 Test MSE 0.0015023997546560633 Test RE 0.00043186410083037753\n",
      "79 Train Loss 0.59107393 Test MSE 0.0008384311078431402 Test RE 0.0003226175910265423\n",
      "80 Train Loss 0.5352231 Test MSE 0.0022520867993598287 Test RE 0.0005287457807397439\n",
      "81 Train Loss 0.48510602 Test MSE 0.0033067857422300504 Test RE 0.0006407039191606144\n",
      "82 Train Loss 0.4704588 Test MSE 0.0017388376489420835 Test RE 0.0004646049898294638\n",
      "83 Train Loss 0.43394396 Test MSE 0.0012147493697245112 Test RE 0.00038832709467282237\n",
      "84 Train Loss 0.41965201 Test MSE 0.0013580018578629542 Test RE 0.00041058637581317415\n",
      "85 Train Loss 0.38419256 Test MSE 0.002919849976640098 Test RE 0.0006020528564131431\n",
      "86 Train Loss 0.34300092 Test MSE 0.0015317771512495372 Test RE 0.0004360659194457052\n",
      "87 Train Loss 0.31545603 Test MSE 0.0014675796411161627 Test RE 0.0004268302506994148\n",
      "88 Train Loss 0.3046869 Test MSE 0.0011749493863165612 Test RE 0.00038191255158716574\n",
      "89 Train Loss 0.27281824 Test MSE 0.0006054646661046044 Test RE 0.0002741566307016462\n",
      "90 Train Loss 0.25319713 Test MSE 0.0003873843362543952 Test RE 0.00021929330880240884\n",
      "91 Train Loss 0.23784511 Test MSE 0.0009539184864653526 Test RE 0.0003441200560684783\n",
      "92 Train Loss 0.22233683 Test MSE 0.0006948178344953799 Test RE 0.0002936904542722729\n",
      "93 Train Loss 0.21053307 Test MSE 0.001033013854608667 Test RE 0.00035810255980897186\n",
      "94 Train Loss 0.20185632 Test MSE 0.0003129367186223644 Test RE 0.0001970981802223352\n",
      "95 Train Loss 0.18836483 Test MSE 0.001148859297953673 Test RE 0.0003776485087147293\n",
      "96 Train Loss 0.17650232 Test MSE 0.00032814970656731444 Test RE 0.00020183215741512728\n",
      "97 Train Loss 0.17004408 Test MSE 0.0012607414115883482 Test RE 0.0003956100916518397\n",
      "98 Train Loss 0.14669663 Test MSE 0.0012834760263140974 Test RE 0.00039916112029742175\n",
      "99 Train Loss 0.13748483 Test MSE 0.00017971737126579442 Test RE 0.00014936518499747948\n",
      "100 Train Loss 0.13085583 Test MSE 0.00016199151552321215 Test RE 0.00014180791988462115\n",
      "101 Train Loss 0.123015784 Test MSE 0.0004103420960232027 Test RE 0.00022569783263868195\n",
      "102 Train Loss 0.115188174 Test MSE 0.0001751220369855806 Test RE 0.00014744320153927152\n",
      "103 Train Loss 0.11186362 Test MSE 0.00013122735857369117 Test RE 0.00012763404874482939\n",
      "104 Train Loss 0.10960053 Test MSE 8.817917730245028e-05 Test RE 0.00010462545836552553\n",
      "105 Train Loss 0.10767279 Test MSE 0.00010612189968988471 Test RE 0.00011477752620872407\n",
      "106 Train Loss 0.103171125 Test MSE 0.00012762555533769198 Test RE 0.00012587027318371744\n",
      "107 Train Loss 0.1010935 Test MSE 0.00010759273820903155 Test RE 0.00011557019139811423\n",
      "108 Train Loss 0.09582702 Test MSE 0.00021290004645102502 Test RE 0.0001625706830490877\n",
      "109 Train Loss 0.077978835 Test MSE 0.0001710005242897047 Test RE 0.00014569782658369184\n",
      "110 Train Loss 0.056965176 Test MSE 8.913896852901916e-05 Test RE 0.00010519331817204121\n",
      "111 Train Loss 0.049749155 Test MSE 0.00012347161516941953 Test RE 0.00012380492374750677\n",
      "112 Train Loss 0.045452718 Test MSE 0.0001730673608850491 Test RE 0.00014657568683897334\n",
      "113 Train Loss 0.04229264 Test MSE 6.188420335510998e-05 Test RE 8.764845289111144e-05\n",
      "114 Train Loss 0.041352317 Test MSE 7.626779739908762e-05 Test RE 9.730271411975908e-05\n",
      "115 Train Loss 0.040205505 Test MSE 0.0001318410679486506 Test RE 0.0001279321529098791\n",
      "116 Train Loss 0.039302003 Test MSE 5.869840383763323e-05 Test RE 8.536257322218322e-05\n",
      "117 Train Loss 0.03775025 Test MSE 5.9347690954833875e-05 Test RE 8.583339004324086e-05\n",
      "118 Train Loss 0.033105962 Test MSE 5.878098438228865e-05 Test RE 8.542259879126323e-05\n",
      "119 Train Loss 0.029319067 Test MSE 0.0005332709702430249 Test RE 0.0002572932090271624\n",
      "120 Train Loss 0.026762446 Test MSE 5.4463466711530605e-05 Test RE 8.222558900882638e-05\n",
      "121 Train Loss 0.025829345 Test MSE 2.9989234755620048e-05 Test RE 6.101506022632654e-05\n",
      "122 Train Loss 0.025588278 Test MSE 2.8225864551459223e-05 Test RE 5.919403963014489e-05\n",
      "123 Train Loss 0.025222763 Test MSE 2.93829199264177e-05 Test RE 6.0395117168157663e-05\n",
      "124 Train Loss 0.024869483 Test MSE 2.988639115589599e-05 Test RE 6.091034936045047e-05\n",
      "125 Train Loss 0.024682634 Test MSE 1.684528912016642e-05 Test RE 4.5729198233507255e-05\n",
      "126 Train Loss 0.024508486 Test MSE 3.192818815219817e-05 Test RE 6.295663242442806e-05\n",
      "127 Train Loss 0.024187133 Test MSE 2.760129239212295e-05 Test RE 5.8535463455510515e-05\n",
      "128 Train Loss 0.023837706 Test MSE 1.43587507712939e-05 Test RE 4.221946066160837e-05\n",
      "129 Train Loss 0.022953404 Test MSE 2.8859610670736634e-05 Test RE 5.985488301670789e-05\n",
      "130 Train Loss 0.020260423 Test MSE 1.4927137549833624e-05 Test RE 4.30469731796902e-05\n",
      "131 Train Loss 0.017829755 Test MSE 2.925292376899463e-05 Test RE 6.0261368782983634e-05\n",
      "132 Train Loss 0.016834179 Test MSE 1.2932865057172766e-05 Test RE 4.006837460585721e-05\n",
      "133 Train Loss 0.0162053 Test MSE 1.679272886630478e-05 Test RE 4.5657800941163504e-05\n",
      "134 Train Loss 0.015898807 Test MSE 9.50025726295157e-06 Test RE 3.4341719397786976e-05\n",
      "135 Train Loss 0.015795827 Test MSE 1.1339243074736223e-05 Test RE 3.7518579314598865e-05\n",
      "136 Train Loss 0.015260913 Test MSE 1.0654781017304061e-05 Test RE 3.636860277810895e-05\n",
      "137 Train Loss 0.014912963 Test MSE 1.0991861384160686e-05 Test RE 3.6939411638735786e-05\n",
      "138 Train Loss 0.01443483 Test MSE 2.0157282677215098e-05 Test RE 5.0023070444733914e-05\n",
      "139 Train Loss 0.013257481 Test MSE 1.5101267170717136e-05 Test RE 4.329732324219987e-05\n",
      "140 Train Loss 0.012511945 Test MSE 9.423142216999847e-06 Test RE 3.420205690190698e-05\n",
      "141 Train Loss 0.012193194 Test MSE 9.560218260948157e-06 Test RE 3.4449923039776416e-05\n",
      "142 Train Loss 0.011894395 Test MSE 1.4926949394185554e-05 Test RE 4.304670187661442e-05\n",
      "143 Train Loss 0.011694001 Test MSE 7.365996343187013e-06 Test RE 3.0239186380857433e-05\n",
      "144 Train Loss 0.0115959225 Test MSE 6.864316972469657e-06 Test RE 2.9191271834419895e-05\n",
      "145 Train Loss 0.011519981 Test MSE 1.1900895328589337e-05 Test RE 3.84365297225455e-05\n",
      "146 Train Loss 0.011052145 Test MSE 1.6678463911367727e-05 Test RE 4.550219812766657e-05\n",
      "147 Train Loss 0.010444317 Test MSE 3.487519558692726e-05 Test RE 6.579799777665381e-05\n",
      "148 Train Loss 0.009738192 Test MSE 6.172981567018128e-05 Test RE 8.753905266219128e-05\n",
      "149 Train Loss 0.00845103 Test MSE 6.5780171978318854e-06 Test RE 2.8576027466596098e-05\n",
      "150 Train Loss 0.0076893 Test MSE 1.4958699045619878e-05 Test RE 4.309245776962765e-05\n",
      "151 Train Loss 0.0070197056 Test MSE 1.0374472524145115e-05 Test RE 3.5887017359699646e-05\n",
      "152 Train Loss 0.00658402 Test MSE 4.352987872383436e-06 Test RE 2.32459918362137e-05\n",
      "153 Train Loss 0.0064550345 Test MSE 3.3565615416814993e-06 Test RE 2.0412756711685344e-05\n",
      "154 Train Loss 0.006435386 Test MSE 3.5644845419416407e-06 Test RE 2.1035494226735547e-05\n",
      "155 Train Loss 0.0063971076 Test MSE 6.4978454378765955e-06 Test RE 2.8401353719024866e-05\n",
      "156 Train Loss 0.0063534263 Test MSE 2.7206021926667197e-06 Test RE 1.8377518737390367e-05\n",
      "157 Train Loss 0.006301827 Test MSE 3.819264514142927e-06 Test RE 2.1774300952830743e-05\n",
      "158 Train Loss 0.006093887 Test MSE 4.653592084978059e-06 Test RE 2.4035242509730724e-05\n",
      "159 Train Loss 0.0057428502 Test MSE 8.567279465051669e-06 Test RE 3.261187877310229e-05\n",
      "160 Train Loss 0.0054233563 Test MSE 4.096334287940227e-06 Test RE 2.2550285657399515e-05\n",
      "161 Train Loss 0.005285281 Test MSE 2.4764112400398226e-06 Test RE 1.7533383644388105e-05\n",
      "162 Train Loss 0.005280536 Test MSE 4.194047959404117e-06 Test RE 2.281765705760726e-05\n",
      "163 Train Loss 0.005254318 Test MSE 2.9466664833665054e-06 Test RE 1.912581030403058e-05\n",
      "164 Train Loss 0.005253748 Test MSE 2.7255665321113475e-06 Test RE 1.8394278016088582e-05\n",
      "165 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "166 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "167 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "168 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "169 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "170 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "171 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "172 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "173 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "174 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "175 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "176 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "177 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "178 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "179 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "180 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "181 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "182 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "183 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "184 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "185 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "186 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "187 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "188 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "189 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "190 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "191 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "192 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "193 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "194 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "195 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "196 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "197 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "198 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "199 Train Loss 0.0052530174 Test MSE 2.433953967483697e-06 Test RE 1.738243173596636e-05\n",
      "Training time: 32.62\n",
      "Training time: 32.62\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 17193.215 Test MSE 4807.710434804804 Test RE 0.7725444975451304\n",
      "1 Train Loss 4987.164 Test MSE 91.54736490050398 Test RE 0.10660492682476909\n",
      "2 Train Loss 4044.2236 Test MSE 51.01884930440418 Test RE 0.07958288555064304\n",
      "3 Train Loss 2888.9722 Test MSE 95.24617273871485 Test RE 0.10873719335211343\n",
      "4 Train Loss 1887.03 Test MSE 137.75603846159333 Test RE 0.13077046705558218\n",
      "5 Train Loss 845.63074 Test MSE 10.519450950918069 Test RE 0.03613689957710627\n",
      "6 Train Loss 452.3034 Test MSE 13.886383513688209 Test RE 0.04151919552656441\n",
      "7 Train Loss 251.35199 Test MSE 19.85402719250368 Test RE 0.049645359340496895\n",
      "8 Train Loss 141.89378 Test MSE 1.4190507145457847 Test RE 0.01327251762427598\n",
      "9 Train Loss 103.71285 Test MSE 1.3763521366315967 Test RE 0.013071310557217797\n",
      "10 Train Loss 69.9159 Test MSE 0.28337253858842315 Test RE 0.005931072499706209\n",
      "11 Train Loss 46.500767 Test MSE 0.16853828401429718 Test RE 0.004574078737892527\n",
      "12 Train Loss 33.30179 Test MSE 0.07747209931142786 Test RE 0.0031011802864774614\n",
      "13 Train Loss 26.824265 Test MSE 0.05004133623572535 Test RE 0.002492406076188291\n",
      "14 Train Loss 22.369429 Test MSE 0.06521509643723859 Test RE 0.0028453023513301734\n",
      "15 Train Loss 19.334475 Test MSE 0.0627559360147337 Test RE 0.0027911408832196625\n",
      "16 Train Loss 17.662804 Test MSE 0.037631824854856756 Test RE 0.002161384296281972\n",
      "17 Train Loss 16.822744 Test MSE 0.030872702224147196 Test RE 0.001957679866369768\n",
      "18 Train Loss 14.625107 Test MSE 0.048163230206451975 Test RE 0.0024451874357980866\n",
      "19 Train Loss 12.515659 Test MSE 0.03676305809824274 Test RE 0.0021362898036233124\n",
      "20 Train Loss 11.770319 Test MSE 0.023584080316831058 Test RE 0.0017110544297385196\n",
      "21 Train Loss 11.268243 Test MSE 0.030651311338501512 Test RE 0.0019506478889830987\n",
      "22 Train Loss 9.648538 Test MSE 0.029209270755116278 Test RE 0.001904209421346048\n",
      "23 Train Loss 8.95141 Test MSE 0.016153398956609968 Test RE 0.001416075183977932\n",
      "24 Train Loss 8.161778 Test MSE 0.014770692242077504 Test RE 0.0013541125932541682\n",
      "25 Train Loss 7.569647 Test MSE 0.016478866685507684 Test RE 0.0014302699773346313\n",
      "26 Train Loss 7.0366 Test MSE 0.012016980017038367 Test RE 0.001221383424475874\n",
      "27 Train Loss 6.7857637 Test MSE 0.010664472440751397 Test RE 0.001150599127814411\n",
      "28 Train Loss 6.427803 Test MSE 0.008935543733822965 Test RE 0.0010532096865364898\n",
      "29 Train Loss 5.852813 Test MSE 0.018715955396753192 Test RE 0.0015242645633463565\n",
      "30 Train Loss 5.1057954 Test MSE 0.008937495326067656 Test RE 0.0010533246948504192\n",
      "31 Train Loss 4.831735 Test MSE 0.008040541691778865 Test RE 0.000999072503425873\n",
      "32 Train Loss 4.442404 Test MSE 0.009512705240068586 Test RE 0.0010866917558681694\n",
      "33 Train Loss 3.6320446 Test MSE 0.00871811130771041 Test RE 0.0010403166686878506\n",
      "34 Train Loss 3.077399 Test MSE 0.007819247216206497 Test RE 0.000985228178123794\n",
      "35 Train Loss 2.7090487 Test MSE 0.012482818093868066 Test RE 0.0012448317975267478\n",
      "36 Train Loss 2.29145 Test MSE 0.003425646528710763 Test RE 0.00065211715734237\n",
      "37 Train Loss 1.8948386 Test MSE 0.003028913531096559 Test RE 0.0006131938493718216\n",
      "38 Train Loss 1.675275 Test MSE 0.002006493720415381 Test RE 0.0004990835491018623\n",
      "39 Train Loss 1.361485 Test MSE 0.0037361192457635033 Test RE 0.0006810276062913628\n",
      "40 Train Loss 1.2003365 Test MSE 0.0013675639876948413 Test RE 0.00041202937577507843\n",
      "41 Train Loss 1.0128416 Test MSE 0.000888578753755024 Test RE 0.0003321255715528691\n",
      "42 Train Loss 0.87543994 Test MSE 0.0007961692317747269 Test RE 0.00031438154752529634\n",
      "43 Train Loss 0.81603706 Test MSE 0.0007152168084125938 Test RE 0.00029797045801243207\n",
      "44 Train Loss 0.69615734 Test MSE 0.0010221478406035101 Test RE 0.000356214185278923\n",
      "45 Train Loss 0.64571553 Test MSE 0.0008430654747951821 Test RE 0.0003235079849570238\n",
      "46 Train Loss 0.60692334 Test MSE 0.0006474070247337891 Test RE 0.00028349346757104726\n",
      "47 Train Loss 0.53440756 Test MSE 0.0021410729213577756 Test RE 0.000515549157875019\n",
      "48 Train Loss 0.49638522 Test MSE 0.0003132274330558742 Test RE 0.0001971897098847106\n",
      "49 Train Loss 0.46953568 Test MSE 0.0003088400837947535 Test RE 0.00019580383028682544\n",
      "50 Train Loss 0.40179756 Test MSE 0.001092955921739042 Test RE 0.00036834576084246765\n",
      "51 Train Loss 0.3613349 Test MSE 0.0011609231574770146 Test RE 0.00037962612289628905\n",
      "52 Train Loss 0.33995205 Test MSE 0.0005252640932823068 Test RE 0.0002553543198281344\n",
      "53 Train Loss 0.32040262 Test MSE 0.00026707878344474524 Test RE 0.00018208494823803508\n",
      "54 Train Loss 0.28293753 Test MSE 0.0008505584506682787 Test RE 0.00032494243775254346\n",
      "55 Train Loss 0.2550964 Test MSE 0.000315229328196841 Test RE 0.00019781884442524392\n",
      "56 Train Loss 0.1959331 Test MSE 0.00018249732398287265 Test RE 0.000150515977247811\n",
      "57 Train Loss 0.1872222 Test MSE 0.000121553390483104 Test RE 0.0001228394578155769\n",
      "58 Train Loss 0.17591332 Test MSE 0.00018514585224366188 Test RE 0.00015160423940793202\n",
      "59 Train Loss 0.11741572 Test MSE 0.00018053936053466382 Test RE 0.00014970637769898439\n",
      "60 Train Loss 0.09856702 Test MSE 0.0004171720264751613 Test RE 0.00022756839256869108\n",
      "61 Train Loss 0.08750336 Test MSE 0.0003964551832383593 Test RE 0.00022184589776996913\n",
      "62 Train Loss 0.07624705 Test MSE 0.00014027918358687025 Test RE 0.0001319626314526527\n",
      "63 Train Loss 0.06496021 Test MSE 0.00017596951833143915 Test RE 0.00014779953747858074\n",
      "64 Train Loss 0.0600752 Test MSE 0.00017966972255713625 Test RE 0.00014934538298853943\n",
      "65 Train Loss 0.05460159 Test MSE 8.868874886509072e-05 Test RE 0.0001049273287076209\n",
      "66 Train Loss 0.052440528 Test MSE 5.3636776901480654e-05 Test RE 8.159916012022578e-05\n",
      "67 Train Loss 0.04853726 Test MSE 6.11382139790864e-05 Test RE 8.71185675991176e-05\n",
      "68 Train Loss 0.041871525 Test MSE 0.00011762089963660942 Test RE 0.0001208360724114007\n",
      "69 Train Loss 0.03782615 Test MSE 0.00010464947566171942 Test RE 0.00011397848517013402\n",
      "70 Train Loss 0.034264967 Test MSE 0.0004816513877885537 Test RE 0.0002445235883244498\n",
      "71 Train Loss 0.0309413 Test MSE 6.33366788257985e-05 Test RE 8.867107949331493e-05\n",
      "72 Train Loss 0.02942366 Test MSE 5.1134055606530857e-05 Test RE 7.967268843790418e-05\n",
      "73 Train Loss 0.027022397 Test MSE 3.58690051434717e-05 Test RE 6.67289080325958e-05\n",
      "74 Train Loss 0.024238707 Test MSE 0.0001506471289351806 Test RE 0.00013675234490472527\n",
      "75 Train Loss 0.020823646 Test MSE 2.2645742583731072e-05 Test RE 5.302096594498469e-05\n",
      "76 Train Loss 0.018758168 Test MSE 2.7871742270189427e-05 Test RE 5.882154278057291e-05\n",
      "77 Train Loss 0.018014666 Test MSE 1.3893175728196611e-05 Test RE 4.152934837903295e-05\n",
      "78 Train Loss 0.016134761 Test MSE 1.4687555371819617e-05 Test RE 4.270012150207004e-05\n",
      "79 Train Loss 0.014750817 Test MSE 2.279772725991848e-05 Test RE 5.319859091678257e-05\n",
      "80 Train Loss 0.013327781 Test MSE 1.259134872838223e-05 Test RE 3.9535795210249334e-05\n",
      "81 Train Loss 0.012089324 Test MSE 2.5700694788244595e-05 Test RE 5.6484174287717576e-05\n",
      "82 Train Loss 0.011626171 Test MSE 3.2689647430220395e-05 Test RE 6.370293917956563e-05\n",
      "83 Train Loss 0.011193472 Test MSE 1.0442646881647513e-05 Test RE 3.600473747364514e-05\n",
      "84 Train Loss 0.010782777 Test MSE 1.0371138064762127e-05 Test RE 3.588124967279722e-05\n",
      "85 Train Loss 0.010625808 Test MSE 1.2017217794244786e-05 Test RE 3.862391729279214e-05\n",
      "86 Train Loss 0.010143201 Test MSE 6.696225603381211e-05 Test RE 9.117366037631517e-05\n",
      "87 Train Loss 0.009212036 Test MSE 9.407316481595146e-05 Test RE 0.00010806554044946776\n",
      "88 Train Loss 0.008843207 Test MSE 2.322246349748471e-05 Test RE 5.3691865896308944e-05\n",
      "89 Train Loss 0.008696252 Test MSE 1.310807452579964e-05 Test RE 4.033887696656317e-05\n",
      "90 Train Loss 0.008384876 Test MSE 9.931815845697239e-06 Test RE 3.511306023549832e-05\n",
      "91 Train Loss 0.0076473737 Test MSE 1.5188668470524083e-05 Test RE 4.3422437995126176e-05\n",
      "92 Train Loss 0.007234006 Test MSE 9.528155069606223e-06 Test RE 3.4392105208920994e-05\n",
      "93 Train Loss 0.007090163 Test MSE 8.311370256158453e-06 Test RE 3.2121119065612336e-05\n",
      "94 Train Loss 0.0068544163 Test MSE 1.523556926613951e-05 Test RE 4.348942797396075e-05\n",
      "95 Train Loss 0.0060182135 Test MSE 4.396741200082968e-05 Test RE 7.387879510222909e-05\n",
      "96 Train Loss 0.00524841 Test MSE 8.51177765085922e-06 Test RE 3.250607158776016e-05\n",
      "97 Train Loss 0.004669969 Test MSE 3.23706041813298e-05 Test RE 6.33913141376714e-05\n",
      "98 Train Loss 0.0043402878 Test MSE 1.8362704202962183e-05 Test RE 4.7744425459614136e-05\n",
      "99 Train Loss 0.0043139514 Test MSE 1.4464722009035708e-05 Test RE 4.237496945174379e-05\n",
      "100 Train Loss 0.0040866598 Test MSE 1.9562217080623717e-05 Test RE 4.9279170549279594e-05\n",
      "101 Train Loss 0.0033982575 Test MSE 2.1647187643732103e-05 Test RE 5.1838818332883404e-05\n",
      "102 Train Loss 0.003134547 Test MSE 2.908180085715751e-05 Test RE 6.008485264892997e-05\n",
      "103 Train Loss 0.0029732934 Test MSE 2.76036268454468e-05 Test RE 5.8537938800071534e-05\n",
      "104 Train Loss 0.002934193 Test MSE 2.8426317266462747e-05 Test RE 5.940385807167374e-05\n",
      "105 Train Loss 0.0027695473 Test MSE 4.0650520283904933e-05 Test RE 7.103745706880222e-05\n",
      "106 Train Loss 0.0025534402 Test MSE 9.13563121857949e-06 Test RE 3.367624282061186e-05\n",
      "107 Train Loss 0.002520045 Test MSE 1.1650934711869569e-05 Test RE 3.8030736557387124e-05\n",
      "108 Train Loss 0.00245965 Test MSE 9.514656472468048e-06 Test RE 3.436773481869889e-05\n",
      "109 Train Loss 0.0023668855 Test MSE 1.1903475906519299e-05 Test RE 3.844069676549351e-05\n",
      "110 Train Loss 0.0022322168 Test MSE 7.6019356958722944e-06 Test RE 3.0719663075024367e-05\n",
      "111 Train Loss 0.002219987 Test MSE 8.204140435889539e-06 Test RE 3.191323977921315e-05\n",
      "112 Train Loss 0.002172075 Test MSE 5.328245722096642e-06 Test RE 2.5718549715539893e-05\n",
      "113 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "114 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "115 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "116 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "117 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "118 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "119 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "120 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "121 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "122 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "123 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "124 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "125 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "126 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "127 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "128 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "129 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "130 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "131 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "132 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "133 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "134 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "135 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "136 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "137 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "138 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "139 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "140 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "141 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "142 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "143 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "144 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "145 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "146 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "147 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "148 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "149 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "150 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "151 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "152 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "153 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "154 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "155 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "156 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "157 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "158 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "159 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "160 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "161 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "162 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "163 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "164 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "165 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "166 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "167 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "168 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "169 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "170 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "171 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "172 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "173 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "174 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "175 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "176 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "177 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "178 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "179 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "180 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "181 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "182 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "183 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "184 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "185 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "186 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "187 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "188 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "189 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "190 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "191 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "192 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "193 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "194 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "195 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "196 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "197 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "198 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "199 Train Loss 0.002104756 Test MSE 7.083793112604567e-06 Test RE 2.965427336591579e-05\n",
      "Training time: 24.03\n",
      "Training time: 24.03\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 13025.89 Test MSE 5909.136799318578 Test RE 0.856478320585113\n",
      "1 Train Loss 5260.2905 Test MSE 207.37645560230328 Test RE 0.16044791433078895\n",
      "2 Train Loss 4756.7188 Test MSE 57.680353057516044 Test RE 0.08461908157650691\n",
      "3 Train Loss 4505.2456 Test MSE 63.62820266602314 Test RE 0.08887491127993895\n",
      "4 Train Loss 4074.6099 Test MSE 46.9225873247967 Test RE 0.07632122421469731\n",
      "5 Train Loss 3089.2131 Test MSE 80.98398077855649 Test RE 0.10026605151569114\n",
      "6 Train Loss 2492.578 Test MSE 40.30697156520976 Test RE 0.07073664161546384\n",
      "7 Train Loss 1616.9028 Test MSE 76.61492619786672 Test RE 0.09752389677855025\n",
      "8 Train Loss 767.4281 Test MSE 74.7537148008456 Test RE 0.09633203659957833\n",
      "9 Train Loss 496.72314 Test MSE 3.278207065723756 Test RE 0.020173095447406524\n",
      "10 Train Loss 322.84152 Test MSE 4.717258955145844 Test RE 0.02419909982843768\n",
      "11 Train Loss 273.9321 Test MSE 1.3250997192575633 Test RE 0.012825627823744941\n",
      "12 Train Loss 203.13007 Test MSE 1.5670238493361122 Test RE 0.013947364647535317\n",
      "13 Train Loss 149.61308 Test MSE 0.7721193685752502 Test RE 0.009790312981722352\n",
      "14 Train Loss 120.34058 Test MSE 0.7283514504987317 Test RE 0.009508781042643901\n",
      "15 Train Loss 100.168564 Test MSE 5.813760055304554 Test RE 0.0268647562320861\n",
      "16 Train Loss 83.01 Test MSE 0.39717346879208176 Test RE 0.007021735519270936\n",
      "17 Train Loss 72.95707 Test MSE 0.5379619369309712 Test RE 0.008172033280938785\n",
      "18 Train Loss 61.55116 Test MSE 0.32843625238035185 Test RE 0.006385279266827522\n",
      "19 Train Loss 57.217564 Test MSE 0.17265187498223644 Test RE 0.004629563036934322\n",
      "20 Train Loss 53.98955 Test MSE 0.2447644411365887 Test RE 0.0055122450315357755\n",
      "21 Train Loss 47.754795 Test MSE 0.15023027775347325 Test RE 0.004318501625915597\n",
      "22 Train Loss 43.217632 Test MSE 0.11515782861447306 Test RE 0.0037809513216734646\n",
      "23 Train Loss 37.919304 Test MSE 0.17833689333088873 Test RE 0.004705166007340352\n",
      "24 Train Loss 33.37298 Test MSE 0.36105018947875744 Test RE 0.006694808224334105\n",
      "25 Train Loss 30.744755 Test MSE 0.2271045495908611 Test RE 0.005309666814265174\n",
      "26 Train Loss 27.037338 Test MSE 0.08969353353109638 Test RE 0.003336836436819499\n",
      "27 Train Loss 23.96649 Test MSE 0.08174388212296617 Test RE 0.00318553207171292\n",
      "28 Train Loss 20.069807 Test MSE 0.057045468433555575 Test RE 0.002661122872146208\n",
      "29 Train Loss 18.892351 Test MSE 0.047186200164052394 Test RE 0.0024202590635511454\n",
      "30 Train Loss 17.066366 Test MSE 0.06581072989557918 Test RE 0.002858266413587706\n",
      "31 Train Loss 14.727901 Test MSE 0.028991438330798928 Test RE 0.0018970956729296934\n",
      "32 Train Loss 13.678015 Test MSE 0.05582002271763933 Test RE 0.0026323846932144886\n",
      "33 Train Loss 12.620929 Test MSE 0.029620417589037537 Test RE 0.0019175643226408516\n",
      "34 Train Loss 11.903609 Test MSE 0.046482670556318356 Test RE 0.002402148700601621\n",
      "35 Train Loss 10.481395 Test MSE 0.029852289927364557 Test RE 0.0019250551582485223\n",
      "36 Train Loss 10.048959 Test MSE 0.052846075778990746 Test RE 0.0025613016185608837\n",
      "37 Train Loss 9.077838 Test MSE 0.016625575315232833 Test RE 0.00143662259832849\n",
      "38 Train Loss 8.793985 Test MSE 0.01451150724685237 Test RE 0.001342179538978715\n",
      "39 Train Loss 8.435762 Test MSE 0.029340232915604086 Test RE 0.0019084734866593863\n",
      "40 Train Loss 7.8740387 Test MSE 0.025818283357767795 Test RE 0.0017902679374688165\n",
      "41 Train Loss 7.299148 Test MSE 0.01428836920338477 Test RE 0.0013318204653038467\n",
      "42 Train Loss 6.929373 Test MSE 0.008855724374409315 Test RE 0.0010484950823981913\n",
      "43 Train Loss 6.6768436 Test MSE 0.01718053845621326 Test RE 0.0014604030719934664\n",
      "44 Train Loss 5.8568444 Test MSE 0.015512359345993798 Test RE 0.0013876926265513044\n",
      "45 Train Loss 5.6102033 Test MSE 0.013559765172172979 Test RE 0.0012974195465363975\n",
      "46 Train Loss 5.2788544 Test MSE 0.025766926797372365 Test RE 0.0017884864911691526\n",
      "47 Train Loss 4.6305885 Test MSE 0.019916017128587874 Test RE 0.0015723730730683757\n",
      "48 Train Loss 3.9788325 Test MSE 0.017293560397773324 Test RE 0.0014651988187340498\n",
      "49 Train Loss 3.7639601 Test MSE 0.00801258631647635 Test RE 0.0009973342022985615\n",
      "50 Train Loss 3.155652 Test MSE 0.020134521555203434 Test RE 0.0015809750253520862\n",
      "51 Train Loss 2.8539548 Test MSE 0.011511845652341363 Test RE 0.0011954373793575251\n",
      "52 Train Loss 2.477598 Test MSE 0.019244293405472228 Test RE 0.0015456292831474057\n",
      "53 Train Loss 2.2175686 Test MSE 0.0034430858532321054 Test RE 0.000653774953260296\n",
      "54 Train Loss 2.0007753 Test MSE 0.005528041106564816 Test RE 0.0008283997978590654\n",
      "55 Train Loss 1.8602335 Test MSE 0.010980058593229173 Test RE 0.0011674994406823348\n",
      "56 Train Loss 1.6660621 Test MSE 0.003041144719217364 Test RE 0.0006144306844430081\n",
      "57 Train Loss 1.4904821 Test MSE 0.0017379617760692647 Test RE 0.00046448796160523747\n",
      "58 Train Loss 1.3254465 Test MSE 0.001450726015954889 Test RE 0.0004243723229808205\n",
      "59 Train Loss 1.1513801 Test MSE 0.015989434741918745 Test RE 0.0014088699554513726\n",
      "60 Train Loss 0.9044587 Test MSE 0.0021460768328284657 Test RE 0.0005161512524567165\n",
      "61 Train Loss 0.8223551 Test MSE 0.0007082759118366764 Test RE 0.0002965210902639478\n",
      "62 Train Loss 0.75296116 Test MSE 0.002352356503441342 Test RE 0.0005403882814135288\n",
      "63 Train Loss 0.69446665 Test MSE 0.001505057723575409 Test RE 0.0004322459479749741\n",
      "64 Train Loss 0.64701647 Test MSE 0.00045923512481012383 Test RE 0.00023876567972880617\n",
      "65 Train Loss 0.57155746 Test MSE 0.0030561370107578564 Test RE 0.0006159433383395658\n",
      "66 Train Loss 0.53170747 Test MSE 0.0006977750885563829 Test RE 0.00029431478706164\n",
      "67 Train Loss 0.49747026 Test MSE 0.0010631452646004853 Test RE 0.0003632876689712795\n",
      "68 Train Loss 0.4626374 Test MSE 0.001132188395196441 Test RE 0.000374898499243624\n",
      "69 Train Loss 0.40641975 Test MSE 0.0006236856094952603 Test RE 0.0002782513077344727\n",
      "70 Train Loss 0.38839412 Test MSE 0.0004445475574555947 Test RE 0.00023491647016023404\n",
      "71 Train Loss 0.35028896 Test MSE 0.0005462240651717763 Test RE 0.00026039927299005723\n",
      "72 Train Loss 0.31298748 Test MSE 0.002692938724306023 Test RE 0.0005781860219604133\n",
      "73 Train Loss 0.27958524 Test MSE 0.0007248672343278469 Test RE 0.0002999739811141923\n",
      "74 Train Loss 0.26829505 Test MSE 0.00047467885610284267 Test RE 0.0002427472372966859\n",
      "75 Train Loss 0.251796 Test MSE 0.00020337937661320647 Test RE 0.00015889411347347958\n",
      "76 Train Loss 0.2408042 Test MSE 0.0003277006003324462 Test RE 0.00020169399621365697\n",
      "77 Train Loss 0.21200281 Test MSE 0.0007971389965331252 Test RE 0.00031457295366867327\n",
      "78 Train Loss 0.18683785 Test MSE 0.0002892272001346996 Test RE 0.00018948459990133986\n",
      "79 Train Loss 0.18099137 Test MSE 0.00016211497789799306 Test RE 0.00014186194928187564\n",
      "80 Train Loss 0.17288232 Test MSE 0.000580090438687387 Test RE 0.0002683503746761062\n",
      "81 Train Loss 0.15952662 Test MSE 0.00028901319689547255 Test RE 0.00018941448578023296\n",
      "82 Train Loss 0.1437597 Test MSE 0.0003239341606829927 Test RE 0.00020053155751528298\n",
      "83 Train Loss 0.1379753 Test MSE 0.0004900356781687727 Test RE 0.0002466426641479623\n",
      "84 Train Loss 0.12926573 Test MSE 0.0002975408559427448 Test RE 0.000192188614689387\n",
      "85 Train Loss 0.12328741 Test MSE 0.00011286098132096099 Test RE 0.00011836580700235408\n",
      "86 Train Loss 0.11985086 Test MSE 0.00016417947935131754 Test RE 0.0001427623832550264\n",
      "87 Train Loss 0.11668081 Test MSE 0.0003343694235368094 Test RE 0.000203735932111263\n",
      "88 Train Loss 0.103050224 Test MSE 0.00017141778936229768 Test RE 0.0001458754797598697\n",
      "89 Train Loss 0.09983491 Test MSE 0.00021516727312988025 Test RE 0.00016343401891649555\n",
      "90 Train Loss 0.09615113 Test MSE 0.00014266985697221883 Test RE 0.00013308235126815966\n",
      "91 Train Loss 0.094075024 Test MSE 7.900445599256469e-05 Test RE 9.90330480076004e-05\n",
      "92 Train Loss 0.08883305 Test MSE 0.0001717110165226452 Test RE 0.00014600019369973832\n",
      "93 Train Loss 0.08693673 Test MSE 0.00011589126037611495 Test RE 0.00011994432241334848\n",
      "94 Train Loss 0.08364814 Test MSE 0.0001450005422747368 Test RE 0.0001341649785513234\n",
      "95 Train Loss 0.0794089 Test MSE 9.083503472480087e-05 Test RE 0.00010618937034159976\n",
      "96 Train Loss 0.07217538 Test MSE 6.283949112446838e-05 Test RE 8.832236346919096e-05\n",
      "97 Train Loss 0.07107971 Test MSE 6.077405218128182e-05 Test RE 8.68587248985642e-05\n",
      "98 Train Loss 0.06735332 Test MSE 0.00025265433815704083 Test RE 0.0001770996619309053\n",
      "99 Train Loss 0.06278924 Test MSE 7.853328874601886e-05 Test RE 9.873729945984515e-05\n",
      "100 Train Loss 0.061690688 Test MSE 3.864268093275775e-05 Test RE 6.926087548094274e-05\n",
      "101 Train Loss 0.061478686 Test MSE 4.612310719718334e-05 Test RE 7.56682396813212e-05\n",
      "102 Train Loss 0.061011802 Test MSE 4.9680498929881e-05 Test RE 7.85321209356357e-05\n",
      "103 Train Loss 0.06036372 Test MSE 3.027492316785847e-05 Test RE 6.130499723484172e-05\n",
      "104 Train Loss 0.05991301 Test MSE 3.1048146434167836e-05 Test RE 6.20829280168925e-05\n",
      "105 Train Loss 0.059288565 Test MSE 3.673546389486597e-05 Test RE 6.75300570457866e-05\n",
      "106 Train Loss 0.05825244 Test MSE 4.670639296911822e-05 Test RE 7.614519739257848e-05\n",
      "107 Train Loss 0.05781925 Test MSE 5.9760380166491614e-05 Test RE 8.613130515016412e-05\n",
      "108 Train Loss 0.056423083 Test MSE 3.540549580099332e-05 Test RE 6.629636128577944e-05\n",
      "109 Train Loss 0.056024704 Test MSE 3.086749609232428e-05 Test RE 6.190205307179676e-05\n",
      "110 Train Loss 0.055505242 Test MSE 3.1028115395544454e-05 Test RE 6.206289805835053e-05\n",
      "111 Train Loss 0.053836226 Test MSE 7.961135407941701e-05 Test RE 9.941269737533981e-05\n",
      "112 Train Loss 0.05238711 Test MSE 5.021833224935862e-05 Test RE 7.895606487240265e-05\n",
      "113 Train Loss 0.04969868 Test MSE 6.92176883702145e-05 Test RE 9.269640639814774e-05\n",
      "114 Train Loss 0.047502156 Test MSE 3.953644551549385e-05 Test RE 7.005726252127484e-05\n",
      "115 Train Loss 0.045583516 Test MSE 3.9950070085283e-05 Test RE 7.042277349747745e-05\n",
      "116 Train Loss 0.04395662 Test MSE 0.00013385023073819542 Test RE 0.00012890326401246015\n",
      "117 Train Loss 0.04281832 Test MSE 8.865005196761574e-05 Test RE 0.00010490443513241108\n",
      "118 Train Loss 0.041731417 Test MSE 7.190681100458868e-05 Test RE 9.44798873254455e-05\n",
      "119 Train Loss 0.04117768 Test MSE 8.373136440901448e-05 Test RE 0.00010195263069648437\n",
      "120 Train Loss 0.040865574 Test MSE 4.2221222086080735e-05 Test RE 7.239686364260955e-05\n",
      "121 Train Loss 0.040358298 Test MSE 8.55366288632432e-05 Test RE 0.0001030458289716937\n",
      "122 Train Loss 0.039747614 Test MSE 4.7285930240954476e-05 Test RE 7.661614934131544e-05\n",
      "123 Train Loss 0.039296377 Test MSE 5.464126359781493e-05 Test RE 8.235969304823191e-05\n",
      "124 Train Loss 0.038799785 Test MSE 4.106389458221616e-05 Test RE 7.139773269103197e-05\n",
      "125 Train Loss 0.03855037 Test MSE 2.3937710371713494e-05 Test RE 5.4512444355575246e-05\n",
      "126 Train Loss 0.037768733 Test MSE 5.8279178239798025e-05 Test RE 8.505719608151907e-05\n",
      "127 Train Loss 0.03661459 Test MSE 0.00010182709006890363 Test RE 0.00011243098587035639\n",
      "128 Train Loss 0.035210967 Test MSE 0.00012380371500789043 Test RE 0.00012397131010777833\n",
      "129 Train Loss 0.034155957 Test MSE 4.578307876265446e-05 Test RE 7.538880329149428e-05\n",
      "130 Train Loss 0.032905307 Test MSE 3.877974240417245e-05 Test RE 6.938359722938999e-05\n",
      "131 Train Loss 0.031809762 Test MSE 3.4701757298499014e-05 Test RE 6.563418341703464e-05\n",
      "132 Train Loss 0.031189552 Test MSE 8.514399106472715e-05 Test RE 0.00010280905190172917\n",
      "133 Train Loss 0.030692693 Test MSE 0.00011849496297562006 Test RE 0.00012128421933666549\n",
      "134 Train Loss 0.03022976 Test MSE 3.659951848387044e-05 Test RE 6.740498838569308e-05\n",
      "135 Train Loss 0.030092446 Test MSE 4.2968995228667895e-05 Test RE 7.303515437241853e-05\n",
      "136 Train Loss 0.029833546 Test MSE 5.868067284069527e-05 Test RE 8.534967953391349e-05\n",
      "137 Train Loss 0.029454147 Test MSE 5.143239872654661e-05 Test RE 7.990477669642348e-05\n",
      "138 Train Loss 0.029360494 Test MSE 5.014047638067208e-05 Test RE 7.889483646075116e-05\n",
      "139 Train Loss 0.028881475 Test MSE 7.112942293923e-05 Test RE 9.396778612536792e-05\n",
      "140 Train Loss 0.028674215 Test MSE 4.3123440050484326e-05 Test RE 7.316629292466678e-05\n",
      "141 Train Loss 0.028436746 Test MSE 7.404422071345048e-05 Test RE 9.587379879401163e-05\n",
      "142 Train Loss 0.027528087 Test MSE 0.00016356499930914194 Test RE 0.00014249497202896847\n",
      "143 Train Loss 0.025387803 Test MSE 0.0001266490363055752 Test RE 0.00012538780421649187\n",
      "144 Train Loss 0.023509867 Test MSE 0.0001652495045377047 Test RE 0.00014322684828830466\n",
      "145 Train Loss 0.021776551 Test MSE 4.616362609128142e-05 Test RE 7.570146944951733e-05\n",
      "146 Train Loss 0.02049317 Test MSE 0.00011226691311599715 Test RE 0.00011805387395573135\n",
      "147 Train Loss 0.020005465 Test MSE 2.2299270420113844e-05 Test RE 5.261380119376056e-05\n",
      "148 Train Loss 0.019708727 Test MSE 4.8556336990748715e-05 Test RE 7.763853122775896e-05\n",
      "149 Train Loss 0.018147819 Test MSE 8.037735243535555e-05 Test RE 9.988981314691092e-05\n",
      "150 Train Loss 0.016911292 Test MSE 2.4728805713596496e-05 Test RE 5.5405888484498114e-05\n",
      "151 Train Loss 0.016446603 Test MSE 2.946616973517565e-05 Test RE 6.048061455343236e-05\n",
      "152 Train Loss 0.016166275 Test MSE 2.8341900993021953e-05 Test RE 5.9315588093526145e-05\n",
      "153 Train Loss 0.016031401 Test MSE 2.7374122890487306e-05 Test RE 5.829408080742359e-05\n",
      "154 Train Loss 0.01576062 Test MSE 1.9823243954868998e-05 Test RE 4.9606857385288586e-05\n",
      "155 Train Loss 0.015551398 Test MSE 3.8245103782043984e-05 Test RE 6.890365730467918e-05\n",
      "156 Train Loss 0.014966822 Test MSE 1.5702078448156286e-05 Test RE 4.415022525952775e-05\n",
      "157 Train Loss 0.014720131 Test MSE 2.927515483162292e-05 Test RE 6.028426256013033e-05\n",
      "158 Train Loss 0.014522591 Test MSE 2.1232107606734073e-05 Test RE 5.1339413812502864e-05\n",
      "159 Train Loss 0.01439719 Test MSE 2.266052442209621e-05 Test RE 5.303826764068071e-05\n",
      "160 Train Loss 0.014175406 Test MSE 1.1107946662138887e-05 Test RE 3.713395828445843e-05\n",
      "161 Train Loss 0.014006937 Test MSE 9.776691207909337e-06 Test RE 3.483776630614996e-05\n",
      "162 Train Loss 0.013747646 Test MSE 9.620514594848317e-06 Test RE 3.455839018248279e-05\n",
      "163 Train Loss 0.013517952 Test MSE 2.340408549539217e-05 Test RE 5.3901417983340605e-05\n",
      "164 Train Loss 0.013424032 Test MSE 1.7083731283593717e-05 Test RE 4.605170544398405e-05\n",
      "165 Train Loss 0.013269916 Test MSE 5.859756760570633e-05 Test RE 8.5289220800747e-05\n",
      "166 Train Loss 0.013146396 Test MSE 1.7158547165960382e-05 Test RE 4.615243387951014e-05\n",
      "167 Train Loss 0.012665802 Test MSE 3.602345342068964e-05 Test RE 6.68724176496432e-05\n",
      "168 Train Loss 0.012180773 Test MSE 2.221134735383844e-05 Test RE 5.250997412795953e-05\n",
      "169 Train Loss 0.0118622 Test MSE 1.2969949022451504e-05 Test RE 4.012577992786226e-05\n",
      "170 Train Loss 0.0117642945 Test MSE 2.2118792597130686e-05 Test RE 5.240045530098995e-05\n",
      "171 Train Loss 0.011731294 Test MSE 2.7808056252688006e-05 Test RE 5.8754301699094906e-05\n",
      "172 Train Loss 0.011682712 Test MSE 1.5389186319096183e-05 Test RE 4.3708125481764196e-05\n",
      "173 Train Loss 0.011496413 Test MSE 2.8667693819604385e-05 Test RE 5.9655533101397706e-05\n",
      "174 Train Loss 0.011389934 Test MSE 1.7183400516326977e-05 Test RE 4.618584660203213e-05\n",
      "175 Train Loss 0.011291325 Test MSE 2.968292116001619e-05 Test RE 6.070265291170148e-05\n",
      "176 Train Loss 0.011168662 Test MSE 9.04062788961438e-06 Test RE 3.35006820782802e-05\n",
      "177 Train Loss 0.011065555 Test MSE 2.4789596224621685e-05 Test RE 5.54739484806539e-05\n",
      "178 Train Loss 0.011011295 Test MSE 1.1042135326123016e-05 Test RE 3.702379094227937e-05\n",
      "179 Train Loss 0.011008726 Test MSE 1.2164331694261378e-05 Test RE 3.8859613725640426e-05\n",
      "180 Train Loss 0.011004857 Test MSE 1.3434470133924287e-05 Test RE 4.083801491786914e-05\n",
      "181 Train Loss 0.010965057 Test MSE 1.604610083673549e-05 Test RE 4.463125621358518e-05\n",
      "182 Train Loss 0.010719261 Test MSE 1.3200546273055144e-05 Test RE 4.048091349475821e-05\n",
      "183 Train Loss 0.0106069725 Test MSE 1.5015355470323217e-05 Test RE 4.317398749266495e-05\n",
      "184 Train Loss 0.01055263 Test MSE 1.776358991387483e-05 Test RE 4.695909533415542e-05\n",
      "185 Train Loss 0.01048858 Test MSE 1.463177033483028e-05 Test RE 4.261895435386022e-05\n",
      "186 Train Loss 0.010445079 Test MSE 1.3017480568543512e-05 Test RE 4.019923804872053e-05\n",
      "187 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "188 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "189 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "190 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "191 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "192 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "193 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "194 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "195 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "196 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "197 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "198 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "199 Train Loss 0.010437246 Test MSE 1.3362464376762612e-05 Test RE 4.072842656220602e-05\n",
      "Training time: 38.56\n",
      "Training time: 38.56\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 12242.148 Test MSE 2356.3082140684733 Test RE 0.5408419885849896\n",
      "1 Train Loss 5422.624 Test MSE 533.7352829970617 Test RE 0.2574051957397067\n",
      "2 Train Loss 4153.092 Test MSE 84.16300970648517 Test RE 0.10221508195237053\n",
      "3 Train Loss 3764.0488 Test MSE 128.634844778479 Test RE 0.12636699722057326\n",
      "4 Train Loss 3469.1582 Test MSE 104.32208015795665 Test RE 0.11380005486814662\n",
      "5 Train Loss 3167.4944 Test MSE 127.96725863451492 Test RE 0.12603866240976003\n",
      "6 Train Loss 2312.231 Test MSE 354.33677433002214 Test RE 0.20973092197081683\n",
      "7 Train Loss 2017.6063 Test MSE 166.50082892764235 Test RE 0.14376810631820702\n",
      "8 Train Loss 1814.7277 Test MSE 87.27013267083511 Test RE 0.1040847660640216\n",
      "9 Train Loss 1685.4528 Test MSE 51.42730230665448 Test RE 0.0799008177290017\n",
      "10 Train Loss 1535.7748 Test MSE 18.32197307601347 Test RE 0.04769144405153233\n",
      "11 Train Loss 1390.0753 Test MSE 14.494263984508358 Test RE 0.04241821956696717\n",
      "12 Train Loss 1248.657 Test MSE 25.318321976480675 Test RE 0.056062416251713695\n",
      "13 Train Loss 1116.8367 Test MSE 30.418431632254784 Test RE 0.06145012369540683\n",
      "14 Train Loss 1017.028 Test MSE 14.321425948105325 Test RE 0.042164551312699666\n",
      "15 Train Loss 964.2543 Test MSE 22.51135358365989 Test RE 0.05286340791047027\n",
      "16 Train Loss 808.54266 Test MSE 30.518221498028883 Test RE 0.0615508369521387\n",
      "17 Train Loss 671.8641 Test MSE 34.472279788847096 Test RE 0.06541680895564983\n",
      "18 Train Loss 615.4983 Test MSE 10.094397893969086 Test RE 0.035399290861069785\n",
      "19 Train Loss 562.2177 Test MSE 6.409943700422378 Test RE 0.028208595280108092\n",
      "20 Train Loss 525.08655 Test MSE 5.850661357310185 Test RE 0.026949879833000234\n",
      "21 Train Loss 497.258 Test MSE 3.6930447263757413 Test RE 0.021411477461380765\n",
      "22 Train Loss 450.32022 Test MSE 5.216689084401794 Test RE 0.02544789294399565\n",
      "23 Train Loss 413.43497 Test MSE 2.458215218799309 Test RE 0.017468849525286986\n",
      "24 Train Loss 381.61362 Test MSE 7.855593231806954 Test RE 0.031227976652362193\n",
      "25 Train Loss 323.17923 Test MSE 2.4868749806005472 Test RE 0.017570387067246288\n",
      "26 Train Loss 283.23547 Test MSE 1.7058597794915236 Test RE 0.014552111615943173\n",
      "27 Train Loss 261.14465 Test MSE 2.063767126165396 Test RE 0.016006069469592005\n",
      "28 Train Loss 217.64812 Test MSE 1.17273246721818 Test RE 0.012065736224824673\n",
      "29 Train Loss 203.40408 Test MSE 2.5982175867985458 Test RE 0.017959411911035165\n",
      "30 Train Loss 170.4165 Test MSE 0.8694377210050348 Test RE 0.010388996298321958\n",
      "31 Train Loss 135.65273 Test MSE 0.798968658680252 Test RE 0.009959080070507734\n",
      "32 Train Loss 123.117256 Test MSE 0.6492405777476727 Test RE 0.008977536512609107\n",
      "33 Train Loss 119.77192 Test MSE 0.468857021605486 Test RE 0.00762912208144133\n",
      "34 Train Loss 108.76724 Test MSE 0.334250541658833 Test RE 0.006441550445358063\n",
      "35 Train Loss 104.338036 Test MSE 0.3872692381454308 Test RE 0.006933633038036936\n",
      "36 Train Loss 97.760254 Test MSE 0.5527982170207469 Test RE 0.008283953819189793\n",
      "37 Train Loss 87.409065 Test MSE 0.23849039809872796 Test RE 0.005441138762273385\n",
      "38 Train Loss 75.35067 Test MSE 0.7487451470688741 Test RE 0.009640984011455645\n",
      "39 Train Loss 71.99514 Test MSE 0.5317011067970803 Test RE 0.008124340830235112\n",
      "40 Train Loss 66.302216 Test MSE 1.5450914045011113 Test RE 0.013849415364737369\n",
      "41 Train Loss 63.486385 Test MSE 1.0826935719682347 Test RE 0.011593301528767688\n",
      "42 Train Loss 61.11218 Test MSE 0.46549901720153086 Test RE 0.00760175269140577\n",
      "43 Train Loss 55.578304 Test MSE 1.3002490510860027 Test RE 0.012704793925707671\n",
      "44 Train Loss 51.47083 Test MSE 0.32588572306824654 Test RE 0.006360437942486209\n",
      "45 Train Loss 48.69947 Test MSE 0.15399460727685213 Test RE 0.004372271365428457\n",
      "46 Train Loss 47.23121 Test MSE 0.20074387931247156 Test RE 0.004992010712027809\n",
      "47 Train Loss 43.67646 Test MSE 0.3345466356960497 Test RE 0.006444402920122852\n",
      "48 Train Loss 41.304207 Test MSE 0.18311514726155173 Test RE 0.004767783075231088\n",
      "49 Train Loss 36.445038 Test MSE 0.13915557477720758 Test RE 0.004156278657341844\n",
      "50 Train Loss 33.831448 Test MSE 0.14077011747942053 Test RE 0.004180320586658444\n",
      "51 Train Loss 31.865852 Test MSE 0.12256913405272121 Test RE 0.003900721205312801\n",
      "52 Train Loss 28.548733 Test MSE 0.10938623882559234 Test RE 0.0036849847692668296\n",
      "53 Train Loss 27.623526 Test MSE 0.0863674407609034 Test RE 0.003274382252633929\n",
      "54 Train Loss 26.950844 Test MSE 0.0761286986494719 Test RE 0.0030741747798426035\n",
      "55 Train Loss 26.180437 Test MSE 0.07822995123482913 Test RE 0.0031163116418701712\n",
      "56 Train Loss 24.029716 Test MSE 0.08475599218693278 Test RE 0.003243691617431215\n",
      "57 Train Loss 22.726555 Test MSE 0.06645002051184588 Test RE 0.002872115574501877\n",
      "58 Train Loss 20.688324 Test MSE 0.2697173155039939 Test RE 0.005786404190398256\n",
      "59 Train Loss 18.975569 Test MSE 0.07561891339456411 Test RE 0.0030638645984976073\n",
      "60 Train Loss 18.10396 Test MSE 0.08072474352859339 Test RE 0.0031656120418227184\n",
      "61 Train Loss 17.133627 Test MSE 0.061832033583315765 Test RE 0.002770518901580322\n",
      "62 Train Loss 14.824616 Test MSE 0.053184487262687506 Test RE 0.002569489460790983\n",
      "63 Train Loss 13.429928 Test MSE 0.10130583011789965 Test RE 0.0035462681548174774\n",
      "64 Train Loss 11.9754095 Test MSE 0.025821107883129087 Test RE 0.0017903658626257793\n",
      "65 Train Loss 11.168112 Test MSE 0.03424060802873344 Test RE 0.0020616981744938164\n",
      "66 Train Loss 10.546411 Test MSE 0.03739936101920462 Test RE 0.002154698173159195\n",
      "67 Train Loss 10.082543 Test MSE 0.02485789883951262 Test RE 0.001756655341085969\n",
      "68 Train Loss 9.889294 Test MSE 0.014015687695334515 Test RE 0.001319050911093834\n",
      "69 Train Loss 9.592705 Test MSE 0.025499452056975236 Test RE 0.0017791795432072872\n",
      "70 Train Loss 8.885856 Test MSE 0.02456810132208076 Test RE 0.0017463856318327316\n",
      "71 Train Loss 7.856566 Test MSE 0.07248459124458904 Test RE 0.002999695692325763\n",
      "72 Train Loss 6.9530697 Test MSE 0.030803063784911346 Test RE 0.001955470685994331\n",
      "73 Train Loss 6.440129 Test MSE 0.025129168342005494 Test RE 0.0017662143550447526\n",
      "74 Train Loss 5.178297 Test MSE 0.030115137802132215 Test RE 0.0019335115901755\n",
      "75 Train Loss 4.6855073 Test MSE 0.009927412966216662 Test RE 0.0011101263123916775\n",
      "76 Train Loss 4.4171534 Test MSE 0.010291325937229798 Test RE 0.0011302903475833008\n",
      "77 Train Loss 4.1273265 Test MSE 0.016179878653341632 Test RE 0.0014172353697421776\n",
      "78 Train Loss 3.38253 Test MSE 0.06317210338102675 Test RE 0.002800380346601777\n",
      "79 Train Loss 2.6576176 Test MSE 0.015339052500818426 Test RE 0.0013799190789465128\n",
      "80 Train Loss 2.0011752 Test MSE 0.004246495667055988 Test RE 0.0007260552916316128\n",
      "81 Train Loss 1.7734135 Test MSE 0.0030956446159461537 Test RE 0.0006199117968418382\n",
      "82 Train Loss 1.6965098 Test MSE 0.0022606857431374744 Test RE 0.0005297542506365345\n",
      "83 Train Loss 1.5107536 Test MSE 0.008968433366113353 Test RE 0.001055146214617376\n",
      "84 Train Loss 1.3073543 Test MSE 0.002671472285881951 Test RE 0.0005758769408089815\n",
      "85 Train Loss 1.2394801 Test MSE 0.002196431712034638 Test RE 0.0005221715488357057\n",
      "86 Train Loss 1.1520522 Test MSE 0.0017692087124695267 Test RE 0.00046864489119289156\n",
      "87 Train Loss 1.1185902 Test MSE 0.0021036687041794235 Test RE 0.0005110260337094812\n",
      "88 Train Loss 1.0021658 Test MSE 0.003344612013340968 Test RE 0.0006443580002556419\n",
      "89 Train Loss 0.9306466 Test MSE 0.0017728640489026708 Test RE 0.00046912877158993585\n",
      "90 Train Loss 0.9096417 Test MSE 0.0009494529460296816 Test RE 0.00034331365349284164\n",
      "91 Train Loss 0.8839682 Test MSE 0.0011887904456585865 Test RE 0.00038415545571247585\n",
      "92 Train Loss 0.809647 Test MSE 0.0013400710995578144 Test RE 0.0004078667223858687\n",
      "93 Train Loss 0.76634586 Test MSE 0.0008152206027735608 Test RE 0.0003181206973543271\n",
      "94 Train Loss 0.7419054 Test MSE 0.000815181986960448 Test RE 0.00031811316280795236\n",
      "95 Train Loss 0.7001759 Test MSE 0.0011722412001507253 Test RE 0.0003814721551826176\n",
      "96 Train Loss 0.64952797 Test MSE 0.0009569335424058717 Test RE 0.0003446634581968518\n",
      "97 Train Loss 0.6287099 Test MSE 0.0012590860811857922 Test RE 0.0003953502919403143\n",
      "98 Train Loss 0.6206036 Test MSE 0.0009098276246815736 Test RE 0.00033607322367886465\n",
      "99 Train Loss 0.6079844 Test MSE 0.0010473488240033838 Test RE 0.0003605786654820933\n",
      "100 Train Loss 0.5753046 Test MSE 0.0014845403112871472 Test RE 0.00042928958266735546\n",
      "101 Train Loss 0.48765385 Test MSE 0.0014790383061539752 Test RE 0.0004284933274215121\n",
      "102 Train Loss 0.448802 Test MSE 0.000768579454099655 Test RE 0.00030888636481630214\n",
      "103 Train Loss 0.4372243 Test MSE 0.0008955646890623639 Test RE 0.00033342858789427057\n",
      "104 Train Loss 0.42608848 Test MSE 0.0016412878900796644 Test RE 0.00045138459674014594\n",
      "105 Train Loss 0.40586397 Test MSE 0.0004970264464207535 Test RE 0.0002483957159079137\n",
      "106 Train Loss 0.39763847 Test MSE 0.001015444637013356 Test RE 0.00035504424501470747\n",
      "107 Train Loss 0.37219757 Test MSE 0.0005073958581095331 Test RE 0.00025097346761893065\n",
      "108 Train Loss 0.35439187 Test MSE 0.0003258669708687254 Test RE 0.0002011289211884879\n",
      "109 Train Loss 0.3390212 Test MSE 0.00047238073244088453 Test RE 0.00024215890266177824\n",
      "110 Train Loss 0.3378793 Test MSE 0.00033209161611244114 Test RE 0.00020304079638469182\n",
      "111 Train Loss 0.32460153 Test MSE 0.0003971679555155538 Test RE 0.0002220452325298338\n",
      "112 Train Loss 0.29407522 Test MSE 0.0003569209010233355 Test RE 0.00021049430129015738\n",
      "113 Train Loss 0.2832296 Test MSE 0.00027296488878040387 Test RE 0.000184080483437465\n",
      "114 Train Loss 0.2807945 Test MSE 0.0004034561224728132 Test RE 0.00022379609665429965\n",
      "115 Train Loss 0.27596205 Test MSE 0.0002490962258110029 Test RE 0.00017584819952887453\n",
      "116 Train Loss 0.27286237 Test MSE 0.00026847020155847654 Test RE 0.000182558642117683\n",
      "117 Train Loss 0.2715198 Test MSE 0.00023813323328981194 Test RE 0.00017193502523024269\n",
      "118 Train Loss 0.27052188 Test MSE 0.00027155171747117663 Test RE 0.00018360336195929943\n",
      "119 Train Loss 0.26898903 Test MSE 0.0002767154628596447 Test RE 0.00018534081416024927\n",
      "120 Train Loss 0.26589894 Test MSE 0.00024977838670477224 Test RE 0.0001760888188921742\n",
      "121 Train Loss 0.26173034 Test MSE 0.0002803759198634111 Test RE 0.0001865626526104889\n",
      "122 Train Loss 0.25977588 Test MSE 0.0003503377826839038 Test RE 0.00020854406795344012\n",
      "123 Train Loss 0.25770417 Test MSE 0.00025944570404991377 Test RE 0.00017946410371895045\n",
      "124 Train Loss 0.253707 Test MSE 0.0002446142049225313 Test RE 0.0001742589885614805\n",
      "125 Train Loss 0.2498017 Test MSE 0.0002279872589443984 Test RE 0.0001682324001241714\n",
      "126 Train Loss 0.24731243 Test MSE 0.0002658235780547084 Test RE 0.00018165656681535554\n",
      "127 Train Loss 0.24411212 Test MSE 0.0002261274979423348 Test RE 0.00016754483380534207\n",
      "128 Train Loss 0.24291024 Test MSE 0.0002597375856139705 Test RE 0.00017956502568061385\n",
      "129 Train Loss 0.24176124 Test MSE 0.0002409719345221757 Test RE 0.0001729567772830983\n",
      "130 Train Loss 0.24053879 Test MSE 0.0002709215483535344 Test RE 0.000183390201143429\n",
      "131 Train Loss 0.23973435 Test MSE 0.00024404621736666665 Test RE 0.00017405655865910575\n",
      "132 Train Loss 0.23817787 Test MSE 0.0002441703522200003 Test RE 0.00017410082023128123\n",
      "133 Train Loss 0.23406826 Test MSE 0.0002719211888687329 Test RE 0.0001837282242372684\n",
      "134 Train Loss 0.22864962 Test MSE 0.00035058933504252774 Test RE 0.00020861892476485038\n",
      "135 Train Loss 0.22281183 Test MSE 0.0002547270974002805 Test RE 0.00017782463493429566\n",
      "136 Train Loss 0.2153192 Test MSE 0.0002993985688212883 Test RE 0.00019278765126591761\n",
      "137 Train Loss 0.20799844 Test MSE 0.0004955667935926866 Test RE 0.0002480307070630267\n",
      "138 Train Loss 0.20076911 Test MSE 0.0003699956077753831 Test RE 0.0002143150335932641\n",
      "139 Train Loss 0.19494395 Test MSE 0.00021907920376084783 Test RE 0.00016491301407862895\n",
      "140 Train Loss 0.19185555 Test MSE 0.00019791249941773038 Test RE 0.00015674401394078015\n",
      "141 Train Loss 0.18980849 Test MSE 0.00017767784782095152 Test RE 0.00014851523093280285\n",
      "142 Train Loss 0.18662791 Test MSE 0.00019537863054657192 Test RE 0.00015573738672453545\n",
      "143 Train Loss 0.1828155 Test MSE 0.00018882520755125336 Test RE 0.00015310322459363866\n",
      "144 Train Loss 0.177778 Test MSE 0.00022776781503563312 Test RE 0.0001681514165125114\n",
      "145 Train Loss 0.16965012 Test MSE 0.0001972282957581886 Test RE 0.0001564728393613516\n",
      "146 Train Loss 0.1674108 Test MSE 0.0002068833088426055 Test RE 0.00016025702606238927\n",
      "147 Train Loss 0.16347808 Test MSE 0.00026543193182312967 Test RE 0.00018152269732424543\n",
      "148 Train Loss 0.15854889 Test MSE 0.00015153192360803738 Test RE 0.00013715335023141732\n",
      "149 Train Loss 0.15144846 Test MSE 0.0001712869803925675 Test RE 0.00014581981032493855\n",
      "150 Train Loss 0.14326726 Test MSE 0.0002706274067240048 Test RE 0.00018329062002412407\n",
      "151 Train Loss 0.13855895 Test MSE 0.00016457610409947962 Test RE 0.00014293472190008585\n",
      "152 Train Loss 0.13488215 Test MSE 0.00014793435787572532 Test RE 0.00013551547067430314\n",
      "153 Train Loss 0.13263048 Test MSE 0.00013477382445859954 Test RE 0.00012934722879101462\n",
      "154 Train Loss 0.13069536 Test MSE 0.00011684245616154172 Test RE 0.00012043554748678653\n",
      "155 Train Loss 0.12965722 Test MSE 0.00013491866500014426 Test RE 0.0001294167144345467\n",
      "156 Train Loss 0.12815511 Test MSE 0.00014934797660683775 Test RE 0.00013616140493713963\n",
      "157 Train Loss 0.12607107 Test MSE 0.00012079152889911251 Test RE 0.00012245389156992988\n",
      "158 Train Loss 0.124544136 Test MSE 0.00010908158772776532 Test RE 0.00011636706418422642\n",
      "159 Train Loss 0.1234339 Test MSE 0.00011143960802962613 Test RE 0.00011761809478377477\n",
      "160 Train Loss 0.121460944 Test MSE 0.00011947530784701401 Test RE 0.00012178489652490619\n",
      "161 Train Loss 0.11927151 Test MSE 0.00012113058285834277 Test RE 0.0001226256311904187\n",
      "162 Train Loss 0.114526264 Test MSE 0.00011951615472434823 Test RE 0.00012180571299197226\n",
      "163 Train Loss 0.11280106 Test MSE 0.00017893890481236773 Test RE 0.00014904133768671855\n",
      "164 Train Loss 0.11050486 Test MSE 0.00010151509531655254 Test RE 0.0001122586113668287\n",
      "165 Train Loss 0.10893306 Test MSE 9.876013968690971e-05 Test RE 0.00011072487536780178\n",
      "166 Train Loss 0.10697079 Test MSE 0.00015396672471493374 Test RE 0.00013825084294827571\n",
      "167 Train Loss 0.10536918 Test MSE 0.00011396639258663997 Test RE 0.00011894405854197031\n",
      "168 Train Loss 0.10488685 Test MSE 0.00010592302683767846 Test RE 0.0001146699290107324\n",
      "169 Train Loss 0.10460132 Test MSE 0.0001136229037267291 Test RE 0.00011876467763390698\n",
      "170 Train Loss 0.10393621 Test MSE 9.065508796153253e-05 Test RE 0.00010608413613039417\n",
      "171 Train Loss 0.10348804 Test MSE 0.00010647886557879623 Test RE 0.00011497040470585187\n",
      "172 Train Loss 0.10143226 Test MSE 0.0003236341517737713 Test RE 0.00020043867569383177\n",
      "173 Train Loss 0.099554054 Test MSE 9.049521948497256e-05 Test RE 0.00010599055620480665\n",
      "174 Train Loss 0.098685846 Test MSE 9.467349377639917e-05 Test RE 0.00010840980282589921\n",
      "175 Train Loss 0.09838834 Test MSE 7.888745855040519e-05 Test RE 9.895969197986608e-05\n",
      "176 Train Loss 0.09833151 Test MSE 7.494283818896393e-05 Test RE 9.645381738780624e-05\n",
      "177 Train Loss 0.098223746 Test MSE 7.752865801088613e-05 Test RE 9.810372223875591e-05\n",
      "178 Train Loss 0.09807007 Test MSE 8.180927096047972e-05 Test RE 0.00010077565129260398\n",
      "179 Train Loss 0.09760032 Test MSE 7.948261340659708e-05 Test RE 9.933228399696209e-05\n",
      "180 Train Loss 0.09643694 Test MSE 0.00013701158190312568 Test RE 0.00013041663568307837\n",
      "181 Train Loss 0.094085604 Test MSE 0.0001123673018429391 Test RE 0.00011810664386641958\n",
      "182 Train Loss 0.0906298 Test MSE 0.0002744846276212374 Test RE 0.00018459220851180594\n",
      "183 Train Loss 0.08388372 Test MSE 0.00019064558388251078 Test RE 0.0001538394530632454\n",
      "184 Train Loss 0.077841565 Test MSE 0.0003303342600321191 Test RE 0.00020250286007352186\n",
      "185 Train Loss 0.06958161 Test MSE 0.0001679563797201843 Test RE 0.0001443951495252297\n",
      "186 Train Loss 0.06530877 Test MSE 0.00013322319121116224 Test RE 0.0001286009771751281\n",
      "187 Train Loss 0.063440114 Test MSE 5.4567551573689644e-05 Test RE 8.230412196421225e-05\n",
      "188 Train Loss 0.061987888 Test MSE 0.00014352102964306003 Test RE 0.00013347874758055527\n",
      "189 Train Loss 0.06077386 Test MSE 6.200741283183665e-05 Test RE 8.773566214322851e-05\n",
      "190 Train Loss 0.059874162 Test MSE 6.823640640272937e-05 Test RE 9.203699401521869e-05\n",
      "191 Train Loss 0.059584107 Test MSE 6.188318205744863e-05 Test RE 8.764772964087608e-05\n",
      "192 Train Loss 0.059503306 Test MSE 5.7653678261967375e-05 Test RE 8.459951288798066e-05\n",
      "193 Train Loss 0.05933604 Test MSE 7.642100002184351e-05 Test RE 9.740039330358707e-05\n",
      "194 Train Loss 0.059213188 Test MSE 6.93397503695265e-05 Test RE 9.277810318057584e-05\n",
      "195 Train Loss 0.058982592 Test MSE 7.24966897810273e-05 Test RE 9.48666229417421e-05\n",
      "196 Train Loss 0.058849085 Test MSE 7.534366818043759e-05 Test RE 9.671141388654703e-05\n",
      "197 Train Loss 0.05814902 Test MSE 5.1809780530076354e-05 Test RE 8.019738891297976e-05\n",
      "198 Train Loss 0.05617436 Test MSE 0.00022712880383631958 Test RE 0.00016791537326727842\n",
      "199 Train Loss 0.052221254 Test MSE 0.00014902525943187087 Test RE 0.00013601421383240342\n",
      "Training time: 76.57\n",
      "Training time: 76.57\n"
     ]
    }
   ],
   "source": [
    " \n",
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  beta_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers)\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "7ef8bb86-89cf-4917-9bf1-6cda3bafbc51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1D_FODE_swish_medium'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "bb023909-b810-4d9b-857a-cc29fc84d142"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_swish_tune4.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_swish_tune4.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31363/2114102953.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_swish_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_swish_tune4.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(4,5):\n",
    "    label = \"1D_FODE_swish_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(i,' ',np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "swish_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
