{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "84a34ebd-2e54-4cae-ca1c-79397867998c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "94a6280c-bfd4-43c8-a396-40f22c70c38f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "150eeb9e-6cdc-4ff0-fd50-61a1c228e3a0"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/atanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "30d0ca6b-cde8-4b85-ccae-4eac06a2c482"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dmSz5jcVVt4p"
   },
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1]).reshape(-1,1)\n",
    "n_value = np.array([1.0,3.0,5.0,8.0,10.0]).reshape(-1,1)\n",
    "\n",
    "LR_tune,N_value = np.meshgrid(lr_tune,n_value)\n",
    "\n",
    "LR_tune = LR_tune.flatten('F').reshape(-1,1)\n",
    "N_value = N_value.flatten('F').reshape(-1,1)\n",
    "\n",
    "lrn_tune = np.hstack((LR_tune,N_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"medium\"\n",
    "label = \"1D_FODE_atanh_\" + level\n",
    "\n",
    "extent = 20.0\n",
    "\n",
    "\n",
    "x = np.linspace(extent,-1.0*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "        \n",
    "              \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "       \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "      \n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,123)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(i)\n",
    "\n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "509236d6-c6b5-4579-8ffe-6c945b3ae573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D_FODE_atanh_medium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 16003.682 Test MSE 9820.224653866333 Test RE 1.1041169165444569\n",
      "1 Train Loss 14227.959 Test MSE 11368.664670273381 Test RE 1.1879798673043038\n",
      "2 Train Loss 13278.755 Test MSE 12363.89091528116 Test RE 1.238887681512215\n",
      "3 Train Loss 11831.809 Test MSE 13012.422107866103 Test RE 1.2709645104327367\n",
      "4 Train Loss 11193.525 Test MSE 13138.496167289039 Test RE 1.2771066952665233\n",
      "5 Train Loss 10660.272 Test MSE 13374.237303393335 Test RE 1.2885131784840365\n",
      "6 Train Loss 9936.217 Test MSE 14116.567491154718 Test RE 1.323789422965523\n",
      "7 Train Loss 9236.568 Test MSE 13145.001042611399 Test RE 1.2774228041926494\n",
      "8 Train Loss 8849.504 Test MSE 12973.25359023406 Test RE 1.2690502121648588\n",
      "9 Train Loss 8447.03 Test MSE 12882.615478079495 Test RE 1.2646093090038062\n",
      "10 Train Loss 8109.8584 Test MSE 12546.82336225721 Test RE 1.2480191355104686\n",
      "11 Train Loss 7938.6484 Test MSE 12044.13972089548 Test RE 1.2227628762965004\n",
      "12 Train Loss 7540.118 Test MSE 11580.910988901844 Test RE 1.1990180310999856\n",
      "13 Train Loss 7246.244 Test MSE 11312.700571892241 Test RE 1.1850522480124919\n",
      "14 Train Loss 7018.0093 Test MSE 11097.51422853021 Test RE 1.1737273041972718\n",
      "15 Train Loss 6852.4067 Test MSE 10888.327055429467 Test RE 1.1626123474771757\n",
      "16 Train Loss 6657.6475 Test MSE 10527.849536830588 Test RE 1.1432051890241646\n",
      "17 Train Loss 6411.9146 Test MSE 9868.275477441686 Test RE 1.1068148684103405\n",
      "18 Train Loss 6263.4385 Test MSE 9600.425730687317 Test RE 1.0916906694861992\n",
      "19 Train Loss 6054.118 Test MSE 9472.355160567 Test RE 1.0843845943312742\n",
      "20 Train Loss 5932.845 Test MSE 9330.487057520148 Test RE 1.076233508696129\n",
      "21 Train Loss 5769.028 Test MSE 9104.18844366292 Test RE 1.0631020890414808\n",
      "22 Train Loss 5572.0874 Test MSE 8941.699586022369 Test RE 1.0535724113527092\n",
      "23 Train Loss 5342.458 Test MSE 8595.232766428197 Test RE 1.0329592129814618\n",
      "24 Train Loss 5175.242 Test MSE 8329.540034006215 Test RE 1.0168686594046563\n",
      "25 Train Loss 4994.3696 Test MSE 8161.314655002895 Test RE 1.0065478219813848\n",
      "26 Train Loss 4891.7056 Test MSE 8049.543803316417 Test RE 0.9996316228565576\n",
      "27 Train Loss 4725.0615 Test MSE 7877.726809072635 Test RE 0.9889055409249922\n",
      "28 Train Loss 4583.9023 Test MSE 7703.614867863941 Test RE 0.9779161843456041\n",
      "29 Train Loss 4507.2095 Test MSE 7561.21046009334 Test RE 0.9688354370167853\n",
      "30 Train Loss 4437.913 Test MSE 7465.122523246527 Test RE 0.9626597690438776\n",
      "31 Train Loss 4387.6113 Test MSE 7381.817155138475 Test RE 0.9572734065254033\n",
      "32 Train Loss 4329.2915 Test MSE 7173.4817987297 Test RE 0.9436682703756549\n",
      "33 Train Loss 4270.3335 Test MSE 7090.367757102306 Test RE 0.9381855357668716\n",
      "34 Train Loss 4216.2295 Test MSE 7004.136985158702 Test RE 0.9324631286727485\n",
      "35 Train Loss 4163.418 Test MSE 6937.838002697572 Test RE 0.9280394324560797\n",
      "36 Train Loss 4107.865 Test MSE 6795.883331220411 Test RE 0.9184960851745506\n",
      "37 Train Loss 4078.3806 Test MSE 6767.96674108105 Test RE 0.9166076135459132\n",
      "38 Train Loss 4047.4731 Test MSE 6729.761571893254 Test RE 0.9140168273430437\n",
      "39 Train Loss 4018.951 Test MSE 6684.951064308059 Test RE 0.9109687278641234\n",
      "40 Train Loss 3983.604 Test MSE 6673.458634547247 Test RE 0.9101853453502409\n",
      "41 Train Loss 3961.3955 Test MSE 6660.736906286743 Test RE 0.9093173805583348\n",
      "42 Train Loss 3920.7642 Test MSE 6651.2217287243475 Test RE 0.9086676469982036\n",
      "43 Train Loss 3888.434 Test MSE 6612.724907050789 Test RE 0.9060341774296975\n",
      "44 Train Loss 3857.6643 Test MSE 6526.36437256127 Test RE 0.9000984439898115\n",
      "45 Train Loss 3814.5764 Test MSE 6575.066292455044 Test RE 0.9034506200890625\n",
      "46 Train Loss 3785.0703 Test MSE 6575.9376770594445 Test RE 0.9035104846474186\n",
      "47 Train Loss 3754.1633 Test MSE 6524.352439474156 Test RE 0.8999596931227726\n",
      "48 Train Loss 3734.331 Test MSE 6549.432448917029 Test RE 0.901687784019795\n",
      "49 Train Loss 3708.405 Test MSE 6518.88292643459 Test RE 0.8995823856901498\n",
      "50 Train Loss 3681.3354 Test MSE 6501.1546250996 Test RE 0.8983583320162031\n",
      "51 Train Loss 3659.1685 Test MSE 6505.04746356772 Test RE 0.8986272565929155\n",
      "52 Train Loss 3625.569 Test MSE 6426.230880297281 Test RE 0.8931666832404245\n",
      "53 Train Loss 3601.4783 Test MSE 6369.95535660971 Test RE 0.8892472824712823\n",
      "54 Train Loss 3568.15 Test MSE 6350.929566949422 Test RE 0.8879182869875596\n",
      "55 Train Loss 3547.0847 Test MSE 6348.178660890444 Test RE 0.8877259651921396\n",
      "56 Train Loss 3518.3962 Test MSE 6312.871714839753 Test RE 0.8852538707269519\n",
      "57 Train Loss 3494.4656 Test MSE 6318.265578524477 Test RE 0.8856319806745075\n",
      "58 Train Loss 3461.8643 Test MSE 6259.635452997337 Test RE 0.8815133080654787\n",
      "59 Train Loss 3444.6172 Test MSE 6182.317116507319 Test RE 0.8760522136896315\n",
      "60 Train Loss 3428.8774 Test MSE 6100.181626420931 Test RE 0.870213337439674\n",
      "61 Train Loss 3401.6145 Test MSE 6026.10603411617 Test RE 0.864913621652812\n",
      "62 Train Loss 3377.6636 Test MSE 5953.874149543781 Test RE 0.859714353411053\n",
      "63 Train Loss 3352.721 Test MSE 5983.313670272421 Test RE 0.8618372038924775\n",
      "64 Train Loss 3335.9363 Test MSE 5948.3586499942985 Test RE 0.8593160536926464\n",
      "65 Train Loss 3310.3447 Test MSE 5855.421647849222 Test RE 0.8525766601010938\n",
      "66 Train Loss 3301.1301 Test MSE 5853.689292487703 Test RE 0.8524505312674139\n",
      "67 Train Loss 3283.5598 Test MSE 5856.685839181939 Test RE 0.852668691206595\n",
      "68 Train Loss 3262.9854 Test MSE 5848.552418826446 Test RE 0.8520764174768384\n",
      "69 Train Loss 3241.3186 Test MSE 5841.882287880334 Test RE 0.8515903927086232\n",
      "70 Train Loss 3222.6394 Test MSE 5823.911179655304 Test RE 0.8502795300229136\n",
      "71 Train Loss 3210.3662 Test MSE 5811.331007470964 Test RE 0.8493606934156754\n",
      "72 Train Loss 3198.8374 Test MSE 5783.843481997843 Test RE 0.8473495795503708\n",
      "73 Train Loss 3189.7905 Test MSE 5771.257230386239 Test RE 0.8464271165392423\n",
      "74 Train Loss 3180.7378 Test MSE 5772.899782543634 Test RE 0.8465475583876889\n",
      "75 Train Loss 3171.725 Test MSE 5778.737319726115 Test RE 0.8469754632877499\n",
      "76 Train Loss 3165.4814 Test MSE 5781.107069235043 Test RE 0.84714910969604\n",
      "77 Train Loss 3155.4958 Test MSE 5801.93107398491 Test RE 0.8486734872346091\n",
      "78 Train Loss 3148.9038 Test MSE 5797.137069775343 Test RE 0.8483227949390315\n",
      "79 Train Loss 3139.5217 Test MSE 5774.21991804578 Test RE 0.8466443462798457\n",
      "80 Train Loss 3131.8328 Test MSE 5755.637183952652 Test RE 0.8452809027805852\n",
      "81 Train Loss 3123.2534 Test MSE 5740.5162460898055 Test RE 0.8441698315522613\n",
      "82 Train Loss 3117.3394 Test MSE 5744.777027355633 Test RE 0.8444830573737477\n",
      "83 Train Loss 3108.4517 Test MSE 5752.417220863014 Test RE 0.8450444255672428\n",
      "84 Train Loss 3101.154 Test MSE 5742.683179652642 Test RE 0.8443291453898456\n",
      "85 Train Loss 3093.2468 Test MSE 5752.752415134113 Test RE 0.8450690456454816\n",
      "86 Train Loss 3085.1394 Test MSE 5756.844150601653 Test RE 0.845369526537255\n",
      "87 Train Loss 3078.916 Test MSE 5757.292639893944 Test RE 0.8454024553248682\n",
      "88 Train Loss 3072.3167 Test MSE 5721.346956292788 Test RE 0.8427591859510681\n",
      "89 Train Loss 3063.1963 Test MSE 5684.67101751149 Test RE 0.8400536448919409\n",
      "90 Train Loss 3052.568 Test MSE 5672.221331798785 Test RE 0.8391332630262865\n",
      "91 Train Loss 3047.7178 Test MSE 5644.83944296241 Test RE 0.8371054110458124\n",
      "92 Train Loss 3044.3533 Test MSE 5654.11673805142 Test RE 0.8377930201204914\n",
      "93 Train Loss 3034.561 Test MSE 5602.880819807996 Test RE 0.8339884664312541\n",
      "94 Train Loss 3028.9937 Test MSE 5612.506097722584 Test RE 0.8347045200469073\n",
      "95 Train Loss 3023.5972 Test MSE 5609.507257641475 Test RE 0.8344814931331977\n",
      "96 Train Loss 3016.1978 Test MSE 5618.131605608732 Test RE 0.8351227343649886\n",
      "97 Train Loss 3009.2334 Test MSE 5613.425470420754 Test RE 0.8347728828343374\n",
      "98 Train Loss 3001.754 Test MSE 5604.965578432634 Test RE 0.8341436100975791\n",
      "99 Train Loss 2999.0305 Test MSE 5607.854755977356 Test RE 0.8343585693570004\n",
      "100 Train Loss 2994.31 Test MSE 5599.717793900184 Test RE 0.8337530250916039\n",
      "101 Train Loss 2990.7393 Test MSE 5597.60903624904 Test RE 0.8335960217664261\n",
      "102 Train Loss 2982.687 Test MSE 5587.604427133217 Test RE 0.8328507453393649\n",
      "103 Train Loss 2978.6348 Test MSE 5554.549524140595 Test RE 0.8303836204090944\n",
      "104 Train Loss 2971.5532 Test MSE 5520.124071081117 Test RE 0.8278063850800602\n",
      "105 Train Loss 2969.208 Test MSE 5504.962057400406 Test RE 0.8266687437906127\n",
      "106 Train Loss 2963.9897 Test MSE 5509.936195361532 Test RE 0.827042137457161\n",
      "107 Train Loss 2957.481 Test MSE 5473.031060076169 Test RE 0.8242677511985692\n",
      "108 Train Loss 2952.6042 Test MSE 5473.432806695957 Test RE 0.8242980032382975\n",
      "109 Train Loss 2948.066 Test MSE 5475.593083784131 Test RE 0.8244606558626257\n",
      "110 Train Loss 2944.858 Test MSE 5466.926182025114 Test RE 0.8238079092866314\n",
      "111 Train Loss 2940.1304 Test MSE 5450.246188726921 Test RE 0.8225501999951178\n",
      "112 Train Loss 2933.2322 Test MSE 5419.00329464349 Test RE 0.8201892255795016\n",
      "113 Train Loss 2928.0093 Test MSE 5414.209803811095 Test RE 0.8198263876974913\n",
      "114 Train Loss 2924.9172 Test MSE 5405.57384103916 Test RE 0.819172292647829\n",
      "115 Train Loss 2920.9075 Test MSE 5401.046778966905 Test RE 0.8188292004352071\n",
      "116 Train Loss 2912.4297 Test MSE 5398.00840716297 Test RE 0.8185988508706032\n",
      "117 Train Loss 2903.164 Test MSE 5394.255525208513 Test RE 0.8183142422920626\n",
      "118 Train Loss 2897.5571 Test MSE 5388.366006585464 Test RE 0.8178673972031011\n",
      "119 Train Loss 2882.9434 Test MSE 5336.220046868438 Test RE 0.8139003165172151\n",
      "120 Train Loss 2870.817 Test MSE 5331.495543611959 Test RE 0.8135399372452691\n",
      "121 Train Loss 2861.061 Test MSE 5325.4321038465105 Test RE 0.8130771915034332\n",
      "122 Train Loss 2852.3877 Test MSE 5325.902553432258 Test RE 0.8131131043996123\n",
      "123 Train Loss 2846.7344 Test MSE 5315.6762190666195 Test RE 0.8123320948194924\n",
      "124 Train Loss 2842.9849 Test MSE 5328.3645626197485 Test RE 0.813301021904001\n",
      "125 Train Loss 2837.0598 Test MSE 5331.416510462035 Test RE 0.8135339073366266\n",
      "126 Train Loss 2827.414 Test MSE 5297.078898766513 Test RE 0.8109098452187418\n",
      "127 Train Loss 2820.7712 Test MSE 5253.2758822293135 Test RE 0.8075500657031117\n",
      "128 Train Loss 2815.268 Test MSE 5235.330014547066 Test RE 0.806169538111267\n",
      "129 Train Loss 2807.1858 Test MSE 5207.311179931117 Test RE 0.8040093845020145\n",
      "130 Train Loss 2799.9185 Test MSE 5200.153371795501 Test RE 0.8034566113224347\n",
      "131 Train Loss 2792.329 Test MSE 5201.916626596552 Test RE 0.8035928167911751\n",
      "132 Train Loss 2784.441 Test MSE 5159.5362749377 Test RE 0.8003126608557656\n",
      "133 Train Loss 2777.6455 Test MSE 5152.553699541817 Test RE 0.7997709323779408\n",
      "134 Train Loss 2763.5337 Test MSE 5114.845891574179 Test RE 0.7968390864677717\n",
      "135 Train Loss 2758.2825 Test MSE 5098.077567287977 Test RE 0.7955318500848366\n",
      "136 Train Loss 2746.9048 Test MSE 5097.289614518605 Test RE 0.795470369483672\n",
      "137 Train Loss 2736.3853 Test MSE 5093.41587679774 Test RE 0.7951680490864187\n",
      "138 Train Loss 2730.2986 Test MSE 5080.751786273052 Test RE 0.7941788948854878\n",
      "139 Train Loss 2726.6938 Test MSE 5065.193808408076 Test RE 0.79296201877038\n",
      "140 Train Loss 2723.6326 Test MSE 5080.470359478006 Test RE 0.7941568994874076\n",
      "141 Train Loss 2717.3525 Test MSE 5087.5853369875695 Test RE 0.7947127960063849\n",
      "142 Train Loss 2711.3384 Test MSE 5072.033505076192 Test RE 0.7934972194157291\n",
      "143 Train Loss 2707.7913 Test MSE 5063.365027062603 Test RE 0.7928188569171386\n",
      "144 Train Loss 2702.5461 Test MSE 5025.757938491241 Test RE 0.78986912115106\n",
      "145 Train Loss 2695.6602 Test MSE 5014.679117140157 Test RE 0.7889980439018288\n",
      "146 Train Loss 2691.3125 Test MSE 4980.663949152583 Test RE 0.7863175566202547\n",
      "147 Train Loss 2688.802 Test MSE 4969.08779221786 Test RE 0.7854032376903627\n",
      "148 Train Loss 2686.4856 Test MSE 4982.823404591071 Test RE 0.7864879991285025\n",
      "149 Train Loss 2682.7153 Test MSE 4976.651920263793 Test RE 0.7860007952064028\n",
      "150 Train Loss 2678.6973 Test MSE 4946.543411931464 Test RE 0.7836195543580966\n",
      "151 Train Loss 2672.555 Test MSE 4924.13024158549 Test RE 0.781842218390888\n",
      "152 Train Loss 2668.3455 Test MSE 4923.608775050117 Test RE 0.78180081865861\n",
      "153 Train Loss 2664.7249 Test MSE 4907.324597829541 Test RE 0.7805068971049587\n",
      "154 Train Loss 2657.7407 Test MSE 4899.301031250436 Test RE 0.7798685644626686\n",
      "155 Train Loss 2653.4846 Test MSE 4890.448779599024 Test RE 0.7791636971779864\n",
      "156 Train Loss 2647.8044 Test MSE 4894.9144012686265 Test RE 0.7795193553712112\n",
      "157 Train Loss 2640.6147 Test MSE 4872.213334883958 Test RE 0.7777096725128066\n",
      "158 Train Loss 2635.1055 Test MSE 4872.246362869811 Test RE 0.7777123084955487\n",
      "159 Train Loss 2629.3245 Test MSE 4835.25714881717 Test RE 0.7747545584612691\n",
      "160 Train Loss 2625.6418 Test MSE 4806.115408454475 Test RE 0.7724163355991879\n",
      "161 Train Loss 2621.0037 Test MSE 4795.882119184254 Test RE 0.7715935742682859\n",
      "162 Train Loss 2613.5413 Test MSE 4774.839716325175 Test RE 0.769898992221852\n",
      "163 Train Loss 2606.769 Test MSE 4765.124079917938 Test RE 0.7691153148605133\n",
      "164 Train Loss 2601.457 Test MSE 4756.42955812793 Test RE 0.7684133244316439\n",
      "165 Train Loss 2596.7522 Test MSE 4718.166356287081 Test RE 0.7653163244677443\n",
      "166 Train Loss 2590.9565 Test MSE 4703.069846420466 Test RE 0.7640909689719413\n",
      "167 Train Loss 2584.481 Test MSE 4681.677410153989 Test RE 0.7623512119707033\n",
      "168 Train Loss 2579.1145 Test MSE 4674.8984802571595 Test RE 0.7617990810701665\n",
      "169 Train Loss 2575.4026 Test MSE 4665.548283834641 Test RE 0.7610368681283749\n",
      "170 Train Loss 2570.0906 Test MSE 4636.852343207156 Test RE 0.7586928400128862\n",
      "171 Train Loss 2565.3586 Test MSE 4628.463434971641 Test RE 0.7580062227312719\n",
      "172 Train Loss 2558.5278 Test MSE 4609.7644994378525 Test RE 0.7564735052011232\n",
      "173 Train Loss 2552.477 Test MSE 4599.280961439712 Test RE 0.7556128286119926\n",
      "174 Train Loss 2548.5242 Test MSE 4575.640406385854 Test RE 0.7536683811708232\n",
      "175 Train Loss 2544.0735 Test MSE 4577.19096925621 Test RE 0.7537960694416075\n",
      "176 Train Loss 2540.6235 Test MSE 4586.152253086021 Test RE 0.7545336044886319\n",
      "177 Train Loss 2537.8892 Test MSE 4561.583034216901 Test RE 0.7525097732230561\n",
      "178 Train Loss 2534.9065 Test MSE 4555.861982047647 Test RE 0.7520377333254745\n",
      "179 Train Loss 2532.0093 Test MSE 4556.525442617346 Test RE 0.7520924901663439\n",
      "180 Train Loss 2529.322 Test MSE 4544.488100694015 Test RE 0.7510984014000116\n",
      "181 Train Loss 2526.6597 Test MSE 4552.245240939848 Test RE 0.7517391656972673\n",
      "182 Train Loss 2524.976 Test MSE 4540.983578695258 Test RE 0.7508087374733715\n",
      "183 Train Loss 2522.9863 Test MSE 4533.395768355522 Test RE 0.7501811888313159\n",
      "184 Train Loss 2520.74 Test MSE 4532.517074125763 Test RE 0.7501084826458885\n",
      "185 Train Loss 2517.9705 Test MSE 4519.177949987448 Test RE 0.7490038908070022\n",
      "186 Train Loss 2515.895 Test MSE 4490.106960221092 Test RE 0.7465909060560628\n",
      "187 Train Loss 2514.872 Test MSE 4495.163749889926 Test RE 0.7470111956900197\n",
      "188 Train Loss 2512.8071 Test MSE 4485.042287535259 Test RE 0.7461697239463048\n",
      "189 Train Loss 2511.3242 Test MSE 4475.7987219404695 Test RE 0.7454004083201238\n",
      "190 Train Loss 2510.0293 Test MSE 4465.887630864857 Test RE 0.7445746533959349\n",
      "191 Train Loss 2506.3247 Test MSE 4462.282125835747 Test RE 0.7442740289803472\n",
      "192 Train Loss 2504.0889 Test MSE 4457.204920162519 Test RE 0.7438504892173915\n",
      "193 Train Loss 2497.5046 Test MSE 4436.744303283246 Test RE 0.7421412177528341\n",
      "194 Train Loss 2492.615 Test MSE 4435.31431502298 Test RE 0.7420216099185654\n",
      "195 Train Loss 2484.09 Test MSE 4439.75454198889 Test RE 0.7423929387514021\n",
      "196 Train Loss 2477.3574 Test MSE 4412.090561528037 Test RE 0.740076410233124\n",
      "197 Train Loss 2469.7664 Test MSE 4396.116666974493 Test RE 0.7387354787592586\n",
      "198 Train Loss 2460.732 Test MSE 4358.260929027005 Test RE 0.7355479108287071\n",
      "199 Train Loss 2453.4395 Test MSE 4355.686363779931 Test RE 0.7353306228012066\n",
      "Training time: 37.68\n",
      "Training time: 37.68\n",
      "1D_FODE_atanh_medium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 15313.018 Test MSE 11865.564170680198 Test RE 1.2136642195573555\n",
      "1 Train Loss 14676.378 Test MSE 12252.371493798857 Test RE 1.2332877860456586\n",
      "2 Train Loss 14257.023 Test MSE 12151.142698075164 Test RE 1.228182522415283\n",
      "3 Train Loss 13543.564 Test MSE 12731.837015299621 Test RE 1.257187017476974\n",
      "4 Train Loss 12913.173 Test MSE 13181.558560426532 Test RE 1.2791978889929907\n",
      "5 Train Loss 12091.41 Test MSE 13124.292432159293 Test RE 1.2764161828115563\n",
      "6 Train Loss 11180.5205 Test MSE 12464.240372809458 Test RE 1.2439051338286862\n",
      "7 Train Loss 10165.121 Test MSE 11368.565812914996 Test RE 1.1879747021943192\n",
      "8 Train Loss 9505.078 Test MSE 11078.511221232538 Test RE 1.1727219481979854\n",
      "9 Train Loss 8743.37 Test MSE 10136.814488296153 Test RE 1.121773307166976\n",
      "10 Train Loss 8163.0244 Test MSE 9471.630511725922 Test RE 1.0843431150446827\n",
      "11 Train Loss 7714.465 Test MSE 8523.664203925216 Test RE 1.0286497345791086\n",
      "12 Train Loss 7418.2783 Test MSE 8268.99678228127 Test RE 1.0131663652908898\n",
      "13 Train Loss 7158.097 Test MSE 8139.154738003838 Test RE 1.0051803843450966\n",
      "14 Train Loss 6909.47 Test MSE 7722.809675219339 Test RE 0.979133744863633\n",
      "15 Train Loss 6754.6035 Test MSE 7384.060530414629 Test RE 0.9574188558308585\n",
      "16 Train Loss 6585.0723 Test MSE 6957.861836736484 Test RE 0.9293777109291917\n",
      "17 Train Loss 6418.845 Test MSE 6727.652476002498 Test RE 0.9138735904559685\n",
      "18 Train Loss 6173.676 Test MSE 6363.126632349768 Test RE 0.8887705088939952\n",
      "19 Train Loss 6072.9688 Test MSE 6192.56351754243 Test RE 0.8767778854658607\n",
      "20 Train Loss 5980.1587 Test MSE 5972.254477144958 Test RE 0.8610403517703525\n",
      "21 Train Loss 5910.218 Test MSE 5814.7303383459675 Test RE 0.849609073341408\n",
      "22 Train Loss 5795.15 Test MSE 5604.48184138684 Test RE 0.8341076139021872\n",
      "23 Train Loss 5720.398 Test MSE 5588.731153766446 Test RE 0.8329347122546162\n",
      "24 Train Loss 5635.4487 Test MSE 5488.745049095744 Test RE 0.8254502084465252\n",
      "25 Train Loss 5593.087 Test MSE 5443.73954354484 Test RE 0.8220590624926695\n",
      "26 Train Loss 5540.962 Test MSE 5423.5853808371485 Test RE 0.8205359114383213\n",
      "27 Train Loss 5391.1895 Test MSE 5070.121298405293 Test RE 0.7933476271748742\n",
      "28 Train Loss 5236.627 Test MSE 4853.219459750803 Test RE 0.7761922774326204\n",
      "29 Train Loss 5192.9224 Test MSE 4845.386498622026 Test RE 0.7755656481239126\n",
      "30 Train Loss 5133.6963 Test MSE 4698.191531252623 Test RE 0.7636945849313799\n",
      "31 Train Loss 4964.2524 Test MSE 4326.026702471853 Test RE 0.7328227618029641\n",
      "32 Train Loss 4859.054 Test MSE 4395.610450284345 Test RE 0.7386929445155881\n",
      "33 Train Loss 4762.517 Test MSE 4337.816951811533 Test RE 0.7338207080320125\n",
      "34 Train Loss 4702.0513 Test MSE 4236.2065165416225 Test RE 0.7251751514575862\n",
      "35 Train Loss 4632.106 Test MSE 4126.743560778041 Test RE 0.715744622031983\n",
      "36 Train Loss 4557.672 Test MSE 3970.2025320166827 Test RE 0.702038101901709\n",
      "37 Train Loss 4538.205 Test MSE 3910.303488848184 Test RE 0.696722097604319\n",
      "38 Train Loss 4505.1465 Test MSE 3844.7218243920497 Test RE 0.6908548547878647\n",
      "39 Train Loss 4480.0146 Test MSE 3808.2471264152678 Test RE 0.6875699913711351\n",
      "40 Train Loss 4465.7935 Test MSE 3821.9482955667304 Test RE 0.6888057376946708\n",
      "41 Train Loss 4446.0586 Test MSE 3780.7458772366717 Test RE 0.6850828503399053\n",
      "42 Train Loss 4427.2534 Test MSE 3692.7979269865677 Test RE 0.6770677437430065\n",
      "43 Train Loss 4381.2456 Test MSE 3606.408113774888 Test RE 0.6691011681235206\n",
      "44 Train Loss 4341.642 Test MSE 3554.3821413851515 Test RE 0.6642574155596445\n",
      "45 Train Loss 4330.081 Test MSE 3522.3567190121225 Test RE 0.6612581235704941\n",
      "46 Train Loss 4301.0503 Test MSE 3517.8641041831993 Test RE 0.6608362858396329\n",
      "47 Train Loss 4272.718 Test MSE 3466.8148568994316 Test RE 0.6560239229105741\n",
      "48 Train Loss 4222.823 Test MSE 3432.856961362312 Test RE 0.6528030972288704\n",
      "49 Train Loss 4181.507 Test MSE 3447.674883854167 Test RE 0.6542104919588428\n",
      "50 Train Loss 4147.961 Test MSE 3384.3137655196115 Test RE 0.648171098978592\n",
      "51 Train Loss 4102.4277 Test MSE 3292.9869460075506 Test RE 0.639365733708734\n",
      "52 Train Loss 4072.4685 Test MSE 3236.7090126521675 Test RE 0.6338787325969347\n",
      "53 Train Loss 4039.9229 Test MSE 3261.898295705354 Test RE 0.636340493269707\n",
      "54 Train Loss 4015.1252 Test MSE 3233.7391396167013 Test RE 0.6335878551374501\n",
      "55 Train Loss 3993.0715 Test MSE 3161.647187603053 Test RE 0.6264855447849276\n",
      "56 Train Loss 3970.8733 Test MSE 3116.685816200167 Test RE 0.6220150096269483\n",
      "57 Train Loss 3951.4106 Test MSE 3081.9344981812296 Test RE 0.6185375281610414\n",
      "58 Train Loss 3935.532 Test MSE 3064.0642151390193 Test RE 0.6167416576789814\n",
      "59 Train Loss 3905.8313 Test MSE 3075.956653906408 Test RE 0.6179373668451861\n",
      "60 Train Loss 3888.595 Test MSE 3034.8616212760658 Test RE 0.6137956399811527\n",
      "61 Train Loss 3879.933 Test MSE 3049.302925976183 Test RE 0.6152542715751792\n",
      "62 Train Loss 3865.9604 Test MSE 3029.703338381571 Test RE 0.6132737911392488\n",
      "63 Train Loss 3840.7876 Test MSE 2964.181565209034 Test RE 0.6066060722116717\n",
      "64 Train Loss 3827.5818 Test MSE 2904.891616932035 Test RE 0.6005087211054201\n",
      "65 Train Loss 3821.0222 Test MSE 2883.7713995453464 Test RE 0.5983217183655137\n",
      "66 Train Loss 3803.4268 Test MSE 2835.1603920316998 Test RE 0.5932574065154131\n",
      "67 Train Loss 3785.5544 Test MSE 2810.746121116899 Test RE 0.5906975401875061\n",
      "68 Train Loss 3770.8176 Test MSE 2792.135249321694 Test RE 0.5887386911963484\n",
      "69 Train Loss 3765.8108 Test MSE 2791.646749044889 Test RE 0.5886871873170029\n",
      "70 Train Loss 3752.7693 Test MSE 2782.967881990461 Test RE 0.5877713990044054\n",
      "71 Train Loss 3738.0496 Test MSE 2717.584811018186 Test RE 0.5808258084866059\n",
      "72 Train Loss 3721.218 Test MSE 2673.714128511954 Test RE 0.5761185219673712\n",
      "73 Train Loss 3704.6033 Test MSE 2651.0765044509826 Test RE 0.5736744166776991\n",
      "74 Train Loss 3693.4534 Test MSE 2572.728945804633 Test RE 0.5651339119352597\n",
      "75 Train Loss 3678.8716 Test MSE 2582.423775493603 Test RE 0.5661977094289059\n",
      "76 Train Loss 3672.1582 Test MSE 2607.5725554095643 Test RE 0.5689479711487471\n",
      "77 Train Loss 3658.011 Test MSE 2671.2980383490876 Test RE 0.5758581596348303\n",
      "78 Train Loss 3631.6736 Test MSE 2690.7576435413926 Test RE 0.5779518306202355\n",
      "79 Train Loss 3611.3894 Test MSE 2732.0172249714183 Test RE 0.5823660765756783\n",
      "80 Train Loss 3609.2085 Test MSE 2725.6549382591197 Test RE 0.5816875779966556\n",
      "81 Train Loss 3602.6501 Test MSE 2711.00637805782 Test RE 0.5801223826452031\n",
      "82 Train Loss 3584.9746 Test MSE 2750.596939920367 Test RE 0.5843429787669883\n",
      "83 Train Loss 3569.3171 Test MSE 2750.9642705928018 Test RE 0.5843819957400647\n",
      "84 Train Loss 3556.8506 Test MSE 2698.8986050605586 Test RE 0.5788254749184758\n",
      "85 Train Loss 3537.6594 Test MSE 2667.6469676914303 Test RE 0.5754644900212309\n",
      "86 Train Loss 3534.2485 Test MSE 2685.116971485135 Test RE 0.5773457286443261\n",
      "87 Train Loss 3528.6719 Test MSE 2685.1094974656426 Test RE 0.5773449251232359\n",
      "88 Train Loss 3497.7769 Test MSE 2626.5139393141085 Test RE 0.5710106486158144\n",
      "89 Train Loss 3483.139 Test MSE 2596.8115501527755 Test RE 0.567772782036395\n",
      "90 Train Loss 3461.418 Test MSE 2605.5368494793297 Test RE 0.568725841778724\n",
      "91 Train Loss 3449.6772 Test MSE 2602.242991914648 Test RE 0.5683662432689249\n",
      "92 Train Loss 3445.2056 Test MSE 2618.2710742753766 Test RE 0.5701139348593933\n",
      "93 Train Loss 3438.9553 Test MSE 2633.414541195804 Test RE 0.5717602605647782\n",
      "94 Train Loss 3436.6401 Test MSE 2619.9937829768714 Test RE 0.5703014591283257\n",
      "95 Train Loss 3434.9802 Test MSE 2619.376966542617 Test RE 0.5702343230875303\n",
      "96 Train Loss 3426.7737 Test MSE 2596.6007137522593 Test RE 0.5677497326935312\n",
      "97 Train Loss 3414.9714 Test MSE 2582.870637304247 Test RE 0.5662466946480788\n",
      "98 Train Loss 3412.818 Test MSE 2587.9823463692346 Test RE 0.5668067416030506\n",
      "99 Train Loss 3411.7363 Test MSE 2587.9929497944704 Test RE 0.5668079027560158\n",
      "100 Train Loss 3405.2969 Test MSE 2548.794934421509 Test RE 0.5624990586826465\n",
      "101 Train Loss 3394.881 Test MSE 2507.7760941320994 Test RE 0.5579544316395819\n",
      "102 Train Loss 3391.098 Test MSE 2491.200195497203 Test RE 0.5561073908124246\n",
      "103 Train Loss 3388.5093 Test MSE 2464.504242762685 Test RE 0.5531197137271346\n",
      "104 Train Loss 3384.8135 Test MSE 2456.966172260954 Test RE 0.5522731644611347\n",
      "105 Train Loss 3379.0054 Test MSE 2491.2879521140626 Test RE 0.5561171856240862\n",
      "106 Train Loss 3378.0422 Test MSE 2491.651071826842 Test RE 0.5561577128049572\n",
      "107 Train Loss 3376.5288 Test MSE 2494.6649346939457 Test RE 0.5564939710661593\n",
      "108 Train Loss 3363.5806 Test MSE 2489.5281628848306 Test RE 0.5559207366512666\n",
      "109 Train Loss 3351.9736 Test MSE 2468.6290743229188 Test RE 0.5535823974111415\n",
      "110 Train Loss 3348.936 Test MSE 2459.7802859472936 Test RE 0.5525893500733824\n",
      "111 Train Loss 3344.4521 Test MSE 2455.138185044846 Test RE 0.5520676801239568\n",
      "112 Train Loss 3340.8716 Test MSE 2479.416714999909 Test RE 0.5547906263396502\n",
      "113 Train Loss 3337.9473 Test MSE 2482.488974504678 Test RE 0.5551342420557389\n",
      "114 Train Loss 3336.637 Test MSE 2470.6025461236136 Test RE 0.553803625665269\n",
      "115 Train Loss 3334.94 Test MSE 2479.01786089957 Test RE 0.5547460010423665\n",
      "116 Train Loss 3332.7246 Test MSE 2467.681400147147 Test RE 0.5534761307172953\n",
      "117 Train Loss 3324.0315 Test MSE 2460.1569613263164 Test RE 0.5526316584933877\n",
      "118 Train Loss 3313.2046 Test MSE 2466.4253183644532 Test RE 0.5533352495291246\n",
      "119 Train Loss 3299.364 Test MSE 2438.5973253279885 Test RE 0.5502048304661415\n",
      "120 Train Loss 3295.733 Test MSE 2446.4854040264545 Test RE 0.5510939799269382\n",
      "121 Train Loss 3294.486 Test MSE 2434.847314968185 Test RE 0.5497816224983373\n",
      "122 Train Loss 3292.838 Test MSE 2433.726236762906 Test RE 0.5496550397854117\n",
      "123 Train Loss 3291.4268 Test MSE 2443.1328467325206 Test RE 0.5507162528552995\n",
      "124 Train Loss 3289.665 Test MSE 2424.9466656527907 Test RE 0.5486627146287821\n",
      "125 Train Loss 3285.4 Test MSE 2434.2888990118645 Test RE 0.5497185745131274\n",
      "126 Train Loss 3281.8657 Test MSE 2441.8398050118553 Test RE 0.5505704987392899\n",
      "127 Train Loss 3272.248 Test MSE 2457.7618137788445 Test RE 0.5523625787753877\n",
      "128 Train Loss 3263.0981 Test MSE 2465.4068733483973 Test RE 0.5532209951647625\n",
      "129 Train Loss 3259.6514 Test MSE 2450.451420799019 Test RE 0.5515404904371835\n",
      "130 Train Loss 3255.2583 Test MSE 2445.177730666851 Test RE 0.5509466773434631\n",
      "131 Train Loss 3250.823 Test MSE 2475.5343757633514 Test RE 0.5543561029257817\n",
      "132 Train Loss 3247.0718 Test MSE 2481.903072834531 Test RE 0.5550687285174524\n",
      "133 Train Loss 3244.171 Test MSE 2494.0986681321956 Test RE 0.5564308079118908\n",
      "134 Train Loss 3242.6536 Test MSE 2503.646040155082 Test RE 0.5574947950161351\n",
      "135 Train Loss 3241.8113 Test MSE 2496.6912336487835 Test RE 0.5567199321261808\n",
      "136 Train Loss 3238.338 Test MSE 2507.566239336081 Test RE 0.557931085882484\n",
      "137 Train Loss 3235.3022 Test MSE 2508.6730564245104 Test RE 0.5580542051689431\n",
      "138 Train Loss 3233.7341 Test MSE 2507.6078193361036 Test RE 0.557935711618393\n",
      "139 Train Loss 3232.286 Test MSE 2514.5116494032686 Test RE 0.5587032251309411\n",
      "140 Train Loss 3230.9124 Test MSE 2503.0677611970677 Test RE 0.5574304076942092\n",
      "141 Train Loss 3228.018 Test MSE 2495.277002570156 Test RE 0.5565622349817786\n",
      "142 Train Loss 3218.0044 Test MSE 2458.3538250658153 Test RE 0.5524290997030703\n",
      "143 Train Loss 3212.9363 Test MSE 2423.7965384199297 Test RE 0.54853258665949\n",
      "144 Train Loss 3206.9055 Test MSE 2419.247653651962 Test RE 0.548017612874172\n",
      "145 Train Loss 3194.7312 Test MSE 2411.788786542603 Test RE 0.5471721545647412\n",
      "146 Train Loss 3172.0076 Test MSE 2465.038533011072 Test RE 0.5531796670533934\n",
      "147 Train Loss 3168.1865 Test MSE 2470.2596665971564 Test RE 0.5537651948553407\n",
      "148 Train Loss 3163.2026 Test MSE 2449.4795492224052 Test RE 0.5514311065742219\n",
      "149 Train Loss 3159.4998 Test MSE 2464.538047771543 Test RE 0.5531235072188193\n",
      "150 Train Loss 3157.26 Test MSE 2471.2665148797228 Test RE 0.5538780373919078\n",
      "151 Train Loss 3154.0435 Test MSE 2482.3850342222863 Test RE 0.55512262036991\n",
      "152 Train Loss 3153.2244 Test MSE 2478.620882648133 Test RE 0.5547015820573326\n",
      "153 Train Loss 3152.5754 Test MSE 2481.0369163089777 Test RE 0.5549718636639612\n",
      "154 Train Loss 3152.0808 Test MSE 2477.4712016494127 Test RE 0.5545729210262194\n",
      "155 Train Loss 3152.0808 Test MSE 2477.4712016494127 Test RE 0.5545729210262194\n",
      "156 Train Loss 3152.0808 Test MSE 2477.4712016494127 Test RE 0.5545729210262194\n",
      "157 Train Loss 3152.0557 Test MSE 2477.4568385499438 Test RE 0.5545713134600915\n",
      "158 Train Loss 3151.99 Test MSE 2476.977154098788 Test RE 0.5545176228952605\n",
      "159 Train Loss 3151.99 Test MSE 2476.977154098788 Test RE 0.5545176228952605\n",
      "160 Train Loss 3151.99 Test MSE 2476.977154098788 Test RE 0.5545176228952605\n",
      "161 Train Loss 3151.99 Test MSE 2476.977154098788 Test RE 0.5545176228952605\n",
      "162 Train Loss 3151.99 Test MSE 2476.977154098788 Test RE 0.5545176228952605\n",
      "163 Train Loss 3151.99 Test MSE 2476.977154098788 Test RE 0.5545176228952605\n",
      "164 Train Loss 3151.99 Test MSE 2476.977154098788 Test RE 0.5545176228952605\n",
      "165 Train Loss 3151.99 Test MSE 2476.977154098788 Test RE 0.5545176228952605\n",
      "166 Train Loss 3151.99 Test MSE 2476.977138139225 Test RE 0.5545176211088374\n",
      "167 Train Loss 3151.99 Test MSE 2476.977138139225 Test RE 0.5545176211088374\n",
      "168 Train Loss 3151.99 Test MSE 2476.977138139225 Test RE 0.5545176211088374\n",
      "169 Train Loss 3151.99 Test MSE 2476.977138139225 Test RE 0.5545176211088374\n",
      "170 Train Loss 3151.99 Test MSE 2476.977138139225 Test RE 0.5545176211088374\n",
      "171 Train Loss 3151.99 Test MSE 2476.977138139225 Test RE 0.5545176211088374\n",
      "172 Train Loss 3151.9893 Test MSE 2476.9773569920562 Test RE 0.5545176456059848\n",
      "173 Train Loss 3151.9893 Test MSE 2476.9773569920562 Test RE 0.5545176456059848\n",
      "174 Train Loss 3151.9885 Test MSE 2476.977103112801 Test RE 0.5545176171881776\n",
      "175 Train Loss 3151.9849 Test MSE 2476.977483899084 Test RE 0.5545176598112389\n",
      "176 Train Loss 3151.9849 Test MSE 2476.977483899084 Test RE 0.5545176598112389\n",
      "177 Train Loss 3151.9849 Test MSE 2476.977483899084 Test RE 0.5545176598112389\n",
      "178 Train Loss 3151.9849 Test MSE 2476.977483899084 Test RE 0.5545176598112389\n",
      "179 Train Loss 3151.9849 Test MSE 2476.977483899084 Test RE 0.5545176598112389\n",
      "180 Train Loss 3151.9697 Test MSE 2475.171062293496 Test RE 0.5543154223294149\n",
      "181 Train Loss 3151.917 Test MSE 2475.2592268420794 Test RE 0.5543252944822016\n",
      "182 Train Loss 3151.917 Test MSE 2475.2592268420794 Test RE 0.5543252944822016\n",
      "183 Train Loss 3151.917 Test MSE 2475.2592268420794 Test RE 0.5543252944822016\n",
      "184 Train Loss 3151.9155 Test MSE 2475.2588617983383 Test RE 0.5543252536070914\n",
      "185 Train Loss 3151.8037 Test MSE 2476.439039720192 Test RE 0.5544573861438674\n",
      "186 Train Loss 3151.8037 Test MSE 2476.439039720192 Test RE 0.5544573861438674\n",
      "187 Train Loss 3151.8037 Test MSE 2476.439039720192 Test RE 0.5544573861438674\n",
      "188 Train Loss 3151.8037 Test MSE 2476.439039720192 Test RE 0.5544573861438674\n",
      "189 Train Loss 3151.8037 Test MSE 2476.439039720192 Test RE 0.5544573861438674\n",
      "190 Train Loss 3151.8037 Test MSE 2476.439039720192 Test RE 0.5544573861438674\n",
      "191 Train Loss 3151.8037 Test MSE 2476.439039720192 Test RE 0.5544573861438674\n",
      "192 Train Loss 3151.6855 Test MSE 2476.886973784017 Test RE 0.5545075285290577\n",
      "193 Train Loss 3151.3828 Test MSE 2484.2840828798967 Test RE 0.5553349168731387\n",
      "194 Train Loss 3150.8948 Test MSE 2488.805844053876 Test RE 0.5558400825832233\n",
      "195 Train Loss 3150.6584 Test MSE 2490.2118747167865 Test RE 0.5559970690860712\n",
      "196 Train Loss 3150.5452 Test MSE 2490.9659578920046 Test RE 0.5560812459193278\n",
      "197 Train Loss 3150.5452 Test MSE 2490.9659578920046 Test RE 0.5560812459193278\n",
      "198 Train Loss 3149.5684 Test MSE 2487.025019081266 Test RE 0.5556411857841635\n",
      "199 Train Loss 3149.051 Test MSE 2484.134623281513 Test RE 0.5553182115811357\n",
      "Training time: 32.95\n",
      "Training time: 32.95\n",
      "1D_FODE_atanh_medium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 16331.214 Test MSE 9504.137173497882 Test RE 1.086202255532606\n",
      "1 Train Loss 14502.156 Test MSE 11907.754605683062 Test RE 1.2158200203226057\n",
      "2 Train Loss 13758.49 Test MSE 12881.347140921369 Test RE 1.2645470549351199\n",
      "3 Train Loss 13199.261 Test MSE 13008.900805789346 Test RE 1.2707925304296972\n",
      "4 Train Loss 12924.16 Test MSE 13329.877281437042 Test RE 1.2863745164228646\n",
      "5 Train Loss 12644.748 Test MSE 13065.052648379513 Test RE 1.2735322125490058\n",
      "6 Train Loss 12173.708 Test MSE 13585.648466470713 Test RE 1.298657233231426\n",
      "7 Train Loss 11670.996 Test MSE 13217.053268041474 Test RE 1.2809190143803055\n",
      "8 Train Loss 11173.748 Test MSE 13045.631684517517 Test RE 1.2725853192622907\n",
      "9 Train Loss 10651.82 Test MSE 12911.758925135506 Test RE 1.2660389198766955\n",
      "10 Train Loss 9957.035 Test MSE 12920.327885613373 Test RE 1.2664589570764357\n",
      "11 Train Loss 9587.858 Test MSE 13014.880407268663 Test RE 1.2710845597102354\n",
      "12 Train Loss 9292.1 Test MSE 12925.773108597761 Test RE 1.2667258011165707\n",
      "13 Train Loss 8886.078 Test MSE 12235.880420289677 Test RE 1.2324575350318732\n",
      "14 Train Loss 8504.182 Test MSE 11861.56242987506 Test RE 1.213459544114838\n",
      "15 Train Loss 8182.66 Test MSE 11360.950254521096 Test RE 1.1875767361498493\n",
      "16 Train Loss 7985.023 Test MSE 11265.630153913351 Test RE 1.1825842674772633\n",
      "17 Train Loss 7781.8813 Test MSE 11078.508032910657 Test RE 1.1727217794471831\n",
      "18 Train Loss 7626.516 Test MSE 10896.809947245947 Test RE 1.1630651440628974\n",
      "19 Train Loss 7499.431 Test MSE 10756.469155823803 Test RE 1.1555512733284228\n",
      "20 Train Loss 7412.803 Test MSE 10744.977092588468 Test RE 1.1549338208464812\n",
      "21 Train Loss 7358.235 Test MSE 10652.294005160677 Test RE 1.1499419691892772\n",
      "22 Train Loss 7284.732 Test MSE 10571.97129253931 Test RE 1.1455982457526168\n",
      "23 Train Loss 7214.781 Test MSE 10563.010886175825 Test RE 1.1451126597860977\n",
      "24 Train Loss 7174.4297 Test MSE 10495.088360469117 Test RE 1.1414250567655397\n",
      "25 Train Loss 7139.936 Test MSE 10409.56046697631 Test RE 1.1367646202029056\n",
      "26 Train Loss 7098.433 Test MSE 10380.712126502725 Test RE 1.1351883516829293\n",
      "27 Train Loss 7065.951 Test MSE 10342.795865962586 Test RE 1.133113278591901\n",
      "28 Train Loss 7042.59 Test MSE 10268.8850449586 Test RE 1.1290573399744785\n",
      "29 Train Loss 7010.5513 Test MSE 10206.987067297787 Test RE 1.1256493751278347\n",
      "30 Train Loss 6975.6665 Test MSE 10160.098098576089 Test RE 1.1230608887519256\n",
      "31 Train Loss 6923.751 Test MSE 10105.038922916372 Test RE 1.1200137327571542\n",
      "32 Train Loss 6873.0405 Test MSE 10073.263123374816 Test RE 1.1182513766538604\n",
      "33 Train Loss 6814.191 Test MSE 10161.318145791081 Test RE 1.1231283165545405\n",
      "34 Train Loss 6770.7476 Test MSE 10202.755347280448 Test RE 1.1254160091608394\n",
      "35 Train Loss 6729.1226 Test MSE 10198.931594853615 Test RE 1.125205099689803\n",
      "36 Train Loss 6700.9907 Test MSE 10207.956289021642 Test RE 1.125702817829502\n",
      "37 Train Loss 6673.5776 Test MSE 10183.519691616804 Test RE 1.1243546131342912\n",
      "38 Train Loss 6637.7285 Test MSE 10061.618492630701 Test RE 1.1176048438666695\n",
      "39 Train Loss 6601.1616 Test MSE 9960.546101802684 Test RE 1.1119773145883916\n",
      "40 Train Loss 6561.4414 Test MSE 9879.409932730541 Test RE 1.1074391064749267\n",
      "41 Train Loss 6532.395 Test MSE 9731.29685711224 Test RE 1.0991063396653002\n",
      "42 Train Loss 6484.6475 Test MSE 9602.37631015356 Test RE 1.0918015667167846\n",
      "43 Train Loss 6455.609 Test MSE 9595.532418789762 Test RE 1.0914124180855045\n",
      "44 Train Loss 6429.039 Test MSE 9575.572376454558 Test RE 1.0902766823239862\n",
      "45 Train Loss 6398.3955 Test MSE 9429.040736484247 Test RE 1.0819024602110197\n",
      "46 Train Loss 6364.8784 Test MSE 9355.424159445569 Test RE 1.0776707453717436\n",
      "47 Train Loss 6349.249 Test MSE 9359.560243590051 Test RE 1.0779089411105243\n",
      "48 Train Loss 6327.251 Test MSE 9294.185565677406 Test RE 1.074137854071661\n",
      "49 Train Loss 6278.69 Test MSE 9298.812321991303 Test RE 1.0744051801172794\n",
      "50 Train Loss 6255.903 Test MSE 9306.164875393046 Test RE 1.0748298612621145\n",
      "51 Train Loss 6237.685 Test MSE 9262.987050523368 Test RE 1.0723335175942905\n",
      "52 Train Loss 6210.423 Test MSE 9223.570002204937 Test RE 1.070049519783354\n",
      "53 Train Loss 6188.229 Test MSE 9201.261464756486 Test RE 1.068754701655939\n",
      "54 Train Loss 6160.541 Test MSE 9143.989083699256 Test RE 1.0654233283699273\n",
      "55 Train Loss 6132.823 Test MSE 9077.18596165657 Test RE 1.061524369500758\n",
      "56 Train Loss 6095.969 Test MSE 9072.510229741534 Test RE 1.0612509343893142\n",
      "57 Train Loss 6074.5737 Test MSE 9002.147064620774 Test RE 1.0571275814647099\n",
      "58 Train Loss 6026.5854 Test MSE 8864.064639338849 Test RE 1.0489886992064748\n",
      "59 Train Loss 5968.0107 Test MSE 8608.537004126705 Test RE 1.033758343233181\n",
      "60 Train Loss 5913.0894 Test MSE 8461.729511830288 Test RE 1.0249057310441405\n",
      "61 Train Loss 5854.431 Test MSE 8367.888788087757 Test RE 1.0192067756483978\n",
      "62 Train Loss 5708.9062 Test MSE 8129.752396158312 Test RE 1.0045996249829565\n",
      "63 Train Loss 5630.1543 Test MSE 8092.576285170129 Test RE 1.0023000530597461\n",
      "64 Train Loss 5570.892 Test MSE 8054.871050426529 Test RE 0.9999623499149759\n",
      "65 Train Loss 5523.7305 Test MSE 8026.043873955071 Test RE 0.9981713883797136\n",
      "66 Train Loss 5484.8164 Test MSE 8054.43904033999 Test RE 0.999935533867202\n",
      "67 Train Loss 5448.6255 Test MSE 7987.8424608327705 Test RE 0.9957930660084481\n",
      "68 Train Loss 5408.8794 Test MSE 7937.134683584562 Test RE 0.9926273272749495\n",
      "69 Train Loss 5371.025 Test MSE 7931.6074462188635 Test RE 0.9922816457052959\n",
      "70 Train Loss 5325.3364 Test MSE 7867.135753852724 Test RE 0.988240560020332\n",
      "71 Train Loss 5231.794 Test MSE 7476.773685529937 Test RE 0.9634107099826337\n",
      "72 Train Loss 5163.471 Test MSE 7340.896671849478 Test RE 0.9546164368796513\n",
      "73 Train Loss 5123.5396 Test MSE 7276.474370783162 Test RE 0.9504184410140528\n",
      "74 Train Loss 5095.291 Test MSE 7252.463746664782 Test RE 0.9488490685987604\n",
      "75 Train Loss 5081.716 Test MSE 7225.332468561574 Test RE 0.9470725957732472\n",
      "76 Train Loss 5060.3696 Test MSE 7194.147969504391 Test RE 0.9450266054547076\n",
      "77 Train Loss 5023.7617 Test MSE 7002.7234241943415 Test RE 0.9323690299998747\n",
      "78 Train Loss 5002.0444 Test MSE 6930.2751999410275 Test RE 0.9275334756347517\n",
      "79 Train Loss 4967.578 Test MSE 6788.667549435533 Test RE 0.9180083319844621\n",
      "80 Train Loss 4949.057 Test MSE 6769.370014916825 Test RE 0.9167026335766594\n",
      "81 Train Loss 4923.6113 Test MSE 6659.090090509771 Test RE 0.9092049627582418\n",
      "82 Train Loss 4907.8623 Test MSE 6639.631610483734 Test RE 0.9078756002240135\n",
      "83 Train Loss 4889.2324 Test MSE 6624.170350926653 Test RE 0.9068179299836174\n",
      "84 Train Loss 4859.914 Test MSE 6615.34184045754 Test RE 0.906213437614199\n",
      "85 Train Loss 4837.256 Test MSE 6613.115431010926 Test RE 0.9060609306090722\n",
      "86 Train Loss 4810.232 Test MSE 6661.198747870429 Test RE 0.909348905095745\n",
      "87 Train Loss 4785.698 Test MSE 6693.160609938837 Test RE 0.9115279200418314\n",
      "88 Train Loss 4743.951 Test MSE 6551.674462612967 Test RE 0.9018421045198889\n",
      "89 Train Loss 4732.513 Test MSE 6562.354555061295 Test RE 0.9025768659188941\n",
      "90 Train Loss 4710.652 Test MSE 6503.511148381745 Test RE 0.8985211346751479\n",
      "91 Train Loss 4696.8975 Test MSE 6529.697148564995 Test RE 0.9003282383627719\n",
      "92 Train Loss 4665.051 Test MSE 6417.076768090403 Test RE 0.892530302290259\n",
      "93 Train Loss 4645.529 Test MSE 6353.897435100502 Test RE 0.888125730368925\n",
      "94 Train Loss 4629.96 Test MSE 6383.275017453821 Test RE 0.890176510878264\n",
      "95 Train Loss 4607.2812 Test MSE 6352.319382113108 Test RE 0.8880154361355995\n",
      "96 Train Loss 4591.1226 Test MSE 6387.138536002423 Test RE 0.8904458626771274\n",
      "97 Train Loss 4573.9756 Test MSE 6359.135062688731 Test RE 0.8884917036676919\n",
      "98 Train Loss 4555.6904 Test MSE 6348.439842026601 Test RE 0.8877442267206671\n",
      "99 Train Loss 4539.155 Test MSE 6281.521005657417 Test RE 0.8830529801823567\n",
      "100 Train Loss 4530.626 Test MSE 6274.235410785406 Test RE 0.8825407290232082\n",
      "101 Train Loss 4524.4614 Test MSE 6259.075355105359 Test RE 0.8814738692839124\n",
      "102 Train Loss 4512.325 Test MSE 6253.650097980441 Test RE 0.88109176339331\n",
      "103 Train Loss 4497.831 Test MSE 6230.445212873653 Test RE 0.8794555481786841\n",
      "104 Train Loss 4473.3027 Test MSE 6100.760698096452 Test RE 0.870254639811308\n",
      "105 Train Loss 4465.912 Test MSE 6069.164095645609 Test RE 0.8679981355441165\n",
      "106 Train Loss 4458.222 Test MSE 6075.23444433757 Test RE 0.8684321108331547\n",
      "107 Train Loss 4444.534 Test MSE 6070.396435293899 Test RE 0.8680862542872304\n",
      "108 Train Loss 4436.3765 Test MSE 6053.72471098715 Test RE 0.866893379543674\n",
      "109 Train Loss 4424.1978 Test MSE 6019.393567496115 Test RE 0.8644317747169109\n",
      "110 Train Loss 4411.844 Test MSE 5993.282709758345 Test RE 0.8625548758906276\n",
      "111 Train Loss 4397.4863 Test MSE 5979.727989844658 Test RE 0.8615789242762214\n",
      "112 Train Loss 4385.763 Test MSE 5939.6510344669405 Test RE 0.8586868604443747\n",
      "113 Train Loss 4375.247 Test MSE 5963.755740918417 Test RE 0.8604274877279547\n",
      "114 Train Loss 4366.762 Test MSE 5940.811317109319 Test RE 0.8587707265504653\n",
      "115 Train Loss 4352.701 Test MSE 5958.10387853222 Test RE 0.8600196767205736\n",
      "116 Train Loss 4328.6934 Test MSE 5984.7267288607745 Test RE 0.8619389664471292\n",
      "117 Train Loss 4304.3457 Test MSE 6005.167982114708 Test RE 0.8634097181046756\n",
      "118 Train Loss 4280.1978 Test MSE 6001.706092842564 Test RE 0.8631608108504353\n",
      "119 Train Loss 4263.9736 Test MSE 5952.368337656851 Test RE 0.85960563008874\n",
      "120 Train Loss 4253.292 Test MSE 5888.690477819231 Test RE 0.8549952777805611\n",
      "121 Train Loss 4216.579 Test MSE 5806.251718582188 Test RE 0.8489894280880659\n",
      "122 Train Loss 4202.931 Test MSE 5818.2900906722725 Test RE 0.8498690970192213\n",
      "123 Train Loss 4194.6206 Test MSE 5784.930144032434 Test RE 0.8474291753568748\n",
      "124 Train Loss 4183.071 Test MSE 5755.95092211223 Test RE 0.8453039404784485\n",
      "125 Train Loss 4171.4824 Test MSE 5698.5473561755925 Test RE 0.84107830963264\n",
      "126 Train Loss 4157.438 Test MSE 5641.038565505294 Test RE 0.8368235366990432\n",
      "127 Train Loss 4142.2563 Test MSE 5594.808746059157 Test RE 0.8333874860537904\n",
      "128 Train Loss 4134.264 Test MSE 5604.584159284972 Test RE 0.8341152277861081\n",
      "129 Train Loss 4124.442 Test MSE 5561.362509891516 Test RE 0.8308927218249863\n",
      "130 Train Loss 4112.2573 Test MSE 5533.913219483833 Test RE 0.8288396612700228\n",
      "131 Train Loss 4102.077 Test MSE 5521.519393449876 Test RE 0.8279110008250596\n",
      "132 Train Loss 4087.887 Test MSE 5469.012947957635 Test RE 0.8239651210548515\n",
      "133 Train Loss 4076.162 Test MSE 5426.3978646049945 Test RE 0.8207486346341718\n",
      "134 Train Loss 4068.4473 Test MSE 5415.386210586239 Test RE 0.8199154493489929\n",
      "135 Train Loss 4057.4055 Test MSE 5376.060399744438 Test RE 0.8169329666837818\n",
      "136 Train Loss 4049.816 Test MSE 5420.299700832599 Test RE 0.8202873280112565\n",
      "137 Train Loss 4040.5723 Test MSE 5399.859069598757 Test RE 0.8187391637604927\n",
      "138 Train Loss 3997.2117 Test MSE 5309.362889499319 Test RE 0.8118495556571924\n",
      "139 Train Loss 3975.886 Test MSE 5245.647435746693 Test RE 0.806963518315171\n",
      "140 Train Loss 3949.9873 Test MSE 5171.509143013241 Test RE 0.8012406982782942\n",
      "141 Train Loss 3894.3655 Test MSE 5112.251148643382 Test RE 0.7966369440261875\n",
      "142 Train Loss 3855.5786 Test MSE 5073.78457712608 Test RE 0.7936341813360754\n",
      "143 Train Loss 3832.7375 Test MSE 4994.282913896629 Test RE 0.7873918632500937\n",
      "144 Train Loss 3819.2083 Test MSE 4994.949406360892 Test RE 0.787444400645854\n",
      "145 Train Loss 3798.465 Test MSE 4970.344698060735 Test RE 0.7855025633153274\n",
      "146 Train Loss 3769.6558 Test MSE 4933.999451569487 Test RE 0.782625331573258\n",
      "147 Train Loss 3708.264 Test MSE 4780.121436451059 Test RE 0.7703246889309474\n",
      "148 Train Loss 3662.6133 Test MSE 4600.052681388221 Test RE 0.7556762186331102\n",
      "149 Train Loss 3590.9124 Test MSE 4580.329189279626 Test RE 0.7540544345175699\n",
      "150 Train Loss 3566.226 Test MSE 4554.203076925913 Test RE 0.7519008028345868\n",
      "151 Train Loss 3553.0117 Test MSE 4552.356544977293 Test RE 0.7517483557879121\n",
      "152 Train Loss 3536.578 Test MSE 4545.694964662355 Test RE 0.7511981280802196\n",
      "153 Train Loss 3515.062 Test MSE 4532.8517915716675 Test RE 0.7501361791505229\n",
      "154 Train Loss 3501.35 Test MSE 4500.339836662495 Test RE 0.7474411558148043\n",
      "155 Train Loss 3487.4277 Test MSE 4458.776660180439 Test RE 0.7439816293099173\n",
      "156 Train Loss 3468.4688 Test MSE 4440.184125575674 Test RE 0.7424288542625239\n",
      "157 Train Loss 3432.772 Test MSE 4469.8050516565945 Test RE 0.7449011476006533\n",
      "158 Train Loss 3410.9814 Test MSE 4476.736444221264 Test RE 0.7454784884581721\n",
      "159 Train Loss 3389.906 Test MSE 4455.785524047062 Test RE 0.7437320402585174\n",
      "160 Train Loss 3379.0918 Test MSE 4455.869677578367 Test RE 0.743739063417698\n",
      "161 Train Loss 3367.3372 Test MSE 4455.222123014129 Test RE 0.74368501907182\n",
      "162 Train Loss 3359.2043 Test MSE 4450.17146541665 Test RE 0.7432633606880199\n",
      "163 Train Loss 3339.538 Test MSE 4466.475351977885 Test RE 0.7446236456550082\n",
      "164 Train Loss 3326.947 Test MSE 4449.80642394528 Test RE 0.7432328756250082\n",
      "165 Train Loss 3299.658 Test MSE 4382.135045836929 Test RE 0.7375597882643333\n",
      "166 Train Loss 3259.0994 Test MSE 4319.561405429927 Test RE 0.73227495099387\n",
      "167 Train Loss 3235.8833 Test MSE 4280.866257515619 Test RE 0.7289876691516363\n",
      "168 Train Loss 3194.4148 Test MSE 4243.098529015748 Test RE 0.7257648164098216\n",
      "169 Train Loss 3173.3804 Test MSE 4222.714751962423 Test RE 0.7240194364424142\n",
      "170 Train Loss 3153.2466 Test MSE 4259.972778580715 Test RE 0.7272065204836545\n",
      "171 Train Loss 3141.0176 Test MSE 4263.210676070683 Test RE 0.7274828336243577\n",
      "172 Train Loss 3122.0745 Test MSE 4291.594686004756 Test RE 0.7299005682806398\n",
      "173 Train Loss 3110.971 Test MSE 4332.17589704378 Test RE 0.7333434092522396\n",
      "174 Train Loss 3102.6619 Test MSE 4319.517726994755 Test RE 0.7322712486845582\n",
      "175 Train Loss 3095.7952 Test MSE 4319.841948778333 Test RE 0.7322987302056845\n",
      "176 Train Loss 3085.1157 Test MSE 4308.924216882444 Test RE 0.7313727589259651\n",
      "177 Train Loss 3078.9163 Test MSE 4292.498015502222 Test RE 0.7299773819209758\n",
      "178 Train Loss 3073.4802 Test MSE 4288.501521343573 Test RE 0.7296374831380094\n",
      "179 Train Loss 3069.286 Test MSE 4290.990910196073 Test RE 0.7298492223545475\n",
      "180 Train Loss 3059.9446 Test MSE 4294.515379068626 Test RE 0.7301488970603414\n",
      "181 Train Loss 3046.064 Test MSE 4312.379490503484 Test RE 0.731665939597714\n",
      "182 Train Loss 2998.1733 Test MSE 4297.850426601776 Test RE 0.7304323526409936\n",
      "183 Train Loss 2989.0242 Test MSE 4314.275093404191 Test RE 0.7318267319975919\n",
      "184 Train Loss 2977.4583 Test MSE 4297.775085179321 Test RE 0.7304259503644863\n",
      "185 Train Loss 2952.8335 Test MSE 4197.951445058637 Test RE 0.7218933778057728\n",
      "186 Train Loss 2932.3235 Test MSE 4149.51000483336 Test RE 0.7177162186918792\n",
      "187 Train Loss 2922.8435 Test MSE 4167.60903390022 Test RE 0.719279756654732\n",
      "188 Train Loss 2913.938 Test MSE 4126.600412830049 Test RE 0.7157322080957954\n",
      "189 Train Loss 2908.7773 Test MSE 4127.974020892337 Test RE 0.7158513199110265\n",
      "190 Train Loss 2898.8823 Test MSE 4143.439086899046 Test RE 0.7171910011217734\n",
      "191 Train Loss 2888.596 Test MSE 4166.484158556915 Test RE 0.7191826800503959\n",
      "192 Train Loss 2882.8557 Test MSE 4159.4886804396965 Test RE 0.7185786767657992\n",
      "193 Train Loss 2872.4365 Test MSE 4179.656918865739 Test RE 0.7203186671997029\n",
      "194 Train Loss 2858.6702 Test MSE 4152.170828418687 Test RE 0.717946295278331\n",
      "195 Train Loss 2850.0298 Test MSE 4157.278718995365 Test RE 0.7183877588091604\n",
      "196 Train Loss 2836.6768 Test MSE 4087.4338018535227 Test RE 0.7123275121826969\n",
      "197 Train Loss 2826.2856 Test MSE 4094.3896948512347 Test RE 0.7129333651415077\n",
      "198 Train Loss 2818.3198 Test MSE 4083.8595346698226 Test RE 0.712015995737715\n",
      "199 Train Loss 2811.9011 Test MSE 4086.5393862835563 Test RE 0.7122495718775913\n",
      "Training time: 35.17\n",
      "Training time: 35.17\n",
      "1D_FODE_atanh_medium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 16745.555 Test MSE 11456.492296318835 Test RE 1.192559856103928\n",
      "1 Train Loss 15320.294 Test MSE 13912.094850487569 Test RE 1.3141671812247002\n",
      "2 Train Loss 14525.757 Test MSE 14233.611684272832 Test RE 1.3292660384229085\n",
      "3 Train Loss 14086.52 Test MSE 13554.125351379818 Test RE 1.2971497050365233\n",
      "4 Train Loss 13777.699 Test MSE 13564.09204661797 Test RE 1.2976265310839432\n",
      "5 Train Loss 13374.685 Test MSE 13560.321578047759 Test RE 1.297446165155646\n",
      "6 Train Loss 13007.762 Test MSE 13570.997770031714 Test RE 1.2979568115634437\n",
      "7 Train Loss 12684.257 Test MSE 12814.032995478674 Test RE 1.2612386509114204\n",
      "8 Train Loss 12418.565 Test MSE 12571.86692445438 Test RE 1.2492640428171071\n",
      "9 Train Loss 12060.978 Test MSE 12238.0189793372 Test RE 1.2325652333734352\n",
      "10 Train Loss 11797.715 Test MSE 12168.501324089808 Test RE 1.2290594750190056\n",
      "11 Train Loss 11477.125 Test MSE 11690.006226581225 Test RE 1.2046523262015847\n",
      "12 Train Loss 11283.211 Test MSE 10931.134351230658 Test RE 1.1648955022035268\n",
      "13 Train Loss 10980.719 Test MSE 10577.458768108692 Test RE 1.1458955236521295\n",
      "14 Train Loss 10858.144 Test MSE 10430.004107296994 Test RE 1.1378803353213824\n",
      "15 Train Loss 10769.827 Test MSE 10360.49266079838 Test RE 1.1340822575425773\n",
      "16 Train Loss 10681.705 Test MSE 10088.672874756792 Test RE 1.11910638214177\n",
      "17 Train Loss 10590.775 Test MSE 9643.21611076755 Test RE 1.0941208701454905\n",
      "18 Train Loss 10527.057 Test MSE 9575.400829109194 Test RE 1.090266916071855\n",
      "19 Train Loss 10468.396 Test MSE 9548.140549011627 Test RE 1.0887138654252355\n",
      "20 Train Loss 10406.469 Test MSE 9284.135016556695 Test RE 1.0735569212225597\n",
      "21 Train Loss 10372.003 Test MSE 9196.632579469222 Test RE 1.0684858382353966\n",
      "22 Train Loss 10325.391 Test MSE 9013.407221023286 Test RE 1.0577885183420943\n",
      "23 Train Loss 10242.496 Test MSE 8920.671349019574 Test RE 1.0523328365459197\n",
      "24 Train Loss 10200.88 Test MSE 8920.151741105366 Test RE 1.0523021881557062\n",
      "25 Train Loss 10148.29 Test MSE 8791.82316476466 Test RE 1.0447053637790862\n",
      "26 Train Loss 10088.333 Test MSE 8674.005775241028 Test RE 1.0376818147336597\n",
      "27 Train Loss 10038.297 Test MSE 8654.33595494729 Test RE 1.0365045847508012\n",
      "28 Train Loss 10006.162 Test MSE 8472.326143361199 Test RE 1.0255472754429138\n",
      "29 Train Loss 9984.587 Test MSE 8383.622546646347 Test RE 1.0201645096059184\n",
      "30 Train Loss 9970.877 Test MSE 8327.733138569363 Test RE 1.0167583606974304\n",
      "31 Train Loss 9944.444 Test MSE 8380.083361929388 Test RE 1.0199491533112994\n",
      "32 Train Loss 9925.991 Test MSE 8332.076224592545 Test RE 1.0170234564539844\n",
      "33 Train Loss 9877.088 Test MSE 8159.305097554514 Test RE 1.0064238934057332\n",
      "34 Train Loss 9782.188 Test MSE 7868.998377948437 Test RE 0.9883575410791074\n",
      "35 Train Loss 9729.554 Test MSE 7781.584689862037 Test RE 0.9828525675993545\n",
      "36 Train Loss 9677.389 Test MSE 7748.003093510646 Test RE 0.9807295138883049\n",
      "37 Train Loss 9631.744 Test MSE 7672.107296409833 Test RE 0.9759143102909609\n",
      "38 Train Loss 9594.582 Test MSE 7556.9220319135475 Test RE 0.9685606549242343\n",
      "39 Train Loss 9571.409 Test MSE 7543.992689745209 Test RE 0.9677317319133792\n",
      "40 Train Loss 9544.812 Test MSE 7490.764091321764 Test RE 0.9643116472083807\n",
      "41 Train Loss 9501.324 Test MSE 7407.1769472072765 Test RE 0.9589163245132489\n",
      "42 Train Loss 9439.421 Test MSE 7390.034477714433 Test RE 0.9578060691671267\n",
      "43 Train Loss 9376.826 Test MSE 7320.40689452996 Test RE 0.9532832519182136\n",
      "44 Train Loss 9286.454 Test MSE 7313.995503041881 Test RE 0.9528657060745678\n",
      "45 Train Loss 9171.767 Test MSE 7369.691144173435 Test RE 0.9564868333458177\n",
      "46 Train Loss 9111.039 Test MSE 7358.5640301979065 Test RE 0.9557644856827388\n",
      "47 Train Loss 9077.441 Test MSE 7330.240649937789 Test RE 0.9539233261899079\n",
      "48 Train Loss 9045.284 Test MSE 7272.9857398474705 Test RE 0.950190579517112\n",
      "49 Train Loss 9007.307 Test MSE 7213.2863865386 Test RE 0.9462827862205531\n",
      "50 Train Loss 8967.618 Test MSE 7012.776882219668 Test RE 0.933038067635299\n",
      "51 Train Loss 8925.516 Test MSE 6935.729739727776 Test RE 0.9278984159153021\n",
      "52 Train Loss 8896.364 Test MSE 6893.09037907465 Test RE 0.9250417596163086\n",
      "53 Train Loss 8854.268 Test MSE 6759.883388978006 Test RE 0.9160600727550208\n",
      "54 Train Loss 8811.024 Test MSE 6726.212253043398 Test RE 0.9137757664245281\n",
      "55 Train Loss 8776.64 Test MSE 6660.68909591087 Test RE 0.9093141170392693\n",
      "56 Train Loss 8689.428 Test MSE 6552.964490156253 Test RE 0.9019308867005553\n",
      "57 Train Loss 8361.375 Test MSE 6346.218194161341 Test RE 0.8875888792893283\n",
      "58 Train Loss 7786.225 Test MSE 5987.287511842496 Test RE 0.862123352691917\n",
      "59 Train Loss 7665.327 Test MSE 5962.234536126431 Test RE 0.8603177439732607\n",
      "60 Train Loss 7545.356 Test MSE 5852.288221052089 Test RE 0.8523485088073374\n",
      "61 Train Loss 7486.691 Test MSE 5820.565596189903 Test RE 0.8500352706495639\n",
      "62 Train Loss 7413.652 Test MSE 5770.131078206674 Test RE 0.8463445303531955\n",
      "63 Train Loss 7336.0654 Test MSE 5795.998534682705 Test RE 0.8482394872056609\n",
      "64 Train Loss 7223.724 Test MSE 5684.757751704747 Test RE 0.8400600534507687\n",
      "65 Train Loss 7169.4077 Test MSE 5676.11306069658 Test RE 0.8394210796524122\n",
      "66 Train Loss 7121.5996 Test MSE 5576.316189650819 Test RE 0.832009045629021\n",
      "67 Train Loss 7082.668 Test MSE 5542.827441016509 Test RE 0.8295069546534711\n",
      "68 Train Loss 7060.1904 Test MSE 5554.04567516317 Test RE 0.8303459578205675\n",
      "69 Train Loss 7036.6006 Test MSE 5518.215471920051 Test RE 0.8276632644596268\n",
      "70 Train Loss 7016.562 Test MSE 5501.937064260436 Test RE 0.8264415841046445\n",
      "71 Train Loss 7000.3667 Test MSE 5468.048489019239 Test RE 0.8238924648395523\n",
      "72 Train Loss 6980.022 Test MSE 5425.963609157309 Test RE 0.8207157931704975\n",
      "73 Train Loss 6963.345 Test MSE 5375.810027612873 Test RE 0.8169139434944507\n",
      "74 Train Loss 6946.4233 Test MSE 5285.397606821287 Test RE 0.8100152292574412\n",
      "75 Train Loss 6923.76 Test MSE 5146.579213739463 Test RE 0.7993071229474495\n",
      "76 Train Loss 6900.7305 Test MSE 5083.003715357858 Test RE 0.7943548763642336\n",
      "77 Train Loss 6880.5293 Test MSE 4981.409615296538 Test RE 0.7863764150819772\n",
      "78 Train Loss 6853.0713 Test MSE 4942.03317390509 Test RE 0.7832622223357235\n",
      "79 Train Loss 6828.0176 Test MSE 4844.838029932628 Test RE 0.7755217521918957\n",
      "80 Train Loss 6784.548 Test MSE 4748.720268338307 Test RE 0.7677903441829832\n",
      "81 Train Loss 6702.1094 Test MSE 4775.996932101025 Test RE 0.7699922817705845\n",
      "82 Train Loss 6621.125 Test MSE 4920.776544198993 Test RE 0.7815759268142496\n",
      "83 Train Loss 6546.4097 Test MSE 4929.476646284402 Test RE 0.7822665482413759\n",
      "84 Train Loss 6482.1636 Test MSE 4918.38860876988 Test RE 0.7813862637287086\n",
      "85 Train Loss 6443.1177 Test MSE 4877.660742250988 Test RE 0.7781443125427492\n",
      "86 Train Loss 6404.5967 Test MSE 4866.745383504239 Test RE 0.7772731488874562\n",
      "87 Train Loss 6374.0894 Test MSE 4812.242178465828 Test RE 0.7729085116701485\n",
      "88 Train Loss 6346.2847 Test MSE 4723.113982700657 Test RE 0.7657174874231841\n",
      "89 Train Loss 6318.425 Test MSE 4682.741737105817 Test RE 0.7624378630532812\n",
      "90 Train Loss 6274.4736 Test MSE 4667.394943207496 Test RE 0.7611874653082814\n",
      "91 Train Loss 6251.225 Test MSE 4662.528790564286 Test RE 0.7607905607831437\n",
      "92 Train Loss 6222.201 Test MSE 4688.138626797768 Test RE 0.7628770937835038\n",
      "93 Train Loss 6194.3525 Test MSE 4723.1523497522785 Test RE 0.7657205974754521\n",
      "94 Train Loss 6164.9575 Test MSE 4705.001603171743 Test RE 0.7642478756731884\n",
      "95 Train Loss 6134.7534 Test MSE 4614.794616590819 Test RE 0.7568861198680573\n",
      "96 Train Loss 6092.5635 Test MSE 4578.384149641884 Test RE 0.7538943126746042\n",
      "97 Train Loss 6049.2495 Test MSE 4532.865695732406 Test RE 0.7501373296410405\n",
      "98 Train Loss 6028.0645 Test MSE 4543.9616252688875 Test RE 0.7510548930559698\n",
      "99 Train Loss 6007.1807 Test MSE 4515.894564104986 Test RE 0.7487317488729072\n",
      "100 Train Loss 5974.6157 Test MSE 4429.5235968806255 Test RE 0.7415370623656011\n",
      "101 Train Loss 5951.3643 Test MSE 4390.075227841276 Test RE 0.7382276942564104\n",
      "102 Train Loss 5939.7095 Test MSE 4346.92899792143 Test RE 0.7345910379470982\n",
      "103 Train Loss 5915.2393 Test MSE 4351.2912993473465 Test RE 0.7349595399374693\n",
      "104 Train Loss 5873.9224 Test MSE 4283.184587570401 Test RE 0.7291850363632127\n",
      "105 Train Loss 5851.7007 Test MSE 4296.859228951252 Test RE 0.7303481193024302\n",
      "106 Train Loss 5842.4663 Test MSE 4291.917031988875 Test RE 0.7299279795480511\n",
      "107 Train Loss 5832.346 Test MSE 4280.219066834599 Test RE 0.7289325620972773\n",
      "108 Train Loss 5811.311 Test MSE 4250.551286331418 Test RE 0.7264019187496555\n",
      "109 Train Loss 5796.154 Test MSE 4201.701623473792 Test RE 0.72221575226067\n",
      "110 Train Loss 5770.4585 Test MSE 4138.136209057541 Test RE 0.7167319146216806\n",
      "111 Train Loss 5742.696 Test MSE 4028.383274987702 Test RE 0.7071633499115827\n",
      "112 Train Loss 5727.432 Test MSE 3984.2123300993726 Test RE 0.7032756647975312\n",
      "113 Train Loss 5714.2964 Test MSE 3943.522149324108 Test RE 0.6996752224930024\n",
      "114 Train Loss 5699.4683 Test MSE 3889.6963721507445 Test RE 0.6948838260519459\n",
      "115 Train Loss 5692.811 Test MSE 3883.9376192349987 Test RE 0.6943692426366139\n",
      "116 Train Loss 5685.1377 Test MSE 3881.971456889181 Test RE 0.6941934654205547\n",
      "117 Train Loss 5671.2363 Test MSE 3853.484182630971 Test RE 0.6916416571684715\n",
      "118 Train Loss 5627.5464 Test MSE 3806.6448014533607 Test RE 0.6874253281659146\n",
      "119 Train Loss 5600.481 Test MSE 3808.40085291344 Test RE 0.6875838687085118\n",
      "120 Train Loss 5591.3423 Test MSE 3812.2080671470367 Test RE 0.6879274676728501\n",
      "121 Train Loss 5573.3213 Test MSE 3760.9589725703136 Test RE 0.6832877744098319\n",
      "122 Train Loss 5541.4253 Test MSE 3672.7545933650495 Test RE 0.6752277893995497\n",
      "123 Train Loss 5527.696 Test MSE 3648.2448401863753 Test RE 0.6729709860686508\n",
      "124 Train Loss 5522.1606 Test MSE 3650.454140426031 Test RE 0.6731747237563779\n",
      "125 Train Loss 5513.819 Test MSE 3628.2061046276212 Test RE 0.6711202253321609\n",
      "126 Train Loss 5499.925 Test MSE 3610.314236621763 Test RE 0.6694634238584537\n",
      "127 Train Loss 5489.116 Test MSE 3609.2098180709563 Test RE 0.6693610194236956\n",
      "128 Train Loss 5464.1797 Test MSE 3586.5914295010543 Test RE 0.6672603294050424\n",
      "129 Train Loss 5444.373 Test MSE 3563.6757566258416 Test RE 0.6651252629812514\n",
      "130 Train Loss 5423.4146 Test MSE 3564.431574285488 Test RE 0.6651957922327538\n",
      "131 Train Loss 5411.7505 Test MSE 3543.59541075688 Test RE 0.6632487156020446\n",
      "132 Train Loss 5406.2485 Test MSE 3516.216437012083 Test RE 0.6606815092839632\n",
      "133 Train Loss 5400.593 Test MSE 3503.9228962362686 Test RE 0.6595255470621199\n",
      "134 Train Loss 5393.3413 Test MSE 3491.719365890774 Test RE 0.6583760411513616\n",
      "135 Train Loss 5367.992 Test MSE 3468.3490280735195 Test RE 0.6561690621394752\n",
      "136 Train Loss 5348.0703 Test MSE 3428.7205576105407 Test RE 0.6524096827760242\n",
      "137 Train Loss 5337.629 Test MSE 3393.0508300329693 Test RE 0.6490072304348887\n",
      "138 Train Loss 5319.5073 Test MSE 3348.1344666265345 Test RE 0.6446972210170647\n",
      "139 Train Loss 5300.5493 Test MSE 3346.287295585186 Test RE 0.6445193562471514\n",
      "140 Train Loss 5289.617 Test MSE 3338.720787449708 Test RE 0.6437902615172109\n",
      "141 Train Loss 5262.5854 Test MSE 3455.5114407385736 Test RE 0.6549535793926063\n",
      "142 Train Loss 5234.5103 Test MSE 3549.995038562098 Test RE 0.6638473491618097\n",
      "143 Train Loss 5213.988 Test MSE 3601.167848805698 Test RE 0.6686148751255051\n",
      "144 Train Loss 5199.548 Test MSE 3588.9802196172127 Test RE 0.6674825012908401\n",
      "145 Train Loss 5188.0005 Test MSE 3588.303115017522 Test RE 0.6674195339905332\n",
      "146 Train Loss 5174.6553 Test MSE 3578.445397072922 Test RE 0.6665021423837812\n",
      "147 Train Loss 5143.9067 Test MSE 3531.325969756587 Test RE 0.6620994947821899\n",
      "148 Train Loss 5132.222 Test MSE 3495.509028245584 Test RE 0.6587332213861361\n",
      "149 Train Loss 5079.1494 Test MSE 3502.676788248117 Test RE 0.6594082623560736\n",
      "150 Train Loss 5041.6943 Test MSE 3473.8289258826608 Test RE 0.6566872222503903\n",
      "151 Train Loss 5004.884 Test MSE 3462.282542927381 Test RE 0.655594958726924\n",
      "152 Train Loss 4991.069 Test MSE 3448.7120693158345 Test RE 0.6543088896630189\n",
      "153 Train Loss 4970.8936 Test MSE 3454.7603363276094 Test RE 0.6548823938002195\n",
      "154 Train Loss 4925.099 Test MSE 3464.027488544058 Test RE 0.6557601436062922\n",
      "155 Train Loss 4905.501 Test MSE 3491.8367258493736 Test RE 0.6583871053761166\n",
      "156 Train Loss 4877.425 Test MSE 3500.266380530037 Test RE 0.6591813335808028\n",
      "157 Train Loss 4835.5596 Test MSE 3463.2915636656357 Test RE 0.6556904825196554\n",
      "158 Train Loss 4814.4077 Test MSE 3451.877299255991 Test RE 0.6546090833388042\n",
      "159 Train Loss 4797.9478 Test MSE 3477.0165642828315 Test RE 0.6569884462692842\n",
      "160 Train Loss 4783.3486 Test MSE 3461.7584800138466 Test RE 0.6555453403029524\n",
      "161 Train Loss 4755.2754 Test MSE 3414.0774118766544 Test RE 0.6510150587947491\n",
      "162 Train Loss 4735.1963 Test MSE 3429.8386768107534 Test RE 0.6525160507811234\n",
      "163 Train Loss 4717.296 Test MSE 3431.524022699523 Test RE 0.6526763469767283\n",
      "164 Train Loss 4693.735 Test MSE 3439.981807841993 Test RE 0.6534801879244884\n",
      "165 Train Loss 4681.4937 Test MSE 3445.1140690824427 Test RE 0.653967484257315\n",
      "166 Train Loss 4671.551 Test MSE 3441.7223180428105 Test RE 0.6536454860515271\n",
      "167 Train Loss 4661.595 Test MSE 3446.126349273546 Test RE 0.6540635550542402\n",
      "168 Train Loss 4652.876 Test MSE 3457.9948941180332 Test RE 0.6551888925388496\n",
      "169 Train Loss 4643.7783 Test MSE 3460.061933653315 Test RE 0.655384685051594\n",
      "170 Train Loss 4635.179 Test MSE 3462.889741741714 Test RE 0.6556524437855552\n",
      "171 Train Loss 4619.9214 Test MSE 3458.220840432735 Test RE 0.6552102972982711\n",
      "172 Train Loss 4602.541 Test MSE 3433.263233527799 Test RE 0.6528417250954626\n",
      "173 Train Loss 4597.9277 Test MSE 3436.984002061759 Test RE 0.6531953850128691\n",
      "174 Train Loss 4589.603 Test MSE 3470.029320576676 Test RE 0.6563279882512913\n",
      "175 Train Loss 4570.1904 Test MSE 3492.827101244518 Test RE 0.6584804665800891\n",
      "176 Train Loss 4559.6157 Test MSE 3536.6465108049906 Test RE 0.6625980895979074\n",
      "177 Train Loss 4550.783 Test MSE 3516.1674363294474 Test RE 0.660676905762205\n",
      "178 Train Loss 4536.1504 Test MSE 3504.2647970584094 Test RE 0.6595577234017563\n",
      "179 Train Loss 4501.471 Test MSE 3640.6086860248556 Test RE 0.6722663181657567\n",
      "180 Train Loss 4487.0737 Test MSE 3710.7378870767416 Test RE 0.6787103805692523\n",
      "181 Train Loss 4475.5825 Test MSE 3701.5810777144907 Test RE 0.6778724528446128\n",
      "182 Train Loss 4471.4453 Test MSE 3713.383888271989 Test RE 0.6789523201111621\n",
      "183 Train Loss 4455.495 Test MSE 3960.641776819709 Test RE 0.7011922936467112\n",
      "184 Train Loss 4408.476 Test MSE 4140.453753592159 Test RE 0.7169325877684412\n",
      "185 Train Loss 4304.578 Test MSE 4131.420463404047 Test RE 0.7161500894369417\n",
      "186 Train Loss 4264.004 Test MSE 4214.515130934104 Test RE 0.7233161483808577\n",
      "187 Train Loss 4252.4565 Test MSE 4252.551757562881 Test RE 0.7265728348387474\n",
      "188 Train Loss 4244.0415 Test MSE 4226.08258525097 Test RE 0.7243081003604989\n",
      "189 Train Loss 4237.1445 Test MSE 4244.24205945392 Test RE 0.7258626079462203\n",
      "190 Train Loss 4220.0747 Test MSE 4205.041138152462 Test RE 0.7225027039861074\n",
      "191 Train Loss 4200.098 Test MSE 4201.257749704464 Test RE 0.7221776033005775\n",
      "192 Train Loss 4189.3364 Test MSE 4161.599002484638 Test RE 0.7187609395686186\n",
      "193 Train Loss 4180.9556 Test MSE 4138.0045010481 Test RE 0.7167205085103115\n",
      "194 Train Loss 4174.7695 Test MSE 4123.570534453359 Test RE 0.7154694034224531\n",
      "195 Train Loss 4169.821 Test MSE 4113.338749897827 Test RE 0.7145812076869138\n",
      "196 Train Loss 4160.264 Test MSE 4079.700524805104 Test RE 0.7116533442002752\n",
      "197 Train Loss 4150.5835 Test MSE 4042.045662989515 Test RE 0.7083615181860953\n",
      "198 Train Loss 4141.6865 Test MSE 4022.1947050385775 Test RE 0.7066199542581901\n",
      "199 Train Loss 4127.896 Test MSE 3999.9082390199596 Test RE 0.7046595895942089\n",
      "Training time: 34.23\n",
      "Training time: 34.23\n",
      "1D_FODE_atanh_medium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 16303.207 Test MSE 9228.311282592304 Test RE 1.0703245083715691\n",
      "1 Train Loss 13502.402 Test MSE 12295.344693316538 Test RE 1.23544867109095\n",
      "2 Train Loss 12870.657 Test MSE 13007.051726602016 Test RE 1.270702212286751\n",
      "3 Train Loss 12443.924 Test MSE 12894.911613976416 Test RE 1.2652126841196751\n",
      "4 Train Loss 11808.389 Test MSE 12681.219375644409 Test RE 1.2546854454634107\n",
      "5 Train Loss 11204.287 Test MSE 12777.746537613564 Test RE 1.2594516128724786\n",
      "6 Train Loss 10710.578 Test MSE 12645.946837666866 Test RE 1.2529392901520764\n",
      "7 Train Loss 10227.947 Test MSE 12432.024834724094 Test RE 1.2422965720905093\n",
      "8 Train Loss 9826.666 Test MSE 11669.846283988018 Test RE 1.2036131393626888\n",
      "9 Train Loss 9472.321 Test MSE 11559.020260818232 Test RE 1.1978842777655538\n",
      "10 Train Loss 9175.129 Test MSE 11046.71136548887 Test RE 1.171037642987136\n",
      "11 Train Loss 8898.408 Test MSE 10738.549360532696 Test RE 1.1545883238004706\n",
      "12 Train Loss 8494.454 Test MSE 10827.573530514868 Test RE 1.1593643002320086\n",
      "13 Train Loss 8331.584 Test MSE 10494.936214427551 Test RE 1.1414167831842432\n",
      "14 Train Loss 8201.691 Test MSE 10337.19040962149 Test RE 1.1328061818493795\n",
      "15 Train Loss 8027.9824 Test MSE 9973.17016644959 Test RE 1.1126817553046553\n",
      "16 Train Loss 7832.431 Test MSE 9914.847978134982 Test RE 1.1094235542610584\n",
      "17 Train Loss 7635.6577 Test MSE 9477.352126050037 Test RE 1.084670580121504\n",
      "18 Train Loss 7470.6465 Test MSE 9367.931558597758 Test RE 1.0783908814087169\n",
      "19 Train Loss 7360.3013 Test MSE 9106.257852830264 Test RE 1.0632229053130493\n",
      "20 Train Loss 7265.9414 Test MSE 8902.607901356703 Test RE 1.051266863435479\n",
      "21 Train Loss 7141.2554 Test MSE 8560.629955502236 Test RE 1.0308778651068562\n",
      "22 Train Loss 7050.0654 Test MSE 8342.760217691693 Test RE 1.0176752982204726\n",
      "23 Train Loss 6983.3726 Test MSE 8226.852719316132 Test RE 1.010581197310623\n",
      "24 Train Loss 6826.762 Test MSE 7929.35771256977 Test RE 0.992140909559218\n",
      "25 Train Loss 6757.076 Test MSE 7804.019830368501 Test RE 0.9842683823568121\n",
      "26 Train Loss 6634.383 Test MSE 7726.256848405316 Test RE 0.9793522448119122\n",
      "27 Train Loss 6548.535 Test MSE 7574.708773018967 Test RE 0.9696998364806961\n",
      "28 Train Loss 6433.9604 Test MSE 7427.088605087912 Test RE 0.9602043185414509\n",
      "29 Train Loss 6358.285 Test MSE 7311.970162480635 Test RE 0.9527337664812437\n",
      "30 Train Loss 6252.5835 Test MSE 7233.791245055632 Test RE 0.9476268077872957\n",
      "31 Train Loss 6215.8325 Test MSE 7190.627615001324 Test RE 0.9447953594639472\n",
      "32 Train Loss 6175.7856 Test MSE 7155.786725646302 Test RE 0.942503662326596\n",
      "33 Train Loss 6129.869 Test MSE 7042.480162247074 Test RE 0.9350119651957719\n",
      "34 Train Loss 6066.4844 Test MSE 7019.70058697128 Test RE 0.933498547591416\n",
      "35 Train Loss 6023.4834 Test MSE 7013.570178388637 Test RE 0.9330908394976957\n",
      "36 Train Loss 5979.4424 Test MSE 6948.354538606223 Test RE 0.9287425379692862\n",
      "37 Train Loss 5909.467 Test MSE 6859.214557618761 Test RE 0.9227659193749377\n",
      "38 Train Loss 5882.3975 Test MSE 6899.25646414604 Test RE 0.9254554065340773\n",
      "39 Train Loss 5849.367 Test MSE 6899.468313651103 Test RE 0.9254696150046445\n",
      "40 Train Loss 5809.5415 Test MSE 6694.073058101017 Test RE 0.9115900501534183\n",
      "41 Train Loss 5753.4736 Test MSE 6584.869665760015 Test RE 0.9041238881883858\n",
      "42 Train Loss 5718.8037 Test MSE 6422.220007182075 Test RE 0.8928879088347434\n",
      "43 Train Loss 5690.7817 Test MSE 6294.409806921167 Test RE 0.883958466451578\n",
      "44 Train Loss 5656.3223 Test MSE 6178.626698673435 Test RE 0.8757907032182852\n",
      "45 Train Loss 5636.2686 Test MSE 6114.255403964345 Test RE 0.8712165971716084\n",
      "46 Train Loss 5615.7534 Test MSE 6041.354601529004 Test RE 0.8660072267855133\n",
      "47 Train Loss 5567.093 Test MSE 5973.483096470076 Test RE 0.8611289143406424\n",
      "48 Train Loss 5507.275 Test MSE 5947.9566375972645 Test RE 0.8592870153003876\n",
      "49 Train Loss 5439.9736 Test MSE 5896.396641260941 Test RE 0.8555545344794855\n",
      "50 Train Loss 5412.639 Test MSE 5899.486119843462 Test RE 0.8557786434927174\n",
      "51 Train Loss 5387.8613 Test MSE 5869.508825627219 Test RE 0.8536016233419473\n",
      "52 Train Loss 5352.3774 Test MSE 5842.873316610777 Test RE 0.8516626224040212\n",
      "53 Train Loss 5333.4297 Test MSE 5858.442662066529 Test RE 0.8527965686094696\n",
      "54 Train Loss 5322.022 Test MSE 5838.531140565714 Test RE 0.8513461037877045\n",
      "55 Train Loss 5301.9062 Test MSE 5808.1526814481285 Test RE 0.8491283959953304\n",
      "56 Train Loss 5290.3496 Test MSE 5806.503823851493 Test RE 0.84900785928908\n",
      "57 Train Loss 5282.972 Test MSE 5810.725874494025 Test RE 0.8493164703672031\n",
      "58 Train Loss 5259.7295 Test MSE 5729.914063523544 Test RE 0.8433899209505663\n",
      "59 Train Loss 5249.605 Test MSE 5726.827118653069 Test RE 0.8431627055936425\n",
      "60 Train Loss 5237.803 Test MSE 5725.068100091286 Test RE 0.8430332051979992\n",
      "61 Train Loss 5222.64 Test MSE 5716.396879569038 Test RE 0.842394531841626\n",
      "62 Train Loss 5210.8394 Test MSE 5707.465664146921 Test RE 0.841736202111871\n",
      "63 Train Loss 5205.3184 Test MSE 5724.737432082708 Test RE 0.8430088589254676\n",
      "64 Train Loss 5185.0903 Test MSE 5640.74655003775 Test RE 0.836801876806451\n",
      "65 Train Loss 5154.159 Test MSE 5582.852997677213 Test RE 0.8324965619649787\n",
      "66 Train Loss 5138.2935 Test MSE 5537.520533129717 Test RE 0.8291097592474475\n",
      "67 Train Loss 5122.3955 Test MSE 5507.64911660618 Test RE 0.8268704742328222\n",
      "68 Train Loss 5098.43 Test MSE 5437.764185320014 Test RE 0.8216077692198429\n",
      "69 Train Loss 5072.013 Test MSE 5388.011948676004 Test RE 0.8178405266102846\n",
      "70 Train Loss 5056.306 Test MSE 5381.793175989902 Test RE 0.8173684199443406\n",
      "71 Train Loss 5036.5586 Test MSE 5359.751577721242 Test RE 0.8156929011849343\n",
      "72 Train Loss 5020.063 Test MSE 5367.531198738285 Test RE 0.8162846712051455\n",
      "73 Train Loss 5007.372 Test MSE 5363.14741321874 Test RE 0.815951263933609\n",
      "74 Train Loss 4992.82 Test MSE 5344.494507086473 Test RE 0.8145310979555984\n",
      "75 Train Loss 4972.972 Test MSE 5299.444829459411 Test RE 0.8110909207083203\n",
      "76 Train Loss 4950.8823 Test MSE 5238.890138777012 Test RE 0.8064435968563145\n",
      "77 Train Loss 4940.813 Test MSE 5162.827981880142 Test RE 0.8005679139017159\n",
      "78 Train Loss 4922.4746 Test MSE 5107.7271199009965 Test RE 0.7962843785895718\n",
      "79 Train Loss 4912.143 Test MSE 5080.753161325798 Test RE 0.7941790023536187\n",
      "80 Train Loss 4902.8384 Test MSE 5078.7645657378325 Test RE 0.7940235671874187\n",
      "81 Train Loss 4892.838 Test MSE 5060.6381386098665 Test RE 0.7926053408333723\n",
      "82 Train Loss 4886.3994 Test MSE 5019.2335178634685 Test RE 0.7893562520395123\n",
      "83 Train Loss 4871.8154 Test MSE 4954.745384584187 Test RE 0.7842689537007487\n",
      "84 Train Loss 4854.884 Test MSE 4901.6250703036685 Test RE 0.7800535122849331\n",
      "85 Train Loss 4832.7246 Test MSE 4859.551070951981 Test RE 0.7766984307086273\n",
      "86 Train Loss 4820.0874 Test MSE 4823.755146168298 Test RE 0.7738325253118137\n",
      "87 Train Loss 4808.7954 Test MSE 4814.060784575842 Test RE 0.7730545437394852\n",
      "88 Train Loss 4799.007 Test MSE 4817.833004773465 Test RE 0.7733573609513431\n",
      "89 Train Loss 4787.5947 Test MSE 4803.2582076056915 Test RE 0.7721867035030584\n",
      "90 Train Loss 4773.0127 Test MSE 4814.51469433485 Test RE 0.7730909878919761\n",
      "91 Train Loss 4753.8916 Test MSE 4775.271624207201 Test RE 0.7699338120214221\n",
      "92 Train Loss 4739.6777 Test MSE 4785.183981722944 Test RE 0.7707324998679814\n",
      "93 Train Loss 4724.3853 Test MSE 4747.417961733006 Test RE 0.7676850561323535\n",
      "94 Train Loss 4704.9863 Test MSE 4710.889512123647 Test RE 0.7647259217380167\n",
      "95 Train Loss 4669.468 Test MSE 4717.058756201795 Test RE 0.7652264893373297\n",
      "96 Train Loss 4636.3755 Test MSE 4651.817758426243 Test RE 0.7599161921839743\n",
      "97 Train Loss 4624.859 Test MSE 4614.265658782734 Test RE 0.7568427406573434\n",
      "98 Train Loss 4598.569 Test MSE 4555.221500470457 Test RE 0.7519848692082902\n",
      "99 Train Loss 4578.9507 Test MSE 4494.734759059065 Test RE 0.7469755497583692\n",
      "100 Train Loss 4561.9175 Test MSE 4467.4628677010905 Test RE 0.7447059574176595\n",
      "101 Train Loss 4516.7217 Test MSE 4490.142807047577 Test RE 0.7465938862591501\n",
      "102 Train Loss 4495.794 Test MSE 4472.881634802406 Test RE 0.7451574625931587\n",
      "103 Train Loss 4462.207 Test MSE 4485.8543646413655 Test RE 0.7462372729107292\n",
      "104 Train Loss 4441.788 Test MSE 4454.527487988916 Test RE 0.7436270410647453\n",
      "105 Train Loss 4421.602 Test MSE 4427.796655353639 Test RE 0.7413924964817796\n",
      "106 Train Loss 4397.479 Test MSE 4397.678098469843 Test RE 0.7388666607232407\n",
      "107 Train Loss 4377.4233 Test MSE 4349.542481176847 Test RE 0.7348118320871257\n",
      "108 Train Loss 4358.903 Test MSE 4329.057808974106 Test RE 0.7330794494097944\n",
      "109 Train Loss 4343.528 Test MSE 4276.226923438506 Test RE 0.7285925465370584\n",
      "110 Train Loss 4323.2886 Test MSE 4204.3093425836205 Test RE 0.7224398333428591\n",
      "111 Train Loss 4294.641 Test MSE 4163.70185182005 Test RE 0.7189425110125038\n",
      "112 Train Loss 4280.296 Test MSE 4157.286762901229 Test RE 0.7183884538119616\n",
      "113 Train Loss 4252.3857 Test MSE 4131.150987817192 Test RE 0.7161267332917194\n",
      "114 Train Loss 4237.3354 Test MSE 4107.650445474895 Test RE 0.714086942329291\n",
      "115 Train Loss 4227.5073 Test MSE 4101.344253618903 Test RE 0.7135385876190853\n",
      "116 Train Loss 4213.4863 Test MSE 4085.5190140940904 Test RE 0.7121606451649862\n",
      "117 Train Loss 4208.813 Test MSE 4083.895266840469 Test RE 0.7120191106613791\n",
      "118 Train Loss 4202.233 Test MSE 4083.3122651265576 Test RE 0.7119682862461312\n",
      "119 Train Loss 4197.4453 Test MSE 4075.356531904206 Test RE 0.7112743653492226\n",
      "120 Train Loss 4187.842 Test MSE 4089.0030944931736 Test RE 0.7124642413754266\n",
      "121 Train Loss 4176.488 Test MSE 4053.5394810706794 Test RE 0.7093679391175185\n",
      "122 Train Loss 4163.458 Test MSE 3999.2277151916505 Test RE 0.7045996434640526\n",
      "123 Train Loss 4146.6406 Test MSE 4001.0285897897647 Test RE 0.7047582681879454\n",
      "124 Train Loss 4141.679 Test MSE 3996.7307923421354 Test RE 0.7043796502840289\n",
      "125 Train Loss 4136.576 Test MSE 3991.7698385089598 Test RE 0.7039423578895451\n",
      "126 Train Loss 4129.7437 Test MSE 4004.4223950367095 Test RE 0.7050571045079183\n",
      "127 Train Loss 4117.7896 Test MSE 3997.464774926941 Test RE 0.7044443254759695\n",
      "128 Train Loss 4107.9536 Test MSE 4019.7741388344793 Test RE 0.7064072994867187\n",
      "129 Train Loss 4103.6367 Test MSE 4010.8967064664116 Test RE 0.7056268390720505\n",
      "130 Train Loss 4097.614 Test MSE 4029.291691986676 Test RE 0.7072430795391318\n",
      "131 Train Loss 4094.831 Test MSE 4031.880742171239 Test RE 0.7074702650987021\n",
      "132 Train Loss 4090.7256 Test MSE 4015.42548522623 Test RE 0.7060250949388818\n",
      "133 Train Loss 4086.4302 Test MSE 4015.638724432385 Test RE 0.7060438414244794\n",
      "134 Train Loss 4083.1318 Test MSE 4011.9284580749504 Test RE 0.7057175899522581\n",
      "135 Train Loss 4072.5369 Test MSE 3987.9335423863477 Test RE 0.7036040141727551\n",
      "136 Train Loss 4065.6448 Test MSE 3975.7605288347595 Test RE 0.7025293313612431\n",
      "137 Train Loss 4061.4343 Test MSE 3960.2798574387775 Test RE 0.7011602557987028\n",
      "138 Train Loss 4058.2134 Test MSE 3948.163481382224 Test RE 0.7000868431159379\n",
      "139 Train Loss 4053.3674 Test MSE 3931.6106157849536 Test RE 0.6986177277562414\n",
      "140 Train Loss 4036.2126 Test MSE 3899.8953936482435 Test RE 0.6957942435701775\n",
      "141 Train Loss 4017.5886 Test MSE 3863.4592666578324 Test RE 0.6925362663458917\n",
      "142 Train Loss 4010.896 Test MSE 3853.979345515263 Test RE 0.6916860928350705\n",
      "143 Train Loss 4006.918 Test MSE 3859.5143218632466 Test RE 0.6921826046509614\n",
      "144 Train Loss 4001.2468 Test MSE 3861.924755304788 Test RE 0.692398719883831\n",
      "145 Train Loss 3994.717 Test MSE 3847.398020828772 Test RE 0.6910952547130552\n",
      "146 Train Loss 3985.3577 Test MSE 3813.7024194759992 Test RE 0.6880622852474368\n",
      "147 Train Loss 3975.6528 Test MSE 3846.66988163963 Test RE 0.691029855013462\n",
      "148 Train Loss 3967.7888 Test MSE 3851.9356896778136 Test RE 0.6915026777674159\n",
      "149 Train Loss 3961.0142 Test MSE 3839.0390139685614 Test RE 0.6903440962521463\n",
      "150 Train Loss 3951.5005 Test MSE 3815.966430793766 Test RE 0.6882664896534921\n",
      "151 Train Loss 3948.341 Test MSE 3809.9067835389274 Test RE 0.6877197986309473\n",
      "152 Train Loss 3944.346 Test MSE 3802.866069151225 Test RE 0.6870840510852009\n",
      "153 Train Loss 3937.0928 Test MSE 3775.8110850062103 Test RE 0.6846356045410912\n",
      "154 Train Loss 3922.0107 Test MSE 3754.0701587457465 Test RE 0.6826617107240395\n",
      "155 Train Loss 3913.245 Test MSE 3706.4751175031265 Test RE 0.6783204288367829\n",
      "156 Train Loss 3907.721 Test MSE 3675.7790524312422 Test RE 0.6755057522337639\n",
      "157 Train Loss 3904.83 Test MSE 3659.317030757299 Test RE 0.673991424439476\n",
      "158 Train Loss 3902.2637 Test MSE 3654.967869778228 Test RE 0.6735907801838733\n",
      "159 Train Loss 3898.991 Test MSE 3659.120724592016 Test RE 0.6739733458683458\n",
      "160 Train Loss 3895.5996 Test MSE 3641.290947155845 Test RE 0.6723293075902597\n",
      "161 Train Loss 3890.0762 Test MSE 3628.2469414208203 Test RE 0.6711240021739313\n",
      "162 Train Loss 3885.5486 Test MSE 3613.6907944916197 Test RE 0.6697764095932901\n",
      "163 Train Loss 3881.948 Test MSE 3609.068187761172 Test RE 0.6693478859757427\n",
      "164 Train Loss 3879.826 Test MSE 3611.295949693507 Test RE 0.6695544375873894\n",
      "165 Train Loss 3873.6865 Test MSE 3584.441741315615 Test RE 0.6670603321830301\n",
      "166 Train Loss 3866.835 Test MSE 3565.8729049158214 Test RE 0.6653302695185727\n",
      "167 Train Loss 3860.8853 Test MSE 3532.3799172981335 Test RE 0.6621982913930696\n",
      "168 Train Loss 3856.866 Test MSE 3508.4960718129337 Test RE 0.6599557994854978\n",
      "169 Train Loss 3851.7124 Test MSE 3479.9109979675336 Test RE 0.6572618435728801\n",
      "170 Train Loss 3844.3276 Test MSE 3447.7352751644453 Test RE 0.6542162216835306\n",
      "171 Train Loss 3840.0232 Test MSE 3431.824149773255 Test RE 0.6527048884582788\n",
      "172 Train Loss 3834.7498 Test MSE 3431.2057290655025 Test RE 0.6526460765280148\n",
      "173 Train Loss 3826.776 Test MSE 3442.5518691808306 Test RE 0.6537242547082295\n",
      "174 Train Loss 3823.9963 Test MSE 3435.8728238810377 Test RE 0.6530897873241972\n",
      "175 Train Loss 3818.2183 Test MSE 3414.9094244721778 Test RE 0.651094380331317\n",
      "176 Train Loss 3814.028 Test MSE 3398.98217116092 Test RE 0.6495742426362687\n",
      "177 Train Loss 3810.2156 Test MSE 3399.2588463828943 Test RE 0.6496006795858568\n",
      "178 Train Loss 3804.2373 Test MSE 3394.0674086980775 Test RE 0.6491044464105499\n",
      "179 Train Loss 3800.5254 Test MSE 3397.108518926853 Test RE 0.64939518256168\n",
      "180 Train Loss 3798.1475 Test MSE 3386.311044631407 Test RE 0.6483623323779562\n",
      "181 Train Loss 3795.2651 Test MSE 3380.9356985721133 Test RE 0.647847530868284\n",
      "182 Train Loss 3793.525 Test MSE 3378.664342507175 Test RE 0.6476298781569434\n",
      "183 Train Loss 3791.5464 Test MSE 3376.1311954197017 Test RE 0.6473870530066982\n",
      "184 Train Loss 3788.6992 Test MSE 3379.919431676173 Test RE 0.6477501561263451\n",
      "185 Train Loss 3786.522 Test MSE 3372.574192534056 Test RE 0.6470459281609409\n",
      "186 Train Loss 3784.9092 Test MSE 3373.531048829134 Test RE 0.647137710583809\n",
      "187 Train Loss 3782.4722 Test MSE 3367.4884748531067 Test RE 0.6465578833876491\n",
      "188 Train Loss 3779.2495 Test MSE 3352.4704407580593 Test RE 0.6451145408782472\n",
      "189 Train Loss 3776.7986 Test MSE 3354.3223414310446 Test RE 0.6452926965298782\n",
      "190 Train Loss 3772.877 Test MSE 3355.092479466834 Test RE 0.6453667704973268\n",
      "191 Train Loss 3768.3958 Test MSE 3339.9911628394298 Test RE 0.6439127302070518\n",
      "192 Train Loss 3765.7886 Test MSE 3337.983998615518 Test RE 0.6437192217869475\n",
      "193 Train Loss 3763.1199 Test MSE 3335.3381032952907 Test RE 0.6434640451100244\n",
      "194 Train Loss 3762.479 Test MSE 3333.611661792668 Test RE 0.6432974882584467\n",
      "195 Train Loss 3762.479 Test MSE 3333.611661792668 Test RE 0.6432974882584467\n",
      "196 Train Loss 3761.4146 Test MSE 3336.5061014414086 Test RE 0.6435767022084393\n",
      "197 Train Loss 3758.6318 Test MSE 3331.8324405173826 Test RE 0.6431257943938551\n",
      "198 Train Loss 3756.9211 Test MSE 3334.200498420019 Test RE 0.6433543005743295\n",
      "199 Train Loss 3756.3157 Test MSE 3336.6621561535453 Test RE 0.6435917526833391\n",
      "Training time: 34.81\n",
      "Training time: 34.81\n",
      "1D_FODE_atanh_medium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 16731.004 Test MSE 10159.492539457497 Test RE 1.1230274200841481\n",
      "1 Train Loss 14590.114 Test MSE 13605.683448985685 Test RE 1.2996144562003864\n",
      "2 Train Loss 13888.045 Test MSE 13782.594126377522 Test RE 1.308036418725725\n",
      "3 Train Loss 13509.57 Test MSE 13910.962765761804 Test RE 1.3141137105261376\n",
      "4 Train Loss 12863.905 Test MSE 13025.20458764681 Test RE 1.2715886098598803\n",
      "5 Train Loss 12346.116 Test MSE 12823.546538502367 Test RE 1.2617067557585893\n",
      "6 Train Loss 11903.636 Test MSE 12355.719512526917 Test RE 1.2384782180389335\n",
      "7 Train Loss 11498.686 Test MSE 12149.433027830743 Test RE 1.2280961165096462\n",
      "8 Train Loss 11228.809 Test MSE 11315.57523872285 Test RE 1.185202805078035\n",
      "9 Train Loss 11009.964 Test MSE 10873.910127439549 Test RE 1.1618424013515798\n",
      "10 Train Loss 10817.965 Test MSE 10469.563151730219 Test RE 1.1400361761598221\n",
      "11 Train Loss 10702.7 Test MSE 10176.994229235825 Test RE 1.1239943197543039\n",
      "12 Train Loss 10611.498 Test MSE 9924.265591499665 Test RE 1.10995032190573\n",
      "13 Train Loss 10518.166 Test MSE 9442.7933138601 Test RE 1.0826911685379224\n",
      "14 Train Loss 10381.551 Test MSE 8840.131268082405 Test RE 1.0475715837723338\n",
      "15 Train Loss 10203.11 Test MSE 8588.251945828582 Test RE 1.0325396567070981\n",
      "16 Train Loss 9862.605 Test MSE 8227.788072254958 Test RE 1.0106386447488493\n",
      "17 Train Loss 9457.2295 Test MSE 7984.537488334666 Test RE 0.9955870398378183\n",
      "18 Train Loss 9092.702 Test MSE 7710.238406952691 Test RE 0.9783364983475097\n",
      "19 Train Loss 8895.266 Test MSE 7745.739202000092 Test RE 0.9805862235848201\n",
      "20 Train Loss 8709.885 Test MSE 7660.332459257704 Test RE 0.9751651259997907\n",
      "21 Train Loss 8572.837 Test MSE 7442.952404896533 Test RE 0.9612292399242996\n",
      "22 Train Loss 8429.779 Test MSE 7127.368589146139 Test RE 0.940630294376316\n",
      "23 Train Loss 8324.416 Test MSE 6988.288127915068 Test RE 0.9314075493313466\n",
      "24 Train Loss 8254.522 Test MSE 6812.576997347048 Test RE 0.9196235075862482\n",
      "25 Train Loss 8194.005 Test MSE 6598.768191233082 Test RE 0.9050775414749596\n",
      "26 Train Loss 8141.4585 Test MSE 6530.609377380679 Test RE 0.900391126170651\n",
      "27 Train Loss 8069.7754 Test MSE 6258.842458222869 Test RE 0.881457469543196\n",
      "28 Train Loss 7984.5713 Test MSE 5886.199281740307 Test RE 0.8548144068205511\n",
      "29 Train Loss 7845.211 Test MSE 5691.070893568437 Test RE 0.8405263834975015\n",
      "30 Train Loss 7743.5825 Test MSE 5636.642625994161 Test RE 0.8364974138979091\n",
      "31 Train Loss 7662.7715 Test MSE 5594.16982351337 Test RE 0.8333398986132574\n",
      "32 Train Loss 7588.963 Test MSE 5584.738080643388 Test RE 0.8326370987692275\n",
      "33 Train Loss 7462.316 Test MSE 5557.461670895828 Test RE 0.8306012692106907\n",
      "34 Train Loss 7358.2046 Test MSE 5662.0224847999625 Test RE 0.8383785285313866\n",
      "35 Train Loss 7268.7705 Test MSE 5588.264021122305 Test RE 0.8328999012112253\n",
      "36 Train Loss 7196.609 Test MSE 5511.947569991057 Test RE 0.827193077479807\n",
      "37 Train Loss 7155.4487 Test MSE 5395.8828710983935 Test RE 0.8184376680263455\n",
      "38 Train Loss 7097.025 Test MSE 5258.136058073451 Test RE 0.8079235400879012\n",
      "39 Train Loss 7045.821 Test MSE 5058.116919643272 Test RE 0.79240787753737\n",
      "40 Train Loss 7010.3223 Test MSE 5065.095313747178 Test RE 0.7929543090056815\n",
      "41 Train Loss 6990.548 Test MSE 4965.924362951833 Test RE 0.7851531955045531\n",
      "42 Train Loss 6968.5435 Test MSE 4947.067752945417 Test RE 0.7836610856810295\n",
      "43 Train Loss 6934.94 Test MSE 4816.5287729638385 Test RE 0.7732526763825283\n",
      "44 Train Loss 6901.602 Test MSE 4763.374942899953 Test RE 0.7689741420891071\n",
      "45 Train Loss 6834.406 Test MSE 4572.256010577749 Test RE 0.7533896022765402\n",
      "46 Train Loss 6818.1514 Test MSE 4557.267052352634 Test RE 0.7521536921091964\n",
      "47 Train Loss 6797.171 Test MSE 4529.782819227159 Test RE 0.7498821958863328\n",
      "48 Train Loss 6778.616 Test MSE 4467.072876380796 Test RE 0.7446734518091346\n",
      "49 Train Loss 6738.826 Test MSE 4416.473321993989 Test RE 0.7404438973102028\n",
      "50 Train Loss 6726.066 Test MSE 4381.566761031325 Test RE 0.7375119625348354\n",
      "51 Train Loss 6707.2954 Test MSE 4347.5098414698205 Test RE 0.7346401149176164\n",
      "52 Train Loss 6672.191 Test MSE 4282.322722229061 Test RE 0.7291116691156251\n",
      "53 Train Loss 6634.418 Test MSE 4270.290154818659 Test RE 0.7280866113076829\n",
      "54 Train Loss 6602.225 Test MSE 4230.1101828588335 Test RE 0.7246531630506128\n",
      "55 Train Loss 6578.4893 Test MSE 4198.877438605836 Test RE 0.7219729918460198\n",
      "56 Train Loss 6565.229 Test MSE 4184.30470532986 Test RE 0.7207190537887307\n",
      "57 Train Loss 6546.668 Test MSE 4208.671663385282 Test RE 0.7228145318950414\n",
      "58 Train Loss 6535.7056 Test MSE 4193.078168484718 Test RE 0.7214742438892309\n",
      "59 Train Loss 6514.5537 Test MSE 4150.78759204147 Test RE 0.7178266985425841\n",
      "60 Train Loss 6484.232 Test MSE 4016.818896170966 Test RE 0.7061475847928482\n",
      "61 Train Loss 6472.0073 Test MSE 3980.853763431746 Test RE 0.7029791825831294\n",
      "62 Train Loss 6455.0444 Test MSE 3940.060755604884 Test RE 0.6993680880327094\n",
      "63 Train Loss 6444.0454 Test MSE 3923.02914145198 Test RE 0.6978548794409898\n",
      "64 Train Loss 6437.92 Test MSE 3901.985206677015 Test RE 0.6959806440993921\n",
      "65 Train Loss 6433.4136 Test MSE 3887.4144402845486 Test RE 0.6946799656440703\n",
      "66 Train Loss 6426.4062 Test MSE 3873.455465388473 Test RE 0.6934316113639956\n",
      "67 Train Loss 6421.5005 Test MSE 3873.0670922431605 Test RE 0.6933968469308781\n",
      "68 Train Loss 6413.6943 Test MSE 3860.6887823827637 Test RE 0.6922879131480983\n",
      "69 Train Loss 6407.3726 Test MSE 3879.279800948731 Test RE 0.6939527560290276\n",
      "70 Train Loss 6401.312 Test MSE 3867.014204206426 Test RE 0.6928548095136545\n",
      "71 Train Loss 6390.8394 Test MSE 3876.329812966968 Test RE 0.6936888485859991\n",
      "72 Train Loss 6378.413 Test MSE 3877.2310023207115 Test RE 0.6937694800989636\n",
      "73 Train Loss 6362.452 Test MSE 3848.152459224128 Test RE 0.691163010016098\n",
      "74 Train Loss 6358.76 Test MSE 3845.0247269963106 Test RE 0.6908820684099138\n",
      "75 Train Loss 6355.6685 Test MSE 3838.638505159388 Test RE 0.690308085143315\n",
      "76 Train Loss 6350.3574 Test MSE 3832.135959578331 Test RE 0.6897231560919656\n",
      "77 Train Loss 6340.3696 Test MSE 3825.522816037955 Test RE 0.689127769103824\n",
      "78 Train Loss 6329.568 Test MSE 3850.2006064973257 Test RE 0.6913469184420997\n",
      "79 Train Loss 6318.507 Test MSE 3855.682337504893 Test RE 0.6918388966869268\n",
      "80 Train Loss 6314.659 Test MSE 3870.5417442014314 Test RE 0.6931707530035971\n",
      "81 Train Loss 6311.76 Test MSE 3870.6778950848816 Test RE 0.6931829444469026\n",
      "82 Train Loss 6308.373 Test MSE 3881.920372384639 Test RE 0.6941888978127944\n",
      "83 Train Loss 6305.9795 Test MSE 3883.7122329048702 Test RE 0.6943490950929071\n",
      "84 Train Loss 6302.191 Test MSE 3888.3271734821433 Test RE 0.6947615134520769\n",
      "85 Train Loss 6297.659 Test MSE 3886.9615020903448 Test RE 0.6946394944954762\n",
      "86 Train Loss 6292.1206 Test MSE 3869.3509036320434 Test RE 0.6930641116843663\n",
      "87 Train Loss 6285.171 Test MSE 3854.160904011417 Test RE 0.6917023850873876\n",
      "88 Train Loss 6278.3105 Test MSE 3830.7365120223103 Test RE 0.6895972055080131\n",
      "89 Train Loss 6271.9614 Test MSE 3806.9748909738237 Test RE 0.6874551322308935\n",
      "90 Train Loss 6265.3286 Test MSE 3774.9247377864936 Test RE 0.6845552429357071\n",
      "91 Train Loss 6264.083 Test MSE 3769.6241687454753 Test RE 0.6840744642145784\n",
      "92 Train Loss 6263.3022 Test MSE 3764.9697105675923 Test RE 0.6836520110348095\n",
      "93 Train Loss 6261.639 Test MSE 3771.8649822870507 Test RE 0.6842777544525874\n",
      "94 Train Loss 6259.778 Test MSE 3784.3661608834664 Test RE 0.6854107751557892\n",
      "95 Train Loss 6258.798 Test MSE 3776.8480903817117 Test RE 0.6847296137546752\n",
      "96 Train Loss 6256.8003 Test MSE 3765.250157519181 Test RE 0.6836774726675622\n",
      "97 Train Loss 6252.3696 Test MSE 3754.305075242141 Test RE 0.6826830696733637\n",
      "98 Train Loss 6244.354 Test MSE 3705.541609561763 Test RE 0.6782350030127337\n",
      "99 Train Loss 6239.807 Test MSE 3716.8714295386135 Test RE 0.6792710749989841\n",
      "100 Train Loss 6235.274 Test MSE 3716.4526430593774 Test RE 0.6792328065841746\n",
      "101 Train Loss 6232.9 Test MSE 3729.8795034010614 Test RE 0.6804586720217789\n",
      "102 Train Loss 6229.463 Test MSE 3731.7273053637273 Test RE 0.6806272025577226\n",
      "103 Train Loss 6223.676 Test MSE 3779.161946016583 Test RE 0.6849393286875173\n",
      "104 Train Loss 6219.0303 Test MSE 3773.9727029240944 Test RE 0.68446891518113\n",
      "105 Train Loss 6216.753 Test MSE 3777.7529380121096 Test RE 0.6848116317295818\n",
      "106 Train Loss 6213.597 Test MSE 3787.5281028698905 Test RE 0.685697055144292\n",
      "107 Train Loss 6205.8457 Test MSE 3797.0402437210278 Test RE 0.6865575579243695\n",
      "108 Train Loss 6196.4976 Test MSE 3791.5876204229185 Test RE 0.6860644258517318\n",
      "109 Train Loss 6186.921 Test MSE 3785.0235018100643 Test RE 0.6854703001821236\n",
      "110 Train Loss 6179.573 Test MSE 3790.328399524501 Test RE 0.6859504922586139\n",
      "111 Train Loss 6174.881 Test MSE 3772.21851853049 Test RE 0.6843098223181485\n",
      "112 Train Loss 6173.3154 Test MSE 3766.927538048648 Test RE 0.6838297413802703\n",
      "113 Train Loss 6169.0146 Test MSE 3752.9596951481626 Test RE 0.6825607367124609\n",
      "114 Train Loss 6158.402 Test MSE 3755.1910210457354 Test RE 0.6827636151420038\n",
      "115 Train Loss 6149.4595 Test MSE 3715.1153420519636 Test RE 0.6791105905180832\n",
      "116 Train Loss 6133.5513 Test MSE 3702.8187215684384 Test RE 0.6779857685522832\n",
      "117 Train Loss 6115.958 Test MSE 3690.2252146961628 Test RE 0.6768318516045276\n",
      "118 Train Loss 6099.8022 Test MSE 3701.3687957165735 Test RE 0.6778530149100123\n",
      "119 Train Loss 6084.336 Test MSE 3715.5704457139827 Test RE 0.6791521849537341\n",
      "120 Train Loss 6077.8237 Test MSE 3743.5484723912255 Test RE 0.6817043774808572\n",
      "121 Train Loss 6073.7256 Test MSE 3742.834462034984 Test RE 0.6816393633371245\n",
      "122 Train Loss 6072.6987 Test MSE 3752.2858074770556 Test RE 0.6824994530919742\n",
      "123 Train Loss 6071.7837 Test MSE 3749.675544507695 Test RE 0.6822620227532212\n",
      "124 Train Loss 6071.5713 Test MSE 3750.153412677905 Test RE 0.6823054959702562\n",
      "125 Train Loss 6071.5713 Test MSE 3750.153412677905 Test RE 0.6823054959702562\n",
      "126 Train Loss 6071.554 Test MSE 3750.393444405529 Test RE 0.6823273313898229\n",
      "127 Train Loss 6070.322 Test MSE 3758.537106621039 Test RE 0.6830677377251652\n",
      "128 Train Loss 6068.713 Test MSE 3770.8524709808676 Test RE 0.684185905265448\n",
      "129 Train Loss 6067.549 Test MSE 3774.119969221825 Test RE 0.6844822695728638\n",
      "130 Train Loss 6064.262 Test MSE 3782.265314499782 Test RE 0.6852204998779209\n",
      "131 Train Loss 6059.668 Test MSE 3791.893774793353 Test RE 0.6860921236664183\n",
      "132 Train Loss 6053.8374 Test MSE 3792.5395483295083 Test RE 0.6861505431925249\n",
      "133 Train Loss 6049.511 Test MSE 3811.9045768044225 Test RE 0.6879000841336278\n",
      "134 Train Loss 6046.509 Test MSE 3826.221662965007 Test RE 0.6891907111975588\n",
      "135 Train Loss 6034.0854 Test MSE 3843.7385903487416 Test RE 0.6907665108871378\n",
      "136 Train Loss 6027.1704 Test MSE 3815.2168187909397 Test RE 0.6881988844778157\n",
      "137 Train Loss 6022.422 Test MSE 3798.0408735677684 Test RE 0.6866480158449346\n",
      "138 Train Loss 6015.0728 Test MSE 3763.3950605873806 Test RE 0.6835090317691933\n",
      "139 Train Loss 6006.387 Test MSE 3745.6133885872855 Test RE 0.6818923633396755\n",
      "140 Train Loss 6000.782 Test MSE 3730.181054429284 Test RE 0.6804861781201477\n",
      "141 Train Loss 5990.789 Test MSE 3706.1434399584546 Test RE 0.6782900780748528\n",
      "142 Train Loss 5983.6787 Test MSE 3690.730687426093 Test RE 0.6768782049175457\n",
      "143 Train Loss 5980.0176 Test MSE 3693.582844601205 Test RE 0.6771396965240513\n",
      "144 Train Loss 5977.891 Test MSE 3700.8374309862734 Test RE 0.6778043572198057\n",
      "145 Train Loss 5976.237 Test MSE 3698.878911359892 Test RE 0.6776249831134958\n",
      "146 Train Loss 5974.493 Test MSE 3709.073477553345 Test RE 0.6785581495633167\n",
      "147 Train Loss 5973.2007 Test MSE 3706.514631027958 Test RE 0.6783240445038013\n",
      "148 Train Loss 5972.7075 Test MSE 3711.9023969841323 Test RE 0.6788168692229634\n",
      "149 Train Loss 5971.5503 Test MSE 3711.3079752696776 Test RE 0.6787625143936143\n",
      "150 Train Loss 5970.165 Test MSE 3710.963534877375 Test RE 0.6787310162461905\n",
      "151 Train Loss 5968.747 Test MSE 3719.075622650456 Test RE 0.6794724570945644\n",
      "152 Train Loss 5967.952 Test MSE 3727.301967352029 Test RE 0.680223515648791\n",
      "153 Train Loss 5967.158 Test MSE 3740.6352756192246 Test RE 0.6814390776567611\n",
      "154 Train Loss 5966.484 Test MSE 3751.0192253835244 Test RE 0.6823842547048109\n",
      "155 Train Loss 5964.8486 Test MSE 3751.557457962566 Test RE 0.6824332105006771\n",
      "156 Train Loss 5960.984 Test MSE 3737.519003456443 Test RE 0.6811551697198465\n",
      "157 Train Loss 5956.414 Test MSE 3716.7957306408025 Test RE 0.6792641578464166\n",
      "158 Train Loss 5954.526 Test MSE 3707.689249222239 Test RE 0.6784315186038774\n",
      "159 Train Loss 5952.4536 Test MSE 3690.130607227689 Test RE 0.6768231754730243\n",
      "160 Train Loss 5950.9473 Test MSE 3690.4041754133978 Test RE 0.6768482631835055\n",
      "161 Train Loss 5947.5977 Test MSE 3682.3955649224513 Test RE 0.6761134441933424\n",
      "162 Train Loss 5943.859 Test MSE 3674.065069819313 Test RE 0.675348242751139\n",
      "163 Train Loss 5942.483 Test MSE 3674.5872921513846 Test RE 0.6753962371927382\n",
      "164 Train Loss 5940.64 Test MSE 3679.67154498126 Test RE 0.6758633234224989\n",
      "165 Train Loss 5937.471 Test MSE 3682.2686557474585 Test RE 0.6761017933892401\n",
      "166 Train Loss 5936.069 Test MSE 3681.8281015040793 Test RE 0.6760613470704695\n",
      "167 Train Loss 5934.464 Test MSE 3667.7029512172835 Test RE 0.6747632630082797\n",
      "168 Train Loss 5930.352 Test MSE 3657.679203228908 Test RE 0.6738405759006181\n",
      "169 Train Loss 5926.0215 Test MSE 3633.9959071732783 Test RE 0.6716554904955703\n",
      "170 Train Loss 5922.208 Test MSE 3635.2689925762606 Test RE 0.6717731295830757\n",
      "171 Train Loss 5917.9697 Test MSE 3639.0624150868834 Test RE 0.672123537608925\n",
      "172 Train Loss 5910.7856 Test MSE 3632.2478825097487 Test RE 0.6714939312073143\n",
      "173 Train Loss 5906.3984 Test MSE 3624.3668426441513 Test RE 0.6707650514147407\n",
      "174 Train Loss 5903.922 Test MSE 3618.492189845094 Test RE 0.6702212171362903\n",
      "175 Train Loss 5900.484 Test MSE 3601.48641817584 Test RE 0.6686444482415246\n",
      "176 Train Loss 5893.056 Test MSE 3600.2284525113055 Test RE 0.6685276624033043\n",
      "177 Train Loss 5886.972 Test MSE 3595.0448718873126 Test RE 0.6680462186096683\n",
      "178 Train Loss 5885.557 Test MSE 3598.0272420332735 Test RE 0.6683232593888598\n",
      "179 Train Loss 5884.5366 Test MSE 3599.869692925132 Test RE 0.6684943524778438\n",
      "180 Train Loss 5883.5503 Test MSE 3596.838294826398 Test RE 0.6682128284953787\n",
      "181 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "182 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "183 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "184 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "185 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "186 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "187 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "188 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "189 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "190 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "191 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "192 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "193 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "194 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "195 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "196 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "197 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "198 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "199 Train Loss 5882.8643 Test MSE 3589.6095701920935 Test RE 0.6675410223826086\n",
      "Training time: 33.11\n",
      "Training time: 33.11\n",
      "1D_FODE_atanh_medium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 16128.1 Test MSE 9464.743789825812 Test RE 1.083948836184265\n",
      "1 Train Loss 13634.912 Test MSE 12146.507249528244 Test RE 1.2279482349866924\n",
      "2 Train Loss 12471.967 Test MSE 12479.99115955048 Test RE 1.2446908334847777\n",
      "3 Train Loss 11489.38 Test MSE 13957.910630089187 Test RE 1.3163293323950374\n",
      "4 Train Loss 10580.037 Test MSE 13850.409390638411 Test RE 1.311250472167772\n",
      "5 Train Loss 9673.512 Test MSE 14496.27905260264 Test RE 1.3414751209156848\n",
      "6 Train Loss 9000.559 Test MSE 14211.883430831354 Test RE 1.3282510584903024\n",
      "7 Train Loss 8600.954 Test MSE 13980.522350939696 Test RE 1.3173951232355732\n",
      "8 Train Loss 8375.55 Test MSE 13996.924688994288 Test RE 1.3181676990182676\n",
      "9 Train Loss 7808.7397 Test MSE 12991.494504714567 Test RE 1.269942066508429\n",
      "10 Train Loss 7541.8975 Test MSE 12879.98640972893 Test RE 1.2644802624619553\n",
      "11 Train Loss 7344.2495 Test MSE 12755.155139441902 Test RE 1.2583377482240197\n",
      "12 Train Loss 7106.123 Test MSE 12236.611960752936 Test RE 1.232494376642358\n",
      "13 Train Loss 7007.2383 Test MSE 12034.350109776977 Test RE 1.2222658376233873\n",
      "14 Train Loss 6899.6235 Test MSE 11674.106883134647 Test RE 1.2038328357071537\n",
      "15 Train Loss 6723.0225 Test MSE 11330.342314322734 Test RE 1.1859759108486263\n",
      "16 Train Loss 6537.862 Test MSE 11337.011897379061 Test RE 1.1863249206542037\n",
      "17 Train Loss 6407.61 Test MSE 11276.025368916791 Test RE 1.1831297488665764\n",
      "18 Train Loss 6222.478 Test MSE 11119.758813023092 Test RE 1.1749030632484994\n",
      "19 Train Loss 6093.7817 Test MSE 10894.269970778516 Test RE 1.162929584652428\n",
      "20 Train Loss 5996.87 Test MSE 10408.267237746448 Test RE 1.1366940051706422\n",
      "21 Train Loss 5913.1855 Test MSE 10364.717503709384 Test RE 1.1343134642615469\n",
      "22 Train Loss 5869.11 Test MSE 10309.423322534249 Test RE 1.1312837237159654\n",
      "23 Train Loss 5838.697 Test MSE 10117.978818930462 Test RE 1.1207306139412176\n",
      "24 Train Loss 5808.7295 Test MSE 10053.638126133088 Test RE 1.117161542152037\n",
      "25 Train Loss 5772.5957 Test MSE 10067.104230554476 Test RE 1.1179094694021245\n",
      "26 Train Loss 5732.363 Test MSE 10068.239479031476 Test RE 1.1179724999030944\n",
      "27 Train Loss 5706.9243 Test MSE 9879.56500815899 Test RE 1.1074477980830877\n",
      "28 Train Loss 5685.2993 Test MSE 9866.93852416789 Test RE 1.1067398902701362\n",
      "29 Train Loss 5664.6865 Test MSE 9793.875609441302 Test RE 1.1026346710916886\n",
      "30 Train Loss 5644.454 Test MSE 9667.304128361151 Test RE 1.095486533046215\n",
      "31 Train Loss 5621.943 Test MSE 9662.591818918352 Test RE 1.095219504063581\n",
      "32 Train Loss 5604.059 Test MSE 9600.855921428345 Test RE 1.091715128295128\n",
      "33 Train Loss 5590.6377 Test MSE 9524.264803232936 Test RE 1.08735181354074\n",
      "34 Train Loss 5566.915 Test MSE 9454.482834805076 Test RE 1.083361109425014\n",
      "35 Train Loss 5532.4526 Test MSE 9193.00167781142 Test RE 1.0682748941771107\n",
      "36 Train Loss 5510.9224 Test MSE 9162.31431353784 Test RE 1.0664903875620508\n",
      "37 Train Loss 5475.4487 Test MSE 9021.72941768125 Test RE 1.0582767406527058\n",
      "38 Train Loss 5436.623 Test MSE 8810.511612255461 Test RE 1.0458151197799235\n",
      "39 Train Loss 5294.693 Test MSE 8621.194930102749 Test RE 1.034518079179315\n",
      "40 Train Loss 5200.468 Test MSE 8416.965816516764 Test RE 1.0221911911389354\n",
      "41 Train Loss 5175.6035 Test MSE 8406.855361715301 Test RE 1.021577078911821\n",
      "42 Train Loss 5143.0723 Test MSE 8246.795630387256 Test RE 1.0118053429535583\n",
      "43 Train Loss 5108.5146 Test MSE 8145.659177652908 Test RE 1.0055819511928819\n",
      "44 Train Loss 5053.93 Test MSE 7875.348124424559 Test RE 0.9887562293226974\n",
      "45 Train Loss 4962.3438 Test MSE 7847.996146068947 Test RE 0.9870377045334163\n",
      "46 Train Loss 4877.339 Test MSE 7773.192931803784 Test RE 0.9823224644049601\n",
      "47 Train Loss 4805.6895 Test MSE 7519.150128158381 Test RE 0.9661370352687757\n",
      "48 Train Loss 4742.6265 Test MSE 7344.106280109637 Test RE 0.9548251041654416\n",
      "49 Train Loss 4490.3433 Test MSE 6453.341385566359 Test RE 0.895048713001231\n",
      "50 Train Loss 4351.6387 Test MSE 6497.721051521902 Test RE 0.8981210674842527\n",
      "51 Train Loss 4290.142 Test MSE 6414.190498111799 Test RE 0.892329558770882\n",
      "52 Train Loss 4213.753 Test MSE 6348.622348749598 Test RE 0.8877569871885368\n",
      "53 Train Loss 4148.363 Test MSE 6228.210442009615 Test RE 0.879297810020474\n",
      "54 Train Loss 4092.9426 Test MSE 6210.10534403771 Test RE 0.8780188423708661\n",
      "55 Train Loss 4028.1274 Test MSE 6179.30627343388 Test RE 0.8758388651256155\n",
      "56 Train Loss 3861.8752 Test MSE 5928.1499656663555 Test RE 0.8578551110769667\n",
      "57 Train Loss 3651.2925 Test MSE 5794.272637187674 Test RE 0.8481131859827576\n",
      "58 Train Loss 3537.0847 Test MSE 5639.098349941261 Test RE 0.8366796130522843\n",
      "59 Train Loss 3418.2466 Test MSE 5558.083625560613 Test RE 0.8306477456339073\n",
      "60 Train Loss 3137.9329 Test MSE 4672.13910423507 Test RE 0.7615742205293422\n",
      "61 Train Loss 2954.7112 Test MSE 4706.263688992694 Test RE 0.7643503710402771\n",
      "62 Train Loss 2902.5251 Test MSE 4623.159910702142 Test RE 0.7575718175853228\n",
      "63 Train Loss 2856.1226 Test MSE 4552.2375905298395 Test RE 0.7517385340182882\n",
      "64 Train Loss 2784.4817 Test MSE 4397.005031891699 Test RE 0.7388101166250142\n",
      "65 Train Loss 2739.7573 Test MSE 4187.441278836707 Test RE 0.7209891302973858\n",
      "66 Train Loss 2673.2695 Test MSE 3920.563499139714 Test RE 0.697635542430949\n",
      "67 Train Loss 2654.2537 Test MSE 3934.209972188425 Test RE 0.6988486326689045\n",
      "68 Train Loss 2620.0342 Test MSE 3889.072994388849 Test RE 0.6948281414380602\n",
      "69 Train Loss 2594.219 Test MSE 3852.509470777656 Test RE 0.6915541786781764\n",
      "70 Train Loss 2537.6807 Test MSE 3758.967275008399 Test RE 0.68310682550479\n",
      "71 Train Loss 2498.1482 Test MSE 3618.5882707588958 Test RE 0.670230115185001\n",
      "72 Train Loss 2472.0383 Test MSE 3551.443256506157 Test RE 0.6639827433810348\n",
      "73 Train Loss 2445.9575 Test MSE 3468.6593805314974 Test RE 0.656198418920506\n",
      "74 Train Loss 2405.6636 Test MSE 3323.523912309939 Test RE 0.6423234184849255\n",
      "75 Train Loss 2384.747 Test MSE 3214.6509449198634 Test RE 0.6317151084586792\n",
      "76 Train Loss 2357.1184 Test MSE 3178.8562757509917 Test RE 0.628188235396929\n",
      "77 Train Loss 2336.856 Test MSE 3159.063451489879 Test RE 0.6262295067032888\n",
      "78 Train Loss 2328.1716 Test MSE 3086.0078269772225 Test RE 0.6189461472898895\n",
      "79 Train Loss 2301.206 Test MSE 3018.9308887041325 Test RE 0.6121825384188385\n",
      "80 Train Loss 2282.0151 Test MSE 2983.1864952647634 Test RE 0.6085476007400775\n",
      "81 Train Loss 2248.166 Test MSE 2863.0002519689738 Test RE 0.5961630367905613\n",
      "82 Train Loss 2237.3306 Test MSE 2831.84816887476 Test RE 0.592910763840077\n",
      "83 Train Loss 2220.4863 Test MSE 2834.9065918259075 Test RE 0.5932308520703592\n",
      "84 Train Loss 2199.4905 Test MSE 2731.1927071374193 Test RE 0.582278191432453\n",
      "85 Train Loss 2175.001 Test MSE 2617.0210775555743 Test RE 0.5699778287029738\n",
      "86 Train Loss 2162.78 Test MSE 2548.774011220101 Test RE 0.5624967498846551\n",
      "87 Train Loss 2155.4543 Test MSE 2507.2964315683284 Test RE 0.5579010690901114\n",
      "88 Train Loss 2141.5674 Test MSE 2515.3405736638547 Test RE 0.5587953075232356\n",
      "89 Train Loss 2136.1106 Test MSE 2480.1728936395334 Test RE 0.5548752205986177\n",
      "90 Train Loss 2126.935 Test MSE 2433.691882627228 Test RE 0.549651160345283\n",
      "91 Train Loss 2116.7537 Test MSE 2379.4188770459623 Test RE 0.5434878050706146\n",
      "92 Train Loss 2107.5012 Test MSE 2352.4591784630315 Test RE 0.5404000746457633\n",
      "93 Train Loss 2093.3782 Test MSE 2358.418101996427 Test RE 0.5410840750500207\n",
      "94 Train Loss 2084.3486 Test MSE 2341.7667186883946 Test RE 0.5391705555766944\n",
      "95 Train Loss 2072.8767 Test MSE 2308.7595123008655 Test RE 0.5353572658023988\n",
      "96 Train Loss 2064.6665 Test MSE 2298.3966996523136 Test RE 0.534154445342619\n",
      "97 Train Loss 2059.5134 Test MSE 2318.008052848016 Test RE 0.5364284741174596\n",
      "98 Train Loss 2049.68 Test MSE 2330.888578903652 Test RE 0.5379168013450747\n",
      "99 Train Loss 2040.0138 Test MSE 2322.335473920364 Test RE 0.536928961912159\n",
      "100 Train Loss 2032.2076 Test MSE 2313.740013560414 Test RE 0.5359343963127606\n",
      "101 Train Loss 2026.8488 Test MSE 2320.5379356586827 Test RE 0.5367211243284319\n",
      "102 Train Loss 2020.7101 Test MSE 2324.2034526478215 Test RE 0.5371448588584334\n",
      "103 Train Loss 2010.3961 Test MSE 2320.2410913878252 Test RE 0.5366867944250424\n",
      "104 Train Loss 2000.3679 Test MSE 2353.382272236372 Test RE 0.5405060894541348\n",
      "105 Train Loss 1994.9603 Test MSE 2365.901321378595 Test RE 0.5419418203387076\n",
      "106 Train Loss 1990.6885 Test MSE 2391.7478527283097 Test RE 0.5448940287809771\n",
      "107 Train Loss 1981.5532 Test MSE 2380.9646014022346 Test RE 0.5436643073997988\n",
      "108 Train Loss 1975.7504 Test MSE 2341.172872393467 Test RE 0.5391021873793852\n",
      "109 Train Loss 1968.4834 Test MSE 2325.551882337837 Test RE 0.5373006535352819\n",
      "110 Train Loss 1959.4896 Test MSE 2269.156405383793 Test RE 0.5307458023639093\n",
      "111 Train Loss 1949.9525 Test MSE 2243.9289394533766 Test RE 0.5277872592263216\n",
      "112 Train Loss 1937.0342 Test MSE 2227.594914026036 Test RE 0.5258628141080585\n",
      "113 Train Loss 1927.945 Test MSE 2206.2454980626503 Test RE 0.5233367952795352\n",
      "114 Train Loss 1922.0944 Test MSE 2208.284252712459 Test RE 0.5235785428435865\n",
      "115 Train Loss 1912.3353 Test MSE 2232.8760230950347 Test RE 0.5264857942603126\n",
      "116 Train Loss 1901.5972 Test MSE 2189.9900535530137 Test RE 0.521405278569742\n",
      "117 Train Loss 1892.614 Test MSE 2161.3659449053766 Test RE 0.517986575613884\n",
      "118 Train Loss 1878.5828 Test MSE 2118.1867068271044 Test RE 0.5127863681662358\n",
      "119 Train Loss 1865.6132 Test MSE 2084.5236257769816 Test RE 0.5086953446929575\n",
      "120 Train Loss 1857.1111 Test MSE 2069.192575242124 Test RE 0.5068212410751504\n",
      "121 Train Loss 1833.2373 Test MSE 2055.3636160344677 Test RE 0.50512479191908\n",
      "122 Train Loss 1826.0173 Test MSE 2064.464201607659 Test RE 0.5062418337176463\n",
      "123 Train Loss 1811.2036 Test MSE 2041.0662734393172 Test RE 0.5033648733378464\n",
      "124 Train Loss 1798.7925 Test MSE 2047.9008252814817 Test RE 0.5042069327610387\n",
      "125 Train Loss 1783.2753 Test MSE 2046.566728178624 Test RE 0.5040426741733584\n",
      "126 Train Loss 1771.3885 Test MSE 2038.2228481308891 Test RE 0.5030141303785536\n",
      "127 Train Loss 1761.186 Test MSE 2007.3292293546308 Test RE 0.4991874480980844\n",
      "128 Train Loss 1743.3911 Test MSE 1950.9399688815672 Test RE 0.4921259945224393\n",
      "129 Train Loss 1730.1141 Test MSE 1929.9760767777857 Test RE 0.48947477474721474\n",
      "130 Train Loss 1714.9062 Test MSE 1892.176395101632 Test RE 0.4846577508278518\n",
      "131 Train Loss 1690.226 Test MSE 1844.2154097311031 Test RE 0.478476018562819\n",
      "132 Train Loss 1659.2012 Test MSE 1882.4906538244538 Test RE 0.4834157174955881\n",
      "133 Train Loss 1647.5747 Test MSE 1926.0537476114362 Test RE 0.48897713706816476\n",
      "134 Train Loss 1618.1791 Test MSE 1870.5786496776998 Test RE 0.48188381386555906\n",
      "135 Train Loss 1598.0765 Test MSE 1894.6838630440236 Test RE 0.4849787730732229\n",
      "136 Train Loss 1572.8992 Test MSE 1837.5157557814687 Test RE 0.47760612549794346\n",
      "137 Train Loss 1553.6154 Test MSE 1828.2572796166487 Test RE 0.47640137690569\n",
      "138 Train Loss 1522.2704 Test MSE 1748.1196122154738 Test RE 0.4658433765110644\n",
      "139 Train Loss 1494.4446 Test MSE 1713.429002804704 Test RE 0.46119799359441654\n",
      "140 Train Loss 1454.6816 Test MSE 1666.9663045933771 Test RE 0.45490191279580955\n",
      "141 Train Loss 1415.03 Test MSE 1610.588268510982 Test RE 0.44714318713072715\n",
      "142 Train Loss 1375.0712 Test MSE 1636.7066453683692 Test RE 0.4507541929166495\n",
      "143 Train Loss 1357.342 Test MSE 1613.1901833104857 Test RE 0.44750422259727457\n",
      "144 Train Loss 1331.9974 Test MSE 1586.2536359373553 Test RE 0.4437523516897172\n",
      "145 Train Loss 1310.7297 Test MSE 1575.2643404959313 Test RE 0.442212559785272\n",
      "146 Train Loss 1277.7645 Test MSE 1535.8937175683081 Test RE 0.4366514778081097\n",
      "147 Train Loss 1250.8127 Test MSE 1604.7992746393377 Test RE 0.4463388725201511\n",
      "148 Train Loss 1220.2443 Test MSE 1571.965232501245 Test RE 0.4417492497206209\n",
      "149 Train Loss 1187.3042 Test MSE 1502.049593702456 Test RE 0.4318137710971711\n",
      "150 Train Loss 1136.7434 Test MSE 1479.7800536645898 Test RE 0.4286007600750986\n",
      "151 Train Loss 1100.3673 Test MSE 1425.7873897142404 Test RE 0.4207089363149535\n",
      "152 Train Loss 1068.1198 Test MSE 1353.5076995120162 Test RE 0.4099064174738719\n",
      "153 Train Loss 1036.3285 Test MSE 1348.641798816357 Test RE 0.4091689411442401\n",
      "154 Train Loss 1007.94727 Test MSE 1307.5927415456508 Test RE 0.40289381734478374\n",
      "155 Train Loss 992.8724 Test MSE 1260.450796538322 Test RE 0.3955644927400542\n",
      "156 Train Loss 943.1929 Test MSE 1087.354779402093 Test RE 0.36740070574541545\n",
      "157 Train Loss 900.0465 Test MSE 1069.7140468894645 Test RE 0.36440825094773555\n",
      "158 Train Loss 858.7 Test MSE 1025.673773739186 Test RE 0.3568280427225072\n",
      "159 Train Loss 824.7877 Test MSE 936.4603016453726 Test RE 0.34095655013104\n",
      "160 Train Loss 807.47406 Test MSE 899.7933532612014 Test RE 0.33421484995237\n",
      "161 Train Loss 789.27277 Test MSE 892.606427919416 Test RE 0.3328774357844104\n",
      "162 Train Loss 777.511 Test MSE 877.1903624903827 Test RE 0.32999037905959594\n",
      "163 Train Loss 763.26624 Test MSE 866.8645882968051 Test RE 0.32804240217601616\n",
      "164 Train Loss 741.1024 Test MSE 849.3486281695357 Test RE 0.3247112587170271\n",
      "165 Train Loss 712.4655 Test MSE 793.0780254491052 Test RE 0.3137706451439416\n",
      "166 Train Loss 683.60596 Test MSE 776.6932672945763 Test RE 0.31051252486387393\n",
      "167 Train Loss 665.7619 Test MSE 773.2545700862838 Test RE 0.3098243876947088\n",
      "168 Train Loss 649.0356 Test MSE 739.7852434761402 Test RE 0.3030450429450814\n",
      "169 Train Loss 635.4601 Test MSE 725.10111925478 Test RE 0.300022371861391\n",
      "170 Train Loss 624.2106 Test MSE 704.3875261880871 Test RE 0.2957060299549148\n",
      "171 Train Loss 615.63513 Test MSE 684.3684520062786 Test RE 0.29147367918500733\n",
      "172 Train Loss 607.1137 Test MSE 670.084303501355 Test RE 0.288415817630875\n",
      "173 Train Loss 597.15765 Test MSE 667.3022502493548 Test RE 0.2878164730927883\n",
      "174 Train Loss 589.6312 Test MSE 647.1523509762017 Test RE 0.2834377024607435\n",
      "175 Train Loss 583.366 Test MSE 642.7873159111142 Test RE 0.282480193131712\n",
      "176 Train Loss 575.2604 Test MSE 627.463963968978 Test RE 0.2790928732537196\n",
      "177 Train Loss 565.3475 Test MSE 615.3037563243155 Test RE 0.2763752417964545\n",
      "178 Train Loss 556.5104 Test MSE 616.5069508342151 Test RE 0.2766453285349957\n",
      "179 Train Loss 545.5914 Test MSE 597.413672775787 Test RE 0.2723277709551973\n",
      "180 Train Loss 535.33344 Test MSE 608.5042425546858 Test RE 0.2748439348795867\n",
      "181 Train Loss 528.54865 Test MSE 587.5394118616307 Test RE 0.27006782972722476\n",
      "182 Train Loss 520.4728 Test MSE 578.6411937808233 Test RE 0.26801495403042114\n",
      "183 Train Loss 514.32336 Test MSE 563.7398555020544 Test RE 0.2645414454922218\n",
      "184 Train Loss 511.23148 Test MSE 558.1349376370842 Test RE 0.26322307411006995\n",
      "185 Train Loss 503.57462 Test MSE 553.2369547353741 Test RE 0.2620655555344415\n",
      "186 Train Loss 501.0015 Test MSE 543.4002614411592 Test RE 0.25972531033662527\n",
      "187 Train Loss 498.97473 Test MSE 540.9397115078377 Test RE 0.2591366170503211\n",
      "188 Train Loss 496.4799 Test MSE 534.1162773007259 Test RE 0.25749705065492007\n",
      "189 Train Loss 492.71402 Test MSE 528.447603470012 Test RE 0.2561269740706181\n",
      "190 Train Loss 488.95508 Test MSE 528.4125354354359 Test RE 0.2561184755756502\n",
      "191 Train Loss 484.3404 Test MSE 525.2446097537519 Test RE 0.2553495838777977\n",
      "192 Train Loss 481.172 Test MSE 518.193758356043 Test RE 0.25362989455819374\n",
      "193 Train Loss 478.19125 Test MSE 516.7914356990744 Test RE 0.25328647870753557\n",
      "194 Train Loss 476.3228 Test MSE 514.6247785907957 Test RE 0.25275496703945854\n",
      "195 Train Loss 473.6086 Test MSE 509.4618097467985 Test RE 0.2514838899250762\n",
      "196 Train Loss 471.9634 Test MSE 504.84762170962057 Test RE 0.25034245663418897\n",
      "197 Train Loss 465.92758 Test MSE 492.4517248423241 Test RE 0.24724993370096862\n",
      "198 Train Loss 459.9422 Test MSE 482.00846177148765 Test RE 0.2446142107511258\n",
      "199 Train Loss 457.1636 Test MSE 475.1064310185126 Test RE 0.2428565420039279\n",
      "Training time: 35.75\n",
      "Training time: 35.75\n",
      "1D_FODE_atanh_medium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 16540.312 Test MSE 9051.228756918368 Test RE 1.0600055104462702\n",
      "1 Train Loss 13593.877 Test MSE 11850.54480445286 Test RE 1.2128958515659345\n",
      "2 Train Loss 12987.93 Test MSE 13084.00471488205 Test RE 1.2744555659130636\n",
      "3 Train Loss 12650.513 Test MSE 13252.249302008451 Test RE 1.2826233767207227\n",
      "4 Train Loss 12380.802 Test MSE 13595.26491480993 Test RE 1.2991167718780567\n",
      "5 Train Loss 12054.327 Test MSE 13363.99782932372 Test RE 1.288019833582945\n",
      "6 Train Loss 11580.101 Test MSE 13252.836098883838 Test RE 1.2826517730722116\n",
      "7 Train Loss 10975.839 Test MSE 12066.181791729725 Test RE 1.2238812586160408\n",
      "8 Train Loss 10378.22 Test MSE 11603.945418642441 Test RE 1.2002098620736839\n",
      "9 Train Loss 9774.296 Test MSE 10849.263937508893 Test RE 1.1605249712743106\n",
      "10 Train Loss 8860.801 Test MSE 9961.81691555423 Test RE 1.1120482479979759\n",
      "11 Train Loss 8422.715 Test MSE 9455.903861229048 Test RE 1.083442521964842\n",
      "12 Train Loss 7971.2417 Test MSE 8991.200142567242 Test RE 1.0564846341006158\n",
      "13 Train Loss 7679.8677 Test MSE 8580.068435497315 Test RE 1.032047600066435\n",
      "14 Train Loss 7333.707 Test MSE 8060.429206715618 Test RE 1.000307295757256\n",
      "15 Train Loss 6953.752 Test MSE 7442.556409820781 Test RE 0.9612036689486955\n",
      "16 Train Loss 6510.815 Test MSE 6406.147068203033 Test RE 0.8917698901893836\n",
      "17 Train Loss 6294.8135 Test MSE 5836.2894874145995 Test RE 0.8511826546387636\n",
      "18 Train Loss 6094.58 Test MSE 5453.865402345585 Test RE 0.8228232602141575\n",
      "19 Train Loss 5982.714 Test MSE 5286.744004586541 Test RE 0.8101183939888067\n",
      "20 Train Loss 5870.1377 Test MSE 5234.864158096932 Test RE 0.8061336695382091\n",
      "21 Train Loss 5767.949 Test MSE 5101.885237186187 Test RE 0.7958288794306402\n",
      "22 Train Loss 5721.891 Test MSE 5024.73831948776 Test RE 0.7897889932949178\n",
      "23 Train Loss 5646.964 Test MSE 4973.677809701294 Test RE 0.7857658980645237\n",
      "24 Train Loss 5609.893 Test MSE 4855.1142599112645 Test RE 0.7763437836380412\n",
      "25 Train Loss 5561.7695 Test MSE 4834.8421600084175 Test RE 0.774721310863444\n",
      "26 Train Loss 5523.579 Test MSE 4760.077724908471 Test RE 0.7687079532708921\n",
      "27 Train Loss 5489.99 Test MSE 4634.492515396729 Test RE 0.7584997551156922\n",
      "28 Train Loss 5455.5684 Test MSE 4623.0502244258805 Test RE 0.7575628306882491\n",
      "29 Train Loss 5413.2036 Test MSE 4492.894374008668 Test RE 0.7468226082102504\n",
      "30 Train Loss 5384.8433 Test MSE 4418.542738167637 Test RE 0.740617350992832\n",
      "31 Train Loss 5365.4883 Test MSE 4372.812872922058 Test RE 0.736774860326912\n",
      "32 Train Loss 5332.5815 Test MSE 4290.977319003859 Test RE 0.7298480664992765\n",
      "33 Train Loss 5290.53 Test MSE 4182.164306945504 Test RE 0.7205346954147147\n",
      "34 Train Loss 5260.4443 Test MSE 4251.732661329761 Test RE 0.7265028578265479\n",
      "35 Train Loss 5116.7476 Test MSE 4188.706444357231 Test RE 0.7210980394902216\n",
      "36 Train Loss 5056.507 Test MSE 4204.112384323259 Test RE 0.7224229111628175\n",
      "37 Train Loss 4978.1724 Test MSE 4185.174051840184 Test RE 0.7207939195188839\n",
      "38 Train Loss 4893.222 Test MSE 4066.1186256582073 Test RE 0.7104677593946744\n",
      "39 Train Loss 4851.4775 Test MSE 4026.35683144354 Test RE 0.7069854613182526\n",
      "40 Train Loss 4818.979 Test MSE 3960.6461277228286 Test RE 0.7011926787886997\n",
      "41 Train Loss 4787.2275 Test MSE 3909.9359931455715 Test RE 0.6966893573843334\n",
      "42 Train Loss 4740.943 Test MSE 3906.6553738068146 Test RE 0.696397018557076\n",
      "43 Train Loss 4714.0327 Test MSE 3894.3461202977924 Test RE 0.6952990345225385\n",
      "44 Train Loss 4671.792 Test MSE 3899.6965681881056 Test RE 0.6957765067644478\n",
      "45 Train Loss 4649.681 Test MSE 3840.797498250483 Test RE 0.6905021853279928\n",
      "46 Train Loss 4620.13 Test MSE 3811.0931166494483 Test RE 0.6878268617840488\n",
      "47 Train Loss 4606.7827 Test MSE 3779.395760255198 Test RE 0.6849605167303862\n",
      "48 Train Loss 4549.999 Test MSE 3654.702635503431 Test RE 0.6735663391203919\n",
      "49 Train Loss 4383.0117 Test MSE 3675.7172251787865 Test RE 0.6755000711468832\n",
      "50 Train Loss 4321.3696 Test MSE 3640.1896628271274 Test RE 0.672227629128745\n",
      "51 Train Loss 4283.9116 Test MSE 3619.8051101001247 Test RE 0.6703427963964448\n",
      "52 Train Loss 4239.649 Test MSE 3612.0444035827527 Test RE 0.6696238177582852\n",
      "53 Train Loss 4219.016 Test MSE 3580.685477635164 Test RE 0.6667107224718717\n",
      "54 Train Loss 4193.7476 Test MSE 3560.2611233190387 Test RE 0.6648065326399761\n",
      "55 Train Loss 4170.7256 Test MSE 3531.4774877683235 Test RE 0.6621136989258743\n",
      "56 Train Loss 4148.7935 Test MSE 3511.9232930818325 Test RE 0.6602780547226472\n",
      "57 Train Loss 4126.17 Test MSE 3455.6587963444517 Test RE 0.6549675440479541\n",
      "58 Train Loss 4107.399 Test MSE 3415.4543081528545 Test RE 0.6511463226389499\n",
      "59 Train Loss 4092.2651 Test MSE 3378.6766902734 Test RE 0.6476310615794765\n",
      "60 Train Loss 4079.743 Test MSE 3349.793768752052 Test RE 0.644856953992785\n",
      "61 Train Loss 4068.251 Test MSE 3308.016545045856 Test RE 0.6408231447295671\n",
      "62 Train Loss 4052.885 Test MSE 3271.8410080875983 Test RE 0.6373095818049698\n",
      "63 Train Loss 4013.178 Test MSE 3123.8352615820168 Test RE 0.6227280290349845\n",
      "64 Train Loss 3955.207 Test MSE 3082.0563955943753 Test RE 0.6185497603124928\n",
      "65 Train Loss 3897.259 Test MSE 3085.4058835123983 Test RE 0.6188857798541755\n",
      "66 Train Loss 3864.915 Test MSE 3106.1361562013067 Test RE 0.6209613889487607\n",
      "67 Train Loss 3836.916 Test MSE 3119.97509439065 Test RE 0.6223431532048549\n",
      "68 Train Loss 3799.0698 Test MSE 3092.141823501547 Test RE 0.619560975408985\n",
      "69 Train Loss 3766.7957 Test MSE 3086.0826543485978 Test RE 0.6189536511322447\n",
      "70 Train Loss 3724.4587 Test MSE 3053.1016800870757 Test RE 0.615637387371682\n",
      "71 Train Loss 3658.8171 Test MSE 3011.57143977345 Test RE 0.6114359040341532\n",
      "72 Train Loss 3602.37 Test MSE 3018.186010364287 Test RE 0.6121070100842795\n",
      "73 Train Loss 3567.251 Test MSE 2980.7064723268336 Test RE 0.6082945951358125\n",
      "74 Train Loss 3527.9875 Test MSE 2942.2075678366423 Test RE 0.6043534511209891\n",
      "75 Train Loss 3473.5884 Test MSE 2892.281518650049 Test RE 0.5992039030809541\n",
      "76 Train Loss 3425.8223 Test MSE 2843.0572538441934 Test RE 0.5940830412972443\n",
      "77 Train Loss 3364.222 Test MSE 2735.72209240915 Test RE 0.5827608138630759\n",
      "78 Train Loss 3311.65 Test MSE 2704.5206317283646 Test RE 0.5794280317051401\n",
      "79 Train Loss 3275.2898 Test MSE 2648.9339767029637 Test RE 0.573442555811298\n",
      "80 Train Loss 3218.429 Test MSE 2497.9843921640427 Test RE 0.5568640897044004\n",
      "81 Train Loss 3157.178 Test MSE 2399.8297541891775 Test RE 0.5458138719692857\n",
      "82 Train Loss 3128.9434 Test MSE 2390.4940981593422 Test RE 0.5447511932957343\n",
      "83 Train Loss 3115.4377 Test MSE 2362.863927678979 Test RE 0.5415938304803377\n",
      "84 Train Loss 3104.441 Test MSE 2351.7453646875206 Test RE 0.5403180808140563\n",
      "85 Train Loss 3091.5713 Test MSE 2348.063094895725 Test RE 0.5398949107729512\n",
      "86 Train Loss 3073.012 Test MSE 2339.647713828167 Test RE 0.5389265595391001\n",
      "87 Train Loss 3063.0752 Test MSE 2327.885294605605 Test RE 0.5375701443190047\n",
      "88 Train Loss 3053.9802 Test MSE 2317.857150122277 Test RE 0.5364110130399856\n",
      "89 Train Loss 3046.8157 Test MSE 2299.4392693025784 Test RE 0.5342755798001645\n",
      "90 Train Loss 3030.9329 Test MSE 2280.558383401402 Test RE 0.5320775680124612\n",
      "91 Train Loss 3020.6736 Test MSE 2275.6381631801537 Test RE 0.5315032892787476\n",
      "92 Train Loss 3007.9534 Test MSE 2259.5485451433724 Test RE 0.5296209921212347\n",
      "93 Train Loss 2996.4092 Test MSE 2235.0446821604537 Test RE 0.5267414043077298\n",
      "94 Train Loss 2985.27 Test MSE 2217.617937348341 Test RE 0.5246838724756616\n",
      "95 Train Loss 2974.532 Test MSE 2196.588253715714 Test RE 0.5221901563242106\n",
      "96 Train Loss 2958.6694 Test MSE 2159.949451517704 Test RE 0.5178168114849593\n",
      "97 Train Loss 2949.123 Test MSE 2155.9465059787526 Test RE 0.5173367646625023\n",
      "98 Train Loss 2934.0435 Test MSE 2134.2733822765026 Test RE 0.5147298760568708\n",
      "99 Train Loss 2920.681 Test MSE 2116.2649495020096 Test RE 0.5125536987386835\n",
      "100 Train Loss 2906.472 Test MSE 2088.13898970908 Test RE 0.5091362900569797\n",
      "101 Train Loss 2891.6055 Test MSE 2049.3081365617036 Test RE 0.5043801477508737\n",
      "102 Train Loss 2885.721 Test MSE 2017.3794461260625 Test RE 0.5004355438275123\n",
      "103 Train Loss 2879.2798 Test MSE 1993.1072426845226 Test RE 0.4974159258175616\n",
      "104 Train Loss 2870.9092 Test MSE 1987.0058400388475 Test RE 0.49665398460901683\n",
      "105 Train Loss 2860.701 Test MSE 1977.8885467837267 Test RE 0.4955132365097514\n",
      "106 Train Loss 2847.4807 Test MSE 1971.6952144908537 Test RE 0.4947368317204859\n",
      "107 Train Loss 2834.5679 Test MSE 1980.7836311645285 Test RE 0.4958757513921315\n",
      "108 Train Loss 2824.3481 Test MSE 1989.5392486088663 Test RE 0.49697049768483204\n",
      "109 Train Loss 2813.7769 Test MSE 1967.5823286311563 Test RE 0.49422056066076564\n",
      "110 Train Loss 2805.3699 Test MSE 1952.351400316072 Test RE 0.4923039796284155\n",
      "111 Train Loss 2799.3604 Test MSE 1952.3147589892674 Test RE 0.49229935987716594\n",
      "112 Train Loss 2788.7246 Test MSE 1955.9739973753765 Test RE 0.492760504112096\n",
      "113 Train Loss 2779.0637 Test MSE 1947.8203934006337 Test RE 0.49173237954402266\n",
      "114 Train Loss 2773.6555 Test MSE 1945.0291399805456 Test RE 0.4913799235978521\n",
      "115 Train Loss 2768.981 Test MSE 1929.4405841794025 Test RE 0.489406865018704\n",
      "116 Train Loss 2759.9177 Test MSE 1922.75876531743 Test RE 0.48855870101060417\n",
      "117 Train Loss 2750.1382 Test MSE 1901.9894350150325 Test RE 0.485912870477276\n",
      "118 Train Loss 2739.537 Test MSE 1893.40532404572 Test RE 0.4848151128110838\n",
      "119 Train Loss 2727.162 Test MSE 1883.9827896564339 Test RE 0.4836072666626376\n",
      "120 Train Loss 2714.5037 Test MSE 1874.5134003859914 Test RE 0.48239036744478053\n",
      "121 Train Loss 2698.127 Test MSE 1865.6796077792537 Test RE 0.4812523737669259\n",
      "122 Train Loss 2685.8167 Test MSE 1841.0586054666185 Test RE 0.4780663315881756\n",
      "123 Train Loss 2675.5012 Test MSE 1835.9372475770645 Test RE 0.4774009389126453\n",
      "124 Train Loss 2662.8845 Test MSE 1832.2296363279554 Test RE 0.47691864802302136\n",
      "125 Train Loss 2654.8118 Test MSE 1817.0421414316368 Test RE 0.4749379268885031\n",
      "126 Train Loss 2647.5525 Test MSE 1807.3571379845246 Test RE 0.47367050412179496\n",
      "127 Train Loss 2643.0342 Test MSE 1803.3597587652475 Test RE 0.4731463994242207\n",
      "128 Train Loss 2636.433 Test MSE 1803.9480249846517 Test RE 0.4732235646562999\n",
      "129 Train Loss 2631.6187 Test MSE 1802.1457389824086 Test RE 0.47298711179685426\n",
      "130 Train Loss 2627.9468 Test MSE 1801.94008354218 Test RE 0.472960123095036\n",
      "131 Train Loss 2623.362 Test MSE 1811.5770282699016 Test RE 0.47422315421382716\n",
      "132 Train Loss 2617.982 Test MSE 1822.8814507066604 Test RE 0.4757004532082347\n",
      "133 Train Loss 2614.2126 Test MSE 1819.3963504600902 Test RE 0.47524549851911835\n",
      "134 Train Loss 2608.101 Test MSE 1814.2053447821888 Test RE 0.474567041547544\n",
      "135 Train Loss 2602.709 Test MSE 1805.2927734674934 Test RE 0.47339991345113946\n",
      "136 Train Loss 2597.769 Test MSE 1798.3027137572124 Test RE 0.4724825267773377\n",
      "137 Train Loss 2594.5493 Test MSE 1797.5382931086212 Test RE 0.4723820949126188\n",
      "138 Train Loss 2591.7244 Test MSE 1790.8868456828666 Test RE 0.4715073050160515\n",
      "139 Train Loss 2589.6182 Test MSE 1787.928766629616 Test RE 0.47111774039744425\n",
      "140 Train Loss 2584.642 Test MSE 1779.7822470893987 Test RE 0.4700432144515724\n",
      "141 Train Loss 2581.3547 Test MSE 1773.865190482196 Test RE 0.46926121209861094\n",
      "142 Train Loss 2577.9343 Test MSE 1763.8702688715414 Test RE 0.46793730807263545\n",
      "143 Train Loss 2576.0457 Test MSE 1763.1876057451411 Test RE 0.46784674742723986\n",
      "144 Train Loss 2573.0237 Test MSE 1753.4958598531523 Test RE 0.4665591646885082\n",
      "145 Train Loss 2571.4644 Test MSE 1755.9902079942717 Test RE 0.4668908870048678\n",
      "146 Train Loss 2569.6802 Test MSE 1763.44014696057 Test RE 0.4678802510531367\n",
      "147 Train Loss 2566.0942 Test MSE 1770.8416880743641 Test RE 0.46886112039227124\n",
      "148 Train Loss 2563.101 Test MSE 1772.7593103534139 Test RE 0.4691149136201937\n",
      "149 Train Loss 2559.534 Test MSE 1789.4414480032165 Test RE 0.47131699340256333\n",
      "150 Train Loss 2556.2834 Test MSE 1788.326340250912 Test RE 0.47117011764487027\n",
      "151 Train Loss 2554.5967 Test MSE 1781.4259170182854 Test RE 0.4702602122340048\n",
      "152 Train Loss 2551.7947 Test MSE 1785.1446264947408 Test RE 0.4707507881854798\n",
      "153 Train Loss 2549.2979 Test MSE 1780.5332563172228 Test RE 0.47014237533506364\n",
      "154 Train Loss 2546.7192 Test MSE 1773.7182737772312 Test RE 0.4692417789029602\n",
      "155 Train Loss 2544.8506 Test MSE 1770.6657810818315 Test RE 0.46883783259685363\n",
      "156 Train Loss 2542.7422 Test MSE 1771.08236862024 Test RE 0.4688929814889217\n",
      "157 Train Loss 2541.6882 Test MSE 1771.0443441811283 Test RE 0.4688879479883237\n",
      "158 Train Loss 2539.5894 Test MSE 1768.7853963675827 Test RE 0.46858882183392364\n",
      "159 Train Loss 2538.4573 Test MSE 1772.055647614564 Test RE 0.4690218013048019\n",
      "160 Train Loss 2536.7842 Test MSE 1771.7199168888226 Test RE 0.46897736915366584\n",
      "161 Train Loss 2535.13 Test MSE 1770.9560127720952 Test RE 0.4688762548735518\n",
      "162 Train Loss 2532.7 Test MSE 1768.5526950969622 Test RE 0.46855799706539536\n",
      "163 Train Loss 2529.6946 Test MSE 1766.6427837606836 Test RE 0.468304924038059\n",
      "164 Train Loss 2527.4814 Test MSE 1766.3371154775657 Test RE 0.46826440872964115\n",
      "165 Train Loss 2524.6272 Test MSE 1765.0226715730078 Test RE 0.4680901436234646\n",
      "166 Train Loss 2522.8113 Test MSE 1766.4315829641148 Test RE 0.4682769304532425\n",
      "167 Train Loss 2521.319 Test MSE 1761.691975885139 Test RE 0.46764827903618783\n",
      "168 Train Loss 2519.0515 Test MSE 1750.8870115939778 Test RE 0.46621196251941693\n",
      "169 Train Loss 2517.6274 Test MSE 1756.7612340664975 Test RE 0.46699337776419514\n",
      "170 Train Loss 2513.6611 Test MSE 1751.4740925278704 Test RE 0.4662901175382152\n",
      "171 Train Loss 2509.2878 Test MSE 1758.2879976166687 Test RE 0.46719626066314773\n",
      "172 Train Loss 2505.475 Test MSE 1754.898187420195 Test RE 0.4667456886591548\n",
      "173 Train Loss 2501.799 Test MSE 1754.5359257066093 Test RE 0.46669751127169806\n",
      "174 Train Loss 2498.9736 Test MSE 1751.1639593363464 Test RE 0.46624883275840634\n",
      "175 Train Loss 2495.8372 Test MSE 1746.0806782551308 Test RE 0.46557162708547417\n",
      "176 Train Loss 2493.758 Test MSE 1747.0684397012365 Test RE 0.46570329588230447\n",
      "177 Train Loss 2491.1396 Test MSE 1736.40869992528 Test RE 0.4642803775216158\n",
      "178 Train Loss 2487.9834 Test MSE 1727.6543146543884 Test RE 0.4631085263328217\n",
      "179 Train Loss 2485.8193 Test MSE 1721.081232172405 Test RE 0.4622267088861575\n",
      "180 Train Loss 2481.4243 Test MSE 1706.401239853909 Test RE 0.46025120195640185\n",
      "181 Train Loss 2477.9834 Test MSE 1705.3300950868986 Test RE 0.4601067244896554\n",
      "182 Train Loss 2475.1877 Test MSE 1703.784794655579 Test RE 0.4598982122885964\n",
      "183 Train Loss 2471.5557 Test MSE 1701.9074525717497 Test RE 0.459644769413659\n",
      "184 Train Loss 2467.3594 Test MSE 1709.8003612776627 Test RE 0.4607093800713256\n",
      "185 Train Loss 2465.3503 Test MSE 1712.456788157167 Test RE 0.46106713113490433\n",
      "186 Train Loss 2462.2424 Test MSE 1701.2631615505084 Test RE 0.4595577573288797\n",
      "187 Train Loss 2458.26 Test MSE 1687.7269768257536 Test RE 0.4577258591096765\n",
      "188 Train Loss 2456.3618 Test MSE 1672.780678140481 Test RE 0.45569457046473066\n",
      "189 Train Loss 2453.9653 Test MSE 1670.6991284557344 Test RE 0.45541095702648754\n",
      "190 Train Loss 2450.0503 Test MSE 1669.9170681110654 Test RE 0.4553043547862868\n",
      "191 Train Loss 2447.3955 Test MSE 1658.8360861974847 Test RE 0.4537912207281757\n",
      "192 Train Loss 2445.0352 Test MSE 1650.464529990908 Test RE 0.45264471088072167\n",
      "193 Train Loss 2443.2417 Test MSE 1643.0545295776951 Test RE 0.45162746071098775\n",
      "194 Train Loss 2442.331 Test MSE 1642.2457986845925 Test RE 0.4515162988388078\n",
      "195 Train Loss 2441.5117 Test MSE 1644.6877721161054 Test RE 0.4518518701736836\n",
      "196 Train Loss 2439.5696 Test MSE 1649.854656319111 Test RE 0.452561073337063\n",
      "197 Train Loss 2436.1628 Test MSE 1639.8906798506364 Test RE 0.45119242647577085\n",
      "198 Train Loss 2432.0237 Test MSE 1623.5495901386475 Test RE 0.44893878983102226\n",
      "199 Train Loss 2428.8723 Test MSE 1616.8906704120411 Test RE 0.44801719219184627\n",
      "Training time: 35.18\n",
      "Training time: 35.18\n",
      "1D_FODE_atanh_medium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 15815.172 Test MSE 12301.6778930444 Test RE 1.2357668132855508\n",
      "1 Train Loss 13369.142 Test MSE 14098.298977536464 Test RE 1.3229325753530903\n",
      "2 Train Loss 12141.025 Test MSE 13812.09344284171 Test RE 1.3094354860991633\n",
      "3 Train Loss 11198.981 Test MSE 14705.069841068307 Test RE 1.351101257235366\n",
      "4 Train Loss 10493.371 Test MSE 15115.137092285237 Test RE 1.3698102058187025\n",
      "5 Train Loss 10037.573 Test MSE 15727.153492278332 Test RE 1.3972670412921493\n",
      "6 Train Loss 9398.621 Test MSE 15784.159802248501 Test RE 1.399797091911652\n",
      "7 Train Loss 9141.574 Test MSE 15842.639335894066 Test RE 1.4023877841295351\n",
      "8 Train Loss 8846.309 Test MSE 15487.669786216835 Test RE 1.3865878570298433\n",
      "9 Train Loss 8561.344 Test MSE 14960.235574702489 Test RE 1.362773150606468\n",
      "10 Train Loss 8307.096 Test MSE 14485.21904808078 Test RE 1.3409632808819052\n",
      "11 Train Loss 8085.15 Test MSE 14781.305061431489 Test RE 1.3545989743806446\n",
      "12 Train Loss 7860.3223 Test MSE 14483.236489632645 Test RE 1.3408715104694056\n",
      "13 Train Loss 7711.455 Test MSE 14449.406937496018 Test RE 1.3393046092459622\n",
      "14 Train Loss 7517.339 Test MSE 13794.54488133086 Test RE 1.3086033887547726\n",
      "15 Train Loss 7363.98 Test MSE 13603.726802513707 Test RE 1.2995210034355738\n",
      "16 Train Loss 7260.957 Test MSE 13579.865316176134 Test RE 1.2983807970568662\n",
      "17 Train Loss 7149.872 Test MSE 13576.578403690326 Test RE 1.2982236555011617\n",
      "18 Train Loss 7071.9927 Test MSE 13614.994802371135 Test RE 1.3000590902312184\n",
      "19 Train Loss 6972.9185 Test MSE 13372.458931555535 Test RE 1.2884275088613126\n",
      "20 Train Loss 6896.5586 Test MSE 13139.913149064558 Test RE 1.2771755611435618\n",
      "21 Train Loss 6806.392 Test MSE 12748.07102411612 Test RE 1.2579882641254536\n",
      "22 Train Loss 6693.3643 Test MSE 12478.81799428044 Test RE 1.2446323293417283\n",
      "23 Train Loss 6629.6147 Test MSE 11997.358822664359 Test RE 1.220385886326278\n",
      "24 Train Loss 6514.5205 Test MSE 11743.638168377402 Test RE 1.207412543304665\n",
      "25 Train Loss 6407.671 Test MSE 11718.329239116812 Test RE 1.2061107831443416\n",
      "26 Train Loss 6338.4585 Test MSE 11750.196157791172 Test RE 1.207749623408544\n",
      "27 Train Loss 6263.1504 Test MSE 11907.364682778292 Test RE 1.2158001139686916\n",
      "28 Train Loss 6179.0356 Test MSE 11792.442387805593 Test RE 1.2099188250338473\n",
      "29 Train Loss 6094.665 Test MSE 11694.706288202759 Test RE 1.2048944719739265\n",
      "30 Train Loss 5990.4775 Test MSE 11588.384278140533 Test RE 1.1994048384689755\n",
      "31 Train Loss 5931.007 Test MSE 11497.716287906896 Test RE 1.1947035284652827\n",
      "32 Train Loss 5876.999 Test MSE 11282.662421358391 Test RE 1.1834778918859379\n",
      "33 Train Loss 5830.3438 Test MSE 11198.03062910484 Test RE 1.1790308746363367\n",
      "34 Train Loss 5770.994 Test MSE 11089.574942717627 Test RE 1.1733073802580698\n",
      "35 Train Loss 5718.173 Test MSE 10786.673721159737 Test RE 1.15717255144456\n",
      "36 Train Loss 5657.4995 Test MSE 10590.264567549213 Test RE 1.146588963820154\n",
      "37 Train Loss 5598.8677 Test MSE 10374.717610017902 Test RE 1.1348605375652627\n",
      "38 Train Loss 5563.766 Test MSE 10361.325275807514 Test RE 1.134127826559891\n",
      "39 Train Loss 5530.739 Test MSE 10340.929608071972 Test RE 1.1330110442914936\n",
      "40 Train Loss 5505.096 Test MSE 10296.725113259008 Test RE 1.1305868028887538\n",
      "41 Train Loss 5473.242 Test MSE 10234.867937753492 Test RE 1.1271857090940247\n",
      "42 Train Loss 5431.935 Test MSE 10143.802691754197 Test RE 1.1221599093642767\n",
      "43 Train Loss 5403.0317 Test MSE 10141.61148158229 Test RE 1.1220387013180462\n",
      "44 Train Loss 5374.3657 Test MSE 9992.020201308913 Test RE 1.1137327846279086\n",
      "45 Train Loss 5355.7817 Test MSE 9941.765327658784 Test RE 1.1109284941692348\n",
      "46 Train Loss 5314.374 Test MSE 9748.076416201584 Test RE 1.1000535195137355\n",
      "47 Train Loss 5182.446 Test MSE 9477.44710544113 Test RE 1.084676015241554\n",
      "48 Train Loss 5080.17 Test MSE 9338.67064917459 Test RE 1.0767053771602018\n",
      "49 Train Loss 4995.9937 Test MSE 9317.285334105241 Test RE 1.0754718567929347\n",
      "50 Train Loss 4920.169 Test MSE 9330.876515360003 Test RE 1.0762559696459777\n",
      "51 Train Loss 4857.1743 Test MSE 9152.429566439712 Test RE 1.0659149416518294\n",
      "52 Train Loss 4801.584 Test MSE 9038.52838112054 Test RE 1.0592615675779877\n",
      "53 Train Loss 4738.9546 Test MSE 8821.474677056858 Test RE 1.0464655799928255\n",
      "54 Train Loss 4698.1567 Test MSE 8712.94354949226 Test RE 1.0400082932985522\n",
      "55 Train Loss 4650.715 Test MSE 8579.140660683364 Test RE 1.0319918001819177\n",
      "56 Train Loss 4612.012 Test MSE 8517.384287739947 Test RE 1.0282707294797764\n",
      "57 Train Loss 4571.7603 Test MSE 8449.588872063547 Test RE 1.0241702148781409\n",
      "58 Train Loss 4428.772 Test MSE 8101.839763356902 Test RE 1.0028735496091985\n",
      "59 Train Loss 4354.4595 Test MSE 8027.594005387646 Test RE 0.9982677759752342\n",
      "60 Train Loss 4274.188 Test MSE 7843.002736776024 Test RE 0.9867236455435904\n",
      "61 Train Loss 4158.78 Test MSE 7611.585768688631 Test RE 0.9720574320002814\n",
      "62 Train Loss 4039.6687 Test MSE 7366.864659039644 Test RE 0.9563033958700312\n",
      "63 Train Loss 3952.6816 Test MSE 6957.584465653753 Test RE 0.929359186195794\n",
      "64 Train Loss 3885.8872 Test MSE 6867.384627518402 Test RE 0.9233153130682281\n",
      "65 Train Loss 3801.345 Test MSE 6655.939581810762 Test RE 0.9089898585180687\n",
      "66 Train Loss 3750.295 Test MSE 6460.369879595399 Test RE 0.8955359902280764\n",
      "67 Train Loss 3664.502 Test MSE 6445.069450770264 Test RE 0.8944748894401218\n",
      "68 Train Loss 3617.0251 Test MSE 6356.908023071966 Test RE 0.8883361102202117\n",
      "69 Train Loss 3565.8496 Test MSE 6322.221891949501 Test RE 0.8859092157260166\n",
      "70 Train Loss 3529.0376 Test MSE 6149.384051480283 Test RE 0.8737157426767506\n",
      "71 Train Loss 3458.5369 Test MSE 6038.116671912765 Test RE 0.8657751226920458\n",
      "72 Train Loss 3400.4775 Test MSE 5885.657741854831 Test RE 0.8547750837598151\n",
      "73 Train Loss 3359.9 Test MSE 5838.676431846298 Test RE 0.8513566965543737\n",
      "74 Train Loss 3315.7163 Test MSE 5683.261467089701 Test RE 0.8399494901065456\n",
      "75 Train Loss 3267.7249 Test MSE 5548.091211966756 Test RE 0.8299007336879076\n",
      "76 Train Loss 3233.3286 Test MSE 5504.73122822533 Test RE 0.8266514120394982\n",
      "77 Train Loss 3208.2124 Test MSE 5486.596990962869 Test RE 0.82528866983143\n",
      "78 Train Loss 3194.5957 Test MSE 5443.227511114009 Test RE 0.8220204005769959\n",
      "79 Train Loss 3166.0566 Test MSE 5348.687790482657 Test RE 0.8148505753192646\n",
      "80 Train Loss 3117.6675 Test MSE 5166.15537252389 Test RE 0.8008258513282174\n",
      "81 Train Loss 3086.1584 Test MSE 5146.365185057287 Test RE 0.799290502545653\n",
      "82 Train Loss 3063.0208 Test MSE 5133.338057484803 Test RE 0.7982782291590376\n",
      "83 Train Loss 3029.378 Test MSE 5094.947726359103 Test RE 0.7952876138623888\n",
      "84 Train Loss 3001.417 Test MSE 4987.759630358136 Test RE 0.7868774692133766\n",
      "85 Train Loss 2990.6567 Test MSE 4908.293772578872 Test RE 0.7805839666177049\n",
      "86 Train Loss 2959.832 Test MSE 4866.373090309295 Test RE 0.7772434186452278\n",
      "87 Train Loss 2943.3738 Test MSE 4833.19761716608 Test RE 0.7745895412312576\n",
      "88 Train Loss 2911.6257 Test MSE 4810.515127682155 Test RE 0.7727698058457086\n",
      "89 Train Loss 2894.2246 Test MSE 4765.29745205377 Test RE 0.7691293063064601\n",
      "90 Train Loss 2864.2317 Test MSE 4626.607470806857 Test RE 0.7578542313128136\n",
      "91 Train Loss 2847.9348 Test MSE 4593.868268317924 Test RE 0.7551680738329988\n",
      "92 Train Loss 2840.0688 Test MSE 4572.309641125619 Test RE 0.7533940207275795\n",
      "93 Train Loss 2826.3306 Test MSE 4571.475806205309 Test RE 0.7533253207776573\n",
      "94 Train Loss 2809.777 Test MSE 4591.386879624374 Test RE 0.7549640933831631\n",
      "95 Train Loss 2791.157 Test MSE 4570.793924020644 Test RE 0.7532691356096919\n",
      "96 Train Loss 2770.877 Test MSE 4524.314724923114 Test RE 0.7494294518006692\n",
      "97 Train Loss 2748.4019 Test MSE 4513.064118635477 Test RE 0.7484970692836992\n",
      "98 Train Loss 2723.9307 Test MSE 4466.505114792178 Test RE 0.7446261265886995\n",
      "99 Train Loss 2696.032 Test MSE 4412.30883034631 Test RE 0.7400947160230298\n",
      "100 Train Loss 2675.7375 Test MSE 4375.081435689728 Test RE 0.7369659505179307\n",
      "101 Train Loss 2664.6404 Test MSE 4332.697047756262 Test RE 0.7333875176813622\n",
      "102 Train Loss 2649.5771 Test MSE 4338.8646575847715 Test RE 0.7339093219342382\n",
      "103 Train Loss 2638.9304 Test MSE 4323.6661852176185 Test RE 0.7326228003913843\n",
      "104 Train Loss 2626.4836 Test MSE 4275.447872194279 Test RE 0.7285261753183945\n",
      "105 Train Loss 2616.063 Test MSE 4265.676725530357 Test RE 0.7276932090226793\n",
      "106 Train Loss 2596.2297 Test MSE 4222.910614446836 Test RE 0.7240362273707123\n",
      "107 Train Loss 2581.8096 Test MSE 4225.588368485187 Test RE 0.7242657472278174\n",
      "108 Train Loss 2566.4424 Test MSE 4189.452283557478 Test RE 0.7211622358302144\n",
      "109 Train Loss 2551.728 Test MSE 4161.729067190968 Test RE 0.7187721713932181\n",
      "110 Train Loss 2536.1877 Test MSE 4116.78524861623 Test RE 0.7148805129103175\n",
      "111 Train Loss 2529.4834 Test MSE 4105.091839620632 Test RE 0.7138645096200702\n",
      "112 Train Loss 2515.5552 Test MSE 4075.466317681989 Test RE 0.7112839457727895\n",
      "113 Train Loss 2494.1143 Test MSE 3998.8895783531552 Test RE 0.7045698556963773\n",
      "114 Train Loss 2462.7402 Test MSE 3908.5626363587016 Test RE 0.696566991303085\n",
      "115 Train Loss 2446.746 Test MSE 3890.4295519899024 Test RE 0.6949493132721878\n",
      "116 Train Loss 2433.7615 Test MSE 3850.1285954169057 Test RE 0.6913404532112696\n",
      "117 Train Loss 2422.8853 Test MSE 3805.2530519221336 Test RE 0.6872996516986826\n",
      "118 Train Loss 2413.2666 Test MSE 3789.3863774204583 Test RE 0.6858652462571894\n",
      "119 Train Loss 2405.0425 Test MSE 3764.236771819342 Test RE 0.6835854634293071\n",
      "120 Train Loss 2395.828 Test MSE 3734.9965741166443 Test RE 0.6809252771391933\n",
      "121 Train Loss 2385.7854 Test MSE 3736.192762010573 Test RE 0.6810343066058041\n",
      "122 Train Loss 2377.8252 Test MSE 3717.0577186166597 Test RE 0.6792880972715044\n",
      "123 Train Loss 2373.1406 Test MSE 3703.186563513992 Test RE 0.6780194436292332\n",
      "124 Train Loss 2370.4102 Test MSE 3698.72509514654 Test RE 0.677610893602176\n",
      "125 Train Loss 2365.3503 Test MSE 3674.2208498565255 Test RE 0.6753625599525539\n",
      "126 Train Loss 2360.2024 Test MSE 3659.7738135321865 Test RE 0.6740334894018096\n",
      "127 Train Loss 2354.9285 Test MSE 3635.012255873315 Test RE 0.6717494075608568\n",
      "128 Train Loss 2350.5103 Test MSE 3607.5658528238237 Test RE 0.6692085578539578\n",
      "129 Train Loss 2344.4778 Test MSE 3586.272220779542 Test RE 0.6672306354657912\n",
      "130 Train Loss 2333.8198 Test MSE 3564.621662578269 Test RE 0.6652135291767947\n",
      "131 Train Loss 2328.7175 Test MSE 3565.9645482901783 Test RE 0.6653388189987192\n",
      "132 Train Loss 2317.8484 Test MSE 3555.9964002876923 Test RE 0.6644082380773874\n",
      "133 Train Loss 2312.8357 Test MSE 3555.2297735508123 Test RE 0.6643366153143673\n",
      "134 Train Loss 2307.4607 Test MSE 3538.9947741277465 Test RE 0.6628180291072264\n",
      "135 Train Loss 2299.652 Test MSE 3542.252708218211 Test RE 0.6631230480234906\n",
      "136 Train Loss 2291.39 Test MSE 3512.2625325274194 Test RE 0.660309944222156\n",
      "137 Train Loss 2285.9224 Test MSE 3494.2040148113706 Test RE 0.6586102441677288\n",
      "138 Train Loss 2279.9648 Test MSE 3485.3645946493307 Test RE 0.6577766610146906\n",
      "139 Train Loss 2276.5085 Test MSE 3467.7138260399684 Test RE 0.6561089731743162\n",
      "140 Train Loss 2271.0198 Test MSE 3465.759243141018 Test RE 0.6559240386319086\n",
      "141 Train Loss 2264.4963 Test MSE 3451.7281862962946 Test RE 0.6545949444017043\n",
      "142 Train Loss 2255.4285 Test MSE 3465.79514336875 Test RE 0.655927435832887\n",
      "143 Train Loss 2249.4954 Test MSE 3461.336777846431 Test RE 0.6555054106960922\n",
      "144 Train Loss 2244.7827 Test MSE 3460.9653420630575 Test RE 0.6554702386348901\n",
      "145 Train Loss 2234.85 Test MSE 3446.22985683537 Test RE 0.6540733776795077\n",
      "146 Train Loss 2222.9812 Test MSE 3431.4147311196857 Test RE 0.6526659532571171\n",
      "147 Train Loss 2208.9277 Test MSE 3416.8049066512585 Test RE 0.6512750537304596\n",
      "148 Train Loss 2190.3179 Test MSE 3404.0671141752905 Test RE 0.6500599488577818\n",
      "149 Train Loss 2184.0696 Test MSE 3393.0428174365943 Test RE 0.6490064641280586\n",
      "150 Train Loss 2175.7927 Test MSE 3390.6190596026795 Test RE 0.6487746197918975\n",
      "151 Train Loss 2169.5698 Test MSE 3397.6366530505807 Test RE 0.649445659963989\n",
      "152 Train Loss 2163.1345 Test MSE 3392.9059421892484 Test RE 0.6489933735452126\n",
      "153 Train Loss 2155.8518 Test MSE 3398.946298929878 Test RE 0.649570814883839\n",
      "154 Train Loss 2146.6729 Test MSE 3386.3757973451825 Test RE 0.6483685313093716\n",
      "155 Train Loss 2139.4778 Test MSE 3383.240401503973 Test RE 0.6480683043274098\n",
      "156 Train Loss 2134.2524 Test MSE 3384.21993723009 Test RE 0.6481621138177467\n",
      "157 Train Loss 2127.4763 Test MSE 3376.9803499267055 Test RE 0.6474684623239977\n",
      "158 Train Loss 2120.5796 Test MSE 3353.1057460048714 Test RE 0.6451756637494158\n",
      "159 Train Loss 2114.3523 Test MSE 3347.527208224098 Test RE 0.6446387532999368\n",
      "160 Train Loss 2112.1755 Test MSE 3341.1964257635555 Test RE 0.6440289002956571\n",
      "161 Train Loss 2109.5012 Test MSE 3344.825699648799 Test RE 0.6443785838513274\n",
      "162 Train Loss 2102.5508 Test MSE 3343.231070997446 Test RE 0.6442249634323922\n",
      "163 Train Loss 2093.4004 Test MSE 3328.753845619067 Test RE 0.6428286033741906\n",
      "164 Train Loss 2086.268 Test MSE 3321.7168159571743 Test RE 0.6421487698044251\n",
      "165 Train Loss 2082.8223 Test MSE 3324.7191914691953 Test RE 0.6424389113772522\n",
      "166 Train Loss 2069.0842 Test MSE 3306.51533050667 Test RE 0.6406777219094834\n",
      "167 Train Loss 2055.0127 Test MSE 3296.581030290478 Test RE 0.6397145519248617\n",
      "168 Train Loss 2048.7856 Test MSE 3286.4892301467585 Test RE 0.6387346245769219\n",
      "169 Train Loss 2037.4509 Test MSE 3265.572606966511 Test RE 0.6366987899986145\n",
      "170 Train Loss 2029.3938 Test MSE 3249.6477915968053 Test RE 0.6351444374527017\n",
      "171 Train Loss 2022.4305 Test MSE 3225.970141465895 Test RE 0.6328263059403203\n",
      "172 Train Loss 2018.7545 Test MSE 3221.7561569557656 Test RE 0.6324128502097103\n",
      "173 Train Loss 2013.5586 Test MSE 3202.1057736948774 Test RE 0.6304812698147721\n",
      "174 Train Loss 2009.72 Test MSE 3190.7220733564013 Test RE 0.6293595704423076\n",
      "175 Train Loss 2005.1462 Test MSE 3189.467081530932 Test RE 0.6292357867376426\n",
      "176 Train Loss 2001.9333 Test MSE 3191.4961517496145 Test RE 0.6294359080376846\n",
      "177 Train Loss 1993.9406 Test MSE 3175.5957885839043 Test RE 0.627865992902956\n",
      "178 Train Loss 1970.7458 Test MSE 3123.5447452875605 Test RE 0.6226990715467194\n",
      "179 Train Loss 1950.6307 Test MSE 3114.4178863490583 Test RE 0.6217886565046591\n",
      "180 Train Loss 1947.9475 Test MSE 3107.409542649261 Test RE 0.6210886600587959\n",
      "181 Train Loss 1944.4084 Test MSE 3078.8545676362073 Test RE 0.6182283832361899\n",
      "182 Train Loss 1932.137 Test MSE 3074.4519190957553 Test RE 0.6177862032047585\n",
      "183 Train Loss 1928.4706 Test MSE 3065.7520430752447 Test RE 0.6169114991728778\n",
      "184 Train Loss 1923.7253 Test MSE 3048.566712311114 Test RE 0.6151799946081588\n",
      "185 Train Loss 1914.3693 Test MSE 3022.230165519396 Test RE 0.6125169627898349\n",
      "186 Train Loss 1897.5088 Test MSE 2993.585256843773 Test RE 0.6096073126231921\n",
      "187 Train Loss 1894.3745 Test MSE 2983.215271675655 Test RE 0.6085505358186595\n",
      "188 Train Loss 1889.3439 Test MSE 2959.4512142491953 Test RE 0.6061218567099073\n",
      "189 Train Loss 1881.7288 Test MSE 2948.431456775389 Test RE 0.6049923322265269\n",
      "190 Train Loss 1864.5731 Test MSE 2939.0407396156447 Test RE 0.6040281173712334\n",
      "191 Train Loss 1853.895 Test MSE 2929.1984272458567 Test RE 0.6030158791107848\n",
      "192 Train Loss 1848.6577 Test MSE 2907.2185578172284 Test RE 0.6007491893840272\n",
      "193 Train Loss 1844.1072 Test MSE 2896.8995966210514 Test RE 0.5996820838233081\n",
      "194 Train Loss 1840.5602 Test MSE 2869.9362952236183 Test RE 0.5968847466848788\n",
      "195 Train Loss 1837.3792 Test MSE 2872.0475702004815 Test RE 0.597104256113026\n",
      "196 Train Loss 1832.4594 Test MSE 2853.882276074866 Test RE 0.5952129608984399\n",
      "197 Train Loss 1824.1467 Test MSE 2824.8982578541318 Test RE 0.5921827572255568\n",
      "198 Train Loss 1815.468 Test MSE 2799.763807214703 Test RE 0.5895424065048069\n",
      "199 Train Loss 1808.3091 Test MSE 2767.8286922028274 Test RE 0.5861704970457878\n",
      "Training time: 35.44\n",
      "Training time: 35.44\n",
      "1D_FODE_atanh_medium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 15982.508 Test MSE 10544.191276105617 Test RE 1.1440921088540548\n",
      "1 Train Loss 14533.68 Test MSE 12880.786812731127 Test RE 1.2645195512485625\n",
      "2 Train Loss 13943.57 Test MSE 12616.906070692323 Test RE 1.2514998079103008\n",
      "3 Train Loss 13594.246 Test MSE 12968.606431833456 Test RE 1.2688228981166618\n",
      "4 Train Loss 13121.825 Test MSE 12237.45434514802 Test RE 1.232536799175879\n",
      "5 Train Loss 12483.239 Test MSE 12481.692894947979 Test RE 1.2447756918080914\n",
      "6 Train Loss 12192.559 Test MSE 12301.754239626343 Test RE 1.2357706479830086\n",
      "7 Train Loss 11892.019 Test MSE 11599.880366591311 Test RE 1.199999617077201\n",
      "8 Train Loss 11539.538 Test MSE 10757.701497917025 Test RE 1.1556174657596787\n",
      "9 Train Loss 11195.826 Test MSE 10265.576840500753 Test RE 1.1288754578429332\n",
      "10 Train Loss 10807.18 Test MSE 9243.523357114016 Test RE 1.0712063139046377\n",
      "11 Train Loss 10505.14 Test MSE 8660.944220370664 Test RE 1.0369002355789434\n",
      "12 Train Loss 10328.69 Test MSE 8084.209694909635 Test RE 1.0017818001491796\n",
      "13 Train Loss 10072.325 Test MSE 7302.446781045386 Test RE 0.9521131264128553\n",
      "14 Train Loss 9892.837 Test MSE 7007.052078384426 Test RE 0.9326571521610477\n",
      "15 Train Loss 9805.813 Test MSE 6858.55308996612 Test RE 0.922721424883791\n",
      "16 Train Loss 9713.563 Test MSE 6727.661859391406 Test RE 0.9138742277680438\n",
      "17 Train Loss 9659.756 Test MSE 6627.029967289437 Test RE 0.9070136429145605\n",
      "18 Train Loss 9589.146 Test MSE 6424.368894808096 Test RE 0.8930372773787896\n",
      "19 Train Loss 9552.343 Test MSE 6412.5401605152 Test RE 0.8922147555265773\n",
      "20 Train Loss 9502.913 Test MSE 6251.897262116992 Test RE 0.8809682741147711\n",
      "21 Train Loss 9473.28 Test MSE 6116.159811044386 Test RE 0.8713522655214293\n",
      "22 Train Loss 9448.986 Test MSE 6039.285159181434 Test RE 0.865858890390236\n",
      "23 Train Loss 9421.147 Test MSE 5928.373546246434 Test RE 0.8578712879564375\n",
      "24 Train Loss 9385.338 Test MSE 5863.841942461598 Test RE 0.8531894569286512\n",
      "25 Train Loss 9344.248 Test MSE 5748.027037301495 Test RE 0.8447218995653276\n",
      "26 Train Loss 9308.243 Test MSE 5683.417909965159 Test RE 0.8399610506523658\n",
      "27 Train Loss 9290.137 Test MSE 5668.591445076527 Test RE 0.8388647221870038\n",
      "28 Train Loss 9279.228 Test MSE 5667.192271754956 Test RE 0.8387611876858064\n",
      "29 Train Loss 9244.586 Test MSE 5660.407618027796 Test RE 0.8382589629362309\n",
      "30 Train Loss 9223.56 Test MSE 5661.0497856909815 Test RE 0.8383065114141041\n",
      "31 Train Loss 9204.781 Test MSE 5593.4020061586925 Test RE 0.8332827073933228\n",
      "32 Train Loss 9179.293 Test MSE 5505.634350356916 Test RE 0.8267192206695556\n",
      "33 Train Loss 9150.985 Test MSE 5467.7510892486525 Test RE 0.8238700593358096\n",
      "34 Train Loss 9126.975 Test MSE 5532.825943164637 Test RE 0.828758234080124\n",
      "35 Train Loss 9062.438 Test MSE 5630.637535519586 Test RE 0.8360517069764829\n",
      "36 Train Loss 9011.421 Test MSE 5644.097751142805 Test RE 0.8370504143857876\n",
      "37 Train Loss 8948.885 Test MSE 5653.800119784789 Test RE 0.8377695624966287\n",
      "38 Train Loss 8920.123 Test MSE 5577.685146432196 Test RE 0.8321111663204709\n",
      "39 Train Loss 8858.427 Test MSE 5415.2214749986615 Test RE 0.819902978375061\n",
      "40 Train Loss 8817.079 Test MSE 5292.060828687914 Test RE 0.8105256554905529\n",
      "41 Train Loss 8805.8545 Test MSE 5245.5854294351175 Test RE 0.8069587489344773\n",
      "42 Train Loss 8789.906 Test MSE 5190.323872744887 Test RE 0.8026968922306648\n",
      "43 Train Loss 8777.795 Test MSE 5184.859295182752 Test RE 0.8022742254871456\n",
      "44 Train Loss 8760.626 Test MSE 5112.340850716583 Test RE 0.7966439330873587\n",
      "45 Train Loss 8730.298 Test MSE 5054.860364782118 Test RE 0.7921527494676971\n",
      "46 Train Loss 8707.716 Test MSE 4993.864213026852 Test RE 0.7873588566529733\n",
      "47 Train Loss 8689.904 Test MSE 4957.883671550927 Test RE 0.7845172885023939\n",
      "48 Train Loss 8663.882 Test MSE 4887.322350602423 Test RE 0.7789146004652302\n",
      "49 Train Loss 8639.271 Test MSE 4814.185756328872 Test RE 0.7730645778207793\n",
      "50 Train Loss 8613.915 Test MSE 4760.658207766153 Test RE 0.7687548231133685\n",
      "51 Train Loss 8571.529 Test MSE 4757.200581057671 Test RE 0.7684756022681564\n",
      "52 Train Loss 8518.848 Test MSE 4717.470596058657 Test RE 0.7652598940398763\n",
      "53 Train Loss 8467.068 Test MSE 4634.584820149224 Test RE 0.7585073085623019\n",
      "54 Train Loss 8444.385 Test MSE 4634.300026280519 Test RE 0.758484003179199\n",
      "55 Train Loss 8401.883 Test MSE 4637.122347308569 Test RE 0.7587149290488672\n",
      "56 Train Loss 8373.62 Test MSE 4653.038657879016 Test RE 0.7600159080847059\n",
      "57 Train Loss 8338.876 Test MSE 4553.739285575065 Test RE 0.7518625157883149\n",
      "58 Train Loss 8309.342 Test MSE 4561.24147453219 Test RE 0.7524815996909165\n",
      "59 Train Loss 8273.945 Test MSE 4529.0674884517875 Test RE 0.7498229838873312\n",
      "60 Train Loss 8243.085 Test MSE 4532.487393498763 Test RE 0.7501060266455946\n",
      "61 Train Loss 8228.335 Test MSE 4528.4856950103795 Test RE 0.7497748220851594\n",
      "62 Train Loss 8201.273 Test MSE 4532.075941332284 Test RE 0.7500719791428027\n",
      "63 Train Loss 8184.2104 Test MSE 4550.890936451857 Test RE 0.7516273352263787\n",
      "64 Train Loss 8173.193 Test MSE 4522.776665267303 Test RE 0.7493020551389712\n",
      "65 Train Loss 8149.9175 Test MSE 4525.659240421539 Test RE 0.7495407995655068\n",
      "66 Train Loss 8140.7744 Test MSE 4484.723497218574 Test RE 0.7461432051428699\n",
      "67 Train Loss 8126.615 Test MSE 4439.439182183534 Test RE 0.7423665718601641\n",
      "68 Train Loss 8114.455 Test MSE 4468.063751605857 Test RE 0.7447560380552638\n",
      "69 Train Loss 8105.44 Test MSE 4463.1660866412985 Test RE 0.7443477442310389\n",
      "70 Train Loss 8099.652 Test MSE 4451.3443212521815 Test RE 0.7433612988626271\n",
      "71 Train Loss 8091.563 Test MSE 4443.353564333861 Test RE 0.7426937828056717\n",
      "72 Train Loss 8088.7017 Test MSE 4437.502984959502 Test RE 0.742204667980792\n",
      "73 Train Loss 8084.558 Test MSE 4431.0618527693505 Test RE 0.7416658092515486\n",
      "74 Train Loss 8079.4175 Test MSE 4402.41514562271 Test RE 0.7392644961382292\n",
      "75 Train Loss 8073.272 Test MSE 4385.486907525014 Test RE 0.7378418112748509\n",
      "76 Train Loss 8064.2134 Test MSE 4330.599602660013 Test RE 0.733209980890187\n",
      "77 Train Loss 8049.0303 Test MSE 4281.985396866743 Test RE 0.7290829519079876\n",
      "78 Train Loss 8033.6094 Test MSE 4210.018428309123 Test RE 0.7229301721102905\n",
      "79 Train Loss 8025.0864 Test MSE 4173.439988958104 Test RE 0.7197827575271557\n",
      "80 Train Loss 8021.393 Test MSE 4159.722960233795 Test RE 0.7185989131586485\n",
      "81 Train Loss 8017.1577 Test MSE 4141.550684680749 Test RE 0.7170275500130012\n",
      "82 Train Loss 8000.5566 Test MSE 4083.7636190473586 Test RE 0.7120076343019391\n",
      "83 Train Loss 7986.352 Test MSE 4054.3939035729622 Test RE 0.7094426969922955\n",
      "84 Train Loss 7983.8604 Test MSE 4071.514457798904 Test RE 0.7109390065667414\n",
      "85 Train Loss 7978.769 Test MSE 4077.4157954698258 Test RE 0.7114540448930677\n",
      "86 Train Loss 7966.7554 Test MSE 4074.005454341608 Test RE 0.7111564533961147\n",
      "87 Train Loss 7956.1465 Test MSE 4113.020846865066 Test RE 0.7145535936322162\n",
      "88 Train Loss 7950.9204 Test MSE 4078.3437527364404 Test RE 0.7115349982990266\n",
      "89 Train Loss 7944.508 Test MSE 4050.515114483553 Test RE 0.7091032582104008\n",
      "90 Train Loss 7933.2114 Test MSE 3964.465006428765 Test RE 0.7015306444304203\n",
      "91 Train Loss 7923.366 Test MSE 3948.7494080590086 Test RE 0.7001387893362009\n",
      "92 Train Loss 7919.3843 Test MSE 3958.366525633074 Test RE 0.700990859399717\n",
      "93 Train Loss 7915.5073 Test MSE 3954.570148052398 Test RE 0.700654626719917\n",
      "94 Train Loss 7911.3423 Test MSE 3937.7877778667776 Test RE 0.6991663300494906\n",
      "95 Train Loss 7899.7764 Test MSE 3950.1510552467585 Test RE 0.7002630388636373\n",
      "96 Train Loss 7895.4604 Test MSE 3960.665870145946 Test RE 0.701194426385538\n",
      "97 Train Loss 7883.3696 Test MSE 3966.551503753504 Test RE 0.7017152278823295\n",
      "98 Train Loss 7872.6206 Test MSE 3952.7553714810065 Test RE 0.7004938409119151\n",
      "99 Train Loss 7865.3887 Test MSE 3933.2872952765615 Test RE 0.6987666785645726\n",
      "100 Train Loss 7861.929 Test MSE 3912.898150117305 Test RE 0.6969532124096728\n",
      "101 Train Loss 7857.7603 Test MSE 3894.9616531240745 Test RE 0.6953539811626865\n",
      "102 Train Loss 7849.795 Test MSE 3902.5473028297342 Test RE 0.6960307716542069\n",
      "103 Train Loss 7839.7925 Test MSE 3911.3611027871607 Test RE 0.6968163119263402\n",
      "104 Train Loss 7836.1904 Test MSE 3901.673905737181 Test RE 0.6959528808278019\n",
      "105 Train Loss 7834.505 Test MSE 3908.639231564484 Test RE 0.6965738165014526\n",
      "106 Train Loss 7830.0513 Test MSE 3901.39070402297 Test RE 0.6959276226142415\n",
      "107 Train Loss 7823.36 Test MSE 3888.7224257740863 Test RE 0.694796824151274\n",
      "108 Train Loss 7817.9663 Test MSE 3867.0898189802833 Test RE 0.6928615834483841\n",
      "109 Train Loss 7811.6396 Test MSE 3853.6444951541894 Test RE 0.6916560438456706\n",
      "110 Train Loss 7809.7363 Test MSE 3856.812024087729 Test RE 0.6919402411197836\n",
      "111 Train Loss 7804.035 Test MSE 3850.569699778682 Test RE 0.6913800550775189\n",
      "112 Train Loss 7797.941 Test MSE 3834.4618947959766 Test RE 0.6899324399016643\n",
      "113 Train Loss 7791.6514 Test MSE 3820.7289351193235 Test RE 0.6886958500916506\n",
      "114 Train Loss 7785.4307 Test MSE 3847.997254593525 Test RE 0.6911490717973758\n",
      "115 Train Loss 7782.2134 Test MSE 3842.5878280796765 Test RE 0.6906631001681456\n",
      "116 Train Loss 7779.46 Test MSE 3841.998787363523 Test RE 0.6906101613288124\n",
      "117 Train Loss 7775.939 Test MSE 3837.3355027336574 Test RE 0.6901909147648909\n",
      "118 Train Loss 7772.161 Test MSE 3834.2211893507733 Test RE 0.6899107845682717\n",
      "119 Train Loss 7769.8706 Test MSE 3841.8855626296127 Test RE 0.6905999850205691\n",
      "120 Train Loss 7766.075 Test MSE 3847.751966133429 Test RE 0.6911270429883551\n",
      "121 Train Loss 7760.978 Test MSE 3851.468120228364 Test RE 0.6914607072667709\n",
      "122 Train Loss 7756.9644 Test MSE 3840.649130861927 Test RE 0.6904888483848879\n",
      "123 Train Loss 7754.995 Test MSE 3831.492657248787 Test RE 0.6896652615991361\n",
      "124 Train Loss 7753.423 Test MSE 3834.2214635129644 Test RE 0.689910809233965\n",
      "125 Train Loss 7752.3745 Test MSE 3834.994174312661 Test RE 0.6899803246078041\n",
      "126 Train Loss 7750.912 Test MSE 3833.7725336164617 Test RE 0.6898704189412286\n",
      "127 Train Loss 7748.6265 Test MSE 3845.9725789527693 Test RE 0.6909672191714884\n",
      "128 Train Loss 7746.83 Test MSE 3833.633041197219 Test RE 0.6898578683049786\n",
      "129 Train Loss 7744.5664 Test MSE 3828.2200292902744 Test RE 0.6893706636216843\n",
      "130 Train Loss 7740.5728 Test MSE 3828.156244562272 Test RE 0.6893649205474753\n",
      "131 Train Loss 7737.724 Test MSE 3840.5757316301733 Test RE 0.690482250334477\n",
      "132 Train Loss 7735.2925 Test MSE 3841.1768240642937 Test RE 0.6905362822618646\n",
      "133 Train Loss 7732.228 Test MSE 3859.404586961007 Test RE 0.6921727644063048\n",
      "134 Train Loss 7730.034 Test MSE 3858.948785578986 Test RE 0.6921318898865295\n",
      "135 Train Loss 7728.4653 Test MSE 3856.1930912035064 Test RE 0.691884718352587\n",
      "136 Train Loss 7724.8447 Test MSE 3852.3598348774103 Test RE 0.6915407481677864\n",
      "137 Train Loss 7719.471 Test MSE 3864.010054811541 Test RE 0.6925856297727171\n",
      "138 Train Loss 7712.841 Test MSE 3868.7430258097716 Test RE 0.6930096691097245\n",
      "139 Train Loss 7708.367 Test MSE 3861.7112972464033 Test RE 0.6923795843312133\n",
      "140 Train Loss 7704.5166 Test MSE 3864.7999426129936 Test RE 0.6926564159478978\n",
      "141 Train Loss 7701.9263 Test MSE 3867.949503745195 Test RE 0.6929385934837111\n",
      "142 Train Loss 7700.746 Test MSE 3869.2692934924944 Test RE 0.6930568027896031\n",
      "143 Train Loss 7699.9414 Test MSE 3870.7982475849144 Test RE 0.6931937210671891\n",
      "144 Train Loss 7698.1636 Test MSE 3872.112311228986 Test RE 0.6933113742376175\n",
      "145 Train Loss 7695.6064 Test MSE 3869.663440848568 Test RE 0.6930921013859866\n",
      "146 Train Loss 7693.638 Test MSE 3860.7258034938386 Test RE 0.6922912324011813\n",
      "147 Train Loss 7689.1177 Test MSE 3844.2015675970497 Test RE 0.6908081109519268\n",
      "148 Train Loss 7685.863 Test MSE 3838.3326361930444 Test RE 0.6902805821593252\n",
      "149 Train Loss 7683.388 Test MSE 3840.653776664664 Test RE 0.6904892660062198\n",
      "150 Train Loss 7682.3027 Test MSE 3830.2466346696415 Test RE 0.689553111003839\n",
      "151 Train Loss 7681.7505 Test MSE 3831.827946392072 Test RE 0.6896954368124014\n",
      "152 Train Loss 7680.72 Test MSE 3828.2528524498493 Test RE 0.6893736189474786\n",
      "153 Train Loss 7679.661 Test MSE 3829.456016639998 Test RE 0.6894819404879745\n",
      "154 Train Loss 7678.417 Test MSE 3821.9819533701466 Test RE 0.688808770655255\n",
      "155 Train Loss 7673.456 Test MSE 3803.2064434691674 Test RE 0.6871147990169211\n",
      "156 Train Loss 7671.8047 Test MSE 3796.2821744423286 Test RE 0.6864890197816399\n",
      "157 Train Loss 7669.709 Test MSE 3804.761594256527 Test RE 0.68725526705662\n",
      "158 Train Loss 7668.978 Test MSE 3810.0533653758803 Test RE 0.6877330281228387\n",
      "159 Train Loss 7667.9595 Test MSE 3805.052936041306 Test RE 0.687281579131413\n",
      "160 Train Loss 7665.415 Test MSE 3805.8671279652885 Test RE 0.6873551062530644\n",
      "161 Train Loss 7663.9873 Test MSE 3814.7725517511935 Test RE 0.6881588142803828\n",
      "162 Train Loss 7663.134 Test MSE 3821.6311292348123 Test RE 0.6887771566536808\n",
      "163 Train Loss 7661.623 Test MSE 3809.761246474515 Test RE 0.6877066631814238\n",
      "164 Train Loss 7659.4478 Test MSE 3814.5076363121366 Test RE 0.6881349194010595\n",
      "165 Train Loss 7657.487 Test MSE 3813.1562454617842 Test RE 0.6880130135483149\n",
      "166 Train Loss 7655.2017 Test MSE 3806.474050513305 Test RE 0.6874099104104581\n",
      "167 Train Loss 7654.4175 Test MSE 3809.7453290910566 Test RE 0.6877052265425653\n",
      "168 Train Loss 7653.6274 Test MSE 3817.256813969792 Test RE 0.6883828497482111\n",
      "169 Train Loss 7651.9185 Test MSE 3822.461147463108 Test RE 0.6888519501826234\n",
      "170 Train Loss 7651.258 Test MSE 3819.848764661704 Test RE 0.6886165190704956\n",
      "171 Train Loss 7649.981 Test MSE 3812.7817837780585 Test RE 0.6879792304011927\n",
      "172 Train Loss 7649.016 Test MSE 3810.946012454334 Test RE 0.6878135869584037\n",
      "173 Train Loss 7648.0215 Test MSE 3806.3312596055684 Test RE 0.6873970170077539\n",
      "174 Train Loss 7646.9214 Test MSE 3805.1594912250525 Test RE 0.6872912022435598\n",
      "175 Train Loss 7645.98 Test MSE 3793.457231707237 Test RE 0.686233552328532\n",
      "176 Train Loss 7645.6025 Test MSE 3791.7718039423653 Test RE 0.6860810890860601\n",
      "177 Train Loss 7644.867 Test MSE 3800.3274167356567 Test RE 0.6868546768772267\n",
      "178 Train Loss 7641.9795 Test MSE 3802.5994690695093 Test RE 0.6870599666352952\n",
      "179 Train Loss 7638.268 Test MSE 3793.7125070858924 Test RE 0.6862566415018396\n",
      "180 Train Loss 7633.374 Test MSE 3783.878575006298 Test RE 0.6853666188340748\n",
      "181 Train Loss 7630.2456 Test MSE 3778.6091557521813 Test RE 0.684889232707932\n",
      "182 Train Loss 7624.2783 Test MSE 3774.670580245129 Test RE 0.6845321977337279\n",
      "183 Train Loss 7618.1597 Test MSE 3762.323431913983 Test RE 0.6834117100669465\n",
      "184 Train Loss 7614.111 Test MSE 3755.6431432071313 Test RE 0.6828047160165855\n",
      "185 Train Loss 7611.0 Test MSE 3761.929047717925 Test RE 0.6833758899352699\n",
      "186 Train Loss 7608.087 Test MSE 3779.6822106848495 Test RE 0.6849864737257807\n",
      "187 Train Loss 7604.895 Test MSE 3770.3171196678527 Test RE 0.6841373362977224\n",
      "188 Train Loss 7601.9683 Test MSE 3774.3877722749776 Test RE 0.6845065538022309\n",
      "189 Train Loss 7600.5547 Test MSE 3778.02685392277 Test RE 0.6848364583136225\n",
      "190 Train Loss 7599.7764 Test MSE 3775.3219259556017 Test RE 0.6845912555863917\n",
      "191 Train Loss 7598.616 Test MSE 3777.3336315251404 Test RE 0.6847736258127666\n",
      "192 Train Loss 7597.7163 Test MSE 3765.337038016914 Test RE 0.6836853603103467\n",
      "193 Train Loss 7596.5103 Test MSE 3761.8620049572287 Test RE 0.6833698005580117\n",
      "194 Train Loss 7593.8613 Test MSE 3753.7625827041857 Test RE 0.6826337444529261\n",
      "195 Train Loss 7588.763 Test MSE 3758.5175468755097 Test RE 0.6830659603516641\n",
      "196 Train Loss 7584.505 Test MSE 3736.592634350778 Test RE 0.681070750054138\n",
      "197 Train Loss 7582.394 Test MSE 3729.9753798453385 Test RE 0.6804674175507763\n",
      "198 Train Loss 7579.915 Test MSE 3708.5285839609096 Test RE 0.6785083048284298\n",
      "199 Train Loss 7577.6104 Test MSE 3708.2097510085696 Test RE 0.6784791375386322\n",
      "Training time: 35.16\n",
      "Training time: 35.16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "n_val = 3.0\n",
    "\n",
    "for reps in range(max_reps):  \n",
    "  print(label) \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  alpha_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers,n_val)\n",
    "\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.5, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  alpha_full.append(alpha_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "77a1e198-62ae-4129-82a3-1a1f3e433466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1D_FODE_atanh_medium'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "d2yA4xTDHldi"
   },
   "outputs": [],
   "source": [
    "#3,4,8,9,13,14,18,19,23,24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "1986cfc6-aa7b-43ff-e3e8-c586ef7bafd1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_atanh_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_atanh_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25585/41594696.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_atanh_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_atanh_tune0.mat'"
     ]
    }
   ],
   "source": [
    "s = set([3,4,8,9,13,14,18,19,23,24])\n",
    "for tune_reps in range(25):\n",
    "  if tune_reps not in s:\n",
    "    label = \"1D_FODE_atanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2eNXAFRRtWs",
    "outputId": "737b4c47-e8bf-4e68-c774-00d25a78ecb3"
   },
   "outputs": [],
   "source": [
    "lrn_tune[5]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "atanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
