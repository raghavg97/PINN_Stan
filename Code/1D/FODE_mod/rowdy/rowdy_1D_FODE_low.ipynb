{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "84a34ebd-2e54-4cae-ca1c-79397867998c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "94a6280c-bfd4-43c8-a396-40f22c70c38f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "150eeb9e-6cdc-4ff0-fd50-61a1c228e3a0"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/atanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "30d0ca6b-cde8-4b85-ccae-4eac06a2c482"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"low\"\n",
    "label = \"1D_FODE_rowdy\" + level\n",
    "extent = 1.0\n",
    "\n",
    "x = np.linspace(extent,-1*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        self.omega1.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        self.omega.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "\n",
    "                      \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "       \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "      \n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    omega_val.append(PINN.omega.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,123)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(i)\n",
    "\n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "509236d6-c6b5-4579-8ffe-6c945b3ae573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D_FODE_rowdylow\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 26.969318 Test MSE 0.4464314692885019 Test RE 1.9431766147661542\n",
      "1 Train Loss 3.0445251 Test MSE 1.2081286188728708 Test RE 3.1966233027843733\n",
      "2 Train Loss 2.4107065 Test MSE 1.4047952333737008 Test RE 3.4470008253585727\n",
      "3 Train Loss 0.7148338 Test MSE 0.0020442197215682647 Test RE 0.13149179737438935\n",
      "4 Train Loss 0.48248768 Test MSE 0.00018937674605103453 Test RE 0.040021945842567255\n",
      "5 Train Loss 0.19583355 Test MSE 0.005929095869576115 Test RE 0.22393867860973027\n",
      "6 Train Loss 0.066245824 Test MSE 0.001720200234254105 Test RE 0.12062140314511598\n",
      "7 Train Loss 0.008205947 Test MSE 0.002446664482007298 Test RE 0.14385404678711913\n",
      "8 Train Loss 0.0010093314 Test MSE 0.00011721459752994072 Test RE 0.031486596974968646\n",
      "9 Train Loss 6.216245e-05 Test MSE 1.2602006361548608e-08 Test RE 0.0003264786020601391\n",
      "10 Train Loss 5.42211e-05 Test MSE 9.619561428567248e-08 Test RE 0.0009020124066914441\n",
      "11 Train Loss 5.4068078e-05 Test MSE 9.829112134864635e-08 Test RE 0.0009117841109617273\n",
      "12 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "13 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "14 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "15 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "16 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "17 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "18 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "19 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "20 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "21 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "22 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "23 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "24 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "25 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "26 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "27 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "28 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "29 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "30 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "31 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "32 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "33 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "34 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "35 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "36 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "37 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "38 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "39 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "40 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "41 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "42 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "43 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "44 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "45 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "46 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "47 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "48 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "49 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "50 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "51 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "52 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "53 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "54 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "55 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "56 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "57 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "58 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "59 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "60 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "61 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "62 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "63 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "64 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "65 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "66 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "67 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "68 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "69 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "70 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "71 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "72 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "73 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "74 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "75 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "76 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "77 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "78 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "79 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "80 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "81 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "82 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "83 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "84 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "85 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "86 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "87 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "88 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "89 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "90 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "91 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "92 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "93 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "94 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "95 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "96 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "97 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "98 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "99 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "100 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "101 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "102 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "103 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "104 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "105 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "106 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "107 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "108 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "109 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "110 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "111 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "112 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "113 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "114 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "115 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "116 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "117 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "118 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "119 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "120 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "121 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "122 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "123 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "124 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "125 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "126 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "127 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "128 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "129 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "130 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "131 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "132 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "133 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "134 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "135 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "136 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "137 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "138 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "139 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "140 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "141 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "142 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "143 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "144 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "145 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "146 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "147 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "148 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "149 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "150 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "151 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "152 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "153 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "154 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "155 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "156 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "157 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "158 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "159 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "160 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "161 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "162 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "163 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "164 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "165 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "166 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "167 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "168 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "169 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "170 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "171 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "172 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "173 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "174 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "175 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "176 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "177 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "178 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "179 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "180 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "181 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "182 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "183 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "184 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "185 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "186 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "187 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "188 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "189 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "190 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "191 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "192 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "193 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "194 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "195 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "196 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "197 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "198 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "199 Train Loss 5.3928383e-05 Test MSE 9.787332763152364e-08 Test RE 0.0009098442443121068\n",
      "Training time: 7.75\n",
      "Training time: 7.75\n",
      "1D_FODE_rowdylow\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 3.6209455 Test MSE 1.2827187706019616 Test RE 3.293825594781068\n",
      "1 Train Loss 2.8783753 Test MSE 1.5833941232885973 Test RE 3.659564358985299\n",
      "2 Train Loss 1.3010364 Test MSE 1.0197030225264614 Test RE 2.936782125627799\n",
      "3 Train Loss 0.9832572 Test MSE 0.6109525823537754 Test RE 2.273205129294205\n",
      "4 Train Loss 0.6166322 Test MSE 0.30489347533464334 Test RE 1.605864658072562\n",
      "5 Train Loss 0.35514122 Test MSE 0.2877739424467126 Test RE 1.5601293539478505\n",
      "6 Train Loss 0.11042174 Test MSE 0.07269108510064201 Test RE 0.7841072164344435\n",
      "7 Train Loss 0.08180901 Test MSE 0.027827919115335255 Test RE 0.48514911233764074\n",
      "8 Train Loss 0.053706426 Test MSE 0.026670654799770932 Test RE 0.4749541798837596\n",
      "9 Train Loss 0.014183074 Test MSE 0.005166723120215022 Test RE 0.2090462923459951\n",
      "10 Train Loss 0.0065016365 Test MSE 0.0008456775109767566 Test RE 0.08457407678698572\n",
      "11 Train Loss 0.0062309126 Test MSE 0.0011641623290907315 Test RE 0.09922969257892253\n",
      "12 Train Loss 0.0048358524 Test MSE 0.0002508324612919232 Test RE 0.0460602981415399\n",
      "13 Train Loss 0.0045382003 Test MSE 0.00014153601786151126 Test RE 0.03459938355316239\n",
      "14 Train Loss 0.002805532 Test MSE 0.00022014515061172818 Test RE 0.04315085809819929\n",
      "15 Train Loss 0.0011856614 Test MSE 6.366540523820341e-06 Test RE 0.007338150740471227\n",
      "16 Train Loss 0.0007535396 Test MSE 1.2587068651685578e-06 Test RE 0.0032628504999648233\n",
      "17 Train Loss 0.0005626058 Test MSE 3.495715462809719e-06 Test RE 0.005437545608462524\n",
      "18 Train Loss 0.0003505587 Test MSE 5.693270629491968e-08 Test RE 0.0006939302010596964\n",
      "19 Train Loss 0.00020502303 Test MSE 3.9986843514143386e-08 Test RE 0.0005815585385069338\n",
      "20 Train Loss 0.0001736042 Test MSE 2.6912023863317944e-08 Test RE 0.00047709850372275195\n",
      "21 Train Loss 0.00014192882 Test MSE 6.168937354263682e-08 Test RE 0.000722337322304193\n",
      "22 Train Loss 8.557194e-05 Test MSE 3.957518660748511e-08 Test RE 0.000578557277204351\n",
      "23 Train Loss 8.3556144e-05 Test MSE 9.800190731635162e-09 Test RE 0.0002879069434840457\n",
      "24 Train Loss 8.27669e-05 Test MSE 1.4156244036607778e-08 Test RE 0.0003460261297744958\n",
      "25 Train Loss 8.220547e-05 Test MSE 5.24331484511187e-08 Test RE 0.0006659442036615694\n",
      "26 Train Loss 8.1818165e-05 Test MSE 1.0981077648846505e-07 Test RE 0.0009637343889053326\n",
      "27 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "28 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "29 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "30 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "31 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "32 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "33 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "34 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "35 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "36 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "37 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "38 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "39 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "40 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "41 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "42 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "43 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "44 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "45 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "46 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "47 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "48 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "49 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "50 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "51 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "52 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "53 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "54 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "55 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "56 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "57 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "58 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "59 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "60 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "61 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "62 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "63 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "64 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "65 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "66 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "67 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "68 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "69 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "70 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "71 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "72 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "73 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "74 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "75 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "76 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "77 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "78 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "79 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "80 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "81 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "82 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "83 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "84 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "85 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "86 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "87 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "88 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "89 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "90 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "91 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "92 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "93 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "94 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "95 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "96 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "97 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "98 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "99 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "100 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "101 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "102 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "103 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "104 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "105 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "106 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "107 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "108 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "109 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "110 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "111 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "112 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "113 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "114 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "115 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "116 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "117 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "118 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "119 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "120 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "121 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "122 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "123 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "124 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "125 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "126 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "127 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "128 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "129 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "130 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "131 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "132 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "133 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "134 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "135 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "136 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "137 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "138 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "139 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "140 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "141 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "142 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "143 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "144 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "145 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "146 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "147 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "148 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "149 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "150 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "151 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "152 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "153 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "154 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "155 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "156 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "157 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "158 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "159 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "160 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "161 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "162 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "163 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "164 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "165 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "166 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "167 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "168 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "169 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "170 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "171 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "172 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "173 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "174 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "175 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "176 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "177 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "178 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "179 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "180 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "181 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "182 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "183 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "184 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "185 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "186 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "187 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "188 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "189 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "190 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "191 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "192 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "193 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "194 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "195 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "196 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "197 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "198 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "199 Train Loss 8.1560385e-05 Test MSE 1.5873063793474218e-07 Test RE 0.0011586846558466705\n",
      "Training time: 12.16\n",
      "Training time: 12.16\n",
      "1D_FODE_rowdylow\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 32.85489 Test MSE 0.07291241740822066 Test RE 0.7853000473963087\n",
      "1 Train Loss 21.75851 Test MSE 0.4962521087548259 Test RE 2.0487362769034454\n",
      "2 Train Loss 3.141456 Test MSE 1.5031249916706426 Test RE 3.5655983716468285\n",
      "3 Train Loss 1.4381058 Test MSE 0.966663346297478 Test RE 2.8593841180630677\n",
      "4 Train Loss 0.9042715 Test MSE 0.7577484645769975 Test RE 2.531613526355401\n",
      "5 Train Loss 0.6067893 Test MSE 0.389234626489935 Test RE 1.8144316341598776\n",
      "6 Train Loss 0.48894256 Test MSE 0.3654271879756383 Test RE 1.7580665177309753\n",
      "7 Train Loss 0.40492433 Test MSE 0.23948032982608128 Test RE 1.4232126613812603\n",
      "8 Train Loss 0.24002266 Test MSE 0.1643225043144817 Test RE 1.1789174537932277\n",
      "9 Train Loss 0.17387028 Test MSE 0.13805992422594768 Test RE 1.0806092736138453\n",
      "10 Train Loss 0.070773795 Test MSE 0.048550141273063674 Test RE 0.6408112446055301\n",
      "11 Train Loss 0.025748814 Test MSE 0.002361802715532846 Test RE 0.14133726520875325\n",
      "12 Train Loss 0.012615332 Test MSE 0.00020161189707505774 Test RE 0.041294570459096964\n",
      "13 Train Loss 0.008109136 Test MSE 0.00038176963882985757 Test RE 0.056824492858360616\n",
      "14 Train Loss 0.0034446095 Test MSE 0.00012152184433758629 Test RE 0.03205989170479913\n",
      "15 Train Loss 0.0013450305 Test MSE 2.743237822783987e-05 Test RE 0.015232339296288871\n",
      "16 Train Loss 0.0007802027 Test MSE 0.00016657485693544324 Test RE 0.037535274770338724\n",
      "17 Train Loss 0.00035112273 Test MSE 1.1727877983617888e-05 Test RE 0.009959661869744821\n",
      "18 Train Loss 0.0002224117 Test MSE 6.381187528361308e-06 Test RE 0.007346587047363296\n",
      "19 Train Loss 0.00016261035 Test MSE 5.154228554357443e-07 Test RE 0.002087933734631346\n",
      "20 Train Loss 0.000120926234 Test MSE 1.5036596638117517e-06 Test RE 0.003566232469484371\n",
      "21 Train Loss 0.000106258914 Test MSE 5.707503718050951e-07 Test RE 0.002197141243316608\n",
      "22 Train Loss 0.000100315854 Test MSE 1.165471745035183e-07 Test RE 0.0009928548223244167\n",
      "23 Train Loss 9.725576e-05 Test MSE 1.0218275970272787e-07 Test RE 0.0009296590229833981\n",
      "24 Train Loss 9.675477e-05 Test MSE 1.188653514969639e-07 Test RE 0.0010026803741144175\n",
      "25 Train Loss 9.614786e-05 Test MSE 1.988995289160919e-07 Test RE 0.0012970351692294477\n",
      "26 Train Loss 9.578404e-05 Test MSE 2.1026851438582933e-07 Test RE 0.0013335889799461285\n",
      "27 Train Loss 9.540975e-05 Test MSE 2.785192655897063e-07 Test RE 0.0015348378322404205\n",
      "28 Train Loss 9.5049865e-05 Test MSE 3.259378100189721e-07 Test RE 0.0016603599401295156\n",
      "29 Train Loss 9.456117e-05 Test MSE 4.206466456331449e-07 Test RE 0.0018862254050613797\n",
      "30 Train Loss 9.423213e-05 Test MSE 4.79109528972663e-07 Test RE 0.0020130394188250093\n",
      "31 Train Loss 9.381498e-05 Test MSE 5.631732566555722e-07 Test RE 0.002182508212545542\n",
      "32 Train Loss 9.31088e-05 Test MSE 6.085869907090507e-07 Test RE 0.0022687999670303713\n",
      "33 Train Loss 9.228895e-05 Test MSE 7.522521022681902e-07 Test RE 0.0025224152300805107\n",
      "34 Train Loss 9.159282e-05 Test MSE 8.226021622171814e-07 Test RE 0.002637726717221203\n",
      "35 Train Loss 8.961355e-05 Test MSE 8.143329229567616e-07 Test RE 0.0026244353060933634\n",
      "36 Train Loss 8.8941146e-05 Test MSE 8.65385175619552e-07 Test RE 0.002705450551394167\n",
      "37 Train Loss 8.709425e-05 Test MSE 9.10048592627136e-07 Test RE 0.0027743878003622926\n",
      "38 Train Loss 8.536543e-05 Test MSE 8.244560019653895e-07 Test RE 0.0026406972726977355\n",
      "39 Train Loss 8.454197e-05 Test MSE 8.130846945376517e-07 Test RE 0.002622423137024846\n",
      "40 Train Loss 8.359287e-05 Test MSE 6.835972946758302e-07 Test RE 0.0024045568123635956\n",
      "41 Train Loss 6.2596766e-05 Test MSE 4.501869090386803e-07 Test RE 0.0019513326259011563\n",
      "42 Train Loss 4.3180913e-05 Test MSE 7.971717477972893e-09 Test RE 0.00025966345073694764\n",
      "43 Train Loss 2.7561797e-05 Test MSE 8.254426870258481e-08 Test RE 0.0008355613387437835\n",
      "44 Train Loss 2.1366912e-05 Test MSE 1.0936104395785275e-07 Test RE 0.0009617588660848768\n",
      "45 Train Loss 2.0714679e-05 Test MSE 6.365587299455281e-08 Test RE 0.0007337601371005964\n",
      "46 Train Loss 2.0260239e-05 Test MSE 3.47708427571102e-08 Test RE 0.0005423035949805843\n",
      "47 Train Loss 1.9951289e-05 Test MSE 1.636062247750538e-08 Test RE 0.000371993016285438\n",
      "48 Train Loss 1.9589776e-05 Test MSE 5.6773048033056616e-09 Test RE 0.0002191320898295117\n",
      "49 Train Loss 1.9249981e-05 Test MSE 4.533537528658751e-09 Test RE 0.00019581839315050355\n",
      "50 Train Loss 1.8948043e-05 Test MSE 1.0549372851442485e-08 Test RE 0.00029870892297336686\n",
      "51 Train Loss 1.8579962e-05 Test MSE 1.7984850261212193e-08 Test RE 0.00039002126635338867\n",
      "52 Train Loss 1.8348519e-05 Test MSE 2.2094360443480112e-08 Test RE 0.00043229040114489415\n",
      "53 Train Loss 1.800478e-05 Test MSE 2.355088360951248e-08 Test RE 0.00044631191172859964\n",
      "54 Train Loss 1.7529032e-05 Test MSE 2.006615285337968e-08 Test RE 0.0004119712725402451\n",
      "55 Train Loss 1.7010536e-05 Test MSE 1.8381231589254148e-08 Test RE 0.00039429582479737717\n",
      "56 Train Loss 1.6542961e-05 Test MSE 4.3844583840029054e-09 Test RE 0.00019257187147506756\n",
      "57 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "58 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "59 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "60 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "61 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "62 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "63 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "64 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "65 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "66 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "67 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "68 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "69 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "70 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "71 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "72 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "73 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "74 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "75 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "76 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "77 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "78 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "79 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "80 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "81 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "82 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "83 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "84 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "85 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "86 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "87 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "88 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "89 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "90 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "91 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "92 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "93 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "94 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "95 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "96 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "97 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "98 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "99 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "100 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "101 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "102 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "103 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "104 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "105 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "106 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "107 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "108 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "109 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "110 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "111 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "112 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "113 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "114 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "115 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "116 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "117 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "118 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "119 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "120 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "121 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "122 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "123 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "124 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "125 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "126 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "127 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "128 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "129 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "130 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "131 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "132 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "133 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "134 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "135 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "136 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "137 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "138 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "139 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "140 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "141 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "142 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "143 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "144 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "145 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "146 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "147 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "148 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "149 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "150 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "151 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "152 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "153 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "154 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "155 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "156 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "157 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "158 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "159 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "160 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "161 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "162 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "163 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "164 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "165 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "166 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "167 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "168 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "169 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "170 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "171 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "172 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "173 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "174 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "175 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "176 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "177 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "178 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "179 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "180 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "181 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "182 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "183 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "184 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "185 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "186 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "187 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "188 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "189 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "190 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "191 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "192 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "193 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "194 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "195 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "196 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "197 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "198 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "199 Train Loss 1.6246015e-05 Test MSE 2.9594817713875694e-09 Test RE 0.0001582131981680224\n",
      "Training time: 13.22\n",
      "Training time: 13.22\n",
      "1D_FODE_rowdylow\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 5.389349 Test MSE 1.3299005187598014 Test RE 3.3538563141464266\n",
      "1 Train Loss 3.5540323 Test MSE 1.538285913003257 Test RE 3.6070603318116516\n",
      "2 Train Loss 1.6216408 Test MSE 0.9011149395804928 Test RE 2.7607365809416784\n",
      "3 Train Loss 0.8712685 Test MSE 0.16263504212170374 Test RE 1.1728485578435066\n",
      "4 Train Loss 0.45721382 Test MSE 0.0011928527114765033 Test RE 0.10044499141123829\n",
      "5 Train Loss 0.27961996 Test MSE 0.0052808891467423635 Test RE 0.2113432591692703\n",
      "6 Train Loss 0.2042147 Test MSE 0.00030400918876024506 Test RE 0.05070820415443605\n",
      "7 Train Loss 0.19216262 Test MSE 0.00019674361772276653 Test RE 0.040792958295183625\n",
      "8 Train Loss 0.1237073 Test MSE 0.000571835295628359 Test RE 0.0695457113882442\n",
      "9 Train Loss 0.061975434 Test MSE 0.0005385410748915226 Test RE 0.06749075575155442\n",
      "10 Train Loss 0.050885793 Test MSE 0.0012151179609130513 Test RE 0.10137808775329647\n",
      "11 Train Loss 0.044888306 Test MSE 0.0002745802963919357 Test RE 0.04819140183768448\n",
      "12 Train Loss 0.031422257 Test MSE 0.00026028546101683665 Test RE 0.04692019732981709\n",
      "13 Train Loss 0.016148102 Test MSE 0.00032003199466560766 Test RE 0.05202733422494006\n",
      "14 Train Loss 0.0086347675 Test MSE 6.440762476322725e-05 Test RE 0.02334014322040744\n",
      "15 Train Loss 0.006829995 Test MSE 6.295937163608887e-06 Test RE 0.007297348163836734\n",
      "16 Train Loss 0.006228021 Test MSE 4.119381534613796e-06 Test RE 0.005902702348079187\n",
      "17 Train Loss 0.0055561448 Test MSE 6.5607027676809485e-06 Test RE 0.007449207231122554\n",
      "18 Train Loss 0.0042291265 Test MSE 2.7653806011668535e-05 Test RE 0.015293691691521366\n",
      "19 Train Loss 0.0026489082 Test MSE 8.992657790621092e-07 Test RE 0.0027579024992144367\n",
      "20 Train Loss 0.002486144 Test MSE 1.945049364159159e-06 Test RE 0.0040560209439445775\n",
      "21 Train Loss 0.0017593912 Test MSE 3.1625062961553973e-06 Test RE 0.005171905421206236\n",
      "22 Train Loss 0.0013498825 Test MSE 9.370624239852156e-07 Test RE 0.0028152640623832484\n",
      "23 Train Loss 0.000992245 Test MSE 3.202065260586165e-06 Test RE 0.005204151900270034\n",
      "24 Train Loss 0.00076655654 Test MSE 5.701068242375703e-07 Test RE 0.002195902204522098\n",
      "25 Train Loss 0.00071594154 Test MSE 9.154420257959233e-07 Test RE 0.0027825969061056654\n",
      "26 Train Loss 0.0005588003 Test MSE 3.924204908410457e-07 Test RE 0.0018218420140330537\n",
      "27 Train Loss 0.0004615696 Test MSE 3.3423652292371975e-07 Test RE 0.0016813643207025148\n",
      "28 Train Loss 0.0004116233 Test MSE 7.71385834024725e-07 Test RE 0.0025542929485733567\n",
      "29 Train Loss 0.00034228415 Test MSE 4.262182623774811e-07 Test RE 0.0018986761802978827\n",
      "30 Train Loss 0.00032290968 Test MSE 1.19979852044256e-06 Test RE 0.003185583813325219\n",
      "31 Train Loss 0.00028812693 Test MSE 3.1985266552099427e-07 Test RE 0.0016447877472252832\n",
      "32 Train Loss 0.00027362895 Test MSE 9.765277212854329e-08 Test RE 0.0009088185086013536\n",
      "33 Train Loss 0.00026117527 Test MSE 1.7190064002025313e-07 Test RE 0.0012057953972454407\n",
      "34 Train Loss 0.000260519 Test MSE 1.2950098462013128e-07 Test RE 0.001046577539483931\n",
      "35 Train Loss 0.00025865054 Test MSE 9.26793488893009e-08 Test RE 0.0008853731797468547\n",
      "36 Train Loss 0.00025775746 Test MSE 1.202749120953048e-07 Test RE 0.0010086079778452892\n",
      "37 Train Loss 0.00025730912 Test MSE 9.930865822839602e-08 Test RE 0.0009164914800110168\n",
      "38 Train Loss 0.00025658435 Test MSE 8.927104054749985e-08 Test RE 0.0008689407679022217\n",
      "39 Train Loss 0.00025516842 Test MSE 6.513372385391114e-08 Test RE 0.0007422288467287291\n",
      "40 Train Loss 0.0002542058 Test MSE 6.634194753793591e-08 Test RE 0.0007490813477327069\n",
      "41 Train Loss 0.00025346602 Test MSE 5.974381573428843e-08 Test RE 0.0007108555414811325\n",
      "42 Train Loss 0.00025324055 Test MSE 5.7036239365639634e-08 Test RE 0.000694560876256905\n",
      "43 Train Loss 0.00025163603 Test MSE 9.09583932147375e-08 Test RE 0.000877114448047564\n",
      "44 Train Loss 0.00025108817 Test MSE 6.557682868568935e-08 Test RE 0.0007447492594412728\n",
      "45 Train Loss 0.0002503881 Test MSE 5.7444217770497645e-08 Test RE 0.0006970405358474618\n",
      "46 Train Loss 0.0002501849 Test MSE 5.5011404357381205e-08 Test RE 0.0006821207185948046\n",
      "47 Train Loss 0.0002500244 Test MSE 5.473790914897e-08 Test RE 0.0006804229870037284\n",
      "48 Train Loss 0.0002498048 Test MSE 5.523963675122163e-08 Test RE 0.0006835342518996447\n",
      "49 Train Loss 0.0002494483 Test MSE 5.402241241700854e-08 Test RE 0.0006759613458277358\n",
      "50 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "51 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "52 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "53 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "54 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "55 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "56 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "57 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "58 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "59 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "60 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "61 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "62 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "63 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "64 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "65 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "66 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "67 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "68 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "69 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "70 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "71 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "72 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "73 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "74 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "75 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "76 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "77 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "78 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "79 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "80 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "81 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "82 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "83 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "84 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "85 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "86 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "87 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "88 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "89 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "90 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "91 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "92 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "93 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "94 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "95 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "96 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "97 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "98 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "99 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "100 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "101 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "102 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "103 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "104 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "105 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "106 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "107 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "108 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "109 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "110 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "111 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "112 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "113 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "114 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "115 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "116 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "117 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "118 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "119 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "120 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "121 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "122 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "123 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "124 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "125 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "126 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "127 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "128 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "129 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "130 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "131 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "132 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "133 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "134 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "135 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "136 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "137 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "138 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "139 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "140 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "141 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "142 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "143 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "144 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "145 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "146 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "147 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "148 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "149 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "150 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "151 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "152 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "153 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "154 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "155 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "156 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "157 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "158 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "159 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "160 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "161 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "162 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "163 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "164 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "165 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "166 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "167 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "168 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "169 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "170 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "171 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "172 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "173 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "174 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "175 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "176 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "177 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "178 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "179 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "180 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "181 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "182 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "183 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "184 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "185 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "186 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "187 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "188 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "189 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "190 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "191 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "192 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "193 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "194 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "195 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "196 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "197 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "198 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "199 Train Loss 0.00024910315 Test MSE 5.840934938457092e-08 Test RE 0.0007028717028706406\n",
      "Training time: 15.36\n",
      "Training time: 15.36\n",
      "1D_FODE_rowdylow\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 32.179417 Test MSE 0.08228632137813208 Test RE 0.8342547704023687\n",
      "1 Train Loss 5.714145 Test MSE 0.9219232610341085 Test RE 2.792429782586201\n",
      "2 Train Loss 3.4471183 Test MSE 1.5128255827123165 Test RE 3.5770853690967135\n",
      "3 Train Loss 2.8550746 Test MSE 1.7828846528407318 Test RE 3.8832602584642113\n",
      "4 Train Loss 0.97219354 Test MSE 0.4570289900855738 Test RE 1.9661051889718952\n",
      "5 Train Loss 0.6481106 Test MSE 0.47577309298430726 Test RE 2.0060179440155346\n",
      "6 Train Loss 0.51107174 Test MSE 0.45423483799125997 Test RE 1.9600858560528154\n",
      "7 Train Loss 0.3921486 Test MSE 0.3236235417196404 Test RE 1.654454881904558\n",
      "8 Train Loss 0.33275327 Test MSE 0.24606723785783324 Test RE 1.4426526307699958\n",
      "9 Train Loss 0.09638707 Test MSE 0.023707982091425335 Test RE 0.447798021256382\n",
      "10 Train Loss 0.05189211 Test MSE 3.124942945791375e-05 Test RE 0.01625758080247808\n",
      "11 Train Loss 0.031801544 Test MSE 0.00848925454246074 Test RE 0.26795980481069437\n",
      "12 Train Loss 0.014151277 Test MSE 0.006014949133189273 Test RE 0.2255541667550497\n",
      "13 Train Loss 0.009441563 Test MSE 0.0013020333654131721 Test RE 0.1049411771900269\n",
      "14 Train Loss 0.002311593 Test MSE 1.3672371875070394e-05 Test RE 0.010753672500445156\n",
      "15 Train Loss 0.0009164929 Test MSE 6.039888355335578e-06 Test RE 0.007147420449812842\n",
      "16 Train Loss 0.0006184482 Test MSE 1.921126655575303e-07 Test RE 0.0012747143470029103\n",
      "17 Train Loss 0.00023458674 Test MSE 9.993497623005826e-07 Test RE 0.002907325327217945\n",
      "18 Train Loss 8.371656e-05 Test MSE 6.360884499230923e-07 Test RE 0.002319496010041662\n",
      "19 Train Loss 4.027368e-05 Test MSE 8.215766385716218e-07 Test RE 0.0026360820007019854\n",
      "20 Train Loss 2.81486e-05 Test MSE 1.7064877893008392e-07 Test RE 0.0012013967906041553\n",
      "21 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "22 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "23 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "24 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "25 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "26 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "27 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "28 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "29 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "30 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "31 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "32 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "33 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "34 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "35 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "36 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "37 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "38 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "39 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "40 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "41 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "42 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "43 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "44 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "45 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "46 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "47 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "48 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "49 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "50 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "51 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "52 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "53 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "54 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "55 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "56 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "57 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "58 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "59 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "60 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "61 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "62 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "63 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "64 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "65 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "66 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "67 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "68 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "69 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "70 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "71 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "72 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "73 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "74 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "75 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "76 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "77 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "78 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "79 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "80 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "81 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "82 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "83 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "84 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "85 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "86 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "87 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "88 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "89 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "90 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "91 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "92 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "93 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "94 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "95 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "96 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "97 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "98 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "99 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "100 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "101 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "102 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "103 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "104 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "105 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "106 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "107 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "108 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "109 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "110 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "111 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "112 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "113 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "114 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "115 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "116 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "117 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "118 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "119 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "120 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "121 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "122 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "123 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "124 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "125 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "126 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "127 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "128 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "129 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "130 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "131 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "132 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "133 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "134 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "135 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "136 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "137 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "138 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "139 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "140 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "141 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "142 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "143 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "144 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "145 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "146 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "147 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "148 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "149 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "150 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "151 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "152 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "153 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "154 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "155 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "156 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "157 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "158 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "159 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "160 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "161 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "162 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "163 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "164 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "165 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "166 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "167 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "168 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "169 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "170 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "171 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "172 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "173 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "174 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "175 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "176 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "177 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "178 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "179 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "180 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "181 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "182 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "183 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "184 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "185 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "186 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "187 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "188 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "189 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "190 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "191 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "192 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "193 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "194 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "195 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "196 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "197 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "198 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "199 Train Loss 2.7983997e-05 Test MSE 1.454957285928339e-07 Test RE 0.0011093280557079141\n",
      "Training time: 10.50\n",
      "Training time: 10.50\n",
      "1D_FODE_rowdylow\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 5.2476444 Test MSE 0.8706035529846907 Test RE 2.7135953884224486\n",
      "1 Train Loss 2.9175858 Test MSE 1.354756114550274 Test RE 3.3850527036798934\n",
      "2 Train Loss 1.1125393 Test MSE 0.4041574173481268 Test RE 1.8488860758391044\n",
      "3 Train Loss 0.5259509 Test MSE 0.00018156246412897575 Test RE 0.039187531660625746\n",
      "4 Train Loss 0.45022014 Test MSE 0.0009800136986975814 Test RE 0.09104391991332045\n",
      "5 Train Loss 0.27319285 Test MSE 0.00013844987569949736 Test RE 0.03422009099193921\n",
      "6 Train Loss 0.25145406 Test MSE 0.0006840395844552223 Test RE 0.07606335759523318\n",
      "7 Train Loss 0.1974056 Test MSE 0.0013123749632766159 Test RE 0.10535710854741488\n",
      "8 Train Loss 0.17264873 Test MSE 7.339836116725347e-05 Test RE 0.024915984755486224\n",
      "9 Train Loss 0.12799563 Test MSE 0.00219248267614485 Test RE 0.1361767484587731\n",
      "10 Train Loss 0.07079848 Test MSE 0.0010597140706075545 Test RE 0.09467367274126337\n",
      "11 Train Loss 0.022270998 Test MSE 0.00016205965191930173 Test RE 0.03702306127427013\n",
      "12 Train Loss 0.0070009935 Test MSE 3.721737583842487e-05 Test RE 0.017742211376081153\n",
      "13 Train Loss 0.0060743713 Test MSE 7.949948645883642e-06 Test RE 0.008200060121098774\n",
      "14 Train Loss 0.005838962 Test MSE 1.9256574812257237e-05 Test RE 0.012762166183869883\n",
      "15 Train Loss 0.003723967 Test MSE 9.337698949961855e-05 Test RE 0.028103137543849327\n",
      "16 Train Loss 0.002294742 Test MSE 3.553467359845283e-06 Test RE 0.005482277821886303\n",
      "17 Train Loss 0.0015773276 Test MSE 6.042612698150034e-07 Test RE 0.0022607224882259377\n",
      "18 Train Loss 0.0010570302 Test MSE 1.7232496136646777e-06 Test RE 0.003817763045374318\n",
      "19 Train Loss 0.0006051633 Test MSE 1.7082833663649334e-05 Test RE 0.012020286830146954\n",
      "20 Train Loss 0.0003549674 Test MSE 9.825707050455292e-08 Test RE 0.0009116261632878077\n",
      "21 Train Loss 0.00018452536 Test MSE 2.573109377912436e-07 Test RE 0.0014752444814906632\n",
      "22 Train Loss 8.400498e-05 Test MSE 1.2757709736514498e-06 Test RE 0.0032848930427437544\n",
      "23 Train Loss 5.260504e-05 Test MSE 3.8665457051194893e-07 Test RE 0.0018084081225251845\n",
      "24 Train Loss 4.9993967e-05 Test MSE 1.072717084585551e-07 Test RE 0.0009525273920733973\n",
      "25 Train Loss 4.9165228e-05 Test MSE 5.292950720041489e-08 Test RE 0.000669088861581732\n",
      "26 Train Loss 4.8458067e-05 Test MSE 3.4097924905322434e-08 Test RE 0.0005370303742091841\n",
      "27 Train Loss 4.771804e-05 Test MSE 9.025351541891604e-09 Test RE 0.00027629112728672854\n",
      "28 Train Loss 4.7281505e-05 Test MSE 8.31131149693257e-09 Test RE 0.00026513658281139324\n",
      "29 Train Loss 4.661245e-05 Test MSE 7.709732867635879e-09 Test RE 0.0002553609822540105\n",
      "30 Train Loss 4.620416e-05 Test MSE 7.578213336898734e-09 Test RE 0.0002531735250123636\n",
      "31 Train Loss 4.591146e-05 Test MSE 8.019545830444133e-09 Test RE 0.00026044124439316796\n",
      "32 Train Loss 4.5754758e-05 Test MSE 8.564774127421037e-09 Test RE 0.000269149038056682\n",
      "33 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "34 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "35 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "36 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "37 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "38 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "39 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "40 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "41 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "42 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "43 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "44 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "45 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "46 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "47 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "48 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "49 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "50 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "51 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "52 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "53 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "54 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "55 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "56 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "57 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "58 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "59 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "60 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "61 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "62 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "63 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "64 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "65 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "66 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "67 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "68 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "69 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "70 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "71 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "72 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "73 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "74 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "75 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "76 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "77 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "78 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "79 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "80 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "81 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "82 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "83 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "84 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "85 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "86 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "87 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "88 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "89 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "90 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "91 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "92 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "93 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "94 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "95 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "96 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "97 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "98 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "99 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "100 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "101 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "102 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "103 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "104 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "105 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "106 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "107 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "108 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "109 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "110 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "111 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "112 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "113 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "114 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "115 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "116 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "117 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "118 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "119 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "120 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "121 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "122 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "123 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "124 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "125 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "126 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "127 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "128 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "129 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "130 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "131 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "132 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "133 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "134 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "135 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "136 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "137 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "138 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "139 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "140 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "141 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "142 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "143 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "144 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "145 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "146 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "147 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "148 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "149 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "150 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "151 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "152 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "153 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "154 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "155 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "156 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "157 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "158 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "159 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "160 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "161 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "162 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "163 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "164 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "165 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "166 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "167 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "168 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "169 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "170 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "171 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "172 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "173 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "174 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "175 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "176 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "177 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "178 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "179 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "180 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "181 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "182 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "183 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "184 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "185 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "186 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "187 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "188 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "189 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "190 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "191 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "192 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "193 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "194 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "195 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "196 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "197 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "198 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "199 Train Loss 4.549582e-05 Test MSE 1.0182887376999488e-08 Test RE 0.00029347448228688914\n",
      "Training time: 11.90\n",
      "Training time: 11.90\n",
      "1D_FODE_rowdylow\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 53.539932 Test MSE 0.12526218047688414 Test RE 1.0293068395314742\n",
      "1 Train Loss 39.515617 Test MSE 0.07643406388101605 Test RE 0.8040412876290012\n",
      "2 Train Loss 34.000755 Test MSE 0.0649008171403883 Test RE 0.7409006185368722\n",
      "3 Train Loss 25.960863 Test MSE 0.4690190822356566 Test RE 1.991728469608176\n",
      "4 Train Loss 3.3164344 Test MSE 2.1111220321102757 Test RE 4.225630747608784\n",
      "5 Train Loss 2.1146884 Test MSE 0.8806301180236594 Test RE 2.729176620005945\n",
      "6 Train Loss 1.9137919 Test MSE 0.5933008098941794 Test RE 2.2401254779830984\n",
      "7 Train Loss 1.5808452 Test MSE 0.31073760278274554 Test RE 1.6211820272539892\n",
      "8 Train Loss 0.436166 Test MSE 0.0019488302140742398 Test RE 0.12838724422094258\n",
      "9 Train Loss 0.27864435 Test MSE 0.02201899569238435 Test RE 0.43155249138479906\n",
      "10 Train Loss 0.15124871 Test MSE 0.00027115667740957114 Test RE 0.047890020920582185\n",
      "11 Train Loss 0.044529 Test MSE 0.00585627819623006 Test RE 0.22255928864490676\n",
      "12 Train Loss 0.03436365 Test MSE 3.646054392830974e-05 Test RE 0.01756088692866305\n",
      "13 Train Loss 0.034216437 Test MSE 5.10902313073747e-05 Test RE 0.02078757405460968\n",
      "14 Train Loss 0.032263033 Test MSE 2.5978896034737687e-05 Test RE 0.01482331101609966\n",
      "15 Train Loss 0.031956293 Test MSE 0.00010871540973390307 Test RE 0.030323576903309172\n",
      "16 Train Loss 0.029019654 Test MSE 0.00024232006998739126 Test RE 0.04527198820714047\n",
      "17 Train Loss 0.026833706 Test MSE 3.4054015529502546e-05 Test RE 0.016971453548628234\n",
      "18 Train Loss 0.018957917 Test MSE 0.00010827491820792336 Test RE 0.03026208223395388\n",
      "19 Train Loss 0.013548662 Test MSE 4.391595832666944e-05 Test RE 0.01927285513664581\n",
      "20 Train Loss 0.010801922 Test MSE 3.3331651157241594e-05 Test RE 0.016790486847766784\n",
      "21 Train Loss 0.008916381 Test MSE 4.975573767473383e-06 Test RE 0.006487187635313598\n",
      "22 Train Loss 0.007535574 Test MSE 4.144402433007597e-06 Test RE 0.005920601555319363\n",
      "23 Train Loss 0.0067635733 Test MSE 5.553755720027497e-05 Test RE 0.021673460653130323\n",
      "24 Train Loss 0.0057679145 Test MSE 3.875130180732857e-06 Test RE 0.005725033381282549\n",
      "25 Train Loss 0.005230142 Test MSE 6.576424233669906e-06 Test RE 0.007458127188848333\n",
      "26 Train Loss 0.0044743926 Test MSE 1.8545120275420167e-05 Test RE 0.012524191573276177\n",
      "27 Train Loss 0.0033868721 Test MSE 2.277739441262981e-05 Test RE 0.01387991785839882\n",
      "28 Train Loss 0.0020985038 Test MSE 2.250357461324084e-05 Test RE 0.013796236474456087\n",
      "29 Train Loss 0.0014186512 Test MSE 8.216063332079002e-06 Test RE 0.008336173866262125\n",
      "30 Train Loss 0.0010917826 Test MSE 1.4049776302245775e-05 Test RE 0.010901081327068922\n",
      "31 Train Loss 0.00084237615 Test MSE 3.416900520796307e-07 Test RE 0.0017000083025890426\n",
      "32 Train Loss 0.00081740174 Test MSE 4.5908209117997615e-07 Test RE 0.001970516385592433\n",
      "33 Train Loss 0.00081650174 Test MSE 4.332345674666665e-07 Test RE 0.0019142401700926982\n",
      "34 Train Loss 0.0008157614 Test MSE 4.5235526612675513e-07 Test RE 0.0019560263465840818\n",
      "35 Train Loss 0.00081493566 Test MSE 4.358971199457426e-07 Test RE 0.0019201133833583776\n",
      "36 Train Loss 0.0007740193 Test MSE 5.968415051417801e-07 Test RE 0.002246799835362584\n",
      "37 Train Loss 0.000773104 Test MSE 1.2948435092803919e-06 Test RE 0.003309356217928603\n",
      "38 Train Loss 0.0007698905 Test MSE 7.417133847028325e-07 Test RE 0.0025046839511437893\n",
      "39 Train Loss 0.0007407438 Test MSE 1.8335380472919155e-06 Test RE 0.003938037415555042\n",
      "40 Train Loss 0.00061017566 Test MSE 1.658407629222633e-06 Test RE 0.0037452474622394075\n",
      "41 Train Loss 0.00047034168 Test MSE 5.712284069218423e-07 Test RE 0.0021980611646090957\n",
      "42 Train Loss 0.000337762 Test MSE 1.4327977252076293e-06 Test RE 0.003481186707764028\n",
      "43 Train Loss 0.00023735526 Test MSE 1.2661566664577951e-07 Test RE 0.001034852844834202\n",
      "44 Train Loss 0.00015407236 Test MSE 6.979218957628288e-07 Test RE 0.0024296196239508433\n",
      "45 Train Loss 9.343976e-05 Test MSE 3.814370299768479e-08 Test RE 0.0005679973388607263\n",
      "46 Train Loss 6.5670734e-05 Test MSE 9.810846160164697e-08 Test RE 0.0009109365079421741\n",
      "47 Train Loss 5.3078642e-05 Test MSE 3.5526446162822015e-07 Test RE 0.0017334477586053029\n",
      "48 Train Loss 3.3990116e-05 Test MSE 5.325872974809626e-07 Test RE 0.00212241485640068\n",
      "49 Train Loss 3.1507385e-05 Test MSE 1.0468947941772714e-07 Test RE 0.0009409930049538337\n",
      "50 Train Loss 3.086528e-05 Test MSE 3.2636279931242403e-08 Test RE 0.0005253941099171007\n",
      "51 Train Loss 3.0238967e-05 Test MSE 6.6843389624264764e-09 Test RE 0.00023777385955836268\n",
      "52 Train Loss 2.9950865e-05 Test MSE 1.900274413881946e-08 Test RE 0.0004009064425033376\n",
      "53 Train Loss 2.9719988e-05 Test MSE 3.955368779808574e-08 Test RE 0.0005784001082381634\n",
      "54 Train Loss 2.9362764e-05 Test MSE 8.757175805004791e-08 Test RE 0.0008606308490209714\n",
      "55 Train Loss 2.9111392e-05 Test MSE 1.1910114598517644e-07 Test RE 0.0010036743953677687\n",
      "56 Train Loss 2.872641e-05 Test MSE 1.5960624510205447e-07 Test RE 0.0011618760916716497\n",
      "57 Train Loss 2.8334303e-05 Test MSE 1.6059806757571095e-07 Test RE 0.0011654805561852192\n",
      "58 Train Loss 2.7891221e-05 Test MSE 2.058681137434859e-07 Test RE 0.0013195608365994002\n",
      "59 Train Loss 2.755549e-05 Test MSE 2.1203061138365007e-07 Test RE 0.001339165208196855\n",
      "60 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "61 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "62 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "63 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "64 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "65 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "66 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "67 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "68 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "69 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "70 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "71 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "72 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "73 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "74 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "75 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "76 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "77 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "78 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "79 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "80 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "81 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "82 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "83 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "84 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "85 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "86 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "87 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "88 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "89 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "90 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "91 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "92 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "93 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "94 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "95 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "96 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "97 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "98 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "99 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "100 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "101 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "102 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "103 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "104 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "105 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "106 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "107 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "108 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "109 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "110 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "111 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "112 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "113 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "114 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "115 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "116 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "117 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "118 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "119 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "120 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "121 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "122 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "123 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "124 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "125 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "126 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "127 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "128 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "129 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "130 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "131 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "132 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "133 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "134 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "135 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "136 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "137 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "138 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "139 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "140 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "141 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "142 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "143 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "144 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "145 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "146 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "147 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "148 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "149 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "150 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "151 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "152 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "153 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "154 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "155 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "156 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "157 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "158 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "159 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "160 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "161 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "162 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "163 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "164 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "165 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "166 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "167 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "168 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "169 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "170 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "171 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "172 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "173 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "174 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "175 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "176 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "177 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "178 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "179 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "180 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "181 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "182 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "183 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "184 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "185 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "186 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "187 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "188 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "189 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "190 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "191 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "192 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "193 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "194 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "195 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "196 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "197 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "198 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "199 Train Loss 2.6998589e-05 Test MSE 1.6046450989342446e-07 Test RE 0.0011649958328626454\n",
      "Training time: 17.70\n",
      "Training time: 17.70\n",
      "1D_FODE_rowdylow\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 52.45414 Test MSE 0.1214582648820215 Test RE 1.0135575457399295\n",
      "1 Train Loss 36.702034 Test MSE 0.0627996651454475 Test RE 0.7288086842987702\n",
      "2 Train Loss 32.841904 Test MSE 0.07040695745151404 Test RE 0.7716896287818356\n",
      "3 Train Loss 11.955148 Test MSE 0.24048153353804724 Test RE 1.4261845956450327\n",
      "4 Train Loss 1.795718 Test MSE 0.3108462762801597 Test RE 1.621465488473768\n",
      "5 Train Loss 1.2852361 Test MSE 0.5441938781413589 Test RE 2.145416917427122\n",
      "6 Train Loss 0.7147833 Test MSE 0.1970236184146957 Test RE 1.2909042193778517\n",
      "7 Train Loss 0.34389982 Test MSE 0.00127572502711018 Test RE 0.10387556827555193\n",
      "8 Train Loss 0.2562343 Test MSE 0.0012440079502214448 Test RE 0.10257616375262837\n",
      "9 Train Loss 0.22719017 Test MSE 0.011538236057997387 Test RE 0.3123953673010206\n",
      "10 Train Loss 0.19413625 Test MSE 0.0005441286345003576 Test RE 0.06783997284962541\n",
      "11 Train Loss 0.093902156 Test MSE 0.0004508552833611432 Test RE 0.061752345330827706\n",
      "12 Train Loss 0.029871209 Test MSE 2.4899143928001885e-05 Test RE 0.014511993751814308\n",
      "13 Train Loss 0.021152204 Test MSE 0.0007422191363943769 Test RE 0.07923206019853066\n",
      "14 Train Loss 0.007408846 Test MSE 1.6110312427374106e-05 Test RE 0.011673117478844195\n",
      "15 Train Loss 0.003964994 Test MSE 3.681374236999894e-05 Test RE 0.017645739326341874\n",
      "16 Train Loss 0.0030204598 Test MSE 1.940574088217922e-05 Test RE 0.012811500237472222\n",
      "17 Train Loss 0.002581758 Test MSE 2.3075028573661034e-05 Test RE 0.013970308567925513\n",
      "18 Train Loss 0.002352124 Test MSE 1.0858423115551167e-06 Test RE 0.0030305276809642198\n",
      "19 Train Loss 0.0022539012 Test MSE 2.798115698539793e-06 Test RE 0.004864830452150441\n",
      "20 Train Loss 0.0021863936 Test MSE 1.2125997132006443e-06 Test RE 0.0032025329406410305\n",
      "21 Train Loss 0.0021362954 Test MSE 9.611288934867704e-07 Test RE 0.0028511869299903624\n",
      "22 Train Loss 0.0020879908 Test MSE 2.6635226711861916e-06 Test RE 0.004746386212624795\n",
      "23 Train Loss 0.0019397547 Test MSE 1.821096979775907e-05 Test RE 0.012410846722101155\n",
      "24 Train Loss 0.0015008338 Test MSE 1.8003866769056577e-05 Test RE 0.012340074173096285\n",
      "25 Train Loss 0.001411038 Test MSE 1.710131359157359e-06 Test RE 0.003803203905315036\n",
      "26 Train Loss 0.0013558111 Test MSE 6.222858945737912e-07 Test RE 0.0022941924878443795\n",
      "27 Train Loss 0.00103193 Test MSE 3.675803635543397e-07 Test RE 0.0017632383635156838\n",
      "28 Train Loss 0.0006329007 Test MSE 3.8559996410245005e-07 Test RE 0.0018059402077887886\n",
      "29 Train Loss 0.00050166505 Test MSE 2.129301586367698e-07 Test RE 0.0013420029291171536\n",
      "30 Train Loss 0.00046411058 Test MSE 1.808113442916878e-07 Test RE 0.0012366525930116474\n",
      "31 Train Loss 0.00035461315 Test MSE 8.981513527775241e-08 Test RE 0.00087158478260881\n",
      "32 Train Loss 0.00021295712 Test MSE 5.074692858022419e-08 Test RE 0.0006551485074212395\n",
      "33 Train Loss 0.00014247482 Test MSE 5.045665088100851e-08 Test RE 0.0006532720614717786\n",
      "34 Train Loss 0.00013599587 Test MSE 6.769529535154088e-08 Test RE 0.0007566832467166142\n",
      "35 Train Loss 0.00013524335 Test MSE 6.808370150741412e-08 Test RE 0.0007588509015470544\n",
      "36 Train Loss 0.00013432198 Test MSE 6.95706161840498e-08 Test RE 0.0007670926117679067\n",
      "37 Train Loss 0.00013338607 Test MSE 7.023613590380927e-08 Test RE 0.0007707529225606058\n",
      "38 Train Loss 0.00013273589 Test MSE 7.269707097083724e-08 Test RE 0.0007841395000864851\n",
      "39 Train Loss 0.000108252236 Test MSE 4.120075453264597e-08 Test RE 0.0005903199488576466\n",
      "40 Train Loss 5.823968e-05 Test MSE 2.6802279863643783e-08 Test RE 0.00047612473479448234\n",
      "41 Train Loss 4.097746e-05 Test MSE 9.407734713717385e-09 Test RE 0.00028208331977056525\n",
      "42 Train Loss 4.079214e-05 Test MSE 9.230762500878575e-09 Test RE 0.0002794175391515474\n",
      "43 Train Loss 4.0433457e-05 Test MSE 9.00179763957361e-09 Test RE 0.0002759303665102165\n",
      "44 Train Loss 3.9826104e-05 Test MSE 9.541549534336576e-09 Test RE 0.00028408240078829416\n",
      "45 Train Loss 3.9412516e-05 Test MSE 8.609857747820516e-09 Test RE 0.00026985648734988393\n",
      "46 Train Loss 3.9069015e-05 Test MSE 8.039422313286583e-09 Test RE 0.0002607637970920523\n",
      "47 Train Loss 3.868483e-05 Test MSE 7.875708470421704e-09 Test RE 0.0002580950592205777\n",
      "48 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "49 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "50 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "51 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "52 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "53 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "54 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "55 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "56 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "57 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "58 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "59 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "60 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "61 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "62 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "63 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "64 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "65 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "66 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "67 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "68 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "69 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "70 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "71 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "72 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "73 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "74 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "75 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "76 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "77 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "78 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "79 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "80 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "81 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "82 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "83 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "84 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "85 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "86 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "87 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "88 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "89 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "90 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "91 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "92 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "93 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "94 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "95 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "96 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "97 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "98 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "99 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "100 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "101 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "102 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "103 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "104 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "105 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "106 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "107 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "108 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "109 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "110 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "111 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "112 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "113 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "114 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "115 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "116 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "117 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "118 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "119 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "120 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "121 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "122 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "123 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "124 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "125 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "126 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "127 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "128 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "129 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "130 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "131 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "132 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "133 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "134 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "135 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "136 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "137 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "138 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "139 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "140 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "141 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "142 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "143 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "144 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "145 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "146 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "147 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "148 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "149 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "150 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "151 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "152 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "153 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "154 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "155 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "156 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "157 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "158 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "159 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "160 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "161 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "162 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "163 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "164 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "165 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "166 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "167 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "168 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "169 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "170 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "171 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "172 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "173 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "174 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "175 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "176 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "177 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "178 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "179 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "180 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "181 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "182 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "183 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "184 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "185 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "186 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "187 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "188 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "189 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "190 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "191 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "192 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "193 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "194 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "195 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "196 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "197 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "198 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "199 Train Loss 3.8088645e-05 Test MSE 1.4211597803839682e-08 Test RE 0.00034670198568863237\n",
      "Training time: 15.53\n",
      "Training time: 15.53\n",
      "1D_FODE_rowdylow\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 51.940567 Test MSE 0.11976797049667082 Test RE 1.0064801639896999\n",
      "1 Train Loss 34.026234 Test MSE 0.050493325176263315 Test RE 0.6535094329591894\n",
      "2 Train Loss 33.418236 Test MSE 0.05169592497827681 Test RE 0.661245957681985\n",
      "3 Train Loss 15.878706 Test MSE 0.1330015701008343 Test RE 1.0606284171206843\n",
      "4 Train Loss 2.0735817 Test MSE 0.14003595206526026 Test RE 1.0883150854918273\n",
      "5 Train Loss 0.3107441 Test MSE 0.13915947168390597 Test RE 1.0849038754313025\n",
      "6 Train Loss 0.2555498 Test MSE 0.16131000864215833 Test RE 1.168061022838039\n",
      "7 Train Loss 0.22354513 Test MSE 0.17517612787431716 Test RE 1.2172291272696238\n",
      "8 Train Loss 0.21290609 Test MSE 0.169989542432197 Test RE 1.1990739758709374\n",
      "9 Train Loss 0.20126638 Test MSE 0.14922969653014279 Test RE 1.1234726460642002\n",
      "10 Train Loss 0.07405259 Test MSE 0.030829785891812834 Test RE 0.5106462291621348\n",
      "11 Train Loss 0.024044579 Test MSE 0.00098261416421063 Test RE 0.09116463237066277\n",
      "12 Train Loss 0.0106968265 Test MSE 0.001468088159449665 Test RE 0.1114322610789094\n",
      "13 Train Loss 0.0061475155 Test MSE 6.265817161059976e-05 Test RE 0.023020976093339043\n",
      "14 Train Loss 0.0041165454 Test MSE 6.131039754110586e-05 Test RE 0.022772040156776144\n",
      "15 Train Loss 0.0025180245 Test MSE 8.585297251636742e-05 Test RE 0.026947131591030574\n",
      "16 Train Loss 0.0018999549 Test MSE 5.708273023435889e-07 Test RE 0.0021972893129211138\n",
      "17 Train Loss 0.0017977469 Test MSE 1.770030515706304e-06 Test RE 0.0038692362844788613\n",
      "18 Train Loss 0.0017585767 Test MSE 6.717467644985375e-07 Test RE 0.002383623544548963\n",
      "19 Train Loss 0.0014551097 Test MSE 1.2988709573691115e-05 Test RE 0.010481365796194167\n",
      "20 Train Loss 0.00073487556 Test MSE 3.137960701022498e-07 Test RE 0.0016291408181371234\n",
      "21 Train Loss 0.00040199235 Test MSE 2.7628428976182694e-06 Test RE 0.004834070392191285\n",
      "22 Train Loss 0.00036001054 Test MSE 7.332833476361726e-07 Test RE 0.002490409625326639\n",
      "23 Train Loss 0.00035935905 Test MSE 6.724071505325636e-07 Test RE 0.002384794912317236\n",
      "24 Train Loss 0.00035868413 Test MSE 6.238889280088632e-07 Test RE 0.002297145553218072\n",
      "25 Train Loss 0.00034238864 Test MSE 4.0797654289721857e-07 Test RE 0.001857601151813111\n",
      "26 Train Loss 0.0002571125 Test MSE 2.3118454805969345e-06 Test RE 0.0044219545712928165\n",
      "27 Train Loss 0.00020264598 Test MSE 4.947764784236108e-07 Test RE 0.0020456879995488877\n",
      "28 Train Loss 0.00019286072 Test MSE 3.347122134588571e-08 Test RE 0.0005320723060492384\n",
      "29 Train Loss 0.00017612442 Test MSE 3.212709016427423e-06 Test RE 0.005212794098837891\n",
      "30 Train Loss 0.00014346481 Test MSE 9.341028778268444e-07 Test RE 0.0028108147893954835\n",
      "31 Train Loss 0.00012343058 Test MSE 3.9917971703402863e-07 Test RE 0.001837465137519326\n",
      "32 Train Loss 8.838256e-05 Test MSE 2.8823950254490127e-08 Test RE 0.0004937551343651968\n",
      "33 Train Loss 7.2497925e-05 Test MSE 3.72190958516433e-08 Test RE 0.0005610709513552209\n",
      "34 Train Loss 6.2214654e-05 Test MSE 3.1347401673990073e-08 Test RE 0.0005149151255308611\n",
      "35 Train Loss 6.041088e-05 Test MSE 2.427115661310834e-08 Test RE 0.0004530854451851361\n",
      "36 Train Loss 5.8103098e-05 Test MSE 9.317203593455265e-09 Test RE 0.00028072278751405154\n",
      "37 Train Loss 5.734008e-05 Test MSE 1.4489213744424393e-08 Test RE 0.00035007192645572917\n",
      "38 Train Loss 5.6900742e-05 Test MSE 1.2732972974045885e-08 Test RE 0.0003281706849932473\n",
      "39 Train Loss 5.6520083e-05 Test MSE 1.5474824810286945e-08 Test RE 0.00036178265823921894\n",
      "40 Train Loss 5.6270565e-05 Test MSE 1.962971430921601e-08 Test RE 0.0004074664582583761\n",
      "41 Train Loss 5.6205583e-05 Test MSE 2.301751374150601e-08 Test RE 0.0004412290320401964\n",
      "42 Train Loss 5.590984e-05 Test MSE 3.637342669753012e-08 Test RE 0.0005546601740462088\n",
      "43 Train Loss 5.5690867e-05 Test MSE 4.0790534821217714e-08 Test RE 0.0005873738053150251\n",
      "44 Train Loss 5.5357163e-05 Test MSE 5.320585027116573e-08 Test RE 0.0006708332322719094\n",
      "45 Train Loss 5.4940803e-05 Test MSE 5.382889186317848e-08 Test RE 0.0006747495360584168\n",
      "46 Train Loss 5.460289e-05 Test MSE 7.876435896986481e-08 Test RE 0.0008162059311060533\n",
      "47 Train Loss 5.4277338e-05 Test MSE 8.615102574063593e-08 Test RE 0.0008536210208079577\n",
      "48 Train Loss 5.379977e-05 Test MSE 8.507100780681719e-08 Test RE 0.000848253506896209\n",
      "49 Train Loss 5.3229138e-05 Test MSE 8.226178360432655e-08 Test RE 0.0008341303737782923\n",
      "50 Train Loss 5.2453444e-05 Test MSE 7.176340004574984e-08 Test RE 0.0007790877545496876\n",
      "51 Train Loss 5.1601724e-05 Test MSE 6.679436038893681e-08 Test RE 0.0007516311539876228\n",
      "52 Train Loss 4.9895465e-05 Test MSE 2.900711453751203e-08 Test RE 0.0004953214548133239\n",
      "53 Train Loss 4.9348066e-05 Test MSE 1.3531789009611346e-08 Test RE 0.0003383081682519634\n",
      "54 Train Loss 4.9183775e-05 Test MSE 1.2369307786062024e-08 Test RE 0.0003234503109831564\n",
      "55 Train Loss 4.8464233e-05 Test MSE 1.0031236131900925e-08 Test RE 0.0002912809630094889\n",
      "56 Train Loss 4.819335e-05 Test MSE 1.3722972138047879e-08 Test RE 0.00034068967009586424\n",
      "57 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "58 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "59 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "60 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "61 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "62 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "63 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "64 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "65 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "66 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "67 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "68 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "69 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "70 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "71 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "72 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "73 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "74 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "75 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "76 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "77 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "78 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "79 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "80 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "81 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "82 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "83 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "84 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "85 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "86 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "87 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "88 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "89 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "90 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "91 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "92 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "93 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "94 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "95 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "96 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "97 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "98 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "99 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "100 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "101 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "102 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "103 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "104 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "105 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "106 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "107 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "108 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "109 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "110 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "111 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "112 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "113 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "114 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "115 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "116 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "117 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "118 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "119 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "120 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "121 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "122 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "123 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "124 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "125 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "126 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "127 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "128 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "129 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "130 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "131 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "132 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "133 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "134 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "135 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "136 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "137 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "138 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "139 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "140 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "141 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "142 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "143 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "144 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "145 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "146 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "147 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "148 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "149 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "150 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "151 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "152 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "153 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "154 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "155 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "156 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "157 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "158 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "159 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "160 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "161 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "162 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "163 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "164 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "165 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "166 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "167 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "168 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "169 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "170 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "171 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "172 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "173 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "174 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "175 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "176 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "177 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "178 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "179 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "180 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "181 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "182 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "183 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "184 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "185 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "186 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "187 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "188 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "189 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "190 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "191 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "192 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "193 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "194 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "195 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "196 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "197 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "198 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "199 Train Loss 4.793935e-05 Test MSE 2.2835664259516074e-08 Test RE 0.0004394826145239909\n",
      "Training time: 14.64\n",
      "Training time: 14.64\n",
      "1D_FODE_rowdylow\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 52.488613 Test MSE 0.12163108959903052 Test RE 1.0142783922310357\n",
      "1 Train Loss 36.777103 Test MSE 0.08839004186248851 Test RE 0.8646424323064896\n",
      "2 Train Loss 34.59847 Test MSE 0.07373818334613563 Test RE 0.7897344655121262\n",
      "3 Train Loss 33.54565 Test MSE 0.06416105192811744 Test RE 0.7366659776140971\n",
      "4 Train Loss 27.393766 Test MSE 0.023990170639977618 Test RE 0.45045513645152124\n",
      "5 Train Loss 2.3746848 Test MSE 0.5386186932431901 Test RE 2.134398887523606\n",
      "6 Train Loss 0.6428035 Test MSE 0.21440808096923078 Test RE 1.346652215087391\n",
      "7 Train Loss 0.4014591 Test MSE 0.05799740929097052 Test RE 0.7003887668898597\n",
      "8 Train Loss 0.12931038 Test MSE 0.0009659776756445922 Test RE 0.09038959068731388\n",
      "9 Train Loss 0.059065405 Test MSE 0.017694273953908702 Test RE 0.38685770264009406\n",
      "10 Train Loss 0.0029371127 Test MSE 0.0005194012574745002 Test RE 0.06628059116336313\n",
      "11 Train Loss 0.0018558129 Test MSE 1.5513731406040075e-05 Test RE 0.011454945017644326\n",
      "12 Train Loss 0.0016631145 Test MSE 1.5611331660337676e-05 Test RE 0.011490921296436621\n",
      "13 Train Loss 0.0011714271 Test MSE 4.753253520649407e-05 Test RE 0.020050738093583022\n",
      "14 Train Loss 0.0007324713 Test MSE 3.8083147192042465e-06 Test RE 0.0056754629195216386\n",
      "15 Train Loss 0.00044212744 Test MSE 6.975925133704246e-07 Test RE 0.0024290462300128493\n",
      "16 Train Loss 0.0002765715 Test MSE 8.785860454679521e-07 Test RE 0.002726007368872122\n",
      "17 Train Loss 0.00018214861 Test MSE 1.1514408528121094e-06 Test RE 0.0031207263786387435\n",
      "18 Train Loss 0.00012798107 Test MSE 1.3032084932440777e-07 Test RE 0.0010498852293738651\n",
      "19 Train Loss 9.287574e-05 Test MSE 1.989282814835294e-07 Test RE 0.00129712891440752\n",
      "20 Train Loss 7.509366e-05 Test MSE 2.494600045248055e-07 Test RE 0.0014525642052068439\n",
      "21 Train Loss 5.979883e-05 Test MSE 1.6709442185175094e-07 Test RE 0.001188819310527381\n",
      "22 Train Loss 5.8140176e-05 Test MSE 1.1149491034637031e-07 Test RE 0.0009710965165167572\n",
      "23 Train Loss 5.7552737e-05 Test MSE 7.193327347797606e-08 Test RE 0.0007800093112419137\n",
      "24 Train Loss 5.7116835e-05 Test MSE 6.624411335391326e-08 Test RE 0.000748528810434416\n",
      "25 Train Loss 5.6610024e-05 Test MSE 5.047931085433931e-08 Test RE 0.0006534187365442637\n",
      "26 Train Loss 5.6115943e-05 Test MSE 4.409928191232751e-08 Test RE 0.0006107319407011926\n",
      "27 Train Loss 5.5370536e-05 Test MSE 2.5442274402717876e-08 Test RE 0.00046388768262722635\n",
      "28 Train Loss 5.496015e-05 Test MSE 2.513835304011286e-08 Test RE 0.0004611086671944588\n",
      "29 Train Loss 5.3964806e-05 Test MSE 1.2570185913194076e-08 Test RE 0.0003260661573496347\n",
      "30 Train Loss 5.3637315e-05 Test MSE 1.451552789430665e-08 Test RE 0.0003503896685583878\n",
      "31 Train Loss 5.3089287e-05 Test MSE 1.569514699240507e-08 Test RE 0.00036434898887860386\n",
      "32 Train Loss 5.3035354e-05 Test MSE 2.446910302207805e-08 Test RE 0.0004549292904858057\n",
      "33 Train Loss 5.2570824e-05 Test MSE 2.010655821323899e-08 Test RE 0.0004123858382149547\n",
      "34 Train Loss 5.2026917e-05 Test MSE 1.5523896629604848e-08 Test RE 0.00036235582405664814\n",
      "35 Train Loss 5.1715477e-05 Test MSE 1.1449167141950527e-08 Test RE 0.0003111872700323522\n",
      "36 Train Loss 5.098658e-05 Test MSE 9.281337275490126e-09 Test RE 0.0002801819492170737\n",
      "37 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "38 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "39 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "40 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "41 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "42 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "43 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "44 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "45 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "46 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "47 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "48 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "49 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "50 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "51 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "52 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "53 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "54 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "55 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "56 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "57 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "58 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "59 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "60 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "61 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "62 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "63 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "64 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "65 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "66 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "67 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "68 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "69 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "70 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "71 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "72 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "73 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "74 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "75 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "76 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "77 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "78 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "79 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "80 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "81 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "82 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "83 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "84 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "85 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "86 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "87 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "88 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "89 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "90 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "91 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "92 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "93 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "94 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "95 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "96 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "97 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "98 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "99 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "100 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "101 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "102 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "103 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "104 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "105 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "106 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "107 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "108 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "109 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "110 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "111 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "112 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "113 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "114 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "115 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "116 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "117 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "118 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "119 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "120 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "121 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "122 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "123 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "124 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "125 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "126 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "127 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "128 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "129 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "130 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "131 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "132 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "133 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "134 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "135 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "136 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "137 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "138 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "139 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "140 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "141 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "142 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "143 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "144 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "145 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "146 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "147 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "148 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "149 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "150 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "151 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "152 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "153 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "154 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "155 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "156 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "157 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "158 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "159 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "160 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "161 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "162 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "163 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "164 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "165 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "166 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "167 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "168 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "169 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "170 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "171 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "172 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "173 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "174 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "175 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "176 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "177 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "178 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "179 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "180 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "181 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "182 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "183 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "184 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "185 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "186 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "187 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "188 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "189 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "190 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "191 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "192 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "193 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "194 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "195 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "196 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "197 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "198 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "199 Train Loss 5.071552e-05 Test MSE 2.012806900493548e-08 Test RE 0.0004126063725915971\n",
      "Training time: 10.70\n",
      "Training time: 10.70\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "omega_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val =8.0\n",
    "rowdy_terms = 2\n",
    "\n",
    "for reps in range(max_reps):  \n",
    "  print(label) \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  alpha_val = []\n",
    "  omega_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.05, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  alpha_full.append(alpha_val)\n",
    "  omega_full.append(omega_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full,\"omega\": omega_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "77a1e198-62ae-4129-82a3-1a1f3e433466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1D_FODE_rowdylow'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d2yA4xTDHldi"
   },
   "outputs": [],
   "source": [
    "#3,4,8,9,13,14,18,19,23,24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "1986cfc6-aa7b-43ff-e3e8-c586ef7bafd1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25615/2033279215.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#  if tune_reps not in s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_rowdy_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(70):\n",
    "#  if tune_reps not in s:\n",
    "    label = \"1D_FODE_rowdy_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2eNXAFRRtWs",
    "outputId": "737b4c47-e8bf-4e68-c774-00d25a78ecb3"
   },
   "outputs": [],
   "source": [
    "lrnr_tune[2]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "atanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
