{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "84a34ebd-2e54-4cae-ca1c-79397867998c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "94a6280c-bfd4-43c8-a396-40f22c70c38f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "150eeb9e-6cdc-4ff0-fd50-61a1c228e3a0"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/atanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "30d0ca6b-cde8-4b85-ccae-4eac06a2c482"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"high\"\n",
    "label = \"1D_FODE_rowdy\" + level\n",
    "extent = 100.0\n",
    "\n",
    "x = np.linspace(extent,-1*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        self.omega1.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        self.omega.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "\n",
    "                      \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "       \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "      \n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    omega_val.append(PINN.omega.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,123)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(i)\n",
    "\n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "509236d6-c6b5-4579-8ffe-6c945b3ae573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D_FODE_rowdyhigh\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 457733.47 Test MSE 5010166.547034746 Test RE 1.0004903522400685\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 82.60\n",
      "Training time: 82.60\n",
      "1D_FODE_rowdyhigh\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 457628.62 Test MSE 5013812.744072135 Test RE 1.0008543442801907\n",
      "1 Train Loss 455864.28 Test MSE 5000395.595613449 Test RE 0.9995142855350221\n",
      "2 Train Loss 450838.12 Test MSE 5049196.76388208 Test RE 1.0043798037403393\n",
      "3 Train Loss 431712.12 Test MSE 4973678.796727655 Test RE 0.9968405383826644\n",
      "4 Train Loss 428097.4 Test MSE 5003040.318101126 Test RE 0.9997785734717705\n",
      "5 Train Loss 425673.7 Test MSE 4984869.687421861 Test RE 0.997961365235249\n",
      "6 Train Loss 422060.12 Test MSE 5018894.393552263 Test RE 1.00136141376697\n",
      "7 Train Loss 411753.97 Test MSE 4966713.7275304375 Test RE 0.9961423131797915\n",
      "8 Train Loss 407170.94 Test MSE 4999488.449794473 Test RE 0.9994236180754218\n",
      "9 Train Loss 396707.94 Test MSE 5081311.234567635 Test RE 1.0075688258320838\n",
      "10 Train Loss 368906.2 Test MSE 5220691.144593397 Test RE 1.0212941029047171\n",
      "11 Train Loss 333085.3 Test MSE 5759103.274275737 Test RE 1.0726653622418807\n",
      "12 Train Loss 323554.53 Test MSE 5518924.670937178 Test RE 1.0500598588626457\n",
      "13 Train Loss 320624.56 Test MSE 5234489.062706216 Test RE 1.0226428164592236\n",
      "14 Train Loss 317150.53 Test MSE 5213132.140417424 Test RE 1.0205544725931575\n",
      "15 Train Loss 314376.3 Test MSE 5233438.904553784 Test RE 1.022540228551662\n",
      "16 Train Loss 310216.88 Test MSE 5133930.885908736 Test RE 1.0127723419010177\n",
      "17 Train Loss 306613.62 Test MSE 5002374.638518466 Test RE 0.999712058484803\n",
      "18 Train Loss 303953.03 Test MSE 4938955.098836257 Test RE 0.9933547266470059\n",
      "19 Train Loss 297579.84 Test MSE 4969218.951893808 Test RE 0.996393509998928\n",
      "20 Train Loss 292707.84 Test MSE 4872123.349774704 Test RE 0.9866110180148917\n",
      "21 Train Loss 289294.84 Test MSE 4921904.900220432 Test RE 0.9916386209459224\n",
      "22 Train Loss 288106.88 Test MSE 4906244.853578846 Test RE 0.9900598136225742\n",
      "23 Train Loss 284897.7 Test MSE 4868740.530205684 Test RE 0.9862684459626837\n",
      "24 Train Loss 276238.88 Test MSE 4599096.549070909 Test RE 0.9585683537769388\n",
      "25 Train Loss 263805.16 Test MSE 4165381.9046510183 Test RE 0.912250765920018\n",
      "26 Train Loss 255608.23 Test MSE 3889603.830955536 Test RE 0.8815348950614098\n",
      "27 Train Loss 248228.56 Test MSE 3702926.36085703 Test RE 0.8601206241053087\n",
      "28 Train Loss 246642.0 Test MSE 3574339.2739182375 Test RE 0.8450544833335569\n",
      "29 Train Loss 245296.31 Test MSE 3527822.581326046 Test RE 0.8395376774868392\n",
      "30 Train Loss 243209.83 Test MSE 3475752.4829336805 Test RE 0.833318924150545\n",
      "31 Train Loss 242596.89 Test MSE 3464776.3213522127 Test RE 0.8320021048818677\n",
      "32 Train Loss 242258.72 Test MSE 3443281.940072584 Test RE 0.8294173503590456\n",
      "33 Train Loss 240877.17 Test MSE 3317556.447654655 Test RE 0.814134172422272\n",
      "34 Train Loss 237706.2 Test MSE 3286745.7337263105 Test RE 0.8103448522581831\n",
      "35 Train Loss 237271.4 Test MSE 3322922.269106589 Test RE 0.8147922974155936\n",
      "36 Train Loss 236828.88 Test MSE 3323982.635861667 Test RE 0.8149222898860999\n",
      "37 Train Loss 233713.06 Test MSE 3006483.8306227806 Test RE 0.7750259781443267\n",
      "38 Train Loss 228720.83 Test MSE 3007027.894760505 Test RE 0.7750961007176618\n",
      "39 Train Loss 227079.08 Test MSE 2960454.268612833 Test RE 0.7690702326271207\n",
      "40 Train Loss 225863.89 Test MSE 2901823.400567558 Test RE 0.7614165510889169\n",
      "41 Train Loss 224948.92 Test MSE 2874558.146499676 Test RE 0.7578310104574048\n",
      "42 Train Loss 220024.39 Test MSE 2804075.802506937 Test RE 0.7484825823846869\n",
      "43 Train Loss 216495.36 Test MSE 2463832.9625914153 Test RE 0.7016046427529061\n",
      "44 Train Loss 213918.11 Test MSE 2475074.929535128 Test RE 0.7032034604530494\n",
      "45 Train Loss 212146.95 Test MSE 2460292.084048383 Test RE 0.7011003086367327\n",
      "46 Train Loss 208780.34 Test MSE 2484924.596677861 Test RE 0.704601285366692\n",
      "47 Train Loss 201832.5 Test MSE 2151655.6661616075 Test RE 0.6556517268939325\n",
      "48 Train Loss 198856.48 Test MSE 2087343.850027762 Test RE 0.6457788570243082\n",
      "49 Train Loss 195325.33 Test MSE 1819263.8031362286 Test RE 0.6028852559910732\n",
      "50 Train Loss 191881.25 Test MSE 1547163.612405942 Test RE 0.5559745922700359\n",
      "51 Train Loss 191326.86 Test MSE 1585218.1962527153 Test RE 0.5627705312233114\n",
      "52 Train Loss 190885.53 Test MSE 1552778.8974682246 Test RE 0.5569826072645357\n",
      "53 Train Loss 190489.48 Test MSE 1484101.680272022 Test RE 0.5445260386038018\n",
      "54 Train Loss 190241.89 Test MSE 1495741.2442571006 Test RE 0.5466571820372809\n",
      "55 Train Loss 190020.86 Test MSE 1520110.8106173687 Test RE 0.5510924325553139\n",
      "56 Train Loss 189357.45 Test MSE 1509432.1762522275 Test RE 0.5491533350067997\n",
      "57 Train Loss 188404.34 Test MSE 1552368.587987666 Test RE 0.5569090132893117\n",
      "58 Train Loss 187221.58 Test MSE 1441324.997274315 Test RE 0.5366211467888304\n",
      "59 Train Loss 186615.0 Test MSE 1419088.7618463556 Test RE 0.5324656596658689\n",
      "60 Train Loss 185070.7 Test MSE 1340705.6339609867 Test RE 0.5175514633287973\n",
      "61 Train Loss 184169.81 Test MSE 1397395.2795130173 Test RE 0.5283801083327893\n",
      "62 Train Loss 183023.66 Test MSE 1415562.276226835 Test RE 0.5318036501595553\n",
      "63 Train Loss 180137.88 Test MSE 1314759.6638087826 Test RE 0.5125190464808194\n",
      "64 Train Loss 170466.62 Test MSE 1084045.2480574558 Test RE 0.46538301478594857\n",
      "65 Train Loss 157990.6 Test MSE 819425.8264610062 Test RE 0.40461469119674576\n",
      "66 Train Loss 154277.61 Test MSE 662483.5018661962 Test RE 0.36380976964711004\n",
      "67 Train Loss 151952.86 Test MSE 567655.5070468469 Test RE 0.33676678540144583\n",
      "68 Train Loss 150659.53 Test MSE 595333.7811546203 Test RE 0.34487926708592404\n",
      "69 Train Loss 150244.64 Test MSE 601010.6642737641 Test RE 0.3465196864307281\n",
      "70 Train Loss 149863.2 Test MSE 543368.678954019 Test RE 0.32948384403107356\n",
      "71 Train Loss 148733.6 Test MSE 533970.0824159202 Test RE 0.32662188889552185\n",
      "72 Train Loss 147775.72 Test MSE 543092.9825050433 Test RE 0.3294002460481489\n",
      "73 Train Loss 147555.73 Test MSE 534423.3848243871 Test RE 0.32676049879552654\n",
      "74 Train Loss 147461.53 Test MSE 519180.5112762326 Test RE 0.32206684176605915\n",
      "75 Train Loss 147297.05 Test MSE 507788.82280537393 Test RE 0.3185139018118416\n",
      "76 Train Loss 147209.92 Test MSE 518922.17332944967 Test RE 0.3219867035121327\n",
      "77 Train Loss 147086.34 Test MSE 504556.9420697453 Test RE 0.31749867455357794\n",
      "78 Train Loss 146900.81 Test MSE 508277.3441049468 Test RE 0.3186670790895521\n",
      "79 Train Loss 146813.12 Test MSE 518431.7511568156 Test RE 0.321834516196142\n",
      "80 Train Loss 146568.95 Test MSE 517983.99022851686 Test RE 0.3216955046000039\n",
      "81 Train Loss 146170.83 Test MSE 513173.3752437228 Test RE 0.3201981966414\n",
      "82 Train Loss 145464.31 Test MSE 482303.3224051175 Test RE 0.31041803860259254\n",
      "83 Train Loss 144466.19 Test MSE 449733.80251740024 Test RE 0.299753725253689\n",
      "84 Train Loss 143431.33 Test MSE 405616.0262917288 Test RE 0.28467175362563146\n",
      "85 Train Loss 143093.12 Test MSE 396668.92411742656 Test RE 0.2815145931896584\n",
      "86 Train Loss 142385.25 Test MSE 397017.8872090529 Test RE 0.2816383949301472\n",
      "87 Train Loss 141763.03 Test MSE 381309.22980535036 Test RE 0.27601042291139805\n",
      "88 Train Loss 141135.97 Test MSE 383660.4409212147 Test RE 0.27686007642284327\n",
      "89 Train Loss 140332.97 Test MSE 359151.8530429169 Test RE 0.2678711112967417\n",
      "90 Train Loss 139428.66 Test MSE 320062.0077090442 Test RE 0.2528738299206378\n",
      "91 Train Loss 138380.94 Test MSE 261765.40147981158 Test RE 0.22868777311140773\n",
      "92 Train Loss 138280.52 Test MSE 257829.12282775898 Test RE 0.22696182198571394\n",
      "93 Train Loss 138136.61 Test MSE 245725.21873610755 Test RE 0.22157037300835528\n",
      "94 Train Loss 137229.77 Test MSE 219592.17016157566 Test RE 0.20945717848157736\n",
      "95 Train Loss 136210.95 Test MSE 192817.8021673896 Test RE 0.19627292187764983\n",
      "96 Train Loss 135288.47 Test MSE 147555.2199715724 Test RE 0.1716975557161029\n",
      "97 Train Loss 134165.67 Test MSE 139122.50074487456 Test RE 0.1667191592195385\n",
      "98 Train Loss 133082.78 Test MSE 93993.59782103795 Test RE 0.1370364061225682\n",
      "99 Train Loss 132643.58 Test MSE 91909.96606381884 Test RE 0.13550899567800664\n",
      "100 Train Loss 131516.8 Test MSE 57402.009355315866 Test RE 0.10709035820099276\n",
      "101 Train Loss 130686.3 Test MSE 45236.980004260186 Test RE 0.09506783979257855\n",
      "102 Train Loss 129844.83 Test MSE 30261.163014831476 Test RE 0.07775523373075509\n",
      "103 Train Loss 129461.71 Test MSE 18361.58065539184 Test RE 0.06056780793482731\n",
      "104 Train Loss 129028.39 Test MSE 23556.49650801078 Test RE 0.06860285240611516\n",
      "105 Train Loss 128547.836 Test MSE 18008.356670572 Test RE 0.0599824037054495\n",
      "106 Train Loss 127977.945 Test MSE 25823.064437797602 Test RE 0.07182749376889033\n",
      "107 Train Loss 127886.65 Test MSE 26403.5141955465 Test RE 0.07263027531017134\n",
      "108 Train Loss 127871.87 Test MSE 25643.911839301498 Test RE 0.07157790141987327\n",
      "109 Train Loss 127698.21 Test MSE 12654.30882765756 Test RE 0.050281246812373656\n",
      "110 Train Loss 127304.94 Test MSE 12934.25066022292 Test RE 0.05083437170764919\n",
      "111 Train Loss 126103.18 Test MSE 10551.816071511132 Test RE 0.04591456032205591\n",
      "112 Train Loss 125604.09 Test MSE 8463.042844041798 Test RE 0.04111971476231948\n",
      "113 Train Loss 125508.67 Test MSE 6984.074128223907 Test RE 0.037354355169780716\n",
      "114 Train Loss 125446.56 Test MSE 9538.611883954505 Test RE 0.04365453964192972\n",
      "115 Train Loss 124730.21 Test MSE 3380.9924990040654 Test RE 0.025990158454670998\n",
      "116 Train Loss 124326.016 Test MSE 3898.2668957790734 Test RE 0.027907607646216945\n",
      "117 Train Loss 124279.01 Test MSE 3816.826386008485 Test RE 0.027614553569065017\n",
      "118 Train Loss 124250.266 Test MSE 4296.135129814998 Test RE 0.02929717803454121\n",
      "119 Train Loss 124239.0 Test MSE 4521.117899336448 Test RE 0.030054516099984753\n",
      "120 Train Loss 124236.625 Test MSE 4472.500155042175 Test RE 0.02989248402355984\n",
      "121 Train Loss 124232.734 Test MSE 4350.783213759979 Test RE 0.029482923514733774\n",
      "122 Train Loss 124230.93 Test MSE 4327.399600389651 Test RE 0.029403587671091178\n",
      "123 Train Loss 124230.65 Test MSE 4311.339252756225 Test RE 0.02934897394822446\n",
      "124 Train Loss 124230.65 Test MSE 4311.339252756225 Test RE 0.02934897394822446\n",
      "125 Train Loss 124230.65 Test MSE 4311.339252756225 Test RE 0.02934897394822446\n",
      "126 Train Loss 124230.65 Test MSE 4311.339252756225 Test RE 0.02934897394822446\n",
      "127 Train Loss 124230.65 Test MSE 4311.339252756225 Test RE 0.02934897394822446\n",
      "128 Train Loss 124230.57 Test MSE 4308.237390413231 Test RE 0.029338414252957537\n",
      "129 Train Loss 124230.57 Test MSE 4308.237390413231 Test RE 0.029338414252957537\n",
      "130 Train Loss 124230.57 Test MSE 4308.237390413231 Test RE 0.029338414252957537\n",
      "131 Train Loss 124230.57 Test MSE 4308.237390413231 Test RE 0.029338414252957537\n",
      "132 Train Loss 124230.58 Test MSE 4307.5368339737015 Test RE 0.029336028816783974\n",
      "133 Train Loss 124230.125 Test MSE 4293.832994119386 Test RE 0.029289327360020306\n",
      "134 Train Loss 124228.84 Test MSE 4294.518222146018 Test RE 0.02929166432414666\n",
      "135 Train Loss 124219.8 Test MSE 4347.362172338722 Test RE 0.029471329954157157\n",
      "136 Train Loss 124202.63 Test MSE 4443.733225001456 Test RE 0.0297961953521537\n",
      "137 Train Loss 124189.28 Test MSE 4342.880180627472 Test RE 0.02945613403602249\n",
      "138 Train Loss 124175.375 Test MSE 4150.568316205668 Test RE 0.028796559755719896\n",
      "139 Train Loss 124168.516 Test MSE 4263.2987795749605 Test RE 0.029185000734578033\n",
      "140 Train Loss 124163.586 Test MSE 4354.482937076808 Test RE 0.02949545637089947\n",
      "141 Train Loss 124158.03 Test MSE 4261.764539527712 Test RE 0.029179748835940333\n",
      "142 Train Loss 124154.79 Test MSE 4151.343813135547 Test RE 0.02879924982114713\n",
      "143 Train Loss 124151.555 Test MSE 4145.486223664636 Test RE 0.028778924627733658\n",
      "144 Train Loss 124149.48 Test MSE 4220.983231361089 Test RE 0.02903980107435429\n",
      "145 Train Loss 124148.9 Test MSE 4217.86693512734 Test RE 0.029029079244031836\n",
      "146 Train Loss 124147.695 Test MSE 4127.234883698555 Test RE 0.028715502230555058\n",
      "147 Train Loss 124146.85 Test MSE 4084.3751235494315 Test RE 0.02856601335216637\n",
      "148 Train Loss 124145.9 Test MSE 4099.834233421897 Test RE 0.028620022601133856\n",
      "149 Train Loss 124145.09 Test MSE 4121.333529414742 Test RE 0.028694965360686185\n",
      "150 Train Loss 124142.36 Test MSE 4124.428073843848 Test RE 0.028705736289820465\n",
      "151 Train Loss 124138.04 Test MSE 4014.478722584113 Test RE 0.028320531776241643\n",
      "152 Train Loss 124115.945 Test MSE 4271.66546085093 Test RE 0.029213624334309896\n",
      "153 Train Loss 124069.06 Test MSE 5291.652581412529 Test RE 0.03251490468753416\n",
      "154 Train Loss 124052.61 Test MSE 5010.858696626963 Test RE 0.031640468224423915\n",
      "155 Train Loss 124015.13 Test MSE 3904.4463160886685 Test RE 0.02792971805507124\n",
      "156 Train Loss 123974.484 Test MSE 3826.0801483611485 Test RE 0.02764800856436685\n",
      "157 Train Loss 123949.9 Test MSE 4011.7767356008803 Test RE 0.028310999456633564\n",
      "158 Train Loss 123934.445 Test MSE 3683.4345447447345 Test RE 0.027127720489623065\n",
      "159 Train Loss 123907.23 Test MSE 3225.499194126222 Test RE 0.02538547490673018\n",
      "160 Train Loss 123883.805 Test MSE 3189.0070476466717 Test RE 0.025241465329229936\n",
      "161 Train Loss 123860.39 Test MSE 3103.142886060723 Test RE 0.024899332823526445\n",
      "162 Train Loss 123847.445 Test MSE 2848.345624853634 Test RE 0.023855205761258404\n",
      "163 Train Loss 123834.414 Test MSE 2592.0132673742964 Test RE 0.022756498235741333\n",
      "164 Train Loss 123824.055 Test MSE 2450.9065630959685 Test RE 0.022128409567101128\n",
      "165 Train Loss 123817.336 Test MSE 2484.9155483618247 Test RE 0.022281408473831903\n",
      "166 Train Loss 123809.68 Test MSE 2599.4182058369697 Test RE 0.02278898076416646\n",
      "167 Train Loss 123792.69 Test MSE 2598.1341033119065 Test RE 0.02278335123472596\n",
      "168 Train Loss 123783.23 Test MSE 2692.92082717873 Test RE 0.023195226420628757\n",
      "169 Train Loss 123780.51 Test MSE 2701.547279577148 Test RE 0.02323234829357016\n",
      "170 Train Loss 123780.195 Test MSE 2692.7770369922914 Test RE 0.0231946071505743\n",
      "171 Train Loss 123780.164 Test MSE 2689.9172568293834 Test RE 0.023182287322905094\n",
      "172 Train Loss 123780.016 Test MSE 2688.8980282163157 Test RE 0.023177894940736327\n",
      "173 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "174 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "175 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "176 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "177 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "178 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "179 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "180 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "181 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "182 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "183 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "184 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "185 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "186 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "187 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "188 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "189 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "190 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "191 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "192 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "193 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "194 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "195 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "196 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "197 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "198 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "199 Train Loss 123779.87 Test MSE 2680.834796261894 Test RE 0.023143116927955034\n",
      "Training time: 47.37\n",
      "Training time: 47.37\n",
      "1D_FODE_rowdyhigh\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 457313.03 Test MSE 5017641.762070063 Test RE 1.0012364444999675\n",
      "1 Train Loss 457313.03 Test MSE 5017641.762070063 Test RE 1.0012364444999675\n",
      "2 Train Loss 457313.03 Test MSE 5017641.762070063 Test RE 1.0012364444999675\n",
      "3 Train Loss 457313.03 Test MSE 5017641.762070063 Test RE 1.0012364444999675\n",
      "4 Train Loss 457313.03 Test MSE 5017641.762070063 Test RE 1.0012364444999675\n",
      "5 Train Loss 457313.03 Test MSE 5017641.762070063 Test RE 1.0012364444999675\n",
      "6 Train Loss 457090.3 Test MSE 5017300.605235731 Test RE 1.0012024061530382\n",
      "7 Train Loss 455164.3 Test MSE 5018977.416226243 Test RE 1.0013696960052347\n",
      "8 Train Loss 449970.6 Test MSE 4991497.980637413 Test RE 0.9986246306296008\n",
      "9 Train Loss 430017.47 Test MSE 4988830.99499831 Test RE 0.998357809586042\n",
      "10 Train Loss 412526.7 Test MSE 5059209.822181761 Test RE 1.0053752029071017\n",
      "11 Train Loss 376853.4 Test MSE 4615345.849163889 Test RE 0.9602602437797036\n",
      "12 Train Loss 321915.53 Test MSE 4539069.586586904 Test RE 0.9522922370667929\n",
      "13 Train Loss 302081.28 Test MSE 4622659.839618221 Test RE 0.9610208101813857\n",
      "14 Train Loss 267888.4 Test MSE 3664599.9228840843 Test RE 0.8556577883268257\n",
      "15 Train Loss 253152.73 Test MSE 3833886.674574327 Test RE 0.8751982878695723\n",
      "16 Train Loss 249837.42 Test MSE 3875149.707002605 Test RE 0.8798954383609974\n",
      "17 Train Loss 242516.53 Test MSE 3889942.6275544646 Test RE 0.8815732864418654\n",
      "18 Train Loss 231162.23 Test MSE 3560634.644091287 Test RE 0.8434328855556928\n",
      "19 Train Loss 224365.67 Test MSE 3380866.3277903465 Test RE 0.8218656391149939\n",
      "20 Train Loss 214277.64 Test MSE 2884723.097307063 Test RE 0.759169740879509\n",
      "21 Train Loss 208908.22 Test MSE 2692342.323846362 Test RE 0.7334186727579008\n",
      "22 Train Loss 198908.88 Test MSE 2415063.806065633 Test RE 0.6946261492228559\n",
      "23 Train Loss 196708.16 Test MSE 2347420.70591801 Test RE 0.6848292307606964\n",
      "24 Train Loss 195171.69 Test MSE 2306744.8689169516 Test RE 0.6788699814346866\n",
      "25 Train Loss 191866.94 Test MSE 2231162.4783172975 Test RE 0.6676554870122153\n",
      "26 Train Loss 186318.47 Test MSE 1961828.6273904557 Test RE 0.6260620189713945\n",
      "27 Train Loss 182088.02 Test MSE 1775983.6933105285 Test RE 0.5956707989585592\n",
      "28 Train Loss 176776.48 Test MSE 1559388.922593418 Test RE 0.55816685803814\n",
      "29 Train Loss 175069.17 Test MSE 1529050.3739412774 Test RE 0.552710506654896\n",
      "30 Train Loss 174237.23 Test MSE 1470135.3174479592 Test RE 0.5419578099157751\n",
      "31 Train Loss 170983.81 Test MSE 1264765.7588261398 Test RE 0.5026803089631181\n",
      "32 Train Loss 169002.55 Test MSE 1060356.5512703822 Test RE 0.46027012373746895\n",
      "33 Train Loss 164958.16 Test MSE 1159765.7627974595 Test RE 0.4813621802993507\n",
      "34 Train Loss 161374.39 Test MSE 1127602.1607204438 Test RE 0.4746404787172432\n",
      "35 Train Loss 160548.47 Test MSE 1043780.3216507294 Test RE 0.4566583215588232\n",
      "36 Train Loss 159569.77 Test MSE 1011068.3322742685 Test RE 0.44944554262988873\n",
      "37 Train Loss 156595.61 Test MSE 918567.7159053138 Test RE 0.4283930460252672\n",
      "38 Train Loss 154545.83 Test MSE 771131.4936321722 Test RE 0.3925102874940233\n",
      "39 Train Loss 153346.22 Test MSE 691640.0963264556 Test RE 0.3717293950742771\n",
      "40 Train Loss 152778.84 Test MSE 741603.1312161873 Test RE 0.384921882482916\n",
      "41 Train Loss 150888.44 Test MSE 690461.0724944487 Test RE 0.3714124204235774\n",
      "42 Train Loss 148000.53 Test MSE 519350.3079429251 Test RE 0.3221195030317541\n",
      "43 Train Loss 146903.0 Test MSE 480400.4437316032 Test RE 0.30980507201604474\n",
      "44 Train Loss 146155.55 Test MSE 401794.1839685236 Test RE 0.2833274459165767\n",
      "45 Train Loss 143947.23 Test MSE 383424.7776281034 Test RE 0.27677503275824433\n",
      "46 Train Loss 141272.55 Test MSE 330213.3320311458 Test RE 0.25685269412647904\n",
      "47 Train Loss 138266.52 Test MSE 247051.3926132556 Test RE 0.22216747379674515\n",
      "48 Train Loss 137949.4 Test MSE 259659.8886548793 Test RE 0.2277661898961547\n",
      "49 Train Loss 137766.97 Test MSE 264361.7417759744 Test RE 0.2298191033824026\n",
      "50 Train Loss 137675.38 Test MSE 262151.04768810136 Test RE 0.22885616838735895\n",
      "51 Train Loss 137430.02 Test MSE 236528.2390955957 Test RE 0.21738437398759994\n",
      "52 Train Loss 137131.19 Test MSE 227143.7232461054 Test RE 0.21302824709953053\n",
      "53 Train Loss 136724.17 Test MSE 238622.35456182194 Test RE 0.21834456550839648\n",
      "54 Train Loss 135893.72 Test MSE 236209.4512414383 Test RE 0.21723783151928602\n",
      "55 Train Loss 135701.9 Test MSE 245033.17838905516 Test RE 0.2212581467106357\n",
      "56 Train Loss 135492.45 Test MSE 252605.86048606754 Test RE 0.2246510923523331\n",
      "57 Train Loss 135377.33 Test MSE 249662.62045024513 Test RE 0.22333849534543748\n",
      "58 Train Loss 135226.6 Test MSE 254747.29873454152 Test RE 0.2256013101572412\n",
      "59 Train Loss 135103.19 Test MSE 255928.4582544403 Test RE 0.22612371602960518\n",
      "60 Train Loss 135025.23 Test MSE 254920.27212950564 Test RE 0.225677888795779\n",
      "61 Train Loss 134596.11 Test MSE 243436.8381864738 Test RE 0.22053624361967564\n",
      "62 Train Loss 132916.52 Test MSE 193444.52660662637 Test RE 0.19659164048706654\n",
      "63 Train Loss 132162.22 Test MSE 137860.89847040424 Test RE 0.16596150936360246\n",
      "64 Train Loss 130365.77 Test MSE 90518.72238540034 Test RE 0.13447948318937403\n",
      "65 Train Loss 129275.65 Test MSE 93893.69110672311 Test RE 0.1369635580916071\n",
      "66 Train Loss 128248.85 Test MSE 68229.24438124971 Test RE 0.11675409033294001\n",
      "67 Train Loss 127898.625 Test MSE 62012.79841581988 Test RE 0.11130828430446306\n",
      "68 Train Loss 127815.59 Test MSE 57839.20034748185 Test RE 0.10749740084260107\n",
      "69 Train Loss 127712.45 Test MSE 53711.52188995426 Test RE 0.10359064869942099\n",
      "70 Train Loss 127651.04 Test MSE 51241.45408705563 Test RE 0.10118066892828417\n",
      "71 Train Loss 127534.23 Test MSE 45574.3768655359 Test RE 0.09542170961728848\n",
      "72 Train Loss 127466.39 Test MSE 43085.51914713853 Test RE 0.09277959849416009\n",
      "73 Train Loss 127378.23 Test MSE 44772.37809088589 Test RE 0.09457838742459561\n",
      "74 Train Loss 127065.32 Test MSE 43063.630287835265 Test RE 0.09275602795797179\n",
      "75 Train Loss 126729.89 Test MSE 28929.089603698987 Test RE 0.07602461105940662\n",
      "76 Train Loss 126651.414 Test MSE 28501.79857375523 Test RE 0.0754610696414715\n",
      "77 Train Loss 126634.06 Test MSE 27632.443735572124 Test RE 0.07430131000283896\n",
      "78 Train Loss 126614.49 Test MSE 25122.34699678648 Test RE 0.07084625999782174\n",
      "79 Train Loss 126594.766 Test MSE 25904.249424875663 Test RE 0.07194031419148354\n",
      "80 Train Loss 126582.664 Test MSE 26404.136854607437 Test RE 0.07263113170436315\n",
      "81 Train Loss 126556.01 Test MSE 24739.2216914183 Test RE 0.0703039683692871\n",
      "82 Train Loss 126442.09 Test MSE 22344.607317285638 Test RE 0.06681487912399964\n",
      "83 Train Loss 126244.695 Test MSE 21917.33049936825 Test RE 0.06617297376176881\n",
      "84 Train Loss 126217.59 Test MSE 20196.62637205998 Test RE 0.06352230362402761\n",
      "85 Train Loss 126205.16 Test MSE 17892.582762380327 Test RE 0.05978928240470278\n",
      "86 Train Loss 126183.4 Test MSE 15677.551103115702 Test RE 0.055966214958056544\n",
      "87 Train Loss 126141.36 Test MSE 15697.534984253674 Test RE 0.056001873142141605\n",
      "88 Train Loss 126092.37 Test MSE 16758.271333116336 Test RE 0.057863064747534686\n",
      "89 Train Loss 125994.305 Test MSE 12823.157663135924 Test RE 0.05061559129470288\n",
      "90 Train Loss 125909.38 Test MSE 10760.584200504978 Test RE 0.04636654639388299\n",
      "91 Train Loss 125776.72 Test MSE 9819.441826479422 Test RE 0.04429250312074896\n",
      "92 Train Loss 125689.055 Test MSE 6505.458957217534 Test RE 0.03605170380244532\n",
      "93 Train Loss 125630.484 Test MSE 4370.895929060558 Test RE 0.029550991479884704\n",
      "94 Train Loss 125509.05 Test MSE 3032.441500439719 Test RE 0.024614047787030535\n",
      "95 Train Loss 125411.48 Test MSE 2651.5159557730476 Test RE 0.023016217137982836\n",
      "96 Train Loss 125293.32 Test MSE 2644.912932284152 Test RE 0.022987540833729926\n",
      "97 Train Loss 125161.664 Test MSE 2593.0808533308254 Test RE 0.0227611841718011\n",
      "98 Train Loss 125069.22 Test MSE 2868.3034332566376 Test RE 0.023938634287247493\n",
      "99 Train Loss 124983.23 Test MSE 2711.6193227826243 Test RE 0.02327561600225421\n",
      "100 Train Loss 124948.7 Test MSE 2186.7906994354094 Test RE 0.02090212462089193\n",
      "101 Train Loss 124929.445 Test MSE 1837.518524138765 Test RE 0.019160316849266956\n",
      "102 Train Loss 124909.2 Test MSE 1921.8068900503672 Test RE 0.019594838874782444\n",
      "103 Train Loss 124894.766 Test MSE 2503.171363250244 Test RE 0.02236310559824015\n",
      "104 Train Loss 124889.53 Test MSE 2702.323409209664 Test RE 0.023235685273679352\n",
      "105 Train Loss 124882.51 Test MSE 2563.5082053806773 Test RE 0.022631022666317096\n",
      "106 Train Loss 124856.74 Test MSE 1872.6682166118196 Test RE 0.01934270656380206\n",
      "107 Train Loss 124843.76 Test MSE 1848.746533477495 Test RE 0.019218766485801144\n",
      "108 Train Loss 124839.33 Test MSE 1934.2314801021207 Test RE 0.019658077698645342\n",
      "109 Train Loss 124801.58 Test MSE 2298.744030782087 Test RE 0.02143049146913507\n",
      "110 Train Loss 124689.82 Test MSE 1744.4869109277395 Test RE 0.018668983904392904\n",
      "111 Train Loss 124659.414 Test MSE 1418.9559323486546 Test RE 0.01683725454829699\n",
      "112 Train Loss 124648.41 Test MSE 1332.044894964555 Test RE 0.01631346647853898\n",
      "113 Train Loss 124645.34 Test MSE 1334.962406846328 Test RE 0.016331321995222206\n",
      "114 Train Loss 124644.5 Test MSE 1338.023347473901 Test RE 0.01635003435162738\n",
      "115 Train Loss 124644.016 Test MSE 1343.0300902418037 Test RE 0.0163805958440969\n",
      "116 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "117 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "118 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "119 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "120 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "121 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "122 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "123 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "124 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "125 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "126 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "127 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "128 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "129 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "130 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "131 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "132 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "133 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "134 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "135 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "136 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "137 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "138 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "139 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "140 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "141 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "142 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "143 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "144 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "145 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "146 Train Loss 124643.77 Test MSE 1347.7396339120996 Test RE 0.016409291262019746\n",
      "147 Train Loss 124643.77 Test MSE 1348.137170238312 Test RE 0.016411711168741704\n",
      "148 Train Loss 124643.77 Test MSE 1348.137170238312 Test RE 0.016411711168741704\n",
      "149 Train Loss 124643.77 Test MSE 1348.137170238312 Test RE 0.016411711168741704\n",
      "150 Train Loss 124643.77 Test MSE 1348.5332438526116 Test RE 0.016414121816760673\n",
      "151 Train Loss 124643.75 Test MSE 1349.6225504687366 Test RE 0.016420749907796392\n",
      "152 Train Loss 124643.75 Test MSE 1350.0702213229663 Test RE 0.016423473069782\n",
      "153 Train Loss 124643.66 Test MSE 1350.3213144680196 Test RE 0.01642500026063326\n",
      "154 Train Loss 124643.66 Test MSE 1350.3213144680196 Test RE 0.01642500026063326\n",
      "155 Train Loss 124643.66 Test MSE 1350.3213144680196 Test RE 0.01642500026063326\n",
      "156 Train Loss 124643.66 Test MSE 1350.3213144680196 Test RE 0.01642500026063326\n",
      "157 Train Loss 124643.66 Test MSE 1350.3213144680196 Test RE 0.01642500026063326\n",
      "158 Train Loss 124643.66 Test MSE 1350.3213144680196 Test RE 0.01642500026063326\n",
      "159 Train Loss 124643.66 Test MSE 1350.3213144680196 Test RE 0.01642500026063326\n",
      "160 Train Loss 124643.66 Test MSE 1350.3213144680196 Test RE 0.01642500026063326\n",
      "161 Train Loss 124643.66 Test MSE 1350.3213144680196 Test RE 0.01642500026063326\n",
      "162 Train Loss 124643.66 Test MSE 1350.3212995220808 Test RE 0.016425000169733767\n",
      "163 Train Loss 124643.66 Test MSE 1351.4383045242478 Test RE 0.01643179226237872\n",
      "164 Train Loss 124643.63 Test MSE 1351.779823403054 Test RE 0.01643386835152094\n",
      "165 Train Loss 124643.63 Test MSE 1351.779823403054 Test RE 0.01643386835152094\n",
      "166 Train Loss 124643.64 Test MSE 1352.0338466114717 Test RE 0.01643541238546496\n",
      "167 Train Loss 124643.64 Test MSE 1352.0338466114717 Test RE 0.01643541238546496\n",
      "168 Train Loss 124643.48 Test MSE 1358.3341764962233 Test RE 0.016473661490371928\n",
      "169 Train Loss 124643.484 Test MSE 1358.5949836644531 Test RE 0.016475242928453482\n",
      "170 Train Loss 124643.45 Test MSE 1359.1037372954756 Test RE 0.016478327385271642\n",
      "171 Train Loss 124643.45 Test MSE 1359.266321811109 Test RE 0.016479312976247645\n",
      "172 Train Loss 124643.01 Test MSE 1363.9517267495557 Test RE 0.016507690723028056\n",
      "173 Train Loss 124643.01 Test MSE 1363.9517267495557 Test RE 0.016507690723028056\n",
      "174 Train Loss 124643.01 Test MSE 1363.9517267495557 Test RE 0.016507690723028056\n",
      "175 Train Loss 124642.29 Test MSE 1367.7150086077454 Test RE 0.016530448237032317\n",
      "176 Train Loss 124638.7 Test MSE 1383.766201328654 Test RE 0.01662716409901699\n",
      "177 Train Loss 124633.57 Test MSE 1379.558962711628 Test RE 0.0166018680263719\n",
      "178 Train Loss 124633.57 Test MSE 1379.558962711628 Test RE 0.0166018680263719\n",
      "179 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "180 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "181 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "182 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "183 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "184 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "185 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "186 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "187 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "188 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "189 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "190 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "191 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "192 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "193 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "194 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "195 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "196 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "197 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "198 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "199 Train Loss 124633.336 Test MSE 1376.0919117532396 Test RE 0.01658099333613378\n",
      "Training time: 39.48\n",
      "Training time: 39.48\n",
      "1D_FODE_rowdyhigh\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 457705.1 Test MSE 5018266.5003141165 Test RE 1.0012987737034826\n",
      "1 Train Loss 456625.22 Test MSE 5003494.0803191075 Test RE 0.9998239110493371\n",
      "2 Train Loss 455619.53 Test MSE 4993925.510076776 Test RE 0.9988674330938998\n",
      "3 Train Loss 453765.22 Test MSE 4988135.205108485 Test RE 0.998288186913591\n",
      "4 Train Loss 450817.78 Test MSE 4976705.983517517 Test RE 0.9971438514442723\n",
      "5 Train Loss 447371.38 Test MSE 4976269.243480843 Test RE 0.9971000973830041\n",
      "6 Train Loss 442831.84 Test MSE 4951391.818841903 Test RE 0.9946046172586233\n",
      "7 Train Loss 437053.97 Test MSE 4947333.075695163 Test RE 0.9941968862176186\n",
      "8 Train Loss 430259.7 Test MSE 4899997.934817708 Test RE 0.9894293117435112\n",
      "9 Train Loss 420051.3 Test MSE 4833636.010798541 Test RE 0.9827064247156259\n",
      "10 Train Loss 407669.4 Test MSE 4770018.227253422 Test RE 0.9762180714968887\n",
      "11 Train Loss 395875.78 Test MSE 4731512.29075532 Test RE 0.9722698307712911\n",
      "12 Train Loss 382669.03 Test MSE 4675914.49470342 Test RE 0.9665406058214314\n",
      "13 Train Loss 362944.8 Test MSE 4505031.391342099 Test RE 0.9487149283683405\n",
      "14 Train Loss 343031.97 Test MSE 4591369.769817063 Test RE 0.9577627869099188\n",
      "15 Train Loss 327732.25 Test MSE 4289508.407794862 Test RE 0.9257433166373706\n",
      "16 Train Loss 322210.7 Test MSE 4267496.860067218 Test RE 0.923365042757501\n",
      "17 Train Loss 298206.16 Test MSE 4238027.816389965 Test RE 0.9201713880034559\n",
      "18 Train Loss 285016.44 Test MSE 4099750.223537545 Test RE 0.9050353083490534\n",
      "19 Train Loss 278570.78 Test MSE 3976852.6173592974 Test RE 0.8913670412629302\n",
      "20 Train Loss 269603.22 Test MSE 3769517.497914406 Test RE 0.867820101307627\n",
      "21 Train Loss 263665.7 Test MSE 3732405.7013258254 Test RE 0.8635375869602733\n",
      "22 Train Loss 253178.77 Test MSE 3776709.3391266093 Test RE 0.8686475613618685\n",
      "23 Train Loss 246473.84 Test MSE 3541246.670457698 Test RE 0.8411334674548836\n",
      "24 Train Loss 238160.3 Test MSE 3529695.0452903877 Test RE 0.8397604488243404\n",
      "25 Train Loss 232563.62 Test MSE 3491216.426343096 Test RE 0.8351706232218741\n",
      "26 Train Loss 226035.47 Test MSE 3373338.3515503462 Test RE 0.8209501292586234\n",
      "27 Train Loss 218414.53 Test MSE 3223075.412899814 Test RE 0.8024575310258062\n",
      "28 Train Loss 217234.78 Test MSE 3225461.784736747 Test RE 0.8027545466828689\n",
      "29 Train Loss 206382.44 Test MSE 2884279.722020655 Test RE 0.7591113973185357\n",
      "30 Train Loss 201804.06 Test MSE 2539569.4040755928 Test RE 0.7123064332906227\n",
      "31 Train Loss 200040.73 Test MSE 2510627.9843055513 Test RE 0.7082360129060831\n",
      "32 Train Loss 198591.89 Test MSE 2491020.798121843 Test RE 0.7054650460140685\n",
      "33 Train Loss 188927.02 Test MSE 2124057.853049636 Test RE 0.6514333589566631\n",
      "34 Train Loss 186386.69 Test MSE 2016014.4330981143 Test RE 0.6346490614810036\n",
      "35 Train Loss 185227.1 Test MSE 1936195.1081778628 Test RE 0.6219584648264542\n",
      "36 Train Loss 183632.23 Test MSE 1928688.481521027 Test RE 0.6207516277653851\n",
      "37 Train Loss 177915.02 Test MSE 1739498.207645314 Test RE 0.5895203704896115\n",
      "38 Train Loss 170949.4 Test MSE 1514870.803198625 Test RE 0.5501417711622866\n",
      "39 Train Loss 169110.42 Test MSE 1471212.8907762715 Test RE 0.5421563944606805\n",
      "40 Train Loss 167900.98 Test MSE 1429535.9643008844 Test RE 0.5344220474711273\n",
      "41 Train Loss 165560.84 Test MSE 1279544.382730771 Test RE 0.5056086565835086\n",
      "42 Train Loss 160517.22 Test MSE 1120999.1269315705 Test RE 0.4732487339853407\n",
      "43 Train Loss 159719.23 Test MSE 1075911.7705630448 Test RE 0.46363386778279037\n",
      "44 Train Loss 159140.75 Test MSE 1037659.5976786263 Test RE 0.4553174315649624\n",
      "45 Train Loss 158529.22 Test MSE 1005849.5106680477 Test RE 0.44828409257995433\n",
      "46 Train Loss 158133.62 Test MSE 1011758.8364174585 Test RE 0.44959898974643214\n",
      "47 Train Loss 157487.08 Test MSE 1004852.4274446672 Test RE 0.44806184891006773\n",
      "48 Train Loss 155984.89 Test MSE 932029.9501298836 Test RE 0.4315208234162669\n",
      "49 Train Loss 154554.86 Test MSE 916042.3390589138 Test RE 0.4278037598693439\n",
      "50 Train Loss 153414.05 Test MSE 911040.8624076963 Test RE 0.4266342838630167\n",
      "51 Train Loss 151998.69 Test MSE 836325.7536443127 Test RE 0.40876580582288913\n",
      "52 Train Loss 149805.58 Test MSE 768209.4881617359 Test RE 0.3917659230325604\n",
      "53 Train Loss 148147.7 Test MSE 733793.5983822079 Test RE 0.38288978754601366\n",
      "54 Train Loss 147038.98 Test MSE 664929.5923082314 Test RE 0.3644807989291706\n",
      "55 Train Loss 145053.2 Test MSE 567152.2364269677 Test RE 0.3366174673654529\n",
      "56 Train Loss 144424.1 Test MSE 593004.4539699294 Test RE 0.34420391150333685\n",
      "57 Train Loss 143661.58 Test MSE 566029.2455060778 Test RE 0.33628404218887525\n",
      "58 Train Loss 143188.55 Test MSE 531090.2616993871 Test RE 0.32573992548756103\n",
      "59 Train Loss 143018.1 Test MSE 539313.342777118 Test RE 0.3282520191079977\n",
      "60 Train Loss 142515.7 Test MSE 554099.5116856797 Test RE 0.3327213790206323\n",
      "61 Train Loss 140909.73 Test MSE 457909.5591868633 Test RE 0.3024660805014995\n",
      "62 Train Loss 137721.56 Test MSE 299181.81811308296 Test RE 0.24448624038141295\n",
      "63 Train Loss 135330.56 Test MSE 273273.09250858624 Test RE 0.23366047726166103\n",
      "64 Train Loss 134883.39 Test MSE 256144.8108306487 Test RE 0.22621927420608415\n",
      "65 Train Loss 134722.31 Test MSE 244709.27966696606 Test RE 0.22111186258311924\n",
      "66 Train Loss 134550.05 Test MSE 237447.93258207833 Test RE 0.21780659212594\n",
      "67 Train Loss 134028.05 Test MSE 210020.67255353404 Test RE 0.20484145222294642\n",
      "68 Train Loss 133187.97 Test MSE 189520.58040078866 Test RE 0.1945875331995361\n",
      "69 Train Loss 132792.27 Test MSE 189883.59224790524 Test RE 0.19477380264549712\n",
      "70 Train Loss 132482.66 Test MSE 192208.77265981646 Test RE 0.1959627053420383\n",
      "71 Train Loss 132333.3 Test MSE 201799.38786663758 Test RE 0.20079215736131892\n",
      "72 Train Loss 132305.89 Test MSE 204870.71527823864 Test RE 0.20231438609422844\n",
      "73 Train Loss 132276.2 Test MSE 200915.3732569184 Test RE 0.2003518735111603\n",
      "74 Train Loss 132242.16 Test MSE 195341.11643574754 Test RE 0.19755301239028686\n",
      "75 Train Loss 132196.53 Test MSE 189163.4407262009 Test RE 0.1944041027279378\n",
      "76 Train Loss 132166.03 Test MSE 189353.48352066107 Test RE 0.19450173212250393\n",
      "77 Train Loss 132142.84 Test MSE 188144.35678753967 Test RE 0.19387973701248887\n",
      "78 Train Loss 132108.61 Test MSE 185849.6735329893 Test RE 0.19269379274309925\n",
      "79 Train Loss 132062.78 Test MSE 186926.93759371844 Test RE 0.19325145354968495\n",
      "80 Train Loss 132016.23 Test MSE 186598.4901435267 Test RE 0.19308159880744158\n",
      "81 Train Loss 131978.56 Test MSE 184812.1427407657 Test RE 0.19215517045416586\n",
      "82 Train Loss 131809.78 Test MSE 174312.53189288624 Test RE 0.1866169680440119\n",
      "83 Train Loss 131423.38 Test MSE 154528.0714659345 Test RE 0.17570758754114527\n",
      "84 Train Loss 131307.98 Test MSE 154703.43057828062 Test RE 0.17580725613168524\n",
      "85 Train Loss 131257.28 Test MSE 156209.6957601932 Test RE 0.1766610538863816\n",
      "86 Train Loss 131119.8 Test MSE 156385.2638425179 Test RE 0.17676030295112136\n",
      "87 Train Loss 131000.445 Test MSE 150422.0845158895 Test RE 0.17335749587158764\n",
      "88 Train Loss 130982.25 Test MSE 148484.10043319274 Test RE 0.17223713776001112\n",
      "89 Train Loss 130974.93 Test MSE 147771.7006972609 Test RE 0.17182345972873717\n",
      "90 Train Loss 130968.14 Test MSE 146153.50487583896 Test RE 0.1708800808874975\n",
      "91 Train Loss 130962.945 Test MSE 144896.1402188432 Test RE 0.17014344893910574\n",
      "92 Train Loss 130953.81 Test MSE 144393.08099743805 Test RE 0.16984783495262396\n",
      "93 Train Loss 130939.555 Test MSE 144033.36977192858 Test RE 0.16963614104555366\n",
      "94 Train Loss 130881.016 Test MSE 140954.0192984735 Test RE 0.1678129823905016\n",
      "95 Train Loss 130759.445 Test MSE 138751.92067939808 Test RE 0.16649696656865512\n",
      "96 Train Loss 130649.39 Test MSE 145743.53408605632 Test RE 0.1706402473005915\n",
      "97 Train Loss 130573.93 Test MSE 150204.6123027274 Test RE 0.17323213504243912\n",
      "98 Train Loss 130342.16 Test MSE 143789.16338276988 Test RE 0.16949227228851346\n",
      "99 Train Loss 129788.85 Test MSE 116670.56582659538 Test RE 0.15267484076307114\n",
      "100 Train Loss 129528.58 Test MSE 106166.46391325157 Test RE 0.14563994287947232\n",
      "101 Train Loss 129247.04 Test MSE 101236.69027960488 Test RE 0.14221840145879028\n",
      "102 Train Loss 129027.016 Test MSE 94950.85467136318 Test RE 0.1377324468136166\n",
      "103 Train Loss 128875.164 Test MSE 85525.10331304651 Test RE 0.13071746812558818\n",
      "104 Train Loss 128826.13 Test MSE 82545.41385660488 Test RE 0.12842018709360242\n",
      "105 Train Loss 128762.82 Test MSE 82900.25536786346 Test RE 0.12869591377520714\n",
      "106 Train Loss 128703.02 Test MSE 85382.74115207365 Test RE 0.13060862890155744\n",
      "107 Train Loss 128624.83 Test MSE 86797.74487646106 Test RE 0.13168643617632517\n",
      "108 Train Loss 128463.445 Test MSE 77076.40506806523 Test RE 0.12409307570456479\n",
      "109 Train Loss 128305.08 Test MSE 65398.928921009385 Test RE 0.11430681962736305\n",
      "110 Train Loss 128150.195 Test MSE 62994.99446168883 Test RE 0.11218630512595874\n",
      "111 Train Loss 128112.29 Test MSE 64448.07937855604 Test RE 0.11347281095836323\n",
      "112 Train Loss 128045.56 Test MSE 65193.53219907219 Test RE 0.11412717823400143\n",
      "113 Train Loss 127949.52 Test MSE 64481.30471149139 Test RE 0.11350205687359856\n",
      "114 Train Loss 127883.164 Test MSE 61940.219730697536 Test RE 0.11124312860858993\n",
      "115 Train Loss 127763.484 Test MSE 56325.70315039382 Test RE 0.10608161788094668\n",
      "116 Train Loss 127620.5 Test MSE 52932.560108221856 Test RE 0.10283673351131567\n",
      "117 Train Loss 127549.93 Test MSE 54421.93109188481 Test RE 0.10427346316238857\n",
      "118 Train Loss 127531.9 Test MSE 54756.900861877286 Test RE 0.10459387513081465\n",
      "119 Train Loss 127519.305 Test MSE 55075.43242915167 Test RE 0.10489765546529076\n",
      "120 Train Loss 127497.48 Test MSE 54089.15612802994 Test RE 0.1039541727161217\n",
      "121 Train Loss 127482.02 Test MSE 53069.16554417143 Test RE 0.10296934569602782\n",
      "122 Train Loss 127472.09 Test MSE 52298.79814061026 Test RE 0.10221924713477265\n",
      "123 Train Loss 127461.305 Test MSE 53353.41553688331 Test RE 0.10324474052507956\n",
      "124 Train Loss 127448.84 Test MSE 54502.00769846722 Test RE 0.10435014912034837\n",
      "125 Train Loss 127443.51 Test MSE 56121.922017261444 Test RE 0.10588954730749164\n",
      "126 Train Loss 127411.01 Test MSE 59142.998067113316 Test RE 0.10870223951048763\n",
      "127 Train Loss 127314.42 Test MSE 56055.53914912864 Test RE 0.10582690394602941\n",
      "128 Train Loss 127041.37 Test MSE 55254.957835148874 Test RE 0.1050684800249594\n",
      "129 Train Loss 126893.57 Test MSE 56723.0291043449 Test RE 0.10645511442095347\n",
      "130 Train Loss 126779.47 Test MSE 54656.67982606745 Test RE 0.10449811270413903\n",
      "131 Train Loss 126717.13 Test MSE 49748.55766035989 Test RE 0.09969584773736757\n",
      "132 Train Loss 126632.91 Test MSE 47326.790267991324 Test RE 0.09723896986130522\n",
      "133 Train Loss 126593.2 Test MSE 47945.18674088376 Test RE 0.09787219555460774\n",
      "134 Train Loss 126556.555 Test MSE 46366.26127870723 Test RE 0.09624714653909922\n",
      "135 Train Loss 126477.03 Test MSE 41046.598438047935 Test RE 0.09055770547925557\n",
      "136 Train Loss 126388.31 Test MSE 35018.97008196462 Test RE 0.08364471548472383\n",
      "137 Train Loss 126289.41 Test MSE 28082.579632102144 Test RE 0.07490405395094316\n",
      "138 Train Loss 126136.83 Test MSE 21823.748246205803 Test RE 0.06603155050733893\n",
      "139 Train Loss 126040.664 Test MSE 19137.23735624164 Test RE 0.0618338723901511\n",
      "140 Train Loss 125790.39 Test MSE 14547.552652022872 Test RE 0.053911546796124546\n",
      "141 Train Loss 125554.31 Test MSE 14123.936020979654 Test RE 0.05312081071143126\n",
      "142 Train Loss 125462.086 Test MSE 17874.493444934575 Test RE 0.05975905141955861\n",
      "143 Train Loss 125374.086 Test MSE 19428.23580641074 Test RE 0.0623022177919106\n",
      "144 Train Loss 125096.08 Test MSE 12560.705820428571 Test RE 0.05009493827204841\n",
      "145 Train Loss 124861.17 Test MSE 7699.117044340667 Test RE 0.039219972483497186\n",
      "146 Train Loss 124711.13 Test MSE 5474.114504905783 Test RE 0.03307072854014407\n",
      "147 Train Loss 124678.66 Test MSE 4372.419885177441 Test RE 0.02955614265371921\n",
      "148 Train Loss 124637.56 Test MSE 2844.8630932558945 Test RE 0.023840618009682388\n",
      "149 Train Loss 124598.9 Test MSE 2114.8504560832557 Test RE 0.02055543421442178\n",
      "150 Train Loss 124567.45 Test MSE 2282.9571917609596 Test RE 0.021356776740973957\n",
      "151 Train Loss 124550.82 Test MSE 2434.415309130709 Test RE 0.02205383692456004\n",
      "152 Train Loss 124536.31 Test MSE 2307.8698601125316 Test RE 0.02147298799963719\n",
      "153 Train Loss 124517.08 Test MSE 1880.2670923358426 Test RE 0.019381911057637303\n",
      "154 Train Loss 124506.67 Test MSE 1887.2147777846083 Test RE 0.0194176866285279\n",
      "155 Train Loss 124503.22 Test MSE 1953.312220079615 Test RE 0.019754800909450518\n",
      "156 Train Loss 124501.664 Test MSE 1960.6512397119045 Test RE 0.019791877661509905\n",
      "157 Train Loss 124500.69 Test MSE 1955.1028689801865 Test RE 0.01976385368883927\n",
      "158 Train Loss 124499.45 Test MSE 1930.623685160671 Test RE 0.019639735681008835\n",
      "159 Train Loss 124498.35 Test MSE 1926.1249856011175 Test RE 0.019616840281782528\n",
      "160 Train Loss 124496.71 Test MSE 1927.6966748993248 Test RE 0.01962484217449553\n",
      "161 Train Loss 124494.516 Test MSE 1959.2929235081187 Test RE 0.019785020683235146\n",
      "162 Train Loss 124491.26 Test MSE 2035.4604701149485 Test RE 0.02016592556972093\n",
      "163 Train Loss 124487.96 Test MSE 2034.9656521561615 Test RE 0.020163474264774033\n",
      "164 Train Loss 124487.09 Test MSE 1995.0763348470368 Test RE 0.019964874393501\n",
      "165 Train Loss 124485.734 Test MSE 1942.3844914123672 Test RE 0.019699464677045846\n",
      "166 Train Loss 124483.62 Test MSE 1936.9832656908557 Test RE 0.019672056270829862\n",
      "167 Train Loss 124483.17 Test MSE 1956.1484454218414 Test RE 0.019769137773388807\n",
      "168 Train Loss 124483.03 Test MSE 1963.6726780081055 Test RE 0.019807121809767472\n",
      "169 Train Loss 124483.03 Test MSE 1963.6726780081055 Test RE 0.019807121809767472\n",
      "170 Train Loss 124483.03 Test MSE 1963.6726780081055 Test RE 0.019807121809767472\n",
      "171 Train Loss 124483.03 Test MSE 1963.6726780081055 Test RE 0.019807121809767472\n",
      "172 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "173 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "174 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "175 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "176 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "177 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "178 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "179 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "180 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "181 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "182 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "183 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "184 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "185 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "186 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "187 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "188 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "189 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "190 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "191 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "192 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "193 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "194 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "195 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "196 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "197 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "198 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "199 Train Loss 124483.03 Test MSE 1963.6727188546606 Test RE 0.01980712201577245\n",
      "Training time: 61.47\n",
      "Training time: 61.47\n",
      "1D_FODE_rowdyhigh\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 457136.0 Test MSE 5012781.391259031 Test RE 1.0007513999656685\n",
      "1 Train Loss 452809.8 Test MSE 5033510.555715716 Test RE 1.0028184498454749\n",
      "2 Train Loss 443900.0 Test MSE 5006380.072994626 Test RE 1.0001122164289529\n",
      "3 Train Loss 426827.7 Test MSE 5036775.327899046 Test RE 1.003143614860522\n",
      "4 Train Loss 411565.47 Test MSE 5063129.183147555 Test RE 1.005764558715564\n",
      "5 Train Loss 406938.78 Test MSE 4979400.026702107 Test RE 0.9974137071634606\n",
      "6 Train Loss 400533.84 Test MSE 4994369.944823067 Test RE 0.9989118792432089\n",
      "7 Train Loss 364766.3 Test MSE 5031995.449051453 Test RE 1.0026675123187307\n",
      "8 Train Loss 353746.16 Test MSE 4926452.754650869 Test RE 0.9920966536481508\n",
      "9 Train Loss 348039.0 Test MSE 5005098.332889976 Test RE 0.9999841832017341\n",
      "10 Train Loss 342302.8 Test MSE 4797349.970300891 Test RE 0.97901089412148\n",
      "11 Train Loss 339029.34 Test MSE 4888619.140421173 Test RE 0.9882798157030207\n",
      "12 Train Loss 328109.25 Test MSE 4930085.218702182 Test RE 0.9924623418580042\n",
      "13 Train Loss 320373.56 Test MSE 5170388.192765669 Test RE 1.0163619533348225\n",
      "14 Train Loss 319205.38 Test MSE 5163585.524124927 Test RE 1.015693120647403\n",
      "15 Train Loss 317658.22 Test MSE 5193140.874203719 Test RE 1.0185957870366562\n",
      "16 Train Loss 308590.88 Test MSE 4809078.585993347 Test RE 0.9802069120346324\n",
      "17 Train Loss 294870.7 Test MSE 5106859.350385719 Test RE 1.0100986069080715\n",
      "18 Train Loss 290689.53 Test MSE 4939965.62236461 Test RE 0.9934563429770766\n",
      "19 Train Loss 290207.2 Test MSE 4921639.755810996 Test RE 0.9916119106596668\n",
      "20 Train Loss 289650.88 Test MSE 4888953.658620079 Test RE 0.9883136281068032\n",
      "21 Train Loss 289073.38 Test MSE 4914275.442875087 Test RE 0.9908697520956\n",
      "22 Train Loss 286038.88 Test MSE 4909475.577717658 Test RE 0.9903857333272053\n",
      "23 Train Loss 283681.8 Test MSE 4871112.508188866 Test RE 0.9865086643685653\n",
      "24 Train Loss 282957.6 Test MSE 4846174.202649678 Test RE 0.9839801430684234\n",
      "25 Train Loss 277938.88 Test MSE 4756273.402102025 Test RE 0.9748105688438814\n",
      "26 Train Loss 276473.12 Test MSE 4830140.517333358 Test RE 0.9823510333369032\n",
      "27 Train Loss 276309.66 Test MSE 4852885.235089237 Test RE 0.9846612203273948\n",
      "28 Train Loss 276255.9 Test MSE 4854940.9576162305 Test RE 0.9848697535847741\n",
      "29 Train Loss 275417.8 Test MSE 4825112.628509295 Test RE 0.9818396157317348\n",
      "30 Train Loss 272385.38 Test MSE 4638992.249236815 Test RE 0.9627170139616458\n",
      "31 Train Loss 269486.22 Test MSE 4597470.534719041 Test RE 0.9583988874835757\n",
      "32 Train Loss 265201.84 Test MSE 4517050.770344884 Test RE 0.9499796663557206\n",
      "33 Train Loss 260609.42 Test MSE 4468548.032502386 Test RE 0.9448656024629087\n",
      "34 Train Loss 259386.31 Test MSE 4405811.239734428 Test RE 0.9382093720296889\n",
      "35 Train Loss 257009.05 Test MSE 4364199.724093026 Test RE 0.9337683133200095\n",
      "36 Train Loss 256615.33 Test MSE 4328835.951274249 Test RE 0.9299773848911501\n",
      "37 Train Loss 256490.52 Test MSE 4341779.168495758 Test RE 0.931366663127236\n",
      "38 Train Loss 256213.6 Test MSE 4365031.278686238 Test RE 0.933857269187632\n",
      "39 Train Loss 254903.4 Test MSE 4358525.857195757 Test RE 0.9331611229326903\n",
      "40 Train Loss 253522.81 Test MSE 4352944.055480304 Test RE 0.9325633991552323\n",
      "41 Train Loss 253385.53 Test MSE 4339579.049622879 Test RE 0.9311306565331919\n",
      "42 Train Loss 250901.11 Test MSE 4290402.446417465 Test RE 0.9258397854025362\n",
      "43 Train Loss 245665.39 Test MSE 4176758.8277361197 Test RE 0.9134957333582219\n",
      "44 Train Loss 245474.6 Test MSE 4184293.07081528 Test RE 0.9143192664180994\n",
      "45 Train Loss 244062.88 Test MSE 4166575.5810765913 Test RE 0.9123814687289765\n",
      "46 Train Loss 243524.84 Test MSE 4109745.908753696 Test RE 0.9061379292634855\n",
      "47 Train Loss 243289.23 Test MSE 4080325.6296584806 Test RE 0.9028887365767578\n",
      "48 Train Loss 243241.55 Test MSE 4086429.900960919 Test RE 0.9035638564711751\n",
      "49 Train Loss 243232.0 Test MSE 4087204.1110903807 Test RE 0.9036494464820759\n",
      "50 Train Loss 243089.83 Test MSE 4083578.729216535 Test RE 0.9032485855227553\n",
      "51 Train Loss 241537.56 Test MSE 4015835.8820275697 Test RE 0.8957252184192158\n",
      "52 Train Loss 235378.42 Test MSE 3814702.118646367 Test RE 0.8730058198773898\n",
      "53 Train Loss 223097.55 Test MSE 3471478.3674940905 Test RE 0.8328064024847165\n",
      "54 Train Loss 219816.78 Test MSE 3386663.846189063 Test RE 0.8225700059528084\n",
      "55 Train Loss 218111.06 Test MSE 3357599.363701828 Test RE 0.8190327362617865\n",
      "56 Train Loss 216674.64 Test MSE 3346120.938369339 Test RE 0.817631548435539\n",
      "57 Train Loss 216594.03 Test MSE 3339784.901502673 Test RE 0.8168570697996977\n",
      "58 Train Loss 216548.27 Test MSE 3334860.5560860825 Test RE 0.8162546402542182\n",
      "59 Train Loss 216491.64 Test MSE 3332054.1296229013 Test RE 0.8159111115323908\n",
      "60 Train Loss 216326.9 Test MSE 3334089.7167616272 Test RE 0.8161602978479294\n",
      "61 Train Loss 215597.12 Test MSE 3304702.830377456 Test RE 0.8125554917042201\n",
      "62 Train Loss 208309.61 Test MSE 3119904.1852479437 Test RE 0.7895096669791649\n",
      "63 Train Loss 202858.97 Test MSE 2867742.7334474376 Test RE 0.7569320903154957\n",
      "64 Train Loss 201865.9 Test MSE 2866458.7810303867 Test RE 0.7567626236507712\n",
      "65 Train Loss 200059.55 Test MSE 2801399.774670866 Test RE 0.7481253455501055\n",
      "66 Train Loss 198505.89 Test MSE 2812455.5425634147 Test RE 0.7496001360827469\n",
      "67 Train Loss 197852.94 Test MSE 2803458.1716857054 Test RE 0.7484001467796277\n",
      "68 Train Loss 197797.7 Test MSE 2790789.9178824364 Test RE 0.7467072986470152\n",
      "69 Train Loss 197788.67 Test MSE 2785002.8494060715 Test RE 0.7459326991806468\n",
      "70 Train Loss 197481.27 Test MSE 2727640.2031567637 Test RE 0.7382107498813967\n",
      "71 Train Loss 196872.2 Test MSE 2675228.536565182 Test RE 0.7310839806568088\n",
      "72 Train Loss 196115.48 Test MSE 2612195.0395713383 Test RE 0.7224197722211478\n",
      "73 Train Loss 193843.83 Test MSE 2535120.7925165975 Test RE 0.7116822795374488\n",
      "74 Train Loss 189983.19 Test MSE 2333968.267829798 Test RE 0.6828641250753147\n",
      "75 Train Loss 186358.23 Test MSE 2338543.063700646 Test RE 0.6835330361967508\n",
      "76 Train Loss 186168.53 Test MSE 2327834.56010598 Test RE 0.6819662455940964\n",
      "77 Train Loss 186125.11 Test MSE 2327245.1612584307 Test RE 0.6818799045000188\n",
      "78 Train Loss 185857.66 Test MSE 2314347.469305877 Test RE 0.6799877755346591\n",
      "79 Train Loss 182566.98 Test MSE 2237825.0270072697 Test RE 0.6686515980950685\n",
      "80 Train Loss 179784.52 Test MSE 2175390.7480718372 Test RE 0.6592580814116574\n",
      "81 Train Loss 176660.53 Test MSE 2009064.7615568375 Test RE 0.6335542255244128\n",
      "82 Train Loss 175286.56 Test MSE 2013790.2516688053 Test RE 0.6342988744533942\n",
      "83 Train Loss 174913.92 Test MSE 2004537.8984241288 Test RE 0.6328400547546925\n",
      "84 Train Loss 174825.02 Test MSE 1996121.5351076878 Test RE 0.6315101187316547\n",
      "85 Train Loss 174689.6 Test MSE 1995682.420699907 Test RE 0.6314406539121893\n",
      "86 Train Loss 174550.45 Test MSE 1996815.8026085796 Test RE 0.6316199313928186\n",
      "87 Train Loss 174410.58 Test MSE 1989054.8588730854 Test RE 0.630391290500804\n",
      "88 Train Loss 174246.62 Test MSE 1986854.0929293667 Test RE 0.6300424495319237\n",
      "89 Train Loss 173923.73 Test MSE 1998831.7661176086 Test RE 0.6319386892648607\n",
      "90 Train Loss 173453.92 Test MSE 1992330.8122899483 Test RE 0.630910200997225\n",
      "91 Train Loss 173341.22 Test MSE 1984516.303093774 Test RE 0.6296716773748233\n",
      "92 Train Loss 173333.17 Test MSE 1983003.4494956231 Test RE 0.6294316232419133\n",
      "93 Train Loss 173332.44 Test MSE 1982571.1763943085 Test RE 0.6293630148919144\n",
      "94 Train Loss 173331.92 Test MSE 1982260.0818000953 Test RE 0.6293136347951732\n",
      "95 Train Loss 173331.92 Test MSE 1982260.0818000953 Test RE 0.6293136347951732\n",
      "96 Train Loss 173331.92 Test MSE 1982260.0818000953 Test RE 0.6293136347951732\n",
      "97 Train Loss 173330.86 Test MSE 1981352.1594133773 Test RE 0.6291694979630377\n",
      "98 Train Loss 173324.64 Test MSE 1978879.4291292282 Test RE 0.6287767731849372\n",
      "99 Train Loss 173282.23 Test MSE 1968292.737578981 Test RE 0.6270925895567536\n",
      "100 Train Loss 172626.66 Test MSE 1929247.717809649 Test RE 0.6208416168120992\n",
      "101 Train Loss 172232.6 Test MSE 1922148.0900862804 Test RE 0.619698215963408\n",
      "102 Train Loss 171657.42 Test MSE 1914653.4355860078 Test RE 0.618488902235875\n",
      "103 Train Loss 169336.97 Test MSE 1884509.9241609315 Test RE 0.613600970845175\n",
      "104 Train Loss 167912.33 Test MSE 1880910.4425189658 Test RE 0.613014690810733\n",
      "105 Train Loss 167792.62 Test MSE 1873291.9508239948 Test RE 0.6117719452892797\n",
      "106 Train Loss 167755.44 Test MSE 1870375.449038604 Test RE 0.6112955302347024\n",
      "107 Train Loss 167637.97 Test MSE 1871561.1599864427 Test RE 0.6114892627192069\n",
      "108 Train Loss 167456.05 Test MSE 1860937.9909812675 Test RE 0.6097513558590613\n",
      "109 Train Loss 167050.47 Test MSE 1833002.8613665975 Test RE 0.6051574652153819\n",
      "110 Train Loss 164564.08 Test MSE 1785941.4925636502 Test RE 0.5973384040797652\n",
      "111 Train Loss 161110.88 Test MSE 1695176.0822419133 Test RE 0.5819614693587363\n",
      "112 Train Loss 160626.06 Test MSE 1690431.757279738 Test RE 0.5811465248552341\n",
      "113 Train Loss 160591.12 Test MSE 1684112.448925614 Test RE 0.5800592633729081\n",
      "114 Train Loss 160566.89 Test MSE 1681367.787078265 Test RE 0.5795863983565926\n",
      "115 Train Loss 160392.44 Test MSE 1666409.3875606721 Test RE 0.5770024741762934\n",
      "116 Train Loss 160349.53 Test MSE 1662122.9478043797 Test RE 0.5762598958829328\n",
      "117 Train Loss 160308.0 Test MSE 1659114.958393888 Test RE 0.5757382230983773\n",
      "118 Train Loss 160253.53 Test MSE 1659692.6304727478 Test RE 0.5758384448911432\n",
      "119 Train Loss 160215.64 Test MSE 1657043.4225904462 Test RE 0.5753786835582289\n",
      "120 Train Loss 159495.77 Test MSE 1631434.3922355645 Test RE 0.5709152323171118\n",
      "121 Train Loss 154776.22 Test MSE 1551392.1281672963 Test RE 0.5567338342692073\n",
      "122 Train Loss 153208.55 Test MSE 1477688.4899573966 Test RE 0.5433482453439662\n",
      "123 Train Loss 153126.61 Test MSE 1478462.7542855747 Test RE 0.5434905757720421\n",
      "124 Train Loss 153094.81 Test MSE 1485408.0908507872 Test RE 0.5447656509245388\n",
      "125 Train Loss 153031.66 Test MSE 1494802.3854436504 Test RE 0.5464855900329019\n",
      "126 Train Loss 152379.81 Test MSE 1459542.941467581 Test RE 0.5400018679752887\n",
      "127 Train Loss 150372.6 Test MSE 1357976.570596422 Test RE 0.5208743388121773\n",
      "128 Train Loss 149161.3 Test MSE 1349752.4450506617 Test RE 0.5192946939522565\n",
      "129 Train Loss 146989.39 Test MSE 1207230.1027675564 Test RE 0.4911134766333696\n",
      "130 Train Loss 144555.14 Test MSE 1161953.9307175472 Test RE 0.48181606717819514\n",
      "131 Train Loss 144423.48 Test MSE 1161438.1820528288 Test RE 0.481709125083763\n",
      "132 Train Loss 144379.67 Test MSE 1171587.6487880251 Test RE 0.4838093040476389\n",
      "133 Train Loss 144302.52 Test MSE 1174546.5732670762 Test RE 0.4844198654774464\n",
      "134 Train Loss 144163.12 Test MSE 1163632.9946428828 Test RE 0.4821640620118748\n",
      "135 Train Loss 143406.9 Test MSE 1126142.6156257617 Test RE 0.4743331968029713\n",
      "136 Train Loss 141610.67 Test MSE 1069887.4365417252 Test RE 0.4623340371820726\n",
      "137 Train Loss 139930.66 Test MSE 1013346.1131763804 Test RE 0.4499515235355549\n",
      "138 Train Loss 138591.55 Test MSE 977985.1648253469 Test RE 0.4420312333769355\n",
      "139 Train Loss 138006.66 Test MSE 997065.0107652645 Test RE 0.446322274625699\n",
      "140 Train Loss 137708.33 Test MSE 980787.9774140576 Test RE 0.44266418996734036\n",
      "141 Train Loss 137689.97 Test MSE 981275.4362343869 Test RE 0.44277417997758806\n",
      "142 Train Loss 137671.66 Test MSE 982880.1947815237 Test RE 0.44313608416765954\n",
      "143 Train Loss 137524.55 Test MSE 983630.7950208115 Test RE 0.44330525767113416\n",
      "144 Train Loss 136683.36 Test MSE 968385.9247464649 Test RE 0.4398565442790396\n",
      "145 Train Loss 135380.31 Test MSE 954631.5019728113 Test RE 0.43672163222036015\n",
      "146 Train Loss 133699.72 Test MSE 892613.4476808668 Test RE 0.4222975252392111\n",
      "147 Train Loss 131281.86 Test MSE 726231.8781266616 Test RE 0.3809118450029673\n",
      "148 Train Loss 129572.42 Test MSE 699488.8595165681 Test RE 0.37383264598012705\n",
      "149 Train Loss 129454.07 Test MSE 700249.7907698002 Test RE 0.3740359255749765\n",
      "150 Train Loss 129419.83 Test MSE 701589.5505278225 Test RE 0.37439356853639016\n",
      "151 Train Loss 129403.984 Test MSE 699794.5925187641 Test RE 0.3739143345513871\n",
      "152 Train Loss 129399.52 Test MSE 699541.9669785914 Test RE 0.3738468370040168\n",
      "153 Train Loss 129397.41 Test MSE 699854.5277012858 Test RE 0.373930346495677\n",
      "154 Train Loss 129395.46 Test MSE 700406.5330380216 Test RE 0.3740777848941544\n",
      "155 Train Loss 129393.13 Test MSE 700521.310963191 Test RE 0.3741084343178179\n",
      "156 Train Loss 129383.24 Test MSE 699688.995653408 Test RE 0.37388612222187967\n",
      "157 Train Loss 129278.016 Test MSE 697865.6459274006 Test RE 0.37339864144353774\n",
      "158 Train Loss 128866.36 Test MSE 691874.4062364761 Test RE 0.37179235593066945\n",
      "159 Train Loss 126917.61 Test MSE 611437.134453208 Test RE 0.34951251348640383\n",
      "160 Train Loss 124847.02 Test MSE 546241.648780667 Test RE 0.3303537406895119\n",
      "161 Train Loss 124755.734 Test MSE 540745.7972076786 Test RE 0.32868766033050406\n",
      "162 Train Loss 124635.87 Test MSE 528628.036389616 Test RE 0.32498395525747525\n",
      "163 Train Loss 124618.55 Test MSE 526196.7481716645 Test RE 0.32423575406346083\n",
      "164 Train Loss 124607.85 Test MSE 525031.5246681896 Test RE 0.32387655713669455\n",
      "165 Train Loss 124598.68 Test MSE 522998.4614258924 Test RE 0.32324888035486055\n",
      "166 Train Loss 124564.375 Test MSE 515355.28619213693 Test RE 0.32087818408367824\n",
      "167 Train Loss 124498.75 Test MSE 511885.06822030304 Test RE 0.3197960198801896\n",
      "168 Train Loss 124440.05 Test MSE 510359.2999763093 Test RE 0.31931905856624926\n",
      "169 Train Loss 124208.42 Test MSE 506822.457053369 Test RE 0.3182106778190793\n",
      "170 Train Loss 123561.77 Test MSE 485501.0226637409 Test RE 0.31144538378031905\n",
      "171 Train Loss 122388.125 Test MSE 448652.8314420378 Test RE 0.2993932675292394\n",
      "172 Train Loss 121969.03 Test MSE 448325.6789983078 Test RE 0.2992840905729674\n",
      "173 Train Loss 121830.66 Test MSE 442611.44632777845 Test RE 0.2973706787607038\n",
      "174 Train Loss 121753.375 Test MSE 439528.2357762731 Test RE 0.2963331336380607\n",
      "175 Train Loss 121721.914 Test MSE 438564.2229888093 Test RE 0.29600798303610837\n",
      "176 Train Loss 121709.695 Test MSE 437489.3750077983 Test RE 0.2956450273422769\n",
      "177 Train Loss 121703.12 Test MSE 436487.95616538665 Test RE 0.2953064658411044\n",
      "178 Train Loss 121696.086 Test MSE 436004.1809149272 Test RE 0.2951427710997424\n",
      "179 Train Loss 121688.57 Test MSE 435683.65630982 Test RE 0.29503426535957356\n",
      "180 Train Loss 121671.23 Test MSE 435869.6312999712 Test RE 0.29509722748786776\n",
      "181 Train Loss 121625.52 Test MSE 435213.26577716786 Test RE 0.2948749538928195\n",
      "182 Train Loss 121587.23 Test MSE 432832.5355330038 Test RE 0.2940673263843975\n",
      "183 Train Loss 121467.93 Test MSE 424883.88878020877 Test RE 0.29135465102901636\n",
      "184 Train Loss 121333.74 Test MSE 415383.5694763672 Test RE 0.28807892029393223\n",
      "185 Train Loss 121165.71 Test MSE 391666.13619092334 Test RE 0.27973372947871583\n",
      "186 Train Loss 121014.84 Test MSE 376024.06568096706 Test RE 0.2740909171377665\n",
      "187 Train Loss 119949.9 Test MSE 280646.7607817304 Test RE 0.23679189910270235\n",
      "188 Train Loss 119303.086 Test MSE 277844.4496406556 Test RE 0.23560672712415878\n",
      "189 Train Loss 118924.17 Test MSE 270887.30115868704 Test RE 0.23263826316760458\n",
      "190 Train Loss 118708.93 Test MSE 271641.925692082 Test RE 0.2329620739317853\n",
      "191 Train Loss 118484.89 Test MSE 264757.90082892077 Test RE 0.2299912365255083\n",
      "192 Train Loss 118228.44 Test MSE 255618.66238057375 Test RE 0.22598681564991557\n",
      "193 Train Loss 118004.48 Test MSE 245861.94684439577 Test RE 0.22163200828750637\n",
      "194 Train Loss 117853.45 Test MSE 225505.2586032253 Test RE 0.21225853407190184\n",
      "195 Train Loss 117734.734 Test MSE 213991.2239673435 Test RE 0.20676870370993503\n",
      "196 Train Loss 117635.92 Test MSE 214366.8045391325 Test RE 0.20695007624816172\n",
      "197 Train Loss 117574.02 Test MSE 211924.64356028207 Test RE 0.20576786636651112\n",
      "198 Train Loss 117506.664 Test MSE 199870.83784921395 Test RE 0.19983039192819238\n",
      "199 Train Loss 117470.51 Test MSE 187329.03155761154 Test RE 0.19345919113263413\n",
      "Training time: 70.78\n",
      "Training time: 70.78\n",
      "1D_FODE_rowdyhigh\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 457638.0 Test MSE 5013030.687880887 Test RE 1.0007762844381887\n",
      "1 Train Loss 454181.97 Test MSE 5006302.36852316 Test RE 1.000104454983397\n",
      "2 Train Loss 443586.62 Test MSE 5003124.685059677 Test RE 0.9997870031381849\n",
      "3 Train Loss 407622.28 Test MSE 4992249.899413057 Test RE 0.9986998441563152\n",
      "4 Train Loss 379822.38 Test MSE 4993267.61653072 Test RE 0.9988016361491241\n",
      "5 Train Loss 355400.4 Test MSE 4991157.148608495 Test RE 0.9985905357475916\n",
      "6 Train Loss 334591.72 Test MSE 4979059.607673898 Test RE 0.9973796122517771\n",
      "7 Train Loss 318678.88 Test MSE 4981513.554829511 Test RE 0.9976253630122452\n",
      "8 Train Loss 308192.34 Test MSE 4970417.183171611 Test RE 0.9965136332936378\n",
      "9 Train Loss 299157.34 Test MSE 4977376.002401976 Test RE 0.9972109724202552\n",
      "10 Train Loss 293101.66 Test MSE 4972553.4654525025 Test RE 0.9967277607647573\n",
      "11 Train Loss 289323.12 Test MSE 4966252.187419017 Test RE 0.9960960280161082\n",
      "12 Train Loss 286358.28 Test MSE 4968757.444104888 Test RE 0.9963472397452486\n",
      "13 Train Loss 281881.94 Test MSE 4967602.761220626 Test RE 0.9962314631185983\n",
      "14 Train Loss 277122.56 Test MSE 4967983.002214503 Test RE 0.9962695902405992\n",
      "15 Train Loss 271399.44 Test MSE 4961781.074258896 Test RE 0.9956475347913136\n",
      "16 Train Loss 267004.0 Test MSE 4955478.631300168 Test RE 0.9950149992567947\n",
      "17 Train Loss 261614.2 Test MSE 4936404.352062343 Test RE 0.9930981821405334\n",
      "18 Train Loss 256602.44 Test MSE 4925140.315119791 Test RE 0.9919644942970817\n",
      "19 Train Loss 251749.78 Test MSE 4919675.164710963 Test RE 0.991413978011322\n",
      "20 Train Loss 248194.25 Test MSE 4908691.52108842 Test RE 0.9903066465191612\n",
      "21 Train Loss 244014.58 Test MSE 4901056.721356595 Test RE 0.9895362034060915\n",
      "22 Train Loss 240107.44 Test MSE 4882031.042442197 Test RE 0.98761366856305\n",
      "23 Train Loss 236384.31 Test MSE 4868897.930667708 Test RE 0.9862843882637222\n",
      "24 Train Loss 232413.92 Test MSE 4861529.169752807 Test RE 0.9855377669714674\n",
      "25 Train Loss 228189.62 Test MSE 4856804.490249206 Test RE 0.9850587528800048\n",
      "26 Train Loss 224845.67 Test MSE 4856370.310030664 Test RE 0.9850147216054882\n",
      "27 Train Loss 222141.72 Test MSE 4854257.71221376 Test RE 0.9848004498163435\n",
      "28 Train Loss 218094.03 Test MSE 4847606.906459486 Test RE 0.9841255823224427\n",
      "29 Train Loss 215318.17 Test MSE 4845606.117936092 Test RE 0.9839224686600315\n",
      "30 Train Loss 213007.78 Test MSE 4845282.913977826 Test RE 0.9838896540923857\n",
      "31 Train Loss 208738.17 Test MSE 4837623.443625531 Test RE 0.9831116753447776\n",
      "32 Train Loss 206197.16 Test MSE 4830694.528007159 Test RE 0.9824073688980667\n",
      "33 Train Loss 203703.08 Test MSE 4820926.896372535 Test RE 0.9814136557988064\n",
      "34 Train Loss 199155.25 Test MSE 4812652.727545585 Test RE 0.98057109277067\n",
      "35 Train Loss 196015.69 Test MSE 4800018.542103246 Test RE 0.9792831483522474\n",
      "36 Train Loss 192496.84 Test MSE 4797237.140079195 Test RE 0.9789993812376573\n",
      "37 Train Loss 189874.27 Test MSE 4786825.197436289 Test RE 0.9779363920624095\n",
      "38 Train Loss 186130.98 Test MSE 4773555.448810968 Test RE 0.9765799631622861\n",
      "39 Train Loss 183739.92 Test MSE 4754666.769407323 Test RE 0.9746459131691126\n",
      "40 Train Loss 180652.25 Test MSE 4741063.603863794 Test RE 0.9732506769771334\n",
      "41 Train Loss 178334.2 Test MSE 4738378.360906567 Test RE 0.9729750231475782\n",
      "42 Train Loss 175552.94 Test MSE 4719987.018101802 Test RE 0.9710849551571378\n",
      "43 Train Loss 173074.19 Test MSE 4703440.930804659 Test RE 0.969381373923282\n",
      "44 Train Loss 171318.52 Test MSE 4696513.948898612 Test RE 0.9686672838037288\n",
      "45 Train Loss 168879.39 Test MSE 4688745.040200037 Test RE 0.9678657741643131\n",
      "46 Train Loss 166597.58 Test MSE 4683255.739454781 Test RE 0.9672990487198078\n",
      "47 Train Loss 164264.47 Test MSE 4671189.425052633 Test RE 0.96605213174682\n",
      "48 Train Loss 162235.75 Test MSE 4653950.707827582 Test RE 0.9642679081706792\n",
      "49 Train Loss 159519.44 Test MSE 4632435.05742162 Test RE 0.9620363755694701\n",
      "50 Train Loss 156227.62 Test MSE 4606262.886940777 Test RE 0.9593148863524295\n",
      "51 Train Loss 154259.16 Test MSE 4598712.653186554 Test RE 0.9585283461230977\n",
      "52 Train Loss 151583.7 Test MSE 4573007.551072844 Test RE 0.9558456827059935\n",
      "53 Train Loss 149753.81 Test MSE 4552523.666639201 Test RE 0.9537025190356891\n",
      "54 Train Loss 147791.4 Test MSE 4519269.01260808 Test RE 0.950212896676043\n",
      "55 Train Loss 145785.0 Test MSE 4484153.470378175 Test RE 0.9465140339350194\n",
      "56 Train Loss 144259.25 Test MSE 4469177.377168579 Test RE 0.9449321369599114\n",
      "57 Train Loss 142004.4 Test MSE 4437958.7100303555 Test RE 0.9416260231016079\n",
      "58 Train Loss 140144.95 Test MSE 4413435.101410813 Test RE 0.9390207648073782\n",
      "59 Train Loss 137987.6 Test MSE 4395863.969695865 Test RE 0.9371496471423364\n",
      "60 Train Loss 136547.39 Test MSE 4380350.81071104 Test RE 0.9354945685657703\n",
      "61 Train Loss 134127.62 Test MSE 4341030.193364502 Test RE 0.9312863273331127\n",
      "62 Train Loss 132171.23 Test MSE 4317996.519908794 Test RE 0.9288123206078895\n",
      "63 Train Loss 130446.4 Test MSE 4292714.181099138 Test RE 0.9260891801551132\n",
      "64 Train Loss 128617.52 Test MSE 4265430.020980215 Test RE 0.9231414130565521\n",
      "65 Train Loss 127248.88 Test MSE 4248359.876484452 Test RE 0.9212923667941633\n",
      "66 Train Loss 125603.08 Test MSE 4227060.19814421 Test RE 0.9189799580803127\n",
      "67 Train Loss 124238.04 Test MSE 4208497.678789867 Test RE 0.9169599546663992\n",
      "68 Train Loss 122065.46 Test MSE 4158222.885255835 Test RE 0.9114664885582124\n",
      "69 Train Loss 121191.984 Test MSE 4135061.1122996323 Test RE 0.9089244579208532\n",
      "70 Train Loss 119829.336 Test MSE 4108975.0925545427 Test RE 0.9060529485172476\n",
      "71 Train Loss 118534.83 Test MSE 4097761.472990366 Test RE 0.9048157696336567\n",
      "72 Train Loss 117672.79 Test MSE 4077346.48121353 Test RE 0.9025590654942348\n",
      "73 Train Loss 115899.66 Test MSE 4050834.2765834806 Test RE 0.8996199167188691\n",
      "74 Train Loss 115122.14 Test MSE 4049563.409930916 Test RE 0.8994787869466212\n",
      "75 Train Loss 114162.08 Test MSE 4028079.662460945 Test RE 0.8970896561905451\n",
      "76 Train Loss 112837.75 Test MSE 3997402.557155505 Test RE 0.8936670933744619\n",
      "77 Train Loss 111476.195 Test MSE 3978271.7647640547 Test RE 0.8915260700870268\n",
      "78 Train Loss 110331.31 Test MSE 3960888.5447293427 Test RE 0.8895761580159267\n",
      "79 Train Loss 108665.516 Test MSE 3930310.5284082117 Test RE 0.8861357460515297\n",
      "80 Train Loss 107440.766 Test MSE 3895694.137290921 Test RE 0.8822247747794727\n",
      "81 Train Loss 106175.62 Test MSE 3855309.920131784 Test RE 0.8776401268962098\n",
      "82 Train Loss 105466.766 Test MSE 3837346.779917157 Test RE 0.8755931346109183\n",
      "83 Train Loss 104359.336 Test MSE 3808536.4670742075 Test RE 0.8723000208039826\n",
      "84 Train Loss 102872.06 Test MSE 3762686.5110864197 Test RE 0.867033428241456\n",
      "85 Train Loss 101934.27 Test MSE 3729789.349718553 Test RE 0.8632348714720722\n",
      "86 Train Loss 100768.7 Test MSE 3683971.665500316 Test RE 0.8579163888714727\n",
      "87 Train Loss 98995.45 Test MSE 3626426.825962732 Test RE 0.8511895496533534\n",
      "88 Train Loss 97948.55 Test MSE 3595062.5608510054 Test RE 0.8475006692322709\n",
      "89 Train Loss 96462.734 Test MSE 3544300.7676506736 Test RE 0.8414961010075789\n",
      "90 Train Loss 95671.54 Test MSE 3508121.819390027 Test RE 0.8371902397873823\n",
      "91 Train Loss 94685.92 Test MSE 3462265.6828310424 Test RE 0.8317006084960632\n",
      "92 Train Loss 93673.87 Test MSE 3417344.0589640075 Test RE 0.8262874881045363\n",
      "93 Train Loss 91813.15 Test MSE 3338098.8773560943 Test RE 0.8166508567280986\n",
      "94 Train Loss 89998.125 Test MSE 3294433.151703386 Test RE 0.8112919625306476\n",
      "95 Train Loss 88493.95 Test MSE 3258211.1829161043 Test RE 0.8068195975446317\n",
      "96 Train Loss 87288.73 Test MSE 3216712.683753817 Test RE 0.8016650670544518\n",
      "97 Train Loss 86499.836 Test MSE 3190562.125418528 Test RE 0.7983998126775338\n",
      "98 Train Loss 85114.35 Test MSE 3122922.6937303618 Test RE 0.789891500096679\n",
      "99 Train Loss 83739.27 Test MSE 3057296.3346644775 Test RE 0.7815478837879561\n",
      "100 Train Loss 82205.71 Test MSE 2996716.2586353277 Test RE 0.7737659879050204\n",
      "101 Train Loss 81243.73 Test MSE 2972873.48321515 Test RE 0.770681683336012\n",
      "102 Train Loss 79646.51 Test MSE 2916038.6140127755 Test RE 0.7632792550012009\n",
      "103 Train Loss 78297.65 Test MSE 2860603.3832564126 Test RE 0.7559892981397035\n",
      "104 Train Loss 77391.32 Test MSE 2830408.644544777 Test RE 0.7519888386390651\n",
      "105 Train Loss 76341.63 Test MSE 2805689.265983152 Test RE 0.7486978896238807\n",
      "106 Train Loss 75340.4 Test MSE 2779404.7689969544 Test RE 0.745182629613993\n",
      "107 Train Loss 74680.98 Test MSE 2762954.903319822 Test RE 0.7429741809567337\n",
      "108 Train Loss 73860.45 Test MSE 2736930.6934624184 Test RE 0.7394668740877042\n",
      "109 Train Loss 73296.92 Test MSE 2720361.820845588 Test RE 0.7372251783355706\n",
      "110 Train Loss 72650.69 Test MSE 2695957.572717087 Test RE 0.7339109209953445\n",
      "111 Train Loss 71853.46 Test MSE 2664786.7078574537 Test RE 0.729655819063899\n",
      "112 Train Loss 71066.89 Test MSE 2633850.862015607 Test RE 0.7254081217288524\n",
      "113 Train Loss 70466.08 Test MSE 2606099.8272164892 Test RE 0.7215764443902601\n",
      "114 Train Loss 69286.59 Test MSE 2553921.53145802 Test RE 0.7143163625309856\n",
      "115 Train Loss 68500.4 Test MSE 2530550.7850811873 Test RE 0.7110405230585966\n",
      "116 Train Loss 67459.24 Test MSE 2487977.5228164266 Test RE 0.7050339816730606\n",
      "117 Train Loss 66634.25 Test MSE 2457199.2531303545 Test RE 0.7006594937793149\n",
      "118 Train Loss 65927.64 Test MSE 2436118.522946245 Test RE 0.6976474812577427\n",
      "119 Train Loss 65315.926 Test MSE 2413201.808088056 Test RE 0.6943583215412111\n",
      "120 Train Loss 64477.047 Test MSE 2373653.7392571084 Test RE 0.6886451712118643\n",
      "121 Train Loss 63327.473 Test MSE 2315347.4561840105 Test RE 0.6801346647606992\n",
      "122 Train Loss 62343.297 Test MSE 2278416.1047232663 Test RE 0.6746885571821746\n",
      "123 Train Loss 61676.86 Test MSE 2256041.124448085 Test RE 0.6713675244665497\n",
      "124 Train Loss 60908.598 Test MSE 2232221.268454177 Test RE 0.6678138849787898\n",
      "125 Train Loss 60379.992 Test MSE 2214015.636539919 Test RE 0.6650850190797277\n",
      "126 Train Loss 59301.26 Test MSE 2174022.401412648 Test RE 0.659050708208573\n",
      "127 Train Loss 58560.57 Test MSE 2147045.039906053 Test RE 0.6549488759976636\n",
      "128 Train Loss 58162.645 Test MSE 2130038.7890589647 Test RE 0.6523498693897996\n",
      "129 Train Loss 57634.81 Test MSE 2105910.5210997397 Test RE 0.6486445610213556\n",
      "130 Train Loss 56665.977 Test MSE 2074834.9440138417 Test RE 0.6438409573956221\n",
      "131 Train Loss 56267.305 Test MSE 2056736.288700077 Test RE 0.6410267146570732\n",
      "132 Train Loss 55564.406 Test MSE 2023577.3293738803 Test RE 0.6358383614875807\n",
      "133 Train Loss 54972.535 Test MSE 2003227.5443212662 Test RE 0.6326331791138813\n",
      "134 Train Loss 54303.77 Test MSE 1979642.5163780232 Test RE 0.628897994640898\n",
      "135 Train Loss 53698.945 Test MSE 1950630.559103231 Test RE 0.6242726888535146\n",
      "136 Train Loss 52938.37 Test MSE 1906284.3861876796 Test RE 0.6171356983622133\n",
      "137 Train Loss 52280.92 Test MSE 1871664.2758414727 Test RE 0.6115061078458924\n",
      "138 Train Loss 51292.664 Test MSE 1846436.5937843537 Test RE 0.6073709595381348\n",
      "139 Train Loss 50631.598 Test MSE 1830211.0254700286 Test RE 0.6046964337086994\n",
      "140 Train Loss 50171.83 Test MSE 1812433.6897495873 Test RE 0.6017524772286192\n",
      "141 Train Loss 49595.38 Test MSE 1792383.3519544182 Test RE 0.5984147289139468\n",
      "142 Train Loss 48905.65 Test MSE 1767157.1841281112 Test RE 0.5941887350553691\n",
      "143 Train Loss 48433.953 Test MSE 1751229.1166528459 Test RE 0.591504847820753\n",
      "144 Train Loss 47607.016 Test MSE 1715206.0721803857 Test RE 0.5853895648117152\n",
      "145 Train Loss 46953.86 Test MSE 1689767.8821830475 Test RE 0.5810323982155887\n",
      "146 Train Loss 46464.805 Test MSE 1670142.1514157525 Test RE 0.5776483566367859\n",
      "147 Train Loss 45878.35 Test MSE 1646597.4337641883 Test RE 0.5735622249277879\n",
      "148 Train Loss 45422.957 Test MSE 1632129.6685082605 Test RE 0.5710368742089904\n",
      "149 Train Loss 45192.336 Test MSE 1623482.5375626916 Test RE 0.5695221697272799\n",
      "150 Train Loss 44765.32 Test MSE 1605000.6370096882 Test RE 0.5662711397784689\n",
      "151 Train Loss 44103.93 Test MSE 1579987.046049605 Test RE 0.5618412049270846\n",
      "152 Train Loss 43513.18 Test MSE 1555793.8348159424 Test RE 0.557523074849635\n",
      "153 Train Loss 42964.523 Test MSE 1533445.494475639 Test RE 0.5535042954638559\n",
      "154 Train Loss 42223.86 Test MSE 1497754.9578742844 Test RE 0.5470250400340677\n",
      "155 Train Loss 41791.36 Test MSE 1481882.5766668762 Test RE 0.5441187849265362\n",
      "156 Train Loss 41342.715 Test MSE 1462678.5652572403 Test RE 0.5405816159934593\n",
      "157 Train Loss 40713.496 Test MSE 1433740.8387039776 Test RE 0.5352074518236906\n",
      "158 Train Loss 39928.664 Test MSE 1393360.113418319 Test RE 0.527616672625642\n",
      "159 Train Loss 39112.707 Test MSE 1361944.0599133263 Test RE 0.521634681881778\n",
      "160 Train Loss 38386.07 Test MSE 1329559.2709955925 Test RE 0.5153955625027422\n",
      "161 Train Loss 37632.9 Test MSE 1300733.0945538883 Test RE 0.5097778000037904\n",
      "162 Train Loss 37117.273 Test MSE 1278464.023762412 Test RE 0.5053951609813663\n",
      "163 Train Loss 36313.16 Test MSE 1243256.4519843436 Test RE 0.4983875495943249\n",
      "164 Train Loss 35875.48 Test MSE 1222484.1011038246 Test RE 0.4942064776586405\n",
      "165 Train Loss 35401.67 Test MSE 1204030.3251270452 Test RE 0.49046219375472094\n",
      "166 Train Loss 34906.473 Test MSE 1185329.5471841893 Test RE 0.4866384036778632\n",
      "167 Train Loss 34479.535 Test MSE 1174969.6634632354 Test RE 0.48450710545883324\n",
      "168 Train Loss 33882.453 Test MSE 1159689.2627998227 Test RE 0.4813463043293479\n",
      "169 Train Loss 33397.39 Test MSE 1144494.6820832093 Test RE 0.4781825384789631\n",
      "170 Train Loss 33084.465 Test MSE 1131892.7241409756 Test RE 0.4755426326904654\n",
      "171 Train Loss 32740.74 Test MSE 1120605.6510927468 Test RE 0.4731656704568852\n",
      "172 Train Loss 32430.87 Test MSE 1113645.9028946804 Test RE 0.47169403634690504\n",
      "173 Train Loss 32126.43 Test MSE 1102640.5530088863 Test RE 0.46935754556168335\n",
      "174 Train Loss 31749.035 Test MSE 1090300.8976310068 Test RE 0.4667238652490338\n",
      "175 Train Loss 31487.262 Test MSE 1080511.6561280154 Test RE 0.46462390627424993\n",
      "176 Train Loss 31303.062 Test MSE 1072528.2145775035 Test RE 0.462904269649647\n",
      "177 Train Loss 30929.025 Test MSE 1055798.5163537632 Test RE 0.4592798027543874\n",
      "178 Train Loss 30665.89 Test MSE 1050577.4331932846 Test RE 0.4581427913354583\n",
      "179 Train Loss 30320.139 Test MSE 1035905.3679224991 Test RE 0.4549323971803895\n",
      "180 Train Loss 29996.73 Test MSE 1020173.5747950611 Test RE 0.4514647624964872\n",
      "181 Train Loss 29667.584 Test MSE 1011336.7893817673 Test RE 0.4495052066696055\n",
      "182 Train Loss 29428.865 Test MSE 1007193.1078988762 Test RE 0.44858339791997703\n",
      "183 Train Loss 28896.23 Test MSE 993824.2990696396 Test RE 0.4455963545472966\n",
      "184 Train Loss 28639.23 Test MSE 983939.3166613587 Test RE 0.44337477488384786\n",
      "185 Train Loss 28245.965 Test MSE 968409.1241282774 Test RE 0.4398618130146425\n",
      "186 Train Loss 27864.188 Test MSE 957652.2691986975 Test RE 0.4374120517257148\n",
      "187 Train Loss 27636.512 Test MSE 953795.1091374132 Test RE 0.4365302751962858\n",
      "188 Train Loss 27315.53 Test MSE 944081.2530912044 Test RE 0.4343016812176151\n",
      "189 Train Loss 26859.252 Test MSE 929648.0418337425 Test RE 0.4309690704592126\n",
      "190 Train Loss 26548.213 Test MSE 920788.7809824487 Test RE 0.4289106531351542\n",
      "191 Train Loss 26252.75 Test MSE 912961.5452497666 Test RE 0.427083768486164\n",
      "192 Train Loss 25997.244 Test MSE 902223.5030646601 Test RE 0.42456470925887274\n",
      "193 Train Loss 25735.502 Test MSE 894055.639311423 Test RE 0.4226385396801465\n",
      "194 Train Loss 25611.912 Test MSE 890666.2457602649 Test RE 0.4218366608542255\n",
      "195 Train Loss 25341.734 Test MSE 880163.9782768503 Test RE 0.4193422479326656\n",
      "196 Train Loss 25130.426 Test MSE 872914.5293114494 Test RE 0.4176117261578127\n",
      "197 Train Loss 24860.928 Test MSE 863347.4574706375 Test RE 0.415316925948946\n",
      "198 Train Loss 24588.818 Test MSE 853617.3170197514 Test RE 0.41296993191359554\n",
      "199 Train Loss 24339.484 Test MSE 844349.624831969 Test RE 0.41072201410084996\n",
      "Training time: 70.76\n",
      "Training time: 70.76\n",
      "1D_FODE_rowdyhigh\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 457367.72 Test MSE 5015579.460268795 Test RE 1.0010306641719482\n",
      "1 Train Loss 454811.72 Test MSE 4991562.893094244 Test RE 0.9986311239676459\n",
      "2 Train Loss 451800.8 Test MSE 5025119.626280961 Test RE 1.0019822453232818\n",
      "3 Train Loss 449419.72 Test MSE 4987479.896919681 Test RE 0.9982226105124059\n",
      "4 Train Loss 446915.56 Test MSE 4972445.318526468 Test RE 0.9967169219039723\n",
      "5 Train Loss 444494.4 Test MSE 4948447.540311388 Test RE 0.9943088591576726\n",
      "6 Train Loss 441219.16 Test MSE 4950193.847289955 Test RE 0.9944842894639842\n",
      "7 Train Loss 438201.34 Test MSE 4898045.213872989 Test RE 0.9892321410615122\n",
      "8 Train Loss 434116.72 Test MSE 4910618.709604264 Test RE 0.990501028290898\n",
      "9 Train Loss 429495.44 Test MSE 4892470.513121655 Test RE 0.9886690344606742\n",
      "10 Train Loss 426622.12 Test MSE 4915068.47512169 Test RE 0.9909496987709401\n",
      "11 Train Loss 423884.25 Test MSE 4887537.358441356 Test RE 0.9881704635101191\n",
      "12 Train Loss 421821.06 Test MSE 4877820.799047676 Test RE 0.987187719736038\n",
      "13 Train Loss 416309.84 Test MSE 4889808.286777864 Test RE 0.9884000068909992\n",
      "14 Train Loss 411988.28 Test MSE 4912036.210714053 Test RE 0.9906439771820743\n",
      "15 Train Loss 405753.4 Test MSE 4935513.078758017 Test RE 0.9930085256019652\n",
      "16 Train Loss 403292.22 Test MSE 4909036.620097842 Test RE 0.9903414570012258\n",
      "17 Train Loss 398633.0 Test MSE 4918286.114903186 Test RE 0.9912740073253047\n",
      "18 Train Loss 394899.4 Test MSE 4891970.599878116 Test RE 0.9886185220080468\n",
      "19 Train Loss 391332.47 Test MSE 4847894.430800538 Test RE 0.9841547674306186\n",
      "20 Train Loss 381410.94 Test MSE 4877291.339950168 Test RE 0.9871341415374104\n",
      "21 Train Loss 378733.06 Test MSE 4870775.305570074 Test RE 0.9864745182611103\n",
      "22 Train Loss 372402.94 Test MSE 4816438.951419111 Test RE 0.9809567357797784\n",
      "23 Train Loss 365762.3 Test MSE 4592084.486721034 Test RE 0.9578373292198207\n",
      "24 Train Loss 351289.44 Test MSE 4503306.042288562 Test RE 0.9485332402718285\n",
      "25 Train Loss 345670.94 Test MSE 4591127.607436218 Test RE 0.9577375289600375\n",
      "26 Train Loss 341404.34 Test MSE 4450392.622645552 Test RE 0.9429441861605411\n",
      "27 Train Loss 338172.4 Test MSE 4405496.111429972 Test RE 0.9381758184342802\n",
      "28 Train Loss 328786.22 Test MSE 4430398.140573387 Test RE 0.9408235974701515\n",
      "29 Train Loss 323611.6 Test MSE 4405535.08695285 Test RE 0.9381799684563521\n",
      "30 Train Loss 318414.94 Test MSE 4429436.562435675 Test RE 0.9407214932723674\n",
      "31 Train Loss 317126.97 Test MSE 4465280.441808429 Test RE 0.9445200765058053\n",
      "32 Train Loss 314260.2 Test MSE 4364776.361943268 Test RE 0.9338300002731658\n",
      "33 Train Loss 308797.34 Test MSE 4416022.237207347 Test RE 0.9392959493587262\n",
      "34 Train Loss 306992.16 Test MSE 4374128.123032265 Test RE 0.9348298547488546\n",
      "35 Train Loss 306102.03 Test MSE 4363665.52368071 Test RE 0.9337111625575597\n",
      "36 Train Loss 303603.88 Test MSE 4268426.096884037 Test RE 0.9234655675051602\n",
      "37 Train Loss 300281.2 Test MSE 4145339.3355399123 Test RE 0.9100533808283259\n",
      "38 Train Loss 295162.38 Test MSE 4156211.4476705566 Test RE 0.9112460121951781\n",
      "39 Train Loss 289279.56 Test MSE 4027132.0080687897 Test RE 0.8969841243948927\n",
      "40 Train Loss 288150.66 Test MSE 3989686.0304528694 Test RE 0.8928041158417224\n",
      "41 Train Loss 285136.16 Test MSE 3925728.743372121 Test RE 0.8856190861808614\n",
      "42 Train Loss 283142.56 Test MSE 3894461.4776223516 Test RE 0.882085188752183\n",
      "43 Train Loss 281717.6 Test MSE 3887020.008069005 Test RE 0.8812420492434477\n",
      "44 Train Loss 279935.5 Test MSE 3915107.7862724317 Test RE 0.88442026507504\n",
      "45 Train Loss 277339.75 Test MSE 3838155.072174048 Test RE 0.8756853464862545\n",
      "46 Train Loss 274767.2 Test MSE 3828021.714753016 Test RE 0.8745286061849517\n",
      "47 Train Loss 271680.72 Test MSE 3796752.664875316 Test RE 0.8709495054210129\n",
      "48 Train Loss 270544.8 Test MSE 3810467.364291025 Test RE 0.8725211173152922\n",
      "49 Train Loss 269257.5 Test MSE 3798778.227886794 Test RE 0.8711817997033585\n",
      "50 Train Loss 268128.75 Test MSE 3777851.0336057586 Test RE 0.8687788469729288\n",
      "51 Train Loss 266964.12 Test MSE 3762549.13917352 Test RE 0.8670176008363073\n",
      "52 Train Loss 265976.3 Test MSE 3716549.1081843437 Test RE 0.8617013264906795\n",
      "53 Train Loss 265443.44 Test MSE 3703294.069602217 Test RE 0.8601633289815734\n",
      "54 Train Loss 263522.25 Test MSE 3725249.735424203 Test RE 0.8627093797991813\n",
      "55 Train Loss 259491.55 Test MSE 3540327.1675690985 Test RE 0.8410242580524555\n",
      "56 Train Loss 249585.84 Test MSE 3146306.754908851 Test RE 0.7928432899612953\n",
      "57 Train Loss 237957.66 Test MSE 2964584.576529656 Test RE 0.7696065337187787\n",
      "58 Train Loss 229373.1 Test MSE 2722697.2763241045 Test RE 0.7375415677200735\n",
      "59 Train Loss 222747.69 Test MSE 2403187.8349623834 Test RE 0.6929161474965579\n",
      "60 Train Loss 218259.44 Test MSE 2299837.4884038004 Test RE 0.6778528058928603\n",
      "61 Train Loss 215123.14 Test MSE 2236892.174965163 Test RE 0.6685122176657122\n",
      "62 Train Loss 213351.89 Test MSE 2249943.070230986 Test RE 0.6704595609995057\n",
      "63 Train Loss 212226.95 Test MSE 2148925.2551817717 Test RE 0.6552355899174048\n",
      "64 Train Loss 211427.7 Test MSE 2150212.4923547828 Test RE 0.6554318083143658\n",
      "65 Train Loss 210384.9 Test MSE 2123373.0604517544 Test RE 0.6513283399943526\n",
      "66 Train Loss 209873.33 Test MSE 2135992.447965614 Test RE 0.6532609228578744\n",
      "67 Train Loss 209451.06 Test MSE 2155787.2054501516 Test RE 0.6562809055764122\n",
      "68 Train Loss 208917.44 Test MSE 2134914.6842622096 Test RE 0.6530960932146119\n",
      "69 Train Loss 208558.84 Test MSE 2094778.6065560074 Test RE 0.6469279108570192\n",
      "70 Train Loss 208320.77 Test MSE 2090133.1664842668 Test RE 0.6462101899434066\n",
      "71 Train Loss 208145.92 Test MSE 2097402.028627973 Test RE 0.6473328782175454\n",
      "72 Train Loss 207990.89 Test MSE 2101405.5336501505 Test RE 0.6479503957143625\n",
      "73 Train Loss 207704.9 Test MSE 2091945.7407330775 Test RE 0.6464903276251184\n",
      "74 Train Loss 207145.78 Test MSE 2057002.8771406342 Test RE 0.6410682573613886\n",
      "75 Train Loss 205755.56 Test MSE 2036536.0385816987 Test RE 0.637871022902143\n",
      "76 Train Loss 205248.27 Test MSE 2017116.9336875668 Test RE 0.634822573465202\n",
      "77 Train Loss 204743.83 Test MSE 2030558.6510760277 Test RE 0.6369342351312903\n",
      "78 Train Loss 204169.06 Test MSE 1993635.713003397 Test RE 0.6311167782400683\n",
      "79 Train Loss 203236.31 Test MSE 1954539.5342361701 Test RE 0.6248978828665881\n",
      "80 Train Loss 202379.05 Test MSE 2002509.3733472496 Test RE 0.6325197672561194\n",
      "81 Train Loss 202162.48 Test MSE 2004704.667080497 Test RE 0.6328663789490944\n",
      "82 Train Loss 202060.33 Test MSE 1998753.950458082 Test RE 0.6319263882785223\n",
      "83 Train Loss 201901.92 Test MSE 1989281.057468927 Test RE 0.6304271340499\n",
      "84 Train Loss 201720.28 Test MSE 1994220.262136157 Test RE 0.631209295575232\n",
      "85 Train Loss 201453.2 Test MSE 2011187.5589415794 Test RE 0.6338888469377693\n",
      "86 Train Loss 201214.64 Test MSE 2000429.9781961995 Test RE 0.6321912793670603\n",
      "87 Train Loss 201035.44 Test MSE 2000318.6885020107 Test RE 0.6321736938095862\n",
      "88 Train Loss 200962.08 Test MSE 2000508.1975727612 Test RE 0.6322036389909669\n",
      "89 Train Loss 200856.86 Test MSE 1983503.838349533 Test RE 0.6295110332656216\n",
      "90 Train Loss 200785.3 Test MSE 1964773.0671012078 Test RE 0.6265316600727139\n",
      "91 Train Loss 200668.5 Test MSE 1964621.8608792953 Test RE 0.6265075511031938\n",
      "92 Train Loss 200555.53 Test MSE 1980111.324416023 Test RE 0.6289724563125\n",
      "93 Train Loss 200340.36 Test MSE 1997704.7783730172 Test RE 0.6317605132959192\n",
      "94 Train Loss 199545.83 Test MSE 2000251.9619550204 Test RE 0.6321631497098593\n",
      "95 Train Loss 198613.8 Test MSE 1957507.789931192 Test RE 0.625372202516615\n",
      "96 Train Loss 197811.4 Test MSE 1960258.5637866638 Test RE 0.6258114481719386\n",
      "97 Train Loss 197085.97 Test MSE 1963207.6894780023 Test RE 0.6262820246101889\n",
      "98 Train Loss 196072.69 Test MSE 1933946.6560816497 Test RE 0.6215972279764241\n",
      "99 Train Loss 194138.19 Test MSE 1820521.4377780808 Test RE 0.6030936035632508\n",
      "100 Train Loss 190963.66 Test MSE 1740571.1116107071 Test RE 0.5897021474068981\n",
      "101 Train Loss 190101.64 Test MSE 1744085.007862672 Test RE 0.5902970979324919\n",
      "102 Train Loss 189267.62 Test MSE 1681652.3669452078 Test RE 0.5796354452227256\n",
      "103 Train Loss 188328.17 Test MSE 1631851.982394978 Test RE 0.5709882948104296\n",
      "104 Train Loss 186624.97 Test MSE 1605525.679461967 Test RE 0.566363754095807\n",
      "105 Train Loss 182605.83 Test MSE 1541927.8973250254 Test RE 0.5550330656579433\n",
      "106 Train Loss 181361.62 Test MSE 1483967.8948243875 Test RE 0.5445014946986783\n",
      "107 Train Loss 180917.66 Test MSE 1492909.4459963585 Test RE 0.5461394600540659\n",
      "108 Train Loss 180616.55 Test MSE 1481297.419651789 Test RE 0.5440113451176279\n",
      "109 Train Loss 180391.23 Test MSE 1467768.756642012 Test RE 0.5415214240024959\n",
      "110 Train Loss 179870.88 Test MSE 1464452.5033056485 Test RE 0.5409093256281782\n",
      "111 Train Loss 178673.78 Test MSE 1367550.3475584546 Test RE 0.5227072041723838\n",
      "112 Train Loss 178187.77 Test MSE 1336399.4304375616 Test RE 0.5167196348012079\n",
      "113 Train Loss 177946.34 Test MSE 1317123.280305082 Test RE 0.5129795315966622\n",
      "114 Train Loss 177800.02 Test MSE 1311708.337773582 Test RE 0.511923967710842\n",
      "115 Train Loss 177556.98 Test MSE 1303216.8925851998 Test RE 0.5102642876702248\n",
      "116 Train Loss 177415.7 Test MSE 1300476.504620652 Test RE 0.5097275167044617\n",
      "117 Train Loss 177211.92 Test MSE 1302725.9677223598 Test RE 0.5101681697398845\n",
      "118 Train Loss 177057.05 Test MSE 1303064.4781072591 Test RE 0.5102344484548609\n",
      "119 Train Loss 176944.06 Test MSE 1296970.5996485802 Test RE 0.509039975534266\n",
      "120 Train Loss 176662.02 Test MSE 1292050.8689922078 Test RE 0.5080736008979932\n",
      "121 Train Loss 176447.84 Test MSE 1302025.795468675 Test RE 0.5100310520284559\n",
      "122 Train Loss 176356.78 Test MSE 1297979.2233700843 Test RE 0.5092378713126531\n",
      "123 Train Loss 176247.56 Test MSE 1284115.0742285606 Test RE 0.5065109000378457\n",
      "124 Train Loss 175993.31 Test MSE 1257726.5090268848 Test RE 0.5012794845436206\n",
      "125 Train Loss 175709.92 Test MSE 1243842.8450556658 Test RE 0.49850507022044777\n",
      "126 Train Loss 175206.45 Test MSE 1215316.9164684096 Test RE 0.492755630175614\n",
      "127 Train Loss 174404.58 Test MSE 1185932.6903529137 Test RE 0.4867621984914086\n",
      "128 Train Loss 173824.05 Test MSE 1195339.4531929363 Test RE 0.4886888730031521\n",
      "129 Train Loss 173562.06 Test MSE 1179408.6801098392 Test RE 0.4854214727147726\n",
      "130 Train Loss 172942.77 Test MSE 1170787.9692260837 Test RE 0.48364416127977017\n",
      "131 Train Loss 172101.55 Test MSE 1167705.3244252172 Test RE 0.483007032326091\n",
      "132 Train Loss 171149.03 Test MSE 1120715.2108143615 Test RE 0.47318880019573184\n",
      "133 Train Loss 170609.78 Test MSE 1141667.464524546 Test RE 0.4775915518930893\n",
      "134 Train Loss 169195.12 Test MSE 1152278.3463748256 Test RE 0.4798058336853061\n",
      "135 Train Loss 166938.67 Test MSE 1097184.5392916957 Test RE 0.46819488340333243\n",
      "136 Train Loss 165764.58 Test MSE 1059100.8304216464 Test RE 0.45999750694374253\n",
      "137 Train Loss 165025.77 Test MSE 1044588.830858329 Test RE 0.45683515042788864\n",
      "138 Train Loss 164060.8 Test MSE 1014684.357635714 Test RE 0.450248532847354\n",
      "139 Train Loss 163294.08 Test MSE 1004489.5495319857 Test RE 0.4479809383078219\n",
      "140 Train Loss 162696.02 Test MSE 1002611.1923679758 Test RE 0.4475618886761953\n",
      "141 Train Loss 161913.95 Test MSE 959331.3289925081 Test RE 0.4377953429105776\n",
      "142 Train Loss 160921.83 Test MSE 947857.6284844867 Test RE 0.43516942927471597\n",
      "143 Train Loss 160429.8 Test MSE 905677.2732250496 Test RE 0.42537656368235005\n",
      "144 Train Loss 159957.31 Test MSE 907488.974861269 Test RE 0.42580180919896743\n",
      "145 Train Loss 159778.88 Test MSE 902663.4641881632 Test RE 0.4246682142105551\n",
      "146 Train Loss 159617.81 Test MSE 906903.8007129622 Test RE 0.42566450263186084\n",
      "147 Train Loss 159295.72 Test MSE 880751.2665191025 Test RE 0.4194821273811773\n",
      "148 Train Loss 159051.66 Test MSE 887894.2183598116 Test RE 0.42117970655444426\n",
      "149 Train Loss 158925.19 Test MSE 888859.883415327 Test RE 0.4214086797759318\n",
      "150 Train Loss 158865.64 Test MSE 892705.0051273651 Test RE 0.4223191827056924\n",
      "151 Train Loss 158673.27 Test MSE 887858.2623121124 Test RE 0.4211711784490543\n",
      "152 Train Loss 158061.94 Test MSE 830080.7657250928 Test RE 0.40723678389817214\n",
      "153 Train Loss 156307.3 Test MSE 757983.1159836315 Test RE 0.38914960107976737\n",
      "154 Train Loss 154904.7 Test MSE 740509.2865260462 Test RE 0.3846379030122428\n",
      "155 Train Loss 153828.83 Test MSE 731532.7301604602 Test RE 0.3822994776985377\n",
      "156 Train Loss 153393.19 Test MSE 709306.96410699 Test RE 0.37644708242576924\n",
      "157 Train Loss 152723.45 Test MSE 690208.798056417 Test RE 0.3713445625648532\n",
      "158 Train Loss 152351.22 Test MSE 658167.7658259254 Test RE 0.362622817518277\n",
      "159 Train Loss 152032.64 Test MSE 658107.7691105815 Test RE 0.3626062893054717\n",
      "160 Train Loss 151575.33 Test MSE 641311.9517050497 Test RE 0.35794927776686186\n",
      "161 Train Loss 151267.28 Test MSE 622222.0901161247 Test RE 0.3525815123931466\n",
      "162 Train Loss 150402.48 Test MSE 606865.147911188 Test RE 0.3482033315489498\n",
      "163 Train Loss 148332.48 Test MSE 547111.2875741116 Test RE 0.3306166043656292\n",
      "164 Train Loss 147495.36 Test MSE 534049.511761053 Test RE 0.32664618089134945\n",
      "165 Train Loss 147157.4 Test MSE 498799.55586085556 Test RE 0.3156820242211141\n",
      "166 Train Loss 146796.25 Test MSE 494752.7964450181 Test RE 0.314398852634714\n",
      "167 Train Loss 146392.17 Test MSE 494549.92426609556 Test RE 0.31433438678370984\n",
      "168 Train Loss 146293.72 Test MSE 478102.0243332138 Test RE 0.3090630704897446\n",
      "169 Train Loss 145972.67 Test MSE 468031.64168591634 Test RE 0.3057908112627833\n",
      "170 Train Loss 145837.58 Test MSE 467619.04436310177 Test RE 0.30565599528313914\n",
      "171 Train Loss 145338.23 Test MSE 443958.660728912 Test RE 0.2978229012183091\n",
      "172 Train Loss 145106.77 Test MSE 447453.35569455585 Test RE 0.29899278492497283\n",
      "173 Train Loss 144967.88 Test MSE 453993.69887658785 Test RE 0.3011700189293883\n",
      "174 Train Loss 144680.11 Test MSE 432360.28352016356 Test RE 0.293906858101092\n",
      "175 Train Loss 144139.23 Test MSE 423042.2056539621 Test RE 0.2907225187164063\n",
      "176 Train Loss 143861.3 Test MSE 408775.8231633955 Test RE 0.2857784158828969\n",
      "177 Train Loss 143072.25 Test MSE 400607.0986374045 Test RE 0.2829085963446226\n",
      "178 Train Loss 139418.95 Test MSE 287801.5520506253 Test RE 0.23979128195272012\n",
      "179 Train Loss 133737.58 Test MSE 175487.48832244892 Test RE 0.1872448590834458\n",
      "180 Train Loss 131898.61 Test MSE 134006.71159669696 Test RE 0.16362516545843553\n",
      "181 Train Loss 130012.48 Test MSE 87497.14242080659 Test RE 0.13221592217342068\n",
      "182 Train Loss 129235.51 Test MSE 87913.00829119491 Test RE 0.1325297547698737\n",
      "183 Train Loss 128774.586 Test MSE 66303.82960640834 Test RE 0.11509491335331246\n",
      "184 Train Loss 128499.81 Test MSE 53917.09838951151 Test RE 0.10378870178105279\n",
      "185 Train Loss 128261.05 Test MSE 48947.530979936164 Test RE 0.09888996396138539\n",
      "186 Train Loss 127758.33 Test MSE 45030.194457176716 Test RE 0.09485030568136323\n",
      "187 Train Loss 127631.03 Test MSE 37203.770725974355 Test RE 0.08621449790554579\n",
      "188 Train Loss 127520.195 Test MSE 33279.15228541069 Test RE 0.0815404213298213\n",
      "189 Train Loss 127378.12 Test MSE 38782.212839054766 Test RE 0.08802440869765689\n",
      "190 Train Loss 127239.195 Test MSE 39344.75408164397 Test RE 0.08866051328331029\n",
      "191 Train Loss 127005.72 Test MSE 45105.737038833315 Test RE 0.09492983270172109\n",
      "192 Train Loss 126810.516 Test MSE 40665.30053004297 Test RE 0.09013611113251917\n",
      "193 Train Loss 126747.766 Test MSE 38483.33174888104 Test RE 0.08768456584403851\n",
      "194 Train Loss 126690.984 Test MSE 33078.723978101065 Test RE 0.08129450626154663\n",
      "195 Train Loss 126599.9 Test MSE 35721.533134124664 Test RE 0.08447960386109962\n",
      "196 Train Loss 126554.01 Test MSE 34508.19371879487 Test RE 0.08303246619437757\n",
      "197 Train Loss 126512.74 Test MSE 32955.367774834274 Test RE 0.08114278414072748\n",
      "198 Train Loss 126459.35 Test MSE 34239.76875497722 Test RE 0.0827088981373551\n",
      "199 Train Loss 126241.37 Test MSE 30429.047800170767 Test RE 0.07797062309675865\n",
      "Training time: 71.22\n",
      "Training time: 71.22\n",
      "1D_FODE_rowdyhigh\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 457585.94 Test MSE 5014744.088405791 Test RE 1.0009472971671831\n",
      "1 Train Loss 455913.47 Test MSE 5013429.293432559 Test RE 1.0008160714530998\n",
      "2 Train Loss 452114.4 Test MSE 5015536.569977861 Test RE 1.0010263840495268\n",
      "3 Train Loss 446714.62 Test MSE 5017459.758759334 Test RE 1.0012182855710454\n",
      "4 Train Loss 440863.16 Test MSE 5037672.4358418165 Test RE 1.0032329466231793\n",
      "5 Train Loss 429478.88 Test MSE 5043395.026594005 Test RE 1.003802600780883\n",
      "6 Train Loss 413740.8 Test MSE 4989532.063764677 Test RE 0.9984279555672295\n",
      "7 Train Loss 396959.44 Test MSE 5013786.600788899 Test RE 1.0008517349233959\n",
      "8 Train Loss 383668.75 Test MSE 4935966.819892064 Test RE 0.9930541701430867\n",
      "9 Train Loss 361475.1 Test MSE 4971413.70711172 Test RE 0.9966135242973738\n",
      "10 Train Loss 345818.66 Test MSE 4762632.481701511 Test RE 0.9754620061035768\n",
      "11 Train Loss 316225.44 Test MSE 4907316.138874986 Test RE 0.9901678981822267\n",
      "12 Train Loss 298876.78 Test MSE 4855153.335960745 Test RE 0.9848912948066174\n",
      "13 Train Loss 280760.6 Test MSE 4592869.512038023 Test RE 0.9579191977505618\n",
      "14 Train Loss 265315.8 Test MSE 4119031.53612108 Test RE 0.9071610231465466\n",
      "15 Train Loss 239588.39 Test MSE 3354605.076568463 Test RE 0.8186674505434165\n",
      "16 Train Loss 224971.23 Test MSE 3159765.2368485 Test RE 0.7945371935453144\n",
      "17 Train Loss 214415.53 Test MSE 2912471.1371410238 Test RE 0.7628122148172515\n",
      "18 Train Loss 206142.16 Test MSE 2697304.63154535 Test RE 0.7340942506094345\n",
      "19 Train Loss 201307.73 Test MSE 2502178.8658207487 Test RE 0.7070432808407598\n",
      "20 Train Loss 194702.73 Test MSE 2258165.985496461 Test RE 0.6716836151045089\n",
      "21 Train Loss 176857.64 Test MSE 1631121.6772453391 Test RE 0.5708605128909597\n",
      "22 Train Loss 169137.36 Test MSE 1190746.4200847046 Test RE 0.4877490878748989\n",
      "23 Train Loss 164788.2 Test MSE 1120715.092706567 Test RE 0.47318877526197234\n",
      "24 Train Loss 161923.34 Test MSE 1119631.9615959 Test RE 0.47296005996166474\n",
      "25 Train Loss 159744.94 Test MSE 1076811.5979940698 Test RE 0.4638277049039382\n",
      "26 Train Loss 156397.19 Test MSE 883354.0658140344 Test RE 0.4201014976694837\n",
      "27 Train Loss 152897.23 Test MSE 771812.4499020469 Test RE 0.392683554545649\n",
      "28 Train Loss 151092.39 Test MSE 729734.0995660858 Test RE 0.3818292056987217\n",
      "29 Train Loss 144862.28 Test MSE 551131.9785318824 Test RE 0.3318292222582747\n",
      "30 Train Loss 141782.1 Test MSE 446777.5278439762 Test RE 0.2987669021526351\n",
      "31 Train Loss 136856.95 Test MSE 371721.434646881 Test RE 0.27251827168140064\n",
      "32 Train Loss 135804.23 Test MSE 367199.87319654314 Test RE 0.2708557657595259\n",
      "33 Train Loss 134716.58 Test MSE 335391.1597012639 Test RE 0.25885861861845866\n",
      "34 Train Loss 133489.8 Test MSE 253562.6900711586 Test RE 0.22507616096350866\n",
      "35 Train Loss 132262.2 Test MSE 195257.04465852614 Test RE 0.19751049594377745\n",
      "36 Train Loss 131864.75 Test MSE 186153.08260644146 Test RE 0.1928510198225741\n",
      "37 Train Loss 130874.88 Test MSE 138042.66167189283 Test RE 0.1660708796024886\n",
      "38 Train Loss 130188.38 Test MSE 122727.98138281748 Test RE 0.15658805119972455\n",
      "39 Train Loss 129025.516 Test MSE 79290.8628188554 Test RE 0.12586309169255674\n",
      "40 Train Loss 127852.266 Test MSE 52932.25480440407 Test RE 0.10283643694061745\n",
      "41 Train Loss 127191.13 Test MSE 46578.770766365444 Test RE 0.09646745812823827\n",
      "42 Train Loss 126964.18 Test MSE 48376.02557085895 Test RE 0.0983109553039954\n",
      "43 Train Loss 126725.57 Test MSE 50028.2894161773 Test RE 0.0999757453123163\n",
      "44 Train Loss 126639.195 Test MSE 47766.15750147427 Test RE 0.09768929531498712\n",
      "45 Train Loss 126620.72 Test MSE 46692.183426512274 Test RE 0.09658482897380367\n",
      "46 Train Loss 126485.53 Test MSE 45073.20957736214 Test RE 0.09489559777323418\n",
      "47 Train Loss 126265.16 Test MSE 43931.674458998634 Test RE 0.09368621685036307\n",
      "48 Train Loss 125970.44 Test MSE 35913.00712449464 Test RE 0.08470571437803508\n",
      "49 Train Loss 125689.305 Test MSE 27366.123810657347 Test RE 0.07394238718447547\n",
      "50 Train Loss 125521.02 Test MSE 25768.5099860643 Test RE 0.07175158137426116\n",
      "51 Train Loss 125298.54 Test MSE 25158.751589723695 Test RE 0.07089757279085268\n",
      "52 Train Loss 125121.26 Test MSE 19418.920818311282 Test RE 0.06228728040896451\n",
      "53 Train Loss 124985.484 Test MSE 17183.985635420708 Test RE 0.05859341006404715\n",
      "54 Train Loss 124828.555 Test MSE 16466.37532142334 Test RE 0.05735692086551083\n",
      "55 Train Loss 124667.63 Test MSE 14209.42394336679 Test RE 0.05328133030187395\n",
      "56 Train Loss 124478.68 Test MSE 11485.159927226654 Test RE 0.047902187588317206\n",
      "57 Train Loss 124352.39 Test MSE 10444.773461369736 Test RE 0.04568107716977555\n",
      "58 Train Loss 124322.32 Test MSE 10870.623447603455 Test RE 0.046603018793134096\n",
      "59 Train Loss 124274.23 Test MSE 10963.505131734759 Test RE 0.04680169001276624\n",
      "60 Train Loss 124159.42 Test MSE 10539.575328537094 Test RE 0.04588792076450678\n",
      "61 Train Loss 124101.43 Test MSE 10063.822759756089 Test RE 0.04484027975120423\n",
      "62 Train Loss 123948.64 Test MSE 9048.844529271146 Test RE 0.04251903378478838\n",
      "63 Train Loss 123823.836 Test MSE 6688.091091559704 Test RE 0.036554253005819\n",
      "64 Train Loss 123764.94 Test MSE 4477.32923410089 Test RE 0.02990861753044947\n",
      "65 Train Loss 123719.51 Test MSE 3350.2736377892898 Test RE 0.02587181896628031\n",
      "66 Train Loss 123681.41 Test MSE 3711.926334008278 Test RE 0.027232436399171514\n",
      "67 Train Loss 123636.42 Test MSE 4610.39353491458 Test RE 0.030349799227455256\n",
      "68 Train Loss 123591.625 Test MSE 4891.313995186797 Test RE 0.031260764530576884\n",
      "69 Train Loss 123550.6 Test MSE 4944.988167791532 Test RE 0.03143181444845585\n",
      "70 Train Loss 123528.234 Test MSE 5510.342542691163 Test RE 0.03317998017156581\n",
      "71 Train Loss 123463.47 Test MSE 7536.517888787042 Test RE 0.03880361534401902\n",
      "72 Train Loss 123366.234 Test MSE 8563.752987579546 Test RE 0.04136365333355568\n",
      "73 Train Loss 123318.87 Test MSE 6987.303042061004 Test RE 0.03736298910282376\n",
      "74 Train Loss 123249.35 Test MSE 4621.797413849616 Test RE 0.030387311391383134\n",
      "75 Train Loss 123212.24 Test MSE 4427.590747838015 Test RE 0.029742026707853655\n",
      "76 Train Loss 123171.61 Test MSE 5157.819174370665 Test RE 0.03210109743571397\n",
      "77 Train Loss 123123.266 Test MSE 4938.447025810465 Test RE 0.03141101884793613\n",
      "78 Train Loss 123050.83 Test MSE 3028.1527945630123 Test RE 0.02459663611373664\n",
      "79 Train Loss 123002.555 Test MSE 2096.5224750909215 Test RE 0.020466170361367914\n",
      "80 Train Loss 122974.82 Test MSE 2140.1937420692934 Test RE 0.020678230332638287\n",
      "81 Train Loss 122950.375 Test MSE 2290.9317304830156 Test RE 0.021394044626712985\n",
      "82 Train Loss 122938.26 Test MSE 2053.064164526489 Test RE 0.02025294041327364\n",
      "83 Train Loss 122930.914 Test MSE 1959.6214721978522 Test RE 0.019786679462803103\n",
      "84 Train Loss 122921.15 Test MSE 1856.9363833779475 Test RE 0.019261288507579202\n",
      "85 Train Loss 122901.81 Test MSE 1584.3990141307102 Test RE 0.017791767940672398\n",
      "86 Train Loss 122887.54 Test MSE 1395.262594341657 Test RE 0.01669609085412146\n",
      "87 Train Loss 122854.234 Test MSE 1368.601443285348 Test RE 0.01653580417339409\n",
      "88 Train Loss 122797.51 Test MSE 1832.185372090713 Test RE 0.0191324915147224\n",
      "89 Train Loss 122774.65 Test MSE 2075.4744155841618 Test RE 0.020363176039504553\n",
      "90 Train Loss 122757.95 Test MSE 2066.7076527611157 Test RE 0.020320123702207753\n",
      "91 Train Loss 122728.875 Test MSE 2116.5716512431277 Test RE 0.02056379715046731\n",
      "92 Train Loss 122693.16 Test MSE 2653.215756139952 Test RE 0.023023593428920124\n",
      "93 Train Loss 122674.64 Test MSE 3383.469490462835 Test RE 0.025999677200092077\n",
      "94 Train Loss 122662.44 Test MSE 3412.143010110922 Test RE 0.026109613089549927\n",
      "95 Train Loss 122652.945 Test MSE 2984.0953325329897 Test RE 0.024417048752680727\n",
      "96 Train Loss 122638.24 Test MSE 3016.34012762823 Test RE 0.02454861413452479\n",
      "97 Train Loss 122624.72 Test MSE 3422.8596016596734 Test RE 0.026150582460446544\n",
      "98 Train Loss 122611.3 Test MSE 3320.7246123049727 Test RE 0.02575747305494188\n",
      "99 Train Loss 122596.39 Test MSE 2894.860251132095 Test RE 0.024049199507788187\n",
      "100 Train Loss 122588.47 Test MSE 2761.576489867068 Test RE 0.023489045114856125\n",
      "101 Train Loss 122578.26 Test MSE 2655.18071724371 Test RE 0.023032117442152868\n",
      "102 Train Loss 122554.14 Test MSE 1864.7912350883364 Test RE 0.019301983199547266\n",
      "103 Train Loss 122536.42 Test MSE 1454.8342143478103 Test RE 0.017048790603478015\n",
      "104 Train Loss 122526.23 Test MSE 1353.1865070463132 Test RE 0.016442416800938078\n",
      "105 Train Loss 122507.195 Test MSE 1309.836270086815 Test RE 0.016176901075281018\n",
      "106 Train Loss 122481.0 Test MSE 1368.0648051704131 Test RE 0.016532561953806098\n",
      "107 Train Loss 122447.05 Test MSE 1633.3513547284608 Test RE 0.01806452856678925\n",
      "108 Train Loss 122431.68 Test MSE 1632.738617739504 Test RE 0.018061139876690776\n",
      "109 Train Loss 122394.41 Test MSE 1760.667247703202 Test RE 0.018755362666865685\n",
      "110 Train Loss 122377.836 Test MSE 1750.574814937675 Test RE 0.01870153100913801\n",
      "111 Train Loss 122353.37 Test MSE 1791.1542091709614 Test RE 0.018917045683741175\n",
      "112 Train Loss 122322.47 Test MSE 1822.6543512615979 Test RE 0.019082663056975945\n",
      "113 Train Loss 122300.266 Test MSE 1928.0361460670981 Test RE 0.01962657008503822\n",
      "114 Train Loss 122283.84 Test MSE 1835.5529523070802 Test RE 0.019150066325161644\n",
      "115 Train Loss 122261.22 Test MSE 1937.8042772353492 Test RE 0.019676224937257698\n",
      "116 Train Loss 122223.85 Test MSE 2141.3574105686016 Test RE 0.020683851163789922\n",
      "117 Train Loss 122203.98 Test MSE 2047.0044311817571 Test RE 0.020223029484630985\n",
      "118 Train Loss 122182.305 Test MSE 2291.504037672983 Test RE 0.021396716727504105\n",
      "119 Train Loss 122165.34 Test MSE 2269.0473212206057 Test RE 0.021291614789999722\n",
      "120 Train Loss 122152.72 Test MSE 1883.891000002146 Test RE 0.01940057980042888\n",
      "121 Train Loss 122139.18 Test MSE 1585.833891836893 Test RE 0.017799822488045413\n",
      "122 Train Loss 122122.93 Test MSE 1516.6316476655527 Test RE 0.017407118297207154\n",
      "123 Train Loss 122099.266 Test MSE 1497.5535548405771 Test RE 0.017297287536529968\n",
      "124 Train Loss 122080.15 Test MSE 1442.8161347406499 Test RE 0.016978226334545432\n",
      "125 Train Loss 122042.414 Test MSE 1342.9761870707787 Test RE 0.016380267119176502\n",
      "126 Train Loss 122019.1 Test MSE 1398.29296726126 Test RE 0.016714212152412988\n",
      "127 Train Loss 122015.71 Test MSE 1409.5053899937182 Test RE 0.01678109106405085\n",
      "128 Train Loss 122011.31 Test MSE 1463.8039734524925 Test RE 0.017101266877102304\n",
      "129 Train Loss 122007.56 Test MSE 1539.2561582218343 Test RE 0.01753647391412013\n",
      "130 Train Loss 122004.75 Test MSE 1584.4541601229698 Test RE 0.017792077564747898\n",
      "131 Train Loss 122002.39 Test MSE 1582.7666551859998 Test RE 0.017782600415460887\n",
      "132 Train Loss 122001.3 Test MSE 1591.642545526911 Test RE 0.017832391630417162\n",
      "133 Train Loss 122000.31 Test MSE 1602.5704315466296 Test RE 0.01789350365657506\n",
      "134 Train Loss 121997.555 Test MSE 1648.954335054618 Test RE 0.018150606355297444\n",
      "135 Train Loss 121994.56 Test MSE 1680.6410576402996 Test RE 0.018324169828913012\n",
      "136 Train Loss 121989.02 Test MSE 1739.0727563220755 Test RE 0.018639991049403115\n",
      "137 Train Loss 121985.91 Test MSE 1767.0907782654215 Test RE 0.01878954458315674\n",
      "138 Train Loss 121969.25 Test MSE 1819.4281710566017 Test RE 0.019065766990884577\n",
      "139 Train Loss 121946.22 Test MSE 1580.2226191000282 Test RE 0.017768303370971333\n",
      "140 Train Loss 121934.336 Test MSE 1465.2558749477062 Test RE 0.017109745881663356\n",
      "141 Train Loss 121903.055 Test MSE 1439.2877862861094 Test RE 0.016957453844576628\n",
      "142 Train Loss 121882.945 Test MSE 1556.2330161076081 Test RE 0.01763291589612834\n",
      "143 Train Loss 121860.14 Test MSE 1602.3954990050868 Test RE 0.01789252702508518\n",
      "144 Train Loss 121844.32 Test MSE 1547.730130089016 Test RE 0.017584678893621652\n",
      "145 Train Loss 121836.56 Test MSE 1534.6440591873045 Test RE 0.017510181789055734\n",
      "146 Train Loss 121826.24 Test MSE 1556.8693641103323 Test RE 0.017636520601815142\n",
      "147 Train Loss 121811.05 Test MSE 1517.6124213256683 Test RE 0.017412745795468074\n",
      "148 Train Loss 121806.08 Test MSE 1536.776557949287 Test RE 0.01752234339681053\n",
      "149 Train Loss 121799.16 Test MSE 1571.8711058783613 Test RE 0.017721288221765424\n",
      "150 Train Loss 121793.32 Test MSE 1665.4857220750646 Test RE 0.018241362781341367\n",
      "151 Train Loss 121792.24 Test MSE 1668.226136166285 Test RE 0.018256363913064875\n",
      "152 Train Loss 121783.836 Test MSE 1639.3238436769188 Test RE 0.01809752567711312\n",
      "153 Train Loss 121772.02 Test MSE 1576.8670302595176 Test RE 0.017749427927179484\n",
      "154 Train Loss 121763.35 Test MSE 1537.4668643057532 Test RE 0.017526278395343556\n",
      "155 Train Loss 121756.016 Test MSE 1537.7607561858895 Test RE 0.017527953418364512\n",
      "156 Train Loss 121733.35 Test MSE 1612.6862225382124 Test RE 0.017949888760844378\n",
      "157 Train Loss 121710.61 Test MSE 1677.673434451806 Test RE 0.018307984559146825\n",
      "158 Train Loss 121693.94 Test MSE 1727.530869360226 Test RE 0.018578033083575696\n",
      "159 Train Loss 121663.11 Test MSE 1773.8984680108897 Test RE 0.01882570300585968\n",
      "160 Train Loss 121636.84 Test MSE 1792.4521367205848 Test RE 0.018923898390300925\n",
      "161 Train Loss 121610.984 Test MSE 1812.6982454531417 Test RE 0.019030472916422077\n",
      "162 Train Loss 121574.195 Test MSE 1720.484037219033 Test RE 0.018540103208551637\n",
      "163 Train Loss 121539.94 Test MSE 1504.251904349534 Test RE 0.017335928560736232\n",
      "164 Train Loss 121515.195 Test MSE 1410.7239338869172 Test RE 0.016788343281234457\n",
      "165 Train Loss 121512.11 Test MSE 1412.9272221087438 Test RE 0.016801448300116283\n",
      "166 Train Loss 121503.37 Test MSE 1424.741900941879 Test RE 0.01687154762090139\n",
      "167 Train Loss 121492.69 Test MSE 1472.424426902193 Test RE 0.017151548291676318\n",
      "168 Train Loss 121481.25 Test MSE 1480.6741526406834 Test RE 0.01719952967755493\n",
      "169 Train Loss 121469.6 Test MSE 1552.193549642445 Test RE 0.01761001641623032\n",
      "170 Train Loss 121460.4 Test MSE 1623.0250944275151 Test RE 0.01800733487409634\n",
      "171 Train Loss 121454.8 Test MSE 1659.7261181772249 Test RE 0.01820979420865578\n",
      "172 Train Loss 121439.7 Test MSE 1711.0302176684647 Test RE 0.01848909540266373\n",
      "173 Train Loss 121404.695 Test MSE 1827.8475185608759 Test RE 0.019109829198684845\n",
      "174 Train Loss 121365.44 Test MSE 1683.4456554460273 Test RE 0.01833945283769335\n",
      "175 Train Loss 121360.82 Test MSE 1660.1932854114245 Test RE 0.01821235680635305\n",
      "176 Train Loss 121357.664 Test MSE 1634.0853392209594 Test RE 0.018068586969336557\n",
      "177 Train Loss 121348.79 Test MSE 1580.0355482541138 Test RE 0.017767251610959284\n",
      "178 Train Loss 121331.53 Test MSE 1583.1662414548068 Test RE 0.01778484497706658\n",
      "179 Train Loss 121326.05 Test MSE 1599.5096194248279 Test RE 0.017876407737413592\n",
      "180 Train Loss 121321.87 Test MSE 1605.9204563079502 Test RE 0.017912196247291137\n",
      "181 Train Loss 121316.555 Test MSE 1576.2735083608359 Test RE 0.017746087231533314\n",
      "182 Train Loss 121300.53 Test MSE 1508.668216608978 Test RE 0.01736135806574362\n",
      "183 Train Loss 121268.66 Test MSE 1562.7324760377874 Test RE 0.01766969863358336\n",
      "184 Train Loss 121257.17 Test MSE 1683.6551167171438 Test RE 0.018340593737492257\n",
      "185 Train Loss 121243.97 Test MSE 1758.0290825698019 Test RE 0.018741305981027755\n",
      "186 Train Loss 121229.19 Test MSE 1639.286990776429 Test RE 0.01809732225481074\n",
      "187 Train Loss 121209.35 Test MSE 1589.2675280388844 Test RE 0.017819082092673418\n",
      "188 Train Loss 121185.18 Test MSE 1641.767794386182 Test RE 0.018111010806523727\n",
      "189 Train Loss 121179.68 Test MSE 1647.3524570199786 Test RE 0.018141788002448995\n",
      "190 Train Loss 121173.04 Test MSE 1615.2214149916094 Test RE 0.017963992109517834\n",
      "191 Train Loss 121162.375 Test MSE 1583.184350813655 Test RE 0.01778494669450165\n",
      "192 Train Loss 121158.09 Test MSE 1594.2320171847448 Test RE 0.01784689165329559\n",
      "193 Train Loss 121154.336 Test MSE 1610.042404926419 Test RE 0.017935169314147435\n",
      "194 Train Loss 121146.3 Test MSE 1642.2678511861127 Test RE 0.01811376876188859\n",
      "195 Train Loss 121128.02 Test MSE 1729.8800790500045 Test RE 0.018590660605549793\n",
      "196 Train Loss 121113.92 Test MSE 1831.008950895175 Test RE 0.01912634817272126\n",
      "197 Train Loss 121094.22 Test MSE 1911.7971385650308 Test RE 0.019543742291023958\n",
      "198 Train Loss 121055.984 Test MSE 2114.651439507794 Test RE 0.02055446701403193\n",
      "199 Train Loss 121032.51 Test MSE 2127.243385538182 Test RE 0.020615573204534565\n",
      "Training time: 71.00\n",
      "Training time: 71.00\n",
      "1D_FODE_rowdyhigh\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 457320.94 Test MSE 5014763.148542064 Test RE 1.000949199375294\n",
      "1 Train Loss 453904.9 Test MSE 5037559.808409731 Test RE 1.0032217319021401\n",
      "2 Train Loss 443284.47 Test MSE 5007914.282065408 Test RE 1.0002654472740748\n",
      "3 Train Loss 429066.56 Test MSE 4908499.9369054735 Test RE 0.9902873207028814\n",
      "4 Train Loss 402909.88 Test MSE 4980611.692942701 Test RE 0.9975350530082947\n",
      "5 Train Loss 373748.2 Test MSE 4884669.2198240515 Test RE 0.9878804784339232\n",
      "6 Train Loss 345176.56 Test MSE 4717145.057245151 Test RE 0.9707925601812033\n",
      "7 Train Loss 321665.78 Test MSE 4767220.666377985 Test RE 0.9759317591706663\n",
      "8 Train Loss 298622.1 Test MSE 4848538.775591647 Test RE 0.984220168393594\n",
      "9 Train Loss 280679.78 Test MSE 4661536.304601564 Test RE 0.9650534310388459\n",
      "10 Train Loss 248887.05 Test MSE 4055377.5207409975 Test RE 0.9001242631433602\n",
      "11 Train Loss 232328.19 Test MSE 3862620.774066606 Test RE 0.8784718706430711\n",
      "12 Train Loss 226457.53 Test MSE 3932988.992345799 Test RE 0.8864376405690907\n",
      "13 Train Loss 217273.47 Test MSE 3868325.9035382355 Test RE 0.8791203871296195\n",
      "14 Train Loss 214670.33 Test MSE 3900350.091802751 Test RE 0.8827518145964525\n",
      "15 Train Loss 207420.17 Test MSE 3822641.1956744003 Test RE 0.8739137882969632\n",
      "16 Train Loss 204119.22 Test MSE 3734526.7168209488 Test RE 0.8637829135157643\n",
      "17 Train Loss 200567.06 Test MSE 3741862.0711834594 Test RE 0.8646308182073138\n",
      "18 Train Loss 197282.92 Test MSE 3684920.7168094427 Test RE 0.8580268883967705\n",
      "19 Train Loss 195439.33 Test MSE 3546133.8689776366 Test RE 0.8417136824604318\n",
      "20 Train Loss 192973.44 Test MSE 3558696.3920797086 Test RE 0.8432032905273776\n",
      "21 Train Loss 190238.66 Test MSE 3496905.8329299376 Test RE 0.835850857614071\n",
      "22 Train Loss 187184.75 Test MSE 3479574.164130768 Test RE 0.8337769263170599\n",
      "23 Train Loss 183459.38 Test MSE 3431402.5801030844 Test RE 0.8279853647815795\n",
      "24 Train Loss 181169.83 Test MSE 3365949.6452745837 Test RE 0.8200505627346274\n",
      "25 Train Loss 180948.08 Test MSE 3365380.5307387216 Test RE 0.8199812327573902\n",
      "26 Train Loss 180118.14 Test MSE 3331795.169962663 Test RE 0.8158794055394245\n",
      "27 Train Loss 179120.31 Test MSE 3296502.629563475 Test RE 0.8115467388596287\n",
      "28 Train Loss 177495.94 Test MSE 3300107.402526559 Test RE 0.8119903366289926\n",
      "29 Train Loss 176343.1 Test MSE 3270375.6774980715 Test RE 0.8083243203055192\n",
      "30 Train Loss 174688.19 Test MSE 3194240.2056487673 Test RE 0.7988598778035071\n",
      "31 Train Loss 171898.17 Test MSE 3062383.7185730287 Test RE 0.7821978668159857\n",
      "32 Train Loss 167819.44 Test MSE 2943623.7932640305 Test RE 0.7668809965139113\n",
      "33 Train Loss 166262.28 Test MSE 2870849.915267398 Test RE 0.7573420449591198\n",
      "34 Train Loss 164988.31 Test MSE 2838174.03458986 Test RE 0.7530196945360187\n",
      "35 Train Loss 162908.31 Test MSE 2774676.4895337196 Test RE 0.7445485133562888\n",
      "36 Train Loss 158197.73 Test MSE 2541265.2075398276 Test RE 0.7125442157534129\n",
      "37 Train Loss 155968.45 Test MSE 2437288.397020303 Test RE 0.6978149734657021\n",
      "38 Train Loss 155644.97 Test MSE 2387927.123054708 Test RE 0.6907125672293091\n",
      "39 Train Loss 154770.22 Test MSE 2344834.954715989 Test RE 0.6844519473199588\n",
      "40 Train Loss 153077.27 Test MSE 2344880.4796035322 Test RE 0.6844585915928594\n",
      "41 Train Loss 152102.67 Test MSE 2253493.4834518787 Test RE 0.6709883455250277\n",
      "42 Train Loss 151597.88 Test MSE 2220626.1032282976 Test RE 0.6660771632785045\n",
      "43 Train Loss 151162.0 Test MSE 2234015.249188791 Test RE 0.6680821837912264\n",
      "44 Train Loss 150206.11 Test MSE 2171425.05080089 Test RE 0.6586568996302086\n",
      "45 Train Loss 149435.61 Test MSE 2089132.3364296998 Test RE 0.6460554572139594\n",
      "46 Train Loss 148546.16 Test MSE 2053085.534607407 Test RE 0.6404575434102564\n",
      "47 Train Loss 147733.14 Test MSE 2012547.7492254144 Test RE 0.6341031640250617\n",
      "48 Train Loss 147396.0 Test MSE 2000420.552215759 Test RE 0.6321897899298596\n",
      "49 Train Loss 146850.1 Test MSE 2008024.5697727238 Test RE 0.6333901931755337\n",
      "50 Train Loss 145589.86 Test MSE 1957164.4674397502 Test RE 0.6253173588631966\n",
      "51 Train Loss 145148.52 Test MSE 1920845.9299437576 Test RE 0.6194882729745623\n",
      "52 Train Loss 144358.7 Test MSE 1918215.4295327717 Test RE 0.6190639488747453\n",
      "53 Train Loss 142911.62 Test MSE 1900892.2304307693 Test RE 0.6162622588162839\n",
      "54 Train Loss 142518.64 Test MSE 1859310.6607876567 Test RE 0.609484693611847\n",
      "55 Train Loss 142157.12 Test MSE 1828451.867165685 Test RE 0.6044057534330547\n",
      "56 Train Loss 141828.23 Test MSE 1799851.9284784126 Test RE 0.5996601823889589\n",
      "57 Train Loss 140953.03 Test MSE 1728145.6429086854 Test RE 0.5875935149689095\n",
      "58 Train Loss 140201.66 Test MSE 1715535.1381442216 Test RE 0.5854457162404472\n",
      "59 Train Loss 138984.73 Test MSE 1632474.4034371155 Test RE 0.571097177616926\n",
      "60 Train Loss 136869.56 Test MSE 1481852.2581585075 Test RE 0.5441132187114481\n",
      "61 Train Loss 135183.52 Test MSE 1406619.4102764153 Test RE 0.5301211442155922\n",
      "62 Train Loss 134559.02 Test MSE 1410804.3177981467 Test RE 0.5309091542123874\n",
      "63 Train Loss 133540.0 Test MSE 1376546.8942490227 Test RE 0.5244237227137072\n",
      "64 Train Loss 131696.75 Test MSE 1388706.8518355635 Test RE 0.526734922246563\n",
      "65 Train Loss 131177.2 Test MSE 1379909.9254044692 Test RE 0.5250639397115323\n",
      "66 Train Loss 130606.805 Test MSE 1360932.446887249 Test RE 0.5214409182465103\n",
      "67 Train Loss 130150.28 Test MSE 1338375.5735575054 Test RE 0.517101532131267\n",
      "68 Train Loss 128768.625 Test MSE 1245583.871251915 Test RE 0.49885383087582785\n",
      "69 Train Loss 126153.766 Test MSE 1107895.9917510613 Test RE 0.47047474899429476\n",
      "70 Train Loss 124288.836 Test MSE 1033923.038652219 Test RE 0.4544969048631611\n",
      "71 Train Loss 123157.67 Test MSE 978993.774248439 Test RE 0.44225911105501475\n",
      "72 Train Loss 121901.05 Test MSE 996579.9454076065 Test RE 0.4462136950402479\n",
      "73 Train Loss 119441.33 Test MSE 1010231.1580176256 Test RE 0.4492594314908591\n",
      "74 Train Loss 118574.61 Test MSE 972329.5266827748 Test RE 0.4407512581891343\n",
      "75 Train Loss 117092.586 Test MSE 897634.6585654862 Test RE 0.4234836328782823\n",
      "76 Train Loss 114955.766 Test MSE 849992.5443972101 Test RE 0.4120921881187588\n",
      "77 Train Loss 113835.26 Test MSE 835616.2544695543 Test RE 0.40859238025495753\n",
      "78 Train Loss 112920.17 Test MSE 764438.1433193561 Test RE 0.39080309829408144\n",
      "79 Train Loss 112740.734 Test MSE 733672.9581350352 Test RE 0.3828583115169046\n",
      "80 Train Loss 112015.15 Test MSE 694688.0508850189 Test RE 0.3725475726184806\n",
      "81 Train Loss 110591.48 Test MSE 668541.9625691364 Test RE 0.3654695173020544\n",
      "82 Train Loss 108312.43 Test MSE 607130.6088074984 Test RE 0.3482794804781088\n",
      "83 Train Loss 107393.336 Test MSE 587780.6064894514 Test RE 0.3426844911071512\n",
      "84 Train Loss 107030.22 Test MSE 552900.1104863528 Test RE 0.3323610803730187\n",
      "85 Train Loss 104630.33 Test MSE 462098.90313650033 Test RE 0.30384653805783485\n",
      "86 Train Loss 102949.016 Test MSE 425522.00589529757 Test RE 0.291573356233783\n",
      "87 Train Loss 102672.67 Test MSE 397897.3750996769 Test RE 0.2819501699666264\n",
      "88 Train Loss 102101.62 Test MSE 380271.69940969336 Test RE 0.27563465929651854\n",
      "89 Train Loss 101715.23 Test MSE 394004.815894312 Test RE 0.2805676462439686\n",
      "90 Train Loss 100811.336 Test MSE 385521.51903943793 Test RE 0.2775307669950304\n",
      "91 Train Loss 99497.49 Test MSE 359613.43837580614 Test RE 0.2680431912581718\n",
      "92 Train Loss 97977.57 Test MSE 325158.87102769286 Test RE 0.25487933605470336\n",
      "93 Train Loss 97382.16 Test MSE 325241.8032156325 Test RE 0.25491183763355496\n",
      "94 Train Loss 97186.23 Test MSE 327276.06404453336 Test RE 0.25570778213330975\n",
      "95 Train Loss 96979.266 Test MSE 312853.9782100653 Test RE 0.2500101637440313\n",
      "96 Train Loss 96781.64 Test MSE 299467.8829168612 Test RE 0.24460309607582806\n",
      "97 Train Loss 96313.44 Test MSE 274643.96578464296 Test RE 0.23424582246685507\n",
      "98 Train Loss 95981.74 Test MSE 250820.0386956166 Test RE 0.2238555874696622\n",
      "99 Train Loss 95766.18 Test MSE 251603.2135912841 Test RE 0.22420480485020194\n",
      "100 Train Loss 95621.26 Test MSE 257161.55158570604 Test RE 0.2266678067375369\n",
      "101 Train Loss 95479.42 Test MSE 245909.5986812672 Test RE 0.22165348509748053\n",
      "102 Train Loss 95343.51 Test MSE 233821.00910074488 Test RE 0.21613673611240355\n",
      "103 Train Loss 95141.75 Test MSE 233161.6139252822 Test RE 0.21583175893603507\n",
      "104 Train Loss 94804.06 Test MSE 241065.5120078049 Test RE 0.21945948965872222\n",
      "105 Train Loss 94504.67 Test MSE 227716.28469664793 Test RE 0.21329656839310504\n",
      "106 Train Loss 94018.3 Test MSE 214015.82974484088 Test RE 0.20678059101628937\n",
      "107 Train Loss 93639.49 Test MSE 214897.95953261992 Test RE 0.20720630659064784\n",
      "108 Train Loss 92896.17 Test MSE 207878.3705127769 Test RE 0.2037940384854712\n",
      "109 Train Loss 92511.086 Test MSE 199443.07724402848 Test RE 0.1996164403711776\n",
      "110 Train Loss 92334.984 Test MSE 204184.7077649226 Test RE 0.2019753782296839\n",
      "111 Train Loss 92228.63 Test MSE 204468.75338031384 Test RE 0.20211581549080043\n",
      "112 Train Loss 92133.8 Test MSE 197686.7013451546 Test RE 0.19873554540162233\n",
      "113 Train Loss 92043.98 Test MSE 195232.11610157957 Test RE 0.19749788741327465\n",
      "114 Train Loss 91838.28 Test MSE 203877.9652493163 Test RE 0.20182360946599434\n",
      "115 Train Loss 91690.06 Test MSE 198121.26797517305 Test RE 0.19895386161918283\n",
      "116 Train Loss 91581.63 Test MSE 187354.9554663513 Test RE 0.19347257679121518\n",
      "117 Train Loss 91465.34 Test MSE 182639.34432940383 Test RE 0.1910222663387582\n",
      "118 Train Loss 91249.33 Test MSE 182090.31839422855 Test RE 0.190734937467567\n",
      "119 Train Loss 91113.62 Test MSE 181408.34146305226 Test RE 0.19037742573876004\n",
      "120 Train Loss 90866.86 Test MSE 167606.41307336325 Test RE 0.18299201509951837\n",
      "121 Train Loss 90705.27 Test MSE 160413.38070079035 Test RE 0.17902229465059866\n",
      "122 Train Loss 90537.81 Test MSE 158236.8192497735 Test RE 0.17780361883092094\n",
      "123 Train Loss 90465.195 Test MSE 159093.1441938721 Test RE 0.17828407666060986\n",
      "124 Train Loss 90371.76 Test MSE 161275.76697738198 Test RE 0.17950286375615754\n",
      "125 Train Loss 90242.84 Test MSE 154504.0157111842 Test RE 0.1756939105984883\n",
      "126 Train Loss 90143.16 Test MSE 151805.90102845477 Test RE 0.17415307637972638\n",
      "127 Train Loss 89966.4 Test MSE 149419.29052234927 Test RE 0.17277868273845093\n",
      "128 Train Loss 89820.01 Test MSE 146668.49267791567 Test RE 0.17118087344532373\n",
      "129 Train Loss 89440.945 Test MSE 138759.62962805523 Test RE 0.1665015917253134\n",
      "130 Train Loss 89007.516 Test MSE 123319.28591366796 Test RE 0.1569648192546966\n",
      "131 Train Loss 88561.46 Test MSE 111634.99680329223 Test RE 0.14934373404175225\n",
      "132 Train Loss 88099.82 Test MSE 108250.85427480719 Test RE 0.14706268465110048\n",
      "133 Train Loss 87628.4 Test MSE 107671.77425608621 Test RE 0.1466688066576372\n",
      "134 Train Loss 87234.28 Test MSE 105256.51697224239 Test RE 0.14501446377611696\n",
      "135 Train Loss 87024.42 Test MSE 104733.5921793192 Test RE 0.14465379215164342\n",
      "136 Train Loss 86961.12 Test MSE 103685.57545344772 Test RE 0.14392823340191715\n",
      "137 Train Loss 86889.1 Test MSE 100683.08271034059 Test RE 0.1418290114278108\n",
      "138 Train Loss 86800.54 Test MSE 97843.64794046809 Test RE 0.13981479871596786\n",
      "139 Train Loss 86732.72 Test MSE 99609.67016203898 Test RE 0.1410709447006576\n",
      "140 Train Loss 86700.29 Test MSE 101108.61564805474 Test RE 0.1421284126722138\n",
      "141 Train Loss 86484.82 Test MSE 102841.33043606405 Test RE 0.14334107819061143\n",
      "142 Train Loss 86255.69 Test MSE 106776.91607806113 Test RE 0.14605805411540834\n",
      "143 Train Loss 85975.92 Test MSE 117406.24053670364 Test RE 0.15315543548520152\n",
      "144 Train Loss 85683.15 Test MSE 123615.34109558191 Test RE 0.1571531206654593\n",
      "145 Train Loss 85575.58 Test MSE 117562.30514661252 Test RE 0.1532571941539006\n",
      "146 Train Loss 85533.52 Test MSE 114741.8474951218 Test RE 0.15140762350335962\n",
      "147 Train Loss 85458.32 Test MSE 114857.62994630427 Test RE 0.15148399461841855\n",
      "148 Train Loss 85367.055 Test MSE 116918.17530950291 Test RE 0.1528367655025344\n",
      "149 Train Loss 85194.29 Test MSE 118003.29894846663 Test RE 0.15354437043212527\n",
      "150 Train Loss 84776.84 Test MSE 114089.55659707249 Test RE 0.15097664483718692\n",
      "151 Train Loss 84468.83 Test MSE 110813.21505779264 Test RE 0.14879303464962532\n",
      "152 Train Loss 84127.195 Test MSE 107523.42327368169 Test RE 0.14656773113614213\n",
      "153 Train Loss 83982.37 Test MSE 107690.955238849 Test RE 0.14668187009321532\n",
      "154 Train Loss 83849.07 Test MSE 105475.17030561893 Test RE 0.14516500764211027\n",
      "155 Train Loss 83619.13 Test MSE 97197.80132600512 Test RE 0.13935258976591752\n",
      "156 Train Loss 83310.91 Test MSE 86358.73590321746 Test RE 0.13135298965066322\n",
      "157 Train Loss 83192.73 Test MSE 85611.73248584812 Test RE 0.13078365383957535\n",
      "158 Train Loss 83135.87 Test MSE 86584.89241530426 Test RE 0.13152487099160082\n",
      "159 Train Loss 82981.1 Test MSE 89145.46621907027 Test RE 0.13345549300166107\n",
      "160 Train Loss 82060.15 Test MSE 85730.13436994617 Test RE 0.13087406014420908\n",
      "161 Train Loss 81541.26 Test MSE 85381.22320717046 Test RE 0.1306074679082405\n",
      "162 Train Loss 80904.086 Test MSE 81380.65388699359 Test RE 0.12751092938326009\n",
      "163 Train Loss 80632.2 Test MSE 76420.06346599093 Test RE 0.12356359083162907\n",
      "164 Train Loss 80484.09 Test MSE 79282.57368419145 Test RE 0.12585651260294056\n",
      "165 Train Loss 80448.32 Test MSE 80098.01303427828 Test RE 0.12650208834234397\n",
      "166 Train Loss 80404.625 Test MSE 82313.81938680152 Test RE 0.12823990878288535\n",
      "167 Train Loss 80355.97 Test MSE 81454.56181336097 Test RE 0.12756881740224013\n",
      "168 Train Loss 80204.85 Test MSE 75509.00335218538 Test RE 0.12282483592825615\n",
      "169 Train Loss 80096.34 Test MSE 72063.55716021589 Test RE 0.11998989450757541\n",
      "170 Train Loss 79980.01 Test MSE 68488.1622636785 Test RE 0.11697541109712847\n",
      "171 Train Loss 79904.53 Test MSE 68385.69890668381 Test RE 0.1168878764112938\n",
      "172 Train Loss 79772.29 Test MSE 68071.3862761299 Test RE 0.1166189484855768\n",
      "173 Train Loss 79646.73 Test MSE 66663.22877985163 Test RE 0.11540642713560331\n",
      "174 Train Loss 79532.13 Test MSE 61662.41124081472 Test RE 0.11099337960959424\n",
      "175 Train Loss 79468.76 Test MSE 59140.32669162285 Test RE 0.10869978454720391\n",
      "176 Train Loss 79442.18 Test MSE 59454.48787276536 Test RE 0.10898811590534936\n",
      "177 Train Loss 79417.11 Test MSE 59642.47899211193 Test RE 0.10916028648606867\n",
      "178 Train Loss 79338.59 Test MSE 58397.02170770447 Test RE 0.10801452815210069\n",
      "179 Train Loss 79153.23 Test MSE 56033.118010757884 Test RE 0.10580573746538569\n",
      "180 Train Loss 78925.73 Test MSE 60447.21697158615 Test RE 0.1098942523964568\n",
      "181 Train Loss 78841.08 Test MSE 60515.20527455033 Test RE 0.10995603707714711\n",
      "182 Train Loss 78643.695 Test MSE 56680.657430220475 Test RE 0.10641534640993257\n",
      "183 Train Loss 78237.82 Test MSE 51290.258040537236 Test RE 0.10122884126772132\n",
      "184 Train Loss 78003.76 Test MSE 49864.178793996725 Test RE 0.09981163257389035\n",
      "185 Train Loss 77953.586 Test MSE 50003.863863464874 Test RE 0.09995133651280311\n",
      "186 Train Loss 77837.53 Test MSE 50334.53310821735 Test RE 0.10028127474238324\n",
      "187 Train Loss 77718.46 Test MSE 51275.816139806535 Test RE 0.10121458866052903\n",
      "188 Train Loss 77680.43 Test MSE 50419.98141335724 Test RE 0.10036635779446726\n",
      "189 Train Loss 77585.64 Test MSE 46613.760640292465 Test RE 0.09650368440133494\n",
      "190 Train Loss 77447.77 Test MSE 43401.89113524511 Test RE 0.0931196104037648\n",
      "191 Train Loss 77279.94 Test MSE 42023.97995342518 Test RE 0.09162952051523977\n",
      "192 Train Loss 77165.266 Test MSE 39094.59062827717 Test RE 0.08837820133251989\n",
      "193 Train Loss 77131.66 Test MSE 38555.89784160153 Test RE 0.08776719810725436\n",
      "194 Train Loss 77087.35 Test MSE 38484.244519186774 Test RE 0.0876856057149353\n",
      "195 Train Loss 77006.914 Test MSE 37771.19251992262 Test RE 0.08686947003018797\n",
      "196 Train Loss 76902.18 Test MSE 34818.44492767336 Test RE 0.08340488904812618\n",
      "197 Train Loss 76881.2 Test MSE 34369.77690520281 Test RE 0.08286577190537425\n",
      "198 Train Loss 76863.25 Test MSE 34694.23356084329 Test RE 0.08325598677477289\n",
      "199 Train Loss 76813.53 Test MSE 34686.17157185551 Test RE 0.08324631300802812\n",
      "Training time: 71.23\n",
      "Training time: 71.23\n",
      "1D_FODE_rowdyhigh\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 456736.16 Test MSE 5012925.125113511 Test RE 1.000765747372205\n",
      "1 Train Loss 450894.72 Test MSE 4970714.7343587335 Test RE 0.9965434607071245\n",
      "2 Train Loss 440820.5 Test MSE 4809356.67123448 Test RE 0.980235251885004\n",
      "3 Train Loss 431138.72 Test MSE 4586313.012204296 Test RE 0.9572352201092692\n",
      "4 Train Loss 410088.06 Test MSE 4400772.799220341 Test RE 0.9376727552642424\n",
      "5 Train Loss 392104.44 Test MSE 4105834.9828828294 Test RE 0.905706676109506\n",
      "6 Train Loss 366823.2 Test MSE 4298386.636869926 Test RE 0.9267008520978981\n",
      "7 Train Loss 341245.25 Test MSE 3919159.1085742507 Test RE 0.8848777422743216\n",
      "8 Train Loss 310475.44 Test MSE 3997221.37359952 Test RE 0.8936468402708133\n",
      "9 Train Loss 305888.94 Test MSE 3977090.891976004 Test RE 0.8913937441583193\n",
      "10 Train Loss 286656.6 Test MSE 3580805.7498061173 Test RE 0.8458185483444821\n",
      "11 Train Loss 264008.3 Test MSE 3920476.302851555 Test RE 0.8850264295244659\n",
      "12 Train Loss 235367.69 Test MSE 3355413.564750137 Test RE 0.8187660974881891\n",
      "13 Train Loss 207573.02 Test MSE 2728690.4693108895 Test RE 0.7383528586436678\n",
      "14 Train Loss 202051.45 Test MSE 2590799.272447899 Test RE 0.7194551187965544\n",
      "15 Train Loss 198157.98 Test MSE 2421823.876730219 Test RE 0.695597643320177\n",
      "16 Train Loss 192015.84 Test MSE 2186743.723092688 Test RE 0.66097611777275\n",
      "17 Train Loss 189880.47 Test MSE 2077921.8583499016 Test RE 0.6443197287790485\n",
      "18 Train Loss 188448.97 Test MSE 2039564.5718458965 Test RE 0.6383451357849834\n",
      "19 Train Loss 188401.89 Test MSE 2045734.7244766396 Test RE 0.6393099771564664\n",
      "20 Train Loss 188322.44 Test MSE 2054455.5666668206 Test RE 0.6406711976930848\n",
      "21 Train Loss 188059.23 Test MSE 2049873.7788028016 Test RE 0.639956395675536\n",
      "22 Train Loss 187945.47 Test MSE 2030706.5861079742 Test RE 0.6369574364237673\n",
      "23 Train Loss 187929.8 Test MSE 2026138.946761264 Test RE 0.6362406835150466\n",
      "24 Train Loss 187843.34 Test MSE 1999610.8369346764 Test RE 0.6320618304506641\n",
      "25 Train Loss 187143.77 Test MSE 1954304.472750521 Test RE 0.6248603052584586\n",
      "26 Train Loss 186654.11 Test MSE 1967518.3076059346 Test RE 0.626969211802426\n",
      "27 Train Loss 186607.06 Test MSE 1972457.1903002101 Test RE 0.6277556305565115\n",
      "28 Train Loss 186560.69 Test MSE 1977580.5137740676 Test RE 0.6285703781260736\n",
      "29 Train Loss 186512.39 Test MSE 1979737.935959259 Test RE 0.6289131510289057\n",
      "30 Train Loss 186353.83 Test MSE 1958306.1422573493 Test RE 0.6254997157914254\n",
      "31 Train Loss 186222.28 Test MSE 1920014.8925262447 Test RE 0.6193542503490465\n",
      "32 Train Loss 186190.81 Test MSE 1907388.9939662723 Test RE 0.6173144739356933\n",
      "33 Train Loss 186179.75 Test MSE 1902815.9224793015 Test RE 0.6165740069023377\n",
      "34 Train Loss 186156.52 Test MSE 1903261.5608484074 Test RE 0.6166462033102561\n",
      "35 Train Loss 186156.52 Test MSE 1903261.5608484074 Test RE 0.6166462033102561\n",
      "36 Train Loss 186156.52 Test MSE 1903261.5608484074 Test RE 0.6166462033102561\n",
      "37 Train Loss 186117.78 Test MSE 1919919.186272427 Test RE 0.6193388137985242\n",
      "38 Train Loss 185636.92 Test MSE 1948522.651036823 Test RE 0.6239352940749296\n",
      "39 Train Loss 184603.48 Test MSE 1957253.0776360915 Test RE 0.6253315142568076\n",
      "40 Train Loss 184104.95 Test MSE 1944221.2750322365 Test RE 0.6232462430512123\n",
      "41 Train Loss 183921.25 Test MSE 1930794.0642477798 Test RE 0.6210903780046027\n",
      "42 Train Loss 183897.16 Test MSE 1924352.6081200829 Test RE 0.6200534811007994\n",
      "43 Train Loss 183797.22 Test MSE 1890631.4450356797 Test RE 0.6145967538128487\n",
      "44 Train Loss 183591.02 Test MSE 1845867.072080372 Test RE 0.6072772824461037\n",
      "45 Train Loss 182139.28 Test MSE 1734096.286407204 Test RE 0.5886042963022773\n",
      "46 Train Loss 177385.98 Test MSE 1664687.2871201185 Test RE 0.5767042542217217\n",
      "47 Train Loss 176438.69 Test MSE 1618334.4369868047 Test RE 0.5686184687755379\n",
      "48 Train Loss 174898.7 Test MSE 1453388.1578261245 Test RE 0.5388620913322942\n",
      "49 Train Loss 171218.44 Test MSE 1259680.897887194 Test RE 0.5016688039784736\n",
      "50 Train Loss 168331.55 Test MSE 1099613.7257072811 Test RE 0.4687128928115305\n",
      "51 Train Loss 167869.94 Test MSE 1088962.7197358776 Test RE 0.4664373611672096\n",
      "52 Train Loss 166294.42 Test MSE 907546.4136647515 Test RE 0.4258152843816559\n",
      "53 Train Loss 165397.33 Test MSE 915389.97680626 Test RE 0.4276514018844941\n",
      "54 Train Loss 165255.56 Test MSE 914715.3097662026 Test RE 0.4274937775415513\n",
      "55 Train Loss 165157.67 Test MSE 904540.5646913273 Test RE 0.42510953645422084\n",
      "56 Train Loss 164803.81 Test MSE 880996.7252577322 Test RE 0.4195405765624882\n",
      "57 Train Loss 163876.36 Test MSE 848275.2335114733 Test RE 0.4116756855162957\n",
      "58 Train Loss 163768.73 Test MSE 833015.6488030021 Test RE 0.40795607400236156\n",
      "59 Train Loss 163606.94 Test MSE 836542.7811606614 Test RE 0.40881883998610635\n",
      "60 Train Loss 163119.77 Test MSE 890381.053941883 Test RE 0.42176911928247246\n",
      "61 Train Loss 159011.12 Test MSE 674368.0919898049 Test RE 0.36705853784794\n",
      "62 Train Loss 154890.8 Test MSE 537140.3104021183 Test RE 0.32759004565129685\n",
      "63 Train Loss 153937.9 Test MSE 442223.33049756545 Test RE 0.2972402714012055\n",
      "64 Train Loss 153340.45 Test MSE 405143.39784172346 Test RE 0.2845058538869032\n",
      "65 Train Loss 152626.8 Test MSE 435499.8189187745 Test RE 0.29497201371033066\n",
      "66 Train Loss 152108.73 Test MSE 425108.8151096685 Test RE 0.2914317599324055\n",
      "67 Train Loss 151938.73 Test MSE 410082.5956832945 Test RE 0.28623483891103774\n",
      "68 Train Loss 151866.38 Test MSE 405079.03938925127 Test RE 0.28448325561207405\n",
      "69 Train Loss 151803.0 Test MSE 398432.43425075 Test RE 0.28213967779717253\n",
      "70 Train Loss 151778.84 Test MSE 390681.1011011321 Test RE 0.2793817447375627\n",
      "71 Train Loss 151661.39 Test MSE 358826.64013791963 Test RE 0.2677498048476587\n",
      "72 Train Loss 148916.61 Test MSE 38621.787638604685 Test RE 0.08784216062417295\n",
      "73 Train Loss 146340.95 Test MSE 39122.3734981345 Test RE 0.08840959907763146\n",
      "74 Train Loss 145670.95 Test MSE 55971.949707983134 Test RE 0.10574797051567826\n",
      "75 Train Loss 144449.38 Test MSE 37959.61170927961 Test RE 0.08708587189973019\n",
      "76 Train Loss 142778.94 Test MSE 20057.67745386318 Test RE 0.06330341586124409\n",
      "77 Train Loss 141406.78 Test MSE 37797.84259786044 Test RE 0.08690011070865289\n",
      "78 Train Loss 138737.12 Test MSE 33168.19100037272 Test RE 0.08140436941952178\n",
      "79 Train Loss 138000.3 Test MSE 43815.09056371859 Test RE 0.09356182414123694\n",
      "80 Train Loss 137871.45 Test MSE 43159.119108280975 Test RE 0.09285880911148238\n",
      "81 Train Loss 137771.4 Test MSE 28872.682340883337 Test RE 0.07595045676149703\n",
      "82 Train Loss 137671.22 Test MSE 23961.335461545266 Test RE 0.0691898411201886\n",
      "83 Train Loss 137631.03 Test MSE 26219.37384530841 Test RE 0.07237656733703492\n",
      "84 Train Loss 137583.11 Test MSE 31536.125293186265 Test RE 0.07937632536035637\n",
      "85 Train Loss 137366.55 Test MSE 29353.64748053624 Test RE 0.07658044061964611\n",
      "86 Train Loss 137005.75 Test MSE 19378.27451166498 Test RE 0.06222205860466241\n",
      "87 Train Loss 136778.98 Test MSE 25816.872873582386 Test RE 0.07181888225800401\n",
      "88 Train Loss 136493.11 Test MSE 29383.96911907182 Test RE 0.07661998332206285\n",
      "89 Train Loss 136271.6 Test MSE 24491.933833703213 Test RE 0.0699517143371385\n",
      "90 Train Loss 136001.66 Test MSE 25589.57213383546 Test RE 0.07150202405811487\n",
      "91 Train Loss 135692.78 Test MSE 22701.977355724604 Test RE 0.06734706390009838\n",
      "92 Train Loss 135469.19 Test MSE 19256.43005359732 Test RE 0.062026133833297865\n",
      "93 Train Loss 135122.03 Test MSE 13562.408474858785 Test RE 0.05205413497430129\n",
      "94 Train Loss 134855.38 Test MSE 12789.5678634496 Test RE 0.05054925496554582\n",
      "95 Train Loss 134498.38 Test MSE 16782.935939165633 Test RE 0.05790563014500523\n",
      "96 Train Loss 134316.12 Test MSE 16371.604747625544 Test RE 0.057191626682362134\n",
      "97 Train Loss 134245.77 Test MSE 15023.959203861434 Test RE 0.05478718938875434\n",
      "98 Train Loss 134217.64 Test MSE 14693.114060328993 Test RE 0.05418059232832643\n",
      "99 Train Loss 134205.03 Test MSE 14627.421980935258 Test RE 0.05405933746833625\n",
      "100 Train Loss 134179.77 Test MSE 14673.584259516898 Test RE 0.05414457246150053\n",
      "101 Train Loss 134018.02 Test MSE 15196.376567581987 Test RE 0.05510066586093891\n",
      "102 Train Loss 133805.19 Test MSE 14822.945525036257 Test RE 0.05441944144728818\n",
      "103 Train Loss 133644.12 Test MSE 16848.9930567738 Test RE 0.058019475618029476\n",
      "104 Train Loss 133315.45 Test MSE 17444.654815669895 Test RE 0.059036148134128684\n",
      "105 Train Loss 132858.25 Test MSE 16730.393840321427 Test RE 0.05781491692434499\n",
      "106 Train Loss 132012.4 Test MSE 18800.893868463016 Test RE 0.0612880879514566\n",
      "107 Train Loss 130444.21 Test MSE 6936.7766122958255 Test RE 0.037227654795990925\n",
      "108 Train Loss 128206.055 Test MSE 10667.283271654493 Test RE 0.04616509543145135\n",
      "109 Train Loss 127800.48 Test MSE 7261.600522523666 Test RE 0.0380893008042192\n",
      "110 Train Loss 127728.81 Test MSE 7663.061870625173 Test RE 0.03912803061874287\n",
      "111 Train Loss 127490.11 Test MSE 8381.29126753768 Test RE 0.04092062803048907\n",
      "112 Train Loss 127200.66 Test MSE 8126.395683734587 Test RE 0.040293575435768045\n",
      "113 Train Loss 127182.484 Test MSE 8542.563260152774 Test RE 0.04131244754824677\n",
      "114 Train Loss 127137.75 Test MSE 9109.891626198647 Test RE 0.04266221783605096\n",
      "115 Train Loss 126970.445 Test MSE 7859.245383782196 Test RE 0.03962572744074375\n",
      "116 Train Loss 126932.33 Test MSE 7423.546487143481 Test RE 0.038511686701665465\n",
      "117 Train Loss 126882.97 Test MSE 7071.351056503538 Test RE 0.03758703105664392\n",
      "118 Train Loss 126831.45 Test MSE 5805.013935327269 Test RE 0.03405559378753962\n",
      "119 Train Loss 126821.57 Test MSE 5247.233424997557 Test RE 0.032378148891096976\n",
      "120 Train Loss 126788.586 Test MSE 4748.304019079244 Test RE 0.030800380557075475\n",
      "121 Train Loss 126759.38 Test MSE 5200.78766686136 Test RE 0.0322345331860663\n",
      "122 Train Loss 126710.69 Test MSE 5462.41909580594 Test RE 0.03303538195522472\n",
      "123 Train Loss 126621.23 Test MSE 4482.4469995336985 Test RE 0.029925706018473396\n",
      "124 Train Loss 126546.22 Test MSE 3685.615821517381 Test RE 0.027135751623082082\n",
      "125 Train Loss 126514.766 Test MSE 3557.8557611599012 Test RE 0.026661279780671388\n",
      "126 Train Loss 126493.59 Test MSE 3412.537964909242 Test RE 0.02611112413679391\n",
      "127 Train Loss 126459.95 Test MSE 3128.0536167327173 Test RE 0.02499907375877322\n",
      "128 Train Loss 126432.09 Test MSE 3118.860498251944 Test RE 0.02496231151308769\n",
      "129 Train Loss 126394.14 Test MSE 2958.324210246791 Test RE 0.024311385366732108\n",
      "130 Train Loss 126383.51 Test MSE 3074.104673797442 Test RE 0.02478255902764782\n",
      "131 Train Loss 126369.3 Test MSE 3342.4047054862613 Test RE 0.02584141797579268\n",
      "132 Train Loss 126360.24 Test MSE 3375.9036970972106 Test RE 0.02597059192623543\n",
      "133 Train Loss 126355.16 Test MSE 3294.106161742403 Test RE 0.025654031245741945\n",
      "134 Train Loss 126344.15 Test MSE 3142.5072558664133 Test RE 0.02505676317278451\n",
      "135 Train Loss 126324.12 Test MSE 2995.886424199564 Test RE 0.024465240882826478\n",
      "136 Train Loss 126312.11 Test MSE 2891.0235824343736 Test RE 0.0240332575632608\n",
      "137 Train Loss 126302.22 Test MSE 2890.842628355719 Test RE 0.024032505410276045\n",
      "138 Train Loss 126296.97 Test MSE 2923.249695464525 Test RE 0.024166835182706622\n",
      "139 Train Loss 126294.82 Test MSE 2900.8392371813784 Test RE 0.02407402206350861\n",
      "140 Train Loss 126291.45 Test MSE 2878.329171196797 Test RE 0.023980434801362232\n",
      "141 Train Loss 126287.23 Test MSE 2900.896793430011 Test RE 0.024074260891553387\n",
      "142 Train Loss 126281.6 Test MSE 2980.0456903725253 Test RE 0.024400475240639374\n",
      "143 Train Loss 126277.29 Test MSE 2991.93951193317 Test RE 0.02444911978034837\n",
      "144 Train Loss 126274.85 Test MSE 2990.628476292511 Test RE 0.024443762523049327\n",
      "145 Train Loss 126272.78 Test MSE 2979.8062443271106 Test RE 0.024399494934416368\n",
      "146 Train Loss 126271.6 Test MSE 3019.2753416208266 Test RE 0.024560555412997367\n",
      "147 Train Loss 126271.31 Test MSE 3037.5190386426075 Test RE 0.024634646122629507\n",
      "148 Train Loss 126270.68 Test MSE 3074.5698453126065 Test RE 0.024784433997058607\n",
      "149 Train Loss 126267.78 Test MSE 3255.4135599121355 Test RE 0.02550291995066982\n",
      "150 Train Loss 126263.25 Test MSE 3025.078330256964 Test RE 0.02458414653854601\n",
      "151 Train Loss 126255.0 Test MSE 2891.5640020261326 Test RE 0.02403550372901542\n",
      "152 Train Loss 126247.28 Test MSE 2840.711868180134 Test RE 0.023823217541211056\n",
      "153 Train Loss 126236.305 Test MSE 2788.1810627315313 Test RE 0.02360191871017334\n",
      "154 Train Loss 126217.43 Test MSE 2919.275491321409 Test RE 0.0241504019984017\n",
      "155 Train Loss 126196.34 Test MSE 3138.143129577984 Test RE 0.02503935846034713\n",
      "156 Train Loss 126174.14 Test MSE 2974.986424746447 Test RE 0.02437975392659607\n",
      "157 Train Loss 126137.336 Test MSE 2641.1992729397716 Test RE 0.022971397035271998\n",
      "158 Train Loss 126038.19 Test MSE 2222.494270436152 Test RE 0.021072067494245065\n",
      "159 Train Loss 125928.37 Test MSE 2298.6230306551706 Test RE 0.021429927438021273\n",
      "160 Train Loss 125703.25 Test MSE 3714.4556542681376 Test RE 0.027241712960344007\n",
      "161 Train Loss 125583.65 Test MSE 3763.7721085829644 Test RE 0.02742195939684539\n",
      "162 Train Loss 125554.25 Test MSE 4471.439987996617 Test RE 0.02988894093763298\n",
      "163 Train Loss 125537.586 Test MSE 5211.021984406711 Test RE 0.03226623379877453\n",
      "164 Train Loss 125514.484 Test MSE 5934.1615212807665 Test RE 0.034432337395296594\n",
      "165 Train Loss 125468.26 Test MSE 6304.958491947764 Test RE 0.03549179297087659\n",
      "166 Train Loss 125346.28 Test MSE 3745.8336261243344 Test RE 0.02735653356281743\n",
      "167 Train Loss 124986.51 Test MSE 2532.313001188357 Test RE 0.022492903292077922\n",
      "168 Train Loss 124949.16 Test MSE 2501.0571724750134 Test RE 0.022353659609108834\n",
      "169 Train Loss 124928.62 Test MSE 2685.771344154951 Test RE 0.02316441524879094\n",
      "170 Train Loss 124915.03 Test MSE 2761.9362197051214 Test RE 0.023490574935825063\n",
      "171 Train Loss 124905.5 Test MSE 2505.6673026559524 Test RE 0.022374252068339\n",
      "172 Train Loss 124815.02 Test MSE 2308.2023475818773 Test RE 0.02147453471646901\n",
      "173 Train Loss 124681.18 Test MSE 4845.01773660208 Test RE 0.03111247132026451\n",
      "174 Train Loss 124653.58 Test MSE 5570.995420538835 Test RE 0.03336208806223447\n",
      "175 Train Loss 124646.16 Test MSE 6640.486700659671 Test RE 0.036423928038257766\n",
      "176 Train Loss 124642.68 Test MSE 7408.643944652161 Test RE 0.03847301176572422\n",
      "177 Train Loss 124641.41 Test MSE 7497.926565245944 Test RE 0.03870413937816097\n",
      "178 Train Loss 124639.82 Test MSE 7700.567539731941 Test RE 0.03922366678440523\n",
      "179 Train Loss 124636.74 Test MSE 7748.351501710452 Test RE 0.03934517494673069\n",
      "180 Train Loss 124626.04 Test MSE 7052.733660161042 Test RE 0.037537519029508006\n",
      "181 Train Loss 124618.51 Test MSE 6834.896509276775 Test RE 0.03695326319141832\n",
      "182 Train Loss 124617.66 Test MSE 6837.044759670235 Test RE 0.03695907005515608\n",
      "183 Train Loss 124613.96 Test MSE 7021.1952705488075 Test RE 0.0374534949166932\n",
      "184 Train Loss 124590.99 Test MSE 7656.921297847214 Test RE 0.03911235041962142\n",
      "185 Train Loss 124547.516 Test MSE 7636.317639373064 Test RE 0.039059692156550925\n",
      "186 Train Loss 124491.42 Test MSE 5660.117078049155 Test RE 0.03362788324803948\n",
      "187 Train Loss 124453.8 Test MSE 4558.647319185926 Test RE 0.030178998311355783\n",
      "188 Train Loss 124441.81 Test MSE 4242.881778756575 Test RE 0.029115033165343987\n",
      "189 Train Loss 124437.37 Test MSE 3792.769801492694 Test RE 0.02752739190152856\n",
      "190 Train Loss 124419.91 Test MSE 3092.664250632337 Test RE 0.02485725747069679\n",
      "191 Train Loss 124395.74 Test MSE 3270.4784077888785 Test RE 0.02556186087274309\n",
      "192 Train Loss 124222.09 Test MSE 2817.2941924434804 Test RE 0.0237248198655577\n",
      "193 Train Loss 124085.81 Test MSE 2378.269690181359 Test RE 0.021798036435815172\n",
      "194 Train Loss 124020.26 Test MSE 2451.3117984630458 Test RE 0.02213023885828614\n",
      "195 Train Loss 123951.91 Test MSE 2516.2981370126286 Test RE 0.022421665627841144\n",
      "196 Train Loss 123910.16 Test MSE 2899.8833134269817 Test RE 0.024070055138100482\n",
      "197 Train Loss 123855.664 Test MSE 2410.9995526759253 Test RE 0.021947516720249236\n",
      "198 Train Loss 123833.27 Test MSE 2341.6261476212576 Test RE 0.0216294563215911\n",
      "199 Train Loss 123826.336 Test MSE 2329.8348226905778 Test RE 0.021574929721782543\n",
      "Training time: 70.53\n",
      "Training time: 70.53\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "omega_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val =8.0\n",
    "rowdy_terms = 2\n",
    "\n",
    "for reps in range(max_reps):  \n",
    "  print(label) \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  alpha_val = []\n",
    "  omega_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.05, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  alpha_full.append(alpha_val)\n",
    "  omega_full.append(omega_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full,\"omega\": omega_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "77a1e198-62ae-4129-82a3-1a1f3e433466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1D_FODE_rowdyhigh'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d2yA4xTDHldi"
   },
   "outputs": [],
   "source": [
    "#3,4,8,9,13,14,18,19,23,24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "1986cfc6-aa7b-43ff-e3e8-c586ef7bafd1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24568/2033279215.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#  if tune_reps not in s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_rowdy_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(70):\n",
    "#  if tune_reps not in s:\n",
    "    label = \"1D_FODE_rowdy_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2eNXAFRRtWs",
    "outputId": "737b4c47-e8bf-4e68-c774-00d25a78ecb3"
   },
   "outputs": [],
   "source": [
    "lrnr_tune[2]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "atanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
