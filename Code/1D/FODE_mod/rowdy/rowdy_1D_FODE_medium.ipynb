{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "84a34ebd-2e54-4cae-ca1c-79397867998c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "94a6280c-bfd4-43c8-a396-40f22c70c38f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "150eeb9e-6cdc-4ff0-fd50-61a1c228e3a0"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/atanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "30d0ca6b-cde8-4b85-ccae-4eac06a2c482"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"medium\"\n",
    "label = \"1D_FODE_rowdy\" + level\n",
    "extent = 20.0\n",
    "\n",
    "x = np.linspace(extent,-1*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        self.omega1.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        self.omega.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "\n",
    "                      \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "       \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "      \n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    omega_val.append(PINN.omega.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,123)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(i)\n",
    "\n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "509236d6-c6b5-4579-8ffe-6c945b3ae573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D_FODE_rowdymedium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 16878.238 Test MSE 8504.513703303 Test RE 1.0274935279229043\n",
      "1 Train Loss 15402.701 Test MSE 8784.492067662884 Test RE 1.044269707057212\n",
      "2 Train Loss 11827.686 Test MSE 8041.501661774173 Test RE 0.999132141882987\n",
      "3 Train Loss 9281.6875 Test MSE 5532.749382827735 Test RE 0.8287525000998976\n",
      "4 Train Loss 6147.8257 Test MSE 1422.9111735707772 Test RE 0.4202843776772156\n",
      "5 Train Loss 4948.8916 Test MSE 112.25658977937562 Test RE 0.11804844609696179\n",
      "6 Train Loss 4826.7593 Test MSE 54.107630447720005 Test RE 0.08195653898802106\n",
      "7 Train Loss 4782.562 Test MSE 56.5234513118079 Test RE 0.08376617568107667\n",
      "8 Train Loss 4740.595 Test MSE 54.60215207678891 Test RE 0.08233021176168766\n",
      "9 Train Loss 4662.7812 Test MSE 53.35461611385159 Test RE 0.08138424747481465\n",
      "10 Train Loss 4642.589 Test MSE 49.80962866807568 Test RE 0.07863411519356606\n",
      "11 Train Loss 4635.5537 Test MSE 50.01708319141413 Test RE 0.07879769854982521\n",
      "12 Train Loss 4626.188 Test MSE 50.28376617130927 Test RE 0.0790074875591855\n",
      "13 Train Loss 4618.1626 Test MSE 50.18238341528244 Test RE 0.07892779943133732\n",
      "14 Train Loss 4596.9097 Test MSE 50.20750856486059 Test RE 0.07894755561342932\n",
      "15 Train Loss 4579.1445 Test MSE 62.25376210360833 Test RE 0.08790977190561906\n",
      "16 Train Loss 4563.2524 Test MSE 51.23445040403403 Test RE 0.07975086335552191\n",
      "17 Train Loss 4554.492 Test MSE 51.75519717905045 Test RE 0.08015513245349383\n",
      "18 Train Loss 4541.6157 Test MSE 49.48632213078743 Test RE 0.07837849883315585\n",
      "19 Train Loss 4524.5586 Test MSE 50.763395686850004 Test RE 0.07938339802626168\n",
      "20 Train Loss 4456.0103 Test MSE 64.60534959445205 Test RE 0.08955474318332117\n",
      "21 Train Loss 4371.5527 Test MSE 48.18721883856124 Test RE 0.07734286989861928\n",
      "22 Train Loss 4356.6567 Test MSE 45.308572901824306 Test RE 0.07499711271770033\n",
      "23 Train Loss 4315.8237 Test MSE 46.063388961448 Test RE 0.07561923780702967\n",
      "24 Train Loss 4294.0605 Test MSE 45.475801818278306 Test RE 0.07513538825706152\n",
      "25 Train Loss 4290.7764 Test MSE 45.98161954709445 Test RE 0.07555209025822682\n",
      "26 Train Loss 4285.2036 Test MSE 42.53703978872703 Test RE 0.0726671259978667\n",
      "27 Train Loss 4266.323 Test MSE 41.28174022445335 Test RE 0.07158686613042671\n",
      "28 Train Loss 4252.1797 Test MSE 42.29065398134424 Test RE 0.07245636673546053\n",
      "29 Train Loss 4237.46 Test MSE 42.19909675484336 Test RE 0.07237789196895501\n",
      "30 Train Loss 4228.6875 Test MSE 40.74187885967999 Test RE 0.07111723758068118\n",
      "31 Train Loss 4218.3765 Test MSE 40.90731129482612 Test RE 0.07126147711088097\n",
      "32 Train Loss 4178.6245 Test MSE 43.04908949057625 Test RE 0.07310319149230904\n",
      "33 Train Loss 4099.194 Test MSE 81.11510901901659 Test RE 0.10034719344610307\n",
      "34 Train Loss 4021.036 Test MSE 63.80914663697758 Test RE 0.08900119146689618\n",
      "35 Train Loss 3992.2783 Test MSE 64.66886835333709 Test RE 0.08959875663327946\n",
      "36 Train Loss 3941.113 Test MSE 103.12046405523998 Test RE 0.11314276339167226\n",
      "37 Train Loss 3866.8794 Test MSE 86.76626160666727 Test RE 0.10378385428386311\n",
      "38 Train Loss 3626.649 Test MSE 127.62271351577049 Test RE 0.1258688718072772\n",
      "39 Train Loss 3389.5737 Test MSE 384.9131393538265 Test RE 0.21859273328970405\n",
      "40 Train Loss 2967.9705 Test MSE 80.25945431941727 Test RE 0.09981652669141454\n",
      "41 Train Loss 2909.0398 Test MSE 55.576852400046214 Test RE 0.08306179760211892\n",
      "42 Train Loss 2692.207 Test MSE 82.24611532773169 Test RE 0.10104435349911893\n",
      "43 Train Loss 2633.8342 Test MSE 59.45972461427094 Test RE 0.08591436787616971\n",
      "44 Train Loss 2613.958 Test MSE 32.8806575489579 Test RE 0.06388878063067684\n",
      "45 Train Loss 2554.2715 Test MSE 30.862986894916382 Test RE 0.06189753150692628\n",
      "46 Train Loss 2488.4502 Test MSE 58.48561224850814 Test RE 0.08520770589520561\n",
      "47 Train Loss 2456.048 Test MSE 102.2714736068756 Test RE 0.11267604878809194\n",
      "48 Train Loss 2335.3386 Test MSE 67.32472334634936 Test RE 0.0914200892802168\n",
      "49 Train Loss 2260.4587 Test MSE 45.53977078333306 Test RE 0.07518821463727929\n",
      "50 Train Loss 2170.4446 Test MSE 35.46452688546221 Test RE 0.06635160576298463\n",
      "51 Train Loss 2137.7983 Test MSE 29.73835636634088 Test RE 0.06075930997730749\n",
      "52 Train Loss 2079.518 Test MSE 50.93236663712579 Test RE 0.07951540598720798\n",
      "53 Train Loss 2017.4354 Test MSE 69.36314175066475 Test RE 0.09279375095090361\n",
      "54 Train Loss 1909.2438 Test MSE 45.626922318830665 Test RE 0.07526012580588759\n",
      "55 Train Loss 1843.4353 Test MSE 36.30109636489454 Test RE 0.06712962532616372\n",
      "56 Train Loss 1799.2908 Test MSE 33.80850537300905 Test RE 0.06478393716083002\n",
      "57 Train Loss 1717.0211 Test MSE 29.120217254378833 Test RE 0.060124524913320286\n",
      "58 Train Loss 1679.3224 Test MSE 18.454509481988907 Test RE 0.047863627005563895\n",
      "59 Train Loss 1655.411 Test MSE 22.797557017391355 Test RE 0.053198392285590916\n",
      "60 Train Loss 1547.3533 Test MSE 27.05966702084497 Test RE 0.05795829171435569\n",
      "61 Train Loss 1424.0404 Test MSE 29.75799763279797 Test RE 0.06077937148975423\n",
      "62 Train Loss 1240.6713 Test MSE 20.794639104179137 Test RE 0.0508077597458322\n",
      "63 Train Loss 1186.254 Test MSE 18.744253567217203 Test RE 0.048237903866092925\n",
      "64 Train Loss 1123.4653 Test MSE 50.989069638420354 Test RE 0.07955965592357578\n",
      "65 Train Loss 979.1768 Test MSE 12.733107914500174 Test RE 0.03975772837117801\n",
      "66 Train Loss 942.87946 Test MSE 8.763811919166049 Test RE 0.032983814294159385\n",
      "67 Train Loss 919.5341 Test MSE 12.435316427496923 Test RE 0.039290067300754565\n",
      "68 Train Loss 848.7599 Test MSE 27.556912134146643 Test RE 0.058488384789157674\n",
      "69 Train Loss 765.57526 Test MSE 78.49359228791465 Test RE 0.09871234178544887\n",
      "70 Train Loss 722.0232 Test MSE 65.01312075226552 Test RE 0.08983692105281889\n",
      "71 Train Loss 654.26746 Test MSE 4.3188971524743405 Test RE 0.023154786634034957\n",
      "72 Train Loss 546.26044 Test MSE 11.093177813404624 Test RE 0.0371092638812487\n",
      "73 Train Loss 394.64957 Test MSE 24.218536001989982 Test RE 0.05483126881286917\n",
      "74 Train Loss 343.73404 Test MSE 11.233380259849062 Test RE 0.03734303249370353\n",
      "75 Train Loss 285.03436 Test MSE 28.452903269767035 Test RE 0.05943163061178223\n",
      "76 Train Loss 274.0432 Test MSE 37.26632637123667 Test RE 0.06801624373397686\n",
      "77 Train Loss 245.47466 Test MSE 12.323478631087275 Test RE 0.03911298942189609\n",
      "78 Train Loss 191.8345 Test MSE 14.3055261384921 Test RE 0.042141139031065575\n",
      "79 Train Loss 158.67131 Test MSE 2.4162129970204727 Test RE 0.017318966030912472\n",
      "80 Train Loss 151.21832 Test MSE 3.225218387816427 Test RE 0.020009393080363185\n",
      "81 Train Loss 134.23732 Test MSE 2.383712454249993 Test RE 0.01720209275664208\n",
      "82 Train Loss 87.2881 Test MSE 1.889526019663633 Test RE 0.01531548628450767\n",
      "83 Train Loss 59.87879 Test MSE 0.7909151089757306 Test RE 0.009908759517733321\n",
      "84 Train Loss 53.51575 Test MSE 2.4214634526964014 Test RE 0.017337772965134675\n",
      "85 Train Loss 51.40409 Test MSE 0.715638150342825 Test RE 0.009425428312266133\n",
      "86 Train Loss 48.993828 Test MSE 0.557433174345957 Test RE 0.008318609887358977\n",
      "87 Train Loss 47.86359 Test MSE 0.6045948971668922 Test RE 0.00866336457715117\n",
      "88 Train Loss 47.442204 Test MSE 0.31162880940362375 Test RE 0.0062197532050473825\n",
      "89 Train Loss 43.29198 Test MSE 0.4896240248203833 Test RE 0.007796249193594065\n",
      "90 Train Loss 35.467045 Test MSE 0.6340573993260358 Test RE 0.00887194089496166\n",
      "91 Train Loss 33.13631 Test MSE 1.6077184908337974 Test RE 0.014127306115721603\n",
      "92 Train Loss 32.12742 Test MSE 0.7890832110601815 Test RE 0.009897277654131368\n",
      "93 Train Loss 31.184618 Test MSE 0.2922314877961398 Test RE 0.006023069256001655\n",
      "94 Train Loss 28.856028 Test MSE 0.45979593345979136 Test RE 0.007555042562116621\n",
      "95 Train Loss 27.513706 Test MSE 0.315649744968192 Test RE 0.006259751223718709\n",
      "96 Train Loss 26.389284 Test MSE 0.13082879993639193 Test RE 0.0040300091408926875\n",
      "97 Train Loss 25.743204 Test MSE 0.09218827625066248 Test RE 0.003382923676653932\n",
      "98 Train Loss 25.289248 Test MSE 0.134634669584734 Test RE 0.004088206334157826\n",
      "99 Train Loss 24.378603 Test MSE 0.07285869306324307 Test RE 0.003007426627805979\n",
      "100 Train Loss 23.08726 Test MSE 0.4089520522528162 Test RE 0.007125093180484319\n",
      "101 Train Loss 21.348341 Test MSE 0.22095720119841253 Test RE 0.005237311828071068\n",
      "102 Train Loss 20.50363 Test MSE 0.3744736490990784 Test RE 0.006818125386603065\n",
      "103 Train Loss 19.845238 Test MSE 0.6174852897013607 Test RE 0.008755232032224338\n",
      "104 Train Loss 16.839582 Test MSE 0.6324427383412731 Test RE 0.008860637258709723\n",
      "105 Train Loss 15.692669 Test MSE 0.24439445182566624 Test RE 0.005508077263052202\n",
      "106 Train Loss 14.827421 Test MSE 0.09835056909036927 Test RE 0.0034941600259337916\n",
      "107 Train Loss 14.65659 Test MSE 0.15267450562734403 Test RE 0.0043534906247645905\n",
      "108 Train Loss 14.591911 Test MSE 0.13987639979660743 Test RE 0.004167029501907561\n",
      "109 Train Loss 14.543154 Test MSE 0.09791616315900732 Test RE 0.0034864347852128644\n",
      "110 Train Loss 14.414085 Test MSE 0.07475350573990004 Test RE 0.003046282213252437\n",
      "111 Train Loss 14.2235985 Test MSE 0.19449905546735413 Test RE 0.004913750495990901\n",
      "112 Train Loss 13.734225 Test MSE 0.2539586303332058 Test RE 0.005614820028707406\n",
      "113 Train Loss 12.321802 Test MSE 0.2778975243838394 Test RE 0.005873496189261327\n",
      "114 Train Loss 11.603009 Test MSE 0.12122273976954782 Test RE 0.003879237773560821\n",
      "115 Train Loss 11.426201 Test MSE 0.13348242129427818 Test RE 0.004070674628108449\n",
      "116 Train Loss 11.3755455 Test MSE 0.1011476769018458 Test RE 0.003543498952009914\n",
      "117 Train Loss 10.945354 Test MSE 0.05714722522184608 Test RE 0.002663495248736462\n",
      "118 Train Loss 9.087091 Test MSE 0.2902798592958314 Test RE 0.006002923437327339\n",
      "119 Train Loss 7.639113 Test MSE 0.10999684197790854 Test RE 0.0036952554032305706\n",
      "120 Train Loss 7.4618034 Test MSE 0.031717200044701084 Test RE 0.001984274599363666\n",
      "121 Train Loss 7.4360604 Test MSE 0.02741948983879932 Test RE 0.0018449476065111388\n",
      "122 Train Loss 7.4227347 Test MSE 0.028717804204101388 Test RE 0.001888121629888235\n",
      "123 Train Loss 7.3993344 Test MSE 0.04434140567165239 Test RE 0.002346167857476942\n",
      "124 Train Loss 7.340861 Test MSE 0.07947206394439686 Test RE 0.0031409541612337556\n",
      "125 Train Loss 7.122979 Test MSE 0.053412935675530265 Test RE 0.002575002034331657\n",
      "126 Train Loss 6.1498556 Test MSE 0.07341564000478125 Test RE 0.003018899440454379\n",
      "127 Train Loss 5.032957 Test MSE 0.054317325680694625 Test RE 0.002596710547426996\n",
      "128 Train Loss 4.825407 Test MSE 0.030796006565384785 Test RE 0.0019552466664531577\n",
      "129 Train Loss 4.6410904 Test MSE 0.035678469888187306 Test RE 0.0021045413481327094\n",
      "130 Train Loss 4.524781 Test MSE 0.06228067070290094 Test RE 0.00278055181693486\n",
      "131 Train Loss 4.4557004 Test MSE 0.05224295613430013 Test RE 0.0025466439154322256\n",
      "132 Train Loss 4.3847485 Test MSE 0.020558396718189913 Test RE 0.0015975298199508142\n",
      "133 Train Loss 4.289151 Test MSE 0.03708102338303639 Test RE 0.0021455083452534074\n",
      "134 Train Loss 4.201754 Test MSE 0.051541580183691586 Test RE 0.0025294914568416565\n",
      "135 Train Loss 4.1435657 Test MSE 0.022882981797416213 Test RE 0.0016854297670986951\n",
      "136 Train Loss 4.1125603 Test MSE 0.022047109586129647 Test RE 0.0016543606163651914\n",
      "137 Train Loss 4.0431094 Test MSE 0.03801293950239868 Test RE 0.002172301387419486\n",
      "138 Train Loss 3.8781996 Test MSE 0.05863597638908442 Test RE 0.0026979657554964498\n",
      "139 Train Loss 3.56394 Test MSE 0.0338200450107345 Test RE 0.0020489975682440836\n",
      "140 Train Loss 3.3796153 Test MSE 0.018063016628776792 Test RE 0.001497440218210047\n",
      "141 Train Loss 3.2835763 Test MSE 0.024270110619335837 Test RE 0.0017357622152426267\n",
      "142 Train Loss 3.1703348 Test MSE 0.06091182297578698 Test RE 0.0027498256013538088\n",
      "143 Train Loss 2.9616091 Test MSE 0.02336827749750538 Test RE 0.0017032080574126776\n",
      "144 Train Loss 2.759126 Test MSE 0.009254233563201304 Test RE 0.0010718267223004268\n",
      "145 Train Loss 2.7243278 Test MSE 0.009589641057503005 Test RE 0.0010910773198423277\n",
      "146 Train Loss 2.7220912 Test MSE 0.01075136760926883 Test RE 0.0011552772151000468\n",
      "147 Train Loss 2.7178602 Test MSE 0.009030105938679813 Test RE 0.0010587679225652607\n",
      "148 Train Loss 2.700807 Test MSE 0.005849159843638459 Test RE 0.000852120664230796\n",
      "149 Train Loss 2.6859221 Test MSE 0.006462424740785714 Test RE 0.0008956784012571142\n",
      "150 Train Loss 2.6654365 Test MSE 0.006191039926968555 Test RE 0.0008766700195800548\n",
      "151 Train Loss 2.6012003 Test MSE 0.006082591768401388 Test RE 0.0008689578027441095\n",
      "152 Train Loss 2.420155 Test MSE 0.005079683958054519 Test RE 0.000794095433693754\n",
      "153 Train Loss 2.1242445 Test MSE 0.00891578482237639 Test RE 0.0010520445759074999\n",
      "154 Train Loss 2.012533 Test MSE 0.01101841105029026 Test RE 0.0011695366538618664\n",
      "155 Train Loss 1.9776739 Test MSE 0.005084852114589697 Test RE 0.0007944992940714432\n",
      "156 Train Loss 1.9337817 Test MSE 0.004575252081833508 Test RE 0.0007536363994020951\n",
      "157 Train Loss 1.91889 Test MSE 0.005284308313024475 Test RE 0.0008099317549290583\n",
      "158 Train Loss 1.9072127 Test MSE 0.007828860452023943 Test RE 0.0009858336278094932\n",
      "159 Train Loss 1.8937174 Test MSE 0.006539767665833893 Test RE 0.0009010222428257858\n",
      "160 Train Loss 1.8848368 Test MSE 0.006592653020186881 Test RE 0.0009046580702431927\n",
      "161 Train Loss 1.8209019 Test MSE 0.01261556353177383 Test RE 0.0012514332213839413\n",
      "162 Train Loss 1.7174084 Test MSE 0.017932679034673746 Test RE 0.0014920278855648451\n",
      "163 Train Loss 1.6533152 Test MSE 0.002557226931284205 Test RE 0.0005634287282266785\n",
      "164 Train Loss 1.6043301 Test MSE 0.00426308262356713 Test RE 0.0007274719079740968\n",
      "165 Train Loss 1.5950167 Test MSE 0.0037446767934008578 Test RE 0.0006818071040018656\n",
      "166 Train Loss 1.5884826 Test MSE 0.002952112418705925 Test RE 0.000605369865018224\n",
      "167 Train Loss 1.5532347 Test MSE 0.0022723814385402163 Test RE 0.0005311228290554738\n",
      "168 Train Loss 1.5231328 Test MSE 0.0066437849071410955 Test RE 0.0009081595080845899\n",
      "169 Train Loss 1.4625643 Test MSE 0.013009508582901605 Test RE 0.0012708222158583507\n",
      "170 Train Loss 1.3988533 Test MSE 0.012769058300132658 Test RE 0.0012590233575700133\n",
      "171 Train Loss 1.2689574 Test MSE 0.012077450851330948 Test RE 0.0012244526395373085\n",
      "172 Train Loss 1.1293495 Test MSE 0.018993335629889016 Test RE 0.0015355182188668956\n",
      "173 Train Loss 0.94727325 Test MSE 0.004798914833709521 Test RE 0.0007718374974054665\n",
      "174 Train Loss 0.8790492 Test MSE 0.0025387474694779292 Test RE 0.000561389265520035\n",
      "175 Train Loss 0.8488004 Test MSE 0.0014750448383260885 Test RE 0.00042791446109543955\n",
      "176 Train Loss 0.8317942 Test MSE 0.0008280050440274386 Test RE 0.00032060540782500376\n",
      "177 Train Loss 0.8248802 Test MSE 0.0011085209901340592 Test RE 0.00037095934226273353\n",
      "178 Train Loss 0.82387114 Test MSE 0.0012417120522662077 Test RE 0.0003926131129578001\n",
      "179 Train Loss 0.82283676 Test MSE 0.0010811182833082053 Test RE 0.00036634558188940874\n",
      "180 Train Loss 0.8222744 Test MSE 0.0008122494856841989 Test RE 0.0003175404638599786\n",
      "181 Train Loss 0.8218188 Test MSE 0.0007722520105849002 Test RE 0.00030962347188809346\n",
      "182 Train Loss 0.8206894 Test MSE 0.0008404962296461427 Test RE 0.0003230146629304025\n",
      "183 Train Loss 0.81776935 Test MSE 0.0008569618719207531 Test RE 0.0003261633072698632\n",
      "184 Train Loss 0.8111198 Test MSE 0.0018073742659902628 Test RE 0.0004736727485625091\n",
      "185 Train Loss 0.79935807 Test MSE 0.0012826321073597918 Test RE 0.0003990298692962172\n",
      "186 Train Loss 0.76514184 Test MSE 0.0024640226558403926 Test RE 0.0005530656687329554\n",
      "187 Train Loss 0.7068525 Test MSE 0.00497043337296054 Test RE 0.0007855095702790954\n",
      "188 Train Loss 0.66895723 Test MSE 0.00543181908760073 Test RE 0.0008211585152523115\n",
      "189 Train Loss 0.65061945 Test MSE 0.0024798417905371704 Test RE 0.0005548381814390634\n",
      "190 Train Loss 0.64452165 Test MSE 0.0023284863911448186 Test RE 0.0005376395443657695\n",
      "191 Train Loss 0.6406289 Test MSE 0.0040409787302493495 Test RE 0.0007082680229563903\n",
      "192 Train Loss 0.63871956 Test MSE 0.004435491170460903 Test RE 0.0007420364035993837\n",
      "193 Train Loss 0.6364479 Test MSE 0.003157130534443289 Test RE 0.0006260378937582696\n",
      "194 Train Loss 0.63510025 Test MSE 0.0020316517576744035 Test RE 0.0005022026342965355\n",
      "195 Train Loss 0.6347491 Test MSE 0.001679168847868056 Test RE 0.00045656386562738504\n",
      "196 Train Loss 0.6338696 Test MSE 0.0008639625376095862 Test RE 0.00032749283896268066\n",
      "197 Train Loss 0.6330776 Test MSE 0.0005503835630806332 Test RE 0.00026138886325561097\n",
      "198 Train Loss 0.6330759 Test MSE 0.0005503411949593933 Test RE 0.00026137880230091694\n",
      "199 Train Loss 0.6330759 Test MSE 0.0005503411949593933 Test RE 0.00026137880230091694\n",
      "Training time: 52.98\n",
      "Training time: 52.98\n",
      "1D_FODE_rowdymedium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 16686.785 Test MSE 8384.981432275257 Test RE 1.0202471845303265\n",
      "1 Train Loss 13203.598 Test MSE 7771.9412422919695 Test RE 0.9822433712807629\n",
      "2 Train Loss 9373.356 Test MSE 7021.202765388795 Test RE 0.933598424099071\n",
      "3 Train Loss 7283.902 Test MSE 6355.274702163883 Test RE 0.8882219799584067\n",
      "4 Train Loss 5784.3555 Test MSE 5842.844192568867 Test RE 0.8516604998277241\n",
      "5 Train Loss 4087.8342 Test MSE 5854.7334874786075 Test RE 0.8525265589516807\n",
      "6 Train Loss 2788.591 Test MSE 4610.107796586154 Test RE 0.7565016726229434\n",
      "7 Train Loss 2236.502 Test MSE 3921.966838026928 Test RE 0.6977603881952621\n",
      "8 Train Loss 1638.0093 Test MSE 2906.954465376104 Test RE 0.6007219026630665\n",
      "9 Train Loss 1494.9066 Test MSE 2602.890127407157 Test RE 0.5684369105943169\n",
      "10 Train Loss 1210.1287 Test MSE 1951.3488031267123 Test RE 0.49217755618583264\n",
      "11 Train Loss 1078.69 Test MSE 1713.3904343758352 Test RE 0.46119280289725884\n",
      "12 Train Loss 786.3741 Test MSE 1053.5279547455423 Test RE 0.3616407691732386\n",
      "13 Train Loss 668.84235 Test MSE 883.5959706138741 Test RE 0.33119305080997014\n",
      "14 Train Loss 492.8581 Test MSE 500.35116824171155 Test RE 0.24922511864312355\n",
      "15 Train Loss 336.23862 Test MSE 333.768623504532 Test RE 0.20355281191543945\n",
      "16 Train Loss 285.92017 Test MSE 243.08725846263292 Test RE 0.17371425182235303\n",
      "17 Train Loss 224.08539 Test MSE 123.90806528932552 Test RE 0.12402354487438665\n",
      "18 Train Loss 168.4368 Test MSE 58.024395131563615 Test RE 0.08487106722154573\n",
      "19 Train Loss 118.12291 Test MSE 45.22434777788079 Test RE 0.07492737338386718\n",
      "20 Train Loss 87.13625 Test MSE 10.805733414769517 Test RE 0.036625324130159106\n",
      "21 Train Loss 66.428635 Test MSE 1.212972904983489 Test RE 0.012270998478767205\n",
      "22 Train Loss 59.840027 Test MSE 0.8854356255874365 Test RE 0.010484140884048027\n",
      "23 Train Loss 57.1718 Test MSE 1.127502015115949 Test RE 0.011830770117761319\n",
      "24 Train Loss 50.66007 Test MSE 6.297386012252287 Test RE 0.027959828932919706\n",
      "25 Train Loss 44.969852 Test MSE 7.229689138417689 Test RE 0.029958092978014987\n",
      "26 Train Loss 39.88585 Test MSE 4.775081674372434 Test RE 0.02434696068683339\n",
      "27 Train Loss 34.443314 Test MSE 3.25034457294768 Test RE 0.02008718383097189\n",
      "28 Train Loss 31.439274 Test MSE 1.1055585840578943 Test RE 0.011715079303736053\n",
      "29 Train Loss 25.956352 Test MSE 0.9724988066782918 Test RE 0.010987500071155738\n",
      "30 Train Loss 23.286629 Test MSE 0.8653531678152103 Test RE 0.010364564206883574\n",
      "31 Train Loss 22.7383 Test MSE 0.692457899601336 Test RE 0.009271522132915013\n",
      "32 Train Loss 21.865982 Test MSE 0.27132897559714164 Test RE 0.005803666387710109\n",
      "33 Train Loss 20.88014 Test MSE 0.3583044108300775 Test RE 0.006669302705850894\n",
      "34 Train Loss 18.88867 Test MSE 0.14647142714802389 Test RE 0.004264133656587494\n",
      "35 Train Loss 18.414831 Test MSE 0.09446304740309049 Test RE 0.0034244066228498048\n",
      "36 Train Loss 16.848768 Test MSE 0.08093588380352375 Test RE 0.0031697492597697378\n",
      "37 Train Loss 15.850665 Test MSE 0.1694041702421508 Test RE 0.004585813631761502\n",
      "38 Train Loss 15.178967 Test MSE 0.1211567799914657 Test RE 0.003878182243554002\n",
      "39 Train Loss 13.420983 Test MSE 0.25760054210305994 Test RE 0.005654936579751323\n",
      "40 Train Loss 12.801051 Test MSE 0.3340168085811756 Test RE 0.006439297843607872\n",
      "41 Train Loss 12.427879 Test MSE 0.11020171896605443 Test RE 0.003698695141073013\n",
      "42 Train Loss 12.208345 Test MSE 0.06635158226302573 Test RE 0.002869987427589859\n",
      "43 Train Loss 11.536115 Test MSE 0.08837742292611223 Test RE 0.003312264569423333\n",
      "44 Train Loss 10.670043 Test MSE 0.46786871612834974 Test RE 0.007621077112152209\n",
      "45 Train Loss 10.133294 Test MSE 0.5283650692770021 Test RE 0.0080988135627068\n",
      "46 Train Loss 9.862912 Test MSE 0.5053616773371552 Test RE 0.007920553011822203\n",
      "47 Train Loss 8.725724 Test MSE 0.23865734605447633 Test RE 0.0054430428810219485\n",
      "48 Train Loss 7.800196 Test MSE 0.0449726491372399 Test RE 0.002362808843603222\n",
      "49 Train Loss 7.601528 Test MSE 0.01556638861666949 Test RE 0.0013901071802395898\n",
      "50 Train Loss 7.5684595 Test MSE 0.011541339395852947 Test RE 0.001196967775542274\n",
      "51 Train Loss 7.5460844 Test MSE 0.014761382607737364 Test RE 0.0013536857926721862\n",
      "52 Train Loss 7.504377 Test MSE 0.016622021077527995 Test RE 0.001436469028571171\n",
      "53 Train Loss 7.415025 Test MSE 0.029746547912524336 Test RE 0.0019216426932060439\n",
      "54 Train Loss 7.2948966 Test MSE 0.027302271862422754 Test RE 0.0018409998188264889\n",
      "55 Train Loss 7.200622 Test MSE 0.011557081314557701 Test RE 0.00119778380512176\n",
      "56 Train Loss 6.9280987 Test MSE 0.012958807190799967 Test RE 0.0012683434383116378\n",
      "57 Train Loss 6.77262 Test MSE 0.012682114842675772 Test RE 0.0012547297436331863\n",
      "58 Train Loss 6.759176 Test MSE 0.013629459186420377 Test RE 0.0013007494894001779\n",
      "59 Train Loss 6.745068 Test MSE 0.017721018331461533 Test RE 0.0014831964924817197\n",
      "60 Train Loss 6.6418986 Test MSE 0.022573746496022732 Test RE 0.0016740027771475407\n",
      "61 Train Loss 6.419246 Test MSE 0.05756370434602992 Test RE 0.002673183176860303\n",
      "62 Train Loss 6.303941 Test MSE 0.02948815935485592 Test RE 0.0019132784713843443\n",
      "63 Train Loss 6.2613897 Test MSE 0.02390013823337615 Test RE 0.001722481470720645\n",
      "64 Train Loss 6.244343 Test MSE 0.029758347566362524 Test RE 0.0019220237873498185\n",
      "65 Train Loss 6.2222877 Test MSE 0.027680209693682956 Test RE 0.0018536982514081055\n",
      "66 Train Loss 6.185227 Test MSE 0.018608611547619135 Test RE 0.0015198871296275309\n",
      "67 Train Loss 6.092563 Test MSE 0.02418295776495099 Test RE 0.0017326428911238526\n",
      "68 Train Loss 6.02557 Test MSE 0.012310917288517942 Test RE 0.001236230798578077\n",
      "69 Train Loss 5.976183 Test MSE 0.00956023630483577 Test RE 0.0010894032482965457\n",
      "70 Train Loss 5.9618373 Test MSE 0.013871599694186292 Test RE 0.0013122531564645722\n",
      "71 Train Loss 5.882111 Test MSE 0.07208331080698623 Test RE 0.002991380892048267\n",
      "72 Train Loss 5.3379025 Test MSE 0.039331481427701126 Test RE 0.002209655169479589\n",
      "73 Train Loss 5.2604947 Test MSE 0.009234018777505884 Test RE 0.001070655442561138\n",
      "74 Train Loss 5.238295 Test MSE 0.011591044758790593 Test RE 0.0011995425112523582\n",
      "75 Train Loss 5.227379 Test MSE 0.011155431464214393 Test RE 0.001176786123298846\n",
      "76 Train Loss 5.1822762 Test MSE 0.011883471698021118 Test RE 0.001214579706209368\n",
      "77 Train Loss 5.0071125 Test MSE 0.04312319680375093 Test RE 0.0023137148104076647\n",
      "78 Train Loss 4.363092 Test MSE 0.012046099241982352 Test RE 0.0012228623409427225\n",
      "79 Train Loss 3.9800823 Test MSE 0.00585634307490018 Test RE 0.0008526437394970543\n",
      "80 Train Loss 3.919885 Test MSE 0.025279472648711426 Test RE 0.0017714885814334497\n",
      "81 Train Loss 3.8948648 Test MSE 0.01722500987608213 Test RE 0.00146229195995636\n",
      "82 Train Loss 3.8720486 Test MSE 0.008748008243966918 Test RE 0.001042098916067298\n",
      "83 Train Loss 3.8462586 Test MSE 0.008888898896239238 Test RE 0.0010504571358034814\n",
      "84 Train Loss 3.7841196 Test MSE 0.012276582646210205 Test RE 0.0012345056964860458\n",
      "85 Train Loss 3.6336153 Test MSE 0.0076961658517941825 Test RE 0.0009774432716098092\n",
      "86 Train Loss 3.4689565 Test MSE 0.009096394175796385 Test RE 0.0010626469207014057\n",
      "87 Train Loss 3.2590468 Test MSE 0.01667704006837149 Test RE 0.0014388444251605683\n",
      "88 Train Loss 3.1491559 Test MSE 0.01885041349202641 Test RE 0.0015297300318429807\n",
      "89 Train Loss 3.1143932 Test MSE 0.004789147684552701 Test RE 0.0007710516435245258\n",
      "90 Train Loss 3.1040258 Test MSE 0.004099785787280204 Test RE 0.0007134030062753948\n",
      "91 Train Loss 3.0829 Test MSE 0.0036510839305372066 Test RE 0.0006732327905726755\n",
      "92 Train Loss 2.946337 Test MSE 0.007843377701307924 Test RE 0.0009867472322973015\n",
      "93 Train Loss 2.7794833 Test MSE 0.009465969833425129 Test RE 0.0010840190401711306\n",
      "94 Train Loss 2.607642 Test MSE 0.01813696239320286 Test RE 0.0015005021726509046\n",
      "95 Train Loss 2.5348852 Test MSE 0.027136882520944056 Test RE 0.0018354152237605732\n",
      "96 Train Loss 2.475312 Test MSE 0.009328461948581085 Test RE 0.001076116708342692\n",
      "97 Train Loss 2.4570646 Test MSE 0.0038336983490542638 Test RE 0.0006898637443169347\n",
      "98 Train Loss 2.453846 Test MSE 0.003849324623100248 Test RE 0.0006912682676217349\n",
      "99 Train Loss 2.451245 Test MSE 0.004851162092962151 Test RE 0.0007760277390780025\n",
      "100 Train Loss 2.4470096 Test MSE 0.0050977926270078175 Test RE 0.0007955096179558912\n",
      "101 Train Loss 2.437967 Test MSE 0.007242977570265466 Test RE 0.0009482283212790733\n",
      "102 Train Loss 2.4031992 Test MSE 0.007628261994590105 Test RE 0.0009731216898809857\n",
      "103 Train Loss 2.3842733 Test MSE 0.003123031148561182 Test RE 0.0006226478750090557\n",
      "104 Train Loss 2.3709931 Test MSE 0.0020531944176767724 Test RE 0.0005048581711826123\n",
      "105 Train Loss 2.3452551 Test MSE 0.004160961794410368 Test RE 0.0007187059105032228\n",
      "106 Train Loss 2.3331816 Test MSE 0.0034138813674102495 Test RE 0.000650996367107852\n",
      "107 Train Loss 2.3324094 Test MSE 0.00283467429098474 Test RE 0.0005932065460051158\n",
      "108 Train Loss 2.3316002 Test MSE 0.00226217266813625 Test RE 0.0005299284401183786\n",
      "109 Train Loss 2.3252516 Test MSE 0.002377383596515876 Test RE 0.0005432553141037117\n",
      "110 Train Loss 2.2963123 Test MSE 0.006961239488841034 Test RE 0.0009296032639641087\n",
      "111 Train Loss 2.2187395 Test MSE 0.007876070520153237 Test RE 0.0009888015769623437\n",
      "112 Train Loss 2.1897218 Test MSE 0.003627084476410538 Test RE 0.0006710164818366987\n",
      "113 Train Loss 2.1844413 Test MSE 0.003211271672347587 Test RE 0.0006313829885978584\n",
      "114 Train Loss 2.1823635 Test MSE 0.002910420154316184 Test RE 0.000601079888164817\n",
      "115 Train Loss 2.1810048 Test MSE 0.003030472273403582 Test RE 0.0006133516102730704\n",
      "116 Train Loss 2.1791828 Test MSE 0.003710251955161563 Test RE 0.0006786659395654514\n",
      "117 Train Loss 2.177343 Test MSE 0.005251745986308369 Test RE 0.000807432466937821\n",
      "118 Train Loss 2.1735504 Test MSE 0.006235640247095713 Test RE 0.0008798221230804225\n",
      "119 Train Loss 2.1699393 Test MSE 0.004650505068308341 Test RE 0.0007598089647611823\n",
      "120 Train Loss 2.1629653 Test MSE 0.0031739023302612916 Test RE 0.0006276985587028422\n",
      "121 Train Loss 2.148555 Test MSE 0.0025901329664413217 Test RE 0.000567042201635697\n",
      "122 Train Loss 2.1135511 Test MSE 0.0030531090957013093 Test RE 0.0006156381350255564\n",
      "123 Train Loss 2.0742211 Test MSE 0.004932209859052524 Test RE 0.0007824833871452558\n",
      "124 Train Loss 2.048656 Test MSE 0.0023776749773741076 Test RE 0.0005432886047661675\n",
      "125 Train Loss 2.0386453 Test MSE 0.003727431499520403 Test RE 0.0006802353351984591\n",
      "126 Train Loss 2.0274189 Test MSE 0.003032997445933436 Test RE 0.0006136070978653902\n",
      "127 Train Loss 2.0186381 Test MSE 0.001950653391880789 Test RE 0.0004920898485688851\n",
      "128 Train Loss 2.007835 Test MSE 0.0026537583551793885 Test RE 0.0005739645102027662\n",
      "129 Train Loss 1.9973998 Test MSE 0.0019139146509270823 Test RE 0.00048743379411844305\n",
      "130 Train Loss 1.9874774 Test MSE 0.0037193597522551867 Test RE 0.0006794984117366689\n",
      "131 Train Loss 1.9781588 Test MSE 0.0031386820805109233 Test RE 0.0006242061112820326\n",
      "132 Train Loss 1.9703715 Test MSE 0.0019678016778821713 Test RE 0.000494248108145581\n",
      "133 Train Loss 1.9588643 Test MSE 0.002173390360968076 Test RE 0.0005194254451699849\n",
      "134 Train Loss 1.9533627 Test MSE 0.0038505164747668283 Test RE 0.0006913752767146194\n",
      "135 Train Loss 1.9400114 Test MSE 0.004497217769417949 Test RE 0.0007471818457964063\n",
      "136 Train Loss 1.909999 Test MSE 0.0063263697496263776 Test RE 0.000886199779936951\n",
      "137 Train Loss 1.8826331 Test MSE 0.009919418048686625 Test RE 0.001109679209204662\n",
      "138 Train Loss 1.8606534 Test MSE 0.016437491308248082 Test RE 0.0014284732775387006\n",
      "139 Train Loss 1.823009 Test MSE 0.03334833664486256 Test RE 0.0020346580959793035\n",
      "140 Train Loss 1.7803736 Test MSE 0.036327188318853135 Test RE 0.0021235879141090234\n",
      "141 Train Loss 1.7692279 Test MSE 0.025625655356213996 Test RE 0.0017835769159194987\n",
      "142 Train Loss 1.7633061 Test MSE 0.021061715972182225 Test RE 0.001616967266515866\n",
      "143 Train Loss 1.7542765 Test MSE 0.019262462117074997 Test RE 0.001546358732316733\n",
      "144 Train Loss 1.7395939 Test MSE 0.0160962185297218 Test RE 0.0014135666231600307\n",
      "145 Train Loss 1.7283399 Test MSE 0.013921714922736151 Test RE 0.001314621469331609\n",
      "146 Train Loss 1.7206004 Test MSE 0.011203758506724733 Test RE 0.001179332377704496\n",
      "147 Train Loss 1.7146043 Test MSE 0.006562359638803086 Test RE 0.0009025772155241162\n",
      "148 Train Loss 1.7114308 Test MSE 0.004105384106025082 Test RE 0.0007138899213414412\n",
      "149 Train Loss 1.7074037 Test MSE 0.0026088083488766075 Test RE 0.0005690827744737221\n",
      "150 Train Loss 1.7019289 Test MSE 0.0027441952534263256 Test RE 0.0005836625883411011\n",
      "151 Train Loss 1.6929417 Test MSE 0.0031595882092946576 Test RE 0.0006262815166075747\n",
      "152 Train Loss 1.6760347 Test MSE 0.002316860702520718 Test RE 0.000536295699003972\n",
      "153 Train Loss 1.6611401 Test MSE 0.004544039964635549 Test RE 0.000751061367242584\n",
      "154 Train Loss 1.6543503 Test MSE 0.00788641208697713 Test RE 0.0009894505302101377\n",
      "155 Train Loss 1.6424297 Test MSE 0.010220594706052322 Test RE 0.0011263994656383603\n",
      "156 Train Loss 1.6245714 Test MSE 0.008425827049388476 Test RE 0.0010227291220063716\n",
      "157 Train Loss 1.6023217 Test MSE 0.003534199332314396 Test RE 0.0006623688079347638\n",
      "158 Train Loss 1.5767188 Test MSE 0.00364236347007713 Test RE 0.0006724283158146946\n",
      "159 Train Loss 1.5311439 Test MSE 0.008733234583881139 Test RE 0.0010412185944977579\n",
      "160 Train Loss 1.4718893 Test MSE 0.006632542075861955 Test RE 0.000907390774036901\n",
      "161 Train Loss 1.4341053 Test MSE 0.01456296383903989 Test RE 0.0013445570614694158\n",
      "162 Train Loss 1.3828051 Test MSE 0.014681839908200421 Test RE 0.0013500336527651452\n",
      "163 Train Loss 1.3068228 Test MSE 0.008368045323686884 Test RE 0.0010192163086023593\n",
      "164 Train Loss 1.2453556 Test MSE 0.004062450113595034 Test RE 0.0007101471898386469\n",
      "165 Train Loss 1.2147759 Test MSE 0.005217793916658799 Test RE 0.0008048182454483413\n",
      "166 Train Loss 1.2039791 Test MSE 0.004694358463462016 Test RE 0.00076338298732993\n",
      "167 Train Loss 1.1899642 Test MSE 0.002546096306619681 Test RE 0.0005622011968198992\n",
      "168 Train Loss 1.1769607 Test MSE 0.0021965468563208165 Test RE 0.000522185235644623\n",
      "169 Train Loss 1.1504732 Test MSE 0.008390493589815856 Test RE 0.0010205824768214754\n",
      "170 Train Loss 1.1342592 Test MSE 0.008957032593675227 Test RE 0.001054475344531973\n",
      "171 Train Loss 1.1258035 Test MSE 0.0037396544106126015 Test RE 0.0006813497287201952\n",
      "172 Train Loss 1.1227137 Test MSE 0.001980491084173064 Test RE 0.0004958391314621072\n",
      "173 Train Loss 1.1193691 Test MSE 0.002409900532541585 Test RE 0.0005469579147596099\n",
      "174 Train Loss 1.1140542 Test MSE 0.0030415194237056404 Test RE 0.0006144685357893162\n",
      "175 Train Loss 1.108559 Test MSE 0.0018375342216076461 Test RE 0.0004776085253058117\n",
      "176 Train Loss 1.1040407 Test MSE 0.0011628308312814385 Test RE 0.0003799379030258086\n",
      "177 Train Loss 1.0986894 Test MSE 0.0011416086372202862 Test RE 0.00037645491815618744\n",
      "178 Train Loss 1.0873367 Test MSE 0.0036356502383688882 Test RE 0.0006718083544818772\n",
      "179 Train Loss 1.078221 Test MSE 0.004753553513615372 Test RE 0.0007681809731400976\n",
      "180 Train Loss 1.0735236 Test MSE 0.003904030605063555 Test RE 0.0006961630347422042\n",
      "181 Train Loss 1.063299 Test MSE 0.003756623608070338 Test RE 0.0006828938382147311\n",
      "182 Train Loss 1.0437207 Test MSE 0.001994848149939083 Test RE 0.0004976331158318965\n",
      "183 Train Loss 1.0222929 Test MSE 0.0014606260679051817 Test RE 0.00042581786290482517\n",
      "184 Train Loss 1.0118968 Test MSE 0.001620711573161305 Test RE 0.000448546238475518\n",
      "185 Train Loss 1.0068402 Test MSE 0.0015803187190693761 Test RE 0.0004429214311829735\n",
      "186 Train Loss 0.999975 Test MSE 0.00103346888636554 Test RE 0.00035818142133436665\n",
      "187 Train Loss 0.9901727 Test MSE 0.00374362535023469 Test RE 0.0006817113772157006\n",
      "188 Train Loss 0.9733156 Test MSE 0.004652279654677485 Test RE 0.0007599539186971359\n",
      "189 Train Loss 0.94797486 Test MSE 0.0018410178998662268 Test RE 0.0004780610465623316\n",
      "190 Train Loss 0.9371026 Test MSE 0.0014705422712419734 Test RE 0.0004272608585450217\n",
      "191 Train Loss 0.9295343 Test MSE 0.0025167036956607503 Test RE 0.0005589466991508282\n",
      "192 Train Loss 0.9167484 Test MSE 0.0035525757560102805 Test RE 0.0006640886017794106\n",
      "193 Train Loss 0.90196 Test MSE 0.005737476183545186 Test RE 0.0008439462742243746\n",
      "194 Train Loss 0.8879335 Test MSE 0.0031264654481352157 Test RE 0.0006229901341287271\n",
      "195 Train Loss 0.87837034 Test MSE 0.0015081464324541685 Test RE 0.0004326892524436596\n",
      "196 Train Loss 0.8702534 Test MSE 0.003223368043631698 Test RE 0.0006325710326305951\n",
      "197 Train Loss 0.8583894 Test MSE 0.005788456979308075 Test RE 0.0008476874574488841\n",
      "198 Train Loss 0.8489062 Test MSE 0.002507570238074771 Test RE 0.0005579315307400704\n",
      "199 Train Loss 0.8437368 Test MSE 0.0014211783867158726 Test RE 0.00042002839363937074\n",
      "Training time: 55.60\n",
      "Training time: 55.60\n",
      "1D_FODE_rowdymedium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 18325.053 Test MSE 8122.008323250187 Test RE 1.0041210405256369\n",
      "1 Train Loss 14622.769 Test MSE 6968.875674225971 Test RE 0.9301129919525057\n",
      "2 Train Loss 11144.907 Test MSE 9001.230739464147 Test RE 1.0570737777864783\n",
      "3 Train Loss 9176.55 Test MSE 9250.37917788054 Test RE 1.0716034913104941\n",
      "4 Train Loss 7817.5156 Test MSE 7334.823567685959 Test RE 0.9542214793646635\n",
      "5 Train Loss 6382.3276 Test MSE 4759.461261259035 Test RE 0.7686581751074545\n",
      "6 Train Loss 4775.161 Test MSE 2691.599386591775 Test RE 0.578042223171451\n",
      "7 Train Loss 4516.069 Test MSE 1948.4881305391282 Test RE 0.49181665831980476\n",
      "8 Train Loss 4177.994 Test MSE 1339.5704708923372 Test RE 0.4077905290976761\n",
      "9 Train Loss 4091.5862 Test MSE 968.8872726366103 Test RE 0.34680949397647926\n",
      "10 Train Loss 3645.715 Test MSE 196.80593925613627 Test RE 0.15630520940841539\n",
      "11 Train Loss 3529.1086 Test MSE 173.2243188752795 Test RE 0.1466421378765245\n",
      "12 Train Loss 3505.2698 Test MSE 140.12754374177925 Test RE 0.13189128728293514\n",
      "13 Train Loss 3496.9292 Test MSE 136.9492320153721 Test RE 0.13038695794419597\n",
      "14 Train Loss 3467.856 Test MSE 107.79147096189729 Test RE 0.1156768760438064\n",
      "15 Train Loss 3291.9634 Test MSE 42.4667585737946 Test RE 0.07260706957153913\n",
      "16 Train Loss 2731.2488 Test MSE 371.9153835501235 Test RE 0.2148703165226734\n",
      "17 Train Loss 1824.9519 Test MSE 511.59026618385843 Test RE 0.25200867371307445\n",
      "18 Train Loss 1765.4369 Test MSE 551.4160600987237 Test RE 0.2616339257775365\n",
      "19 Train Loss 1706.6332 Test MSE 395.5562592641869 Test RE 0.22159424792940907\n",
      "20 Train Loss 1651.4293 Test MSE 328.5392734791653 Test RE 0.20195192562877548\n",
      "21 Train Loss 1514.9868 Test MSE 355.3521161296127 Test RE 0.21003119596978562\n",
      "22 Train Loss 1227.7212 Test MSE 166.38904937035812 Test RE 0.14371983919103617\n",
      "23 Train Loss 1147.7458 Test MSE 131.64552963739473 Test RE 0.12783724727914095\n",
      "24 Train Loss 1144.0009 Test MSE 147.20678081344687 Test RE 0.13518181093269363\n",
      "25 Train Loss 1127.4518 Test MSE 144.7620415821224 Test RE 0.13405459410514256\n",
      "26 Train Loss 1052.1605 Test MSE 103.33719577818285 Test RE 0.11326159894635558\n",
      "27 Train Loss 911.19934 Test MSE 126.20083884565383 Test RE 0.125165740530532\n",
      "28 Train Loss 729.1766 Test MSE 112.77255451802165 Test RE 0.1183194279936676\n",
      "29 Train Loss 715.46515 Test MSE 109.56020100634116 Test RE 0.11662207451362754\n",
      "30 Train Loss 625.7309 Test MSE 242.5729330874228 Test RE 0.17353038172179697\n",
      "31 Train Loss 370.5085 Test MSE 46.949874805485884 Test RE 0.07634341300858648\n",
      "32 Train Loss 295.35 Test MSE 10.25219520634018 Test RE 0.035674901749963295\n",
      "33 Train Loss 281.2348 Test MSE 9.48231779784879 Test RE 0.034309280108571656\n",
      "34 Train Loss 237.11287 Test MSE 2.936203119761836 Test RE 0.019091823037866253\n",
      "35 Train Loss 181.34578 Test MSE 13.309372899893113 Test RE 0.04064743534804352\n",
      "36 Train Loss 169.67883 Test MSE 15.822006447846134 Test RE 0.044318507965195465\n",
      "37 Train Loss 157.84285 Test MSE 9.925920340178806 Test RE 0.03510263716821685\n",
      "38 Train Loss 148.3232 Test MSE 3.5065123669955094 Test RE 0.02086373413078774\n",
      "39 Train Loss 133.88072 Test MSE 3.2847835355416843 Test RE 0.020193320112986555\n",
      "40 Train Loss 127.87301 Test MSE 1.6216272479497886 Test RE 0.01418828386817975\n",
      "41 Train Loss 125.7326 Test MSE 0.9629687743266615 Test RE 0.01093353135399468\n",
      "42 Train Loss 125.59749 Test MSE 0.9024915318886486 Test RE 0.010584635821874256\n",
      "43 Train Loss 125.258125 Test MSE 0.8278839250254321 Test RE 0.010137691646467113\n",
      "44 Train Loss 119.51584 Test MSE 2.189364673413421 Test RE 0.016485928253290406\n",
      "45 Train Loss 114.540504 Test MSE 1.6334843312363203 Test RE 0.014240060644262927\n",
      "46 Train Loss 114.022026 Test MSE 1.4519096639247246 Test RE 0.01342530467228979\n",
      "47 Train Loss 113.50368 Test MSE 2.0932980440207007 Test RE 0.016120179973486744\n",
      "48 Train Loss 112.83628 Test MSE 3.2595187182078362 Test RE 0.020115512041443684\n",
      "49 Train Loss 109.54756 Test MSE 4.024985908485616 Test RE 0.022353036870394853\n",
      "50 Train Loss 104.6597 Test MSE 3.6922972036620196 Test RE 0.02140931036391229\n",
      "51 Train Loss 103.25432 Test MSE 5.75133092515805 Test RE 0.026720127794909038\n",
      "52 Train Loss 101.85874 Test MSE 5.108829422383362 Test RE 0.025183440004479838\n",
      "53 Train Loss 98.746826 Test MSE 5.286595162392661 Test RE 0.025617832366112436\n",
      "54 Train Loss 86.342 Test MSE 6.367150684837546 Test RE 0.028114276797794106\n",
      "55 Train Loss 71.32549 Test MSE 1.0356925163722062 Test RE 0.011338869877029643\n",
      "56 Train Loss 67.193054 Test MSE 1.4631040694703987 Test RE 0.013476960686016747\n",
      "57 Train Loss 66.35875 Test MSE 2.8675716699875036 Test RE 0.01886737550112778\n",
      "58 Train Loss 63.63458 Test MSE 2.8404246054004516 Test RE 0.01877785518274373\n",
      "59 Train Loss 62.13227 Test MSE 1.1772346441284498 Test RE 0.012088874512591124\n",
      "60 Train Loss 61.72826 Test MSE 1.1960314920938926 Test RE 0.012185003544255455\n",
      "61 Train Loss 58.456142 Test MSE 1.1444551389774313 Test RE 0.01191938201676534\n",
      "62 Train Loss 53.82647 Test MSE 0.2053125982399291 Test RE 0.005048497573673789\n",
      "63 Train Loss 51.94959 Test MSE 0.2236588007715606 Test RE 0.005269232335995621\n",
      "64 Train Loss 51.38264 Test MSE 0.1657375420825669 Test RE 0.004535913869094583\n",
      "65 Train Loss 51.000717 Test MSE 0.22653773052489787 Test RE 0.0053030366066633555\n",
      "66 Train Loss 50.851875 Test MSE 0.37585554531641385 Test RE 0.006830694048520341\n",
      "67 Train Loss 49.768486 Test MSE 1.727849315935161 Test RE 0.014645603929231055\n",
      "68 Train Loss 42.508102 Test MSE 1.6619349380728552 Test RE 0.01436353580398061\n",
      "69 Train Loss 38.76285 Test MSE 0.3323971319380791 Test RE 0.0064236665126672365\n",
      "70 Train Loss 37.067875 Test MSE 1.575738807313601 Test RE 0.013986094806299252\n",
      "71 Train Loss 36.79354 Test MSE 1.793306153234903 Test RE 0.014920437976924593\n",
      "72 Train Loss 36.29479 Test MSE 1.1674200054076376 Test RE 0.0120383763958707\n",
      "73 Train Loss 35.272377 Test MSE 0.5576566316320747 Test RE 0.008320277053777895\n",
      "74 Train Loss 34.339256 Test MSE 0.730767759954985 Test RE 0.009524540696311262\n",
      "75 Train Loss 32.622124 Test MSE 0.4561249308017652 Test RE 0.007524822458473602\n",
      "76 Train Loss 31.334276 Test MSE 0.13254641444939383 Test RE 0.004056377306239812\n",
      "77 Train Loss 31.17684 Test MSE 0.1483999170545495 Test RE 0.004292113337794196\n",
      "78 Train Loss 31.130695 Test MSE 0.1692587640366306 Test RE 0.004583845117921932\n",
      "79 Train Loss 31.069412 Test MSE 0.2031162876223106 Test RE 0.005021422075222554\n",
      "80 Train Loss 30.76091 Test MSE 0.2142029282327132 Test RE 0.0051566428614587614\n",
      "81 Train Loss 29.871544 Test MSE 0.45253585159565557 Test RE 0.007495158961217699\n",
      "82 Train Loss 29.539835 Test MSE 0.2517389442534295 Test RE 0.005590228443572924\n",
      "83 Train Loss 28.872536 Test MSE 0.15695196602641517 Test RE 0.0044140549205211555\n",
      "84 Train Loss 27.42551 Test MSE 0.27384338682772075 Test RE 0.005830495722295157\n",
      "85 Train Loss 26.843164 Test MSE 0.21790218004655826 Test RE 0.00520097947603757\n",
      "86 Train Loss 26.59479 Test MSE 0.33641537566375274 Test RE 0.006462376710976316\n",
      "87 Train Loss 26.357647 Test MSE 0.775243859752888 Test RE 0.00981010193132961\n",
      "88 Train Loss 25.849463 Test MSE 1.5280492727805615 Test RE 0.013772825073468964\n",
      "89 Train Loss 24.697142 Test MSE 1.059091742182936 Test RE 0.011466243049568978\n",
      "90 Train Loss 24.375135 Test MSE 0.9886572900884069 Test RE 0.011078405025994076\n",
      "91 Train Loss 24.20615 Test MSE 1.1883772516868054 Test RE 0.012145950790803526\n",
      "92 Train Loss 24.068213 Test MSE 1.3320743534803072 Test RE 0.01285933723456362\n",
      "93 Train Loss 23.672766 Test MSE 1.2074339579450997 Test RE 0.012242949137683406\n",
      "94 Train Loss 22.789238 Test MSE 1.2671087227246693 Test RE 0.012541841056836431\n",
      "95 Train Loss 19.380642 Test MSE 1.6540218413354115 Test RE 0.014329299907223345\n",
      "96 Train Loss 16.815973 Test MSE 0.29671956017834517 Test RE 0.0060691439818848355\n",
      "97 Train Loss 15.27072 Test MSE 0.07766791817430704 Test RE 0.003105097092349917\n",
      "98 Train Loss 13.703711 Test MSE 0.1630050688168456 Test RE 0.004498367233585487\n",
      "99 Train Loss 13.267652 Test MSE 0.28175205469202946 Test RE 0.005914089577637207\n",
      "100 Train Loss 12.824602 Test MSE 0.2633838220912671 Test RE 0.005718062528456964\n",
      "101 Train Loss 12.5357 Test MSE 0.19921970340513048 Test RE 0.004973023333418003\n",
      "102 Train Loss 12.37462 Test MSE 0.1594161545233634 Test RE 0.00444857090116357\n",
      "103 Train Loss 12.296114 Test MSE 0.2198835483148684 Test RE 0.0052245720252792555\n",
      "104 Train Loss 12.210486 Test MSE 0.3052931699253871 Test RE 0.006156202493881479\n",
      "105 Train Loss 12.054115 Test MSE 0.29230867002312966 Test RE 0.0060238645898843994\n",
      "106 Train Loss 11.839964 Test MSE 0.11153489222743712 Test RE 0.0037210004996213845\n",
      "107 Train Loss 11.734131 Test MSE 0.1491706360480194 Test RE 0.004303244507508346\n",
      "108 Train Loss 11.404434 Test MSE 0.14389362416045806 Test RE 0.004226444086425678\n",
      "109 Train Loss 11.131828 Test MSE 0.2467475605605006 Test RE 0.005534530514126194\n",
      "110 Train Loss 10.985049 Test MSE 0.5567581230297229 Test RE 0.008313571445146613\n",
      "111 Train Loss 10.874141 Test MSE 0.45643949015168217 Test RE 0.007527416698724488\n",
      "112 Train Loss 10.789007 Test MSE 0.20705531521020898 Test RE 0.005069878413093209\n",
      "113 Train Loss 10.412808 Test MSE 0.12986207888520107 Test RE 0.004015092248431731\n",
      "114 Train Loss 10.087486 Test MSE 0.1985768406117244 Test RE 0.004964993116359526\n",
      "115 Train Loss 9.689137 Test MSE 0.2050329296494827 Test RE 0.005045057971450973\n",
      "116 Train Loss 9.429911 Test MSE 0.13018642179368567 Test RE 0.004020103159195472\n",
      "117 Train Loss 9.131354 Test MSE 0.04805154032944711 Test RE 0.0024423506119701337\n",
      "118 Train Loss 8.765111 Test MSE 0.2750027926374275 Test RE 0.005842825343842834\n",
      "119 Train Loss 8.152943 Test MSE 0.0879916624813909 Test RE 0.003305027777652881\n",
      "120 Train Loss 7.7336984 Test MSE 0.09726704321432758 Test RE 0.003474859180598747\n",
      "121 Train Loss 7.281379 Test MSE 0.08959053263940508 Test RE 0.0033349199337896897\n",
      "122 Train Loss 6.8419385 Test MSE 0.06775927095699713 Test RE 0.002900271898846339\n",
      "123 Train Loss 6.6442366 Test MSE 0.03780249230414317 Test RE 0.0021662798954068013\n",
      "124 Train Loss 6.527455 Test MSE 0.040192488039710386 Test RE 0.0022337100486726513\n",
      "125 Train Loss 6.4000096 Test MSE 0.05708057125010895 Test RE 0.0026619415045865146\n",
      "126 Train Loss 6.348634 Test MSE 0.03562678871850461 Test RE 0.002103016554963549\n",
      "127 Train Loss 6.303852 Test MSE 0.02543445231168902 Test RE 0.0017769104746727636\n",
      "128 Train Loss 6.229242 Test MSE 0.021433358085315962 Test RE 0.0016311708893779432\n",
      "129 Train Loss 6.18591 Test MSE 0.026227578574453507 Test RE 0.0018044026271578902\n",
      "130 Train Loss 6.153705 Test MSE 0.020785736140743933 Test RE 0.001606338458805113\n",
      "131 Train Loss 6.134533 Test MSE 0.019400599082999553 Test RE 0.0015518935311646827\n",
      "132 Train Loss 6.0611334 Test MSE 0.02674777279166275 Test RE 0.0018222089066662207\n",
      "133 Train Loss 5.8497305 Test MSE 0.02443499331649936 Test RE 0.0017416483177684061\n",
      "134 Train Loss 5.7767076 Test MSE 0.01926664109723169 Test RE 0.0015465264640418736\n",
      "135 Train Loss 5.758711 Test MSE 0.02087694109302418 Test RE 0.0016098587974894595\n",
      "136 Train Loss 5.7542186 Test MSE 0.02306661612509945 Test RE 0.001692178981633374\n",
      "137 Train Loss 5.7482333 Test MSE 0.023369101555112643 Test RE 0.0017032380880639144\n",
      "138 Train Loss 5.741939 Test MSE 0.021926903537454766 Test RE 0.0016498444697687369\n",
      "139 Train Loss 5.737478 Test MSE 0.023447606264872356 Test RE 0.0017060965656039775\n",
      "140 Train Loss 5.7260704 Test MSE 0.029947847529169735 Test RE 0.0019281337609334457\n",
      "141 Train Loss 5.706983 Test MSE 0.034907227038422244 Test RE 0.002081670691537092\n",
      "142 Train Loss 5.6199064 Test MSE 0.03783114430114274 Test RE 0.0021671006943111103\n",
      "143 Train Loss 5.3557053 Test MSE 0.02605946803095459 Test RE 0.0017986105036750433\n",
      "144 Train Loss 4.9128094 Test MSE 0.06723078298821072 Test RE 0.0028889394333346335\n",
      "145 Train Loss 4.7326655 Test MSE 0.12650020904390502 Test RE 0.003962780104817719\n",
      "146 Train Loss 4.645096 Test MSE 0.09881125941172732 Test RE 0.003502334076510472\n",
      "147 Train Loss 4.5045104 Test MSE 0.07952583904022707 Test RE 0.003142016651244188\n",
      "148 Train Loss 4.356731 Test MSE 0.06852166387752909 Test RE 0.0029165424534368565\n",
      "149 Train Loss 4.236413 Test MSE 0.06168688653905383 Test RE 0.002767265176291319\n",
      "150 Train Loss 4.1362143 Test MSE 0.04336761961789719 Test RE 0.002320262627356953\n",
      "151 Train Loss 4.090799 Test MSE 0.04398561456987832 Test RE 0.002336736188978239\n",
      "152 Train Loss 4.079436 Test MSE 0.04929877001328312 Test RE 0.002473844482228326\n",
      "153 Train Loss 4.0719523 Test MSE 0.036811514590904815 Test RE 0.0021376972358142367\n",
      "154 Train Loss 4.0511656 Test MSE 0.023146218435711623 Test RE 0.0016950963004009625\n",
      "155 Train Loss 4.011519 Test MSE 0.029588256726473798 Test RE 0.0019165230261855286\n",
      "156 Train Loss 3.9669445 Test MSE 0.06103726532138003 Test RE 0.002752655652596111\n",
      "157 Train Loss 3.9406602 Test MSE 0.04326189299333913 Test RE 0.002317432598480179\n",
      "158 Train Loss 3.9161549 Test MSE 0.024136964127250582 Test RE 0.0017309944476792856\n",
      "159 Train Loss 3.8861673 Test MSE 0.014543457349659727 Test RE 0.0013436562703629277\n",
      "160 Train Loss 3.863378 Test MSE 0.024507348957213442 Test RE 0.0017442250511975619\n",
      "161 Train Loss 3.846159 Test MSE 0.03319337810275407 Test RE 0.0020299254046904766\n",
      "162 Train Loss 3.8285902 Test MSE 0.021289542960941224 Test RE 0.0016256892032715277\n",
      "163 Train Loss 3.821228 Test MSE 0.014066101486740874 Test RE 0.0013214210647510191\n",
      "164 Train Loss 3.8109558 Test MSE 0.011832069368281841 Test RE 0.0012119500081004628\n",
      "165 Train Loss 3.7994387 Test MSE 0.015138953951175208 Test RE 0.0013708889831626195\n",
      "166 Train Loss 3.791769 Test MSE 0.015289725771248323 Test RE 0.0013776985472312966\n",
      "167 Train Loss 3.780772 Test MSE 0.01145247665327631 Test RE 0.001192350834254987\n",
      "168 Train Loss 3.7716322 Test MSE 0.009447674997192058 Test RE 0.0010829709942385107\n",
      "169 Train Loss 3.7648947 Test MSE 0.009204622533124124 Test RE 0.0010689498830261913\n",
      "170 Train Loss 3.7412019 Test MSE 0.015303445367327246 Test RE 0.0013783165187260156\n",
      "171 Train Loss 3.6883743 Test MSE 0.011689304425763965 Test RE 0.0012046161654562578\n",
      "172 Train Loss 3.6645262 Test MSE 0.03910023607144192 Test RE 0.002203149874652976\n",
      "173 Train Loss 3.5735662 Test MSE 0.09232726996460469 Test RE 0.003385472959732459\n",
      "174 Train Loss 3.3465443 Test MSE 0.01548207788405179 Test RE 0.0013863375171224166\n",
      "175 Train Loss 3.116817 Test MSE 0.019581499451541362 Test RE 0.0015591120379290326\n",
      "176 Train Loss 3.0043387 Test MSE 0.01317548342739359 Test RE 0.0012789030758670183\n",
      "177 Train Loss 2.8121998 Test MSE 0.007338737257242315 Test RE 0.0009544760204979795\n",
      "178 Train Loss 2.6275694 Test MSE 0.009139169906907392 Test RE 0.0010651425351616342\n",
      "179 Train Loss 2.5968838 Test MSE 0.006456672843852793 Test RE 0.0008952797121488965\n",
      "180 Train Loss 2.5860946 Test MSE 0.005880322993969357 Test RE 0.0008543876127637911\n",
      "181 Train Loss 2.5734143 Test MSE 0.005745619556149592 Test RE 0.0008445449810309395\n",
      "182 Train Loss 2.5646992 Test MSE 0.0058760910375057086 Test RE 0.0008540801141823849\n",
      "183 Train Loss 2.5494516 Test MSE 0.009409969971406371 Test RE 0.0010808078021487973\n",
      "184 Train Loss 2.5428026 Test MSE 0.010763218952761378 Test RE 0.001155913776725804\n",
      "185 Train Loss 2.5368342 Test MSE 0.01199725284771708 Test RE 0.001220380496364309\n",
      "186 Train Loss 2.5287015 Test MSE 0.01650666723014041 Test RE 0.0014314759318783438\n",
      "187 Train Loss 2.5221193 Test MSE 0.022826999062776042 Test RE 0.001683366820313519\n",
      "188 Train Loss 2.4626408 Test MSE 0.04237010379973068 Test RE 0.002293422750389091\n",
      "189 Train Loss 2.3915153 Test MSE 0.032213297458442834 Test RE 0.0019997326791475886\n",
      "190 Train Loss 2.34412 Test MSE 0.016999234890589004 Test RE 0.0014526769308444484\n",
      "191 Train Loss 2.3194187 Test MSE 0.010972657336710372 Test RE 0.001167105889982991\n",
      "192 Train Loss 2.3113668 Test MSE 0.008132467397382683 Test RE 0.0010047673583529159\n",
      "193 Train Loss 2.306551 Test MSE 0.006130529723966265 Test RE 0.000872375285727175\n",
      "194 Train Loss 2.2883182 Test MSE 0.005310979318967275 Test RE 0.0008119731295874313\n",
      "195 Train Loss 2.264224 Test MSE 0.007917921176520244 Test RE 0.000991425167504718\n",
      "196 Train Loss 2.245202 Test MSE 0.01204553136860138 Test RE 0.00122283351670915\n",
      "197 Train Loss 2.2355742 Test MSE 0.018196370351425826 Test RE 0.0015029576249857343\n",
      "198 Train Loss 2.2283628 Test MSE 0.012819681639622112 Test RE 0.0012615166080295092\n",
      "199 Train Loss 2.2226932 Test MSE 0.005346279015338506 Test RE 0.0008146670711661031\n",
      "Training time: 67.94\n",
      "Training time: 67.94\n",
      "1D_FODE_rowdymedium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 18216.65 Test MSE 9475.383521630034 Test RE 1.0845579221678316\n",
      "1 Train Loss 16051.372 Test MSE 9547.543410540691 Test RE 1.0886798209380215\n",
      "2 Train Loss 13025.9 Test MSE 8506.52595496609 Test RE 1.027615078275152\n",
      "3 Train Loss 11418.785 Test MSE 7987.985064978137 Test RE 0.9958019547406716\n",
      "4 Train Loss 9567.375 Test MSE 4685.548274641576 Test RE 0.7626663072085352\n",
      "5 Train Loss 6441.974 Test MSE 977.8093023470109 Test RE 0.348402637959154\n",
      "6 Train Loss 5012.9697 Test MSE 174.69737625294957 Test RE 0.14726432244563287\n",
      "7 Train Loss 4254.531 Test MSE 160.78114809519565 Test RE 0.14127714670103786\n",
      "8 Train Loss 3852.651 Test MSE 69.14339013446086 Test RE 0.09264664289993861\n",
      "9 Train Loss 3777.7412 Test MSE 48.13284019353217 Test RE 0.07729921737221497\n",
      "10 Train Loss 3632.7056 Test MSE 46.695791405598804 Test RE 0.07613655506431001\n",
      "11 Train Loss 3567.0547 Test MSE 60.94908913387222 Test RE 0.08698371701865609\n",
      "12 Train Loss 3470.5598 Test MSE 56.03744217320487 Test RE 0.0834052722289304\n",
      "13 Train Loss 3189.8904 Test MSE 156.12590876524817 Test RE 0.13921686252004162\n",
      "14 Train Loss 3066.9292 Test MSE 219.27036788913557 Test RE 0.16498494828762192\n",
      "15 Train Loss 2915.025 Test MSE 225.2485621918807 Test RE 0.1672189014843741\n",
      "16 Train Loss 2618.1094 Test MSE 195.90984401864907 Test RE 0.15594895960910557\n",
      "17 Train Loss 2319.5757 Test MSE 44.26856956716555 Test RE 0.07413138205013162\n",
      "18 Train Loss 1728.4845 Test MSE 117.64446998127892 Test RE 0.12084817912547736\n",
      "19 Train Loss 1356.3914 Test MSE 82.78334569926727 Test RE 0.1013738264351624\n",
      "20 Train Loss 1151.4789 Test MSE 50.53447455794177 Test RE 0.07920420324665578\n",
      "21 Train Loss 944.18176 Test MSE 116.20880395419528 Test RE 0.12010853451515838\n",
      "22 Train Loss 747.6306 Test MSE 94.31062837517149 Test RE 0.10820184634644028\n",
      "23 Train Loss 554.4771 Test MSE 60.05018210896 Test RE 0.08633989511509114\n",
      "24 Train Loss 511.3102 Test MSE 86.75315023759529 Test RE 0.10377601252715919\n",
      "25 Train Loss 391.8524 Test MSE 92.94460488679456 Test RE 0.10741537405104248\n",
      "26 Train Loss 350.4443 Test MSE 62.4724729523721 Test RE 0.08806405947627466\n",
      "27 Train Loss 282.89804 Test MSE 50.52417156836019 Test RE 0.07919612874221209\n",
      "28 Train Loss 170.05344 Test MSE 19.01861718682527 Test RE 0.048589655596720994\n",
      "29 Train Loss 163.4199 Test MSE 16.45437927757811 Test RE 0.045195490510641055\n",
      "30 Train Loss 148.41368 Test MSE 11.718038540106154 Test RE 0.03814009876880468\n",
      "31 Train Loss 135.96642 Test MSE 9.116433561934613 Test RE 0.03364084050791349\n",
      "32 Train Loss 128.54471 Test MSE 3.877994756225777 Test RE 0.02194107798773083\n",
      "33 Train Loss 104.56949 Test MSE 5.602608470168124 Test RE 0.02637238997308431\n",
      "34 Train Loss 89.51547 Test MSE 5.847853795727316 Test RE 0.02694341282679281\n",
      "35 Train Loss 76.33136 Test MSE 11.181107833497345 Test RE 0.037256046786885176\n",
      "36 Train Loss 72.7455 Test MSE 11.69580294578988 Test RE 0.038103895164594205\n",
      "37 Train Loss 53.2498 Test MSE 6.692269459212408 Test RE 0.028823124784416638\n",
      "38 Train Loss 45.718037 Test MSE 3.6323151446518844 Test RE 0.021234699185818485\n",
      "39 Train Loss 41.845234 Test MSE 2.6603826452811963 Test RE 0.018172990744404496\n",
      "40 Train Loss 36.3339 Test MSE 1.9821109369798229 Test RE 0.015686221068524808\n",
      "41 Train Loss 28.73981 Test MSE 0.6267254086123728 Test RE 0.008820495920301302\n",
      "42 Train Loss 24.81923 Test MSE 0.32928187265438585 Test RE 0.0063934940277025785\n",
      "43 Train Loss 22.897284 Test MSE 0.8315525481986304 Test RE 0.010160128523572558\n",
      "44 Train Loss 19.608511 Test MSE 0.28104785930266846 Test RE 0.0059066942808870945\n",
      "45 Train Loss 18.797077 Test MSE 0.217470725633837 Test RE 0.005195827858372047\n",
      "46 Train Loss 18.26852 Test MSE 0.14144934049722116 Test RE 0.004190393580937422\n",
      "47 Train Loss 16.862825 Test MSE 0.496932354684203 Test RE 0.007854218689016326\n",
      "48 Train Loss 15.035959 Test MSE 0.06219981638089626 Test RE 0.00277874633986279\n",
      "49 Train Loss 14.416824 Test MSE 0.07494797114339678 Test RE 0.003050241972235743\n",
      "50 Train Loss 13.933228 Test MSE 0.14056579423328253 Test RE 0.0041772856853224995\n",
      "51 Train Loss 12.728963 Test MSE 0.6712441094818349 Test RE 0.00912839860914764\n",
      "52 Train Loss 12.359641 Test MSE 0.39725013300626216 Test RE 0.0070224131701005265\n",
      "53 Train Loss 11.801211 Test MSE 0.23205630791655618 Test RE 0.005367240320625653\n",
      "54 Train Loss 11.182338 Test MSE 0.11834258989629413 Test RE 0.0038328770392857523\n",
      "55 Train Loss 9.411809 Test MSE 0.03252469917540743 Test RE 0.0020093750090324617\n",
      "56 Train Loss 8.212073 Test MSE 0.23276884539479514 Test RE 0.005375474159874231\n",
      "57 Train Loss 7.4533305 Test MSE 0.20593378849917862 Test RE 0.005056129129188884\n",
      "58 Train Loss 6.3611054 Test MSE 0.04428075140876393 Test RE 0.0023445626559991484\n",
      "59 Train Loss 5.7828174 Test MSE 0.21847603009932537 Test RE 0.00520782341844084\n",
      "60 Train Loss 5.6531634 Test MSE 0.13324705094206252 Test RE 0.004067084122154781\n",
      "61 Train Loss 5.193244 Test MSE 0.04786664976383033 Test RE 0.002437647299640521\n",
      "62 Train Loss 4.684436 Test MSE 0.10442599765484224 Test RE 0.003600465624869218\n",
      "63 Train Loss 4.452479 Test MSE 0.06560643385793656 Test RE 0.002853826511587977\n",
      "64 Train Loss 4.218728 Test MSE 0.03501093970024133 Test RE 0.002084760817894668\n",
      "65 Train Loss 4.1458883 Test MSE 0.043730056679588576 Test RE 0.0023299380425631042\n",
      "66 Train Loss 4.028893 Test MSE 0.041962404080424814 Test RE 0.0022823620270887774\n",
      "67 Train Loss 3.805567 Test MSE 0.018018686973999304 Test RE 0.0014956016054562457\n",
      "68 Train Loss 3.6489103 Test MSE 0.014703460384848892 Test RE 0.001351027316824046\n",
      "69 Train Loss 3.5391967 Test MSE 0.02518714040851786 Test RE 0.0017682504771632628\n",
      "70 Train Loss 3.4231794 Test MSE 0.09814043533843486 Test RE 0.003490425255645359\n",
      "71 Train Loss 3.176606 Test MSE 0.03927962684938181 Test RE 0.0022081980856935675\n",
      "72 Train Loss 2.932894 Test MSE 0.03562982570418365 Test RE 0.0021031061882884334\n",
      "73 Train Loss 2.7695785 Test MSE 0.061275273168318815 Test RE 0.002758017264144199\n",
      "74 Train Loss 2.623285 Test MSE 0.021074507584771376 Test RE 0.0016174582160502827\n",
      "75 Train Loss 2.561671 Test MSE 0.03365702682919013 Test RE 0.0020440533503554553\n",
      "76 Train Loss 2.5147438 Test MSE 0.07930309773491269 Test RE 0.003137613380321862\n",
      "77 Train Loss 2.420181 Test MSE 0.14531582557171777 Test RE 0.004247279183727487\n",
      "78 Train Loss 2.317743 Test MSE 0.037585760877805935 Test RE 0.002160061048693507\n",
      "79 Train Loss 2.2224543 Test MSE 0.0273376696434103 Test RE 0.0018421928733790753\n",
      "80 Train Loss 2.176545 Test MSE 0.041324516658383936 Test RE 0.0022649480417346046\n",
      "81 Train Loss 2.1397135 Test MSE 0.04796181323846395 Test RE 0.002440069234384923\n",
      "82 Train Loss 2.095709 Test MSE 0.02899868304027366 Test RE 0.0018973326920166003\n",
      "83 Train Loss 2.0533965 Test MSE 0.024627026068508598 Test RE 0.0017484786649975526\n",
      "84 Train Loss 2.038477 Test MSE 0.030187712221388045 Test RE 0.0019358399713718332\n",
      "85 Train Loss 2.0188556 Test MSE 0.02532087418716972 Test RE 0.0017729386185653029\n",
      "86 Train Loss 1.9981927 Test MSE 0.0158794644574674 Test RE 0.0014040167148957824\n",
      "87 Train Loss 1.976553 Test MSE 0.016937719932724575 Test RE 0.0014500461551027195\n",
      "88 Train Loss 1.950782 Test MSE 0.019229489890994076 Test RE 0.0015450346874693961\n",
      "89 Train Loss 1.8185197 Test MSE 0.016419545238282415 Test RE 0.0014276932776658658\n",
      "90 Train Loss 1.7788616 Test MSE 0.010900529085468394 Test RE 0.0011632636072383092\n",
      "91 Train Loss 1.7574097 Test MSE 0.0077882085385915754 Test RE 0.0009832707910179084\n",
      "92 Train Loss 1.7169436 Test MSE 0.006293278536175255 Test RE 0.0008838790276066496\n",
      "93 Train Loss 1.5605447 Test MSE 0.020676216865494187 Test RE 0.0016021010007051457\n",
      "94 Train Loss 1.4581101 Test MSE 0.03909029434690497 Test RE 0.0022028697676276716\n",
      "95 Train Loss 1.4224112 Test MSE 0.009879011675085342 Test RE 0.0011074167847705593\n",
      "96 Train Loss 1.4027575 Test MSE 0.007704890633177239 Test RE 0.0009779971554170297\n",
      "97 Train Loss 1.3730704 Test MSE 0.009849508413543831 Test RE 0.0011057619209893946\n",
      "98 Train Loss 1.3601477 Test MSE 0.007135775215553356 Test RE 0.0009411848606965691\n",
      "99 Train Loss 1.3449216 Test MSE 0.00926445216683588 Test RE 0.001072418319138377\n",
      "100 Train Loss 1.3132477 Test MSE 0.012546884928686807 Test RE 0.0012480221974802504\n",
      "101 Train Loss 1.2848295 Test MSE 0.012783534532553691 Test RE 0.001259736830387784\n",
      "102 Train Loss 1.2608831 Test MSE 0.007793112435905647 Test RE 0.0009835803038010574\n",
      "103 Train Loss 1.2511516 Test MSE 0.006458009584745474 Test RE 0.0008953723833353637\n",
      "104 Train Loss 1.2392716 Test MSE 0.006841070387217173 Test RE 0.0009215446491591378\n",
      "105 Train Loss 1.1586776 Test MSE 0.012894420170219356 Test RE 0.001265188574346071\n",
      "106 Train Loss 1.0433743 Test MSE 0.007912530478598214 Test RE 0.0009910876178221536\n",
      "107 Train Loss 0.88337225 Test MSE 0.02486878799664141 Test RE 0.0017570400558555733\n",
      "108 Train Loss 0.80237 Test MSE 0.024045282186106853 Test RE 0.001727703811796214\n",
      "109 Train Loss 0.73726517 Test MSE 0.01571264568493014 Test RE 0.001396622425019974\n",
      "110 Train Loss 0.6867992 Test MSE 0.016389130709156177 Test RE 0.0014263703803163582\n",
      "111 Train Loss 0.62168485 Test MSE 0.00960101822968719 Test RE 0.0010917243563074107\n",
      "112 Train Loss 0.60191435 Test MSE 0.007820211369371761 Test RE 0.000985288918087615\n",
      "113 Train Loss 0.59063226 Test MSE 0.008861046610397855 Test RE 0.0010488101046278837\n",
      "114 Train Loss 0.5775042 Test MSE 0.008700525196358864 Test RE 0.0010392668793673145\n",
      "115 Train Loss 0.56789374 Test MSE 0.007710646678478201 Test RE 0.0009783624003771294\n",
      "116 Train Loss 0.5573638 Test MSE 0.01475002202399677 Test RE 0.0013531647838593056\n",
      "117 Train Loss 0.5392228 Test MSE 0.024011459313342087 Test RE 0.0017264882621163594\n",
      "118 Train Loss 0.5245886 Test MSE 0.01827287670500618 Test RE 0.0015061138917210495\n",
      "119 Train Loss 0.5114964 Test MSE 0.009021820225162836 Test RE 0.0010582820666384103\n",
      "120 Train Loss 0.5023999 Test MSE 0.004012010197732992 Test RE 0.0007057247791159311\n",
      "121 Train Loss 0.5000428 Test MSE 0.004021577687484759 Test RE 0.0007065657532970554\n",
      "122 Train Loss 0.49700686 Test MSE 0.005629301468945225 Test RE 0.0008359525097715439\n",
      "123 Train Loss 0.49418926 Test MSE 0.007084924225217915 Test RE 0.0009378253271257782\n",
      "124 Train Loss 0.49159816 Test MSE 0.006452933650801678 Test RE 0.0008950204370880879\n",
      "125 Train Loss 0.48705035 Test MSE 0.0037307458571243872 Test RE 0.0006805376938340255\n",
      "126 Train Loss 0.4820945 Test MSE 0.002146242195021327 Test RE 0.0005161711376391927\n",
      "127 Train Loss 0.47327712 Test MSE 0.003094787007517813 Test RE 0.0006198259216084096\n",
      "128 Train Loss 0.4695051 Test MSE 0.0030476812442023415 Test RE 0.0006150906474037654\n",
      "129 Train Loss 0.46774107 Test MSE 0.002296821981103724 Test RE 0.0005339714292781804\n",
      "130 Train Loss 0.4666656 Test MSE 0.0022791118670170392 Test RE 0.0005319087977215223\n",
      "131 Train Loss 0.46500155 Test MSE 0.003623515742940151 Test RE 0.0006706862898709413\n",
      "132 Train Loss 0.46397308 Test MSE 0.002821633194235373 Test RE 0.0005918404310212603\n",
      "133 Train Loss 0.46365246 Test MSE 0.002233760731433529 Test RE 0.0005265900858193214\n",
      "134 Train Loss 0.46338585 Test MSE 0.0019531155065582169 Test RE 0.000492400308533306\n",
      "135 Train Loss 0.463219 Test MSE 0.0018822000199017494 Test RE 0.00048337839926796024\n",
      "136 Train Loss 0.46254364 Test MSE 0.0020788397987273693 Test RE 0.0005080013468047435\n",
      "137 Train Loss 0.4603887 Test MSE 0.003443939360207041 Test RE 0.0006538559804158696\n",
      "138 Train Loss 0.4571591 Test MSE 0.003716202038052107 Test RE 0.0006792099054431673\n",
      "139 Train Loss 0.45200163 Test MSE 0.0018821153119735364 Test RE 0.0004833675219852557\n",
      "140 Train Loss 0.44760168 Test MSE 0.0017397910732344151 Test RE 0.0004647323464517978\n",
      "141 Train Loss 0.44452786 Test MSE 0.0020479658828182084 Test RE 0.0005042149414986027\n",
      "142 Train Loss 0.4419539 Test MSE 0.002457580098159467 Test RE 0.0005523421588219758\n",
      "143 Train Loss 0.43964884 Test MSE 0.002300793809102468 Test RE 0.0005344329205484383\n",
      "144 Train Loss 0.43754417 Test MSE 0.0024829785950447603 Test RE 0.0005551889838349605\n",
      "145 Train Loss 0.43225053 Test MSE 0.0019192680973024936 Test RE 0.00048811502316093683\n",
      "146 Train Loss 0.42891634 Test MSE 0.0020729657150614584 Test RE 0.0005072831208579278\n",
      "147 Train Loss 0.4248134 Test MSE 0.0030698083259714467 Test RE 0.0006173194806985674\n",
      "148 Train Loss 0.42337334 Test MSE 0.0038809714103921877 Test RE 0.0006941040430140274\n",
      "149 Train Loss 0.42308688 Test MSE 0.003960082282035429 Test RE 0.0007011427653998931\n",
      "150 Train Loss 0.42283115 Test MSE 0.0040173115569224534 Test RE 0.000706190887782386\n",
      "151 Train Loss 0.42222312 Test MSE 0.0033225621325789364 Test RE 0.0006422304722084573\n",
      "152 Train Loss 0.42156038 Test MSE 0.0030566825494487424 Test RE 0.0006159983106669152\n",
      "153 Train Loss 0.42092797 Test MSE 0.0033659912639854624 Test RE 0.0006464141351433005\n",
      "154 Train Loss 0.42042878 Test MSE 0.0036012381879979385 Test RE 0.0006686214048962021\n",
      "155 Train Loss 0.4199317 Test MSE 0.003158430909792894 Test RE 0.0006261668083574646\n",
      "156 Train Loss 0.41861513 Test MSE 0.0022202830096874912 Test RE 0.000524999053145031\n",
      "157 Train Loss 0.41677442 Test MSE 0.0022521756602180373 Test RE 0.0005287562120296039\n",
      "158 Train Loss 0.4123008 Test MSE 0.0033369143034776 Test RE 0.000643616069929875\n",
      "159 Train Loss 0.4095127 Test MSE 0.0033801124722199903 Test RE 0.0006477686536467096\n",
      "160 Train Loss 0.4084605 Test MSE 0.003356701983783112 Test RE 0.0006455215495481597\n",
      "161 Train Loss 0.40758 Test MSE 0.003657439237410466 Test RE 0.0006738184715349121\n",
      "162 Train Loss 0.40484738 Test MSE 0.002808242048323431 Test RE 0.0005904343575371561\n",
      "163 Train Loss 0.40155035 Test MSE 0.0023607117508084655 Test RE 0.0005413471232449361\n",
      "164 Train Loss 0.38673362 Test MSE 0.002626642935788144 Test RE 0.0005710246705204441\n",
      "165 Train Loss 0.36905557 Test MSE 0.0013840518121239751 Test RE 0.0004145057185566742\n",
      "166 Train Loss 0.36243185 Test MSE 0.0008357492650451325 Test RE 0.0003221012083219173\n",
      "167 Train Loss 0.35736033 Test MSE 0.0015407315196740747 Test RE 0.0004373386258114066\n",
      "168 Train Loss 0.35374427 Test MSE 0.0020640140862081603 Test RE 0.0005061866427225964\n",
      "169 Train Loss 0.34959218 Test MSE 0.0016175739656753443 Test RE 0.0004481118478465049\n",
      "170 Train Loss 0.347368 Test MSE 0.0014268795397637786 Test RE 0.00042087003653683237\n",
      "171 Train Loss 0.34588164 Test MSE 0.0010514345470448263 Test RE 0.0003612812922269115\n",
      "172 Train Loss 0.34328136 Test MSE 0.0011279204287348164 Test RE 0.0003741912119262188\n",
      "173 Train Loss 0.34036598 Test MSE 0.002344076118123472 Test RE 0.0005394363492038582\n",
      "174 Train Loss 0.33769596 Test MSE 0.0033568864940783376 Test RE 0.0006455392907321499\n",
      "175 Train Loss 0.33462086 Test MSE 0.002077642290828257 Test RE 0.0005078550095885377\n",
      "176 Train Loss 0.33020255 Test MSE 0.002254895921630139 Test RE 0.0005290754413603367\n",
      "177 Train Loss 0.3255854 Test MSE 0.00324798365461329 Test RE 0.0006349817886414591\n",
      "178 Train Loss 0.31954148 Test MSE 0.0018557437264061438 Test RE 0.00047996918189208235\n",
      "179 Train Loss 0.31725186 Test MSE 0.0009688086968874569 Test RE 0.000346795430746887\n",
      "180 Train Loss 0.31635404 Test MSE 0.0008773918003631848 Test RE 0.0003300282663569811\n",
      "181 Train Loss 0.31586567 Test MSE 0.001181593892593465 Test RE 0.00038299091412481343\n",
      "182 Train Loss 0.31507805 Test MSE 0.0016698248296160173 Test RE 0.00045529178015931397\n",
      "183 Train Loss 0.313612 Test MSE 0.0013265066303510945 Test RE 0.00040579721757953263\n",
      "184 Train Loss 0.312226 Test MSE 0.0010338139204040604 Test RE 0.0003582412075895072\n",
      "185 Train Loss 0.3096352 Test MSE 0.0011097871929417866 Test RE 0.00037117114506598353\n",
      "186 Train Loss 0.30676004 Test MSE 0.0012995806432111868 Test RE 0.0004016575819292359\n",
      "187 Train Loss 0.30547088 Test MSE 0.0014643963007969739 Test RE 0.0004263670787100871\n",
      "188 Train Loss 0.30428067 Test MSE 0.0018590570129765488 Test RE 0.00048039746469496494\n",
      "189 Train Loss 0.30255267 Test MSE 0.0017277877922773136 Test RE 0.00046312641574241956\n",
      "190 Train Loss 0.30082536 Test MSE 0.0023329512898069772 Test RE 0.0005381547624156038\n",
      "191 Train Loss 0.29804927 Test MSE 0.00227545319611887 Test RE 0.0005314816881734272\n",
      "192 Train Loss 0.2945996 Test MSE 0.0013713402974407792 Test RE 0.0004125978602900667\n",
      "193 Train Loss 0.28655067 Test MSE 0.0007809595273217319 Test RE 0.0003113641564380093\n",
      "194 Train Loss 0.27865073 Test MSE 0.0008843924197233218 Test RE 0.0003313422813436452\n",
      "195 Train Loss 0.27305356 Test MSE 0.0018879673960031638 Test RE 0.0004841184090101165\n",
      "196 Train Loss 0.26974905 Test MSE 0.0032331331577137787 Test RE 0.0006335284872128377\n",
      "197 Train Loss 0.2677401 Test MSE 0.0028524814966700653 Test RE 0.0005950668679080821\n",
      "198 Train Loss 0.26723388 Test MSE 0.003134146553603968 Test RE 0.0006237549462634063\n",
      "199 Train Loss 0.26666397 Test MSE 0.003498900851098002 Test RE 0.0006590527406079409\n",
      "Training time: 71.70\n",
      "Training time: 71.70\n",
      "1D_FODE_rowdymedium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 18354.643 Test MSE 8311.308740149025 Test RE 1.015755213367485\n",
      "1 Train Loss 17825.414 Test MSE 8601.3607847987 Test RE 1.0333273743423181\n",
      "2 Train Loss 15970.041 Test MSE 9082.621090756149 Test RE 1.0618421253901955\n",
      "3 Train Loss 10480.236 Test MSE 8542.78248640098 Test RE 1.0298027012215232\n",
      "4 Train Loss 8632.561 Test MSE 8506.900050509643 Test RE 1.0276376739856026\n",
      "5 Train Loss 6810.021 Test MSE 8495.334749829912 Test RE 1.0269388894213078\n",
      "6 Train Loss 5496.1934 Test MSE 7599.622801725561 Test RE 0.9712932506565863\n",
      "7 Train Loss 4042.9033 Test MSE 6740.45366956013 Test RE 0.914742624124822\n",
      "8 Train Loss 3054.6736 Test MSE 5422.267193701198 Test RE 0.8204361909087969\n",
      "9 Train Loss 2523.2554 Test MSE 4573.864641691871 Test RE 0.7535221210347798\n",
      "10 Train Loss 2068.6003 Test MSE 3768.933615871636 Test RE 0.6840118039595852\n",
      "11 Train Loss 1602.2374 Test MSE 2946.6325449341716 Test RE 0.6048077435832219\n",
      "12 Train Loss 1386.1223 Test MSE 2477.2981027463316 Test RE 0.5545535469077445\n",
      "13 Train Loss 1222.6194 Test MSE 2255.865313973576 Test RE 0.5291891553828347\n",
      "14 Train Loss 1083.5342 Test MSE 1881.9149493504365 Test RE 0.48334179259405335\n",
      "15 Train Loss 904.9247 Test MSE 1435.6076138184403 Test RE 0.42215528326958573\n",
      "16 Train Loss 773.1117 Test MSE 1333.0359975675865 Test RE 0.40679470470324813\n",
      "17 Train Loss 680.509 Test MSE 1158.9661805554226 Test RE 0.37930601862969926\n",
      "18 Train Loss 461.91553 Test MSE 714.8321546034915 Test RE 0.2978903208533702\n",
      "19 Train Loss 341.66388 Test MSE 454.85743925390204 Test RE 0.23762493078562558\n",
      "20 Train Loss 273.48715 Test MSE 322.2298033541142 Test RE 0.20000332027228318\n",
      "21 Train Loss 202.8673 Test MSE 201.80780904493025 Test RE 0.15827901396769578\n",
      "22 Train Loss 138.71747 Test MSE 145.44961640360003 Test RE 0.13437257585636836\n",
      "23 Train Loss 99.96165 Test MSE 115.04886653111069 Test RE 0.11950759991902468\n",
      "24 Train Loss 64.6696 Test MSE 51.20370764876274 Test RE 0.07972693288339822\n",
      "25 Train Loss 46.357178 Test MSE 23.41463641535003 Test RE 0.05391356640643472\n",
      "26 Train Loss 37.711037 Test MSE 9.465921417097443 Test RE 0.03427960427269605\n",
      "27 Train Loss 34.57703 Test MSE 7.603950155715838 Test RE 0.03072373305344926\n",
      "28 Train Loss 30.570377 Test MSE 4.94714892675786 Test RE 0.024781742756662513\n",
      "29 Train Loss 28.131222 Test MSE 3.2879021503275574 Test RE 0.020202903734819155\n",
      "30 Train Loss 23.640633 Test MSE 0.7926078484248406 Test RE 0.009919357357527117\n",
      "31 Train Loss 21.190495 Test MSE 0.1842946124018288 Test RE 0.004783113340837451\n",
      "32 Train Loss 19.718203 Test MSE 0.38057113997935055 Test RE 0.006873410435381223\n",
      "33 Train Loss 18.518925 Test MSE 0.33990626203323154 Test RE 0.006495819298493423\n",
      "34 Train Loss 17.086138 Test MSE 0.4807030845597321 Test RE 0.007724898944794472\n",
      "35 Train Loss 16.407513 Test MSE 0.24244563743146874 Test RE 0.005486072457438418\n",
      "36 Train Loss 14.790317 Test MSE 0.27064914594821976 Test RE 0.005796391125282526\n",
      "37 Train Loss 12.8541565 Test MSE 0.9563396716826206 Test RE 0.010895833002577572\n",
      "38 Train Loss 12.544367 Test MSE 0.8115535265296914 Test RE 0.010037208298277166\n",
      "39 Train Loss 11.961883 Test MSE 0.12973101164292783 Test RE 0.004013065560106905\n",
      "40 Train Loss 11.601879 Test MSE 0.12232401898644141 Test RE 0.0038968189013589404\n",
      "41 Train Loss 11.372782 Test MSE 0.2454584781614304 Test RE 0.005520054568714769\n",
      "42 Train Loss 10.9292145 Test MSE 0.19626780834934687 Test RE 0.0049360424820388505\n",
      "43 Train Loss 10.436228 Test MSE 0.19360786188418525 Test RE 0.0049024801824094615\n",
      "44 Train Loss 9.9225235 Test MSE 0.5814364324992836 Test RE 0.008495823332226586\n",
      "45 Train Loss 8.66499 Test MSE 0.7256813409566302 Test RE 0.009491335619174925\n",
      "46 Train Loss 8.030878 Test MSE 0.24917977006598366 Test RE 0.005561740769655735\n",
      "47 Train Loss 7.76157 Test MSE 0.09552102764748487 Test RE 0.0034435297977393206\n",
      "48 Train Loss 7.4536877 Test MSE 0.09730032475563352 Test RE 0.0034754536202693796\n",
      "49 Train Loss 7.2968335 Test MSE 0.07633254020955892 Test RE 0.0030782877206934605\n",
      "50 Train Loss 6.779533 Test MSE 0.011461708735821096 Test RE 0.0011928313269959838\n",
      "51 Train Loss 6.20943 Test MSE 0.024168143255707212 Test RE 0.001732112100252825\n",
      "52 Train Loss 5.936134 Test MSE 0.17591934888872143 Test RE 0.004673165446226604\n",
      "53 Train Loss 5.7983704 Test MSE 0.07353126138485211 Test RE 0.0030212757188558784\n",
      "54 Train Loss 5.6809025 Test MSE 0.05784934286113131 Test RE 0.0026798073091928373\n",
      "55 Train Loss 5.432858 Test MSE 0.24846321782583056 Test RE 0.00555373821994388\n",
      "56 Train Loss 5.1280656 Test MSE 0.39334246470624573 Test RE 0.006987788790480549\n",
      "57 Train Loss 4.757852 Test MSE 0.0801996803439794 Test RE 0.003155300098454316\n",
      "58 Train Loss 4.615188 Test MSE 0.024633138738218024 Test RE 0.0017486956463215854\n",
      "59 Train Loss 4.5589647 Test MSE 0.017961018335253983 Test RE 0.0014932063579696532\n",
      "60 Train Loss 4.531422 Test MSE 0.026347819099700392 Test RE 0.0018085340459443257\n",
      "61 Train Loss 4.501203 Test MSE 0.027607657335502477 Test RE 0.0018512673012016129\n",
      "62 Train Loss 4.423053 Test MSE 0.013843132740880401 Test RE 0.0013109059782359556\n",
      "63 Train Loss 4.305283 Test MSE 0.005208249405653077 Test RE 0.0008040818123139778\n",
      "64 Train Loss 4.203236 Test MSE 0.01055273568490119 Test RE 0.0011445555683470203\n",
      "65 Train Loss 4.060645 Test MSE 0.02957825274326705 Test RE 0.001916199004306878\n",
      "66 Train Loss 3.993862 Test MSE 0.011511931501188127 Test RE 0.0011954418367978073\n",
      "67 Train Loss 3.9789162 Test MSE 0.006779200644353169 Test RE 0.0009173680200510858\n",
      "68 Train Loss 3.9496174 Test MSE 0.007375747240012462 Test RE 0.0009568797525526309\n",
      "69 Train Loss 3.9116385 Test MSE 0.0043530190848354074 Test RE 0.0007351054421890859\n",
      "70 Train Loss 3.7432356 Test MSE 0.019078164727897723 Test RE 0.0015389434073657233\n",
      "71 Train Loss 3.5131662 Test MSE 0.010895000871637715 Test RE 0.0011629685946998604\n",
      "72 Train Loss 3.446585 Test MSE 0.033892757475852416 Test RE 0.002051199038850591\n",
      "73 Train Loss 3.424762 Test MSE 0.031070552215223552 Test RE 0.0019639428162155264\n",
      "74 Train Loss 3.406735 Test MSE 0.027092921024072767 Test RE 0.001833927943389643\n",
      "75 Train Loss 3.3510652 Test MSE 0.026538526822850746 Test RE 0.0018150674055178587\n",
      "76 Train Loss 3.275653 Test MSE 0.03301208588786089 Test RE 0.002024374394818654\n",
      "77 Train Loss 3.223359 Test MSE 0.03483563155823352 Test RE 0.0020795348199135204\n",
      "78 Train Loss 3.111229 Test MSE 0.017149764324642405 Test RE 0.001459094533847657\n",
      "79 Train Loss 2.8903744 Test MSE 0.01006244043803357 Test RE 0.0011176504921589644\n",
      "80 Train Loss 2.749002 Test MSE 0.007096048539672749 Test RE 0.0009385612963147503\n",
      "81 Train Loss 2.65419 Test MSE 0.019168946450278418 Test RE 0.0015426005235639722\n",
      "82 Train Loss 2.5080626 Test MSE 0.008076470964271318 Test RE 0.001001302200040157\n",
      "83 Train Loss 2.4418287 Test MSE 0.004006624027900526 Test RE 0.0007052508981986275\n",
      "84 Train Loss 2.419225 Test MSE 0.004339589991734127 Test RE 0.00073397066370104\n",
      "85 Train Loss 2.3915312 Test MSE 0.009694772306761627 Test RE 0.0010970417585088434\n",
      "86 Train Loss 2.3258493 Test MSE 0.005519450956571727 Test RE 0.0008277559128923985\n",
      "87 Train Loss 2.2587671 Test MSE 0.005419066363000053 Test RE 0.0008201939983977864\n",
      "88 Train Loss 2.2165775 Test MSE 0.003194899911771988 Test RE 0.0006297714681868523\n",
      "89 Train Loss 2.1879141 Test MSE 0.0022049244313774637 Test RE 0.0005231800887091653\n",
      "90 Train Loss 2.1227863 Test MSE 0.007018229130373988 Test RE 0.0009334007033479227\n",
      "91 Train Loss 2.0602179 Test MSE 0.02063109318231229 Test RE 0.0016003518368139552\n",
      "92 Train Loss 1.9523838 Test MSE 0.017564918541826555 Test RE 0.0014766494990031702\n",
      "93 Train Loss 1.8232706 Test MSE 0.0028426424163833152 Test RE 0.0005940396976588637\n",
      "94 Train Loss 1.7682855 Test MSE 0.007000004782451235 Test RE 0.000932188027318776\n",
      "95 Train Loss 1.7430345 Test MSE 0.020860419157666753 Test RE 0.001609221653203371\n",
      "96 Train Loss 1.7232058 Test MSE 0.02109537601790439 Test RE 0.0016182588389518052\n",
      "97 Train Loss 1.6864595 Test MSE 0.004715689382415796 Test RE 0.0007651154077067341\n",
      "98 Train Loss 1.6240094 Test MSE 0.0016924112824910098 Test RE 0.0004583606306582099\n",
      "99 Train Loss 1.5715686 Test MSE 0.0069588937668674505 Test RE 0.0009294466270221295\n",
      "100 Train Loss 1.5439448 Test MSE 0.016992385919909786 Test RE 0.0014523842604943981\n",
      "101 Train Loss 1.5244755 Test MSE 0.01731678151006555 Test RE 0.001466182194389781\n",
      "102 Train Loss 1.4800261 Test MSE 0.0048871052496464625 Test RE 0.0007788973000939607\n",
      "103 Train Loss 1.4204131 Test MSE 0.0014044341559537501 Test RE 0.00041754668863379607\n",
      "104 Train Loss 1.3731024 Test MSE 0.005145275913698876 Test RE 0.0007992059097996246\n",
      "105 Train Loss 1.3561813 Test MSE 0.012527459283929142 Test RE 0.0012470557015318308\n",
      "106 Train Loss 1.3366429 Test MSE 0.004524346006988992 Test RE 0.0007494320426528074\n",
      "107 Train Loss 1.2917536 Test MSE 0.007612959382705206 Test RE 0.0009721451385255279\n",
      "108 Train Loss 1.2281051 Test MSE 0.0025001698562042863 Test RE 0.0005571076341349728\n",
      "109 Train Loss 1.1887212 Test MSE 0.005580884517399312 Test RE 0.0008323497823933677\n",
      "110 Train Loss 1.122171 Test MSE 0.002543177929758593 Test RE 0.0005618789023758571\n",
      "111 Train Loss 1.0774608 Test MSE 0.0009303474579744115 Test RE 0.00033984191320286393\n",
      "112 Train Loss 1.0512111 Test MSE 0.0031686718576252326 Test RE 0.0006271811335365539\n",
      "113 Train Loss 1.0262728 Test MSE 0.008453593017576687 Test RE 0.0010244128563193047\n",
      "114 Train Loss 1.0046614 Test MSE 0.009132035613301542 Test RE 0.001064726713853978\n",
      "115 Train Loss 0.9968873 Test MSE 0.009044767002823077 Test RE 0.0010596270691291955\n",
      "116 Train Loss 0.9857335 Test MSE 0.009310682888822844 Test RE 0.001075090737066716\n",
      "117 Train Loss 0.9593377 Test MSE 0.013335679027171915 Test RE 0.0012866544292008857\n",
      "118 Train Loss 0.93894637 Test MSE 0.01497234411126644 Test RE 0.0013633245406849148\n",
      "119 Train Loss 0.9223057 Test MSE 0.014087155423714548 Test RE 0.0013224096369244206\n",
      "120 Train Loss 0.8964694 Test MSE 0.00988595718730016 Test RE 0.0011078060051515285\n",
      "121 Train Loss 0.856053 Test MSE 0.008873464879205335 Test RE 0.0010495447721185116\n",
      "122 Train Loss 0.81986463 Test MSE 0.002462928932545284 Test RE 0.00055294290850904\n",
      "123 Train Loss 0.8037802 Test MSE 0.005399940546005546 Test RE 0.0008187453405581343\n",
      "124 Train Loss 0.7818799 Test MSE 0.014724136720064044 Test RE 0.0013519769055398338\n",
      "125 Train Loss 0.75483644 Test MSE 0.03786523360411074 Test RE 0.0021680768519052747\n",
      "126 Train Loss 0.73225105 Test MSE 0.052615079922724725 Test RE 0.002555697626115181\n",
      "127 Train Loss 0.710946 Test MSE 0.053227930487461404 Test RE 0.002570538677657719\n",
      "128 Train Loss 0.69346327 Test MSE 0.03595815403173674 Test RE 0.0021127740136697277\n",
      "129 Train Loss 0.6802966 Test MSE 0.025006561503227935 Test RE 0.0017619003494558823\n",
      "130 Train Loss 0.66767365 Test MSE 0.025770408427112045 Test RE 0.001788607317325038\n",
      "131 Train Loss 0.65825313 Test MSE 0.02476857829098103 Test RE 0.0017534964533736288\n",
      "132 Train Loss 0.6469546 Test MSE 0.015860366972450145 Test RE 0.0014031721884685852\n",
      "133 Train Loss 0.6274532 Test MSE 0.006515299643042383 Test RE 0.0008993351115983754\n",
      "134 Train Loss 0.60503334 Test MSE 0.00253020786768995 Test RE 0.0005604442957929204\n",
      "135 Train Loss 0.59739006 Test MSE 0.001983134000787956 Test RE 0.0004961698637199155\n",
      "136 Train Loss 0.58546054 Test MSE 0.002848442926078481 Test RE 0.0005946454680175711\n",
      "137 Train Loss 0.5721637 Test MSE 0.003510872430974766 Test RE 0.0006601792608363368\n",
      "138 Train Loss 0.5650884 Test MSE 0.006690341185716189 Test RE 0.0009113359139964864\n",
      "139 Train Loss 0.5541587 Test MSE 0.007061068458033751 Test RE 0.0009362451121181548\n",
      "140 Train Loss 0.542146 Test MSE 0.008476530293365599 Test RE 0.0010258016931654387\n",
      "141 Train Loss 0.52393156 Test MSE 0.009063190894585528 Test RE 0.0010607057327856424\n",
      "142 Train Loss 0.5122934 Test MSE 0.0070513461125570175 Test RE 0.0009356003347775344\n",
      "143 Train Loss 0.50291413 Test MSE 0.004766244666449499 Test RE 0.0007692057437333913\n",
      "144 Train Loss 0.4948838 Test MSE 0.003341645975242943 Test RE 0.0006440722250634888\n",
      "145 Train Loss 0.48425466 Test MSE 0.0011940950490506048 Test RE 0.00038501158815650515\n",
      "146 Train Loss 0.46880433 Test MSE 0.0005767433212808502 Test RE 0.00026757506486774186\n",
      "147 Train Loss 0.46413103 Test MSE 0.0016709997689281703 Test RE 0.0004554519305339466\n",
      "148 Train Loss 0.46181068 Test MSE 0.0015128693246390923 Test RE 0.0004333662249380023\n",
      "149 Train Loss 0.45269164 Test MSE 0.0020567437076491678 Test RE 0.000505294348658818\n",
      "150 Train Loss 0.4315499 Test MSE 0.0020835797841669743 Test RE 0.0005085801667721578\n",
      "151 Train Loss 0.41534963 Test MSE 0.0026153668683552298 Test RE 0.0005697976598043735\n",
      "152 Train Loss 0.38788718 Test MSE 0.00343017815535644 Test RE 0.000652548342346386\n",
      "153 Train Loss 0.36194298 Test MSE 0.00938293620442993 Test RE 0.0010792541669209807\n",
      "154 Train Loss 0.34394532 Test MSE 0.003771985411735622 Test RE 0.0006842886782973237\n",
      "155 Train Loss 0.33440524 Test MSE 0.0005444095529741817 Test RE 0.0002599664005297325\n",
      "156 Train Loss 0.3264727 Test MSE 0.0007658077361448808 Test RE 0.00030832889535063485\n",
      "157 Train Loss 0.320824 Test MSE 0.002368971155967393 Test RE 0.0005422933000079628\n",
      "158 Train Loss 0.316928 Test MSE 0.001136024158316623 Test RE 0.0003755330252317902\n",
      "159 Train Loss 0.31605724 Test MSE 0.0005463334258818214 Test RE 0.0002604253392382919\n",
      "160 Train Loss 0.31535044 Test MSE 0.0003767925222916589 Test RE 0.00021627458633177566\n",
      "161 Train Loss 0.31402564 Test MSE 0.0005535367935685873 Test RE 0.00026213656198648746\n",
      "162 Train Loss 0.3119063 Test MSE 0.0011341955508957832 Test RE 0.00037523066412754056\n",
      "163 Train Loss 0.3111611 Test MSE 0.0014129516411100684 Test RE 0.00041881092440848626\n",
      "164 Train Loss 0.30797967 Test MSE 0.0014273862613293589 Test RE 0.0004209447607820697\n",
      "165 Train Loss 0.30515924 Test MSE 0.0016317747523384234 Test RE 0.00045007455105979075\n",
      "166 Train Loss 0.30090895 Test MSE 0.002816179880387847 Test RE 0.0005912682353580466\n",
      "167 Train Loss 0.2950726 Test MSE 0.001341798017018236 Test RE 0.0004081294418006479\n",
      "168 Train Loss 0.29239452 Test MSE 0.001112339594938542 Test RE 0.0003715977285966638\n",
      "169 Train Loss 0.29133382 Test MSE 0.001746601696647938 Test RE 0.0004656410835805821\n",
      "170 Train Loss 0.289731 Test MSE 0.003155242104055064 Test RE 0.0006258506341867007\n",
      "171 Train Loss 0.2865815 Test MSE 0.0032942016877387246 Test RE 0.0006394836498497219\n",
      "172 Train Loss 0.28338158 Test MSE 0.003210424309510368 Test RE 0.0006312996811369311\n",
      "173 Train Loss 0.28063166 Test MSE 0.00393506637555973 Test RE 0.0006989246916187928\n",
      "174 Train Loss 0.27613845 Test MSE 0.004458881236816481 Test RE 0.0007439903539720613\n",
      "175 Train Loss 0.26355308 Test MSE 0.0030372083539393444 Test RE 0.0006140329054830247\n",
      "176 Train Loss 0.2442612 Test MSE 0.0005999345137191291 Test RE 0.00027290172194446545\n",
      "177 Train Loss 0.23691976 Test MSE 0.00023974981387006125 Test RE 0.00017251763333381314\n",
      "178 Train Loss 0.23265685 Test MSE 0.00029131174418050047 Test RE 0.0001901662091129946\n",
      "179 Train Loss 0.23033972 Test MSE 0.0005257823847643833 Test RE 0.00025548027107712373\n",
      "180 Train Loss 0.22750308 Test MSE 0.0007326927964560918 Test RE 0.00030158887220215304\n",
      "181 Train Loss 0.22376727 Test MSE 0.0002730048498647253 Test RE 0.00018409395730684813\n",
      "182 Train Loss 0.22117786 Test MSE 0.00020087998518078783 Test RE 0.0001579147460288769\n",
      "183 Train Loss 0.21860991 Test MSE 0.00017623800606040945 Test RE 0.00014791224801392192\n",
      "184 Train Loss 0.21737577 Test MSE 0.0002186273547099011 Test RE 0.00016474286043249528\n",
      "185 Train Loss 0.21504627 Test MSE 0.0003501347223344229 Test RE 0.0002084836217620556\n",
      "186 Train Loss 0.20822929 Test MSE 0.00087393515736069 Test RE 0.0003293775218990222\n",
      "187 Train Loss 0.20139517 Test MSE 0.001074464734061273 Test RE 0.00036521653788006104\n",
      "188 Train Loss 0.19630244 Test MSE 0.0008596754647951849 Test RE 0.00032667930156879556\n",
      "189 Train Loss 0.19305533 Test MSE 0.0003195530036708212 Test RE 0.000199170862654383\n",
      "190 Train Loss 0.19122867 Test MSE 0.00033360361814416874 Test RE 0.0002035024904428877\n",
      "191 Train Loss 0.18816456 Test MSE 0.0002702001184188548 Test RE 0.0001831458658814796\n",
      "192 Train Loss 0.18615374 Test MSE 0.00024835568474170763 Test RE 0.0001755866143871226\n",
      "193 Train Loss 0.1856268 Test MSE 0.0002945771035733314 Test RE 0.00019122904060151307\n",
      "194 Train Loss 0.18524745 Test MSE 0.00027808905532215715 Test RE 0.00018580025287850743\n",
      "195 Train Loss 0.18472591 Test MSE 0.00018244440478191407 Test RE 0.00015049415292025799\n",
      "196 Train Loss 0.18423739 Test MSE 0.0001511146668848389 Test RE 0.0001369643880438554\n",
      "197 Train Loss 0.18405838 Test MSE 0.00015932145258782735 Test RE 0.00014063437291997693\n",
      "198 Train Loss 0.18401316 Test MSE 0.00015915290934949547 Test RE 0.00014055996597634054\n",
      "199 Train Loss 0.18401316 Test MSE 0.00015915290934949547 Test RE 0.00014055996597634054\n",
      "Training time: 70.73\n",
      "Training time: 70.73\n",
      "1D_FODE_rowdymedium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 17412.281 Test MSE 8266.731346044215 Test RE 1.0130275684642018\n",
      "1 Train Loss 13991.939 Test MSE 8738.819494930627 Test RE 1.0415514713821568\n",
      "2 Train Loss 11666.969 Test MSE 8304.2613880958 Test RE 1.0153244808019988\n",
      "3 Train Loss 7441.604 Test MSE 2412.1308124395323 Test RE 0.5472109515799332\n",
      "4 Train Loss 5500.1567 Test MSE 186.56907399287567 Test RE 0.15218581707625667\n",
      "5 Train Loss 5129.65 Test MSE 165.13334834396744 Test RE 0.14317650135942114\n",
      "6 Train Loss 4954.0 Test MSE 95.49713962566521 Test RE 0.10888035649107103\n",
      "7 Train Loss 4828.1245 Test MSE 57.080034957240706 Test RE 0.08417758608388048\n",
      "8 Train Loss 4742.7417 Test MSE 58.30305365342315 Test RE 0.0850746171215337\n",
      "9 Train Loss 4665.377 Test MSE 69.27879710604638 Test RE 0.0927373158149376\n",
      "10 Train Loss 4609.297 Test MSE 49.88134427360935 Test RE 0.07869070329653205\n",
      "11 Train Loss 4598.811 Test MSE 52.27725364030812 Test RE 0.08055838190180117\n",
      "12 Train Loss 4596.035 Test MSE 54.55314980041644 Test RE 0.08229326016549178\n",
      "13 Train Loss 4595.9453 Test MSE 53.972274701682906 Test RE 0.0818539634841185\n",
      "14 Train Loss 4595.681 Test MSE 52.808539234138294 Test RE 0.08096669826010687\n",
      "15 Train Loss 4591.342 Test MSE 51.15480559776286 Test RE 0.07968885222429568\n",
      "16 Train Loss 4586.981 Test MSE 53.001676414796336 Test RE 0.08111462327548105\n",
      "17 Train Loss 4584.803 Test MSE 52.893305730238275 Test RE 0.08103165471838047\n",
      "18 Train Loss 4584.0815 Test MSE 51.56846345565824 Test RE 0.08001040117562493\n",
      "19 Train Loss 4583.1025 Test MSE 50.72577989890204 Test RE 0.07935398093937931\n",
      "20 Train Loss 4579.794 Test MSE 50.38766856150148 Test RE 0.07908907284166854\n",
      "21 Train Loss 4557.475 Test MSE 57.41581464383865 Test RE 0.08442481505916832\n",
      "22 Train Loss 4496.486 Test MSE 47.11021350162734 Test RE 0.07647366223987233\n",
      "23 Train Loss 4480.0054 Test MSE 46.99177250179404 Test RE 0.07637746954079862\n",
      "24 Train Loss 4441.0757 Test MSE 64.20655133342038 Test RE 0.089277911919072\n",
      "25 Train Loss 4386.946 Test MSE 57.30311318919866 Test RE 0.08434191565888918\n",
      "26 Train Loss 4272.5127 Test MSE 70.05168069219829 Test RE 0.09325317604321176\n",
      "27 Train Loss 4262.6387 Test MSE 50.82357114279669 Test RE 0.07943043504268284\n",
      "28 Train Loss 4251.1123 Test MSE 48.28258975182549 Test RE 0.07741936958251093\n",
      "29 Train Loss 4112.4067 Test MSE 53.199008318480345 Test RE 0.08126548295788932\n",
      "30 Train Loss 3878.885 Test MSE 80.59312982961599 Test RE 0.10002380311191728\n",
      "31 Train Loss 3778.1719 Test MSE 59.88115062446887 Test RE 0.08621829310944032\n",
      "32 Train Loss 3755.4734 Test MSE 42.357708002489844 Test RE 0.07251378564446419\n",
      "33 Train Loss 3730.411 Test MSE 42.980895885495315 Test RE 0.07304526754973785\n",
      "34 Train Loss 3662.2776 Test MSE 53.061069739560935 Test RE 0.08116005880302861\n",
      "35 Train Loss 3584.0388 Test MSE 51.14780472434734 Test RE 0.07968339906452288\n",
      "36 Train Loss 3561.8801 Test MSE 48.02386398982751 Test RE 0.07721166229923591\n",
      "37 Train Loss 3526.1646 Test MSE 46.28681876073634 Test RE 0.07580241096351378\n",
      "38 Train Loss 3488.4802 Test MSE 39.794367706034684 Test RE 0.07028540580272503\n",
      "39 Train Loss 3473.3591 Test MSE 38.42691005469132 Test RE 0.06906723726090766\n",
      "40 Train Loss 3471.8271 Test MSE 37.93612851671725 Test RE 0.06862476279512827\n",
      "41 Train Loss 3460.8538 Test MSE 39.53657515598732 Test RE 0.07005737738049551\n",
      "42 Train Loss 3445.057 Test MSE 37.36912467107668 Test RE 0.06810998974747819\n",
      "43 Train Loss 3429.502 Test MSE 38.438224208718474 Test RE 0.06907740435276725\n",
      "44 Train Loss 3412.2488 Test MSE 37.10437502499455 Test RE 0.06786829091790536\n",
      "45 Train Loss 3407.2712 Test MSE 38.176090157848016 Test RE 0.06884146060733326\n",
      "46 Train Loss 3404.3323 Test MSE 42.75707588528641 Test RE 0.07285483025060069\n",
      "47 Train Loss 3335.8184 Test MSE 108.08866432137117 Test RE 0.11583623343738493\n",
      "48 Train Loss 3141.0242 Test MSE 65.9454829006154 Test RE 0.09047880974092454\n",
      "49 Train Loss 2981.264 Test MSE 94.31023353774906 Test RE 0.1082016198492598\n",
      "50 Train Loss 2873.5466 Test MSE 49.379326354407915 Test RE 0.07829372079881387\n",
      "51 Train Loss 2853.245 Test MSE 36.760368030823514 Test RE 0.06755294355118999\n",
      "52 Train Loss 2819.159 Test MSE 33.808760337963584 Test RE 0.0647841814425909\n",
      "53 Train Loss 2788.5645 Test MSE 29.866778359712644 Test RE 0.06089036002288201\n",
      "54 Train Loss 2654.1504 Test MSE 79.61225532551343 Test RE 0.09941326007806554\n",
      "55 Train Loss 2460.1729 Test MSE 26.446845264773774 Test RE 0.05729824096362434\n",
      "56 Train Loss 2373.1223 Test MSE 27.14361144023729 Test RE 0.05804812112216037\n",
      "57 Train Loss 2151.5332 Test MSE 26.81064530644361 Test RE 0.05769098923532624\n",
      "58 Train Loss 2112.6626 Test MSE 27.931423216902285 Test RE 0.05888448552898844\n",
      "59 Train Loss 2105.547 Test MSE 34.25948323264187 Test RE 0.06521458820035769\n",
      "60 Train Loss 2077.1992 Test MSE 27.152509909169563 Test RE 0.05805763527756817\n",
      "61 Train Loss 2064.7866 Test MSE 26.954431937552396 Test RE 0.05784548198901655\n",
      "62 Train Loss 2033.0684 Test MSE 22.362504857707766 Test RE 0.05268834732896147\n",
      "63 Train Loss 2002.9791 Test MSE 24.42326876604844 Test RE 0.05506254069027752\n",
      "64 Train Loss 1996.8809 Test MSE 24.559206780099128 Test RE 0.05521556496450911\n",
      "65 Train Loss 1993.1615 Test MSE 25.22187106588944 Test RE 0.055955528624532874\n",
      "66 Train Loss 1981.1786 Test MSE 23.795024278498268 Test RE 0.0543497346989616\n",
      "67 Train Loss 1975.4025 Test MSE 23.350587458044274 Test RE 0.05383977768054244\n",
      "68 Train Loss 1971.6948 Test MSE 23.603453424978422 Test RE 0.05413051101143412\n",
      "69 Train Loss 1964.6305 Test MSE 23.834652244054137 Test RE 0.054394972590285084\n",
      "70 Train Loss 1960.0197 Test MSE 27.93654262616514 Test RE 0.058889881601479906\n",
      "71 Train Loss 1954.7316 Test MSE 22.975004544223975 Test RE 0.053405029011723705\n",
      "72 Train Loss 1953.227 Test MSE 22.948884577616454 Test RE 0.05337466265709164\n",
      "73 Train Loss 1952.332 Test MSE 22.88088868448798 Test RE 0.05329553135676664\n",
      "74 Train Loss 1949.3224 Test MSE 23.18993589437584 Test RE 0.05365424973856702\n",
      "75 Train Loss 1939.3455 Test MSE 33.27822683388714 Test RE 0.06427386869054229\n",
      "76 Train Loss 1874.8088 Test MSE 23.539059079988963 Test RE 0.05405662183545036\n",
      "77 Train Loss 1816.5093 Test MSE 24.995791647971465 Test RE 0.055704181898027644\n",
      "78 Train Loss 1792.2554 Test MSE 20.752553487141473 Test RE 0.050756319590942935\n",
      "79 Train Loss 1779.5662 Test MSE 20.844869216851393 Test RE 0.050869086614385134\n",
      "80 Train Loss 1771.4431 Test MSE 20.78027547866694 Test RE 0.05079020931622103\n",
      "81 Train Loss 1747.8884 Test MSE 23.133347369653137 Test RE 0.05358874569033628\n",
      "82 Train Loss 1741.2384 Test MSE 22.67144812178125 Test RE 0.053051049875780264\n",
      "83 Train Loss 1731.6454 Test MSE 21.87562683058714 Test RE 0.052111623737318126\n",
      "84 Train Loss 1726.8989 Test MSE 21.41376093508814 Test RE 0.05155856570089426\n",
      "85 Train Loss 1718.0541 Test MSE 22.285973693672176 Test RE 0.05259811243739205\n",
      "86 Train Loss 1708.317 Test MSE 22.64975250667751 Test RE 0.053025659996774395\n",
      "87 Train Loss 1698.6133 Test MSE 20.978259970768917 Test RE 0.05103158811364929\n",
      "88 Train Loss 1666.6023 Test MSE 23.344520412507816 Test RE 0.053832782790071566\n",
      "89 Train Loss 1632.7772 Test MSE 26.14400299619767 Test RE 0.056969235918574584\n",
      "90 Train Loss 1614.9806 Test MSE 20.828303310630673 Test RE 0.05084886916895394\n",
      "91 Train Loss 1599.4727 Test MSE 21.182813094925063 Test RE 0.05127978190962732\n",
      "92 Train Loss 1591.568 Test MSE 21.54629602535018 Test RE 0.05171787397224695\n",
      "93 Train Loss 1561.3737 Test MSE 31.40401699709695 Test RE 0.062437708269657666\n",
      "94 Train Loss 1471.5543 Test MSE 46.36751028957688 Test RE 0.07586845513280353\n",
      "95 Train Loss 1421.058 Test MSE 23.086810421371258 Test RE 0.05353481678584498\n",
      "96 Train Loss 1385.428 Test MSE 20.792076394085775 Test RE 0.05080462890114871\n",
      "97 Train Loss 1376.8334 Test MSE 20.685806127315566 Test RE 0.05067462894881678\n",
      "98 Train Loss 1362.6096 Test MSE 28.749147978853923 Test RE 0.05974022328587178\n",
      "99 Train Loss 1345.3782 Test MSE 51.51195891458403 Test RE 0.07996655470630638\n",
      "100 Train Loss 1312.3964 Test MSE 85.79586279151707 Test RE 0.10320186017376898\n",
      "101 Train Loss 1143.8171 Test MSE 32.12809091991567 Test RE 0.06315341101088809\n",
      "102 Train Loss 1094.7513 Test MSE 13.128249929528492 Test RE 0.04036990899211765\n",
      "103 Train Loss 1070.975 Test MSE 14.389911795853948 Test RE 0.0422652476758486\n",
      "104 Train Loss 1051.5411 Test MSE 13.011056118743898 Test RE 0.04018931716358789\n",
      "105 Train Loss 1018.1299 Test MSE 14.748823860322496 Test RE 0.04278908965236797\n",
      "106 Train Loss 1010.78107 Test MSE 13.072766898138312 Test RE 0.04028451236728207\n",
      "107 Train Loss 1005.28217 Test MSE 9.665181274462583 Test RE 0.034638522122704754\n",
      "108 Train Loss 1003.1918 Test MSE 9.717142677123398 Test RE 0.034731508148556994\n",
      "109 Train Loss 1000.90686 Test MSE 11.439906193215762 Test RE 0.03768474526843391\n",
      "110 Train Loss 999.7577 Test MSE 12.074585416686668 Test RE 0.038715998681424946\n",
      "111 Train Loss 997.68713 Test MSE 12.544431823050768 Test RE 0.039462068863642535\n",
      "112 Train Loss 995.40955 Test MSE 13.986090244250605 Test RE 0.041667986562444116\n",
      "113 Train Loss 994.8933 Test MSE 14.751876044350094 Test RE 0.042793516900980794\n",
      "114 Train Loss 994.22034 Test MSE 14.556040046901728 Test RE 0.04250851888740078\n",
      "115 Train Loss 993.1535 Test MSE 13.931818833686272 Test RE 0.04158706407482497\n",
      "116 Train Loss 991.9681 Test MSE 12.900679948593883 Test RE 0.04001848587978178\n",
      "117 Train Loss 990.3926 Test MSE 11.888846386704499 Test RE 0.03841706745606711\n",
      "118 Train Loss 983.1147 Test MSE 12.789688825739333 Test RE 0.0398459642931391\n",
      "119 Train Loss 975.7839 Test MSE 11.784583454356008 Test RE 0.03824824129281959\n",
      "120 Train Loss 965.90735 Test MSE 11.19404979309114 Test RE 0.03727760220049051\n",
      "121 Train Loss 959.2766 Test MSE 11.767123258739502 Test RE 0.038219896238267076\n",
      "122 Train Loss 950.40247 Test MSE 11.750295733611969 Test RE 0.03819255836022837\n",
      "123 Train Loss 935.2796 Test MSE 11.105551037403027 Test RE 0.03712995377180519\n",
      "124 Train Loss 931.50134 Test MSE 10.613911870942822 Test RE 0.03629878520933697\n",
      "125 Train Loss 928.2523 Test MSE 11.703542164116532 Test RE 0.03811649992536648\n",
      "126 Train Loss 923.28784 Test MSE 12.435504644601425 Test RE 0.03929036464078462\n",
      "127 Train Loss 917.9699 Test MSE 10.100124236318276 Test RE 0.035409330078891105\n",
      "128 Train Loss 912.8946 Test MSE 10.446952233615809 Test RE 0.03601215882452434\n",
      "129 Train Loss 910.7036 Test MSE 9.641505542162895 Test RE 0.03459607101949546\n",
      "130 Train Loss 907.0752 Test MSE 10.958579440435775 Test RE 0.03688344534622402\n",
      "131 Train Loss 906.31226 Test MSE 11.145315480400921 Test RE 0.03719636797508526\n",
      "132 Train Loss 905.89575 Test MSE 11.390220183353415 Test RE 0.03760281967892474\n",
      "133 Train Loss 904.3898 Test MSE 11.823621061450558 Test RE 0.03831153947124936\n",
      "134 Train Loss 887.21124 Test MSE 12.42931931831211 Test RE 0.03928059205980235\n",
      "135 Train Loss 830.7716 Test MSE 26.197881236413505 Test RE 0.05702790754643562\n",
      "136 Train Loss 775.7716 Test MSE 45.74277861877214 Test RE 0.07535561582814655\n",
      "137 Train Loss 732.0849 Test MSE 49.13127367463573 Test RE 0.07809682242027917\n",
      "138 Train Loss 720.43744 Test MSE 27.746853273960173 Test RE 0.058689609672309496\n",
      "139 Train Loss 712.1926 Test MSE 22.961320904944994 Test RE 0.053389122943153955\n",
      "140 Train Loss 695.246 Test MSE 27.559869147640566 Test RE 0.05849152277324694\n",
      "141 Train Loss 682.20917 Test MSE 17.16716089720197 Test RE 0.04616401687594886\n",
      "142 Train Loss 672.52563 Test MSE 11.183060658670241 Test RE 0.03725930010358021\n",
      "143 Train Loss 665.25946 Test MSE 8.830127166805179 Test RE 0.033108372395474865\n",
      "144 Train Loss 661.2191 Test MSE 6.6124548133467265 Test RE 0.02865073125546196\n",
      "145 Train Loss 658.3351 Test MSE 7.277611717882838 Test RE 0.030057218805162503\n",
      "146 Train Loss 655.6642 Test MSE 9.518293033000527 Test RE 0.03437430197162817\n",
      "147 Train Loss 642.5952 Test MSE 8.051732856987497 Test RE 0.03161542548563356\n",
      "148 Train Loss 629.114 Test MSE 6.42581458308512 Test RE 0.028243495627774097\n",
      "149 Train Loss 623.3529 Test MSE 10.342600417629614 Test RE 0.0358318495103848\n",
      "150 Train Loss 621.549 Test MSE 9.243977454820419 Test RE 0.033875350009178\n",
      "151 Train Loss 619.41315 Test MSE 9.07099157775452 Test RE 0.03355689231145498\n",
      "152 Train Loss 617.3528 Test MSE 10.68418492853335 Test RE 0.03641875126980261\n",
      "153 Train Loss 595.0509 Test MSE 23.275400157738517 Test RE 0.05375302758437472\n",
      "154 Train Loss 524.93494 Test MSE 70.2584645770957 Test RE 0.09339071053454055\n",
      "155 Train Loss 470.83572 Test MSE 43.7111163250158 Test RE 0.07366315254592871\n",
      "156 Train Loss 460.42517 Test MSE 24.568236119689903 Test RE 0.05522571419846027\n",
      "157 Train Loss 457.09683 Test MSE 22.51219945039251 Test RE 0.052864401075495185\n",
      "158 Train Loss 453.774 Test MSE 23.19670248718334 Test RE 0.0536620770560254\n",
      "159 Train Loss 449.2304 Test MSE 23.792194348361992 Test RE 0.054346502709710184\n",
      "160 Train Loss 448.35782 Test MSE 21.96730492557081 Test RE 0.05222070631159824\n",
      "161 Train Loss 447.94196 Test MSE 20.50959616644834 Test RE 0.05045833397461383\n",
      "162 Train Loss 447.6246 Test MSE 20.04887214171696 Test RE 0.049888371259576375\n",
      "163 Train Loss 447.50034 Test MSE 20.825630646466838 Test RE 0.05084560662979392\n",
      "164 Train Loss 447.33554 Test MSE 21.57295387346998 Test RE 0.05174985768422976\n",
      "165 Train Loss 447.10175 Test MSE 21.044634400582233 Test RE 0.05111225537491708\n",
      "166 Train Loss 446.3062 Test MSE 19.70803628710255 Test RE 0.04946249609308478\n",
      "167 Train Loss 440.11343 Test MSE 14.599201719908379 Test RE 0.042571495517856106\n",
      "168 Train Loss 421.024 Test MSE 8.278437339700224 Test RE 0.0320574176496038\n",
      "169 Train Loss 403.78644 Test MSE 4.381625583680839 Test RE 0.023322332582197725\n",
      "170 Train Loss 393.69003 Test MSE 10.167161038391447 Test RE 0.03552664559260984\n",
      "171 Train Loss 384.63748 Test MSE 6.087244409287497 Test RE 0.02748936590304278\n",
      "172 Train Loss 379.90277 Test MSE 7.868421415388551 Test RE 0.031253463894047186\n",
      "173 Train Loss 375.16095 Test MSE 7.871264752166292 Test RE 0.031259110267829474\n",
      "174 Train Loss 372.9567 Test MSE 6.7847451516196715 Test RE 0.029021584631655543\n",
      "175 Train Loss 371.97562 Test MSE 7.666467980058341 Test RE 0.030849776031492707\n",
      "176 Train Loss 370.82352 Test MSE 8.840408891691974 Test RE 0.03312764234112071\n",
      "177 Train Loss 369.76416 Test MSE 8.45666823864559 Test RE 0.032400670602114635\n",
      "178 Train Loss 369.23508 Test MSE 7.521323013574849 Test RE 0.030556349766090476\n",
      "179 Train Loss 368.77124 Test MSE 6.8219069555233425 Test RE 0.029100955458809568\n",
      "180 Train Loss 368.51553 Test MSE 6.953710689662476 Test RE 0.029380735351196778\n",
      "181 Train Loss 368.357 Test MSE 7.240792729950938 Test RE 0.029981089458112457\n",
      "182 Train Loss 367.98135 Test MSE 7.030272125063326 Test RE 0.029542035812022527\n",
      "183 Train Loss 367.46902 Test MSE 6.073074508181835 Test RE 0.027457352358273724\n",
      "184 Train Loss 366.96564 Test MSE 5.414889026099612 Test RE 0.0259268128398094\n",
      "185 Train Loss 366.39978 Test MSE 5.336962061355785 Test RE 0.02573957727433138\n",
      "186 Train Loss 365.4208 Test MSE 5.390716888697748 Test RE 0.02586887929294244\n",
      "187 Train Loss 363.45013 Test MSE 4.963223431256571 Test RE 0.02482197109607823\n",
      "188 Train Loss 357.56735 Test MSE 3.298586842187394 Test RE 0.02023570378544896\n",
      "189 Train Loss 346.18176 Test MSE 2.360624558696496 Test RE 0.017118582998965293\n",
      "190 Train Loss 340.81195 Test MSE 3.4881673861549025 Test RE 0.020809086281731566\n",
      "191 Train Loss 325.70312 Test MSE 6.644161345194824 Test RE 0.028719338829745318\n",
      "192 Train Loss 305.70557 Test MSE 13.163272790783807 Test RE 0.040423721496556826\n",
      "193 Train Loss 290.43835 Test MSE 3.4849492604844 Test RE 0.02079948500691485\n",
      "194 Train Loss 275.57758 Test MSE 6.629899396410607 Test RE 0.02868849868629971\n",
      "195 Train Loss 267.63947 Test MSE 17.603178565040675 Test RE 0.04674658606766513\n",
      "196 Train Loss 263.19064 Test MSE 20.689697585142756 Test RE 0.05067939523413305\n",
      "197 Train Loss 255.92813 Test MSE 23.9127247972199 Test RE 0.054483987575134736\n",
      "198 Train Loss 251.95975 Test MSE 19.9808766940663 Test RE 0.0498037015800665\n",
      "199 Train Loss 246.3828 Test MSE 9.994254253062325 Test RE 0.03522326005356027\n",
      "Training time: 72.09\n",
      "Training time: 72.09\n",
      "1D_FODE_rowdymedium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 18415.629 Test MSE 8057.676895544159 Test RE 1.0001364988965984\n",
      "1 Train Loss 16702.535 Test MSE 8206.173488761404 Test RE 1.0093102865940413\n",
      "2 Train Loss 12621.168 Test MSE 7218.597008818637 Test RE 0.9466310619972292\n",
      "3 Train Loss 7950.5825 Test MSE 6870.760197963606 Test RE 0.9235422067949227\n",
      "4 Train Loss 4403.839 Test MSE 7095.539896733162 Test RE 0.9385276577954235\n",
      "5 Train Loss 3101.9285 Test MSE 6504.608113836375 Test RE 0.8985969095191568\n",
      "6 Train Loss 1890.4072 Test MSE 3387.51344639536 Test RE 0.64847743149471\n",
      "7 Train Loss 1249.3431 Test MSE 2071.060172577528 Test RE 0.5070499110711438\n",
      "8 Train Loss 627.74915 Test MSE 705.9136609086557 Test RE 0.2960261967991201\n",
      "9 Train Loss 188.22162 Test MSE 99.5041950971968 Test RE 0.11114119136517561\n",
      "10 Train Loss 89.61673 Test MSE 13.246270492305467 Test RE 0.04055096203868715\n",
      "11 Train Loss 57.89395 Test MSE 5.2842882222872865 Test RE 0.025612242260211953\n",
      "12 Train Loss 33.77261 Test MSE 2.118024100093569 Test RE 0.016215106336942297\n",
      "13 Train Loss 17.699284 Test MSE 0.8764262976796726 Test RE 0.010430666322409058\n",
      "14 Train Loss 13.133561 Test MSE 0.3672159496206999 Test RE 0.006751730835368786\n",
      "15 Train Loss 9.624098 Test MSE 0.024225810814345564 Test RE 0.001734177363628361\n",
      "16 Train Loss 7.2837796 Test MSE 0.11145321362284255 Test RE 0.0037196377790180584\n",
      "17 Train Loss 6.7889953 Test MSE 0.11429913560235216 Test RE 0.003766828306627891\n",
      "18 Train Loss 5.9892817 Test MSE 0.1356821770053857 Test RE 0.004104079396490678\n",
      "19 Train Loss 4.8595243 Test MSE 0.07988077628489637 Test RE 0.003149020520446513\n",
      "20 Train Loss 4.063755 Test MSE 0.11897735301576652 Test RE 0.0038431426386505707\n",
      "21 Train Loss 3.793651 Test MSE 0.011491258430978204 Test RE 0.0011943679701721518\n",
      "22 Train Loss 3.7466292 Test MSE 0.012415049872339452 Test RE 0.0012414481527354428\n",
      "23 Train Loss 3.5288415 Test MSE 0.01871840222076766 Test RE 0.0015243641971927106\n",
      "24 Train Loss 3.091511 Test MSE 0.01461005673841099 Test RE 0.0013467292835616634\n",
      "25 Train Loss 2.8291671 Test MSE 0.006980278751042751 Test RE 0.000930873646558953\n",
      "26 Train Loss 2.6131856 Test MSE 0.015597904066571815 Test RE 0.001391513662581784\n",
      "27 Train Loss 2.496755 Test MSE 0.004884643589791542 Test RE 0.0007787011081125966\n",
      "28 Train Loss 2.436008 Test MSE 0.005332986699498985 Test RE 0.0008136536980132603\n",
      "29 Train Loss 2.3961308 Test MSE 0.006793262022509067 Test RE 0.0009183189268944777\n",
      "30 Train Loss 2.2346315 Test MSE 0.013937006800426241 Test RE 0.0013153432738460245\n",
      "31 Train Loss 2.0406916 Test MSE 0.0034450230349663885 Test RE 0.0006539588439417917\n",
      "32 Train Loss 1.9746596 Test MSE 0.005165671726060345 Test RE 0.000800788364490484\n",
      "33 Train Loss 1.9446396 Test MSE 0.0034952931299515526 Test RE 0.0006587128779148902\n",
      "34 Train Loss 1.7833797 Test MSE 0.006441037887691485 Test RE 0.0008941950867105996\n",
      "35 Train Loss 1.5212536 Test MSE 0.0028105046450242893 Test RE 0.0005906721657154794\n",
      "36 Train Loss 1.4698879 Test MSE 0.0027401380044088687 Test RE 0.0005832309608185751\n",
      "37 Train Loss 1.4293321 Test MSE 0.003414031239466155 Test RE 0.0006510106565752705\n",
      "38 Train Loss 1.3675563 Test MSE 0.007451869874874106 Test RE 0.0009618048963635227\n",
      "39 Train Loss 1.295021 Test MSE 0.01623950227647661 Test RE 0.0014198442583874898\n",
      "40 Train Loss 1.2193644 Test MSE 0.002181403463424653 Test RE 0.000520382102569156\n",
      "41 Train Loss 1.1913574 Test MSE 0.002929831026433586 Test RE 0.0006030809902275766\n",
      "42 Train Loss 1.1268426 Test MSE 0.0017601789289334987 Test RE 0.0004674474136735911\n",
      "43 Train Loss 0.98897487 Test MSE 0.0030281345924849236 Test RE 0.0006131149974876143\n",
      "44 Train Loss 0.9289162 Test MSE 0.007765936894264513 Test RE 0.000981863873391898\n",
      "45 Train Loss 0.91006666 Test MSE 0.003971851576113973 Test RE 0.0007021838843385398\n",
      "46 Train Loss 0.8878169 Test MSE 0.0036683537170031726 Test RE 0.0006748231224590863\n",
      "47 Train Loss 0.8644994 Test MSE 0.004299739406149142 Test RE 0.0007305928538291289\n",
      "48 Train Loss 0.81546813 Test MSE 0.01105810493218378 Test RE 0.0011716413908588726\n",
      "49 Train Loss 0.78809804 Test MSE 0.0027811100721858426 Test RE 0.0005875751786715243\n",
      "50 Train Loss 0.7768288 Test MSE 0.0034011543981575785 Test RE 0.0006497817749602832\n",
      "51 Train Loss 0.74727505 Test MSE 0.013524455381103409 Test RE 0.0012957291973700643\n",
      "52 Train Loss 0.71051526 Test MSE 0.003386275905279801 Test RE 0.0006483589683793794\n",
      "53 Train Loss 0.6646176 Test MSE 0.0010397896708496707 Test RE 0.000359275085817339\n",
      "54 Train Loss 0.65092427 Test MSE 0.002463849871860882 Test RE 0.0005530462771575058\n",
      "55 Train Loss 0.6458067 Test MSE 0.0022587828203286604 Test RE 0.0005295312444809723\n",
      "56 Train Loss 0.64156836 Test MSE 0.0009887446669742139 Test RE 0.0003503454078630673\n",
      "57 Train Loss 0.6220452 Test MSE 0.0009338103585513466 Test RE 0.0003404737984654566\n",
      "58 Train Loss 0.5876204 Test MSE 0.0013248234950686165 Test RE 0.0004055396883686528\n",
      "59 Train Loss 0.53892225 Test MSE 0.0008862465781338588 Test RE 0.00033168943459483503\n",
      "60 Train Loss 0.5145124 Test MSE 0.0018471325553101469 Test RE 0.0004788542912620414\n",
      "61 Train Loss 0.49078652 Test MSE 0.0012664544773486612 Test RE 0.00039650543456780065\n",
      "62 Train Loss 0.48150155 Test MSE 0.0007811014936871084 Test RE 0.0003113924557463396\n",
      "63 Train Loss 0.47634348 Test MSE 0.0006579894581974186 Test RE 0.00028580105013972004\n",
      "64 Train Loss 0.46480265 Test MSE 0.0006307648523184103 Test RE 0.00027982601972622396\n",
      "65 Train Loss 0.44763204 Test MSE 0.0009355420136988371 Test RE 0.0003407893390477091\n",
      "66 Train Loss 0.43593803 Test MSE 0.0020868693056152114 Test RE 0.0005089814774346424\n",
      "67 Train Loss 0.42101905 Test MSE 0.0026180906593129176 Test RE 0.0005700942923447014\n",
      "68 Train Loss 0.40287265 Test MSE 0.0015938455873379003 Test RE 0.0004448130032809755\n",
      "69 Train Loss 0.39039826 Test MSE 0.0008888430587656899 Test RE 0.0003321749627439575\n",
      "70 Train Loss 0.3847494 Test MSE 0.0007473863254419675 Test RE 0.00030459791491689895\n",
      "71 Train Loss 0.38326725 Test MSE 0.0005948250494534208 Test RE 0.00027173712551084323\n",
      "72 Train Loss 0.38067323 Test MSE 0.0006508828912734007 Test RE 0.00028425347352481587\n",
      "73 Train Loss 0.3611533 Test MSE 0.0010961143998121975 Test RE 0.00036887760877738824\n",
      "74 Train Loss 0.34124663 Test MSE 0.0010919251961568719 Test RE 0.00036817203336406357\n",
      "75 Train Loss 0.3289169 Test MSE 0.0005100772788098863 Test RE 0.0002516357500180848\n",
      "76 Train Loss 0.31451255 Test MSE 0.00040782555246971446 Test RE 0.00022500468911828756\n",
      "77 Train Loss 0.30839902 Test MSE 0.0006397637804553352 Test RE 0.0002818150465188545\n",
      "78 Train Loss 0.30142087 Test MSE 0.0006813575349502276 Test RE 0.00029083179507669005\n",
      "79 Train Loss 0.2988813 Test MSE 0.0004154650298806456 Test RE 0.00022710232984402554\n",
      "80 Train Loss 0.29691282 Test MSE 0.0003486724202637612 Test RE 0.000208047810930871\n",
      "81 Train Loss 0.29472092 Test MSE 0.00034194368860349014 Test RE 0.00020603056259884385\n",
      "82 Train Loss 0.29264775 Test MSE 0.0004049791458370205 Test RE 0.00022421810737823295\n",
      "83 Train Loss 0.2846679 Test MSE 0.0006098179860092126 Test RE 0.0002751404650579778\n",
      "84 Train Loss 0.2696144 Test MSE 0.000554220932617233 Test RE 0.0002622985046808676\n",
      "85 Train Loss 0.2605553 Test MSE 0.0007140447976553106 Test RE 0.00029772621894945097\n",
      "86 Train Loss 0.25275812 Test MSE 0.001394428657459035 Test RE 0.0004160566827847472\n",
      "87 Train Loss 0.24349827 Test MSE 0.0012959620361737514 Test RE 0.00040109799598634364\n",
      "88 Train Loss 0.23667221 Test MSE 0.00028349175341943277 Test RE 0.0001875964291302591\n",
      "89 Train Loss 0.23012431 Test MSE 0.00027031984390882356 Test RE 0.0001831864372924206\n",
      "90 Train Loss 0.22224489 Test MSE 0.00030897799899549694 Test RE 0.00019584754435099106\n",
      "91 Train Loss 0.2186184 Test MSE 0.0002634237187870174 Test RE 0.00018083470856151244\n",
      "92 Train Loss 0.21603233 Test MSE 0.00031680190534464606 Test RE 0.00019831165768053656\n",
      "93 Train Loss 0.21419056 Test MSE 0.0002687231912133737 Test RE 0.00018264463782996051\n",
      "94 Train Loss 0.2120438 Test MSE 0.0002392228986970787 Test RE 0.00017232795193712516\n",
      "95 Train Loss 0.20973235 Test MSE 0.000230961949432363 Test RE 0.00016932635927974533\n",
      "96 Train Loss 0.20763044 Test MSE 0.0002722992535595516 Test RE 0.0001838559028260169\n",
      "97 Train Loss 0.20655775 Test MSE 0.0002453124873834027 Test RE 0.00017450753357122487\n",
      "98 Train Loss 0.20479852 Test MSE 0.00026418266012117144 Test RE 0.0001810950196417659\n",
      "99 Train Loss 0.20262493 Test MSE 0.0004339885946445906 Test RE 0.0002321098177016219\n",
      "100 Train Loss 0.19958274 Test MSE 0.00022687673584955136 Test RE 0.00016782217099771383\n",
      "101 Train Loss 0.19034061 Test MSE 0.0002320373434411163 Test RE 0.00016972010613309257\n",
      "102 Train Loss 0.18476944 Test MSE 0.00044081150575206587 Test RE 0.00023392724881177816\n",
      "103 Train Loss 0.17619392 Test MSE 0.0003440711211532126 Test RE 0.00020667048738290056\n",
      "104 Train Loss 0.17226666 Test MSE 0.0003575418611676686 Test RE 0.0002106773275153445\n",
      "105 Train Loss 0.16947973 Test MSE 0.00042687564795719756 Test RE 0.00023019985326917198\n",
      "106 Train Loss 0.16771518 Test MSE 0.0003504300578165367 Test RE 0.0002085715302562817\n",
      "107 Train Loss 0.16629909 Test MSE 0.0002742376362806682 Test RE 0.0001845091383986592\n",
      "108 Train Loss 0.1647636 Test MSE 0.0002768866072279869 Test RE 0.00018539812055932799\n",
      "109 Train Loss 0.16283648 Test MSE 0.00021443197643794507 Test RE 0.00016315452628118063\n",
      "110 Train Loss 0.16074397 Test MSE 0.0003199001610417497 Test RE 0.00019927902133745707\n",
      "111 Train Loss 0.15736108 Test MSE 0.0002145236213524857 Test RE 0.0001631893874189968\n",
      "112 Train Loss 0.15568425 Test MSE 0.00021624372240734718 Test RE 0.0001638423266992827\n",
      "113 Train Loss 0.15428744 Test MSE 0.0002575399655326359 Test RE 0.00017880376897071415\n",
      "114 Train Loss 0.15268922 Test MSE 0.0002678873913454854 Test RE 0.00018236038017574414\n",
      "115 Train Loss 0.151231 Test MSE 0.0003869930961187723 Test RE 0.00021918254281451353\n",
      "116 Train Loss 0.14939398 Test MSE 0.00026625505168207113 Test RE 0.00018180393568006055\n",
      "117 Train Loss 0.14665893 Test MSE 0.0003328419834273556 Test RE 0.0002032700542228182\n",
      "118 Train Loss 0.1453612 Test MSE 0.00023349437500703337 Test RE 0.00017025213378938885\n",
      "119 Train Loss 0.14406112 Test MSE 0.0003550361885557661 Test RE 0.00020993781056703392\n",
      "120 Train Loss 0.14146502 Test MSE 0.0009371778738196957 Test RE 0.0003410871558182577\n",
      "121 Train Loss 0.13644294 Test MSE 0.0003521162707525096 Test RE 0.00020907273433862027\n",
      "122 Train Loss 0.1340655 Test MSE 0.0002775310667301601 Test RE 0.00018561375420532309\n",
      "123 Train Loss 0.13206582 Test MSE 0.0005324164299365725 Test RE 0.00025708697656536667\n",
      "124 Train Loss 0.12828225 Test MSE 0.00042146605292672545 Test RE 0.00022873659526437883\n",
      "125 Train Loss 0.124212615 Test MSE 0.0013741314335358333 Test RE 0.0004130175341656931\n",
      "126 Train Loss 0.116935834 Test MSE 0.00034493997276759185 Test RE 0.0002069312659807704\n",
      "127 Train Loss 0.11383741 Test MSE 0.00028601719161055295 Test RE 0.00018843016193699307\n",
      "128 Train Loss 0.109569095 Test MSE 0.0002508954187783649 Test RE 0.00017648212241178025\n",
      "129 Train Loss 0.1026215 Test MSE 0.0005632367969933942 Test RE 0.00026442338613757614\n",
      "130 Train Loss 0.097638905 Test MSE 0.0002190205388963376 Test RE 0.00016489093245880424\n",
      "131 Train Loss 0.09409045 Test MSE 0.00016320070741435223 Test RE 0.000142336201206482\n",
      "132 Train Loss 0.092960425 Test MSE 0.0001240220571838669 Test RE 0.00012408058082577614\n",
      "133 Train Loss 0.09146503 Test MSE 0.0003164465619553968 Test RE 0.00019820040754768683\n",
      "134 Train Loss 0.08888426 Test MSE 0.00018389278957608188 Test RE 0.00015109034149957264\n",
      "135 Train Loss 0.08733681 Test MSE 0.00022211075047539843 Test RE 0.0001660501002424091\n",
      "136 Train Loss 0.086211555 Test MSE 0.00011170101432334582 Test RE 0.00011775596363237259\n",
      "137 Train Loss 0.08408729 Test MSE 0.0003785262065583753 Test RE 0.0002167715727514988\n",
      "138 Train Loss 0.08153689 Test MSE 0.0002803571987080416 Test RE 0.00018655642396091\n",
      "139 Train Loss 0.08060988 Test MSE 0.00013180761000681484 Test RE 0.00012791591890103392\n",
      "140 Train Loss 0.078404315 Test MSE 0.00012903425236142008 Test RE 0.0001265630281608274\n",
      "141 Train Loss 0.076267585 Test MSE 0.00023468770935751375 Test RE 0.00017068663846474472\n",
      "142 Train Loss 0.075110845 Test MSE 0.00016454835819109163 Test RE 0.00014292267269985093\n",
      "143 Train Loss 0.073203824 Test MSE 0.00011162463886807875 Test RE 0.0001177156989881098\n",
      "144 Train Loss 0.07133022 Test MSE 0.00018105777340425138 Test RE 0.00014992116210676425\n",
      "145 Train Loss 0.06976947 Test MSE 0.00045804871696946943 Test RE 0.00023845706149477411\n",
      "146 Train Loss 0.066392764 Test MSE 0.0010682698677361641 Test RE 0.00036416218119420836\n",
      "147 Train Loss 0.062329743 Test MSE 0.00030765015577197217 Test RE 0.00019542626057672392\n",
      "148 Train Loss 0.05914671 Test MSE 0.00012231055089826186 Test RE 0.00012322144956626203\n",
      "149 Train Loss 0.056216184 Test MSE 0.0001273423345609693 Test RE 0.0001257305328467719\n",
      "150 Train Loss 0.054518513 Test MSE 0.00014379701281209628 Test RE 0.00013360702214609645\n",
      "151 Train Loss 0.053534243 Test MSE 6.027571206601432e-05 Test RE 8.650187617394534e-05\n",
      "152 Train Loss 0.052813962 Test MSE 6.888601684272238e-05 Test RE 9.247405227181709e-05\n",
      "153 Train Loss 0.052070774 Test MSE 7.876712746002864e-05 Test RE 9.888418902750794e-05\n",
      "154 Train Loss 0.050838683 Test MSE 0.000168513841701595 Test RE 0.0001446345811103123\n",
      "155 Train Loss 0.050007574 Test MSE 0.00019023254046620234 Test RE 0.00015367271217618628\n",
      "156 Train Loss 0.04923318 Test MSE 9.236037892895945e-05 Test RE 0.00010707724912033767\n",
      "157 Train Loss 0.04816488 Test MSE 7.522791155683479e-05 Test RE 9.663709251187138e-05\n",
      "158 Train Loss 0.047497135 Test MSE 9.201735942054532e-05 Test RE 0.0001068782257296428\n",
      "159 Train Loss 0.045998614 Test MSE 0.00012037177172249671 Test RE 0.0001222409394148666\n",
      "160 Train Loss 0.044556044 Test MSE 0.00011365360991927751 Test RE 0.00011878072441931987\n",
      "161 Train Loss 0.042717032 Test MSE 0.00021734329036069094 Test RE 0.00016425835573763005\n",
      "162 Train Loss 0.041497726 Test MSE 5.675573229093487e-05 Test RE 8.393811617722559e-05\n",
      "163 Train Loss 0.040265337 Test MSE 5.669042034575329e-05 Test RE 8.388980616971213e-05\n",
      "164 Train Loss 0.037874795 Test MSE 0.00010136579364403935 Test RE 0.00011217602972990364\n",
      "165 Train Loss 0.036526315 Test MSE 7.815582724111567e-05 Test RE 9.849972873571471e-05\n",
      "166 Train Loss 0.03606606 Test MSE 9.89841295043445e-05 Test RE 0.0001108503672828702\n",
      "167 Train Loss 0.035245083 Test MSE 7.39064504330063e-05 Test RE 9.578456353793828e-05\n",
      "168 Train Loss 0.033852406 Test MSE 0.00019946934544999491 Test RE 0.00015735930675209848\n",
      "169 Train Loss 0.032668665 Test MSE 6.249863455255698e-05 Test RE 8.808249684120965e-05\n",
      "170 Train Loss 0.0318895 Test MSE 6.966488603916726e-05 Test RE 9.299536810844015e-05\n",
      "171 Train Loss 0.031165868 Test MSE 4.954570340895261e-05 Test RE 7.842551000581679e-05\n",
      "172 Train Loss 0.03056288 Test MSE 7.337705129938743e-05 Test RE 9.544088989096827e-05\n",
      "173 Train Loss 0.029972134 Test MSE 4.15701648823245e-05 Test RE 7.183651013986791e-05\n",
      "174 Train Loss 0.029740853 Test MSE 4.935875195236018e-05 Test RE 7.827740815911874e-05\n",
      "175 Train Loss 0.029405592 Test MSE 4.857200495610722e-05 Test RE 7.765105626342008e-05\n",
      "176 Train Loss 0.029130688 Test MSE 5.5395057820793835e-05 Test RE 8.292583674349885e-05\n",
      "177 Train Loss 0.028632974 Test MSE 0.00016116435541557047 Test RE 0.00014144540715111992\n",
      "178 Train Loss 0.028010486 Test MSE 5.9455913760853975e-05 Test RE 8.591161464858017e-05\n",
      "179 Train Loss 0.027439564 Test MSE 4.614192514676638e-05 Test RE 7.568367419991387e-05\n",
      "180 Train Loss 0.026920665 Test MSE 4.6015000770636084e-05 Test RE 7.5579509514852e-05\n",
      "181 Train Loss 0.026429921 Test MSE 4.84131925160856e-05 Test RE 7.752400725166637e-05\n",
      "182 Train Loss 0.025924705 Test MSE 4.565247873435736e-05 Test RE 7.528120009378627e-05\n",
      "183 Train Loss 0.025471557 Test MSE 4.555105783059595e-05 Test RE 7.519753177194436e-05\n",
      "184 Train Loss 0.025267959 Test MSE 3.674029913125986e-05 Test RE 6.753450115797517e-05\n",
      "185 Train Loss 0.024752812 Test MSE 5.18855417901007e-05 Test RE 8.025600367277661e-05\n",
      "186 Train Loss 0.024112752 Test MSE 3.264959815197935e-05 Test RE 6.366390482427234e-05\n",
      "187 Train Loss 0.023870584 Test MSE 3.281350495354729e-05 Test RE 6.382350684162768e-05\n",
      "188 Train Loss 0.023544038 Test MSE 9.96213462599912e-05 Test RE 0.00011120659810345112\n",
      "189 Train Loss 0.022526545 Test MSE 0.0003561719969485202 Test RE 0.00021027335202961382\n",
      "190 Train Loss 0.021641944 Test MSE 5.086128936023848e-05 Test RE 7.945990383738727e-05\n",
      "191 Train Loss 0.021193279 Test MSE 4.139744951289392e-05 Test RE 7.168712194680916e-05\n",
      "192 Train Loss 0.020798378 Test MSE 3.11209089733818e-05 Test RE 6.21556323241659e-05\n",
      "193 Train Loss 0.020047331 Test MSE 0.00013249817580311674 Test RE 0.00012825056938234469\n",
      "194 Train Loss 0.01925254 Test MSE 9.599625451059231e-05 Test RE 0.00010916451675451923\n",
      "195 Train Loss 0.018689035 Test MSE 4.315262003945713e-05 Test RE 7.319104315996216e-05\n",
      "196 Train Loss 0.018400053 Test MSE 3.078669006770468e-05 Test RE 6.182097528137287e-05\n",
      "197 Train Loss 0.018239839 Test MSE 4.5885971978983884e-05 Test RE 7.547347041375579e-05\n",
      "198 Train Loss 0.017986808 Test MSE 4.949487619107484e-05 Test RE 7.838527267898534e-05\n",
      "199 Train Loss 0.017580396 Test MSE 6.029686772974116e-05 Test RE 8.65170551240984e-05\n",
      "Training time: 71.31\n",
      "Training time: 71.31\n",
      "1D_FODE_rowdymedium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 18413.844 Test MSE 8062.294610176605 Test RE 1.0004230382752226\n",
      "1 Train Loss 17262.52 Test MSE 8017.474084399563 Test RE 0.997638348472192\n",
      "2 Train Loss 16032.276 Test MSE 7760.919751294601 Test RE 0.9815466581361862\n",
      "3 Train Loss 11964.813 Test MSE 6911.286308377689 Test RE 0.9262618873219257\n",
      "4 Train Loss 7944.1895 Test MSE 5952.279909341044 Test RE 0.8595992449193309\n",
      "5 Train Loss 5870.6494 Test MSE 4254.806533357892 Test RE 0.7267654299950226\n",
      "6 Train Loss 3964.6267 Test MSE 2170.8313001003644 Test RE 0.5191195560706314\n",
      "7 Train Loss 2602.3164 Test MSE 1095.5225010415593 Test RE 0.36877799887961765\n",
      "8 Train Loss 1720.4187 Test MSE 507.7720177311519 Test RE 0.25106648039438323\n",
      "9 Train Loss 1104.3381 Test MSE 230.794997221827 Test RE 0.16926514893627087\n",
      "10 Train Loss 589.0032 Test MSE 160.85216957745504 Test RE 0.14130834626855404\n",
      "11 Train Loss 330.7919 Test MSE 30.100935147433855 Test RE 0.061128585490876915\n",
      "12 Train Loss 214.78769 Test MSE 36.27770043272827 Test RE 0.06710798943283658\n",
      "13 Train Loss 158.3773 Test MSE 6.380593381524638 Test RE 0.02814393939310178\n",
      "14 Train Loss 99.31786 Test MSE 10.96264933043038 Test RE 0.03689029375349973\n",
      "15 Train Loss 44.179077 Test MSE 4.752690810210253 Test RE 0.024289810872925918\n",
      "16 Train Loss 30.663118 Test MSE 0.4830714030154626 Test RE 0.007743905003606343\n",
      "17 Train Loss 24.461708 Test MSE 1.1647058226252252 Test RE 0.012024373994255634\n",
      "18 Train Loss 13.557299 Test MSE 0.6726719412477201 Test RE 0.009138102153273807\n",
      "19 Train Loss 10.92178 Test MSE 0.22899789725797892 Test RE 0.00533175395293499\n",
      "20 Train Loss 10.538153 Test MSE 0.22393475568560142 Test RE 0.005272481978558596\n",
      "21 Train Loss 10.359497 Test MSE 0.046458565437903866 Test RE 0.002401525763202074\n",
      "22 Train Loss 10.1072645 Test MSE 0.1556999616957221 Test RE 0.004396414233258684\n",
      "23 Train Loss 8.978791 Test MSE 0.04048285067502129 Test RE 0.0022417640257347024\n",
      "24 Train Loss 7.3534074 Test MSE 0.23548505380500928 Test RE 0.005406746729603532\n",
      "25 Train Loss 6.0075183 Test MSE 0.3582384613576285 Test RE 0.006668688902025555\n",
      "26 Train Loss 5.490313 Test MSE 0.1063392459590836 Test RE 0.0036332990105157003\n",
      "27 Train Loss 5.18501 Test MSE 0.016245371802422602 Test RE 0.0014201008259741984\n",
      "28 Train Loss 5.062074 Test MSE 0.030671432611799186 Test RE 0.001951288042344803\n",
      "29 Train Loss 4.733625 Test MSE 0.04860730546945228 Test RE 0.002456434146056759\n",
      "30 Train Loss 4.117142 Test MSE 0.08591383716163366 Test RE 0.003265772371008208\n",
      "31 Train Loss 3.1877022 Test MSE 0.08973788952622049 Test RE 0.0033376614149466504\n",
      "32 Train Loss 2.5173693 Test MSE 0.014938404602390511 Test RE 0.0013617784629147735\n",
      "33 Train Loss 2.3270142 Test MSE 0.021569337909938046 Test RE 0.0016363370336710992\n",
      "34 Train Loss 1.9989882 Test MSE 0.013487676366565065 Test RE 0.0012939661656989263\n",
      "35 Train Loss 1.9108415 Test MSE 0.013478020993529793 Test RE 0.0012935029293917493\n",
      "36 Train Loss 1.8606834 Test MSE 0.021081147856232878 Test RE 0.0016177130147849445\n",
      "37 Train Loss 1.8403909 Test MSE 0.007700039386591547 Test RE 0.0009776892177287876\n",
      "38 Train Loss 1.8174155 Test MSE 0.00537689640410704 Test RE 0.00081699648280195\n",
      "39 Train Loss 1.6811516 Test MSE 0.009017022364556877 Test RE 0.0010580006286940392\n",
      "40 Train Loss 1.5248652 Test MSE 0.08699763304799407 Test RE 0.0032863065377303794\n",
      "41 Train Loss 1.3509151 Test MSE 0.014956807331004175 Test RE 0.0013626169971112934\n",
      "42 Train Loss 1.210872 Test MSE 0.005581826390738398 Test RE 0.0008324200163313792\n",
      "43 Train Loss 1.1444753 Test MSE 0.008611833195321638 Test RE 0.0010339562362684084\n",
      "44 Train Loss 1.1227851 Test MSE 0.00870808333761099 Test RE 0.0010397181866472675\n",
      "45 Train Loss 1.1024424 Test MSE 0.0033865732200156445 Test RE 0.0006483874306857253\n",
      "46 Train Loss 1.0930969 Test MSE 0.0037579289596792378 Test RE 0.0006830124738886108\n",
      "47 Train Loss 1.0875635 Test MSE 0.003481330516596521 Test RE 0.0006573958844010209\n",
      "48 Train Loss 1.0802333 Test MSE 0.0028505243701089393 Test RE 0.0005948626911222946\n",
      "49 Train Loss 1.0630842 Test MSE 0.0034504085554724457 Test RE 0.000654469803284404\n",
      "50 Train Loss 1.045692 Test MSE 0.003438403036860684 Test RE 0.000653330214172317\n",
      "51 Train Loss 1.0348166 Test MSE 0.002458978789706392 Test RE 0.0005524993147206693\n",
      "52 Train Loss 1.0248302 Test MSE 0.002839434334056654 Test RE 0.0005937043993764481\n",
      "53 Train Loss 1.0092528 Test MSE 0.003968925515416846 Test RE 0.0007019251874590298\n",
      "54 Train Loss 0.9742749 Test MSE 0.0073192042946650035 Test RE 0.0009532049457930254\n",
      "55 Train Loss 0.95685005 Test MSE 0.003882566676635549 Test RE 0.0006942466834600743\n",
      "56 Train Loss 0.93021077 Test MSE 0.005886219643970134 Test RE 0.0008548158853563196\n",
      "57 Train Loss 0.9026325 Test MSE 0.006321736227358713 Test RE 0.0008858751878947176\n",
      "58 Train Loss 0.882326 Test MSE 0.0038705046895414976 Test RE 0.0006931674349579976\n",
      "59 Train Loss 0.86240757 Test MSE 0.003301012808620988 Test RE 0.0006401444095358203\n",
      "60 Train Loss 0.8468486 Test MSE 0.005408227275578956 Test RE 0.0008193733215712554\n",
      "61 Train Loss 0.83846104 Test MSE 0.0067967351384395185 Test RE 0.0009185536462775914\n",
      "62 Train Loss 0.82756895 Test MSE 0.00855701393695243 Test RE 0.0010306601201962255\n",
      "63 Train Loss 0.8096716 Test MSE 0.006961174133287448 Test RE 0.0009295989001666392\n",
      "64 Train Loss 0.79486734 Test MSE 0.00492698083675472 Test RE 0.0007820684911621331\n",
      "65 Train Loss 0.78636295 Test MSE 0.005894980638684965 Test RE 0.0008554517988394199\n",
      "66 Train Loss 0.7772157 Test MSE 0.004177137016006599 Test RE 0.0007201014954591379\n",
      "67 Train Loss 0.76175344 Test MSE 0.0037050072357304514 Test RE 0.0006781860973273157\n",
      "68 Train Loss 0.7440358 Test MSE 0.0044592991639765866 Test RE 0.0007440252199478209\n",
      "69 Train Loss 0.7310346 Test MSE 0.007216378405872192 Test RE 0.0009464855794431271\n",
      "70 Train Loss 0.70421374 Test MSE 0.006282792148012958 Test RE 0.0008831423239306979\n",
      "71 Train Loss 0.6853986 Test MSE 0.0019445230437294483 Test RE 0.0004913159909525323\n",
      "72 Train Loss 0.66157615 Test MSE 0.005556129638697001 Test RE 0.0008305017225107605\n",
      "73 Train Loss 0.64738333 Test MSE 0.009293057493903165 Test RE 0.0010740726659303318\n",
      "74 Train Loss 0.6156459 Test MSE 0.006717181805667482 Test RE 0.0009131621539492085\n",
      "75 Train Loss 0.59337115 Test MSE 0.0015853282484644795 Test RE 0.0004436228948469977\n",
      "76 Train Loss 0.5661359 Test MSE 0.00445172096253176 Test RE 0.0007433927471856889\n",
      "77 Train Loss 0.55498224 Test MSE 0.006530191824541253 Test RE 0.0009003623411936819\n",
      "78 Train Loss 0.537504 Test MSE 0.001250045346699331 Test RE 0.00039392834932858243\n",
      "79 Train Loss 0.51428735 Test MSE 0.007719175767789931 Test RE 0.000978903355912279\n",
      "80 Train Loss 0.49432528 Test MSE 0.0026539586045456385 Test RE 0.0005739861651249338\n",
      "81 Train Loss 0.48684946 Test MSE 0.001746790640808297 Test RE 0.00046566626899763525\n",
      "82 Train Loss 0.47560403 Test MSE 0.0021435675789557413 Test RE 0.0005158494148631935\n",
      "83 Train Loss 0.44442913 Test MSE 0.004248693819023293 Test RE 0.0007262431846039427\n",
      "84 Train Loss 0.42572135 Test MSE 0.003976811467032037 Test RE 0.0007026221772606947\n",
      "85 Train Loss 0.41771317 Test MSE 0.002747476664226744 Test RE 0.0005840114455366506\n",
      "86 Train Loss 0.41211137 Test MSE 0.0021174103341990674 Test RE 0.0005126923845278962\n",
      "87 Train Loss 0.3981978 Test MSE 0.004238232790261607 Test RE 0.0007253485645898088\n",
      "88 Train Loss 0.37683824 Test MSE 0.00215431726956775 Test RE 0.0005171412535056974\n",
      "89 Train Loss 0.35825816 Test MSE 0.0008480275812205383 Test RE 0.00032445863822050657\n",
      "90 Train Loss 0.33856365 Test MSE 0.0007799931875641585 Test RE 0.0003111714597059792\n",
      "91 Train Loss 0.3238095 Test MSE 0.004738098697347628 Test RE 0.0007669311964032195\n",
      "92 Train Loss 0.29529282 Test MSE 0.00488475393742554 Test RE 0.0007787099037737341\n",
      "93 Train Loss 0.272772 Test MSE 0.0008041596713649388 Test RE 0.0003159551924879503\n",
      "94 Train Loss 0.2589187 Test MSE 0.0008324370105532157 Test RE 0.0003214622963965941\n",
      "95 Train Loss 0.25241122 Test MSE 0.0018360556112651184 Test RE 0.0004774163277896772\n",
      "96 Train Loss 0.24451295 Test MSE 0.0010663388262413297 Test RE 0.0003638328962544986\n",
      "97 Train Loss 0.23991768 Test MSE 0.0007520795844200913 Test RE 0.0003055527890036542\n",
      "98 Train Loss 0.23637868 Test MSE 0.0010461440950996195 Test RE 0.00036037122526685954\n",
      "99 Train Loss 0.23436882 Test MSE 0.0010048234169103586 Test RE 0.0003531825404416329\n",
      "100 Train Loss 0.231571 Test MSE 0.0007267877201881753 Test RE 0.000300371098465512\n",
      "101 Train Loss 0.22844967 Test MSE 0.001000892340511042 Test RE 0.00035249100195670116\n",
      "102 Train Loss 0.22399123 Test MSE 0.0018730984059091174 Test RE 0.0004822082645675495\n",
      "103 Train Loss 0.21538174 Test MSE 0.0010343270139268777 Test RE 0.0003583300961401216\n",
      "104 Train Loss 0.20562196 Test MSE 0.0007104977379363771 Test RE 0.0002969858120095611\n",
      "105 Train Loss 0.20062298 Test MSE 0.0007603919429381007 Test RE 0.00030723670978564276\n",
      "106 Train Loss 0.19403234 Test MSE 0.0007778741704819509 Test RE 0.0003107484905741196\n",
      "107 Train Loss 0.19157839 Test MSE 0.0008480224058761341 Test RE 0.0003244576481655856\n",
      "108 Train Loss 0.18974695 Test MSE 0.001262049987991228 Test RE 0.0003958153485600274\n",
      "109 Train Loss 0.18727086 Test MSE 0.0019534889676569534 Test RE 0.0004924473829561483\n",
      "110 Train Loss 0.18317047 Test MSE 0.0019397020373593985 Test RE 0.000490706559380573\n",
      "111 Train Loss 0.17959374 Test MSE 0.002062663949552843 Test RE 0.000506021059322819\n",
      "112 Train Loss 0.1730166 Test MSE 0.0006354311776475389 Test RE 0.00028085917270440026\n",
      "113 Train Loss 0.16851263 Test MSE 0.000503991487972191 Test RE 0.00025013009793811014\n",
      "114 Train Loss 0.16101114 Test MSE 0.0012928358662705362 Test RE 0.0004006139318168169\n",
      "115 Train Loss 0.15636589 Test MSE 0.0013060833969295448 Test RE 0.00040266122152995195\n",
      "116 Train Loss 0.15218785 Test MSE 0.00030721947982921484 Test RE 0.00019528942517519555\n",
      "117 Train Loss 0.14615025 Test MSE 0.0007686904023142653 Test RE 0.00030890865864280603\n",
      "118 Train Loss 0.14193574 Test MSE 0.0007688596753400112 Test RE 0.0003089426691005937\n",
      "119 Train Loss 0.13847697 Test MSE 0.001754396907853245 Test RE 0.000466679021889281\n",
      "120 Train Loss 0.13517687 Test MSE 0.0004251361395853948 Test RE 0.000229730344938626\n",
      "121 Train Loss 0.13364135 Test MSE 0.00031493718096995907 Test RE 0.00019772715621925333\n",
      "122 Train Loss 0.13115545 Test MSE 0.0004388049048480511 Test RE 0.00023339421595657513\n",
      "123 Train Loss 0.12746632 Test MSE 0.0007317705402650095 Test RE 0.00030139900423366804\n",
      "124 Train Loss 0.12345256 Test MSE 0.0004320066346740013 Test RE 0.00023157920606761356\n",
      "125 Train Loss 0.12139444 Test MSE 0.00039632247532348403 Test RE 0.00022180876473212307\n",
      "126 Train Loss 0.11975175 Test MSE 0.0004550337668992329 Test RE 0.00023767098453897792\n",
      "127 Train Loss 0.118176624 Test MSE 0.0005294084099189306 Test RE 0.00025635970924706635\n",
      "128 Train Loss 0.11724539 Test MSE 0.0006626554719899402 Test RE 0.00028681261332699743\n",
      "129 Train Loss 0.116488054 Test MSE 0.0005244189098876674 Test RE 0.000255148796434212\n",
      "130 Train Loss 0.11614206 Test MSE 0.0006640860701575711 Test RE 0.0002871220443963721\n",
      "131 Train Loss 0.11594361 Test MSE 0.0007125430197913572 Test RE 0.0002974129655030569\n",
      "132 Train Loss 0.11577731 Test MSE 0.000665610919008164 Test RE 0.00028745149467557826\n",
      "133 Train Loss 0.11563327 Test MSE 0.0005468334916242046 Test RE 0.0002605444972449499\n",
      "134 Train Loss 0.11557786 Test MSE 0.0005260693573290287 Test RE 0.0002555499822632503\n",
      "135 Train Loss 0.11552663 Test MSE 0.00056070280284908 Test RE 0.00026382789712742834\n",
      "136 Train Loss 0.11552144 Test MSE 0.0005675010481239166 Test RE 0.00026542246998095787\n",
      "137 Train Loss 0.11550612 Test MSE 0.0005850761090590312 Test RE 0.0002695010953254157\n",
      "138 Train Loss 0.11550606 Test MSE 0.0005850517615778097 Test RE 0.0002694954877292225\n",
      "139 Train Loss 0.115504675 Test MSE 0.000585428777958263 Test RE 0.00026958230726934287\n",
      "140 Train Loss 0.11530219 Test MSE 0.0005905169501652058 Test RE 0.0002707512911775779\n",
      "141 Train Loss 0.11439504 Test MSE 0.0005012255911770216 Test RE 0.0002494427987875029\n",
      "142 Train Loss 0.11266632 Test MSE 0.0004551366355179714 Test RE 0.00023769784793467512\n",
      "143 Train Loss 0.11205767 Test MSE 0.0005576696755290318 Test RE 0.0002631133396650011\n",
      "144 Train Loss 0.111337684 Test MSE 0.0006020912162869996 Test RE 0.0002733918086285557\n",
      "145 Train Loss 0.11020073 Test MSE 0.0003592711838591079 Test RE 0.00021118620444294172\n",
      "146 Train Loss 0.1094631 Test MSE 0.0003012223588631409 Test RE 0.00019337394393642563\n",
      "147 Train Loss 0.10793788 Test MSE 0.0006693048614348542 Test RE 0.0002882480261823853\n",
      "148 Train Loss 0.10491223 Test MSE 0.000725453922391789 Test RE 0.00030009535200092575\n",
      "149 Train Loss 0.101618744 Test MSE 0.0003165090507383548 Test RE 0.00019821997592409942\n",
      "150 Train Loss 0.09710559 Test MSE 0.001742387480495722 Test RE 0.00046507899284159107\n",
      "151 Train Loss 0.084298655 Test MSE 0.00047419967864178927 Test RE 0.0002426246824645922\n",
      "152 Train Loss 0.07543059 Test MSE 0.000609706435439575 Test RE 0.00027511529895922195\n",
      "153 Train Loss 0.072154045 Test MSE 0.0004209386718715497 Test RE 0.0002285934412590905\n",
      "154 Train Loss 0.06981051 Test MSE 0.0013777219290731185 Test RE 0.0004135567730409684\n",
      "155 Train Loss 0.06821267 Test MSE 0.0009204452475262933 Test RE 0.0003380285108665268\n",
      "156 Train Loss 0.06465141 Test MSE 0.0010659115811257143 Test RE 0.0003637600013183104\n",
      "157 Train Loss 0.060921695 Test MSE 0.0009991796977797615 Test RE 0.0003521892963708696\n",
      "158 Train Loss 0.05924345 Test MSE 0.0006215519452530566 Test RE 0.0002777749431261911\n",
      "159 Train Loss 0.05829678 Test MSE 0.0003195399530547345 Test RE 0.00019916679552158518\n",
      "160 Train Loss 0.05779038 Test MSE 0.00011422972190768865 Test RE 0.00011908139458287715\n",
      "161 Train Loss 0.05736745 Test MSE 0.0001646352229443199 Test RE 0.00014296039202080815\n",
      "162 Train Loss 0.057177473 Test MSE 0.0003020097264466511 Test RE 0.00019362650986364395\n",
      "163 Train Loss 0.05707531 Test MSE 0.0003510028734245889 Test RE 0.00020874192694778575\n",
      "164 Train Loss 0.056808047 Test MSE 0.0002955363538828327 Test RE 0.00019154014323438263\n",
      "165 Train Loss 0.0563539 Test MSE 0.00015089637163115627 Test RE 0.0001368654251770607\n",
      "166 Train Loss 0.05580484 Test MSE 0.00012256510124242372 Test RE 0.00012334960596615928\n",
      "167 Train Loss 0.054660536 Test MSE 0.0002966899767551124 Test RE 0.0001919136165371408\n",
      "168 Train Loss 0.053510446 Test MSE 0.00035114799931704557 Test RE 0.00020878507577939373\n",
      "169 Train Loss 0.052717786 Test MSE 0.0005346938484110964 Test RE 0.00025763623633398423\n",
      "170 Train Loss 0.051680375 Test MSE 0.0011626078980235802 Test RE 0.0003799014811954616\n",
      "171 Train Loss 0.050320625 Test MSE 0.0004058508500705326 Test RE 0.00022445928869899506\n",
      "172 Train Loss 0.049345497 Test MSE 0.00013842633189077585 Test RE 0.00013108823249428363\n",
      "173 Train Loss 0.048803646 Test MSE 0.00018218225845692277 Test RE 0.00015038599484633734\n",
      "174 Train Loss 0.048410114 Test MSE 0.00028993209579171084 Test RE 0.00018971536241127633\n",
      "175 Train Loss 0.04786197 Test MSE 0.0002884224768166093 Test RE 0.00018922081266471578\n",
      "176 Train Loss 0.04717377 Test MSE 0.00020837048343610282 Test RE 0.000160831996088015\n",
      "177 Train Loss 0.046314534 Test MSE 0.00048201243013459274 Test RE 0.00024461521770026456\n",
      "178 Train Loss 0.04548543 Test MSE 0.0008694123550511419 Test RE 0.00032852411658666194\n",
      "179 Train Loss 0.044576358 Test MSE 0.0004845843713786645 Test RE 0.0002452669632958292\n",
      "180 Train Loss 0.043924063 Test MSE 0.00012541485747127082 Test RE 0.00012477536438298408\n",
      "181 Train Loss 0.043436337 Test MSE 0.00016915362238074453 Test RE 0.0001449088812709186\n",
      "182 Train Loss 0.042752262 Test MSE 0.00015917044896718394 Test RE 0.0001405677110441333\n",
      "183 Train Loss 0.042265993 Test MSE 9.233211901505166e-05 Test RE 0.00010706086641716278\n",
      "184 Train Loss 0.042013522 Test MSE 0.0001158066461762802 Test RE 0.00011990052771304988\n",
      "185 Train Loss 0.041793622 Test MSE 0.00013690821902703488 Test RE 0.0001303674326093951\n",
      "186 Train Loss 0.041572843 Test MSE 7.626455056072846e-05 Test RE 9.730064293403019e-05\n",
      "187 Train Loss 0.041283496 Test MSE 6.697130430453671e-05 Test RE 9.11798200858626e-05\n",
      "188 Train Loss 0.041023247 Test MSE 8.67695264432054e-05 Test RE 0.00010378580685232624\n",
      "189 Train Loss 0.04075144 Test MSE 0.00011865114702754074 Test RE 0.00012136412325211745\n",
      "190 Train Loss 0.040506486 Test MSE 0.00010124333504300973 Test RE 0.00011210825010460295\n",
      "191 Train Loss 0.040027324 Test MSE 7.19839606390311e-05 Test RE 9.453055801003793e-05\n",
      "192 Train Loss 0.039474025 Test MSE 0.00010511429258835353 Test RE 0.00011423133130419477\n",
      "193 Train Loss 0.039052147 Test MSE 0.0002050939495249937 Test RE 0.0001595624795799025\n",
      "194 Train Loss 0.03888381 Test MSE 0.00022324645371751134 Test RE 0.0001664740850862225\n",
      "195 Train Loss 0.03867287 Test MSE 0.0001319655709408561 Test RE 0.00012799254447643004\n",
      "196 Train Loss 0.038396947 Test MSE 7.871558632130332e-05 Test RE 9.885183138111275e-05\n",
      "197 Train Loss 0.038048256 Test MSE 0.00018868092596127336 Test RE 0.0001530447202278287\n",
      "198 Train Loss 0.03726222 Test MSE 0.00024198370703880836 Test RE 0.00017331949506687458\n",
      "199 Train Loss 0.036810257 Test MSE 7.249491486711945e-05 Test RE 9.486546163962217e-05\n",
      "Training time: 71.23\n",
      "Training time: 71.23\n",
      "1D_FODE_rowdymedium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 18403.08 Test MSE 8066.251529041993 Test RE 1.000668508540917\n",
      "1 Train Loss 16788.23 Test MSE 8699.40123031986 Test RE 1.0391997490286948\n",
      "2 Train Loss 14000.365 Test MSE 9878.765832041765 Test RE 1.10740300543637\n",
      "3 Train Loss 12962.49 Test MSE 9118.717374476433 Test RE 1.0639500272971734\n",
      "4 Train Loss 11472.376 Test MSE 7981.669565094541 Test RE 0.995408223992105\n",
      "5 Train Loss 10359.233 Test MSE 4271.47256950015 Test RE 0.7281874054787192\n",
      "6 Train Loss 7605.0396 Test MSE 2911.001843776597 Test RE 0.6011399524079122\n",
      "7 Train Loss 6175.9897 Test MSE 2030.5998179297283 Test RE 0.502072603322937\n",
      "8 Train Loss 5463.2573 Test MSE 899.6560148129389 Test RE 0.3341893428176849\n",
      "9 Train Loss 5338.2334 Test MSE 542.4027656468297 Test RE 0.2594868177139081\n",
      "10 Train Loss 5261.649 Test MSE 298.9781351656159 Test RE 0.19265224164674297\n",
      "11 Train Loss 5127.7295 Test MSE 173.4381159569372 Test RE 0.14673260436984228\n",
      "12 Train Loss 4998.9307 Test MSE 150.37164792722197 Test RE 0.13662725154121838\n",
      "13 Train Loss 4923.3486 Test MSE 192.34020877809706 Test RE 0.1545216702684264\n",
      "14 Train Loss 4684.8296 Test MSE 99.86578863164628 Test RE 0.1113429491508299\n",
      "15 Train Loss 4640.719 Test MSE 85.79183063581517 Test RE 0.1031994350518301\n",
      "16 Train Loss 4564.242 Test MSE 68.54881559920142 Test RE 0.09224744155727284\n",
      "17 Train Loss 4522.435 Test MSE 68.9301551838017 Test RE 0.09250367365096357\n",
      "18 Train Loss 4413.763 Test MSE 53.66815511922872 Test RE 0.08162302491971142\n",
      "19 Train Loss 4405.733 Test MSE 47.85396640234153 Test RE 0.0770749625751294\n",
      "20 Train Loss 4404.7637 Test MSE 47.24240068906569 Test RE 0.07658087632757461\n",
      "21 Train Loss 4395.966 Test MSE 46.89852342211475 Test RE 0.07630165131657775\n",
      "22 Train Loss 4350.4834 Test MSE 47.69214878115869 Test RE 0.0769445381876328\n",
      "23 Train Loss 4343.343 Test MSE 49.23158157818155 Test RE 0.0781765041955187\n",
      "24 Train Loss 4336.294 Test MSE 51.468990355434464 Test RE 0.07993319580723\n",
      "25 Train Loss 4270.4614 Test MSE 71.67888656183591 Test RE 0.0943300310957483\n",
      "26 Train Loss 4250.334 Test MSE 60.33461780820724 Test RE 0.08654413376609162\n",
      "27 Train Loss 4210.116 Test MSE 47.25978673701506 Test RE 0.07659496659704267\n",
      "28 Train Loss 4096.9126 Test MSE 60.64746092956204 Test RE 0.08676821516480879\n",
      "29 Train Loss 4092.2397 Test MSE 60.84221185575605 Test RE 0.08690741840508676\n",
      "30 Train Loss 4088.4702 Test MSE 56.33165451562162 Test RE 0.08362393616912546\n",
      "31 Train Loss 4051.3257 Test MSE 58.24256735553355 Test RE 0.08503047548880678\n",
      "32 Train Loss 4005.1326 Test MSE 110.38067136550069 Test RE 0.1170579375444002\n",
      "33 Train Loss 3979.798 Test MSE 65.67963242508691 Test RE 0.09029624889682974\n",
      "34 Train Loss 3977.114 Test MSE 67.59321231429328 Test RE 0.09160219818027003\n",
      "35 Train Loss 3951.1885 Test MSE 74.45103994951681 Test RE 0.09613681647566101\n",
      "36 Train Loss 3885.3389 Test MSE 53.250057391069035 Test RE 0.08130446425593031\n",
      "37 Train Loss 3882.5203 Test MSE 51.53003631549034 Test RE 0.07998058504696959\n",
      "38 Train Loss 3877.25 Test MSE 50.63192937656967 Test RE 0.07928053839713387\n",
      "39 Train Loss 3790.8079 Test MSE 50.37210354503303 Test RE 0.0790768563823796\n",
      "40 Train Loss 3749.4119 Test MSE 63.88786647847053 Test RE 0.08905607388228962\n",
      "41 Train Loss 3747.5515 Test MSE 64.65330375710911 Test RE 0.0895879736056278\n",
      "42 Train Loss 3746.587 Test MSE 65.25310930887963 Test RE 0.09000257971513122\n",
      "43 Train Loss 3701.004 Test MSE 74.43188461432568 Test RE 0.09612444827092391\n",
      "44 Train Loss 3497.5632 Test MSE 62.000546724051624 Test RE 0.08773080450474345\n",
      "45 Train Loss 3438.8743 Test MSE 157.02012817390718 Test RE 0.13961497925082272\n",
      "46 Train Loss 3394.962 Test MSE 212.35903833887158 Test RE 0.16236399449863842\n",
      "47 Train Loss 3388.2747 Test MSE 205.69641506988458 Test RE 0.15979666592122627\n",
      "48 Train Loss 3372.2 Test MSE 210.46860274529556 Test RE 0.16163969090451413\n",
      "49 Train Loss 3234.3694 Test MSE 187.9108432716739 Test RE 0.15273208239559452\n",
      "50 Train Loss 3047.8884 Test MSE 57.828145075635646 Test RE 0.0847274202351861\n",
      "51 Train Loss 2787.509 Test MSE 337.34725317075237 Test RE 0.2046411376519796\n",
      "52 Train Loss 2418.7004 Test MSE 292.6613181710919 Test RE 0.19060619620642494\n",
      "53 Train Loss 1753.3068 Test MSE 275.2643886310744 Test RE 0.18485421904371044\n",
      "54 Train Loss 1567.2239 Test MSE 40.74394842746423 Test RE 0.07111904383113975\n",
      "55 Train Loss 1454.9089 Test MSE 41.41301490682799 Test RE 0.07170059781835997\n",
      "56 Train Loss 1438.7225 Test MSE 35.54622264428405 Test RE 0.06642798527670103\n",
      "57 Train Loss 1405.9631 Test MSE 40.776439548478905 Test RE 0.07114739499812182\n",
      "58 Train Loss 1275.7485 Test MSE 28.374094945304144 Test RE 0.05934926722526171\n",
      "59 Train Loss 1132.0513 Test MSE 34.254015445356 Test RE 0.0652093838935329\n",
      "60 Train Loss 1022.112 Test MSE 8.549208875342934 Test RE 0.03257746720954276\n",
      "61 Train Loss 966.7231 Test MSE 31.089201318254975 Test RE 0.062123960505018\n",
      "62 Train Loss 795.3967 Test MSE 48.04345618155429 Test RE 0.0772274106304739\n",
      "63 Train Loss 738.6515 Test MSE 19.20405806710161 Test RE 0.04882596748594271\n",
      "64 Train Loss 733.5324 Test MSE 22.31704769275823 Test RE 0.052634769223902304\n",
      "65 Train Loss 731.16925 Test MSE 25.865354961138255 Test RE 0.056664827855708304\n",
      "66 Train Loss 723.69836 Test MSE 12.56329734244476 Test RE 0.03949173113707155\n",
      "67 Train Loss 706.9235 Test MSE 9.03283326511396 Test RE 0.03348623719962579\n",
      "68 Train Loss 701.04364 Test MSE 6.538774860781568 Test RE 0.028490662261682953\n",
      "69 Train Loss 700.2401 Test MSE 7.7563655545175525 Test RE 0.031030122269547596\n",
      "70 Train Loss 696.6416 Test MSE 11.996492100237145 Test RE 0.038590596229839506\n",
      "71 Train Loss 639.337 Test MSE 11.535240530532834 Test RE 0.037841442200834324\n",
      "72 Train Loss 615.222 Test MSE 5.943005361839636 Test RE 0.02716172909791622\n",
      "73 Train Loss 588.2414 Test MSE 6.615033663770315 Test RE 0.02865631758837941\n",
      "74 Train Loss 565.4878 Test MSE 7.76663586315946 Test RE 0.031050659176000008\n",
      "75 Train Loss 562.25165 Test MSE 7.037649776094853 Test RE 0.02955753262900496\n",
      "76 Train Loss 561.77795 Test MSE 6.101375270563628 Test RE 0.02752125416120761\n",
      "77 Train Loss 558.0398 Test MSE 6.522938726430212 Test RE 0.02845614085105962\n",
      "78 Train Loss 501.08435 Test MSE 14.246783645203273 Test RE 0.04205452837331884\n",
      "79 Train Loss 444.38156 Test MSE 9.794600700026585 Test RE 0.03486966059498451\n",
      "80 Train Loss 442.6054 Test MSE 7.744150162304867 Test RE 0.031005678187643732\n",
      "81 Train Loss 440.73654 Test MSE 11.431136932690643 Test RE 0.03767029887797742\n",
      "82 Train Loss 436.59613 Test MSE 11.983508851462929 Test RE 0.038569708167680544\n",
      "83 Train Loss 435.12506 Test MSE 10.508389752036063 Test RE 0.03611789561168873\n",
      "84 Train Loss 432.68182 Test MSE 8.754074598306872 Test RE 0.03296548532679767\n",
      "85 Train Loss 421.61658 Test MSE 4.23945097884529 Test RE 0.022940831829425645\n",
      "86 Train Loss 360.30685 Test MSE 30.121821006292244 Test RE 0.06114978917794365\n",
      "87 Train Loss 327.20474 Test MSE 23.7496178937111 Test RE 0.054297854033552424\n",
      "88 Train Loss 324.81033 Test MSE 26.23555943076843 Test RE 0.05706890201739049\n",
      "89 Train Loss 324.35504 Test MSE 29.117997772618093 Test RE 0.06012223358719316\n",
      "90 Train Loss 323.42206 Test MSE 29.81841257981342 Test RE 0.06084103761259287\n",
      "91 Train Loss 308.12643 Test MSE 15.611216462436156 Test RE 0.04402229960395444\n",
      "92 Train Loss 257.70673 Test MSE 8.283355077998946 Test RE 0.03206693795991985\n",
      "93 Train Loss 252.92299 Test MSE 7.602142622258248 Test RE 0.030720081170221097\n",
      "94 Train Loss 252.55733 Test MSE 8.744714890238907 Test RE 0.03294785754484192\n",
      "95 Train Loss 252.53502 Test MSE 8.848067854562562 Test RE 0.03314198944065717\n",
      "96 Train Loss 252.39114 Test MSE 8.70573531472306 Test RE 0.03287434297627348\n",
      "97 Train Loss 249.43065 Test MSE 5.680271297524699 Test RE 0.026554546670498124\n",
      "98 Train Loss 209.40579 Test MSE 4.10256914673162 Test RE 0.022567440554687342\n",
      "99 Train Loss 179.0748 Test MSE 2.5109827560598554 Test RE 0.01765534536662614\n",
      "100 Train Loss 177.98895 Test MSE 1.7373498183581637 Test RE 0.014685812833379722\n",
      "101 Train Loss 177.9106 Test MSE 1.6089477637401062 Test RE 0.014132706002708346\n",
      "102 Train Loss 175.76846 Test MSE 1.6631567441882689 Test RE 0.014368814660332116\n",
      "103 Train Loss 151.00476 Test MSE 6.587044311875466 Test RE 0.0285956284049546\n",
      "104 Train Loss 136.4062 Test MSE 3.5039113828706525 Test RE 0.020855994772927357\n",
      "105 Train Loss 130.97346 Test MSE 2.163207715234714 Test RE 0.01638715131700381\n",
      "106 Train Loss 130.2832 Test MSE 2.0521362376419914 Test RE 0.015960902589100205\n",
      "107 Train Loss 130.03807 Test MSE 2.0810559666657533 Test RE 0.016072973636507223\n",
      "108 Train Loss 129.83559 Test MSE 2.3450821542086606 Test RE 0.01706213536720557\n",
      "109 Train Loss 128.58913 Test MSE 3.1119361151154745 Test RE 0.0196548479625486\n",
      "110 Train Loss 119.78116 Test MSE 7.660424929463149 Test RE 0.030837615052679335\n",
      "111 Train Loss 108.80583 Test MSE 1.5082101968070611 Test RE 0.013683124819706904\n",
      "112 Train Loss 107.7376 Test MSE 1.1266916495111843 Test RE 0.011826517809417444\n",
      "113 Train Loss 107.63423 Test MSE 1.3912999722931163 Test RE 0.013142099186537401\n",
      "114 Train Loss 107.52148 Test MSE 1.5548265162224937 Test RE 0.013892977156277752\n",
      "115 Train Loss 105.154236 Test MSE 1.0032392528899452 Test RE 0.011159805111480806\n",
      "116 Train Loss 95.59359 Test MSE 1.5601014132481594 Test RE 0.013916523826137528\n",
      "117 Train Loss 89.76873 Test MSE 1.1056237270880596 Test RE 0.011715424443529602\n",
      "118 Train Loss 85.34816 Test MSE 0.9605284433734763 Test RE 0.010919668827499252\n",
      "119 Train Loss 82.31636 Test MSE 0.676743808901807 Test RE 0.009165718143179298\n",
      "120 Train Loss 80.402855 Test MSE 1.0642374868996602 Test RE 0.011494064466273372\n",
      "121 Train Loss 78.907776 Test MSE 0.7182542747594439 Test RE 0.009442640641482154\n",
      "122 Train Loss 78.82807 Test MSE 0.9060659954397398 Test RE 0.010605576188241806\n",
      "123 Train Loss 78.81543 Test MSE 0.9398812623869169 Test RE 0.010801668582890736\n",
      "124 Train Loss 78.810165 Test MSE 0.9250393194341412 Test RE 0.01071604303173577\n",
      "125 Train Loss 78.79427 Test MSE 0.8934699694497492 Test RE 0.010531599429834875\n",
      "126 Train Loss 78.65894 Test MSE 0.6709017460546651 Test RE 0.00912607037386752\n",
      "127 Train Loss 73.5187 Test MSE 0.40902438794267826 Test RE 0.007125723298047875\n",
      "128 Train Loss 68.187096 Test MSE 1.0349863691330883 Test RE 0.011335003731045826\n",
      "129 Train Loss 67.32272 Test MSE 1.0765235570116753 Test RE 0.01156022058765642\n",
      "130 Train Loss 67.00547 Test MSE 0.5887374881517068 Test RE 0.008548997649104459\n",
      "131 Train Loss 66.69813 Test MSE 0.49366960449996294 Test RE 0.007828391676379975\n",
      "132 Train Loss 66.4735 Test MSE 0.47928515867921234 Test RE 0.007713497495891196\n",
      "133 Train Loss 66.407234 Test MSE 0.5393206859379008 Test RE 0.008182346965706792\n",
      "134 Train Loss 66.35938 Test MSE 0.5886134738339457 Test RE 0.00854809720198716\n",
      "135 Train Loss 66.287285 Test MSE 0.5010226411626494 Test RE 0.00788647676902063\n",
      "136 Train Loss 65.4292 Test MSE 0.3902629394343272 Test RE 0.0069603809224696375\n",
      "137 Train Loss 64.78797 Test MSE 0.4122723333697542 Test RE 0.007153959019082741\n",
      "138 Train Loss 64.41287 Test MSE 0.3414323787549667 Test RE 0.006510385485051901\n",
      "139 Train Loss 62.700085 Test MSE 0.343833293384291 Test RE 0.0065332355400877975\n",
      "140 Train Loss 56.61151 Test MSE 0.38808638149020125 Test RE 0.006940944213272804\n",
      "141 Train Loss 53.489 Test MSE 0.2711937928839802 Test RE 0.005802220443515697\n",
      "142 Train Loss 49.933136 Test MSE 2.1502061725484714 Test RE 0.016337831192100073\n",
      "143 Train Loss 42.33556 Test MSE 0.3366826590527648 Test RE 0.006464943393603802\n",
      "144 Train Loss 36.05556 Test MSE 0.38286383838950017 Test RE 0.006894083304107486\n",
      "145 Train Loss 33.148193 Test MSE 0.7171835466680242 Test RE 0.009435599770454649\n",
      "146 Train Loss 31.498608 Test MSE 0.6599276478925484 Test RE 0.009051123988076514\n",
      "147 Train Loss 31.289087 Test MSE 0.4623081735173728 Test RE 0.007575654124610505\n",
      "148 Train Loss 31.192661 Test MSE 0.4887867158095924 Test RE 0.007789580134688295\n",
      "149 Train Loss 31.087685 Test MSE 0.561003274257137 Test RE 0.00834520578311243\n",
      "150 Train Loss 31.039473 Test MSE 0.5829376599198256 Test RE 0.008506784066934598\n",
      "151 Train Loss 31.02317 Test MSE 0.6056807079784536 Test RE 0.008671140490638598\n",
      "152 Train Loss 30.99831 Test MSE 0.6399524047165691 Test RE 0.008913087910286966\n",
      "153 Train Loss 30.959217 Test MSE 0.6605641494337792 Test RE 0.00905548784972033\n",
      "154 Train Loss 30.94244 Test MSE 0.5940975431540538 Test RE 0.008587825882044115\n",
      "155 Train Loss 30.936049 Test MSE 0.5617270111433298 Test RE 0.008350587023162034\n",
      "156 Train Loss 30.931427 Test MSE 0.5275922855623518 Test RE 0.00809288875642427\n",
      "157 Train Loss 30.902876 Test MSE 0.47591072710906956 Test RE 0.007686295896771461\n",
      "158 Train Loss 30.864588 Test MSE 0.5432436153070921 Test RE 0.008212051565493785\n",
      "159 Train Loss 30.822916 Test MSE 0.6336512060866906 Test RE 0.008869098644591933\n",
      "160 Train Loss 30.78298 Test MSE 0.6401919736892118 Test RE 0.008914756080838204\n",
      "161 Train Loss 30.538172 Test MSE 0.4970386260576604 Test RE 0.00785505847533675\n",
      "162 Train Loss 29.244518 Test MSE 0.47565860761395795 Test RE 0.007684259672695948\n",
      "163 Train Loss 28.893427 Test MSE 0.4219120579133941 Test RE 0.007237112454915316\n",
      "164 Train Loss 28.79033 Test MSE 0.3561999373388875 Test RE 0.006649688043027297\n",
      "165 Train Loss 28.729214 Test MSE 0.3716362745028354 Test RE 0.006792245914840446\n",
      "166 Train Loss 28.508493 Test MSE 0.5500605332714404 Test RE 0.008263415588841585\n",
      "167 Train Loss 27.317783 Test MSE 0.35191016895394 Test RE 0.0066095251679248465\n",
      "168 Train Loss 24.67696 Test MSE 0.0961261027918079 Test RE 0.0034544190497362063\n",
      "169 Train Loss 23.747316 Test MSE 0.13634730275684181 Test RE 0.004114126374603932\n",
      "170 Train Loss 23.523903 Test MSE 0.0994273463830232 Test RE 0.003513235614841583\n",
      "171 Train Loss 23.254324 Test MSE 0.09313474817011039 Test RE 0.00340024510950134\n",
      "172 Train Loss 23.050194 Test MSE 0.12361718960524884 Test RE 0.003917362713388105\n",
      "173 Train Loss 22.811594 Test MSE 0.1333022097601298 Test RE 0.004067925838125024\n",
      "174 Train Loss 22.697475 Test MSE 0.10809524258147275 Test RE 0.003663174797420943\n",
      "175 Train Loss 22.668692 Test MSE 0.09227535574313123 Test RE 0.0033845210258887635\n",
      "176 Train Loss 22.663727 Test MSE 0.09861373861179579 Test RE 0.0034988317940156037\n",
      "177 Train Loss 22.663416 Test MSE 0.09936193153034352 Test RE 0.0035120797175397745\n",
      "178 Train Loss 22.662554 Test MSE 0.10312343674876934 Test RE 0.0035779399010462173\n",
      "179 Train Loss 22.661758 Test MSE 0.10544279430218371 Test RE 0.0036179520407506305\n",
      "180 Train Loss 22.661758 Test MSE 0.10544277551330979 Test RE 0.003617951718408795\n",
      "181 Train Loss 22.661758 Test MSE 0.10544277551330979 Test RE 0.003617951718408795\n",
      "182 Train Loss 22.650852 Test MSE 0.11520467210606271 Test RE 0.0037817202444461752\n",
      "183 Train Loss 22.574614 Test MSE 0.10138204661877358 Test RE 0.0035476019049692593\n",
      "184 Train Loss 22.391607 Test MSE 0.10093070898452985 Test RE 0.003539696401381016\n",
      "185 Train Loss 21.798681 Test MSE 0.05513394814298251 Test RE 0.0026161575775987245\n",
      "186 Train Loss 20.647043 Test MSE 0.2567384106812473 Test RE 0.005645465744698441\n",
      "187 Train Loss 19.844452 Test MSE 0.27613971455905234 Test RE 0.005854890647932698\n",
      "188 Train Loss 19.691908 Test MSE 0.2725457095573322 Test RE 0.00581666466608065\n",
      "189 Train Loss 19.42013 Test MSE 0.25379283263783176 Test RE 0.005612986902957157\n",
      "190 Train Loss 18.954044 Test MSE 0.3154331077099796 Test RE 0.006257602753581947\n",
      "191 Train Loss 18.692053 Test MSE 0.38362238113110975 Test RE 0.006900909319906\n",
      "192 Train Loss 18.547726 Test MSE 0.2892224241019529 Test RE 0.00599197969849789\n",
      "193 Train Loss 18.516804 Test MSE 0.3006865646945643 Test RE 0.006109580114088462\n",
      "194 Train Loss 18.510836 Test MSE 0.3024922376252237 Test RE 0.00612789717936786\n",
      "195 Train Loss 18.500452 Test MSE 0.30160291324449856 Test RE 0.006118882568258712\n",
      "196 Train Loss 18.489244 Test MSE 0.2933651992550433 Test RE 0.00603474118907631\n",
      "197 Train Loss 18.484095 Test MSE 0.2987194514444475 Test RE 0.0060895626640083906\n",
      "198 Train Loss 18.478746 Test MSE 0.30871518102024326 Test RE 0.00619060858340837\n",
      "199 Train Loss 18.463177 Test MSE 0.3404440165338901 Test RE 0.006500955678641837\n",
      "Training time: 71.86\n",
      "Training time: 71.86\n",
      "1D_FODE_rowdymedium\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 18425.164 Test MSE 8059.843138759737 Test RE 1.0002709292875653\n",
      "1 Train Loss 17733.527 Test MSE 8652.69135952185 Test RE 1.0364060958720225\n",
      "2 Train Loss 15083.565 Test MSE 7448.132536598969 Test RE 0.9615636789828674\n",
      "3 Train Loss 10416.25 Test MSE 7837.762942797075 Test RE 0.9863939827462391\n",
      "4 Train Loss 6154.8477 Test MSE 8026.947176040682 Test RE 0.9982275570814515\n",
      "5 Train Loss 4164.754 Test MSE 7311.32814463463 Test RE 0.9526919388004453\n",
      "6 Train Loss 3311.2625 Test MSE 6672.190502805955 Test RE 0.9100988617269035\n",
      "7 Train Loss 2742.5908 Test MSE 5437.131775098939 Test RE 0.8215599914713724\n",
      "8 Train Loss 2163.636 Test MSE 4266.614878139557 Test RE 0.7277732256056093\n",
      "9 Train Loss 1560.7417 Test MSE 3077.3500099547664 Test RE 0.6180773085578285\n",
      "10 Train Loss 1240.9591 Test MSE 2157.587839594606 Test RE 0.5175336528207587\n",
      "11 Train Loss 849.5095 Test MSE 1515.226417016501 Test RE 0.43370369184385354\n",
      "12 Train Loss 597.5596 Test MSE 854.0427795620963 Test RE 0.32560732396145353\n",
      "13 Train Loss 314.74686 Test MSE 414.92979629259247 Test RE 0.22695599746977724\n",
      "14 Train Loss 155.78752 Test MSE 105.23246343021938 Test RE 0.11429552343497779\n",
      "15 Train Loss 66.72005 Test MSE 7.162728731168067 Test RE 0.029819036336532403\n",
      "16 Train Loss 34.40192 Test MSE 0.5902062306581037 Test RE 0.008559654737452464\n",
      "17 Train Loss 20.654581 Test MSE 0.7142856628556411 Test RE 0.009416517522250712\n",
      "18 Train Loss 18.12472 Test MSE 0.5110192321906237 Test RE 0.007964765154247315\n",
      "19 Train Loss 15.534839 Test MSE 0.03092924221900325 Test RE 0.0019594716851945096\n",
      "20 Train Loss 12.287181 Test MSE 1.7475750273612787 Test RE 0.014728966262032217\n",
      "21 Train Loss 11.357859 Test MSE 0.41603364430589734 Test RE 0.007186519012834077\n",
      "22 Train Loss 10.723833 Test MSE 0.14648023867237878 Test RE 0.004264261916935682\n",
      "23 Train Loss 9.42532 Test MSE 0.06049258470042032 Test RE 0.0027403461391255807\n",
      "24 Train Loss 8.557418 Test MSE 0.14323744109771241 Test RE 0.004216796369257733\n",
      "25 Train Loss 8.120505 Test MSE 0.02287033003797813 Test RE 0.0016849637745026992\n",
      "26 Train Loss 7.894077 Test MSE 0.021082607347776935 Test RE 0.0016177690126276238\n",
      "27 Train Loss 7.617463 Test MSE 0.054649967778845766 Test RE 0.002604649605700862\n",
      "28 Train Loss 7.2345862 Test MSE 0.020013642268668384 Test RE 0.0015762221230111095\n",
      "29 Train Loss 6.9527802 Test MSE 0.04368542504368747 Test RE 0.002328748751934941\n",
      "30 Train Loss 6.4634037 Test MSE 0.0491156078551865 Test RE 0.00246924460734752\n",
      "31 Train Loss 6.4001637 Test MSE 0.014716939356650622 Test RE 0.001351646432564978\n",
      "32 Train Loss 6.1996613 Test MSE 0.04577874956136813 Test RE 0.002383890567629588\n",
      "33 Train Loss 5.9727774 Test MSE 0.04384604389930371 Test RE 0.0023330258967639104\n",
      "34 Train Loss 5.8752465 Test MSE 0.04565213035665004 Test RE 0.0023805914895786845\n",
      "35 Train Loss 5.7280464 Test MSE 0.023442080680453566 Test RE 0.001705895527255899\n",
      "36 Train Loss 5.6517863 Test MSE 0.06468145637108119 Test RE 0.0028336372131638607\n",
      "37 Train Loss 5.5385027 Test MSE 0.07586146299435705 Test RE 0.003068774376641673\n",
      "38 Train Loss 5.4168696 Test MSE 0.11897174962024774 Test RE 0.003843052138646788\n",
      "39 Train Loss 5.219024 Test MSE 0.059251100053942865 Test RE 0.0027120804073093615\n",
      "40 Train Loss 5.085377 Test MSE 0.011076779839013338 Test RE 0.0011726303064049132\n",
      "41 Train Loss 5.0349216 Test MSE 0.00833453323241169 Test RE 0.0010171733980968048\n",
      "42 Train Loss 4.896156 Test MSE 0.053531216788990095 Test RE 0.002577851584474753\n",
      "43 Train Loss 4.650157 Test MSE 0.042866008647206584 Test RE 0.00230680495694025\n",
      "44 Train Loss 4.324946 Test MSE 0.005410979410748256 Test RE 0.0008195817761358571\n",
      "45 Train Loss 4.1690297 Test MSE 0.07130197375499474 Test RE 0.002975124390309133\n",
      "46 Train Loss 3.9944913 Test MSE 0.018268266151724385 Test RE 0.0015059238708355406\n",
      "47 Train Loss 3.8984601 Test MSE 0.0073683348349283225 Test RE 0.0009563988139428994\n",
      "48 Train Loss 3.8072286 Test MSE 0.007614856821035937 Test RE 0.0009722662787047473\n",
      "49 Train Loss 3.7631574 Test MSE 0.007282037046655262 Test RE 0.000950781656730087\n",
      "50 Train Loss 3.7263308 Test MSE 0.010427416089871536 Test RE 0.0011377391543205705\n",
      "51 Train Loss 3.6497128 Test MSE 0.004911426166339187 Test RE 0.0007808330049270334\n",
      "52 Train Loss 3.4925222 Test MSE 0.011815056730514925 Test RE 0.0012110783988032606\n",
      "53 Train Loss 3.4007032 Test MSE 0.005030786503328139 Test RE 0.0007902641774890395\n",
      "54 Train Loss 3.304026 Test MSE 0.01173925235033101 Test RE 0.0012071870601044737\n",
      "55 Train Loss 3.1313572 Test MSE 0.0225641213614131 Test RE 0.0016736458532321129\n",
      "56 Train Loss 2.9648361 Test MSE 0.00845270379187265 Test RE 0.0010243589763774955\n",
      "57 Train Loss 2.8841088 Test MSE 0.007192599995814352 Test RE 0.0009449249287149096\n",
      "58 Train Loss 2.7882617 Test MSE 0.009510381314944777 Test RE 0.0010865590100054149\n",
      "59 Train Loss 2.6433523 Test MSE 0.007096874348099729 Test RE 0.0009386159076434925\n",
      "60 Train Loss 2.3017333 Test MSE 0.04153818164882074 Test RE 0.002270795855691778\n",
      "61 Train Loss 2.1270642 Test MSE 0.025132020799214463 Test RE 0.0017663145952882746\n",
      "62 Train Loss 2.085488 Test MSE 0.022205940224463133 Test RE 0.00166030905152362\n",
      "63 Train Loss 2.0344896 Test MSE 0.006071912348886026 Test RE 0.0008681946377858336\n",
      "64 Train Loss 1.9844205 Test MSE 0.0044573186295061625 Test RE 0.0007438599774743784\n",
      "65 Train Loss 1.9532113 Test MSE 0.00780776520067204 Test RE 0.0009845045431718994\n",
      "66 Train Loss 1.9232279 Test MSE 0.00386271572264805 Test RE 0.0006924696219302816\n",
      "67 Train Loss 1.8719147 Test MSE 0.002781699015209739 Test RE 0.0005876373894390204\n",
      "68 Train Loss 1.7226642 Test MSE 0.01753423511706719 Test RE 0.0014753591864991133\n",
      "69 Train Loss 1.6701982 Test MSE 0.004189802887362069 Test RE 0.0007211924112465695\n",
      "70 Train Loss 1.6540016 Test MSE 0.006744280160498855 Test RE 0.0009150022325955415\n",
      "71 Train Loss 1.6327522 Test MSE 0.005246750558803352 Test RE 0.0008070483632536743\n",
      "72 Train Loss 1.6049551 Test MSE 0.003325083897899374 Test RE 0.000642474146710431\n",
      "73 Train Loss 1.5655494 Test MSE 0.006398530236159078 Test RE 0.0008912395806567504\n",
      "74 Train Loss 1.5363275 Test MSE 0.0029857358025389244 Test RE 0.0006088075649652642\n",
      "75 Train Loss 1.4570411 Test MSE 0.0021764807928383568 Test RE 0.0005197946100337882\n",
      "76 Train Loss 1.4381111 Test MSE 0.0067941471295365876 Test RE 0.000918378749705601\n",
      "77 Train Loss 1.393876 Test MSE 0.00631605983835835 Test RE 0.000885477377759379\n",
      "78 Train Loss 1.3547286 Test MSE 0.0022160386475603344 Test RE 0.0005244970108327256\n",
      "79 Train Loss 1.3376545 Test MSE 0.0017222845873438438 Test RE 0.00046238827177416566\n",
      "80 Train Loss 1.3159947 Test MSE 0.0015655526302556266 Test RE 0.00044084730321457255\n",
      "81 Train Loss 1.2694012 Test MSE 0.0019220987510232311 Test RE 0.0004884748414519669\n",
      "82 Train Loss 1.0850489 Test MSE 0.011693429707143268 Test RE 0.0012048287077126637\n",
      "83 Train Loss 0.99436444 Test MSE 0.0013142550895462635 Test RE 0.00040391891036826777\n",
      "84 Train Loss 0.969353 Test MSE 0.0016872929044974257 Test RE 0.0004576669932774168\n",
      "85 Train Loss 0.9453408 Test MSE 0.0009186440668389448 Test RE 0.00033769761200131093\n",
      "86 Train Loss 0.9118578 Test MSE 0.004658922356699063 Test RE 0.0007604962707382486\n",
      "87 Train Loss 0.8927881 Test MSE 0.0021329775707538143 Test RE 0.0005145735947245552\n",
      "88 Train Loss 0.8727151 Test MSE 0.001398274145749583 Test RE 0.00041662997836050525\n",
      "89 Train Loss 0.8629698 Test MSE 0.0024740812388455652 Test RE 0.0005541933757230294\n",
      "90 Train Loss 0.8443628 Test MSE 0.003190917386276488 Test RE 0.0006293788325672467\n",
      "91 Train Loss 0.81487924 Test MSE 0.0009296689779921994 Test RE 0.00033971797134278134\n",
      "92 Train Loss 0.7680861 Test MSE 0.005356444804323823 Test RE 0.0008154412358128213\n",
      "93 Train Loss 0.7313835 Test MSE 0.003976066352533077 Test RE 0.0007025563508440837\n",
      "94 Train Loss 0.6921288 Test MSE 0.0024021766265255855 Test RE 0.0005460806914083826\n",
      "95 Train Loss 0.6729539 Test MSE 0.0033097748803665567 Test RE 0.0006409934329162162\n",
      "96 Train Loss 0.6640342 Test MSE 0.0014379921293368792 Test RE 0.0004225057335460948\n",
      "97 Train Loss 0.64882004 Test MSE 0.0009504944869087445 Test RE 0.00034350190778998556\n",
      "98 Train Loss 0.6342966 Test MSE 0.0019092046519680107 Test RE 0.0004868336558474626\n",
      "99 Train Loss 0.6231403 Test MSE 0.0017456417612892576 Test RE 0.000465513107415694\n",
      "100 Train Loss 0.6071234 Test MSE 0.0022925550331091764 Test RE 0.0005334752028582891\n",
      "101 Train Loss 0.58862716 Test MSE 0.0032456294259915843 Test RE 0.000634751620721429\n",
      "102 Train Loss 0.58324885 Test MSE 0.002235349310727611 Test RE 0.0005267772995659685\n",
      "103 Train Loss 0.57945883 Test MSE 0.0015631669627294083 Test RE 0.00044051128255178187\n",
      "104 Train Loss 0.5757889 Test MSE 0.0008723059647039762 Test RE 0.0003290703653778914\n",
      "105 Train Loss 0.56924266 Test MSE 0.0006403940147125401 Test RE 0.0002819538210028781\n",
      "106 Train Loss 0.56322783 Test MSE 0.0011834834022294582 Test RE 0.0003832970158877272\n",
      "107 Train Loss 0.5526522 Test MSE 0.0008225402695009965 Test RE 0.000319545669912597\n",
      "108 Train Loss 0.5390816 Test MSE 0.002036957143533661 Test RE 0.0005028579241598148\n",
      "109 Train Loss 0.5292131 Test MSE 0.0010674862959825441 Test RE 0.00036402860092951987\n",
      "110 Train Loss 0.51470464 Test MSE 0.003856176158381154 Test RE 0.0006918831992930368\n",
      "111 Train Loss 0.5021771 Test MSE 0.0023075572069585467 Test RE 0.0005352178518189813\n",
      "112 Train Loss 0.4916313 Test MSE 0.0012207902477775127 Test RE 0.00038929146126720954\n",
      "113 Train Loss 0.48343292 Test MSE 0.0011251508958527057 Test RE 0.00037373152887406946\n",
      "114 Train Loss 0.4774682 Test MSE 0.0010254872861058051 Test RE 0.0003567956020752263\n",
      "115 Train Loss 0.47198007 Test MSE 0.000831533968139517 Test RE 0.00032128788508610197\n",
      "116 Train Loss 0.46663496 Test MSE 0.0004583974964976816 Test RE 0.00023854783034989733\n",
      "117 Train Loss 0.46061173 Test MSE 0.0011692695781054462 Test RE 0.0003809883339396219\n",
      "118 Train Loss 0.44823688 Test MSE 0.001304731639691615 Test RE 0.0004024527964292064\n",
      "119 Train Loss 0.42395276 Test MSE 0.000461741100746492 Test RE 0.00023941624734784116\n",
      "120 Train Loss 0.41311973 Test MSE 0.0004293646481923295 Test RE 0.00023086999539588104\n",
      "121 Train Loss 0.40318924 Test MSE 0.0009771123178955346 Test RE 0.00034827844477086883\n",
      "122 Train Loss 0.39783278 Test MSE 0.000522749066520866 Test RE 0.000254742252905866\n",
      "123 Train Loss 0.3951061 Test MSE 0.0005290931523309019 Test RE 0.0002562833680164978\n",
      "124 Train Loss 0.392777 Test MSE 0.00064318270253364 Test RE 0.00028256705834878783\n",
      "125 Train Loss 0.39017802 Test MSE 0.0006125201481413336 Test RE 0.00027574937819359037\n",
      "126 Train Loss 0.38794914 Test MSE 0.0007011565964333427 Test RE 0.0002950270688193187\n",
      "127 Train Loss 0.3851662 Test MSE 0.000899586772416108 Test RE 0.00033417648205980944\n",
      "128 Train Loss 0.38248906 Test MSE 0.0005165477922170208 Test RE 0.0002532267651842174\n",
      "129 Train Loss 0.37759525 Test MSE 0.00041447861560003695 Test RE 0.00022683257175263585\n",
      "130 Train Loss 0.3722598 Test MSE 0.0010115090344488935 Test RE 0.0003543555469179002\n",
      "131 Train Loss 0.3586309 Test MSE 0.0037488764455298187 Test RE 0.0006821893199382076\n",
      "132 Train Loss 0.3360192 Test MSE 0.0030253275453636036 Test RE 0.00061283075620507\n",
      "133 Train Loss 0.32193652 Test MSE 0.0006231659150762642 Test RE 0.00027813535525319545\n",
      "134 Train Loss 0.31687358 Test MSE 0.0008768165848166678 Test RE 0.0003299200658279041\n",
      "135 Train Loss 0.31515703 Test MSE 0.0005137915583379486 Test RE 0.00025255026850925057\n",
      "136 Train Loss 0.31417575 Test MSE 0.0008624362314540324 Test RE 0.00032720343098811106\n",
      "137 Train Loss 0.31160706 Test MSE 0.0012588216683823007 Test RE 0.00039530877723793886\n",
      "138 Train Loss 0.30492604 Test MSE 0.0007135922460660517 Test RE 0.0002976318566424345\n",
      "139 Train Loss 0.29706153 Test MSE 0.0005631071342532492 Test RE 0.0002643929479324978\n",
      "140 Train Loss 0.29085743 Test MSE 0.0004194465213484989 Test RE 0.00022818792061764188\n",
      "141 Train Loss 0.2808924 Test MSE 0.000978108313364668 Test RE 0.00034845590410425366\n",
      "142 Train Loss 0.27369738 Test MSE 0.0004208568288303404 Test RE 0.00022857121748498968\n",
      "143 Train Loss 0.2690155 Test MSE 0.0008554902081178866 Test RE 0.0003258831262001887\n",
      "144 Train Loss 0.26693586 Test MSE 0.0008945431015676104 Test RE 0.0003332383594969536\n",
      "145 Train Loss 0.26555264 Test MSE 0.00024914497456677925 Test RE 0.00017586540565380992\n",
      "146 Train Loss 0.2639624 Test MSE 0.00035315685917588975 Test RE 0.0002093814365877793\n",
      "147 Train Loss 0.2599268 Test MSE 0.0012407049226059793 Test RE 0.00039245386004535315\n",
      "148 Train Loss 0.25544173 Test MSE 0.0020224961887414096 Test RE 0.0005010697770902809\n",
      "149 Train Loss 0.25196916 Test MSE 0.00042979236375257095 Test RE 0.00023098495841184397\n",
      "150 Train Loss 0.24773753 Test MSE 0.0006913915027200053 Test RE 0.00029296542642064035\n",
      "151 Train Loss 0.2421887 Test MSE 0.0003465642142263008 Test RE 0.00020741788921253428\n",
      "152 Train Loss 0.23694955 Test MSE 0.0009336777033936994 Test RE 0.0003404496141066393\n",
      "153 Train Loss 0.23234616 Test MSE 0.0007730376422693339 Test RE 0.0003097809257838194\n",
      "154 Train Loss 0.22723442 Test MSE 0.0002445206016640128 Test RE 0.0001742256446887125\n",
      "155 Train Loss 0.2256953 Test MSE 0.0003453567597897068 Test RE 0.00020705624458005012\n",
      "156 Train Loss 0.22253147 Test MSE 0.00039745580474715645 Test RE 0.00022212568208788944\n",
      "157 Train Loss 0.22063573 Test MSE 0.00045371332245950074 Test RE 0.00023732589000152043\n",
      "158 Train Loss 0.21931125 Test MSE 0.0004029936519687045 Test RE 0.0002236677942635153\n",
      "159 Train Loss 0.21645093 Test MSE 0.0004268878608492472 Test RE 0.0002302031462490632\n",
      "160 Train Loss 0.21438146 Test MSE 0.0007958268184051079 Test RE 0.00031431393625781497\n",
      "161 Train Loss 0.21328786 Test MSE 0.00043135134139028004 Test RE 0.000231403502876263\n",
      "162 Train Loss 0.21080548 Test MSE 0.0002489410826237746 Test RE 0.00017579342973198864\n",
      "163 Train Loss 0.20305239 Test MSE 0.0005134538379628934 Test RE 0.0002524672529455023\n",
      "164 Train Loss 0.19603498 Test MSE 0.0009711109362285267 Test RE 0.0003472072418319766\n",
      "165 Train Loss 0.18509535 Test MSE 0.002243322786071759 Test RE 0.0005277159687245864\n",
      "166 Train Loss 0.17308074 Test MSE 0.0004191979767814022 Test RE 0.00022812030380691604\n",
      "167 Train Loss 0.16979492 Test MSE 0.00041021990616223213 Test RE 0.0002256642264837477\n",
      "168 Train Loss 0.16902056 Test MSE 0.0006160778523930372 Test RE 0.00027654903704798784\n",
      "169 Train Loss 0.16811676 Test MSE 0.00035902811719907825 Test RE 0.0002111147528307801\n",
      "170 Train Loss 0.16717322 Test MSE 0.00021674494409296176 Test RE 0.00016403209821028413\n",
      "171 Train Loss 0.16641946 Test MSE 0.00036946292258545376 Test RE 0.00021416070262055584\n",
      "172 Train Loss 0.16528124 Test MSE 0.00023157587438434412 Test RE 0.00016955125495742273\n",
      "173 Train Loss 0.16350657 Test MSE 0.0003237885872031342 Test RE 0.00020048649379462248\n",
      "174 Train Loss 0.16017656 Test MSE 0.0012261145575635825 Test RE 0.000390139458413716\n",
      "175 Train Loss 0.1564751 Test MSE 0.0004832927743828925 Test RE 0.00024493988151034194\n",
      "176 Train Loss 0.15451781 Test MSE 0.0003047307087826486 Test RE 0.0001944968012785354\n",
      "177 Train Loss 0.15360913 Test MSE 0.00024863242164137285 Test RE 0.00017568441316881847\n",
      "178 Train Loss 0.15224288 Test MSE 0.0001363521115601644 Test RE 0.00013010239347099854\n",
      "179 Train Loss 0.15129708 Test MSE 0.00020414816032007405 Test RE 0.00015919414385791262\n",
      "180 Train Loss 0.14828742 Test MSE 0.0003201452275702163 Test RE 0.00019935533775487763\n",
      "181 Train Loss 0.14411406 Test MSE 0.0005429554262915319 Test RE 0.00025961898116289803\n",
      "182 Train Loss 0.14260904 Test MSE 0.00047037025891271756 Test RE 0.00024164303362499893\n",
      "183 Train Loss 0.141427 Test MSE 0.00029321766486971443 Test RE 0.00019078728057338336\n",
      "184 Train Loss 0.13884619 Test MSE 0.0001794829361011141 Test RE 0.00014926773231833433\n",
      "185 Train Loss 0.13510388 Test MSE 0.00013757842085619366 Test RE 0.0001306861345306302\n",
      "186 Train Loss 0.1337463 Test MSE 0.00013189888520368108 Test RE 0.0001279602013597026\n",
      "187 Train Loss 0.1326707 Test MSE 0.00017611458806184995 Test RE 0.00014786044808976891\n",
      "188 Train Loss 0.13127376 Test MSE 0.0005861336714671112 Test RE 0.0002697445555726054\n",
      "189 Train Loss 0.12830229 Test MSE 0.0006769424603756621 Test RE 0.00028988799475272806\n",
      "190 Train Loss 0.12663265 Test MSE 0.00022566978154060733 Test RE 0.0001673751798147165\n",
      "191 Train Loss 0.12535353 Test MSE 0.00025493339054939945 Test RE 0.00017789662684267513\n",
      "192 Train Loss 0.1246294 Test MSE 0.00017865100248771475 Test RE 0.00014892138998390765\n",
      "193 Train Loss 0.124198295 Test MSE 0.0002468202486949021 Test RE 0.0001750429988708813\n",
      "194 Train Loss 0.1238383 Test MSE 0.000249331300507959 Test RE 0.00017593115484871308\n",
      "195 Train Loss 0.12313822 Test MSE 0.00029291660252282433 Test RE 0.0001906893096378002\n",
      "196 Train Loss 0.122225136 Test MSE 0.00025661775685386344 Test RE 0.0001784833482797471\n",
      "197 Train Loss 0.12166759 Test MSE 0.00023153304270892995 Test RE 0.0001695355743513005\n",
      "198 Train Loss 0.12136514 Test MSE 0.0003093310631010515 Test RE 0.000195959408296583\n",
      "199 Train Loss 0.12030985 Test MSE 0.00044754666499513914 Test RE 0.00023570756152387084\n",
      "Training time: 78.19\n",
      "Training time: 78.19\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "omega_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val =8.0\n",
    "rowdy_terms = 2\n",
    "\n",
    "for reps in range(max_reps):  \n",
    "  print(label) \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  alpha_val = []\n",
    "  omega_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.05, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  alpha_full.append(alpha_val)\n",
    "  omega_full.append(omega_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full,\"omega\": omega_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "77a1e198-62ae-4129-82a3-1a1f3e433466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1D_FODE_rowdymedium'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d2yA4xTDHldi"
   },
   "outputs": [],
   "source": [
    "#3,4,8,9,13,14,18,19,23,24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "1986cfc6-aa7b-43ff-e3e8-c586ef7bafd1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28631/2033279215.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#  if tune_reps not in s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_rowdy_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_rowdy_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(70):\n",
    "#  if tune_reps not in s:\n",
    "    label = \"1D_FODE_rowdy_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2eNXAFRRtWs",
    "outputId": "737b4c47-e8bf-4e68-c774-00d25a78ecb3"
   },
   "outputs": [],
   "source": [
    "lrnr_tune[2]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "atanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
