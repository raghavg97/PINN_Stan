{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "3df10486-4078-44cd-95da-12a75fb13c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "515a82ba-2a23-4124-c9e1-230f67f43912"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "d35a8c58-7c75-4550-d489-9565724f04e6"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "7b44eee8-32ab-4621-ca04-81e30b53601d"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"medium\"\n",
    "label = \"1D_FODE_tanhALR_\" +level\n",
    "extent = 20.0\n",
    "\n",
    "x = np.linspace(extent,-1.0*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "             \n",
    "        self.lambdas = torch.ones((1,),device = device)\n",
    "        self.lambda_alpha = 0.1\n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def lambda_update(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc1.backward()\n",
    "        bc1_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc1_grads.append(param.grad.view(-1))\n",
    "        bc1_grads = torch.cat(bc1_grads)\n",
    "        bc1_grads = torch.mean(torch.abs(bc1_grads))        \n",
    "    \n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        loss_f.backward()\n",
    "        f_grads = []\n",
    "        for param in self.parameters():\n",
    "            f_grads.append(param.grad.view(-1))   \n",
    "        f_grads = torch.cat(f_grads)\n",
    "        f_grads = torch.max(torch.abs(f_grads))\n",
    "    \n",
    "        self.lambdas[0] = (1.0-self.lambda_alpha)*self.lambdas[0] + self.lambda_alpha*f_grads/bc1_grads\n",
    "        \n",
    "        return None\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    PINN.lambda_update(x_bc1_train,y_bc1_train,x_coll_train,f_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "   \n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fAcpqTqePPt9"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    x_coll_np_array = colloc_pts(N_f,123)\n",
    "    x_coll = torch.from_numpy(x_coll_np_array).float().to(device)\n",
    "\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(i)        \n",
    "    \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "3645d237-1d2a-45c9-8d9f-de486f1ca919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 17917.797 Test MSE 10066.183768531624 Test RE 1.1178583615209516\n",
      "1 Train Loss 15462.455 Test MSE 9228.43938383911 Test RE 1.0703319371103706\n",
      "2 Train Loss 12020.328 Test MSE 7017.817262942973 Test RE 0.9333733144594268\n",
      "3 Train Loss 10705.364 Test MSE 5378.313911993866 Test RE 0.8171041678449263\n",
      "4 Train Loss 10299.096 Test MSE 4971.889346648113 Test RE 0.7856246103005948\n",
      "5 Train Loss 10152.536 Test MSE 4865.880675805107 Test RE 0.7772040941208078\n",
      "6 Train Loss 10001.434 Test MSE 4732.970173188979 Test RE 0.7665160203665333\n",
      "7 Train Loss 9896.885 Test MSE 4584.046919053567 Test RE 0.7543603952773976\n",
      "8 Train Loss 9741.792 Test MSE 4542.221815878064 Test RE 0.75091109590653\n",
      "9 Train Loss 9410.033 Test MSE 4348.048431714801 Test RE 0.7346856188681861\n",
      "10 Train Loss 9232.018 Test MSE 4264.168347042661 Test RE 0.7275645384853554\n",
      "11 Train Loss 9077.98 Test MSE 4169.559992163614 Test RE 0.7194480930538633\n",
      "12 Train Loss 8956.832 Test MSE 4158.520128367326 Test RE 0.7184950100653757\n",
      "13 Train Loss 8872.064 Test MSE 4120.103358363528 Test RE 0.7151685500657221\n",
      "14 Train Loss 8824.7 Test MSE 4111.703133892105 Test RE 0.7144391215687415\n",
      "15 Train Loss 8795.679 Test MSE 4114.618436758911 Test RE 0.7146923545103602\n",
      "16 Train Loss 8761.552 Test MSE 4078.981153543407 Test RE 0.7115905987204737\n",
      "17 Train Loss 8680.86 Test MSE 4422.270828122918 Test RE 0.7409297284108789\n",
      "18 Train Loss 8532.654 Test MSE 4488.978900690581 Test RE 0.7464971163203221\n",
      "19 Train Loss 8454.321 Test MSE 4411.351578737747 Test RE 0.740014429792647\n",
      "20 Train Loss 8420.244 Test MSE 4420.03245674035 Test RE 0.7407421906185074\n",
      "21 Train Loss 8401.594 Test MSE 4508.239651304655 Test RE 0.7480968904754728\n",
      "22 Train Loss 8397.398 Test MSE 4544.271590421196 Test RE 0.7510805091255516\n",
      "23 Train Loss 8393.394 Test MSE 4553.947770238188 Test RE 0.7518797269195832\n",
      "24 Train Loss 8388.913 Test MSE 4546.205056570175 Test RE 0.7512402744781097\n",
      "25 Train Loss 8380.713 Test MSE 4526.6726733850655 Test RE 0.7496247173765126\n",
      "26 Train Loss 8352.968 Test MSE 4463.510319440515 Test RE 0.7443764485143023\n",
      "27 Train Loss 8305.472 Test MSE 4527.869358054983 Test RE 0.7497237973401393\n",
      "28 Train Loss 8275.859 Test MSE 4536.219175398587 Test RE 0.7504147595671424\n",
      "29 Train Loss 8247.696 Test MSE 4480.379561705166 Test RE 0.7457817577525022\n",
      "30 Train Loss 8239.155 Test MSE 4496.096724005474 Test RE 0.7470887129941086\n",
      "31 Train Loss 8232.988 Test MSE 4487.084644411025 Test RE 0.7463395965269886\n",
      "32 Train Loss 8228.744 Test MSE 4493.628595429951 Test RE 0.7468836279795914\n",
      "33 Train Loss 8222.238 Test MSE 4517.034634035618 Test RE 0.748826254255275\n",
      "34 Train Loss 8217.092 Test MSE 4512.295502469752 Test RE 0.7484333286155608\n",
      "35 Train Loss 8212.96 Test MSE 4520.933757591019 Test RE 0.7491493795472577\n",
      "36 Train Loss 8207.13 Test MSE 4517.070133433204 Test RE 0.7488291967641166\n",
      "37 Train Loss 8203.162 Test MSE 4513.517825358788 Test RE 0.7485346922388696\n",
      "38 Train Loss 8199.532 Test MSE 4547.619551953025 Test RE 0.7513571349412402\n",
      "39 Train Loss 8197.572 Test MSE 4550.296370635506 Test RE 0.751578234234533\n",
      "40 Train Loss 8193.084 Test MSE 4547.6948432987165 Test RE 0.7513633547288668\n",
      "41 Train Loss 8189.869 Test MSE 4570.605398050177 Test RE 0.7532536008621685\n",
      "42 Train Loss 8187.6147 Test MSE 4597.2925879268505 Test RE 0.7554494766699301\n",
      "43 Train Loss 8186.172 Test MSE 4594.143488522327 Test RE 0.7551906946817789\n",
      "44 Train Loss 8184.66 Test MSE 4605.22493734886 Test RE 0.7561009368950058\n",
      "45 Train Loss 8183.514 Test MSE 4616.3662443517405 Test RE 0.7570149925563715\n",
      "46 Train Loss 8182.7905 Test MSE 4606.5516106379655 Test RE 0.7562098378387934\n",
      "47 Train Loss 8181.968 Test MSE 4611.0427117093095 Test RE 0.7565783767946791\n",
      "48 Train Loss 8181.27 Test MSE 4625.864158147344 Test RE 0.7577933502811415\n",
      "49 Train Loss 8180.0806 Test MSE 4628.211128127384 Test RE 0.7579855622283751\n",
      "50 Train Loss 8178.965 Test MSE 4637.811206279244 Test RE 0.7587712816892684\n",
      "51 Train Loss 8178.4614 Test MSE 4639.498595737855 Test RE 0.7589093022089362\n",
      "52 Train Loss 8177.7715 Test MSE 4643.974330963221 Test RE 0.7592752747624334\n",
      "53 Train Loss 8176.171 Test MSE 4645.948866466174 Test RE 0.7594366727971295\n",
      "54 Train Loss 8175.561 Test MSE 4641.297942942385 Test RE 0.7590564526960708\n",
      "55 Train Loss 8175.0703 Test MSE 4643.295877331861 Test RE 0.7592198102134933\n",
      "56 Train Loss 8174.5146 Test MSE 4645.44843620765 Test RE 0.7593957709990308\n",
      "57 Train Loss 8173.9434 Test MSE 4642.981893845306 Test RE 0.7591941402454994\n",
      "58 Train Loss 8173.5376 Test MSE 4643.400792020078 Test RE 0.7592283874032573\n",
      "59 Train Loss 8172.756 Test MSE 4652.543627849191 Test RE 0.7599754785146436\n",
      "60 Train Loss 8172.4214 Test MSE 4657.102437789715 Test RE 0.7603477195684314\n",
      "61 Train Loss 8172.033 Test MSE 4653.533045447862 Test RE 0.7600562830379928\n",
      "62 Train Loss 8171.309 Test MSE 4653.338140552658 Test RE 0.7600403660734081\n",
      "63 Train Loss 8170.7393 Test MSE 4656.768695966112 Test RE 0.7603204746898455\n",
      "64 Train Loss 8170.5596 Test MSE 4657.357886597628 Test RE 0.7603685723688349\n",
      "65 Train Loss 8170.3164 Test MSE 4661.081006580104 Test RE 0.7606724332651268\n",
      "66 Train Loss 8169.836 Test MSE 4661.134855262002 Test RE 0.7606768272125314\n",
      "67 Train Loss 8169.248 Test MSE 4660.214321015289 Test RE 0.7606017099216141\n",
      "68 Train Loss 8168.7144 Test MSE 4667.817416849301 Test RE 0.7612219143283171\n",
      "69 Train Loss 8168.304 Test MSE 4670.804791816158 Test RE 0.7614654640817683\n",
      "70 Train Loss 8167.644 Test MSE 4668.044899911599 Test RE 0.7612404629311197\n",
      "71 Train Loss 8166.9204 Test MSE 4671.724872375617 Test RE 0.7615404591952822\n",
      "72 Train Loss 8166.5347 Test MSE 4674.014906938558 Test RE 0.7617270862286878\n",
      "73 Train Loss 8166.189 Test MSE 4674.429762599251 Test RE 0.7617608901197969\n",
      "74 Train Loss 8165.9854 Test MSE 4676.363777798796 Test RE 0.7619184606533784\n",
      "75 Train Loss 8165.5938 Test MSE 4676.79566592102 Test RE 0.7619536435381511\n",
      "76 Train Loss 8165.321 Test MSE 4675.538051055038 Test RE 0.7618511899860136\n",
      "77 Train Loss 8165.0312 Test MSE 4676.430590787765 Test RE 0.761923903543442\n",
      "78 Train Loss 8164.718 Test MSE 4676.323152605376 Test RE 0.7619151511212793\n",
      "79 Train Loss 8164.4497 Test MSE 4676.2601750008525 Test RE 0.7619100206211987\n",
      "80 Train Loss 8164.253 Test MSE 4676.611860829026 Test RE 0.7619386704298919\n",
      "81 Train Loss 8164.037 Test MSE 4677.1813531331245 Test RE 0.7619850613869215\n",
      "82 Train Loss 8163.9126 Test MSE 4678.962416956572 Test RE 0.7621301289767118\n",
      "83 Train Loss 8163.7925 Test MSE 4682.488173997881 Test RE 0.7624172203676316\n",
      "84 Train Loss 8163.616 Test MSE 4686.208054923878 Test RE 0.7627200015095411\n",
      "85 Train Loss 8163.4775 Test MSE 4691.235115237268 Test RE 0.7631289901497335\n",
      "86 Train Loss 8163.3325 Test MSE 4697.847885032263 Test RE 0.7636666544441845\n",
      "87 Train Loss 8163.238 Test MSE 4697.650043080269 Test RE 0.763650574007355\n",
      "88 Train Loss 8163.132 Test MSE 4696.5209710207355 Test RE 0.7635587974453782\n",
      "89 Train Loss 8163.008 Test MSE 4698.235809670913 Test RE 0.7636981836680833\n",
      "90 Train Loss 8162.925 Test MSE 4699.0727003623415 Test RE 0.7637661989260928\n",
      "91 Train Loss 8162.8647 Test MSE 4698.360783138752 Test RE 0.7637083408185091\n",
      "92 Train Loss 8162.739 Test MSE 4699.7540372079675 Test RE 0.763821567636503\n",
      "93 Train Loss 8162.6313 Test MSE 4699.706890801536 Test RE 0.7638177364219225\n",
      "94 Train Loss 8162.4907 Test MSE 4696.5269668267965 Test RE 0.7635592848432876\n",
      "95 Train Loss 8162.429 Test MSE 4695.903871215559 Test RE 0.7635086318582185\n",
      "96 Train Loss 8162.3574 Test MSE 4695.867913099454 Test RE 0.7635057086313658\n",
      "97 Train Loss 8162.2974 Test MSE 4696.11418612189 Test RE 0.7635257292534057\n",
      "98 Train Loss 8162.153 Test MSE 4696.272188130847 Test RE 0.7635385736583347\n",
      "99 Train Loss 8162.009 Test MSE 4696.072885799788 Test RE 0.7635223718043922\n",
      "100 Train Loss 8161.9414 Test MSE 4696.242178834501 Test RE 0.7635361341391782\n",
      "101 Train Loss 8161.861 Test MSE 4695.000677942888 Test RE 0.763435203074259\n",
      "102 Train Loss 8161.762 Test MSE 4693.594306530673 Test RE 0.763320852306902\n",
      "103 Train Loss 8161.707 Test MSE 4692.955091317973 Test RE 0.7632688726424102\n",
      "104 Train Loss 8161.646 Test MSE 4691.445748893402 Test RE 0.7631461219754788\n",
      "105 Train Loss 8161.553 Test MSE 4694.018830394149 Test RE 0.7633553717571495\n",
      "106 Train Loss 8161.487 Test MSE 4695.751555604043 Test RE 0.7634962492338727\n",
      "107 Train Loss 8161.4355 Test MSE 4692.773700890232 Test RE 0.7632541217016441\n",
      "108 Train Loss 8161.3813 Test MSE 4690.7400294179 Test RE 0.7630887209774685\n",
      "109 Train Loss 8161.3403 Test MSE 4689.873942964344 Test RE 0.7630182703332696\n",
      "110 Train Loss 8161.274 Test MSE 4690.068248573915 Test RE 0.763034076429163\n",
      "111 Train Loss 8161.228 Test MSE 4691.124846556987 Test RE 0.7631200213260598\n",
      "112 Train Loss 8161.186 Test MSE 4690.362302367083 Test RE 0.763057996075512\n",
      "113 Train Loss 8161.1626 Test MSE 4689.838569179555 Test RE 0.7630153927617926\n",
      "114 Train Loss 8161.1504 Test MSE 4689.353321120548 Test RE 0.7629759179151998\n",
      "115 Train Loss 8161.133 Test MSE 4688.805445952512 Test RE 0.7629313459091137\n",
      "116 Train Loss 8161.116 Test MSE 4689.489710924165 Test RE 0.7629870134087395\n",
      "117 Train Loss 8161.088 Test MSE 4689.9180796186565 Test RE 0.7630218607276819\n",
      "118 Train Loss 8161.069 Test MSE 4690.814687248301 Test RE 0.7630947936143307\n",
      "119 Train Loss 8161.0537 Test MSE 4691.037701571412 Test RE 0.7631129332188069\n",
      "120 Train Loss 8161.0366 Test MSE 4689.896823754932 Test RE 0.7630201316242315\n",
      "121 Train Loss 8161.015 Test MSE 4689.266197116078 Test RE 0.7629688301760718\n",
      "122 Train Loss 8160.9897 Test MSE 4689.043348371402 Test RE 0.7629507006160317\n",
      "123 Train Loss 8160.9663 Test MSE 4689.444325394903 Test RE 0.7629833212529462\n",
      "124 Train Loss 8160.9434 Test MSE 4690.1521865098275 Test RE 0.7630409043915135\n",
      "125 Train Loss 8160.914 Test MSE 4691.399533814773 Test RE 0.763142363118745\n",
      "126 Train Loss 8160.893 Test MSE 4691.335308698969 Test RE 0.7631371394030879\n",
      "127 Train Loss 8160.8726 Test MSE 4690.881497371935 Test RE 0.7631002278810173\n",
      "128 Train Loss 8160.871 Test MSE 4690.860247328908 Test RE 0.7630984994285878\n",
      "129 Train Loss 8160.8564 Test MSE 4690.507441600977 Test RE 0.7630698020714111\n",
      "130 Train Loss 8160.84 Test MSE 4690.789863633023 Test RE 0.763092774477155\n",
      "131 Train Loss 8160.8164 Test MSE 4691.6685131846525 Test RE 0.7631642400243785\n",
      "132 Train Loss 8160.791 Test MSE 4691.005729252695 Test RE 0.7631103326714396\n",
      "133 Train Loss 8160.7607 Test MSE 4690.980430698491 Test RE 0.7631082749448818\n",
      "134 Train Loss 8160.745 Test MSE 4691.501239971144 Test RE 0.7631506352617691\n",
      "135 Train Loss 8160.729 Test MSE 4691.11782663077 Test RE 0.7631194503491168\n",
      "136 Train Loss 8160.7153 Test MSE 4690.501744731911 Test RE 0.7630693386769782\n",
      "137 Train Loss 8160.699 Test MSE 4689.80685554888 Test RE 0.7630128129257366\n",
      "138 Train Loss 8160.6904 Test MSE 4688.972202080224 Test RE 0.7629449125144326\n",
      "139 Train Loss 8160.688 Test MSE 4688.863385680578 Test RE 0.762936059678822\n",
      "140 Train Loss 8160.6875 Test MSE 4688.770890233013 Test RE 0.7629285345651087\n",
      "141 Train Loss 8160.684 Test MSE 4688.688302594229 Test RE 0.7629218154541557\n",
      "142 Train Loss 8160.681 Test MSE 4688.658402211736 Test RE 0.7629193828238559\n",
      "143 Train Loss 8160.68 Test MSE 4688.673725502968 Test RE 0.762920629494581\n",
      "144 Train Loss 8160.669 Test MSE 4688.988156680423 Test RE 0.7629462105036483\n",
      "145 Train Loss 8160.656 Test MSE 4689.57161087473 Test RE 0.7629936760020812\n",
      "146 Train Loss 8160.6353 Test MSE 4691.490090098436 Test RE 0.7631497284051936\n",
      "147 Train Loss 8160.608 Test MSE 4691.736345703847 Test RE 0.7631697569492959\n",
      "148 Train Loss 8160.5903 Test MSE 4691.157612868813 Test RE 0.7631226864208648\n",
      "149 Train Loss 8160.5757 Test MSE 4691.236846424777 Test RE 0.7631291309569218\n",
      "150 Train Loss 8160.57 Test MSE 4691.380332484802 Test RE 0.7631408013925245\n",
      "151 Train Loss 8160.5537 Test MSE 4691.430928471291 Test RE 0.7631449165734345\n",
      "152 Train Loss 8160.539 Test MSE 4692.016218888226 Test RE 0.7631925190515493\n",
      "153 Train Loss 8160.5386 Test MSE 4692.070235719837 Test RE 0.7631969121654278\n",
      "154 Train Loss 8160.5376 Test MSE 4692.0934579487275 Test RE 0.7631988007892722\n",
      "155 Train Loss 8160.5376 Test MSE 4692.118248619187 Test RE 0.763200816966608\n",
      "156 Train Loss 8160.533 Test MSE 4692.308423744949 Test RE 0.7632162833650459\n",
      "157 Train Loss 8160.5293 Test MSE 4692.392303132497 Test RE 0.7632231049358529\n",
      "158 Train Loss 8160.5283 Test MSE 4692.350881596131 Test RE 0.7632197362977126\n",
      "159 Train Loss 8160.528 Test MSE 4692.294284191054 Test RE 0.7632151334463994\n",
      "160 Train Loss 8160.5254 Test MSE 4692.1882253497715 Test RE 0.7632065080101837\n",
      "161 Train Loss 8160.5254 Test MSE 4692.137741188101 Test RE 0.7632024022558399\n",
      "162 Train Loss 8160.5146 Test MSE 4691.564325411812 Test RE 0.7631557661921274\n",
      "163 Train Loss 8160.5146 Test MSE 4691.552747431033 Test RE 0.7631548245223952\n",
      "164 Train Loss 8160.508 Test MSE 4691.2403823081295 Test RE 0.7631294185500632\n",
      "165 Train Loss 8160.497 Test MSE 4690.3708539486015 Test RE 0.763058691688053\n",
      "166 Train Loss 8160.497 Test MSE 4690.324831548747 Test RE 0.7630549480737997\n",
      "167 Train Loss 8160.4966 Test MSE 4690.287451163759 Test RE 0.7630519074161073\n",
      "168 Train Loss 8160.487 Test MSE 4689.955820254547 Test RE 0.763024930810336\n",
      "169 Train Loss 8160.485 Test MSE 4689.905942377418 Test RE 0.7630208733984547\n",
      "170 Train Loss 8160.4834 Test MSE 4689.85050536324 Test RE 0.7630163637425579\n",
      "171 Train Loss 8160.4834 Test MSE 4689.815661470644 Test RE 0.763013529269521\n",
      "172 Train Loss 8160.4697 Test MSE 4688.483802412906 Test RE 0.7629051776078365\n",
      "173 Train Loss 8160.469 Test MSE 4688.372335009223 Test RE 0.7628961086242975\n",
      "174 Train Loss 8160.468 Test MSE 4688.334088325229 Test RE 0.762892996850764\n",
      "175 Train Loss 8160.468 Test MSE 4688.300792155667 Test RE 0.7628902878437688\n",
      "176 Train Loss 8160.468 Test MSE 4688.276579366063 Test RE 0.7628883178628845\n",
      "177 Train Loss 8160.467 Test MSE 4688.1940902753995 Test RE 0.7628816064157926\n",
      "178 Train Loss 8160.457 Test MSE 4687.774160318866 Test RE 0.7628474393135236\n",
      "179 Train Loss 8160.457 Test MSE 4687.774160318866 Test RE 0.7628474393135236\n",
      "180 Train Loss 8160.4565 Test MSE 4687.743312962225 Test RE 0.762844929394644\n",
      "181 Train Loss 8160.445 Test MSE 4687.3387443456595 Test RE 0.7628120105938231\n",
      "182 Train Loss 8160.4434 Test MSE 4687.285848262887 Test RE 0.7628077064584398\n",
      "183 Train Loss 8160.4424 Test MSE 4687.209421698753 Test RE 0.7628014876132881\n",
      "184 Train Loss 8160.4355 Test MSE 4686.908959320151 Test RE 0.7627770384366205\n",
      "185 Train Loss 8160.434 Test MSE 4686.871292702769 Test RE 0.7627739733793696\n",
      "186 Train Loss 8160.433 Test MSE 4686.839835968367 Test RE 0.7627714136314\n",
      "187 Train Loss 8160.419 Test MSE 4686.083121466511 Test RE 0.7627098344532793\n",
      "188 Train Loss 8160.418 Test MSE 4686.058620720667 Test RE 0.7627078405722758\n",
      "189 Train Loss 8160.418 Test MSE 4686.0404489998355 Test RE 0.7627063617466239\n",
      "190 Train Loss 8160.415 Test MSE 4686.070636206623 Test RE 0.7627088183982289\n",
      "191 Train Loss 8160.414 Test MSE 4686.077360584778 Test RE 0.7627093656307692\n",
      "192 Train Loss 8160.4023 Test MSE 4686.115292574785 Test RE 0.7627124525436885\n",
      "193 Train Loss 8160.3853 Test MSE 4685.693990507928 Test RE 0.7626781661961245\n",
      "194 Train Loss 8160.3657 Test MSE 4685.564303631278 Test RE 0.7626676117260869\n",
      "195 Train Loss 8160.346 Test MSE 4685.714778353504 Test RE 0.7626798579858988\n",
      "196 Train Loss 8160.3296 Test MSE 4685.893061415127 Test RE 0.7626943671497293\n",
      "197 Train Loss 8160.326 Test MSE 4686.141773896375 Test RE 0.7627146075915201\n",
      "198 Train Loss 8160.326 Test MSE 4686.1932157008105 Test RE 0.7627187939040457\n",
      "199 Train Loss 8160.3247 Test MSE 4686.291487963499 Test RE 0.7627267911957991\n",
      "Training time: 26.64\n",
      "Training time: 26.64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 17615.838 Test MSE 13817.385394459188 Test RE 1.3096863099752458\n",
      "1 Train Loss 14669.531 Test MSE 10249.03857049444 Test RE 1.127965758715813\n",
      "2 Train Loss 13053.852 Test MSE 7853.495623146704 Test RE 0.9873834769135766\n",
      "3 Train Loss 10439.294 Test MSE 5455.509402113374 Test RE 0.8229472657793903\n",
      "4 Train Loss 9905.123 Test MSE 4573.339859580537 Test RE 0.7534788921349549\n",
      "5 Train Loss 9756.373 Test MSE 4596.779079921295 Test RE 0.7554072844252584\n",
      "6 Train Loss 9510.95 Test MSE 4356.055074798891 Test RE 0.7353617451942231\n",
      "7 Train Loss 9443.841 Test MSE 4384.050625574334 Test RE 0.7377209768405448\n",
      "8 Train Loss 9373.658 Test MSE 4254.138754351965 Test RE 0.7267083959399605\n",
      "9 Train Loss 9311.57 Test MSE 4209.030677980149 Test RE 0.722845360557056\n",
      "10 Train Loss 9176.705 Test MSE 4199.874048683255 Test RE 0.7220586674676303\n",
      "11 Train Loss 9091.292 Test MSE 4172.071445395133 Test RE 0.7196647332079501\n",
      "12 Train Loss 8958.1045 Test MSE 4126.94735103727 Test RE 0.7157622945598725\n",
      "13 Train Loss 8871.57 Test MSE 4093.786790758685 Test RE 0.712880873036453\n",
      "14 Train Loss 8816.945 Test MSE 4078.017483485187 Test RE 0.7115065361770893\n",
      "15 Train Loss 8789.039 Test MSE 4062.558232989069 Test RE 0.7101566398221342\n",
      "16 Train Loss 8768.826 Test MSE 4074.436806916 Test RE 0.7111941007496811\n",
      "17 Train Loss 8746.303 Test MSE 4066.06126988857 Test RE 0.7104627485264982\n",
      "18 Train Loss 8739.951 Test MSE 4067.8587008278387 Test RE 0.7106197636996929\n",
      "19 Train Loss 8734.632 Test MSE 4066.6933287517004 Test RE 0.7105179661926367\n",
      "20 Train Loss 8729.064 Test MSE 4065.3928340885373 Test RE 0.7104043482438407\n",
      "21 Train Loss 8726.833 Test MSE 4065.4864125806057 Test RE 0.710412524352255\n",
      "22 Train Loss 8725.726 Test MSE 4064.541541297326 Test RE 0.7103299650553297\n",
      "23 Train Loss 8724.887 Test MSE 4065.8327498048716 Test RE 0.7104427835927197\n",
      "24 Train Loss 8723.804 Test MSE 4065.2827522762022 Test RE 0.7103947300924427\n",
      "25 Train Loss 8722.863 Test MSE 4063.5861453390353 Test RE 0.7102464763942494\n",
      "26 Train Loss 8721.758 Test MSE 4066.5495922867885 Test RE 0.7105054095237544\n",
      "27 Train Loss 8721.146 Test MSE 4065.8713869025337 Test RE 0.7104461592089452\n",
      "28 Train Loss 8719.723 Test MSE 4066.493816862582 Test RE 0.7105005369806313\n",
      "29 Train Loss 8719.221 Test MSE 4065.6704594203666 Test RE 0.7104286045560764\n",
      "30 Train Loss 8718.772 Test MSE 4065.519908607628 Test RE 0.7104154509329497\n",
      "31 Train Loss 8718.226 Test MSE 4064.827928869434 Test RE 0.7103549895370251\n",
      "32 Train Loss 8717.945 Test MSE 4064.472923909635 Test RE 0.7103239691524932\n",
      "33 Train Loss 8717.847 Test MSE 4065.7177082210005 Test RE 0.7104327326331442\n",
      "34 Train Loss 8717.623 Test MSE 4064.3269598314837 Test RE 0.7103112143973057\n",
      "35 Train Loss 8717.34 Test MSE 4065.005743102243 Test RE 0.710370526461142\n",
      "36 Train Loss 8717.268 Test MSE 4065.843245189321 Test RE 0.7104437005469809\n",
      "37 Train Loss 8717.124 Test MSE 4064.778351075039 Test RE 0.7103506575035883\n",
      "38 Train Loss 8716.881 Test MSE 4066.568862437923 Test RE 0.7105070929571042\n",
      "39 Train Loss 8716.597 Test MSE 4066.619305859522 Test RE 0.7105114996570651\n",
      "40 Train Loss 8716.412 Test MSE 4063.9360356286697 Test RE 0.710277053203415\n",
      "41 Train Loss 8716.182 Test MSE 4066.8670605435314 Test RE 0.7105331429260526\n",
      "42 Train Loss 8715.847 Test MSE 4066.3428541670046 Test RE 0.7104873487063366\n",
      "43 Train Loss 8715.65 Test MSE 4064.357585479468 Test RE 0.7103138905722843\n",
      "44 Train Loss 8715.492 Test MSE 4065.8667173166036 Test RE 0.710445751241006\n",
      "45 Train Loss 8715.221 Test MSE 4065.6848022230492 Test RE 0.7104298576739092\n",
      "46 Train Loss 8714.953 Test MSE 4064.816033842057 Test RE 0.7103539501697534\n",
      "47 Train Loss 8714.79 Test MSE 4065.2152102796845 Test RE 0.7103888286975577\n",
      "48 Train Loss 8714.727 Test MSE 4065.511055737611 Test RE 0.7104146774501958\n",
      "49 Train Loss 8714.616 Test MSE 4064.897649295175 Test RE 0.7103610815587289\n",
      "50 Train Loss 8714.5 Test MSE 4065.3373653431177 Test RE 0.7103995018029235\n",
      "51 Train Loss 8714.46 Test MSE 4065.2480267186597 Test RE 0.7103916959977362\n",
      "52 Train Loss 8714.4 Test MSE 4064.958633496493 Test RE 0.7103664101849901\n",
      "53 Train Loss 8714.306 Test MSE 4065.7511995018235 Test RE 0.7104356587159252\n",
      "54 Train Loss 8714.27 Test MSE 4065.3143879051386 Test RE 0.7103974941978847\n",
      "55 Train Loss 8714.251 Test MSE 4065.1084788544395 Test RE 0.710379503076906\n",
      "56 Train Loss 8714.221 Test MSE 4065.5292074475124 Test RE 0.7104162633795617\n",
      "57 Train Loss 8714.19 Test MSE 4064.9372295057574 Test RE 0.7103645399696387\n",
      "58 Train Loss 8714.156 Test MSE 4065.561462228825 Test RE 0.7104190814967855\n",
      "59 Train Loss 8714.124 Test MSE 4065.681444837103 Test RE 0.7104295643423023\n",
      "60 Train Loss 8714.066 Test MSE 4064.624932695864 Test RE 0.7103372518679727\n",
      "61 Train Loss 8714.0 Test MSE 4065.831205081177 Test RE 0.7104426486341548\n",
      "62 Train Loss 8713.924 Test MSE 4065.927940255627 Test RE 0.7104511000898734\n",
      "63 Train Loss 8713.904 Test MSE 4065.2394183526158 Test RE 0.7103909438523628\n",
      "64 Train Loss 8713.904 Test MSE 4065.2282392797583 Test RE 0.7103899670934611\n",
      "65 Train Loss 8713.903 Test MSE 4065.2232986160025 Test RE 0.7103895354081015\n",
      "66 Train Loss 8713.902 Test MSE 4065.2214927695936 Test RE 0.7103893776240832\n",
      "67 Train Loss 8713.9 Test MSE 4065.2338080845548 Test RE 0.710390453661677\n",
      "68 Train Loss 8713.9 Test MSE 4065.2385006962204 Test RE 0.7103908636732192\n",
      "69 Train Loss 8713.9 Test MSE 4065.2448741639687 Test RE 0.710391420547248\n",
      "70 Train Loss 8713.898 Test MSE 4065.24816600857 Test RE 0.7103917081680141\n",
      "71 Train Loss 8713.896 Test MSE 4065.251186234187 Test RE 0.7103919720563119\n",
      "72 Train Loss 8713.895 Test MSE 4065.2423290856823 Test RE 0.7103911981741663\n",
      "73 Train Loss 8713.893 Test MSE 4065.2225964442164 Test RE 0.7103894740565504\n",
      "74 Train Loss 8713.89 Test MSE 4065.172755986423 Test RE 0.7103851192833145\n",
      "75 Train Loss 8713.856 Test MSE 4065.1321315058553 Test RE 0.7103815697295432\n",
      "76 Train Loss 8713.824 Test MSE 4065.584753354203 Test RE 0.7104211164477207\n",
      "77 Train Loss 8713.81 Test MSE 4065.290239061501 Test RE 0.7103953842376396\n",
      "78 Train Loss 8713.807 Test MSE 4065.14330885211 Test RE 0.7103825463491295\n",
      "79 Train Loss 8713.804 Test MSE 4065.05097625786 Test RE 0.7103744787570564\n",
      "80 Train Loss 8713.803 Test MSE 4065.024633404144 Test RE 0.710372177024384\n",
      "81 Train Loss 8713.801 Test MSE 4064.990510586036 Test RE 0.7103691954986073\n",
      "82 Train Loss 8713.774 Test MSE 4065.477202346915 Test RE 0.7104117196430015\n",
      "83 Train Loss 8713.753 Test MSE 4065.6267899373183 Test RE 0.7104247891788191\n",
      "84 Train Loss 8713.731 Test MSE 4065.102594263503 Test RE 0.7103789889092865\n",
      "85 Train Loss 8713.716 Test MSE 4065.4255828673517 Test RE 0.7104072095697898\n",
      "86 Train Loss 8713.705 Test MSE 4065.5271664371858 Test RE 0.7104160850550386\n",
      "87 Train Loss 8713.6875 Test MSE 4065.0092388596677 Test RE 0.7103708319075135\n",
      "88 Train Loss 8713.684 Test MSE 4065.049678554187 Test RE 0.7103743653691003\n",
      "89 Train Loss 8713.667 Test MSE 4065.9239963731243 Test RE 0.7104507555269122\n",
      "90 Train Loss 8713.637 Test MSE 4065.7841802978946 Test RE 0.7104385401866442\n",
      "91 Train Loss 8713.598 Test MSE 4064.8672913219348 Test RE 0.7103584289503695\n",
      "92 Train Loss 8713.584 Test MSE 4064.974984497663 Test RE 0.7103678388822255\n",
      "93 Train Loss 8713.579 Test MSE 4065.107178756882 Test RE 0.7103793894805853\n",
      "94 Train Loss 8713.578 Test MSE 4065.184156846428 Test RE 0.7103861154274027\n",
      "95 Train Loss 8713.576 Test MSE 4065.341666426331 Test RE 0.7103998776003405\n",
      "96 Train Loss 8713.56 Test MSE 4065.7361614647807 Test RE 0.7104343448667609\n",
      "97 Train Loss 8713.555 Test MSE 4065.5304912189126 Test RE 0.7104163755435583\n",
      "98 Train Loss 8713.552 Test MSE 4065.2755967301114 Test RE 0.7103941048881481\n",
      "99 Train Loss 8713.548 Test MSE 4065.0776687933544 Test RE 0.7103768110359102\n",
      "100 Train Loss 8713.548 Test MSE 4065.0526229238294 Test RE 0.7103746226358625\n",
      "101 Train Loss 8713.548 Test MSE 4065.0399121104024 Test RE 0.7103735120172324\n",
      "102 Train Loss 8713.548 Test MSE 4065.074132489922 Test RE 0.7103765020493782\n",
      "103 Train Loss 8713.548 Test MSE 4065.0854566919857 Test RE 0.7103774915075266\n",
      "104 Train Loss 8713.548 Test MSE 4065.10273200432 Test RE 0.7103790009444295\n",
      "105 Train Loss 8713.546 Test MSE 4065.158528590601 Test RE 0.7103838761702012\n",
      "106 Train Loss 8713.546 Test MSE 4065.1928261013886 Test RE 0.7103868728980158\n",
      "107 Train Loss 8713.546 Test MSE 4065.22587707659 Test RE 0.7103897606984476\n",
      "108 Train Loss 8713.545 Test MSE 4065.296328787832 Test RE 0.710395916316729\n",
      "109 Train Loss 8713.545 Test MSE 4065.3373060819395 Test RE 0.7103994966251106\n",
      "110 Train Loss 8713.545 Test MSE 4065.367553307544 Test RE 0.7104021394038346\n",
      "111 Train Loss 8713.544 Test MSE 4065.418522196423 Test RE 0.7104065926659001\n",
      "112 Train Loss 8713.541 Test MSE 4065.4155625503495 Test RE 0.7104063340759844\n",
      "113 Train Loss 8713.54 Test MSE 4065.392797436426 Test RE 0.7104043450414663\n",
      "114 Train Loss 8713.534 Test MSE 4065.07821467544 Test RE 0.7103768587326572\n",
      "115 Train Loss 8713.531 Test MSE 4065.0068900521205 Test RE 0.7103706266774001\n",
      "116 Train Loss 8713.53 Test MSE 4064.992074764065 Test RE 0.7103693321709784\n",
      "117 Train Loss 8713.53 Test MSE 4065.0206334905147 Test RE 0.7103718275273567\n",
      "118 Train Loss 8713.529 Test MSE 4065.028089044924 Test RE 0.7103724789648104\n",
      "119 Train Loss 8713.527 Test MSE 4065.0795865236582 Test RE 0.7103769785986345\n",
      "120 Train Loss 8713.523 Test MSE 4065.2392056508625 Test RE 0.7103909252677991\n",
      "121 Train Loss 8713.5205 Test MSE 4065.312368528448 Test RE 0.7103973177588468\n",
      "122 Train Loss 8713.5205 Test MSE 4065.311220951309 Test RE 0.7103972174915479\n",
      "123 Train Loss 8713.5205 Test MSE 4065.3024162932857 Test RE 0.7103964482013749\n",
      "124 Train Loss 8713.5205 Test MSE 4065.287860300492 Test RE 0.710395176397487\n",
      "125 Train Loss 8713.5205 Test MSE 4065.27216458296 Test RE 0.7103938050096333\n",
      "126 Train Loss 8713.519 Test MSE 4065.240762813472 Test RE 0.7103910613230257\n",
      "127 Train Loss 8713.519 Test MSE 4065.229266423525 Test RE 0.7103900568390471\n",
      "128 Train Loss 8713.519 Test MSE 4065.2197450726176 Test RE 0.7103892249207802\n",
      "129 Train Loss 8713.519 Test MSE 4065.214519448952 Test RE 0.7103887683368595\n",
      "130 Train Loss 8713.519 Test MSE 4065.2144301595604 Test RE 0.7103887605352808\n",
      "131 Train Loss 8713.518 Test MSE 4065.238956756617 Test RE 0.7103909035209588\n",
      "132 Train Loss 8713.518 Test MSE 4065.251768220962 Test RE 0.7103920229066404\n",
      "133 Train Loss 8713.517 Test MSE 4065.270004027144 Test RE 0.7103936162343668\n",
      "134 Train Loss 8713.517 Test MSE 4065.298482255417 Test RE 0.7103961044720629\n",
      "135 Train Loss 8713.517 Test MSE 4065.3313071058856 Test RE 0.7103989724778113\n",
      "136 Train Loss 8713.517 Test MSE 4065.366297097476 Test RE 0.7104020296456913\n",
      "137 Train Loss 8713.517 Test MSE 4065.3973508507693 Test RE 0.7104047428830269\n",
      "138 Train Loss 8713.516 Test MSE 4065.4498170579577 Test RE 0.7104093269518097\n",
      "139 Train Loss 8713.515 Test MSE 4065.487384751474 Test RE 0.710412609291946\n",
      "140 Train Loss 8713.515 Test MSE 4065.495774990613 Test RE 0.7104133423564029\n",
      "141 Train Loss 8713.514 Test MSE 4065.4849181065647 Test RE 0.7104123937783131\n",
      "142 Train Loss 8713.514 Test MSE 4065.4675285715743 Test RE 0.7104108744325722\n",
      "143 Train Loss 8713.514 Test MSE 4065.4403175148786 Test RE 0.7104084969614951\n",
      "144 Train Loss 8713.513 Test MSE 4065.4233334529044 Test RE 0.7104070130343434\n",
      "145 Train Loss 8713.511 Test MSE 4065.370858408324 Test RE 0.7104024281784849\n",
      "146 Train Loss 8713.506 Test MSE 4065.229856000452 Test RE 0.7103901083526942\n",
      "147 Train Loss 8713.506 Test MSE 4065.202916416425 Test RE 0.7103877545318279\n",
      "148 Train Loss 8713.503 Test MSE 4065.1663012774998 Test RE 0.7103845553059309\n",
      "149 Train Loss 8713.503 Test MSE 4065.1628624410355 Test RE 0.7103842548389084\n",
      "150 Train Loss 8713.499 Test MSE 4065.2002583535173 Test RE 0.7103875222856538\n",
      "151 Train Loss 8713.499 Test MSE 4065.2291025392196 Test RE 0.7103900425198323\n",
      "152 Train Loss 8713.497 Test MSE 4065.2673067674905 Test RE 0.7103933805653515\n",
      "153 Train Loss 8713.496 Test MSE 4065.3139216374957 Test RE 0.710397453458677\n",
      "154 Train Loss 8713.495 Test MSE 4065.3439180974724 Test RE 0.7104000743349346\n",
      "155 Train Loss 8713.493 Test MSE 4065.371196683035 Test RE 0.7104024577343581\n",
      "156 Train Loss 8713.493 Test MSE 4065.3889775838284 Test RE 0.7104040112925945\n",
      "157 Train Loss 8713.493 Test MSE 4065.3881137985945 Test RE 0.7104039358217686\n",
      "158 Train Loss 8713.492 Test MSE 4065.382772835973 Test RE 0.7104034691698762\n",
      "159 Train Loss 8713.492 Test MSE 4065.371388948457 Test RE 0.7104024745330487\n",
      "160 Train Loss 8713.492 Test MSE 4065.362330720194 Test RE 0.7104016830935048\n",
      "161 Train Loss 8713.491 Test MSE 4065.336627453161 Test RE 0.7103994373314376\n",
      "162 Train Loss 8713.489 Test MSE 4065.303943691591 Test RE 0.7103965816549432\n",
      "163 Train Loss 8713.466 Test MSE 4065.4230577356443 Test RE 0.7104069889444194\n",
      "164 Train Loss 8713.448 Test MSE 4065.36906067129 Test RE 0.710402271105866\n",
      "165 Train Loss 8713.438 Test MSE 4065.200976097835 Test RE 0.7103875849980115\n",
      "166 Train Loss 8713.436 Test MSE 4065.274871399012 Test RE 0.7103940415134832\n",
      "167 Train Loss 8713.433 Test MSE 4065.408441575907 Test RE 0.710405711902496\n",
      "168 Train Loss 8713.43 Test MSE 4065.4992616853965 Test RE 0.7104136469925534\n",
      "169 Train Loss 8713.427 Test MSE 4065.542956153854 Test RE 0.7104174646126395\n",
      "170 Train Loss 8713.419 Test MSE 4065.4749871041076 Test RE 0.7104115260944229\n",
      "171 Train Loss 8713.415 Test MSE 4065.3463926213244 Test RE 0.710400290540709\n",
      "172 Train Loss 8713.395 Test MSE 4065.017800784069 Test RE 0.7103715800162878\n",
      "173 Train Loss 8713.389 Test MSE 4065.2187943699314 Test RE 0.7103891418540547\n",
      "174 Train Loss 8713.388 Test MSE 4065.268175932656 Test RE 0.7103934565073626\n",
      "175 Train Loss 8713.386 Test MSE 4065.340423714604 Test RE 0.7103997690212348\n",
      "176 Train Loss 8713.384 Test MSE 4065.4306815443733 Test RE 0.7104076550503063\n",
      "177 Train Loss 8713.384 Test MSE 4065.4452468139343 Test RE 0.7104089276423807\n",
      "178 Train Loss 8713.383 Test MSE 4065.453331519642 Test RE 0.7104096340157183\n",
      "179 Train Loss 8713.382 Test MSE 4065.4469271341486 Test RE 0.7104090744546342\n",
      "180 Train Loss 8713.381 Test MSE 4065.4267533104025 Test RE 0.710407311833514\n",
      "181 Train Loss 8713.381 Test MSE 4065.407239272903 Test RE 0.7104056068548734\n",
      "182 Train Loss 8713.38 Test MSE 4065.3614069204395 Test RE 0.7104016023788124\n",
      "183 Train Loss 8713.379 Test MSE 4065.3083040277525 Test RE 0.7103969626310175\n",
      "184 Train Loss 8713.379 Test MSE 4065.2893058692425 Test RE 0.7103953027015781\n",
      "185 Train Loss 8713.379 Test MSE 4065.2724482253993 Test RE 0.7103938297924547\n",
      "186 Train Loss 8713.377 Test MSE 4065.259236500147 Test RE 0.7103926754373845\n",
      "187 Train Loss 8713.377 Test MSE 4065.2454081593796 Test RE 0.7103914672044306\n",
      "188 Train Loss 8713.376 Test MSE 4065.2247086729653 Test RE 0.7103896586103895\n",
      "189 Train Loss 8713.376 Test MSE 4065.2135617181852 Test RE 0.7103886846560085\n",
      "190 Train Loss 8713.374 Test MSE 4065.204484720962 Test RE 0.7103878915611785\n",
      "191 Train Loss 8713.371 Test MSE 4065.202643354449 Test RE 0.7103877306732542\n",
      "192 Train Loss 8713.37 Test MSE 4065.209562864073 Test RE 0.7103883352596769\n",
      "193 Train Loss 8713.37 Test MSE 4065.220316803013 Test RE 0.7103892748751642\n",
      "194 Train Loss 8713.368 Test MSE 4065.252299335603 Test RE 0.7103920693120801\n",
      "195 Train Loss 8713.368 Test MSE 4065.26970041366 Test RE 0.710393589706598\n",
      "196 Train Loss 8713.367 Test MSE 4065.2941393689243 Test RE 0.7103957250201625\n",
      "197 Train Loss 8713.366 Test MSE 4065.3447361486874 Test RE 0.7104001458102668\n",
      "198 Train Loss 8713.366 Test MSE 4065.3633655007357 Test RE 0.7104017735048546\n",
      "199 Train Loss 8713.365 Test MSE 4065.385062380679 Test RE 0.7104036692125736\n",
      "Training time: 17.09\n",
      "Training time: 17.09\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 20632.42 Test MSE 11844.540139942574 Test RE 1.2125885258013502\n",
      "1 Train Loss 14493.185 Test MSE 4650.349742796253 Test RE 0.7597962759563898\n",
      "2 Train Loss 7024.876 Test MSE 2720.1293123190494 Test RE 0.5810976613162324\n",
      "3 Train Loss 5011.7344 Test MSE 2226.9187385716714 Test RE 0.5257829965181503\n",
      "4 Train Loss 4255.8486 Test MSE 1713.8771379282177 Test RE 0.4612583011727863\n",
      "5 Train Loss 3625.8188 Test MSE 1260.915127677492 Test RE 0.3956373460396685\n",
      "6 Train Loss 3205.818 Test MSE 908.4401265118335 Test RE 0.3358168680327787\n",
      "7 Train Loss 2824.7937 Test MSE 618.4873347044587 Test RE 0.27708930137246485\n",
      "8 Train Loss 2597.2444 Test MSE 499.6987669065221 Test RE 0.2490625849604036\n",
      "9 Train Loss 2343.5222 Test MSE 369.76822085253934 Test RE 0.21424916804700286\n",
      "10 Train Loss 2183.0298 Test MSE 340.1642197939348 Test RE 0.20549377365557236\n",
      "11 Train Loss 2111.3738 Test MSE 288.14894686253257 Test RE 0.18913106612716332\n",
      "12 Train Loss 2004.2382 Test MSE 228.14851230555684 Test RE 0.16829188424828784\n",
      "13 Train Loss 1916.6802 Test MSE 257.34159030884746 Test RE 0.17873489214483132\n",
      "14 Train Loss 1794.4827 Test MSE 204.21330930248573 Test RE 0.15921954332551805\n",
      "15 Train Loss 1646.6525 Test MSE 101.0732290289747 Test RE 0.11201403005236284\n",
      "16 Train Loss 1572.9792 Test MSE 82.53214916862377 Test RE 0.1012199059810365\n",
      "17 Train Loss 1520.1675 Test MSE 66.13254495031201 Test RE 0.09060704571185171\n",
      "18 Train Loss 1492.5559 Test MSE 65.40973485599875 Test RE 0.09011053054366107\n",
      "19 Train Loss 1468.9934 Test MSE 59.33928987205525 Test RE 0.08582731466841087\n",
      "20 Train Loss 1447.6449 Test MSE 50.416146948801305 Test RE 0.07911141968917826\n",
      "21 Train Loss 1428.9874 Test MSE 32.15126680174247 Test RE 0.06317618503966045\n",
      "22 Train Loss 1411.2228 Test MSE 29.671919362980944 Test RE 0.06069140233165799\n",
      "23 Train Loss 1392.1268 Test MSE 34.040216945005334 Test RE 0.06500556120440605\n",
      "24 Train Loss 1376.521 Test MSE 33.10011421313563 Test RE 0.06410163375683804\n",
      "25 Train Loss 1367.3623 Test MSE 29.042398196329543 Test RE 0.06004413464882852\n",
      "26 Train Loss 1362.8473 Test MSE 27.127828612473934 Test RE 0.0580312424412284\n",
      "27 Train Loss 1357.0232 Test MSE 25.89318914172616 Test RE 0.05669530868544155\n",
      "28 Train Loss 1348.7257 Test MSE 26.322739397150055 Test RE 0.05716364249094203\n",
      "29 Train Loss 1339.6884 Test MSE 27.366706605833564 Test RE 0.05828618366338825\n",
      "30 Train Loss 1326.1298 Test MSE 27.393516499877133 Test RE 0.058314726810815634\n",
      "31 Train Loss 1307.2129 Test MSE 28.633311890761274 Test RE 0.059619749134041174\n",
      "32 Train Loss 1277.3824 Test MSE 28.462751825267937 Test RE 0.059441915415870426\n",
      "33 Train Loss 1216.6449 Test MSE 25.82306825602484 Test RE 0.056618488862257614\n",
      "34 Train Loss 1096.2871 Test MSE 39.11586310683516 Test RE 0.06968363722420197\n",
      "35 Train Loss 993.8506 Test MSE 32.79533816261986 Test RE 0.06380583684824467\n",
      "36 Train Loss 851.39154 Test MSE 18.482179961406743 Test RE 0.04789949665108205\n",
      "37 Train Loss 736.13434 Test MSE 17.203623831095015 Test RE 0.046213016900972875\n",
      "38 Train Loss 691.3721 Test MSE 18.0311618494902 Test RE 0.04731144451884336\n",
      "39 Train Loss 669.22394 Test MSE 29.57631570788803 Test RE 0.06059354884982313\n",
      "40 Train Loss 649.10785 Test MSE 33.249092442441295 Test RE 0.06424572731615072\n",
      "41 Train Loss 640.42035 Test MSE 35.279658043073006 Test RE 0.06617844157792617\n",
      "42 Train Loss 632.7378 Test MSE 42.82397532245249 Test RE 0.07291180376942089\n",
      "43 Train Loss 624.45557 Test MSE 37.98729307239525 Test RE 0.06867102440056466\n",
      "44 Train Loss 617.14484 Test MSE 30.320106200508423 Test RE 0.06135072671470189\n",
      "45 Train Loss 610.08636 Test MSE 34.05848363167483 Test RE 0.06502300053157328\n",
      "46 Train Loss 605.71204 Test MSE 39.56966801133883 Test RE 0.07008669091756778\n",
      "47 Train Loss 602.5024 Test MSE 45.803614957779864 Test RE 0.0754057093804096\n",
      "48 Train Loss 600.7639 Test MSE 45.44565331060393 Test RE 0.07511047835663849\n",
      "49 Train Loss 598.8397 Test MSE 46.24112065382289 Test RE 0.07576498257474441\n",
      "50 Train Loss 597.2343 Test MSE 44.64109428749723 Test RE 0.07444264033552504\n",
      "51 Train Loss 594.6165 Test MSE 41.0125654492497 Test RE 0.0713530957941068\n",
      "52 Train Loss 591.4804 Test MSE 41.125831266247324 Test RE 0.07145155701326483\n",
      "53 Train Loss 587.37177 Test MSE 44.32646159463347 Test RE 0.07417983870774472\n",
      "54 Train Loss 560.2262 Test MSE 66.00849063704423 Test RE 0.09052202349621483\n",
      "55 Train Loss 504.98303 Test MSE 56.46328230729252 Test RE 0.08372157941793809\n",
      "56 Train Loss 449.85602 Test MSE 42.64338408796859 Test RE 0.072757904655094\n",
      "57 Train Loss 339.55875 Test MSE 56.767488988488005 Test RE 0.08394680943080468\n",
      "58 Train Loss 252.47491 Test MSE 40.79231038706238 Test RE 0.07116123949978644\n",
      "59 Train Loss 204.16943 Test MSE 40.46656438218424 Test RE 0.07087654182323375\n",
      "60 Train Loss 171.3941 Test MSE 38.81431960947027 Test RE 0.06941452260691398\n",
      "61 Train Loss 158.62015 Test MSE 33.69185795552015 Test RE 0.06467208056720825\n",
      "62 Train Loss 144.99918 Test MSE 28.26256897827645 Test RE 0.059232514579611505\n",
      "63 Train Loss 137.47412 Test MSE 25.17385981873071 Test RE 0.05590224601121468\n",
      "64 Train Loss 124.35992 Test MSE 21.887797762599217 Test RE 0.052126118381061605\n",
      "65 Train Loss 112.36342 Test MSE 24.310795225076838 Test RE 0.05493560793792905\n",
      "66 Train Loss 108.73195 Test MSE 26.02847078165379 Test RE 0.05684322098812666\n",
      "67 Train Loss 100.37157 Test MSE 25.256345219665846 Test RE 0.05599375657321131\n",
      "68 Train Loss 92.74087 Test MSE 23.815622184077895 Test RE 0.054373253240622914\n",
      "69 Train Loss 84.786995 Test MSE 24.201389891217644 Test RE 0.054811855800722765\n",
      "70 Train Loss 76.10002 Test MSE 23.348400365284913 Test RE 0.05383725621624213\n",
      "71 Train Loss 69.52088 Test MSE 23.953310714963653 Test RE 0.05453020449889191\n",
      "72 Train Loss 66.78997 Test MSE 25.634256113680753 Test RE 0.05641111863425593\n",
      "73 Train Loss 64.49672 Test MSE 25.031090735611446 Test RE 0.05574350077840044\n",
      "74 Train Loss 62.74158 Test MSE 24.949757871938793 Test RE 0.055652864148445336\n",
      "75 Train Loss 60.966675 Test MSE 27.1426424321946 Test RE 0.058047084974144895\n",
      "76 Train Loss 59.743244 Test MSE 27.615541954199156 Test RE 0.05855057139106434\n",
      "77 Train Loss 58.40462 Test MSE 27.94424084986033 Test RE 0.05889799492210603\n",
      "78 Train Loss 56.71464 Test MSE 29.840139091151162 Test RE 0.06086319879892626\n",
      "79 Train Loss 54.280914 Test MSE 27.714616280420525 Test RE 0.05865550622992728\n",
      "80 Train Loss 51.557335 Test MSE 25.379429236562014 Test RE 0.056130030449046915\n",
      "81 Train Loss 50.25671 Test MSE 25.102865356501376 Test RE 0.055823363551244884\n",
      "82 Train Loss 49.310474 Test MSE 23.42717110377566 Test RE 0.05392799540130477\n",
      "83 Train Loss 47.828484 Test MSE 22.515935395978868 Test RE 0.052868787371315985\n",
      "84 Train Loss 46.0936 Test MSE 21.731423648426706 Test RE 0.05193958096348766\n",
      "85 Train Loss 44.573303 Test MSE 21.51827593893775 Test RE 0.05168423453047423\n",
      "86 Train Loss 42.90589 Test MSE 20.561327142876006 Test RE 0.05052192896168208\n",
      "87 Train Loss 37.736885 Test MSE 15.505148273187297 Test RE 0.04387249308467967\n",
      "88 Train Loss 28.91851 Test MSE 10.000142877124448 Test RE 0.035233635314582214\n",
      "89 Train Loss 22.91594 Test MSE 5.478667245475546 Test RE 0.026079052836130552\n",
      "90 Train Loss 16.919798 Test MSE 2.6955761689883917 Test RE 0.018292798749349318\n",
      "91 Train Loss 10.196032 Test MSE 0.9960073408400248 Test RE 0.011119509289579688\n",
      "92 Train Loss 7.1516137 Test MSE 0.48301194437531486 Test RE 0.007743428411297967\n",
      "93 Train Loss 5.9231143 Test MSE 0.11636511236754404 Test RE 0.0038007188864936474\n",
      "94 Train Loss 5.178054 Test MSE 0.08798136594965474 Test RE 0.003304834399564363\n",
      "95 Train Loss 4.687888 Test MSE 0.0828766366786504 Test RE 0.003207527668987176\n",
      "96 Train Loss 4.168361 Test MSE 0.03682778763776519 Test RE 0.002138169683145244\n",
      "97 Train Loss 3.9367256 Test MSE 0.08855002073528453 Test RE 0.003315497356368629\n",
      "98 Train Loss 3.7323012 Test MSE 0.15144293538708217 Test RE 0.0043358960503207125\n",
      "99 Train Loss 3.5505633 Test MSE 0.14211621593458154 Test RE 0.00420025995637931\n",
      "100 Train Loss 3.4823794 Test MSE 0.1149218881778663 Test RE 0.0037770760458111603\n",
      "101 Train Loss 3.3215716 Test MSE 0.139926440449489 Test RE 0.004167774810733611\n",
      "102 Train Loss 3.2131805 Test MSE 0.14294617562792933 Test RE 0.0042125068756217274\n",
      "103 Train Loss 2.9673867 Test MSE 0.13977037863811634 Test RE 0.004165449975113175\n",
      "104 Train Loss 2.7542224 Test MSE 0.18440109696848564 Test RE 0.004784494971570385\n",
      "105 Train Loss 2.593653 Test MSE 0.19318457252108753 Test RE 0.004897118046847782\n",
      "106 Train Loss 2.4207327 Test MSE 0.14334212417751838 Test RE 0.004218336981140338\n",
      "107 Train Loss 2.3175497 Test MSE 0.10805613169257972 Test RE 0.003662512034745791\n",
      "108 Train Loss 2.2315774 Test MSE 0.1290897075530765 Test RE 0.004003134304092253\n",
      "109 Train Loss 2.1478093 Test MSE 0.12736293243306793 Test RE 0.003976270097955907\n",
      "110 Train Loss 2.0578258 Test MSE 0.11534229909946561 Test RE 0.0037839784490356692\n",
      "111 Train Loss 1.9309602 Test MSE 0.12086679206667116 Test RE 0.0038735382617083773\n",
      "112 Train Loss 1.7751269 Test MSE 0.03588648373684296 Test RE 0.0021106674168693143\n",
      "113 Train Loss 1.7066993 Test MSE 0.0028348341306211958 Test RE 0.0005932232704278059\n",
      "114 Train Loss 1.6706159 Test MSE 0.003183587198842107 Test RE 0.0006286555112122969\n",
      "115 Train Loss 1.6395956 Test MSE 0.003471854903301113 Test RE 0.0006565006126554234\n",
      "116 Train Loss 1.5275881 Test MSE 0.005240369418074232 Test RE 0.0008065574445497461\n",
      "117 Train Loss 1.4186742 Test MSE 0.013523280572497912 Test RE 0.0012956729190643063\n",
      "118 Train Loss 1.3598301 Test MSE 0.012699151221561952 Test RE 0.00125557222446444\n",
      "119 Train Loss 1.3373183 Test MSE 0.016063403377553902 Test RE 0.0014121249780393835\n",
      "120 Train Loss 1.3021301 Test MSE 0.006783085231182181 Test RE 0.0009176308154426306\n",
      "121 Train Loss 1.2587593 Test MSE 0.014162023243490342 Test RE 0.0013259190299556593\n",
      "122 Train Loss 1.2145463 Test MSE 0.009142837524102445 Test RE 0.0010653562385540168\n",
      "123 Train Loss 1.1806871 Test MSE 0.004441439481051183 Test RE 0.0007425337988137312\n",
      "124 Train Loss 1.1616367 Test MSE 0.006449216266919008 Test RE 0.0008947625997975857\n",
      "125 Train Loss 1.1447777 Test MSE 0.004876314689105206 Test RE 0.0007780369356742465\n",
      "126 Train Loss 1.1036042 Test MSE 0.007942470953812602 Test RE 0.0009929609513005453\n",
      "127 Train Loss 1.0806786 Test MSE 0.007684462503296423 Test RE 0.0009766998032611145\n",
      "128 Train Loss 1.048715 Test MSE 0.0038249775844472807 Test RE 0.0006890786584807009\n",
      "129 Train Loss 1.0105113 Test MSE 0.00817451653385918 Test RE 0.001007361597301865\n",
      "130 Train Loss 0.97165644 Test MSE 0.008061436219690682 Test RE 0.0010003697794625324\n",
      "131 Train Loss 0.94049513 Test MSE 0.0029433988598097072 Test RE 0.0006044757892864234\n",
      "132 Train Loss 0.9159705 Test MSE 0.0033252765316953005 Test RE 0.000642492756833517\n",
      "133 Train Loss 0.8906789 Test MSE 0.005093490455846282 Test RE 0.0007951738705882246\n",
      "134 Train Loss 0.86014175 Test MSE 0.007590113112702437 Test RE 0.0009706853528457716\n",
      "135 Train Loss 0.84112144 Test MSE 0.003555246753995428 Test RE 0.0006643382018106489\n",
      "136 Train Loss 0.7971157 Test MSE 0.0016165369191540016 Test RE 0.00044796817981338714\n",
      "137 Train Loss 0.7483706 Test MSE 0.010708188389942818 Test RE 0.0011529549917139563\n",
      "138 Train Loss 0.7200597 Test MSE 0.008474605015316541 Test RE 0.0010256851911551858\n",
      "139 Train Loss 0.70589745 Test MSE 0.006205255883061994 Test RE 0.0008776759536877354\n",
      "140 Train Loss 0.68815905 Test MSE 0.010208852685803333 Test RE 0.001125752242719402\n",
      "141 Train Loss 0.665427 Test MSE 0.006869056438084518 Test RE 0.0009234276931405981\n",
      "142 Train Loss 0.6493443 Test MSE 0.009111386284943335 Test RE 0.0010635222543481583\n",
      "143 Train Loss 0.6260317 Test MSE 0.0175591657756369 Test RE 0.0014764076671111024\n",
      "144 Train Loss 0.6117971 Test MSE 0.007346537855655778 Test RE 0.0009549831586067061\n",
      "145 Train Loss 0.59580123 Test MSE 0.00282977349053282 Test RE 0.000592693533884673\n",
      "146 Train Loss 0.57122684 Test MSE 0.0031208914380681766 Test RE 0.0006224345382847744\n",
      "147 Train Loss 0.5597218 Test MSE 0.003317664111349592 Test RE 0.0006417569191904043\n",
      "148 Train Loss 0.55028844 Test MSE 0.001921416359501222 Test RE 0.0004883881235659203\n",
      "149 Train Loss 0.54009193 Test MSE 0.0011508174109807463 Test RE 0.0003779702033046548\n",
      "150 Train Loss 0.52183557 Test MSE 0.004724804445000576 Test RE 0.0007658545051564343\n",
      "151 Train Loss 0.50327027 Test MSE 0.008556928619420827 Test RE 0.0010306549820956444\n",
      "152 Train Loss 0.4766155 Test MSE 0.008180253198535593 Test RE 0.0010077150054914096\n",
      "153 Train Loss 0.46052194 Test MSE 0.005362609910168873 Test RE 0.0008159103749510426\n",
      "154 Train Loss 0.43163222 Test MSE 0.0009056590063436676 Test RE 0.00033530243514094503\n",
      "155 Train Loss 0.41255742 Test MSE 0.00038006270611554464 Test RE 0.000217211082761982\n",
      "156 Train Loss 0.4013421 Test MSE 0.001501944014064782 Test RE 0.00043179859465331\n",
      "157 Train Loss 0.39297804 Test MSE 0.000904450692818277 Test RE 0.00033507868332545475\n",
      "158 Train Loss 0.38912556 Test MSE 0.0011720597737652455 Test RE 0.00038144263404297184\n",
      "159 Train Loss 0.38480237 Test MSE 0.0015425027498314132 Test RE 0.0004375899365856832\n",
      "160 Train Loss 0.377287 Test MSE 0.0013318569594804612 Test RE 0.00040661476486937017\n",
      "161 Train Loss 0.36357376 Test MSE 0.0023405310545046307 Test RE 0.0005390282865690463\n",
      "162 Train Loss 0.34931967 Test MSE 0.004638766018913928 Test RE 0.0007588493839545153\n",
      "163 Train Loss 0.33826074 Test MSE 0.0015436417401526032 Test RE 0.0004377514658696036\n",
      "164 Train Loss 0.33091062 Test MSE 0.0008639152827104342 Test RE 0.0003274838826410681\n",
      "165 Train Loss 0.32479778 Test MSE 0.0012111819543437893 Test RE 0.000387756465591342\n",
      "166 Train Loss 0.31601846 Test MSE 0.0010402559642948572 Test RE 0.0003593556352036769\n",
      "167 Train Loss 0.3094018 Test MSE 0.0007085491140847562 Test RE 0.00029657827307690666\n",
      "168 Train Loss 0.30263257 Test MSE 0.00036651168713314354 Test RE 0.0002133036397704109\n",
      "169 Train Loss 0.29563272 Test MSE 0.0005231485334638961 Test RE 0.00025483956697334135\n",
      "170 Train Loss 0.28478462 Test MSE 0.0029695814025357133 Test RE 0.0006071583466964774\n",
      "171 Train Loss 0.28093442 Test MSE 0.00144300598343972 Test RE 0.00042324166899780256\n",
      "172 Train Loss 0.27564138 Test MSE 0.0007199494479188542 Test RE 0.00029895467818535904\n",
      "173 Train Loss 0.2708508 Test MSE 0.0005297904053642544 Test RE 0.000256452180938831\n",
      "174 Train Loss 0.26397952 Test MSE 0.0012149546987798453 Test RE 0.00038835991274558177\n",
      "175 Train Loss 0.2569443 Test MSE 0.0024817541176680408 Test RE 0.0005550520716229187\n",
      "176 Train Loss 0.25175074 Test MSE 0.003771774569297098 Test RE 0.0006842695532088021\n",
      "177 Train Loss 0.24907875 Test MSE 0.003970980146551784 Test RE 0.0007021068500700144\n",
      "178 Train Loss 0.24443558 Test MSE 0.003385887815961733 Test RE 0.0006483218142302919\n",
      "179 Train Loss 0.23989372 Test MSE 0.0019796063535486973 Test RE 0.0004957283677552255\n",
      "180 Train Loss 0.2363261 Test MSE 0.0012357177197575425 Test RE 0.0003916643017066612\n",
      "181 Train Loss 0.23354484 Test MSE 0.0010342320152902443 Test RE 0.00035831364019736666\n",
      "182 Train Loss 0.23132104 Test MSE 0.0008057231702714275 Test RE 0.00031626219353151166\n",
      "183 Train Loss 0.22962512 Test MSE 0.0005197477311782183 Test RE 0.0002540099058127994\n",
      "184 Train Loss 0.22814639 Test MSE 0.0003460468979748523 Test RE 0.00020726302510316552\n",
      "185 Train Loss 0.22650611 Test MSE 0.00017902483909184376 Test RE 0.00014907712147179685\n",
      "186 Train Loss 0.22520007 Test MSE 0.00017422474961796043 Test RE 0.00014706498293306957\n",
      "187 Train Loss 0.22388752 Test MSE 0.0001489739752866573 Test RE 0.00013599080849517104\n",
      "188 Train Loss 0.22219509 Test MSE 0.00018161590475245903 Test RE 0.00015015205888897423\n",
      "189 Train Loss 0.21987434 Test MSE 0.0006425126238843153 Test RE 0.0002824198284149542\n",
      "190 Train Loss 0.21801539 Test MSE 0.0009577589232190712 Test RE 0.00034481206689152027\n",
      "191 Train Loss 0.21672012 Test MSE 0.001499217394921282 Test RE 0.00043140647446529605\n",
      "192 Train Loss 0.21485354 Test MSE 0.0018813057156588115 Test RE 0.00048326354996659776\n",
      "193 Train Loss 0.21207684 Test MSE 0.001930887872990419 Test RE 0.0004895903846117796\n",
      "194 Train Loss 0.20928691 Test MSE 0.0020043306094157274 Test RE 0.0004988144567492133\n",
      "195 Train Loss 0.20595701 Test MSE 0.0017608857619916378 Test RE 0.0004675412604171903\n",
      "196 Train Loss 0.20355791 Test MSE 0.0018738651034334343 Test RE 0.000482306943328092\n",
      "197 Train Loss 0.20163524 Test MSE 0.001794057787029589 Test RE 0.0004719245454415046\n",
      "198 Train Loss 0.19895443 Test MSE 0.0025717757636843108 Test RE 0.0005650292127121531\n",
      "199 Train Loss 0.19667251 Test MSE 0.0034269864550207346 Test RE 0.0006522446812274286\n",
      "Training time: 30.02\n",
      "Training time: 30.02\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 13538.988 Test MSE 6899.421738015765 Test RE 0.9254664912561114\n",
      "1 Train Loss 10926.94 Test MSE 5722.761635537416 Test RE 0.8428633712284052\n",
      "2 Train Loss 9923.614 Test MSE 4613.255528988294 Test RE 0.7567598941868846\n",
      "3 Train Loss 9546.612 Test MSE 3707.0954502992845 Test RE 0.6783771898820267\n",
      "4 Train Loss 9451.101 Test MSE 3477.624317754576 Test RE 0.6570458618086193\n",
      "5 Train Loss 9267.33 Test MSE 3363.701152780527 Test RE 0.6461941981290955\n",
      "6 Train Loss 9047.913 Test MSE 3106.1112761389645 Test RE 0.620958902002241\n",
      "7 Train Loss 8987.542 Test MSE 2940.690280225773 Test RE 0.6041975993950282\n",
      "8 Train Loss 8929.984 Test MSE 2877.7722732484963 Test RE 0.5976990482978107\n",
      "9 Train Loss 8886.388 Test MSE 2974.903307530513 Test RE 0.6077021594747604\n",
      "10 Train Loss 8817.566 Test MSE 3207.347966091541 Test RE 0.630997141674656\n",
      "11 Train Loss 8647.961 Test MSE 3170.354269976329 Test RE 0.627347612949367\n",
      "12 Train Loss 8251.232 Test MSE 2920.1984016228334 Test RE 0.6020887767515499\n",
      "13 Train Loss 7984.08 Test MSE 2738.0966584603148 Test RE 0.5830136728611276\n",
      "14 Train Loss 7882.8022 Test MSE 2668.6750637312853 Test RE 0.5755753697175391\n",
      "15 Train Loss 7795.385 Test MSE 2772.7900767319434 Test RE 0.5866956225985369\n",
      "16 Train Loss 7775.6646 Test MSE 2805.8620423086736 Test RE 0.5901841057494585\n",
      "17 Train Loss 7765.832 Test MSE 2873.2583098874643 Test RE 0.5972301004154191\n",
      "18 Train Loss 7752.7964 Test MSE 3003.0941593035245 Test RE 0.610574731300022\n",
      "19 Train Loss 7743.9287 Test MSE 3014.8305956202744 Test RE 0.6117666659112877\n",
      "20 Train Loss 7733.735 Test MSE 2973.699332722843 Test RE 0.6075791752871491\n",
      "21 Train Loss 7719.7046 Test MSE 2971.789791245165 Test RE 0.6073840674736991\n",
      "22 Train Loss 7714.8975 Test MSE 3001.6609290508572 Test RE 0.6104290151544662\n",
      "23 Train Loss 7705.0312 Test MSE 3021.488879098447 Test RE 0.6124418397304039\n",
      "24 Train Loss 7695.6377 Test MSE 2992.128611193224 Test RE 0.6094589804710875\n",
      "25 Train Loss 7687.0176 Test MSE 2931.923471749753 Test RE 0.603296307894683\n",
      "26 Train Loss 7676.9604 Test MSE 2885.347804027025 Test RE 0.5984852313566558\n",
      "27 Train Loss 7666.338 Test MSE 2836.9687200548897 Test RE 0.593446572706184\n",
      "28 Train Loss 7633.9927 Test MSE 2930.0302606952637 Test RE 0.6031014952246432\n",
      "29 Train Loss 7621.057 Test MSE 2983.67253877563 Test RE 0.6085971733306843\n",
      "30 Train Loss 7609.8647 Test MSE 2974.4799158873498 Test RE 0.6076589135026108\n",
      "31 Train Loss 7593.7534 Test MSE 3005.599025697607 Test RE 0.610829316947248\n",
      "32 Train Loss 7585.6587 Test MSE 3023.2875386881333 Test RE 0.612624102605129\n",
      "33 Train Loss 7571.3975 Test MSE 2951.6466241083945 Test RE 0.6053221044494542\n",
      "34 Train Loss 7544.111 Test MSE 2952.168951835672 Test RE 0.6053756614250722\n",
      "35 Train Loss 7529.4634 Test MSE 2974.4224707526373 Test RE 0.6076530457177087\n",
      "36 Train Loss 7507.4966 Test MSE 2986.241007935088 Test RE 0.6088590698333548\n",
      "37 Train Loss 7483.8867 Test MSE 2993.4284485888065 Test RE 0.6095913463649194\n",
      "38 Train Loss 7456.398 Test MSE 2963.848804358252 Test RE 0.6065720222701211\n",
      "39 Train Loss 7434.5977 Test MSE 2987.032175354974 Test RE 0.608939719311506\n",
      "40 Train Loss 7423.884 Test MSE 3003.299835914518 Test RE 0.6105956395341133\n",
      "41 Train Loss 7409.8423 Test MSE 2967.221016342562 Test RE 0.6069169973479069\n",
      "42 Train Loss 7396.234 Test MSE 2967.741216723754 Test RE 0.6069701960505395\n",
      "43 Train Loss 7380.676 Test MSE 3013.0700806483733 Test RE 0.611588018783544\n",
      "44 Train Loss 7372.463 Test MSE 3009.7708563415044 Test RE 0.6112530915075816\n",
      "45 Train Loss 7366.022 Test MSE 2968.574685616919 Test RE 0.6070554216862302\n",
      "46 Train Loss 7360.203 Test MSE 2966.0717937897152 Test RE 0.6067994546631678\n",
      "47 Train Loss 7351.217 Test MSE 2975.4485379418975 Test RE 0.6077578457414945\n",
      "48 Train Loss 7341.194 Test MSE 2972.1627487706546 Test RE 0.6074221794142962\n",
      "49 Train Loss 7335.9165 Test MSE 3010.464610687031 Test RE 0.6113235345869721\n",
      "50 Train Loss 7300.2114 Test MSE 3009.9424127963575 Test RE 0.6112705119233094\n",
      "51 Train Loss 6782.066 Test MSE 2884.183758173822 Test RE 0.5983644946937504\n",
      "52 Train Loss 6506.633 Test MSE 2912.9600348212994 Test RE 0.6013421077204976\n",
      "53 Train Loss 6433.268 Test MSE 2851.274129625707 Test RE 0.5949409178943248\n",
      "54 Train Loss 6167.933 Test MSE 2467.1567565220853 Test RE 0.5534172914442771\n",
      "55 Train Loss 6070.0854 Test MSE 2369.5655772348937 Test RE 0.5423613317464347\n",
      "56 Train Loss 5882.8696 Test MSE 2349.9449136183684 Test RE 0.5401112126418975\n",
      "57 Train Loss 5751.037 Test MSE 2376.602237712427 Test RE 0.543166032717636\n",
      "58 Train Loss 5643.483 Test MSE 2276.990914136886 Test RE 0.5316612416227295\n",
      "59 Train Loss 5543.1816 Test MSE 2198.175194333452 Test RE 0.5223787522409945\n",
      "60 Train Loss 5518.016 Test MSE 2199.5529686057953 Test RE 0.5225424351143496\n",
      "61 Train Loss 5434.2666 Test MSE 1959.0410551629293 Test RE 0.4931466884250617\n",
      "62 Train Loss 4706.8335 Test MSE 1918.561438629024 Test RE 0.4880251549264626\n",
      "63 Train Loss 3874.1597 Test MSE 1906.5369414961067 Test RE 0.4864934133194121\n",
      "64 Train Loss 3141.1182 Test MSE 2318.7176808490135 Test RE 0.5365105781325584\n",
      "65 Train Loss 2782.8303 Test MSE 2430.9486847053263 Test RE 0.5493412963356723\n",
      "66 Train Loss 2568.8333 Test MSE 2328.0565222902683 Test RE 0.5375899144508931\n",
      "67 Train Loss 2354.73 Test MSE 2164.8561237069316 Test RE 0.5184046298823349\n",
      "68 Train Loss 2248.6743 Test MSE 2306.034357441917 Test RE 0.5350412168127201\n",
      "69 Train Loss 2124.6658 Test MSE 2179.8625542143495 Test RE 0.5201982752204284\n",
      "70 Train Loss 2082.6826 Test MSE 2053.2010190498067 Test RE 0.5048589827848673\n",
      "71 Train Loss 2019.334 Test MSE 1996.6971801742577 Test RE 0.4978636911657177\n",
      "72 Train Loss 1954.9519 Test MSE 1823.9176704819843 Test RE 0.4758356403277047\n",
      "73 Train Loss 1921.7318 Test MSE 1782.4803572547737 Test RE 0.47039936703418644\n",
      "74 Train Loss 1868.4623 Test MSE 1685.7359628025524 Test RE 0.45745578949761295\n",
      "75 Train Loss 1834.7529 Test MSE 1592.9549604408219 Test RE 0.4446887071174928\n",
      "76 Train Loss 1782.749 Test MSE 1459.8237927776079 Test RE 0.42570090278363615\n",
      "77 Train Loss 1734.7213 Test MSE 1379.152188069065 Test RE 0.413771380883781\n",
      "78 Train Loss 1689.508 Test MSE 1292.4397023648003 Test RE 0.4005525470176269\n",
      "79 Train Loss 1624.5486 Test MSE 1257.6080531578045 Test RE 0.39511817500679675\n",
      "80 Train Loss 1585.0906 Test MSE 1209.8577999919385 Test RE 0.3875444454974239\n",
      "81 Train Loss 1526.1272 Test MSE 1082.737223920293 Test RE 0.36661977476995083\n",
      "82 Train Loss 1475.798 Test MSE 839.1074550316534 Test RE 0.32274768967839057\n",
      "83 Train Loss 1420.6089 Test MSE 783.6715249104415 Test RE 0.31190431696472093\n",
      "84 Train Loss 1371.0308 Test MSE 688.8443880297104 Test RE 0.29242528015008606\n",
      "85 Train Loss 1314.8995 Test MSE 523.5593016236664 Test RE 0.2549395953907547\n",
      "86 Train Loss 1247.4648 Test MSE 537.1458209873905 Test RE 0.25822628839809314\n",
      "87 Train Loss 1178.4662 Test MSE 390.87174559812024 Test RE 0.22027818606176122\n",
      "88 Train Loss 1090.1514 Test MSE 262.544040199284 Test RE 0.18053251586385513\n",
      "89 Train Loss 1004.8547 Test MSE 169.449450046055 Test RE 0.14503553930263857\n",
      "90 Train Loss 915.68414 Test MSE 111.42207799796144 Test RE 0.11760884345000919\n",
      "91 Train Loss 828.01196 Test MSE 124.17398284937265 Test RE 0.12415655624379693\n",
      "92 Train Loss 767.7985 Test MSE 155.5335577940837 Test RE 0.1389525130196456\n",
      "93 Train Loss 642.4474 Test MSE 106.36156273907453 Test RE 0.11490705846689027\n",
      "94 Train Loss 534.533 Test MSE 121.45236062765163 Test RE 0.12278839781451047\n",
      "95 Train Loss 472.9528 Test MSE 110.0029623778688 Test RE 0.11685748703546468\n",
      "96 Train Loss 442.83325 Test MSE 82.3366730199546 Test RE 0.10109996601073107\n",
      "97 Train Loss 420.06458 Test MSE 81.93151223321581 Test RE 0.10085091382308245\n",
      "98 Train Loss 382.0553 Test MSE 76.1851498199495 Test RE 0.09724997879860194\n",
      "99 Train Loss 360.49908 Test MSE 58.34874997485554 Test RE 0.08510795015777077\n",
      "100 Train Loss 337.14523 Test MSE 53.26983502546111 Test RE 0.08131956152311665\n",
      "101 Train Loss 322.29633 Test MSE 58.65925478608566 Test RE 0.0853341020801858\n",
      "102 Train Loss 309.66513 Test MSE 36.573467524845604 Test RE 0.0673809952125384\n",
      "103 Train Loss 299.24866 Test MSE 25.342039097351865 Test RE 0.0560886685417018\n",
      "104 Train Loss 284.2999 Test MSE 19.9120883897498 Test RE 0.049717897890809354\n",
      "105 Train Loss 270.17535 Test MSE 12.113537023037209 Test RE 0.03877839569277882\n",
      "106 Train Loss 255.24698 Test MSE 6.741923598834989 Test RE 0.02892985558441609\n",
      "107 Train Loss 246.80368 Test MSE 8.858728272612998 Test RE 0.03316194866302437\n",
      "108 Train Loss 241.6546 Test MSE 7.538900429032113 Test RE 0.030592034193998932\n",
      "109 Train Loss 233.3134 Test MSE 8.313587838454213 Test RE 0.03212540394716874\n",
      "110 Train Loss 230.16234 Test MSE 12.200360845565687 Test RE 0.03891711970943657\n",
      "111 Train Loss 226.64314 Test MSE 11.12817750721253 Test RE 0.037167758843124565\n",
      "112 Train Loss 223.14342 Test MSE 9.231532621053228 Test RE 0.033852539747876054\n",
      "113 Train Loss 216.48181 Test MSE 10.18818372028055 Test RE 0.035563355923572404\n",
      "114 Train Loss 211.96124 Test MSE 9.437390975286934 Test RE 0.03422790564449299\n",
      "115 Train Loss 209.91583 Test MSE 7.798582507766267 Test RE 0.03111445426162244\n",
      "116 Train Loss 207.20036 Test MSE 8.518971791867793 Test RE 0.03251980572650276\n",
      "117 Train Loss 202.33623 Test MSE 9.900479911794127 Test RE 0.03505762375666615\n",
      "118 Train Loss 200.71117 Test MSE 10.256394404376163 Test RE 0.03568220704593776\n",
      "119 Train Loss 193.81386 Test MSE 11.541425428992891 Test RE 0.03785158564401158\n",
      "120 Train Loss 186.6233 Test MSE 12.088844351083667 Test RE 0.038738851888518624\n",
      "121 Train Loss 180.98976 Test MSE 10.546819183015899 Test RE 0.03618387734371702\n",
      "122 Train Loss 176.34854 Test MSE 7.900427165594026 Test RE 0.03131696299816941\n",
      "123 Train Loss 167.19362 Test MSE 6.8926715424117475 Test RE 0.029251500183994306\n",
      "124 Train Loss 155.69035 Test MSE 8.607098748114547 Test RE 0.03268757819648233\n",
      "125 Train Loss 149.27415 Test MSE 8.918227038852864 Test RE 0.03327312675914517\n",
      "126 Train Loss 142.1891 Test MSE 9.652466699458675 Test RE 0.03461573108485947\n",
      "127 Train Loss 136.95074 Test MSE 10.4959100108519 Test RE 0.036096442472598474\n",
      "128 Train Loss 131.66489 Test MSE 8.95985967689752 Test RE 0.0333507002007959\n",
      "129 Train Loss 121.548615 Test MSE 3.5480109708984275 Test RE 0.020986829263883518\n",
      "130 Train Loss 116.3663 Test MSE 2.909137396497864 Test RE 0.019003625746525026\n",
      "131 Train Loss 113.51476 Test MSE 2.7589093138283602 Test RE 0.018506447733608197\n",
      "132 Train Loss 105.403244 Test MSE 2.238479921885145 Test RE 0.016669821675411003\n",
      "133 Train Loss 96.96525 Test MSE 2.7316616523630968 Test RE 0.018414833875741558\n",
      "134 Train Loss 91.81576 Test MSE 2.860773929932776 Test RE 0.01884499914433618\n",
      "135 Train Loss 88.82046 Test MSE 2.0490853063334327 Test RE 0.015949033559876084\n",
      "136 Train Loss 83.774605 Test MSE 1.9596096482113887 Test RE 0.015596930497766209\n",
      "137 Train Loss 80.760345 Test MSE 2.9706628475485064 Test RE 0.019203528519740446\n",
      "138 Train Loss 78.6564 Test MSE 3.056463062104642 Test RE 0.01947887757998631\n",
      "139 Train Loss 76.62979 Test MSE 3.7090478532853193 Test RE 0.02145781865345123\n",
      "140 Train Loss 74.38963 Test MSE 3.826120260267843 Test RE 0.021793835099820778\n",
      "141 Train Loss 72.64182 Test MSE 3.681343304090784 Test RE 0.021377529386545465\n",
      "142 Train Loss 70.43446 Test MSE 2.666867135495 Test RE 0.01819512494003158\n",
      "143 Train Loss 69.753204 Test MSE 2.2034344750274752 Test RE 0.016538816261558738\n",
      "144 Train Loss 69.12701 Test MSE 1.9654543118040413 Test RE 0.015620172611653932\n",
      "145 Train Loss 68.25802 Test MSE 1.9272156401941545 Test RE 0.015467478039815415\n",
      "146 Train Loss 66.4768 Test MSE 1.1612667662532745 Test RE 0.012006608533658859\n",
      "147 Train Loss 65.00213 Test MSE 1.0420691062667646 Test RE 0.011373722100674674\n",
      "148 Train Loss 64.21786 Test MSE 1.29559430807883 Test RE 0.012682032681621451\n",
      "149 Train Loss 62.754498 Test MSE 0.9675002772283334 Test RE 0.01095922646476629\n",
      "150 Train Loss 61.583897 Test MSE 1.1142557711097638 Test RE 0.011761069013700031\n",
      "151 Train Loss 60.766674 Test MSE 1.3546979055769073 Test RE 0.012968077044579918\n",
      "152 Train Loss 59.411236 Test MSE 1.7453954545089858 Test RE 0.014719778424483371\n",
      "153 Train Loss 58.956894 Test MSE 1.7635472783086066 Test RE 0.014796122077021075\n",
      "154 Train Loss 57.737427 Test MSE 1.3106262778409608 Test RE 0.012755391354932888\n",
      "155 Train Loss 57.05285 Test MSE 0.9107959503911396 Test RE 0.010633222408426533\n",
      "156 Train Loss 56.188545 Test MSE 0.8266548530836187 Test RE 0.010130163670677967\n",
      "157 Train Loss 55.463703 Test MSE 1.346181925188148 Test RE 0.012927252446666954\n",
      "158 Train Loss 54.56762 Test MSE 1.6083942273133125 Test RE 0.014130274711674556\n",
      "159 Train Loss 53.44266 Test MSE 1.6452514049545768 Test RE 0.014291258918333166\n",
      "160 Train Loss 51.712673 Test MSE 1.7457808642377135 Test RE 0.014721403509689797\n",
      "161 Train Loss 49.21842 Test MSE 2.008055058079304 Test RE 0.015788546864312757\n",
      "162 Train Loss 47.82795 Test MSE 2.4782061427677315 Test RE 0.01753973659118386\n",
      "163 Train Loss 46.53332 Test MSE 2.3157430398777974 Test RE 0.016955068006342652\n",
      "164 Train Loss 45.200752 Test MSE 1.704828702759658 Test RE 0.014547713068117014\n",
      "165 Train Loss 44.059692 Test MSE 1.549808813832005 Test RE 0.013870541483483802\n",
      "166 Train Loss 42.984085 Test MSE 0.9277500548352323 Test RE 0.010731732693186747\n",
      "167 Train Loss 41.919865 Test MSE 0.6715847700162981 Test RE 0.00913071467468851\n",
      "168 Train Loss 41.308548 Test MSE 0.47784370514893 Test RE 0.00770188956223934\n",
      "169 Train Loss 40.253994 Test MSE 0.6057072509148917 Test RE 0.008671330487617495\n",
      "170 Train Loss 39.68903 Test MSE 0.9279628693427707 Test RE 0.010732963486673843\n",
      "171 Train Loss 39.311718 Test MSE 0.9245753940499595 Test RE 0.010713355541727755\n",
      "172 Train Loss 38.91948 Test MSE 0.809725873106573 Test RE 0.010025899815642881\n",
      "173 Train Loss 37.884975 Test MSE 0.8089055841423574 Test RE 0.01002082018365923\n",
      "174 Train Loss 36.736626 Test MSE 0.6314206697576227 Test RE 0.008853474680797951\n",
      "175 Train Loss 35.59902 Test MSE 0.6005151871832385 Test RE 0.00863408559953589\n",
      "176 Train Loss 34.819244 Test MSE 0.48736137698306076 Test RE 0.007778214341986175\n",
      "177 Train Loss 34.39622 Test MSE 0.3726129657929084 Test RE 0.006801165354314677\n",
      "178 Train Loss 33.669518 Test MSE 0.3029762337631719 Test RE 0.00613279762436373\n",
      "179 Train Loss 33.215946 Test MSE 0.3903026026472452 Test RE 0.006960734612288172\n",
      "180 Train Loss 32.757977 Test MSE 0.3305809923063515 Test RE 0.006406093776111669\n",
      "181 Train Loss 32.36332 Test MSE 0.20607068051978075 Test RE 0.0050578093506634956\n",
      "182 Train Loss 31.881409 Test MSE 0.2118984246107791 Test RE 0.005128828961968078\n",
      "183 Train Loss 31.35166 Test MSE 0.2935590248698605 Test RE 0.006036734428706731\n",
      "184 Train Loss 30.922049 Test MSE 0.23932565244782517 Test RE 0.005450658563905846\n",
      "185 Train Loss 30.603611 Test MSE 0.21497973803338863 Test RE 0.005165984716884449\n",
      "186 Train Loss 30.287167 Test MSE 0.2246110640416785 Test RE 0.005280437723008354\n",
      "187 Train Loss 29.700312 Test MSE 0.3725685673718415 Test RE 0.006800760148341739\n",
      "188 Train Loss 29.525932 Test MSE 0.38285013284694985 Test RE 0.006893959907761044\n",
      "189 Train Loss 29.275194 Test MSE 0.4715725744064357 Test RE 0.007651183575197599\n",
      "190 Train Loss 28.846605 Test MSE 0.5414046896198909 Test RE 0.008198140537680055\n",
      "191 Train Loss 28.636389 Test MSE 0.5620157044267693 Test RE 0.008352732592693651\n",
      "192 Train Loss 28.549774 Test MSE 0.5502609372629019 Test RE 0.00826492076014503\n",
      "193 Train Loss 28.449104 Test MSE 0.5490577743559466 Test RE 0.008255880060444878\n",
      "194 Train Loss 28.232805 Test MSE 0.5302684353460452 Test RE 0.00811338790736228\n",
      "195 Train Loss 28.064646 Test MSE 0.49829599509563316 Test RE 0.007864987752822175\n",
      "196 Train Loss 27.788107 Test MSE 0.4857029062755497 Test RE 0.007764968592058985\n",
      "197 Train Loss 27.44647 Test MSE 0.4283116902873252 Test RE 0.007291792748950429\n",
      "198 Train Loss 27.25298 Test MSE 0.3559683853046421 Test RE 0.0066475263369930844\n",
      "199 Train Loss 26.994076 Test MSE 0.24777824860742184 Test RE 0.005546077598752834\n",
      "Training time: 31.07\n",
      "Training time: 31.07\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 17868.855 Test MSE 9902.686606650823 Test RE 1.1087429461549003\n",
      "1 Train Loss 10858.095 Test MSE 5157.6196386357515 Test RE 0.8001639991645411\n",
      "2 Train Loss 9059.025 Test MSE 4502.481971020709 Test RE 0.7476190233707313\n",
      "3 Train Loss 8379.566 Test MSE 3892.3450948929803 Test RE 0.6951203793954994\n",
      "4 Train Loss 8055.258 Test MSE 3672.2724408080167 Test RE 0.6751834666055153\n",
      "5 Train Loss 7830.4346 Test MSE 3554.369974889347 Test RE 0.6642562786965197\n",
      "6 Train Loss 7616.3813 Test MSE 3623.682638378212 Test RE 0.6707017352561999\n",
      "7 Train Loss 7315.793 Test MSE 3455.7054426044197 Test RE 0.6549719645774437\n",
      "8 Train Loss 6691.8936 Test MSE 3503.8369123386838 Test RE 0.6595174548570863\n",
      "9 Train Loss 5371.195 Test MSE 3284.33830307994 Test RE 0.6385255722476357\n",
      "10 Train Loss 4734.0796 Test MSE 2596.4022572629888 Test RE 0.5677280359091328\n",
      "11 Train Loss 4440.3726 Test MSE 2377.4956984882106 Test RE 0.5432681221491582\n",
      "12 Train Loss 4273.4077 Test MSE 2273.0136506826057 Test RE 0.531196707266281\n",
      "13 Train Loss 4129.423 Test MSE 2201.178155749087 Test RE 0.5227354453417872\n",
      "14 Train Loss 3996.448 Test MSE 2131.5802384808935 Test RE 0.514405016278183\n",
      "15 Train Loss 3806.8289 Test MSE 1988.5851521691359 Test RE 0.4968513206837204\n",
      "16 Train Loss 3736.1914 Test MSE 1916.88494715714 Test RE 0.487811883459938\n",
      "17 Train Loss 3656.0361 Test MSE 1855.5991536922406 Test RE 0.4799504853992002\n",
      "18 Train Loss 3572.1726 Test MSE 1723.3690672505059 Test RE 0.4625338260805097\n",
      "19 Train Loss 3444.362 Test MSE 1565.0032046974861 Test RE 0.4407699394691396\n",
      "20 Train Loss 3353.9734 Test MSE 1560.128284327107 Test RE 0.44008291395585003\n",
      "21 Train Loss 3302.7124 Test MSE 1501.7923927783945 Test RE 0.43177679906367816\n",
      "22 Train Loss 3254.4668 Test MSE 1453.9602341928187 Test RE 0.4248451030165751\n",
      "23 Train Loss 3156.823 Test MSE 1362.2769451516688 Test RE 0.41123214566592536\n",
      "24 Train Loss 3064.549 Test MSE 1300.9465710217933 Test RE 0.40186860814716396\n",
      "25 Train Loss 3002.846 Test MSE 1284.0353543467704 Test RE 0.39924808634935127\n",
      "26 Train Loss 2905.5193 Test MSE 1195.8147888697579 Test RE 0.3852887359154873\n",
      "27 Train Loss 2810.4893 Test MSE 1123.2723549091997 Test RE 0.373419409286982\n",
      "28 Train Loss 2727.1477 Test MSE 1085.311271988385 Test RE 0.36705530829220356\n",
      "29 Train Loss 2651.7515 Test MSE 1032.0893562398073 Test RE 0.35794228154356833\n",
      "30 Train Loss 2532.4448 Test MSE 877.976255331701 Test RE 0.3301381685402765\n",
      "31 Train Loss 2454.2188 Test MSE 883.9182324524127 Test RE 0.331253441053456\n",
      "32 Train Loss 2407.6294 Test MSE 812.0282804018034 Test RE 0.3174972219668094\n",
      "33 Train Loss 2380.1904 Test MSE 757.3908546311067 Test RE 0.30662981482916823\n",
      "34 Train Loss 2360.554 Test MSE 735.9700178145815 Test RE 0.3022625998221683\n",
      "35 Train Loss 2327.868 Test MSE 711.2748127375778 Test RE 0.2971481750345502\n",
      "36 Train Loss 2310.0752 Test MSE 691.115662454635 Test RE 0.29290697927275605\n",
      "37 Train Loss 2288.908 Test MSE 679.7681792941446 Test RE 0.2904923954182125\n",
      "38 Train Loss 2266.0764 Test MSE 678.9024161486781 Test RE 0.2903073487019278\n",
      "39 Train Loss 2252.9182 Test MSE 667.1339105419453 Test RE 0.2877801672082332\n",
      "40 Train Loss 2235.7925 Test MSE 653.2380213866813 Test RE 0.2847672751899882\n",
      "41 Train Loss 2225.287 Test MSE 634.8607102279223 Test RE 0.280733071728015\n",
      "42 Train Loss 2203.5293 Test MSE 565.1829266094239 Test RE 0.2648798179890615\n",
      "43 Train Loss 2191.6897 Test MSE 535.8457633164144 Test RE 0.25791360566848975\n",
      "44 Train Loss 2168.3657 Test MSE 504.5526398899456 Test RE 0.2502693085589318\n",
      "45 Train Loss 2133.029 Test MSE 476.4035035645845 Test RE 0.24318782340862546\n",
      "46 Train Loss 2099.2437 Test MSE 468.9692728208635 Test RE 0.24128290138753727\n",
      "47 Train Loss 2066.4622 Test MSE 466.38045945670444 Test RE 0.24061601247180991\n",
      "48 Train Loss 2039.8662 Test MSE 491.44597457731095 Test RE 0.24699732134203709\n",
      "49 Train Loss 2005.6997 Test MSE 439.62462336663333 Test RE 0.23361211267276857\n",
      "50 Train Loss 1981.7682 Test MSE 392.87545221260734 Test RE 0.22084206495759143\n",
      "51 Train Loss 1950.658 Test MSE 386.90013604341164 Test RE 0.21915621618280037\n",
      "52 Train Loss 1919.5823 Test MSE 383.47636717580247 Test RE 0.21818437935810514\n",
      "53 Train Loss 1890.1626 Test MSE 361.84982006052627 Test RE 0.21194273426333848\n",
      "54 Train Loss 1867.2106 Test MSE 337.5354602489887 Test RE 0.20469821465474672\n",
      "55 Train Loss 1831.0319 Test MSE 342.92607033322486 Test RE 0.20632630646648145\n",
      "56 Train Loss 1793.5043 Test MSE 320.6583862657345 Test RE 0.19951504646628596\n",
      "57 Train Loss 1781.8402 Test MSE 316.5090600810593 Test RE 0.19821997884962503\n",
      "58 Train Loss 1763.0364 Test MSE 290.6843591326091 Test RE 0.18996132251876838\n",
      "59 Train Loss 1736.1033 Test MSE 277.6535725271481 Test RE 0.18565471583966683\n",
      "60 Train Loss 1712.5642 Test MSE 264.8995693884283 Test RE 0.1813405708419154\n",
      "61 Train Loss 1695.8881 Test MSE 250.2529970772858 Test RE 0.1762560349564315\n",
      "62 Train Loss 1669.0945 Test MSE 267.91094454014075 Test RE 0.18236839674402\n",
      "63 Train Loss 1649.9573 Test MSE 280.3447068644242 Test RE 0.18655226772799624\n",
      "64 Train Loss 1620.4858 Test MSE 258.16342869136435 Test RE 0.17902006584051788\n",
      "65 Train Loss 1554.7435 Test MSE 218.86589658896207 Test RE 0.1648327104834259\n",
      "66 Train Loss 1517.9403 Test MSE 221.37030122448922 Test RE 0.16577308908008587\n",
      "67 Train Loss 1492.3585 Test MSE 212.19822310235136 Test RE 0.1623025053585631\n",
      "68 Train Loss 1479.4194 Test MSE 208.25878195038834 Test RE 0.16078888158130278\n",
      "69 Train Loss 1466.7102 Test MSE 196.2778045345894 Test RE 0.15609534362770852\n",
      "70 Train Loss 1442.6913 Test MSE 178.28855894271513 Test RE 0.14877024893315688\n",
      "71 Train Loss 1422.244 Test MSE 172.6208236112978 Test RE 0.14638647213014663\n",
      "72 Train Loss 1371.3647 Test MSE 202.53866329306817 Test RE 0.15856536152208556\n",
      "73 Train Loss 1355.1345 Test MSE 211.31757617141145 Test RE 0.16196536821180993\n",
      "74 Train Loss 1341.8572 Test MSE 198.29702360094535 Test RE 0.1568962090193292\n",
      "75 Train Loss 1331.2125 Test MSE 199.26336820868448 Test RE 0.1572780391076126\n",
      "76 Train Loss 1317.7909 Test MSE 206.68338507767268 Test RE 0.16017957435234878\n",
      "77 Train Loss 1304.3804 Test MSE 201.24320243511676 Test RE 0.1580574467972799\n",
      "78 Train Loss 1291.6561 Test MSE 198.14672791844447 Test RE 0.15683673941094106\n",
      "79 Train Loss 1274.1016 Test MSE 201.83536642013766 Test RE 0.15828982030196\n",
      "80 Train Loss 1258.7043 Test MSE 210.342278943071 Test RE 0.16159117534239664\n",
      "81 Train Loss 1238.0548 Test MSE 216.57818751632362 Test RE 0.1639689855630484\n",
      "82 Train Loss 1228.7223 Test MSE 230.66261177085087 Test RE 0.16921659619976184\n",
      "83 Train Loss 1223.0803 Test MSE 231.29897555136088 Test RE 0.1694498571165977\n",
      "84 Train Loss 1218.0522 Test MSE 220.65777673453113 Test RE 0.1655060871731979\n",
      "85 Train Loss 1210.5292 Test MSE 217.69930658457582 Test RE 0.16439283127518267\n",
      "86 Train Loss 1201.1907 Test MSE 221.77326486821687 Test RE 0.16592390008720195\n",
      "87 Train Loss 1194.0735 Test MSE 222.06595318323403 Test RE 0.1660333541597745\n",
      "88 Train Loss 1187.9318 Test MSE 215.60123504407187 Test RE 0.16359874753366124\n",
      "89 Train Loss 1182.007 Test MSE 211.69891996731496 Test RE 0.16211144372880099\n",
      "90 Train Loss 1161.2792 Test MSE 241.09166614540376 Test RE 0.1729997404273943\n",
      "91 Train Loss 1132.1992 Test MSE 232.63584772911207 Test RE 0.16993884849759486\n",
      "92 Train Loss 1111.6841 Test MSE 217.68164454247727 Test RE 0.1643861625079609\n",
      "93 Train Loss 1087.3975 Test MSE 227.82931021643049 Test RE 0.1681741146358012\n",
      "94 Train Loss 1046.7524 Test MSE 211.80446994399188 Test RE 0.16215185188684203\n",
      "95 Train Loss 950.0943 Test MSE 148.3886243490839 Test RE 0.13572337690249034\n",
      "96 Train Loss 794.1035 Test MSE 121.93854274386976 Test RE 0.12303391753413567\n",
      "97 Train Loss 711.52704 Test MSE 103.12387625751224 Test RE 0.1131446352936475\n",
      "98 Train Loss 621.0893 Test MSE 61.07974073049363 Test RE 0.08707689706340938\n",
      "99 Train Loss 526.8356 Test MSE 29.270964120645274 Test RE 0.06027994758786003\n",
      "100 Train Loss 482.13126 Test MSE 27.045945213531375 Test RE 0.057943594686520966\n",
      "101 Train Loss 450.00616 Test MSE 33.624673196705274 Test RE 0.06460756725990331\n",
      "102 Train Loss 422.76144 Test MSE 49.997017781436604 Test RE 0.07878189128327405\n",
      "103 Train Loss 394.78116 Test MSE 58.81598467568139 Test RE 0.08544802683677129\n",
      "104 Train Loss 375.56964 Test MSE 52.58108440995026 Test RE 0.08079214183743491\n",
      "105 Train Loss 350.98557 Test MSE 57.717562252114945 Test RE 0.08464637076670552\n",
      "106 Train Loss 327.55988 Test MSE 64.18647002635747 Test RE 0.08926394950146264\n",
      "107 Train Loss 293.36276 Test MSE 69.51682263729967 Test RE 0.09289649093169806\n",
      "108 Train Loss 253.89027 Test MSE 53.65648297698871 Test RE 0.0816141484513353\n",
      "109 Train Loss 227.43512 Test MSE 42.42676728913339 Test RE 0.07257287419137787\n",
      "110 Train Loss 212.00655 Test MSE 38.55959933714456 Test RE 0.06918638012799261\n",
      "111 Train Loss 207.95807 Test MSE 36.049159738391246 Test RE 0.06689627345582759\n",
      "112 Train Loss 201.89706 Test MSE 32.77465997066706 Test RE 0.0637857181750173\n",
      "113 Train Loss 195.27419 Test MSE 32.446704379051106 Test RE 0.06346578385711055\n",
      "114 Train Loss 186.85234 Test MSE 29.79847585708486 Test RE 0.06082069491810185\n",
      "115 Train Loss 180.01852 Test MSE 26.684603470143042 Test RE 0.05755522143807561\n",
      "116 Train Loss 172.42928 Test MSE 24.618117497093422 Test RE 0.055281748702696046\n",
      "117 Train Loss 165.01434 Test MSE 25.871433175786976 Test RE 0.056671485424401646\n",
      "118 Train Loss 159.30634 Test MSE 23.89824119629674 Test RE 0.05446748498360639\n",
      "119 Train Loss 152.12674 Test MSE 21.363369527548965 Test RE 0.05149786550466955\n",
      "120 Train Loss 137.214 Test MSE 24.904189262981667 Test RE 0.05560201831192016\n",
      "121 Train Loss 121.9673 Test MSE 23.053039392504182 Test RE 0.053495647505949984\n",
      "122 Train Loss 110.765976 Test MSE 25.047425248285037 Test RE 0.055761686051067766\n",
      "123 Train Loss 102.453575 Test MSE 20.962273049054698 Test RE 0.05101213956319471\n",
      "124 Train Loss 97.75106 Test MSE 19.341974813309633 Test RE 0.04900097923626046\n",
      "125 Train Loss 93.43644 Test MSE 16.708565548058186 Test RE 0.04554324127137286\n",
      "126 Train Loss 88.66777 Test MSE 17.009309939193155 Test RE 0.04595128913531228\n",
      "127 Train Loss 85.514175 Test MSE 19.06712621023764 Test RE 0.04865158269853721\n",
      "128 Train Loss 83.32992 Test MSE 19.300289880384174 Test RE 0.048948148429926217\n",
      "129 Train Loss 81.02798 Test MSE 17.30280961143497 Test RE 0.04634604371223145\n",
      "130 Train Loss 79.22252 Test MSE 15.35005835673039 Test RE 0.04365252480488781\n",
      "131 Train Loss 77.82324 Test MSE 15.737664538792716 Test RE 0.044200226434633866\n",
      "132 Train Loss 77.11912 Test MSE 15.878837122936888 Test RE 0.04439802989933902\n",
      "133 Train Loss 75.33956 Test MSE 13.632915998543712 Test RE 0.041138526466459546\n",
      "134 Train Loss 73.93556 Test MSE 12.7419707463353 Test RE 0.039771562572875986\n",
      "135 Train Loss 72.81959 Test MSE 14.226858151363217 Test RE 0.04202510943698581\n",
      "136 Train Loss 71.76746 Test MSE 14.929200691501727 Test RE 0.043049947927367015\n",
      "137 Train Loss 69.565094 Test MSE 13.266600391094078 Test RE 0.04058206818601064\n",
      "138 Train Loss 68.54036 Test MSE 11.068688119173691 Test RE 0.037068279383069856\n",
      "139 Train Loss 67.02943 Test MSE 9.490166440992603 Test RE 0.03432347629999531\n",
      "140 Train Loss 66.32274 Test MSE 9.233658091948143 Test RE 0.03385643663313805\n",
      "141 Train Loss 65.95632 Test MSE 9.084390664425175 Test RE 0.033581667209842306\n",
      "142 Train Loss 65.290855 Test MSE 9.418298205975995 Test RE 0.034193264906951744\n",
      "143 Train Loss 64.55547 Test MSE 8.319140051356456 Test RE 0.03213612959986928\n",
      "144 Train Loss 63.960358 Test MSE 7.614285068354284 Test RE 0.030744605052345535\n",
      "145 Train Loss 62.866318 Test MSE 7.589507110770013 Test RE 0.030694540649362844\n",
      "146 Train Loss 61.935005 Test MSE 6.881625451346146 Test RE 0.029228051780035146\n",
      "147 Train Loss 61.435833 Test MSE 7.211921437195047 Test RE 0.029921257792253422\n",
      "148 Train Loss 60.414604 Test MSE 7.3230366274885235 Test RE 0.030150877452486406\n",
      "149 Train Loss 59.330555 Test MSE 6.467774183176812 Test RE 0.028335558466599232\n",
      "150 Train Loss 58.544415 Test MSE 7.154929318569285 Test RE 0.02980279711249706\n",
      "151 Train Loss 57.701202 Test MSE 8.267840137926767 Test RE 0.03203689277895806\n",
      "152 Train Loss 57.53914 Test MSE 8.20047802009106 Test RE 0.03190611577874998\n",
      "153 Train Loss 57.300507 Test MSE 8.239836903611401 Test RE 0.03198259216709934\n",
      "154 Train Loss 56.956036 Test MSE 7.6133680553840675 Test RE 0.030742753660504746\n",
      "155 Train Loss 56.676792 Test MSE 7.855232991836667 Test RE 0.03122726062150225\n",
      "156 Train Loss 56.41011 Test MSE 8.095099583479435 Test RE 0.031700451675420585\n",
      "157 Train Loss 56.116432 Test MSE 7.2380949018262735 Test RE 0.029975503649704274\n",
      "158 Train Loss 55.6632 Test MSE 7.272887738230016 Test RE 0.030047461982126402\n",
      "159 Train Loss 55.46958 Test MSE 7.1578775173765505 Test RE 0.02980893662259369\n",
      "160 Train Loss 55.18874 Test MSE 7.420614044459879 Test RE 0.030351088728555742\n",
      "161 Train Loss 54.928032 Test MSE 8.160264515734594 Test RE 0.03182778903031336\n",
      "162 Train Loss 54.628315 Test MSE 7.840174099538469 Test RE 0.031197314116814326\n",
      "163 Train Loss 54.34088 Test MSE 8.209994017040549 Test RE 0.03192462265539283\n",
      "164 Train Loss 54.21422 Test MSE 8.645008912542748 Test RE 0.032759485698960866\n",
      "165 Train Loss 54.08518 Test MSE 8.004874295985399 Test RE 0.031523295315435344\n",
      "166 Train Loss 53.729755 Test MSE 7.267260654727397 Test RE 0.030035835768380956\n",
      "167 Train Loss 53.576305 Test MSE 7.26827562607954 Test RE 0.03003793315073289\n",
      "168 Train Loss 53.338467 Test MSE 7.114588900478209 Test RE 0.02971866233932705\n",
      "169 Train Loss 52.728466 Test MSE 7.128790593479591 Test RE 0.029748308810455922\n",
      "170 Train Loss 51.909542 Test MSE 6.839106686139082 Test RE 0.02913761775173689\n",
      "171 Train Loss 51.353924 Test MSE 6.741651028056638 Test RE 0.02892927077261567\n",
      "172 Train Loss 51.026436 Test MSE 6.552532089397814 Test RE 0.028520617919841517\n",
      "173 Train Loss 50.426105 Test MSE 7.587208920129196 Test RE 0.030689892966315042\n",
      "174 Train Loss 49.66895 Test MSE 7.663588299260874 Test RE 0.030843981586662655\n",
      "175 Train Loss 48.852272 Test MSE 8.40916871199113 Test RE 0.0323095482087487\n",
      "176 Train Loss 48.502235 Test MSE 8.59623683929688 Test RE 0.03266694629771427\n",
      "177 Train Loss 48.087044 Test MSE 8.818526070928465 Test RE 0.033086616217197024\n",
      "178 Train Loss 47.511875 Test MSE 9.504650606020139 Test RE 0.03434965905204618\n",
      "179 Train Loss 47.05063 Test MSE 9.668240461371024 Test RE 0.0346440035165222\n",
      "180 Train Loss 46.789722 Test MSE 9.36757566586043 Test RE 0.034101066154739824\n",
      "181 Train Loss 46.577377 Test MSE 9.844683041055784 Test RE 0.03495869574737464\n",
      "182 Train Loss 46.464787 Test MSE 9.156887114750653 Test RE 0.033715397358108724\n",
      "183 Train Loss 46.32159 Test MSE 8.818893291072694 Test RE 0.03308730510473878\n",
      "184 Train Loss 46.0519 Test MSE 9.58556103058928 Test RE 0.034495553726159665\n",
      "185 Train Loss 45.7913 Test MSE 9.576298304826837 Test RE 0.03447888281452124\n",
      "186 Train Loss 45.67475 Test MSE 9.14077110529223 Test RE 0.03368571494845168\n",
      "187 Train Loss 45.527218 Test MSE 9.186959596589515 Test RE 0.03377071498814098\n",
      "188 Train Loss 45.364174 Test MSE 9.474110276621888 Test RE 0.03429442851261357\n",
      "189 Train Loss 45.162918 Test MSE 9.191092546441045 Test RE 0.033778310372452984\n",
      "190 Train Loss 45.026978 Test MSE 9.194905534538263 Test RE 0.033785316228367605\n",
      "191 Train Loss 44.9288 Test MSE 9.351239506067728 Test RE 0.03407131867409438\n",
      "192 Train Loss 44.889095 Test MSE 9.286998637773161 Test RE 0.03395408591844713\n",
      "193 Train Loss 44.82293 Test MSE 9.381882622207987 Test RE 0.03412709724007728\n",
      "194 Train Loss 44.74351 Test MSE 9.61732944996778 Test RE 0.03455266894009335\n",
      "195 Train Loss 44.583466 Test MSE 9.291941976236407 Test RE 0.03396312135690291\n",
      "196 Train Loss 44.411263 Test MSE 9.795943672669289 Test RE 0.03487205106482401\n",
      "197 Train Loss 44.27951 Test MSE 9.74113561600728 Test RE 0.03477436010744796\n",
      "198 Train Loss 44.198467 Test MSE 9.39071678462531 Test RE 0.03414316082744631\n",
      "199 Train Loss 44.169983 Test MSE 9.44259916129294 Test RE 0.034237348970077\n",
      "Training time: 29.81\n",
      "Training time: 29.81\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 16561.064 Test MSE 11337.061575024327 Test RE 1.1863275198295662\n",
      "1 Train Loss 14969.123 Test MSE 11007.498941241152 Test RE 1.168957383731268\n",
      "2 Train Loss 14775.646 Test MSE 9439.466554192466 Test RE 1.0825004320425096\n",
      "3 Train Loss 11444.695 Test MSE 5949.617940126416 Test RE 0.8594070091161381\n",
      "4 Train Loss 10627.352 Test MSE 5459.4880313186395 Test RE 0.8232472932419514\n",
      "5 Train Loss 10337.738 Test MSE 5117.684826322861 Test RE 0.7970601938489571\n",
      "6 Train Loss 9888.924 Test MSE 4650.508559405306 Test RE 0.7598092499523857\n",
      "7 Train Loss 9094.122 Test MSE 4220.16189427023 Test RE 0.7238005490521189\n",
      "8 Train Loss 8596.251 Test MSE 4137.390413188284 Test RE 0.7166673251832673\n",
      "9 Train Loss 8404.292 Test MSE 4049.7060759976275 Test RE 0.7090324375295823\n",
      "10 Train Loss 8141.953 Test MSE 3998.98994165018 Test RE 0.7045786972145834\n",
      "11 Train Loss 7942.77 Test MSE 3774.1463866583154 Test RE 0.6844846651293632\n",
      "12 Train Loss 7658.8003 Test MSE 3463.6044747038195 Test RE 0.655720102918584\n",
      "13 Train Loss 7365.075 Test MSE 3427.038327074176 Test RE 0.6522496175094038\n",
      "14 Train Loss 7105.0225 Test MSE 3295.7013482115094 Test RE 0.6396291933414497\n",
      "15 Train Loss 6930.343 Test MSE 3163.000499547934 Test RE 0.6266196109241585\n",
      "16 Train Loss 6782.9746 Test MSE 3118.5617673442594 Test RE 0.6222021786751248\n",
      "17 Train Loss 6576.187 Test MSE 2915.3522879962607 Test RE 0.601588981573462\n",
      "18 Train Loss 6422.271 Test MSE 2833.9484199666144 Test RE 0.5931305903636439\n",
      "19 Train Loss 6240.963 Test MSE 2768.769338180608 Test RE 0.5862700935423757\n",
      "20 Train Loss 6040.4795 Test MSE 2664.773744117348 Test RE 0.5751545008035891\n",
      "21 Train Loss 5829.18 Test MSE 2603.764182594186 Test RE 0.5685323436519004\n",
      "22 Train Loss 5633.7397 Test MSE 2450.0819932446557 Test RE 0.551498914029504\n",
      "23 Train Loss 5526.295 Test MSE 2383.616863226118 Test RE 0.5439670289837235\n",
      "24 Train Loss 5459.653 Test MSE 2305.862781525108 Test RE 0.5350213121017114\n",
      "25 Train Loss 5406.2617 Test MSE 2232.3851155501693 Test RE 0.5264279159783981\n",
      "26 Train Loss 5353.098 Test MSE 2191.75514460177 Test RE 0.5216153577026196\n",
      "27 Train Loss 5304.2324 Test MSE 2174.2222002784197 Test RE 0.5195248376161202\n",
      "28 Train Loss 5276.108 Test MSE 2172.203910605841 Test RE 0.5192836490510832\n",
      "29 Train Loss 5210.021 Test MSE 2106.735207088463 Test RE 0.5113983575829166\n",
      "30 Train Loss 5164.2524 Test MSE 2083.9233753075364 Test RE 0.5086220985564598\n",
      "31 Train Loss 5106.7603 Test MSE 2031.9889241939538 Test RE 0.5022443045505688\n",
      "32 Train Loss 5081.416 Test MSE 2002.566134667176 Test RE 0.4985948474444393\n",
      "33 Train Loss 5060.2676 Test MSE 1990.742324449793 Test RE 0.49712073418821845\n",
      "34 Train Loss 5033.5034 Test MSE 1972.8870584107328 Test RE 0.4948863375873471\n",
      "35 Train Loss 5010.39 Test MSE 1952.5597274823804 Test RE 0.49233024476624465\n",
      "36 Train Loss 4968.626 Test MSE 1934.2776376408633 Test RE 0.4900199456613832\n",
      "37 Train Loss 4939.512 Test MSE 1931.5546181135137 Test RE 0.4896749063054102\n",
      "38 Train Loss 4906.009 Test MSE 1963.2487781937064 Test RE 0.49367600649585447\n",
      "39 Train Loss 4881.3843 Test MSE 1953.0315696791201 Test RE 0.4923897277486342\n",
      "40 Train Loss 4870.438 Test MSE 1954.2711373115205 Test RE 0.4925459601320669\n",
      "41 Train Loss 4842.847 Test MSE 1957.3804508737196 Test RE 0.4929376333060885\n",
      "42 Train Loss 4802.6904 Test MSE 1916.326657132087 Test RE 0.48774084102684184\n",
      "43 Train Loss 4743.1504 Test MSE 1847.7387179083787 Test RE 0.47893285621151344\n",
      "44 Train Loss 4708.5913 Test MSE 1819.7783205331075 Test RE 0.4752953832050463\n",
      "45 Train Loss 4607.596 Test MSE 1785.318753338506 Test RE 0.4707737466474824\n",
      "46 Train Loss 4508.5127 Test MSE 1752.9446871445648 Test RE 0.46648583263928417\n",
      "47 Train Loss 4419.502 Test MSE 1709.3598025977083 Test RE 0.46065002150607076\n",
      "48 Train Loss 4324.4736 Test MSE 1724.2014648973973 Test RE 0.462645515908356\n",
      "49 Train Loss 4235.817 Test MSE 1735.9568811345457 Test RE 0.4642199700132182\n",
      "50 Train Loss 4190.6133 Test MSE 1720.905387012219 Test RE 0.462203095123953\n",
      "51 Train Loss 4143.889 Test MSE 1743.7988731408257 Test RE 0.4652673195492474\n",
      "52 Train Loss 4084.7434 Test MSE 1858.5260451770428 Test RE 0.480328856309461\n",
      "53 Train Loss 3737.3735 Test MSE 2117.948606447043 Test RE 0.5127575468021788\n",
      "54 Train Loss 3472.982 Test MSE 2165.6868047622925 Test RE 0.5185040793558828\n",
      "55 Train Loss 3304.8123 Test MSE 2119.134980472127 Test RE 0.512901137885645\n",
      "56 Train Loss 3144.393 Test MSE 2082.57332564157 Test RE 0.5084573189031444\n",
      "57 Train Loss 3070.9316 Test MSE 2102.9937470799046 Test RE 0.5109440463889521\n",
      "58 Train Loss 3031.8594 Test MSE 2076.9985663220527 Test RE 0.5077763280841994\n",
      "59 Train Loss 3004.0334 Test MSE 2111.4147217780755 Test RE 0.5119660057373407\n",
      "60 Train Loss 2977.4602 Test MSE 2101.1921775140904 Test RE 0.5107251445327778\n",
      "61 Train Loss 2937.4873 Test MSE 2084.0968520202027 Test RE 0.5086432683015909\n",
      "62 Train Loss 2890.5942 Test MSE 2092.4667842518475 Test RE 0.5096636248658143\n",
      "63 Train Loss 2853.9788 Test MSE 2079.33698635627 Test RE 0.5080620914771813\n",
      "64 Train Loss 2838.8464 Test MSE 2099.1071008116037 Test RE 0.5104716776138043\n",
      "65 Train Loss 2829.4788 Test MSE 2106.707870871856 Test RE 0.5113950397142122\n",
      "66 Train Loss 2818.7869 Test MSE 2102.951588686664 Test RE 0.5109389249548019\n",
      "67 Train Loss 2809.1458 Test MSE 2097.498013134382 Test RE 0.5102759869895453\n",
      "68 Train Loss 2797.8862 Test MSE 2082.8069355372786 Test RE 0.5084858358655365\n",
      "69 Train Loss 2785.4026 Test MSE 2069.2426565956152 Test RE 0.506827374419251\n",
      "70 Train Loss 2769.528 Test MSE 2044.2749908112273 Test RE 0.503760382622609\n",
      "71 Train Loss 2753.6265 Test MSE 2051.371426428588 Test RE 0.5046339945529886\n",
      "72 Train Loss 2734.9626 Test MSE 2062.375839120899 Test RE 0.505985717880675\n",
      "73 Train Loss 2717.2527 Test MSE 2038.8719619688452 Test RE 0.503094221581763\n",
      "74 Train Loss 2708.0542 Test MSE 2035.4116598245707 Test RE 0.5026671233371264\n",
      "75 Train Loss 2702.9736 Test MSE 2034.1836113813229 Test RE 0.5025154604747202\n",
      "76 Train Loss 2697.7878 Test MSE 2030.8938515160955 Test RE 0.5021089524014547\n",
      "77 Train Loss 2691.7883 Test MSE 2030.3543248099788 Test RE 0.5020422529077139\n",
      "78 Train Loss 2685.3042 Test MSE 2029.9691688361395 Test RE 0.5019946322186558\n",
      "79 Train Loss 2681.2363 Test MSE 2035.6462924766704 Test RE 0.5026960950492971\n",
      "80 Train Loss 2678.7966 Test MSE 2041.003984304937 Test RE 0.5033571924501982\n",
      "81 Train Loss 2675.5933 Test MSE 2051.024779906471 Test RE 0.5045913555146484\n",
      "82 Train Loss 2670.8955 Test MSE 2055.085787039729 Test RE 0.5050906512310631\n",
      "83 Train Loss 2666.665 Test MSE 2055.1821350341634 Test RE 0.5051024911019806\n",
      "84 Train Loss 2661.5708 Test MSE 2053.49717885556 Test RE 0.5048953926506116\n",
      "85 Train Loss 2659.0464 Test MSE 2041.6636377277307 Test RE 0.5034385285163698\n",
      "86 Train Loss 2656.198 Test MSE 2044.230705771366 Test RE 0.503754926123472\n",
      "87 Train Loss 2652.5974 Test MSE 2043.87521378952 Test RE 0.5037111226959116\n",
      "88 Train Loss 2649.4731 Test MSE 2024.0684470989481 Test RE 0.5012645013375875\n",
      "89 Train Loss 2643.8965 Test MSE 2014.3000003888712 Test RE 0.5000534509478199\n",
      "90 Train Loss 2639.8577 Test MSE 2010.758478662078 Test RE 0.4996136631152148\n",
      "91 Train Loss 2635.39 Test MSE 1995.6550525482119 Test RE 0.497733750274316\n",
      "92 Train Loss 2631.5547 Test MSE 1984.0454918237895 Test RE 0.49628387579079203\n",
      "93 Train Loss 2628.2505 Test MSE 1963.3172183939196 Test RE 0.4936846113631141\n",
      "94 Train Loss 2624.981 Test MSE 1960.1364558465007 Test RE 0.4932845410052372\n",
      "95 Train Loss 2621.0825 Test MSE 1968.9966797067038 Test RE 0.4943981582639867\n",
      "96 Train Loss 2614.1956 Test MSE 1960.513306634088 Test RE 0.49333195753411696\n",
      "97 Train Loss 2610.1008 Test MSE 1960.6384380810355 Test RE 0.4933477009510272\n",
      "98 Train Loss 2603.1458 Test MSE 1972.9639114334502 Test RE 0.4948959765427032\n",
      "99 Train Loss 2595.8682 Test MSE 1969.0211256815226 Test RE 0.4944012273416389\n",
      "100 Train Loss 2587.483 Test MSE 1966.8577621067843 Test RE 0.4941295533768133\n",
      "101 Train Loss 2581.3203 Test MSE 1974.0650651282758 Test RE 0.4950340633351632\n",
      "102 Train Loss 2577.2249 Test MSE 1974.5710668080435 Test RE 0.49509750400449587\n",
      "103 Train Loss 2573.245 Test MSE 1969.108684311273 Test RE 0.49441221976122585\n",
      "104 Train Loss 2567.6558 Test MSE 1983.307539858012 Test RE 0.4961915725336123\n",
      "105 Train Loss 2562.2822 Test MSE 1989.8350485792398 Test RE 0.49700744050839135\n",
      "106 Train Loss 2559.6802 Test MSE 1992.0093941106163 Test RE 0.4972789129732104\n",
      "107 Train Loss 2551.7317 Test MSE 1997.240802466084 Test RE 0.49793146092674423\n",
      "108 Train Loss 2546.6125 Test MSE 2000.3754846633076 Test RE 0.4983220610287728\n",
      "109 Train Loss 2540.671 Test MSE 1989.7522779261224 Test RE 0.49699710345600834\n",
      "110 Train Loss 2535.164 Test MSE 1979.5093162147086 Test RE 0.4957162176758382\n",
      "111 Train Loss 2527.2295 Test MSE 1980.07784293713 Test RE 0.49578739887246726\n",
      "112 Train Loss 2518.151 Test MSE 1961.5474614118502 Test RE 0.4934620546718821\n",
      "113 Train Loss 2512.9558 Test MSE 1931.4888927833736 Test RE 0.48966657510981176\n",
      "114 Train Loss 2492.9912 Test MSE 1891.390484765294 Test RE 0.48455708973294714\n",
      "115 Train Loss 2476.8694 Test MSE 1863.4334143701838 Test RE 0.48096258353016047\n",
      "116 Train Loss 2447.7234 Test MSE 1808.0714013243473 Test RE 0.47376409161742117\n",
      "117 Train Loss 2425.2388 Test MSE 1777.0965356171555 Test RE 0.46968843030329677\n",
      "118 Train Loss 2405.9778 Test MSE 1753.3928325193308 Test RE 0.4665454580542363\n",
      "119 Train Loss 2392.2288 Test MSE 1739.5321935661595 Test RE 0.46469776924498185\n",
      "120 Train Loss 2367.5425 Test MSE 1736.4126971035607 Test RE 0.4642809119034043\n",
      "121 Train Loss 2355.6343 Test MSE 1729.168107748859 Test RE 0.46331137275385326\n",
      "122 Train Loss 2337.4902 Test MSE 1720.9650076722014 Test RE 0.4622111015533341\n",
      "123 Train Loss 2322.8748 Test MSE 1704.8561871616423 Test RE 0.4600427886643489\n",
      "124 Train Loss 2300.5408 Test MSE 1668.4148480960791 Test RE 0.4550995179062461\n",
      "125 Train Loss 2283.6702 Test MSE 1636.3674986161168 Test RE 0.4507074894523791\n",
      "126 Train Loss 2216.3918 Test MSE 1498.380450834847 Test RE 0.43128604046280394\n",
      "127 Train Loss 2157.5776 Test MSE 1433.9394377518213 Test RE 0.42190993975415053\n",
      "128 Train Loss 2123.1265 Test MSE 1430.8718249948527 Test RE 0.42145840420868513\n",
      "129 Train Loss 2096.3584 Test MSE 1402.4675589641988 Test RE 0.4172542456891321\n",
      "130 Train Loss 2069.9097 Test MSE 1367.7229969933123 Test RE 0.41205332880333123\n",
      "131 Train Loss 2047.2075 Test MSE 1346.550923526935 Test RE 0.40885163929397944\n",
      "132 Train Loss 2020.2965 Test MSE 1281.242778624945 Test RE 0.3988136990215271\n",
      "133 Train Loss 1960.1104 Test MSE 1147.3455264901422 Test RE 0.37739962620384643\n",
      "134 Train Loss 1904.303 Test MSE 1116.2858733722692 Test RE 0.37225630884905625\n",
      "135 Train Loss 1860.7625 Test MSE 1089.4860408348661 Test RE 0.36776058995865435\n",
      "136 Train Loss 1827.0479 Test MSE 1079.3287991098323 Test RE 0.36604226580358956\n",
      "137 Train Loss 1810.6892 Test MSE 1075.964173580496 Test RE 0.3654712829506946\n",
      "138 Train Loss 1778.8229 Test MSE 983.0378423397038 Test RE 0.34933288501607757\n",
      "139 Train Loss 1723.1957 Test MSE 924.7872945208836 Test RE 0.3388248693706196\n",
      "140 Train Loss 1701.8286 Test MSE 913.6890213318516 Test RE 0.3367856322688088\n",
      "141 Train Loss 1668.4922 Test MSE 843.9029389235653 Test RE 0.3236686243691267\n",
      "142 Train Loss 1647.1594 Test MSE 815.8152587862778 Test RE 0.3182367014762918\n",
      "143 Train Loss 1631.258 Test MSE 798.0212557564727 Test RE 0.31474698739478446\n",
      "144 Train Loss 1619.0209 Test MSE 776.6700460269486 Test RE 0.31050788303894755\n",
      "145 Train Loss 1602.1443 Test MSE 729.3615903617748 Test RE 0.3009025004928101\n",
      "146 Train Loss 1590.3737 Test MSE 718.8018838350026 Test RE 0.29871632362415623\n",
      "147 Train Loss 1569.7218 Test MSE 723.6433185369258 Test RE 0.2997206257524983\n",
      "148 Train Loss 1551.5216 Test MSE 703.649545962103 Test RE 0.2955510851391824\n",
      "149 Train Loss 1540.5828 Test MSE 695.119393768336 Test RE 0.2937541799482531\n",
      "150 Train Loss 1518.6051 Test MSE 659.9461589839068 Test RE 0.28622568612608695\n",
      "151 Train Loss 1496.3119 Test MSE 629.0499590157206 Test RE 0.2794453720311159\n",
      "152 Train Loss 1462.5338 Test MSE 607.6681929440136 Test RE 0.27465506015190505\n",
      "153 Train Loss 1441.7559 Test MSE 591.0046599516132 Test RE 0.27086307526851827\n",
      "154 Train Loss 1419.0946 Test MSE 573.8299625465003 Test RE 0.26689839548833016\n",
      "155 Train Loss 1405.5083 Test MSE 577.9344934280792 Test RE 0.26785123933910737\n",
      "156 Train Loss 1376.2847 Test MSE 547.963646528692 Test RE 0.2608135953005271\n",
      "157 Train Loss 1335.5256 Test MSE 505.43427155122987 Test RE 0.2504878675621143\n",
      "158 Train Loss 1313.0543 Test MSE 508.29977017338166 Test RE 0.25119691938349237\n",
      "159 Train Loss 1297.348 Test MSE 488.0253555584916 Test RE 0.2461362307218417\n",
      "160 Train Loss 1280.4462 Test MSE 477.598880305323 Test RE 0.2434927318942669\n",
      "161 Train Loss 1259.0513 Test MSE 451.3426848741401 Test RE 0.23670506790662868\n",
      "162 Train Loss 1240.6338 Test MSE 438.6314313231555 Test RE 0.23334807732047924\n",
      "163 Train Loss 1217.3324 Test MSE 438.1495146822054 Test RE 0.23321985437698062\n",
      "164 Train Loss 1191.7231 Test MSE 408.04019869771867 Test RE 0.2250638934206612\n",
      "165 Train Loss 1177.911 Test MSE 393.96471224870015 Test RE 0.22114799897405182\n",
      "166 Train Loss 1157.5006 Test MSE 374.2936087553597 Test RE 0.2155562194311077\n",
      "167 Train Loss 1109.6428 Test MSE 373.04937217841956 Test RE 0.21519764238174988\n",
      "168 Train Loss 1086.5714 Test MSE 367.92507984757754 Test RE 0.213714529417559\n",
      "169 Train Loss 1078.1987 Test MSE 361.4662714294721 Test RE 0.21183037839943802\n",
      "170 Train Loss 1073.3971 Test MSE 356.04885807944737 Test RE 0.21023700012471025\n",
      "171 Train Loss 1070.0613 Test MSE 355.12107071592453 Test RE 0.20996290506508836\n",
      "172 Train Loss 1067.0964 Test MSE 358.8929255501089 Test RE 0.2110750015725058\n",
      "173 Train Loss 1061.1683 Test MSE 356.66913233048683 Test RE 0.2104200478296102\n",
      "174 Train Loss 1054.7009 Test MSE 353.73393375156274 Test RE 0.20955243621712913\n",
      "175 Train Loss 1051.2616 Test MSE 351.99979481723847 Test RE 0.2090381520735248\n",
      "176 Train Loss 1046.3888 Test MSE 346.7771050288089 Test RE 0.20748158676093437\n",
      "177 Train Loss 1043.3374 Test MSE 344.7831591103711 Test RE 0.2068842239734535\n",
      "178 Train Loss 1039.1194 Test MSE 344.9229792170887 Test RE 0.20692616865876062\n",
      "179 Train Loss 1034.7352 Test MSE 341.387206243117 Test RE 0.20586284630199642\n",
      "180 Train Loss 1026.653 Test MSE 340.1701640577273 Test RE 0.2054955691175741\n",
      "181 Train Loss 1020.83984 Test MSE 332.49484327519804 Test RE 0.2031640255225987\n",
      "182 Train Loss 1016.93036 Test MSE 326.77728281454716 Test RE 0.2014096528802055\n",
      "183 Train Loss 1014.2979 Test MSE 321.65174051529556 Test RE 0.19982384217314156\n",
      "184 Train Loss 1010.1907 Test MSE 309.62666958409625 Test RE 0.19605301842152414\n",
      "185 Train Loss 1004.9832 Test MSE 305.56867271750383 Test RE 0.19476403626740896\n",
      "186 Train Loss 1002.61993 Test MSE 308.3429844367939 Test RE 0.19564618696037855\n",
      "187 Train Loss 1000.5377 Test MSE 308.7880437292996 Test RE 0.1957873329570453\n",
      "188 Train Loss 997.05493 Test MSE 307.4640528321068 Test RE 0.19536714325998747\n",
      "189 Train Loss 994.35114 Test MSE 306.673584497944 Test RE 0.1951158440840356\n",
      "190 Train Loss 991.4583 Test MSE 301.85394649524284 Test RE 0.1935765660766094\n",
      "191 Train Loss 989.1914 Test MSE 294.13644145150346 Test RE 0.19108595593614194\n",
      "192 Train Loss 986.22205 Test MSE 291.08198023501717 Test RE 0.19009120019514503\n",
      "193 Train Loss 981.3814 Test MSE 288.4029715011565 Test RE 0.18921441428327845\n",
      "194 Train Loss 979.35614 Test MSE 282.9691193979356 Test RE 0.1874234267336881\n",
      "195 Train Loss 978.03955 Test MSE 282.37155675188706 Test RE 0.18722542557129343\n",
      "196 Train Loss 976.8199 Test MSE 284.66953594752385 Test RE 0.18798571521061147\n",
      "197 Train Loss 972.6136 Test MSE 277.318824126651 Test RE 0.18554276633057742\n",
      "198 Train Loss 966.9768 Test MSE 275.73115842579404 Test RE 0.1850108826406153\n",
      "199 Train Loss 962.64026 Test MSE 280.565773548819 Test RE 0.18662580641698892\n",
      "Training time: 29.70\n",
      "Training time: 29.70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 18616.328 Test MSE 11562.844255805283 Test RE 1.1980824054866543\n",
      "1 Train Loss 15796.815 Test MSE 9336.83928000979 Test RE 1.0765997978018798\n",
      "2 Train Loss 11515.025 Test MSE 5911.68938812131 Test RE 0.8566632884575095\n",
      "3 Train Loss 9698.371 Test MSE 4671.327199428575 Test RE 0.7615080460618011\n",
      "4 Train Loss 8642.643 Test MSE 3921.908020196116 Test RE 0.6977551560109998\n",
      "5 Train Loss 8260.087 Test MSE 3563.276940486485 Test RE 0.6650880443719299\n",
      "6 Train Loss 7907.916 Test MSE 3562.409447072438 Test RE 0.6650070803284502\n",
      "7 Train Loss 7356.645 Test MSE 3020.9251730463093 Test RE 0.6123847067589939\n",
      "8 Train Loss 6952.2515 Test MSE 2567.824488215773 Test RE 0.5645949905116293\n",
      "9 Train Loss 6596.146 Test MSE 2291.6682631891076 Test RE 0.5333720176541484\n",
      "10 Train Loss 6381.624 Test MSE 1980.1045355059466 Test RE 0.49579074060842726\n",
      "11 Train Loss 6257.745 Test MSE 1935.425448737993 Test RE 0.49016531437809724\n",
      "12 Train Loss 6127.3325 Test MSE 1785.6477893753793 Test RE 0.4708171266856695\n",
      "13 Train Loss 6039.3384 Test MSE 1728.6603046586677 Test RE 0.46324333766194\n",
      "14 Train Loss 5899.3267 Test MSE 1657.1640597284418 Test RE 0.45356246327852096\n",
      "15 Train Loss 5813.3574 Test MSE 1467.5978403308525 Test RE 0.4268328972172148\n",
      "16 Train Loss 5390.5913 Test MSE 1661.3143357327149 Test RE 0.45413006920524296\n",
      "17 Train Loss 4836.362 Test MSE 1998.8206563995182 Test RE 0.4981283584346084\n",
      "18 Train Loss 4483.72 Test MSE 2091.3072306205063 Test RE 0.509522388644466\n",
      "19 Train Loss 4205.5234 Test MSE 2165.5181108334123 Test RE 0.5184838847937058\n",
      "20 Train Loss 4140.7285 Test MSE 2188.0834402532537 Test RE 0.5211782604830505\n",
      "21 Train Loss 3997.418 Test MSE 2257.2257920382062 Test RE 0.5293487042970451\n",
      "22 Train Loss 3820.4033 Test MSE 2278.773092018783 Test RE 0.531869263879104\n",
      "23 Train Loss 3747.0518 Test MSE 2284.716182339131 Test RE 0.532562375627085\n",
      "24 Train Loss 3618.3713 Test MSE 2299.4677571329416 Test RE 0.5342788893689684\n",
      "25 Train Loss 3549.3467 Test MSE 2303.1483548145357 Test RE 0.5347063098814911\n",
      "26 Train Loss 3455.2031 Test MSE 2306.3213057980597 Test RE 0.5350745043527309\n",
      "27 Train Loss 3397.5466 Test MSE 2272.7389497175163 Test RE 0.531164607886435\n",
      "28 Train Loss 3364.39 Test MSE 2251.374403465268 Test RE 0.5286621458379921\n",
      "29 Train Loss 3322.5596 Test MSE 2253.560685694054 Test RE 0.5289187722329415\n",
      "30 Train Loss 3301.122 Test MSE 2232.445217023698 Test RE 0.5264350023185389\n",
      "31 Train Loss 3246.6743 Test MSE 2234.6680562231886 Test RE 0.5266970220108587\n",
      "32 Train Loss 3210.4434 Test MSE 2214.9362536024782 Test RE 0.5243665360635834\n",
      "33 Train Loss 3180.892 Test MSE 2174.0718810994013 Test RE 0.5195068781138873\n",
      "34 Train Loss 3146.5808 Test MSE 2187.164437717986 Test RE 0.5210688006617048\n",
      "35 Train Loss 3115.195 Test MSE 2171.953544466047 Test RE 0.5192537221209986\n",
      "36 Train Loss 3056.1453 Test MSE 2112.5140682160813 Test RE 0.5120992705944039\n",
      "37 Train Loss 2994.988 Test MSE 2072.062672518656 Test RE 0.5071726153784929\n",
      "38 Train Loss 2895.5095 Test MSE 2051.3791629801485 Test RE 0.5046349461415666\n",
      "39 Train Loss 2834.9275 Test MSE 2036.9883375946279 Test RE 0.5028617745404522\n",
      "40 Train Loss 2787.5596 Test MSE 2018.7698623636093 Test RE 0.5006079689646404\n",
      "41 Train Loss 2757.3237 Test MSE 2009.054474754955 Test RE 0.4994019211069434\n",
      "42 Train Loss 2733.988 Test MSE 2003.5919460184473 Test RE 0.4987225333078228\n",
      "43 Train Loss 2706.6462 Test MSE 1989.7431831249833 Test RE 0.4969959676123563\n",
      "44 Train Loss 2672.9492 Test MSE 1971.4278264589734 Test RE 0.4947032841437555\n",
      "45 Train Loss 2631.8564 Test MSE 1918.7108510227833 Test RE 0.4880441575983485\n",
      "46 Train Loss 2587.2007 Test MSE 1898.0514538367554 Test RE 0.48540957976726434\n",
      "47 Train Loss 2564.11 Test MSE 1863.7370335834485 Test RE 0.4810017648425266\n",
      "48 Train Loss 2545.2976 Test MSE 1841.805005821232 Test RE 0.4781632303830819\n",
      "49 Train Loss 2535.2402 Test MSE 1838.6889232895385 Test RE 0.47775856571012754\n",
      "50 Train Loss 2526.48 Test MSE 1822.1181169036008 Test RE 0.4756008427102688\n",
      "51 Train Loss 2496.6702 Test MSE 1797.0250752158684 Test RE 0.47231465483325663\n",
      "52 Train Loss 2486.5227 Test MSE 1781.055583327284 Test RE 0.4702113294119878\n",
      "53 Train Loss 2471.4526 Test MSE 1752.6712456442908 Test RE 0.46644944770322794\n",
      "54 Train Loss 2418.4592 Test MSE 1715.9307674634379 Test RE 0.4615345666241357\n",
      "55 Train Loss 2348.913 Test MSE 1613.790861109538 Test RE 0.44758752983414024\n",
      "56 Train Loss 2272.3718 Test MSE 1407.0879640055764 Test RE 0.4179409989667431\n",
      "57 Train Loss 2192.7664 Test MSE 1336.2786787160396 Test RE 0.40728917908286794\n",
      "58 Train Loss 2120.5745 Test MSE 1233.009843601915 Test RE 0.3912349317681338\n",
      "59 Train Loss 2031.8934 Test MSE 1220.80772745308 Test RE 0.3892942482587089\n",
      "60 Train Loss 1980.3438 Test MSE 1212.5414732605482 Test RE 0.387974027618174\n",
      "61 Train Loss 1936.9749 Test MSE 1141.2323724017822 Test RE 0.37639287482094946\n",
      "62 Train Loss 1911.0409 Test MSE 1119.5576309467958 Test RE 0.37280143860185755\n",
      "63 Train Loss 1877.7076 Test MSE 1129.885106048583 Test RE 0.374516964127619\n",
      "64 Train Loss 1837.4718 Test MSE 1121.71529256281 Test RE 0.3731605054985821\n",
      "65 Train Loss 1781.3617 Test MSE 1163.2052539925003 Test RE 0.379999066664686\n",
      "66 Train Loss 1745.1173 Test MSE 1163.6094592378029 Test RE 0.380065084366307\n",
      "67 Train Loss 1717.4404 Test MSE 1133.2850407357023 Test RE 0.3750800199431703\n",
      "68 Train Loss 1701.693 Test MSE 1125.3246799919577 Test RE 0.3737603899382144\n",
      "69 Train Loss 1691.4042 Test MSE 1107.157171582058 Test RE 0.3707310755259595\n",
      "70 Train Loss 1683.7449 Test MSE 1099.8018884605967 Test RE 0.36949756683597434\n",
      "71 Train Loss 1668.3735 Test MSE 1089.793413241053 Test RE 0.3678124637236593\n",
      "72 Train Loss 1653.163 Test MSE 1066.1116871670763 Test RE 0.3637941444682647\n",
      "73 Train Loss 1645.6252 Test MSE 1049.9580043661126 Test RE 0.36102752718667697\n",
      "74 Train Loss 1641.4614 Test MSE 1047.7554384695684 Test RE 0.36064865280182623\n",
      "75 Train Loss 1639.8285 Test MSE 1048.9257565160806 Test RE 0.3608500145965472\n",
      "76 Train Loss 1634.8403 Test MSE 1051.225498090212 Test RE 0.36124537499787895\n",
      "77 Train Loss 1616.677 Test MSE 1048.6285702285518 Test RE 0.360798892163664\n",
      "78 Train Loss 1594.5264 Test MSE 1064.0395647967107 Test RE 0.36344043263892345\n",
      "79 Train Loss 1585.0087 Test MSE 1054.7929926126967 Test RE 0.3618578265439251\n",
      "80 Train Loss 1573.8446 Test MSE 1043.4100212835874 Test RE 0.35990000618194246\n",
      "81 Train Loss 1561.207 Test MSE 1040.990219018316 Test RE 0.3594824367013454\n",
      "82 Train Loss 1553.6935 Test MSE 1027.5204428778247 Test RE 0.35714912288467415\n",
      "83 Train Loss 1542.9226 Test MSE 986.0157895691282 Test RE 0.3498616074079984\n",
      "84 Train Loss 1526.9296 Test MSE 955.3515490291556 Test RE 0.34437844318636585\n",
      "85 Train Loss 1520.009 Test MSE 927.1716674824465 Test RE 0.33926138314584253\n",
      "86 Train Loss 1511.3918 Test MSE 908.3888769710096 Test RE 0.3358073953650024\n",
      "87 Train Loss 1499.4015 Test MSE 892.6324573926958 Test RE 0.33288228930152747\n",
      "88 Train Loss 1486.5281 Test MSE 839.029053099161 Test RE 0.3227326113749359\n",
      "89 Train Loss 1472.657 Test MSE 832.4015005944309 Test RE 0.32145543988103215\n",
      "90 Train Loss 1454.5288 Test MSE 847.8199626799282 Test RE 0.3244189179602041\n",
      "91 Train Loss 1410.5161 Test MSE 790.9789389516189 Test RE 0.31335513236275286\n",
      "92 Train Loss 1392.2749 Test MSE 771.2125985272203 Test RE 0.30941503297887635\n",
      "93 Train Loss 1380.9597 Test MSE 772.8750390277556 Test RE 0.3097483439087232\n",
      "94 Train Loss 1364.7722 Test MSE 734.0312218895583 Test RE 0.30186420590695434\n",
      "95 Train Loss 1341.8948 Test MSE 725.4529808676157 Test RE 0.30009515726276864\n",
      "96 Train Loss 1329.7109 Test MSE 720.7779740301571 Test RE 0.2991266489654132\n",
      "97 Train Loss 1321.5814 Test MSE 694.4223418639484 Test RE 0.2936068575810901\n",
      "98 Train Loss 1315.4918 Test MSE 686.6265586861305 Test RE 0.2919541489019023\n",
      "99 Train Loss 1308.5858 Test MSE 687.8757006816548 Test RE 0.2922195963042316\n",
      "100 Train Loss 1294.4279 Test MSE 682.7130304679885 Test RE 0.2911209423326468\n",
      "101 Train Loss 1290.4222 Test MSE 691.5922974521652 Test RE 0.29300796501393095\n",
      "102 Train Loss 1272.2157 Test MSE 683.5627926144246 Test RE 0.2913020628145028\n",
      "103 Train Loss 1248.6194 Test MSE 673.8663719626011 Test RE 0.2892286060470974\n",
      "104 Train Loss 1236.2509 Test MSE 682.5940823572884 Test RE 0.29109558043608796\n",
      "105 Train Loss 1229.1285 Test MSE 691.0798648536993 Test RE 0.29289939334792064\n",
      "106 Train Loss 1222.1982 Test MSE 701.1413383049817 Test RE 0.2950238587052021\n",
      "107 Train Loss 1217.1694 Test MSE 688.8049471559505 Test RE 0.29241690839453716\n",
      "108 Train Loss 1207.4692 Test MSE 658.8805070457421 Test RE 0.28599450045698777\n",
      "109 Train Loss 1202.9376 Test MSE 652.8243723865095 Test RE 0.284677099520249\n",
      "110 Train Loss 1200.2595 Test MSE 655.8395670987936 Test RE 0.28533376008791633\n",
      "111 Train Loss 1197.675 Test MSE 654.9867113458881 Test RE 0.2851481752930398\n",
      "112 Train Loss 1191.9971 Test MSE 655.2212497574857 Test RE 0.2851992238204834\n",
      "113 Train Loss 1177.9259 Test MSE 649.2078365824992 Test RE 0.2838874730864356\n",
      "114 Train Loss 1147.1464 Test MSE 629.2674782409958 Test RE 0.2794936825716208\n",
      "115 Train Loss 1133.1864 Test MSE 626.5756082443665 Test RE 0.2788952351553927\n",
      "116 Train Loss 1125.7885 Test MSE 623.1404576315055 Test RE 0.27812967403124\n",
      "117 Train Loss 1111.5405 Test MSE 595.8619588383402 Test RE 0.2719738708258373\n",
      "118 Train Loss 1099.4794 Test MSE 577.0156227905853 Test RE 0.2676382233763704\n",
      "119 Train Loss 1094.8634 Test MSE 578.4920645492464 Test RE 0.26798041497570774\n",
      "120 Train Loss 1086.8765 Test MSE 561.1452949686541 Test RE 0.2639319796658957\n",
      "121 Train Loss 1073.517 Test MSE 541.6450381510085 Test RE 0.259305505019858\n",
      "122 Train Loss 1065.7947 Test MSE 528.824840446183 Test RE 0.2562183770095012\n",
      "123 Train Loss 1062.292 Test MSE 518.2027080540637 Test RE 0.2536320847632357\n",
      "124 Train Loss 1054.8235 Test MSE 503.2111944880141 Test RE 0.24993639378576327\n",
      "125 Train Loss 1044.3151 Test MSE 493.8954748159569 Test RE 0.24761210710263398\n",
      "126 Train Loss 1034.1403 Test MSE 497.8747898767615 Test RE 0.24860761110984284\n",
      "127 Train Loss 1029.578 Test MSE 497.46985737252885 Test RE 0.24850649152912455\n",
      "128 Train Loss 1018.2936 Test MSE 472.1559228001865 Test RE 0.2421012731579004\n",
      "129 Train Loss 998.8802 Test MSE 432.6241186334515 Test RE 0.23174464957299032\n",
      "130 Train Loss 991.3293 Test MSE 434.3223065316295 Test RE 0.23219904000125244\n",
      "131 Train Loss 985.8863 Test MSE 425.44378730807847 Test RE 0.22981345153602656\n",
      "132 Train Loss 979.6556 Test MSE 413.55298728857775 Test RE 0.22657914492004305\n",
      "133 Train Loss 974.01245 Test MSE 416.8990468654223 Test RE 0.22749392485178208\n",
      "134 Train Loss 970.6949 Test MSE 404.79060334675916 Test RE 0.22416590770046815\n",
      "135 Train Loss 962.14197 Test MSE 371.89897822242625 Test RE 0.21486557746510254\n",
      "136 Train Loss 941.1303 Test MSE 345.4579492440718 Test RE 0.20708657607540487\n",
      "137 Train Loss 929.99854 Test MSE 345.1465587521986 Test RE 0.20699322270362894\n",
      "138 Train Loss 913.6893 Test MSE 351.0594632993853 Test RE 0.20875875331064966\n",
      "139 Train Loss 903.85864 Test MSE 342.07650952617803 Test RE 0.20607057286003064\n",
      "140 Train Loss 898.22406 Test MSE 336.45582098556287 Test RE 0.20437057910011272\n",
      "141 Train Loss 887.0569 Test MSE 318.3738978737131 Test RE 0.19880306677766074\n",
      "142 Train Loss 877.88043 Test MSE 327.7654033120178 Test RE 0.20171393777891294\n",
      "143 Train Loss 869.5818 Test MSE 307.7915817406882 Test RE 0.19547117388508242\n",
      "144 Train Loss 860.5119 Test MSE 282.6820012292424 Test RE 0.18732831683525872\n",
      "145 Train Loss 847.3244 Test MSE 267.07743225736215 Test RE 0.1820844876413663\n",
      "146 Train Loss 822.9884 Test MSE 189.98033120319272 Test RE 0.15357080916818622\n",
      "147 Train Loss 805.3919 Test MSE 138.45441342529418 Test RE 0.1311015282740748\n",
      "148 Train Loss 779.91284 Test MSE 100.20727894765096 Test RE 0.11153315487803685\n",
      "149 Train Loss 767.4258 Test MSE 89.04214964046683 Test RE 0.10513617443701327\n",
      "150 Train Loss 735.0231 Test MSE 71.47682930335183 Test RE 0.09419698272145124\n",
      "151 Train Loss 718.85535 Test MSE 75.45574212623369 Test RE 0.09678331642538057\n",
      "152 Train Loss 710.6926 Test MSE 77.18965795255843 Test RE 0.09788900420415864\n",
      "153 Train Loss 706.6389 Test MSE 79.80947353310106 Test RE 0.09953631888145234\n",
      "154 Train Loss 699.5452 Test MSE 89.69654344948925 Test RE 0.10552180369356462\n",
      "155 Train Loss 693.22205 Test MSE 91.06721022735843 Test RE 0.10632499442240317\n",
      "156 Train Loss 677.8491 Test MSE 81.2506671440373 Test RE 0.10043100766444901\n",
      "157 Train Loss 658.3594 Test MSE 75.75314796054697 Test RE 0.09697386266640962\n",
      "158 Train Loss 642.6866 Test MSE 76.11548663353422 Test RE 0.09720550626805426\n",
      "159 Train Loss 632.88275 Test MSE 74.7265919040411 Test RE 0.09631455893349454\n",
      "160 Train Loss 616.6066 Test MSE 78.92489671650205 Test RE 0.09898317118680348\n",
      "161 Train Loss 606.36554 Test MSE 65.30708885704179 Test RE 0.09003979858727851\n",
      "162 Train Loss 597.24713 Test MSE 58.72156405260297 Test RE 0.08537941201541394\n",
      "163 Train Loss 584.88947 Test MSE 59.95097878199014 Test RE 0.08626854857695859\n",
      "164 Train Loss 575.1752 Test MSE 51.32207407088863 Test RE 0.07981903113859792\n",
      "165 Train Loss 564.14307 Test MSE 46.087790391019126 Test RE 0.07563926426668013\n",
      "166 Train Loss 548.5379 Test MSE 49.22770340090889 Test RE 0.07817342499002622\n",
      "167 Train Loss 524.3069 Test MSE 48.1323361188672 Test RE 0.07729881261032105\n",
      "168 Train Loss 508.5562 Test MSE 49.48779909284308 Test RE 0.07837966846144938\n",
      "169 Train Loss 499.95047 Test MSE 55.69840939845257 Test RE 0.083152583851473\n",
      "170 Train Loss 493.32504 Test MSE 55.753045127816975 Test RE 0.08319335690546643\n",
      "171 Train Loss 487.74353 Test MSE 58.67405884197859 Test RE 0.0853448694443986\n",
      "172 Train Loss 480.4322 Test MSE 60.56372026178405 Test RE 0.0867082906593624\n",
      "173 Train Loss 475.89954 Test MSE 56.52781486800916 Test RE 0.08376940895286672\n",
      "174 Train Loss 470.80484 Test MSE 54.51968924848577 Test RE 0.08226801872410444\n",
      "175 Train Loss 466.55505 Test MSE 53.46311448073414 Test RE 0.08146695422156883\n",
      "176 Train Loss 460.02365 Test MSE 46.27570435586984 Test RE 0.07579330956824407\n",
      "177 Train Loss 455.6778 Test MSE 49.3325963594601 Test RE 0.07825666550209966\n",
      "178 Train Loss 454.39954 Test MSE 51.88551474387987 Test RE 0.08025598275537064\n",
      "179 Train Loss 451.6434 Test MSE 47.46298093772394 Test RE 0.07675945062155251\n",
      "180 Train Loss 443.62372 Test MSE 44.96739706708824 Test RE 0.07471421313230385\n",
      "181 Train Loss 432.43332 Test MSE 43.76001977747595 Test RE 0.07370434773572772\n",
      "182 Train Loss 428.99948 Test MSE 42.47895281531629 Test RE 0.07261749330791614\n",
      "183 Train Loss 423.78558 Test MSE 44.761069743995115 Test RE 0.0745426076091074\n",
      "184 Train Loss 422.35233 Test MSE 46.844826818264465 Test RE 0.0762579579049871\n",
      "185 Train Loss 421.32938 Test MSE 46.97904757814823 Test RE 0.07636712769561518\n",
      "186 Train Loss 419.0633 Test MSE 49.006930255467886 Test RE 0.07799793451117011\n",
      "187 Train Loss 417.42886 Test MSE 50.247457100333996 Test RE 0.0789789574118145\n",
      "188 Train Loss 415.2902 Test MSE 50.10368835681897 Test RE 0.07886588861362347\n",
      "189 Train Loss 412.83716 Test MSE 54.821924710685664 Test RE 0.0824957341488156\n",
      "190 Train Loss 409.0512 Test MSE 66.68724550276873 Test RE 0.09098624499218555\n",
      "191 Train Loss 405.78223 Test MSE 68.35498117386167 Test RE 0.09211692589601983\n",
      "192 Train Loss 403.79236 Test MSE 70.93535822875273 Test RE 0.0938395108926732\n",
      "193 Train Loss 402.41473 Test MSE 69.20153260158229 Test RE 0.09268558785504039\n",
      "194 Train Loss 401.19913 Test MSE 66.84962512268983 Test RE 0.09109695078795518\n",
      "195 Train Loss 400.58383 Test MSE 65.54414771142702 Test RE 0.09020306873978211\n",
      "196 Train Loss 398.22098 Test MSE 59.640612369812665 Test RE 0.0860449525337737\n",
      "197 Train Loss 395.2383 Test MSE 55.15530449196887 Test RE 0.08274618800558049\n",
      "198 Train Loss 390.2295 Test MSE 53.45813703817489 Test RE 0.08146316182631193\n",
      "199 Train Loss 387.9396 Test MSE 47.90972257365564 Test RE 0.0771198507433258\n",
      "Training time: 28.88\n",
      "Training time: 28.88\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 18120.89 Test MSE 10436.146960007665 Test RE 1.1382153688626433\n",
      "1 Train Loss 16475.467 Test MSE 8836.638633476368 Test RE 1.0473646215614676\n",
      "2 Train Loss 13562.792 Test MSE 5962.815383822217 Test RE 0.860359649521099\n",
      "3 Train Loss 11887.959 Test MSE 4845.515314401266 Test RE 0.7755759573561436\n",
      "4 Train Loss 11208.709 Test MSE 4251.06051791753 Test RE 0.7264454302494515\n",
      "5 Train Loss 10652.422 Test MSE 3980.130614126407 Test RE 0.7029153291955675\n",
      "6 Train Loss 10208.287 Test MSE 3801.9645771321652 Test RE 0.6870026075778928\n",
      "7 Train Loss 9838.627 Test MSE 3526.7014834623233 Test RE 0.6616658229619597\n",
      "8 Train Loss 9604.676 Test MSE 3479.345413685166 Test RE 0.6572084295525186\n",
      "9 Train Loss 9055.8955 Test MSE 3330.5175166641106 Test RE 0.6429988755113228\n",
      "10 Train Loss 8723.981 Test MSE 3178.7835121441813 Test RE 0.6281810457822734\n",
      "11 Train Loss 8102.756 Test MSE 2862.7181719273526 Test RE 0.5961336672792429\n",
      "12 Train Loss 7538.876 Test MSE 2490.7827837472223 Test RE 0.5560607997187345\n",
      "13 Train Loss 7034.7627 Test MSE 2236.377729541131 Test RE 0.5268984630428744\n",
      "14 Train Loss 6677.654 Test MSE 2222.000677383447 Test RE 0.5252020902282887\n",
      "15 Train Loss 6397.2227 Test MSE 2221.838092592039 Test RE 0.525182875239919\n",
      "16 Train Loss 6083.1123 Test MSE 2077.605891443066 Test RE 0.5078505608701125\n",
      "17 Train Loss 5761.2227 Test MSE 1933.9178809266746 Test RE 0.4899743740847313\n",
      "18 Train Loss 5552.76 Test MSE 1805.719530580819 Test RE 0.4734558641660332\n",
      "19 Train Loss 5303.959 Test MSE 1600.6439757454332 Test RE 0.4457606464508965\n",
      "20 Train Loss 5049.149 Test MSE 1516.5254705143586 Test RE 0.4338895662409305\n",
      "21 Train Loss 4784.391 Test MSE 1546.480665801419 Test RE 0.4381538173256983\n",
      "22 Train Loss 4622.431 Test MSE 1537.022893382512 Test RE 0.4368119595175383\n",
      "23 Train Loss 4397.4634 Test MSE 1364.439170767826 Test RE 0.41155837306554727\n",
      "24 Train Loss 4209.2256 Test MSE 1362.1295855484632 Test RE 0.41120990325593415\n",
      "25 Train Loss 4013.636 Test MSE 1236.3806901512332 Test RE 0.39176935280932407\n",
      "26 Train Loss 3749.1782 Test MSE 1190.6113931898956 Test RE 0.38444956106070277\n",
      "27 Train Loss 3472.713 Test MSE 1144.2771590802695 Test RE 0.37689464494952285\n",
      "28 Train Loss 3336.4568 Test MSE 1141.048474353045 Test RE 0.376362547647633\n",
      "29 Train Loss 3209.5547 Test MSE 1109.2366263668646 Test RE 0.3710790644496509\n",
      "30 Train Loss 3036.472 Test MSE 1084.4820432110578 Test RE 0.36691505775147504\n",
      "31 Train Loss 2955.225 Test MSE 1089.725022148875 Test RE 0.3678009223202722\n",
      "32 Train Loss 2862.806 Test MSE 1066.8280461942893 Test RE 0.36391634716964183\n",
      "33 Train Loss 2702.0488 Test MSE 1008.023754876437 Test RE 0.35374453218430074\n",
      "34 Train Loss 2548.4976 Test MSE 1004.9207266272664 Test RE 0.35319964158617995\n",
      "35 Train Loss 2364.6677 Test MSE 956.020360538827 Test RE 0.3444989663435919\n",
      "36 Train Loss 2187.7676 Test MSE 907.8705823338948 Test RE 0.33571158177133525\n",
      "37 Train Loss 2112.164 Test MSE 896.580050656052 Test RE 0.33361754949666395\n",
      "38 Train Loss 2000.6062 Test MSE 873.7151794019751 Test RE 0.32933606553104444\n",
      "39 Train Loss 1940.5139 Test MSE 863.4091671918094 Test RE 0.3273879421244048\n",
      "40 Train Loss 1857.5114 Test MSE 865.0295555655824 Test RE 0.32769500797969386\n",
      "41 Train Loss 1807.4745 Test MSE 849.4356887095954 Test RE 0.32472790018333486\n",
      "42 Train Loss 1766.2754 Test MSE 843.0064411863146 Test RE 0.32349665832893143\n",
      "43 Train Loss 1710.7349 Test MSE 838.9842455884393 Test RE 0.3227239936530805\n",
      "44 Train Loss 1603.7991 Test MSE 796.7188090712277 Test RE 0.31449003398041214\n",
      "45 Train Loss 1542.0243 Test MSE 805.1980649262192 Test RE 0.3161591196463524\n",
      "46 Train Loss 1489.2653 Test MSE 800.2507116057059 Test RE 0.31518633978685645\n",
      "47 Train Loss 1430.0812 Test MSE 770.8702129304759 Test RE 0.3093463417958927\n",
      "48 Train Loss 1305.6001 Test MSE 803.1253556077912 Test RE 0.3157519352271728\n",
      "49 Train Loss 1147.6495 Test MSE 788.3041554809307 Test RE 0.31282486103171997\n",
      "50 Train Loss 1096.1559 Test MSE 788.0633888280886 Test RE 0.31277708534385357\n",
      "51 Train Loss 1026.3967 Test MSE 771.5434468666004 Test RE 0.3094813950127231\n",
      "52 Train Loss 940.07367 Test MSE 724.0562747344287 Test RE 0.2998061332351555\n",
      "53 Train Loss 910.3052 Test MSE 702.5796819328152 Test RE 0.2953263143285825\n",
      "54 Train Loss 873.0941 Test MSE 693.0613451204415 Test RE 0.2933189967665488\n",
      "55 Train Loss 856.5459 Test MSE 690.8990884795589 Test RE 0.2928610817459241\n",
      "56 Train Loss 842.662 Test MSE 691.5730732119385 Test RE 0.2930038926040203\n",
      "57 Train Loss 813.0547 Test MSE 683.6713726663 Test RE 0.2913251977316518\n",
      "58 Train Loss 778.2521 Test MSE 669.2902634180209 Test RE 0.28824488271763177\n",
      "59 Train Loss 743.2803 Test MSE 664.6088509254137 Test RE 0.2872350360404217\n",
      "60 Train Loss 726.34357 Test MSE 658.3437978188842 Test RE 0.28587799438578415\n",
      "61 Train Loss 699.78204 Test MSE 638.2306115767796 Test RE 0.2814771645986619\n",
      "62 Train Loss 686.18787 Test MSE 623.8987989531444 Test RE 0.2782988598794746\n",
      "63 Train Loss 667.80725 Test MSE 616.8866311312084 Test RE 0.2767305024437563\n",
      "64 Train Loss 647.187 Test MSE 614.323384969911 Test RE 0.27615497791818455\n",
      "65 Train Loss 629.6063 Test MSE 580.9413381773106 Test RE 0.2685471160019715\n",
      "66 Train Loss 618.828 Test MSE 559.0422575823699 Test RE 0.26343693866746465\n",
      "67 Train Loss 611.6389 Test MSE 545.1798906897797 Test RE 0.260150261310288\n",
      "68 Train Loss 598.72015 Test MSE 541.1391653480612 Test RE 0.2591843867267103\n",
      "69 Train Loss 585.89185 Test MSE 539.6143158554129 Test RE 0.2588189576331784\n",
      "70 Train Loss 573.73126 Test MSE 531.467721859596 Test RE 0.2568578239459421\n",
      "71 Train Loss 564.66144 Test MSE 548.0834101694692 Test RE 0.26084209562110255\n",
      "72 Train Loss 557.3988 Test MSE 541.9359775516682 Test RE 0.25937513739425855\n",
      "73 Train Loss 527.2636 Test MSE 478.0050592184957 Test RE 0.24359625034693247\n",
      "74 Train Loss 489.2987 Test MSE 474.7519922995119 Test RE 0.2427659372299828\n",
      "75 Train Loss 480.52634 Test MSE 461.59497143833505 Test RE 0.23937835977513927\n",
      "76 Train Loss 466.3044 Test MSE 454.0230657141956 Test RE 0.23740688558637135\n",
      "77 Train Loss 456.58948 Test MSE 447.11172434023405 Test RE 0.23559299948029327\n",
      "78 Train Loss 441.1096 Test MSE 412.82026914849115 Test RE 0.22637833358942594\n",
      "79 Train Loss 428.75107 Test MSE 390.5711692642513 Test RE 0.22019347394836303\n",
      "80 Train Loss 419.76547 Test MSE 383.2500498782738 Test RE 0.21811998661972895\n",
      "81 Train Loss 409.46686 Test MSE 373.8855995718274 Test RE 0.2154387008629274\n",
      "82 Train Loss 378.8068 Test MSE 323.3236952023991 Test RE 0.20034251397189065\n",
      "83 Train Loss 360.705 Test MSE 314.99739099926046 Test RE 0.19774605616126265\n",
      "84 Train Loss 344.44955 Test MSE 299.6315520201018 Test RE 0.19286264753113785\n",
      "85 Train Loss 335.8642 Test MSE 292.31586600467506 Test RE 0.1904936689241054\n",
      "86 Train Loss 328.22308 Test MSE 285.7723600131688 Test RE 0.18834949627114872\n",
      "87 Train Loss 319.49405 Test MSE 276.5283816727536 Test RE 0.185278151160395\n",
      "88 Train Loss 312.68607 Test MSE 266.6492014066244 Test RE 0.18193845232241798\n",
      "89 Train Loss 297.5895 Test MSE 233.74737478727457 Test RE 0.1703443460552082\n",
      "90 Train Loss 279.12796 Test MSE 216.07177473107396 Test RE 0.1637771735710996\n",
      "91 Train Loss 266.1894 Test MSE 199.66071259045168 Test RE 0.15743477243679904\n",
      "92 Train Loss 255.3854 Test MSE 178.68700093860858 Test RE 0.14893639317235208\n",
      "93 Train Loss 239.86719 Test MSE 150.12599288061364 Test RE 0.13651560518647451\n",
      "94 Train Loss 227.51697 Test MSE 144.11700522343145 Test RE 0.13375559781543378\n",
      "95 Train Loss 218.16194 Test MSE 132.696380546998 Test RE 0.12834645889846721\n",
      "96 Train Loss 201.13608 Test MSE 115.43707575258762 Test RE 0.11970905727732871\n",
      "97 Train Loss 175.40453 Test MSE 92.42245928824511 Test RE 0.10711322925344016\n",
      "98 Train Loss 156.9821 Test MSE 59.94831820266873 Test RE 0.08626663428908808\n",
      "99 Train Loss 146.38527 Test MSE 45.34050648817187 Test RE 0.0750235371312561\n",
      "100 Train Loss 140.45177 Test MSE 34.88900706899141 Test RE 0.0658110253438797\n",
      "101 Train Loss 132.01447 Test MSE 29.886971819094953 Test RE 0.06091094107168007\n",
      "102 Train Loss 117.988884 Test MSE 19.31100604365727 Test RE 0.04896173536473233\n",
      "103 Train Loss 111.37123 Test MSE 15.117223840006854 Test RE 0.0433201921396491\n",
      "104 Train Loss 107.00562 Test MSE 15.229003039793408 Test RE 0.0434800554261681\n",
      "105 Train Loss 100.51123 Test MSE 12.85039037654798 Test RE 0.03994040946564829\n",
      "106 Train Loss 94.30663 Test MSE 7.917235895034965 Test RE 0.03135025984761439\n",
      "107 Train Loss 90.28932 Test MSE 4.6672919822719345 Test RE 0.02407059566901631\n",
      "108 Train Loss 84.849594 Test MSE 3.898623126612576 Test RE 0.02199935661013314\n",
      "109 Train Loss 80.476326 Test MSE 5.677598477431947 Test RE 0.026548298388204328\n",
      "110 Train Loss 78.31285 Test MSE 6.454696973394841 Test RE 0.02830689810172868\n",
      "111 Train Loss 75.107765 Test MSE 6.169575436393527 Test RE 0.02767464073840684\n",
      "112 Train Loss 72.198906 Test MSE 7.143954277125979 Test RE 0.029779930886577058\n",
      "113 Train Loss 69.79741 Test MSE 6.910351539774419 Test RE 0.029288991832121265\n",
      "114 Train Loss 68.31229 Test MSE 6.022907894805096 Test RE 0.027343711501590703\n",
      "115 Train Loss 66.389366 Test MSE 4.703694673444975 Test RE 0.02416428302989777\n",
      "116 Train Loss 65.035805 Test MSE 4.982082983541615 Test RE 0.024869086383433932\n",
      "117 Train Loss 63.450756 Test MSE 5.0774536773850665 Test RE 0.025105989180007664\n",
      "118 Train Loss 61.01679 Test MSE 3.4929691553577706 Test RE 0.020823404124730903\n",
      "119 Train Loss 59.036694 Test MSE 2.490155810088681 Test RE 0.017581973183292816\n",
      "120 Train Loss 56.933163 Test MSE 2.5424532595617646 Test RE 0.017765639335690024\n",
      "121 Train Loss 53.669952 Test MSE 2.1879642999866724 Test RE 0.016480655000055335\n",
      "122 Train Loss 51.82804 Test MSE 1.9589245126526675 Test RE 0.015594203692992154\n",
      "123 Train Loss 49.559113 Test MSE 1.4588426815515676 Test RE 0.013457320102261246\n",
      "124 Train Loss 48.68192 Test MSE 1.5747122447626007 Test RE 0.01398153823249359\n",
      "125 Train Loss 48.00807 Test MSE 1.604671779687129 Test RE 0.014113913773643629\n",
      "126 Train Loss 47.662273 Test MSE 1.34145541132482 Test RE 0.012904538367995997\n",
      "127 Train Loss 47.242878 Test MSE 1.2346512450761027 Test RE 0.0123801669613145\n",
      "128 Train Loss 46.81549 Test MSE 1.1714232300695935 Test RE 0.012058999257141068\n",
      "129 Train Loss 46.129524 Test MSE 0.9485098065829587 Test RE 0.010851137459375063\n",
      "130 Train Loss 44.984 Test MSE 1.0770533201222012 Test RE 0.011563064661586311\n",
      "131 Train Loss 43.53205 Test MSE 1.5836490930011462 Test RE 0.0140211562979156\n",
      "132 Train Loss 42.697712 Test MSE 1.388924705910571 Test RE 0.01313087611401424\n",
      "133 Train Loss 42.14161 Test MSE 1.1830838663775256 Test RE 0.01211886976390708\n",
      "134 Train Loss 41.67149 Test MSE 0.9709503998575932 Test RE 0.010978749470445762\n",
      "135 Train Loss 40.80377 Test MSE 0.7364743835416729 Test RE 0.009561657323647934\n",
      "136 Train Loss 40.079407 Test MSE 0.685170524024985 Test RE 0.00922260669127311\n",
      "137 Train Loss 39.066956 Test MSE 0.6323131736673105 Test RE 0.008859729599951712\n",
      "138 Train Loss 38.443882 Test MSE 0.6027338198397704 Test RE 0.00865002042035207\n",
      "139 Train Loss 37.981182 Test MSE 0.5532609665625005 Test RE 0.008287420358890615\n",
      "140 Train Loss 37.12405 Test MSE 0.4481943415010739 Test RE 0.007459119020289678\n",
      "141 Train Loss 36.139675 Test MSE 0.4114843148005323 Test RE 0.007147118699550618\n",
      "142 Train Loss 34.5187 Test MSE 0.5278062906259797 Test RE 0.008094529932412298\n",
      "143 Train Loss 33.560135 Test MSE 0.6621265990632471 Test RE 0.009066191115201547\n",
      "144 Train Loss 32.89388 Test MSE 0.754189039106602 Test RE 0.009675968827040799\n",
      "145 Train Loss 31.326756 Test MSE 0.6625995640202047 Test RE 0.009069428581593342\n",
      "146 Train Loss 30.212225 Test MSE 0.7627970532398259 Test RE 0.009731030990872932\n",
      "147 Train Loss 29.83831 Test MSE 0.9965407549367863 Test RE 0.011122486430832914\n",
      "148 Train Loss 29.480001 Test MSE 0.8968648224195335 Test RE 0.010551588536884843\n",
      "149 Train Loss 29.126083 Test MSE 0.9867811083902228 Test RE 0.011067888251709379\n",
      "150 Train Loss 28.40167 Test MSE 1.485902863578666 Test RE 0.013581557047908768\n",
      "151 Train Loss 27.960882 Test MSE 1.5450810346184423 Test RE 0.013849368889476125\n",
      "152 Train Loss 27.660091 Test MSE 1.7997029739312445 Test RE 0.01494702529577687\n",
      "153 Train Loss 27.136633 Test MSE 1.7651454604404313 Test RE 0.014802824914889294\n",
      "154 Train Loss 26.40391 Test MSE 1.1288868400503773 Test RE 0.011838033305611291\n",
      "155 Train Loss 25.995293 Test MSE 0.7886359096835669 Test RE 0.009894472060615224\n",
      "156 Train Loss 25.662518 Test MSE 0.6922192833056707 Test RE 0.00926992454345169\n",
      "157 Train Loss 25.060425 Test MSE 0.5403102076292169 Test RE 0.008189849829584747\n",
      "158 Train Loss 23.804974 Test MSE 0.33649672935987945 Test RE 0.006463158046326738\n",
      "159 Train Loss 23.128593 Test MSE 0.3926971768427733 Test RE 0.006982054619168335\n",
      "160 Train Loss 22.580687 Test MSE 0.5432196700254742 Test RE 0.008211870576662261\n",
      "161 Train Loss 22.201 Test MSE 0.5047247713952157 Test RE 0.007915560312589017\n",
      "162 Train Loss 21.90243 Test MSE 0.5783011777235452 Test RE 0.00847288653799186\n",
      "163 Train Loss 21.660978 Test MSE 0.6825275249918236 Test RE 0.009204801713010462\n",
      "164 Train Loss 21.371872 Test MSE 0.5335916368094764 Test RE 0.008138771570743504\n",
      "165 Train Loss 20.654505 Test MSE 0.407481029231013 Test RE 0.007112266959934933\n",
      "166 Train Loss 20.18252 Test MSE 0.4148232656258713 Test RE 0.00717605742472804\n",
      "167 Train Loss 20.032383 Test MSE 0.4872063118755372 Test RE 0.0077769768356357434\n",
      "168 Train Loss 19.601572 Test MSE 0.5318414291264515 Test RE 0.00812541281523625\n",
      "169 Train Loss 19.198523 Test MSE 0.5762768268582987 Test RE 0.008458043812031168\n",
      "170 Train Loss 18.719568 Test MSE 0.8772844669832679 Test RE 0.010435771764559046\n",
      "171 Train Loss 18.49432 Test MSE 0.7931681904061928 Test RE 0.00992286303208719\n",
      "172 Train Loss 18.223993 Test MSE 0.6384641789455576 Test RE 0.008902718070395436\n",
      "173 Train Loss 17.952114 Test MSE 0.7944721786833254 Test RE 0.00993101639946956\n",
      "174 Train Loss 17.6126 Test MSE 0.5864356308692881 Test RE 0.008532268762713301\n",
      "175 Train Loss 17.255543 Test MSE 0.3881533465696466 Test RE 0.0069415430243287765\n",
      "176 Train Loss 17.124863 Test MSE 0.433869893302327 Test RE 0.007338953058296147\n",
      "177 Train Loss 16.967646 Test MSE 0.4081305908481531 Test RE 0.0071179335010077786\n",
      "178 Train Loss 16.796047 Test MSE 0.38345819583344515 Test RE 0.00689943241297518\n",
      "179 Train Loss 16.656662 Test MSE 0.4398127967142627 Test RE 0.007389044516274776\n",
      "180 Train Loss 16.544428 Test MSE 0.437637118315778 Test RE 0.007370745690593917\n",
      "181 Train Loss 16.12715 Test MSE 0.3891338309320903 Test RE 0.006950304744137705\n",
      "182 Train Loss 15.7271595 Test MSE 0.4125794867854142 Test RE 0.0071566234639774025\n",
      "183 Train Loss 15.598341 Test MSE 0.4552159032002435 Test RE 0.007517320475678521\n",
      "184 Train Loss 15.512069 Test MSE 0.47042278187826253 Test RE 0.007641850290005005\n",
      "185 Train Loss 15.388156 Test MSE 0.4504077570458115 Test RE 0.0074775148307115995\n",
      "186 Train Loss 15.32293 Test MSE 0.4252441931374897 Test RE 0.007265634525614107\n",
      "187 Train Loss 15.303675 Test MSE 0.4075422050193683 Test RE 0.007112800827989849\n",
      "188 Train Loss 15.265078 Test MSE 0.4635441343463013 Test RE 0.007585773956579582\n",
      "189 Train Loss 15.147304 Test MSE 0.5797513105310036 Test RE 0.008483503080320533\n",
      "190 Train Loss 15.058038 Test MSE 0.5971159112903263 Test RE 0.008609613869451594\n",
      "191 Train Loss 14.888526 Test MSE 0.6888544967749968 Test RE 0.009247367158371222\n",
      "192 Train Loss 14.690298 Test MSE 0.5782734369754955 Test RE 0.008472683316004289\n",
      "193 Train Loss 14.549089 Test MSE 0.5444619860321385 Test RE 0.00822125528120205\n",
      "194 Train Loss 14.417931 Test MSE 0.5445918924892125 Test RE 0.008222236002057218\n",
      "195 Train Loss 14.304714 Test MSE 0.4663767583780631 Test RE 0.007608916217776606\n",
      "196 Train Loss 14.212611 Test MSE 0.39192137968677787 Test RE 0.006975154472800691\n",
      "197 Train Loss 14.155087 Test MSE 0.4131086996220922 Test RE 0.007161211868628436\n",
      "198 Train Loss 14.042486 Test MSE 0.4192661507656257 Test RE 0.007214383970110814\n",
      "199 Train Loss 13.83125 Test MSE 0.5277199083909396 Test RE 0.008093867518747345\n",
      "Training time: 29.14\n",
      "Training time: 29.14\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 16649.734 Test MSE 6721.257108441754 Test RE 0.9134391189097033\n",
      "1 Train Loss 13720.684 Test MSE 6020.326114153622 Test RE 0.8644987326034197\n",
      "2 Train Loss 10687.142 Test MSE 5157.132218340418 Test RE 0.8001261885643846\n",
      "3 Train Loss 8507.686 Test MSE 4674.982967011707 Test RE 0.7618059648176382\n",
      "4 Train Loss 7776.431 Test MSE 4790.247109331592 Test RE 0.7711401420103322\n",
      "5 Train Loss 7542.669 Test MSE 4912.454593704595 Test RE 0.7809147518544732\n",
      "6 Train Loss 7362.153 Test MSE 4983.974039493489 Test RE 0.7865788018954533\n",
      "7 Train Loss 7135.2607 Test MSE 5210.615687744387 Test RE 0.8042644522165654\n",
      "8 Train Loss 7001.8794 Test MSE 5345.612277206456 Test RE 0.8146162707369135\n",
      "9 Train Loss 6773.6934 Test MSE 5499.952659577727 Test RE 0.8262925327402999\n",
      "10 Train Loss 6592.6055 Test MSE 5442.996564638906 Test RE 0.8220029619592546\n",
      "11 Train Loss 6364.728 Test MSE 5373.208313617083 Test RE 0.8167162399256468\n",
      "12 Train Loss 6188.822 Test MSE 5130.806518041473 Test RE 0.7980813668041358\n",
      "13 Train Loss 6010.4707 Test MSE 5010.84857897188 Test RE 0.7886966423139432\n",
      "14 Train Loss 5667.9326 Test MSE 4764.298253051043 Test RE 0.7690486656398794\n",
      "15 Train Loss 5545.59 Test MSE 4629.477627788658 Test RE 0.7580892656642756\n",
      "16 Train Loss 5450.219 Test MSE 4533.947362007559 Test RE 0.7502268259890427\n",
      "17 Train Loss 5263.3374 Test MSE 4245.206981988176 Test RE 0.7259451151846253\n",
      "18 Train Loss 5178.83 Test MSE 4251.42511078371 Test RE 0.7264765814341726\n",
      "19 Train Loss 5100.116 Test MSE 4381.6557796778525 Test RE 0.7375194543735804\n",
      "20 Train Loss 4900.703 Test MSE 4258.478074869464 Test RE 0.7270789312120842\n",
      "21 Train Loss 4704.6104 Test MSE 4107.469459128976 Test RE 0.7140712105366628\n",
      "22 Train Loss 4513.1953 Test MSE 4049.255370527313 Test RE 0.7089929811240946\n",
      "23 Train Loss 4246.7407 Test MSE 4034.50118876841 Test RE 0.7077001313869262\n",
      "24 Train Loss 4143.798 Test MSE 3949.334699645479 Test RE 0.7001906754040084\n",
      "25 Train Loss 4063.4895 Test MSE 3874.303462765216 Test RE 0.6935075120697871\n",
      "26 Train Loss 3973.9734 Test MSE 3926.4164162375955 Test RE 0.6981560900770073\n",
      "27 Train Loss 3871.8604 Test MSE 3964.548265154275 Test RE 0.7015380109023919\n",
      "28 Train Loss 3790.6743 Test MSE 3811.0756437374853 Test RE 0.6878252850248869\n",
      "29 Train Loss 3623.7656 Test MSE 3593.5329320483415 Test RE 0.6679057263561257\n",
      "30 Train Loss 3502.4146 Test MSE 3411.33170041833 Test RE 0.6507532224585149\n",
      "31 Train Loss 3339.2007 Test MSE 3257.1218273364398 Test RE 0.6358744189987445\n",
      "32 Train Loss 3174.5015 Test MSE 3126.551202779071 Test RE 0.6229986779510769\n",
      "33 Train Loss 2973.1755 Test MSE 2921.5068110093257 Test RE 0.6022236460782884\n",
      "34 Train Loss 2881.15 Test MSE 2809.375774945927 Test RE 0.5905535288178806\n",
      "35 Train Loss 2753.0923 Test MSE 2394.993621446015 Test RE 0.5452636330370155\n",
      "36 Train Loss 2617.117 Test MSE 2023.4570404556475 Test RE 0.501188787595224\n",
      "37 Train Loss 2251.3862 Test MSE 1671.9005148347255 Test RE 0.45557466878895575\n",
      "38 Train Loss 2104.303 Test MSE 1756.3649498664909 Test RE 0.46694070340779337\n",
      "39 Train Loss 1981.6052 Test MSE 1712.3466694426256 Test RE 0.46105230654592944\n",
      "40 Train Loss 1810.7573 Test MSE 1653.387181491715 Test RE 0.45304530646391866\n",
      "41 Train Loss 1704.061 Test MSE 1555.249738679395 Test RE 0.43939430211751\n",
      "42 Train Loss 1589.9169 Test MSE 1475.9688892753097 Test RE 0.4280484749388065\n",
      "43 Train Loss 1447.0731 Test MSE 1310.193577929023 Test RE 0.40329430150446693\n",
      "44 Train Loss 1354.8734 Test MSE 1162.25311305844 Test RE 0.37984351082630946\n",
      "45 Train Loss 1212.5752 Test MSE 1114.848640260231 Test RE 0.3720165891553673\n",
      "46 Train Loss 1102.9291 Test MSE 921.0537750936456 Test RE 0.3381402316239549\n",
      "47 Train Loss 1015.4697 Test MSE 753.6138906546919 Test RE 0.3058643070255596\n",
      "48 Train Loss 916.2336 Test MSE 745.8631018415653 Test RE 0.30428736108487786\n",
      "49 Train Loss 857.92395 Test MSE 771.0120357411049 Test RE 0.30937479687770697\n",
      "50 Train Loss 818.0938 Test MSE 742.5798175611037 Test RE 0.3036168869727732\n",
      "51 Train Loss 759.76196 Test MSE 649.555905038709 Test RE 0.28396356507739035\n",
      "52 Train Loss 702.8908 Test MSE 583.7314705761805 Test RE 0.2691912296628014\n",
      "53 Train Loss 683.39655 Test MSE 594.5422586970991 Test RE 0.27167252342083587\n",
      "54 Train Loss 657.3589 Test MSE 527.9182806010114 Test RE 0.255998666334458\n",
      "55 Train Loss 643.82654 Test MSE 514.7205830201058 Test RE 0.2527784928387344\n",
      "56 Train Loss 620.64136 Test MSE 505.6590965568942 Test RE 0.2505435718131464\n",
      "57 Train Loss 603.85223 Test MSE 478.7369696579405 Test RE 0.24378267352254787\n",
      "58 Train Loss 588.63776 Test MSE 444.14750587749705 Test RE 0.23481074484965603\n",
      "59 Train Loss 568.9552 Test MSE 401.18117625201296 Test RE 0.2231642512328375\n",
      "60 Train Loss 550.01733 Test MSE 374.71350425371014 Test RE 0.21567709474620392\n",
      "61 Train Loss 532.55914 Test MSE 357.9653090594335 Test RE 0.21080204643877198\n",
      "62 Train Loss 519.25745 Test MSE 344.46523860202467 Test RE 0.20678881921690132\n",
      "63 Train Loss 504.5623 Test MSE 302.2732995121386 Test RE 0.19371098330648703\n",
      "64 Train Loss 498.4439 Test MSE 276.81576020280426 Test RE 0.1853744001169369\n",
      "65 Train Loss 494.59674 Test MSE 273.6939758909016 Test RE 0.18432615827299595\n",
      "66 Train Loss 488.0313 Test MSE 266.77614114977564 Test RE 0.1819817535441905\n",
      "67 Train Loss 476.73914 Test MSE 236.70825219744435 Test RE 0.1714198266971524\n",
      "68 Train Loss 456.83078 Test MSE 197.66268474425854 Test RE 0.15664505778836715\n",
      "69 Train Loss 435.32816 Test MSE 161.7715324755961 Test RE 0.14171160022171406\n",
      "70 Train Loss 398.29843 Test MSE 128.30901987444378 Test RE 0.1262068554625545\n",
      "71 Train Loss 357.6745 Test MSE 86.3380626113256 Test RE 0.10352744640129605\n",
      "72 Train Loss 334.687 Test MSE 67.22495494352621 Test RE 0.0913523265224644\n",
      "73 Train Loss 309.9077 Test MSE 68.49218674239707 Test RE 0.0922093304212099\n",
      "74 Train Loss 275.3461 Test MSE 57.03466828991307 Test RE 0.08414412766320371\n",
      "75 Train Loss 249.13121 Test MSE 67.53052986651886 Test RE 0.09155971475924253\n",
      "76 Train Loss 230.58246 Test MSE 42.924427654048856 Test RE 0.07299726840211702\n",
      "77 Train Loss 213.82913 Test MSE 27.09898891345455 Test RE 0.05800038761997027\n",
      "78 Train Loss 198.5902 Test MSE 26.05911249147352 Test RE 0.056876670151896125\n",
      "79 Train Loss 179.64432 Test MSE 16.19754003652418 Test RE 0.04484137109888512\n",
      "80 Train Loss 164.90231 Test MSE 27.62239409424037 Test RE 0.05855783490650723\n",
      "81 Train Loss 151.28743 Test MSE 40.62924516581278 Test RE 0.07101886532539771\n",
      "82 Train Loss 140.65099 Test MSE 28.212500517171478 Test RE 0.05918002473907513\n",
      "83 Train Loss 135.55272 Test MSE 27.071138925551722 Test RE 0.057970576077351496\n",
      "84 Train Loss 127.585526 Test MSE 28.939791176079638 Test RE 0.05993797259907205\n",
      "85 Train Loss 118.1925 Test MSE 19.824722834059475 Test RE 0.049608707768127994\n",
      "86 Train Loss 115.257164 Test MSE 15.955633248209956 Test RE 0.04450526332111074\n",
      "87 Train Loss 112.037544 Test MSE 15.98373541345183 Test RE 0.04454443895352379\n",
      "88 Train Loss 109.07286 Test MSE 12.174785052475526 Test RE 0.038876307048407346\n",
      "89 Train Loss 104.9562 Test MSE 11.481938140012256 Test RE 0.037753911523733065\n",
      "90 Train Loss 102.82998 Test MSE 11.905191142795779 Test RE 0.0384434662297679\n",
      "91 Train Loss 97.601074 Test MSE 8.281720740448621 Test RE 0.03206377433928076\n",
      "92 Train Loss 94.95462 Test MSE 8.990281539546501 Test RE 0.03340727087789403\n",
      "93 Train Loss 93.5562 Test MSE 11.802767675879403 Test RE 0.03827773942477905\n",
      "94 Train Loss 91.55406 Test MSE 8.11681514604599 Test RE 0.031742942326057316\n",
      "95 Train Loss 90.47047 Test MSE 5.179645954264952 Test RE 0.02535738064675068\n",
      "96 Train Loss 89.33608 Test MSE 4.604008140524502 Test RE 0.023906852044378552\n",
      "97 Train Loss 88.47855 Test MSE 5.477954267371411 Test RE 0.026077355854201296\n",
      "98 Train Loss 87.37493 Test MSE 6.145719723594944 Test RE 0.027621084564474097\n",
      "99 Train Loss 85.25726 Test MSE 4.596424353506282 Test RE 0.023887154077735097\n",
      "100 Train Loss 83.13595 Test MSE 4.1405408554892755 Test RE 0.02267163752705711\n",
      "101 Train Loss 81.58215 Test MSE 6.467649413700824 Test RE 0.02833528515543127\n",
      "102 Train Loss 81.23985 Test MSE 6.172643452329675 Test RE 0.027681520927062882\n",
      "103 Train Loss 80.93612 Test MSE 6.446852340592993 Test RE 0.028289691660287015\n",
      "104 Train Loss 80.78681 Test MSE 6.879058967083641 Test RE 0.029222601008937615\n",
      "105 Train Loss 80.33392 Test MSE 5.983806486128225 Test RE 0.02725480771801225\n",
      "106 Train Loss 78.43285 Test MSE 6.436434098232341 Test RE 0.028266824064079463\n",
      "107 Train Loss 76.88936 Test MSE 5.314696704453597 Test RE 0.02568582948202959\n",
      "108 Train Loss 75.62459 Test MSE 2.53300874814291 Test RE 0.017732611413870315\n",
      "109 Train Loss 74.94857 Test MSE 3.133320806200462 Test RE 0.019722264713315077\n",
      "110 Train Loss 74.367676 Test MSE 2.819638748979362 Test RE 0.01870902207728563\n",
      "111 Train Loss 73.18656 Test MSE 2.9297613585282787 Test RE 0.019070868681331097\n",
      "112 Train Loss 71.268616 Test MSE 6.912309214711326 Test RE 0.029293140265421114\n",
      "113 Train Loss 69.737305 Test MSE 4.749839064689801 Test RE 0.024282522501352224\n",
      "114 Train Loss 69.20124 Test MSE 3.2197550140083613 Test RE 0.019992438394595666\n",
      "115 Train Loss 67.29309 Test MSE 3.1953614180721677 Test RE 0.019916560775740857\n",
      "116 Train Loss 65.480705 Test MSE 3.86077656106567 Test RE 0.021892314894968515\n",
      "117 Train Loss 64.677826 Test MSE 2.94512851100349 Test RE 0.019120818424728805\n",
      "118 Train Loss 63.79376 Test MSE 2.8176000189685912 Test RE 0.018702257107479595\n",
      "119 Train Loss 62.644173 Test MSE 1.9696973448278157 Test RE 0.015637023976922154\n",
      "120 Train Loss 60.45327 Test MSE 2.6777699769730727 Test RE 0.018232280188218243\n",
      "121 Train Loss 59.153145 Test MSE 4.756792937942765 Test RE 0.02430029108506565\n",
      "122 Train Loss 57.020294 Test MSE 3.205428521156932 Test RE 0.0199479100302092\n",
      "123 Train Loss 51.621803 Test MSE 4.5817737402087495 Test RE 0.023849054813853826\n",
      "124 Train Loss 48.374836 Test MSE 7.947006983561159 Test RE 0.03140914754659502\n",
      "125 Train Loss 44.948254 Test MSE 5.286850624978743 Test RE 0.02561845132013162\n",
      "126 Train Loss 43.132923 Test MSE 5.258414614116838 Test RE 0.02554946234920863\n",
      "127 Train Loss 41.473244 Test MSE 6.909220683501453 Test RE 0.029286595210536653\n",
      "128 Train Loss 37.82953 Test MSE 5.769767297660941 Test RE 0.026762920331263446\n",
      "129 Train Loss 36.532063 Test MSE 4.595980576561185 Test RE 0.023886000917873487\n",
      "130 Train Loss 34.81526 Test MSE 4.076279812108846 Test RE 0.022495018070813225\n",
      "131 Train Loss 33.25559 Test MSE 3.5643318102664794 Test RE 0.021035043555586667\n",
      "132 Train Loss 31.617332 Test MSE 2.5415642021084603 Test RE 0.017762532876399995\n",
      "133 Train Loss 29.711748 Test MSE 1.199441233287876 Test RE 0.012202360168671048\n",
      "134 Train Loss 28.99262 Test MSE 1.6290181210207106 Test RE 0.01422058000548557\n",
      "135 Train Loss 28.89845 Test MSE 1.72714160437702 Test RE 0.014642604268138739\n",
      "136 Train Loss 28.274906 Test MSE 1.0632939382986224 Test RE 0.011488968041144357\n",
      "137 Train Loss 26.833143 Test MSE 0.5852676303734433 Test RE 0.008523767692244168\n",
      "138 Train Loss 26.062136 Test MSE 0.6569186481830178 Test RE 0.009030465704223249\n",
      "139 Train Loss 25.465433 Test MSE 0.932527052625439 Test RE 0.010759326138641587\n",
      "140 Train Loss 25.088715 Test MSE 1.1094715904632015 Test RE 0.011735793126662484\n",
      "141 Train Loss 24.621712 Test MSE 0.9538873250538061 Test RE 0.010881853915486493\n",
      "142 Train Loss 24.21913 Test MSE 0.8887190006745194 Test RE 0.010503561558356463\n",
      "143 Train Loss 23.763075 Test MSE 0.891773348625761 Test RE 0.010521595388244735\n",
      "144 Train Loss 23.499994 Test MSE 0.600745251154118 Test RE 0.008635739347721293\n",
      "145 Train Loss 23.440247 Test MSE 0.6193037042208355 Test RE 0.008768114069644816\n",
      "146 Train Loss 23.333822 Test MSE 0.7020343105953488 Test RE 0.00933541268559715\n",
      "147 Train Loss 23.015165 Test MSE 0.5329377439628888 Test RE 0.008133783190514205\n",
      "148 Train Loss 22.244852 Test MSE 0.37109729495513893 Test RE 0.006787318772122371\n",
      "149 Train Loss 21.90205 Test MSE 0.4533244671384022 Test RE 0.007501686870494289\n",
      "150 Train Loss 21.725098 Test MSE 0.37561512121622953 Test RE 0.006828508998702591\n",
      "151 Train Loss 21.53501 Test MSE 0.43765126689739536 Test RE 0.007370864835828359\n",
      "152 Train Loss 21.391413 Test MSE 0.3956502464518011 Test RE 0.007008257857934301\n",
      "153 Train Loss 20.83562 Test MSE 0.11762131827705116 Test RE 0.00382117892350965\n",
      "154 Train Loss 20.468775 Test MSE 0.20482511317137841 Test RE 0.00504250054814835\n",
      "155 Train Loss 20.10778 Test MSE 0.32794829182361607 Test RE 0.0063805341716327395\n",
      "156 Train Loss 19.74021 Test MSE 0.29000207792660826 Test RE 0.006000050521148091\n",
      "157 Train Loss 19.502148 Test MSE 0.24523213877349076 Test RE 0.005517508936686332\n",
      "158 Train Loss 19.327923 Test MSE 0.11320721836695387 Test RE 0.0037487925834464855\n",
      "159 Train Loss 19.228945 Test MSE 0.1159902011638244 Test RE 0.003794591269519187\n",
      "160 Train Loss 19.16189 Test MSE 0.1900157330260919 Test RE 0.004856787845906012\n",
      "161 Train Loss 19.024904 Test MSE 0.2601749136628658 Test RE 0.005683123082610941\n",
      "162 Train Loss 18.81303 Test MSE 0.2127767825764587 Test RE 0.005139447938897813\n",
      "163 Train Loss 18.707027 Test MSE 0.22825004961384565 Test RE 0.005323040771698469\n",
      "164 Train Loss 18.630167 Test MSE 0.3010307010056653 Test RE 0.0061130753269891735\n",
      "165 Train Loss 18.58354 Test MSE 0.3545591850658856 Test RE 0.006634355244215152\n",
      "166 Train Loss 18.507038 Test MSE 0.49027570152795763 Test RE 0.007801435769747365\n",
      "167 Train Loss 18.420519 Test MSE 0.4442062052584408 Test RE 0.007425858387220597\n",
      "168 Train Loss 18.27242 Test MSE 0.3934798095617329 Test RE 0.0069890086601407195\n",
      "169 Train Loss 18.067436 Test MSE 0.4326641652954382 Test RE 0.007328748458200075\n",
      "170 Train Loss 17.901402 Test MSE 0.40344345395167136 Test RE 0.007076942858217897\n",
      "171 Train Loss 17.813751 Test MSE 0.36574438317007196 Test RE 0.006738188947431274\n",
      "172 Train Loss 17.769436 Test MSE 0.34474647204457676 Test RE 0.006541905519693147\n",
      "173 Train Loss 17.711372 Test MSE 0.26408628031823245 Test RE 0.005725682634757564\n",
      "174 Train Loss 17.642334 Test MSE 0.23023980383192807 Test RE 0.005346192048445062\n",
      "175 Train Loss 17.577883 Test MSE 0.23455574518670175 Test RE 0.005396067700906256\n",
      "176 Train Loss 17.484787 Test MSE 0.1873741599395839 Test RE 0.004822910489512027\n",
      "177 Train Loss 17.240843 Test MSE 0.08614313919999461 Test RE 0.0032701276022913494\n",
      "178 Train Loss 16.863495 Test MSE 0.11658452547205533 Test RE 0.0038043004358898074\n",
      "179 Train Loss 16.638062 Test MSE 0.17318534566449317 Test RE 0.004636709878829609\n",
      "180 Train Loss 16.572622 Test MSE 0.22429899084878116 Test RE 0.0052767681445423315\n",
      "181 Train Loss 16.477024 Test MSE 0.20789627555175752 Test RE 0.005080163699179912\n",
      "182 Train Loss 16.392794 Test MSE 0.23398907756562476 Test RE 0.005389545528716052\n",
      "183 Train Loss 16.248724 Test MSE 0.2576453988812501 Test RE 0.005655428914107416\n",
      "184 Train Loss 16.055056 Test MSE 0.22576271639534515 Test RE 0.005293957656632341\n",
      "185 Train Loss 15.91073 Test MSE 0.22938019768543166 Test RE 0.005336202644006052\n",
      "186 Train Loss 15.664913 Test MSE 0.26591384467945856 Test RE 0.005745460285094167\n",
      "187 Train Loss 15.314471 Test MSE 0.2542314613265783 Test RE 0.005617835255460654\n",
      "188 Train Loss 14.987577 Test MSE 0.2607872089357988 Test RE 0.0056898064796499235\n",
      "189 Train Loss 14.703904 Test MSE 0.2044529498374309 Test RE 0.005037917401546667\n",
      "190 Train Loss 14.44869 Test MSE 0.13874218151467965 Test RE 0.004150100480308374\n",
      "191 Train Loss 14.26517 Test MSE 0.12243640741000804 Test RE 0.0038986086430092114\n",
      "192 Train Loss 14.134028 Test MSE 0.1208855834463484 Test RE 0.003873839363019916\n",
      "193 Train Loss 14.0114155 Test MSE 0.12019534649283041 Test RE 0.0038627640355243815\n",
      "194 Train Loss 13.97457 Test MSE 0.14226126128749098 Test RE 0.0042024028252163675\n",
      "195 Train Loss 13.939634 Test MSE 0.13222303316027742 Test RE 0.0040514259931552846\n",
      "196 Train Loss 13.890675 Test MSE 0.08912956790205663 Test RE 0.0033263293887364977\n",
      "197 Train Loss 13.844389 Test MSE 0.07141912834918433 Test RE 0.0029775675655565937\n",
      "198 Train Loss 13.807664 Test MSE 0.06337657052985822 Test RE 0.0028049086366634286\n",
      "199 Train Loss 13.713462 Test MSE 0.06131705882436227 Test RE 0.0027589574959379567\n",
      "Training time: 29.17\n",
      "Training time: 29.17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 18716.719 Test MSE 10766.947366380227 Test RE 1.1561139655134378\n",
      "1 Train Loss 14837.837 Test MSE 7250.816110061876 Test RE 0.9487412812789695\n",
      "2 Train Loss 11867.156 Test MSE 6362.466169338056 Test RE 0.8887243825701215\n",
      "3 Train Loss 10140.01 Test MSE 6067.127752811548 Test RE 0.8678525067521652\n",
      "4 Train Loss 9352.557 Test MSE 5204.03703095917 Test RE 0.8037565802876002\n",
      "5 Train Loss 9171.015 Test MSE 4885.301744985684 Test RE 0.7787535673050644\n",
      "6 Train Loss 9077.265 Test MSE 4793.667347038851 Test RE 0.7714153900203283\n",
      "7 Train Loss 9024.711 Test MSE 4664.692577222893 Test RE 0.7609670741724271\n",
      "8 Train Loss 8859.228 Test MSE 4482.35624600484 Test RE 0.7459462541428687\n",
      "9 Train Loss 8540.753 Test MSE 4173.538948973766 Test RE 0.7197912911697748\n",
      "10 Train Loss 8178.737 Test MSE 3909.4588876021276 Test RE 0.6966468497197986\n",
      "11 Train Loss 7888.0273 Test MSE 3785.262615421124 Test RE 0.6854919516580171\n",
      "12 Train Loss 7690.0654 Test MSE 3651.2656828666127 Test RE 0.6732495472547299\n",
      "13 Train Loss 7627.2773 Test MSE 3572.8502717523916 Test RE 0.6659808794559939\n",
      "14 Train Loss 7549.443 Test MSE 3465.207337374618 Test RE 0.6558718101522285\n",
      "15 Train Loss 7509.313 Test MSE 3360.6770471385935 Test RE 0.6459036552350399\n",
      "16 Train Loss 7484.475 Test MSE 3233.2722298108188 Test RE 0.6335421125699622\n",
      "17 Train Loss 7458.922 Test MSE 3124.203291250839 Test RE 0.6227647108093597\n",
      "18 Train Loss 7440.3896 Test MSE 3127.364567289066 Test RE 0.62307970845882\n",
      "19 Train Loss 7424.2837 Test MSE 3093.7549310808113 Test RE 0.619722560525741\n",
      "20 Train Loss 7411.3594 Test MSE 2989.018250745607 Test RE 0.6091421274468072\n",
      "21 Train Loss 7396.435 Test MSE 2870.5928562158238 Test RE 0.5969530180314062\n",
      "22 Train Loss 7387.2407 Test MSE 2852.415245456876 Test RE 0.5950599574108731\n",
      "23 Train Loss 7380.7563 Test MSE 2802.79463381079 Test RE 0.5898614186829089\n",
      "24 Train Loss 7376.459 Test MSE 2808.6154720289132 Test RE 0.5904736124967926\n",
      "25 Train Loss 7374.066 Test MSE 2822.2012590026675 Test RE 0.5919000041042497\n",
      "26 Train Loss 7372.457 Test MSE 2792.4747911483537 Test RE 0.5887744873372631\n",
      "27 Train Loss 7370.94 Test MSE 2779.968530609805 Test RE 0.5874545774869634\n",
      "28 Train Loss 7370.075 Test MSE 2776.3532393215814 Test RE 0.5870724669814079\n",
      "29 Train Loss 7369.0903 Test MSE 2757.4857061029043 Test RE 0.585074253654445\n",
      "30 Train Loss 7368.623 Test MSE 2756.6912595133176 Test RE 0.5849899660500063\n",
      "31 Train Loss 7368.106 Test MSE 2749.0676981490374 Test RE 0.5841805184085119\n",
      "32 Train Loss 7367.7847 Test MSE 2746.362229361721 Test RE 0.5838929898028408\n",
      "33 Train Loss 7367.3745 Test MSE 2766.749408756023 Test RE 0.5860562006297239\n",
      "34 Train Loss 7366.6924 Test MSE 2772.6507447003155 Test RE 0.5866808817566898\n",
      "35 Train Loss 7366.0996 Test MSE 2761.3280760701996 Test RE 0.5854817424669971\n",
      "36 Train Loss 7365.2246 Test MSE 2773.625955180856 Test RE 0.5867840478416745\n",
      "37 Train Loss 7364.898 Test MSE 2765.6452192752686 Test RE 0.5859392435848193\n",
      "38 Train Loss 7364.463 Test MSE 2748.7753802545 Test RE 0.5841494586133906\n",
      "39 Train Loss 7363.79 Test MSE 2739.5209482510913 Test RE 0.5831652877542394\n",
      "40 Train Loss 7363.513 Test MSE 2739.1200262991442 Test RE 0.5831226138114838\n",
      "41 Train Loss 7363.221 Test MSE 2735.351295453001 Test RE 0.5827213191243641\n",
      "42 Train Loss 7362.744 Test MSE 2741.7581030875103 Test RE 0.5834033521511641\n",
      "43 Train Loss 7362.393 Test MSE 2757.911665565496 Test RE 0.585119441248789\n",
      "44 Train Loss 7362.075 Test MSE 2759.5390462702903 Test RE 0.5852920486010025\n",
      "45 Train Loss 7361.689 Test MSE 2764.4077024314956 Test RE 0.5858081365991985\n",
      "46 Train Loss 7361.4453 Test MSE 2768.478907299743 Test RE 0.5862393442483241\n",
      "47 Train Loss 7361.0923 Test MSE 2761.1654758103 Test RE 0.5854645042246802\n",
      "48 Train Loss 7361.003 Test MSE 2759.6387446109643 Test RE 0.5853026214028431\n",
      "49 Train Loss 7360.733 Test MSE 2768.438453392706 Test RE 0.5862350610734537\n",
      "50 Train Loss 7360.62 Test MSE 2769.7432784281596 Test RE 0.5863731974427365\n",
      "51 Train Loss 7360.5264 Test MSE 2767.3855671574333 Test RE 0.5861235726776105\n",
      "52 Train Loss 7360.4326 Test MSE 2772.647682299095 Test RE 0.5866805577611869\n",
      "53 Train Loss 7360.3555 Test MSE 2776.5959824058787 Test RE 0.5870981309827517\n",
      "54 Train Loss 7360.144 Test MSE 2768.4995879136136 Test RE 0.5862415338562783\n",
      "55 Train Loss 7359.8423 Test MSE 2766.3619047313114 Test RE 0.5860151584073918\n",
      "56 Train Loss 7359.619 Test MSE 2769.232087736404 Test RE 0.5863190836996648\n",
      "57 Train Loss 7359.54 Test MSE 2764.9256581190593 Test RE 0.585863014257887\n",
      "58 Train Loss 7359.4277 Test MSE 2770.2131769542875 Test RE 0.5864229356653947\n",
      "59 Train Loss 7359.255 Test MSE 2772.9687191749767 Test RE 0.5867145218026535\n",
      "60 Train Loss 7359.114 Test MSE 2765.8301473317297 Test RE 0.5859588330089216\n",
      "61 Train Loss 7359.042 Test MSE 2763.1356811014066 Test RE 0.5856733434961128\n",
      "62 Train Loss 7358.9087 Test MSE 2756.3543186461734 Test RE 0.5849542143043135\n",
      "63 Train Loss 7358.746 Test MSE 2751.5655963036425 Test RE 0.5844458614764797\n",
      "64 Train Loss 7358.701 Test MSE 2753.8466006426474 Test RE 0.5846880594777938\n",
      "65 Train Loss 7358.6313 Test MSE 2757.8838890666666 Test RE 0.5851164947058303\n",
      "66 Train Loss 7358.6064 Test MSE 2760.97743429573 Test RE 0.585444568167334\n",
      "67 Train Loss 7358.5073 Test MSE 2765.085677709903 Test RE 0.5858799673725505\n",
      "68 Train Loss 7358.239 Test MSE 2765.9421945271642 Test RE 0.5859707018467484\n",
      "69 Train Loss 7358.0645 Test MSE 2767.4086347511998 Test RE 0.5861260154944801\n",
      "70 Train Loss 7357.8584 Test MSE 2765.8393160390638 Test RE 0.5859598042328057\n",
      "71 Train Loss 7357.4453 Test MSE 2759.170432636947 Test RE 0.5852529562326368\n",
      "72 Train Loss 7356.813 Test MSE 2769.2156935877592 Test RE 0.5863173481614121\n",
      "73 Train Loss 7356.01 Test MSE 2765.9723224953113 Test RE 0.5859738931749332\n",
      "74 Train Loss 7355.439 Test MSE 2768.465183324291 Test RE 0.5862378911860812\n",
      "75 Train Loss 7355.1577 Test MSE 2766.172188684316 Test RE 0.585995063714554\n",
      "76 Train Loss 7354.7524 Test MSE 2756.8818172649476 Test RE 0.5850101845721037\n",
      "77 Train Loss 7354.2446 Test MSE 2759.7321302626374 Test RE 0.5853125245839076\n",
      "78 Train Loss 7352.4165 Test MSE 2779.008248399346 Test RE 0.5873531067511473\n",
      "79 Train Loss 7350.5586 Test MSE 2779.539844602545 Test RE 0.5874092814226798\n",
      "80 Train Loss 7346.0547 Test MSE 2786.7804440590394 Test RE 0.5881738736409542\n",
      "81 Train Loss 7338.695 Test MSE 2856.963282378071 Test RE 0.5955341654933937\n",
      "82 Train Loss 7335.6475 Test MSE 2874.725845107438 Test RE 0.5973826005088545\n",
      "83 Train Loss 7333.11 Test MSE 2876.822507731097 Test RE 0.5976004093615528\n",
      "84 Train Loss 7331.2886 Test MSE 2889.878276169685 Test RE 0.5989549073442422\n",
      "85 Train Loss 7330.6953 Test MSE 2912.128051392791 Test RE 0.6012562255952177\n",
      "86 Train Loss 7330.2046 Test MSE 2935.3314091878324 Test RE 0.603646828464389\n",
      "87 Train Loss 7329.8213 Test MSE 2937.2297629888853 Test RE 0.6038419938265027\n",
      "88 Train Loss 7329.5703 Test MSE 2927.027718816907 Test RE 0.6027924025727063\n",
      "89 Train Loss 7329.3706 Test MSE 2935.364541573315 Test RE 0.6036502352693099\n",
      "90 Train Loss 7329.0566 Test MSE 2939.1191622644465 Test RE 0.6040361759816991\n",
      "91 Train Loss 7328.8687 Test MSE 2933.359183172221 Test RE 0.6034440016184306\n",
      "92 Train Loss 7328.6475 Test MSE 2944.3142131583554 Test RE 0.6045697734783767\n",
      "93 Train Loss 7328.5767 Test MSE 2951.1765297802535 Test RE 0.6052738991838512\n",
      "94 Train Loss 7328.5483 Test MSE 2952.4517304402502 Test RE 0.6054046542077356\n",
      "95 Train Loss 7328.5015 Test MSE 2958.633498930228 Test RE 0.6060381132498822\n",
      "96 Train Loss 7328.4087 Test MSE 2966.0183485873863 Test RE 0.606793987724406\n",
      "97 Train Loss 7328.2427 Test MSE 2957.6985402812147 Test RE 0.605942348541719\n",
      "98 Train Loss 7328.1543 Test MSE 2947.6462310999177 Test RE 0.604911766143666\n",
      "99 Train Loss 7328.1294 Test MSE 2950.6733273469686 Test RE 0.6052222946322223\n",
      "100 Train Loss 7328.1035 Test MSE 2952.369665050626 Test RE 0.6053962403336725\n",
      "101 Train Loss 7328.0557 Test MSE 2950.721298374726 Test RE 0.605227214359734\n",
      "102 Train Loss 7327.9897 Test MSE 2953.43906454734 Test RE 0.6055058729157948\n",
      "103 Train Loss 7327.954 Test MSE 2952.3629868035623 Test RE 0.6053955556314824\n",
      "104 Train Loss 7327.901 Test MSE 2949.0256818693697 Test RE 0.605053294049641\n",
      "105 Train Loss 7327.7935 Test MSE 2955.515751241165 Test RE 0.6057187137767004\n",
      "106 Train Loss 7327.7617 Test MSE 2954.0528520749463 Test RE 0.6055687881541449\n",
      "107 Train Loss 7327.7065 Test MSE 2949.530618699335 Test RE 0.6051050909223541\n",
      "108 Train Loss 7327.6475 Test MSE 2957.6558309612374 Test RE 0.6059379736064908\n",
      "109 Train Loss 7327.596 Test MSE 2961.82948331745 Test RE 0.6063653530994827\n",
      "110 Train Loss 7327.5264 Test MSE 2961.1106851421005 Test RE 0.6062917700726516\n",
      "111 Train Loss 7327.4683 Test MSE 2961.6429906758876 Test RE 0.6063462627944506\n",
      "112 Train Loss 7327.3613 Test MSE 2968.735664037665 Test RE 0.6070718810158169\n",
      "113 Train Loss 7327.27 Test MSE 2968.8801912464505 Test RE 0.6070866579017722\n",
      "114 Train Loss 7327.1963 Test MSE 2965.13076339122 Test RE 0.6067031889503993\n",
      "115 Train Loss 7327.144 Test MSE 2965.1592480992517 Test RE 0.6067061031088419\n",
      "116 Train Loss 7327.086 Test MSE 2965.87884261334 Test RE 0.606779717350496\n",
      "117 Train Loss 7327.002 Test MSE 2971.6896687251915 Test RE 0.6073738357043079\n",
      "118 Train Loss 7326.9385 Test MSE 2978.9915593404917 Test RE 0.6081195825343222\n",
      "119 Train Loss 7326.876 Test MSE 2978.901300486524 Test RE 0.6081103699213851\n",
      "120 Train Loss 7326.8096 Test MSE 2972.2669714805443 Test RE 0.6074328293409591\n",
      "121 Train Loss 7326.7236 Test MSE 2976.8429749176307 Test RE 0.6079002412043076\n",
      "122 Train Loss 7326.6836 Test MSE 2982.4283097668404 Test RE 0.6084702637572638\n",
      "123 Train Loss 7326.6235 Test MSE 2974.1315764751134 Test RE 0.6076233311903582\n",
      "124 Train Loss 7326.5977 Test MSE 2973.6531967483966 Test RE 0.6075744620725814\n",
      "125 Train Loss 7326.5786 Test MSE 2973.36399946754 Test RE 0.6075449170747295\n",
      "126 Train Loss 7326.537 Test MSE 2971.5744449811714 Test RE 0.6073620604899399\n",
      "127 Train Loss 7326.4595 Test MSE 2975.9405235125637 Test RE 0.6078080895497215\n",
      "128 Train Loss 7326.3984 Test MSE 2983.062907448464 Test RE 0.6085349951171694\n",
      "129 Train Loss 7326.305 Test MSE 2983.9786402711734 Test RE 0.6086283911879935\n",
      "130 Train Loss 7326.219 Test MSE 2984.9383120922867 Test RE 0.6087262532428213\n",
      "131 Train Loss 7326.17 Test MSE 2983.9292613442085 Test RE 0.6086233553709127\n",
      "132 Train Loss 7326.1465 Test MSE 2985.8493490814817 Test RE 0.6088191412301182\n",
      "133 Train Loss 7326.066 Test MSE 2986.335550864706 Test RE 0.6088687078472382\n",
      "134 Train Loss 7325.9463 Test MSE 2976.9004975435014 Test RE 0.6079061145153141\n",
      "135 Train Loss 7325.813 Test MSE 2979.3408868586394 Test RE 0.6081552366597153\n",
      "136 Train Loss 7325.7095 Test MSE 2976.4579930592176 Test RE 0.607860931416458\n",
      "137 Train Loss 7325.6636 Test MSE 2975.956038668863 Test RE 0.6078096739606236\n",
      "138 Train Loss 7325.614 Test MSE 2975.8705878372807 Test RE 0.6078009476531367\n",
      "139 Train Loss 7325.566 Test MSE 2975.020006873428 Test RE 0.6077140788112707\n",
      "140 Train Loss 7325.521 Test MSE 2979.4801017986065 Test RE 0.6081694450549573\n",
      "141 Train Loss 7325.492 Test MSE 2981.3841429730473 Test RE 0.6083637398113909\n",
      "142 Train Loss 7325.4585 Test MSE 2983.7111310539944 Test RE 0.6086011092645495\n",
      "143 Train Loss 7325.458 Test MSE 2983.7810400272206 Test RE 0.6086082390481592\n",
      "144 Train Loss 7325.4424 Test MSE 2983.422419409816 Test RE 0.6085716636396319\n",
      "145 Train Loss 7325.4287 Test MSE 2980.9668164833242 Test RE 0.6083211597249203\n",
      "146 Train Loss 7325.4263 Test MSE 2979.727868703389 Test RE 0.6081947315350352\n",
      "147 Train Loss 7325.425 Test MSE 2979.5631132278645 Test RE 0.6081779171140925\n",
      "148 Train Loss 7325.4233 Test MSE 2979.4709993511074 Test RE 0.608168516061562\n",
      "149 Train Loss 7325.423 Test MSE 2979.4370493028873 Test RE 0.6081650511160618\n",
      "150 Train Loss 7325.4165 Test MSE 2979.966408417474 Test RE 0.6082190753174775\n",
      "151 Train Loss 7325.4126 Test MSE 2980.9409385542394 Test RE 0.6083185192852634\n",
      "152 Train Loss 7325.4106 Test MSE 2981.6506209256313 Test RE 0.6083909271669451\n",
      "153 Train Loss 7325.409 Test MSE 2982.374229585451 Test RE 0.608464747056108\n",
      "154 Train Loss 7325.407 Test MSE 2982.940200372356 Test RE 0.6085224790690353\n",
      "155 Train Loss 7325.406 Test MSE 2983.3559886092144 Test RE 0.6085648881780635\n",
      "156 Train Loss 7325.399 Test MSE 2983.327031074825 Test RE 0.6085619346952227\n",
      "157 Train Loss 7325.38 Test MSE 2979.764481832187 Test RE 0.6081984680916299\n",
      "158 Train Loss 7325.3154 Test MSE 2976.5027095588794 Test RE 0.6078654974662911\n",
      "159 Train Loss 7325.2563 Test MSE 2976.1838970779827 Test RE 0.6078329424317719\n",
      "160 Train Loss 7325.2275 Test MSE 2978.298763814126 Test RE 0.6080488661500519\n",
      "161 Train Loss 7325.2114 Test MSE 2981.065010324043 Test RE 0.6083311787729072\n",
      "162 Train Loss 7325.194 Test MSE 2982.1630761975584 Test RE 0.6084432068909505\n",
      "163 Train Loss 7325.1846 Test MSE 2983.3164114404785 Test RE 0.608560851557017\n",
      "164 Train Loss 7325.171 Test MSE 2987.500113721554 Test RE 0.6089874146629566\n",
      "165 Train Loss 7325.155 Test MSE 2986.8369642507637 Test RE 0.6089198210094052\n",
      "166 Train Loss 7325.1367 Test MSE 2983.255018933506 Test RE 0.6085545898563824\n",
      "167 Train Loss 7325.0786 Test MSE 2982.600903492281 Test RE 0.6084878696507543\n",
      "168 Train Loss 7325.048 Test MSE 2983.815894221283 Test RE 0.6086117936802585\n",
      "169 Train Loss 7324.975 Test MSE 2979.9137664764175 Test RE 0.6082137031136126\n",
      "170 Train Loss 7324.3994 Test MSE 2984.2799537467317 Test RE 0.6086591191738\n",
      "171 Train Loss 6959.156 Test MSE 2268.8680290256366 Test RE 0.530712076305123\n",
      "172 Train Loss 6354.4355 Test MSE 1926.445719866231 Test RE 0.48902689053966125\n",
      "173 Train Loss 5849.314 Test MSE 1535.697341546868 Test RE 0.43662356226289767\n",
      "174 Train Loss 5696.1304 Test MSE 1436.13036327337 Test RE 0.4222321362189955\n",
      "175 Train Loss 5629.901 Test MSE 1364.5844111610454 Test RE 0.41158027705019823\n",
      "176 Train Loss 5590.2446 Test MSE 1383.37545008365 Test RE 0.41440442531363536\n",
      "177 Train Loss 5570.9697 Test MSE 1389.5825498661109 Test RE 0.41533308524517654\n",
      "178 Train Loss 5555.0396 Test MSE 1337.1121447437363 Test RE 0.40741617683555004\n",
      "179 Train Loss 5538.1953 Test MSE 1308.8469889237492 Test RE 0.40308699958642613\n",
      "180 Train Loss 5525.704 Test MSE 1258.9643723214745 Test RE 0.39533118331913614\n",
      "181 Train Loss 5505.7373 Test MSE 1181.3350236232134 Test RE 0.38294895813002255\n",
      "182 Train Loss 5488.126 Test MSE 1161.916760178957 Test RE 0.37978854401143247\n",
      "183 Train Loss 5459.272 Test MSE 1113.1516396888996 Test RE 0.3717333431758879\n",
      "184 Train Loss 5441.4043 Test MSE 1121.2058225189503 Test RE 0.3730757532926655\n",
      "185 Train Loss 5412.942 Test MSE 1131.8955895943272 Test RE 0.37485001814299795\n",
      "186 Train Loss 5399.142 Test MSE 1102.53260655336 Test RE 0.36995599856159467\n",
      "187 Train Loss 5382.13 Test MSE 1101.8595921682863 Test RE 0.36984306597537236\n",
      "188 Train Loss 5364.2524 Test MSE 1082.1929205161873 Test RE 0.3665276113749052\n",
      "189 Train Loss 5350.0854 Test MSE 1088.3939560883746 Test RE 0.3675762248488686\n",
      "190 Train Loss 5343.7734 Test MSE 1118.9578856731628 Test RE 0.37270157065120396\n",
      "191 Train Loss 5338.81 Test MSE 1124.7776273243435 Test RE 0.37366953106107575\n",
      "192 Train Loss 5333.928 Test MSE 1136.4658567544268 Test RE 0.37560602378083874\n",
      "193 Train Loss 5331.8696 Test MSE 1139.9702685025122 Test RE 0.3761846883291821\n",
      "194 Train Loss 5329.284 Test MSE 1122.5532638216716 Test RE 0.3732998632316166\n",
      "195 Train Loss 5323.7397 Test MSE 1131.7018350085448 Test RE 0.3748179339035014\n",
      "196 Train Loss 5321.971 Test MSE 1130.3209384390514 Test RE 0.3745891886774831\n",
      "197 Train Loss 5320.2456 Test MSE 1104.5269197874804 Test RE 0.37029044436184655\n",
      "198 Train Loss 5318.7266 Test MSE 1101.3463933746334 Test RE 0.3697569274499574\n",
      "199 Train Loss 5316.978 Test MSE 1097.9169864718604 Test RE 0.36918079825576033\n",
      "Training time: 27.85\n",
      "Training time: 27.85\n"
     ]
    }
   ],
   "source": [
    " \n",
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers)\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "e199619a-d416-48f4-91f7-2c23d1e79435"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13157/2488343543.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_tanh_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_FODE_tanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
