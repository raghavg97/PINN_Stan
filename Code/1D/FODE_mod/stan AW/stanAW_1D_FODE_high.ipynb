{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "3df10486-4078-44cd-95da-12a75fb13c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "515a82ba-2a23-4124-c9e1-230f67f43912"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "d35a8c58-7c75-4550-d489-9565724f04e6"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "7b44eee8-32ab-4621-ca04-81e30b53601d"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"high\"\n",
    "label = \"1D_FODE_tanhAW_\" +level\n",
    "extent = 100.0\n",
    "\n",
    "x = np.linspace(extent,-1.0*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "            \n",
    "        self.m_lambda = nn.Sigmoid()    \n",
    "        self.lambdas_bc1 = Parameter(torch.ones(1,1))\n",
    "        self.lambdas_bc1.requiresGrad = True\n",
    "        \n",
    "        self.lambdas_f = Parameter(torch.ones(N_f+1,1))\n",
    "        self.lambdas_f.requiresGrad = True\n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "             \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) + self.beta[:,i]*z*self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y,lambda_ind):\n",
    "        m = self.m_lambda(self.lambdas_bc1)\n",
    "        u_pred = self.forward(x)\n",
    "        \n",
    "        if(lambda_ind):\n",
    "            u_pred = u_pred.detach()\n",
    "        else:\n",
    "            m = m.detach()\n",
    "            \n",
    "        loss_bc1 = torch.sum(m*torch.square(u_pred - y))/2.0\n",
    "                \n",
    "        # loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat,lambda_ind):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        m = self.m_lambda(self.lambdas_f)\n",
    "        \n",
    "        if(lambda_ind):\n",
    "            f = f.detach()\n",
    "        else:\n",
    "            m = m.detach()\n",
    "        \n",
    "        #loss_f  = torch.sum(m*(torch.square(f)))/2.0\n",
    "        loss_f = self.loss_function(m*(torch.square(f)),f_hat)/2.0\n",
    "        \n",
    "        # loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        lambda_ind = False\n",
    "        \n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1,lambda_ind)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat,lambda_ind)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100.0*loss_f\n",
    "        return loss_val\n",
    "    \n",
    "    def loss_lambdas(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        lambda_ind = True        \n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1,lambda_ind)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat,lambda_ind)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100.0*loss_f\n",
    "        \n",
    "        return -1.0*loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    for i in range(20):\n",
    "        optimizer_lambda.zero_grad()\n",
    "        loss = PINN.loss_lambdas(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        optimizer_lambda.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fAcpqTqePPt9"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    x_coll_np_array = colloc_pts(N_f,123)\n",
    "    x_coll = torch.from_numpy(x_coll_np_array).float().to(device)\n",
    "\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "    loss_np = 0\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np)==False):\n",
    "            train_step(i)        \n",
    "    \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "3645d237-1d2a-45c9-8d9f-de486f1ca919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "0\n",
      "0 Train Loss 585607000.0 Test MSE 824007.504257929 Test RE 0.4057442809571158\n",
      "1 Train Loss 403490660.0 Test MSE 1059289.2429912474 Test RE 0.46003842158357616\n",
      "2 Train Loss 338765400.0 Test MSE 1686862.852006605 Test RE 0.5805327311446625\n",
      "3 Train Loss 250288200.0 Test MSE 2829968.7908298355 Test RE 0.7519304057452197\n",
      "4 Train Loss 198026020.0 Test MSE 4718704.067228649 Test RE 0.9709529697345607\n",
      "5 Train Loss 154311170.0 Test MSE 2675793.3071096987 Test RE 0.7311611465704555\n",
      "6 Train Loss 123011800.0 Test MSE 3083730.727849211 Test RE 0.7849193722013103\n",
      "7 Train Loss 108094470.0 Test MSE 4484076.079108296 Test RE 0.9465058660344787\n",
      "8 Train Loss 99000330.0 Test MSE 5040536.125518428 Test RE 1.0035180524632012\n",
      "9 Train Loss 92201290.0 Test MSE 6549926.566257892 Test RE 1.143944722717162\n",
      "10 Train Loss 85868890.0 Test MSE 6901199.348556012 Test RE 1.1742190177801661\n",
      "11 Train Loss 83752500.0 Test MSE 5648458.546810166 Test RE 1.062311288804554\n",
      "12 Train Loss 79699350.0 Test MSE 4277728.1610710705 Test RE 0.9244712615032683\n",
      "13 Train Loss 78311290.0 Test MSE 3548109.1266396553 Test RE 0.8419480743364833\n",
      "14 Train Loss 77862470.0 Test MSE 2657751.63458374 Test RE 0.7286920318809024\n",
      "15 Train Loss 77129064.0 Test MSE 2243322.2472148254 Test RE 0.6694723661276386\n",
      "16 Train Loss 77034270.0 Test MSE 1946614.7520760205 Test RE 0.6236297556614723\n",
      "17 Train Loss 76719220.0 Test MSE 1444413.7477173419 Test RE 0.5371958269481265\n",
      "18 Train Loss 76502380.0 Test MSE 1106643.0645088078 Test RE 0.4702086421631457\n",
      "19 Train Loss 76169290.0 Test MSE 738188.0019114045 Test RE 0.3840345649636633\n",
      "20 Train Loss 76014880.0 Test MSE 662328.9073711917 Test RE 0.36376731857549827\n",
      "21 Train Loss 75722210.0 Test MSE 549063.6800650436 Test RE 0.3312059895119452\n",
      "22 Train Loss 75788240.0 Test MSE 494781.2117547185 Test RE 0.31440788099449407\n",
      "23 Train Loss 75298460.0 Test MSE 195450.04869000302 Test RE 0.19760808757377452\n",
      "24 Train Loss 75103820.0 Test MSE 155584.7320169215 Test RE 0.1763073069461593\n",
      "25 Train Loss 74549176.0 Test MSE 26979.866180827623 Test RE 0.07341870489438615\n",
      "26 Train Loss 74263190.0 Test MSE 6437.648738438282 Test RE 0.035863317562038324\n",
      "27 Train Loss 74098680.0 Test MSE 19396.1351676125 Test RE 0.062250726555082354\n",
      "28 Train Loss 73556440.0 Test MSE 97793.0362566829 Test RE 0.13977863296656462\n",
      "29 Train Loss 73495096.0 Test MSE 98495.46935816534 Test RE 0.14027973948924194\n",
      "30 Train Loss 73319060.0 Test MSE 103466.96127747552 Test RE 0.14377642175959715\n",
      "31 Train Loss 72978664.0 Test MSE 159486.68777008838 Test RE 0.17850444824650993\n",
      "32 Train Loss 72962456.0 Test MSE 195598.2722880324 Test RE 0.19768300346874787\n",
      "33 Train Loss 72867640.0 Test MSE 197670.9406473843 Test RE 0.19872762308495193\n",
      "34 Train Loss 72555624.0 Test MSE 206484.5942018394 Test RE 0.2031096935572054\n",
      "35 Train Loss 72622100.0 Test MSE 110202.1364173809 Test RE 0.14838220845731181\n",
      "36 Train Loss 72653050.0 Test MSE 86576.07216861942 Test RE 0.13151817172039806\n",
      "37 Train Loss 72766664.0 Test MSE 88197.84622989195 Test RE 0.1327442791915615\n",
      "38 Train Loss 72955710.0 Test MSE 86164.5223100375 Test RE 0.13120520555710577\n",
      "39 Train Loss 73083720.0 Test MSE 39983.16394638286 Test RE 0.08937692371799237\n",
      "40 Train Loss 73244050.0 Test MSE 27020.269001032644 Test RE 0.07347365722466076\n",
      "41 Train Loss 73405040.0 Test MSE 16215.970848288745 Test RE 0.056919136263259326\n",
      "42 Train Loss 73487170.0 Test MSE 2507.9892214673514 Test RE 0.022384616406598046\n",
      "43 Train Loss 73576370.0 Test MSE 13665.460449424643 Test RE 0.05225152358736218\n",
      "44 Train Loss 73635770.0 Test MSE 22371.85167595769 Test RE 0.06685559977687555\n",
      "45 Train Loss 73432120.0 Test MSE 71500.07758044309 Test RE 0.11951986121355836\n",
      "46 Train Loss 73394100.0 Test MSE 86173.10492718143 Test RE 0.1312117398938388\n",
      "47 Train Loss 73361850.0 Test MSE 52735.1174332323 Test RE 0.1026447597117636\n",
      "48 Train Loss 73142440.0 Test MSE 56236.98348480761 Test RE 0.10599803938901797\n",
      "49 Train Loss 72999110.0 Test MSE 38181.6479460677 Test RE 0.08734019518018628\n",
      "50 Train Loss 72971360.0 Test MSE 35315.46745352093 Test RE 0.08399806917305677\n",
      "51 Train Loss 73027096.0 Test MSE 34096.540841047565 Test RE 0.08253572761375758\n",
      "52 Train Loss 73001330.0 Test MSE 25344.303056748264 Test RE 0.07115853530484814\n",
      "53 Train Loss 72836130.0 Test MSE 4364.029661273823 Test RE 0.02952777143838724\n",
      "54 Train Loss 72859176.0 Test MSE 19980.817960004944 Test RE 0.06318201251103407\n",
      "55 Train Loss 72848904.0 Test MSE 73651.88934611504 Test RE 0.12130501885165866\n",
      "56 Train Loss 72175784.0 Test MSE 196057.57491674973 Test RE 0.1979149663658021\n",
      "57 Train Loss 71585070.0 Test MSE 574216.6242031166 Test RE 0.33870741510294944\n",
      "58 Train Loss 71505896.0 Test MSE 691914.8781686648 Test RE 0.3718032299670831\n",
      "59 Train Loss 71357890.0 Test MSE 752405.3369982699 Test RE 0.3877151374560512\n",
      "60 Train Loss 71260440.0 Test MSE 533128.0211338704 Test RE 0.3263642488397146\n",
      "61 Train Loss 70810000.0 Test MSE 319268.40292987996 Test RE 0.2525601306545749\n",
      "62 Train Loss 69904040.0 Test MSE 129393.69286180034 Test RE 0.16078420310953878\n",
      "63 Train Loss 69689530.0 Test MSE 82416.1210010625 Test RE 0.12831957387503165\n",
      "64 Train Loss 69366460.0 Test MSE 168924.21806187482 Test RE 0.18370999370875515\n",
      "65 Train Loss 68554420.0 Test MSE 369336.0819794328 Test RE 0.27164248360677473\n",
      "66 Train Loss 67877140.0 Test MSE 294383.29664139356 Test RE 0.24251768049117728\n",
      "67 Train Loss 67070516.0 Test MSE 219978.17089707643 Test RE 0.20964119033893855\n",
      "68 Train Loss 66244440.0 Test MSE 298770.64860721247 Test RE 0.24431818229328547\n",
      "69 Train Loss 65096424.0 Test MSE 61677.1997380898 Test RE 0.11100668858385354\n",
      "70 Train Loss 64744404.0 Test MSE 30835.166491717147 Test RE 0.07848921264019205\n",
      "71 Train Loss 64265548.0 Test MSE 51027.01814288041 Test RE 0.10096873584090874\n",
      "72 Train Loss 63709640.0 Test MSE 2041.9611668090745 Test RE 0.020198102088519573\n",
      "73 Train Loss 63565076.0 Test MSE 3858.416522597222 Test RE 0.02776459724726179\n",
      "74 Train Loss 63186676.0 Test MSE 3615.2137061736785 Test RE 0.026875330337506113\n",
      "75 Train Loss 62872092.0 Test MSE 1628.2028944441156 Test RE 0.018036035642456944\n",
      "76 Train Loss 62232176.0 Test MSE 20765.695560074924 Test RE 0.0644110034443544\n",
      "77 Train Loss 61924988.0 Test MSE 17984.189417029167 Test RE 0.059942141935413494\n",
      "78 Train Loss 61861764.0 Test MSE 32282.266812729733 Test RE 0.0803098537398952\n",
      "79 Train Loss 61710056.0 Test MSE 93420.90578916497 Test RE 0.13661829485166152\n",
      "80 Train Loss 61201810.0 Test MSE 146603.39885047046 Test RE 0.17114288282222107\n",
      "81 Train Loss 60736824.0 Test MSE 167289.73021852298 Test RE 0.1828190568215483\n",
      "82 Train Loss 60683240.0 Test MSE 172854.76053466555 Test RE 0.18583499317690066\n",
      "83 Train Loss 60704972.0 Test MSE 162955.14226309623 Test RE 0.18043503098917732\n",
      "84 Train Loss 60643690.0 Test MSE 113108.5285991205 Test RE 0.15032613793855798\n",
      "85 Train Loss 60245852.0 Test MSE 8918.876467907508 Test RE 0.042212580126850044\n",
      "86 Train Loss 60014476.0 Test MSE 1242.0174479293357 Test RE 0.01575254293843512\n",
      "87 Train Loss 59896050.0 Test MSE 20904.62966674794 Test RE 0.06462611703882973\n",
      "88 Train Loss 59813584.0 Test MSE 43240.302817120966 Test RE 0.09294610330225249\n",
      "89 Train Loss 59756970.0 Test MSE 60925.61677060666 Test RE 0.110328265570106\n",
      "90 Train Loss 59579776.0 Test MSE 97383.27177799682 Test RE 0.13948548099202104\n",
      "91 Train Loss 59219212.0 Test MSE 46578.033215072 Test RE 0.09646669436849314\n",
      "92 Train Loss 58747036.0 Test MSE 43902.64431287803 Test RE 0.09365525770702696\n",
      "93 Train Loss 58543996.0 Test MSE 18746.84514371295 Test RE 0.061199929187079456\n",
      "94 Train Loss 58276920.0 Test MSE 14348.2374927854 Test RE 0.05354095359084425\n",
      "95 Train Loss 57951044.0 Test MSE 119040.5706277585 Test RE 0.15421773618066079\n",
      "96 Train Loss 57890696.0 Test MSE 143278.95878467392 Test RE 0.1691913018220545\n",
      "97 Train Loss 57876670.0 Test MSE 155386.26123451252 Test RE 0.1761948183519632\n",
      "98 Train Loss 57808270.0 Test MSE 171222.8692104195 Test RE 0.18495569522494182\n",
      "99 Train Loss 57657020.0 Test MSE 246699.26647918078 Test RE 0.22200908798747615\n",
      "100 Train Loss 57558084.0 Test MSE 295849.5962398056 Test RE 0.24312091082508505\n",
      "101 Train Loss 57458908.0 Test MSE 432578.21692155645 Test RE 0.29398092139310095\n",
      "102 Train Loss 57391550.0 Test MSE 511494.5389707369 Test RE 0.31967400662288636\n",
      "103 Train Loss 57266504.0 Test MSE 492733.7382591821 Test RE 0.31375667482233077\n",
      "104 Train Loss 57164496.0 Test MSE 382099.94431861286 Test RE 0.2762964537812824\n",
      "105 Train Loss 56949012.0 Test MSE 200032.75982613643 Test RE 0.19991132014602617\n",
      "106 Train Loss 56452296.0 Test MSE 66471.66464899981 Test RE 0.11524049130092096\n",
      "107 Train Loss 55842972.0 Test MSE 9147.739174665307 Test RE 0.04275074725271\n",
      "108 Train Loss 55631344.0 Test MSE 18612.756249770413 Test RE 0.060980666760253835\n",
      "109 Train Loss 55459350.0 Test MSE 52273.390525854884 Test RE 0.10219441422412294\n",
      "110 Train Loss 54880012.0 Test MSE 9503.083826875016 Test RE 0.04357316470549709\n",
      "111 Train Loss 54572348.0 Test MSE 5175.504854758456 Test RE 0.0321560861712325\n",
      "112 Train Loss 54272216.0 Test MSE 91672.41008479263 Test RE 0.13533376005821457\n",
      "113 Train Loss 54096144.0 Test MSE 187551.86276582678 Test RE 0.19357421850694603\n",
      "114 Train Loss 53884344.0 Test MSE 288388.3433145551 Test RE 0.24003560965046336\n",
      "115 Train Loss 53649536.0 Test MSE 390774.7007024436 Test RE 0.2794152099522556\n",
      "116 Train Loss 53037780.0 Test MSE 213633.57544141606 Test RE 0.20659584277345724\n",
      "117 Train Loss 52503170.0 Test MSE 54264.03592620187 Test RE 0.10412208820398823\n",
      "118 Train Loss 52110104.0 Test MSE 2021.1115801743724 Test RE 0.020094720451392035\n",
      "119 Train Loss 51921150.0 Test MSE 2344.9230402529874 Test RE 0.021644677562751676\n",
      "120 Train Loss 51731284.0 Test MSE 15343.964063652662 Test RE 0.05536758869047924\n",
      "121 Train Loss 51540636.0 Test MSE 7240.5137015447435 Test RE 0.038033957206118636\n",
      "122 Train Loss 51484456.0 Test MSE 3267.2722171396417 Test RE 0.02554932810456143\n",
      "123 Train Loss 51363236.0 Test MSE 4026.0671083488232 Test RE 0.028361378019239502\n",
      "124 Train Loss 51203844.0 Test MSE 13067.531069969526 Test RE 0.051095610710406296\n",
      "125 Train Loss 51139108.0 Test MSE 17048.74231151805 Test RE 0.05836238039564801\n",
      "126 Train Loss 51088676.0 Test MSE 14261.884327612805 Test RE 0.053379595507111015\n",
      "127 Train Loss 51051200.0 Test MSE 10200.381905605262 Test RE 0.045143480522218664\n",
      "128 Train Loss 51035628.0 Test MSE 8747.170573296675 Test RE 0.041804267822161074\n",
      "129 Train Loss 50975204.0 Test MSE 4535.470968072294 Test RE 0.03010218491986072\n",
      "130 Train Loss 50900824.0 Test MSE 4960.8787158792575 Test RE 0.031482276464650516\n",
      "131 Train Loss 50778080.0 Test MSE 9441.73039899205 Test RE 0.043432279285182895\n",
      "132 Train Loss 50559660.0 Test MSE 4368.963569671204 Test RE 0.02954445855740695\n",
      "133 Train Loss 50432336.0 Test MSE 3415.667633454174 Test RE 0.02612309476349019\n",
      "134 Train Loss 50309650.0 Test MSE 4080.6093429645566 Test RE 0.028552841429630053\n",
      "135 Train Loss 50228148.0 Test MSE 8405.564553719858 Test RE 0.04097984086284462\n",
      "136 Train Loss 50123770.0 Test MSE 4966.45169096145 Test RE 0.03149995485446084\n",
      "137 Train Loss 50001320.0 Test MSE 17402.08111941811 Test RE 0.05896406524054178\n",
      "138 Train Loss 49844250.0 Test MSE 15188.891581891132 Test RE 0.05508709425419476\n",
      "139 Train Loss 49652500.0 Test MSE 7292.266238509808 Test RE 0.03816964157215029\n",
      "140 Train Loss 49511028.0 Test MSE 8019.300283986748 Test RE 0.04002718621622253\n",
      "141 Train Loss 49451384.0 Test MSE 14908.463004364741 Test RE 0.05457619573323577\n",
      "142 Train Loss 49392670.0 Test MSE 38788.438192649024 Test RE 0.0880314732904179\n",
      "143 Train Loss 49327892.0 Test MSE 33598.03627849788 Test RE 0.08193015396675495\n",
      "144 Train Loss 49264148.0 Test MSE 14789.758690668732 Test RE 0.054358487941781136\n",
      "145 Train Loss 49229950.0 Test MSE 6305.96105095534 Test RE 0.03549461465498341\n",
      "146 Train Loss 49212540.0 Test MSE 4136.79571029345 Test RE 0.028748743024007893\n",
      "147 Train Loss 49153420.0 Test MSE 5598.674601386067 Test RE 0.03344486421180124\n",
      "148 Train Loss 49034864.0 Test MSE 26134.545488867192 Test RE 0.0722593914037808\n",
      "149 Train Loss 48904900.0 Test MSE 31939.25043649982 Test RE 0.07988204667902132\n",
      "150 Train Loss 48809188.0 Test MSE 17690.211062302194 Test RE 0.05945020149487275\n",
      "151 Train Loss 48722316.0 Test MSE 12971.186718345452 Test RE 0.050906903267354336\n",
      "152 Train Loss 48626960.0 Test MSE 6755.157012705281 Test RE 0.03673707269403666\n",
      "153 Train Loss 48545716.0 Test MSE 4438.086788577236 Test RE 0.02977725904426335\n",
      "154 Train Loss 48478988.0 Test MSE 6519.961945445337 Test RE 0.03609186748303458\n",
      "155 Train Loss 48395892.0 Test MSE 8234.64011499182 Test RE 0.04056104499837661\n",
      "156 Train Loss 48357920.0 Test MSE 6916.149015911448 Test RE 0.0371722624422128\n",
      "157 Train Loss 48238620.0 Test MSE 8723.02547850715 Test RE 0.04174653112253778\n",
      "158 Train Loss 48094772.0 Test MSE 43567.72527188823 Test RE 0.09329734099272236\n",
      "159 Train Loss 48021910.0 Test MSE 78396.73893975752 Test RE 0.12515143179988855\n",
      "160 Train Loss 47950324.0 Test MSE 55330.58954682593 Test RE 0.10514036309128241\n",
      "161 Train Loss 47874144.0 Test MSE 34150.954529762355 Test RE 0.08260155955614956\n",
      "162 Train Loss 47783664.0 Test MSE 34940.29224161508 Test RE 0.08355069949677892\n",
      "163 Train Loss 47607044.0 Test MSE 43320.73617680787 Test RE 0.09303250988939472\n",
      "164 Train Loss 47361024.0 Test MSE 54746.34416715647 Test RE 0.1045837922114405\n",
      "165 Train Loss 46985292.0 Test MSE 68882.90589220793 Test RE 0.11731203098064413\n",
      "166 Train Loss 46856284.0 Test MSE 56316.79705023954 Test RE 0.1060732308497169\n",
      "167 Train Loss 46724844.0 Test MSE 48418.000749429964 Test RE 0.09835359755386723\n",
      "168 Train Loss 46539668.0 Test MSE 56469.98086772747 Test RE 0.10621739448308916\n",
      "169 Train Loss 46446452.0 Test MSE 46528.09058705394 Test RE 0.09641496298303663\n",
      "170 Train Loss 46360988.0 Test MSE 25864.049144978613 Test RE 0.07188447115956434\n",
      "171 Train Loss 46201828.0 Test MSE 8315.950766457254 Test RE 0.040760807434248876\n",
      "172 Train Loss 46020140.0 Test MSE 9673.00650173872 Test RE 0.0439610000554986\n",
      "173 Train Loss 45878492.0 Test MSE 8408.671512899527 Test RE 0.0409874138776314\n",
      "174 Train Loss 45703524.0 Test MSE 32851.3643445178 Test RE 0.08101464421652405\n",
      "175 Train Loss 45569070.0 Test MSE 58445.705884130824 Test RE 0.10805954331431832\n",
      "176 Train Loss 45439644.0 Test MSE 52239.17755505958 Test RE 0.10216096559226358\n",
      "177 Train Loss 45254030.0 Test MSE 33436.09798135272 Test RE 0.08173246897070735\n",
      "178 Train Loss 45176540.0 Test MSE 27585.528222289413 Test RE 0.07423820727824951\n",
      "179 Train Loss 45148856.0 Test MSE 9004.285747680251 Test RE 0.04241421739298143\n",
      "180 Train Loss 45106164.0 Test MSE 4959.164606692242 Test RE 0.03147683703297925\n",
      "181 Train Loss 45049640.0 Test MSE 14720.06198611213 Test RE 0.054230254562431135\n",
      "182 Train Loss 44961564.0 Test MSE 33240.3304523706 Test RE 0.08149284691554255\n",
      "183 Train Loss 44787504.0 Test MSE 73125.87070629575 Test RE 0.12087106501825703\n",
      "184 Train Loss 44623780.0 Test MSE 90786.743395954 Test RE 0.13467842924649104\n",
      "185 Train Loss 44403604.0 Test MSE 42609.4672779599 Test RE 0.09226561393932967\n",
      "186 Train Loss 44188470.0 Test MSE 19392.449958847512 Test RE 0.06224481254647082\n",
      "187 Train Loss 43769436.0 Test MSE 18094.72768512808 Test RE 0.06012607433822019\n",
      "188 Train Loss 43648988.0 Test MSE 9646.309195088872 Test RE 0.04390029239318264\n",
      "189 Train Loss 43575040.0 Test MSE 5952.898627065985 Test RE 0.0344866545784026\n",
      "190 Train Loss 43495210.0 Test MSE 5388.753929062825 Test RE 0.032811871337039694\n",
      "191 Train Loss 43449716.0 Test MSE 5448.116568051178 Test RE 0.032992104503390435\n",
      "192 Train Loss 43396520.0 Test MSE 4960.106002320257 Test RE 0.03147982450697798\n",
      "193 Train Loss 43347132.0 Test MSE 4030.641891813962 Test RE 0.028377486832507546\n",
      "194 Train Loss 43308696.0 Test MSE 5066.138325139826 Test RE 0.03181451781669974\n",
      "195 Train Loss 43265668.0 Test MSE 6326.186428100495 Test RE 0.03555149077998145\n",
      "196 Train Loss 43218084.0 Test MSE 7440.638684251282 Test RE 0.03855599644522809\n",
      "197 Train Loss 43180932.0 Test MSE 9418.546758105382 Test RE 0.043378923745931976\n",
      "198 Train Loss 43073836.0 Test MSE 13986.497864042982 Test RE 0.05286172308543417\n",
      "199 Train Loss 42925150.0 Test MSE 20451.777645221944 Test RE 0.06392229438060061\n",
      "Training time: 78.72\n",
      "Training time: 78.72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "1\n",
      "0 Train Loss 1319857900.0 Test MSE 4995182.544783406 Test RE 0.9989931390165058\n",
      "1 Train Loss 734357570.0 Test MSE 18590734.47478373 Test RE 1.927236879345483\n",
      "2 Train Loss 243210740.0 Test MSE 131366447.97426304 Test RE 5.12305539918514\n",
      "3 Train Loss 107572400.0 Test MSE 52782721.053345725 Test RE 3.2473770063495104\n",
      "4 Train Loss 79536330.0 Test MSE 13319023.310455116 Test RE 1.6312593469695735\n",
      "5 Train Loss 75533660.0 Test MSE 4501388.174644367 Test RE 0.9483312381292703\n",
      "6 Train Loss 74849310.0 Test MSE 2795201.1439791243 Test RE 0.7472972022646078\n",
      "7 Train Loss 75057736.0 Test MSE 1767817.9752027427 Test RE 0.5942998168308908\n",
      "8 Train Loss 75540540.0 Test MSE 1428587.5984538055 Test RE 0.5342447480828302\n",
      "9 Train Loss 75788540.0 Test MSE 488319.03972649726 Test RE 0.31234794473143257\n",
      "10 Train Loss 76354570.0 Test MSE 276713.32959287404 Test RE 0.2351266540476134\n",
      "11 Train Loss 76936184.0 Test MSE 188888.63540672764 Test RE 0.1942628420858331\n",
      "12 Train Loss 77490010.0 Test MSE 97931.7155564837 Test RE 0.13987770717650524\n",
      "13 Train Loss 78086120.0 Test MSE 68682.61211242761 Test RE 0.11714135020442781\n",
      "14 Train Loss 78663416.0 Test MSE 52993.21727019286 Test RE 0.10289563863881188\n",
      "15 Train Loss 79157440.0 Test MSE 103909.03256567214 Test RE 0.14408324280224916\n",
      "16 Train Loss 79563416.0 Test MSE 213201.71730042182 Test RE 0.20638692141962015\n",
      "17 Train Loss 79974264.0 Test MSE 266215.3033230112 Test RE 0.23062337968225527\n",
      "18 Train Loss 80213080.0 Test MSE 239015.08734006286 Test RE 0.2185241710905794\n",
      "19 Train Loss 80588860.0 Test MSE 182619.76117428645 Test RE 0.19101202506526035\n",
      "20 Train Loss 81121470.0 Test MSE 192325.8812119287 Test RE 0.19602239412177505\n",
      "21 Train Loss 80901310.0 Test MSE 200819.88966448855 Test RE 0.20030425995688247\n",
      "22 Train Loss 80988570.0 Test MSE 238765.08519528407 Test RE 0.21840985653988143\n",
      "23 Train Loss 81042100.0 Test MSE 259704.3729895287 Test RE 0.2277856992503987\n",
      "24 Train Loss 80719470.0 Test MSE 217852.95476311387 Test RE 0.20862605746328755\n",
      "25 Train Loss 80290880.0 Test MSE 149838.62082074405 Test RE 0.17302095592714142\n",
      "26 Train Loss 79691570.0 Test MSE 122258.84002268214 Test RE 0.15628847701502696\n",
      "27 Train Loss 79485624.0 Test MSE 90572.17491700953 Test RE 0.13451918330752224\n",
      "28 Train Loss 79182230.0 Test MSE 90143.33542956057 Test RE 0.13420034596143818\n",
      "29 Train Loss 78206720.0 Test MSE 85173.04980139069 Test RE 0.1304481495391843\n",
      "30 Train Loss 78033576.0 Test MSE 86287.95114877487 Test RE 0.1312991462551058\n",
      "31 Train Loss 77700696.0 Test MSE 117191.80984505339 Test RE 0.15301551006548195\n",
      "32 Train Loss 77227410.0 Test MSE 121368.97107179796 Test RE 0.1557186603164269\n",
      "33 Train Loss 76437080.0 Test MSE 105060.28732208975 Test RE 0.14487922553444185\n",
      "34 Train Loss 76085460.0 Test MSE 104445.96853180142 Test RE 0.1444550285330656\n",
      "35 Train Loss 75573590.0 Test MSE 104002.33065401918 Test RE 0.14414791319061446\n",
      "36 Train Loss 75105144.0 Test MSE 104401.4054756315 Test RE 0.14442420855776902\n",
      "37 Train Loss 73722870.0 Test MSE 151193.21958114413 Test RE 0.17380128427094677\n",
      "38 Train Loss 72892730.0 Test MSE 164217.3305884148 Test RE 0.1811324734987137\n",
      "39 Train Loss 70331920.0 Test MSE 183131.3459811604 Test RE 0.19127938525795776\n",
      "40 Train Loss 68373390.0 Test MSE 228685.20472444463 Test RE 0.2137498691841555\n",
      "41 Train Loss 67230710.0 Test MSE 277851.60416620836 Test RE 0.23560976055437566\n",
      "42 Train Loss 66499970.0 Test MSE 277198.01822108636 Test RE 0.2353324868403296\n",
      "43 Train Loss 65146996.0 Test MSE 278682.2559338724 Test RE 0.2359616815228719\n",
      "44 Train Loss 64321236.0 Test MSE 251480.08088658797 Test RE 0.2241499360706721\n",
      "45 Train Loss 63504116.0 Test MSE 280603.3459935941 Test RE 0.2367735830749101\n",
      "46 Train Loss 62224780.0 Test MSE 286159.4313991816 Test RE 0.23910621006322597\n",
      "47 Train Loss 61929320.0 Test MSE 261965.77454801925 Test RE 0.228775282967311\n",
      "48 Train Loss 61438170.0 Test MSE 261902.73932647886 Test RE 0.22874775691304425\n",
      "49 Train Loss 61050772.0 Test MSE 250510.89503669433 Test RE 0.22371759037664601\n",
      "50 Train Loss 60745430.0 Test MSE 263940.20904055465 Test RE 0.2296358035533475\n",
      "51 Train Loss 59949836.0 Test MSE 260397.15017925604 Test RE 0.22808931300259075\n",
      "52 Train Loss 59150004.0 Test MSE 267838.8046010247 Test RE 0.2313255336144939\n",
      "53 Train Loss 57831970.0 Test MSE 269601.22057174856 Test RE 0.23208536254595677\n",
      "54 Train Loss 56623520.0 Test MSE 262873.6285846482 Test RE 0.22917135556863155\n",
      "55 Train Loss 55851260.0 Test MSE 253656.6419762644 Test RE 0.22511785553546954\n",
      "56 Train Loss 55220230.0 Test MSE 250687.25702026032 Test RE 0.22379632614623196\n",
      "57 Train Loss 54694536.0 Test MSE 295155.65458130505 Test RE 0.24283561252060074\n",
      "58 Train Loss 54008520.0 Test MSE 336699.6476963318 Test RE 0.2593630798507216\n",
      "59 Train Loss 53463764.0 Test MSE 373458.9517184469 Test RE 0.2731544377387147\n",
      "60 Train Loss 52907028.0 Test MSE 401316.47014895175 Test RE 0.28315896451901645\n",
      "61 Train Loss 52564252.0 Test MSE 481179.7572724262 Test RE 0.3100562556432118\n",
      "62 Train Loss 52206410.0 Test MSE 592896.4939978373 Test RE 0.3441725778970749\n",
      "63 Train Loss 51895244.0 Test MSE 610127.2490181379 Test RE 0.3491379313860275\n",
      "64 Train Loss 51445176.0 Test MSE 653266.0631856074 Test RE 0.36126997777136505\n",
      "65 Train Loss 50670268.0 Test MSE 653497.314412453 Test RE 0.3613339155282006\n",
      "66 Train Loss 50200870.0 Test MSE 589810.0412504796 Test RE 0.3432755760658021\n",
      "67 Train Loss 49717170.0 Test MSE 465766.5311784931 Test RE 0.3050499531687124\n",
      "68 Train Loss 49258904.0 Test MSE 417651.1398616328 Test RE 0.2888641585609344\n",
      "69 Train Loss 49094948.0 Test MSE 398265.6821440367 Test RE 0.2820806310112956\n",
      "70 Train Loss 48873296.0 Test MSE 372540.4523464222 Test RE 0.2728183276631013\n",
      "71 Train Loss 48596860.0 Test MSE 337007.1480964619 Test RE 0.2594814881268175\n",
      "72 Train Loss 48316348.0 Test MSE 307860.6293251932 Test RE 0.2480069777855957\n",
      "73 Train Loss 47821944.0 Test MSE 258285.8470122151 Test RE 0.22716275562460864\n",
      "74 Train Loss 47304936.0 Test MSE 203208.46481963998 Test RE 0.20149195983389953\n",
      "75 Train Loss 46872372.0 Test MSE 180660.65251174988 Test RE 0.18998469277704105\n",
      "76 Train Loss 46585796.0 Test MSE 168908.50059570523 Test RE 0.18370144690944823\n",
      "77 Train Loss 46309332.0 Test MSE 198504.45400406525 Test RE 0.1991461668532545\n",
      "78 Train Loss 46028516.0 Test MSE 201320.6452622166 Test RE 0.20055383939183447\n",
      "79 Train Loss 45780988.0 Test MSE 178970.0628942345 Test RE 0.18909368225127487\n",
      "80 Train Loss 45521920.0 Test MSE 163031.1863085797 Test RE 0.18047712665163163\n",
      "81 Train Loss 45192324.0 Test MSE 117484.21914018507 Test RE 0.15320628825305843\n",
      "82 Train Loss 45074748.0 Test MSE 97710.25109943305 Test RE 0.1397194567382327\n",
      "83 Train Loss 44977796.0 Test MSE 80761.86162012188 Test RE 0.12702522833488708\n",
      "84 Train Loss 44695590.0 Test MSE 64972.899510870484 Test RE 0.11393389582115798\n",
      "85 Train Loss 44622372.0 Test MSE 51841.5673136677 Test RE 0.10177143193858375\n",
      "86 Train Loss 44456744.0 Test MSE 43045.670232982484 Test RE 0.09273668359394638\n",
      "87 Train Loss 44265636.0 Test MSE 45219.6311842622 Test RE 0.09504960832573012\n",
      "88 Train Loss 43749036.0 Test MSE 45423.419672779986 Test RE 0.09526354463098931\n",
      "89 Train Loss 43353944.0 Test MSE 46259.356132517656 Test RE 0.09613612558585222\n",
      "90 Train Loss 43108540.0 Test MSE 44054.98311598201 Test RE 0.09381760527035111\n",
      "91 Train Loss 42930830.0 Test MSE 39900.157149314735 Test RE 0.08928410031527438\n",
      "92 Train Loss 42732428.0 Test MSE 34593.36410911099 Test RE 0.08313487012499754\n",
      "93 Train Loss 42503400.0 Test MSE 30950.578830652892 Test RE 0.07863596331696095\n",
      "94 Train Loss 42314676.0 Test MSE 27241.00636928764 Test RE 0.07377316188600723\n",
      "95 Train Loss 41935096.0 Test MSE 27794.538604603924 Test RE 0.0745189210509423\n",
      "96 Train Loss 41705130.0 Test MSE 24657.11149043798 Test RE 0.07018720093562061\n",
      "97 Train Loss 41546508.0 Test MSE 24803.81325795781 Test RE 0.07039568676126279\n",
      "98 Train Loss 41251176.0 Test MSE 16820.841470611264 Test RE 0.05797098538822053\n",
      "99 Train Loss 40831076.0 Test MSE 7799.369296976374 Test RE 0.039474493468162335\n",
      "100 Train Loss 40618612.0 Test MSE 5330.905628952312 Test RE 0.03263527832590513\n",
      "101 Train Loss 40243308.0 Test MSE 5341.297248828912 Test RE 0.03266707107575484\n",
      "102 Train Loss 40056164.0 Test MSE 4168.330333809614 Test RE 0.028858110236954067\n",
      "103 Train Loss 39856384.0 Test MSE 3542.016512511648 Test RE 0.026601866791286833\n",
      "104 Train Loss 39703060.0 Test MSE 6039.556307853713 Test RE 0.03473676263103696\n",
      "105 Train Loss 39603224.0 Test MSE 5698.5725889234955 Test RE 0.033741925797141185\n",
      "106 Train Loss 39471652.0 Test MSE 4114.153842757886 Test RE 0.028669960024086102\n",
      "107 Train Loss 39251904.0 Test MSE 2637.1551324916713 Test RE 0.022953803674276557\n",
      "108 Train Loss 39070184.0 Test MSE 5583.023129431151 Test RE 0.03339808280846248\n",
      "109 Train Loss 38984664.0 Test MSE 5619.3964792643765 Test RE 0.03350670030274393\n",
      "110 Train Loss 38822024.0 Test MSE 2051.4476450615866 Test RE 0.020244965572550865\n",
      "111 Train Loss 38692690.0 Test MSE 2052.0968806765104 Test RE 0.020248168850232732\n",
      "112 Train Loss 38532780.0 Test MSE 1579.3622910250401 Test RE 0.017763465871731773\n",
      "113 Train Loss 38285450.0 Test MSE 1213.4527386607017 Test RE 0.01557034575951861\n",
      "114 Train Loss 38020024.0 Test MSE 1329.7512991382982 Test RE 0.01629941566870888\n",
      "115 Train Loss 37741284.0 Test MSE 1502.2641218360927 Test RE 0.017324470557152576\n",
      "116 Train Loss 37443576.0 Test MSE 2746.916969093083 Test RE 0.023426617669305955\n",
      "117 Train Loss 37210684.0 Test MSE 6331.006764711 Test RE 0.035565032707839714\n",
      "118 Train Loss 36834600.0 Test MSE 12379.194539619055 Test RE 0.049731667074431656\n",
      "119 Train Loss 36460784.0 Test MSE 12097.213380264744 Test RE 0.04916199453939756\n",
      "120 Train Loss 36205724.0 Test MSE 8728.240409963995 Test RE 0.04175900803038659\n",
      "121 Train Loss 35926756.0 Test MSE 3048.4852306265743 Test RE 0.02467907462976116\n",
      "122 Train Loss 35661370.0 Test MSE 4075.8134108508325 Test RE 0.02853605744752225\n",
      "123 Train Loss 35486700.0 Test MSE 3310.4041862918034 Test RE 0.02571741629199259\n",
      "124 Train Loss 35334250.0 Test MSE 6609.595798306044 Test RE 0.03633910898426109\n",
      "125 Train Loss 35078784.0 Test MSE 26113.523560419777 Test RE 0.07223032379771849\n",
      "126 Train Loss 34775776.0 Test MSE 104113.58435201674 Test RE 0.14422499176091336\n",
      "127 Train Loss 34581384.0 Test MSE 196711.64403553033 Test RE 0.1982448242725546\n",
      "128 Train Loss 34369860.0 Test MSE 279977.9880034374 Test RE 0.23650959684106793\n",
      "129 Train Loss 34134200.0 Test MSE 376079.1290523674 Test RE 0.2741109847595891\n",
      "130 Train Loss 33972480.0 Test MSE 485373.9531604105 Test RE 0.311404624030891\n",
      "131 Train Loss 33772364.0 Test MSE 488697.51937175996 Test RE 0.31246896647337574\n",
      "132 Train Loss 33496090.0 Test MSE 481037.04546413233 Test RE 0.31001027285857324\n",
      "133 Train Loss 33342572.0 Test MSE 498008.81379144895 Test RE 0.3154317011565513\n",
      "134 Train Loss 33100194.0 Test MSE 524617.003386395 Test RE 0.32374867887733116\n",
      "135 Train Loss 32848990.0 Test MSE 446061.5678246911 Test RE 0.29852741951523665\n",
      "136 Train Loss 32655868.0 Test MSE 321154.49833426333 Test RE 0.2533050384629156\n",
      "137 Train Loss 32519882.0 Test MSE 224691.31929022179 Test RE 0.21187512451510873\n",
      "138 Train Loss 32358234.0 Test MSE 113490.33951778067 Test RE 0.15057964581400574\n",
      "139 Train Loss 32137208.0 Test MSE 50881.44901773721 Test RE 0.10082461191825685\n",
      "140 Train Loss 31916302.0 Test MSE 15885.640627134291 Test RE 0.05633641285352541\n",
      "141 Train Loss 31804570.0 Test MSE 3605.836842443785 Test RE 0.026840454123859717\n",
      "142 Train Loss 31628190.0 Test MSE 16873.346596584768 Test RE 0.05806139116137641\n",
      "143 Train Loss 31547454.0 Test MSE 26496.590985951523 Test RE 0.07275817960423847\n",
      "144 Train Loss 31434108.0 Test MSE 44174.50322442082 Test RE 0.09394478152432634\n",
      "145 Train Loss 31309858.0 Test MSE 33677.34535572503 Test RE 0.08202679614566438\n",
      "146 Train Loss 31213528.0 Test MSE 29059.761083615194 Test RE 0.07619611758955105\n",
      "147 Train Loss 31132612.0 Test MSE 29663.976776909934 Test RE 0.07698418383931875\n",
      "148 Train Loss 31054514.0 Test MSE 31249.605193469073 Test RE 0.07901491751635016\n",
      "149 Train Loss 30929046.0 Test MSE 33116.08073847974 Test RE 0.08134039742805202\n",
      "150 Train Loss 30834624.0 Test MSE 23029.167045333113 Test RE 0.06783064373174455\n",
      "151 Train Loss 30678450.0 Test MSE 6645.996552482724 Test RE 0.036439036029778715\n",
      "152 Train Loss 30557228.0 Test MSE 7612.255497483546 Test RE 0.038998104789062016\n",
      "153 Train Loss 30470656.0 Test MSE 1236.9641541449828 Test RE 0.01572046474165279\n",
      "154 Train Loss 30407548.0 Test MSE 1629.3696263915729 Test RE 0.018042496584960568\n",
      "155 Train Loss 30334214.0 Test MSE 3310.0887992403295 Test RE 0.02571619119486942\n",
      "156 Train Loss 30271474.0 Test MSE 3252.8709044245934 Test RE 0.0254929584196674\n",
      "157 Train Loss 30254834.0 Test MSE 5799.0092776860965 Test RE 0.03403797582035159\n",
      "158 Train Loss 30204186.0 Test MSE 5071.554541550203 Test RE 0.03183151974910446\n",
      "159 Train Loss 30129036.0 Test MSE 2433.3386986679625 Test RE 0.02204895977455746\n",
      "160 Train Loss 30071580.0 Test MSE 755.0306057768253 Test RE 0.012282000250023338\n",
      "161 Train Loss 30052802.0 Test MSE 1057.9498359694437 Test RE 0.014538491987327219\n",
      "162 Train Loss 30006208.0 Test MSE 2607.2896185360187 Test RE 0.02282345884067787\n",
      "163 Train Loss 29966608.0 Test MSE 2742.968776332712 Test RE 0.0234097758676392\n",
      "164 Train Loss 29953230.0 Test MSE 2934.589102566979 Test RE 0.024213661895171257\n",
      "165 Train Loss 29917246.0 Test MSE 5993.529805976013 Test RE 0.034604147806054274\n",
      "166 Train Loss 29879340.0 Test MSE 4789.6222478729005 Test RE 0.03093409784523616\n",
      "167 Train Loss 29851982.0 Test MSE 1202.2546249679222 Test RE 0.015498335279933906\n",
      "168 Train Loss 29800372.0 Test MSE 975.6398702622047 Test RE 0.013961484340405872\n",
      "169 Train Loss 29783820.0 Test MSE 1330.094503971533 Test RE 0.01630151894822268\n",
      "170 Train Loss 29764166.0 Test MSE 4337.3776915786575 Test RE 0.029437467457529672\n",
      "171 Train Loss 29746410.0 Test MSE 8324.467134166345 Test RE 0.04078167367098117\n",
      "172 Train Loss 29733170.0 Test MSE 8749.855492437011 Test RE 0.04181068318048664\n",
      "173 Train Loss 29717852.0 Test MSE 8738.81892789399 Test RE 0.04178430606453268\n",
      "174 Train Loss 29698918.0 Test MSE 12084.511978442284 Test RE 0.049136179080220256\n",
      "175 Train Loss 29691252.0 Test MSE 14762.340320775163 Test RE 0.05430807763539155\n",
      "176 Train Loss 29678422.0 Test MSE 10263.808437004242 Test RE 0.045283615331184454\n",
      "177 Train Loss 29657894.0 Test MSE 4453.767330606841 Test RE 0.02982981681075098\n",
      "178 Train Loss 29613496.0 Test MSE 965.3895275437102 Test RE 0.013887949074115294\n",
      "179 Train Loss 29609824.0 Test MSE 1777.7890513151287 Test RE 0.01884633633163134\n",
      "180 Train Loss 29592060.0 Test MSE 3807.843690372677 Test RE 0.027582039744536026\n",
      "181 Train Loss 29566232.0 Test MSE 4740.947846557857 Test RE 0.030776513010566962\n",
      "182 Train Loss 29545218.0 Test MSE 5510.2437840261055 Test RE 0.03317968283748855\n",
      "183 Train Loss 29514880.0 Test MSE 11723.078617427038 Test RE 0.04839579878422137\n",
      "184 Train Loss 29482374.0 Test MSE 15035.800215840905 Test RE 0.054808775176610175\n",
      "185 Train Loss 29464564.0 Test MSE 15796.497738106229 Test RE 0.056178123495604755\n",
      "186 Train Loss 29441318.0 Test MSE 20978.015571683856 Test RE 0.06473945296418551\n",
      "187 Train Loss 29415204.0 Test MSE 20710.277190587705 Test RE 0.06432499771634194\n",
      "188 Train Loss 29370146.0 Test MSE 9652.255434145858 Test RE 0.043913820956912174\n",
      "189 Train Loss 29336900.0 Test MSE 639.6621414507283 Test RE 0.011304780844345544\n",
      "190 Train Loss 29310322.0 Test MSE 7760.405979744491 Test RE 0.0393757686299972\n",
      "191 Train Loss 29281144.0 Test MSE 8325.030742434958 Test RE 0.04078305420976421\n",
      "192 Train Loss 29265804.0 Test MSE 8325.913195370296 Test RE 0.04078521565356857\n",
      "193 Train Loss 29234994.0 Test MSE 11455.984228680936 Test RE 0.04784130604687091\n",
      "194 Train Loss 29189020.0 Test MSE 10188.667156816125 Test RE 0.045117550294048396\n",
      "195 Train Loss 29156936.0 Test MSE 10631.242767344864 Test RE 0.0460870427071421\n",
      "196 Train Loss 29143868.0 Test MSE 9057.426950361501 Test RE 0.042539192699303466\n",
      "197 Train Loss 29125914.0 Test MSE 5411.649598018318 Test RE 0.03288150278333179\n",
      "198 Train Loss 29114444.0 Test MSE 3595.524075659775 Test RE 0.02680204451849988\n",
      "199 Train Loss 29092684.0 Test MSE 2337.249804122696 Test RE 0.021609234861524176\n",
      "Training time: 79.31\n",
      "Training time: 79.31\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "2\n",
      "0 Train Loss 317541250.0 Test MSE 35204489.540600844 Test RE 2.6520752916655708\n",
      "1 Train Loss 165829300.0 Test MSE 39586709.98200255 Test RE 2.8122992326402825\n",
      "2 Train Loss 97527240.0 Test MSE 31835040.018552117 Test RE 2.5219677212449128\n",
      "3 Train Loss 83912550.0 Test MSE 12940135.89289765 Test RE 1.6078896595469283\n",
      "4 Train Loss 78304050.0 Test MSE 10119571.25485881 Test RE 1.42189615564889\n",
      "5 Train Loss 76727240.0 Test MSE 2006129.4739878543 Test RE 0.6330912380620125\n",
      "6 Train Loss 76984760.0 Test MSE 995755.4319003277 Test RE 0.4460290709422668\n",
      "7 Train Loss 77897410.0 Test MSE 788401.5459182978 Test RE 0.3968812275023552\n",
      "8 Train Loss 78821290.0 Test MSE 277057.6024486014 Test RE 0.23527287498073662\n",
      "9 Train Loss 79850380.0 Test MSE 191933.45197154325 Test RE 0.1958223061279597\n",
      "10 Train Loss 80908310.0 Test MSE 150885.7132621894 Test RE 0.17362445029676205\n",
      "11 Train Loss 81908560.0 Test MSE 54997.48684723742 Test RE 0.10482340090778748\n",
      "12 Train Loss 82922860.0 Test MSE 52472.03891710121 Test RE 0.10238840877559824\n",
      "13 Train Loss 83900984.0 Test MSE 43074.353991411044 Test RE 0.09276757629035166\n",
      "14 Train Loss 84853130.0 Test MSE 36604.77349840288 Test RE 0.08551763572765461\n",
      "15 Train Loss 85793930.0 Test MSE 35428.29255721139 Test RE 0.08413213979865028\n",
      "16 Train Loss 86688376.0 Test MSE 34262.69588648423 Test RE 0.08273658466270478\n",
      "17 Train Loss 87530270.0 Test MSE 30870.782995277208 Test RE 0.07853452947902613\n",
      "18 Train Loss 88349630.0 Test MSE 26815.980244330585 Test RE 0.07319537871084168\n",
      "19 Train Loss 89156430.0 Test MSE 26172.66749319227 Test RE 0.07231207395409565\n",
      "20 Train Loss 89902120.0 Test MSE 24723.793324381008 Test RE 0.07028204276859122\n",
      "21 Train Loss 90570790.0 Test MSE 31054.39760391848 Test RE 0.07876773879413711\n",
      "22 Train Loss 91107790.0 Test MSE 50630.06280948269 Test RE 0.10057523516967523\n",
      "23 Train Loss 91404910.0 Test MSE 89579.22623427684 Test RE 0.13377977988427392\n",
      "24 Train Loss 91879230.0 Test MSE 105035.13149461089 Test RE 0.1448618794225728\n",
      "25 Train Loss 92224920.0 Test MSE 189790.0007138208 Test RE 0.19472579579675517\n",
      "26 Train Loss 92413630.0 Test MSE 275978.8217557656 Test RE 0.23481438660460444\n",
      "27 Train Loss 92784856.0 Test MSE 290429.5101218154 Test RE 0.2408835787744569\n",
      "28 Train Loss 93112650.0 Test MSE 290888.73242275394 Test RE 0.24107394410358488\n",
      "29 Train Loss 93320710.0 Test MSE 316714.48959084356 Test RE 0.25154795440877675\n",
      "30 Train Loss 93534480.0 Test MSE 328243.77914379566 Test RE 0.25608555132784927\n",
      "31 Train Loss 93733340.0 Test MSE 379475.405012545 Test RE 0.2753459165928894\n",
      "32 Train Loss 93787530.0 Test MSE 374068.59372656216 Test RE 0.27337729826236135\n",
      "33 Train Loss 93926680.0 Test MSE 395470.2851227068 Test RE 0.28108893636870746\n",
      "34 Train Loss 93955240.0 Test MSE 444508.03802214377 Test RE 0.29800711493912274\n",
      "35 Train Loss 94116180.0 Test MSE 444187.8515249764 Test RE 0.2978997658756005\n",
      "36 Train Loss 94178100.0 Test MSE 428820.87757265236 Test RE 0.29270138962214703\n",
      "37 Train Loss 94208630.0 Test MSE 411738.9147903517 Test RE 0.28681230609050534\n",
      "38 Train Loss 93356360.0 Test MSE 322551.1345616323 Test RE 0.25385522724298554\n",
      "39 Train Loss 92633930.0 Test MSE 327863.8948277952 Test RE 0.25593732148476633\n",
      "40 Train Loss 92224870.0 Test MSE 348383.34982589784 Test RE 0.263824740126677\n",
      "41 Train Loss 92157950.0 Test MSE 343324.83570162876 Test RE 0.26190237340990674\n",
      "42 Train Loss 91705280.0 Test MSE 376626.7082687701 Test RE 0.2743104678870881\n",
      "43 Train Loss 91048536.0 Test MSE 389654.5752216062 Test RE 0.2790144615143764\n",
      "44 Train Loss 91049610.0 Test MSE 374234.49906287604 Test RE 0.273437915119265\n",
      "45 Train Loss 90515890.0 Test MSE 334749.8705012092 Test RE 0.2586110231470306\n",
      "46 Train Loss 90128040.0 Test MSE 333287.1090307641 Test RE 0.25804537633133484\n",
      "47 Train Loss 89736970.0 Test MSE 319445.4916008107 Test RE 0.2526301647343585\n",
      "48 Train Loss 88736900.0 Test MSE 290792.78710040776 Test RE 0.24103418349707556\n",
      "49 Train Loss 87921784.0 Test MSE 277664.84665843355 Test RE 0.2355305648839805\n",
      "50 Train Loss 87434230.0 Test MSE 256942.03678990135 Test RE 0.2265710435166134\n",
      "51 Train Loss 86835570.0 Test MSE 228182.62190311335 Test RE 0.2135148603198199\n",
      "52 Train Loss 86260380.0 Test MSE 216362.4213308471 Test RE 0.20791113064605518\n",
      "53 Train Loss 85289310.0 Test MSE 204403.63093307454 Test RE 0.20208362640441824\n",
      "54 Train Loss 83728536.0 Test MSE 214631.1225936427 Test RE 0.20707762349206785\n",
      "55 Train Loss 82869130.0 Test MSE 176952.50368075343 Test RE 0.18802481911839578\n",
      "56 Train Loss 82271990.0 Test MSE 111200.7803654956 Test RE 0.14905300673021296\n",
      "57 Train Loss 81734450.0 Test MSE 52736.470590517565 Test RE 0.10264607661044685\n",
      "58 Train Loss 81126560.0 Test MSE 8759.409278203004 Test RE 0.04183350306201448\n",
      "59 Train Loss 80658456.0 Test MSE 3632.0654223866545 Test RE 0.026937894950428476\n",
      "60 Train Loss 80206456.0 Test MSE 13703.654676946593 Test RE 0.05232449273684045\n",
      "61 Train Loss 79891840.0 Test MSE 32347.04267060952 Test RE 0.08039038607571117\n",
      "62 Train Loss 79688910.0 Test MSE 68200.34527666909 Test RE 0.11672936159635232\n",
      "63 Train Loss 79469910.0 Test MSE 87483.768383602 Test RE 0.13220581711062324\n",
      "64 Train Loss 79229480.0 Test MSE 95072.0820537165 Test RE 0.13782034290493142\n",
      "65 Train Loss 78981430.0 Test MSE 142857.88043016547 Test RE 0.16894250319881954\n",
      "66 Train Loss 78596460.0 Test MSE 248932.8958597694 Test RE 0.22301186484279312\n",
      "67 Train Loss 78247310.0 Test MSE 240311.2521674692 Test RE 0.21911589185250205\n",
      "68 Train Loss 77956350.0 Test MSE 233973.4812333438 Test RE 0.21620719483335935\n",
      "69 Train Loss 77481960.0 Test MSE 237721.26161237317 Test RE 0.2179319159002589\n",
      "70 Train Loss 77188220.0 Test MSE 224558.55593100854 Test RE 0.21181251993883002\n",
      "71 Train Loss 76939480.0 Test MSE 184234.32866441706 Test RE 0.19185454929301116\n",
      "72 Train Loss 76747700.0 Test MSE 149726.83256356395 Test RE 0.17295640207624763\n",
      "73 Train Loss 76597190.0 Test MSE 145659.099871487 Test RE 0.17059081127348572\n",
      "74 Train Loss 76517660.0 Test MSE 102800.76557170592 Test RE 0.14331280558434084\n",
      "75 Train Loss 76252530.0 Test MSE 55943.35570896064 Test RE 0.10572095570145916\n",
      "76 Train Loss 75976830.0 Test MSE 20718.632848776415 Test RE 0.06433797251836712\n",
      "77 Train Loss 75902270.0 Test MSE 9641.765911894377 Test RE 0.043889952949002144\n",
      "78 Train Loss 75691300.0 Test MSE 17047.09125774213 Test RE 0.05835955432907332\n",
      "79 Train Loss 75294936.0 Test MSE 52214.10191050773 Test RE 0.10213644319667352\n",
      "80 Train Loss 75154680.0 Test MSE 73550.98864043225 Test RE 0.12122189839808226\n",
      "81 Train Loss 74971730.0 Test MSE 103325.36914165177 Test RE 0.1436780107311603\n",
      "82 Train Loss 74749096.0 Test MSE 107868.87268890266 Test RE 0.14680298748063353\n",
      "83 Train Loss 74098240.0 Test MSE 185366.5493586725 Test RE 0.19244317188475346\n",
      "84 Train Loss 73765220.0 Test MSE 244876.51297338982 Test RE 0.22118740314404434\n",
      "85 Train Loss 73684744.0 Test MSE 213906.13506004115 Test RE 0.20672759110722186\n",
      "86 Train Loss 73585570.0 Test MSE 162279.01486134043 Test RE 0.18006031474325693\n",
      "87 Train Loss 73535160.0 Test MSE 161630.32945976767 Test RE 0.17970007267326193\n",
      "88 Train Loss 73271030.0 Test MSE 83707.86516924809 Test RE 0.12932126873665853\n",
      "89 Train Loss 72879220.0 Test MSE 40870.6861299116 Test RE 0.09036344675632542\n",
      "90 Train Loss 72483980.0 Test MSE 40494.86487636942 Test RE 0.08994702440133166\n",
      "91 Train Loss 72088590.0 Test MSE 39055.68547219695 Test RE 0.08833421540615123\n",
      "92 Train Loss 71994880.0 Test MSE 20595.416653018485 Test RE 0.0641463744078182\n",
      "93 Train Loss 71725700.0 Test MSE 7249.107846257452 Test RE 0.03805652275938164\n",
      "94 Train Loss 71400696.0 Test MSE 5715.50087720318 Test RE 0.033792005836288046\n",
      "95 Train Loss 70976584.0 Test MSE 2726.122254922084 Test RE 0.02333777710991734\n",
      "96 Train Loss 70592540.0 Test MSE 19019.099747491473 Test RE 0.06164272112196996\n",
      "97 Train Loss 70183896.0 Test MSE 38515.15181046449 Test RE 0.08772080948044007\n",
      "98 Train Loss 69805464.0 Test MSE 76748.27924009037 Test RE 0.12382865255537026\n",
      "99 Train Loss 69633040.0 Test MSE 56256.59727522066 Test RE 0.10601652226235286\n",
      "100 Train Loss 69332760.0 Test MSE 24024.03367477427 Test RE 0.0692803044694946\n",
      "101 Train Loss 69028160.0 Test MSE 18786.00263939615 Test RE 0.06126381155929127\n",
      "102 Train Loss 68690330.0 Test MSE 7008.9677907432615 Test RE 0.03742086789272173\n",
      "103 Train Loss 68150970.0 Test MSE 7613.966838309984 Test RE 0.03900248820067743\n",
      "104 Train Loss 67855610.0 Test MSE 2562.6003660465085 Test RE 0.022627015042739753\n",
      "105 Train Loss 67544430.0 Test MSE 3283.2014700909376 Test RE 0.025611533950780495\n",
      "106 Train Loss 67177980.0 Test MSE 11916.412164444842 Test RE 0.048793231502589296\n",
      "107 Train Loss 67010932.0 Test MSE 9290.378946364886 Test RE 0.04308276202982908\n",
      "108 Train Loss 66889624.0 Test MSE 11009.448516281653 Test RE 0.046899650475724246\n",
      "109 Train Loss 66726710.0 Test MSE 5294.703231350603 Test RE 0.03252427579594685\n",
      "110 Train Loss 66545410.0 Test MSE 2785.0262931813195 Test RE 0.02358856238810894\n",
      "111 Train Loss 66223704.0 Test MSE 40519.55805496387 Test RE 0.08997444441436685\n",
      "112 Train Loss 65862120.0 Test MSE 69497.74379422735 Test RE 0.11783442217401274\n",
      "113 Train Loss 65746308.0 Test MSE 90200.58390443053 Test RE 0.13424295335823597\n",
      "114 Train Loss 65710470.0 Test MSE 95664.06995856822 Test RE 0.1382487618563918\n",
      "115 Train Loss 65618452.0 Test MSE 111949.0678946631 Test RE 0.14955366644282447\n",
      "116 Train Loss 65507524.0 Test MSE 106312.92809933744 Test RE 0.14574036858387862\n",
      "117 Train Loss 65398650.0 Test MSE 103212.35284065187 Test RE 0.14359941241545426\n",
      "118 Train Loss 65068412.0 Test MSE 123697.41104189667 Test RE 0.15720528008214982\n",
      "119 Train Loss 64645136.0 Test MSE 40139.01994182509 Test RE 0.08955095172850902\n",
      "120 Train Loss 64357940.0 Test MSE 16700.603597047804 Test RE 0.05776342119048968\n",
      "121 Train Loss 63921044.0 Test MSE 1211.3228945603641 Test RE 0.01555667527512601\n",
      "122 Train Loss 63635464.0 Test MSE 21348.97928439678 Test RE 0.06530935303057082\n",
      "123 Train Loss 63418890.0 Test MSE 89598.30006212025 Test RE 0.13379402178376984\n",
      "124 Train Loss 63314496.0 Test MSE 128234.02574165337 Test RE 0.16006208210802925\n",
      "125 Train Loss 63193372.0 Test MSE 144164.76870697323 Test RE 0.16971350133693072\n",
      "126 Train Loss 63122156.0 Test MSE 171154.0814106084 Test RE 0.18491853905103278\n",
      "127 Train Loss 62991700.0 Test MSE 191600.94964024643 Test RE 0.19565261294379357\n",
      "128 Train Loss 62916876.0 Test MSE 148984.06029266887 Test RE 0.17252686336099526\n",
      "129 Train Loss 62872588.0 Test MSE 120521.43073453876 Test RE 0.15517400273752693\n",
      "130 Train Loss 62787572.0 Test MSE 73515.10891141907 Test RE 0.12119232748742395\n",
      "131 Train Loss 62707360.0 Test MSE 57362.73708438063 Test RE 0.10705371835861553\n",
      "132 Train Loss 62624020.0 Test MSE 45053.79464843145 Test RE 0.09487515780739314\n",
      "133 Train Loss 62481130.0 Test MSE 16293.170413995826 Test RE 0.05705446319659603\n",
      "134 Train Loss 62371108.0 Test MSE 16644.761035272983 Test RE 0.05766676724744475\n",
      "135 Train Loss 62287228.0 Test MSE 17607.54163084576 Test RE 0.059311128263229186\n",
      "136 Train Loss 62235290.0 Test MSE 6240.914537486734 Test RE 0.035311075168557714\n",
      "137 Train Loss 62182836.0 Test MSE 1061.7952913107454 Test RE 0.014564890408515371\n",
      "138 Train Loss 62095220.0 Test MSE 1506.8945260044209 Test RE 0.017351149481297377\n",
      "139 Train Loss 62003640.0 Test MSE 2514.3642140118936 Test RE 0.022413047787817383\n",
      "140 Train Loss 61939732.0 Test MSE 1484.3456929396398 Test RE 0.017220840804015196\n",
      "141 Train Loss 61854756.0 Test MSE 1698.1852606292844 Test RE 0.0184195644745023\n",
      "142 Train Loss 61726828.0 Test MSE 8873.181146189749 Test RE 0.042104304467987165\n",
      "143 Train Loss 61615024.0 Test MSE 13779.596234761482 Test RE 0.05246927577663677\n",
      "144 Train Loss 61504216.0 Test MSE 16782.802180190025 Test RE 0.057905399392375566\n",
      "145 Train Loss 61471264.0 Test MSE 14416.52221352889 Test RE 0.05366820578933379\n",
      "146 Train Loss 61459940.0 Test MSE 10267.166115496093 Test RE 0.04529102171396405\n",
      "147 Train Loss 61450548.0 Test MSE 12681.904130533145 Test RE 0.050336041216053715\n",
      "148 Train Loss 61411620.0 Test MSE 24865.371094232203 Test RE 0.07048298625823993\n",
      "149 Train Loss 61338220.0 Test MSE 58822.54283462206 Test RE 0.10840734817518353\n",
      "150 Train Loss 61288480.0 Test MSE 39106.686057967556 Test RE 0.08839187188941748\n",
      "151 Train Loss 61252110.0 Test MSE 18914.263803678215 Test RE 0.06147259469803478\n",
      "152 Train Loss 61217348.0 Test MSE 6646.732876793978 Test RE 0.036441054553620254\n",
      "153 Train Loss 61139310.0 Test MSE 3054.6522492837025 Test RE 0.02470402463074242\n",
      "154 Train Loss 61097852.0 Test MSE 4337.69537824301 Test RE 0.02943854549595202\n",
      "155 Train Loss 61055070.0 Test MSE 6612.335464411743 Test RE 0.03634663945312914\n",
      "156 Train Loss 60989290.0 Test MSE 2624.56043933387 Test RE 0.022898925956214074\n",
      "157 Train Loss 60915844.0 Test MSE 4773.695983484575 Test RE 0.030882624594843845\n",
      "158 Train Loss 60872252.0 Test MSE 19932.15192199649 Test RE 0.06310502134885987\n",
      "159 Train Loss 60827144.0 Test MSE 54465.05042487254 Test RE 0.10431476371751225\n",
      "160 Train Loss 60768576.0 Test MSE 68787.94051524372 Test RE 0.1172311370092866\n",
      "161 Train Loss 60702680.0 Test MSE 61700.439957611576 Test RE 0.11102760049981404\n",
      "162 Train Loss 60646056.0 Test MSE 58061.137526253966 Test RE 0.10770344472993978\n",
      "163 Train Loss 60626170.0 Test MSE 54653.272617406605 Test RE 0.10449485553205326\n",
      "164 Train Loss 60614428.0 Test MSE 49282.843407085595 Test RE 0.0992281060322338\n",
      "165 Train Loss 60583230.0 Test MSE 35177.75932695012 Test RE 0.08383413937354045\n",
      "166 Train Loss 60553290.0 Test MSE 22582.781340235 Test RE 0.06717002939920019\n",
      "167 Train Loss 60474676.0 Test MSE 9096.15206465562 Test RE 0.04263003406425297\n",
      "168 Train Loss 60379864.0 Test MSE 7457.975821765524 Test RE 0.03860088920989034\n",
      "169 Train Loss 60256956.0 Test MSE 6231.381651790008 Test RE 0.03528409634329421\n",
      "170 Train Loss 60194220.0 Test MSE 6066.73883327488 Test RE 0.034814845591984445\n",
      "171 Train Loss 60121460.0 Test MSE 10876.517560315398 Test RE 0.04661565128947497\n",
      "172 Train Loss 60048132.0 Test MSE 8316.300198246225 Test RE 0.04076166379888129\n",
      "173 Train Loss 59991930.0 Test MSE 1606.2509145760696 Test RE 0.01791403909350766\n",
      "174 Train Loss 59939360.0 Test MSE 986.3650320589744 Test RE 0.014038013555039572\n",
      "175 Train Loss 59872748.0 Test MSE 1370.428257027695 Test RE 0.016546836516226834\n",
      "176 Train Loss 59796108.0 Test MSE 3477.69214715698 Test RE 0.026359210055950887\n",
      "177 Train Loss 59766396.0 Test MSE 3366.147673257804 Test RE 0.025933038569420964\n",
      "178 Train Loss 59749920.0 Test MSE 1672.700158288847 Test RE 0.01828082842765003\n",
      "179 Train Loss 59736610.0 Test MSE 981.2888032475432 Test RE 0.014001844344577314\n",
      "180 Train Loss 59702708.0 Test MSE 8565.108947389514 Test RE 0.04136692790438868\n",
      "181 Train Loss 59645696.0 Test MSE 15768.45757166385 Test RE 0.05612824080548371\n",
      "182 Train Loss 59586676.0 Test MSE 9474.883958242503 Test RE 0.0435084662104983\n",
      "183 Train Loss 59576890.0 Test MSE 6454.901604741593 Test RE 0.03591134216266531\n",
      "184 Train Loss 59564796.0 Test MSE 2556.5332841284803 Test RE 0.02260021388672882\n",
      "185 Train Loss 59535544.0 Test MSE 1179.8651593166849 Test RE 0.015353345112137743\n",
      "186 Train Loss 59477880.0 Test MSE 4264.750874763295 Test RE 0.02918997057053124\n",
      "187 Train Loss 59433100.0 Test MSE 10860.877571367027 Test RE 0.0465821235289502\n",
      "188 Train Loss 59419400.0 Test MSE 13943.637119006175 Test RE 0.05278066522196924\n",
      "189 Train Loss 59375430.0 Test MSE 18313.067353455648 Test RE 0.0604877416313306\n",
      "190 Train Loss 59366636.0 Test MSE 14760.635311627668 Test RE 0.05430494132905624\n",
      "191 Train Loss 59358960.0 Test MSE 9046.543140190955 Test RE 0.04251362651636611\n",
      "192 Train Loss 59357412.0 Test MSE 6233.814559980335 Test RE 0.03529098362724913\n",
      "193 Train Loss 59357140.0 Test MSE 4971.698466115234 Test RE 0.03151658942209166\n",
      "194 Train Loss 59356692.0 Test MSE 4487.339458836312 Test RE 0.02994203307933597\n",
      "195 Train Loss 59320188.0 Test MSE 4156.669910520085 Test RE 0.028817718351967447\n",
      "196 Train Loss 59289150.0 Test MSE 4300.922854643905 Test RE 0.029313498257830875\n",
      "197 Train Loss 59239544.0 Test MSE 6452.249206165892 Test RE 0.03590396319814966\n",
      "198 Train Loss 59186764.0 Test MSE 8139.177328128102 Test RE 0.04032525096692898\n",
      "199 Train Loss 59142444.0 Test MSE 5185.155813602893 Test RE 0.03218605353995994\n",
      "Training time: 79.75\n",
      "Training time: 79.75\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "3\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 1.81\n",
      "Training time: 1.81\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "4\n",
      "0 Train Loss 389035680.0 Test MSE 12990683.606200911 Test RE 1.611027027272757\n",
      "1 Train Loss 187790960.0 Test MSE 13608987.25565426 Test RE 1.6489205379290461\n",
      "2 Train Loss 103542140.0 Test MSE 11921176.221946627 Test RE 1.5432858618205898\n",
      "3 Train Loss 80425760.0 Test MSE 12802551.238186933 Test RE 1.599318956748711\n",
      "4 Train Loss 80987850.0 Test MSE 12333567.049270827 Test RE 1.569752463223278\n",
      "5 Train Loss 80378800.0 Test MSE 10142758.67066022 Test RE 1.4235242499479528\n",
      "6 Train Loss 79667570.0 Test MSE 8447818.206706934 Test RE 1.2991494188655877\n",
      "7 Train Loss 80108330.0 Test MSE 7260311.680886871 Test RE 1.2043825547319744\n",
      "8 Train Loss 80727280.0 Test MSE 5802535.406887522 Test RE 1.076702504473017\n",
      "9 Train Loss 80676056.0 Test MSE 3748625.3009652137 Test RE 0.8654118540684166\n",
      "10 Train Loss 80756220.0 Test MSE 2342337.924197308 Test RE 0.6840874115031945\n",
      "11 Train Loss 81341940.0 Test MSE 2553764.4352182397 Test RE 0.7142943927604003\n",
      "12 Train Loss 81886950.0 Test MSE 2242444.4719452416 Test RE 0.6693413765244444\n",
      "13 Train Loss 82287430.0 Test MSE 1115285.7402997117 Test RE 0.47204119202170114\n",
      "14 Train Loss 82863870.0 Test MSE 756181.716057303 Test RE 0.388686905377297\n",
      "15 Train Loss 83313480.0 Test MSE 617762.8865148494 Test RE 0.3513158390938384\n",
      "16 Train Loss 83509660.0 Test MSE 413184.1215985308 Test RE 0.28731522188522757\n",
      "17 Train Loss 83751380.0 Test MSE 423714.24195314996 Test RE 0.29095334504047415\n",
      "18 Train Loss 84132730.0 Test MSE 451736.7983723157 Test RE 0.30042049572817764\n",
      "19 Train Loss 84493790.0 Test MSE 482206.947390355 Test RE 0.31038702281199837\n",
      "20 Train Loss 84689390.0 Test MSE 525058.2386306997 Test RE 0.3238847965620874\n",
      "21 Train Loss 85010640.0 Test MSE 538043.7693763226 Test RE 0.3278654297678991\n",
      "22 Train Loss 85363320.0 Test MSE 523108.1633738638 Test RE 0.3232827802371028\n",
      "23 Train Loss 85612960.0 Test MSE 580856.5830931764 Test RE 0.3406601093879386\n",
      "24 Train Loss 85629280.0 Test MSE 622424.9533135846 Test RE 0.35263898382108333\n",
      "25 Train Loss 85728990.0 Test MSE 724038.4298441398 Test RE 0.3803361733147103\n",
      "26 Train Loss 85429144.0 Test MSE 881058.5152825688 Test RE 0.4195552888578771\n",
      "27 Train Loss 85337870.0 Test MSE 894523.2506405872 Test RE 0.4227490499918363\n",
      "28 Train Loss 84882920.0 Test MSE 898326.700465623 Test RE 0.42364684624733717\n",
      "29 Train Loss 84623500.0 Test MSE 885376.8871500432 Test RE 0.4205822246912041\n",
      "30 Train Loss 84741576.0 Test MSE 907174.9000481591 Test RE 0.42572811949011524\n",
      "31 Train Loss 84437000.0 Test MSE 984235.8146336231 Test RE 0.4434415726108677\n",
      "32 Train Loss 83908660.0 Test MSE 981946.4487630167 Test RE 0.4429255422948451\n",
      "33 Train Loss 83414520.0 Test MSE 1056122.543212608 Test RE 0.4593502743325561\n",
      "34 Train Loss 83017816.0 Test MSE 1105958.9850252725 Test RE 0.4700632882455617\n",
      "35 Train Loss 82803640.0 Test MSE 1173334.1230206967 Test RE 0.4841697746555471\n",
      "36 Train Loss 82551280.0 Test MSE 1211155.75620333 Test RE 0.4919113264105854\n",
      "37 Train Loss 82628296.0 Test MSE 1202598.7257267362 Test RE 0.490170525760255\n",
      "38 Train Loss 82737736.0 Test MSE 1239568.068411355 Test RE 0.49764771435780386\n",
      "39 Train Loss 82703656.0 Test MSE 1249719.564110516 Test RE 0.4996813129047956\n",
      "40 Train Loss 82654920.0 Test MSE 1269719.5399862255 Test RE 0.5036637854067987\n",
      "41 Train Loss 82689304.0 Test MSE 1263476.4251484848 Test RE 0.5024240212239651\n",
      "42 Train Loss 82749250.0 Test MSE 1263683.2687105576 Test RE 0.5024651454266759\n",
      "43 Train Loss 82718270.0 Test MSE 1284666.378782102 Test RE 0.506619617631065\n",
      "44 Train Loss 82134020.0 Test MSE 1243007.7449622822 Test RE 0.4983376971754102\n",
      "45 Train Loss 82278904.0 Test MSE 1228482.4461951577 Test RE 0.4954174519037299\n",
      "46 Train Loss 82353700.0 Test MSE 1225792.7327810458 Test RE 0.49487480632074016\n",
      "47 Train Loss 82391600.0 Test MSE 1230625.9868000273 Test RE 0.49584948273648505\n",
      "48 Train Loss 82496670.0 Test MSE 1229873.8661336566 Test RE 0.49569793561861725\n",
      "49 Train Loss 82461864.0 Test MSE 1263661.727673723 Test RE 0.502460862839971\n",
      "50 Train Loss 82373610.0 Test MSE 1326179.9332651475 Test RE 0.5147401559205904\n",
      "51 Train Loss 82298590.0 Test MSE 1332522.1259479495 Test RE 0.5159695092762036\n",
      "52 Train Loss 82108590.0 Test MSE 1333886.2273390805 Test RE 0.5162335404225238\n",
      "53 Train Loss 81958070.0 Test MSE 1311319.1295238037 Test RE 0.5118480133969624\n",
      "54 Train Loss 81983990.0 Test MSE 1322451.570965178 Test RE 0.5140160880595396\n",
      "55 Train Loss 81799050.0 Test MSE 1366478.7272791837 Test RE 0.5225023658579964\n",
      "56 Train Loss 81668620.0 Test MSE 1353842.3351267274 Test RE 0.5200808572884744\n",
      "57 Train Loss 81706424.0 Test MSE 1330055.101547911 Test RE 0.5154916563930523\n",
      "58 Train Loss 81672380.0 Test MSE 1320958.6813096658 Test RE 0.5137258747894096\n",
      "59 Train Loss 80982824.0 Test MSE 1373929.281107693 Test RE 0.5239248687887463\n",
      "60 Train Loss 80635200.0 Test MSE 1418207.0724460343 Test RE 0.5323002217156285\n",
      "61 Train Loss 80080320.0 Test MSE 1447710.4188033033 Test RE 0.5378085144879461\n",
      "62 Train Loss 79681240.0 Test MSE 1442860.5238157883 Test RE 0.5369069174059323\n",
      "63 Train Loss 79262744.0 Test MSE 1425459.5091378398 Test RE 0.5336595263208014\n",
      "64 Train Loss 78849544.0 Test MSE 1446164.226204129 Test RE 0.5375212409823173\n",
      "65 Train Loss 78698830.0 Test MSE 1486633.7001345055 Test RE 0.5449903474832262\n",
      "66 Train Loss 78310060.0 Test MSE 1490641.6232976448 Test RE 0.5457244924273195\n",
      "67 Train Loss 77967710.0 Test MSE 1449385.923869792 Test RE 0.5381196403553892\n",
      "68 Train Loss 77794500.0 Test MSE 1404419.0730345624 Test RE 0.5297063547548702\n",
      "69 Train Loss 77324840.0 Test MSE 1323606.9264215743 Test RE 0.5142405732706637\n",
      "70 Train Loss 76327260.0 Test MSE 1267437.9211602078 Test RE 0.5032110533459817\n",
      "71 Train Loss 75860696.0 Test MSE 1283990.4688880318 Test RE 0.5064863245556313\n",
      "72 Train Loss 74877380.0 Test MSE 1130439.4583236955 Test RE 0.4752372540059502\n",
      "73 Train Loss 74589730.0 Test MSE 1114587.2940755277 Test RE 0.4718933612863539\n",
      "74 Train Loss 74203384.0 Test MSE 1124373.3465546994 Test RE 0.4739604407571014\n",
      "75 Train Loss 73785736.0 Test MSE 1124019.2081065385 Test RE 0.47388579436223893\n",
      "76 Train Loss 73412424.0 Test MSE 1130908.8864106864 Test RE 0.4753359176530975\n",
      "77 Train Loss 73149940.0 Test MSE 1126185.464369992 Test RE 0.4743422206993317\n",
      "78 Train Loss 72856060.0 Test MSE 1136826.0194079317 Test RE 0.47657781981705655\n",
      "79 Train Loss 72637850.0 Test MSE 1153212.7790312897 Test RE 0.48000034197496344\n",
      "80 Train Loss 72361980.0 Test MSE 1107138.5027833802 Test RE 0.47031388535220897\n",
      "81 Train Loss 71876000.0 Test MSE 993560.922720806 Test RE 0.44553730622381266\n",
      "82 Train Loss 71576060.0 Test MSE 932915.2556239496 Test RE 0.4317257186987568\n",
      "83 Train Loss 71286190.0 Test MSE 884259.0286172703 Test RE 0.4203166316256673\n",
      "84 Train Loss 71100720.0 Test MSE 901633.9605734413 Test RE 0.4244259743238582\n",
      "85 Train Loss 70738540.0 Test MSE 873270.6880445116 Test RE 0.4176969125591801\n",
      "86 Train Loss 70218270.0 Test MSE 742114.5320862548 Test RE 0.38505457843089747\n",
      "87 Train Loss 69137410.0 Test MSE 505472.94085376157 Test RE 0.3177867456304261\n",
      "88 Train Loss 68702100.0 Test MSE 435358.9502379766 Test RE 0.29492430338146747\n",
      "89 Train Loss 68091176.0 Test MSE 365213.05177784566 Test RE 0.2701220074058207\n",
      "90 Train Loss 67662790.0 Test MSE 333987.22858932934 Test RE 0.2583162656522324\n",
      "91 Train Loss 67224080.0 Test MSE 341607.8073586196 Test RE 0.2612466424353553\n",
      "92 Train Loss 66909676.0 Test MSE 317214.68356521265 Test RE 0.2517465135775792\n",
      "93 Train Loss 66572830.0 Test MSE 283571.37796586496 Test RE 0.23802250442744108\n",
      "94 Train Loss 66102990.0 Test MSE 300407.67731434683 Test RE 0.24498660389805837\n",
      "95 Train Loss 65501850.0 Test MSE 282065.99937916343 Test RE 0.23738987572142323\n",
      "96 Train Loss 65232810.0 Test MSE 266396.41699841205 Test RE 0.23070181609379997\n",
      "97 Train Loss 64442628.0 Test MSE 229789.9288901709 Test RE 0.21426553471500884\n",
      "98 Train Loss 63595084.0 Test MSE 170220.8523751802 Test RE 0.1844137096273747\n",
      "99 Train Loss 63138040.0 Test MSE 151164.40354653916 Test RE 0.1737847210199928\n",
      "100 Train Loss 62558216.0 Test MSE 148634.68105247093 Test RE 0.17232445014793699\n",
      "101 Train Loss 61939830.0 Test MSE 175546.80026962023 Test RE 0.1872764992848485\n",
      "102 Train Loss 61490484.0 Test MSE 174662.22299012626 Test RE 0.18680406186761206\n",
      "103 Train Loss 60993510.0 Test MSE 169903.24869179368 Test RE 0.18424158670933857\n",
      "104 Train Loss 60523770.0 Test MSE 172680.77068978368 Test RE 0.18574144197222095\n",
      "105 Train Loss 59882572.0 Test MSE 168164.02964529302 Test RE 0.18329616411574143\n",
      "106 Train Loss 59620424.0 Test MSE 178179.36138844295 Test RE 0.18867550569622074\n",
      "107 Train Loss 59275508.0 Test MSE 167816.0806675532 Test RE 0.18310643644946262\n",
      "108 Train Loss 58739330.0 Test MSE 164659.94334671157 Test RE 0.18137641119634895\n",
      "109 Train Loss 58201790.0 Test MSE 180033.20438464108 Test RE 0.1896544902105243\n",
      "110 Train Loss 57790988.0 Test MSE 187704.7031338869 Test RE 0.19365307650721247\n",
      "111 Train Loss 57642510.0 Test MSE 189313.09092758212 Test RE 0.194480985611276\n",
      "112 Train Loss 57221748.0 Test MSE 201862.23656181313 Test RE 0.2008234224281192\n",
      "113 Train Loss 56633420.0 Test MSE 203452.32275340767 Test RE 0.20161282261583097\n",
      "114 Train Loss 56170988.0 Test MSE 198702.18738622474 Test RE 0.19924532846646148\n",
      "115 Train Loss 55697836.0 Test MSE 195353.06512567168 Test RE 0.19755905429184817\n",
      "116 Train Loss 55358064.0 Test MSE 192815.00124496513 Test RE 0.19627149631626886\n",
      "117 Train Loss 54819864.0 Test MSE 225865.12845330354 Test RE 0.21242783166811\n",
      "118 Train Loss 54340236.0 Test MSE 269652.6743448462 Test RE 0.23210750839871244\n",
      "119 Train Loss 53872464.0 Test MSE 314792.60432520683 Test RE 0.25078357202587365\n",
      "120 Train Loss 53525816.0 Test MSE 354838.7489558359 Test RE 0.2662578025135956\n",
      "121 Train Loss 53232110.0 Test MSE 400236.64747798356 Test RE 0.2827777598495214\n",
      "122 Train Loss 53076628.0 Test MSE 394471.0037822962 Test RE 0.28073358148904437\n",
      "123 Train Loss 52873596.0 Test MSE 375169.54211596557 Test RE 0.2737793009588463\n",
      "124 Train Loss 52594868.0 Test MSE 393119.80318703206 Test RE 0.2802523638983873\n",
      "125 Train Loss 52244464.0 Test MSE 420564.2976269498 Test RE 0.2898698358877703\n",
      "126 Train Loss 51571640.0 Test MSE 432535.67628508207 Test RE 0.2939664656917929\n",
      "127 Train Loss 51030932.0 Test MSE 419159.418793882 Test RE 0.2893852813808941\n",
      "128 Train Loss 50679720.0 Test MSE 383125.989941561 Test RE 0.276667171851161\n",
      "129 Train Loss 50458440.0 Test MSE 360529.8848494919 Test RE 0.26838451739782204\n",
      "130 Train Loss 50171936.0 Test MSE 360679.68266363064 Test RE 0.26844026761513756\n",
      "131 Train Loss 49920850.0 Test MSE 350312.9672650685 Test RE 0.26455436432364576\n",
      "132 Train Loss 49457664.0 Test MSE 319254.65732804354 Test RE 0.2525546938053117\n",
      "133 Train Loss 49073004.0 Test MSE 320390.65341537993 Test RE 0.25300362441938606\n",
      "134 Train Loss 48884890.0 Test MSE 337562.39023943874 Test RE 0.2596951568335814\n",
      "135 Train Loss 48569772.0 Test MSE 342592.75545758364 Test RE 0.2616229938658293\n",
      "136 Train Loss 48263744.0 Test MSE 309450.4598009126 Test RE 0.24864652257423936\n",
      "137 Train Loss 48026804.0 Test MSE 280180.4928455182 Test RE 0.23659511370915376\n",
      "138 Train Loss 47776964.0 Test MSE 272089.8718243007 Test RE 0.2331540757264067\n",
      "139 Train Loss 47661270.0 Test MSE 269874.5566538762 Test RE 0.2322029829942231\n",
      "140 Train Loss 47525916.0 Test MSE 234500.7234576457 Test RE 0.21645066134699495\n",
      "141 Train Loss 47226384.0 Test MSE 193468.20619130615 Test RE 0.1966036725306384\n",
      "142 Train Loss 47004336.0 Test MSE 180726.45192488254 Test RE 0.1900192873140048\n",
      "143 Train Loss 46822996.0 Test MSE 160074.75359057102 Test RE 0.1788332398832133\n",
      "144 Train Loss 46725372.0 Test MSE 138467.87551324634 Test RE 0.16632645762424572\n",
      "145 Train Loss 46584140.0 Test MSE 109496.93018120187 Test RE 0.14790668228666054\n",
      "146 Train Loss 46380064.0 Test MSE 84223.94908777914 Test RE 0.12971930823937317\n",
      "147 Train Loss 46259470.0 Test MSE 74477.65159217267 Test RE 0.12198314063801786\n",
      "148 Train Loss 45815056.0 Test MSE 31879.73391288291 Test RE 0.07980758471537816\n",
      "149 Train Loss 45586156.0 Test MSE 23085.48448938279 Test RE 0.06791353244111031\n",
      "150 Train Loss 45361040.0 Test MSE 21935.296270567393 Test RE 0.06620008940387195\n",
      "151 Train Loss 45198236.0 Test MSE 15331.592779197023 Test RE 0.05534526374535945\n",
      "152 Train Loss 45065156.0 Test MSE 13067.56699581396 Test RE 0.0510956809475341\n",
      "153 Train Loss 44939348.0 Test MSE 11275.850532103623 Test RE 0.047463687817981264\n",
      "154 Train Loss 44826584.0 Test MSE 12144.720511232043 Test RE 0.049258432319872876\n",
      "155 Train Loss 44740020.0 Test MSE 12957.827749144577 Test RE 0.05088068211440446\n",
      "156 Train Loss 44617070.0 Test MSE 10318.544723771645 Test RE 0.04540420220297428\n",
      "157 Train Loss 44470456.0 Test MSE 8159.906075012468 Test RE 0.040376568216433255\n",
      "158 Train Loss 44306508.0 Test MSE 8052.617889052476 Test RE 0.04011025005130257\n",
      "159 Train Loss 44103950.0 Test MSE 12222.613216026042 Test RE 0.04941614447257259\n",
      "160 Train Loss 43938612.0 Test MSE 19385.986408247732 Test RE 0.06223443850849018\n",
      "161 Train Loss 43791364.0 Test MSE 30217.019441431326 Test RE 0.07769850017868347\n",
      "162 Train Loss 43526470.0 Test MSE 63425.02520800455 Test RE 0.11256856968498001\n",
      "163 Train Loss 43055920.0 Test MSE 165543.86754059535 Test RE 0.1818625901956533\n",
      "164 Train Loss 42754916.0 Test MSE 224581.97526219825 Test RE 0.21182356467103192\n",
      "165 Train Loss 42466080.0 Test MSE 300396.2437135344 Test RE 0.244981941724123\n",
      "166 Train Loss 42169388.0 Test MSE 372288.97800546064 Test RE 0.2727262324416744\n",
      "167 Train Loss 41973676.0 Test MSE 419768.6818797282 Test RE 0.2895955208975291\n",
      "168 Train Loss 41786264.0 Test MSE 467986.97013135016 Test RE 0.305776217722881\n",
      "169 Train Loss 41385292.0 Test MSE 553726.3090023958 Test RE 0.33260931122022697\n",
      "170 Train Loss 41117196.0 Test MSE 642641.6777226205 Test RE 0.35832017994240317\n",
      "171 Train Loss 40909628.0 Test MSE 658783.3184679849 Test RE 0.3627923497250918\n",
      "172 Train Loss 40691016.0 Test MSE 653112.4898312717 Test RE 0.3612275106155326\n",
      "173 Train Loss 40560810.0 Test MSE 667257.5369369198 Test RE 0.36511827226088434\n",
      "174 Train Loss 40182330.0 Test MSE 755924.5191792055 Test RE 0.38862079854182585\n",
      "175 Train Loss 39738870.0 Test MSE 828550.1953071906 Test RE 0.4068611625186735\n",
      "176 Train Loss 39046676.0 Test MSE 869100.8156302584 Test RE 0.4166984666912539\n",
      "177 Train Loss 38781236.0 Test MSE 905276.3261769932 Test RE 0.4252823952832281\n",
      "178 Train Loss 38575468.0 Test MSE 916547.2786422789 Test RE 0.4279216503223195\n",
      "179 Train Loss 38256828.0 Test MSE 911089.867616533 Test RE 0.4266457581129077\n",
      "180 Train Loss 37920212.0 Test MSE 882922.1765918356 Test RE 0.4199987871604204\n",
      "181 Train Loss 37540770.0 Test MSE 827556.3961776735 Test RE 0.40661708582336337\n",
      "182 Train Loss 37258280.0 Test MSE 793458.3398211399 Test RE 0.39815198777097977\n",
      "183 Train Loss 36993700.0 Test MSE 800385.8963626758 Test RE 0.39988631080605547\n",
      "184 Train Loss 36797664.0 Test MSE 813088.0109816861 Test RE 0.4030469159638223\n",
      "185 Train Loss 36510284.0 Test MSE 842857.0898423287 Test RE 0.4103588421977147\n",
      "186 Train Loss 36347250.0 Test MSE 842908.303153026 Test RE 0.4103713090298189\n",
      "187 Train Loss 36220436.0 Test MSE 829791.1035567895 Test RE 0.4071657237150373\n",
      "188 Train Loss 35967036.0 Test MSE 803421.7827453137 Test RE 0.40064398307149945\n",
      "189 Train Loss 35668332.0 Test MSE 755871.9791722734 Test RE 0.3886072928982525\n",
      "190 Train Loss 35388564.0 Test MSE 695407.5655532188 Test RE 0.37274045348811025\n",
      "191 Train Loss 35175170.0 Test MSE 675585.6141630755 Test RE 0.36738973707262546\n",
      "192 Train Loss 35003540.0 Test MSE 674662.250259481 Test RE 0.3671385842897629\n",
      "193 Train Loss 34769256.0 Test MSE 662695.9731694204 Test RE 0.36386810539345366\n",
      "194 Train Loss 34571856.0 Test MSE 633374.1207606294 Test RE 0.3557271237522519\n",
      "195 Train Loss 34342640.0 Test MSE 594390.9336926043 Test RE 0.3446060611981136\n",
      "196 Train Loss 34135936.0 Test MSE 593382.0835186216 Test RE 0.3443134898380132\n",
      "197 Train Loss 33819710.0 Test MSE 606825.9585513812 Test RE 0.3481920884531802\n",
      "198 Train Loss 33645100.0 Test MSE 578216.09939269 Test RE 0.33988493348578713\n",
      "199 Train Loss 33361468.0 Test MSE 525912.7948779417 Test RE 0.3241482580510893\n",
      "Training time: 78.93\n",
      "Training time: 78.93\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "5\n",
      "0 Train Loss 312589630.0 Test MSE 2041746.1760664429 Test RE 0.6386864449693891\n",
      "1 Train Loss 86779560.0 Test MSE 3190037.212487741 Test RE 0.7983341334009992\n",
      "2 Train Loss 75975250.0 Test MSE 4782465.198660384 Test RE 0.9774909221902409\n",
      "3 Train Loss 75881576.0 Test MSE 5458095.045144554 Test RE 1.0442569411040685\n",
      "4 Train Loss 75644190.0 Test MSE 3844162.633092034 Test RE 0.8763703990729949\n",
      "5 Train Loss 75643304.0 Test MSE 1302038.2088670009 Test RE 0.510033483318043\n",
      "6 Train Loss 76493120.0 Test MSE 764287.9949939945 Test RE 0.3907647163053587\n",
      "7 Train Loss 77508400.0 Test MSE 407431.8182331338 Test RE 0.28530822683737567\n",
      "8 Train Loss 78547730.0 Test MSE 254193.70546788283 Test RE 0.2253560488899224\n",
      "9 Train Loss 79681630.0 Test MSE 227229.5459165474 Test RE 0.21306848797908826\n",
      "10 Train Loss 80747160.0 Test MSE 232586.97697125192 Test RE 0.21556563147844354\n",
      "11 Train Loss 81837940.0 Test MSE 242266.29910580307 Test RE 0.22000539266247537\n",
      "12 Train Loss 82877930.0 Test MSE 255157.46655051614 Test RE 0.22578285708580326\n",
      "13 Train Loss 83867144.0 Test MSE 272277.96807544807 Test RE 0.233234651733475\n",
      "14 Train Loss 84724280.0 Test MSE 315398.8206408142 Test RE 0.25102493088930844\n",
      "15 Train Loss 85556620.0 Test MSE 331856.36861888494 Test RE 0.2574909099067975\n",
      "16 Train Loss 86432650.0 Test MSE 323275.3501608046 Test RE 0.2541400546942009\n",
      "17 Train Loss 87053040.0 Test MSE 338063.97861113824 Test RE 0.25988802742839745\n",
      "18 Train Loss 87511640.0 Test MSE 321032.6099398794 Test RE 0.2532569652230096\n",
      "19 Train Loss 87921770.0 Test MSE 305666.2411392343 Test RE 0.24712151730513715\n",
      "20 Train Loss 88466290.0 Test MSE 285612.7557447587 Test RE 0.2388777080157221\n",
      "21 Train Loss 88649930.0 Test MSE 213082.1881689796 Test RE 0.2063290590619097\n",
      "22 Train Loss 88856024.0 Test MSE 176131.70300056515 Test RE 0.18758823223808582\n",
      "23 Train Loss 88887450.0 Test MSE 113166.40154282706 Test RE 0.15036459084603143\n",
      "24 Train Loss 89152160.0 Test MSE 101722.05820726408 Test RE 0.1425589188705037\n",
      "25 Train Loss 89423120.0 Test MSE 98004.20047668905 Test RE 0.1399294633872494\n",
      "26 Train Loss 89248440.0 Test MSE 70344.64574580267 Test RE 0.11855021531483469\n",
      "27 Train Loss 89086290.0 Test MSE 75315.50503724879 Test RE 0.1226673603748188\n",
      "28 Train Loss 89217790.0 Test MSE 86903.45741148453 Test RE 0.13176660341433713\n",
      "29 Train Loss 89076580.0 Test MSE 72849.16169725236 Test RE 0.12064215962260653\n",
      "30 Train Loss 88989250.0 Test MSE 51842.671863701245 Test RE 0.10177251611722285\n",
      "31 Train Loss 88841670.0 Test MSE 90012.18633071925 Test RE 0.13410268671327913\n",
      "32 Train Loss 88408584.0 Test MSE 147483.28420987295 Test RE 0.1716556978266366\n",
      "33 Train Loss 87943590.0 Test MSE 179410.92541914954 Test RE 0.189326439175842\n",
      "34 Train Loss 87822344.0 Test MSE 183729.67489695418 Test RE 0.1915916055868323\n",
      "35 Train Loss 87901030.0 Test MSE 195338.06435185234 Test RE 0.19755146906255902\n",
      "36 Train Loss 87837310.0 Test MSE 174546.63911167157 Test RE 0.18674224222831012\n",
      "37 Train Loss 87275370.0 Test MSE 193755.56407560696 Test RE 0.19674962584735858\n",
      "38 Train Loss 86316550.0 Test MSE 225601.9413165926 Test RE 0.21230403086429497\n",
      "39 Train Loss 85795384.0 Test MSE 235642.58375064755 Test RE 0.2169770057245324\n",
      "40 Train Loss 84749270.0 Test MSE 205681.24815723297 Test RE 0.2027142006556269\n",
      "41 Train Loss 84151704.0 Test MSE 199013.3306315682 Test RE 0.19940126431505487\n",
      "42 Train Loss 83905370.0 Test MSE 214514.9194769784 Test RE 0.20702155910862832\n",
      "43 Train Loss 83698500.0 Test MSE 222330.5630001812 Test RE 0.21075913502680627\n",
      "44 Train Loss 83487080.0 Test MSE 215043.9248086309 Test RE 0.207276665080142\n",
      "45 Train Loss 83305210.0 Test MSE 207339.99552731478 Test RE 0.20352996882163132\n",
      "46 Train Loss 83117420.0 Test MSE 186674.21275007247 Test RE 0.1931207715760552\n",
      "47 Train Loss 82551560.0 Test MSE 172024.67367730098 Test RE 0.18538824578125393\n",
      "48 Train Loss 82257350.0 Test MSE 170375.45799856898 Test RE 0.1844974388682518\n",
      "49 Train Loss 82198700.0 Test MSE 163135.51060423045 Test RE 0.18053486142758754\n",
      "50 Train Loss 82132710.0 Test MSE 182627.25112213212 Test RE 0.19101594209873854\n",
      "51 Train Loss 81832690.0 Test MSE 197733.45250496684 Test RE 0.19875904361351104\n",
      "52 Train Loss 81463144.0 Test MSE 123722.53195039349 Test RE 0.15722124217441166\n",
      "53 Train Loss 81005440.0 Test MSE 78534.60340156581 Test RE 0.12526142589030162\n",
      "54 Train Loss 80354350.0 Test MSE 31080.523346624886 Test RE 0.07880086506936299\n",
      "55 Train Loss 79984600.0 Test MSE 3050.671789404399 Test RE 0.024687923708959\n",
      "56 Train Loss 79301540.0 Test MSE 40165.02103541996 Test RE 0.08957995151137338\n",
      "57 Train Loss 78662330.0 Test MSE 53297.5883531013 Test RE 0.10319071051020312\n",
      "58 Train Loss 78385780.0 Test MSE 117743.43718236484 Test RE 0.15337521286391753\n",
      "59 Train Loss 78290690.0 Test MSE 122943.35792273967 Test RE 0.1567253899263696\n",
      "60 Train Loss 78032740.0 Test MSE 115825.43501908494 Test RE 0.1521208675912365\n",
      "61 Train Loss 77489576.0 Test MSE 104055.25364079732 Test RE 0.1441845843296468\n",
      "62 Train Loss 77208920.0 Test MSE 143570.0823953649 Test RE 0.1693631016044689\n",
      "63 Train Loss 76629440.0 Test MSE 145508.69768490738 Test RE 0.1705027156527981\n",
      "64 Train Loss 75621270.0 Test MSE 149470.10855941186 Test RE 0.17280806156580522\n",
      "65 Train Loss 75350136.0 Test MSE 143641.3619229599 Test RE 0.16940513899713516\n",
      "66 Train Loss 75015670.0 Test MSE 114040.27863389593 Test RE 0.15094403613355634\n",
      "67 Train Loss 74780980.0 Test MSE 101868.38590455489 Test RE 0.1426614178867769\n",
      "68 Train Loss 74489930.0 Test MSE 67252.96928591898 Test RE 0.11591577827413133\n",
      "69 Train Loss 74021780.0 Test MSE 37899.88864993236 Test RE 0.08701733745205627\n",
      "70 Train Loss 73461320.0 Test MSE 15209.86570533379 Test RE 0.05512511562375502\n",
      "71 Train Loss 72754780.0 Test MSE 11547.912901045042 Test RE 0.04803287405008061\n",
      "72 Train Loss 72548376.0 Test MSE 11285.339566731918 Test RE 0.047483654820122\n",
      "73 Train Loss 72447890.0 Test MSE 15094.080108563054 Test RE 0.05491489391283081\n",
      "74 Train Loss 72313270.0 Test MSE 19574.53507975467 Test RE 0.06253635316286313\n",
      "75 Train Loss 72035050.0 Test MSE 36456.221296307645 Test RE 0.08534393231387999\n",
      "76 Train Loss 71729210.0 Test MSE 67784.4082779929 Test RE 0.116372865500424\n",
      "77 Train Loss 71666610.0 Test MSE 67273.80453081532 Test RE 0.11593373247472451\n",
      "78 Train Loss 71598500.0 Test MSE 47955.77392107144 Test RE 0.0978830009497262\n",
      "79 Train Loss 71476536.0 Test MSE 46446.264215394964 Test RE 0.09633014585255692\n",
      "80 Train Loss 71184060.0 Test MSE 89596.09671619823 Test RE 0.1337923766837821\n",
      "81 Train Loss 70914980.0 Test MSE 95097.96311782286 Test RE 0.13783910074810102\n",
      "82 Train Loss 70613700.0 Test MSE 73903.95500627357 Test RE 0.12151241823491814\n",
      "83 Train Loss 70287550.0 Test MSE 70084.70798968361 Test RE 0.1183309790325674\n",
      "84 Train Loss 70166456.0 Test MSE 85933.71021601484 Test RE 0.13102935559480813\n",
      "85 Train Loss 70118110.0 Test MSE 91484.97533125317 Test RE 0.13519533657146157\n",
      "86 Train Loss 69823620.0 Test MSE 145726.19431810643 Test RE 0.17063009607734103\n",
      "87 Train Loss 69579100.0 Test MSE 217928.08115149307 Test RE 0.20866202661329603\n",
      "88 Train Loss 69384250.0 Test MSE 304166.9425442539 Test RE 0.24651470446523505\n",
      "89 Train Loss 69176810.0 Test MSE 318584.52616676636 Test RE 0.25228949222882957\n",
      "90 Train Loss 69031820.0 Test MSE 317615.1508891549 Test RE 0.251905372008562\n",
      "91 Train Loss 68810320.0 Test MSE 363780.82415271405 Test RE 0.26959182886974337\n",
      "92 Train Loss 68524104.0 Test MSE 406670.0241417062 Test RE 0.28504137505712657\n",
      "93 Train Loss 68139570.0 Test MSE 424672.97471982 Test RE 0.29128232724588093\n",
      "94 Train Loss 67607220.0 Test MSE 364108.2823115262 Test RE 0.2697131384339328\n",
      "95 Train Loss 67430810.0 Test MSE 329771.2013657387 Test RE 0.2566806833687376\n",
      "96 Train Loss 67233460.0 Test MSE 316608.0637868035 Test RE 0.2515056869351587\n",
      "97 Train Loss 67015100.0 Test MSE 361889.4822238086 Test RE 0.2688900947896666\n",
      "98 Train Loss 66855480.0 Test MSE 397926.35230362014 Test RE 0.28196043640634755\n",
      "99 Train Loss 66752744.0 Test MSE 385382.5421127004 Test RE 0.27748073885411084\n",
      "100 Train Loss 66400000.0 Test MSE 324163.7581716598 Test RE 0.25448902215176955\n",
      "101 Train Loss 65985080.0 Test MSE 276523.8657172263 Test RE 0.2350461453940256\n",
      "102 Train Loss 65726030.0 Test MSE 249009.5620268336 Test RE 0.2230462037127421\n",
      "103 Train Loss 65458784.0 Test MSE 132711.95468479945 Test RE 0.1628327833919904\n",
      "104 Train Loss 65293044.0 Test MSE 61939.58232862823 Test RE 0.1112425562278081\n",
      "105 Train Loss 65088210.0 Test MSE 39419.327268580106 Test RE 0.08874449610686821\n",
      "106 Train Loss 64919064.0 Test MSE 30114.646850362336 Test RE 0.07756677068652984\n",
      "107 Train Loss 64736030.0 Test MSE 35695.14644414676 Test RE 0.08444839650903005\n",
      "108 Train Loss 64559024.0 Test MSE 53492.76217641343 Test RE 0.10337947816089767\n",
      "109 Train Loss 64482930.0 Test MSE 54732.00611810086 Test RE 0.10457009608469213\n",
      "110 Train Loss 64386040.0 Test MSE 53448.86483600741 Test RE 0.10333705171520355\n",
      "111 Train Loss 64260144.0 Test MSE 39121.54945065992 Test RE 0.08840866797243545\n",
      "112 Train Loss 64102924.0 Test MSE 15544.398420139289 Test RE 0.05572804184877678\n",
      "113 Train Loss 63858956.0 Test MSE 2083.663430456321 Test RE 0.02040330907774612\n",
      "114 Train Loss 63730468.0 Test MSE 7231.92241292581 Test RE 0.038011385762653255\n",
      "115 Train Loss 63552856.0 Test MSE 8986.710036724578 Test RE 0.04237280243944653\n",
      "116 Train Loss 63402144.0 Test MSE 3902.017352742204 Test RE 0.027921029138626832\n",
      "117 Train Loss 63309576.0 Test MSE 8011.589531509542 Test RE 0.04000793803114514\n",
      "118 Train Loss 63190380.0 Test MSE 13442.81345633998 Test RE 0.0518241168246149\n",
      "119 Train Loss 63110560.0 Test MSE 13051.449709793511 Test RE 0.05106416101001247\n",
      "120 Train Loss 63015940.0 Test MSE 15011.89950685085 Test RE 0.05476519619983046\n",
      "121 Train Loss 62954016.0 Test MSE 18302.558679309303 Test RE 0.060470384157307024\n",
      "122 Train Loss 62801652.0 Test MSE 50073.25811570923 Test RE 0.10002066759011702\n",
      "123 Train Loss 62678384.0 Test MSE 77318.54981901021 Test RE 0.12428784947257693\n",
      "124 Train Loss 62623290.0 Test MSE 87162.85603609087 Test RE 0.131963112325675\n",
      "125 Train Loss 62191388.0 Test MSE 33343.853907602286 Test RE 0.08161964864405244\n",
      "126 Train Loss 61937316.0 Test MSE 11443.76117927242 Test RE 0.04781577691294951\n",
      "127 Train Loss 61659332.0 Test MSE 2653.509475577031 Test RE 0.023024867786223948\n",
      "128 Train Loss 61579956.0 Test MSE 2785.0467311370967 Test RE 0.023588648940453462\n",
      "129 Train Loss 61511280.0 Test MSE 4835.367885734498 Test RE 0.031081472429592024\n",
      "130 Train Loss 61429336.0 Test MSE 7728.362551026735 Test RE 0.03929439145790914\n",
      "131 Train Loss 61286492.0 Test MSE 4977.395359135373 Test RE 0.031534641123631475\n",
      "132 Train Loss 60897490.0 Test MSE 7103.30021143704 Test RE 0.037671846568143506\n",
      "133 Train Loss 60454476.0 Test MSE 74996.25866322407 Test RE 0.12240710389059684\n",
      "134 Train Loss 60158052.0 Test MSE 192064.11333320645 Test RE 0.19588894916440208\n",
      "135 Train Loss 60072750.0 Test MSE 222887.85697440928 Test RE 0.21102311421934322\n",
      "136 Train Loss 59977400.0 Test MSE 286436.5607261736 Test RE 0.2392219625083459\n",
      "137 Train Loss 59854932.0 Test MSE 376093.068597646 Test RE 0.27411606473715544\n",
      "138 Train Loss 59781444.0 Test MSE 408932.7904516291 Test RE 0.2858332791538868\n",
      "139 Train Loss 59740440.0 Test MSE 417419.3078833694 Test RE 0.28878397531857486\n",
      "140 Train Loss 59676870.0 Test MSE 427196.4931178876 Test RE 0.292146483447822\n",
      "141 Train Loss 59571530.0 Test MSE 453350.7847173417 Test RE 0.30095669540899567\n",
      "142 Train Loss 59468460.0 Test MSE 526266.220375467 Test RE 0.3242571573019112\n",
      "143 Train Loss 59370760.0 Test MSE 508420.94899088365 Test RE 0.31871209281897334\n",
      "144 Train Loss 59276476.0 Test MSE 469563.9578640398 Test RE 0.3062909754331424\n",
      "145 Train Loss 59127500.0 Test MSE 417693.34434708214 Test RE 0.28887875334356333\n",
      "146 Train Loss 58980456.0 Test MSE 287463.7149596768 Test RE 0.23965050061204551\n",
      "147 Train Loss 58941464.0 Test MSE 256644.55191008357 Test RE 0.22643984470427364\n",
      "148 Train Loss 58877310.0 Test MSE 217314.86904261078 Test RE 0.20836825029553904\n",
      "149 Train Loss 58687628.0 Test MSE 195734.03621599913 Test RE 0.19775159703368858\n",
      "150 Train Loss 58603370.0 Test MSE 239047.01482521323 Test RE 0.2185387657639268\n",
      "151 Train Loss 58469676.0 Test MSE 353622.3548470397 Test RE 0.26580104227804163\n",
      "152 Train Loss 58334664.0 Test MSE 416425.2330803765 Test RE 0.288439904037992\n",
      "153 Train Loss 58188708.0 Test MSE 495791.9200733673 Test RE 0.31472884361007036\n",
      "154 Train Loss 58121620.0 Test MSE 516171.5859047255 Test RE 0.32113221187390056\n",
      "155 Train Loss 58004384.0 Test MSE 485321.4180923155 Test RE 0.3113877709367734\n",
      "156 Train Loss 57848584.0 Test MSE 359242.7265069829 Test RE 0.26790499784918975\n",
      "157 Train Loss 57672096.0 Test MSE 317564.51270998135 Test RE 0.25188529025585144\n",
      "158 Train Loss 57532292.0 Test MSE 319440.6156455125 Test RE 0.25262823667758016\n",
      "159 Train Loss 57421070.0 Test MSE 277052.7380083879 Test RE 0.23527080956934274\n",
      "160 Train Loss 57347904.0 Test MSE 208497.53731014777 Test RE 0.20409731362343192\n",
      "161 Train Loss 57271416.0 Test MSE 115989.41423652277 Test RE 0.15222851164302573\n",
      "162 Train Loss 57214444.0 Test MSE 86106.22107536874 Test RE 0.1311608095594053\n",
      "163 Train Loss 57111188.0 Test MSE 101430.05393337017 Test RE 0.14235415634614176\n",
      "164 Train Loss 57045630.0 Test MSE 88732.2365022915 Test RE 0.13314582031040437\n",
      "165 Train Loss 57006820.0 Test MSE 87770.33609969773 Test RE 0.13242217121297772\n",
      "166 Train Loss 56960380.0 Test MSE 80786.05668879714 Test RE 0.12704425435726122\n",
      "167 Train Loss 56907550.0 Test MSE 52183.56700375321 Test RE 0.1021065740353949\n",
      "168 Train Loss 56843956.0 Test MSE 32122.670077274393 Test RE 0.08011109026381785\n",
      "169 Train Loss 56748044.0 Test MSE 22077.552087568896 Test RE 0.06641440446351145\n",
      "170 Train Loss 56665490.0 Test MSE 29778.98539814061 Test RE 0.07713327510597073\n",
      "171 Train Loss 56599748.0 Test MSE 56753.723096931455 Test RE 0.10648391304676556\n",
      "172 Train Loss 56523776.0 Test MSE 79684.22089849938 Test RE 0.1261749057583242\n",
      "173 Train Loss 56339468.0 Test MSE 45649.40111441737 Test RE 0.09550021862557921\n",
      "174 Train Loss 56138380.0 Test MSE 7792.140351584331 Test RE 0.039456195507160334\n",
      "175 Train Loss 55969020.0 Test MSE 3705.5630523346363 Test RE 0.02720908437417244\n",
      "176 Train Loss 55832990.0 Test MSE 1677.1962241543697 Test RE 0.01830538054219288\n",
      "177 Train Loss 55634452.0 Test MSE 17776.82542410055 Test RE 0.05959556306602879\n",
      "178 Train Loss 55512380.0 Test MSE 40478.29179014314 Test RE 0.08992861648282925\n",
      "179 Train Loss 55404556.0 Test MSE 36548.947918093414 Test RE 0.08545239979260424\n",
      "180 Train Loss 55320516.0 Test MSE 44001.934963821855 Test RE 0.0937611037198975\n",
      "181 Train Loss 55247670.0 Test MSE 57075.343768666746 Test RE 0.1067852064521311\n",
      "182 Train Loss 55202664.0 Test MSE 67450.84983784778 Test RE 0.11608618436016784\n",
      "183 Train Loss 55147164.0 Test MSE 67689.35782475564 Test RE 0.11629124515233978\n",
      "184 Train Loss 55039484.0 Test MSE 25438.435276269178 Test RE 0.07129055911239143\n",
      "185 Train Loss 54993470.0 Test MSE 11863.623788794092 Test RE 0.04868503726312786\n",
      "186 Train Loss 54966140.0 Test MSE 7895.977966519436 Test RE 0.03971822096003964\n",
      "187 Train Loss 54906010.0 Test MSE 6759.802430181998 Test RE 0.03674970228276428\n",
      "188 Train Loss 54840044.0 Test MSE 6624.521679801708 Test RE 0.03638011658791511\n",
      "189 Train Loss 54773444.0 Test MSE 16834.15893052511 Test RE 0.05799392935116068\n",
      "190 Train Loss 54681804.0 Test MSE 10916.81592634282 Test RE 0.04670192880218711\n",
      "191 Train Loss 54634070.0 Test MSE 6345.751318154353 Test RE 0.03560642308863296\n",
      "192 Train Loss 54571970.0 Test MSE 5382.782739375635 Test RE 0.03279368715049245\n",
      "193 Train Loss 54487856.0 Test MSE 2305.947135859636 Test RE 0.021464041386517904\n",
      "194 Train Loss 54356708.0 Test MSE 5117.544667077556 Test RE 0.03197552211630036\n",
      "195 Train Loss 54316180.0 Test MSE 3809.818552836272 Test RE 0.02758919125582157\n",
      "196 Train Loss 54297670.0 Test MSE 3426.747871868951 Test RE 0.02616543139999055\n",
      "197 Train Loss 54267428.0 Test MSE 3793.8615897734016 Test RE 0.027531353639640203\n",
      "198 Train Loss 54219172.0 Test MSE 4904.342763579782 Test RE 0.03130237077405774\n",
      "199 Train Loss 54187416.0 Test MSE 5140.684318052532 Test RE 0.03204773134588966\n",
      "Training time: 79.82\n",
      "Training time: 79.82\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "6\n",
      "0 Train Loss 467521060.0 Test MSE 4359802.644062077 Test RE 0.9332977930663579\n",
      "1 Train Loss 129083450.0 Test MSE 1467770.9138775384 Test RE 0.5415218219496587\n",
      "2 Train Loss 75913430.0 Test MSE 2641967.061326398 Test RE 0.7265249329229495\n",
      "3 Train Loss 72874880.0 Test MSE 2730981.7757187225 Test RE 0.7386627944262095\n",
      "4 Train Loss 73787460.0 Test MSE 2614226.833705785 Test RE 0.7227006706466401\n",
      "5 Train Loss 74860970.0 Test MSE 2507358.4420155236 Test RE 0.7077747016337561\n",
      "6 Train Loss 75749490.0 Test MSE 1955685.3461167878 Test RE 0.6250810233196054\n",
      "7 Train Loss 76572320.0 Test MSE 1435680.217909255 Test RE 0.5355693092123475\n",
      "8 Train Loss 77593656.0 Test MSE 1082286.6004516745 Test RE 0.46500536591168473\n",
      "9 Train Loss 78446130.0 Test MSE 626821.248238615 Test RE 0.3538821674965438\n",
      "10 Train Loss 79288410.0 Test MSE 435844.66466238204 Test RE 0.29508877577374254\n",
      "11 Train Loss 80284990.0 Test MSE 478865.54099599447 Test RE 0.30930975493771684\n",
      "12 Train Loss 81191704.0 Test MSE 484715.09479884367 Test RE 0.31119319816786534\n",
      "13 Train Loss 81914616.0 Test MSE 388474.3488570614 Test RE 0.2785915870281245\n",
      "14 Train Loss 82598390.0 Test MSE 338847.8678013971 Test RE 0.2601891619303862\n",
      "15 Train Loss 83316860.0 Test MSE 312341.4184091823 Test RE 0.24980527952022624\n",
      "16 Train Loss 83869976.0 Test MSE 287535.9679572878 Test RE 0.2396806163766418\n",
      "17 Train Loss 84463040.0 Test MSE 308685.7115590204 Test RE 0.24833909110739244\n",
      "18 Train Loss 84809340.0 Test MSE 420842.302941024 Test RE 0.28996562628450784\n",
      "19 Train Loss 85361580.0 Test MSE 437505.99949421204 Test RE 0.2956506445073217\n",
      "20 Train Loss 85211960.0 Test MSE 649800.6426534592 Test RE 0.36031047810124717\n",
      "21 Train Loss 85405270.0 Test MSE 652853.8883760317 Test RE 0.3611559890858774\n",
      "22 Train Loss 85515200.0 Test MSE 627725.7096262171 Test RE 0.35413738968266134\n",
      "23 Train Loss 85418264.0 Test MSE 838561.6297491894 Test RE 0.4093118488324125\n",
      "24 Train Loss 85667220.0 Test MSE 758901.9528092038 Test RE 0.38938539570434966\n",
      "25 Train Loss 85619090.0 Test MSE 806827.4736267179 Test RE 0.4014922464962221\n",
      "26 Train Loss 85430104.0 Test MSE 1000772.977502802 Test RE 0.4471514143237113\n",
      "27 Train Loss 85229480.0 Test MSE 1170300.6346885262 Test RE 0.4835434935919184\n",
      "28 Train Loss 85326010.0 Test MSE 1152818.290038392 Test RE 0.47991823611763457\n",
      "29 Train Loss 84720850.0 Test MSE 1270556.2631886513 Test RE 0.503829710934746\n",
      "30 Train Loss 84711920.0 Test MSE 1288313.5124295142 Test RE 0.5073382477529113\n",
      "31 Train Loss 84554616.0 Test MSE 1353858.0336798774 Test RE 0.5200838725928051\n",
      "32 Train Loss 84338990.0 Test MSE 1479794.4720684825 Test RE 0.5437352938589415\n",
      "33 Train Loss 84491150.0 Test MSE 1526280.771076684 Test RE 0.5522097113753662\n",
      "34 Train Loss 84417920.0 Test MSE 1532809.8619420487 Test RE 0.5533895663112656\n",
      "35 Train Loss 83932360.0 Test MSE 1605918.526135263 Test RE 0.5664330399723854\n",
      "36 Train Loss 83891416.0 Test MSE 1527726.5402717735 Test RE 0.5524711897452428\n",
      "37 Train Loss 83005220.0 Test MSE 1589235.291537597 Test RE 0.5634831373664334\n",
      "38 Train Loss 82719510.0 Test MSE 1545891.9497107305 Test RE 0.5557460587518448\n",
      "39 Train Loss 81476520.0 Test MSE 1572533.7520370563 Test RE 0.5605144478820978\n",
      "40 Train Loss 81217630.0 Test MSE 1535131.1754481653 Test RE 0.5538084391025677\n",
      "41 Train Loss 80757350.0 Test MSE 1574673.9478111463 Test RE 0.5608957442343809\n",
      "42 Train Loss 80093800.0 Test MSE 1714904.7595635331 Test RE 0.5853381444571427\n",
      "43 Train Loss 79192904.0 Test MSE 1642625.7578241555 Test RE 0.5728700768149706\n",
      "44 Train Loss 78387624.0 Test MSE 1603134.6388381035 Test RE 0.5659418663226669\n",
      "45 Train Loss 78078520.0 Test MSE 1637735.9780177686 Test RE 0.5720167794973012\n",
      "46 Train Loss 77667770.0 Test MSE 1631974.7656952776 Test RE 0.5710097754683928\n",
      "47 Train Loss 77034970.0 Test MSE 1738185.9581623757 Test RE 0.5892979661920822\n",
      "48 Train Loss 76337500.0 Test MSE 1600051.6440270888 Test RE 0.5653974218766098\n",
      "49 Train Loss 75343290.0 Test MSE 1458340.196078015 Test RE 0.5397793261792408\n",
      "50 Train Loss 74157410.0 Test MSE 1276442.4741583862 Test RE 0.5049954291284192\n",
      "51 Train Loss 72187110.0 Test MSE 1161331.3585858354 Test RE 0.4816869719365339\n",
      "52 Train Loss 70642440.0 Test MSE 1211797.2302140577 Test RE 0.4920415766114079\n",
      "53 Train Loss 68990550.0 Test MSE 1256930.6637111052 Test RE 0.5011208633903946\n",
      "54 Train Loss 68186540.0 Test MSE 1294007.5011376329 Test RE 0.5084581589237783\n",
      "55 Train Loss 67352584.0 Test MSE 1284711.9201301741 Test RE 0.5066285973694058\n",
      "56 Train Loss 66690500.0 Test MSE 1243738.476740324 Test RE 0.49848415551003455\n",
      "57 Train Loss 66099076.0 Test MSE 1235819.5826066341 Test RE 0.49689469487843435\n",
      "58 Train Loss 64846044.0 Test MSE 1087553.84000151 Test RE 0.46613552951372283\n",
      "59 Train Loss 63631652.0 Test MSE 1105428.206516792 Test RE 0.4699504769040401\n",
      "60 Train Loss 62755956.0 Test MSE 1107614.707100235 Test RE 0.47041502058686563\n",
      "61 Train Loss 61411396.0 Test MSE 1103819.915433074 Test RE 0.46960848623123463\n",
      "62 Train Loss 60748980.0 Test MSE 1060482.5066695896 Test RE 0.4602974597244079\n",
      "63 Train Loss 59966550.0 Test MSE 1024696.5595230089 Test RE 0.452464450192075\n",
      "64 Train Loss 59263284.0 Test MSE 1061974.0760309552 Test RE 0.4606210503256707\n",
      "65 Train Loss 59003772.0 Test MSE 1071949.141083814 Test RE 0.46277928842278054\n",
      "66 Train Loss 58569284.0 Test MSE 1032514.9208591812 Test RE 0.45418730579005157\n",
      "67 Train Loss 58057450.0 Test MSE 1002625.776290815 Test RE 0.44756514376867995\n",
      "68 Train Loss 57648970.0 Test MSE 966277.0996871488 Test RE 0.4393773520370609\n",
      "69 Train Loss 57557690.0 Test MSE 988132.2597339539 Test RE 0.4443184656388989\n",
      "70 Train Loss 57112012.0 Test MSE 1077283.685108569 Test RE 0.4639293675759653\n",
      "71 Train Loss 56584760.0 Test MSE 1104090.71227487 Test RE 0.4696660865221261\n",
      "72 Train Loss 56123236.0 Test MSE 1138416.7939743209 Test RE 0.4769111438405767\n",
      "73 Train Loss 55593536.0 Test MSE 1197229.6101702927 Test RE 0.48907509543321903\n",
      "74 Train Loss 54956890.0 Test MSE 1215704.614578211 Test RE 0.4928342208667779\n",
      "75 Train Loss 54200684.0 Test MSE 1126471.473523805 Test RE 0.474402449502226\n",
      "76 Train Loss 53973140.0 Test MSE 1049213.0120328984 Test RE 0.4578451917531879\n",
      "77 Train Loss 53768596.0 Test MSE 960872.8016148731 Test RE 0.438146930856306\n",
      "78 Train Loss 53498364.0 Test MSE 916898.9529145863 Test RE 0.42800373806934466\n",
      "79 Train Loss 53244836.0 Test MSE 928479.4198345074 Test RE 0.4306981086059969\n",
      "80 Train Loss 53053310.0 Test MSE 887401.3215142355 Test RE 0.4210627855499568\n",
      "81 Train Loss 52467916.0 Test MSE 762818.053759001 Test RE 0.39038876010613255\n",
      "82 Train Loss 52035044.0 Test MSE 746068.2652307022 Test RE 0.38607893562639756\n",
      "83 Train Loss 51827184.0 Test MSE 723092.4325780779 Test RE 0.38008762671418983\n",
      "84 Train Loss 51417092.0 Test MSE 674087.212210929 Test RE 0.36698208845788727\n",
      "85 Train Loss 51037384.0 Test MSE 668676.3218128431 Test RE 0.365506240308072\n",
      "86 Train Loss 50643780.0 Test MSE 659087.1725269007 Test RE 0.3628760063817462\n",
      "87 Train Loss 49811916.0 Test MSE 584264.0100710524 Test RE 0.34165784025545803\n",
      "88 Train Loss 49462904.0 Test MSE 544464.4190841905 Test RE 0.32981589007794315\n",
      "89 Train Loss 48683240.0 Test MSE 488420.6988212686 Test RE 0.3123804556047603\n",
      "90 Train Loss 48175584.0 Test MSE 462490.14451258164 Test RE 0.3039751384346038\n",
      "91 Train Loss 47405764.0 Test MSE 418600.2245484187 Test RE 0.28919218469248753\n",
      "92 Train Loss 46674050.0 Test MSE 379029.1133191324 Test RE 0.27518395517797783\n",
      "93 Train Loss 45360670.0 Test MSE 291221.70629971346 Test RE 0.24121188063875124\n",
      "94 Train Loss 44835732.0 Test MSE 284952.75027601875 Test RE 0.2386015442625607\n",
      "95 Train Loss 44126036.0 Test MSE 273543.70839159767 Test RE 0.23377614285683138\n",
      "96 Train Loss 43353910.0 Test MSE 266193.3098911256 Test RE 0.23061385298658169\n",
      "97 Train Loss 42786944.0 Test MSE 262331.5659387145 Test RE 0.22893495045965345\n",
      "98 Train Loss 42451860.0 Test MSE 258728.95290852862 Test RE 0.2273575282450358\n",
      "99 Train Loss 41938988.0 Test MSE 239369.493875986 Test RE 0.21868612259675324\n",
      "100 Train Loss 41694600.0 Test MSE 256101.33318511333 Test RE 0.22620007432694983\n",
      "101 Train Loss 41534550.0 Test MSE 246056.87110693622 Test RE 0.22171984802231207\n",
      "102 Train Loss 41215084.0 Test MSE 214135.03260918087 Test RE 0.20683816948487035\n",
      "103 Train Loss 40913664.0 Test MSE 201520.92819681033 Test RE 0.20065357463333075\n",
      "104 Train Loss 40473720.0 Test MSE 167299.41153782656 Test RE 0.18282434675792136\n",
      "105 Train Loss 40172616.0 Test MSE 156673.35427998228 Test RE 0.17692304054214172\n",
      "106 Train Loss 39954508.0 Test MSE 167961.43742049843 Test RE 0.18318571966240568\n",
      "107 Train Loss 39737650.0 Test MSE 175593.41867353223 Test RE 0.18730136431208916\n",
      "108 Train Loss 39530496.0 Test MSE 175068.93081650854 Test RE 0.18702142569299648\n",
      "109 Train Loss 39387524.0 Test MSE 178782.64436084335 Test RE 0.1889946462922831\n",
      "110 Train Loss 39138356.0 Test MSE 179070.7179182454 Test RE 0.1891468491146031\n",
      "111 Train Loss 38844604.0 Test MSE 146954.42765324117 Test RE 0.17134765352675846\n",
      "112 Train Loss 38719896.0 Test MSE 132264.29499120664 Test RE 0.16255792025461702\n",
      "113 Train Loss 38583924.0 Test MSE 117473.86991427018 Test RE 0.15319954010671105\n",
      "114 Train Loss 38462984.0 Test MSE 107507.59657882128 Test RE 0.14655694386741036\n",
      "115 Train Loss 38248550.0 Test MSE 88979.46555696704 Test RE 0.1333311792029119\n",
      "116 Train Loss 38022676.0 Test MSE 63477.77859807642 Test RE 0.11261537407613638\n",
      "117 Train Loss 37798492.0 Test MSE 42743.34549246342 Test RE 0.0924104487487447\n",
      "118 Train Loss 37596412.0 Test MSE 38901.233037401966 Test RE 0.08815937594236828\n",
      "119 Train Loss 37487084.0 Test MSE 32218.60573523171 Test RE 0.08023062859012277\n",
      "120 Train Loss 37349612.0 Test MSE 28834.63546816417 Test RE 0.075900398545214\n",
      "121 Train Loss 37240596.0 Test MSE 30941.955078795218 Test RE 0.0786250073945804\n",
      "122 Train Loss 37163824.0 Test MSE 27018.54506563093 Test RE 0.07347131332017966\n",
      "123 Train Loss 37019388.0 Test MSE 16253.483765221694 Test RE 0.056984934648651814\n",
      "124 Train Loss 36730372.0 Test MSE 7133.339972181961 Test RE 0.03775141939420168\n",
      "125 Train Loss 36371572.0 Test MSE 3289.7008008614966 Test RE 0.025636871344001968\n",
      "126 Train Loss 36138268.0 Test MSE 5411.503505301533 Test RE 0.03288105894634573\n",
      "127 Train Loss 35974548.0 Test MSE 12487.135771168898 Test RE 0.049948015813532184\n",
      "128 Train Loss 35680650.0 Test MSE 26043.272397209203 Test RE 0.0721331005797165\n",
      "129 Train Loss 35408172.0 Test MSE 52587.82665831752 Test RE 0.10250131452382737\n",
      "130 Train Loss 35285256.0 Test MSE 57487.799424331344 Test RE 0.10717035417304378\n",
      "131 Train Loss 35157050.0 Test MSE 66104.06998932536 Test RE 0.11492140407713494\n",
      "132 Train Loss 34901324.0 Test MSE 97379.25634475848 Test RE 0.13948260523933698\n",
      "133 Train Loss 34632548.0 Test MSE 123577.99560361807 Test RE 0.15712938006866725\n",
      "134 Train Loss 34524960.0 Test MSE 140194.53087198254 Test RE 0.1673602667925006\n",
      "135 Train Loss 34335770.0 Test MSE 156947.9135786273 Test RE 0.1770779954268049\n",
      "136 Train Loss 34143350.0 Test MSE 157732.3868659825 Test RE 0.1775199885830352\n",
      "137 Train Loss 34003084.0 Test MSE 164624.10972840776 Test RE 0.18135667437816452\n",
      "138 Train Loss 33830748.0 Test MSE 170826.67462018764 Test RE 0.1847415857274915\n",
      "139 Train Loss 33569784.0 Test MSE 162609.0523859584 Test RE 0.18024332200491022\n",
      "140 Train Loss 33430020.0 Test MSE 173784.00313015183 Test RE 0.18633383488954441\n",
      "141 Train Loss 33233744.0 Test MSE 184466.5129155197 Test RE 0.19197540510522776\n",
      "142 Train Loss 33046238.0 Test MSE 178446.00968994404 Test RE 0.18881663089269135\n",
      "143 Train Loss 32877752.0 Test MSE 174611.49101373545 Test RE 0.1867769305642414\n",
      "144 Train Loss 32536528.0 Test MSE 151212.62451666984 Test RE 0.17381243720001807\n",
      "145 Train Loss 32401228.0 Test MSE 141106.11564420132 Test RE 0.167903497226057\n",
      "146 Train Loss 32296590.0 Test MSE 126287.126948742 Test RE 0.1588423725210172\n",
      "147 Train Loss 32169294.0 Test MSE 109279.68764887529 Test RE 0.1477598855896454\n",
      "148 Train Loss 32065716.0 Test MSE 100444.82726644688 Test RE 0.1416611006535267\n",
      "149 Train Loss 32007148.0 Test MSE 94388.36790775992 Test RE 0.1373238788431638\n",
      "150 Train Loss 31828490.0 Test MSE 79180.65204535153 Test RE 0.12577558922548984\n",
      "151 Train Loss 31538708.0 Test MSE 50914.892078396544 Test RE 0.10085774118045807\n",
      "152 Train Loss 31407608.0 Test MSE 38493.48183683425 Test RE 0.08769612860819306\n",
      "153 Train Loss 31288626.0 Test MSE 33142.86163056072 Test RE 0.08137328066973538\n",
      "154 Train Loss 31202472.0 Test MSE 30380.59071316513 Test RE 0.07790851575343781\n",
      "155 Train Loss 31125538.0 Test MSE 31860.380597071166 Test RE 0.07978335653519958\n",
      "156 Train Loss 31036746.0 Test MSE 30179.31482985159 Test RE 0.07765000919121992\n",
      "157 Train Loss 30972488.0 Test MSE 33060.46828858605 Test RE 0.08127207050971876\n",
      "158 Train Loss 30895056.0 Test MSE 36990.44100641756 Test RE 0.08596696175977928\n",
      "159 Train Loss 30811900.0 Test MSE 23308.597173314793 Test RE 0.06824092292409394\n",
      "160 Train Loss 30713948.0 Test MSE 18064.800091117348 Test RE 0.06007633130184221\n",
      "161 Train Loss 30566974.0 Test MSE 15313.236629309533 Test RE 0.055312122041178635\n",
      "162 Train Loss 30536078.0 Test MSE 13135.26870193028 Test RE 0.05122787065900637\n",
      "163 Train Loss 30491040.0 Test MSE 10326.111746522742 Test RE 0.04542084755723284\n",
      "164 Train Loss 30348862.0 Test MSE 9128.157722642072 Test RE 0.04270496707951383\n",
      "165 Train Loss 30280176.0 Test MSE 9984.296675162856 Test RE 0.04466276049874569\n",
      "166 Train Loss 30141480.0 Test MSE 10248.707950495933 Test RE 0.04525029162287151\n",
      "167 Train Loss 30042392.0 Test MSE 11286.501097707363 Test RE 0.04748609835832874\n",
      "168 Train Loss 29955544.0 Test MSE 12146.187977717129 Test RE 0.049261408218536855\n",
      "169 Train Loss 29636724.0 Test MSE 11801.083498400536 Test RE 0.0485565436533458\n",
      "170 Train Loss 29479472.0 Test MSE 10557.371618585186 Test RE 0.045926645774137985\n",
      "171 Train Loss 29350854.0 Test MSE 16298.877544357047 Test RE 0.05706445476796536\n",
      "172 Train Loss 29144938.0 Test MSE 12868.083606322449 Test RE 0.050704179652605194\n",
      "173 Train Loss 29003074.0 Test MSE 12011.38897719498 Test RE 0.048987292776126214\n",
      "174 Train Loss 28826188.0 Test MSE 14135.519878315568 Test RE 0.05314258997232085\n",
      "175 Train Loss 28704070.0 Test MSE 15392.190815265185 Test RE 0.05545453180663931\n",
      "176 Train Loss 28577346.0 Test MSE 12489.48680342536 Test RE 0.04995271760711005\n",
      "177 Train Loss 28429794.0 Test MSE 9902.662651248904 Test RE 0.04447979898189803\n",
      "178 Train Loss 28297706.0 Test MSE 10203.137079338576 Test RE 0.045149576849555374\n",
      "179 Train Loss 28209738.0 Test MSE 11941.802973534339 Test RE 0.04884518675417422\n",
      "180 Train Loss 28034596.0 Test MSE 14935.118263636265 Test RE 0.05462496310059432\n",
      "181 Train Loss 27921878.0 Test MSE 15196.172979561206 Test RE 0.05510029676396937\n",
      "182 Train Loss 27819148.0 Test MSE 14794.51823389609 Test RE 0.05436723388439156\n",
      "183 Train Loss 27660434.0 Test MSE 17777.987987417506 Test RE 0.05959751174024679\n",
      "184 Train Loss 27570716.0 Test MSE 18544.041981657072 Test RE 0.06086799896535486\n",
      "185 Train Loss 27525332.0 Test MSE 18805.51622909526 Test RE 0.06129562158885783\n",
      "186 Train Loss 27441644.0 Test MSE 21035.541330263317 Test RE 0.0648281562191416\n",
      "187 Train Loss 27352530.0 Test MSE 26865.54626681875 Test RE 0.07326299378257699\n",
      "188 Train Loss 27252266.0 Test MSE 29125.537906312024 Test RE 0.07628230387261631\n",
      "189 Train Loss 27158580.0 Test MSE 28847.0064454665 Test RE 0.07591667864383204\n",
      "190 Train Loss 27107776.0 Test MSE 24677.027982831543 Test RE 0.07021554165767116\n",
      "191 Train Loss 27064344.0 Test MSE 21718.35006036969 Test RE 0.06587190724188235\n",
      "192 Train Loss 26991592.0 Test MSE 18289.839224770723 Test RE 0.060449368407723504\n",
      "193 Train Loss 26916878.0 Test MSE 14184.548157895488 Test RE 0.0532346712838315\n",
      "194 Train Loss 26862606.0 Test MSE 11632.355693877245 Test RE 0.048208171622896895\n",
      "195 Train Loss 26794146.0 Test MSE 11688.728254569234 Test RE 0.04832484332660593\n",
      "196 Train Loss 26747220.0 Test MSE 12599.973797900935 Test RE 0.05017318195909794\n",
      "197 Train Loss 26677768.0 Test MSE 13335.207740637561 Test RE 0.05161628176884084\n",
      "198 Train Loss 26606148.0 Test MSE 12274.219246344077 Test RE 0.04952035643013313\n",
      "199 Train Loss 26545066.0 Test MSE 11566.81331185949 Test RE 0.04807216556097438\n",
      "Training time: 80.05\n",
      "Training time: 80.05\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "7\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 1.99\n",
      "Training time: 1.99\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "8\n",
      "0 Train Loss 575378000.0 Test MSE 3438600.844017735 Test RE 0.8288533676774523\n",
      "1 Train Loss 262062030.0 Test MSE 2446083.922689748 Test RE 0.6990729538921744\n",
      "2 Train Loss 95282050.0 Test MSE 1214119.4782684655 Test RE 0.4925128170379449\n",
      "3 Train Loss 74502880.0 Test MSE 2512794.4123087595 Test RE 0.7085415164467261\n",
      "4 Train Loss 74134090.0 Test MSE 2523935.6242940994 Test RE 0.7101105426346089\n",
      "5 Train Loss 74680980.0 Test MSE 2710162.247790568 Test RE 0.7358418249450593\n",
      "6 Train Loss 75080020.0 Test MSE 2669292.344911933 Test RE 0.7302724117167022\n",
      "7 Train Loss 75629640.0 Test MSE 2436229.9378868677 Test RE 0.6976634343945194\n",
      "8 Train Loss 75807910.0 Test MSE 1836932.0840078408 Test RE 0.6058057253917377\n",
      "9 Train Loss 76330690.0 Test MSE 1356648.8438811149 Test RE 0.5206196407871994\n",
      "10 Train Loss 76344120.0 Test MSE 776638.9142526654 Test RE 0.39390944784572535\n",
      "11 Train Loss 76651600.0 Test MSE 639019.5035820593 Test RE 0.35730893824299814\n",
      "12 Train Loss 76523070.0 Test MSE 341511.6074872964 Test RE 0.2612098551277525\n",
      "13 Train Loss 76563850.0 Test MSE 306165.3561021336 Test RE 0.24732319436471636\n",
      "14 Train Loss 76277310.0 Test MSE 313508.7709796011 Test RE 0.25027165838893556\n",
      "15 Train Loss 75735544.0 Test MSE 224449.61309573165 Test RE 0.21176113410814493\n",
      "16 Train Loss 75413290.0 Test MSE 238943.45226547233 Test RE 0.2184914217596514\n",
      "17 Train Loss 75057384.0 Test MSE 199021.5516585264 Test RE 0.19940538279856382\n",
      "18 Train Loss 74038790.0 Test MSE 130639.98473349112 Test RE 0.161556666731906\n",
      "19 Train Loss 73782890.0 Test MSE 163520.40223271018 Test RE 0.1807477072371902\n",
      "20 Train Loss 73480720.0 Test MSE 147863.92739646477 Test RE 0.1718770702600035\n",
      "21 Train Loss 72901790.0 Test MSE 134482.43643967182 Test RE 0.16391534344254127\n",
      "22 Train Loss 72384744.0 Test MSE 124478.26020511687 Test RE 0.1577006845395975\n",
      "23 Train Loss 71965220.0 Test MSE 149441.98757616206 Test RE 0.17279180493349744\n",
      "24 Train Loss 71752640.0 Test MSE 152965.50337653467 Test RE 0.1748169640295999\n",
      "25 Train Loss 71567050.0 Test MSE 153792.09882162075 Test RE 0.1752886658590205\n",
      "26 Train Loss 71291350.0 Test MSE 127712.56828972114 Test RE 0.159736308234299\n",
      "27 Train Loss 69618456.0 Test MSE 96859.9144334737 Test RE 0.13911016450168995\n",
      "28 Train Loss 69020580.0 Test MSE 93920.44090491117 Test RE 0.13698306678589023\n",
      "29 Train Loss 68720540.0 Test MSE 73012.06215708969 Test RE 0.12077697029572816\n",
      "30 Train Loss 68217530.0 Test MSE 61717.43357299681 Test RE 0.11104288913021705\n",
      "31 Train Loss 67210640.0 Test MSE 61740.16258708427 Test RE 0.11106333443161626\n",
      "32 Train Loss 66689620.0 Test MSE 36438.22336103504 Test RE 0.08532286315011038\n",
      "33 Train Loss 65672092.0 Test MSE 5408.694635014988 Test RE 0.032872524292594005\n",
      "34 Train Loss 64901092.0 Test MSE 2609.3969278177233 Test RE 0.02283268036558513\n",
      "35 Train Loss 63936040.0 Test MSE 10590.981573139783 Test RE 0.045999692644016654\n",
      "36 Train Loss 63460360.0 Test MSE 26640.986452092813 Test RE 0.07295616124007964\n",
      "37 Train Loss 62801570.0 Test MSE 62231.30799204311 Test RE 0.11150421594283903\n",
      "38 Train Loss 62306550.0 Test MSE 80119.91533802611 Test RE 0.12651938276500035\n",
      "39 Train Loss 61314180.0 Test MSE 83650.73258776664 Test RE 0.1292771288040619\n",
      "40 Train Loss 60190296.0 Test MSE 106764.15659770966 Test RE 0.14604932713294033\n",
      "41 Train Loss 59167492.0 Test MSE 200980.7194663714 Test RE 0.2003844523300778\n",
      "42 Train Loss 57686736.0 Test MSE 250801.73012868877 Test RE 0.22384741716991002\n",
      "43 Train Loss 57029670.0 Test MSE 287377.2262482619 Test RE 0.23961444628384224\n",
      "44 Train Loss 56120428.0 Test MSE 405522.5413934608 Test RE 0.2846389466828981\n",
      "45 Train Loss 55539936.0 Test MSE 435817.98020558397 Test RE 0.2950797422752785\n",
      "46 Train Loss 55125136.0 Test MSE 448657.8441531288 Test RE 0.2993949400560303\n",
      "47 Train Loss 54788388.0 Test MSE 462654.48183764494 Test RE 0.30402913961162165\n",
      "48 Train Loss 54268240.0 Test MSE 484448.1745281021 Test RE 0.31110750328026465\n",
      "49 Train Loss 53685620.0 Test MSE 453669.047881355 Test RE 0.30106231629757674\n",
      "50 Train Loss 53095372.0 Test MSE 412574.75723763707 Test RE 0.2871032773223052\n",
      "51 Train Loss 52470284.0 Test MSE 362966.2529846699 Test RE 0.2692898272437773\n",
      "52 Train Loss 51956092.0 Test MSE 337877.0844531971 Test RE 0.2598161796835788\n",
      "53 Train Loss 51714784.0 Test MSE 281106.7545652891 Test RE 0.23698587640956595\n",
      "54 Train Loss 51369964.0 Test MSE 217042.7777597097 Test RE 0.20823776464963697\n",
      "55 Train Loss 50854144.0 Test MSE 133071.44856281823 Test RE 0.1630531772539391\n",
      "56 Train Loss 50555144.0 Test MSE 126817.0645390353 Test RE 0.15917529806786865\n",
      "57 Train Loss 50301116.0 Test MSE 111481.948892378 Test RE 0.1492413262552398\n",
      "58 Train Loss 49733480.0 Test MSE 33551.33012655844 Test RE 0.0818731867528052\n",
      "59 Train Loss 49358050.0 Test MSE 12488.8375296774 Test RE 0.04995141917867119\n",
      "60 Train Loss 49110636.0 Test MSE 5794.978682068527 Test RE 0.03402614473361682\n",
      "61 Train Loss 48854450.0 Test MSE 3499.895000974245 Test RE 0.026443219583114703\n",
      "62 Train Loss 48764084.0 Test MSE 4124.213040165994 Test RE 0.02870498797024774\n",
      "63 Train Loss 48554376.0 Test MSE 8384.03095689044 Test RE 0.04092731558287124\n",
      "64 Train Loss 48321230.0 Test MSE 18988.160541875506 Test RE 0.061592562252663394\n",
      "65 Train Loss 48001656.0 Test MSE 41133.523509825885 Test RE 0.09065354255502775\n",
      "66 Train Loss 47732790.0 Test MSE 30712.376820385492 Test RE 0.07833277958853949\n",
      "67 Train Loss 47510096.0 Test MSE 11439.879133137936 Test RE 0.047807665995837696\n",
      "68 Train Loss 47197572.0 Test MSE 2978.2325320792015 Test RE 0.024393051083386217\n",
      "69 Train Loss 46785650.0 Test MSE 3887.566085662275 Test RE 0.027869277891114\n",
      "70 Train Loss 46481828.0 Test MSE 8888.208200374858 Test RE 0.04213994196958799\n",
      "71 Train Loss 46127180.0 Test MSE 17000.61660922486 Test RE 0.05827994864093237\n",
      "72 Train Loss 45853744.0 Test MSE 35382.14585934398 Test RE 0.08407732928944994\n",
      "73 Train Loss 45477948.0 Test MSE 31406.21810310772 Test RE 0.07921266865949016\n",
      "74 Train Loss 45280748.0 Test MSE 21639.59962197103 Test RE 0.06575237347201163\n",
      "75 Train Loss 45068436.0 Test MSE 37003.1194430948 Test RE 0.08598169304270721\n",
      "76 Train Loss 44908988.0 Test MSE 50485.93771003272 Test RE 0.10043198286610931\n",
      "77 Train Loss 44794172.0 Test MSE 38067.41607985255 Test RE 0.08720944510082987\n",
      "78 Train Loss 44595812.0 Test MSE 19823.267611686297 Test RE 0.06293242191486817\n",
      "79 Train Loss 44517012.0 Test MSE 16128.57485840189 Test RE 0.05676554617141846\n",
      "80 Train Loss 44473160.0 Test MSE 8104.950313787347 Test RE 0.04024037340679812\n",
      "81 Train Loss 44342370.0 Test MSE 3491.290494493379 Test RE 0.02641069419695677\n",
      "82 Train Loss 44132372.0 Test MSE 5178.904624713855 Test RE 0.03216664604423939\n",
      "83 Train Loss 43788630.0 Test MSE 1710.0414582911733 Test RE 0.018483752449600304\n",
      "84 Train Loss 43483924.0 Test MSE 3793.0473853545122 Test RE 0.027528399215489767\n",
      "85 Train Loss 43244784.0 Test MSE 7689.490735953939 Test RE 0.03919544618823283\n",
      "86 Train Loss 43060276.0 Test MSE 11300.969035488351 Test RE 0.04751652434599341\n",
      "87 Train Loss 42876764.0 Test MSE 11708.056038881192 Test RE 0.04836478036426223\n",
      "88 Train Loss 42666570.0 Test MSE 7444.08732563824 Test RE 0.03856493051710539\n",
      "89 Train Loss 42459484.0 Test MSE 3037.3038079248736 Test RE 0.024633773333615546\n",
      "90 Train Loss 42359550.0 Test MSE 2323.7637777912805 Test RE 0.021546801589041674\n",
      "91 Train Loss 42117730.0 Test MSE 930.4760473705683 Test RE 0.013634506477344559\n",
      "92 Train Loss 42023280.0 Test MSE 1949.381888369816 Test RE 0.019734916219223412\n",
      "93 Train Loss 41960456.0 Test MSE 1538.1635502549616 Test RE 0.017530248864319205\n",
      "94 Train Loss 41905276.0 Test MSE 1254.492473137869 Test RE 0.01583145583141983\n",
      "95 Train Loss 41835536.0 Test MSE 1632.4252958582777 Test RE 0.018059406830820673\n",
      "96 Train Loss 41780876.0 Test MSE 3735.1914160639735 Test RE 0.027317644882256915\n",
      "97 Train Loss 41680650.0 Test MSE 7608.624038217967 Test RE 0.03898880157248158\n",
      "98 Train Loss 41581388.0 Test MSE 5332.192528415139 Test RE 0.03263921722397799\n",
      "99 Train Loss 41468804.0 Test MSE 9168.600267044298 Test RE 0.0427994652695087\n",
      "100 Train Loss 41324650.0 Test MSE 29558.53532258885 Test RE 0.07684724079677353\n",
      "101 Train Loss 41184810.0 Test MSE 58928.38037928205 Test RE 0.10850483130522277\n",
      "102 Train Loss 40986468.0 Test MSE 52550.70639012898 Test RE 0.10246513173968796\n",
      "103 Train Loss 40862030.0 Test MSE 26044.932994726085 Test RE 0.07213540025497414\n",
      "104 Train Loss 40735870.0 Test MSE 24054.92443968785 Test RE 0.0693248314234727\n",
      "105 Train Loss 40673540.0 Test MSE 33931.69100344525 Test RE 0.08233596414222215\n",
      "106 Train Loss 40512796.0 Test MSE 28113.73760303709 Test RE 0.07494559592045157\n",
      "107 Train Loss 40319856.0 Test MSE 20303.277384502027 Test RE 0.06368980184137377\n",
      "108 Train Loss 40248812.0 Test MSE 25591.679772628824 Test RE 0.0715049685648852\n",
      "109 Train Loss 40179480.0 Test MSE 34096.175270536056 Test RE 0.08253528515378522\n",
      "110 Train Loss 40059836.0 Test MSE 55891.351960837506 Test RE 0.10567180630600843\n",
      "111 Train Loss 39944304.0 Test MSE 64687.89098279173 Test RE 0.11368373136125219\n",
      "112 Train Loss 39883420.0 Test MSE 58035.79203938347 Test RE 0.10767993421726432\n",
      "113 Train Loss 39810892.0 Test MSE 55373.60568955335 Test RE 0.10518122524553382\n",
      "114 Train Loss 39759470.0 Test MSE 69996.13948245534 Test RE 0.11825618588811303\n",
      "115 Train Loss 39686932.0 Test MSE 78456.33394642056 Test RE 0.12519899107106824\n",
      "116 Train Loss 39612492.0 Test MSE 68395.0266183509 Test RE 0.11689584780918687\n",
      "117 Train Loss 39554136.0 Test MSE 55392.56129960706 Test RE 0.10519922663506623\n",
      "118 Train Loss 39508984.0 Test MSE 44348.83540374087 Test RE 0.09412997287672996\n",
      "119 Train Loss 39446356.0 Test MSE 41179.92940784049 Test RE 0.0907046647643593\n",
      "120 Train Loss 39390384.0 Test MSE 45258.72680123991 Test RE 0.09509068805303589\n",
      "121 Train Loss 39281830.0 Test MSE 44715.727069078435 Test RE 0.09451853290643625\n",
      "122 Train Loss 39102676.0 Test MSE 32722.553349085414 Test RE 0.08085565802498385\n",
      "123 Train Loss 38964320.0 Test MSE 19921.16324691828 Test RE 0.06308762392537505\n",
      "124 Train Loss 38833644.0 Test MSE 15164.61173838619 Test RE 0.05504304755869627\n",
      "125 Train Loss 38737692.0 Test MSE 8152.529731241325 Test RE 0.040358314404248204\n",
      "126 Train Loss 38640332.0 Test MSE 2222.8253739524484 Test RE 0.02107363707665037\n",
      "127 Train Loss 38575136.0 Test MSE 1030.6657605467701 Test RE 0.014349796691476702\n",
      "128 Train Loss 38522772.0 Test MSE 2159.5588989994544 Test RE 0.020771571281577052\n",
      "129 Train Loss 38455748.0 Test MSE 4540.214301291789 Test RE 0.030117921695829684\n",
      "130 Train Loss 38346536.0 Test MSE 12873.106777678058 Test RE 0.05071407510167859\n",
      "131 Train Loss 38243484.0 Test MSE 40323.67293528742 Test RE 0.08975669762523003\n",
      "132 Train Loss 38199172.0 Test MSE 58342.28921302886 Test RE 0.10796389808318752\n",
      "133 Train Loss 38153748.0 Test MSE 85928.45317838958 Test RE 0.13102534764038726\n",
      "134 Train Loss 38106668.0 Test MSE 115019.16739040056 Test RE 0.15159048183876625\n",
      "135 Train Loss 38077384.0 Test MSE 120386.10010160098 Test RE 0.15508685767862673\n",
      "136 Train Loss 38046588.0 Test MSE 124938.90132614017 Test RE 0.1579922066835126\n",
      "137 Train Loss 38016410.0 Test MSE 137236.53726114097 Test RE 0.1655852695527209\n",
      "138 Train Loss 37976700.0 Test MSE 166682.44516248532 Test RE 0.18248692578810505\n",
      "139 Train Loss 37933084.0 Test MSE 186827.1399478929 Test RE 0.19319985955475777\n",
      "140 Train Loss 37905856.0 Test MSE 215492.2980292719 Test RE 0.20749264168147769\n",
      "141 Train Loss 37846060.0 Test MSE 267661.71626512875 Test RE 0.2312490476337444\n",
      "142 Train Loss 37797100.0 Test MSE 318659.52012384834 Test RE 0.2523191846220392\n",
      "143 Train Loss 37755860.0 Test MSE 340939.0588352882 Test RE 0.2609908024182158\n",
      "144 Train Loss 37685892.0 Test MSE 347090.5048815607 Test RE 0.26333476046793064\n",
      "145 Train Loss 37573944.0 Test MSE 326590.8368992891 Test RE 0.25543995056290014\n",
      "146 Train Loss 37432584.0 Test MSE 270670.6962009677 Test RE 0.23254523429874702\n",
      "147 Train Loss 37232336.0 Test MSE 163353.0052290591 Test RE 0.18065516718823663\n",
      "148 Train Loss 37099250.0 Test MSE 133130.52661746668 Test RE 0.16308936757016515\n",
      "149 Train Loss 37033776.0 Test MSE 106651.08292482082 Test RE 0.145971966391009\n",
      "150 Train Loss 36999420.0 Test MSE 80988.97066509268 Test RE 0.12720370568195508\n",
      "151 Train Loss 36938036.0 Test MSE 49148.579401362455 Test RE 0.09909284750773487\n",
      "152 Train Loss 36858256.0 Test MSE 33148.66429314695 Test RE 0.08138040378769215\n",
      "153 Train Loss 36765030.0 Test MSE 32215.827408704197 Test RE 0.08022716922736689\n",
      "154 Train Loss 36609932.0 Test MSE 42699.89137547332 Test RE 0.09236346324116192\n",
      "155 Train Loss 36444464.0 Test MSE 65070.70090299727 Test RE 0.11401961389444973\n",
      "156 Train Loss 36336630.0 Test MSE 96057.32101281716 Test RE 0.1385326234680467\n",
      "157 Train Loss 36265444.0 Test MSE 129250.82394259928 Test RE 0.16069541435506735\n",
      "158 Train Loss 36109950.0 Test MSE 142538.00788203024 Test RE 0.16875325793994017\n",
      "159 Train Loss 35914700.0 Test MSE 110183.5797085126 Test RE 0.14836971504540397\n",
      "160 Train Loss 35751490.0 Test MSE 65627.7729461985 Test RE 0.11450663627332744\n",
      "161 Train Loss 35620190.0 Test MSE 45143.9207847093 Test RE 0.09497000508379573\n",
      "162 Train Loss 35496490.0 Test MSE 39581.33369246974 Test RE 0.08892667116939462\n",
      "163 Train Loss 35401056.0 Test MSE 28257.39351985738 Test RE 0.07513683089479165\n",
      "164 Train Loss 35347784.0 Test MSE 17242.823426322222 Test RE 0.0586936359623643\n",
      "165 Train Loss 35323850.0 Test MSE 12543.475924270835 Test RE 0.050060568118193156\n",
      "166 Train Loss 35303516.0 Test MSE 9446.985982279866 Test RE 0.04344436553398441\n",
      "167 Train Loss 35282732.0 Test MSE 8505.089188806736 Test RE 0.04122173430884531\n",
      "168 Train Loss 35259652.0 Test MSE 8599.039224484488 Test RE 0.0414487834894272\n",
      "169 Train Loss 35217260.0 Test MSE 6646.132604193136 Test RE 0.03643940900377642\n",
      "170 Train Loss 35171740.0 Test MSE 3697.8339822816924 Test RE 0.02718069318337948\n",
      "171 Train Loss 35134616.0 Test MSE 1944.6136170261477 Test RE 0.019710765217678426\n",
      "172 Train Loss 35080416.0 Test MSE 2047.239840284311 Test RE 0.020224192293144115\n",
      "173 Train Loss 35038052.0 Test MSE 1751.3820710589364 Test RE 0.018705842503058723\n",
      "174 Train Loss 34997876.0 Test MSE 3104.870335803213 Test RE 0.024906262308135724\n",
      "175 Train Loss 34932812.0 Test MSE 2287.166329146945 Test RE 0.021376455649366653\n",
      "176 Train Loss 34872516.0 Test MSE 1371.736421341091 Test RE 0.016554732156787873\n",
      "177 Train Loss 34849536.0 Test MSE 3880.6307300096705 Test RE 0.027844407621351867\n",
      "178 Train Loss 34807268.0 Test MSE 6125.306651509948 Test RE 0.03498249183971917\n",
      "179 Train Loss 34763600.0 Test MSE 6957.415857591446 Test RE 0.03728299606364316\n",
      "180 Train Loss 34705132.0 Test MSE 8047.65254767586 Test RE 0.04009788191228855\n",
      "181 Train Loss 34640650.0 Test MSE 6892.616308283969 Test RE 0.037108967871578434\n",
      "182 Train Loss 34598960.0 Test MSE 3518.1443768362305 Test RE 0.02651207090908435\n",
      "183 Train Loss 34579492.0 Test MSE 2032.0732292551268 Test RE 0.020149139370883903\n",
      "184 Train Loss 34548896.0 Test MSE 2142.0943295077377 Test RE 0.020687409890242585\n",
      "185 Train Loss 34513510.0 Test MSE 2549.158231532405 Test RE 0.02256759194742669\n",
      "186 Train Loss 34440350.0 Test MSE 9417.52705146074 Test RE 0.04337657545509511\n",
      "187 Train Loss 34398420.0 Test MSE 14923.101250909638 Test RE 0.054602982659549985\n",
      "188 Train Loss 34363416.0 Test MSE 18196.34251042856 Test RE 0.060294663417396865\n",
      "189 Train Loss 34324800.0 Test MSE 20391.710770495047 Test RE 0.06382835546001503\n",
      "190 Train Loss 34302148.0 Test MSE 21887.495421061118 Test RE 0.0661279192742933\n",
      "191 Train Loss 34260916.0 Test MSE 27547.491796023427 Test RE 0.07418700778456451\n",
      "192 Train Loss 34202700.0 Test MSE 33734.50569276619 Test RE 0.08209637840393096\n",
      "193 Train Loss 34164948.0 Test MSE 37078.41778197336 Test RE 0.08606913145934256\n",
      "194 Train Loss 34139350.0 Test MSE 40693.87743846298 Test RE 0.09016777644656666\n",
      "195 Train Loss 34112450.0 Test MSE 37542.625834722756 Test RE 0.08660623243023487\n",
      "196 Train Loss 34074644.0 Test MSE 31684.119300883915 Test RE 0.07956235758027617\n",
      "197 Train Loss 34040290.0 Test MSE 28700.70386075281 Test RE 0.07572392164707775\n",
      "198 Train Loss 34023736.0 Test MSE 25320.95558031205 Test RE 0.07112575170417276\n",
      "199 Train Loss 33998564.0 Test MSE 20566.754102639654 Test RE 0.06410172275407883\n",
      "Training time: 74.48\n",
      "Training time: 74.48\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "9\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 1.81\n",
      "Training time: 1.81\n"
     ]
    }
   ],
   "source": [
    " \n",
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  beta_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers)\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.01, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "  optimizer_lambda = torch.optim.Adam(PINN.parameters(), lr=5e-3)\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "e199619a-d416-48f4-91f7-2c23d1e79435"
   },
   "outputs": [],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_FODE_tanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
