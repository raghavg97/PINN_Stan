{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "3df10486-4078-44cd-95da-12a75fb13c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "515a82ba-2a23-4124-c9e1-230f67f43912"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "d35a8c58-7c75-4550-d489-9565724f04e6"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "7b44eee8-32ab-4621-ca04-81e30b53601d"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"high\"\n",
    "label = \"1D_FODE_tanhAW_\" +level\n",
    "extent = 100.0\n",
    "\n",
    "x = np.linspace(extent,-1.0*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "            \n",
    "        self.m_lambda = nn.Sigmoid()    \n",
    "        self.lambdas_bc1 = Parameter(torch.ones(1,1))\n",
    "        self.lambdas_bc1.requiresGrad = True\n",
    "        \n",
    "        self.lambdas_f = Parameter(torch.ones(N_f+1,1))\n",
    "        self.lambdas_f.requiresGrad = True\n",
    "             \n",
    "      \n",
    "              \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y,lambda_ind):\n",
    "        m = self.m_lambda(self.lambdas_bc1)\n",
    "        u_pred = self.forward(x)\n",
    "        \n",
    "        if(lambda_ind):\n",
    "            u_pred = u_pred.detach()\n",
    "        else:\n",
    "            m = m.detach()\n",
    "            \n",
    "        loss_bc1 = torch.sum(m*torch.square(u_pred - y))/2.0\n",
    "                \n",
    "        # loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat,lambda_ind):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        m = self.m_lambda(self.lambdas_f)\n",
    "        \n",
    "        if(lambda_ind):\n",
    "            f = f.detach()\n",
    "        else:\n",
    "            m = m.detach()\n",
    "        \n",
    "        #loss_f  = torch.sum(m*(torch.square(f)))/2.0\n",
    "        loss_f = self.loss_function(m*(torch.square(f)),f_hat)/2.0\n",
    "        \n",
    "        # loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        lambda_ind = False\n",
    "        \n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1,lambda_ind)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat,lambda_ind)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def loss_lambdas(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        lambda_ind = True        \n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1,lambda_ind)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat,lambda_ind)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return -1.0*loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    for i in range(20):\n",
    "        optimizer_lambda.zero_grad()\n",
    "        loss = PINN.loss_lambdas(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        optimizer_lambda.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "   \n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fAcpqTqePPt9"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    x_coll_np_array = colloc_pts(N_f,123)\n",
    "    x_coll = torch.from_numpy(x_coll_np_array).float().to(device)\n",
    "\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(i)        \n",
    "    \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "3645d237-1d2a-45c9-8d9f-de486f1ca919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "0\n",
      "0 Train Loss 1263738500.0 Test MSE 5617656.166033975 Test RE 1.0594108117615746\n",
      "1 Train Loss 1224992800.0 Test MSE 5943791.325478427 Test RE 1.0897292308840152\n",
      "2 Train Loss 1212437900.0 Test MSE 6119392.3448952595 Test RE 1.1057093272051168\n",
      "3 Train Loss 1203108400.0 Test MSE 6318407.033946815 Test RE 1.1235453937769948\n",
      "4 Train Loss 1173147100.0 Test MSE 6727345.51076089 Test RE 1.1593343139178873\n",
      "5 Train Loss 1150867100.0 Test MSE 7145544.093734273 Test RE 1.1948254797930926\n",
      "6 Train Loss 1156700200.0 Test MSE 7225040.840868061 Test RE 1.2014535274537472\n",
      "7 Train Loss 1144500400.0 Test MSE 7774966.845506993 Test RE 1.2463387460505089\n",
      "8 Train Loss 1148193500.0 Test MSE 7800392.97529265 Test RE 1.2483750058423577\n",
      "9 Train Loss 1155723900.0 Test MSE 7982208.604120114 Test RE 1.2628400893884795\n",
      "10 Train Loss 1163144200.0 Test MSE 8154051.531312642 Test RE 1.2763610703553623\n",
      "11 Train Loss 1164131200.0 Test MSE 8216784.609695943 Test RE 1.2812614958606994\n",
      "12 Train Loss 1159281700.0 Test MSE 9004190.602127139 Test RE 1.3412482350159458\n",
      "13 Train Loss 1153523600.0 Test MSE 9279605.322469983 Test RE 1.3616063756807395\n",
      "14 Train Loss 1159428600.0 Test MSE 9255437.83472318 Test RE 1.359832159137507\n",
      "15 Train Loss 1164520400.0 Test MSE 9356133.56925974 Test RE 1.3672093830920504\n",
      "16 Train Loss 1170424800.0 Test MSE 9304038.704448773 Test RE 1.363397765349765\n",
      "17 Train Loss 1175616100.0 Test MSE 9523080.117526818 Test RE 1.3793533776540754\n",
      "18 Train Loss 1185397800.0 Test MSE 9590280.37217877 Test RE 1.3842115720670374\n",
      "19 Train Loss 1194801800.0 Test MSE 9532252.343453093 Test RE 1.380017485049865\n",
      "20 Train Loss 1203020500.0 Test MSE 9553867.20603724 Test RE 1.3815812286828824\n",
      "21 Train Loss 1211753600.0 Test MSE 9615767.969119363 Test RE 1.3860497256842985\n",
      "22 Train Loss 1220620300.0 Test MSE 9710519.450999655 Test RE 1.3928618870132068\n",
      "23 Train Loss 1229276700.0 Test MSE 9644891.957151063 Test RE 1.3881471544127648\n",
      "24 Train Loss 1237744300.0 Test MSE 9608826.491047528 Test RE 1.3855493511540917\n",
      "25 Train Loss 1246021500.0 Test MSE 9598535.962521607 Test RE 1.3848072285559174\n",
      "26 Train Loss 1253814300.0 Test MSE 9674274.132582456 Test RE 1.3902599705766363\n",
      "27 Train Loss 1260539000.0 Test MSE 9743204.275569346 Test RE 1.3952040481225447\n",
      "28 Train Loss 1266388600.0 Test MSE 9853750.531345367 Test RE 1.403096706316106\n",
      "29 Train Loss 1270762200.0 Test MSE 10100792.158555424 Test RE 1.4205762220517681\n",
      "30 Train Loss 1239881200.0 Test MSE 10294496.50100386 Test RE 1.434132833583906\n",
      "31 Train Loss 1233832100.0 Test MSE 10562721.920665497 Test RE 1.452696020738917\n",
      "32 Train Loss 1212311300.0 Test MSE 10502335.452566473 Test RE 1.4485375794142776\n",
      "33 Train Loss 1212790500.0 Test MSE 10234909.906590952 Test RE 1.4299762870045092\n",
      "34 Train Loss 1207651100.0 Test MSE 10117528.626945214 Test RE 1.4217526440671044\n",
      "35 Train Loss 1208389100.0 Test MSE 10103739.496781955 Test RE 1.4207834638776387\n",
      "36 Train Loss 1212115500.0 Test MSE 10115835.684729058 Test RE 1.421633689831522\n",
      "37 Train Loss 1215854000.0 Test MSE 10071870.379169518 Test RE 1.4185409834334073\n",
      "38 Train Loss 1218863000.0 Test MSE 10049211.798503805 Test RE 1.4169444466481262\n",
      "39 Train Loss 1222508200.0 Test MSE 10172224.13699755 Test RE 1.425590472176234\n",
      "40 Train Loss 1226265000.0 Test MSE 10190399.095366286 Test RE 1.4268634722563984\n",
      "41 Train Loss 1229654500.0 Test MSE 10131267.128159342 Test RE 1.4227176091691698\n",
      "42 Train Loss 1233614000.0 Test MSE 10124786.846478144 Test RE 1.4222625286000479\n",
      "43 Train Loss 1236916200.0 Test MSE 10169288.711792171 Test RE 1.4253847641575033\n",
      "44 Train Loss 1239989400.0 Test MSE 10166267.617765345 Test RE 1.4251730216556557\n",
      "45 Train Loss 1243802600.0 Test MSE 10237089.529875178 Test RE 1.4301285425552883\n",
      "46 Train Loss 1247392300.0 Test MSE 10232947.464362172 Test RE 1.4298391885635986\n",
      "47 Train Loss 1250825300.0 Test MSE 10179132.719218077 Test RE 1.4260744930349984\n",
      "48 Train Loss 1253498600.0 Test MSE 10192273.145339819 Test RE 1.4269946688120283\n",
      "49 Train Loss 1256151600.0 Test MSE 10129451.310919305 Test RE 1.422590107303165\n",
      "50 Train Loss 1259706900.0 Test MSE 10122667.276964989 Test RE 1.4221136493135358\n",
      "51 Train Loss 1262945400.0 Test MSE 10191652.691415338 Test RE 1.426951234049994\n",
      "52 Train Loss 1265939200.0 Test MSE 10129489.201615958 Test RE 1.4225927680040342\n",
      "53 Train Loss 1268718000.0 Test MSE 10091689.805597749 Test RE 1.4199359999585974\n",
      "54 Train Loss 1270884700.0 Test MSE 10073609.979208123 Test RE 1.4186634823989244\n",
      "55 Train Loss 1273398300.0 Test MSE 10088188.542572973 Test RE 1.4196896586222956\n",
      "56 Train Loss 1276194800.0 Test MSE 10070965.62980034 Test RE 1.4184772687093705\n",
      "57 Train Loss 1278194300.0 Test MSE 10001510.473058004 Test RE 1.4135774896556819\n",
      "58 Train Loss 1279814700.0 Test MSE 9982457.705402901 Test RE 1.4122304230132623\n",
      "59 Train Loss 1282043500.0 Test MSE 9978046.310004964 Test RE 1.4119183457975688\n",
      "60 Train Loss 1284602600.0 Test MSE 9961455.662263563 Test RE 1.4107440485245633\n",
      "61 Train Loss 1287193100.0 Test MSE 9964567.324342059 Test RE 1.410964368533663\n",
      "62 Train Loss 1289113700.0 Test MSE 9932979.237756673 Test RE 1.40872618592106\n",
      "63 Train Loss 1290732400.0 Test MSE 9913514.63363778 Test RE 1.40734524354702\n",
      "64 Train Loss 1286565600.0 Test MSE 10064166.455682598 Test RE 1.4179983621851153\n",
      "65 Train Loss 1281493200.0 Test MSE 10023208.796156067 Test RE 1.4151100403286874\n",
      "66 Train Loss 1277918700.0 Test MSE 9870368.035836132 Test RE 1.404279309018009\n",
      "67 Train Loss 1273733100.0 Test MSE 10036711.810964448 Test RE 1.416062919841162\n",
      "68 Train Loss 1269219100.0 Test MSE 10106734.319735134 Test RE 1.4209940136287589\n",
      "69 Train Loss 1269657700.0 Test MSE 10221838.467853956 Test RE 1.4290628534983045\n",
      "70 Train Loss 1271212400.0 Test MSE 10253613.844028186 Test RE 1.4312823062551268\n",
      "71 Train Loss 1272474600.0 Test MSE 10200121.027504098 Test RE 1.4275439442749407\n",
      "72 Train Loss 1273537200.0 Test MSE 10182356.464186836 Test RE 1.4263002950096666\n",
      "73 Train Loss 1274062600.0 Test MSE 10135692.356819732 Test RE 1.423028289132506\n",
      "74 Train Loss 1275257700.0 Test MSE 10145898.039453838 Test RE 1.4237445362625103\n",
      "75 Train Loss 1276585300.0 Test MSE 10214820.994234849 Test RE 1.4285722307660238\n",
      "76 Train Loss 1277537800.0 Test MSE 10255897.02301294 Test RE 1.4314416496748197\n",
      "77 Train Loss 1278742100.0 Test MSE 10255216.90357149 Test RE 1.4313941858872132\n",
      "78 Train Loss 1279836700.0 Test MSE 10292533.855472492 Test RE 1.4339961183708263\n",
      "79 Train Loss 1281317600.0 Test MSE 10297544.591475198 Test RE 1.434345133578054\n",
      "80 Train Loss 1282725000.0 Test MSE 10273861.506167328 Test RE 1.4326947754808996\n",
      "81 Train Loss 1283786600.0 Test MSE 10268520.642186606 Test RE 1.4323223340855271\n",
      "82 Train Loss 1284907600.0 Test MSE 10269875.53892218 Test RE 1.4324168260240966\n",
      "83 Train Loss 1286232200.0 Test MSE 10280387.94168118 Test RE 1.4331497604725802\n",
      "84 Train Loss 1287131300.0 Test MSE 10276032.460300025 Test RE 1.43284613776811\n",
      "85 Train Loss 1287666000.0 Test MSE 10301512.683308173 Test RE 1.4346214647441269\n",
      "86 Train Loss 1288566400.0 Test MSE 10364363.694163674 Test RE 1.438991225714846\n",
      "87 Train Loss 1289245200.0 Test MSE 10384862.305118991 Test RE 1.4404135393101778\n",
      "88 Train Loss 1290022900.0 Test MSE 10348064.463667609 Test RE 1.4378592855944365\n",
      "89 Train Loss 1290834200.0 Test MSE 10404863.960872307 Test RE 1.4418000187663988\n",
      "90 Train Loss 1291928000.0 Test MSE 10401397.033218665 Test RE 1.4415597930012063\n",
      "91 Train Loss 1293189100.0 Test MSE 10389950.752841506 Test RE 1.4407663880606953\n",
      "92 Train Loss 1294278500.0 Test MSE 10372742.01027721 Test RE 1.4395727321246548\n",
      "93 Train Loss 1295313400.0 Test MSE 10380700.441680353 Test RE 1.4401248785165524\n",
      "94 Train Loss 1296140300.0 Test MSE 10412354.936292576 Test RE 1.4423189369036435\n",
      "95 Train Loss 1296442100.0 Test MSE 10436922.666297253 Test RE 1.444019494814072\n",
      "96 Train Loss 1296716800.0 Test MSE 10448896.531753113 Test RE 1.4448475903824645\n",
      "97 Train Loss 1296876700.0 Test MSE 10486095.710732022 Test RE 1.4474172106542682\n",
      "98 Train Loss 1297117800.0 Test MSE 10514256.841600897 Test RE 1.4493594767153057\n",
      "99 Train Loss 1297604400.0 Test MSE 10580917.336150961 Test RE 1.453946694310705\n",
      "100 Train Loss 1298176800.0 Test MSE 10618767.755435307 Test RE 1.4565449266781942\n",
      "101 Train Loss 1298490100.0 Test MSE 10606718.227655688 Test RE 1.4557182930872523\n",
      "102 Train Loss 1298534800.0 Test MSE 10577578.348169366 Test RE 1.4537172674358438\n",
      "103 Train Loss 1298364300.0 Test MSE 10548079.177517612 Test RE 1.4516887599233952\n",
      "104 Train Loss 1298465200.0 Test MSE 10546033.229863068 Test RE 1.4515479654147654\n",
      "105 Train Loss 1298861600.0 Test MSE 10526602.62749727 Test RE 1.4502101422701343\n",
      "106 Train Loss 1299568500.0 Test MSE 10531206.252613567 Test RE 1.450527219597848\n",
      "107 Train Loss 1300313000.0 Test MSE 10538447.612279603 Test RE 1.4510258321994918\n",
      "108 Train Loss 1300901500.0 Test MSE 10516400.790470783 Test RE 1.4495072377159655\n",
      "109 Train Loss 1301506300.0 Test MSE 10519521.677462887 Test RE 1.4497223023945516\n",
      "110 Train Loss 1301983600.0 Test MSE 10550906.229951331 Test RE 1.4518832846906655\n",
      "111 Train Loss 1302523600.0 Test MSE 10540041.408542624 Test RE 1.4511355519704587\n",
      "112 Train Loss 1303155200.0 Test MSE 10526051.664899677 Test RE 1.4501721897592124\n",
      "113 Train Loss 1303276300.0 Test MSE 10554692.87284201 Test RE 1.4521437964519308\n",
      "114 Train Loss 1303664400.0 Test MSE 10584073.874649635 Test RE 1.4541635515233768\n",
      "115 Train Loss 1303756900.0 Test MSE 10596426.805859381 Test RE 1.4550118989683933\n",
      "116 Train Loss 1304126000.0 Test MSE 10603445.313239558 Test RE 1.45549368030493\n",
      "117 Train Loss 1304438900.0 Test MSE 10624159.944437 Test RE 1.456914695040732\n",
      "118 Train Loss 1304420200.0 Test MSE 10605932.001715764 Test RE 1.4556643393256365\n",
      "119 Train Loss 1304892900.0 Test MSE 10603950.128931308 Test RE 1.4555283269354538\n",
      "120 Train Loss 1305027600.0 Test MSE 10630563.281374158 Test RE 1.4573536808266476\n",
      "121 Train Loss 1305289300.0 Test MSE 10651641.447983878 Test RE 1.4587977779529213\n",
      "122 Train Loss 1305778000.0 Test MSE 10664458.18525878 Test RE 1.4596751735620577\n",
      "123 Train Loss 1305611600.0 Test MSE 10724149.848359104 Test RE 1.4637545583019953\n",
      "124 Train Loss 1304638200.0 Test MSE 10639231.755244138 Test RE 1.4579477442680768\n",
      "125 Train Loss 1304096600.0 Test MSE 10581057.908272468 Test RE 1.4539563524379757\n",
      "126 Train Loss 1303349100.0 Test MSE 10650284.286180483 Test RE 1.458704839803396\n",
      "127 Train Loss 1303485800.0 Test MSE 10638253.982992556 Test RE 1.4578807481899956\n",
      "128 Train Loss 1303657100.0 Test MSE 10615034.814508596 Test RE 1.456288885947853\n",
      "129 Train Loss 1303935900.0 Test MSE 10628692.962298257 Test RE 1.457225473307573\n",
      "130 Train Loss 1304356200.0 Test MSE 10619070.1115456 Test RE 1.4565656631767112\n",
      "131 Train Loss 1304231700.0 Test MSE 10652716.41417532 Test RE 1.4588713872053725\n",
      "132 Train Loss 1304325900.0 Test MSE 10705545.04903781 Test RE 1.4624843092989823\n",
      "133 Train Loss 1304710300.0 Test MSE 10738057.772803009 Test RE 1.4647034070204865\n",
      "134 Train Loss 1305017500.0 Test MSE 10758403.61381322 Test RE 1.4660903673310335\n",
      "135 Train Loss 1305261700.0 Test MSE 10753040.684385953 Test RE 1.465724907940176\n",
      "136 Train Loss 1305142700.0 Test MSE 10724760.222817315 Test RE 1.4637962131509004\n",
      "137 Train Loss 1304818200.0 Test MSE 10724109.585828625 Test RE 1.4637518105542175\n",
      "138 Train Loss 1304081400.0 Test MSE 10730298.138608426 Test RE 1.4641740926464788\n",
      "139 Train Loss 1303807600.0 Test MSE 10800543.182975572 Test RE 1.4689588243968768\n",
      "140 Train Loss 1303123300.0 Test MSE 10820319.393742854 Test RE 1.4703030694440986\n",
      "141 Train Loss 1303225000.0 Test MSE 10831186.535068924 Test RE 1.4710412168543985\n",
      "142 Train Loss 1303175300.0 Test MSE 10813348.84292481 Test RE 1.469829401661332\n",
      "143 Train Loss 1302980400.0 Test MSE 10809292.714012519 Test RE 1.4695537064627906\n",
      "144 Train Loss 1303217300.0 Test MSE 10835666.447595736 Test RE 1.471345405811628\n",
      "145 Train Loss 1303401900.0 Test MSE 10817437.750937244 Test RE 1.4701072725255824\n",
      "146 Train Loss 1302978400.0 Test MSE 10842941.930094765 Test RE 1.471839281823321\n",
      "147 Train Loss 1301915300.0 Test MSE 10864435.442439118 Test RE 1.4732973424821239\n",
      "148 Train Loss 1301355800.0 Test MSE 10818813.427460464 Test RE 1.4702007478851877\n",
      "149 Train Loss 1301314700.0 Test MSE 10848490.851555133 Test RE 1.4722158436460904\n",
      "150 Train Loss 1300883100.0 Test MSE 10882426.217228085 Test RE 1.4745166785885644\n",
      "151 Train Loss 1300636300.0 Test MSE 10820502.96350175 Test RE 1.4703155414435563\n",
      "152 Train Loss 1300554900.0 Test MSE 10827099.000127712 Test RE 1.4707636156996158\n",
      "153 Train Loss 1300419800.0 Test MSE 10851070.735606253 Test RE 1.4723908873661788\n",
      "154 Train Loss 1300329900.0 Test MSE 10836914.82975184 Test RE 1.4714301605637852\n",
      "155 Train Loss 1300282500.0 Test MSE 10825474.635654375 Test RE 1.4706532839395179\n",
      "156 Train Loss 1299875100.0 Test MSE 10837700.514278661 Test RE 1.4714834994971535\n",
      "157 Train Loss 1299016800.0 Test MSE 10866148.651140204 Test RE 1.4734134997524624\n",
      "158 Train Loss 1298793700.0 Test MSE 10851224.739148919 Test RE 1.472401335764029\n",
      "159 Train Loss 1298285300.0 Test MSE 10775419.84409658 Test RE 1.4672493438572995\n",
      "160 Train Loss 1297998300.0 Test MSE 10757412.006215792 Test RE 1.4660228006222746\n",
      "161 Train Loss 1296650600.0 Test MSE 10892489.693649657 Test RE 1.4751982974939766\n",
      "162 Train Loss 1296562200.0 Test MSE 10874500.560080942 Test RE 1.473979636479922\n",
      "163 Train Loss 1296582100.0 Test MSE 10848254.275001716 Test RE 1.4721997910147246\n",
      "164 Train Loss 1296554000.0 Test MSE 10852403.816929562 Test RE 1.4724813280498608\n",
      "165 Train Loss 1296225400.0 Test MSE 10856867.743632177 Test RE 1.4727841352916973\n",
      "166 Train Loss 1295927300.0 Test MSE 10884992.326668981 Test RE 1.4746905161163475\n",
      "167 Train Loss 1295778000.0 Test MSE 10883765.649267785 Test RE 1.4746074191125262\n",
      "168 Train Loss 1295301800.0 Test MSE 10894972.913536806 Test RE 1.4753664423852908\n",
      "169 Train Loss 1292016100.0 Test MSE 10916407.21036207 Test RE 1.4768170152383413\n",
      "170 Train Loss 1287640000.0 Test MSE 11081324.390711028 Test RE 1.4879305401815117\n",
      "171 Train Loss 1286247600.0 Test MSE 11153388.639929807 Test RE 1.492760866801891\n",
      "172 Train Loss 1284715100.0 Test MSE 11124725.938223395 Test RE 1.4908415360440543\n",
      "173 Train Loss 1283219500.0 Test MSE 11242308.917980008 Test RE 1.4986995642000789\n",
      "174 Train Loss 1281682000.0 Test MSE 11230284.189641032 Test RE 1.4978978482558458\n",
      "175 Train Loss 1280185200.0 Test MSE 11263745.096624224 Test RE 1.5001277001918474\n",
      "176 Train Loss 1278368500.0 Test MSE 11289348.120050965 Test RE 1.5018316629238053\n",
      "177 Train Loss 1277060100.0 Test MSE 11218872.7668413 Test RE 1.4971366257529977\n",
      "178 Train Loss 1275696900.0 Test MSE 11300320.333839495 Test RE 1.5025613071853925\n",
      "179 Train Loss 1273290000.0 Test MSE 11331661.657911053 Test RE 1.5046435337152928\n",
      "180 Train Loss 1271585500.0 Test MSE 11270280.019041622 Test RE 1.500562803994988\n",
      "181 Train Loss 1270577300.0 Test MSE 11324793.716725886 Test RE 1.5041874942627556\n",
      "182 Train Loss 1268000300.0 Test MSE 11278138.81970073 Test RE 1.5010858863359506\n",
      "183 Train Loss 1266437900.0 Test MSE 11224091.54556366 Test RE 1.4974848031726227\n",
      "184 Train Loss 1265413000.0 Test MSE 11245586.29717665 Test RE 1.498918000149799\n",
      "185 Train Loss 1264539300.0 Test MSE 11210976.387591477 Test RE 1.4966096548273595\n",
      "186 Train Loss 1263245000.0 Test MSE 11224699.880202273 Test RE 1.4975253837189308\n",
      "187 Train Loss 1262089100.0 Test MSE 11304674.58697267 Test RE 1.50285076367705\n",
      "188 Train Loss 1260703200.0 Test MSE 11296367.343485301 Test RE 1.5022984770307435\n",
      "189 Train Loss 1258895200.0 Test MSE 11309521.400638686 Test RE 1.5031728984268584\n",
      "190 Train Loss 1256406000.0 Test MSE 11349233.356723497 Test RE 1.5058096866643056\n",
      "191 Train Loss 1255643800.0 Test MSE 11335719.60354013 Test RE 1.5049129211760357\n",
      "192 Train Loss 1254937100.0 Test MSE 11294827.915907914 Test RE 1.5021961096753391\n",
      "193 Train Loss 1254001500.0 Test MSE 11190005.254623434 Test RE 1.4952092285788743\n",
      "194 Train Loss 1253184900.0 Test MSE 11209084.455312345 Test RE 1.4964833677188287\n",
      "195 Train Loss 1252794800.0 Test MSE 11158881.202461151 Test RE 1.4931283817112528\n",
      "196 Train Loss 1252654100.0 Test MSE 11134651.16460328 Test RE 1.4915064351580838\n",
      "197 Train Loss 1252562400.0 Test MSE 11165513.016430106 Test RE 1.4935720049869479\n",
      "198 Train Loss 1252520100.0 Test MSE 11138088.822895404 Test RE 1.4917366576278424\n",
      "199 Train Loss 1252408200.0 Test MSE 11100635.16975949 Test RE 1.4892264408297167\n",
      "Training time: 48.81\n",
      "Training time: 48.81\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "1\n",
      "0 Train Loss 1260387500.0 Test MSE 5328942.302526898 Test RE 1.0318280566609423\n",
      "1 Train Loss 1243981200.0 Test MSE 5562260.278824613 Test RE 1.054174428787449\n",
      "2 Train Loss 1222058200.0 Test MSE 5798141.357033376 Test RE 1.0762947533642402\n",
      "3 Train Loss 1210608000.0 Test MSE 6084537.389787214 Test RE 1.1025558699603384\n",
      "4 Train Loss 1214198500.0 Test MSE 6139053.054021649 Test RE 1.1074841436535934\n",
      "5 Train Loss 1227711400.0 Test MSE 6234716.13963429 Test RE 1.1160795903234368\n",
      "6 Train Loss 1240148600.0 Test MSE 6284389.815280718 Test RE 1.1205168242014354\n",
      "7 Train Loss 1249578400.0 Test MSE 6344636.093518364 Test RE 1.1258750172589305\n",
      "8 Train Loss 1259037700.0 Test MSE 6440443.619010983 Test RE 1.134343834830162\n",
      "9 Train Loss 1255129300.0 Test MSE 6788965.163002827 Test RE 1.1646317181522192\n",
      "10 Train Loss 1252330500.0 Test MSE 6956237.140565463 Test RE 1.1788919796406307\n",
      "11 Train Loss 1249625700.0 Test MSE 7215509.184658017 Test RE 1.2006607553649264\n",
      "12 Train Loss 1260277000.0 Test MSE 7300996.399406674 Test RE 1.2077523488663133\n",
      "13 Train Loss 1270426900.0 Test MSE 7226386.271297629 Test RE 1.201565388197806\n",
      "14 Train Loss 1281282400.0 Test MSE 7237876.759707565 Test RE 1.2025202976532277\n",
      "15 Train Loss 1290973200.0 Test MSE 7341864.244836255 Test RE 1.211127871514148\n",
      "16 Train Loss 1301843200.0 Test MSE 7357128.111906656 Test RE 1.2123861960865339\n",
      "17 Train Loss 1311050600.0 Test MSE 7506392.365961499 Test RE 1.224623120368577\n",
      "18 Train Loss 1320324500.0 Test MSE 7834522.170365998 Test RE 1.2511030435308732\n",
      "19 Train Loss 1329606100.0 Test MSE 7792056.607245044 Test RE 1.2477077512869548\n",
      "20 Train Loss 1339054300.0 Test MSE 7787140.584362013 Test RE 1.247314098627504\n",
      "21 Train Loss 1347839500.0 Test MSE 7755334.407920907 Test RE 1.2447641969870265\n",
      "22 Train Loss 1355118000.0 Test MSE 7656767.001291412 Test RE 1.2368286576747174\n",
      "23 Train Loss 1363535500.0 Test MSE 7685722.288504118 Test RE 1.2391650834135384\n",
      "24 Train Loss 1373693200.0 Test MSE 7709710.040123858 Test RE 1.2410973433814745\n",
      "25 Train Loss 1381801600.0 Test MSE 7864838.079160245 Test RE 1.2535212960143518\n",
      "26 Train Loss 1391082500.0 Test MSE 7871503.698149933 Test RE 1.2540523766071774\n",
      "27 Train Loss 1399882000.0 Test MSE 7893150.412425008 Test RE 1.255775521073544\n",
      "28 Train Loss 1408744600.0 Test MSE 7885318.694574798 Test RE 1.255152365562442\n",
      "29 Train Loss 1416893300.0 Test MSE 7863938.804700299 Test RE 1.253449629446011\n",
      "30 Train Loss 1424353400.0 Test MSE 7809614.655345322 Test RE 1.2491127067831795\n",
      "31 Train Loss 1431344900.0 Test MSE 7717208.0520064365 Test RE 1.2417007059670635\n",
      "32 Train Loss 1438789200.0 Test MSE 7756802.836598259 Test RE 1.2448820359371162\n",
      "33 Train Loss 1444129400.0 Test MSE 7937718.940090573 Test RE 1.2593158870705283\n",
      "34 Train Loss 1450075400.0 Test MSE 8043657.389845912 Test RE 1.267691579782718\n",
      "35 Train Loss 1456900100.0 Test MSE 8064788.772783699 Test RE 1.2693556552366059\n",
      "36 Train Loss 1463290600.0 Test MSE 7974446.859432355 Test RE 1.2622259594664842\n",
      "37 Train Loss 1468848800.0 Test MSE 8066709.464962309 Test RE 1.2695067996996054\n",
      "38 Train Loss 1475136400.0 Test MSE 8137598.6946371095 Test RE 1.2750727314286643\n",
      "39 Train Loss 1481689900.0 Test MSE 8190960.875746689 Test RE 1.2792465353294546\n",
      "40 Train Loss 1487995300.0 Test MSE 8289610.580671999 Test RE 1.2869269280656455\n",
      "41 Train Loss 1493990000.0 Test MSE 8329722.215355771 Test RE 1.2900367513511029\n",
      "42 Train Loss 1499563900.0 Test MSE 8333487.899279229 Test RE 1.2903283170011721\n",
      "43 Train Loss 1504355300.0 Test MSE 8340717.9028967805 Test RE 1.290887929971705\n",
      "44 Train Loss 1508144000.0 Test MSE 8187841.498044674 Test RE 1.279002923305581\n",
      "45 Train Loss 1507274100.0 Test MSE 7943247.995099408 Test RE 1.2597544018875944\n",
      "46 Train Loss 1484414000.0 Test MSE 7664276.547557934 Test RE 1.237435032779513\n",
      "47 Train Loss 1474853600.0 Test MSE 7838282.855042395 Test RE 1.251403281341168\n",
      "48 Train Loss 1471954000.0 Test MSE 7971193.570159919 Test RE 1.2619684616647016\n",
      "49 Train Loss 1468414800.0 Test MSE 8145010.797472703 Test RE 1.2756532969890149\n",
      "50 Train Loss 1467040100.0 Test MSE 8260985.231380857 Test RE 1.2847030244211601\n",
      "51 Train Loss 1468985200.0 Test MSE 8341753.022013772 Test RE 1.2909680298704542\n",
      "52 Train Loss 1471597300.0 Test MSE 8385360.616120477 Test RE 1.2943379826678172\n",
      "53 Train Loss 1474774500.0 Test MSE 8389818.405927835 Test RE 1.2946819821863607\n",
      "54 Train Loss 1477987800.0 Test MSE 8387877.287190762 Test RE 1.2945322008256277\n",
      "55 Train Loss 1480996900.0 Test MSE 8377307.580243849 Test RE 1.2937163126851645\n",
      "56 Train Loss 1483653500.0 Test MSE 8432190.042325426 Test RE 1.297947172381415\n",
      "57 Train Loss 1484430500.0 Test MSE 8439098.439803781 Test RE 1.2984787602069778\n",
      "58 Train Loss 1487434600.0 Test MSE 8424836.838840708 Test RE 1.297381118293902\n",
      "59 Train Loss 1490660200.0 Test MSE 8424679.875276528 Test RE 1.2973690324507667\n",
      "60 Train Loss 1493847000.0 Test MSE 8424701.777667744 Test RE 1.2973707188926287\n",
      "61 Train Loss 1496918400.0 Test MSE 8424701.777667744 Test RE 1.2973707188926287\n",
      "62 Train Loss 1500035700.0 Test MSE 8424701.777667744 Test RE 1.2973707188926287\n",
      "63 Train Loss 1502823400.0 Test MSE 8424701.777667744 Test RE 1.2973707188926287\n",
      "64 Train Loss 1505553000.0 Test MSE 8424701.777667744 Test RE 1.2973707188926287\n",
      "65 Train Loss 1508277600.0 Test MSE 8423815.283402126 Test RE 1.2973024587933444\n",
      "66 Train Loss 1510840700.0 Test MSE 8423815.283402126 Test RE 1.2973024587933444\n",
      "67 Train Loss 1513307300.0 Test MSE 8423853.118025547 Test RE 1.297305372134463\n",
      "68 Train Loss 1515896800.0 Test MSE 8426098.878049579 Test RE 1.2974782883968672\n",
      "69 Train Loss 1517716400.0 Test MSE 8501814.131884234 Test RE 1.3032946926756481\n",
      "70 Train Loss 1519178100.0 Test MSE 8465428.190654825 Test RE 1.3005027913945675\n",
      "71 Train Loss 1521215200.0 Test MSE 8485207.022731835 Test RE 1.3020211681764993\n",
      "72 Train Loss 1523233400.0 Test MSE 8521037.492571274 Test RE 1.3047672935460903\n",
      "73 Train Loss 1525474700.0 Test MSE 8521845.100722358 Test RE 1.3048291237947973\n",
      "74 Train Loss 1527633800.0 Test MSE 8522231.862872155 Test RE 1.3048587331566932\n",
      "75 Train Loss 1529798300.0 Test MSE 8522231.862872155 Test RE 1.3048587331566932\n",
      "76 Train Loss 1531888400.0 Test MSE 8522231.862872155 Test RE 1.3048587331566932\n",
      "77 Train Loss 1533957900.0 Test MSE 8522246.52678276 Test RE 1.304859855768932\n",
      "78 Train Loss 1535986300.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "79 Train Loss 1538052500.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "80 Train Loss 1539977300.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "81 Train Loss 1541824000.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "82 Train Loss 1543568000.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "83 Train Loss 1545261400.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "84 Train Loss 1546965900.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "85 Train Loss 1548657400.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "86 Train Loss 1550267900.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "87 Train Loss 1551855000.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "88 Train Loss 1553406700.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "89 Train Loss 1554879000.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "90 Train Loss 1556330800.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "91 Train Loss 1557866000.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "92 Train Loss 1559344300.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "93 Train Loss 1560744600.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "94 Train Loss 1562135200.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "95 Train Loss 1563415700.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "96 Train Loss 1564663300.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "97 Train Loss 1565961100.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "98 Train Loss 1567212200.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "99 Train Loss 1568416000.0 Test MSE 8517511.87549167 Test RE 1.3044973389902934\n",
      "100 Train Loss 1569610100.0 Test MSE 8506610.699764198 Test RE 1.303662288337562\n",
      "101 Train Loss 1570751000.0 Test MSE 8506610.699764198 Test RE 1.303662288337562\n",
      "102 Train Loss 1571852500.0 Test MSE 8506610.699764198 Test RE 1.303662288337562\n",
      "103 Train Loss 1572949800.0 Test MSE 8506610.699764198 Test RE 1.303662288337562\n",
      "104 Train Loss 1573939100.0 Test MSE 8506816.55296581 Test RE 1.3036780620365018\n",
      "105 Train Loss 1574962200.0 Test MSE 8506367.024598705 Test RE 1.3036436162476985\n",
      "106 Train Loss 1575997400.0 Test MSE 8506367.024598705 Test RE 1.3036436162476985\n",
      "107 Train Loss 1577025000.0 Test MSE 8506443.523469247 Test RE 1.303649478153241\n",
      "108 Train Loss 1578087700.0 Test MSE 8506443.523469247 Test RE 1.303649478153241\n",
      "109 Train Loss 1579060700.0 Test MSE 8507836.119900292 Test RE 1.303756184517022\n",
      "110 Train Loss 1580106200.0 Test MSE 8507836.119900292 Test RE 1.303756184517022\n",
      "111 Train Loss 1581098600.0 Test MSE 8507836.119900292 Test RE 1.303756184517022\n",
      "112 Train Loss 1582046500.0 Test MSE 8507836.119900292 Test RE 1.303756184517022\n",
      "113 Train Loss 1582975100.0 Test MSE 8507836.119900292 Test RE 1.303756184517022\n",
      "114 Train Loss 1583875100.0 Test MSE 8507836.119900292 Test RE 1.303756184517022\n",
      "115 Train Loss 1584797000.0 Test MSE 8507836.119900292 Test RE 1.303756184517022\n",
      "116 Train Loss 1585664400.0 Test MSE 8507836.119900292 Test RE 1.303756184517022\n",
      "117 Train Loss 1586487700.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "118 Train Loss 1587315000.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "119 Train Loss 1588082400.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "120 Train Loss 1588905900.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "121 Train Loss 1589724200.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "122 Train Loss 1590507400.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "123 Train Loss 1591264300.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "124 Train Loss 1592009500.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "125 Train Loss 1592718300.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "126 Train Loss 1593422100.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "127 Train Loss 1594132500.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "128 Train Loss 1594821900.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "129 Train Loss 1595507000.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "130 Train Loss 1596182400.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "131 Train Loss 1596811100.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "132 Train Loss 1597450900.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "133 Train Loss 1598077000.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "134 Train Loss 1598703000.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "135 Train Loss 1599351900.0 Test MSE 8509505.111084873 Test RE 1.303884057858941\n",
      "136 Train Loss 1599922300.0 Test MSE 8525700.754127298 Test RE 1.3051242711405882\n",
      "137 Train Loss 1599645400.0 Test MSE 8538645.311904218 Test RE 1.3061146793928686\n",
      "138 Train Loss 1599857500.0 Test MSE 8517152.176262505 Test RE 1.3044697938780487\n",
      "139 Train Loss 1599491300.0 Test MSE 8504445.944051499 Test RE 1.3034964002976193\n",
      "140 Train Loss 1599813200.0 Test MSE 8503992.201633127 Test RE 1.3034616267508108\n",
      "141 Train Loss 1600299500.0 Test MSE 8501650.139410064 Test RE 1.3032821229141485\n",
      "142 Train Loss 1600825600.0 Test MSE 8501891.662637634 Test RE 1.303300635241993\n",
      "143 Train Loss 1601365000.0 Test MSE 8501891.662637634 Test RE 1.303300635241993\n",
      "144 Train Loss 1601913600.0 Test MSE 8501891.662637634 Test RE 1.303300635241993\n",
      "145 Train Loss 1602415600.0 Test MSE 8501891.662637634 Test RE 1.303300635241993\n",
      "146 Train Loss 1602881800.0 Test MSE 8501715.345664196 Test RE 1.3032871208840116\n",
      "147 Train Loss 1603366400.0 Test MSE 8501715.345664196 Test RE 1.3032871208840116\n",
      "148 Train Loss 1603837800.0 Test MSE 8501715.345664196 Test RE 1.3032871208840116\n",
      "149 Train Loss 1604291700.0 Test MSE 8501715.345664196 Test RE 1.3032871208840116\n",
      "150 Train Loss 1604759000.0 Test MSE 8501715.345664196 Test RE 1.3032871208840116\n",
      "151 Train Loss 1605242500.0 Test MSE 8501178.57319904 Test RE 1.303245977440909\n",
      "152 Train Loss 1605692500.0 Test MSE 8501178.57319904 Test RE 1.303245977440909\n",
      "153 Train Loss 1606128900.0 Test MSE 8501040.219681388 Test RE 1.3032353724761143\n",
      "154 Train Loss 1606567600.0 Test MSE 8497390.841835022 Test RE 1.3029556120759458\n",
      "155 Train Loss 1606998000.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "156 Train Loss 1607452700.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "157 Train Loss 1607865600.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "158 Train Loss 1608256500.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "159 Train Loss 1608658600.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "160 Train Loss 1609065600.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "161 Train Loss 1609472000.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "162 Train Loss 1609867300.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "163 Train Loss 1610245100.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "164 Train Loss 1610609300.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "165 Train Loss 1610963200.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "166 Train Loss 1611332400.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "167 Train Loss 1611684100.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "168 Train Loss 1612057200.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "169 Train Loss 1612415500.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "170 Train Loss 1612762400.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "171 Train Loss 1613125500.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "172 Train Loss 1613454700.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "173 Train Loss 1613770400.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "174 Train Loss 1614084000.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "175 Train Loss 1614409500.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "176 Train Loss 1614722300.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "177 Train Loss 1615024100.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "178 Train Loss 1615319700.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "179 Train Loss 1615623600.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "180 Train Loss 1615912700.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "181 Train Loss 1616207000.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "182 Train Loss 1616492000.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "183 Train Loss 1616767200.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "184 Train Loss 1617043200.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "185 Train Loss 1617319300.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "186 Train Loss 1617602200.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "187 Train Loss 1617873700.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "188 Train Loss 1618133200.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "189 Train Loss 1618398700.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "190 Train Loss 1618669700.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "191 Train Loss 1618923800.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "192 Train Loss 1619166300.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "193 Train Loss 1619405600.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "194 Train Loss 1619649200.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "195 Train Loss 1619881300.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "196 Train Loss 1620113500.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "197 Train Loss 1620340000.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "198 Train Loss 1620572000.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "199 Train Loss 1620801500.0 Test MSE 8497421.49266581 Test RE 1.3029579620111627\n",
      "Training time: 40.93\n",
      "Training time: 40.93\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "2\n",
      "0 Train Loss 1259397500.0 Test MSE 4460765.441294306 Test RE 0.9440424371693467\n",
      "1 Train Loss 1241714200.0 Test MSE 4248774.029507104 Test RE 0.9213372719729813\n",
      "2 Train Loss 1163317100.0 Test MSE 3953374.119544127 Test RE 0.8887319248495829\n",
      "3 Train Loss 1101217000.0 Test MSE 4001933.8077533776 Test RE 0.8941734575180256\n",
      "4 Train Loss 1080526800.0 Test MSE 3877383.707201891 Test RE 0.8801490289979147\n",
      "5 Train Loss 1067941250.0 Test MSE 3643991.0190006117 Test RE 0.853248380462297\n",
      "6 Train Loss 1072304830.0 Test MSE 3606051.0393109038 Test RE 0.8487948939274363\n",
      "7 Train Loss 1072857100.0 Test MSE 3567352.1437561605 Test RE 0.8442281216514477\n",
      "8 Train Loss 1080882000.0 Test MSE 3469770.7708132323 Test RE 0.8326015513779018\n",
      "9 Train Loss 1091736300.0 Test MSE 3483932.5920073325 Test RE 0.834298946999534\n",
      "10 Train Loss 1102683800.0 Test MSE 3479912.709743164 Test RE 0.833817486546736\n",
      "11 Train Loss 1114199800.0 Test MSE 3457805.0823544464 Test RE 0.8311646762271808\n",
      "12 Train Loss 1122666500.0 Test MSE 3422418.09093267 Test RE 0.8269006915057524\n",
      "13 Train Loss 1131236200.0 Test MSE 3389217.8899188973 Test RE 0.8228801170115794\n",
      "14 Train Loss 1140237200.0 Test MSE 3405572.4456826556 Test RE 0.8248631176867222\n",
      "15 Train Loss 1146171800.0 Test MSE 3431086.5301842173 Test RE 0.827947233037029\n",
      "16 Train Loss 1155068800.0 Test MSE 3437575.3829713934 Test RE 0.8287297679550194\n",
      "17 Train Loss 1163957900.0 Test MSE 3443902.684974594 Test RE 0.8294921094694979\n",
      "18 Train Loss 1170165500.0 Test MSE 3451162.242911789 Test RE 0.8303659111619903\n",
      "19 Train Loss 1178175000.0 Test MSE 3457175.927266502 Test RE 0.831089056685043\n",
      "20 Train Loss 1186329200.0 Test MSE 3441914.830049786 Test RE 0.8292526793612366\n",
      "21 Train Loss 1193818800.0 Test MSE 3446771.343157424 Test RE 0.8298375074429313\n",
      "22 Train Loss 1201834200.0 Test MSE 3443852.752064746 Test RE 0.8294860960729757\n",
      "23 Train Loss 1209667300.0 Test MSE 3448688.79650733 Test RE 0.8300682963925554\n",
      "24 Train Loss 1216215200.0 Test MSE 3470180.8109291205 Test RE 0.8326507462633171\n",
      "25 Train Loss 1223282400.0 Test MSE 3476115.7958900146 Test RE 0.833362475532901\n",
      "26 Train Loss 1230762200.0 Test MSE 3462153.1415470415 Test RE 0.8316870911314822\n",
      "27 Train Loss 1238211300.0 Test MSE 3466019.5620197607 Test RE 0.8321513621474625\n",
      "28 Train Loss 1245597800.0 Test MSE 3463628.554073726 Test RE 0.8318642858999697\n",
      "29 Train Loss 1252111500.0 Test MSE 3442698.9957972933 Test RE 0.8293471376128112\n",
      "30 Train Loss 1257599500.0 Test MSE 3442504.206570015 Test RE 0.829323674891636\n",
      "31 Train Loss 1262865300.0 Test MSE 3429889.719303286 Test RE 0.8278028206660056\n",
      "32 Train Loss 1267731800.0 Test MSE 3420550.4869109215 Test RE 0.8266750420151426\n",
      "33 Train Loss 1272950800.0 Test MSE 3423963.897583166 Test RE 0.8270874139125702\n",
      "34 Train Loss 1277443500.0 Test MSE 3431102.921914587 Test RE 0.8279492107591697\n",
      "35 Train Loss 1281527000.0 Test MSE 3441761.6334829847 Test RE 0.8292342245063973\n",
      "36 Train Loss 1284394600.0 Test MSE 3433041.403045056 Test RE 0.8281830622833278\n",
      "37 Train Loss 1286737300.0 Test MSE 3423112.212390502 Test RE 0.8269845416372394\n",
      "38 Train Loss 1291097100.0 Test MSE 3426890.6569915945 Test RE 0.8274408301387621\n",
      "39 Train Loss 1295113000.0 Test MSE 3415572.3032931755 Test RE 0.8260732618925454\n",
      "40 Train Loss 1299367600.0 Test MSE 3408647.9166434417 Test RE 0.8252354882833344\n",
      "41 Train Loss 1303867900.0 Test MSE 3414896.6261456255 Test RE 0.8259915499007436\n",
      "42 Train Loss 1307658000.0 Test MSE 3399339.804764562 Test RE 0.8241079685795663\n",
      "43 Train Loss 1308178400.0 Test MSE 3406813.5486610117 Test RE 0.8250134076650223\n",
      "44 Train Loss 1310898800.0 Test MSE 3414112.2256189547 Test RE 0.8258966794715553\n",
      "45 Train Loss 1314188700.0 Test MSE 3420032.285942361 Test RE 0.8266124205109473\n",
      "46 Train Loss 1316171900.0 Test MSE 3396359.467654012 Test RE 0.8237466251594276\n",
      "47 Train Loss 1318889900.0 Test MSE 3385763.8904469665 Test RE 0.8224607057949426\n",
      "48 Train Loss 1320996500.0 Test MSE 3366055.193113614 Test RE 0.8200634200104917\n",
      "49 Train Loss 1322801000.0 Test MSE 3343245.7915401254 Test RE 0.817280198918213\n",
      "50 Train Loss 1322999300.0 Test MSE 3338643.731041715 Test RE 0.8167175020088823\n",
      "51 Train Loss 1324782300.0 Test MSE 3328930.0539470227 Test RE 0.8155285298417497\n",
      "52 Train Loss 1326924300.0 Test MSE 3343967.3957384867 Test RE 0.8173683947973087\n",
      "53 Train Loss 1330145700.0 Test MSE 3347280.5197898922 Test RE 0.8177732092187854\n",
      "54 Train Loss 1332921500.0 Test MSE 3342535.3608333464 Test RE 0.8171933593865226\n",
      "55 Train Loss 1335561100.0 Test MSE 3335704.9766384535 Test RE 0.8163579756944987\n",
      "56 Train Loss 1337854800.0 Test MSE 3353122.07277923 Test RE 0.8184864722890294\n",
      "57 Train Loss 1340069500.0 Test MSE 3353429.8760108887 Test RE 0.8185240383236728\n",
      "58 Train Loss 1342686100.0 Test MSE 3350850.5231782575 Test RE 0.818209186290045\n",
      "59 Train Loss 1345646800.0 Test MSE 3357375.108087824 Test RE 0.8190053840174804\n",
      "60 Train Loss 1347004400.0 Test MSE 3344428.2882345524 Test RE 0.8174247210013934\n",
      "61 Train Loss 1348509800.0 Test MSE 3316316.0359458555 Test RE 0.8139819585882833\n",
      "62 Train Loss 1350849200.0 Test MSE 3307116.924964637 Test RE 0.8128522245437204\n",
      "63 Train Loss 1352530600.0 Test MSE 3307562.084697171 Test RE 0.8129069303359676\n",
      "64 Train Loss 1354617300.0 Test MSE 3307384.7416938753 Test RE 0.8128851370505805\n",
      "65 Train Loss 1356865700.0 Test MSE 3306365.0197424996 Test RE 0.8127598143583301\n",
      "66 Train Loss 1358749000.0 Test MSE 3312789.416499634 Test RE 0.8135490432479195\n",
      "67 Train Loss 1360737000.0 Test MSE 3316038.4414514615 Test RE 0.8139478904179916\n",
      "68 Train Loss 1362753900.0 Test MSE 3316605.8313231394 Test RE 0.8140175226076957\n",
      "69 Train Loss 1364866200.0 Test MSE 3319067.119938942 Test RE 0.8143195121401515\n",
      "70 Train Loss 1366984000.0 Test MSE 3313506.5241545564 Test RE 0.8136370915064852\n",
      "71 Train Loss 1368835600.0 Test MSE 3304652.200851841 Test RE 0.8125492673235782\n",
      "72 Train Loss 1370690200.0 Test MSE 3302639.0059221108 Test RE 0.8123017270111481\n",
      "73 Train Loss 1372119800.0 Test MSE 3293115.3692773255 Test RE 0.811129686780291\n",
      "74 Train Loss 1373816800.0 Test MSE 3299981.0592044326 Test RE 0.8119747931138778\n",
      "75 Train Loss 1375572100.0 Test MSE 3305107.7060948773 Test RE 0.8126052653039628\n",
      "76 Train Loss 1377209500.0 Test MSE 3300324.863582603 Test RE 0.8120170892987968\n",
      "77 Train Loss 1378376200.0 Test MSE 3305565.081540236 Test RE 0.8126614893170468\n",
      "78 Train Loss 1379206300.0 Test MSE 3288316.822084202 Test RE 0.81053850448476\n",
      "79 Train Loss 1379491500.0 Test MSE 3265785.589874547 Test RE 0.807756865276513\n",
      "80 Train Loss 1379847200.0 Test MSE 3277707.8827297883 Test RE 0.809229947385012\n",
      "81 Train Loss 1378836100.0 Test MSE 3278491.957941655 Test RE 0.809326731360957\n",
      "82 Train Loss 1379560300.0 Test MSE 3280604.94826522 Test RE 0.8095874951698323\n",
      "83 Train Loss 1380066800.0 Test MSE 3283153.2296454 Test RE 0.8099018664971561\n",
      "84 Train Loss 1380627600.0 Test MSE 3291176.4822796974 Test RE 0.8108908672761418\n",
      "85 Train Loss 1381776100.0 Test MSE 3312111.57334481 Test RE 0.8134658072204103\n",
      "86 Train Loss 1382581500.0 Test MSE 3314126.158653949 Test RE 0.8137131640961587\n",
      "87 Train Loss 1383403400.0 Test MSE 3313605.317148182 Test RE 0.8136492208088224\n",
      "88 Train Loss 1384113000.0 Test MSE 3323570.714110903 Test RE 0.8148717940421606\n",
      "89 Train Loss 1385139300.0 Test MSE 3315946.8488939432 Test RE 0.8139366492811515\n",
      "90 Train Loss 1385880000.0 Test MSE 3314671.4128461806 Test RE 0.8137800991259684\n",
      "91 Train Loss 1386948700.0 Test MSE 3320268.3870627815 Test RE 0.8144668617910851\n",
      "92 Train Loss 1388021800.0 Test MSE 3320705.0851165415 Test RE 0.814520421376883\n",
      "93 Train Loss 1388941700.0 Test MSE 3327291.167604849 Test RE 0.8153277561561469\n",
      "94 Train Loss 1390007700.0 Test MSE 3324262.7694289857 Test RE 0.8149566285550336\n",
      "95 Train Loss 1390784300.0 Test MSE 3320552.671331653 Test RE 0.8145017287255282\n",
      "96 Train Loss 1391440100.0 Test MSE 3307495.818859871 Test RE 0.8128987871436685\n",
      "97 Train Loss 1392102700.0 Test MSE 3302017.297137385 Test RE 0.8122252671123159\n",
      "98 Train Loss 1392464100.0 Test MSE 3301084.6613622284 Test RE 0.8121105548365176\n",
      "99 Train Loss 1392547100.0 Test MSE 3294212.9856785308 Test RE 0.8112648528728517\n",
      "100 Train Loss 1390907000.0 Test MSE 3311668.1755929505 Test RE 0.81341135540403\n",
      "101 Train Loss 1390609000.0 Test MSE 3299559.554556774 Test RE 0.8119229349255243\n",
      "102 Train Loss 1390870100.0 Test MSE 3295352.738492754 Test RE 0.8114051840291342\n",
      "103 Train Loss 1390877800.0 Test MSE 3295209.5039533363 Test RE 0.8113875497241034\n",
      "104 Train Loss 1390668400.0 Test MSE 3290099.8878185386 Test RE 0.810758228989244\n",
      "105 Train Loss 1390427300.0 Test MSE 3284275.5886036833 Test RE 0.8100402887513929\n",
      "106 Train Loss 1390714400.0 Test MSE 3279004.8959967173 Test RE 0.8093900406886254\n",
      "107 Train Loss 1390934900.0 Test MSE 3281495.756625927 Test RE 0.8096974045264952\n",
      "108 Train Loss 1391245400.0 Test MSE 3290000.767201511 Test RE 0.8107460160680654\n",
      "109 Train Loss 1391417300.0 Test MSE 3289465.9751994135 Test RE 0.810680119714699\n",
      "110 Train Loss 1391620400.0 Test MSE 3297121.214502286 Test RE 0.8116228781954626\n",
      "111 Train Loss 1391617800.0 Test MSE 3299885.0387137746 Test RE 0.8119629798968022\n",
      "112 Train Loss 1389348600.0 Test MSE 3298696.6546745645 Test RE 0.8118167610551893\n",
      "113 Train Loss 1385644700.0 Test MSE 3310343.709352083 Test RE 0.8132486815548057\n",
      "114 Train Loss 1384235300.0 Test MSE 3293627.760279557 Test RE 0.8111927880295514\n",
      "115 Train Loss 1384156000.0 Test MSE 3288202.8591588135 Test RE 0.8105244589799546\n",
      "116 Train Loss 1384436100.0 Test MSE 3286873.6474966095 Test RE 0.8103606206298806\n",
      "117 Train Loss 1384596200.0 Test MSE 3281490.3429841874 Test RE 0.8096967366277993\n",
      "118 Train Loss 1384521500.0 Test MSE 3283733.173995454 Test RE 0.8099733948783187\n",
      "119 Train Loss 1384432500.0 Test MSE 3293146.8949862234 Test RE 0.8111335693313582\n",
      "120 Train Loss 1384170400.0 Test MSE 3298193.445197942 Test RE 0.8117548381943007\n",
      "121 Train Loss 1384233500.0 Test MSE 3309326.372140432 Test RE 0.8131237078672076\n",
      "122 Train Loss 1384464900.0 Test MSE 3322115.4304016647 Test RE 0.8146933715575967\n",
      "123 Train Loss 1384740700.0 Test MSE 3323267.026478342 Test RE 0.8148345641829947\n",
      "124 Train Loss 1385123500.0 Test MSE 3318519.1285741804 Test RE 0.8142522856477046\n",
      "125 Train Loss 1385554700.0 Test MSE 3319058.8136489717 Test RE 0.8143184931824168\n",
      "126 Train Loss 1386010800.0 Test MSE 3319086.5540902307 Test RE 0.814321896181338\n",
      "127 Train Loss 1386169700.0 Test MSE 3312565.372247789 Test RE 0.8135215325845974\n",
      "128 Train Loss 1386146400.0 Test MSE 3306975.504598393 Test RE 0.8128348445884818\n",
      "129 Train Loss 1386156300.0 Test MSE 3299991.2846440445 Test RE 0.8119760511200046\n",
      "130 Train Loss 1386265900.0 Test MSE 3292702.728925226 Test RE 0.8110788663127951\n",
      "131 Train Loss 1386410600.0 Test MSE 3293500.2979353545 Test RE 0.8111770914265563\n",
      "132 Train Loss 1386557700.0 Test MSE 3297418.1310624937 Test RE 0.811659422021484\n",
      "133 Train Loss 1386187500.0 Test MSE 3306868.508532072 Test RE 0.8128216949848178\n",
      "134 Train Loss 1385964900.0 Test MSE 3313113.632418722 Test RE 0.813588852463717\n",
      "135 Train Loss 1385974500.0 Test MSE 3305748.7123245164 Test RE 0.8126840614931368\n",
      "136 Train Loss 1385874000.0 Test MSE 3298583.384508793 Test RE 0.8118028229126256\n",
      "137 Train Loss 1385288400.0 Test MSE 3305891.2040989646 Test RE 0.8127015763674083\n",
      "138 Train Loss 1384879700.0 Test MSE 3315159.722258016 Test RE 0.813840038980937\n",
      "139 Train Loss 1384619500.0 Test MSE 3325746.3943342254 Test RE 0.8151384666286108\n",
      "140 Train Loss 1384688500.0 Test MSE 3340565.601585212 Test RE 0.8169525374925255\n",
      "141 Train Loss 1384553500.0 Test MSE 3349955.2495191866 Test RE 0.8180998752267857\n",
      "142 Train Loss 1384754400.0 Test MSE 3343073.2478274386 Test RE 0.8172591088775581\n",
      "143 Train Loss 1384940900.0 Test MSE 3340612.517425147 Test RE 0.8169582742276302\n",
      "144 Train Loss 1384713200.0 Test MSE 3332324.3315620697 Test RE 0.815944192671944\n",
      "145 Train Loss 1384230800.0 Test MSE 3326509.844708446 Test RE 0.8152320218765551\n",
      "146 Train Loss 1383839700.0 Test MSE 3339431.179315962 Test RE 0.8168138113072455\n",
      "147 Train Loss 1383100900.0 Test MSE 3337994.3241321333 Test RE 0.8166380673902678\n",
      "148 Train Loss 1381500200.0 Test MSE 3300078.5712584783 Test RE 0.8119867896592502\n",
      "149 Train Loss 1378942200.0 Test MSE 3284367.781666629 Test RE 0.810051658012168\n",
      "150 Train Loss 1377960200.0 Test MSE 3286011.741376582 Test RE 0.8102543645568393\n",
      "151 Train Loss 1376568300.0 Test MSE 3286600.33531089 Test RE 0.8103269281213479\n",
      "152 Train Loss 1376009900.0 Test MSE 3290473.63276346 Test RE 0.8108042774672569\n",
      "153 Train Loss 1375981600.0 Test MSE 3290280.549679447 Test RE 0.8107804883559362\n",
      "154 Train Loss 1376145300.0 Test MSE 3293057.4422174813 Test RE 0.8111225527204011\n",
      "155 Train Loss 1376073500.0 Test MSE 3306927.389848457 Test RE 0.812828931407769\n",
      "156 Train Loss 1375823900.0 Test MSE 3320479.190354776 Test RE 0.8144927165640401\n",
      "157 Train Loss 1375514500.0 Test MSE 3325566.269657516 Test RE 0.8151163921040566\n",
      "158 Train Loss 1374183400.0 Test MSE 3328185.0127420067 Test RE 0.8154372638269756\n",
      "159 Train Loss 1373464000.0 Test MSE 3345333.0291249324 Test RE 0.8175352791441174\n",
      "160 Train Loss 1372529900.0 Test MSE 3341943.814255925 Test RE 0.8171210446205782\n",
      "161 Train Loss 1372080100.0 Test MSE 3343555.4287517797 Test RE 0.8173180445506673\n",
      "162 Train Loss 1371559700.0 Test MSE 3353515.4294682792 Test RE 0.8185344794417805\n",
      "163 Train Loss 1369086200.0 Test MSE 3379739.375630907 Test RE 0.8217286504908944\n",
      "164 Train Loss 1368539900.0 Test MSE 3385606.57539022 Test RE 0.8224415982966413\n",
      "165 Train Loss 1368104400.0 Test MSE 3390472.795577341 Test RE 0.8230324443890448\n",
      "166 Train Loss 1367327700.0 Test MSE 3391105.2976233377 Test RE 0.8231092102946013\n",
      "167 Train Loss 1366927200.0 Test MSE 3398872.348928363 Test RE 0.8240513035583636\n",
      "168 Train Loss 1366088700.0 Test MSE 3416745.718622606 Test RE 0.8262151478935161\n",
      "169 Train Loss 1365778300.0 Test MSE 3425176.6421678504 Test RE 0.827233875296221\n",
      "170 Train Loss 1363729300.0 Test MSE 3501461.166466469 Test RE 0.8363951016432186\n",
      "171 Train Loss 1353939200.0 Test MSE 3538175.8049463616 Test RE 0.8407686851880467\n",
      "172 Train Loss 1344327700.0 Test MSE 3565395.7296790895 Test RE 0.8439965933037247\n",
      "173 Train Loss 1341661800.0 Test MSE 3574251.8782219663 Test RE 0.8450441521127701\n",
      "174 Train Loss 1336565000.0 Test MSE 3536237.1838878486 Test RE 0.840538318567548\n",
      "175 Train Loss 1331723600.0 Test MSE 3508244.069515326 Test RE 0.8372048267551904\n",
      "176 Train Loss 1327882600.0 Test MSE 3518323.001587697 Test RE 0.8384065787666684\n",
      "177 Train Loss 1324065400.0 Test MSE 3502163.6571735293 Test RE 0.8364789995205817\n",
      "178 Train Loss 1320714100.0 Test MSE 3470132.5921483925 Test RE 0.8326449613279757\n",
      "179 Train Loss 1319578400.0 Test MSE 3458702.3805427947 Test RE 0.8312725125804299\n",
      "180 Train Loss 1317788900.0 Test MSE 3434851.733935184 Test RE 0.8284013946020379\n",
      "181 Train Loss 1316677500.0 Test MSE 3415817.5685234712 Test RE 0.8261029206720647\n",
      "182 Train Loss 1315241300.0 Test MSE 3384524.0973870168 Test RE 0.8223101084007544\n",
      "183 Train Loss 1314764200.0 Test MSE 3386515.299415532 Test RE 0.8225519658599838\n",
      "184 Train Loss 1314479500.0 Test MSE 3384221.8230346395 Test RE 0.8222733870186034\n",
      "185 Train Loss 1313960700.0 Test MSE 3385389.328598544 Test RE 0.8224152107555992\n",
      "186 Train Loss 1312926200.0 Test MSE 3373158.1830633073 Test RE 0.8209282056769508\n",
      "187 Train Loss 1311565300.0 Test MSE 3403473.4999986803 Test RE 0.8246088858712394\n",
      "188 Train Loss 1310261000.0 Test MSE 3426622.448765444 Test RE 0.8274084493595091\n",
      "189 Train Loss 1308988700.0 Test MSE 3425758.4026896316 Test RE 0.8273041244582315\n",
      "190 Train Loss 1308298400.0 Test MSE 3417714.8857368026 Test RE 0.8263323184179925\n",
      "191 Train Loss 1307934800.0 Test MSE 3412784.173733705 Test RE 0.8257360315117794\n",
      "192 Train Loss 1307715100.0 Test MSE 3410099.2290634047 Test RE 0.8254111513446711\n",
      "193 Train Loss 1307157400.0 Test MSE 3408136.795981891 Test RE 0.8251736146706798\n",
      "194 Train Loss 1306648600.0 Test MSE 3401566.8969077514 Test RE 0.8243778833239088\n",
      "195 Train Loss 1306542100.0 Test MSE 3402992.6116840662 Test RE 0.8245506279201166\n",
      "196 Train Loss 1306527000.0 Test MSE 3405542.443758081 Test RE 0.8248594842982184\n",
      "197 Train Loss 1306384400.0 Test MSE 3406865.4545134706 Test RE 0.8250196925497825\n",
      "198 Train Loss 1306308700.0 Test MSE 3411466.0825464274 Test RE 0.8255765575395753\n",
      "199 Train Loss 1306064800.0 Test MSE 3417621.8194115553 Test RE 0.8263210675912821\n",
      "Training time: 47.93\n",
      "Training time: 47.93\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "3\n",
      "0 Train Loss 1222095700.0 Test MSE 5307468.79775687 Test RE 1.0297470310607142\n",
      "1 Train Loss 1220932000.0 Test MSE 5438004.659732582 Test RE 1.042333296917484\n",
      "2 Train Loss 1195740200.0 Test MSE 5579813.640799953 Test RE 1.0558364985613586\n",
      "3 Train Loss 1162075500.0 Test MSE 5683770.482701832 Test RE 1.0656266909081311\n",
      "4 Train Loss 1164441600.0 Test MSE 5754796.92433311 Test RE 1.072264246301132\n",
      "5 Train Loss 1165888500.0 Test MSE 5912427.184143605 Test RE 1.0868502915684923\n",
      "6 Train Loss 1168210300.0 Test MSE 5962077.256077478 Test RE 1.0914042064605605\n",
      "7 Train Loss 1170145500.0 Test MSE 6109163.267377767 Test RE 1.1047847977501086\n",
      "8 Train Loss 1177658800.0 Test MSE 6178713.064719831 Test RE 1.1110557142487363\n",
      "9 Train Loss 1186825600.0 Test MSE 6202113.768844532 Test RE 1.1131576823477887\n",
      "10 Train Loss 1191807500.0 Test MSE 6239439.193004753 Test RE 1.1165022483421432\n",
      "11 Train Loss 1194188500.0 Test MSE 6293771.50398708 Test RE 1.121352897385723\n",
      "12 Train Loss 1198643500.0 Test MSE 6317032.867534245 Test RE 1.1234232093173446\n",
      "13 Train Loss 1205988000.0 Test MSE 6320010.222924958 Test RE 1.1236879250619392\n",
      "14 Train Loss 1214886700.0 Test MSE 6367034.282773688 Test RE 1.1278605799003247\n",
      "15 Train Loss 1225759700.0 Test MSE 6382219.832118939 Test RE 1.1292047679234987\n",
      "16 Train Loss 1234525400.0 Test MSE 6390275.243224706 Test RE 1.1299171642722226\n",
      "17 Train Loss 1242606200.0 Test MSE 6393715.492111439 Test RE 1.130221272709229\n",
      "18 Train Loss 1251501300.0 Test MSE 6412544.670575734 Test RE 1.1318842723473632\n",
      "19 Train Loss 1260381400.0 Test MSE 6426880.43076721 Test RE 1.133148775253841\n",
      "20 Train Loss 1269205600.0 Test MSE 6439942.361977678 Test RE 1.1342996912180996\n",
      "21 Train Loss 1276804000.0 Test MSE 6469637.107233296 Test RE 1.1369118265247458\n",
      "22 Train Loss 1285401100.0 Test MSE 6480104.606033141 Test RE 1.1378311836109773\n",
      "23 Train Loss 1294109200.0 Test MSE 6502528.383485294 Test RE 1.139798161021297\n",
      "24 Train Loss 1301064000.0 Test MSE 6558885.997116323 Test RE 1.1447268376836608\n",
      "25 Train Loss 1308599000.0 Test MSE 6579003.764612458 Test RE 1.1464810773666212\n",
      "26 Train Loss 1315684400.0 Test MSE 6585128.451321568 Test RE 1.1470146082926673\n",
      "27 Train Loss 1321111600.0 Test MSE 6659334.669481282 Test RE 1.1534592184224195\n",
      "28 Train Loss 1327789400.0 Test MSE 6649364.111673066 Test RE 1.1525953979067798\n",
      "29 Train Loss 1334050400.0 Test MSE 6649661.224273564 Test RE 1.1526211482480841\n",
      "30 Train Loss 1341222100.0 Test MSE 6683497.473064859 Test RE 1.1555499357382906\n",
      "31 Train Loss 1348775700.0 Test MSE 6700764.235600012 Test RE 1.1570416499334442\n",
      "32 Train Loss 1355958400.0 Test MSE 6703569.405633899 Test RE 1.1572838132771397\n",
      "33 Train Loss 1363031900.0 Test MSE 6707075.8602713635 Test RE 1.1575864455342726\n",
      "34 Train Loss 1369967900.0 Test MSE 6704232.862525675 Test RE 1.157341080449188\n",
      "35 Train Loss 1377150600.0 Test MSE 6708456.342165625 Test RE 1.1577055693478757\n",
      "36 Train Loss 1383834100.0 Test MSE 6704821.812040145 Test RE 1.1573919140428666\n",
      "37 Train Loss 1390492900.0 Test MSE 6697403.162453991 Test RE 1.1567514300967292\n",
      "38 Train Loss 1397148300.0 Test MSE 6698652.895029895 Test RE 1.1568593497244684\n",
      "39 Train Loss 1403357800.0 Test MSE 6693830.251967677 Test RE 1.1564428387985441\n",
      "40 Train Loss 1409323000.0 Test MSE 6695234.803207836 Test RE 1.1565641593255287\n",
      "41 Train Loss 1414690300.0 Test MSE 6693237.57140451 Test RE 1.1563916411777935\n",
      "42 Train Loss 1419031700.0 Test MSE 6676559.6028080685 Test RE 1.1549500150240157\n",
      "43 Train Loss 1423625900.0 Test MSE 6692146.561255727 Test RE 1.1562973903448122\n",
      "44 Train Loss 1428147500.0 Test MSE 6712927.638244797 Test RE 1.1580913199475786\n",
      "45 Train Loss 1432495900.0 Test MSE 6741209.472853804 Test RE 1.1605282985687682\n",
      "46 Train Loss 1436805100.0 Test MSE 6744190.887017578 Test RE 1.1607849018565524\n",
      "47 Train Loss 1440516100.0 Test MSE 6732411.784621287 Test RE 1.159770771338005\n",
      "48 Train Loss 1443443600.0 Test MSE 6753375.953577719 Test RE 1.161575082551888\n",
      "49 Train Loss 1446646900.0 Test MSE 6784514.744879876 Test RE 1.1642499259580277\n",
      "50 Train Loss 1449648600.0 Test MSE 6823096.350494321 Test RE 1.1675556120851929\n",
      "51 Train Loss 1452059900.0 Test MSE 6861292.107898629 Test RE 1.1708190449141822\n",
      "52 Train Loss 1454829000.0 Test MSE 6890912.695850774 Test RE 1.173343569396386\n",
      "53 Train Loss 1456787800.0 Test MSE 6945971.008344232 Test RE 1.1780217441010155\n",
      "54 Train Loss 1459442400.0 Test MSE 6967037.72813269 Test RE 1.1798068267967878\n",
      "55 Train Loss 1462246100.0 Test MSE 6949133.621354338 Test RE 1.1782898997628781\n",
      "56 Train Loss 1460601900.0 Test MSE 7067413.820716571 Test RE 1.1882753399341388\n",
      "57 Train Loss 1458401500.0 Test MSE 7101159.665516246 Test RE 1.1911088801122611\n",
      "58 Train Loss 1459182100.0 Test MSE 7128399.209372982 Test RE 1.1933911980158174\n",
      "59 Train Loss 1461312000.0 Test MSE 7137291.918753141 Test RE 1.1941353463914097\n",
      "60 Train Loss 1463581800.0 Test MSE 7154492.230483677 Test RE 1.19557336662961\n",
      "61 Train Loss 1466071800.0 Test MSE 7151326.421789214 Test RE 1.1953088212759135\n",
      "62 Train Loss 1468987500.0 Test MSE 7154519.380221155 Test RE 1.195575635097532\n",
      "63 Train Loss 1471415600.0 Test MSE 7170448.366008878 Test RE 1.196905823605065\n",
      "64 Train Loss 1473753100.0 Test MSE 7178355.152367587 Test RE 1.1975655502159912\n",
      "65 Train Loss 1476528600.0 Test MSE 7185145.933170932 Test RE 1.1981318695576695\n",
      "66 Train Loss 1479243600.0 Test MSE 7187255.056151433 Test RE 1.1983077060727834\n",
      "67 Train Loss 1481747600.0 Test MSE 7187885.767459267 Test RE 1.198360283143895\n",
      "68 Train Loss 1484217700.0 Test MSE 7206539.296539732 Test RE 1.1999142285752002\n",
      "69 Train Loss 1486581900.0 Test MSE 7205549.013906637 Test RE 1.1998317829659768\n",
      "70 Train Loss 1489084200.0 Test MSE 7209712.9692428615 Test RE 1.2001784133457807\n",
      "71 Train Loss 1491531300.0 Test MSE 7214496.374218631 Test RE 1.2005764865772552\n",
      "72 Train Loss 1493701600.0 Test MSE 7225309.114735733 Test RE 1.2014758329050093\n",
      "73 Train Loss 1495743700.0 Test MSE 7232432.05447893 Test RE 1.2020679135805057\n",
      "74 Train Loss 1497880800.0 Test MSE 7241694.582862113 Test RE 1.2028374075415043\n",
      "75 Train Loss 1499880800.0 Test MSE 7267691.168411957 Test RE 1.2049944753472164\n",
      "76 Train Loss 1502064800.0 Test MSE 7285095.002577304 Test RE 1.2064364039799074\n",
      "77 Train Loss 1504075800.0 Test MSE 7286061.204493207 Test RE 1.2065164044821308\n",
      "78 Train Loss 1505974700.0 Test MSE 7298165.312063793 Test RE 1.207518162754312\n",
      "79 Train Loss 1507729700.0 Test MSE 7338746.447867107 Test RE 1.210870685351968\n",
      "80 Train Loss 1509412500.0 Test MSE 7358606.071988796 Test RE 1.212507966999922\n",
      "81 Train Loss 1510922500.0 Test MSE 7374255.546867251 Test RE 1.2137965965957298\n",
      "82 Train Loss 1511814700.0 Test MSE 7414874.46569148 Test RE 1.2171349267187226\n",
      "83 Train Loss 1512923000.0 Test MSE 7417768.283564359 Test RE 1.2173724103900385\n",
      "84 Train Loss 1514532400.0 Test MSE 7438058.391448014 Test RE 1.219036236255295\n",
      "85 Train Loss 1515966500.0 Test MSE 7447912.6433160445 Test RE 1.2198434841539236\n",
      "86 Train Loss 1517141100.0 Test MSE 7497865.403737329 Test RE 1.2239273612225143\n",
      "87 Train Loss 1518494700.0 Test MSE 7503491.186379401 Test RE 1.224386442429619\n",
      "88 Train Loss 1519782500.0 Test MSE 7512359.817569464 Test RE 1.2251098007218235\n",
      "89 Train Loss 1520832500.0 Test MSE 7536641.037525512 Test RE 1.2270880847141357\n",
      "90 Train Loss 1521727500.0 Test MSE 7517141.056685974 Test RE 1.225499599089585\n",
      "91 Train Loss 1522208100.0 Test MSE 7536016.160750559 Test RE 1.2270372135942589\n",
      "92 Train Loss 1523350800.0 Test MSE 7582928.277944153 Test RE 1.230850475602261\n",
      "93 Train Loss 1524603800.0 Test MSE 7562170.85123286 Test RE 1.2291646626707602\n",
      "94 Train Loss 1525837000.0 Test MSE 7549461.5512068905 Test RE 1.228131335602396\n",
      "95 Train Loss 1527079800.0 Test MSE 7547860.8095865175 Test RE 1.228001125974043\n",
      "96 Train Loss 1528298100.0 Test MSE 7546216.3140934175 Test RE 1.2278673428812585\n",
      "97 Train Loss 1529481100.0 Test MSE 7548981.679720822 Test RE 1.2280923027143786\n",
      "98 Train Loss 1530619900.0 Test MSE 7559270.405046208 Test RE 1.2289289189972528\n",
      "99 Train Loss 1531673100.0 Test MSE 7559138.838490955 Test RE 1.2289182244037675\n",
      "100 Train Loss 1532739500.0 Test MSE 7542089.668828799 Test RE 1.2275315675964908\n",
      "101 Train Loss 1533847400.0 Test MSE 7537410.8662646115 Test RE 1.2271507534512325\n",
      "102 Train Loss 1534921500.0 Test MSE 7535875.678840181 Test RE 1.2270257766936783\n",
      "103 Train Loss 1536007000.0 Test MSE 7534910.3649881985 Test RE 1.2269471857665495\n",
      "104 Train Loss 1536975400.0 Test MSE 7536095.162295181 Test RE 1.227043645214034\n",
      "105 Train Loss 1538038800.0 Test MSE 7536857.876687014 Test RE 1.227105737063253\n",
      "106 Train Loss 1539090700.0 Test MSE 7539491.8264875505 Test RE 1.2273201402419596\n",
      "107 Train Loss 1540103200.0 Test MSE 7540064.0056327665 Test RE 1.2273667105998745\n",
      "108 Train Loss 1541105000.0 Test MSE 7526879.961515936 Test RE 1.226293196066337\n",
      "109 Train Loss 1542047000.0 Test MSE 7527167.074309628 Test RE 1.2263165843168276\n",
      "110 Train Loss 1543087700.0 Test MSE 7531198.456628502 Test RE 1.2266449342247774\n",
      "111 Train Loss 1544112500.0 Test MSE 7532826.305912541 Test RE 1.226777495144575\n",
      "112 Train Loss 1545071100.0 Test MSE 7546215.2720708065 Test RE 1.227867258105954\n",
      "113 Train Loss 1546007300.0 Test MSE 7550551.017177701 Test RE 1.2282199484802903\n",
      "114 Train Loss 1546954900.0 Test MSE 7550599.598883017 Test RE 1.2282238997762607\n",
      "115 Train Loss 1547959600.0 Test MSE 7550567.900836777 Test RE 1.2282213216804212\n",
      "116 Train Loss 1548865300.0 Test MSE 7548476.101393884 Test RE 1.2280511774822442\n",
      "117 Train Loss 1549712500.0 Test MSE 7538895.105204295 Test RE 1.227271570487028\n",
      "118 Train Loss 1550507400.0 Test MSE 7543482.054510327 Test RE 1.2276448729650724\n",
      "119 Train Loss 1551304600.0 Test MSE 7546790.164577167 Test RE 1.2279140284548193\n",
      "120 Train Loss 1552118100.0 Test MSE 7542404.060976752 Test RE 1.2275571521679698\n",
      "121 Train Loss 1552851000.0 Test MSE 7541247.868326584 Test RE 1.2274630610173658\n",
      "122 Train Loss 1553501400.0 Test MSE 7545637.390916184 Test RE 1.227820242820268\n",
      "123 Train Loss 1554193800.0 Test MSE 7550481.577450012 Test RE 1.2282143007166595\n",
      "124 Train Loss 1554990200.0 Test MSE 7550460.326059622 Test RE 1.2282125722653225\n",
      "125 Train Loss 1555665900.0 Test MSE 7541273.933798204 Test RE 1.2274651823092593\n",
      "126 Train Loss 1556208600.0 Test MSE 7534681.936277701 Test RE 1.2269285875301992\n",
      "127 Train Loss 1556858200.0 Test MSE 7528546.949753766 Test RE 1.2264289829510167\n",
      "128 Train Loss 1557583600.0 Test MSE 7526800.365397561 Test RE 1.2262867120758287\n",
      "129 Train Loss 1558355500.0 Test MSE 7526523.655506314 Test RE 1.2262641707059903\n",
      "130 Train Loss 1559129200.0 Test MSE 7526523.655506314 Test RE 1.2262641707059903\n",
      "131 Train Loss 1559830100.0 Test MSE 7526458.687992575 Test RE 1.2262588782555894\n",
      "132 Train Loss 1560520300.0 Test MSE 7526534.515344173 Test RE 1.2262650553790393\n",
      "133 Train Loss 1561177700.0 Test MSE 7526936.945092318 Test RE 1.2262978379923475\n",
      "134 Train Loss 1561715600.0 Test MSE 7527226.954274598 Test RE 1.2263214620913834\n",
      "135 Train Loss 1562283000.0 Test MSE 7529424.381925238 Test RE 1.2265004493907086\n",
      "136 Train Loss 1562817800.0 Test MSE 7534587.654493208 Test RE 1.2269209112022847\n",
      "137 Train Loss 1563417500.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "138 Train Loss 1564078600.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "139 Train Loss 1564725100.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "140 Train Loss 1565316600.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "141 Train Loss 1565872600.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "142 Train Loss 1566425300.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "143 Train Loss 1567028900.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "144 Train Loss 1567617000.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "145 Train Loss 1568134000.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "146 Train Loss 1568639200.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "147 Train Loss 1569191700.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "148 Train Loss 1569712800.0 Test MSE 7535215.867359549 Test RE 1.226972058754898\n",
      "149 Train Loss 1570187400.0 Test MSE 7535268.652170984 Test RE 1.2269763562678344\n",
      "150 Train Loss 1570667500.0 Test MSE 7535193.319591121 Test RE 1.2269702230077189\n",
      "151 Train Loss 1571150000.0 Test MSE 7536059.677016184 Test RE 1.227040756314915\n",
      "152 Train Loss 1571623400.0 Test MSE 7536238.33221514 Test RE 1.2270553007798364\n",
      "153 Train Loss 1572074600.0 Test MSE 7532138.310570425 Test RE 1.2267214712538914\n",
      "154 Train Loss 1572519700.0 Test MSE 7527353.313414753 Test RE 1.2263317551432698\n",
      "155 Train Loss 1572894600.0 Test MSE 7528136.33558798 Test RE 1.2263955371889168\n",
      "156 Train Loss 1573209600.0 Test MSE 7532873.307233786 Test RE 1.2267813223981754\n",
      "157 Train Loss 1573501200.0 Test MSE 7540392.737433389 Test RE 1.2273934656825178\n",
      "158 Train Loss 1573898800.0 Test MSE 7543316.141211368 Test RE 1.2276313723211172\n",
      "159 Train Loss 1574297100.0 Test MSE 7537267.307467181 Test RE 1.227139067135573\n",
      "160 Train Loss 1574591400.0 Test MSE 7534380.960968885 Test RE 1.2269040822556945\n",
      "161 Train Loss 1574650600.0 Test MSE 7520969.989182807 Test RE 1.22581166971802\n",
      "162 Train Loss 1574916500.0 Test MSE 7524139.750835368 Test RE 1.2260699556518968\n",
      "163 Train Loss 1575239300.0 Test MSE 7536142.442799602 Test RE 1.2270474943660319\n",
      "164 Train Loss 1575388700.0 Test MSE 7545863.758201965 Test RE 1.2278386598364133\n",
      "165 Train Loss 1575566600.0 Test MSE 7543187.54973724 Test RE 1.227620908514638\n",
      "166 Train Loss 1575886300.0 Test MSE 7542157.266383609 Test RE 1.2275370685882678\n",
      "167 Train Loss 1576188400.0 Test MSE 7543072.375123021 Test RE 1.2276115363955347\n",
      "168 Train Loss 1576532400.0 Test MSE 7544651.549751676 Test RE 1.2277400325468437\n",
      "169 Train Loss 1576887800.0 Test MSE 7547515.790988382 Test RE 1.2279730592091997\n",
      "170 Train Loss 1577223000.0 Test MSE 7550361.417546354 Test RE 1.2282045276513458\n",
      "171 Train Loss 1577600400.0 Test MSE 7550361.417546354 Test RE 1.2282045276513458\n",
      "172 Train Loss 1577943700.0 Test MSE 7550680.262582489 Test RE 1.2282304603690746\n",
      "173 Train Loss 1578260600.0 Test MSE 7552545.279056871 Test RE 1.2283821373393593\n",
      "174 Train Loss 1578605800.0 Test MSE 7552545.279056871 Test RE 1.2283821373393593\n",
      "175 Train Loss 1578952000.0 Test MSE 7552545.279056871 Test RE 1.2283821373393593\n",
      "176 Train Loss 1579286000.0 Test MSE 7552545.279056871 Test RE 1.2283821373393593\n",
      "177 Train Loss 1579612700.0 Test MSE 7552545.279056871 Test RE 1.2283821373393593\n",
      "178 Train Loss 1579938000.0 Test MSE 7552545.279056871 Test RE 1.2283821373393593\n",
      "179 Train Loss 1580278700.0 Test MSE 7552861.166517779 Test RE 1.2284078257955526\n",
      "180 Train Loss 1580563700.0 Test MSE 7550728.567925231 Test RE 1.228234389154058\n",
      "181 Train Loss 1580840700.0 Test MSE 7547318.6287140455 Test RE 1.227957020054791\n",
      "182 Train Loss 1581079000.0 Test MSE 7547700.673514795 Test RE 1.227988099215576\n",
      "183 Train Loss 1581315300.0 Test MSE 7546200.423733042 Test RE 1.2278660500966343\n",
      "184 Train Loss 1581580200.0 Test MSE 7541795.098515039 Test RE 1.2275075956002905\n",
      "185 Train Loss 1581845500.0 Test MSE 7541156.90663419 Test RE 1.227455658233635\n",
      "186 Train Loss 1582136300.0 Test MSE 7540761.035879783 Test RE 1.227423440353767\n",
      "187 Train Loss 1582432400.0 Test MSE 7539664.41657042 Test RE 1.2273341877452504\n",
      "188 Train Loss 1582697200.0 Test MSE 7538374.001290756 Test RE 1.227229153988236\n",
      "189 Train Loss 1582971600.0 Test MSE 7538439.969233804 Test RE 1.22723452368771\n",
      "190 Train Loss 1583240600.0 Test MSE 7541783.99881528 Test RE 1.2275066923026936\n",
      "191 Train Loss 1583484500.0 Test MSE 7542810.409343961 Test RE 1.227590219153121\n",
      "192 Train Loss 1583733400.0 Test MSE 7544542.98937307 Test RE 1.2277311995078795\n",
      "193 Train Loss 1583996300.0 Test MSE 7544526.084204788 Test RE 1.2277298240094439\n",
      "194 Train Loss 1584259800.0 Test MSE 7544526.084204788 Test RE 1.2277298240094439\n",
      "195 Train Loss 1584511000.0 Test MSE 7544526.084204788 Test RE 1.2277298240094439\n",
      "196 Train Loss 1584761700.0 Test MSE 7545337.220212222 Test RE 1.2277958208057347\n",
      "197 Train Loss 1585006300.0 Test MSE 7545337.220212222 Test RE 1.2277958208057347\n",
      "198 Train Loss 1585255400.0 Test MSE 7545337.220212222 Test RE 1.2277958208057347\n",
      "199 Train Loss 1585502300.0 Test MSE 7545337.220212222 Test RE 1.2277958208057347\n",
      "Training time: 45.13\n",
      "Training time: 45.13\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "4\n",
      "0 Train Loss 1248500600.0 Test MSE 5156628.325896275 Test RE 1.0150086388869082\n",
      "1 Train Loss 1249866800.0 Test MSE 5271443.081667374 Test RE 1.0262462530070973\n",
      "2 Train Loss 1208838700.0 Test MSE 5537808.272451006 Test RE 1.0518547718559172\n",
      "3 Train Loss 1174059600.0 Test MSE 5590961.67223671 Test RE 1.0568907116558404\n",
      "4 Train Loss 1158782200.0 Test MSE 5722549.966752212 Test RE 1.0692558139742898\n",
      "5 Train Loss 1164605600.0 Test MSE 5796341.279740912 Test RE 1.0761276684295351\n",
      "6 Train Loss 1165655600.0 Test MSE 5987338.26567047 Test RE 1.0937138738396024\n",
      "7 Train Loss 1164639000.0 Test MSE 6068815.2691806415 Test RE 1.1011304757512677\n",
      "8 Train Loss 1172907900.0 Test MSE 6068898.486913749 Test RE 1.1011380252699017\n",
      "9 Train Loss 1180569700.0 Test MSE 6149409.4680141695 Test RE 1.1084178976907988\n",
      "10 Train Loss 1184436900.0 Test MSE 6152292.238421248 Test RE 1.108677673847934\n",
      "11 Train Loss 1195155700.0 Test MSE 6177587.999659701 Test RE 1.1109545550867255\n",
      "12 Train Loss 1206804400.0 Test MSE 6170371.113508674 Test RE 1.1103054364067675\n",
      "13 Train Loss 1217325800.0 Test MSE 6167651.641196882 Test RE 1.1100607365661679\n",
      "14 Train Loss 1229496700.0 Test MSE 6180813.417727518 Test RE 1.1112445408621645\n",
      "15 Train Loss 1240043500.0 Test MSE 6203806.104877321 Test RE 1.113309542538987\n",
      "16 Train Loss 1249654000.0 Test MSE 6203335.531780448 Test RE 1.1132673181814419\n",
      "17 Train Loss 1257601800.0 Test MSE 6244378.475739746 Test RE 1.1169440852721435\n",
      "18 Train Loss 1263641100.0 Test MSE 6303896.869904516 Test RE 1.1222545463789289\n",
      "19 Train Loss 1271840900.0 Test MSE 6319607.635905174 Test RE 1.1236521348209885\n",
      "20 Train Loss 1281508200.0 Test MSE 6364317.487505202 Test RE 1.127619926788658\n",
      "21 Train Loss 1290526000.0 Test MSE 6368685.715581268 Test RE 1.128006838356078\n",
      "22 Train Loss 1298891100.0 Test MSE 6373080.794932912 Test RE 1.1283959943567725\n",
      "23 Train Loss 1308206700.0 Test MSE 6367869.503601867 Test RE 1.1279345532539111\n",
      "24 Train Loss 1317579900.0 Test MSE 6366731.758175176 Test RE 1.1278337848802984\n",
      "25 Train Loss 1326577900.0 Test MSE 6357084.898242123 Test RE 1.1269790151610184\n",
      "26 Train Loss 1335400700.0 Test MSE 6353331.116717661 Test RE 1.1266462323082969\n",
      "27 Train Loss 1343744000.0 Test MSE 6365062.833606352 Test RE 1.127685954490107\n",
      "28 Train Loss 1351756700.0 Test MSE 6374929.556454142 Test RE 1.128559650200222\n",
      "29 Train Loss 1359506800.0 Test MSE 6365239.645004039 Test RE 1.127701617049168\n",
      "30 Train Loss 1367013000.0 Test MSE 6370676.085818576 Test RE 1.1281830894658063\n",
      "31 Train Loss 1374017200.0 Test MSE 6383694.879534348 Test RE 1.1293352502940472\n",
      "32 Train Loss 1380470400.0 Test MSE 6374021.216147215 Test RE 1.1284792451754424\n",
      "33 Train Loss 1386867300.0 Test MSE 6391728.629656364 Test RE 1.1300456495759736\n",
      "34 Train Loss 1393606100.0 Test MSE 6410142.481273211 Test RE 1.1316722461457684\n",
      "35 Train Loss 1400541300.0 Test MSE 6412360.700807088 Test RE 1.1318680358927318\n",
      "36 Train Loss 1407280300.0 Test MSE 6423386.631902275 Test RE 1.132840730616665\n",
      "37 Train Loss 1413762800.0 Test MSE 6434557.500498588 Test RE 1.1338253605689192\n",
      "38 Train Loss 1420119600.0 Test MSE 6442487.943232053 Test RE 1.1345238521334309\n",
      "39 Train Loss 1426266100.0 Test MSE 6457824.742201265 Test RE 1.135873456606495\n",
      "40 Train Loss 1431866100.0 Test MSE 6469556.261264294 Test RE 1.1369047229558817\n",
      "41 Train Loss 1437215600.0 Test MSE 6480269.063295984 Test RE 1.137845621912994\n",
      "42 Train Loss 1441165800.0 Test MSE 6508824.21301154 Test RE 1.14034981096161\n",
      "43 Train Loss 1445601500.0 Test MSE 6505443.436025576 Test RE 1.1400536154414058\n",
      "44 Train Loss 1450012300.0 Test MSE 6520037.199463037 Test RE 1.1413316491755046\n",
      "45 Train Loss 1454452500.0 Test MSE 6542562.09701448 Test RE 1.14330143954237\n",
      "46 Train Loss 1458713200.0 Test MSE 6548247.295589023 Test RE 1.1437980709996127\n",
      "47 Train Loss 1463020800.0 Test MSE 6566019.78161862 Test RE 1.1453492006336596\n",
      "48 Train Loss 1467572000.0 Test MSE 6558538.461885644 Test RE 1.1446965095017185\n",
      "49 Train Loss 1472053200.0 Test MSE 6549220.446723553 Test RE 1.1438830591642768\n",
      "50 Train Loss 1476323100.0 Test MSE 6551450.580867415 Test RE 1.144077799557997\n",
      "51 Train Loss 1480435800.0 Test MSE 6552897.449898159 Test RE 1.144204125730563\n",
      "52 Train Loss 1484433300.0 Test MSE 6550753.33962632 Test RE 1.1440169184264055\n",
      "53 Train Loss 1488246300.0 Test MSE 6559456.140898306 Test RE 1.144776590393654\n",
      "54 Train Loss 1491939600.0 Test MSE 6556696.792717659 Test RE 1.1445357800727372\n",
      "55 Train Loss 1495951200.0 Test MSE 6561258.559986028 Test RE 1.1449338614698625\n",
      "56 Train Loss 1499734500.0 Test MSE 6565220.888219693 Test RE 1.145279520692039\n",
      "57 Train Loss 1503462700.0 Test MSE 6565233.783790457 Test RE 1.1452806454847997\n",
      "58 Train Loss 1506896900.0 Test MSE 6571619.987070018 Test RE 1.1458375348114418\n",
      "59 Train Loss 1510526200.0 Test MSE 6580999.231261055 Test RE 1.1466549328154672\n",
      "60 Train Loss 1513964300.0 Test MSE 6581267.782528757 Test RE 1.1466783283883566\n",
      "61 Train Loss 1514898400.0 Test MSE 6632039.89924338 Test RE 1.1510929361559614\n",
      "62 Train Loss 1478385800.0 Test MSE 6603381.601192584 Test RE 1.1486031985038905\n",
      "63 Train Loss 1417361000.0 Test MSE 6657214.755874541 Test RE 1.1532756093498542\n",
      "64 Train Loss 1406024600.0 Test MSE 6756295.19325576 Test RE 1.1618261088334076\n",
      "65 Train Loss 1394080800.0 Test MSE 6813721.610913081 Test RE 1.1667532423439555\n",
      "66 Train Loss 1390635100.0 Test MSE 6895703.640692291 Test RE 1.1737513853002575\n",
      "67 Train Loss 1389248800.0 Test MSE 6865668.895202068 Test RE 1.1711924154760478\n",
      "68 Train Loss 1389008400.0 Test MSE 6878682.281316284 Test RE 1.1723018458930528\n",
      "69 Train Loss 1389617800.0 Test MSE 6940977.827133757 Test RE 1.1775982515822137\n",
      "70 Train Loss 1390073300.0 Test MSE 6972818.821302467 Test RE 1.1802962140479292\n",
      "71 Train Loss 1390607700.0 Test MSE 6975898.480990518 Test RE 1.180556833855904\n",
      "72 Train Loss 1390701700.0 Test MSE 6962950.83018393 Test RE 1.1794607358459785\n",
      "73 Train Loss 1389538600.0 Test MSE 7010928.482630608 Test RE 1.183517249720886\n",
      "74 Train Loss 1376715300.0 Test MSE 6964623.581260495 Test RE 1.1796024017707396\n",
      "75 Train Loss 1369693700.0 Test MSE 7004119.447536146 Test RE 1.182942392332474\n",
      "76 Train Loss 1369837600.0 Test MSE 7014678.231374755 Test RE 1.183833705600881\n",
      "77 Train Loss 1368361200.0 Test MSE 6993140.18111484 Test RE 1.182014871497776\n",
      "78 Train Loss 1368236200.0 Test MSE 6958065.116154501 Test RE 1.179046865404511\n",
      "79 Train Loss 1368961300.0 Test MSE 6987624.038470866 Test RE 1.1815485967812536\n",
      "80 Train Loss 1370387700.0 Test MSE 6990478.698323463 Test RE 1.181789921651447\n",
      "81 Train Loss 1371827800.0 Test MSE 6964982.697597148 Test RE 1.1796328132515421\n",
      "82 Train Loss 1372687000.0 Test MSE 6977979.7417765735 Test RE 1.1807329304127094\n",
      "83 Train Loss 1374008200.0 Test MSE 6986094.309516763 Test RE 1.1814192575364948\n",
      "84 Train Loss 1375055200.0 Test MSE 6980278.115248766 Test RE 1.1809273664759017\n",
      "85 Train Loss 1376233000.0 Test MSE 6970817.2293704515 Test RE 1.1801267961263597\n",
      "86 Train Loss 1377496300.0 Test MSE 6969461.000043546 Test RE 1.1800119888968799\n",
      "87 Train Loss 1378682400.0 Test MSE 6964188.199815236 Test RE 1.1795655307884738\n",
      "88 Train Loss 1379902100.0 Test MSE 6967517.854500598 Test RE 1.1798474786943256\n",
      "89 Train Loss 1381002400.0 Test MSE 6968833.840237818 Test RE 1.179958894924528\n",
      "90 Train Loss 1381784400.0 Test MSE 6981752.335987402 Test RE 1.1810520646379439\n",
      "91 Train Loss 1382828000.0 Test MSE 7000658.03231094 Test RE 1.1826500528846198\n",
      "92 Train Loss 1384074900.0 Test MSE 7001181.921919486 Test RE 1.1826943034735926\n",
      "93 Train Loss 1385135000.0 Test MSE 6997205.284749696 Test RE 1.1823583734684242\n",
      "94 Train Loss 1386068600.0 Test MSE 7015296.962677211 Test RE 1.1838859146114074\n",
      "95 Train Loss 1386940800.0 Test MSE 7030052.382538399 Test RE 1.185130306537402\n",
      "96 Train Loss 1387938400.0 Test MSE 7029359.27279946 Test RE 1.1850718826765083\n",
      "97 Train Loss 1389026700.0 Test MSE 7030689.9724525865 Test RE 1.1851840479576092\n",
      "98 Train Loss 1389964500.0 Test MSE 7039374.954986383 Test RE 1.18591584853048\n",
      "99 Train Loss 1390879900.0 Test MSE 7042234.4084591875 Test RE 1.186156688584655\n",
      "100 Train Loss 1391385900.0 Test MSE 7047935.3285836335 Test RE 1.186636707861605\n",
      "101 Train Loss 1391971500.0 Test MSE 7048198.596843468 Test RE 1.1866588704417966\n",
      "102 Train Loss 1392705800.0 Test MSE 7053429.054611008 Test RE 1.187099097681394\n",
      "103 Train Loss 1393298800.0 Test MSE 7043274.416219666 Test RE 1.18624427205232\n",
      "104 Train Loss 1393774200.0 Test MSE 7040521.45949727 Test RE 1.18601241978298\n",
      "105 Train Loss 1394046300.0 Test MSE 7066426.803314885 Test RE 1.188192361250536\n",
      "106 Train Loss 1394467000.0 Test MSE 7078760.861685089 Test RE 1.189228871282104\n",
      "107 Train Loss 1395119600.0 Test MSE 7069973.044698926 Test RE 1.1884904672473375\n",
      "108 Train Loss 1395764100.0 Test MSE 7067248.089081183 Test RE 1.1882614072584161\n",
      "109 Train Loss 1396114700.0 Test MSE 7053490.966738455 Test RE 1.1871043076061543\n",
      "110 Train Loss 1396339700.0 Test MSE 7068311.215290148 Test RE 1.188350778985877\n",
      "111 Train Loss 1397087900.0 Test MSE 7084177.3057753965 Test RE 1.189683764454904\n",
      "112 Train Loss 1397532400.0 Test MSE 7078630.850149005 Test RE 1.1892179502900502\n",
      "113 Train Loss 1397973800.0 Test MSE 7065368.3281401275 Test RE 1.1881033686626117\n",
      "114 Train Loss 1398636000.0 Test MSE 7076035.87586661 Test RE 1.1889999510088547\n",
      "115 Train Loss 1399193500.0 Test MSE 7080573.835372775 Test RE 1.1893811509440193\n",
      "116 Train Loss 1399746000.0 Test MSE 7073497.610387171 Test RE 1.188786677059932\n",
      "117 Train Loss 1400228000.0 Test MSE 7082502.5449764775 Test RE 1.1895431303758148\n",
      "118 Train Loss 1400337200.0 Test MSE 7093125.638333362 Test RE 1.1904348979929311\n",
      "119 Train Loss 1400459800.0 Test MSE 7086197.232959079 Test RE 1.1898533609512938\n",
      "120 Train Loss 1400745000.0 Test MSE 7082043.921366667 Test RE 1.189504615642284\n",
      "121 Train Loss 1401045100.0 Test MSE 7091002.047883432 Test RE 1.1902566842159414\n",
      "122 Train Loss 1401376500.0 Test MSE 7100717.444597734 Test RE 1.1910717917007492\n",
      "123 Train Loss 1401857800.0 Test MSE 7128165.771087109 Test RE 1.1933716574802617\n",
      "124 Train Loss 1402360700.0 Test MSE 7144115.17079372 Test RE 1.1947060068125372\n",
      "125 Train Loss 1402823200.0 Test MSE 7147845.050714351 Test RE 1.195017838884609\n",
      "126 Train Loss 1402993000.0 Test MSE 7186809.375567109 Test RE 1.1982705520582113\n",
      "127 Train Loss 1402975000.0 Test MSE 7175389.23024538 Test RE 1.197318122145989\n",
      "128 Train Loss 1403309300.0 Test MSE 7162680.766731434 Test RE 1.196257356205552\n",
      "129 Train Loss 1403603300.0 Test MSE 7177730.556627192 Test RE 1.1975134484045544\n",
      "130 Train Loss 1404025700.0 Test MSE 7173512.460830175 Test RE 1.1971615287603026\n",
      "131 Train Loss 1404412200.0 Test MSE 7184280.835621148 Test RE 1.1980597393493841\n",
      "132 Train Loss 1404720400.0 Test MSE 7192614.095912553 Test RE 1.1987543704787074\n",
      "133 Train Loss 1405135600.0 Test MSE 7182399.417076851 Test RE 1.1979028552120297\n",
      "134 Train Loss 1405441400.0 Test MSE 7189748.059335977 Test RE 1.1985155132185217\n",
      "135 Train Loss 1405864400.0 Test MSE 7190146.128486739 Test RE 1.198548691394243\n",
      "136 Train Loss 1406033800.0 Test MSE 7188547.8142178375 Test RE 1.198415469905276\n",
      "137 Train Loss 1406421900.0 Test MSE 7218119.306776962 Test RE 1.2008778978947257\n",
      "138 Train Loss 1406564100.0 Test MSE 7238543.550565566 Test RE 1.2025756875901752\n",
      "139 Train Loss 1406813700.0 Test MSE 7249585.234186203 Test RE 1.2034925433286867\n",
      "140 Train Loss 1407079000.0 Test MSE 7260770.188843787 Test RE 1.2044205841093991\n",
      "141 Train Loss 1407424400.0 Test MSE 7247870.628443448 Test RE 1.2033502153757851\n",
      "142 Train Loss 1407854800.0 Test MSE 7251286.008049305 Test RE 1.2036337064821465\n",
      "143 Train Loss 1408313000.0 Test MSE 7258177.528731138 Test RE 1.2042055289614335\n",
      "144 Train Loss 1408703700.0 Test MSE 7249221.301165349 Test RE 1.203462334967815\n",
      "145 Train Loss 1409056300.0 Test MSE 7255032.655146173 Test RE 1.20394461742715\n",
      "146 Train Loss 1409366500.0 Test MSE 7265305.604426865 Test RE 1.2047966940102426\n",
      "147 Train Loss 1409557900.0 Test MSE 7255489.2805193635 Test RE 1.2039825044385815\n",
      "148 Train Loss 1409630000.0 Test MSE 7264056.005545948 Test RE 1.2046930798318856\n",
      "149 Train Loss 1409379600.0 Test MSE 7276710.683053528 Test RE 1.2057419682645147\n",
      "150 Train Loss 1409305500.0 Test MSE 7289362.4393934235 Test RE 1.2067897032432697\n",
      "151 Train Loss 1408572900.0 Test MSE 7292305.315873471 Test RE 1.2070332824786234\n",
      "152 Train Loss 1408284200.0 Test MSE 7264460.640152968 Test RE 1.2047266322798857\n",
      "153 Train Loss 1407290600.0 Test MSE 7274536.202833678 Test RE 1.2055618004610429\n",
      "154 Train Loss 1406937500.0 Test MSE 7288527.301269373 Test RE 1.2067205706568656\n",
      "155 Train Loss 1406754300.0 Test MSE 7274849.4738939395 Test RE 1.2055877583741674\n",
      "156 Train Loss 1406578300.0 Test MSE 7289206.942567335 Test RE 1.206776831543521\n",
      "157 Train Loss 1406455300.0 Test MSE 7292662.948155093 Test RE 1.2070628800308139\n",
      "158 Train Loss 1406697300.0 Test MSE 7298666.24395975 Test RE 1.2075596028942406\n",
      "159 Train Loss 1407015000.0 Test MSE 7297729.889877298 Test RE 1.2074821408214926\n",
      "160 Train Loss 1407354200.0 Test MSE 7303335.053753183 Test RE 1.2079457669269988\n",
      "161 Train Loss 1407661800.0 Test MSE 7307214.629133939 Test RE 1.2082665583489685\n",
      "162 Train Loss 1407949800.0 Test MSE 7300085.930445404 Test RE 1.2076770402885164\n",
      "163 Train Loss 1408270300.0 Test MSE 7298867.056448367 Test RE 1.2075762149280673\n",
      "164 Train Loss 1408564600.0 Test MSE 7294949.889759441 Test RE 1.2072521295515097\n",
      "165 Train Loss 1408901800.0 Test MSE 7293652.9063059725 Test RE 1.207144804918573\n",
      "166 Train Loss 1409269200.0 Test MSE 7292393.3935239315 Test RE 1.2070405718288308\n",
      "167 Train Loss 1409629400.0 Test MSE 7292064.618430886 Test RE 1.2070133620138979\n",
      "168 Train Loss 1409990000.0 Test MSE 7289807.019543811 Test RE 1.2068265038943504\n",
      "169 Train Loss 1410315400.0 Test MSE 7290762.958034544 Test RE 1.206905629040288\n",
      "170 Train Loss 1410627100.0 Test MSE 7289293.895178771 Test RE 1.2067840293144725\n",
      "171 Train Loss 1410925300.0 Test MSE 7279129.148275344 Test RE 1.2059423199681925\n",
      "172 Train Loss 1411146800.0 Test MSE 7282281.424209728 Test RE 1.206203412428765\n",
      "173 Train Loss 1411399000.0 Test MSE 7286455.915792324 Test RE 1.2065490846363682\n",
      "174 Train Loss 1411682400.0 Test MSE 7285750.9266936155 Test RE 1.2064907143849561\n",
      "175 Train Loss 1411974100.0 Test MSE 7288152.322192297 Test RE 1.2066895286666741\n",
      "176 Train Loss 1412269700.0 Test MSE 7287924.118679742 Test RE 1.2066706368452327\n",
      "177 Train Loss 1412561500.0 Test MSE 7287924.118679742 Test RE 1.2066706368452327\n",
      "178 Train Loss 1412846100.0 Test MSE 7287094.599007633 Test RE 1.2066019625904756\n",
      "179 Train Loss 1413107200.0 Test MSE 7285773.396234601 Test RE 1.206492574815811\n",
      "180 Train Loss 1413353900.0 Test MSE 7286492.809121954 Test RE 1.2065521391773733\n",
      "181 Train Loss 1413638300.0 Test MSE 7286492.809121954 Test RE 1.2065521391773733\n",
      "182 Train Loss 1413914400.0 Test MSE 7286492.809121954 Test RE 1.2065521391773733\n",
      "183 Train Loss 1414183700.0 Test MSE 7286492.809121954 Test RE 1.2065521391773733\n",
      "184 Train Loss 1414458200.0 Test MSE 7286492.809121954 Test RE 1.2065521391773733\n",
      "185 Train Loss 1414739800.0 Test MSE 7286492.809121954 Test RE 1.2065521391773733\n",
      "186 Train Loss 1415037600.0 Test MSE 7287932.859662632 Test RE 1.2066713604727062\n",
      "187 Train Loss 1415321700.0 Test MSE 7287932.859662632 Test RE 1.2066713604727062\n",
      "188 Train Loss 1415586000.0 Test MSE 7287932.859662632 Test RE 1.2066713604727062\n",
      "189 Train Loss 1415849500.0 Test MSE 7287932.859662632 Test RE 1.2066713604727062\n",
      "190 Train Loss 1416114000.0 Test MSE 7290227.338650503 Test RE 1.206861295276691\n",
      "191 Train Loss 1416375400.0 Test MSE 7290796.4618941955 Test RE 1.206908402134859\n",
      "192 Train Loss 1416627700.0 Test MSE 7290796.4618941955 Test RE 1.206908402134859\n",
      "193 Train Loss 1416871200.0 Test MSE 7290796.4618941955 Test RE 1.206908402134859\n",
      "194 Train Loss 1417121800.0 Test MSE 7290796.4618941955 Test RE 1.206908402134859\n",
      "195 Train Loss 1417358700.0 Test MSE 7290796.4618941955 Test RE 1.206908402134859\n",
      "196 Train Loss 1417598800.0 Test MSE 7290796.4618941955 Test RE 1.206908402134859\n",
      "197 Train Loss 1417831300.0 Test MSE 7290796.4618941955 Test RE 1.206908402134859\n",
      "198 Train Loss 1418070800.0 Test MSE 7290796.4618941955 Test RE 1.206908402134859\n",
      "199 Train Loss 1418304100.0 Test MSE 7290796.4618941955 Test RE 1.206908402134859\n",
      "Training time: 45.04\n",
      "Training time: 45.04\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "5\n",
      "0 Train Loss 1257183900.0 Test MSE 5433308.581093582 Test RE 1.0418831376535016\n",
      "1 Train Loss 1269584400.0 Test MSE 5566022.228164637 Test RE 1.0545308558765176\n",
      "2 Train Loss 1271794000.0 Test MSE 5753676.9810073245 Test RE 1.0721599043379575\n",
      "3 Train Loss 1256719000.0 Test MSE 6007237.090274193 Test RE 1.0955298366933137\n",
      "4 Train Loss 1241130400.0 Test MSE 6268587.244133132 Test RE 1.1191071255035332\n",
      "5 Train Loss 1220416900.0 Test MSE 6465632.40937169 Test RE 1.136559898504919\n",
      "6 Train Loss 1218844800.0 Test MSE 6740182.869567278 Test RE 1.1604399281114604\n",
      "7 Train Loss 1216408200.0 Test MSE 7054772.450490631 Test RE 1.1872121397278719\n",
      "8 Train Loss 1210764500.0 Test MSE 7023762.276181845 Test RE 1.184599992998733\n",
      "9 Train Loss 1216308700.0 Test MSE 7046619.976266462 Test RE 1.1865259720147026\n",
      "10 Train Loss 1218118000.0 Test MSE 7260220.852560404 Test RE 1.204375021143968\n",
      "11 Train Loss 1219326600.0 Test MSE 7397262.133617557 Test RE 1.215688555025641\n",
      "12 Train Loss 1217623000.0 Test MSE 7374474.313489438 Test RE 1.2138146008681894\n",
      "13 Train Loss 1211395100.0 Test MSE 7584258.720751014 Test RE 1.2309584486885614\n",
      "14 Train Loss 1213811100.0 Test MSE 7777592.338432635 Test RE 1.2465491634982153\n",
      "15 Train Loss 1216806000.0 Test MSE 8010455.477349432 Test RE 1.2650725405585448\n",
      "16 Train Loss 1221540400.0 Test MSE 8169656.132482251 Test RE 1.2775817877817233\n",
      "17 Train Loss 1226837400.0 Test MSE 8250025.523608454 Test RE 1.2838505448232955\n",
      "18 Train Loss 1231680500.0 Test MSE 8500772.269474113 Test RE 1.3032148335225933\n",
      "19 Train Loss 1236574700.0 Test MSE 8498155.28855274 Test RE 1.303014219344869\n",
      "20 Train Loss 1242726400.0 Test MSE 8547485.722460952 Test RE 1.3067906415894253\n",
      "21 Train Loss 1251249800.0 Test MSE 8630979.820217138 Test RE 1.3131576687175452\n",
      "22 Train Loss 1258875100.0 Test MSE 8691120.545654565 Test RE 1.3177247723602619\n",
      "23 Train Loss 1264013700.0 Test MSE 8732619.248485573 Test RE 1.3208669878642332\n",
      "24 Train Loss 1268976400.0 Test MSE 8831853.152136393 Test RE 1.328350682874896\n",
      "25 Train Loss 1274972900.0 Test MSE 8839987.599013446 Test RE 1.3289622708952826\n",
      "26 Train Loss 1279877500.0 Test MSE 8877789.883916792 Test RE 1.3318007486979164\n",
      "27 Train Loss 1285092200.0 Test MSE 8904995.24800539 Test RE 1.3338397927327572\n",
      "28 Train Loss 1288944400.0 Test MSE 9133181.102439942 Test RE 1.350821170282012\n",
      "29 Train Loss 1293065200.0 Test MSE 9279993.624945318 Test RE 1.3616348634006836\n",
      "30 Train Loss 1296338700.0 Test MSE 9413790.549269985 Test RE 1.3714156126463017\n",
      "31 Train Loss 1300396800.0 Test MSE 9587856.684244819 Test RE 1.3840366497109098\n",
      "32 Train Loss 1299954300.0 Test MSE 9537142.920429427 Test RE 1.3803714526146318\n",
      "33 Train Loss 1299758100.0 Test MSE 9641392.166748514 Test RE 1.3878952767914625\n",
      "34 Train Loss 1300962000.0 Test MSE 9824380.910635702 Test RE 1.4010041442118897\n",
      "35 Train Loss 1302912900.0 Test MSE 10030774.378018996 Test RE 1.415644006624861\n",
      "36 Train Loss 1304239900.0 Test MSE 10185109.13651639 Test RE 1.426493073177465\n",
      "37 Train Loss 1308709900.0 Test MSE 10253135.413812177 Test RE 1.431248914287118\n",
      "38 Train Loss 1312049200.0 Test MSE 10307303.99460717 Test RE 1.435024666311949\n",
      "39 Train Loss 1315035300.0 Test MSE 10287399.170649283 Test RE 1.433638381551282\n",
      "40 Train Loss 1318341000.0 Test MSE 10413964.929663137 Test RE 1.4424304406981328\n",
      "41 Train Loss 1321885600.0 Test MSE 10454028.873532066 Test RE 1.445202390588573\n",
      "42 Train Loss 1325839900.0 Test MSE 10412744.025356384 Test RE 1.442345884951696\n",
      "43 Train Loss 1330014300.0 Test MSE 10443365.462848611 Test RE 1.4444651284925334\n",
      "44 Train Loss 1333406300.0 Test MSE 10495801.799678536 Test RE 1.4480869313560523\n",
      "45 Train Loss 1336631400.0 Test MSE 10440571.684975574 Test RE 1.4442719060750557\n",
      "46 Train Loss 1338999600.0 Test MSE 10527099.047426783 Test RE 1.4502443368129865\n",
      "47 Train Loss 1341879300.0 Test MSE 10656159.304927938 Test RE 1.4591071171755279\n",
      "48 Train Loss 1344966700.0 Test MSE 10649489.559489802 Test RE 1.4586504143408467\n",
      "49 Train Loss 1343823900.0 Test MSE 10619859.034752872 Test RE 1.456619768531532\n",
      "50 Train Loss 1336994800.0 Test MSE 10455179.674265593 Test RE 1.4452819338069518\n",
      "51 Train Loss 1334875500.0 Test MSE 10578511.54042787 Test RE 1.4537813921218399\n",
      "52 Train Loss 1334319100.0 Test MSE 10640178.25357255 Test RE 1.4580125945526161\n",
      "53 Train Loss 1335576800.0 Test MSE 10631526.368683146 Test RE 1.4574196945932645\n",
      "54 Train Loss 1337807900.0 Test MSE 10673197.007774835 Test RE 1.4602731050264521\n",
      "55 Train Loss 1340343700.0 Test MSE 10632275.121687207 Test RE 1.4574710149833878\n",
      "56 Train Loss 1343155800.0 Test MSE 10588369.954620942 Test RE 1.4544586443758905\n",
      "57 Train Loss 1345856000.0 Test MSE 10616781.487627776 Test RE 1.4564086950707575\n",
      "58 Train Loss 1348087700.0 Test MSE 10646357.060648145 Test RE 1.458435870875591\n",
      "59 Train Loss 1350617900.0 Test MSE 10672625.558610315 Test RE 1.4602340125682574\n",
      "60 Train Loss 1353169400.0 Test MSE 10715461.332753194 Test RE 1.4631614841892784\n",
      "61 Train Loss 1355447000.0 Test MSE 10792978.095692014 Test RE 1.4684442785926932\n",
      "62 Train Loss 1357403900.0 Test MSE 10795393.866655152 Test RE 1.4686086088885897\n",
      "63 Train Loss 1356091400.0 Test MSE 10692555.225301925 Test RE 1.4615967701991437\n",
      "64 Train Loss 1352413600.0 Test MSE 10785228.24655366 Test RE 1.4679169790309228\n",
      "65 Train Loss 1353500000.0 Test MSE 10848491.720388446 Test RE 1.4722159025994583\n",
      "66 Train Loss 1355523700.0 Test MSE 10888304.844112316 Test RE 1.4749148877246316\n",
      "67 Train Loss 1357585800.0 Test MSE 10875350.473650582 Test RE 1.4740372359444074\n",
      "68 Train Loss 1359603700.0 Test MSE 10866651.634850431 Test RE 1.473447600814235\n",
      "69 Train Loss 1361743700.0 Test MSE 10894276.079421233 Test RE 1.4753192599775142\n",
      "70 Train Loss 1362608500.0 Test MSE 11033326.552367792 Test RE 1.4847046192697535\n",
      "71 Train Loss 1363691100.0 Test MSE 11054809.919375723 Test RE 1.4861493758674948\n",
      "72 Train Loss 1363904400.0 Test MSE 11142082.318661185 Test RE 1.4920040603318736\n",
      "73 Train Loss 1364388500.0 Test MSE 11284375.32056022 Test RE 1.5015008586004943\n",
      "74 Train Loss 1365739100.0 Test MSE 11286932.203774134 Test RE 1.5016709586184995\n",
      "75 Train Loss 1365548000.0 Test MSE 11419438.725922918 Test RE 1.5104599100765392\n",
      "76 Train Loss 1366152300.0 Test MSE 11521504.808351591 Test RE 1.5171950823415523\n",
      "77 Train Loss 1366533500.0 Test MSE 11664651.446484225 Test RE 1.5265910317293956\n",
      "78 Train Loss 1366390300.0 Test MSE 11714344.707782831 Test RE 1.5298393355366149\n",
      "79 Train Loss 1367427500.0 Test MSE 11749517.40996529 Test RE 1.5321343104026313\n",
      "80 Train Loss 1368381000.0 Test MSE 11726551.631198516 Test RE 1.5306362119148864\n",
      "81 Train Loss 1369187700.0 Test MSE 11678361.510996414 Test RE 1.5274879087303697\n",
      "82 Train Loss 1369568800.0 Test MSE 11615949.412959058 Test RE 1.5234008012041935\n",
      "83 Train Loss 1370035500.0 Test MSE 11551950.039758386 Test RE 1.519198331117274\n",
      "84 Train Loss 1370016000.0 Test MSE 11688204.036202224 Test RE 1.5281314567070066\n",
      "85 Train Loss 1371056500.0 Test MSE 11743824.340887131 Test RE 1.531763077993007\n",
      "86 Train Loss 1371427600.0 Test MSE 11952882.63688577 Test RE 1.5453368158701195\n",
      "87 Train Loss 1371900200.0 Test MSE 11982759.969945502 Test RE 1.547266966456331\n",
      "88 Train Loss 1372844400.0 Test MSE 12002141.078388764 Test RE 1.5485177481240058\n",
      "89 Train Loss 1372560800.0 Test MSE 12012270.208436914 Test RE 1.5491710411324393\n",
      "90 Train Loss 1372556000.0 Test MSE 12060696.522907527 Test RE 1.552290567462525\n",
      "91 Train Loss 1373110900.0 Test MSE 12156175.532659128 Test RE 1.5584228414707226\n",
      "92 Train Loss 1374069800.0 Test MSE 12236545.083002787 Test RE 1.5635660464461536\n",
      "93 Train Loss 1375010300.0 Test MSE 12267268.247282606 Test RE 1.5655276941604548\n",
      "94 Train Loss 1374710400.0 Test MSE 12406887.107644197 Test RE 1.5744114477795526\n",
      "95 Train Loss 1374730400.0 Test MSE 12463547.151050437 Test RE 1.578002380979175\n",
      "96 Train Loss 1375469200.0 Test MSE 12451944.791042568 Test RE 1.5772677259747176\n",
      "97 Train Loss 1376184000.0 Test MSE 12481426.9743461 Test RE 1.579133852291548\n",
      "98 Train Loss 1376918900.0 Test MSE 12556877.796452988 Test RE 1.5838996305781543\n",
      "99 Train Loss 1376565800.0 Test MSE 12571310.062982265 Test RE 1.5848095979058123\n",
      "100 Train Loss 1374868200.0 Test MSE 12634113.937443482 Test RE 1.5887633696734256\n",
      "101 Train Loss 1360254700.0 Test MSE 13123460.192664977 Test RE 1.619239176505651\n",
      "102 Train Loss 1335375900.0 Test MSE 12695754.860062571 Test RE 1.592634384258505\n",
      "103 Train Loss 1334822900.0 Test MSE 12725917.87814079 Test RE 1.5945251800842157\n",
      "104 Train Loss 1335063800.0 Test MSE 12768740.3886706 Test RE 1.5972057028885573\n",
      "105 Train Loss 1335644300.0 Test MSE 12720603.857853418 Test RE 1.5941922287016748\n",
      "106 Train Loss 1336244000.0 Test MSE 12692951.680393124 Test RE 1.5924585504133904\n",
      "107 Train Loss 1336904200.0 Test MSE 12734350.687838303 Test RE 1.5950533974089316\n",
      "108 Train Loss 1336679200.0 Test MSE 12764536.416708075 Test RE 1.596942749748379\n",
      "109 Train Loss 1336286300.0 Test MSE 12728443.390359733 Test RE 1.5946833923676307\n",
      "110 Train Loss 1335643400.0 Test MSE 12634008.296073135 Test RE 1.5887567273599552\n",
      "111 Train Loss 1335877200.0 Test MSE 12588770.23594848 Test RE 1.5859097795182058\n",
      "112 Train Loss 1335617500.0 Test MSE 12423890.163632208 Test RE 1.5754899068785788\n",
      "113 Train Loss 1335464000.0 Test MSE 12353715.486163568 Test RE 1.571034134282062\n",
      "114 Train Loss 1335712000.0 Test MSE 12271771.465465922 Test RE 1.5658150142778393\n",
      "115 Train Loss 1335307900.0 Test MSE 12088218.403599326 Test RE 1.5540606812849411\n",
      "116 Train Loss 1334677600.0 Test MSE 11944617.652401965 Test RE 1.5448024513225576\n",
      "117 Train Loss 1334346200.0 Test MSE 11824256.031713286 Test RE 1.5369995351099945\n",
      "118 Train Loss 1334266200.0 Test MSE 11764560.683481108 Test RE 1.5331148163264119\n",
      "119 Train Loss 1333783700.0 Test MSE 11570573.075231802 Test RE 1.5204223967942787\n",
      "120 Train Loss 1331594800.0 Test MSE 11444063.326334862 Test RE 1.5120875926138404\n",
      "121 Train Loss 1328162000.0 Test MSE 11452633.105627408 Test RE 1.512653642956315\n",
      "122 Train Loss 1325685500.0 Test MSE 11307537.731789613 Test RE 1.5030410657917876\n",
      "123 Train Loss 1323096000.0 Test MSE 11299936.364737399 Test RE 1.5025357795012262\n",
      "124 Train Loss 1319152600.0 Test MSE 11289910.819646116 Test RE 1.5018690906623058\n",
      "125 Train Loss 1316009300.0 Test MSE 11284555.569279024 Test RE 1.5015128505148714\n",
      "126 Train Loss 1309778200.0 Test MSE 11112550.3681043 Test RE 1.490025479311626\n",
      "127 Train Loss 1305735800.0 Test MSE 11216944.034937229 Test RE 1.4970079274714305\n",
      "128 Train Loss 1303667700.0 Test MSE 11288376.362801434 Test RE 1.501767024682628\n",
      "129 Train Loss 1302645600.0 Test MSE 11276805.20031892 Test RE 1.5009971333756056\n",
      "130 Train Loss 1302564700.0 Test MSE 11261591.035442745 Test RE 1.4999842522833722\n",
      "131 Train Loss 1302603400.0 Test MSE 11292262.089156196 Test RE 1.5020254743227668\n",
      "132 Train Loss 1302322200.0 Test MSE 11325176.355830695 Test RE 1.5042129055907243\n",
      "133 Train Loss 1301596700.0 Test MSE 11364790.896237833 Test RE 1.5068414158626513\n",
      "134 Train Loss 1301351800.0 Test MSE 11357530.199747158 Test RE 1.5063599962624101\n",
      "135 Train Loss 1301030100.0 Test MSE 11334067.26432036 Test RE 1.5048032361559975\n",
      "136 Train Loss 1300462500.0 Test MSE 11317538.067381782 Test RE 1.5037055602897718\n",
      "137 Train Loss 1299215500.0 Test MSE 11301584.653632646 Test RE 1.5026453607702095\n",
      "138 Train Loss 1298135300.0 Test MSE 11327370.672847658 Test RE 1.5043586234146398\n",
      "139 Train Loss 1297643900.0 Test MSE 11350347.860677699 Test RE 1.5058836207177533\n",
      "140 Train Loss 1297642000.0 Test MSE 11371145.112857435 Test RE 1.5072626052570652\n",
      "141 Train Loss 1297804700.0 Test MSE 11385052.680358848 Test RE 1.5081840582237775\n",
      "142 Train Loss 1298131700.0 Test MSE 11387778.418376908 Test RE 1.50836458741052\n",
      "143 Train Loss 1298359900.0 Test MSE 11392218.022621978 Test RE 1.5086585819471756\n",
      "144 Train Loss 1298291200.0 Test MSE 11423132.994729506 Test RE 1.5107042125260877\n",
      "145 Train Loss 1298105000.0 Test MSE 11481170.112660337 Test RE 1.5145370417645427\n",
      "146 Train Loss 1298044300.0 Test MSE 11504320.048594879 Test RE 1.5160631832205405\n",
      "147 Train Loss 1297821300.0 Test MSE 11592089.514323968 Test RE 1.5218354158890683\n",
      "148 Train Loss 1297931300.0 Test MSE 11621064.333129643 Test RE 1.5237361683625399\n",
      "149 Train Loss 1298042000.0 Test MSE 11629126.03220578 Test RE 1.5242645955559304\n",
      "150 Train Loss 1298283500.0 Test MSE 11626813.01849825 Test RE 1.5241130011789192\n",
      "151 Train Loss 1298525700.0 Test MSE 11635077.905538922 Test RE 1.5246546106465781\n",
      "152 Train Loss 1298740600.0 Test MSE 11641051.466098059 Test RE 1.5250459465722146\n",
      "153 Train Loss 1298981200.0 Test MSE 11641181.152196191 Test RE 1.525054441367896\n",
      "154 Train Loss 1299321200.0 Test MSE 11644265.572929082 Test RE 1.5252564654551968\n",
      "155 Train Loss 1299443700.0 Test MSE 11643245.199895263 Test RE 1.5251896357932653\n",
      "156 Train Loss 1299741400.0 Test MSE 11621207.54286837 Test RE 1.5237455570544889\n",
      "157 Train Loss 1299820200.0 Test MSE 11613406.42754453 Test RE 1.5232340391975558\n",
      "158 Train Loss 1299833200.0 Test MSE 11610824.552442657 Test RE 1.5230647082319806\n",
      "159 Train Loss 1300056800.0 Test MSE 11602414.113631647 Test RE 1.5225129832868367\n",
      "160 Train Loss 1300238600.0 Test MSE 11613967.948939491 Test RE 1.523270863800617\n",
      "161 Train Loss 1300404500.0 Test MSE 11627119.183245169 Test RE 1.5241330680105905\n",
      "162 Train Loss 1300538000.0 Test MSE 11595168.176513474 Test RE 1.5220374892991522\n",
      "163 Train Loss 1300796200.0 Test MSE 11605096.184576593 Test RE 1.5226889489019786\n",
      "164 Train Loss 1301045400.0 Test MSE 11616571.118628452 Test RE 1.52344156817936\n",
      "165 Train Loss 1301164700.0 Test MSE 11633427.52049472 Test RE 1.5245464740090706\n",
      "166 Train Loss 1301278600.0 Test MSE 11639394.62375031 Test RE 1.524937414682839\n",
      "167 Train Loss 1300487400.0 Test MSE 11618365.721894555 Test RE 1.5235592392030957\n",
      "168 Train Loss 1299687800.0 Test MSE 11581254.032260915 Test RE 1.5211239964543422\n",
      "169 Train Loss 1299650700.0 Test MSE 11544281.535088617 Test RE 1.518694004423807\n",
      "170 Train Loss 1299818500.0 Test MSE 11534505.704718618 Test RE 1.5180508444617427\n",
      "171 Train Loss 1299929100.0 Test MSE 11530903.036625613 Test RE 1.5178137532245977\n",
      "172 Train Loss 1299888400.0 Test MSE 11535237.92568054 Test RE 1.518099027324453\n",
      "173 Train Loss 1299911300.0 Test MSE 11558001.550115861 Test RE 1.5195961964438525\n",
      "174 Train Loss 1300126200.0 Test MSE 11559676.096638186 Test RE 1.5197062735343336\n",
      "175 Train Loss 1300390000.0 Test MSE 11561622.310385762 Test RE 1.5198341987779742\n",
      "176 Train Loss 1300560400.0 Test MSE 11555726.656461295 Test RE 1.5194466424812638\n",
      "177 Train Loss 1300679800.0 Test MSE 11532747.17676123 Test RE 1.517935120534128\n",
      "178 Train Loss 1300740600.0 Test MSE 11534779.25301743 Test RE 1.518068845136181\n",
      "179 Train Loss 1300971500.0 Test MSE 11525866.310121967 Test RE 1.5174822246472277\n",
      "180 Train Loss 1301103000.0 Test MSE 11524690.595066134 Test RE 1.517404826031324\n",
      "181 Train Loss 1301248100.0 Test MSE 11550337.272204699 Test RE 1.519092279788769\n",
      "182 Train Loss 1301441000.0 Test MSE 11544968.58957768 Test RE 1.5187391960628778\n",
      "183 Train Loss 1301620600.0 Test MSE 11514697.726958849 Test RE 1.5167468250837888\n",
      "184 Train Loss 1301673900.0 Test MSE 11511975.093822956 Test RE 1.5165674982183455\n",
      "185 Train Loss 1301340900.0 Test MSE 11499037.11816552 Test RE 1.5157150454779804\n",
      "186 Train Loss 1300786300.0 Test MSE 11507210.46309298 Test RE 1.5162536236715047\n",
      "187 Train Loss 1299859300.0 Test MSE 11435658.132058183 Test RE 1.511532207515675\n",
      "188 Train Loss 1299544700.0 Test MSE 11416311.763171503 Test RE 1.5102530927641105\n",
      "189 Train Loss 1299641200.0 Test MSE 11428015.214207817 Test RE 1.5110270137062383\n",
      "190 Train Loss 1299669900.0 Test MSE 11390347.022323757 Test RE 1.5085346896306324\n",
      "191 Train Loss 1299740700.0 Test MSE 11348292.648029396 Test RE 1.5057472790296358\n",
      "192 Train Loss 1299861100.0 Test MSE 11354661.468285898 Test RE 1.5061697429614145\n",
      "193 Train Loss 1299909800.0 Test MSE 11360406.50405482 Test RE 1.5065507276708467\n",
      "194 Train Loss 1300031900.0 Test MSE 11350075.186931495 Test RE 1.5058655324001362\n",
      "195 Train Loss 1300129000.0 Test MSE 11365190.425151495 Test RE 1.5068679021142894\n",
      "196 Train Loss 1300272600.0 Test MSE 11379461.97429973 Test RE 1.5078137108319751\n",
      "197 Train Loss 1300447100.0 Test MSE 11375940.124607602 Test RE 1.5075803648178194\n",
      "198 Train Loss 1300580200.0 Test MSE 11384677.22664506 Test RE 1.508159189740945\n",
      "199 Train Loss 1300709500.0 Test MSE 11387442.36178387 Test RE 1.5083423311114692\n",
      "Training time: 46.70\n",
      "Training time: 46.70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "6\n",
      "0 Train Loss 1315017200.0 Test MSE 5023933.417498816 Test RE 1.001863976468282\n",
      "1 Train Loss 1245928100.0 Test MSE 5409294.904044227 Test RE 1.0395781745924821\n",
      "2 Train Loss 1191011000.0 Test MSE 5486499.098286191 Test RE 1.0469705838847885\n",
      "3 Train Loss 1143495700.0 Test MSE 5613478.103547162 Test RE 1.0590167766208747\n",
      "4 Train Loss 1106710000.0 Test MSE 5813990.735083818 Test RE 1.0777647900326197\n",
      "5 Train Loss 1085875300.0 Test MSE 5952023.201049257 Test RE 1.0904835820342627\n",
      "6 Train Loss 1071932900.0 Test MSE 6042925.138941739 Test RE 1.0987792028855308\n",
      "7 Train Loss 1067096900.0 Test MSE 6195178.43713787 Test RE 1.112535130306419\n",
      "8 Train Loss 1072130100.0 Test MSE 6254846.39665188 Test RE 1.1178799018964174\n",
      "9 Train Loss 1079396000.0 Test MSE 6298382.272720746 Test RE 1.1217635694518895\n",
      "10 Train Loss 1078850400.0 Test MSE 6325469.936813622 Test RE 1.1241731845751006\n",
      "11 Train Loss 1078288600.0 Test MSE 6417202.497817465 Test RE 1.1322952764533547\n",
      "12 Train Loss 1080565500.0 Test MSE 6521156.71277799 Test RE 1.1414296302985958\n",
      "13 Train Loss 1082130300.0 Test MSE 6532876.487261665 Test RE 1.1424548543075217\n",
      "14 Train Loss 1083603700.0 Test MSE 6570854.688532177 Test RE 1.1457708135674187\n",
      "15 Train Loss 1088051500.0 Test MSE 6621816.3698842265 Test RE 1.1502053682737738\n",
      "16 Train Loss 1094022800.0 Test MSE 6637471.803322367 Test RE 1.1515642350886326\n",
      "17 Train Loss 1098287200.0 Test MSE 6637516.230506901 Test RE 1.1515680890162032\n",
      "18 Train Loss 1104088200.0 Test MSE 6655123.266978382 Test RE 1.153094433535485\n",
      "19 Train Loss 1107911300.0 Test MSE 6687634.410084959 Test RE 1.1559075103322534\n",
      "20 Train Loss 1112966400.0 Test MSE 6685478.745431138 Test RE 1.1557212000738188\n",
      "21 Train Loss 1117827700.0 Test MSE 6704413.572601088 Test RE 1.15735667819086\n",
      "22 Train Loss 1118585300.0 Test MSE 6718671.765075289 Test RE 1.158586692558766\n",
      "23 Train Loss 1111393300.0 Test MSE 6719751.408552603 Test RE 1.1586797772012494\n",
      "24 Train Loss 1070782200.0 Test MSE 6745083.437231781 Test RE 1.160861710517035\n",
      "25 Train Loss 1032861440.0 Test MSE 6866255.959574678 Test RE 1.1712424871190126\n",
      "26 Train Loss 1031691300.0 Test MSE 6945320.193616609 Test RE 1.1779665544191738\n",
      "27 Train Loss 1033715500.0 Test MSE 6979540.146239053 Test RE 1.1808649398204114\n",
      "28 Train Loss 1033166300.0 Test MSE 7067593.392244269 Test RE 1.1882904359132433\n",
      "29 Train Loss 1029805900.0 Test MSE 7129016.907917725 Test RE 1.193442902474009\n",
      "30 Train Loss 1026511300.0 Test MSE 7119569.507764683 Test RE 1.1926518627922313\n",
      "31 Train Loss 1024230460.0 Test MSE 7175677.20565275 Test RE 1.1973421483488518\n",
      "32 Train Loss 1023367040.0 Test MSE 7197719.784692728 Test RE 1.1991797638674988\n",
      "33 Train Loss 1023993100.0 Test MSE 7199878.74398999 Test RE 1.1993595976388451\n",
      "34 Train Loss 1025820900.0 Test MSE 7241016.861461131 Test RE 1.20278112183951\n",
      "35 Train Loss 1026592060.0 Test MSE 7325570.976261737 Test RE 1.2097832408230214\n",
      "36 Train Loss 1029500400.0 Test MSE 7335056.089712552 Test RE 1.2105661981726135\n",
      "37 Train Loss 1032711000.0 Test MSE 7357487.22034539 Test RE 1.2124157845886456\n",
      "38 Train Loss 1035699840.0 Test MSE 7358064.736763799 Test RE 1.2124633671573255\n",
      "39 Train Loss 1038962940.0 Test MSE 7368231.016298629 Test RE 1.2133006788183398\n",
      "40 Train Loss 1040677700.0 Test MSE 7408899.545535406 Test RE 1.2166444430540542\n",
      "41 Train Loss 1040262800.0 Test MSE 7404642.939563871 Test RE 1.2162948958629414\n",
      "42 Train Loss 1037927940.0 Test MSE 7376104.085736559 Test RE 1.2139487210765523\n",
      "43 Train Loss 1038430140.0 Test MSE 7384213.615154032 Test RE 1.2146158651665273\n",
      "44 Train Loss 1036886300.0 Test MSE 7422776.181500232 Test RE 1.2177832784523108\n",
      "45 Train Loss 1033717700.0 Test MSE 7496790.655766839 Test RE 1.2238396388830177\n",
      "46 Train Loss 1029596350.0 Test MSE 7555696.0635759905 Test RE 1.2286383399638625\n",
      "47 Train Loss 1028188540.0 Test MSE 7619336.427302092 Test RE 1.2338017976088156\n",
      "48 Train Loss 1027470100.0 Test MSE 7674130.201105835 Test RE 1.2382302376137448\n",
      "49 Train Loss 1024936960.0 Test MSE 7785485.25898096 Test RE 1.2471815197688303\n",
      "50 Train Loss 1023846850.0 Test MSE 7834588.440829514 Test RE 1.2511083349195162\n",
      "51 Train Loss 1023190000.0 Test MSE 7815566.694800685 Test RE 1.2495886170805721\n",
      "52 Train Loss 1021317570.0 Test MSE 7819574.242212826 Test RE 1.2499089485443446\n",
      "53 Train Loss 1019691300.0 Test MSE 7876202.849492572 Test RE 1.2544266445295225\n",
      "54 Train Loss 1019253200.0 Test MSE 7876186.99394946 Test RE 1.2544253818890005\n",
      "55 Train Loss 1020392300.0 Test MSE 7876367.783770305 Test RE 1.2544397788325232\n",
      "56 Train Loss 1021561340.0 Test MSE 7905932.191588176 Test RE 1.2567918803051805\n",
      "57 Train Loss 1020551600.0 Test MSE 7935941.3441827195 Test RE 1.259174871740708\n",
      "58 Train Loss 1019262850.0 Test MSE 7944843.705475522 Test RE 1.2598809308732781\n",
      "59 Train Loss 1019160770.0 Test MSE 7971442.617590503 Test RE 1.2619881756225457\n",
      "60 Train Loss 1020287400.0 Test MSE 7972368.378477316 Test RE 1.2620614537875288\n",
      "61 Train Loss 1021553200.0 Test MSE 7957000.828289617 Test RE 1.2608444911995493\n",
      "62 Train Loss 1022294100.0 Test MSE 7976141.729639326 Test RE 1.2623600876105432\n",
      "63 Train Loss 1022790600.0 Test MSE 7990444.4114250075 Test RE 1.2634914020011692\n",
      "64 Train Loss 1023680260.0 Test MSE 8000693.772223398 Test RE 1.2643014839251299\n",
      "65 Train Loss 1024501200.0 Test MSE 8017980.142189142 Test RE 1.2656665774677327\n",
      "66 Train Loss 1024423230.0 Test MSE 8016066.495630925 Test RE 1.2655155305094754\n",
      "67 Train Loss 1025134100.0 Test MSE 8023306.965074009 Test RE 1.2660869365959984\n",
      "68 Train Loss 1026732400.0 Test MSE 8031087.2000642475 Test RE 1.266700652802919\n",
      "69 Train Loss 1028083900.0 Test MSE 8036968.201866434 Test RE 1.2671643574895888\n",
      "70 Train Loss 1029438460.0 Test MSE 8026468.013964137 Test RE 1.2663363205847\n",
      "71 Train Loss 1031016060.0 Test MSE 8030233.317704031 Test RE 1.2666333118522142\n",
      "72 Train Loss 1032006300.0 Test MSE 8028420.028576208 Test RE 1.266490295952529\n",
      "73 Train Loss 1032933100.0 Test MSE 8020908.8049659105 Test RE 1.2658977062625951\n",
      "74 Train Loss 1034049700.0 Test MSE 8014711.911705957 Test RE 1.265408600294925\n",
      "75 Train Loss 1035011800.0 Test MSE 8017113.879714117 Test RE 1.265598204320266\n",
      "76 Train Loss 1035459600.0 Test MSE 8031552.886902893 Test RE 1.266737377424185\n",
      "77 Train Loss 1035111740.0 Test MSE 8014244.516979662 Test RE 1.2653717022793756\n",
      "78 Train Loss 1035755840.0 Test MSE 8007620.05623321 Test RE 1.2648486250221112\n",
      "79 Train Loss 1036615700.0 Test MSE 8023520.234443016 Test RE 1.266103763558305\n",
      "80 Train Loss 1037140030.0 Test MSE 8043545.739332948 Test RE 1.2676827816142064\n",
      "81 Train Loss 1037888800.0 Test MSE 8055458.2272714125 Test RE 1.268621153150407\n",
      "82 Train Loss 1038717700.0 Test MSE 8068776.41055126 Test RE 1.2696694331392198\n",
      "83 Train Loss 1039642200.0 Test MSE 8081674.8596912185 Test RE 1.2706838513221475\n",
      "84 Train Loss 1040352100.0 Test MSE 8107914.039803613 Test RE 1.272744976263341\n",
      "85 Train Loss 1040757600.0 Test MSE 8134413.506734607 Test RE 1.274823164947916\n",
      "86 Train Loss 1041236700.0 Test MSE 8151997.230379391 Test RE 1.2762002794347505\n",
      "87 Train Loss 1041628800.0 Test MSE 8167713.165307877 Test RE 1.277429856840985\n",
      "88 Train Loss 1041647400.0 Test MSE 8209635.050105014 Test RE 1.280703951189358\n",
      "89 Train Loss 1042152770.0 Test MSE 8231919.4941553315 Test RE 1.2824409610769758\n",
      "90 Train Loss 1042439200.0 Test MSE 8235923.803005704 Test RE 1.2827528364146472\n",
      "91 Train Loss 1042828800.0 Test MSE 8241010.137842859 Test RE 1.2831488759820282\n",
      "92 Train Loss 1042979500.0 Test MSE 8255873.201362017 Test RE 1.2843054655001607\n",
      "93 Train Loss 1043502700.0 Test MSE 8243327.399463524 Test RE 1.2833292654369672\n",
      "94 Train Loss 1043537860.0 Test MSE 8275210.852580504 Test RE 1.2858086938439577\n",
      "95 Train Loss 1043360640.0 Test MSE 8273265.4406790165 Test RE 1.2856575451534598\n",
      "96 Train Loss 1042237300.0 Test MSE 8263228.853452756 Test RE 1.2848774704647308\n",
      "97 Train Loss 1041512700.0 Test MSE 8263949.019368339 Test RE 1.2849334597647963\n",
      "98 Train Loss 1040891460.0 Test MSE 8267044.49101373 Test RE 1.2851740894374442\n",
      "99 Train Loss 1040687550.0 Test MSE 8267731.160159704 Test RE 1.2852274622643978\n",
      "100 Train Loss 1040402560.0 Test MSE 8278320.158737535 Test RE 1.2860502343607678\n",
      "101 Train Loss 1040731800.0 Test MSE 8290644.7138058925 Test RE 1.287007197956533\n",
      "102 Train Loss 1041162940.0 Test MSE 8299786.85167576 Test RE 1.2877165972752556\n",
      "103 Train Loss 1041144300.0 Test MSE 8313614.32158519 Test RE 1.2887888207452596\n",
      "104 Train Loss 1041154300.0 Test MSE 8326066.92232728 Test RE 1.2897536698958403\n",
      "105 Train Loss 1041439360.0 Test MSE 8335069.999528036 Test RE 1.290450794641668\n",
      "106 Train Loss 1040939500.0 Test MSE 8362801.344529209 Test RE 1.292595720841894\n",
      "107 Train Loss 1040695200.0 Test MSE 8377620.2186932815 Test RE 1.2937404530002103\n",
      "108 Train Loss 1039861800.0 Test MSE 8395843.831939014 Test RE 1.295146808120517\n",
      "109 Train Loss 1038041150.0 Test MSE 8423268.382686915 Test RE 1.2972603456216558\n",
      "110 Train Loss 1036403100.0 Test MSE 8476970.349334788 Test RE 1.3013890724064832\n",
      "111 Train Loss 1035104260.0 Test MSE 8521959.280898495 Test RE 1.3048378651599817\n",
      "112 Train Loss 1033863600.0 Test MSE 8541460.155099133 Test RE 1.306329948029404\n",
      "113 Train Loss 1032163500.0 Test MSE 8536751.249843216 Test RE 1.3059698086683058\n",
      "114 Train Loss 1030880830.0 Test MSE 8504627.798262117 Test RE 1.3035103368340661\n",
      "115 Train Loss 1021350800.0 Test MSE 8458377.382554898 Test RE 1.2999610878013859\n",
      "116 Train Loss 998472400.0 Test MSE 8407981.113623848 Test RE 1.2960826214160075\n",
      "117 Train Loss 986491100.0 Test MSE 8390594.543096077 Test RE 1.2947418659359453\n",
      "118 Train Loss 977321400.0 Test MSE 8369602.458792944 Test RE 1.293121220862909\n",
      "119 Train Loss 972421400.0 Test MSE 8365191.01631563 Test RE 1.2927803873649684\n",
      "120 Train Loss 967922240.0 Test MSE 8389982.3903824 Test RE 1.2946946348250112\n",
      "121 Train Loss 963970500.0 Test MSE 8392510.421796745 Test RE 1.2948896758894701\n",
      "122 Train Loss 959028100.0 Test MSE 8389752.244905625 Test RE 1.2946768773290143\n",
      "123 Train Loss 954760500.0 Test MSE 8392573.329068473 Test RE 1.294894528896494\n",
      "124 Train Loss 950844100.0 Test MSE 8402944.07585055 Test RE 1.2956943358642115\n",
      "125 Train Loss 947287040.0 Test MSE 8415308.337572278 Test RE 1.2966472408768697\n",
      "126 Train Loss 945189950.0 Test MSE 8415102.86872519 Test RE 1.2966314112584392\n",
      "127 Train Loss 943908500.0 Test MSE 8407132.565260377 Test RE 1.2960172182875973\n",
      "128 Train Loss 942214800.0 Test MSE 8418014.292421691 Test RE 1.2968556935407307\n",
      "129 Train Loss 939389630.0 Test MSE 8453202.11486356 Test RE 1.2995633356257708\n",
      "130 Train Loss 937439740.0 Test MSE 8491102.008176552 Test RE 1.3024733706497253\n",
      "131 Train Loss 934820030.0 Test MSE 8548728.973430917 Test RE 1.3068856759487573\n",
      "132 Train Loss 932026750.0 Test MSE 8605724.703707248 Test RE 1.3112350454213302\n",
      "133 Train Loss 931093200.0 Test MSE 8621709.808726441 Test RE 1.31245228779587\n",
      "134 Train Loss 929986400.0 Test MSE 8644062.050905941 Test RE 1.3141524877965038\n",
      "135 Train Loss 928151600.0 Test MSE 8672732.128622772 Test RE 1.3163300325888876\n",
      "136 Train Loss 927099100.0 Test MSE 8686343.416882202 Test RE 1.3173625747505147\n",
      "137 Train Loss 926810300.0 Test MSE 8696720.820628969 Test RE 1.3181492534506485\n",
      "138 Train Loss 926070140.0 Test MSE 8707772.822572375 Test RE 1.3189865554032398\n",
      "139 Train Loss 924506430.0 Test MSE 8734485.707902068 Test RE 1.3210081375490668\n",
      "140 Train Loss 922002600.0 Test MSE 8762992.107667446 Test RE 1.3231620429010773\n",
      "141 Train Loss 920754750.0 Test MSE 8804753.326652331 Test RE 1.3263111489398471\n",
      "142 Train Loss 918940350.0 Test MSE 8842293.464597018 Test RE 1.3291355861019072\n",
      "143 Train Loss 917175800.0 Test MSE 8871736.796341883 Test RE 1.3313466446207844\n",
      "144 Train Loss 916153400.0 Test MSE 8881426.857527418 Test RE 1.3320735208776562\n",
      "145 Train Loss 914294850.0 Test MSE 8897758.44381426 Test RE 1.3332976981527884\n",
      "146 Train Loss 913950660.0 Test MSE 8911388.381050674 Test RE 1.33431850636781\n",
      "147 Train Loss 913060740.0 Test MSE 8942944.018668711 Test RE 1.3366788603961033\n",
      "148 Train Loss 912084030.0 Test MSE 8966335.910242993 Test RE 1.3384258816893488\n",
      "149 Train Loss 911506000.0 Test MSE 8954746.09315829 Test RE 1.3375605824602737\n",
      "150 Train Loss 910704200.0 Test MSE 8963718.63474834 Test RE 1.338230524022198\n",
      "151 Train Loss 909754700.0 Test MSE 8972495.185354544 Test RE 1.3388855074532333\n",
      "152 Train Loss 908492000.0 Test MSE 8982741.552463453 Test RE 1.3396497763533661\n",
      "153 Train Loss 907096300.0 Test MSE 8988914.381355071 Test RE 1.3401099926816131\n",
      "154 Train Loss 905525500.0 Test MSE 9009062.557628233 Test RE 1.3416110448635172\n",
      "155 Train Loss 904448640.0 Test MSE 9028602.357845074 Test RE 1.343065170231891\n",
      "156 Train Loss 903838400.0 Test MSE 9037872.795455143 Test RE 1.343754513218643\n",
      "157 Train Loss 903195400.0 Test MSE 9047541.041104686 Test RE 1.344473060403558\n",
      "158 Train Loss 902780350.0 Test MSE 9057494.649414817 Test RE 1.3452124148621414\n",
      "159 Train Loss 902338940.0 Test MSE 9062731.56886783 Test RE 1.345601250369833\n",
      "160 Train Loss 901786200.0 Test MSE 9078803.017595667 Test RE 1.3467938368592232\n",
      "161 Train Loss 901551900.0 Test MSE 9093714.998246515 Test RE 1.3478994409573477\n",
      "162 Train Loss 901210560.0 Test MSE 9115439.835036807 Test RE 1.3495085427963351\n",
      "163 Train Loss 900986800.0 Test MSE 9141911.502422892 Test RE 1.351466640466843\n",
      "164 Train Loss 900674600.0 Test MSE 9161344.793587174 Test RE 1.3529023086114693\n",
      "165 Train Loss 900457600.0 Test MSE 9158942.421334859 Test RE 1.3527249117259579\n",
      "166 Train Loss 900074100.0 Test MSE 9175025.804135015 Test RE 1.3539121039110675\n",
      "167 Train Loss 899903500.0 Test MSE 9184567.187838638 Test RE 1.3546159078240467\n",
      "168 Train Loss 899563300.0 Test MSE 9190162.88518636 Test RE 1.355028494846784\n",
      "169 Train Loss 899272500.0 Test MSE 9208729.10930638 Test RE 1.3563965374893852\n",
      "170 Train Loss 899071100.0 Test MSE 9215337.030626163 Test RE 1.3568831059494317\n",
      "171 Train Loss 898967940.0 Test MSE 9210449.83063658 Test RE 1.3565232580936204\n",
      "172 Train Loss 898564540.0 Test MSE 9232414.378438758 Test RE 1.3581397740100876\n",
      "173 Train Loss 898321200.0 Test MSE 9243517.21198566 Test RE 1.358956173080614\n",
      "174 Train Loss 897798200.0 Test MSE 9245054.744448602 Test RE 1.359069190252743\n",
      "175 Train Loss 897557500.0 Test MSE 9257394.913395207 Test RE 1.3599759209937532\n",
      "176 Train Loss 897461900.0 Test MSE 9255340.584057571 Test RE 1.359825014962788\n",
      "177 Train Loss 897375500.0 Test MSE 9258619.64962639 Test RE 1.3600658791684812\n",
      "178 Train Loss 897246700.0 Test MSE 9280004.731746856 Test RE 1.3616356782398034\n",
      "179 Train Loss 897058600.0 Test MSE 9303316.590100585 Test RE 1.3633448556283136\n",
      "180 Train Loss 896863500.0 Test MSE 9325581.766437907 Test RE 1.3649752942557951\n",
      "181 Train Loss 896598460.0 Test MSE 9331515.733868338 Test RE 1.3654094993846335\n",
      "182 Train Loss 896069900.0 Test MSE 9341910.5464736 Test RE 1.3661697845231513\n",
      "183 Train Loss 895706100.0 Test MSE 9366977.823188389 Test RE 1.368001487649262\n",
      "184 Train Loss 895388600.0 Test MSE 9389557.47641049 Test RE 1.369649319385625\n",
      "185 Train Loss 895207940.0 Test MSE 9398225.996756963 Test RE 1.3702814095566056\n",
      "186 Train Loss 895173570.0 Test MSE 9407743.00315898 Test RE 1.3709750339264168\n",
      "187 Train Loss 895115500.0 Test MSE 9415463.232095182 Test RE 1.3715374467491055\n",
      "188 Train Loss 895004800.0 Test MSE 9433495.852707075 Test RE 1.3728502118880495\n",
      "189 Train Loss 894880640.0 Test MSE 9455202.014888901 Test RE 1.374428745853727\n",
      "190 Train Loss 894801800.0 Test MSE 9451580.28131374 Test RE 1.3741654891038322\n",
      "191 Train Loss 894779460.0 Test MSE 9448579.701175809 Test RE 1.3739473445789934\n",
      "192 Train Loss 894586600.0 Test MSE 9456791.886305712 Test RE 1.3745442945815116\n",
      "193 Train Loss 894353540.0 Test MSE 9465620.273053888 Test RE 1.3751857477266811\n",
      "194 Train Loss 894130600.0 Test MSE 9476519.137941552 Test RE 1.375977225272003\n",
      "195 Train Loss 894087600.0 Test MSE 9491497.242303725 Test RE 1.3770641957627243\n",
      "196 Train Loss 894003650.0 Test MSE 9510449.328254467 Test RE 1.378438332184497\n",
      "197 Train Loss 893877800.0 Test MSE 9511372.143953029 Test RE 1.378505206715492\n",
      "198 Train Loss 893650900.0 Test MSE 9520998.00161467 Test RE 1.379202579247515\n",
      "199 Train Loss 893527400.0 Test MSE 9528709.553229945 Test RE 1.3797610101560924\n",
      "Training time: 46.51\n",
      "Training time: 46.51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "7\n",
      "0 Train Loss 1187609500.0 Test MSE 5460835.413602291 Test RE 1.0445190554186485\n",
      "1 Train Loss 1167926300.0 Test MSE 5599654.086360646 Test RE 1.057711980363287\n",
      "2 Train Loss 1152975600.0 Test MSE 5796962.256406291 Test RE 1.0761853110218136\n",
      "3 Train Loss 1115723900.0 Test MSE 5900696.351061536 Test RE 1.0857715476463816\n",
      "4 Train Loss 1100426100.0 Test MSE 6015454.941635773 Test RE 1.0962789185386916\n",
      "5 Train Loss 1089423600.0 Test MSE 6100927.078467275 Test RE 1.1040398278751569\n",
      "6 Train Loss 1090865400.0 Test MSE 6160134.299406357 Test RE 1.1093840405801096\n",
      "7 Train Loss 1097990800.0 Test MSE 6188752.743339393 Test RE 1.1119580149880988\n",
      "8 Train Loss 1102140700.0 Test MSE 6194795.130275593 Test RE 1.11250071249661\n",
      "9 Train Loss 1106609800.0 Test MSE 6228058.033885309 Test RE 1.115483495751478\n",
      "10 Train Loss 1111349800.0 Test MSE 6319206.945839341 Test RE 1.1236165120884738\n",
      "11 Train Loss 1118233500.0 Test MSE 6364591.4385181125 Test RE 1.12764419563583\n",
      "12 Train Loss 1123030800.0 Test MSE 6395008.213566927 Test RE 1.1303355245434181\n",
      "13 Train Loss 1127203300.0 Test MSE 6398612.973962797 Test RE 1.1306540553852922\n",
      "14 Train Loss 1135384800.0 Test MSE 6443333.45056492 Test RE 1.1345982967248724\n",
      "15 Train Loss 1143587200.0 Test MSE 6499412.159811937 Test RE 1.1395250140662028\n",
      "16 Train Loss 1149948400.0 Test MSE 6517069.91195922 Test RE 1.1410719079774136\n",
      "17 Train Loss 1151983100.0 Test MSE 6524646.471264937 Test RE 1.1417350041107772\n",
      "18 Train Loss 1156279600.0 Test MSE 6552529.699860998 Test RE 1.1441720187872817\n",
      "19 Train Loss 1158460400.0 Test MSE 6594893.817012993 Test RE 1.1478647714783032\n",
      "20 Train Loss 1161813800.0 Test MSE 6648892.24630997 Test RE 1.1525545008009865\n",
      "21 Train Loss 1166838300.0 Test MSE 6686677.685721595 Test RE 1.1558248260553055\n",
      "22 Train Loss 1169402000.0 Test MSE 6754910.5601093825 Test RE 1.1617070505829297\n",
      "23 Train Loss 1173684000.0 Test MSE 6814638.010643148 Test RE 1.1668316999380093\n",
      "24 Train Loss 1179063700.0 Test MSE 6820280.707058779 Test RE 1.1673146833817445\n",
      "25 Train Loss 1184074400.0 Test MSE 6854125.899983221 Test RE 1.1702074600610821\n",
      "26 Train Loss 1188568600.0 Test MSE 6923173.872940701 Test RE 1.176086982725692\n",
      "27 Train Loss 1192615700.0 Test MSE 6939472.996508132 Test RE 1.1774705907527905\n",
      "28 Train Loss 1196026400.0 Test MSE 6957033.604439829 Test RE 1.1789594671327681\n",
      "29 Train Loss 1200086100.0 Test MSE 6970177.478026578 Test RE 1.180072641426696\n",
      "30 Train Loss 1204512000.0 Test MSE 6996663.19596579 Test RE 1.1823125726378758\n",
      "31 Train Loss 1208180500.0 Test MSE 7075826.728529947 Test RE 1.1889823791639003\n",
      "32 Train Loss 1212627700.0 Test MSE 7077714.841491254 Test RE 1.1891410025578533\n",
      "33 Train Loss 1216704500.0 Test MSE 7090185.596708812 Test RE 1.1901881597369175\n",
      "34 Train Loss 1219024500.0 Test MSE 7170524.76073924 Test RE 1.1969121995699592\n",
      "35 Train Loss 1222623600.0 Test MSE 7209191.316195065 Test RE 1.2001349935830856\n",
      "36 Train Loss 1226952000.0 Test MSE 7246276.50148463 Test RE 1.203217873160497\n",
      "37 Train Loss 1230865000.0 Test MSE 7255946.895475952 Test RE 1.2040204723614185\n",
      "38 Train Loss 1234952200.0 Test MSE 7243460.522055667 Test RE 1.202984058868509\n",
      "39 Train Loss 1238900500.0 Test MSE 7285987.125318037 Test RE 1.2065102709921185\n",
      "40 Train Loss 1241854800.0 Test MSE 7318838.816305407 Test RE 1.2092272209336696\n",
      "41 Train Loss 1244735200.0 Test MSE 7334892.982057326 Test RE 1.2105527385814834\n",
      "42 Train Loss 1248094200.0 Test MSE 7344109.160077734 Test RE 1.2113130201032474\n",
      "43 Train Loss 1251097000.0 Test MSE 7315642.152403391 Test RE 1.2089631137931445\n",
      "44 Train Loss 1253508500.0 Test MSE 7353840.165935653 Test RE 1.2121152543740403\n",
      "45 Train Loss 1256059000.0 Test MSE 7412114.454171726 Test RE 1.2169083808009091\n",
      "46 Train Loss 1259155300.0 Test MSE 7437622.45050903 Test RE 1.2190005121751364\n",
      "47 Train Loss 1261934800.0 Test MSE 7484596.200115385 Test RE 1.2228438706414313\n",
      "48 Train Loss 1264745700.0 Test MSE 7479416.999795371 Test RE 1.2224207049009892\n",
      "49 Train Loss 1266585200.0 Test MSE 7493637.007587755 Test RE 1.2235821976786354\n",
      "50 Train Loss 1268578600.0 Test MSE 7540679.531687758 Test RE 1.2274168070427771\n",
      "51 Train Loss 1269585700.0 Test MSE 7593559.548472498 Test RE 1.2317129999891092\n",
      "52 Train Loss 1271502200.0 Test MSE 7612145.434072542 Test RE 1.2332194401544354\n",
      "53 Train Loss 1272763000.0 Test MSE 7663699.377756307 Test RE 1.23738843845488\n",
      "54 Train Loss 1275236400.0 Test MSE 7660081.307609842 Test RE 1.2370963153905927\n",
      "55 Train Loss 1277123600.0 Test MSE 7653109.814146057 Test RE 1.2365332422515791\n",
      "56 Train Loss 1279041300.0 Test MSE 7649221.416241789 Test RE 1.2362190729615965\n",
      "57 Train Loss 1281402100.0 Test MSE 7661887.5011314945 Test RE 1.2372421561173599\n",
      "58 Train Loss 1283756000.0 Test MSE 7679026.32178243 Test RE 1.2386251721431651\n",
      "59 Train Loss 1286365600.0 Test MSE 7672124.206549583 Test RE 1.238068392206379\n",
      "60 Train Loss 1288662300.0 Test MSE 7654421.631906067 Test RE 1.236639214647256\n",
      "61 Train Loss 1290852100.0 Test MSE 7663052.401981029 Test RE 1.2373362066800193\n",
      "62 Train Loss 1293198600.0 Test MSE 7668914.371466484 Test RE 1.2378093758637767\n",
      "63 Train Loss 1295234800.0 Test MSE 7673855.275052881 Test RE 1.238208057588653\n",
      "64 Train Loss 1297421400.0 Test MSE 7686968.551658508 Test RE 1.239265546527381\n",
      "65 Train Loss 1299522400.0 Test MSE 7681706.029363357 Test RE 1.2388412713990145\n",
      "66 Train Loss 1301524100.0 Test MSE 7692605.101344406 Test RE 1.2397198154475688\n",
      "67 Train Loss 1303635600.0 Test MSE 7701051.219264688 Test RE 1.240400205710135\n",
      "68 Train Loss 1305704400.0 Test MSE 7704075.121216034 Test RE 1.2406437101594014\n",
      "69 Train Loss 1307641300.0 Test MSE 7723798.815235565 Test RE 1.2422308205332617\n",
      "70 Train Loss 1309577900.0 Test MSE 7719813.664876759 Test RE 1.2419103101573432\n",
      "71 Train Loss 1311516400.0 Test MSE 7724446.184747626 Test RE 1.2422828781754585\n",
      "72 Train Loss 1313241300.0 Test MSE 7733989.562021471 Test RE 1.2430500473899986\n",
      "73 Train Loss 1314995000.0 Test MSE 7734018.758567839 Test RE 1.2430523937038773\n",
      "74 Train Loss 1316624400.0 Test MSE 7740824.49205238 Test RE 1.243599200174259\n",
      "75 Train Loss 1317738100.0 Test MSE 7762622.206114215 Test RE 1.2453489209727355\n",
      "76 Train Loss 1319230800.0 Test MSE 7772775.294683577 Test RE 1.2461630792428955\n",
      "77 Train Loss 1321015800.0 Test MSE 7786951.362232837 Test RE 1.2472989441005804\n",
      "78 Train Loss 1322634200.0 Test MSE 7796519.539555136 Test RE 1.248065014998555\n",
      "79 Train Loss 1324315000.0 Test MSE 7796936.15568671 Test RE 1.2480983604592977\n",
      "80 Train Loss 1325719200.0 Test MSE 7816889.702385269 Test RE 1.2496943768626216\n",
      "81 Train Loss 1327190100.0 Test MSE 7817426.439306883 Test RE 1.2497372804741957\n",
      "82 Train Loss 1328436700.0 Test MSE 7827730.8582915235 Test RE 1.250560670101196\n",
      "83 Train Loss 1329545000.0 Test MSE 7862925.789896714 Test RE 1.253368893573292\n",
      "84 Train Loss 1330742100.0 Test MSE 7864473.714931844 Test RE 1.2534922589505686\n",
      "85 Train Loss 1331987800.0 Test MSE 7869226.803000488 Test RE 1.2538709911695476\n",
      "86 Train Loss 1333147500.0 Test MSE 7881936.162179075 Test RE 1.254883127938455\n",
      "87 Train Loss 1334367500.0 Test MSE 7883489.207913229 Test RE 1.255006752061791\n",
      "88 Train Loss 1335557100.0 Test MSE 7881221.471357231 Test RE 1.2548262336825935\n",
      "89 Train Loss 1336638300.0 Test MSE 7879058.281862747 Test RE 1.2546540133471185\n",
      "90 Train Loss 1337464200.0 Test MSE 7876980.68451481 Test RE 1.254488585093168\n",
      "91 Train Loss 1338599600.0 Test MSE 7868769.8021553615 Test RE 1.2538345817206469\n",
      "92 Train Loss 1339545100.0 Test MSE 7865059.518681326 Test RE 1.253538942735037\n",
      "93 Train Loss 1340634600.0 Test MSE 7880272.795105484 Test RE 1.254750708608353\n",
      "94 Train Loss 1341563900.0 Test MSE 7892151.666343887 Test RE 1.255696069872696\n",
      "95 Train Loss 1342253700.0 Test MSE 7912713.066451037 Test RE 1.2573307365523447\n",
      "96 Train Loss 1343094800.0 Test MSE 7909108.753443271 Test RE 1.257044341122678\n",
      "97 Train Loss 1344007700.0 Test MSE 7902864.092355759 Test RE 1.256547991521187\n",
      "98 Train Loss 1344869500.0 Test MSE 7907094.073685306 Test RE 1.256884228070347\n",
      "99 Train Loss 1345571500.0 Test MSE 7926347.683395962 Test RE 1.2584135411597064\n",
      "100 Train Loss 1346133200.0 Test MSE 7941071.9165564105 Test RE 1.2595818331663673\n",
      "101 Train Loss 1346774400.0 Test MSE 7944128.95952598 Test RE 1.2598242579493377\n",
      "102 Train Loss 1347476500.0 Test MSE 7956361.012419583 Test RE 1.2607937984479796\n",
      "103 Train Loss 1347928600.0 Test MSE 7972305.684368946 Test RE 1.2620564913993553\n",
      "104 Train Loss 1348409700.0 Test MSE 7965523.540877242 Test RE 1.2615195532950418\n",
      "105 Train Loss 1348835100.0 Test MSE 7974246.5216582585 Test RE 1.262210104252211\n",
      "106 Train Loss 1349369200.0 Test MSE 7988657.8299617 Test RE 1.263350142241717\n",
      "107 Train Loss 1350111400.0 Test MSE 7989264.492582419 Test RE 1.2633981110478871\n",
      "108 Train Loss 1350908900.0 Test MSE 7994523.338513616 Test RE 1.2638138516360171\n",
      "109 Train Loss 1351654800.0 Test MSE 7999884.886155675 Test RE 1.2642375706111844\n",
      "110 Train Loss 1352226200.0 Test MSE 8017523.731464621 Test RE 1.2656305539299924\n",
      "111 Train Loss 1353022200.0 Test MSE 8023907.731001773 Test RE 1.266134336481018\n",
      "112 Train Loss 1353512400.0 Test MSE 8033244.44597657 Test RE 1.2668707668398325\n",
      "113 Train Loss 1354172900.0 Test MSE 8033929.426151932 Test RE 1.266924777574108\n",
      "114 Train Loss 1354872700.0 Test MSE 8037280.795567836 Test RE 1.2671890000995456\n",
      "115 Train Loss 1355613000.0 Test MSE 8032427.495748769 Test RE 1.2668063472467903\n",
      "116 Train Loss 1356192300.0 Test MSE 8034750.442311925 Test RE 1.2669895117214658\n",
      "117 Train Loss 1356900900.0 Test MSE 8039739.261873935 Test RE 1.2673827909688389\n",
      "118 Train Loss 1357620600.0 Test MSE 8039848.44762854 Test RE 1.2673913969492119\n",
      "119 Train Loss 1358080000.0 Test MSE 8046919.488283487 Test RE 1.2679486093487444\n",
      "120 Train Loss 1358689400.0 Test MSE 8055824.716144411 Test RE 1.268650011238646\n",
      "121 Train Loss 1359138700.0 Test MSE 8073392.44529982 Test RE 1.2700325613223586\n",
      "122 Train Loss 1359577700.0 Test MSE 8073399.685052403 Test RE 1.2700331307681967\n",
      "123 Train Loss 1359878300.0 Test MSE 8082542.59064256 Test RE 1.2707520662733172\n",
      "124 Train Loss 1360327200.0 Test MSE 8100128.81965961 Test RE 1.2721337845634113\n",
      "125 Train Loss 1360667600.0 Test MSE 8101776.712761244 Test RE 1.272263179658563\n",
      "126 Train Loss 1361151400.0 Test MSE 8099100.580826618 Test RE 1.272053039003597\n",
      "127 Train Loss 1361373600.0 Test MSE 8104690.513170929 Test RE 1.2724919435364972\n",
      "128 Train Loss 1361731100.0 Test MSE 8116238.33084367 Test RE 1.2733981640983876\n",
      "129 Train Loss 1362128600.0 Test MSE 8130064.428634918 Test RE 1.2744823261911122\n",
      "130 Train Loss 1362564500.0 Test MSE 8137145.433065082 Test RE 1.275037220368191\n",
      "131 Train Loss 1362890500.0 Test MSE 8141183.760452003 Test RE 1.2753535708061072\n",
      "132 Train Loss 1363286300.0 Test MSE 8147415.839696788 Test RE 1.275841619243832\n",
      "133 Train Loss 1363755000.0 Test MSE 8146849.640135182 Test RE 1.2757972865664227\n",
      "134 Train Loss 1364226400.0 Test MSE 8145509.095979306 Test RE 1.2756923175886699\n",
      "135 Train Loss 1364597000.0 Test MSE 8148582.860455102 Test RE 1.2759329905675174\n",
      "136 Train Loss 1364984300.0 Test MSE 8155364.14460829 Test RE 1.2764637984952394\n",
      "137 Train Loss 1365391200.0 Test MSE 8159593.047176761 Test RE 1.2767947059411435\n",
      "138 Train Loss 1365786500.0 Test MSE 8159580.64948452 Test RE 1.276793735959323\n",
      "139 Train Loss 1366188400.0 Test MSE 8160419.2924941685 Test RE 1.2768593488060644\n",
      "140 Train Loss 1366555900.0 Test MSE 8159369.530180847 Test RE 1.2767772181038304\n",
      "141 Train Loss 1366949600.0 Test MSE 8161523.955132066 Test RE 1.2769457690643211\n",
      "142 Train Loss 1367353900.0 Test MSE 8167237.544343465 Test RE 1.2773926627541303\n",
      "143 Train Loss 1367691300.0 Test MSE 8178512.210894513 Test RE 1.278274062934803\n",
      "144 Train Loss 1368106500.0 Test MSE 8180153.1107522845 Test RE 1.2784022900790133\n",
      "145 Train Loss 1368443600.0 Test MSE 8181127.417540085 Test RE 1.2784784206187332\n",
      "146 Train Loss 1368761000.0 Test MSE 8184075.709966598 Test RE 1.2787087671540407\n",
      "147 Train Loss 1369064000.0 Test MSE 8187524.414732335 Test RE 1.2789781576570314\n",
      "148 Train Loss 1369277000.0 Test MSE 8187694.851556917 Test RE 1.2789914696076556\n",
      "149 Train Loss 1369584000.0 Test MSE 8188016.7714503575 Test RE 1.2790166127497773\n",
      "150 Train Loss 1369915100.0 Test MSE 8193756.216642992 Test RE 1.279464801853508\n",
      "151 Train Loss 1370166300.0 Test MSE 8201853.628609892 Test RE 1.2800968560026917\n",
      "152 Train Loss 1370465200.0 Test MSE 8208696.900813784 Test RE 1.2806307734035263\n",
      "153 Train Loss 1370749200.0 Test MSE 8207850.831331154 Test RE 1.2805647744666944\n",
      "154 Train Loss 1371061500.0 Test MSE 8205130.483942563 Test RE 1.2803525465764436\n",
      "155 Train Loss 1371314300.0 Test MSE 8209091.97781201 Test RE 1.2806615908207337\n",
      "156 Train Loss 1371574900.0 Test MSE 8209633.944919137 Test RE 1.2807038649847973\n",
      "157 Train Loss 1371775500.0 Test MSE 8210990.725881866 Test RE 1.2808096896078633\n",
      "158 Train Loss 1372012900.0 Test MSE 8207850.887291376 Test RE 1.2805647788320695\n",
      "159 Train Loss 1372251900.0 Test MSE 8204591.603489635 Test RE 1.2803105016455103\n",
      "160 Train Loss 1372434600.0 Test MSE 8207738.730818868 Test RE 1.2805560296405314\n",
      "161 Train Loss 1372687400.0 Test MSE 8210188.295522415 Test RE 1.2807471036346845\n",
      "162 Train Loss 1372931500.0 Test MSE 8206685.8661013 Test RE 1.2804738940154259\n",
      "163 Train Loss 1373168800.0 Test MSE 8205414.285744653 Test RE 1.2803746890163923\n",
      "164 Train Loss 1373350800.0 Test MSE 8206698.707409376 Test RE 1.2804748958177123\n",
      "165 Train Loss 1373533700.0 Test MSE 8205890.8943960965 Test RE 1.2804118735369734\n",
      "166 Train Loss 1373793900.0 Test MSE 8205319.095293136 Test RE 1.2803672622251299\n",
      "167 Train Loss 1373986000.0 Test MSE 8203136.706872806 Test RE 1.2801969797243502\n",
      "168 Train Loss 1374121500.0 Test MSE 8202226.210255417 Test RE 1.2801259308434734\n",
      "169 Train Loss 1374330800.0 Test MSE 8203196.118714576 Test RE 1.2802016156779736\n",
      "170 Train Loss 1374544100.0 Test MSE 8204804.811573979 Test RE 1.2803271368900928\n",
      "171 Train Loss 1374542800.0 Test MSE 8209662.078729859 Test RE 1.280706059421815\n",
      "172 Train Loss 1374588800.0 Test MSE 8207682.839678628 Test RE 1.2805516696175807\n",
      "173 Train Loss 1374733700.0 Test MSE 8204406.770803728 Test RE 1.280296080174398\n",
      "174 Train Loss 1374904400.0 Test MSE 8203203.235614186 Test RE 1.280202171014227\n",
      "175 Train Loss 1375081200.0 Test MSE 8201936.840541624 Test RE 1.280103349599557\n",
      "176 Train Loss 1375258800.0 Test MSE 8203181.542937702 Test RE 1.280200478319978\n",
      "177 Train Loss 1375352300.0 Test MSE 8206205.741318925 Test RE 1.280436436980279\n",
      "178 Train Loss 1375319800.0 Test MSE 8211790.159225323 Test RE 1.2808720387862556\n",
      "179 Train Loss 1373636100.0 Test MSE 8249972.993355281 Test RE 1.283846457496455\n",
      "180 Train Loss 1371032300.0 Test MSE 8246601.180586395 Test RE 1.2835840728629966\n",
      "181 Train Loss 1368958300.0 Test MSE 8247385.825691855 Test RE 1.2836451364443502\n",
      "182 Train Loss 1367547300.0 Test MSE 8257443.877807574 Test RE 1.2844276289805872\n",
      "183 Train Loss 1367316100.0 Test MSE 8259487.246522877 Test RE 1.2845865399538952\n",
      "184 Train Loss 1367082500.0 Test MSE 8256370.0598179875 Test RE 1.2843441112263267\n",
      "185 Train Loss 1366555000.0 Test MSE 8260871.893303131 Test RE 1.284694211533437\n",
      "186 Train Loss 1366306600.0 Test MSE 8269434.430715936 Test RE 1.2853598430420135\n",
      "187 Train Loss 1366233300.0 Test MSE 8273521.491071347 Test RE 1.2856774399926973\n",
      "188 Train Loss 1366248800.0 Test MSE 8277818.722440831 Test RE 1.2860112843068823\n",
      "189 Train Loss 1366253700.0 Test MSE 8277902.732879271 Test RE 1.2860178100657411\n",
      "190 Train Loss 1366318100.0 Test MSE 8275632.545391525 Test RE 1.2858414549049586\n",
      "191 Train Loss 1366280300.0 Test MSE 8275645.175050946 Test RE 1.2858424360827332\n",
      "192 Train Loss 1366229200.0 Test MSE 8278396.826783194 Test RE 1.2860561895985398\n",
      "193 Train Loss 1366169900.0 Test MSE 8280240.32157327 Test RE 1.2861993758917698\n",
      "194 Train Loss 1365811500.0 Test MSE 8280140.766136812 Test RE 1.2861916437173304\n",
      "195 Train Loss 1365601400.0 Test MSE 8279143.296261264 Test RE 1.2861141706347632\n",
      "196 Train Loss 1365409300.0 Test MSE 8279094.517100052 Test RE 1.2861103818573119\n",
      "197 Train Loss 1365257100.0 Test MSE 8279609.086705442 Test RE 1.2861503489713206\n",
      "198 Train Loss 1365252200.0 Test MSE 8282153.010272543 Test RE 1.2863479197060135\n",
      "199 Train Loss 1365280000.0 Test MSE 8286836.462412347 Test RE 1.2867115749928033\n",
      "Training time: 47.20\n",
      "Training time: 47.20\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "8\n",
      "0 Train Loss 1281267700.0 Test MSE 5275720.6772615705 Test RE 1.0266625504219598\n",
      "1 Train Loss 1129729700.0 Test MSE 6272555.421521619 Test RE 1.1194612813007208\n",
      "2 Train Loss 1095110100.0 Test MSE 6742704.357105306 Test RE 1.1606569668231215\n",
      "3 Train Loss 1050058800.0 Test MSE 7095759.917342282 Test RE 1.1906559321827455\n",
      "4 Train Loss 1024444860.0 Test MSE 7672210.435382783 Test RE 1.2380753496597547\n",
      "5 Train Loss 1011622600.0 Test MSE 7892660.493872471 Test RE 1.2557365482147769\n",
      "6 Train Loss 1011619700.0 Test MSE 8026600.806664967 Test RE 1.2663467958974006\n",
      "7 Train Loss 989514560.0 Test MSE 8307119.876683986 Test RE 1.2882853331574664\n",
      "8 Train Loss 993041540.0 Test MSE 8512695.835073331 Test RE 1.3041284871277794\n",
      "9 Train Loss 997106370.0 Test MSE 8830440.23588064 Test RE 1.3282444241253903\n",
      "10 Train Loss 1002478900.0 Test MSE 9139402.434054207 Test RE 1.3512811675000473\n",
      "11 Train Loss 1002793100.0 Test MSE 9123024.916597437 Test RE 1.3500698982563188\n",
      "12 Train Loss 1009619460.0 Test MSE 9230648.770669626 Test RE 1.3580099024134016\n",
      "13 Train Loss 1014968260.0 Test MSE 9264062.253419839 Test RE 1.360465572236545\n",
      "14 Train Loss 1021076100.0 Test MSE 9330198.095879892 Test RE 1.3653130960246602\n",
      "15 Train Loss 1029653300.0 Test MSE 9342040.6546582 Test RE 1.3661792980616687\n",
      "16 Train Loss 1037273540.0 Test MSE 9344755.78725705 Test RE 1.3663778140286906\n",
      "17 Train Loss 1044904770.0 Test MSE 9475639.325941809 Test RE 1.3759133500581038\n",
      "18 Train Loss 1053283500.0 Test MSE 9534843.493639292 Test RE 1.3802050372391634\n",
      "19 Train Loss 1060133060.0 Test MSE 9480143.45093384 Test RE 1.3762403226885727\n",
      "20 Train Loss 1066136260.0 Test MSE 9549127.416851932 Test RE 1.3812384765798744\n",
      "21 Train Loss 1073168500.0 Test MSE 9571733.74623507 Test RE 1.3828724621947586\n",
      "22 Train Loss 1076702200.0 Test MSE 9659059.600857653 Test RE 1.3891663238041017\n",
      "23 Train Loss 1080390100.0 Test MSE 9786683.643816428 Test RE 1.398313654688357\n",
      "24 Train Loss 1080290400.0 Test MSE 10005701.239607224 Test RE 1.4138736125687317\n",
      "25 Train Loss 1082672800.0 Test MSE 10110723.820995536 Test RE 1.421274445363327\n",
      "26 Train Loss 1088579800.0 Test MSE 10201944.104657017 Test RE 1.4276715117060108\n",
      "27 Train Loss 1094621300.0 Test MSE 10364146.014572881 Test RE 1.4389761142871138\n",
      "28 Train Loss 1099321700.0 Test MSE 10424385.787858872 Test RE 1.4431519528567236\n",
      "29 Train Loss 1104161000.0 Test MSE 10401920.18899267 Test RE 1.4415960453836592\n",
      "30 Train Loss 1108928900.0 Test MSE 10401712.254850436 Test RE 1.4415816365759704\n",
      "31 Train Loss 1114140700.0 Test MSE 10452830.47078074 Test RE 1.445119552470361\n",
      "32 Train Loss 1117557800.0 Test MSE 10525917.767954785 Test RE 1.4501629662512217\n",
      "33 Train Loss 1120733400.0 Test MSE 10688633.12579977 Test RE 1.4613286839642534\n",
      "34 Train Loss 1123110700.0 Test MSE 10870096.27389948 Test RE 1.4736811176855873\n",
      "35 Train Loss 1127380000.0 Test MSE 10858305.030459875 Test RE 1.472881619355873\n",
      "36 Train Loss 1131062400.0 Test MSE 10899989.703445096 Test RE 1.4757060830472295\n",
      "37 Train Loss 1133353000.0 Test MSE 11055671.787970707 Test RE 1.4862073072349142\n",
      "38 Train Loss 1136127600.0 Test MSE 11170810.390039196 Test RE 1.4939262686329033\n",
      "39 Train Loss 1138600800.0 Test MSE 11327581.573126314 Test RE 1.5043726279080598\n",
      "40 Train Loss 1140916500.0 Test MSE 11479841.749709507 Test RE 1.5144494238183714\n",
      "41 Train Loss 1142739500.0 Test MSE 11657089.050907146 Test RE 1.526096093793145\n",
      "42 Train Loss 1145111600.0 Test MSE 11664347.065868095 Test RE 1.5265711139567872\n",
      "43 Train Loss 1146868600.0 Test MSE 11757936.28244489 Test RE 1.5326831216073311\n",
      "44 Train Loss 1149926700.0 Test MSE 11888648.374327246 Test RE 1.5411789364345356\n",
      "45 Train Loss 1153118500.0 Test MSE 11974055.31859151 Test RE 1.5467048728156598\n",
      "46 Train Loss 1156490500.0 Test MSE 12105597.102134153 Test RE 1.5551773823265311\n",
      "47 Train Loss 1159396500.0 Test MSE 12068053.757988056 Test RE 1.552763957429733\n",
      "48 Train Loss 1161340900.0 Test MSE 12054225.769979186 Test RE 1.5518740974711793\n",
      "49 Train Loss 1164244600.0 Test MSE 12100883.797956197 Test RE 1.554874599340473\n",
      "50 Train Loss 1166857900.0 Test MSE 12037084.412107488 Test RE 1.5507703064277494\n",
      "51 Train Loss 1169679000.0 Test MSE 12049661.444916176 Test RE 1.5515802615742222\n",
      "52 Train Loss 1172278800.0 Test MSE 12125155.423149945 Test RE 1.5564331808850054\n",
      "53 Train Loss 1175079200.0 Test MSE 12122205.821358485 Test RE 1.556243858061138\n",
      "54 Train Loss 1177991800.0 Test MSE 12151984.26024813 Test RE 1.5581541575513898\n",
      "55 Train Loss 1180944900.0 Test MSE 12198934.983086016 Test RE 1.5611613182050517\n",
      "56 Train Loss 1183958700.0 Test MSE 12284790.714127164 Test RE 1.5666453887308232\n",
      "57 Train Loss 1186487900.0 Test MSE 12374913.37769675 Test RE 1.5723814349125864\n",
      "58 Train Loss 1188876900.0 Test MSE 12359369.068689883 Test RE 1.5713935789843803\n",
      "59 Train Loss 1191243300.0 Test MSE 12345897.02171284 Test RE 1.5705369146966668\n",
      "60 Train Loss 1193693700.0 Test MSE 12311065.12102421 Test RE 1.568319845115125\n",
      "61 Train Loss 1195944200.0 Test MSE 12302737.238812046 Test RE 1.567789306436374\n",
      "62 Train Loss 1198101000.0 Test MSE 12393260.349433284 Test RE 1.5735466048072946\n",
      "63 Train Loss 1200245000.0 Test MSE 12423510.796470901 Test RE 1.575465852669772\n",
      "64 Train Loss 1202543900.0 Test MSE 12419436.734063549 Test RE 1.5752075089291422\n",
      "65 Train Loss 1204663300.0 Test MSE 12436251.544432858 Test RE 1.576273493522042\n",
      "66 Train Loss 1206408000.0 Test MSE 12482924.582599457 Test RE 1.579228587170799\n",
      "67 Train Loss 1208318600.0 Test MSE 12486538.287581464 Test RE 1.5794571575355558\n",
      "68 Train Loss 1210132900.0 Test MSE 12494349.860963399 Test RE 1.5799511341742316\n",
      "69 Train Loss 1211914400.0 Test MSE 12588059.802737178 Test RE 1.585865029361812\n",
      "70 Train Loss 1213665500.0 Test MSE 12601796.312019968 Test RE 1.5867300677535252\n",
      "71 Train Loss 1215221800.0 Test MSE 12583943.101535564 Test RE 1.5856056936730045\n",
      "72 Train Loss 1216524500.0 Test MSE 12545114.626697302 Test RE 1.5831575653102172\n",
      "73 Train Loss 1216834700.0 Test MSE 12444377.828436945 Test RE 1.576788405680708\n",
      "74 Train Loss 1217717000.0 Test MSE 12507848.192648927 Test RE 1.580804357739299\n",
      "75 Train Loss 1218874200.0 Test MSE 12640935.314216303 Test RE 1.5891922122163271\n",
      "76 Train Loss 1220337800.0 Test MSE 12702687.944234857 Test RE 1.5930691894866515\n",
      "77 Train Loss 1221923100.0 Test MSE 12730073.599189028 Test RE 1.59478550947783\n",
      "78 Train Loss 1223214800.0 Test MSE 12711323.323018167 Test RE 1.5936105874470095\n",
      "79 Train Loss 1224322400.0 Test MSE 12789195.273646325 Test RE 1.5984845128658676\n",
      "80 Train Loss 1224011900.0 Test MSE 13135255.548733762 Test RE 1.6199666985402377\n",
      "81 Train Loss 1217804300.0 Test MSE 13267082.447106846 Test RE 1.6280754879201904\n",
      "82 Train Loss 1211364900.0 Test MSE 13354259.347761352 Test RE 1.6334157043921531\n",
      "83 Train Loss 1189432700.0 Test MSE 13118447.792012598 Test RE 1.6189299192472686\n",
      "84 Train Loss 1182443500.0 Test MSE 12906497.508761292 Test RE 1.605798413890189\n",
      "85 Train Loss 1177121300.0 Test MSE 12928794.59364043 Test RE 1.607184892792009\n",
      "86 Train Loss 1173798400.0 Test MSE 12997607.55607085 Test RE 1.6114563035436729\n",
      "87 Train Loss 1169140900.0 Test MSE 13009100.099509776 Test RE 1.6121685746093204\n",
      "88 Train Loss 1164827900.0 Test MSE 13055757.44063336 Test RE 1.6150570209759287\n",
      "89 Train Loss 1161710300.0 Test MSE 13063785.538436435 Test RE 1.6155535009079598\n",
      "90 Train Loss 1160119600.0 Test MSE 13079184.479382081 Test RE 1.6165053875573998\n",
      "91 Train Loss 1159176300.0 Test MSE 13172851.886442974 Test RE 1.6222834138855213\n",
      "92 Train Loss 1158168600.0 Test MSE 13244495.50856203 Test RE 1.626689014824088\n",
      "93 Train Loss 1155786900.0 Test MSE 13392218.922943933 Test RE 1.635735554770936\n",
      "94 Train Loss 1151948400.0 Test MSE 13440014.968241384 Test RE 1.638651877258349\n",
      "95 Train Loss 1140569500.0 Test MSE 13140758.350238364 Test RE 1.6203059923483243\n",
      "96 Train Loss 1135476000.0 Test MSE 13210813.058954937 Test RE 1.6246192587450434\n",
      "97 Train Loss 1129848300.0 Test MSE 13062946.052047802 Test RE 1.6155015918744358\n",
      "98 Train Loss 1124848100.0 Test MSE 13127687.472121535 Test RE 1.619499947113207\n",
      "99 Train Loss 1123370800.0 Test MSE 13220139.684535604 Test RE 1.6251926353459827\n",
      "100 Train Loss 1120741000.0 Test MSE 13220676.915828932 Test RE 1.6252256567622554\n",
      "101 Train Loss 1109072300.0 Test MSE 13033214.48169945 Test RE 1.6136620849083885\n",
      "102 Train Loss 1107060200.0 Test MSE 12946134.56143531 Test RE 1.6082623016754098\n",
      "103 Train Loss 1105304700.0 Test MSE 13050891.238554537 Test RE 1.6147560071766958\n",
      "104 Train Loss 1103709600.0 Test MSE 13042017.866852837 Test RE 1.6142069731566075\n",
      "105 Train Loss 1102101600.0 Test MSE 13110230.366193539 Test RE 1.6184227891085827\n",
      "106 Train Loss 1101411700.0 Test MSE 13122601.859472126 Test RE 1.6191862228852545\n",
      "107 Train Loss 1101026600.0 Test MSE 13117356.385594906 Test RE 1.6188625733507378\n",
      "108 Train Loss 1097508500.0 Test MSE 13136622.1855483 Test RE 1.6200509697802508\n",
      "109 Train Loss 1094519200.0 Test MSE 13136339.87847949 Test RE 1.6200335621738164\n",
      "110 Train Loss 1092283100.0 Test MSE 13281079.023386827 Test RE 1.6289340593469046\n",
      "111 Train Loss 1091350500.0 Test MSE 13257760.483880293 Test RE 1.6275034131333044\n",
      "112 Train Loss 1088092400.0 Test MSE 13315076.052658018 Test RE 1.6310176070849554\n",
      "113 Train Loss 1086905600.0 Test MSE 13416054.917984655 Test RE 1.6371905806897025\n",
      "114 Train Loss 1086967600.0 Test MSE 13400615.027076438 Test RE 1.6362482276237322\n",
      "115 Train Loss 1086846300.0 Test MSE 13404852.241371715 Test RE 1.6365068943489853\n",
      "116 Train Loss 1086806500.0 Test MSE 13410374.312591642 Test RE 1.6368439356297328\n",
      "117 Train Loss 1087206300.0 Test MSE 13393815.063711487 Test RE 1.6358330287754357\n",
      "118 Train Loss 1087592600.0 Test MSE 13359847.45368076 Test RE 1.6337574210330525\n",
      "119 Train Loss 1087334000.0 Test MSE 13349478.226733038 Test RE 1.6331232786913794\n",
      "120 Train Loss 1086587000.0 Test MSE 13323434.196468582 Test RE 1.6315294382235874\n",
      "121 Train Loss 1086130000.0 Test MSE 13299269.924385803 Test RE 1.6300492412739187\n",
      "122 Train Loss 1086306700.0 Test MSE 13322573.83815349 Test RE 1.6314767595163022\n",
      "123 Train Loss 1086598400.0 Test MSE 13317639.018959781 Test RE 1.6311745735944876\n",
      "124 Train Loss 1086754200.0 Test MSE 13318860.323275784 Test RE 1.6312493659384233\n",
      "125 Train Loss 1086752400.0 Test MSE 13310897.13294006 Test RE 1.6307616405968446\n",
      "126 Train Loss 1086891300.0 Test MSE 13296721.425997518 Test RE 1.6298930531177265\n",
      "127 Train Loss 1087079800.0 Test MSE 13280990.03400335 Test RE 1.6289286020312668\n",
      "128 Train Loss 1087179100.0 Test MSE 13257099.277386446 Test RE 1.627462828253056\n",
      "129 Train Loss 1087422500.0 Test MSE 13261570.658419477 Test RE 1.6277372620780053\n",
      "130 Train Loss 1087626200.0 Test MSE 13268265.782272665 Test RE 1.62814809303243\n",
      "131 Train Loss 1087828400.0 Test MSE 13244672.731663948 Test RE 1.626699898058882\n",
      "132 Train Loss 1088033500.0 Test MSE 13206506.386444284 Test RE 1.6243544274516173\n",
      "133 Train Loss 1088360700.0 Test MSE 13211799.150709875 Test RE 1.624679890659031\n",
      "134 Train Loss 1088587800.0 Test MSE 13211288.329182725 Test RE 1.6246484820115192\n",
      "135 Train Loss 1088874600.0 Test MSE 13203772.717957122 Test RE 1.6241863028851848\n",
      "136 Train Loss 1089002900.0 Test MSE 13205991.803653223 Test RE 1.62432278119511\n",
      "137 Train Loss 1089002800.0 Test MSE 13174970.940605134 Test RE 1.622413893154903\n",
      "138 Train Loss 1088788500.0 Test MSE 13152740.66302438 Test RE 1.6210445566246843\n",
      "139 Train Loss 1088707200.0 Test MSE 13166439.017236145 Test RE 1.6218884820242696\n",
      "140 Train Loss 1088144100.0 Test MSE 13169536.177476577 Test RE 1.6220792303785754\n",
      "141 Train Loss 1088092500.0 Test MSE 13159846.829735108 Test RE 1.6214824067143419\n",
      "142 Train Loss 1087939000.0 Test MSE 13150661.16631658 Test RE 1.6209164050038254\n",
      "143 Train Loss 1087107100.0 Test MSE 13167539.176423777 Test RE 1.6219562413569275\n",
      "144 Train Loss 1086048600.0 Test MSE 13230506.84317064 Test RE 1.6258297438943639\n",
      "145 Train Loss 1081994000.0 Test MSE 13194879.220426386 Test RE 1.6236392194744416\n",
      "146 Train Loss 1075449300.0 Test MSE 13241218.055586435 Test RE 1.6264877339744996\n",
      "147 Train Loss 1072113800.0 Test MSE 13270730.750913465 Test RE 1.628299324085399\n",
      "148 Train Loss 1069130600.0 Test MSE 13176192.913229542 Test RE 1.62248913048954\n",
      "149 Train Loss 1063911940.0 Test MSE 13223496.614817532 Test RE 1.6253989611569435\n",
      "150 Train Loss 1062401100.0 Test MSE 13234940.440294266 Test RE 1.626102132185382\n",
      "151 Train Loss 1061253760.0 Test MSE 13272132.379863184 Test RE 1.6283853107298116\n",
      "152 Train Loss 1057720770.0 Test MSE 13468274.490612332 Test RE 1.6403737206875404\n",
      "153 Train Loss 1055495800.0 Test MSE 13640140.94667611 Test RE 1.6508068133208011\n",
      "154 Train Loss 1054643840.0 Test MSE 13692359.811666308 Test RE 1.653963705632841\n",
      "155 Train Loss 1054137540.0 Test MSE 13769480.83839295 Test RE 1.6586150686484369\n",
      "156 Train Loss 1053320770.0 Test MSE 13794737.022722272 Test RE 1.6601354998486946\n",
      "157 Train Loss 1052496400.0 Test MSE 13843147.978999231 Test RE 1.6630459706799543\n",
      "158 Train Loss 1050969150.0 Test MSE 13941818.500083283 Test RE 1.6689623361485115\n",
      "159 Train Loss 1050391700.0 Test MSE 14009795.944422485 Test RE 1.673026147426543\n",
      "160 Train Loss 1050157000.0 Test MSE 14032902.123936765 Test RE 1.6744052294828777\n",
      "161 Train Loss 1049787840.0 Test MSE 14012713.976045782 Test RE 1.6732003715566321\n",
      "162 Train Loss 1049217860.0 Test MSE 14042014.928635595 Test RE 1.674948810964964\n",
      "163 Train Loss 1049019200.0 Test MSE 14036581.31807461 Test RE 1.674624715734207\n",
      "164 Train Loss 1048870700.0 Test MSE 14030115.753394974 Test RE 1.674238986428372\n",
      "165 Train Loss 1048818240.0 Test MSE 14072284.46714996 Test RE 1.6767531330121734\n",
      "166 Train Loss 1048848300.0 Test MSE 14057444.387693487 Test RE 1.6758687807436858\n",
      "167 Train Loss 1048921540.0 Test MSE 14045070.403326904 Test RE 1.6751310314424825\n",
      "168 Train Loss 1048861250.0 Test MSE 14075272.720364027 Test RE 1.6769311530408433\n",
      "169 Train Loss 1048440600.0 Test MSE 14085766.382551428 Test RE 1.6775561452084449\n",
      "170 Train Loss 1048163800.0 Test MSE 14126581.25567334 Test RE 1.6799848278951774\n",
      "171 Train Loss 1048098100.0 Test MSE 14150673.176789086 Test RE 1.6814167674238578\n",
      "172 Train Loss 1048070300.0 Test MSE 14131751.238596903 Test RE 1.6802922164342309\n",
      "173 Train Loss 1048001900.0 Test MSE 14113228.113416381 Test RE 1.6791906378604409\n",
      "174 Train Loss 1047909100.0 Test MSE 14102109.172349848 Test RE 1.6785290422127974\n",
      "175 Train Loss 1047586000.0 Test MSE 14105621.681062408 Test RE 1.6787380705478119\n",
      "176 Train Loss 1047336100.0 Test MSE 14068998.614408746 Test RE 1.6765573621852283\n",
      "177 Train Loss 1047151200.0 Test MSE 14025148.247640893 Test RE 1.6739425694836867\n",
      "178 Train Loss 1047003970.0 Test MSE 14005971.262566535 Test RE 1.6727977633175217\n",
      "179 Train Loss 1046811200.0 Test MSE 13965193.711432159 Test RE 1.6703608627739432\n",
      "180 Train Loss 1046611840.0 Test MSE 13930451.907357352 Test RE 1.6682818552157983\n",
      "181 Train Loss 1046400500.0 Test MSE 13946519.787265686 Test RE 1.6692437058240213\n",
      "182 Train Loss 1046266600.0 Test MSE 13967404.895109745 Test RE 1.6704930961164035\n",
      "183 Train Loss 1046227840.0 Test MSE 13965184.739757514 Test RE 1.6703603262279805\n",
      "184 Train Loss 1046171500.0 Test MSE 13949495.919433288 Test RE 1.669421801326\n",
      "185 Train Loss 1046229400.0 Test MSE 13924651.543141851 Test RE 1.6679344992958676\n",
      "186 Train Loss 1046093300.0 Test MSE 13905729.4273259 Test RE 1.6668008415192477\n",
      "187 Train Loss 1046018370.0 Test MSE 13944997.72884418 Test RE 1.6691526165844754\n",
      "188 Train Loss 1045970240.0 Test MSE 13926986.169398328 Test RE 1.668074317533302\n",
      "189 Train Loss 1046056960.0 Test MSE 13923186.833623901 Test RE 1.6678467734458882\n",
      "190 Train Loss 1046166400.0 Test MSE 13918411.102141058 Test RE 1.6675607084959965\n",
      "191 Train Loss 1046366100.0 Test MSE 13918411.102141058 Test RE 1.6675607084959965\n",
      "192 Train Loss 1046534200.0 Test MSE 13911051.094206909 Test RE 1.667119750009475\n",
      "193 Train Loss 1046724540.0 Test MSE 13911051.094206909 Test RE 1.667119750009475\n",
      "194 Train Loss 1046916300.0 Test MSE 13911051.094206909 Test RE 1.667119750009475\n",
      "195 Train Loss 1047093250.0 Test MSE 13911051.094206909 Test RE 1.667119750009475\n",
      "196 Train Loss 1047158200.0 Test MSE 13901857.74909367 Test RE 1.666568787321007\n",
      "197 Train Loss 1047229000.0 Test MSE 13912199.636997743 Test RE 1.6671885700733504\n",
      "198 Train Loss 1047203200.0 Test MSE 13913534.252603168 Test RE 1.667268535951511\n",
      "199 Train Loss 1047124540.0 Test MSE 13898450.38786933 Test RE 1.6663645358473291\n",
      "Training time: 46.85\n",
      "Training time: 46.85\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (m_lambda): Sigmoid()\n",
      ")\n",
      "9\n",
      "0 Train Loss 1267304200.0 Test MSE 5644292.096867819 Test RE 1.0619194223096537\n",
      "1 Train Loss 1265448000.0 Test MSE 5887147.5964282565 Test RE 1.084524295998425\n",
      "2 Train Loss 1252108400.0 Test MSE 6054168.140479263 Test RE 1.0998008799123244\n",
      "3 Train Loss 1174583800.0 Test MSE 6481634.876311635 Test RE 1.137965524533322\n",
      "4 Train Loss 1129992600.0 Test MSE 6998255.664137398 Test RE 1.182447114487853\n",
      "5 Train Loss 1096523100.0 Test MSE 7485857.202668207 Test RE 1.222946878489651\n",
      "6 Train Loss 1094198300.0 Test MSE 7692112.838798105 Test RE 1.2396801489504372\n",
      "7 Train Loss 1091447600.0 Test MSE 8158121.903770301 Test RE 1.2766796001524991\n",
      "8 Train Loss 1095720100.0 Test MSE 8345961.3132876605 Test RE 1.291293625969104\n",
      "9 Train Loss 1090706000.0 Test MSE 8347016.089519123 Test RE 1.2913752212906222\n",
      "10 Train Loss 1066669060.0 Test MSE 8587318.333367512 Test RE 1.3098320260453493\n",
      "11 Train Loss 1070700500.0 Test MSE 8779195.193152474 Test RE 1.324384764893108\n",
      "12 Train Loss 1075173500.0 Test MSE 8707789.66285351 Test RE 1.318987830820853\n",
      "13 Train Loss 1080699900.0 Test MSE 8589594.972437609 Test RE 1.3100056435258554\n",
      "14 Train Loss 1088980900.0 Test MSE 8838168.968351211 Test RE 1.3288255616620441\n",
      "15 Train Loss 1095448800.0 Test MSE 9390803.823041797 Test RE 1.3697402183004928\n",
      "16 Train Loss 1100842400.0 Test MSE 9556064.233458072 Test RE 1.3817400752155486\n",
      "17 Train Loss 1104811000.0 Test MSE 9925218.769718884 Test RE 1.4081757714667302\n",
      "18 Train Loss 1112112900.0 Test MSE 9949628.202066384 Test RE 1.4099062957219801\n",
      "19 Train Loss 1118256900.0 Test MSE 10087532.905905567 Test RE 1.4196435246847507\n",
      "20 Train Loss 1125021700.0 Test MSE 10446037.044783462 Test RE 1.444649875458872\n",
      "21 Train Loss 1132952600.0 Test MSE 10455158.580517547 Test RE 1.445280475848825\n",
      "22 Train Loss 1139890600.0 Test MSE 10493039.797977688 Test RE 1.4478963846114468\n",
      "23 Train Loss 1144632400.0 Test MSE 10460379.653430508 Test RE 1.4456413012182237\n",
      "24 Train Loss 1150903000.0 Test MSE 10462900.088392535 Test RE 1.4458154548121023\n",
      "25 Train Loss 1157941100.0 Test MSE 10536060.194375452 Test RE 1.450861462578878\n",
      "26 Train Loss 1164855800.0 Test MSE 10604117.670276135 Test RE 1.455539825490574\n",
      "27 Train Loss 1171667800.0 Test MSE 10506836.090550683 Test RE 1.4488479220511978\n",
      "28 Train Loss 1178514800.0 Test MSE 10534413.36908731 Test RE 1.450748070633782\n",
      "29 Train Loss 1185228200.0 Test MSE 10575462.053686867 Test RE 1.4535718349168099\n",
      "30 Train Loss 1191535000.0 Test MSE 10592298.244382339 Test RE 1.454728421744497\n",
      "31 Train Loss 1197911300.0 Test MSE 10542898.511771265 Test RE 1.4513322192784737\n",
      "32 Train Loss 1203376500.0 Test MSE 10522581.11421263 Test RE 1.4499331014871832\n",
      "33 Train Loss 1208303200.0 Test MSE 10590915.701072082 Test RE 1.4546334805601753\n",
      "34 Train Loss 1214338200.0 Test MSE 10615104.987509882 Test RE 1.4562936994974436\n",
      "35 Train Loss 1220318300.0 Test MSE 10622853.665002193 Test RE 1.4568251257845557\n",
      "36 Train Loss 1225978800.0 Test MSE 10642696.085590813 Test RE 1.4581850923040056\n",
      "37 Train Loss 1231475100.0 Test MSE 10648381.08433817 Test RE 1.458574498973898\n",
      "38 Train Loss 1237146100.0 Test MSE 10800192.165954638 Test RE 1.468934953665043\n",
      "39 Train Loss 1241711400.0 Test MSE 10958556.755498823 Test RE 1.4796653514188807\n",
      "40 Train Loss 1245445200.0 Test MSE 10948887.56417709 Test RE 1.4790124221582184\n",
      "41 Train Loss 1250014500.0 Test MSE 10919173.301565787 Test RE 1.4770041075543303\n",
      "42 Train Loss 1254963600.0 Test MSE 10935590.662378978 Test RE 1.4781140542925575\n",
      "43 Train Loss 1260054400.0 Test MSE 10886791.492203457 Test RE 1.474812385872595\n",
      "44 Train Loss 1264542000.0 Test MSE 10858768.281174578 Test RE 1.4729130379881388\n",
      "45 Train Loss 1268534100.0 Test MSE 10922177.8392255 Test RE 1.4772073010155904\n",
      "46 Train Loss 1272770700.0 Test MSE 10924822.884318637 Test RE 1.4773861592731123\n",
      "47 Train Loss 1276908800.0 Test MSE 10922178.74161811 Test RE 1.4772073620391766\n",
      "48 Train Loss 1280601700.0 Test MSE 11034903.541187467 Test RE 1.4848107195885227\n",
      "49 Train Loss 1282457200.0 Test MSE 11330622.478510508 Test RE 1.5045745398438761\n",
      "50 Train Loss 1285557900.0 Test MSE 11219923.829160083 Test RE 1.4972067552157227\n",
      "51 Train Loss 1289339300.0 Test MSE 11198887.216441141 Test RE 1.495802515030686\n",
      "52 Train Loss 1292920400.0 Test MSE 11164437.62465981 Test RE 1.4935000775387344\n",
      "53 Train Loss 1295817100.0 Test MSE 11280530.598509217 Test RE 1.501245047131071\n",
      "54 Train Loss 1297571100.0 Test MSE 11581601.376971934 Test RE 1.5211468070416914\n",
      "55 Train Loss 1300462200.0 Test MSE 11705908.454193396 Test RE 1.5292883684370737\n",
      "56 Train Loss 1295753000.0 Test MSE 11594391.487203171 Test RE 1.5219865124600611\n",
      "57 Train Loss 1297654100.0 Test MSE 11595747.986444715 Test RE 1.522075543142215\n",
      "58 Train Loss 1300217900.0 Test MSE 11563743.823076885 Test RE 1.5199736342116146\n",
      "59 Train Loss 1303470700.0 Test MSE 11621560.998147357 Test RE 1.523768728993115\n",
      "60 Train Loss 1306693800.0 Test MSE 11651612.008434858 Test RE 1.5257375362184844\n",
      "61 Train Loss 1309867500.0 Test MSE 11662326.080561943 Test RE 1.5264388600286383\n",
      "62 Train Loss 1311408900.0 Test MSE 11640434.59020333 Test RE 1.5250055388586594\n",
      "63 Train Loss 1311816800.0 Test MSE 11800651.567599194 Test RE 1.5354646320004453\n",
      "64 Train Loss 1314241900.0 Test MSE 11926241.250943892 Test RE 1.543613680040011\n",
      "65 Train Loss 1316877600.0 Test MSE 11915311.154321054 Test RE 1.5429061765716916\n",
      "66 Train Loss 1319563900.0 Test MSE 11884933.79478461 Test RE 1.5409381488018332\n",
      "67 Train Loss 1321887100.0 Test MSE 11882786.609926017 Test RE 1.5407989461536773\n",
      "68 Train Loss 1322746500.0 Test MSE 11876535.449304497 Test RE 1.5403936098848448\n",
      "69 Train Loss 1323324200.0 Test MSE 11842783.665366389 Test RE 1.5382032394996363\n",
      "70 Train Loss 1325329300.0 Test MSE 11846395.670731442 Test RE 1.5384377947754664\n",
      "71 Train Loss 1327680100.0 Test MSE 11869462.355861899 Test RE 1.539934849387847\n",
      "72 Train Loss 1330071700.0 Test MSE 11880257.951127125 Test RE 1.540634996305966\n",
      "73 Train Loss 1332260700.0 Test MSE 11888536.818746518 Test RE 1.5411717056918488\n",
      "74 Train Loss 1334409100.0 Test MSE 11905871.924344515 Test RE 1.542294915500423\n",
      "75 Train Loss 1336109000.0 Test MSE 11933251.626351703 Test RE 1.5440672899159087\n",
      "76 Train Loss 1337679000.0 Test MSE 11857979.574349713 Test RE 1.5391897855582515\n",
      "77 Train Loss 1339229800.0 Test MSE 11843548.20025944 Test RE 1.5382528896116\n",
      "78 Train Loss 1341156400.0 Test MSE 11857429.450425275 Test RE 1.539154081543883\n",
      "79 Train Loss 1342920000.0 Test MSE 11887869.953359442 Test RE 1.5411284805038117\n",
      "80 Train Loss 1344769400.0 Test MSE 11883984.785407778 Test RE 1.540876625785756\n",
      "81 Train Loss 1346628700.0 Test MSE 11855845.003137695 Test RE 1.5390512434880745\n",
      "82 Train Loss 1348180200.0 Test MSE 11730327.741054008 Test RE 1.5308826349659224\n",
      "83 Train Loss 1349427700.0 Test MSE 11512347.793926327 Test RE 1.5165920474500818\n",
      "84 Train Loss 1350918900.0 Test MSE 11512662.691589754 Test RE 1.5166127890066674\n",
      "85 Train Loss 1352609400.0 Test MSE 11499201.79744913 Test RE 1.5157258988203794\n",
      "86 Train Loss 1354105600.0 Test MSE 11414615.827188928 Test RE 1.5101409117136357\n",
      "87 Train Loss 1355668900.0 Test MSE 11417337.320808453 Test RE 1.51032092626596\n",
      "88 Train Loss 1357260400.0 Test MSE 11388868.0860486 Test RE 1.5084367514776087\n",
      "89 Train Loss 1358664700.0 Test MSE 11333530.111752292 Test RE 1.5047675773549196\n",
      "90 Train Loss 1359733500.0 Test MSE 11359444.586413708 Test RE 1.5064869443722717\n",
      "91 Train Loss 1360447900.0 Test MSE 11531511.15463421 Test RE 1.5178537760096726\n",
      "92 Train Loss 1361445400.0 Test MSE 11582343.85111698 Test RE 1.5211955651554336\n",
      "93 Train Loss 1362670000.0 Test MSE 11516333.530494481 Test RE 1.5168545574692398\n",
      "94 Train Loss 1363943800.0 Test MSE 11572323.401896045 Test RE 1.5205373926206904\n",
      "95 Train Loss 1364463600.0 Test MSE 11466858.547098355 Test RE 1.5135927932732935\n",
      "96 Train Loss 1348830100.0 Test MSE 10618390.27413576 Test RE 1.456519037452117\n",
      "97 Train Loss 1325768300.0 Test MSE 10641588.467394171 Test RE 1.4581092114203493\n",
      "98 Train Loss 1316697200.0 Test MSE 10363642.397327803 Test RE 1.4389411523139217\n",
      "99 Train Loss 1304315800.0 Test MSE 10270248.87371096 Test RE 1.4324428616937206\n",
      "100 Train Loss 1296879400.0 Test MSE 10139570.405368747 Test RE 1.423300497721176\n",
      "101 Train Loss 1293002800.0 Test MSE 10093662.21272366 Test RE 1.4200747554645692\n",
      "102 Train Loss 1290530800.0 Test MSE 10153329.645575158 Test RE 1.4242658687140897\n",
      "103 Train Loss 1281620100.0 Test MSE 9920323.282988584 Test RE 1.4078284463230337\n",
      "104 Train Loss 1276281000.0 Test MSE 10025097.560551656 Test RE 1.4152433650758212\n",
      "105 Train Loss 1274543400.0 Test MSE 10329123.644826679 Test RE 1.4365427734117624\n",
      "106 Train Loss 1269269600.0 Test MSE 10555339.344334688 Test RE 1.4521882674377087\n",
      "107 Train Loss 1265658800.0 Test MSE 10618596.886321753 Test RE 1.4565332078259037\n",
      "108 Train Loss 1263039000.0 Test MSE 10802052.983302305 Test RE 1.4690614931688772\n",
      "109 Train Loss 1261813200.0 Test MSE 10960494.755672289 Test RE 1.4797961836534925\n",
      "110 Train Loss 1260812700.0 Test MSE 10962318.030459208 Test RE 1.4799192603455087\n",
      "111 Train Loss 1259244800.0 Test MSE 11009085.449222455 Test RE 1.4830727148707097\n",
      "112 Train Loss 1257748600.0 Test MSE 10977452.451910596 Test RE 1.4809404858096396\n",
      "113 Train Loss 1254353800.0 Test MSE 10926923.91117466 Test RE 1.4775282155245226\n",
      "114 Train Loss 1249195100.0 Test MSE 11119572.28647419 Test RE 1.4904961716647582\n",
      "115 Train Loss 1247138000.0 Test MSE 11167898.222018225 Test RE 1.493731526813276\n",
      "116 Train Loss 1245901800.0 Test MSE 11256438.295108307 Test RE 1.499641054166872\n",
      "117 Train Loss 1244156000.0 Test MSE 11490847.872151596 Test RE 1.515175227490976\n",
      "118 Train Loss 1242568800.0 Test MSE 11538351.920669034 Test RE 1.5183039226978092\n",
      "119 Train Loss 1242230900.0 Test MSE 11620803.53279095 Test RE 1.523719070395995\n",
      "120 Train Loss 1240486900.0 Test MSE 11795068.338108923 Test RE 1.5351013526670347\n",
      "121 Train Loss 1238371200.0 Test MSE 11917467.981677918 Test RE 1.5430458133645624\n",
      "122 Train Loss 1237783900.0 Test MSE 11848117.08115152 Test RE 1.5385495666056954\n",
      "123 Train Loss 1237670500.0 Test MSE 11861895.124597138 Test RE 1.5394438877631835\n",
      "124 Train Loss 1237701100.0 Test MSE 11971569.234774413 Test RE 1.5465442990809453\n",
      "125 Train Loss 1236260100.0 Test MSE 12131837.747814925 Test RE 1.556862006697616\n",
      "126 Train Loss 1234857000.0 Test MSE 12045526.723212454 Test RE 1.5513140340520837\n",
      "127 Train Loss 1232412300.0 Test MSE 12108696.74948576 Test RE 1.5553764717592942\n",
      "128 Train Loss 1231028700.0 Test MSE 12185110.16748094 Test RE 1.560276450563581\n",
      "129 Train Loss 1229722100.0 Test MSE 12335644.371359564 Test RE 1.569884653049548\n",
      "130 Train Loss 1228670200.0 Test MSE 12364615.550997743 Test RE 1.5717270674431025\n",
      "131 Train Loss 1228340400.0 Test MSE 12370068.77062576 Test RE 1.572073622014241\n",
      "132 Train Loss 1227813200.0 Test MSE 12349641.030083315 Test RE 1.570775036625473\n",
      "133 Train Loss 1227447900.0 Test MSE 12422507.610996298 Test RE 1.5754022427775314\n",
      "134 Train Loss 1226651800.0 Test MSE 12475768.767190937 Test RE 1.578775877224125\n",
      "135 Train Loss 1226571800.0 Test MSE 12421509.244290471 Test RE 1.5753389358833394\n",
      "136 Train Loss 1226527200.0 Test MSE 12372911.616088256 Test RE 1.572254255837045\n",
      "137 Train Loss 1226294800.0 Test MSE 12331082.873399384 Test RE 1.5695943687500886\n",
      "138 Train Loss 1226393500.0 Test MSE 12353192.726669181 Test RE 1.571000894011187\n",
      "139 Train Loss 1226384400.0 Test MSE 12367583.595826145 Test RE 1.5719156975084891\n",
      "140 Train Loss 1226627200.0 Test MSE 12395731.597606037 Test RE 1.5737034816190107\n",
      "141 Train Loss 1227015800.0 Test MSE 12415945.868568009 Test RE 1.5749861130591944\n",
      "142 Train Loss 1227334100.0 Test MSE 12452473.08422764 Test RE 1.5773011846418872\n",
      "143 Train Loss 1227447000.0 Test MSE 12582004.222629197 Test RE 1.585483537372862\n",
      "144 Train Loss 1227571200.0 Test MSE 12653771.440585606 Test RE 1.5899988731028547\n",
      "145 Train Loss 1227436500.0 Test MSE 12650559.02061581 Test RE 1.5897970333441114\n",
      "146 Train Loss 1226988300.0 Test MSE 12611729.615266778 Test RE 1.5873553106074767\n",
      "147 Train Loss 1226897400.0 Test MSE 12617096.660989834 Test RE 1.5876930320225362\n",
      "148 Train Loss 1226954000.0 Test MSE 12609942.814564073 Test RE 1.5872428602086122\n",
      "149 Train Loss 1227195300.0 Test MSE 12581389.400359496 Test RE 1.585444799407177\n",
      "150 Train Loss 1227295500.0 Test MSE 12591223.715304056 Test RE 1.586064314364189\n",
      "151 Train Loss 1227403100.0 Test MSE 12607878.298390964 Test RE 1.5871129221613574\n",
      "152 Train Loss 1227443100.0 Test MSE 12647192.645126428 Test RE 1.5895854928958435\n",
      "153 Train Loss 1227565700.0 Test MSE 12695348.700528141 Test RE 1.5926089084667612\n",
      "154 Train Loss 1227830700.0 Test MSE 12677950.229223205 Test RE 1.5915172306772765\n",
      "155 Train Loss 1228145500.0 Test MSE 12685774.6854758 Test RE 1.5920082736276684\n",
      "156 Train Loss 1228459400.0 Test MSE 12718639.479665192 Test RE 1.5940691324483303\n",
      "157 Train Loss 1228744700.0 Test MSE 12697568.269843198 Test RE 1.5927481228930924\n",
      "158 Train Loss 1228961500.0 Test MSE 12729694.32534346 Test RE 1.59476175215492\n",
      "159 Train Loss 1229094700.0 Test MSE 12783523.454193158 Test RE 1.5981300214072998\n",
      "160 Train Loss 1229258100.0 Test MSE 12764876.783989353 Test RE 1.5969640409030663\n",
      "161 Train Loss 1229476400.0 Test MSE 12769528.044234095 Test RE 1.597254964934741\n",
      "162 Train Loss 1229679500.0 Test MSE 12787137.388079856 Test RE 1.5983559031107475\n",
      "163 Train Loss 1229928000.0 Test MSE 12806178.05981491 Test RE 1.599545475421909\n",
      "164 Train Loss 1229838600.0 Test MSE 12836069.15265925 Test RE 1.6014111489598213\n",
      "165 Train Loss 1229070500.0 Test MSE 12736099.21050422 Test RE 1.595162900098013\n",
      "166 Train Loss 1228914600.0 Test MSE 12658434.44074245 Test RE 1.5902918087747546\n",
      "167 Train Loss 1228826200.0 Test MSE 12652254.8596978 Test RE 1.5899035879078471\n",
      "168 Train Loss 1228826000.0 Test MSE 12646546.997850629 Test RE 1.5895449176998007\n",
      "169 Train Loss 1228686300.0 Test MSE 12658244.382271856 Test RE 1.5902798701118448\n",
      "170 Train Loss 1228441200.0 Test MSE 12660484.608566336 Test RE 1.5904205858802567\n",
      "171 Train Loss 1227492200.0 Test MSE 12791724.850729017 Test RE 1.598642587310092\n",
      "172 Train Loss 1227263200.0 Test MSE 12918780.741464453 Test RE 1.6065623587496807\n",
      "173 Train Loss 1227233400.0 Test MSE 12932959.425993705 Test RE 1.6074437381395152\n",
      "174 Train Loss 1227118300.0 Test MSE 12939156.780327363 Test RE 1.6078288280853685\n",
      "175 Train Loss 1227104600.0 Test MSE 13035333.784710595 Test RE 1.6137932766381209\n",
      "176 Train Loss 1227289000.0 Test MSE 13059807.242346535 Test RE 1.6153074910686207\n",
      "177 Train Loss 1227442200.0 Test MSE 13064716.995164234 Test RE 1.6156110949089648\n",
      "178 Train Loss 1227526500.0 Test MSE 13178413.332713382 Test RE 1.62262583366088\n",
      "179 Train Loss 1227445600.0 Test MSE 13258621.060701411 Test RE 1.6275562338562144\n",
      "180 Train Loss 1227513100.0 Test MSE 13236670.174116798 Test RE 1.62620839001003\n",
      "181 Train Loss 1227546100.0 Test MSE 13263828.419602923 Test RE 1.6278758160131928\n",
      "182 Train Loss 1227505900.0 Test MSE 13273754.556672389 Test RE 1.6284848217994017\n",
      "183 Train Loss 1227378200.0 Test MSE 13270148.28226703 Test RE 1.6282635896662365\n",
      "184 Train Loss 1226494100.0 Test MSE 13305444.82439704 Test RE 1.6304276162921378\n",
      "185 Train Loss 1225302800.0 Test MSE 13227220.384681048 Test RE 1.625627803262642\n",
      "186 Train Loss 1225067500.0 Test MSE 13315054.68166371 Test RE 1.6310162981745953\n",
      "187 Train Loss 1224863000.0 Test MSE 13366545.361554608 Test RE 1.634166908699313\n",
      "188 Train Loss 1224875300.0 Test MSE 13322395.587292816 Test RE 1.6314658452172779\n",
      "189 Train Loss 1225052700.0 Test MSE 13339949.700878812 Test RE 1.6325403332413413\n",
      "190 Train Loss 1225190300.0 Test MSE 13363656.822888985 Test RE 1.6339903256996913\n",
      "191 Train Loss 1225082000.0 Test MSE 13367019.825825106 Test RE 1.6341959119648832\n",
      "192 Train Loss 1224127500.0 Test MSE 13384822.540175484 Test RE 1.635283792547119\n",
      "193 Train Loss 1223507600.0 Test MSE 13336243.968478527 Test RE 1.6323135641025748\n",
      "194 Train Loss 1222917900.0 Test MSE 13286620.996935932 Test RE 1.629273887454744\n",
      "195 Train Loss 1222518100.0 Test MSE 13244184.489275342 Test RE 1.6266699150166646\n",
      "196 Train Loss 1222409000.0 Test MSE 13186537.660673369 Test RE 1.6231259209237685\n",
      "197 Train Loss 1222469800.0 Test MSE 13179148.248547457 Test RE 1.6226710772256003\n",
      "198 Train Loss 1222480900.0 Test MSE 13240246.11246064 Test RE 1.6264280384624838\n",
      "199 Train Loss 1222477000.0 Test MSE 13257384.002962088 Test RE 1.6274803048440099\n",
      "Training time: 48.05\n",
      "Training time: 48.05\n"
     ]
    }
   ],
   "source": [
    " \n",
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers)\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "  optimizer_lambda = torch.optim.Adam(PINN.parameters(), lr=5e-3)\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "e199619a-d416-48f4-91f7-2c23d1e79435"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1458/2488343543.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_tanh_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_FODE_tanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
