{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "3df10486-4078-44cd-95da-12a75fb13c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "515a82ba-2a23-4124-c9e1-230f67f43912"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "d35a8c58-7c75-4550-d489-9565724f04e6"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "7b44eee8-32ab-4621-ca04-81e30b53601d"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"high\"\n",
    "label = \"1D_FODE_stanALR_\" +level\n",
    "extent = 100.0\n",
    "\n",
    "x = np.linspace(extent,-1.0*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "             \n",
    "        self.lambdas = torch.ones((1,),device = device)\n",
    "        self.lambda_alpha = 0.1\n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) + self.beta[:,i]*z*self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def lambda_update(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc1.backward()\n",
    "        bc1_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc1_grads.append(param.grad.view(-1))\n",
    "        bc1_grads = torch.cat(bc1_grads)\n",
    "        bc1_grads = torch.mean(torch.abs(bc1_grads))        \n",
    "    \n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        loss_f.backward()\n",
    "        f_grads = []\n",
    "        for param in self.parameters():\n",
    "            f_grads.append(param.grad.view(-1))   \n",
    "        f_grads = torch.cat(f_grads)\n",
    "        f_grads = torch.max(torch.abs(f_grads))\n",
    "    \n",
    "        self.lambdas[0] = (1.0-self.lambda_alpha)*self.lambdas[0] + self.lambda_alpha*f_grads/bc1_grads\n",
    "        \n",
    "        return None\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    PINN.lambda_update(x_bc1_train,y_bc1_train,x_coll_train,f_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fAcpqTqePPt9"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    x_coll_np_array = colloc_pts(N_f,123)\n",
    "    x_coll = torch.from_numpy(x_coll_np_array).float().to(device)\n",
    "\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(i)        \n",
    "    \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "3645d237-1d2a-45c9-8d9f-de486f1ca919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 573571.75 Test MSE 3785705.5725180656 Test RE 0.8696815180956182\n",
      "1 Train Loss 414400.3 Test MSE 4436085.1459558485 Test RE 0.941427239940256\n",
      "2 Train Loss 225778.34 Test MSE 2470844.4154860983 Test RE 0.7026022292770496\n",
      "3 Train Loss 189601.94 Test MSE 1685397.5982745844 Test RE 0.5802805433187308\n",
      "4 Train Loss 180357.78 Test MSE 1176179.997556267 Test RE 0.48475658616784223\n",
      "5 Train Loss 162287.75 Test MSE 565995.282538203 Test RE 0.3362739531558954\n",
      "6 Train Loss 151694.28 Test MSE 165021.76681001973 Test RE 0.1815755799429728\n",
      "7 Train Loss 147366.88 Test MSE 72394.26465463873 Test RE 0.12026490269027247\n",
      "8 Train Loss 145084.4 Test MSE 53494.64547806145 Test RE 0.10338129796810208\n",
      "9 Train Loss 142354.06 Test MSE 35774.85026251155 Test RE 0.08454262649791745\n",
      "10 Train Loss 137997.47 Test MSE 17099.47014640504 Test RE 0.05844914334063968\n",
      "11 Train Loss 136458.05 Test MSE 19565.1434467145 Test RE 0.06252134925747733\n",
      "12 Train Loss 134954.97 Test MSE 27875.616140328842 Test RE 0.07462752891356536\n",
      "13 Train Loss 134049.83 Test MSE 23326.51034712091 Test RE 0.06826714021918805\n",
      "14 Train Loss 131597.86 Test MSE 21115.224465387528 Test RE 0.06495082546580723\n",
      "15 Train Loss 129755.41 Test MSE 24383.7339085032 Test RE 0.06979702773474929\n",
      "16 Train Loss 128440.95 Test MSE 36619.174860713945 Test RE 0.08553445661231651\n",
      "17 Train Loss 126976.72 Test MSE 38064.31474660167 Test RE 0.08720589257364741\n",
      "18 Train Loss 126312.61 Test MSE 27972.264444326865 Test RE 0.07475678853437671\n",
      "19 Train Loss 125274.94 Test MSE 33083.430554257124 Test RE 0.08130028951328072\n",
      "20 Train Loss 124282.47 Test MSE 18650.331630258628 Test RE 0.06104218952553725\n",
      "21 Train Loss 123536.65 Test MSE 19866.375131795456 Test RE 0.06300081092762941\n",
      "22 Train Loss 122897.164 Test MSE 17479.211279599425 Test RE 0.05909459214564644\n",
      "23 Train Loss 121889.94 Test MSE 8003.204182373497 Test RE 0.03998699534829013\n",
      "24 Train Loss 121056.516 Test MSE 8347.665679513102 Test RE 0.04083845912517445\n",
      "25 Train Loss 120787.2 Test MSE 13568.959732150868 Test RE 0.05206670570832248\n",
      "26 Train Loss 120472.93 Test MSE 13507.13913977605 Test RE 0.0519479615576818\n",
      "27 Train Loss 120094.26 Test MSE 12903.913062315161 Test RE 0.05077472008406509\n",
      "28 Train Loss 119687.484 Test MSE 14824.304103399569 Test RE 0.05442193526275775\n",
      "29 Train Loss 119273.65 Test MSE 11603.343669789781 Test RE 0.048148016576586364\n",
      "30 Train Loss 118686.23 Test MSE 2769.9656858361145 Test RE 0.02352469590634719\n",
      "31 Train Loss 118433.91 Test MSE 2507.3535659745185 Test RE 0.022381779511217233\n",
      "32 Train Loss 117719.01 Test MSE 3102.011240504743 Test RE 0.024894792299654783\n",
      "33 Train Loss 117515.62 Test MSE 2352.0681875109485 Test RE 0.021677628916439356\n",
      "34 Train Loss 117095.18 Test MSE 1942.794322291416 Test RE 0.01970154279884518\n",
      "35 Train Loss 116830.66 Test MSE 2139.884081128031 Test RE 0.020676734329781683\n",
      "36 Train Loss 116528.02 Test MSE 4287.395983214062 Test RE 0.029267364881186808\n",
      "37 Train Loss 116122.59 Test MSE 7209.662641509959 Test RE 0.03795284138092621\n",
      "38 Train Loss 115737.7 Test MSE 5665.0174762722045 Test RE 0.033642437219682506\n",
      "39 Train Loss 115352.95 Test MSE 9389.368776991456 Test RE 0.04331167923141771\n",
      "40 Train Loss 115144.97 Test MSE 11848.073782319347 Test RE 0.04865312033396085\n",
      "41 Train Loss 114979.234 Test MSE 9189.395341173033 Test RE 0.04284797398084859\n",
      "42 Train Loss 114678.92 Test MSE 6461.32250449491 Test RE 0.03592919881087815\n",
      "43 Train Loss 114430.55 Test MSE 7285.755552860968 Test RE 0.038152598445700715\n",
      "44 Train Loss 114281.76 Test MSE 6572.327901805564 Test RE 0.03623651598091833\n",
      "45 Train Loss 113816.08 Test MSE 5688.052852013016 Test RE 0.03371076710406227\n",
      "46 Train Loss 112969.375 Test MSE 6031.382938807328 Test RE 0.03471324993511319\n",
      "47 Train Loss 112573.8 Test MSE 5644.39941315911 Test RE 0.03358115989949409\n",
      "48 Train Loss 112172.37 Test MSE 6016.7044899791945 Test RE 0.034670983753546075\n",
      "49 Train Loss 111348.305 Test MSE 5991.256858016475 Test RE 0.03459758565585949\n",
      "50 Train Loss 110392.26 Test MSE 7104.711245082447 Test RE 0.03767558804054855\n",
      "51 Train Loss 109775.89 Test MSE 8521.99662784724 Test RE 0.04126268672663521\n",
      "52 Train Loss 108981.07 Test MSE 9364.449407134902 Test RE 0.04325416648235277\n",
      "53 Train Loss 108387.98 Test MSE 13366.924871420315 Test RE 0.05167762869701506\n",
      "54 Train Loss 107054.58 Test MSE 12434.137929293081 Test RE 0.04984190854399764\n",
      "55 Train Loss 106000.08 Test MSE 12005.598088463223 Test RE 0.048975482561578285\n",
      "56 Train Loss 105076.77 Test MSE 13905.953155583418 Test RE 0.05270929466372695\n",
      "57 Train Loss 104789.58 Test MSE 11168.3598535286 Test RE 0.04723691462759007\n",
      "58 Train Loss 104544.37 Test MSE 10089.954205783228 Test RE 0.04489845752997517\n",
      "59 Train Loss 104337.625 Test MSE 8574.001900659538 Test RE 0.04138839749221199\n",
      "60 Train Loss 104068.016 Test MSE 6334.911684266153 Test RE 0.03557599914561437\n",
      "61 Train Loss 103551.83 Test MSE 5845.975261636301 Test RE 0.03417553408110581\n",
      "62 Train Loss 102792.08 Test MSE 7792.972561731949 Test RE 0.03945830243594534\n",
      "63 Train Loss 102640.38 Test MSE 6785.609016178043 Test RE 0.03681978428108734\n",
      "64 Train Loss 102571.69 Test MSE 6242.828000225846 Test RE 0.035316487936833806\n",
      "65 Train Loss 102159.26 Test MSE 4647.8240415119435 Test RE 0.030472750980922402\n",
      "66 Train Loss 101433.6 Test MSE 4235.717869669515 Test RE 0.02909044308962555\n",
      "67 Train Loss 100879.99 Test MSE 3800.513639486313 Test RE 0.027555479417683056\n",
      "68 Train Loss 100626.18 Test MSE 3368.468687772164 Test RE 0.025941977658354768\n",
      "69 Train Loss 100338.37 Test MSE 3555.1944239106006 Test RE 0.026651306367533094\n",
      "70 Train Loss 99760.086 Test MSE 5687.853938267021 Test RE 0.03371017765862598\n",
      "71 Train Loss 99037.73 Test MSE 14669.628839219624 Test RE 0.05413727434770501\n",
      "72 Train Loss 98343.4 Test MSE 17161.937573721898 Test RE 0.05855580860765872\n",
      "73 Train Loss 97866.2 Test MSE 8545.88976462059 Test RE 0.041320490372234016\n",
      "74 Train Loss 97604.91 Test MSE 8663.984398185348 Test RE 0.04160501227054364\n",
      "75 Train Loss 97563.305 Test MSE 9165.900578264209 Test RE 0.042793163667321624\n",
      "76 Train Loss 97456.055 Test MSE 9220.463296667058 Test RE 0.04292034412336953\n",
      "77 Train Loss 96111.79 Test MSE 11561.290351774802 Test RE 0.04806068736274387\n",
      "78 Train Loss 95353.57 Test MSE 9535.50421067626 Test RE 0.04364742775292616\n",
      "79 Train Loss 94988.016 Test MSE 8346.869788637348 Test RE 0.04083651224966372\n",
      "80 Train Loss 94497.58 Test MSE 7787.153592109024 Test RE 0.03944356803652684\n",
      "81 Train Loss 94280.98 Test MSE 7437.066460610971 Test RE 0.038546740037089786\n",
      "82 Train Loss 94157.664 Test MSE 6686.822789647545 Test RE 0.03655078684286422\n",
      "83 Train Loss 93829.44 Test MSE 5028.274227335728 Test RE 0.031695404675493734\n",
      "84 Train Loss 93310.21 Test MSE 3630.52539038288 Test RE 0.02693218337671181\n",
      "85 Train Loss 92698.266 Test MSE 3821.405355912484 Test RE 0.02763111291653176\n",
      "86 Train Loss 92354.13 Test MSE 5347.336243890261 Test RE 0.03268553293454292\n",
      "87 Train Loss 91796.4 Test MSE 4085.472797393927 Test RE 0.028569851645454093\n",
      "88 Train Loss 91089.695 Test MSE 2691.566071235939 Test RE 0.023189391153639265\n",
      "89 Train Loss 90809.914 Test MSE 3216.923442737866 Test RE 0.025351705805787265\n",
      "90 Train Loss 90654.79 Test MSE 4008.682062303002 Test RE 0.028300077837297273\n",
      "91 Train Loss 90576.47 Test MSE 5218.009088059851 Test RE 0.03228785834761999\n",
      "92 Train Loss 90530.1 Test MSE 5598.519655496181 Test RE 0.03344440140761352\n",
      "93 Train Loss 90484.94 Test MSE 5198.41250035632 Test RE 0.03222717169278696\n",
      "94 Train Loss 90385.87 Test MSE 4880.750062948816 Test RE 0.031226988831750378\n",
      "95 Train Loss 90215.73 Test MSE 4016.4877229480812 Test RE 0.02832761723441986\n",
      "96 Train Loss 89967.44 Test MSE 4488.9006822607425 Test RE 0.029947241303340446\n",
      "97 Train Loss 89837.07 Test MSE 5667.219827882093 Test RE 0.033648976058827294\n",
      "98 Train Loss 89757.03 Test MSE 5087.436927327373 Test RE 0.03188132354003682\n",
      "99 Train Loss 89717.36 Test MSE 4813.722978882301 Test RE 0.031011828282818194\n",
      "100 Train Loss 89639.695 Test MSE 4331.534159935747 Test RE 0.02941763096161658\n",
      "101 Train Loss 89279.0 Test MSE 3643.573425243704 Test RE 0.026980536831649023\n",
      "102 Train Loss 88794.25 Test MSE 3697.487338439952 Test RE 0.02717941916178029\n",
      "103 Train Loss 88307.055 Test MSE 4271.763753409966 Test RE 0.029213960440379366\n",
      "104 Train Loss 87998.65 Test MSE 3960.985057214924 Test RE 0.028131210836639258\n",
      "105 Train Loss 87865.85 Test MSE 3497.441813300757 Test RE 0.026433950511944127\n",
      "106 Train Loss 87775.71 Test MSE 3299.2262944350055 Test RE 0.025673960937759782\n",
      "107 Train Loss 87630.25 Test MSE 2993.598662316883 Test RE 0.02445589784925062\n",
      "108 Train Loss 87506.03 Test MSE 2929.1869771116226 Test RE 0.024191364822523022\n",
      "109 Train Loss 87258.47 Test MSE 2926.1925568713496 Test RE 0.02417899660643033\n",
      "110 Train Loss 87069.12 Test MSE 2938.171417514283 Test RE 0.024228436452088508\n",
      "111 Train Loss 86804.3 Test MSE 2901.0423736677894 Test RE 0.024074864962105483\n",
      "112 Train Loss 86659.84 Test MSE 3061.705861622072 Test RE 0.024732530680104246\n",
      "113 Train Loss 86549.695 Test MSE 2785.1868789686714 Test RE 0.023589242441519963\n",
      "114 Train Loss 86482.4 Test MSE 2721.794868329355 Test RE 0.02331924681594692\n",
      "115 Train Loss 86392.76 Test MSE 2776.213814234823 Test RE 0.023551212936336652\n",
      "116 Train Loss 86256.92 Test MSE 2970.5273611386897 Test RE 0.024361476256734616\n",
      "117 Train Loss 86152.016 Test MSE 2993.4781382967412 Test RE 0.024455405539972514\n",
      "118 Train Loss 86025.33 Test MSE 2973.647417815159 Test RE 0.024374266786673027\n",
      "119 Train Loss 85904.07 Test MSE 2864.028282578414 Test RE 0.023920787599500476\n",
      "120 Train Loss 85751.39 Test MSE 3104.086245057758 Test RE 0.02490311724880131\n",
      "121 Train Loss 85596.92 Test MSE 3428.203804263982 Test RE 0.02617098930140245\n",
      "122 Train Loss 85494.086 Test MSE 3956.554321410647 Test RE 0.028115472726455752\n",
      "123 Train Loss 85403.08 Test MSE 4212.678674903138 Test RE 0.029011219889617735\n",
      "124 Train Loss 85328.87 Test MSE 3944.664370435463 Test RE 0.028073195647652986\n",
      "125 Train Loss 85263.73 Test MSE 3583.045477483356 Test RE 0.026755494609773233\n",
      "126 Train Loss 85204.33 Test MSE 3313.8941253261564 Test RE 0.025730968802115707\n",
      "127 Train Loss 85059.05 Test MSE 2903.1699724145387 Test RE 0.0240836914902962\n",
      "128 Train Loss 84898.625 Test MSE 2725.2208528888077 Test RE 0.0233339184313575\n",
      "129 Train Loss 84753.82 Test MSE 2645.3350974618616 Test RE 0.022989375327396717\n",
      "130 Train Loss 84658.7 Test MSE 2788.6033308637366 Test RE 0.023603705889805107\n",
      "131 Train Loss 84606.88 Test MSE 3146.6489951262747 Test RE 0.025073269802600787\n",
      "132 Train Loss 84520.92 Test MSE 3811.3679781098394 Test RE 0.027594800846440823\n",
      "133 Train Loss 84384.85 Test MSE 4758.270433692288 Test RE 0.030832687719037237\n",
      "134 Train Loss 84118.055 Test MSE 3409.6685691330576 Test RE 0.026100144199532292\n",
      "135 Train Loss 83929.71 Test MSE 3133.3909375915828 Test RE 0.02502039232079473\n",
      "136 Train Loss 83744.94 Test MSE 3207.8200245097137 Test RE 0.025315809600966667\n",
      "137 Train Loss 83647.6 Test MSE 3747.7616325680806 Test RE 0.027363572955530387\n",
      "138 Train Loss 83478.336 Test MSE 3759.2524744240322 Test RE 0.02740548995476381\n",
      "139 Train Loss 83352.805 Test MSE 3627.0575725871636 Test RE 0.026919317715690342\n",
      "140 Train Loss 83169.125 Test MSE 3021.1551391191365 Test RE 0.024568199910677043\n",
      "141 Train Loss 82782.53 Test MSE 2109.4886919182422 Test RE 0.02052936066044206\n",
      "142 Train Loss 82519.47 Test MSE 2958.861508180547 Test RE 0.024313593012537833\n",
      "143 Train Loss 82348.03 Test MSE 3901.8233518392817 Test RE 0.02792033503968998\n",
      "144 Train Loss 82074.94 Test MSE 3267.2243735215 Test RE 0.02554914104075234\n",
      "145 Train Loss 81888.125 Test MSE 3042.407973749051 Test RE 0.024654463078885906\n",
      "146 Train Loss 81724.77 Test MSE 2960.54368104113 Test RE 0.02432050341621421\n",
      "147 Train Loss 81433.54 Test MSE 2417.636774113514 Test RE 0.021977705529754386\n",
      "148 Train Loss 81299.71 Test MSE 2667.571241232852 Test RE 0.023085795114947325\n",
      "149 Train Loss 81179.67 Test MSE 3522.3669236234828 Test RE 0.02652797629517779\n",
      "150 Train Loss 80946.85 Test MSE 2863.405641401071 Test RE 0.02391818726258569\n",
      "151 Train Loss 80873.945 Test MSE 2585.233386505339 Test RE 0.022726716873870345\n",
      "152 Train Loss 80799.14 Test MSE 2458.8478001647018 Test RE 0.022164229951874278\n",
      "153 Train Loss 80714.33 Test MSE 2514.126650829599 Test RE 0.02241198894345786\n",
      "154 Train Loss 80607.31 Test MSE 3081.8282447074757 Test RE 0.02481367211512962\n",
      "155 Train Loss 80564.76 Test MSE 3588.2820530050153 Test RE 0.026775038879471285\n",
      "156 Train Loss 80501.61 Test MSE 4036.385644359493 Test RE 0.028397698903029088\n",
      "157 Train Loss 80446.65 Test MSE 4038.170625262433 Test RE 0.02840397726093885\n",
      "158 Train Loss 80363.164 Test MSE 3685.891604533865 Test RE 0.027136766845477958\n",
      "159 Train Loss 80164.74 Test MSE 2910.2622181349225 Test RE 0.024113090951749808\n",
      "160 Train Loss 79998.695 Test MSE 2748.1840105600977 Test RE 0.02343201992105017\n",
      "161 Train Loss 79939.36 Test MSE 2887.021427383623 Test RE 0.024016616721090726\n",
      "162 Train Loss 79883.25 Test MSE 2990.711628976518 Test RE 0.02444410234298162\n",
      "163 Train Loss 79785.89 Test MSE 3365.1951473697645 Test RE 0.025929369146578514\n",
      "164 Train Loss 79691.54 Test MSE 3755.9057697811877 Test RE 0.027393288259962015\n",
      "165 Train Loss 79563.414 Test MSE 3960.684366379231 Test RE 0.028130143052020926\n",
      "166 Train Loss 79435.984 Test MSE 3692.3727423653772 Test RE 0.027160614519121253\n",
      "167 Train Loss 79341.65 Test MSE 3205.030893355328 Test RE 0.02530480142911274\n",
      "168 Train Loss 79261.03 Test MSE 2935.24255669189 Test RE 0.024216357610989954\n",
      "169 Train Loss 79152.31 Test MSE 3405.5776365915744 Test RE 0.02608448197705514\n",
      "170 Train Loss 78992.67 Test MSE 5624.625594414503 Test RE 0.033522286465189205\n",
      "171 Train Loss 78691.15 Test MSE 6139.661669219998 Test RE 0.0350234596184719\n",
      "172 Train Loss 78396.46 Test MSE 3951.4119378493992 Test RE 0.028097195768544924\n",
      "173 Train Loss 78163.36 Test MSE 2853.384889128478 Test RE 0.023876298630453752\n",
      "174 Train Loss 77918.734 Test MSE 2784.912109686811 Test RE 0.023588078828564448\n",
      "175 Train Loss 77745.78 Test MSE 2882.1596641659758 Test RE 0.023996386129524365\n",
      "176 Train Loss 77585.65 Test MSE 2282.1747393280043 Test RE 0.02135311655538996\n",
      "177 Train Loss 77491.88 Test MSE 2090.859152836021 Test RE 0.020438509103323912\n",
      "178 Train Loss 77446.58 Test MSE 2103.8788138383748 Test RE 0.020502045064868715\n",
      "179 Train Loss 77405.28 Test MSE 2089.172756846907 Test RE 0.02043026503472826\n",
      "180 Train Loss 77326.69 Test MSE 2081.1271804170506 Test RE 0.020390887769856227\n",
      "181 Train Loss 77222.164 Test MSE 2027.945696760371 Test RE 0.020128665575721894\n",
      "182 Train Loss 77078.57 Test MSE 2293.410728957987 Test RE 0.021405616657352876\n",
      "183 Train Loss 76996.47 Test MSE 2622.8953470805272 Test RE 0.022891660954224236\n",
      "184 Train Loss 76923.21 Test MSE 2866.1088915157793 Test RE 0.023929474798764457\n",
      "185 Train Loss 76817.47 Test MSE 3920.0074914703728 Test RE 0.0279853196721505\n",
      "186 Train Loss 76761.266 Test MSE 3883.290792359046 Test RE 0.02785394926251801\n",
      "187 Train Loss 76660.33 Test MSE 4554.237805508603 Test RE 0.030164398925574747\n",
      "188 Train Loss 76598.0 Test MSE 5149.255527570326 Test RE 0.03207443726669646\n",
      "189 Train Loss 76572.45 Test MSE 5563.866592724119 Test RE 0.033340735620105096\n",
      "190 Train Loss 76519.56 Test MSE 6140.336365412912 Test RE 0.03502538395461508\n",
      "191 Train Loss 76440.4 Test MSE 6844.4365154786465 Test RE 0.036979043496233016\n",
      "192 Train Loss 76360.71 Test MSE 7939.334641200888 Test RE 0.039827117699866854\n",
      "193 Train Loss 76190.83 Test MSE 9086.482071318513 Test RE 0.042607368339214656\n",
      "194 Train Loss 75996.48 Test MSE 8730.643377494805 Test RE 0.041764755960675706\n",
      "195 Train Loss 75688.375 Test MSE 8651.175729127503 Test RE 0.04157424686783589\n",
      "196 Train Loss 75538.04 Test MSE 8321.477733849379 Test RE 0.0407743504577818\n",
      "197 Train Loss 75453.08 Test MSE 8557.352242254823 Test RE 0.04134819237262195\n",
      "198 Train Loss 75162.31 Test MSE 8814.184450819994 Test RE 0.04196409784169763\n",
      "199 Train Loss 74772.875 Test MSE 6566.16437537996 Test RE 0.03621952070048854\n",
      "Training time: 50.82\n",
      "Training time: 50.82\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 457277.47 Test MSE 4996951.532187944 Test RE 0.9991700144192529\n",
      "1 Train Loss 457226.53 Test MSE 4772566.553239253 Test RE 0.976478803174487\n",
      "2 Train Loss 364279.94 Test MSE 1899064.5362712077 Test RE 0.6159659217107168\n",
      "3 Train Loss 213888.78 Test MSE 228174.70791288925 Test RE 0.2135111576514161\n",
      "4 Train Loss 182974.55 Test MSE 756809.6195632375 Test RE 0.38884824703792525\n",
      "5 Train Loss 164488.78 Test MSE 282611.7931839332 Test RE 0.23761943778715974\n",
      "6 Train Loss 142986.4 Test MSE 154761.5661286882 Test RE 0.1758402860766122\n",
      "7 Train Loss 127829.86 Test MSE 25430.669513455112 Test RE 0.07127967660673334\n",
      "8 Train Loss 126225.9 Test MSE 27188.334887323093 Test RE 0.0737018058238068\n",
      "9 Train Loss 124983.125 Test MSE 16381.501905364 Test RE 0.05720891115259819\n",
      "10 Train Loss 124102.805 Test MSE 10137.853781306387 Test RE 0.04500490353917631\n",
      "11 Train Loss 123764.68 Test MSE 8303.712165584973 Test RE 0.04073080251092868\n",
      "12 Train Loss 123491.34 Test MSE 7876.316890684124 Test RE 0.03966874072604313\n",
      "13 Train Loss 123347.234 Test MSE 8770.493910723335 Test RE 0.04185996388750286\n",
      "14 Train Loss 123123.37 Test MSE 10840.108538899403 Test RE 0.04653756319814199\n",
      "15 Train Loss 122925.07 Test MSE 11071.711064228894 Test RE 0.047032081033559936\n",
      "16 Train Loss 122777.72 Test MSE 10578.00129194303 Test RE 0.045971495446181676\n",
      "17 Train Loss 122587.07 Test MSE 9489.125637723146 Test RE 0.0435411526774513\n",
      "18 Train Loss 122441.47 Test MSE 9334.092527520275 Test RE 0.04318400072359528\n",
      "19 Train Loss 122281.97 Test MSE 9696.036096534723 Test RE 0.04401330034851849\n",
      "20 Train Loss 121945.2 Test MSE 6499.965990207183 Test RE 0.03603648023089764\n",
      "21 Train Loss 121696.36 Test MSE 5195.644219860703 Test RE 0.032218589675573325\n",
      "22 Train Loss 121485.164 Test MSE 6144.323217068761 Test RE 0.0350367529043132\n",
      "23 Train Loss 121316.46 Test MSE 5440.126421338072 Test RE 0.032967902701215905\n",
      "24 Train Loss 120973.32 Test MSE 3864.8690672120943 Test RE 0.027787803329800704\n",
      "25 Train Loss 120713.266 Test MSE 3393.7895969655065 Test RE 0.02603929853345537\n",
      "26 Train Loss 120316.9 Test MSE 2849.6371923650845 Test RE 0.02386061365778182\n",
      "27 Train Loss 120038.6 Test MSE 3466.165788620889 Test RE 0.026315491713624094\n",
      "28 Train Loss 119702.01 Test MSE 4594.172358193865 Test RE 0.030296360919966514\n",
      "29 Train Loss 119417.67 Test MSE 6244.334391010512 Test RE 0.03532074860387859\n",
      "30 Train Loss 119116.305 Test MSE 5035.356905163452 Test RE 0.03171771942340852\n",
      "31 Train Loss 118631.86 Test MSE 2140.015841173782 Test RE 0.02067737088891809\n",
      "32 Train Loss 118162.83 Test MSE 2499.0952738335795 Test RE 0.022344890473667636\n",
      "33 Train Loss 117659.51 Test MSE 3426.172705645458 Test RE 0.026163235425194786\n",
      "34 Train Loss 117297.92 Test MSE 3455.7417628811145 Test RE 0.026275891773730044\n",
      "35 Train Loss 117084.766 Test MSE 2687.988586677357 Test RE 0.023173974984892036\n",
      "36 Train Loss 116895.45 Test MSE 2341.722039020676 Test RE 0.021629899188528697\n",
      "37 Train Loss 116654.805 Test MSE 2176.6114057217123 Test RE 0.020853419217062037\n",
      "38 Train Loss 116294.57 Test MSE 3044.9071221582526 Test RE 0.024664587052175464\n",
      "39 Train Loss 116095.98 Test MSE 2702.370465907429 Test RE 0.023235887579194606\n",
      "40 Train Loss 115653.24 Test MSE 2196.854375747268 Test RE 0.020950165514779216\n",
      "41 Train Loss 115524.41 Test MSE 2304.660901880222 Test RE 0.021458054338973187\n",
      "42 Train Loss 115120.87 Test MSE 2310.045487459476 Test RE 0.021483106901017533\n",
      "43 Train Loss 115016.27 Test MSE 2418.4924965178184 Test RE 0.021981594689479505\n",
      "44 Train Loss 114786.6 Test MSE 2421.965285925477 Test RE 0.02199737105949771\n",
      "45 Train Loss 114531.766 Test MSE 2438.315638743066 Test RE 0.022071496772300553\n",
      "46 Train Loss 114299.336 Test MSE 2552.0646820429265 Test RE 0.02258045362520239\n",
      "47 Train Loss 114178.78 Test MSE 2749.0818620200084 Test RE 0.023435847313091507\n",
      "48 Train Loss 113914.37 Test MSE 3402.061987807779 Test RE 0.02607101472328696\n",
      "49 Train Loss 113654.945 Test MSE 4259.90464952047 Test RE 0.029173380928325957\n",
      "50 Train Loss 113367.95 Test MSE 4979.4623670286555 Test RE 0.03154118828149222\n",
      "51 Train Loss 113062.61 Test MSE 5422.409166897239 Test RE 0.032914174439953675\n",
      "52 Train Loss 112830.59 Test MSE 8334.409289586618 Test RE 0.040806019778733424\n",
      "53 Train Loss 112481.47 Test MSE 11228.398140356998 Test RE 0.047363711321109885\n",
      "54 Train Loss 112213.95 Test MSE 11249.353247610807 Test RE 0.04740788721328715\n",
      "55 Train Loss 112125.91 Test MSE 11756.540374341153 Test RE 0.04846481881575431\n",
      "56 Train Loss 111920.66 Test MSE 12007.982354973708 Test RE 0.04898034549323198\n",
      "57 Train Loss 111782.055 Test MSE 11326.953448582897 Test RE 0.047571120552550014\n",
      "58 Train Loss 111561.7 Test MSE 12367.041682719364 Test RE 0.04970724988649865\n",
      "59 Train Loss 111072.19 Test MSE 16730.195763747888 Test RE 0.0578145746785303\n",
      "60 Train Loss 110596.39 Test MSE 22040.98000176106 Test RE 0.06635937299955934\n",
      "61 Train Loss 110124.58 Test MSE 23145.80022377872 Test RE 0.06800219383550614\n",
      "62 Train Loss 109834.02 Test MSE 22052.127724181722 Test RE 0.06637615225249513\n",
      "63 Train Loss 109403.414 Test MSE 21863.140006951973 Test RE 0.06609111695589859\n",
      "64 Train Loss 109235.24 Test MSE 20573.50592603108 Test RE 0.0641122438113569\n",
      "65 Train Loss 108782.555 Test MSE 13667.386274320239 Test RE 0.05225520526864609\n",
      "66 Train Loss 108538.69 Test MSE 11285.579772259443 Test RE 0.047484160156075574\n",
      "67 Train Loss 108324.516 Test MSE 9375.611864068633 Test RE 0.043279938364588134\n",
      "68 Train Loss 108156.16 Test MSE 8821.937679246763 Test RE 0.041982550241973095\n",
      "69 Train Loss 107921.76 Test MSE 6431.6269324878795 Test RE 0.03584654028244042\n",
      "70 Train Loss 107773.84 Test MSE 5387.7101109965415 Test RE 0.03280869330337311\n",
      "71 Train Loss 107392.0 Test MSE 3907.960527033874 Test RE 0.027942284349700815\n",
      "72 Train Loss 107069.53 Test MSE 4393.699049743709 Test RE 0.029627975494132826\n",
      "73 Train Loss 106656.836 Test MSE 5382.088567815385 Test RE 0.0327915725213072\n",
      "74 Train Loss 106388.58 Test MSE 4427.85319009507 Test RE 0.02974290816341258\n",
      "75 Train Loss 105810.516 Test MSE 5691.564968973253 Test RE 0.0337211729397263\n",
      "76 Train Loss 105511.07 Test MSE 4804.469135600038 Test RE 0.030982005559962392\n",
      "77 Train Loss 105178.26 Test MSE 5486.158267179516 Test RE 0.03310708849912456\n",
      "78 Train Loss 104930.08 Test MSE 6890.468088842291 Test RE 0.037103184551059674\n",
      "79 Train Loss 104710.64 Test MSE 10607.941520789223 Test RE 0.0460365088870559\n",
      "80 Train Loss 104499.055 Test MSE 11515.657230096089 Test RE 0.047965744344162835\n",
      "81 Train Loss 104192.805 Test MSE 11718.380220274403 Test RE 0.048386099733404256\n",
      "82 Train Loss 103744.54 Test MSE 10918.678650155338 Test RE 0.04670591298058233\n",
      "83 Train Loss 103306.26 Test MSE 7272.193703459224 Test RE 0.038117072905564965\n",
      "84 Train Loss 103076.75 Test MSE 6022.187332042105 Test RE 0.03468677746927849\n",
      "85 Train Loss 102798.1 Test MSE 5737.424368956238 Test RE 0.03385675341571891\n",
      "86 Train Loss 102369.21 Test MSE 4555.223429276408 Test RE 0.030167662824100824\n",
      "87 Train Loss 102019.95 Test MSE 3914.304506619212 Test RE 0.027964955177333717\n",
      "88 Train Loss 101709.7 Test MSE 3968.3884719416665 Test RE 0.02815748836499039\n",
      "89 Train Loss 101181.32 Test MSE 3595.958183885224 Test RE 0.026803662451876355\n",
      "90 Train Loss 101056.33 Test MSE 3456.3243222088704 Test RE 0.02627810643874822\n",
      "91 Train Loss 100680.5 Test MSE 3611.816530043836 Test RE 0.026862700145121546\n",
      "92 Train Loss 100291.664 Test MSE 3380.5265324536913 Test RE 0.02598836741819602\n",
      "93 Train Loss 100173.8 Test MSE 4098.318322880509 Test RE 0.02861473099632059\n",
      "94 Train Loss 100083.61 Test MSE 4706.309436630185 Test RE 0.03066387690356311\n",
      "95 Train Loss 99809.17 Test MSE 5460.272788906794 Test RE 0.033028891146548126\n",
      "96 Train Loss 99424.85 Test MSE 6163.287171054206 Test RE 0.03509078029306197\n",
      "97 Train Loss 99302.14 Test MSE 7069.701091048318 Test RE 0.03758264569093556\n",
      "98 Train Loss 98929.95 Test MSE 5978.831715317473 Test RE 0.034561691430308704\n",
      "99 Train Loss 98788.91 Test MSE 5239.228013205975 Test RE 0.03235344069428966\n",
      "100 Train Loss 98715.93 Test MSE 4663.684710718108 Test RE 0.03052470073103843\n",
      "101 Train Loss 98662.52 Test MSE 3715.4997725642293 Test RE 0.027245541458380346\n",
      "102 Train Loss 98570.03 Test MSE 3206.382946269928 Test RE 0.025310138323539427\n",
      "103 Train Loss 98374.766 Test MSE 3055.4770916984435 Test RE 0.0247073597979344\n",
      "104 Train Loss 98305.055 Test MSE 3436.0217891543366 Test RE 0.02620081364876361\n",
      "105 Train Loss 98201.26 Test MSE 3793.760536989377 Test RE 0.02753098697649322\n",
      "106 Train Loss 98031.4 Test MSE 3625.630507096821 Test RE 0.026914021493068183\n",
      "107 Train Loss 97542.305 Test MSE 2222.1278321206482 Test RE 0.02107033027239371\n",
      "108 Train Loss 97251.45 Test MSE 1827.6452896267106 Test RE 0.01910877203520453\n",
      "109 Train Loss 96884.95 Test MSE 2118.803740159327 Test RE 0.02057463735252427\n",
      "110 Train Loss 96687.27 Test MSE 2209.052992264147 Test RE 0.021008250668053136\n",
      "111 Train Loss 96335.336 Test MSE 1955.5559637084748 Test RE 0.019766143690888596\n",
      "112 Train Loss 96067.48 Test MSE 1866.7497636185865 Test RE 0.019312116656673\n",
      "113 Train Loss 95766.03 Test MSE 1902.9110040406529 Test RE 0.019498269213660754\n",
      "114 Train Loss 95367.12 Test MSE 1894.5410806991215 Test RE 0.019455340545140743\n",
      "115 Train Loss 95130.41 Test MSE 2073.0425319753494 Test RE 0.020351242529660144\n",
      "116 Train Loss 94774.016 Test MSE 2185.748896512216 Test RE 0.02089714506598916\n",
      "117 Train Loss 94511.47 Test MSE 3124.3785715685203 Test RE 0.024984384156740307\n",
      "118 Train Loss 94266.45 Test MSE 3373.017092860523 Test RE 0.02595948632910187\n",
      "119 Train Loss 93900.664 Test MSE 2396.6484859040293 Test RE 0.02188209978984327\n",
      "120 Train Loss 93679.8 Test MSE 3008.2157133866144 Test RE 0.024515531394946805\n",
      "121 Train Loss 93580.414 Test MSE 3300.758565826954 Test RE 0.025679922170147286\n",
      "122 Train Loss 93191.93 Test MSE 3425.3048572412176 Test RE 0.026159921645930808\n",
      "123 Train Loss 92973.914 Test MSE 3981.552541776383 Test RE 0.028204152175412493\n",
      "124 Train Loss 92854.305 Test MSE 4151.756090033691 Test RE 0.02880067983648021\n",
      "125 Train Loss 92756.97 Test MSE 4376.509005557378 Test RE 0.029569959988819616\n",
      "126 Train Loss 92645.28 Test MSE 4446.366678336005 Test RE 0.029805022982456863\n",
      "127 Train Loss 92431.47 Test MSE 3796.4769710590526 Test RE 0.027540841674469286\n",
      "128 Train Loss 92243.59 Test MSE 2756.3371367413233 Test RE 0.023466752444400118\n",
      "129 Train Loss 92049.93 Test MSE 2956.430746822001 Test RE 0.024303603919560022\n",
      "130 Train Loss 91366.555 Test MSE 3472.8666274366287 Test RE 0.026340916164967802\n",
      "131 Train Loss 91165.266 Test MSE 2947.5989848522336 Test RE 0.024267275622934698\n",
      "132 Train Loss 91044.08 Test MSE 2367.2027465911938 Test RE 0.021747260248229046\n",
      "133 Train Loss 90735.234 Test MSE 2269.4351644927747 Test RE 0.021293434376711405\n",
      "134 Train Loss 90398.48 Test MSE 2887.0239133246905 Test RE 0.024016627061138843\n",
      "135 Train Loss 90222.26 Test MSE 3637.3891447965516 Test RE 0.02695762991467766\n",
      "136 Train Loss 90069.25 Test MSE 3754.951730556616 Test RE 0.02738980894859251\n",
      "137 Train Loss 89952.33 Test MSE 3429.495028942062 Test RE 0.02617591745733865\n",
      "138 Train Loss 89802.1 Test MSE 3281.4714257053315 Test RE 0.02560478521338212\n",
      "139 Train Loss 89607.47 Test MSE 3485.772925972224 Test RE 0.026389816467779277\n",
      "140 Train Loss 89369.89 Test MSE 4024.367354522869 Test RE 0.028355390482431672\n",
      "141 Train Loss 88683.5 Test MSE 4667.562724926357 Test RE 0.03053738926300805\n",
      "142 Train Loss 88420.89 Test MSE 5150.321979266797 Test RE 0.032077758530028755\n",
      "143 Train Loss 88036.91 Test MSE 3847.99985386592 Test RE 0.027727093510391577\n",
      "144 Train Loss 87266.48 Test MSE 2391.709920991581 Test RE 0.021859542894466653\n",
      "145 Train Loss 86913.1 Test MSE 1817.5326700172395 Test RE 0.019055832936003585\n",
      "146 Train Loss 86707.445 Test MSE 1637.9886561736926 Test RE 0.01809015418905161\n",
      "147 Train Loss 86545.19 Test MSE 1455.9894172202823 Test RE 0.017055558008174744\n",
      "148 Train Loss 86377.1 Test MSE 1543.5784444215003 Test RE 0.01756107817596776\n",
      "149 Train Loss 86099.836 Test MSE 1938.341499450659 Test RE 0.01967895219221159\n",
      "150 Train Loss 85827.125 Test MSE 1801.3488072231612 Test RE 0.018970803769967248\n",
      "151 Train Loss 85685.22 Test MSE 1731.0159214156997 Test RE 0.018596762934579562\n",
      "152 Train Loss 85418.734 Test MSE 1887.6301426053344 Test RE 0.019419823370005633\n",
      "153 Train Loss 85274.51 Test MSE 2126.8364709217667 Test RE 0.020613601361696852\n",
      "154 Train Loss 85130.68 Test MSE 2423.926510869053 Test RE 0.022006275617897367\n",
      "155 Train Loss 85021.56 Test MSE 2610.6005654370597 Test RE 0.02283794577850223\n",
      "156 Train Loss 84886.72 Test MSE 2676.053369794839 Test RE 0.02312246916240077\n",
      "157 Train Loss 84797.98 Test MSE 2558.7285972294626 Test RE 0.022609915285771682\n",
      "158 Train Loss 84537.82 Test MSE 2260.3742012172315 Test RE 0.02125088370203838\n",
      "159 Train Loss 83833.07 Test MSE 1984.5048819939439 Test RE 0.01991190948821864\n",
      "160 Train Loss 83578.9 Test MSE 1604.7567659606225 Test RE 0.017905705257271625\n",
      "161 Train Loss 83395.49 Test MSE 1644.2179158574265 Test RE 0.018124519913380432\n",
      "162 Train Loss 83025.12 Test MSE 1956.196523642675 Test RE 0.019769380714852094\n",
      "163 Train Loss 82748.43 Test MSE 1853.0771953636543 Test RE 0.019241263159564374\n",
      "164 Train Loss 82546.74 Test MSE 1960.1656438560303 Test RE 0.019789426575683645\n",
      "165 Train Loss 82216.51 Test MSE 2720.1971569823695 Test RE 0.02331240153622583\n",
      "166 Train Loss 81866.08 Test MSE 5649.836610545297 Test RE 0.03359733021554105\n",
      "167 Train Loss 81703.26 Test MSE 6787.527954659437 Test RE 0.036824990144426396\n",
      "168 Train Loss 81477.77 Test MSE 6599.250494360056 Test RE 0.036310658958059905\n",
      "169 Train Loss 81404.38 Test MSE 6850.379159080143 Test RE 0.03699509343668718\n",
      "170 Train Loss 81075.85 Test MSE 8874.832227506236 Test RE 0.04210822157481305\n",
      "171 Train Loss 80607.66 Test MSE 7764.420766273819 Test RE 0.03938595268899631\n",
      "172 Train Loss 80436.984 Test MSE 5244.038121777403 Test RE 0.03236828905163294\n",
      "173 Train Loss 80125.8 Test MSE 4394.99993664842 Test RE 0.029632361296664092\n",
      "174 Train Loss 79925.97 Test MSE 3763.0236325956657 Test RE 0.027419232651170616\n",
      "175 Train Loss 79693.445 Test MSE 2205.3362324310756 Test RE 0.020990569903053223\n",
      "176 Train Loss 79603.03 Test MSE 1723.7216762583316 Test RE 0.018557539565877208\n",
      "177 Train Loss 79557.305 Test MSE 1652.5414434110005 Test RE 0.018170337896670125\n",
      "178 Train Loss 79453.92 Test MSE 1488.005740976525 Test RE 0.017242059007753798\n",
      "179 Train Loss 79316.09 Test MSE 1321.6797559518538 Test RE 0.016249871934814614\n",
      "180 Train Loss 79229.8 Test MSE 1245.5967731595501 Test RE 0.01577522495088499\n",
      "181 Train Loss 78960.336 Test MSE 1738.3658231622726 Test RE 0.018636202085677612\n",
      "182 Train Loss 78697.62 Test MSE 1665.6295038701574 Test RE 0.018242150155032746\n",
      "183 Train Loss 78575.03 Test MSE 2159.3429587572487 Test RE 0.020770532752304116\n",
      "184 Train Loss 78459.68 Test MSE 2773.320602111901 Test RE 0.023538937870158143\n",
      "185 Train Loss 78295.75 Test MSE 2564.1392830316527 Test RE 0.022633808117467506\n",
      "186 Train Loss 78231.266 Test MSE 2336.375578787947 Test RE 0.02160519312250944\n",
      "187 Train Loss 78059.43 Test MSE 2512.845812032575 Test RE 0.0224062792466106\n",
      "188 Train Loss 77790.414 Test MSE 2914.9969596958704 Test RE 0.024132697923086224\n",
      "189 Train Loss 77584.73 Test MSE 2775.9789893677794 Test RE 0.023550216880598815\n",
      "190 Train Loss 77308.63 Test MSE 2401.9306103249073 Test RE 0.021906200186448167\n",
      "191 Train Loss 77105.46 Test MSE 2229.5426441225545 Test RE 0.0211054548100237\n",
      "192 Train Loss 77015.87 Test MSE 2243.6158155876137 Test RE 0.021171960254551078\n",
      "193 Train Loss 76840.67 Test MSE 2206.5202608951345 Test RE 0.020996203986615294\n",
      "194 Train Loss 76522.13 Test MSE 1704.6399247533552 Test RE 0.01845453690776387\n",
      "195 Train Loss 76213.37 Test MSE 1308.3693325503548 Test RE 0.016167839961362077\n",
      "196 Train Loss 76026.09 Test MSE 1276.7357229601325 Test RE 0.015971191928133108\n",
      "197 Train Loss 75825.36 Test MSE 1275.6051108245726 Test RE 0.01596411872476811\n",
      "198 Train Loss 75698.74 Test MSE 1410.2933552573372 Test RE 0.01678578103169139\n",
      "199 Train Loss 75468.35 Test MSE 1747.104121592192 Test RE 0.018682982963682288\n",
      "Training time: 48.88\n",
      "Training time: 48.88\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 459509.97 Test MSE 4890838.982203398 Test RE 0.988504171065545\n",
      "1 Train Loss 425948.44 Test MSE 2945024.0422650366 Test RE 0.7670633731954211\n",
      "2 Train Loss 300206.6 Test MSE 2607950.5958284694 Test RE 0.7218326191542589\n",
      "3 Train Loss 189998.88 Test MSE 740827.6576924653 Test RE 0.38472057885484934\n",
      "4 Train Loss 157964.7 Test MSE 106881.461999815 Test RE 0.14612953978199517\n",
      "5 Train Loss 140231.81 Test MSE 138794.49153668765 Test RE 0.16652250630527896\n",
      "6 Train Loss 134214.56 Test MSE 133884.59686124857 Test RE 0.1635505960670857\n",
      "7 Train Loss 131196.66 Test MSE 32898.555244044444 Test RE 0.0810728119975166\n",
      "8 Train Loss 128017.44 Test MSE 18104.307086602752 Test RE 0.060141987691686674\n",
      "9 Train Loss 126648.35 Test MSE 4077.9863698258696 Test RE 0.028543663220097968\n",
      "10 Train Loss 126000.414 Test MSE 2379.0341277326575 Test RE 0.021801539381440072\n",
      "11 Train Loss 125447.84 Test MSE 5743.905550614924 Test RE 0.033875870864665494\n",
      "12 Train Loss 124988.34 Test MSE 6413.285222835994 Test RE 0.03579539021842721\n",
      "13 Train Loss 124813.54 Test MSE 5344.6646366003415 Test RE 0.03267736682961188\n",
      "14 Train Loss 124593.625 Test MSE 2545.7982581047527 Test RE 0.02255271419072129\n",
      "15 Train Loss 124368.94 Test MSE 1621.2168770642643 Test RE 0.017997301064428338\n",
      "16 Train Loss 124230.016 Test MSE 1915.3709073475532 Test RE 0.019562000558207508\n",
      "17 Train Loss 124097.73 Test MSE 1824.622077903171 Test RE 0.019092961042270432\n",
      "18 Train Loss 124090.29 Test MSE 1862.106821401947 Test RE 0.019288085352055267\n",
      "19 Train Loss 124073.805 Test MSE 2059.035132280544 Test RE 0.020282370047843917\n",
      "20 Train Loss 124034.555 Test MSE 2270.376484074705 Test RE 0.021297849979551194\n",
      "21 Train Loss 123941.02 Test MSE 2391.2994822238243 Test RE 0.021857667167664963\n",
      "22 Train Loss 123797.93 Test MSE 1848.0603372519026 Test RE 0.019215199455724512\n",
      "23 Train Loss 123729.47 Test MSE 2032.7133696938024 Test RE 0.020152312795712134\n",
      "24 Train Loss 123712.7 Test MSE 2147.4023295833754 Test RE 0.020713025202969953\n",
      "25 Train Loss 123614.875 Test MSE 2116.3242188623744 Test RE 0.02056259513635259\n",
      "26 Train Loss 123575.51 Test MSE 2268.9435918952963 Test RE 0.021291128112164062\n",
      "27 Train Loss 123542.97 Test MSE 2586.0276912888594 Test RE 0.022730207961683437\n",
      "28 Train Loss 123498.65 Test MSE 2799.9684392758863 Test RE 0.02365175609170424\n",
      "29 Train Loss 123389.99 Test MSE 2153.0295521413027 Test RE 0.020740146469973252\n",
      "30 Train Loss 123272.22 Test MSE 1729.002086955453 Test RE 0.018585942207765244\n",
      "31 Train Loss 123143.06 Test MSE 1953.4097847865962 Test RE 0.01975529426306694\n",
      "32 Train Loss 123045.57 Test MSE 2555.095079136612 Test RE 0.02259385599707244\n",
      "33 Train Loss 123008.1 Test MSE 2989.0183331221333 Test RE 0.024437181422025302\n",
      "34 Train Loss 122896.81 Test MSE 2649.782870830382 Test RE 0.02300869397383235\n",
      "35 Train Loss 122749.89 Test MSE 3386.5863447710594 Test RE 0.026011649903234714\n",
      "36 Train Loss 122701.83 Test MSE 4403.389749000763 Test RE 0.029660631082996002\n",
      "37 Train Loss 122628.24 Test MSE 5323.844323420092 Test RE 0.03261365685568665\n",
      "38 Train Loss 122487.46 Test MSE 3943.50066975199 Test RE 0.02806905445798199\n",
      "39 Train Loss 122390.24 Test MSE 2552.1897616792203 Test RE 0.022581006965472585\n",
      "40 Train Loss 122326.66 Test MSE 2493.853494932637 Test RE 0.022321444297215626\n",
      "41 Train Loss 122183.8 Test MSE 2322.249355950165 Test RE 0.021539779303587702\n",
      "42 Train Loss 122077.91 Test MSE 2603.6808521776766 Test RE 0.02280765832317502\n",
      "43 Train Loss 122008.45 Test MSE 3477.142479681578 Test RE 0.026357126867965163\n",
      "44 Train Loss 121967.336 Test MSE 2982.0151115673707 Test RE 0.024408536673454176\n",
      "45 Train Loss 121849.16 Test MSE 2190.670865955545 Test RE 0.02092066040923687\n",
      "46 Train Loss 121766.84 Test MSE 2098.7235008920225 Test RE 0.02047691070705031\n",
      "47 Train Loss 121666.195 Test MSE 2451.086050652436 Test RE 0.022129219818603118\n",
      "48 Train Loss 121510.55 Test MSE 3390.9820662120796 Test RE 0.026028525729933145\n",
      "49 Train Loss 121403.18 Test MSE 3622.231032205127 Test RE 0.026901400929997092\n",
      "50 Train Loss 121240.445 Test MSE 3776.3008400345625 Test RE 0.0274675621751373\n",
      "51 Train Loss 121161.12 Test MSE 4446.082093047391 Test RE 0.029804069146729038\n",
      "52 Train Loss 120983.09 Test MSE 5840.537018086467 Test RE 0.03415963441401444\n",
      "53 Train Loss 120846.76 Test MSE 5900.096767969699 Test RE 0.034333366613251995\n",
      "54 Train Loss 120758.7 Test MSE 5758.322258018483 Test RE 0.033918356978946455\n",
      "55 Train Loss 120620.02 Test MSE 6305.626857740571 Test RE 0.035493674099178495\n",
      "56 Train Loss 120485.49 Test MSE 6971.07473054236 Test RE 0.037319575306838715\n",
      "57 Train Loss 120287.336 Test MSE 6026.232165966843 Test RE 0.03469842429257822\n",
      "58 Train Loss 119936.16 Test MSE 5734.0247511422385 Test RE 0.033846721294173605\n",
      "59 Train Loss 119740.92 Test MSE 5639.06162564544 Test RE 0.033565277652248725\n",
      "60 Train Loss 119513.555 Test MSE 6183.932453371743 Test RE 0.03514950329072154\n",
      "61 Train Loss 119371.56 Test MSE 5580.490091428735 Test RE 0.03339050553277754\n",
      "62 Train Loss 119170.055 Test MSE 4700.344856659587 Test RE 0.03064443968483959\n",
      "63 Train Loss 119062.09 Test MSE 5341.202881528909 Test RE 0.032666782501952554\n",
      "64 Train Loss 118868.81 Test MSE 7479.3800381438805 Test RE 0.03865624134863571\n",
      "65 Train Loss 118489.15 Test MSE 9517.393541826465 Test RE 0.04360595853489549\n",
      "66 Train Loss 117875.14 Test MSE 11991.549507629696 Test RE 0.04894681937387014\n",
      "67 Train Loss 117415.2 Test MSE 11053.498213284727 Test RE 0.04699338146687798\n",
      "68 Train Loss 117048.61 Test MSE 11201.239627966203 Test RE 0.04730639652481425\n",
      "69 Train Loss 116652.734 Test MSE 8764.522793833235 Test RE 0.04184571193674564\n",
      "70 Train Loss 116285.625 Test MSE 8473.756226431773 Test RE 0.04114573329412719\n",
      "71 Train Loss 115996.34 Test MSE 7733.1634691363115 Test RE 0.039306594551761845\n",
      "72 Train Loss 115835.03 Test MSE 7704.709598560589 Test RE 0.03923421437671067\n",
      "73 Train Loss 115589.086 Test MSE 8136.075551133675 Test RE 0.04031756641542464\n",
      "74 Train Loss 115345.24 Test MSE 10030.947555039967 Test RE 0.0447669806053745\n",
      "75 Train Loss 115244.44 Test MSE 10446.868853013864 Test RE 0.045685659123969984\n",
      "76 Train Loss 115090.08 Test MSE 9170.33288635421 Test RE 0.04280350905344608\n",
      "77 Train Loss 114867.66 Test MSE 8231.431193738494 Test RE 0.04055314119929707\n",
      "78 Train Loss 114757.016 Test MSE 8240.277989616705 Test RE 0.04057492775191814\n",
      "79 Train Loss 114397.39 Test MSE 7348.761745334634 Test RE 0.038317212482995154\n",
      "80 Train Loss 114204.61 Test MSE 7018.598729443373 Test RE 0.03744656885011298\n",
      "81 Train Loss 113962.05 Test MSE 5358.049299925603 Test RE 0.03271825826949908\n",
      "82 Train Loss 113744.086 Test MSE 4436.549434079355 Test RE 0.029772101172145307\n",
      "83 Train Loss 113599.35 Test MSE 4433.2603878890295 Test RE 0.029761063317979015\n",
      "84 Train Loss 113234.375 Test MSE 4329.218982366022 Test RE 0.029409768142120086\n",
      "85 Train Loss 113020.51 Test MSE 4085.014661698602 Test RE 0.028568249721214523\n",
      "86 Train Loss 112697.29 Test MSE 3964.4196389582125 Test RE 0.028143404521567918\n",
      "87 Train Loss 112172.375 Test MSE 4067.716847833079 Test RE 0.02850770005970075\n",
      "88 Train Loss 111936.8 Test MSE 3654.904704401454 Test RE 0.02702245813148447\n",
      "89 Train Loss 111307.93 Test MSE 4800.464394063941 Test RE 0.030969090419150087\n",
      "90 Train Loss 110684.875 Test MSE 5392.836900276246 Test RE 0.032824299493974626\n",
      "91 Train Loss 110222.18 Test MSE 5668.811923922312 Test RE 0.033653702242137894\n",
      "92 Train Loss 109898.32 Test MSE 5388.378193823929 Test RE 0.032810727399926395\n",
      "93 Train Loss 109692.37 Test MSE 5976.473342018565 Test RE 0.03455487426153534\n",
      "94 Train Loss 109432.6 Test MSE 5808.599455937094 Test RE 0.03406610954042592\n",
      "95 Train Loss 109198.53 Test MSE 5230.305327065159 Test RE 0.03232587913272547\n",
      "96 Train Loss 108497.375 Test MSE 5869.550530944131 Test RE 0.03424437518343554\n",
      "97 Train Loss 108213.73 Test MSE 7132.695515477076 Test RE 0.03774971404264354\n",
      "98 Train Loss 108084.586 Test MSE 7731.679054057762 Test RE 0.039302821832993724\n",
      "99 Train Loss 107761.86 Test MSE 6116.979988129236 Test RE 0.03495870637796277\n",
      "100 Train Loss 107485.164 Test MSE 4201.104536228153 Test RE 0.02897133898956116\n",
      "101 Train Loss 107152.23 Test MSE 3927.980393359442 Test RE 0.028013764881851328\n",
      "102 Train Loss 106433.39 Test MSE 7719.150274450533 Test RE 0.03927096484340868\n",
      "103 Train Loss 106040.836 Test MSE 9662.792881229925 Test RE 0.043937784959030016\n",
      "104 Train Loss 105581.98 Test MSE 7319.214526330984 Test RE 0.03824010375163442\n",
      "105 Train Loss 105182.71 Test MSE 9296.999122271256 Test RE 0.043098109340897514\n",
      "106 Train Loss 104910.46 Test MSE 11052.735475859114 Test RE 0.046991760069358825\n",
      "107 Train Loss 104692.055 Test MSE 11641.76523810737 Test RE 0.04822766574937444\n",
      "108 Train Loss 104525.51 Test MSE 10337.625632340945 Test RE 0.045446163221305874\n",
      "109 Train Loss 104414.57 Test MSE 10990.865459334556 Test RE 0.0468600523543124\n",
      "110 Train Loss 104127.94 Test MSE 11033.15015253897 Test RE 0.046950107173117546\n",
      "111 Train Loss 103882.6 Test MSE 9604.536230705138 Test RE 0.04380513501367445\n",
      "112 Train Loss 103629.29 Test MSE 8060.360367321242 Test RE 0.04012952813772754\n",
      "113 Train Loss 103561.75 Test MSE 7390.623563500516 Test RE 0.03842619345187274\n",
      "114 Train Loss 103407.83 Test MSE 5293.6229516954245 Test RE 0.03252095765853139\n",
      "115 Train Loss 103220.75 Test MSE 3971.6426871679423 Test RE 0.028169031054254542\n",
      "116 Train Loss 103089.55 Test MSE 3723.8448832697436 Test RE 0.027276121400336636\n",
      "117 Train Loss 102918.516 Test MSE 3741.375298716318 Test RE 0.02734024871037089\n",
      "118 Train Loss 102692.58 Test MSE 5330.995207562107 Test RE 0.032635552520459056\n",
      "119 Train Loss 102543.4 Test MSE 6697.030105419455 Test RE 0.036578673267123656\n",
      "120 Train Loss 102412.57 Test MSE 6576.664082423163 Test RE 0.03624846777123561\n",
      "121 Train Loss 102310.94 Test MSE 6160.455205220434 Test RE 0.03508271744394589\n",
      "122 Train Loss 102223.59 Test MSE 6389.777396160433 Test RE 0.03572972618527624\n",
      "123 Train Loss 102102.96 Test MSE 6881.26339053308 Test RE 0.037078393945483214\n",
      "124 Train Loss 101870.57 Test MSE 6870.513102901152 Test RE 0.0370494196729573\n",
      "125 Train Loss 101678.45 Test MSE 6367.637607458991 Test RE 0.035667772931658306\n",
      "126 Train Loss 101615.7 Test MSE 5985.94490402126 Test RE 0.03458224483993428\n",
      "127 Train Loss 101580.73 Test MSE 5734.6814303865385 Test RE 0.03384865935722718\n",
      "128 Train Loss 101496.805 Test MSE 5386.888634881461 Test RE 0.032806192000892125\n",
      "129 Train Loss 101386.15 Test MSE 5022.6729109156895 Test RE 0.031677745986612375\n",
      "130 Train Loss 101261.97 Test MSE 4415.187687614692 Test RE 0.02970033915390232\n",
      "131 Train Loss 101084.82 Test MSE 2720.3838217320213 Test RE 0.023313201391658038\n",
      "132 Train Loss 100970.33 Test MSE 2428.956748180124 Test RE 0.022029097971837545\n",
      "133 Train Loss 100865.34 Test MSE 2320.0633475317804 Test RE 0.02152963887122803\n",
      "134 Train Loss 100761.23 Test MSE 2122.5203526770206 Test RE 0.020592674523542243\n",
      "135 Train Loss 100698.0 Test MSE 1934.6170274172512 Test RE 0.0196600368078599\n",
      "136 Train Loss 100623.84 Test MSE 1988.248542505929 Test RE 0.01993068200612339\n",
      "137 Train Loss 100546.47 Test MSE 2441.4864020438554 Test RE 0.022085842895943345\n",
      "138 Train Loss 100481.84 Test MSE 2749.935249477463 Test RE 0.023439484583146687\n",
      "139 Train Loss 100400.25 Test MSE 2471.9223629543662 Test RE 0.02222307934693989\n",
      "140 Train Loss 100162.96 Test MSE 1975.5854897572535 Test RE 0.01986711188121274\n",
      "141 Train Loss 99873.836 Test MSE 1697.1089925453455 Test RE 0.01841372661573857\n",
      "142 Train Loss 99743.09 Test MSE 1702.4838554071684 Test RE 0.01844286234520309\n",
      "143 Train Loss 99660.336 Test MSE 1729.2739560915768 Test RE 0.0185874033816626\n",
      "144 Train Loss 99613.14 Test MSE 1828.6625645451259 Test RE 0.01911408930613136\n",
      "145 Train Loss 99590.81 Test MSE 1828.093984283556 Test RE 0.019111117533476475\n",
      "146 Train Loss 99399.7 Test MSE 1589.5521032622955 Test RE 0.017820677369176623\n",
      "147 Train Loss 99254.25 Test MSE 1442.0562722102172 Test RE 0.01697375493421844\n",
      "148 Train Loss 99196.51 Test MSE 1520.5307774308496 Test RE 0.017429480037286272\n",
      "149 Train Loss 99107.59 Test MSE 1705.6760233718321 Test RE 0.018460144489562985\n",
      "150 Train Loss 98846.01 Test MSE 1979.7332519065765 Test RE 0.019887956549390292\n",
      "151 Train Loss 98779.25 Test MSE 1838.6921939993001 Test RE 0.01916643496354958\n",
      "152 Train Loss 98539.29 Test MSE 2198.417518038996 Test RE 0.020957617594170957\n",
      "153 Train Loss 98449.234 Test MSE 2365.8648166787534 Test RE 0.021741113663938307\n",
      "154 Train Loss 98356.734 Test MSE 2719.7749430669137 Test RE 0.023310592255182973\n",
      "155 Train Loss 98281.47 Test MSE 2548.3865367511617 Test RE 0.02256417579794492\n",
      "156 Train Loss 98211.78 Test MSE 2446.4374235647733 Test RE 0.022108225184015978\n",
      "157 Train Loss 98124.055 Test MSE 2534.4057439503745 Test RE 0.022502195614813432\n",
      "158 Train Loss 98068.14 Test MSE 2721.381052856028 Test RE 0.023317474046058047\n",
      "159 Train Loss 97991.38 Test MSE 3003.39996804315 Test RE 0.024495900514883144\n",
      "160 Train Loss 97940.34 Test MSE 3189.0392636310694 Test RE 0.02524159282606318\n",
      "161 Train Loss 97868.76 Test MSE 3739.038008826498 Test RE 0.027331707456815003\n",
      "162 Train Loss 97803.7 Test MSE 3890.728633782749 Test RE 0.027880611462381067\n",
      "163 Train Loss 97745.84 Test MSE 3333.6474093698075 Test RE 0.02580754275807115\n",
      "164 Train Loss 97615.914 Test MSE 3171.8831082524457 Test RE 0.02517360484514606\n",
      "165 Train Loss 97471.84 Test MSE 3154.9266910027122 Test RE 0.025106227495862048\n",
      "166 Train Loss 97318.055 Test MSE 3227.5758155056465 Test RE 0.02539364535332603\n",
      "167 Train Loss 97264.33 Test MSE 3184.3631900369846 Test RE 0.025223080221646293\n",
      "168 Train Loss 97188.48 Test MSE 3208.518782420154 Test RE 0.025318566716212708\n",
      "169 Train Loss 97065.5 Test MSE 3427.620012588541 Test RE 0.026168760866766835\n",
      "170 Train Loss 97016.79 Test MSE 3430.6211693361984 Test RE 0.026180214786574306\n",
      "171 Train Loss 96860.19 Test MSE 3787.678994344742 Test RE 0.027508911515606204\n",
      "172 Train Loss 96752.93 Test MSE 3867.9973756598783 Test RE 0.02779904707894074\n",
      "173 Train Loss 96674.79 Test MSE 3580.6145261125966 Test RE 0.02674641680955784\n",
      "174 Train Loss 96541.945 Test MSE 2897.641640545359 Test RE 0.024060750001379114\n",
      "175 Train Loss 96235.11 Test MSE 2436.7947264253035 Test RE 0.022064612091930776\n",
      "176 Train Loss 96107.96 Test MSE 2356.345354202115 Test RE 0.021697330028741933\n",
      "177 Train Loss 95898.46 Test MSE 3383.97711509131 Test RE 0.0260016275031056\n",
      "178 Train Loss 95640.53 Test MSE 3821.3274220154262 Test RE 0.027630831160071975\n",
      "179 Train Loss 95549.99 Test MSE 3887.5702486774085 Test RE 0.027869292813071857\n",
      "180 Train Loss 95387.766 Test MSE 4338.892515939999 Test RE 0.029442607510254248\n",
      "181 Train Loss 95179.26 Test MSE 3762.3056153890943 Test RE 0.02741661661391156\n",
      "182 Train Loss 94912.28 Test MSE 2857.408817978704 Test RE 0.02389312823493955\n",
      "183 Train Loss 94737.305 Test MSE 2515.11529087536 Test RE 0.022416395088219073\n",
      "184 Train Loss 94633.21 Test MSE 2612.0057959942133 Test RE 0.022844091540931324\n",
      "185 Train Loss 94508.516 Test MSE 2737.098203684613 Test RE 0.02338471134593411\n",
      "186 Train Loss 94389.69 Test MSE 2465.7444647749944 Test RE 0.02219529170040637\n",
      "187 Train Loss 94229.984 Test MSE 1926.1948998766907 Test RE 0.01961719630352105\n",
      "188 Train Loss 94054.9 Test MSE 1701.1109122208343 Test RE 0.018435424357139282\n",
      "189 Train Loss 93935.32 Test MSE 1862.7137231720749 Test RE 0.019291228302651488\n",
      "190 Train Loss 93819.82 Test MSE 1651.8788860181546 Test RE 0.018166694992980986\n",
      "191 Train Loss 93737.29 Test MSE 1483.482943115532 Test RE 0.017215835421187008\n",
      "192 Train Loss 93683.1 Test MSE 1509.0740708012852 Test RE 0.01736369314050012\n",
      "193 Train Loss 93641.47 Test MSE 1598.6323310912048 Test RE 0.017871504698773213\n",
      "194 Train Loss 93558.31 Test MSE 1768.6574542030387 Test RE 0.01879787200074106\n",
      "195 Train Loss 93429.38 Test MSE 1842.8460141605653 Test RE 0.019188072356328967\n",
      "196 Train Loss 93224.3 Test MSE 1666.5503848417763 Test RE 0.018247192251025827\n",
      "197 Train Loss 93078.58 Test MSE 1536.1985450830518 Test RE 0.01751904783233616\n",
      "198 Train Loss 92929.46 Test MSE 1879.7281629407503 Test RE 0.019379133199578482\n",
      "199 Train Loss 92807.02 Test MSE 1688.6767830607973 Test RE 0.018367924682241736\n",
      "Training time: 49.59\n",
      "Training time: 49.59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 639702.25 Test MSE 3469095.0121709425 Test RE 0.8325204703601593\n",
      "1 Train Loss 466617.16 Test MSE 4178591.371285179 Test RE 0.9136961084821347\n",
      "2 Train Loss 202565.3 Test MSE 816102.4914681227 Test RE 0.4037933622364857\n",
      "3 Train Loss 173985.03 Test MSE 625121.2424044285 Test RE 0.3534019586594193\n",
      "4 Train Loss 152920.17 Test MSE 234969.71885621749 Test RE 0.21666700110249446\n",
      "5 Train Loss 141339.23 Test MSE 159733.68714824624 Test RE 0.17864262100136824\n",
      "6 Train Loss 134006.92 Test MSE 40107.6327444429 Test RE 0.08951593215039741\n",
      "7 Train Loss 128111.234 Test MSE 16642.69913174026 Test RE 0.05766319534294483\n",
      "8 Train Loss 126340.695 Test MSE 3467.524635886511 Test RE 0.026320649463164286\n",
      "9 Train Loss 125237.375 Test MSE 3470.2896655723976 Test RE 0.026331141511849662\n",
      "10 Train Loss 124964.33 Test MSE 2182.33699377084 Test RE 0.02088082871958363\n",
      "11 Train Loss 124840.53 Test MSE 2675.238317449536 Test RE 0.023118947659775572\n",
      "12 Train Loss 124427.15 Test MSE 1958.6909239494018 Test RE 0.01978198094154837\n",
      "13 Train Loss 124209.07 Test MSE 3015.2085156399567 Test RE 0.024544008866085633\n",
      "14 Train Loss 123831.945 Test MSE 3970.119662522649 Test RE 0.02816362948043879\n",
      "15 Train Loss 123591.95 Test MSE 1901.9993756744843 Test RE 0.01949359813217852\n",
      "16 Train Loss 123368.305 Test MSE 2970.7936492701033 Test RE 0.024362568154876887\n",
      "17 Train Loss 123074.7 Test MSE 3747.9308456253416 Test RE 0.02736419068712965\n",
      "18 Train Loss 123018.18 Test MSE 3077.3560247819496 Test RE 0.02479566129836235\n",
      "19 Train Loss 122875.21 Test MSE 3151.032176754181 Test RE 0.02509072685775895\n",
      "20 Train Loss 122532.445 Test MSE 2646.697289240255 Test RE 0.02299529365276562\n",
      "21 Train Loss 122401.6 Test MSE 2519.810140461866 Test RE 0.02243730715872468\n",
      "22 Train Loss 122166.06 Test MSE 2705.237245472831 Test RE 0.023248209078357417\n",
      "23 Train Loss 122081.42 Test MSE 2769.8260640207386 Test RE 0.023524103010529655\n",
      "24 Train Loss 121912.65 Test MSE 3911.9448030523686 Test RE 0.027956524694653265\n",
      "25 Train Loss 121626.01 Test MSE 3094.732938902047 Test RE 0.02486556961139547\n",
      "26 Train Loss 121432.125 Test MSE 4055.1973686363326 Test RE 0.02846379624222038\n",
      "27 Train Loss 121233.66 Test MSE 3698.786872135696 Test RE 0.02718419503588975\n",
      "28 Train Loss 121042.45 Test MSE 4258.746778668908 Test RE 0.029169415897902697\n",
      "29 Train Loss 120565.31 Test MSE 10773.638537218789 Test RE 0.04639466294553889\n",
      "30 Train Loss 120439.305 Test MSE 12276.91612837151 Test RE 0.0495257964186761\n",
      "31 Train Loss 120278.89 Test MSE 10391.828936716818 Test RE 0.04556515145630348\n",
      "32 Train Loss 120159.875 Test MSE 8967.623841676288 Test RE 0.0423277823248274\n",
      "33 Train Loss 119794.46 Test MSE 8844.933626503509 Test RE 0.042037232117122285\n",
      "34 Train Loss 119428.46 Test MSE 11152.412945345008 Test RE 0.047203178616261963\n",
      "35 Train Loss 119213.93 Test MSE 12891.167945601092 Test RE 0.050749638947786516\n",
      "36 Train Loss 119011.36 Test MSE 14207.58009935895 Test RE 0.05327787324234637\n",
      "37 Train Loss 118703.13 Test MSE 18516.676845114576 Test RE 0.06082307143403859\n",
      "38 Train Loss 118433.1 Test MSE 17049.978054361825 Test RE 0.05836449549557053\n",
      "39 Train Loss 117953.05 Test MSE 17591.270336210426 Test RE 0.05928371694358736\n",
      "40 Train Loss 117612.25 Test MSE 15713.964554546714 Test RE 0.05603117220373636\n",
      "41 Train Loss 117307.75 Test MSE 15073.540285941013 Test RE 0.05487751746605068\n",
      "42 Train Loss 116944.25 Test MSE 14634.01983628972 Test RE 0.054071528115400044\n",
      "43 Train Loss 116757.98 Test MSE 14025.809979663778 Test RE 0.05293596068213162\n",
      "44 Train Loss 116341.234 Test MSE 10269.412393610293 Test RE 0.04529597588855218\n",
      "45 Train Loss 115897.7 Test MSE 6886.7046155538665 Test RE 0.03709305055767315\n",
      "46 Train Loss 115328.16 Test MSE 6615.365928028367 Test RE 0.03635496741468639\n",
      "47 Train Loss 114878.32 Test MSE 6981.75672276724 Test RE 0.037348157328308616\n",
      "48 Train Loss 114542.01 Test MSE 4868.0109356745215 Test RE 0.031186209802470184\n",
      "49 Train Loss 114052.1 Test MSE 2814.6774615763256 Test RE 0.023713799381648654\n",
      "50 Train Loss 113559.11 Test MSE 2988.3788148287035 Test RE 0.02443456704184524\n",
      "51 Train Loss 113155.93 Test MSE 3472.2582283947095 Test RE 0.026338608778619006\n",
      "52 Train Loss 112753.95 Test MSE 4212.925574968313 Test RE 0.02901207003363364\n",
      "53 Train Loss 112280.19 Test MSE 3779.632460526109 Test RE 0.027479676056140556\n",
      "54 Train Loss 112007.95 Test MSE 3226.2914763002805 Test RE 0.025388592443447704\n",
      "55 Train Loss 111434.266 Test MSE 3348.6459058043383 Test RE 0.025865533285151336\n",
      "56 Train Loss 110816.766 Test MSE 3231.0200135025425 Test RE 0.025407190724094704\n",
      "57 Train Loss 109846.88 Test MSE 3519.9299818981976 Test RE 0.026518798046703616\n",
      "58 Train Loss 109056.11 Test MSE 3541.7939201300323 Test RE 0.026601030902197054\n",
      "59 Train Loss 107951.33 Test MSE 15701.251895652887 Test RE 0.05600850289899474\n",
      "60 Train Loss 107458.65 Test MSE 15606.480848172954 Test RE 0.05583921645001816\n",
      "61 Train Loss 106672.12 Test MSE 18692.42552345804 Test RE 0.061111036966047916\n",
      "62 Train Loss 106250.766 Test MSE 13455.259332396936 Test RE 0.05184810165916041\n",
      "63 Train Loss 105439.4 Test MSE 6696.624629945527 Test RE 0.03657756591213561\n",
      "64 Train Loss 104771.61 Test MSE 5368.394873700688 Test RE 0.03274983001330324\n",
      "65 Train Loss 104005.84 Test MSE 4020.5384172019108 Test RE 0.02834189806980504\n",
      "66 Train Loss 103448.47 Test MSE 5459.398225436641 Test RE 0.0330262459473505\n",
      "67 Train Loss 102936.125 Test MSE 6879.495919585454 Test RE 0.03707363179723273\n",
      "68 Train Loss 102601.63 Test MSE 7946.2214496210545 Test RE 0.03984438755229953\n",
      "69 Train Loss 101957.14 Test MSE 11312.363521131816 Test RE 0.04754047317484474\n",
      "70 Train Loss 101629.484 Test MSE 11815.900245274182 Test RE 0.04858701646261513\n",
      "71 Train Loss 101180.87 Test MSE 10986.716261560654 Test RE 0.04685120637310973\n",
      "72 Train Loss 100773.67 Test MSE 8928.718904768788 Test RE 0.04223586557625386\n",
      "73 Train Loss 100455.914 Test MSE 6178.853449823864 Test RE 0.03513506578474379\n",
      "74 Train Loss 100050.516 Test MSE 5040.447310101405 Test RE 0.03173374760710492\n",
      "75 Train Loss 99281.83 Test MSE 2870.7601520856924 Test RE 0.023948883883824327\n",
      "76 Train Loss 98528.836 Test MSE 2288.6663120444614 Test RE 0.02138346411701628\n",
      "77 Train Loss 98196.77 Test MSE 2360.4861526406066 Test RE 0.021716385986312047\n",
      "78 Train Loss 97960.01 Test MSE 2517.01296515807 Test RE 0.022424850166927447\n",
      "79 Train Loss 97678.01 Test MSE 1872.6247797901653 Test RE 0.019342482234003543\n",
      "80 Train Loss 97507.46 Test MSE 1953.163767621996 Test RE 0.01975405020906648\n",
      "81 Train Loss 97292.78 Test MSE 2509.299595952155 Test RE 0.022390463401386576\n",
      "82 Train Loss 96832.08 Test MSE 3047.621775852503 Test RE 0.02467557932433527\n",
      "83 Train Loss 96335.38 Test MSE 3594.37125275186 Test RE 0.026797747441448992\n",
      "84 Train Loss 95741.6 Test MSE 2363.7353728101402 Test RE 0.021731327199582644\n",
      "85 Train Loss 95239.72 Test MSE 1387.2757593055167 Test RE 0.016648235954691122\n",
      "86 Train Loss 94997.51 Test MSE 1493.23330824471 Test RE 0.01727231930725892\n",
      "87 Train Loss 94611.945 Test MSE 1338.7480964994563 Test RE 0.016354461803251476\n",
      "88 Train Loss 94286.695 Test MSE 1831.9228599729613 Test RE 0.01913112083169578\n",
      "89 Train Loss 94017.75 Test MSE 1684.6316547394126 Test RE 0.018345911836986348\n",
      "90 Train Loss 93228.45 Test MSE 1955.117614091831 Test RE 0.019763928216805123\n",
      "91 Train Loss 92648.945 Test MSE 4604.97248169208 Test RE 0.03033195083030184\n",
      "92 Train Loss 91963.305 Test MSE 3808.5919039809196 Test RE 0.027584749446599683\n",
      "93 Train Loss 91697.21 Test MSE 3208.412742646046 Test RE 0.025318148330430935\n",
      "94 Train Loss 91169.79 Test MSE 2349.8535272082613 Test RE 0.021667420902322994\n",
      "95 Train Loss 90861.85 Test MSE 2606.5544202585593 Test RE 0.022820240757317648\n",
      "96 Train Loss 90597.28 Test MSE 2260.923325974374 Test RE 0.02125346484052978\n",
      "97 Train Loss 90298.48 Test MSE 1760.6273332553553 Test RE 0.018755150072978684\n",
      "98 Train Loss 89901.3 Test MSE 1625.667305617299 Test RE 0.018021986475425463\n",
      "99 Train Loss 89612.875 Test MSE 1268.9999531393896 Test RE 0.015922733512407326\n",
      "100 Train Loss 89080.86 Test MSE 1126.1919587931338 Test RE 0.01500006132849047\n",
      "101 Train Loss 88426.78 Test MSE 2765.4576069000314 Test RE 0.023505545060729292\n",
      "102 Train Loss 87632.16 Test MSE 2424.146352753349 Test RE 0.02200727354241904\n",
      "103 Train Loss 87288.58 Test MSE 2201.3381618458325 Test RE 0.02097153429093547\n",
      "104 Train Loss 86587.37 Test MSE 1565.6991256439942 Test RE 0.017686462523370382\n",
      "105 Train Loss 86209.21 Test MSE 1627.718857669725 Test RE 0.018033354541265877\n",
      "106 Train Loss 85749.08 Test MSE 1682.5342619344165 Test RE 0.018334487806264003\n",
      "107 Train Loss 85216.94 Test MSE 1899.6225597376913 Test RE 0.01948141432729512\n",
      "108 Train Loss 84625.97 Test MSE 2182.562707899561 Test RE 0.020881908519865374\n",
      "109 Train Loss 84247.56 Test MSE 1676.4387583878336 Test RE 0.018301246480600587\n",
      "110 Train Loss 83713.195 Test MSE 1743.846737680921 Test RE 0.018665558117528243\n",
      "111 Train Loss 83194.516 Test MSE 1997.807881485787 Test RE 0.01997853711176323\n",
      "112 Train Loss 82582.78 Test MSE 1572.285055957976 Test RE 0.01772362150651852\n",
      "113 Train Loss 82006.12 Test MSE 1413.345503715533 Test RE 0.016803935058329042\n",
      "114 Train Loss 81685.46 Test MSE 1417.5528958707587 Test RE 0.016828928312001907\n",
      "115 Train Loss 81208.63 Test MSE 1454.539856646116 Test RE 0.017047065768908815\n",
      "116 Train Loss 80564.56 Test MSE 2146.9431550854333 Test RE 0.020710810573392788\n",
      "117 Train Loss 80287.26 Test MSE 2325.731335690475 Test RE 0.021555921623073286\n",
      "118 Train Loss 79974.21 Test MSE 1992.8667144586213 Test RE 0.01995381541440356\n",
      "119 Train Loss 79594.56 Test MSE 1890.5092845031224 Test RE 0.01943462794473019\n",
      "120 Train Loss 79395.17 Test MSE 1907.1251715030587 Test RE 0.01951984760833602\n",
      "121 Train Loss 79133.414 Test MSE 1936.6578836594995 Test RE 0.019670403906924656\n",
      "122 Train Loss 78770.58 Test MSE 1809.549777279049 Test RE 0.019013938758458172\n",
      "123 Train Loss 78507.055 Test MSE 1887.7789049956177 Test RE 0.019420588584112407\n",
      "124 Train Loss 78151.79 Test MSE 1818.255557601352 Test RE 0.019059622099144427\n",
      "125 Train Loss 77850.82 Test MSE 3359.181735752335 Test RE 0.02590619163651722\n",
      "126 Train Loss 77475.64 Test MSE 2718.0397434223237 Test RE 0.02330315506170549\n",
      "127 Train Loss 77194.805 Test MSE 1475.6663357261086 Test RE 0.017170419610980064\n",
      "128 Train Loss 76960.64 Test MSE 1387.5834969948546 Test RE 0.016650082381235425\n",
      "129 Train Loss 76550.72 Test MSE 1755.527306498631 Test RE 0.0187279662576546\n",
      "130 Train Loss 76217.67 Test MSE 1780.9322382928588 Test RE 0.018862989431881267\n",
      "131 Train Loss 75887.664 Test MSE 1495.1728319846125 Test RE 0.017283532960915664\n",
      "132 Train Loss 75516.6 Test MSE 1777.175007507774 Test RE 0.01884308131227014\n",
      "133 Train Loss 75314.86 Test MSE 2320.795802043719 Test RE 0.021533037105315195\n",
      "134 Train Loss 75034.37 Test MSE 2158.7285971686038 Test RE 0.020767577796673483\n",
      "135 Train Loss 74649.26 Test MSE 1949.3542879511879 Test RE 0.019734776509841557\n",
      "136 Train Loss 74194.15 Test MSE 1684.7871010705337 Test RE 0.018346758235335468\n",
      "137 Train Loss 73905.914 Test MSE 1303.3941248460658 Test RE 0.01613707075329602\n",
      "138 Train Loss 73756.73 Test MSE 1396.3290316178159 Test RE 0.016702470274292683\n",
      "139 Train Loss 73357.88 Test MSE 1900.1563887273717 Test RE 0.019484151453454012\n",
      "140 Train Loss 73064.41 Test MSE 2143.234199187744 Test RE 0.020692913339548386\n",
      "141 Train Loss 72791.84 Test MSE 1517.0820619035578 Test RE 0.017409702916849058\n",
      "142 Train Loss 72509.836 Test MSE 1414.4982878388935 Test RE 0.016810786660110204\n",
      "143 Train Loss 72336.37 Test MSE 1317.639951521305 Test RE 0.01622501850710046\n",
      "144 Train Loss 72161.38 Test MSE 1307.9183996209658 Test RE 0.016165053576988546\n",
      "145 Train Loss 71917.48 Test MSE 1400.2310637938554 Test RE 0.016725791463884053\n",
      "146 Train Loss 71693.72 Test MSE 1591.648410117555 Test RE 0.017832424483139365\n",
      "147 Train Loss 71503.734 Test MSE 1583.019508619104 Test RE 0.01778402078023322\n",
      "148 Train Loss 71171.35 Test MSE 1392.8063147165285 Test RE 0.016681388126151005\n",
      "149 Train Loss 70854.41 Test MSE 1869.488137680579 Test RE 0.019326276138701744\n",
      "150 Train Loss 70451.48 Test MSE 2206.9038357684967 Test RE 0.020998028865918294\n",
      "151 Train Loss 70230.46 Test MSE 2245.608184578328 Test RE 0.021181358698857785\n",
      "152 Train Loss 69955.03 Test MSE 2573.96471191312 Test RE 0.02267713147389858\n",
      "153 Train Loss 69618.2 Test MSE 2216.1579187965963 Test RE 0.021042007724506928\n",
      "154 Train Loss 69431.17 Test MSE 2046.726938590407 Test RE 0.02022165871792271\n",
      "155 Train Loss 69260.586 Test MSE 1852.7275694613554 Test RE 0.01923944791912192\n",
      "156 Train Loss 68962.37 Test MSE 1777.4938764373233 Test RE 0.0188447716926911\n",
      "157 Train Loss 68678.65 Test MSE 1739.8552667549975 Test RE 0.018644184188249598\n",
      "158 Train Loss 68469.88 Test MSE 1531.438269017001 Test RE 0.017491883306679855\n",
      "159 Train Loss 68330.14 Test MSE 1321.09275802674 Test RE 0.016246263004436018\n",
      "160 Train Loss 68089.47 Test MSE 1175.6026410403465 Test RE 0.015325586377076487\n",
      "161 Train Loss 67916.88 Test MSE 1189.4778675662324 Test RE 0.015415762344861195\n",
      "162 Train Loss 67748.98 Test MSE 1417.0648448388952 Test RE 0.016826031036379325\n",
      "163 Train Loss 67601.695 Test MSE 1449.732242983755 Test RE 0.017018870068724528\n",
      "164 Train Loss 67443.57 Test MSE 1240.2170454947225 Test RE 0.015741121519996723\n",
      "165 Train Loss 67293.73 Test MSE 1175.0722857919068 Test RE 0.01532212903451871\n",
      "166 Train Loss 67177.69 Test MSE 1302.01915532168 Test RE 0.016128556891383358\n",
      "167 Train Loss 67035.375 Test MSE 1370.830989810718 Test RE 0.016549267677423353\n",
      "168 Train Loss 66733.6 Test MSE 1306.68743646257 Test RE 0.01615744481884071\n",
      "169 Train Loss 66591.28 Test MSE 1368.7910715577787 Test RE 0.016536949703155647\n",
      "170 Train Loss 66401.43 Test MSE 1140.8998521721364 Test RE 0.015097692843707095\n",
      "171 Train Loss 66283.39 Test MSE 1356.9220562166147 Test RE 0.016465096278290833\n",
      "172 Train Loss 66185.125 Test MSE 1325.7828565888003 Test RE 0.016275075919521098\n",
      "173 Train Loss 65997.94 Test MSE 1428.8030257544287 Test RE 0.016895576079690507\n",
      "174 Train Loss 65826.37 Test MSE 1195.6426929440347 Test RE 0.015455659120628667\n",
      "175 Train Loss 65670.44 Test MSE 1158.8537730983537 Test RE 0.015216022550007507\n",
      "176 Train Loss 65460.727 Test MSE 1243.1503806955811 Test RE 0.01575972581020091\n",
      "177 Train Loss 65286.285 Test MSE 1099.3793742565188 Test RE 0.014820423570942253\n",
      "178 Train Loss 64986.195 Test MSE 1428.5993815754678 Test RE 0.01689437199198076\n",
      "179 Train Loss 64817.543 Test MSE 1372.191907288095 Test RE 0.01655748043331091\n",
      "180 Train Loss 64643.082 Test MSE 1095.309264083868 Test RE 0.014792964128165496\n",
      "181 Train Loss 64447.52 Test MSE 1060.1649636785094 Test RE 0.014553704323267701\n",
      "182 Train Loss 64206.297 Test MSE 1069.795891671009 Test RE 0.014619660467724524\n",
      "183 Train Loss 63949.625 Test MSE 1352.9160244021564 Test RE 0.016440773416743056\n",
      "184 Train Loss 63648.152 Test MSE 1316.7680798808562 Test RE 0.01621964963741961\n",
      "185 Train Loss 63499.746 Test MSE 1109.789183923956 Test RE 0.014890424111446376\n",
      "186 Train Loss 63414.484 Test MSE 1097.2854026776722 Test RE 0.014806302723378444\n",
      "187 Train Loss 63222.887 Test MSE 1043.6473645939902 Test RE 0.01443988431964211\n",
      "188 Train Loss 63117.125 Test MSE 1055.0606679856608 Test RE 0.014518626743822753\n",
      "189 Train Loss 62993.46 Test MSE 966.041081633146 Test RE 0.01389263486336921\n",
      "190 Train Loss 62840.27 Test MSE 933.9872151177881 Test RE 0.013660207279691172\n",
      "191 Train Loss 62693.84 Test MSE 940.7700182490254 Test RE 0.013709719138297827\n",
      "192 Train Loss 62590.76 Test MSE 1009.7887889734553 Test RE 0.014203719790689314\n",
      "193 Train Loss 62453.145 Test MSE 1237.2858753093365 Test RE 0.015722508971224576\n",
      "194 Train Loss 62389.203 Test MSE 1129.5677026742685 Test RE 0.015022525738831356\n",
      "195 Train Loss 62277.344 Test MSE 927.2703383627904 Test RE 0.013610999170705091\n",
      "196 Train Loss 62221.31 Test MSE 958.6741546023778 Test RE 0.013839561605516628\n",
      "197 Train Loss 62138.24 Test MSE 1004.8581874105219 Test RE 0.014169000361070735\n",
      "198 Train Loss 61953.855 Test MSE 914.7708831814804 Test RE 0.013518950878187181\n",
      "199 Train Loss 61854.22 Test MSE 959.7516925886214 Test RE 0.013847337169932767\n",
      "Training time: 48.14\n",
      "Training time: 48.14\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 472264.94 Test MSE 4752271.289484882 Test RE 0.9744003608544499\n",
      "1 Train Loss 464932.28 Test MSE 4111014.282972312 Test RE 0.9062777473142286\n",
      "2 Train Loss 185713.8 Test MSE 523769.8832362369 Test RE 0.32348718827616996\n",
      "3 Train Loss 174030.36 Test MSE 652202.9109561179 Test RE 0.36097588521076296\n",
      "4 Train Loss 164455.22 Test MSE 378775.1151657292 Test RE 0.2750917354410381\n",
      "5 Train Loss 149516.44 Test MSE 187240.01624075786 Test RE 0.1934132215429351\n",
      "6 Train Loss 145345.56 Test MSE 187691.58112891656 Test RE 0.19364630746785835\n",
      "7 Train Loss 140823.53 Test MSE 161475.0009031375 Test RE 0.1796137050270992\n",
      "8 Train Loss 136562.28 Test MSE 88370.43847100502 Test RE 0.1328740977543519\n",
      "9 Train Loss 134171.64 Test MSE 68922.48592591293 Test RE 0.11734572981546641\n",
      "10 Train Loss 130879.55 Test MSE 26508.03719190946 Test RE 0.07277389323299002\n",
      "11 Train Loss 127140.9 Test MSE 4695.2785858264415 Test RE 0.0306279201641263\n",
      "12 Train Loss 126096.99 Test MSE 6793.289324535817 Test RE 0.03684061567021899\n",
      "13 Train Loss 125985.91 Test MSE 7269.7989442698445 Test RE 0.038110796345122565\n",
      "14 Train Loss 125743.445 Test MSE 7559.181292503479 Test RE 0.03886191560071282\n",
      "15 Train Loss 125214.78 Test MSE 3693.398950846991 Test RE 0.027164388585091202\n",
      "16 Train Loss 125002.34 Test MSE 6541.741882986332 Test RE 0.03615209967811751\n",
      "17 Train Loss 124691.8 Test MSE 2388.3254150480866 Test RE 0.02184407071192581\n",
      "18 Train Loss 124586.63 Test MSE 1739.7672778764709 Test RE 0.018643712740529072\n",
      "19 Train Loss 124496.375 Test MSE 2458.113736560321 Test RE 0.022160921253992757\n",
      "20 Train Loss 124341.3 Test MSE 1702.6301258595183 Test RE 0.01844365459585178\n",
      "21 Train Loss 124322.18 Test MSE 1556.7916065101676 Test RE 0.01763608016966568\n",
      "22 Train Loss 124222.21 Test MSE 1335.9311118874946 Test RE 0.016337246268800277\n",
      "23 Train Loss 124155.586 Test MSE 1390.611807467404 Test RE 0.016668241338321073\n",
      "24 Train Loss 124103.34 Test MSE 1329.8741278741911 Test RE 0.016300168437438617\n",
      "25 Train Loss 124088.53 Test MSE 1326.1503166650493 Test RE 0.01627733120072135\n",
      "26 Train Loss 124041.97 Test MSE 1381.2364760844084 Test RE 0.016611958713076965\n",
      "27 Train Loss 123978.945 Test MSE 1880.0441864611928 Test RE 0.01938076215972111\n",
      "28 Train Loss 123949.195 Test MSE 1861.7466907383398 Test RE 0.019286220108133783\n",
      "29 Train Loss 123918.125 Test MSE 1806.6030634250317 Test RE 0.018998451075929516\n",
      "30 Train Loss 123895.664 Test MSE 2091.8064480888747 Test RE 0.02044313856632167\n",
      "31 Train Loss 123885.18 Test MSE 2367.8457046468616 Test RE 0.021750213444118024\n",
      "32 Train Loss 123851.9 Test MSE 2605.588986392796 Test RE 0.02281601420568731\n",
      "33 Train Loss 123801.89 Test MSE 2344.577626610724 Test RE 0.02164308334363939\n",
      "34 Train Loss 123742.695 Test MSE 2358.5553442848727 Test RE 0.021707502486318992\n",
      "35 Train Loss 123716.625 Test MSE 2394.5979938379505 Test RE 0.02187273699143996\n",
      "36 Train Loss 123663.25 Test MSE 2237.9541169335894 Test RE 0.02114522997050529\n",
      "37 Train Loss 123584.07 Test MSE 1888.0890719499362 Test RE 0.01942218394503955\n",
      "38 Train Loss 123572.15 Test MSE 1687.470244407068 Test RE 0.01836136168235205\n",
      "39 Train Loss 123569.05 Test MSE 1616.714063126293 Test RE 0.017972290577810943\n",
      "40 Train Loss 123568.234 Test MSE 1604.7154464686048 Test RE 0.01790547473653986\n",
      "41 Train Loss 123545.92 Test MSE 1620.5497753191505 Test RE 0.017993597899713554\n",
      "42 Train Loss 123520.96 Test MSE 1709.094436969405 Test RE 0.01847863358778485\n",
      "43 Train Loss 123470.35 Test MSE 1646.655429406841 Test RE 0.018137949520574344\n",
      "44 Train Loss 123383.4 Test MSE 1821.202509284763 Test RE 0.019075061360426315\n",
      "45 Train Loss 123311.46 Test MSE 2004.5379260847465 Test RE 0.020012159814178872\n",
      "46 Train Loss 123256.95 Test MSE 2008.4305828723486 Test RE 0.020031581419087088\n",
      "47 Train Loss 123211.15 Test MSE 3178.061465208117 Test RE 0.02519811013851466\n",
      "48 Train Loss 123133.445 Test MSE 4313.242112765472 Test RE 0.029355449990208615\n",
      "49 Train Loss 123065.58 Test MSE 3264.462094097728 Test RE 0.025538338478466358\n",
      "50 Train Loss 122996.25 Test MSE 2103.1222094287305 Test RE 0.020498358224052084\n",
      "51 Train Loss 122886.21 Test MSE 1766.52457241671 Test RE 0.018786534097641784\n",
      "52 Train Loss 122780.74 Test MSE 2513.6739619274067 Test RE 0.022409971122396503\n",
      "53 Train Loss 122679.336 Test MSE 2568.5462264695325 Test RE 0.022653249941805658\n",
      "54 Train Loss 122569.445 Test MSE 4749.055247340395 Test RE 0.03080281692184265\n",
      "55 Train Loss 122459.54 Test MSE 5584.549907804271 Test RE 0.033402649150361466\n",
      "56 Train Loss 122400.04 Test MSE 6726.031107688785 Test RE 0.036657788352516485\n",
      "57 Train Loss 122351.34 Test MSE 7330.084446396001 Test RE 0.03826848880956267\n",
      "58 Train Loss 122289.57 Test MSE 7607.155100929105 Test RE 0.03898503775994952\n",
      "59 Train Loss 122122.29 Test MSE 9991.477233761674 Test RE 0.044678818010796234\n",
      "60 Train Loss 121957.45 Test MSE 15874.90579691619 Test RE 0.05631737477870689\n",
      "61 Train Loss 121879.54 Test MSE 16301.131340918168 Test RE 0.057068400046583305\n",
      "62 Train Loss 121755.336 Test MSE 17320.748007733975 Test RE 0.05882611198297245\n",
      "63 Train Loss 121664.305 Test MSE 19798.356012597884 Test RE 0.06289286637473489\n",
      "64 Train Loss 121592.695 Test MSE 17317.277982313717 Test RE 0.058820219098652274\n",
      "65 Train Loss 121483.234 Test MSE 17316.927129641048 Test RE 0.05881962323896724\n",
      "66 Train Loss 121410.46 Test MSE 19769.154681759523 Test RE 0.06284646774703988\n",
      "67 Train Loss 121336.97 Test MSE 21326.778048555785 Test RE 0.0652753859381931\n",
      "68 Train Loss 121082.164 Test MSE 24072.592813981777 Test RE 0.06935028634103636\n",
      "69 Train Loss 120910.54 Test MSE 26967.750752987504 Test RE 0.07340221854682438\n",
      "70 Train Loss 120789.25 Test MSE 31866.894086236465 Test RE 0.07979151151422523\n",
      "71 Train Loss 120512.07 Test MSE 31845.36380653705 Test RE 0.07976455212768298\n",
      "72 Train Loss 120277.53 Test MSE 28196.536206568922 Test RE 0.07505587703223762\n",
      "73 Train Loss 120110.72 Test MSE 21806.843693435014 Test RE 0.06600597171907663\n",
      "74 Train Loss 119877.4 Test MSE 24057.72434178018 Test RE 0.06932886587997582\n",
      "75 Train Loss 119657.195 Test MSE 26139.61879879763 Test RE 0.07226640465945013\n",
      "76 Train Loss 119547.6 Test MSE 24975.635288262147 Test RE 0.07063908995841804\n",
      "77 Train Loss 119482.7 Test MSE 22686.93227333867 Test RE 0.06732474403696784\n",
      "78 Train Loss 119314.66 Test MSE 22187.15781869351 Test RE 0.0665790601033346\n",
      "79 Train Loss 119165.375 Test MSE 26588.673839153653 Test RE 0.07288449717426697\n",
      "80 Train Loss 118779.305 Test MSE 38059.326402002385 Test RE 0.08720017820181075\n",
      "81 Train Loss 118230.4 Test MSE 37820.96318587021 Test RE 0.0869266846393873\n",
      "82 Train Loss 117896.164 Test MSE 27200.53957323663 Test RE 0.07371834612448731\n",
      "83 Train Loss 117640.98 Test MSE 28956.308764926373 Test RE 0.07606036814076574\n",
      "84 Train Loss 117160.164 Test MSE 30554.701109773374 Test RE 0.07813144267877273\n",
      "85 Train Loss 116545.195 Test MSE 22945.138292666867 Test RE 0.06770678052024678\n",
      "86 Train Loss 116146.47 Test MSE 25610.97390775098 Test RE 0.07153191807743901\n",
      "87 Train Loss 115762.5 Test MSE 27396.25834106602 Test RE 0.07398308724964661\n",
      "88 Train Loss 115288.2 Test MSE 24551.33578550453 Test RE 0.07003649228747767\n",
      "89 Train Loss 114938.52 Test MSE 24150.34203429383 Test RE 0.06946218920209993\n",
      "90 Train Loss 114402.65 Test MSE 25777.10092658666 Test RE 0.07176354097534939\n",
      "91 Train Loss 114057.49 Test MSE 19077.765863401288 Test RE 0.061737719166901496\n",
      "92 Train Loss 113911.24 Test MSE 14556.495978664 Test RE 0.05392811571685665\n",
      "93 Train Loss 113601.016 Test MSE 10687.391356841194 Test RE 0.0462085861027293\n",
      "94 Train Loss 113351.63 Test MSE 13302.357211120423 Test RE 0.051552665671650434\n",
      "95 Train Loss 112862.78 Test MSE 14288.735720066106 Test RE 0.05342982177558726\n",
      "96 Train Loss 112487.055 Test MSE 16835.54131934852 Test RE 0.057996310477366746\n",
      "97 Train Loss 111905.23 Test MSE 21469.150818808597 Test RE 0.0654929054068227\n",
      "98 Train Loss 111406.74 Test MSE 21360.00047566275 Test RE 0.06532620849681924\n",
      "99 Train Loss 110652.484 Test MSE 21599.542269655587 Test RE 0.06569148773333386\n",
      "100 Train Loss 110130.18 Test MSE 16965.58823290472 Test RE 0.05821987715453633\n",
      "101 Train Loss 109732.734 Test MSE 18420.934413629126 Test RE 0.06066562158809114\n",
      "102 Train Loss 109282.48 Test MSE 23163.138627325276 Test RE 0.06802765911959689\n",
      "103 Train Loss 108820.414 Test MSE 26239.857067803616 Test RE 0.0724048329987465\n",
      "104 Train Loss 108236.53 Test MSE 27704.306513901083 Test RE 0.07439786374169904\n",
      "105 Train Loss 107645.664 Test MSE 27867.370402587734 Test RE 0.07461649051100877\n",
      "106 Train Loss 107346.41 Test MSE 24214.54074722206 Test RE 0.06955445339202541\n",
      "107 Train Loss 106771.22 Test MSE 25607.41048988543 Test RE 0.07152694155872542\n",
      "108 Train Loss 106532.336 Test MSE 25246.52521014121 Test RE 0.07102113850986\n",
      "109 Train Loss 105947.82 Test MSE 17691.775164308816 Test RE 0.05945282961852383\n",
      "110 Train Loss 105299.66 Test MSE 11994.187032704276 Test RE 0.04895220197123005\n",
      "111 Train Loss 104301.62 Test MSE 10802.43038833322 Test RE 0.04645661494820097\n",
      "112 Train Loss 103606.99 Test MSE 7307.24013317902 Test RE 0.03820881012903253\n",
      "113 Train Loss 103139.75 Test MSE 6820.452853507731 Test RE 0.036914197311735925\n",
      "114 Train Loss 102496.125 Test MSE 6097.609318007897 Test RE 0.0349033105353118\n",
      "115 Train Loss 101955.03 Test MSE 6291.346283056256 Test RE 0.03545345943200298\n",
      "116 Train Loss 101316.43 Test MSE 7292.481340693203 Test RE 0.0381702045187315\n",
      "117 Train Loss 100833.37 Test MSE 7859.986431917015 Test RE 0.03962759555134555\n",
      "118 Train Loss 100295.7 Test MSE 7028.323701533568 Test RE 0.037472502857090674\n",
      "119 Train Loss 99569.47 Test MSE 6337.210546512061 Test RE 0.03558245360836655\n",
      "120 Train Loss 99189.86 Test MSE 5391.7909675167975 Test RE 0.03282111622739309\n",
      "121 Train Loss 97125.7 Test MSE 8760.76264105839 Test RE 0.041836734656787646\n",
      "122 Train Loss 96456.27 Test MSE 7546.57209613452 Test RE 0.03882948999654743\n",
      "123 Train Loss 94564.09 Test MSE 7826.63763249461 Test RE 0.039543439077450844\n",
      "124 Train Loss 93733.3 Test MSE 9278.822272246189 Test RE 0.04305595750562398\n",
      "125 Train Loss 92609.086 Test MSE 17679.341971223 Test RE 0.05943193520803568\n",
      "126 Train Loss 91829.56 Test MSE 20084.230145960915 Test RE 0.06334530306849503\n",
      "127 Train Loss 90715.234 Test MSE 19996.3136334364 Test RE 0.06320650745634905\n",
      "128 Train Loss 89595.01 Test MSE 17021.231604045373 Test RE 0.05831527314915511\n",
      "129 Train Loss 88805.305 Test MSE 13676.589005538228 Test RE 0.052272794940741614\n",
      "130 Train Loss 87892.24 Test MSE 12769.585003769915 Test RE 0.050509749583142194\n",
      "131 Train Loss 87259.06 Test MSE 9472.234907032034 Test RE 0.04350238359182265\n",
      "132 Train Loss 86437.42 Test MSE 5475.268349299776 Test RE 0.0330742137124153\n",
      "133 Train Loss 85558.16 Test MSE 4367.36479010433 Test RE 0.029539052309678255\n",
      "134 Train Loss 84640.75 Test MSE 6404.405462710336 Test RE 0.03577060069415573\n",
      "135 Train Loss 83891.65 Test MSE 4527.07101205432 Test RE 0.030074296502519308\n",
      "136 Train Loss 83438.53 Test MSE 3258.1863711715328 Test RE 0.025513778744920758\n",
      "137 Train Loss 82849.44 Test MSE 2446.27038863319 Test RE 0.022107470431639815\n",
      "138 Train Loss 82221.53 Test MSE 2574.959261298358 Test RE 0.022681512137875632\n",
      "139 Train Loss 81927.05 Test MSE 2903.8769079079075 Test RE 0.02408662355768451\n",
      "140 Train Loss 81318.695 Test MSE 2951.406192805316 Test RE 0.024282942738927372\n",
      "141 Train Loss 80831.63 Test MSE 2736.567993487544 Test RE 0.0233824462805258\n",
      "142 Train Loss 80414.2 Test MSE 3555.7365236577334 Test RE 0.026653338199553112\n",
      "143 Train Loss 80039.43 Test MSE 5229.720776241987 Test RE 0.03232407267535129\n",
      "144 Train Loss 79699.32 Test MSE 6012.311824593173 Test RE 0.03465832517624594\n",
      "145 Train Loss 78887.77 Test MSE 5819.003460443006 Test RE 0.03409660444683525\n",
      "146 Train Loss 78069.95 Test MSE 6222.344971795212 Test RE 0.035258502760052955\n",
      "147 Train Loss 77588.64 Test MSE 5785.274775428879 Test RE 0.033997643776738744\n",
      "148 Train Loss 77066.55 Test MSE 7033.777881964831 Test RE 0.0374870399049216\n",
      "149 Train Loss 76715.64 Test MSE 9562.924531130957 Test RE 0.04371013902991477\n",
      "150 Train Loss 76216.805 Test MSE 14305.30996047819 Test RE 0.05346080079557088\n",
      "151 Train Loss 75968.56 Test MSE 16348.57151231629 Test RE 0.0571513810292223\n",
      "152 Train Loss 75607.23 Test MSE 13398.61115992202 Test RE 0.05173884333723376\n",
      "153 Train Loss 75271.02 Test MSE 8613.623407641719 Test RE 0.04148391767948538\n",
      "154 Train Loss 74943.27 Test MSE 7161.181796037786 Test RE 0.03782502059470263\n",
      "155 Train Loss 74528.19 Test MSE 5563.933770933104 Test RE 0.033340936897769395\n",
      "156 Train Loss 74362.73 Test MSE 4234.833329584704 Test RE 0.029087405469166844\n",
      "157 Train Loss 74043.57 Test MSE 3792.291800099579 Test RE 0.027525657213296584\n",
      "158 Train Loss 73678.984 Test MSE 3836.677502480924 Test RE 0.027686271371736702\n",
      "159 Train Loss 73486.14 Test MSE 3309.889113786333 Test RE 0.02571541550166694\n",
      "160 Train Loss 73328.6 Test MSE 2621.7957625846466 Test RE 0.022886862067725496\n",
      "161 Train Loss 73132.77 Test MSE 2246.544306200362 Test RE 0.02118577315147272\n",
      "162 Train Loss 72972.25 Test MSE 2374.039315359659 Test RE 0.021778641051849037\n",
      "163 Train Loss 72702.26 Test MSE 2831.5821619982758 Test RE 0.023784904255346663\n",
      "164 Train Loss 72391.195 Test MSE 2666.5138188223996 Test RE 0.023081219069069552\n",
      "165 Train Loss 72193.64 Test MSE 1826.479447674942 Test RE 0.019102676387963965\n",
      "166 Train Loss 71963.2 Test MSE 1418.5655519077177 Test RE 0.016834938272347055\n",
      "167 Train Loss 71841.59 Test MSE 1443.5494940040905 Test RE 0.016982540660357655\n",
      "168 Train Loss 71664.1 Test MSE 1556.2775508368845 Test RE 0.01763316819495174\n",
      "169 Train Loss 70905.91 Test MSE 2624.5577501668977 Test RE 0.02289891422490657\n",
      "170 Train Loss 70280.34 Test MSE 3089.307619443382 Test RE 0.024843764363981388\n",
      "171 Train Loss 69705.59 Test MSE 3230.4736339480883 Test RE 0.025405042399971864\n",
      "172 Train Loss 69319.37 Test MSE 2399.534475198925 Test RE 0.021895270788041973\n",
      "173 Train Loss 69089.58 Test MSE 2436.1574582584167 Test RE 0.022061726745418356\n",
      "174 Train Loss 68566.57 Test MSE 2722.1650713954077 Test RE 0.023320832637722406\n",
      "175 Train Loss 68024.0 Test MSE 2197.551056953901 Test RE 0.02095348718001383\n",
      "176 Train Loss 67576.32 Test MSE 1450.9638561864908 Test RE 0.017026097684480854\n",
      "177 Train Loss 67130.47 Test MSE 1503.2093599525365 Test RE 0.017329920056527413\n",
      "178 Train Loss 66666.7 Test MSE 1466.8292565939123 Test RE 0.017118929580499997\n",
      "179 Train Loss 66104.44 Test MSE 2437.962487409325 Test RE 0.02206989836136276\n",
      "180 Train Loss 65678.75 Test MSE 1665.4511619941516 Test RE 0.018241173519363375\n",
      "181 Train Loss 65352.3 Test MSE 1582.0030002898766 Test RE 0.01777831001415025\n",
      "182 Train Loss 65126.195 Test MSE 1705.5638242583286 Test RE 0.018459537326807388\n",
      "183 Train Loss 64838.25 Test MSE 1469.4426504809787 Test RE 0.017134172866733317\n",
      "184 Train Loss 64589.24 Test MSE 1913.7807888897323 Test RE 0.019553878800520966\n",
      "185 Train Loss 64264.52 Test MSE 2888.704669610763 Test RE 0.024023616996930928\n",
      "186 Train Loss 64052.5 Test MSE 3065.771498059228 Test RE 0.024748946384843096\n",
      "187 Train Loss 63710.57 Test MSE 2704.428292128079 Test RE 0.023244732835619532\n",
      "188 Train Loss 63395.37 Test MSE 2374.597165952115 Test RE 0.021781199668741775\n",
      "189 Train Loss 63154.734 Test MSE 2202.7451235978497 Test RE 0.020978235086390545\n",
      "190 Train Loss 63079.234 Test MSE 1889.2567898494885 Test RE 0.019428188991787495\n",
      "191 Train Loss 62911.125 Test MSE 1680.5455052897744 Test RE 0.01832364891387934\n",
      "192 Train Loss 62530.13 Test MSE 1844.2214875377058 Test RE 0.01919523186926188\n",
      "193 Train Loss 62239.703 Test MSE 1520.3733672046426 Test RE 0.01742857783607938\n",
      "194 Train Loss 62099.547 Test MSE 1261.2645239013593 Test RE 0.015874129313257445\n",
      "195 Train Loss 61992.703 Test MSE 1142.4927481951747 Test RE 0.015108228679312464\n",
      "196 Train Loss 61798.945 Test MSE 1456.764464845019 Test RE 0.017060096884240032\n",
      "197 Train Loss 61684.094 Test MSE 1957.0726229039728 Test RE 0.019773807162002163\n",
      "198 Train Loss 61580.54 Test MSE 2854.602934248701 Test RE 0.023881394211171605\n",
      "199 Train Loss 61454.633 Test MSE 4130.87342929503 Test RE 0.028728157149581615\n",
      "Training time: 49.83\n",
      "Training time: 49.83\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 580133.6 Test MSE 1766985.7552491135 Test RE 0.5941599137427714\n",
      "1 Train Loss 498582.44 Test MSE 2045427.367845467 Test RE 0.6392619495359779\n",
      "2 Train Loss 344447.62 Test MSE 2276206.5725616706 Test RE 0.674361332568241\n",
      "3 Train Loss 170067.31 Test MSE 603214.0478982604 Test RE 0.3471542985438251\n",
      "4 Train Loss 154474.95 Test MSE 164350.7826398833 Test RE 0.18120605766643652\n",
      "5 Train Loss 142097.22 Test MSE 155767.67903566637 Test RE 0.17641093350215506\n",
      "6 Train Loss 129166.16 Test MSE 28052.1415930032 Test RE 0.07486344958555234\n",
      "7 Train Loss 126855.336 Test MSE 12343.833320802667 Test RE 0.049660586924789925\n",
      "8 Train Loss 126610.63 Test MSE 5332.117760490495 Test RE 0.03263898838986561\n",
      "9 Train Loss 126300.94 Test MSE 5025.343851671289 Test RE 0.031686167611807314\n",
      "10 Train Loss 126012.81 Test MSE 6192.287340934433 Test RE 0.03517323988756044\n",
      "11 Train Loss 125091.66 Test MSE 5129.3045718256135 Test RE 0.032012240244021155\n",
      "12 Train Loss 124820.65 Test MSE 2896.6867639201605 Test RE 0.024056785235597417\n",
      "13 Train Loss 124655.82 Test MSE 2327.76793513372 Test RE 0.021565357616546762\n",
      "14 Train Loss 124648.234 Test MSE 2435.0508748438597 Test RE 0.022056715592757778\n",
      "15 Train Loss 124637.77 Test MSE 2595.1576108646964 Test RE 0.022770296884213184\n",
      "16 Train Loss 124560.0 Test MSE 2633.899581078013 Test RE 0.022939631135862407\n",
      "17 Train Loss 124438.8 Test MSE 1902.001846448249 Test RE 0.01949361079365881\n",
      "18 Train Loss 123977.625 Test MSE 2421.0836381937333 Test RE 0.02199336693572153\n",
      "19 Train Loss 123874.23 Test MSE 3041.853353284416 Test RE 0.024652215764732487\n",
      "20 Train Loss 123716.74 Test MSE 2547.9518523290303 Test RE 0.022562251303001164\n",
      "21 Train Loss 123603.76 Test MSE 2035.5209327507794 Test RE 0.02016622507835235\n",
      "22 Train Loss 123554.734 Test MSE 1682.9468274903938 Test RE 0.01833673552112189\n",
      "23 Train Loss 123497.516 Test MSE 1555.980595083878 Test RE 0.017631485808495197\n",
      "24 Train Loss 123429.695 Test MSE 1506.3911496430612 Test RE 0.01734825117359525\n",
      "25 Train Loss 123331.72 Test MSE 1640.5814982626316 Test RE 0.01810446636567444\n",
      "26 Train Loss 123277.836 Test MSE 1721.5802530010578 Test RE 0.018546008731924555\n",
      "27 Train Loss 123236.55 Test MSE 1642.348123596923 Test RE 0.01811421144793362\n",
      "28 Train Loss 123159.93 Test MSE 1485.4151450570046 Test RE 0.017227043384944882\n",
      "29 Train Loss 123011.625 Test MSE 2097.430609051235 Test RE 0.02047060246555694\n",
      "30 Train Loss 122902.34 Test MSE 2551.680449151925 Test RE 0.022578753731068147\n",
      "31 Train Loss 122551.45 Test MSE 2362.646847725662 Test RE 0.021726322870623\n",
      "32 Train Loss 122316.4 Test MSE 1997.8787497800647 Test RE 0.019978891458220807\n",
      "33 Train Loss 122076.98 Test MSE 3972.528349320449 Test RE 0.02817217167590095\n",
      "34 Train Loss 121838.766 Test MSE 5290.1906169452 Test RE 0.032510412809213504\n",
      "35 Train Loss 121545.61 Test MSE 2994.5709512629082 Test RE 0.024459869034338038\n",
      "36 Train Loss 121260.52 Test MSE 2859.773246197169 Test RE 0.023903011648257266\n",
      "37 Train Loss 120777.586 Test MSE 2535.7354108312875 Test RE 0.022508097688888694\n",
      "38 Train Loss 120424.78 Test MSE 2473.577237943352 Test RE 0.02223051693188057\n",
      "39 Train Loss 120360.31 Test MSE 2843.1663835026607 Test RE 0.02383350753707303\n",
      "40 Train Loss 120244.15 Test MSE 3392.59132652928 Test RE 0.026034701183590497\n",
      "41 Train Loss 120123.555 Test MSE 2915.1072306343403 Test RE 0.024133154374691174\n",
      "42 Train Loss 120000.53 Test MSE 3404.082283620131 Test RE 0.026078754638779233\n",
      "43 Train Loss 119858.85 Test MSE 3560.521548535884 Test RE 0.02667126613194375\n",
      "44 Train Loss 119688.79 Test MSE 6207.366888203389 Test RE 0.03521604103595363\n",
      "45 Train Loss 119563.2 Test MSE 8802.3085302868 Test RE 0.04193581784165249\n",
      "46 Train Loss 119307.91 Test MSE 10892.790453890897 Test RE 0.046650510241624886\n",
      "47 Train Loss 118648.92 Test MSE 4719.517734936111 Test RE 0.030706875973800455\n",
      "48 Train Loss 118456.766 Test MSE 4392.483351556328 Test RE 0.02962387630941919\n",
      "49 Train Loss 118278.72 Test MSE 4389.972578269836 Test RE 0.029615408494833777\n",
      "50 Train Loss 118040.46 Test MSE 3032.0571892124713 Test RE 0.024612488028229407\n",
      "51 Train Loss 117872.48 Test MSE 4128.598327763388 Test RE 0.02872024496379285\n",
      "52 Train Loss 117744.49 Test MSE 7324.097241866738 Test RE 0.03825285678807513\n",
      "53 Train Loss 117465.516 Test MSE 7977.881807655002 Test RE 0.03992368521190323\n",
      "54 Train Loss 117314.805 Test MSE 4410.077679521888 Test RE 0.029683147029485303\n",
      "55 Train Loss 117159.9 Test MSE 3158.15628052039 Test RE 0.025119074398069985\n",
      "56 Train Loss 117058.55 Test MSE 2805.5619726992995 Test RE 0.02367536901524247\n",
      "57 Train Loss 116968.28 Test MSE 1918.0029792220823 Test RE 0.01957543683697895\n",
      "58 Train Loss 116879.65 Test MSE 1681.1922106909647 Test RE 0.018327174216490414\n",
      "59 Train Loss 116706.46 Test MSE 1732.8028219052628 Test RE 0.018606359031575936\n",
      "60 Train Loss 116458.45 Test MSE 1649.1456088678167 Test RE 0.018151659033028934\n",
      "61 Train Loss 116381.195 Test MSE 1845.2890598950144 Test RE 0.019200786878331055\n",
      "62 Train Loss 116297.984 Test MSE 2205.046262784728 Test RE 0.02098918988033133\n",
      "63 Train Loss 116149.95 Test MSE 2483.951201398097 Test RE 0.02227708456558084\n",
      "64 Train Loss 115824.82 Test MSE 3089.07341764193 Test RE 0.02484282263765226\n",
      "65 Train Loss 115617.8 Test MSE 10911.092163847672 Test RE 0.04668968412398871\n",
      "66 Train Loss 115337.11 Test MSE 7343.672364273399 Test RE 0.03830394190234095\n",
      "67 Train Loss 115160.586 Test MSE 5296.385177143788 Test RE 0.03252944130973951\n",
      "68 Train Loss 114982.055 Test MSE 4269.825196409923 Test RE 0.02920733093587659\n",
      "69 Train Loss 114855.49 Test MSE 7222.473136760145 Test RE 0.0379865446855193\n",
      "70 Train Loss 114744.99 Test MSE 8670.941240385673 Test RE 0.04162171252143057\n",
      "71 Train Loss 114360.45 Test MSE 8329.48189738158 Test RE 0.04079395551695683\n",
      "72 Train Loss 114157.45 Test MSE 6855.115475979218 Test RE 0.03700788033548421\n",
      "73 Train Loss 114095.84 Test MSE 7547.243967485493 Test RE 0.0388312184529202\n",
      "74 Train Loss 113849.164 Test MSE 7373.8270424151615 Test RE 0.038382503397023524\n",
      "75 Train Loss 113331.82 Test MSE 3250.383774903235 Test RE 0.025483210659054515\n",
      "76 Train Loss 112847.766 Test MSE 3107.1808840167114 Test RE 0.02491552781867956\n",
      "77 Train Loss 112645.75 Test MSE 3004.9200865355906 Test RE 0.024502098817020205\n",
      "78 Train Loss 112437.37 Test MSE 2901.0021942658136 Test RE 0.02407469824323316\n",
      "79 Train Loss 112185.45 Test MSE 2898.141868001089 Test RE 0.024062826746858543\n",
      "80 Train Loss 112069.39 Test MSE 2430.398743389503 Test RE 0.02203563599285584\n",
      "81 Train Loss 111781.6 Test MSE 1881.1701089364792 Test RE 0.019386564674831866\n",
      "82 Train Loss 111633.73 Test MSE 2391.6931955713153 Test RE 0.02185946646156028\n",
      "83 Train Loss 111535.914 Test MSE 3070.44509301948 Test RE 0.02476780338429022\n",
      "84 Train Loss 111395.02 Test MSE 3366.043962695115 Test RE 0.025932639069606984\n",
      "85 Train Loss 111266.3 Test MSE 3552.3445911987774 Test RE 0.02664062242420699\n",
      "86 Train Loss 111161.414 Test MSE 3462.466234166042 Test RE 0.02630144426290607\n",
      "87 Train Loss 111078.48 Test MSE 3639.1364657752133 Test RE 0.026964104060676824\n",
      "88 Train Loss 110950.46 Test MSE 3093.7094302889027 Test RE 0.024861457426309883\n",
      "89 Train Loss 110830.55 Test MSE 2351.2775774950615 Test RE 0.021673985316503056\n",
      "90 Train Loss 110703.31 Test MSE 2149.178270249985 Test RE 0.020721588456566204\n",
      "91 Train Loss 110356.39 Test MSE 3712.3578497289673 Test RE 0.027234019254252406\n",
      "92 Train Loss 110097.02 Test MSE 3880.090411949339 Test RE 0.027842469101419066\n",
      "93 Train Loss 109991.83 Test MSE 3028.0003880933396 Test RE 0.024596017133470597\n",
      "94 Train Loss 109854.98 Test MSE 2286.8510504551996 Test RE 0.021374982259968263\n",
      "95 Train Loss 109687.01 Test MSE 1866.989812977287 Test RE 0.01931335831002276\n",
      "96 Train Loss 109581.76 Test MSE 1624.0416370863154 Test RE 0.01801297322151682\n",
      "97 Train Loss 109451.83 Test MSE 1556.9387037101778 Test RE 0.017636913343715414\n",
      "98 Train Loss 109325.68 Test MSE 1789.8251571053822 Test RE 0.01891002607479561\n",
      "99 Train Loss 109239.69 Test MSE 2142.1634239462896 Test RE 0.02068774352948189\n",
      "100 Train Loss 109139.445 Test MSE 2013.9041243511879 Test RE 0.02005885871007719\n",
      "101 Train Loss 109047.89 Test MSE 1774.3440026122187 Test RE 0.01882806700121986\n",
      "102 Train Loss 109008.586 Test MSE 1820.1974861315155 Test RE 0.019069797386817723\n",
      "103 Train Loss 108980.984 Test MSE 1859.912340800233 Test RE 0.019276716560900038\n",
      "104 Train Loss 108936.35 Test MSE 1830.5698856046579 Test RE 0.01912405484173998\n",
      "105 Train Loss 108872.17 Test MSE 1702.1217680026762 Test RE 0.018440901009933133\n",
      "106 Train Loss 108719.52 Test MSE 1835.371415327571 Test RE 0.019149119326832494\n",
      "107 Train Loss 108601.81 Test MSE 1767.015472534842 Test RE 0.018789144214518442\n",
      "108 Train Loss 108359.51 Test MSE 2708.6338469915318 Test RE 0.023262799320220448\n",
      "109 Train Loss 108179.67 Test MSE 2590.8493061474605 Test RE 0.022751388181671633\n",
      "110 Train Loss 108015.05 Test MSE 2324.178518561797 Test RE 0.021548724318554716\n",
      "111 Train Loss 107877.61 Test MSE 2359.9503337323436 Test RE 0.021713921089277114\n",
      "112 Train Loss 107749.32 Test MSE 2411.619430478082 Test RE 0.02195033793688191\n",
      "113 Train Loss 107612.734 Test MSE 2411.6188745197437 Test RE 0.021950335406740965\n",
      "114 Train Loss 107483.93 Test MSE 2514.1942313833447 Test RE 0.022412290162261744\n",
      "115 Train Loss 107439.266 Test MSE 2645.507832523572 Test RE 0.022990125895131223\n",
      "116 Train Loss 107346.96 Test MSE 2728.363885419195 Test RE 0.02334737020922303\n",
      "117 Train Loss 106949.84 Test MSE 3091.8058272829016 Test RE 0.024853807446804817\n",
      "118 Train Loss 106727.695 Test MSE 4530.189599837653 Test RE 0.03008465344044735\n",
      "119 Train Loss 106479.14 Test MSE 5450.470343114887 Test RE 0.032999230599739623\n",
      "120 Train Loss 106142.37 Test MSE 5627.6513164550515 Test RE 0.033531301774939876\n",
      "121 Train Loss 106028.68 Test MSE 5656.864664833783 Test RE 0.03361822024225052\n",
      "122 Train Loss 105800.68 Test MSE 4756.666987144847 Test RE 0.03082749226692641\n",
      "123 Train Loss 105577.0 Test MSE 4429.507427881121 Test RE 0.029748463592405777\n",
      "124 Train Loss 105443.0 Test MSE 4515.4201597601195 Test RE 0.030035572025105352\n",
      "125 Train Loss 105111.27 Test MSE 4356.178491302621 Test RE 0.02950119830157309\n",
      "126 Train Loss 104574.98 Test MSE 3320.530789081474 Test RE 0.025756721341100713\n",
      "127 Train Loss 104325.8 Test MSE 2963.4046637954784 Test RE 0.02433225188985849\n",
      "128 Train Loss 103888.37 Test MSE 5193.408725382264 Test RE 0.03221165769319419\n",
      "129 Train Loss 103583.83 Test MSE 9155.40113074103 Test RE 0.042768647073744115\n",
      "130 Train Loss 103275.05 Test MSE 10107.939783673457 Test RE 0.044938455985422864\n",
      "131 Train Loss 102879.91 Test MSE 8298.698981859076 Test RE 0.04071850549120536\n",
      "132 Train Loss 102435.734 Test MSE 7596.0343059813795 Test RE 0.03895653149385231\n",
      "133 Train Loss 102205.516 Test MSE 8180.25359892737 Test RE 0.040426878333692344\n",
      "134 Train Loss 101965.414 Test MSE 10048.677147236509 Test RE 0.04480652571818933\n",
      "135 Train Loss 101792.78 Test MSE 11163.070577842042 Test RE 0.04722572772744858\n",
      "136 Train Loss 101016.98 Test MSE 9056.048331798265 Test RE 0.042535955159945286\n",
      "137 Train Loss 100418.336 Test MSE 6756.886037912035 Test RE 0.03674177393640362\n",
      "138 Train Loss 99514.34 Test MSE 5130.148736393109 Test RE 0.032014874371785344\n",
      "139 Train Loss 99053.266 Test MSE 4132.608000204757 Test RE 0.028734188052799647\n",
      "140 Train Loss 98746.14 Test MSE 3657.5700241022123 Test RE 0.027032309327335545\n",
      "141 Train Loss 98198.734 Test MSE 5643.8812901554775 Test RE 0.03357961858664014\n",
      "142 Train Loss 97725.51 Test MSE 10044.87902379999 Test RE 0.04479805710103246\n",
      "143 Train Loss 97458.99 Test MSE 12157.725141645551 Test RE 0.049284798357364656\n",
      "144 Train Loss 97174.33 Test MSE 12020.21567033981 Test RE 0.04900528887939524\n",
      "145 Train Loss 97017.43 Test MSE 10445.392307269245 Test RE 0.0456824304364917\n",
      "146 Train Loss 96791.586 Test MSE 9954.749368683677 Test RE 0.04459662453998455\n",
      "147 Train Loss 96507.54 Test MSE 9271.841362265814 Test RE 0.04303975791103967\n",
      "148 Train Loss 96231.29 Test MSE 9011.502041643113 Test RE 0.04243120997684797\n",
      "149 Train Loss 96123.23 Test MSE 8891.794770661769 Test RE 0.0421484432679734\n",
      "150 Train Loss 95796.164 Test MSE 9859.58079950872 Test RE 0.04438293812135905\n",
      "151 Train Loss 95572.28 Test MSE 9705.812250110712 Test RE 0.04403548324753592\n",
      "152 Train Loss 95326.96 Test MSE 8387.452556239297 Test RE 0.04093566613598838\n",
      "153 Train Loss 95074.61 Test MSE 7018.731822025852 Test RE 0.037446923895123996\n",
      "154 Train Loss 94804.94 Test MSE 7315.14851641919 Test RE 0.038229480600731995\n",
      "155 Train Loss 94511.38 Test MSE 4958.452961392236 Test RE 0.03147457847245686\n",
      "156 Train Loss 94332.805 Test MSE 3426.2893343946753 Test RE 0.026163680726660594\n",
      "157 Train Loss 94168.46 Test MSE 3629.4935468235412 Test RE 0.026928355862536037\n",
      "158 Train Loss 93953.54 Test MSE 4452.184857024399 Test RE 0.02982451690536522\n",
      "159 Train Loss 93616.04 Test MSE 6011.363230845914 Test RE 0.03465559095616595\n",
      "160 Train Loss 93434.16 Test MSE 7428.846159355626 Test RE 0.038525431001816615\n",
      "161 Train Loss 93304.51 Test MSE 8851.973487571151 Test RE 0.04205395793012875\n",
      "162 Train Loss 93176.92 Test MSE 10246.704382164029 Test RE 0.04524586831004202\n",
      "163 Train Loss 92973.48 Test MSE 11353.652953288753 Test RE 0.047627154055720905\n",
      "164 Train Loss 92644.12 Test MSE 8288.067415156444 Test RE 0.040692414639743546\n",
      "165 Train Loss 92301.52 Test MSE 5993.115020743558 Test RE 0.034602950386645626\n",
      "166 Train Loss 91812.24 Test MSE 5453.619221909938 Test RE 0.03300876148123421\n",
      "167 Train Loss 91383.74 Test MSE 6274.86281621214 Test RE 0.03540698454558046\n",
      "168 Train Loss 90864.945 Test MSE 6376.085584489272 Test RE 0.0356914253967004\n",
      "169 Train Loss 90593.72 Test MSE 5866.513350529609 Test RE 0.03423551421503708\n",
      "170 Train Loss 90323.11 Test MSE 5256.588112031331 Test RE 0.03240699767192267\n",
      "171 Train Loss 90031.48 Test MSE 5090.820821032588 Test RE 0.031891924661783276\n",
      "172 Train Loss 89679.734 Test MSE 4229.8946332800115 Test RE 0.029070439539491576\n",
      "173 Train Loss 89464.72 Test MSE 3069.2791192054747 Test RE 0.024763100262850144\n",
      "174 Train Loss 89329.25 Test MSE 3056.788954402193 Test RE 0.024712663255385348\n",
      "175 Train Loss 89163.734 Test MSE 3578.8572355042083 Test RE 0.026739852713514457\n",
      "176 Train Loss 89011.81 Test MSE 4684.686392469286 Test RE 0.03059335352252965\n",
      "177 Train Loss 88921.81 Test MSE 5047.537774107657 Test RE 0.031756059904692935\n",
      "178 Train Loss 88783.28 Test MSE 4288.518249294758 Test RE 0.02927119513407985\n",
      "179 Train Loss 88591.74 Test MSE 3535.6445916208513 Test RE 0.026577928267614903\n",
      "180 Train Loss 88483.36 Test MSE 3625.90308401968 Test RE 0.026915033179624136\n",
      "181 Train Loss 88343.14 Test MSE 3806.7571277098796 Test RE 0.027578104216289742\n",
      "182 Train Loss 88217.48 Test MSE 3637.4313493079826 Test RE 0.026957786308488482\n",
      "183 Train Loss 88071.1 Test MSE 3263.8158977237345 Test RE 0.025535810711562624\n",
      "184 Train Loss 87886.12 Test MSE 2815.3562448046073 Test RE 0.023716658600721238\n",
      "185 Train Loss 87752.07 Test MSE 2575.234862004844 Test RE 0.022682725918926137\n",
      "186 Train Loss 87651.664 Test MSE 2708.1815621299716 Test RE 0.023260857040123786\n",
      "187 Train Loss 87470.19 Test MSE 2967.218234659655 Test RE 0.024347903301512083\n",
      "188 Train Loss 87149.67 Test MSE 2748.638816793593 Test RE 0.023433958762809327\n",
      "189 Train Loss 86752.37 Test MSE 2457.6999457402276 Test RE 0.022159055927017213\n",
      "190 Train Loss 86319.84 Test MSE 2960.5152873998995 Test RE 0.024320386790793565\n",
      "191 Train Loss 85781.96 Test MSE 3156.654919226381 Test RE 0.02511310298851218\n",
      "192 Train Loss 85352.2 Test MSE 2779.8466683655197 Test RE 0.0235666170362449\n",
      "193 Train Loss 84796.42 Test MSE 2871.031627371011 Test RE 0.023950016227880063\n",
      "194 Train Loss 84587.52 Test MSE 2587.680400144631 Test RE 0.022737470145290227\n",
      "195 Train Loss 84361.7 Test MSE 2703.9246659403134 Test RE 0.02324256838532147\n",
      "196 Train Loss 84181.86 Test MSE 2925.5863885212384 Test RE 0.024176492105904612\n",
      "197 Train Loss 84022.09 Test MSE 3253.0953720400594 Test RE 0.02549383798806101\n",
      "198 Train Loss 83824.945 Test MSE 3280.842323340293 Test RE 0.02560233070426868\n",
      "199 Train Loss 83552.8 Test MSE 3429.4928130997546 Test RE 0.026175909001033233\n",
      "Training time: 50.24\n",
      "Training time: 50.24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 581298.44 Test MSE 3972122.56984704 Test RE 0.8908367899194729\n",
      "1 Train Loss 450690.94 Test MSE 4096737.0215870882 Test RE 0.9047026593742356\n",
      "2 Train Loss 265052.6 Test MSE 821547.9660857435 Test RE 0.4051382856638618\n",
      "3 Train Loss 149688.02 Test MSE 232777.4298105995 Test RE 0.2156538709106542\n",
      "4 Train Loss 140180.66 Test MSE 85472.9264860112 Test RE 0.13067758823639541\n",
      "5 Train Loss 135461.94 Test MSE 70850.92938786071 Test RE 0.11897606455438216\n",
      "6 Train Loss 130538.21 Test MSE 77960.36869598857 Test RE 0.12480263815540477\n",
      "7 Train Loss 128615.98 Test MSE 68084.7244031539 Test RE 0.11663037327244026\n",
      "8 Train Loss 125465.16 Test MSE 32546.544703355044 Test RE 0.08063791090662814\n",
      "9 Train Loss 123551.805 Test MSE 8385.87529337738 Test RE 0.04093181697313442\n",
      "10 Train Loss 123099.45 Test MSE 4639.663910506151 Test RE 0.030445988900764272\n",
      "11 Train Loss 122766.78 Test MSE 5008.908485020189 Test RE 0.03163431043618934\n",
      "12 Train Loss 122686.484 Test MSE 4988.677925729108 Test RE 0.03157036164283138\n",
      "13 Train Loss 122327.34 Test MSE 5219.199166329895 Test RE 0.03229154010509611\n",
      "14 Train Loss 121834.37 Test MSE 4517.858951694197 Test RE 0.030043682081330906\n",
      "15 Train Loss 121468.17 Test MSE 2703.7215962834434 Test RE 0.02324169558936915\n",
      "16 Train Loss 121399.73 Test MSE 2458.023485190578 Test RE 0.022160514423375674\n",
      "17 Train Loss 121274.84 Test MSE 3611.051193668475 Test RE 0.026859853919322392\n",
      "18 Train Loss 121012.32 Test MSE 6567.314735911484 Test RE 0.03622269330476428\n",
      "19 Train Loss 120775.836 Test MSE 7946.300968018853 Test RE 0.03984458691459726\n",
      "20 Train Loss 120632.72 Test MSE 12068.743417327938 Test RE 0.049104110769881255\n",
      "21 Train Loss 120440.195 Test MSE 7669.3443542471405 Test RE 0.03914406669236505\n",
      "22 Train Loss 120223.71 Test MSE 3626.5710095927284 Test RE 0.026917512067052382\n",
      "23 Train Loss 120058.45 Test MSE 1938.3692199616532 Test RE 0.019679092907524245\n",
      "24 Train Loss 120015.46 Test MSE 1792.90388290018 Test RE 0.01892628290592111\n",
      "25 Train Loss 119980.33 Test MSE 1841.8702503495178 Test RE 0.019182991762095005\n",
      "26 Train Loss 119934.914 Test MSE 1969.9739908383965 Test RE 0.019838876313659465\n",
      "27 Train Loss 119847.2 Test MSE 2290.988251142566 Test RE 0.021394308536378758\n",
      "28 Train Loss 119769.555 Test MSE 3242.808430093023 Test RE 0.025453497749840397\n",
      "29 Train Loss 119695.516 Test MSE 4541.420737303028 Test RE 0.030121922931173398\n",
      "30 Train Loss 119583.25 Test MSE 4592.571847874167 Test RE 0.030291083161706492\n",
      "31 Train Loss 119516.03 Test MSE 3420.0986903654025 Test RE 0.026140033677859036\n",
      "32 Train Loss 119324.89 Test MSE 4932.581253700537 Test RE 0.03139235866774359\n",
      "33 Train Loss 119181.78 Test MSE 3221.2966818920904 Test RE 0.02536893211220133\n",
      "34 Train Loss 119103.234 Test MSE 2368.6452037811773 Test RE 0.021753885095773435\n",
      "35 Train Loss 119029.99 Test MSE 2666.674271795384 Test RE 0.023081913495343113\n",
      "36 Train Loss 118944.09 Test MSE 2754.143843599932 Test RE 0.023457414016692272\n",
      "37 Train Loss 118807.484 Test MSE 3494.357904313263 Test RE 0.026422293723909886\n",
      "38 Train Loss 118679.52 Test MSE 3151.916159673393 Test RE 0.02509424605676771\n",
      "39 Train Loss 118530.09 Test MSE 2173.396337401724 Test RE 0.02083801225381533\n",
      "40 Train Loss 118487.52 Test MSE 2109.334624386497 Test RE 0.020528610960836986\n",
      "41 Train Loss 118386.91 Test MSE 2376.499918293476 Test RE 0.021789924502226152\n",
      "42 Train Loss 118282.305 Test MSE 2934.454623312103 Test RE 0.02421310708623528\n",
      "43 Train Loss 118123.98 Test MSE 4637.636580716379 Test RE 0.03043933639256333\n",
      "44 Train Loss 117864.46 Test MSE 5694.450644746029 Test RE 0.033729720328834395\n",
      "45 Train Loss 117770.64 Test MSE 4474.685228139774 Test RE 0.029899785229209518\n",
      "46 Train Loss 117651.8 Test MSE 4169.2543651462365 Test RE 0.028861308678343203\n",
      "47 Train Loss 117530.79 Test MSE 4936.948247833976 Test RE 0.03140625199354632\n",
      "48 Train Loss 117382.85 Test MSE 5021.976683616598 Test RE 0.03167555037520491\n",
      "49 Train Loss 117257.45 Test MSE 3666.5475393828287 Test RE 0.027065464432287557\n",
      "50 Train Loss 117180.23 Test MSE 3321.547582644832 Test RE 0.025760664575716186\n",
      "51 Train Loss 117040.75 Test MSE 4385.640513645042 Test RE 0.0296007925117374\n",
      "52 Train Loss 116799.46 Test MSE 8101.818002636769 Test RE 0.040232596829154046\n",
      "53 Train Loss 116541.32 Test MSE 7559.561993939419 Test RE 0.03886289418557724\n",
      "54 Train Loss 116315.195 Test MSE 6712.144294835113 Test RE 0.03661992628602614\n",
      "55 Train Loss 115877.64 Test MSE 5915.871508333326 Test RE 0.03437923352337285\n",
      "56 Train Loss 115648.95 Test MSE 3916.603493885161 Test RE 0.027973166296128064\n",
      "57 Train Loss 115286.17 Test MSE 4623.72994820466 Test RE 0.030393663723663707\n",
      "58 Train Loss 115091.055 Test MSE 9903.146970114338 Test RE 0.04448088667634669\n",
      "59 Train Loss 114898.32 Test MSE 10606.629033721518 Test RE 0.046033660823106844\n",
      "60 Train Loss 114703.62 Test MSE 8857.565994148043 Test RE 0.042067240273422415\n",
      "61 Train Loss 114349.44 Test MSE 7584.812754818071 Test RE 0.038927745797035666\n",
      "62 Train Loss 113917.86 Test MSE 9537.719921296897 Test RE 0.043652498510054476\n",
      "63 Train Loss 113586.984 Test MSE 10032.237342539396 Test RE 0.04476985860048481\n",
      "64 Train Loss 113238.195 Test MSE 13626.232410662902 Test RE 0.05217647313812446\n",
      "65 Train Loss 112965.93 Test MSE 11042.230717330867 Test RE 0.04696942376899074\n",
      "66 Train Loss 112803.11 Test MSE 9839.945248922824 Test RE 0.04433872134525645\n",
      "67 Train Loss 112647.15 Test MSE 10512.47157849193 Test RE 0.0458288797060293\n",
      "68 Train Loss 111981.84 Test MSE 8208.385324211436 Test RE 0.040496332277294\n",
      "69 Train Loss 111403.336 Test MSE 9407.937509295038 Test RE 0.043354485396802415\n",
      "70 Train Loss 111014.88 Test MSE 6592.436875920402 Test RE 0.03629190903565968\n",
      "71 Train Loss 110217.59 Test MSE 8040.539574411625 Test RE 0.04008015760010442\n",
      "72 Train Loss 109435.62 Test MSE 5003.024412843646 Test RE 0.03161572422486293\n",
      "73 Train Loss 108911.24 Test MSE 3162.410385002312 Test RE 0.025135986671609798\n",
      "74 Train Loss 108346.51 Test MSE 4268.744024500718 Test RE 0.029203632875236613\n",
      "75 Train Loss 107474.91 Test MSE 5003.2145438039 Test RE 0.03161632496857319\n",
      "76 Train Loss 106825.72 Test MSE 3469.396528438699 Test RE 0.02632775291379848\n",
      "77 Train Loss 106277.38 Test MSE 6942.897397682979 Test RE 0.03724407540860135\n",
      "78 Train Loss 105828.94 Test MSE 4574.366095086784 Test RE 0.030230983983224883\n",
      "79 Train Loss 105166.04 Test MSE 3296.933695376502 Test RE 0.02566503909938063\n",
      "80 Train Loss 104298.766 Test MSE 3033.347806296337 Test RE 0.02461772571274204\n",
      "81 Train Loss 103186.805 Test MSE 3777.303529839111 Test RE 0.027471208549955592\n",
      "82 Train Loss 102722.8 Test MSE 3359.1471774709717 Test RE 0.025906058378504907\n",
      "83 Train Loss 101603.79 Test MSE 4057.8891708895335 Test RE 0.028473241676484594\n",
      "84 Train Loss 101160.87 Test MSE 2897.2226380258635 Test RE 0.024059010331572008\n",
      "85 Train Loss 100657.64 Test MSE 3228.188956139897 Test RE 0.025396057246543736\n",
      "86 Train Loss 100261.37 Test MSE 3227.114536765358 Test RE 0.025391830683747573\n",
      "87 Train Loss 99854.96 Test MSE 1890.887462544214 Test RE 0.019436571701912705\n",
      "88 Train Loss 99184.0 Test MSE 2770.259291465907 Test RE 0.02352594263661788\n",
      "89 Train Loss 98606.805 Test MSE 5550.044512340739 Test RE 0.03329929637219251\n",
      "90 Train Loss 98276.945 Test MSE 5077.116624333986 Test RE 0.031848970121531574\n",
      "91 Train Loss 97856.29 Test MSE 4585.409929564286 Test RE 0.030267455125569474\n",
      "92 Train Loss 97250.59 Test MSE 6267.525249040074 Test RE 0.03538627675246136\n",
      "93 Train Loss 96808.66 Test MSE 7324.131022610518 Test RE 0.038252945004303096\n",
      "94 Train Loss 96349.49 Test MSE 9851.105941992842 Test RE 0.04436385921997215\n",
      "95 Train Loss 95930.15 Test MSE 10347.324572590744 Test RE 0.04546747741370517\n",
      "96 Train Loss 95012.67 Test MSE 10556.649232593549 Test RE 0.045925074486591395\n",
      "97 Train Loss 94318.94 Test MSE 10839.322086607499 Test RE 0.046535875012227786\n",
      "98 Train Loss 93527.22 Test MSE 13628.191174350997 Test RE 0.052180223173544794\n",
      "99 Train Loss 92933.195 Test MSE 18650.254787733338 Test RE 0.06104206377332765\n",
      "100 Train Loss 92351.86 Test MSE 15302.649571631631 Test RE 0.055292998263159365\n",
      "101 Train Loss 91611.87 Test MSE 14015.223804422176 Test RE 0.05291597983476825\n",
      "102 Train Loss 90928.016 Test MSE 16076.741777027633 Test RE 0.056674257852979935\n",
      "103 Train Loss 90370.82 Test MSE 17319.95588853162 Test RE 0.058824766838246466\n",
      "104 Train Loss 89897.266 Test MSE 19116.14388734323 Test RE 0.06179978569199515\n",
      "105 Train Loss 89406.72 Test MSE 18964.444555299957 Test RE 0.061554086046148655\n",
      "106 Train Loss 89048.63 Test MSE 17255.282821750458 Test RE 0.0587148376862647\n",
      "107 Train Loss 88283.63 Test MSE 16090.956435768689 Test RE 0.056699307307980264\n",
      "108 Train Loss 87845.87 Test MSE 13350.132324069878 Test RE 0.051645157812525336\n",
      "109 Train Loss 87258.46 Test MSE 10221.176553711313 Test RE 0.04518947217497101\n",
      "110 Train Loss 86408.52 Test MSE 8398.348664760491 Test RE 0.04096224719201114\n",
      "111 Train Loss 85728.84 Test MSE 8271.542408802707 Test RE 0.04065182749828577\n",
      "112 Train Loss 85233.42 Test MSE 5287.285029355566 Test RE 0.03250148356327815\n",
      "113 Train Loss 84932.47 Test MSE 5303.761238416411 Test RE 0.03255208464703238\n",
      "114 Train Loss 84456.25 Test MSE 4837.8005081187885 Test RE 0.031089289826340717\n",
      "115 Train Loss 84280.46 Test MSE 4243.9444501903445 Test RE 0.029118679010150073\n",
      "116 Train Loss 83780.445 Test MSE 2066.0890662786014 Test RE 0.020317082465453058\n",
      "117 Train Loss 83381.33 Test MSE 1454.437212072945 Test RE 0.017046464266085526\n",
      "118 Train Loss 83060.47 Test MSE 2272.010752312397 Test RE 0.0213055139371904\n",
      "119 Train Loss 82794.305 Test MSE 2855.011309282708 Test RE 0.023883102367546764\n",
      "120 Train Loss 82100.98 Test MSE 3764.2798984880073 Test RE 0.027423809153436444\n",
      "121 Train Loss 81744.18 Test MSE 4910.178266013175 Test RE 0.031320988024652704\n",
      "122 Train Loss 81398.33 Test MSE 6170.32650983781 Test RE 0.03511081387192646\n",
      "123 Train Loss 80679.32 Test MSE 5100.337660020973 Test RE 0.03192172030856733\n",
      "124 Train Loss 80236.12 Test MSE 3981.2303773045955 Test RE 0.028203011092944746\n",
      "125 Train Loss 79756.23 Test MSE 3177.8173065971396 Test RE 0.025197142181505677\n",
      "126 Train Loss 79120.4 Test MSE 1841.0836409500148 Test RE 0.019178895074761504\n",
      "127 Train Loss 78572.72 Test MSE 1884.9644318163632 Test RE 0.019406106190727693\n",
      "128 Train Loss 78119.65 Test MSE 2659.329676949516 Test RE 0.02305010529994796\n",
      "129 Train Loss 77881.336 Test MSE 2551.7466180683746 Test RE 0.022579046479712338\n",
      "130 Train Loss 77536.06 Test MSE 1614.3680293329376 Test RE 0.017959245937097832\n",
      "131 Train Loss 77305.06 Test MSE 1490.5967422651304 Test RE 0.017257063911790594\n",
      "132 Train Loss 76860.71 Test MSE 1170.3585053172421 Test RE 0.015291365935237363\n",
      "133 Train Loss 76468.64 Test MSE 1250.3684964218535 Test RE 0.015805412510371753\n",
      "134 Train Loss 76169.21 Test MSE 1346.934196792549 Test RE 0.016404387263064056\n",
      "135 Train Loss 75652.42 Test MSE 2550.0506093170056 Test RE 0.022571541693518965\n",
      "136 Train Loss 75558.44 Test MSE 2746.8253837838806 Test RE 0.02342622713112608\n",
      "137 Train Loss 75482.12 Test MSE 2724.381149984268 Test RE 0.023330323297297288\n",
      "138 Train Loss 75230.76 Test MSE 1713.6338524044775 Test RE 0.018503157267705458\n",
      "139 Train Loss 74831.04 Test MSE 1677.5473700810987 Test RE 0.018307296693480156\n",
      "140 Train Loss 74574.664 Test MSE 2684.2025889101565 Test RE 0.023157649109525835\n",
      "141 Train Loss 74177.164 Test MSE 2968.81568722532 Test RE 0.024354456474220503\n",
      "142 Train Loss 73900.96 Test MSE 1936.2179344494964 Test RE 0.019668169524107822\n",
      "143 Train Loss 73684.95 Test MSE 1871.121954511281 Test RE 0.019334719278518528\n",
      "144 Train Loss 73466.62 Test MSE 2444.9165444637756 Test RE 0.02210135209486602\n",
      "145 Train Loss 73060.33 Test MSE 3099.9879426335783 Test RE 0.02488667211689732\n",
      "146 Train Loss 72630.164 Test MSE 3635.8333878573 Test RE 0.026951864239957445\n",
      "147 Train Loss 72436.305 Test MSE 4023.8466225766465 Test RE 0.028353555903968996\n",
      "148 Train Loss 72190.77 Test MSE 5370.000504193681 Test RE 0.032754727212158274\n",
      "149 Train Loss 71823.44 Test MSE 5560.7318564389125 Test RE 0.03333134205025235\n",
      "150 Train Loss 71580.14 Test MSE 3663.106558860293 Test RE 0.027052761256375485\n",
      "151 Train Loss 71232.51 Test MSE 2320.3019449384733 Test RE 0.021530745906504178\n",
      "152 Train Loss 71030.17 Test MSE 1790.4249052754474 Test RE 0.018913194066811505\n",
      "153 Train Loss 70805.72 Test MSE 1585.3590186107635 Test RE 0.017797157236644056\n",
      "154 Train Loss 70558.37 Test MSE 1644.1945452696002 Test RE 0.018124391103754422\n",
      "155 Train Loss 70399.49 Test MSE 1308.6422702929408 Test RE 0.016169526252655178\n",
      "156 Train Loss 70156.46 Test MSE 1093.9905353060715 Test RE 0.014784056240933468\n",
      "157 Train Loss 69757.99 Test MSE 1220.9367851706297 Test RE 0.015618287498325386\n",
      "158 Train Loss 69472.12 Test MSE 1234.9059851246354 Test RE 0.015707380755531915\n",
      "159 Train Loss 69259.29 Test MSE 1595.5783860576632 Test RE 0.017854426136393108\n",
      "160 Train Loss 69037.766 Test MSE 1425.9022445701562 Test RE 0.016878416517099096\n",
      "161 Train Loss 68915.73 Test MSE 1222.4748497743487 Test RE 0.015628121903705137\n",
      "162 Train Loss 68566.81 Test MSE 1437.1590666535121 Test RE 0.01694490909072878\n",
      "163 Train Loss 68288.69 Test MSE 1320.2119821393892 Test RE 0.016240846389123917\n",
      "164 Train Loss 68169.31 Test MSE 1307.4832142288903 Test RE 0.016162364043584794\n",
      "165 Train Loss 68018.516 Test MSE 1580.7344804731836 Test RE 0.017771180867999923\n",
      "166 Train Loss 67613.72 Test MSE 1905.0483176316202 Test RE 0.019509216183968635\n",
      "167 Train Loss 67317.27 Test MSE 1900.6967525489665 Test RE 0.01948692169441591\n",
      "168 Train Loss 67015.84 Test MSE 1623.6630158680377 Test RE 0.01801087337036231\n",
      "169 Train Loss 66787.195 Test MSE 1803.6388972187299 Test RE 0.018982858916767868\n",
      "170 Train Loss 66570.64 Test MSE 2168.478666297945 Test RE 0.02081442416704348\n",
      "171 Train Loss 66344.25 Test MSE 2422.8963722841304 Test RE 0.02200159892440028\n",
      "172 Train Loss 66016.586 Test MSE 2744.39024926016 Test RE 0.023415840838717762\n",
      "173 Train Loss 65724.46 Test MSE 2646.3758870718634 Test RE 0.022993897391534616\n",
      "174 Train Loss 65555.914 Test MSE 2581.982756312101 Test RE 0.022712424278523456\n",
      "175 Train Loss 65394.805 Test MSE 2732.9664082855275 Test RE 0.023367054446787813\n",
      "176 Train Loss 65143.574 Test MSE 2968.36726784356 Test RE 0.024352617117405686\n",
      "177 Train Loss 64929.94 Test MSE 2460.4449124052794 Test RE 0.022171427025361838\n",
      "178 Train Loss 64625.695 Test MSE 2140.6401523110594 Test RE 0.020680386794530593\n",
      "179 Train Loss 64391.023 Test MSE 2303.8234193448534 Test RE 0.021454155201660788\n",
      "180 Train Loss 64153.848 Test MSE 2304.7520222305848 Test RE 0.021458478532853893\n",
      "181 Train Loss 63759.742 Test MSE 3087.589281444134 Test RE 0.024836854090300477\n",
      "182 Train Loss 63399.51 Test MSE 3190.9331908664753 Test RE 0.025249087033640812\n",
      "183 Train Loss 63178.742 Test MSE 3022.675758258375 Test RE 0.02457438201215166\n",
      "184 Train Loss 63015.023 Test MSE 3327.254099295128 Test RE 0.025782783869914366\n",
      "185 Train Loss 62678.305 Test MSE 3422.6428199244915 Test RE 0.026149754343161104\n",
      "186 Train Loss 62427.55 Test MSE 2277.5109078404957 Test RE 0.021331286879811565\n",
      "187 Train Loss 62114.465 Test MSE 2312.82992937698 Test RE 0.021496050466159943\n",
      "188 Train Loss 61947.586 Test MSE 2430.684438912525 Test RE 0.022036931109051937\n",
      "189 Train Loss 61686.03 Test MSE 2049.7486495439525 Test RE 0.020236580462052612\n",
      "190 Train Loss 61487.793 Test MSE 1438.3391448900916 Test RE 0.016951864554375477\n",
      "191 Train Loss 61177.35 Test MSE 1240.8520298900528 Test RE 0.01574515068872189\n",
      "192 Train Loss 60866.258 Test MSE 1315.7027129945368 Test RE 0.016213086836232966\n",
      "193 Train Loss 60731.324 Test MSE 1387.6556758986983 Test RE 0.016650515425109785\n",
      "194 Train Loss 60611.523 Test MSE 1285.3574802740843 Test RE 0.016025027678730278\n",
      "195 Train Loss 60374.098 Test MSE 1405.371771979693 Test RE 0.016756466272645272\n",
      "196 Train Loss 60048.438 Test MSE 1708.9656459325277 Test RE 0.0184779373339194\n",
      "197 Train Loss 59835.914 Test MSE 1330.0573841172175 Test RE 0.016301291477832967\n",
      "198 Train Loss 59716.84 Test MSE 1186.2980058033615 Test RE 0.015395142878106071\n",
      "199 Train Loss 59464.016 Test MSE 964.8700885282889 Test RE 0.013884212285474581\n",
      "Training time: 49.48\n",
      "Training time: 49.48\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 467906.8 Test MSE 4180588.9603220443 Test RE 0.9139144800677833\n",
      "1 Train Loss 409265.47 Test MSE 3059108.749899501 Test RE 0.7817795066450736\n",
      "2 Train Loss 369313.38 Test MSE 1808402.123634827 Test RE 0.6010828374204265\n",
      "3 Train Loss 308842.2 Test MSE 988231.9837914328 Test RE 0.44434088577642833\n",
      "4 Train Loss 206944.0 Test MSE 484194.6549545858 Test RE 0.3110260888306645\n",
      "5 Train Loss 198260.92 Test MSE 678460.6074398913 Test RE 0.368170631204296\n",
      "6 Train Loss 190830.1 Test MSE 367017.0652444666 Test RE 0.2707883355183674\n",
      "7 Train Loss 176580.67 Test MSE 360220.9577050021 Test RE 0.26826950747115413\n",
      "8 Train Loss 170474.2 Test MSE 461744.76622030087 Test RE 0.30373008690524256\n",
      "9 Train Loss 165540.64 Test MSE 533700.731275823 Test RE 0.326539499377544\n",
      "10 Train Loss 155178.89 Test MSE 284542.6730259094 Test RE 0.2384297959766443\n",
      "11 Train Loss 142208.81 Test MSE 124131.25613821132 Test RE 0.15748072255875067\n",
      "12 Train Loss 133924.2 Test MSE 60881.46934911505 Test RE 0.11028828574418198\n",
      "13 Train Loss 129166.836 Test MSE 34940.30218742611 Test RE 0.08355071138819932\n",
      "14 Train Loss 128673.35 Test MSE 31757.8933035889 Test RE 0.07965493109878827\n",
      "15 Train Loss 127914.766 Test MSE 22629.01435526537 Test RE 0.06723875178380759\n",
      "16 Train Loss 127284.0 Test MSE 21792.428414680464 Test RE 0.06598415169339913\n",
      "17 Train Loss 126704.734 Test MSE 20321.47821533749 Test RE 0.06371834274172805\n",
      "18 Train Loss 126430.95 Test MSE 17399.111190580086 Test RE 0.05895903347023562\n",
      "19 Train Loss 126074.54 Test MSE 12879.917334637532 Test RE 0.05072748854695697\n",
      "20 Train Loss 125635.14 Test MSE 8808.241578368896 Test RE 0.04194994852741537\n",
      "21 Train Loss 125392.984 Test MSE 5945.153705613434 Test RE 0.034464213127646366\n",
      "22 Train Loss 125317.57 Test MSE 5131.68614748307 Test RE 0.03201967114653796\n",
      "23 Train Loss 125292.84 Test MSE 4748.8287139512 Test RE 0.030802082254696776\n",
      "24 Train Loss 125280.23 Test MSE 4299.785789186377 Test RE 0.02930962309304201\n",
      "25 Train Loss 125248.734 Test MSE 3025.967522170791 Test RE 0.024587759406672967\n",
      "26 Train Loss 125228.64 Test MSE 2325.050346066288 Test RE 0.021552765533319782\n",
      "27 Train Loss 125218.1 Test MSE 2016.2079122731175 Test RE 0.02007032850837847\n",
      "28 Train Loss 125197.97 Test MSE 2199.4398792249704 Test RE 0.02096249013638449\n",
      "29 Train Loss 125161.44 Test MSE 2456.3206051695292 Test RE 0.02215283686545003\n",
      "30 Train Loss 125105.31 Test MSE 2232.265010876365 Test RE 0.02111833620972518\n",
      "31 Train Loss 125071.46 Test MSE 1890.1213088299073 Test RE 0.01943263362769207\n",
      "32 Train Loss 125029.33 Test MSE 1903.1241889676053 Test RE 0.01949936138788091\n",
      "33 Train Loss 124997.63 Test MSE 2081.980026094306 Test RE 0.020395065433620553\n",
      "34 Train Loss 124971.78 Test MSE 2119.7354795772762 Test RE 0.02057916068170706\n",
      "35 Train Loss 124954.95 Test MSE 2224.0641606237127 Test RE 0.02107950845657171\n",
      "36 Train Loss 124928.42 Test MSE 2167.584494173798 Test RE 0.020810132310917218\n",
      "37 Train Loss 124902.52 Test MSE 2189.3227370097393 Test RE 0.02091422217865833\n",
      "38 Train Loss 124852.805 Test MSE 2441.915042055877 Test RE 0.02208778156340419\n",
      "39 Train Loss 124780.19 Test MSE 2076.5053613389387 Test RE 0.02036823288901061\n",
      "40 Train Loss 124713.94 Test MSE 1999.4323051320569 Test RE 0.019986657765919173\n",
      "41 Train Loss 124675.414 Test MSE 1949.9569731410033 Test RE 0.019737826991334674\n",
      "42 Train Loss 124631.086 Test MSE 1944.434689757983 Test RE 0.019709858385988762\n",
      "43 Train Loss 124598.81 Test MSE 1829.0984475143962 Test RE 0.019116367203033866\n",
      "44 Train Loss 124567.96 Test MSE 1574.5279056819454 Test RE 0.01773625829057349\n",
      "45 Train Loss 124547.82 Test MSE 1489.337939272619 Test RE 0.017249775611972898\n",
      "46 Train Loss 124527.52 Test MSE 1479.4142167569025 Test RE 0.017192210404616028\n",
      "47 Train Loss 124507.86 Test MSE 1451.080799731041 Test RE 0.017026783798089792\n",
      "48 Train Loss 124487.51 Test MSE 1358.1473769604222 Test RE 0.016472528713851502\n",
      "49 Train Loss 124482.59 Test MSE 1344.6685773576032 Test RE 0.016390584903335642\n",
      "50 Train Loss 124481.01 Test MSE 1341.6550493428667 Test RE 0.016372208184891688\n",
      "51 Train Loss 124480.49 Test MSE 1342.9870045831747 Test RE 0.016380333089588896\n",
      "52 Train Loss 124480.46 Test MSE 1343.1006087109242 Test RE 0.016381025886352787\n",
      "53 Train Loss 124479.97 Test MSE 1345.895484943847 Test RE 0.01639806077815019\n",
      "54 Train Loss 124479.38 Test MSE 1351.1554016087748 Test RE 0.01643007230031098\n",
      "55 Train Loss 124478.71 Test MSE 1355.4999164396581 Test RE 0.01645646578741906\n",
      "56 Train Loss 124478.234 Test MSE 1357.2388377381656 Test RE 0.016467018103441377\n",
      "57 Train Loss 124477.695 Test MSE 1359.2111653426773 Test RE 0.016478978623107158\n",
      "58 Train Loss 124476.38 Test MSE 1362.4811558075537 Test RE 0.016498789280005\n",
      "59 Train Loss 124475.95 Test MSE 1361.3953450578442 Test RE 0.01649221372727332\n",
      "60 Train Loss 124473.74 Test MSE 1351.0115822976877 Test RE 0.016429197854425887\n",
      "61 Train Loss 124472.95 Test MSE 1344.234075286691 Test RE 0.016387936548711995\n",
      "62 Train Loss 124470.414 Test MSE 1327.7956026728693 Test RE 0.016287425291743065\n",
      "63 Train Loss 124467.93 Test MSE 1320.0459379045653 Test RE 0.01623982504416381\n",
      "64 Train Loss 124467.11 Test MSE 1317.9807980644396 Test RE 0.016227116911854418\n",
      "65 Train Loss 124466.31 Test MSE 1315.325442020756 Test RE 0.016210762160017683\n",
      "66 Train Loss 124466.08 Test MSE 1314.5826210655703 Test RE 0.0162061840556021\n",
      "67 Train Loss 124465.625 Test MSE 1312.3627823369368 Test RE 0.016192495180365037\n",
      "68 Train Loss 124465.56 Test MSE 1312.23252658147 Test RE 0.016191691584721068\n",
      "69 Train Loss 124465.336 Test MSE 1311.680202220535 Test RE 0.016188283649478004\n",
      "70 Train Loss 124464.91 Test MSE 1310.7852492033717 Test RE 0.016182760113579324\n",
      "71 Train Loss 124464.914 Test MSE 1310.7851714462229 Test RE 0.016182759633590213\n",
      "72 Train Loss 124464.69 Test MSE 1310.8020342995949 Test RE 0.016182863726400824\n",
      "73 Train Loss 124464.69 Test MSE 1310.8020342995949 Test RE 0.016182863726400824\n",
      "74 Train Loss 124464.69 Test MSE 1310.8020342995949 Test RE 0.016182863726400824\n",
      "75 Train Loss 124464.68 Test MSE 1310.769956885956 Test RE 0.016182665714963587\n",
      "76 Train Loss 124464.68 Test MSE 1310.76852009235 Test RE 0.016182656845689126\n",
      "77 Train Loss 124464.66 Test MSE 1310.8160440054803 Test RE 0.016182950206490673\n",
      "78 Train Loss 124464.62 Test MSE 1310.8675901534032 Test RE 0.016183268390170407\n",
      "79 Train Loss 124464.62 Test MSE 1310.8782349805624 Test RE 0.016183334097701233\n",
      "80 Train Loss 124464.62 Test MSE 1310.8957079129075 Test RE 0.016183441952630846\n",
      "81 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "82 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "83 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "84 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "85 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "86 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "87 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "88 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "89 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "90 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "91 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "92 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "93 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "94 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "95 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "96 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "97 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "98 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "99 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "100 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "101 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "102 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "103 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "104 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "105 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "106 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "107 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "108 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "109 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "110 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "111 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "112 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "113 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "114 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "115 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "116 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "117 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "118 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "119 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "120 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "121 Train Loss 124464.57 Test MSE 1311.013313531056 Test RE 0.016184167876515453\n",
      "122 Train Loss 124464.56 Test MSE 1311.0303075538975 Test RE 0.016184272769892375\n",
      "123 Train Loss 124464.56 Test MSE 1311.0303075538975 Test RE 0.016184272769892375\n",
      "124 Train Loss 124464.375 Test MSE 1312.268316965492 Test RE 0.0161919123927321\n",
      "125 Train Loss 124464.375 Test MSE 1312.268316965492 Test RE 0.0161919123927321\n",
      "126 Train Loss 124464.375 Test MSE 1312.268316965492 Test RE 0.0161919123927321\n",
      "127 Train Loss 124464.375 Test MSE 1312.268316965492 Test RE 0.0161919123927321\n",
      "128 Train Loss 124464.375 Test MSE 1312.268316965492 Test RE 0.0161919123927321\n",
      "129 Train Loss 124464.375 Test MSE 1312.268316965492 Test RE 0.0161919123927321\n",
      "130 Train Loss 124464.375 Test MSE 1312.268316965492 Test RE 0.0161919123927321\n",
      "131 Train Loss 124464.375 Test MSE 1312.268316965492 Test RE 0.0161919123927321\n",
      "132 Train Loss 124464.38 Test MSE 1312.2808344452212 Test RE 0.016191989618345642\n",
      "133 Train Loss 124464.38 Test MSE 1312.2937411738708 Test RE 0.01619206924501432\n",
      "134 Train Loss 124464.14 Test MSE 1313.2199728902242 Test RE 0.01619778250957581\n",
      "135 Train Loss 124464.14 Test MSE 1313.2199728902242 Test RE 0.01619778250957581\n",
      "136 Train Loss 124464.14 Test MSE 1313.2199728902242 Test RE 0.01619778250957581\n",
      "137 Train Loss 124464.13 Test MSE 1313.2200979852328 Test RE 0.016197783281061823\n",
      "138 Train Loss 124464.125 Test MSE 1313.2907220588752 Test RE 0.016198218828028094\n",
      "139 Train Loss 124464.125 Test MSE 1313.2907220588752 Test RE 0.016198218828028094\n",
      "140 Train Loss 124464.125 Test MSE 1313.2907220588752 Test RE 0.016198218828028094\n",
      "141 Train Loss 124464.125 Test MSE 1313.2907220588752 Test RE 0.016198218828028094\n",
      "142 Train Loss 124464.125 Test MSE 1313.37552199815 Test RE 0.016198741783751816\n",
      "143 Train Loss 124464.12 Test MSE 1313.4146028636499 Test RE 0.016198982787230656\n",
      "144 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "145 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "146 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "147 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "148 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "149 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "150 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "151 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "152 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "153 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "154 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "155 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "156 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "157 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "158 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "159 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "160 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "161 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "162 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "163 Train Loss 124464.11 Test MSE 1313.4786777975899 Test RE 0.016199377916114917\n",
      "164 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "165 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "166 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "167 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "168 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "169 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "170 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "171 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "172 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "173 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "174 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "175 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "176 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "177 Train Loss 124464.11 Test MSE 1313.5088591318827 Test RE 0.01619956403106292\n",
      "178 Train Loss 124464.12 Test MSE 1313.532731232468 Test RE 0.016199711238240943\n",
      "179 Train Loss 124464.1 Test MSE 1313.5495641792395 Test RE 0.016199815037711215\n",
      "180 Train Loss 124464.1 Test MSE 1313.5495641792395 Test RE 0.016199815037711215\n",
      "181 Train Loss 124464.086 Test MSE 1313.5838098325091 Test RE 0.01620002620965634\n",
      "182 Train Loss 124464.086 Test MSE 1313.5838098325091 Test RE 0.01620002620965634\n",
      "183 Train Loss 124464.086 Test MSE 1313.5838098325091 Test RE 0.01620002620965634\n",
      "184 Train Loss 124464.086 Test MSE 1313.5838098325091 Test RE 0.01620002620965634\n",
      "185 Train Loss 124464.086 Test MSE 1313.5838098325091 Test RE 0.01620002620965634\n",
      "186 Train Loss 124464.086 Test MSE 1313.5838098325091 Test RE 0.01620002620965634\n",
      "187 Train Loss 124464.086 Test MSE 1313.5838098325091 Test RE 0.01620002620965634\n",
      "188 Train Loss 124464.086 Test MSE 1313.5838098325091 Test RE 0.01620002620965634\n",
      "189 Train Loss 124464.086 Test MSE 1313.5838098325091 Test RE 0.01620002620965634\n",
      "190 Train Loss 124464.086 Test MSE 1313.5838098325091 Test RE 0.01620002620965634\n",
      "191 Train Loss 124464.086 Test MSE 1313.5838098325091 Test RE 0.01620002620965634\n",
      "192 Train Loss 124464.086 Test MSE 1313.5833481447596 Test RE 0.016200023362729386\n",
      "193 Train Loss 124464.02 Test MSE 1313.7245681261093 Test RE 0.016200894150835712\n",
      "194 Train Loss 124464.02 Test MSE 1313.7245681261093 Test RE 0.016200894150835712\n",
      "195 Train Loss 124464.02 Test MSE 1313.7245681261093 Test RE 0.016200894150835712\n",
      "196 Train Loss 124464.02 Test MSE 1313.7245681261093 Test RE 0.016200894150835712\n",
      "197 Train Loss 124464.02 Test MSE 1313.7245681261093 Test RE 0.016200894150835712\n",
      "198 Train Loss 124464.02 Test MSE 1313.7245681261093 Test RE 0.016200894150835712\n",
      "199 Train Loss 124464.02 Test MSE 1313.7258812115565 Test RE 0.016200902247339936\n",
      "Training time: 29.46\n",
      "Training time: 29.46\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 559937.94 Test MSE 3881505.416872518 Test RE 0.8806167097166954\n",
      "1 Train Loss 420888.25 Test MSE 3779147.9715228546 Test RE 0.8689279602560027\n",
      "2 Train Loss 343697.28 Test MSE 1165476.9444639215 Test RE 0.48254594117665955\n",
      "3 Train Loss 178202.42 Test MSE 447152.9652391117 Test RE 0.29889240612946033\n",
      "4 Train Loss 160593.86 Test MSE 453237.72284700157 Test RE 0.30091916503540755\n",
      "5 Train Loss 148634.0 Test MSE 219217.63689527832 Test RE 0.20927847866741225\n",
      "6 Train Loss 143946.67 Test MSE 166832.80370163897 Test RE 0.18256921484533808\n",
      "7 Train Loss 140778.7 Test MSE 131335.91289164743 Test RE 0.16198640689997107\n",
      "8 Train Loss 136359.7 Test MSE 70618.26343251212 Test RE 0.11878055234880588\n",
      "9 Train Loss 131757.48 Test MSE 55511.483073115516 Test RE 0.10531209170982073\n",
      "10 Train Loss 129959.28 Test MSE 39056.48753450372 Test RE 0.0883351224338986\n",
      "11 Train Loss 127733.07 Test MSE 24893.1008312518 Test RE 0.07052227644346241\n",
      "12 Train Loss 125978.945 Test MSE 9790.423364192218 Test RE 0.04422700798664183\n",
      "13 Train Loss 125094.51 Test MSE 9054.366110002058 Test RE 0.04253200430679551\n",
      "14 Train Loss 125015.09 Test MSE 9290.955926436664 Test RE 0.04308409983904726\n",
      "15 Train Loss 124881.83 Test MSE 7524.441051133334 Test RE 0.03877251259494247\n",
      "16 Train Loss 124706.3 Test MSE 5916.602087648158 Test RE 0.03438135628596474\n",
      "17 Train Loss 124537.78 Test MSE 4977.025696953276 Test RE 0.03153347009140925\n",
      "18 Train Loss 124412.13 Test MSE 3247.7854352024456 Test RE 0.025473023050355724\n",
      "19 Train Loss 124307.84 Test MSE 3092.468835985866 Test RE 0.024856472136673875\n",
      "20 Train Loss 124211.92 Test MSE 4775.794077427634 Test RE 0.03088941048253962\n",
      "21 Train Loss 124090.375 Test MSE 3126.9826725802845 Test RE 0.024994793956210713\n",
      "22 Train Loss 124069.9 Test MSE 2773.6947285738142 Test RE 0.023540525541369137\n",
      "23 Train Loss 124000.93 Test MSE 2173.5534695736933 Test RE 0.02083876551333111\n",
      "24 Train Loss 123910.75 Test MSE 1824.2749910447 Test RE 0.01909114498646171\n",
      "25 Train Loss 123879.09 Test MSE 2023.4829888885106 Test RE 0.020106505754555193\n",
      "26 Train Loss 123850.62 Test MSE 2097.939392025659 Test RE 0.020473085137077397\n",
      "27 Train Loss 123744.08 Test MSE 1933.9462774822407 Test RE 0.01965662835248243\n",
      "28 Train Loss 123605.13 Test MSE 2100.315829505879 Test RE 0.020484677282430693\n",
      "29 Train Loss 123588.35 Test MSE 2317.9925815531924 Test RE 0.021520028617208874\n",
      "30 Train Loss 123586.2 Test MSE 2318.7611040588163 Test RE 0.021523595767475357\n",
      "31 Train Loss 123570.13 Test MSE 2148.5759021627287 Test RE 0.020718684347002782\n",
      "32 Train Loss 123516.97 Test MSE 1648.8402343084965 Test RE 0.01814997837139546\n",
      "33 Train Loss 123494.27 Test MSE 1467.054540723439 Test RE 0.01712024414218548\n",
      "34 Train Loss 123484.66 Test MSE 1432.5532807004251 Test RE 0.01691773490537307\n",
      "35 Train Loss 123451.555 Test MSE 1518.2717300716276 Test RE 0.017416527765365418\n",
      "36 Train Loss 123384.375 Test MSE 1994.9071693566568 Test RE 0.01996402794985767\n",
      "37 Train Loss 123344.09 Test MSE 2334.3222926191365 Test RE 0.021595697347187463\n",
      "38 Train Loss 123311.87 Test MSE 2051.8387141171847 Test RE 0.02024689513734077\n",
      "39 Train Loss 123242.65 Test MSE 1416.61235333821 Test RE 0.016823344411293673\n",
      "40 Train Loss 123191.16 Test MSE 1687.544865073767 Test RE 0.01836176765155598\n",
      "41 Train Loss 123101.41 Test MSE 2140.8133024060467 Test RE 0.020681223165493413\n",
      "42 Train Loss 123007.54 Test MSE 1946.392855205141 Test RE 0.019719780409039017\n",
      "43 Train Loss 122942.05 Test MSE 1733.0549903106041 Test RE 0.018607712839735547\n",
      "44 Train Loss 122906.3 Test MSE 1789.7706021150611 Test RE 0.01890973787788802\n",
      "45 Train Loss 122882.65 Test MSE 1852.985128053772 Test RE 0.019240785167242667\n",
      "46 Train Loss 122836.18 Test MSE 1953.4615399040706 Test RE 0.019755555967193503\n",
      "47 Train Loss 122807.305 Test MSE 2175.2197764213806 Test RE 0.020846751773078865\n",
      "48 Train Loss 122728.92 Test MSE 3178.615362812422 Test RE 0.02520030590547874\n",
      "49 Train Loss 122675.375 Test MSE 2012.332524885498 Test RE 0.020051030471414218\n",
      "50 Train Loss 122644.016 Test MSE 1743.2954930285428 Test RE 0.018662607714223043\n",
      "51 Train Loss 122417.62 Test MSE 2419.806295176817 Test RE 0.021987564414151287\n",
      "52 Train Loss 122313.31 Test MSE 3089.926415523381 Test RE 0.0248462523736178\n",
      "53 Train Loss 122127.8 Test MSE 2251.80950792003 Test RE 0.02121058505642986\n",
      "54 Train Loss 122033.1 Test MSE 2350.5839122215953 Test RE 0.021670787990905632\n",
      "55 Train Loss 121873.664 Test MSE 1960.043726862184 Test RE 0.01978881114174771\n",
      "56 Train Loss 121587.17 Test MSE 2185.0412327449744 Test RE 0.020893761935021533\n",
      "57 Train Loss 121244.22 Test MSE 3089.1330852189067 Test RE 0.02484306256459373\n",
      "58 Train Loss 120958.445 Test MSE 2978.717940235434 Test RE 0.024395038856906692\n",
      "59 Train Loss 120578.56 Test MSE 5463.628888054736 Test RE 0.033039040017312185\n",
      "60 Train Loss 120027.8 Test MSE 6691.7724025358475 Test RE 0.03656431185958129\n",
      "61 Train Loss 119932.43 Test MSE 6188.27691687112 Test RE 0.03516184809915391\n",
      "62 Train Loss 119372.766 Test MSE 4954.141659360706 Test RE 0.031460892154919234\n",
      "63 Train Loss 118692.37 Test MSE 9875.483759508621 Test RE 0.044418717315274664\n",
      "64 Train Loss 118182.75 Test MSE 5593.4001117679645 Test RE 0.03342910636117331\n",
      "65 Train Loss 117749.234 Test MSE 5254.441925415619 Test RE 0.03240038134933539\n",
      "66 Train Loss 117093.086 Test MSE 4001.5188043512276 Test RE 0.028274781318677514\n",
      "67 Train Loss 116483.2 Test MSE 4792.3268821261245 Test RE 0.030942830643821227\n",
      "68 Train Loss 115837.68 Test MSE 3607.990836600992 Test RE 0.026848469676482783\n",
      "69 Train Loss 115384.87 Test MSE 3525.674363372864 Test RE 0.0265404280212949\n",
      "70 Train Loss 115050.4 Test MSE 5526.748510059312 Test RE 0.033229336912650766\n",
      "71 Train Loss 114738.47 Test MSE 5443.58498318885 Test RE 0.032978380712681686\n",
      "72 Train Loss 113976.13 Test MSE 6453.480491267268 Test RE 0.03590738881801468\n",
      "73 Train Loss 113336.836 Test MSE 5991.226309762335 Test RE 0.034597497452564956\n",
      "74 Train Loss 113012.52 Test MSE 5931.306466885163 Test RE 0.03442405332491552\n",
      "75 Train Loss 112305.88 Test MSE 5634.99841570599 Test RE 0.033553182790085255\n",
      "76 Train Loss 111681.55 Test MSE 8174.526339610348 Test RE 0.040412723775199444\n",
      "77 Train Loss 110639.29 Test MSE 9677.162005463611 Test RE 0.04397044181923111\n",
      "78 Train Loss 110119.086 Test MSE 9585.081567083114 Test RE 0.0437607473337966\n",
      "79 Train Loss 110075.29 Test MSE 9237.874965957513 Test RE 0.042960849808615344\n",
      "80 Train Loss 109981.28 Test MSE 9615.67614865704 Test RE 0.04383053156492125\n",
      "81 Train Loss 109476.49 Test MSE 13941.768640651431 Test RE 0.0527771287402857\n",
      "82 Train Loss 108840.07 Test MSE 13380.11652860692 Test RE 0.051703122423424085\n",
      "83 Train Loss 108264.9 Test MSE 12052.20198798597 Test RE 0.04907044816475869\n",
      "84 Train Loss 107716.44 Test MSE 14918.772767917884 Test RE 0.05459506321912701\n",
      "85 Train Loss 107314.375 Test MSE 19577.74131848131 Test RE 0.06254147456847069\n",
      "86 Train Loss 107035.64 Test MSE 16807.459113168163 Test RE 0.0579479204657142\n",
      "87 Train Loss 106214.12 Test MSE 12857.458976109558 Test RE 0.05068324318608787\n",
      "88 Train Loss 105814.61 Test MSE 17866.756748316915 Test RE 0.05974611713159786\n",
      "89 Train Loss 105541.63 Test MSE 20819.57289256476 Test RE 0.06449450763048549\n",
      "90 Train Loss 105339.84 Test MSE 19128.281314966818 Test RE 0.061819401870977786\n",
      "91 Train Loss 104765.69 Test MSE 19098.091328556555 Test RE 0.061770598116607976\n",
      "92 Train Loss 104487.82 Test MSE 22338.58889741006 Test RE 0.06680588037383713\n",
      "93 Train Loss 103856.11 Test MSE 22020.599268615435 Test RE 0.0663286854924254\n",
      "94 Train Loss 103023.23 Test MSE 9907.504968714138 Test RE 0.04449067277367942\n",
      "95 Train Loss 102443.79 Test MSE 3659.064024766475 Test RE 0.027037829681633607\n",
      "96 Train Loss 101933.34 Test MSE 5412.293720475996 Test RE 0.032883459588166346\n",
      "97 Train Loss 101831.38 Test MSE 5500.907224940795 Test RE 0.03315156108668744\n",
      "98 Train Loss 101672.2 Test MSE 5088.04129703694 Test RE 0.03188321717865207\n",
      "99 Train Loss 101482.77 Test MSE 5197.647835100137 Test RE 0.032224801362923314\n",
      "100 Train Loss 100790.16 Test MSE 6130.321609285799 Test RE 0.03499680947601265\n",
      "101 Train Loss 100361.8 Test MSE 6741.756095539263 Test RE 0.03670061500166186\n",
      "102 Train Loss 99873.07 Test MSE 5738.698097425251 Test RE 0.0338605113665649\n",
      "103 Train Loss 99068.984 Test MSE 4320.37994661463 Test RE 0.029379729604361422\n",
      "104 Train Loss 98704.734 Test MSE 4518.511375343679 Test RE 0.030045851305881274\n",
      "105 Train Loss 98552.52 Test MSE 4950.760076143848 Test RE 0.031450153081145196\n",
      "106 Train Loss 98352.85 Test MSE 5326.034919230002 Test RE 0.032620365916663036\n",
      "107 Train Loss 97974.44 Test MSE 5397.4227036336515 Test RE 0.03283825261357327\n",
      "108 Train Loss 97383.945 Test MSE 5138.551184540469 Test RE 0.0320410815324898\n",
      "109 Train Loss 97126.94 Test MSE 4669.438199539648 Test RE 0.030543523765072633\n",
      "110 Train Loss 96794.26 Test MSE 4451.433934875904 Test RE 0.02982200164202206\n",
      "111 Train Loss 96537.29 Test MSE 4654.457016988574 Test RE 0.030494487275767382\n",
      "112 Train Loss 96381.07 Test MSE 4057.482177752611 Test RE 0.02847181375373401\n",
      "113 Train Loss 96213.33 Test MSE 3395.510224549869 Test RE 0.026045898568117627\n",
      "114 Train Loss 96086.82 Test MSE 3012.6290338364197 Test RE 0.02453350803833652\n",
      "115 Train Loss 95974.46 Test MSE 2939.132661824177 Test RE 0.024232399383254066\n",
      "116 Train Loss 95827.664 Test MSE 2864.9142990725854 Test RE 0.023924487383749724\n",
      "117 Train Loss 95231.305 Test MSE 2884.2402492694823 Test RE 0.024005045871227804\n",
      "118 Train Loss 94911.95 Test MSE 3043.1016775779567 Test RE 0.024657273668521176\n",
      "119 Train Loss 94753.414 Test MSE 3101.8711248080217 Test RE 0.02489423005305289\n",
      "120 Train Loss 94496.88 Test MSE 2589.246081895587 Test RE 0.022744347783422294\n",
      "121 Train Loss 94187.52 Test MSE 2390.3235509790384 Test RE 0.021853206463897434\n",
      "122 Train Loss 93838.875 Test MSE 2981.5838342881175 Test RE 0.024406771553638375\n",
      "123 Train Loss 93591.44 Test MSE 3422.9561753019884 Test RE 0.026150951368242588\n",
      "124 Train Loss 93212.766 Test MSE 4230.074387789358 Test RE 0.029071057224745428\n",
      "125 Train Loss 92908.29 Test MSE 5309.5483682518925 Test RE 0.032569839196291625\n",
      "126 Train Loss 92817.71 Test MSE 6383.421453920879 Test RE 0.035711951498986\n",
      "127 Train Loss 92668.65 Test MSE 7352.420884515214 Test RE 0.03832675086302346\n",
      "128 Train Loss 92404.45 Test MSE 7623.562075625832 Test RE 0.03902705622856758\n",
      "129 Train Loss 91894.97 Test MSE 6953.897273776726 Test RE 0.03727356728007756\n",
      "130 Train Loss 91436.47 Test MSE 6967.74047358687 Test RE 0.037310649284599776\n",
      "131 Train Loss 90714.87 Test MSE 10374.552126779387 Test RE 0.045527258803599126\n",
      "132 Train Loss 90539.24 Test MSE 10560.419996020979 Test RE 0.04593327581668222\n",
      "133 Train Loss 90350.07 Test MSE 9315.84735978224 Test RE 0.04314177461891054\n",
      "134 Train Loss 90150.01 Test MSE 8272.42960978815 Test RE 0.04065400758590257\n",
      "135 Train Loss 90026.23 Test MSE 7746.803605568829 Test RE 0.0393412447374205\n",
      "136 Train Loss 89831.21 Test MSE 7366.007706813199 Test RE 0.03836214725899472\n",
      "137 Train Loss 89433.17 Test MSE 5959.892213167135 Test RE 0.03450690644286796\n",
      "138 Train Loss 89057.59 Test MSE 3855.0218935041157 Test RE 0.027752380934104513\n",
      "139 Train Loss 88807.375 Test MSE 3637.8571239231696 Test RE 0.026959364015959157\n",
      "140 Train Loss 88446.555 Test MSE 3275.907450560435 Test RE 0.025583068609611875\n",
      "141 Train Loss 88272.77 Test MSE 2857.729931679306 Test RE 0.02389447074414496\n",
      "142 Train Loss 88112.75 Test MSE 2702.4241924360454 Test RE 0.023236118557402423\n",
      "143 Train Loss 87768.8 Test MSE 2590.9252138474017 Test RE 0.022751721468693344\n",
      "144 Train Loss 87366.11 Test MSE 2516.3856228609443 Test RE 0.022422055399100693\n",
      "145 Train Loss 87064.18 Test MSE 2420.8517275659697 Test RE 0.02199231356077826\n",
      "146 Train Loss 86959.266 Test MSE 2354.0214020306953 Test RE 0.02168662786323117\n",
      "147 Train Loss 86897.766 Test MSE 2374.3181203273134 Test RE 0.02177991984597281\n",
      "148 Train Loss 86742.23 Test MSE 2642.3582770178546 Test RE 0.02297643660630977\n",
      "149 Train Loss 86389.14 Test MSE 2405.2205393130234 Test RE 0.02192119753504748\n",
      "150 Train Loss 86277.65 Test MSE 2226.4874380424894 Test RE 0.021090989148334648\n",
      "151 Train Loss 85940.58 Test MSE 2099.6898284044837 Test RE 0.020481624316297777\n",
      "152 Train Loss 85209.51 Test MSE 2089.4090753255323 Test RE 0.02043142049509185\n",
      "153 Train Loss 84987.04 Test MSE 2075.2023614895193 Test RE 0.02036184138875328\n",
      "154 Train Loss 84846.79 Test MSE 2003.8332106091389 Test RE 0.020008641766887773\n",
      "155 Train Loss 84633.68 Test MSE 1866.5306953712861 Test RE 0.01931098345827715\n",
      "156 Train Loss 84204.57 Test MSE 2066.317876879503 Test RE 0.020318207449661816\n",
      "157 Train Loss 83988.26 Test MSE 2331.0161005011555 Test RE 0.021580398512064572\n",
      "158 Train Loss 83777.22 Test MSE 2892.6782402349645 Test RE 0.024040134215686397\n",
      "159 Train Loss 83640.664 Test MSE 3477.0459352693288 Test RE 0.026356760956731964\n",
      "160 Train Loss 83419.18 Test MSE 3000.6313670582435 Test RE 0.02448460747839553\n",
      "161 Train Loss 83114.836 Test MSE 1974.5004103915055 Test RE 0.01986165518137517\n",
      "162 Train Loss 82997.25 Test MSE 2066.919012237322 Test RE 0.020321162731819623\n",
      "163 Train Loss 82569.77 Test MSE 2991.665779489431 Test RE 0.024448001330199292\n",
      "164 Train Loss 82242.625 Test MSE 2772.142731117144 Test RE 0.023533938668720094\n",
      "165 Train Loss 82092.51 Test MSE 2592.287470959343 Test RE 0.02275770188474649\n",
      "166 Train Loss 81780.34 Test MSE 4572.12138070311 Test RE 0.030223565660095618\n",
      "167 Train Loss 81415.26 Test MSE 4892.753955850161 Test RE 0.0312653656417312\n",
      "168 Train Loss 81010.13 Test MSE 4200.37104263584 Test RE 0.028968809747672724\n",
      "169 Train Loss 80706.02 Test MSE 3553.8902431032284 Test RE 0.02664641756169762\n",
      "170 Train Loss 80438.21 Test MSE 3418.198308749521 Test RE 0.026132770299446263\n",
      "171 Train Loss 80303.586 Test MSE 3071.395667337688 Test RE 0.024771637000455756\n",
      "172 Train Loss 80181.234 Test MSE 2660.0052334084126 Test RE 0.02305303285324224\n",
      "173 Train Loss 80072.6 Test MSE 2273.8896621414074 Test RE 0.021314321744697464\n",
      "174 Train Loss 79936.89 Test MSE 1940.1280279324933 Test RE 0.019688018941145333\n",
      "175 Train Loss 79637.945 Test MSE 1870.4504170110226 Test RE 0.01933124939399162\n",
      "176 Train Loss 79486.055 Test MSE 2055.041463015077 Test RE 0.02026269083211979\n",
      "177 Train Loss 79343.37 Test MSE 2405.274668265504 Test RE 0.021921444199493517\n",
      "178 Train Loss 79143.59 Test MSE 2382.528673279798 Test RE 0.02181754556533036\n",
      "179 Train Loss 78888.6 Test MSE 1565.5838867820137 Test RE 0.01768581163033319\n",
      "180 Train Loss 78750.57 Test MSE 1464.2295936479427 Test RE 0.01710375290517343\n",
      "181 Train Loss 78616.97 Test MSE 1661.0886467268647 Test RE 0.018217267211031167\n",
      "182 Train Loss 78315.96 Test MSE 2324.0935918063346 Test RE 0.021548330613866316\n",
      "183 Train Loss 78149.99 Test MSE 2749.8310524286194 Test RE 0.02343904050937145\n",
      "184 Train Loss 78066.836 Test MSE 2764.7491217143834 Test RE 0.023502533914009978\n",
      "185 Train Loss 77959.18 Test MSE 2357.9713212348756 Test RE 0.021704814725197245\n",
      "186 Train Loss 77797.15 Test MSE 1765.2452364938863 Test RE 0.018779730161438437\n",
      "187 Train Loss 77714.664 Test MSE 1443.290095360786 Test RE 0.016981014752883227\n",
      "188 Train Loss 77638.68 Test MSE 1305.091211694479 Test RE 0.01614757298793184\n",
      "189 Train Loss 77582.58 Test MSE 1278.3961722582292 Test RE 0.01598157416196754\n",
      "190 Train Loss 77528.79 Test MSE 1301.3889115864306 Test RE 0.016124652896468642\n",
      "191 Train Loss 77448.016 Test MSE 1343.1144591362963 Test RE 0.0163811103489724\n",
      "192 Train Loss 77349.016 Test MSE 1490.6003259276636 Test RE 0.0172570846563201\n",
      "193 Train Loss 77240.89 Test MSE 1675.5338148482563 Test RE 0.018296306297047423\n",
      "194 Train Loss 77083.414 Test MSE 1749.8407562468733 Test RE 0.018697609594104297\n",
      "195 Train Loss 76978.04 Test MSE 1787.4393513706882 Test RE 0.018897418504414957\n",
      "196 Train Loss 76873.48 Test MSE 1865.2662928315406 Test RE 0.0193044416443563\n",
      "197 Train Loss 76733.97 Test MSE 1765.2178387587207 Test RE 0.018779584424160906\n",
      "198 Train Loss 76647.89 Test MSE 1834.6821669950389 Test RE 0.019145523395835553\n",
      "199 Train Loss 76591.02 Test MSE 2001.6439454887684 Test RE 0.019997708673183866\n",
      "Training time: 50.08\n",
      "Training time: 50.08\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 495603.3 Test MSE 3872310.7581594423 Test RE 0.8795730720009358\n",
      "1 Train Loss 391679.88 Test MSE 1659712.531360168 Test RE 0.5758418972357223\n",
      "2 Train Loss 336828.25 Test MSE 1208061.045069743 Test RE 0.4912824654467176\n",
      "3 Train Loss 269130.72 Test MSE 1264995.180964121 Test RE 0.5027258987337868\n",
      "4 Train Loss 221619.9 Test MSE 997786.2276927128 Test RE 0.44648366680535484\n",
      "5 Train Loss 151295.9 Test MSE 153511.2684110641 Test RE 0.17512855073852054\n",
      "6 Train Loss 137787.47 Test MSE 89120.43286759191 Test RE 0.13343675355827303\n",
      "7 Train Loss 132227.03 Test MSE 144155.76174699934 Test RE 0.1697081996720247\n",
      "8 Train Loss 129517.625 Test MSE 100843.74825518465 Test RE 0.1419421285046645\n",
      "9 Train Loss 128563.77 Test MSE 65336.49750778776 Test RE 0.1142522465605593\n",
      "10 Train Loss 127154.2 Test MSE 49089.46900717186 Test RE 0.09903324070353144\n",
      "11 Train Loss 126416.59 Test MSE 17908.630329190062 Test RE 0.059816088413629204\n",
      "12 Train Loss 125460.15 Test MSE 14641.823147001707 Test RE 0.05408594249732725\n",
      "13 Train Loss 125044.34 Test MSE 5027.768800984652 Test RE 0.031693811674138865\n",
      "14 Train Loss 124630.97 Test MSE 5547.340539941865 Test RE 0.033291183703217986\n",
      "15 Train Loss 124207.586 Test MSE 7479.429887245746 Test RE 0.0386563701678488\n",
      "16 Train Loss 123943.06 Test MSE 3361.4211097178923 Test RE 0.02591482528457315\n",
      "17 Train Loss 123874.2 Test MSE 4364.195916624103 Test RE 0.02952833388910478\n",
      "18 Train Loss 123746.89 Test MSE 6002.168107001492 Test RE 0.034629075805591845\n",
      "19 Train Loss 123488.625 Test MSE 4227.000769593794 Test RE 0.029060493631835105\n",
      "20 Train Loss 123385.33 Test MSE 3397.2700006477453 Test RE 0.026052647040303883\n",
      "21 Train Loss 123152.93 Test MSE 3363.580678941971 Test RE 0.025923148531116054\n",
      "22 Train Loss 122964.6 Test MSE 2848.8835979610903 Test RE 0.023857458446667597\n",
      "23 Train Loss 122819.875 Test MSE 3747.774263859573 Test RE 0.02736361906798484\n",
      "24 Train Loss 122606.06 Test MSE 3903.9852535760074 Test RE 0.02792806894465652\n",
      "25 Train Loss 122403.03 Test MSE 3106.3980491110824 Test RE 0.024912388964799415\n",
      "26 Train Loss 122182.984 Test MSE 4872.48849990309 Test RE 0.03120054894061648\n",
      "27 Train Loss 121989.18 Test MSE 6780.736590626606 Test RE 0.03680656263260782\n",
      "28 Train Loss 121833.54 Test MSE 6742.488398915192 Test RE 0.03670260819557839\n",
      "29 Train Loss 121621.57 Test MSE 7696.497946029041 Test RE 0.039213300958661615\n",
      "30 Train Loss 121387.26 Test MSE 9355.541448526807 Test RE 0.04323358876430265\n",
      "31 Train Loss 120976.55 Test MSE 6382.852598789848 Test RE 0.03571036023796676\n",
      "32 Train Loss 120465.58 Test MSE 10746.12779916112 Test RE 0.0463353901541126\n",
      "33 Train Loss 120065.46 Test MSE 13587.2693680077 Test RE 0.05210182266126749\n",
      "34 Train Loss 119377.94 Test MSE 11795.139279503519 Test RE 0.04854431312046896\n",
      "35 Train Loss 118866.695 Test MSE 15233.676210630494 Test RE 0.05516824695687613\n",
      "36 Train Loss 118183.84 Test MSE 11018.891804746547 Test RE 0.0469197601114384\n",
      "37 Train Loss 117760.24 Test MSE 9598.122260879985 Test RE 0.04379050589829594\n",
      "38 Train Loss 117424.17 Test MSE 10806.676499030795 Test RE 0.04646574440065683\n",
      "39 Train Loss 117212.28 Test MSE 10969.805856756857 Test RE 0.046815136543799624\n",
      "40 Train Loss 116837.48 Test MSE 8380.241651017053 Test RE 0.040918065638212577\n",
      "41 Train Loss 116512.07 Test MSE 7256.759673635684 Test RE 0.038076602826101945\n",
      "42 Train Loss 116167.6 Test MSE 9176.118335464376 Test RE 0.042817009025633034\n",
      "43 Train Loss 115888.33 Test MSE 7964.983162626972 Test RE 0.039891397834619105\n",
      "44 Train Loss 115407.3 Test MSE 8287.773657220812 Test RE 0.040691693493000655\n",
      "45 Train Loss 114863.5 Test MSE 9894.948158089299 Test RE 0.04446247000825625\n",
      "46 Train Loss 114676.29 Test MSE 8409.603223235386 Test RE 0.04098968458943754\n",
      "47 Train Loss 113942.89 Test MSE 6649.904586581463 Test RE 0.036449748047593954\n",
      "48 Train Loss 113462.55 Test MSE 6670.03817841488 Test RE 0.036504884907683166\n",
      "49 Train Loss 113088.79 Test MSE 5795.404892767784 Test RE 0.034027395992775\n",
      "50 Train Loss 112359.445 Test MSE 8676.912130420533 Test RE 0.04163604060262165\n",
      "51 Train Loss 111831.41 Test MSE 8826.503679401218 Test RE 0.04199341336187728\n",
      "52 Train Loss 111224.96 Test MSE 9877.433022287893 Test RE 0.044423100871682296\n",
      "53 Train Loss 110338.32 Test MSE 15121.788413708568 Test RE 0.054965274623831516\n",
      "54 Train Loss 109361.82 Test MSE 15974.48652025699 Test RE 0.056493733547358836\n",
      "55 Train Loss 108359.42 Test MSE 20965.9780438963 Test RE 0.06472087602139459\n",
      "56 Train Loss 107833.12 Test MSE 20357.119366756648 Test RE 0.06377419498325092\n",
      "57 Train Loss 106984.945 Test MSE 21615.230762287356 Test RE 0.06571534039965853\n",
      "58 Train Loss 106295.53 Test MSE 15462.50237304737 Test RE 0.055581045697270126\n",
      "59 Train Loss 105631.2 Test MSE 15810.361333054447 Test RE 0.05620277009620663\n",
      "60 Train Loss 105019.766 Test MSE 20134.04461162189 Test RE 0.06342381138540937\n",
      "61 Train Loss 104533.33 Test MSE 11963.190060643665 Test RE 0.048888906657891466\n",
      "62 Train Loss 104108.06 Test MSE 7292.689496420732 Test RE 0.038170749277752714\n",
      "63 Train Loss 103444.92 Test MSE 5915.146078263125 Test RE 0.034377125592668575\n",
      "64 Train Loss 102888.65 Test MSE 3706.1280060812264 Test RE 0.027211158456853447\n",
      "65 Train Loss 102247.09 Test MSE 4914.454856507912 Test RE 0.031334624788873396\n",
      "66 Train Loss 101518.94 Test MSE 3671.2630850671844 Test RE 0.0270828632827419\n",
      "67 Train Loss 101158.516 Test MSE 4105.685188917793 Test RE 0.028640437423683256\n",
      "68 Train Loss 100620.26 Test MSE 3599.468185056489 Test RE 0.026816740737967148\n",
      "69 Train Loss 99995.82 Test MSE 3769.2633742868125 Test RE 0.027441956141748786\n",
      "70 Train Loss 99676.55 Test MSE 3278.81336282179 Test RE 0.025594412897382315\n",
      "71 Train Loss 99147.914 Test MSE 4625.798274658317 Test RE 0.030400460940495318\n",
      "72 Train Loss 98412.85 Test MSE 3762.0532671677015 Test RE 0.027415697144421085\n",
      "73 Train Loss 97627.24 Test MSE 4354.543551345659 Test RE 0.029495661658108817\n",
      "74 Train Loss 97178.98 Test MSE 5437.541590057486 Test RE 0.03296006955686983\n",
      "75 Train Loss 96291.4 Test MSE 7374.408015624284 Test RE 0.038384015418313905\n",
      "76 Train Loss 95656.84 Test MSE 8477.103413196155 Test RE 0.041153858902923966\n",
      "77 Train Loss 94609.66 Test MSE 12104.01100045522 Test RE 0.049175805060194214\n",
      "78 Train Loss 93819.34 Test MSE 11823.108987551052 Test RE 0.048601835387438924\n",
      "79 Train Loss 93277.71 Test MSE 11820.205240993962 Test RE 0.048595866734076114\n",
      "80 Train Loss 92999.766 Test MSE 13929.545477389225 Test RE 0.05275398802783023\n",
      "81 Train Loss 92365.45 Test MSE 18930.264725501056 Test RE 0.06149859122245702\n",
      "82 Train Loss 91316.44 Test MSE 12694.61210739908 Test RE 0.050361254664872825\n",
      "83 Train Loss 90837.13 Test MSE 11794.947083700765 Test RE 0.04854391761639666\n",
      "84 Train Loss 90521.5 Test MSE 11381.091089158122 Test RE 0.04768466910188035\n",
      "85 Train Loss 90052.8 Test MSE 7184.940952593866 Test RE 0.037887716001227284\n",
      "86 Train Loss 88612.02 Test MSE 6308.474719867841 Test RE 0.03550168834439632\n",
      "87 Train Loss 87567.695 Test MSE 5095.977071251379 Test RE 0.03190807148086317\n",
      "88 Train Loss 86812.125 Test MSE 4496.499651717017 Test RE 0.02997257845831876\n",
      "89 Train Loss 85857.05 Test MSE 1905.5337655110882 Test RE 0.019511701712624268\n",
      "90 Train Loss 85121.97 Test MSE 1672.9275815019244 Test RE 0.018282071131972444\n",
      "91 Train Loss 83874.48 Test MSE 4509.272908821704 Test RE 0.03001511998796439\n",
      "92 Train Loss 82952.71 Test MSE 6991.03074299061 Test RE 0.0373729542837557\n",
      "93 Train Loss 82400.0 Test MSE 7037.0076959745065 Test RE 0.03749564568354872\n",
      "94 Train Loss 81834.11 Test MSE 7084.194866869423 Test RE 0.037621150539792945\n",
      "95 Train Loss 81334.875 Test MSE 7817.086153279157 Test RE 0.03951930268207103\n",
      "96 Train Loss 80953.07 Test MSE 8566.142488746296 Test RE 0.041369423677726266\n",
      "97 Train Loss 79990.83 Test MSE 6269.591099431814 Test RE 0.03539210813948386\n",
      "98 Train Loss 79566.39 Test MSE 6744.907061182332 Test RE 0.03670919057649863\n",
      "99 Train Loss 79022.36 Test MSE 5566.136541680099 Test RE 0.033347536111198346\n",
      "100 Train Loss 78681.336 Test MSE 3822.13088588945 Test RE 0.02763373580620237\n",
      "101 Train Loss 78272.83 Test MSE 2152.09548637168 Test RE 0.020735647051361068\n",
      "102 Train Loss 77852.09 Test MSE 1564.9631759909641 Test RE 0.01768230531472406\n",
      "103 Train Loss 77463.65 Test MSE 1566.1392806642093 Test RE 0.01768894838993859\n",
      "104 Train Loss 77005.266 Test MSE 1737.046844499683 Test RE 0.018629130669240466\n",
      "105 Train Loss 76186.59 Test MSE 7409.503730687404 Test RE 0.038475244130975306\n",
      "106 Train Loss 75650.02 Test MSE 6314.479990896295 Test RE 0.03551858201176294\n",
      "107 Train Loss 75246.98 Test MSE 6125.732144251921 Test RE 0.03498370684320696\n",
      "108 Train Loss 74874.195 Test MSE 6515.439554227596 Test RE 0.036079348249084243\n",
      "109 Train Loss 74465.33 Test MSE 8324.230581488035 Test RE 0.04078109422952791\n",
      "110 Train Loss 74163.85 Test MSE 6668.623023835747 Test RE 0.03650101215657799\n",
      "111 Train Loss 73941.914 Test MSE 4778.084199691278 Test RE 0.030896815748244606\n",
      "112 Train Loss 73733.055 Test MSE 4043.820524376195 Test RE 0.028423840650500742\n",
      "113 Train Loss 73329.02 Test MSE 3196.1651952391253 Test RE 0.025269778351744827\n",
      "114 Train Loss 72969.49 Test MSE 2495.073045672639 Test RE 0.022326901475578278\n",
      "115 Train Loss 72735.25 Test MSE 2480.2380250956044 Test RE 0.022260427700712737\n",
      "116 Train Loss 72468.57 Test MSE 3171.309910707268 Test RE 0.02517133015532289\n",
      "117 Train Loss 72173.88 Test MSE 3724.751352757785 Test RE 0.02727944101596282\n",
      "118 Train Loss 71887.59 Test MSE 3030.5985316346796 Test RE 0.024606567046402208\n",
      "119 Train Loss 71484.36 Test MSE 3267.900864617727 Test RE 0.025551785926728913\n",
      "120 Train Loss 70954.164 Test MSE 2700.799014470821 Test RE 0.023229130663510324\n",
      "121 Train Loss 70600.984 Test MSE 2028.0174630944528 Test RE 0.02012902173608668\n",
      "122 Train Loss 70151.39 Test MSE 1525.5045335768666 Test RE 0.01745796325127117\n",
      "123 Train Loss 69924.13 Test MSE 1322.9449992673187 Test RE 0.016257648071043795\n",
      "124 Train Loss 69698.375 Test MSE 1317.2129817726347 Test RE 0.01622238950614934\n",
      "125 Train Loss 69474.05 Test MSE 1325.8649496973019 Test RE 0.016275579791963254\n",
      "126 Train Loss 69171.46 Test MSE 1587.6612624587913 Test RE 0.017810074982963088\n",
      "127 Train Loss 68880.96 Test MSE 1496.008110574048 Test RE 0.017288360011353855\n",
      "128 Train Loss 68599.695 Test MSE 1578.0667305284906 Test RE 0.01775617863741861\n",
      "129 Train Loss 68195.61 Test MSE 2192.1431355229474 Test RE 0.020927689232880933\n",
      "130 Train Loss 67903.17 Test MSE 1751.4357965310742 Test RE 0.018706129411475148\n",
      "131 Train Loss 67682.55 Test MSE 1667.1234066213983 Test RE 0.01825032901185616\n",
      "132 Train Loss 67540.09 Test MSE 2130.997585064692 Test RE 0.020633756563043774\n",
      "133 Train Loss 67358.51 Test MSE 2120.5414120199275 Test RE 0.020583072452122327\n",
      "134 Train Loss 67167.555 Test MSE 1812.1927411475458 Test RE 0.019027819232392752\n",
      "135 Train Loss 66942.48 Test MSE 1857.4531209982667 Test RE 0.019263968281683173\n",
      "136 Train Loss 66585.555 Test MSE 2035.656096897471 Test RE 0.020166894613436227\n",
      "137 Train Loss 66436.75 Test MSE 1252.3409256367943 Test RE 0.015817873945809392\n",
      "138 Train Loss 66193.945 Test MSE 1142.5073799057209 Test RE 0.015108325423261817\n",
      "139 Train Loss 65841.0 Test MSE 3314.488346903787 Test RE 0.02573327563675534\n",
      "140 Train Loss 65415.31 Test MSE 3059.5195137170167 Test RE 0.024723698418612456\n",
      "141 Train Loss 65065.83 Test MSE 1595.34157589446 Test RE 0.017853101141489646\n",
      "142 Train Loss 64675.008 Test MSE 1046.7126786698727 Test RE 0.014461074583980618\n",
      "143 Train Loss 64309.184 Test MSE 1289.0540983051942 Test RE 0.01604805468744332\n",
      "144 Train Loss 63874.34 Test MSE 1385.4038585825288 Test RE 0.01663700013353889\n",
      "145 Train Loss 63589.816 Test MSE 1532.2127311493264 Test RE 0.017496305649149082\n",
      "146 Train Loss 63310.71 Test MSE 1343.7073466150266 Test RE 0.01638472548526301\n",
      "147 Train Loss 63101.152 Test MSE 1216.0233628475191 Test RE 0.015586829438968266\n",
      "148 Train Loss 62541.035 Test MSE 2626.5537329523204 Test RE 0.022907619911044792\n",
      "149 Train Loss 62163.625 Test MSE 1470.1631141470366 Test RE 0.017138372770771987\n",
      "150 Train Loss 61913.94 Test MSE 1119.4503608369014 Test RE 0.014955097335411095\n",
      "151 Train Loss 61611.51 Test MSE 961.9435700108236 Test RE 0.013863140401351254\n",
      "152 Train Loss 61353.31 Test MSE 1305.2014930550138 Test RE 0.016148255215612466\n",
      "153 Train Loss 60931.96 Test MSE 1596.4387942006624 Test RE 0.017859239445267357\n",
      "154 Train Loss 60613.363 Test MSE 1088.771221628911 Test RE 0.014748747489011099\n",
      "155 Train Loss 60443.742 Test MSE 969.9449987309818 Test RE 0.01392067767262237\n",
      "156 Train Loss 60231.164 Test MSE 1238.4636614437409 Test RE 0.015729990406483967\n",
      "157 Train Loss 59904.36 Test MSE 1619.108461479779 Test RE 0.017985594384135092\n",
      "158 Train Loss 59489.29 Test MSE 1226.2302575599174 Test RE 0.01565210806845259\n",
      "159 Train Loss 59103.902 Test MSE 1441.5870416160617 Test RE 0.016970993165044676\n",
      "160 Train Loss 58472.867 Test MSE 1738.0607857574485 Test RE 0.018634566932694673\n",
      "161 Train Loss 58148.43 Test MSE 1539.5858394542995 Test RE 0.017538351813638248\n",
      "162 Train Loss 57949.07 Test MSE 1354.0428042978974 Test RE 0.01644761836389814\n",
      "163 Train Loss 57810.613 Test MSE 1251.3805263413412 Test RE 0.015811807551139468\n",
      "164 Train Loss 57567.54 Test MSE 1742.7906181842961 Test RE 0.018659905084779313\n",
      "165 Train Loss 57375.754 Test MSE 1878.8556165493264 Test RE 0.019374634901422844\n",
      "166 Train Loss 57240.996 Test MSE 2016.5889270810455 Test RE 0.020072224823503043\n",
      "167 Train Loss 56954.395 Test MSE 1250.1797094322492 Test RE 0.01580421927458016\n",
      "168 Train Loss 56784.543 Test MSE 1144.6882322790116 Test RE 0.015122738161157792\n",
      "169 Train Loss 56619.96 Test MSE 1257.3922576309549 Test RE 0.01584974263365928\n",
      "170 Train Loss 56448.31 Test MSE 943.1189003797779 Test RE 0.013726823445514066\n",
      "171 Train Loss 56283.18 Test MSE 824.9469801658881 Test RE 0.012838073039908377\n",
      "172 Train Loss 56059.97 Test MSE 1051.6614480177905 Test RE 0.014495219643895592\n",
      "173 Train Loss 55921.8 Test MSE 1099.1928083621349 Test RE 0.014819165996460396\n",
      "174 Train Loss 55750.176 Test MSE 1227.1623373127497 Test RE 0.015658055663384265\n",
      "175 Train Loss 55479.332 Test MSE 1370.0797945088498 Test RE 0.01654473267792684\n",
      "176 Train Loss 55329.47 Test MSE 1176.7965978466705 Test RE 0.015333366831093393\n",
      "177 Train Loss 55082.254 Test MSE 1215.951426794243 Test RE 0.015586368398658455\n",
      "178 Train Loss 54952.164 Test MSE 1498.9653925772432 Test RE 0.017305439235053517\n",
      "179 Train Loss 54654.72 Test MSE 1197.210694726367 Test RE 0.015465790308204006\n",
      "180 Train Loss 54464.527 Test MSE 1132.9042279334008 Test RE 0.015044696201736093\n",
      "181 Train Loss 54246.496 Test MSE 1402.075404896776 Test RE 0.01673680318692322\n",
      "182 Train Loss 54050.797 Test MSE 1549.8614191440863 Test RE 0.017596782147155907\n",
      "183 Train Loss 53849.586 Test MSE 1390.328673133335 Test RE 0.016666544390391242\n",
      "184 Train Loss 53599.215 Test MSE 1300.736703097596 Test RE 0.01612061184718144\n",
      "185 Train Loss 53371.062 Test MSE 1218.369488449846 Test RE 0.01560185836001933\n",
      "186 Train Loss 53215.176 Test MSE 1078.2887126849919 Test RE 0.014677576520423601\n",
      "187 Train Loss 53035.668 Test MSE 961.4471190737036 Test RE 0.013859562614945387\n",
      "188 Train Loss 52838.215 Test MSE 926.0839977865571 Test RE 0.013602289494623799\n",
      "189 Train Loss 52602.32 Test MSE 839.3264475762929 Test RE 0.012949478464913167\n",
      "190 Train Loss 52379.46 Test MSE 1167.0931362041258 Test RE 0.015270019129647773\n",
      "191 Train Loss 52261.87 Test MSE 1475.401869328626 Test RE 0.017168880915414683\n",
      "192 Train Loss 51965.918 Test MSE 1631.1704704945623 Test RE 0.01805246447383727\n",
      "193 Train Loss 51677.043 Test MSE 1610.9132872156529 Test RE 0.017940019282592985\n",
      "194 Train Loss 51475.516 Test MSE 1644.51168483427 Test RE 0.01812613897610162\n",
      "195 Train Loss 51237.84 Test MSE 1345.8566298703333 Test RE 0.01639782407609467\n",
      "196 Train Loss 50959.27 Test MSE 1091.7716351176389 Test RE 0.014769055655934152\n",
      "197 Train Loss 50818.59 Test MSE 1109.1779917137656 Test RE 0.014886323258449926\n",
      "198 Train Loss 50673.758 Test MSE 1280.6634338913332 Test RE 0.015995739707568617\n",
      "199 Train Loss 50476.41 Test MSE 991.7933986055767 Test RE 0.014076588992904383\n",
      "Training time: 45.88\n",
      "Training time: 45.88\n"
     ]
    }
   ],
   "source": [
    " \n",
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  beta_val = []\n",
    "\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers)\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.01,\n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "e199619a-d416-48f4-91f7-2c23d1e79435"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30242/2488343543.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_tanh_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_FODE_tanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
