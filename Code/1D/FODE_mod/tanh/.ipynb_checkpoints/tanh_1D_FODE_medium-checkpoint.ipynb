{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "3df10486-4078-44cd-95da-12a75fb13c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvP0Nx4vNOlZ",
    "outputId": "515a82ba-2a23-4124-c9e1-230f67f43912"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDzAYhTsNbP6",
    "outputId": "d35a8c58-7c75-4550-d489-9565724f04e6"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1wXUvTNETmrW",
    "outputId": "7b44eee8-32ab-4621-ca04-81e30b53601d"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "def true_1D_2(x): #True function for 1D_1 dy/dx = cos(0.01*x) BC1: y(0)=0; x \\in [-100,100]\n",
    "    y = extent*np.sin(x)/2 + np.square(x)/2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"medium\"\n",
    "label = \"1D_FODE_tanh_\" +level\n",
    "extent = 20.0\n",
    "\n",
    "x = np.linspace(extent,-1.0*extent,5000).reshape(-1,1)\n",
    "ysol = true_1D_2(x)\n",
    "\n",
    "bc1_x = np.array(0).reshape(-1,1) \n",
    "bc1_y = np.array(0).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "\n",
    " \n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "\n",
    "y_true = true_1D_2(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "\n",
    "  #Collocation Points\n",
    "  # Latin Hypercube sampling for collocation points \n",
    "  # N_f sets of tuples(x,y)\n",
    "  x01 = np.array([[0.0, 1.0]])\n",
    "  sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "  x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "  x_coll_train = np.vstack((x_coll_train, bc1_x)) # append training points to collocation points \n",
    "\n",
    "  return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "             \n",
    "      \n",
    "              \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        f = dy_dx - extent*torch.cos(g)/2.0 - g\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + 100*loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(seed):\n",
    "    x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_coll_train,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "   \n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fAcpqTqePPt9"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    x_coll_np_array = colloc_pts(N_f,123)\n",
    "    x_coll = torch.from_numpy(x_coll_np_array).float().to(device)\n",
    "\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(i)        \n",
    "    \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "3645d237-1d2a-45c9-8d9f-de486f1ca919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 16116.069 Test MSE 10066.183768531624 Test RE 1.1178583615209516\n",
      "1 Train Loss 13767.994 Test MSE 12020.421897377984 Test RE 1.22155832510057\n",
      "2 Train Loss 13010.384 Test MSE 12156.488972134019 Test RE 1.2284526812978658\n",
      "3 Train Loss 12194.24 Test MSE 10902.308213444383 Test RE 1.1633585342996753\n",
      "4 Train Loss 11555.374 Test MSE 8814.644054530496 Test RE 1.0460603532099406\n",
      "5 Train Loss 11026.736 Test MSE 7534.558504618615 Test RE 0.9671264412673941\n",
      "6 Train Loss 10499.16 Test MSE 7213.69309388989 Test RE 0.9463094630166892\n",
      "7 Train Loss 9891.589 Test MSE 6058.861140314216 Test RE 0.8672610699064753\n",
      "8 Train Loss 9470.778 Test MSE 5472.687815383878 Test RE 0.8242419035500153\n",
      "9 Train Loss 9144.623 Test MSE 4659.195183778927 Test RE 0.7605185377909516\n",
      "10 Train Loss 9017.051 Test MSE 4479.852270274301 Test RE 0.7457378713032007\n",
      "11 Train Loss 8918.2 Test MSE 4278.139278755444 Test RE 0.7287554438895371\n",
      "12 Train Loss 8874.232 Test MSE 4163.894126957437 Test RE 0.7189591108050869\n",
      "13 Train Loss 8836.844 Test MSE 4134.400239692689 Test RE 0.7164083035831001\n",
      "14 Train Loss 8812.182 Test MSE 4176.546205820987 Test RE 0.7200505684317032\n",
      "15 Train Loss 8786.394 Test MSE 4024.953213586904 Test RE 0.7068622203887275\n",
      "16 Train Loss 8764.68 Test MSE 4004.3142720067985 Test RE 0.7050475858536063\n",
      "17 Train Loss 8744.964 Test MSE 4069.5816768455757 Test RE 0.7107702422780874\n",
      "18 Train Loss 8728.832 Test MSE 4066.7904335240246 Test RE 0.7105264490394981\n",
      "19 Train Loss 8721.84 Test MSE 4083.9193632574356 Test RE 0.7120212112397424\n",
      "20 Train Loss 8669.427 Test MSE 4222.608265577695 Test RE 0.7240103073983217\n",
      "21 Train Loss 8560.933 Test MSE 4012.9881788613416 Test RE 0.7058107888001552\n",
      "22 Train Loss 8256.6455 Test MSE 3532.9806250634147 Test RE 0.6622545948987585\n",
      "23 Train Loss 8022.566 Test MSE 3308.5315787149 Test RE 0.6408730284960984\n",
      "24 Train Loss 7881.0415 Test MSE 3487.9494653763445 Test RE 0.658020531126678\n",
      "25 Train Loss 7795.745 Test MSE 3648.723313659308 Test RE 0.6730151152625526\n",
      "26 Train Loss 7680.902 Test MSE 3581.2662684637576 Test RE 0.6667647908583272\n",
      "27 Train Loss 7546.437 Test MSE 3621.0214260479524 Test RE 0.6704554102151078\n",
      "28 Train Loss 7404.8276 Test MSE 3504.203255711751 Test RE 0.6595519318518793\n",
      "29 Train Loss 7318.223 Test MSE 3439.3418355619006 Test RE 0.6534193985538048\n",
      "30 Train Loss 7119.7915 Test MSE 3434.429366708012 Test RE 0.6529525869360695\n",
      "31 Train Loss 6886.5327 Test MSE 3660.8916411320492 Test RE 0.6741364186744739\n",
      "32 Train Loss 6657.239 Test MSE 3524.2023263645665 Test RE 0.6614313404147635\n",
      "33 Train Loss 6400.4517 Test MSE 3119.1525380413987 Test RE 0.6222611099126117\n",
      "34 Train Loss 6049.3696 Test MSE 2915.6705710323745 Test RE 0.6016218198590002\n",
      "35 Train Loss 5791.6714 Test MSE 2822.99256151138 Test RE 0.5919829781887804\n",
      "36 Train Loss 5569.6396 Test MSE 2786.4118712611553 Test RE 0.5881349771324318\n",
      "37 Train Loss 5405.9253 Test MSE 2600.4641450343092 Test RE 0.5681719475473911\n",
      "38 Train Loss 5190.137 Test MSE 2247.747509263824 Test RE 0.5282361450560753\n",
      "39 Train Loss 5035.833 Test MSE 2140.244768919633 Test RE 0.5154494427785687\n",
      "40 Train Loss 4864.35 Test MSE 1964.8973521575645 Test RE 0.49388323714289434\n",
      "41 Train Loss 4627.4624 Test MSE 1875.6350119739816 Test RE 0.4825346645502049\n",
      "42 Train Loss 4475.2363 Test MSE 1809.5042151843336 Test RE 0.47395177262575644\n",
      "43 Train Loss 4257.069 Test MSE 1709.5554499227098 Test RE 0.4606763829443223\n",
      "44 Train Loss 3832.1362 Test MSE 1557.9653375832381 Test RE 0.4397777448033775\n",
      "45 Train Loss 3640.5806 Test MSE 1612.9628181233122 Test RE 0.4474726855634757\n",
      "46 Train Loss 3464.354 Test MSE 1649.2074833347199 Test RE 0.4524723036909596\n",
      "47 Train Loss 3390.1343 Test MSE 1523.9477168213823 Test RE 0.43495005104886403\n",
      "48 Train Loss 3104.277 Test MSE 1055.4395065158112 Test RE 0.3619687062522204\n",
      "49 Train Loss 2981.2708 Test MSE 912.8342072229229 Test RE 0.33662805322956346\n",
      "50 Train Loss 2804.9163 Test MSE 642.185480389765 Test RE 0.2823479204323131\n",
      "51 Train Loss 2712.5112 Test MSE 625.9248449122153 Test RE 0.27875036681076587\n",
      "52 Train Loss 2573.8538 Test MSE 496.9875133612291 Test RE 0.24838598705479797\n",
      "53 Train Loss 2420.1533 Test MSE 399.9665339965664 Test RE 0.22282616182335832\n",
      "54 Train Loss 2314.0396 Test MSE 323.45850844259826 Test RE 0.20038427708582562\n",
      "55 Train Loss 2224.1116 Test MSE 241.41474500342972 Test RE 0.17311561719549104\n",
      "56 Train Loss 2150.9424 Test MSE 212.97868123521596 Test RE 0.16260070307630287\n",
      "57 Train Loss 2096.7588 Test MSE 212.49926394038317 Test RE 0.16241759200905995\n",
      "58 Train Loss 2035.1254 Test MSE 187.59516050831172 Test RE 0.15260373654873938\n",
      "59 Train Loss 1996.6893 Test MSE 154.38112550275162 Test RE 0.13843676870702878\n",
      "60 Train Loss 1960.7202 Test MSE 138.96929423170764 Test RE 0.1313450706050016\n",
      "61 Train Loss 1924.2152 Test MSE 152.94753935620318 Test RE 0.13779250629131976\n",
      "62 Train Loss 1868.7764 Test MSE 157.73876760913876 Test RE 0.1399341048743249\n",
      "63 Train Loss 1801.9524 Test MSE 167.11639540422823 Test RE 0.14403362205563874\n",
      "64 Train Loss 1746.803 Test MSE 170.11524990037003 Test RE 0.14532019638324004\n",
      "65 Train Loss 1720.2758 Test MSE 159.77515037996568 Test RE 0.14083447197593196\n",
      "66 Train Loss 1693.3339 Test MSE 141.03398860490339 Test RE 0.13231718308571958\n",
      "67 Train Loss 1681.1451 Test MSE 135.04451046262636 Test RE 0.12947705712411842\n",
      "68 Train Loss 1654.7185 Test MSE 132.01241994876958 Test RE 0.12801526173363975\n",
      "69 Train Loss 1629.0635 Test MSE 148.17398084827403 Test RE 0.1356251797415121\n",
      "70 Train Loss 1608.2031 Test MSE 172.30795891691218 Test RE 0.14625375369914265\n",
      "71 Train Loss 1576.3394 Test MSE 209.9144809179958 Test RE 0.16142676814270046\n",
      "72 Train Loss 1547.0391 Test MSE 232.23510257147694 Test RE 0.16979241464986844\n",
      "73 Train Loss 1503.5518 Test MSE 222.37080191620336 Test RE 0.16614727909500296\n",
      "74 Train Loss 1459.701 Test MSE 238.49337752676004 Test RE 0.17206499032029712\n",
      "75 Train Loss 1419.2164 Test MSE 300.41688883853897 Test RE 0.1931152294454122\n",
      "76 Train Loss 1401.4802 Test MSE 286.23652742572176 Test RE 0.18850239808907315\n",
      "77 Train Loss 1384.7316 Test MSE 275.3361223590219 Test RE 0.18487830392176527\n",
      "78 Train Loss 1368.3978 Test MSE 261.5341425988498 Test RE 0.1801849646128157\n",
      "79 Train Loss 1357.546 Test MSE 253.33521668635555 Test RE 0.17733813443736401\n",
      "80 Train Loss 1348.474 Test MSE 242.85904301197934 Test RE 0.17363268937106172\n",
      "81 Train Loss 1338.9498 Test MSE 230.90662987443608 Test RE 0.1693060797048502\n",
      "82 Train Loss 1321.0083 Test MSE 222.73945551800784 Test RE 0.1662849442638761\n",
      "83 Train Loss 1301.0751 Test MSE 220.6827200762896 Test RE 0.16551544138290947\n",
      "84 Train Loss 1284.1553 Test MSE 212.02383960981575 Test RE 0.16223580193734444\n",
      "85 Train Loss 1267.5002 Test MSE 186.08437521465152 Test RE 0.1519880022683271\n",
      "86 Train Loss 1251.7577 Test MSE 187.37019573347973 Test RE 0.15251220763184817\n",
      "87 Train Loss 1244.6342 Test MSE 185.68494318401505 Test RE 0.15182479273131674\n",
      "88 Train Loss 1238.2899 Test MSE 190.44241418975858 Test RE 0.15375745838649416\n",
      "89 Train Loss 1232.5759 Test MSE 199.85544613463244 Test RE 0.15751152854756034\n",
      "90 Train Loss 1224.488 Test MSE 206.64829263878357 Test RE 0.16016597545918804\n",
      "91 Train Loss 1211.7545 Test MSE 231.73982501644707 Test RE 0.16961126362011106\n",
      "92 Train Loss 1199.3151 Test MSE 243.37676160532828 Test RE 0.17381766295480333\n",
      "93 Train Loss 1193.9502 Test MSE 247.0139475722015 Test RE 0.17511167026850297\n",
      "94 Train Loss 1188.9896 Test MSE 268.0111051972035 Test RE 0.18240248350288704\n",
      "95 Train Loss 1184.0881 Test MSE 304.98253676691803 Test RE 0.19457715029001663\n",
      "96 Train Loss 1179.6143 Test MSE 329.8061481908438 Test RE 0.2023409226833199\n",
      "97 Train Loss 1177.4896 Test MSE 334.27781496594224 Test RE 0.2037080210123457\n",
      "98 Train Loss 1174.0829 Test MSE 343.4715396956996 Test RE 0.2064903359320634\n",
      "99 Train Loss 1171.9674 Test MSE 345.96464044229316 Test RE 0.2072383897742312\n",
      "100 Train Loss 1169.7262 Test MSE 349.50923316340374 Test RE 0.2082973184181824\n",
      "101 Train Loss 1167.3025 Test MSE 349.66213558408026 Test RE 0.20834287612971553\n",
      "102 Train Loss 1165.7683 Test MSE 340.711888117678 Test RE 0.20565913080042642\n",
      "103 Train Loss 1163.7831 Test MSE 331.6546195807843 Test RE 0.20290716258024585\n",
      "104 Train Loss 1161.7537 Test MSE 335.1555750093815 Test RE 0.20397529800134306\n",
      "105 Train Loss 1159.9235 Test MSE 335.79991648949374 Test RE 0.20417127659600767\n",
      "106 Train Loss 1158.6685 Test MSE 338.7019062897555 Test RE 0.20505160492413668\n",
      "107 Train Loss 1157.3794 Test MSE 341.86218114515344 Test RE 0.2060060058824981\n",
      "108 Train Loss 1155.9185 Test MSE 339.0559280279643 Test RE 0.20515874008504806\n",
      "109 Train Loss 1153.6427 Test MSE 331.4026223977298 Test RE 0.20283006166437545\n",
      "110 Train Loss 1151.56 Test MSE 326.81009664699303 Test RE 0.20141976505299833\n",
      "111 Train Loss 1150.467 Test MSE 326.5537667823122 Test RE 0.20134075888174352\n",
      "112 Train Loss 1148.5795 Test MSE 328.7160079778826 Test RE 0.202006237360262\n",
      "113 Train Loss 1146.4694 Test MSE 320.18413052078205 Test RE 0.19936744987555033\n",
      "114 Train Loss 1145.3021 Test MSE 323.881810556704 Test RE 0.20051535317841201\n",
      "115 Train Loss 1144.0461 Test MSE 323.1862989916321 Test RE 0.2002999417329445\n",
      "116 Train Loss 1143.3474 Test MSE 324.01149110481697 Test RE 0.20055549179953705\n",
      "117 Train Loss 1142.1757 Test MSE 328.4600149393312 Test RE 0.20192756418781768\n",
      "118 Train Loss 1136.7683 Test MSE 349.4926986985764 Test RE 0.2082923913302945\n",
      "119 Train Loss 1135.5203 Test MSE 350.4897613389374 Test RE 0.20858929688960604\n",
      "120 Train Loss 1133.7 Test MSE 352.99273786103 Test RE 0.2093327783935882\n",
      "121 Train Loss 1130.2283 Test MSE 349.0291475463314 Test RE 0.20815421073900076\n",
      "122 Train Loss 1128.712 Test MSE 339.9905513067838 Test RE 0.2054413102468497\n",
      "123 Train Loss 1126.4054 Test MSE 335.91049598155644 Test RE 0.20420489080581405\n",
      "124 Train Loss 1124.1962 Test MSE 348.14953969071854 Test RE 0.20789175474897126\n",
      "125 Train Loss 1122.5432 Test MSE 355.06222914639744 Test RE 0.20994550950663304\n",
      "126 Train Loss 1120.268 Test MSE 351.65843017999157 Test RE 0.20893676630148686\n",
      "127 Train Loss 1117.8569 Test MSE 351.2553884694308 Test RE 0.2088169989832713\n",
      "128 Train Loss 1115.6342 Test MSE 355.97995831882264 Test RE 0.21021665743930157\n",
      "129 Train Loss 1114.4053 Test MSE 357.5730659270854 Test RE 0.21068652083310557\n",
      "130 Train Loss 1113.1302 Test MSE 354.6943791697077 Test RE 0.20983672792234537\n",
      "131 Train Loss 1111.8475 Test MSE 350.85897675452435 Test RE 0.20869913478053323\n",
      "132 Train Loss 1109.5693 Test MSE 349.26937357481154 Test RE 0.2082258314884487\n",
      "133 Train Loss 1108.3573 Test MSE 339.93034290971036 Test RE 0.2054231188006488\n",
      "134 Train Loss 1106.7429 Test MSE 330.0178215823476 Test RE 0.20240584463755928\n",
      "135 Train Loss 1105.5394 Test MSE 332.3894567722486 Test RE 0.2031318258607884\n",
      "136 Train Loss 1101.686 Test MSE 329.22989993745193 Test RE 0.2021640770124513\n",
      "137 Train Loss 1096.0056 Test MSE 309.97808050482985 Test RE 0.19616424210058042\n",
      "138 Train Loss 1087.3223 Test MSE 299.95314058113865 Test RE 0.1929661175895269\n",
      "139 Train Loss 1074.7723 Test MSE 272.87336101472744 Test RE 0.18404961886724508\n",
      "140 Train Loss 1056.883 Test MSE 243.79067204338935 Test RE 0.173965405864531\n",
      "141 Train Loss 1036.2854 Test MSE 219.00237923766537 Test RE 0.16488409651287614\n",
      "142 Train Loss 1026.5127 Test MSE 208.19596148209078 Test RE 0.1607646290754115\n",
      "143 Train Loss 1017.27264 Test MSE 200.0023950466496 Test RE 0.15756942512996425\n",
      "144 Train Loss 1012.4681 Test MSE 201.47576454253166 Test RE 0.15814874816527968\n",
      "145 Train Loss 1004.6634 Test MSE 205.7142751732607 Test RE 0.1598036031423323\n",
      "146 Train Loss 998.2057 Test MSE 220.56766118741794 Test RE 0.16547228778734\n",
      "147 Train Loss 990.1635 Test MSE 238.8595096260634 Test RE 0.17219701569701934\n",
      "148 Train Loss 983.52875 Test MSE 261.1947960334579 Test RE 0.18006802960108784\n",
      "149 Train Loss 977.51526 Test MSE 274.58643126282124 Test RE 0.1846264370532434\n",
      "150 Train Loss 970.3074 Test MSE 291.84271346715065 Test RE 0.19033943667778133\n",
      "151 Train Loss 967.925 Test MSE 296.83565471520166 Test RE 0.19196072657680255\n",
      "152 Train Loss 966.51544 Test MSE 298.5159327382248 Test RE 0.19250326959127653\n",
      "153 Train Loss 964.8013 Test MSE 301.2760113379804 Test RE 0.1933911646513061\n",
      "154 Train Loss 963.0123 Test MSE 303.00960451538225 Test RE 0.19394676928894122\n",
      "155 Train Loss 959.91534 Test MSE 312.38568316923624 Test RE 0.19692457333724853\n",
      "156 Train Loss 959.03503 Test MSE 323.0857321776362 Test RE 0.20026877535256232\n",
      "157 Train Loss 958.51196 Test MSE 331.5057947025442 Test RE 0.20286163174723087\n",
      "158 Train Loss 958.1927 Test MSE 334.05809279980866 Test RE 0.2036410609522619\n",
      "159 Train Loss 957.5694 Test MSE 334.32597743371906 Test RE 0.20372269552436986\n",
      "160 Train Loss 956.65936 Test MSE 334.7195151962453 Test RE 0.2038425620619926\n",
      "161 Train Loss 955.88 Test MSE 331.8122559468112 Test RE 0.20295537802194297\n",
      "162 Train Loss 955.09937 Test MSE 330.29906079029104 Test RE 0.20249207079445314\n",
      "163 Train Loss 952.9915 Test MSE 328.82258342894863 Test RE 0.20203898167543632\n",
      "164 Train Loss 951.61005 Test MSE 332.06241384447145 Test RE 0.20303186905589288\n",
      "165 Train Loss 950.7505 Test MSE 330.9268398135006 Test RE 0.20268441153109812\n",
      "166 Train Loss 950.30817 Test MSE 331.8866344903599 Test RE 0.20297812383572655\n",
      "167 Train Loss 949.9757 Test MSE 331.53843196989584 Test RE 0.20287161752495528\n",
      "168 Train Loss 949.6355 Test MSE 329.09976867808274 Test RE 0.20212411942344052\n",
      "169 Train Loss 949.30835 Test MSE 332.31406548154513 Test RE 0.20310878776690844\n",
      "170 Train Loss 948.3979 Test MSE 344.6533714747509 Test RE 0.20684528132074215\n",
      "171 Train Loss 947.81586 Test MSE 346.9285733644184 Test RE 0.20752689462466278\n",
      "172 Train Loss 946.7408 Test MSE 337.03650477532756 Test RE 0.2045468630495026\n",
      "173 Train Loss 946.34607 Test MSE 337.14427650714094 Test RE 0.20457956367301813\n",
      "174 Train Loss 945.9869 Test MSE 337.6944676083354 Test RE 0.20474642394538917\n",
      "175 Train Loss 945.4262 Test MSE 332.8559862372729 Test RE 0.20327433000853137\n",
      "176 Train Loss 944.8381 Test MSE 330.3929014117181 Test RE 0.202520833565152\n",
      "177 Train Loss 944.3448 Test MSE 328.24658907265894 Test RE 0.20186194955209438\n",
      "178 Train Loss 944.0773 Test MSE 320.21216427329216 Test RE 0.19937617750269396\n",
      "179 Train Loss 943.653 Test MSE 317.2945851495651 Test RE 0.19846580162682992\n",
      "180 Train Loss 943.028 Test MSE 310.2795794730845 Test RE 0.1962596181060649\n",
      "181 Train Loss 942.4158 Test MSE 305.8668899283312 Test RE 0.19485905226316072\n",
      "182 Train Loss 941.8296 Test MSE 306.839254765279 Test RE 0.19516853941100437\n",
      "183 Train Loss 940.9503 Test MSE 302.8553901077193 Test RE 0.19389740914951822\n",
      "184 Train Loss 939.958 Test MSE 302.11391969509293 Test RE 0.19365990752194004\n",
      "185 Train Loss 938.9643 Test MSE 312.05982890722095 Test RE 0.1968218390290695\n",
      "186 Train Loss 938.1479 Test MSE 313.40897279662124 Test RE 0.1972468450198162\n",
      "187 Train Loss 937.2908 Test MSE 312.72532675905165 Test RE 0.19703159808648696\n",
      "188 Train Loss 936.58563 Test MSE 313.2883187438238 Test RE 0.1972088739911942\n",
      "189 Train Loss 935.8067 Test MSE 310.43285080142306 Test RE 0.19630808610144346\n",
      "190 Train Loss 935.2877 Test MSE 308.0700272340541 Test RE 0.1955595709800245\n",
      "191 Train Loss 934.7014 Test MSE 310.32991449788034 Test RE 0.19627553654347768\n",
      "192 Train Loss 933.9133 Test MSE 308.8162496476206 Test RE 0.1957962747466175\n",
      "193 Train Loss 933.23737 Test MSE 310.99084582646105 Test RE 0.19648443624604742\n",
      "194 Train Loss 932.80426 Test MSE 312.2302775132787 Test RE 0.1968755842170528\n",
      "195 Train Loss 932.02826 Test MSE 316.54222337378565 Test RE 0.19823036315741815\n",
      "196 Train Loss 931.68964 Test MSE 315.27382544680177 Test RE 0.19783280582281873\n",
      "197 Train Loss 931.26074 Test MSE 316.40467547647313 Test RE 0.19818728970579705\n",
      "198 Train Loss 930.55426 Test MSE 325.70244022376306 Test RE 0.20107813965465798\n",
      "199 Train Loss 930.1806 Test MSE 326.013452819597 Test RE 0.20117412129966455\n",
      "Training time: 25.54\n",
      "Training time: 25.54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 14874.094 Test MSE 13817.385394459188 Test RE 1.3096863099752458\n",
      "1 Train Loss 13015.186 Test MSE 12274.562851290453 Test RE 1.2344041392786123\n",
      "2 Train Loss 12215.549 Test MSE 11706.404338408978 Test RE 1.2054969408476326\n",
      "3 Train Loss 10990.623 Test MSE 9451.61539213425 Test RE 1.0831968110967374\n",
      "4 Train Loss 9408.259 Test MSE 5316.684211213699 Test RE 0.8124091109435632\n",
      "5 Train Loss 9165.707 Test MSE 4536.01684843132 Test RE 0.7503980241725711\n",
      "6 Train Loss 9069.502 Test MSE 4201.189466566731 Test RE 0.7221717344922273\n",
      "7 Train Loss 8980.858 Test MSE 4351.541944241571 Test RE 0.7349807073554564\n",
      "8 Train Loss 8891.523 Test MSE 4079.316511925383 Test RE 0.7116198502612457\n",
      "9 Train Loss 8843.184 Test MSE 4011.4057110319877 Test RE 0.705671611589846\n",
      "10 Train Loss 8809.736 Test MSE 4018.144259604092 Test RE 0.7062640731164632\n",
      "11 Train Loss 8773.056 Test MSE 4035.489446740378 Test RE 0.7077868022589766\n",
      "12 Train Loss 8758.917 Test MSE 4057.739870021262 Test RE 0.7097353772263121\n",
      "13 Train Loss 8742.774 Test MSE 4142.337501423761 Test RE 0.7170956576533101\n",
      "14 Train Loss 8731.373 Test MSE 4061.564002573644 Test RE 0.7100697361404736\n",
      "15 Train Loss 8724.219 Test MSE 4025.6399751691124 Test RE 0.7069225223457277\n",
      "16 Train Loss 8721.098 Test MSE 4071.0779660914495 Test RE 0.710900897000686\n",
      "17 Train Loss 8718.835 Test MSE 4046.497596590238 Test RE 0.7087515076669668\n",
      "18 Train Loss 8717.983 Test MSE 4052.7885840892886 Test RE 0.7093022327247258\n",
      "19 Train Loss 8717.582 Test MSE 4070.732172088892 Test RE 0.7108707046918045\n",
      "20 Train Loss 8717.191 Test MSE 4061.593301058677 Test RE 0.7100722972142381\n",
      "21 Train Loss 8716.948 Test MSE 4063.288413853611 Test RE 0.7102204566909155\n",
      "22 Train Loss 8716.474 Test MSE 4073.6665972018695 Test RE 0.7111268774105735\n",
      "23 Train Loss 8715.68 Test MSE 4065.4121856516344 Test RE 0.7104060390297955\n",
      "24 Train Loss 8715.334 Test MSE 4064.591943290837 Test RE 0.7103343692341204\n",
      "25 Train Loss 8715.076 Test MSE 4066.2740707240678 Test RE 0.7104813396246601\n",
      "26 Train Loss 8714.933 Test MSE 4065.424375094627 Test RE 0.7104071040444889\n",
      "27 Train Loss 8714.841 Test MSE 4065.6975918653684 Test RE 0.7104309750916465\n",
      "28 Train Loss 8714.6875 Test MSE 4062.500071291304 Test RE 0.7101515563179334\n",
      "29 Train Loss 8714.562 Test MSE 4070.6052398176366 Test RE 0.7108596215337002\n",
      "30 Train Loss 8714.445 Test MSE 4068.358297930827 Test RE 0.7106634000083051\n",
      "31 Train Loss 8714.369 Test MSE 4059.8446537085606 Test RE 0.7099194262074684\n",
      "32 Train Loss 8714.168 Test MSE 4067.1933037475287 Test RE 0.7105616417627443\n",
      "33 Train Loss 8714.118 Test MSE 4068.528148267767 Test RE 0.7106782346356021\n",
      "34 Train Loss 8714.102 Test MSE 4064.036875088524 Test RE 0.7102858652897109\n",
      "35 Train Loss 8714.102 Test MSE 4063.7283364747045 Test RE 0.7102589025944126\n",
      "36 Train Loss 8714.081 Test MSE 4061.7834629813024 Test RE 0.7100889196481913\n",
      "37 Train Loss 8714.044 Test MSE 4063.207836998339 Test RE 0.7102134146588427\n",
      "38 Train Loss 8714.012 Test MSE 4066.6039871375615 Test RE 0.7105101614277468\n",
      "39 Train Loss 8713.987 Test MSE 4066.747733221098 Test RE 0.7105227188529114\n",
      "40 Train Loss 8713.966 Test MSE 4065.5871846328987 Test RE 0.7104213288687588\n",
      "41 Train Loss 8713.91 Test MSE 4064.1327945783673 Test RE 0.7102942473317465\n",
      "42 Train Loss 8713.887 Test MSE 4064.2080245078423 Test RE 0.7103008213220116\n",
      "43 Train Loss 8713.883 Test MSE 4064.602358139107 Test RE 0.7103352792910266\n",
      "44 Train Loss 8713.855 Test MSE 4066.1861968600615 Test RE 0.7104736626854234\n",
      "45 Train Loss 8713.797 Test MSE 4067.596779568585 Test RE 0.710596885641085\n",
      "46 Train Loss 8713.754 Test MSE 4064.9645998814376 Test RE 0.71036693150861\n",
      "47 Train Loss 8713.751 Test MSE 4064.929633111366 Test RE 0.7103638762187092\n",
      "48 Train Loss 8713.733 Test MSE 4065.994856254102 Test RE 0.7104569462767498\n",
      "49 Train Loss 8713.711 Test MSE 4067.0837125146695 Test RE 0.7105520685945792\n",
      "50 Train Loss 8713.624 Test MSE 4069.127655121612 Test RE 0.7107305927320778\n",
      "51 Train Loss 8713.523 Test MSE 4065.48515934956 Test RE 0.7104124148559968\n",
      "52 Train Loss 8713.492 Test MSE 4064.099731225099 Test RE 0.7102913580613195\n",
      "53 Train Loss 8713.485 Test MSE 4064.2114242529647 Test RE 0.710301118408336\n",
      "54 Train Loss 8713.462 Test MSE 4064.864510624129 Test RE 0.7103581859790348\n",
      "55 Train Loss 8713.408 Test MSE 4064.7950698836344 Test RE 0.710352118371001\n",
      "56 Train Loss 8713.381 Test MSE 4065.3455423552127 Test RE 0.7104002162506895\n",
      "57 Train Loss 8713.354 Test MSE 4063.46192711339 Test RE 0.7102356206835354\n",
      "58 Train Loss 8713.338 Test MSE 4066.264708856122 Test RE 0.710480521746156\n",
      "59 Train Loss 8713.308 Test MSE 4068.3749215985463 Test RE 0.7106648519232162\n",
      "60 Train Loss 8713.304 Test MSE 4067.0991926240354 Test RE 0.71055342084278\n",
      "61 Train Loss 8713.301 Test MSE 4065.981584486394 Test RE 0.7104557867785724\n",
      "62 Train Loss 8713.3 Test MSE 4065.4616565185934 Test RE 0.7104103613831172\n",
      "63 Train Loss 8713.297 Test MSE 4065.0326675584556 Test RE 0.7103728790172851\n",
      "64 Train Loss 8713.296 Test MSE 4064.8751147773005 Test RE 0.7103591125464613\n",
      "65 Train Loss 8713.293 Test MSE 4065.0568052872272 Test RE 0.7103749880732052\n",
      "66 Train Loss 8713.289 Test MSE 4065.125987524233 Test RE 0.7103810328991504\n",
      "67 Train Loss 8713.289 Test MSE 4065.25928321574 Test RE 0.7103926795190941\n",
      "68 Train Loss 8713.286 Test MSE 4065.296655904314 Test RE 0.7103959448979431\n",
      "69 Train Loss 8713.283 Test MSE 4065.064516101659 Test RE 0.7103756618112824\n",
      "70 Train Loss 8713.282 Test MSE 4064.866938339211 Test RE 0.7103583981075104\n",
      "71 Train Loss 8713.279 Test MSE 4064.675097586294 Test RE 0.7103416352835463\n",
      "72 Train Loss 8713.279 Test MSE 4064.7459754360525 Test RE 0.7103478285544735\n",
      "73 Train Loss 8713.277 Test MSE 4064.8161717341886 Test RE 0.7103539622185422\n",
      "74 Train Loss 8713.277 Test MSE 4064.8973984964564 Test RE 0.7103610596445666\n",
      "75 Train Loss 8713.277 Test MSE 4064.9949762204624 Test RE 0.7103695856899567\n",
      "76 Train Loss 8713.276 Test MSE 4065.197656709779 Test RE 0.7103872949689872\n",
      "77 Train Loss 8713.276 Test MSE 4065.3304695223933 Test RE 0.7103988992957704\n",
      "78 Train Loss 8713.275 Test MSE 4065.677536661049 Test RE 0.7104292228885363\n",
      "79 Train Loss 8713.275 Test MSE 4065.8371743335133 Test RE 0.7104431701523475\n",
      "80 Train Loss 8713.272 Test MSE 4066.1399148949095 Test RE 0.7104696193129272\n",
      "81 Train Loss 8713.272 Test MSE 4066.2073347599603 Test RE 0.7104755093669228\n",
      "82 Train Loss 8713.2705 Test MSE 4066.1681613818487 Test RE 0.7104720870386315\n",
      "83 Train Loss 8713.27 Test MSE 4065.8772463793666 Test RE 0.7104466711338089\n",
      "84 Train Loss 8713.269 Test MSE 4065.695471154867 Test RE 0.710430789807499\n",
      "85 Train Loss 8713.269 Test MSE 4065.261660238708 Test RE 0.7103928872081183\n",
      "86 Train Loss 8713.268 Test MSE 4064.9046076437585 Test RE 0.7103616895614804\n",
      "87 Train Loss 8713.268 Test MSE 4064.7601569739677 Test RE 0.7103490677236537\n",
      "88 Train Loss 8713.268 Test MSE 4064.6421949175 Test RE 0.7103387602465148\n",
      "89 Train Loss 8713.267 Test MSE 4064.4731629907183 Test RE 0.7103239900438886\n",
      "90 Train Loss 8713.267 Test MSE 4064.407447041659 Test RE 0.7103182476263649\n",
      "91 Train Loss 8713.267 Test MSE 4064.336697032457 Test RE 0.7103120652686765\n",
      "92 Train Loss 8713.266 Test MSE 4064.3253423672995 Test RE 0.710311073057414\n",
      "93 Train Loss 8713.266 Test MSE 4064.311467213583 Test RE 0.7103098605949625\n",
      "94 Train Loss 8713.266 Test MSE 4064.334038395136 Test RE 0.7103118329475605\n",
      "95 Train Loss 8713.266 Test MSE 4064.387203530937 Test RE 0.7103164786904065\n",
      "96 Train Loss 8713.266 Test MSE 4064.5098702545374 Test RE 0.7103271975925898\n",
      "97 Train Loss 8713.266 Test MSE 4064.646154988782 Test RE 0.7103391062783799\n",
      "98 Train Loss 8713.266 Test MSE 4064.8426707288904 Test RE 0.7103562776535345\n",
      "99 Train Loss 8713.264 Test MSE 4065.373249045244 Test RE 0.7104026370541426\n",
      "100 Train Loss 8713.264 Test MSE 4065.57218989864 Test RE 0.7104200187764674\n",
      "101 Train Loss 8713.264 Test MSE 4065.688891441763 Test RE 0.710430214944883\n",
      "102 Train Loss 8713.263 Test MSE 4065.7828132122495 Test RE 0.7104384207471499\n",
      "103 Train Loss 8713.263 Test MSE 4065.902575260629 Test RE 0.7104488840377238\n",
      "104 Train Loss 8713.263 Test MSE 4065.9660416859156 Test RE 0.7104544288674668\n",
      "105 Train Loss 8713.263 Test MSE 4066.022224306211 Test RE 0.7104593373016643\n",
      "106 Train Loss 8713.263 Test MSE 4066.067057525781 Test RE 0.7104632541631455\n",
      "107 Train Loss 8713.263 Test MSE 4066.118680896247 Test RE 0.7104677642205106\n",
      "108 Train Loss 8713.262 Test MSE 4066.1207751188213 Test RE 0.7104679471809151\n",
      "109 Train Loss 8713.262 Test MSE 4066.1121972477904 Test RE 0.7104671977804455\n",
      "110 Train Loss 8713.262 Test MSE 4066.1037429327807 Test RE 0.710466459173599\n",
      "111 Train Loss 8713.262 Test MSE 4066.0779290255555 Test RE 0.710464203950229\n",
      "112 Train Loss 8713.262 Test MSE 4066.064360883494 Test RE 0.7104630185711661\n",
      "113 Train Loss 8713.263 Test MSE 4066.0483767991946 Test RE 0.7104616221210693\n",
      "114 Train Loss 8713.263 Test MSE 4066.024893655009 Test RE 0.7104595705103587\n",
      "115 Train Loss 8713.263 Test MSE 4065.9939609484823 Test RE 0.7104568680577463\n",
      "116 Train Loss 8713.263 Test MSE 4065.9580147138627 Test RE 0.7104537275826305\n",
      "117 Train Loss 8713.262 Test MSE 4065.9079076672056 Test RE 0.7104493499122729\n",
      "118 Train Loss 8713.262 Test MSE 4065.840557522661 Test RE 0.7104434657326942\n",
      "119 Train Loss 8713.262 Test MSE 4065.8000498199813 Test RE 0.7104399266730641\n",
      "120 Train Loss 8713.262 Test MSE 4065.753331738257 Test RE 0.7104358450058039\n",
      "121 Train Loss 8713.262 Test MSE 4065.689418226086 Test RE 0.7104302609694927\n",
      "122 Train Loss 8713.262 Test MSE 4065.614633313699 Test RE 0.7104237270580598\n",
      "123 Train Loss 8713.262 Test MSE 4065.5255007957526 Test RE 0.7104159395267298\n",
      "124 Train Loss 8713.262 Test MSE 4065.404636411282 Test RE 0.7104053794375843\n",
      "125 Train Loss 8713.262 Test MSE 4065.2661988929613 Test RE 0.7103932837664543\n",
      "126 Train Loss 8713.262 Test MSE 4065.1093440734126 Test RE 0.7103795786756009\n",
      "127 Train Loss 8713.262 Test MSE 4064.9487502573766 Test RE 0.7103655466183474\n",
      "128 Train Loss 8713.261 Test MSE 4064.684103376457 Test RE 0.7103424222079638\n",
      "129 Train Loss 8713.26 Test MSE 4064.555928469965 Test RE 0.7103312222242737\n",
      "130 Train Loss 8713.259 Test MSE 4064.3103499257504 Test RE 0.710309762962113\n",
      "131 Train Loss 8713.259 Test MSE 4064.1767088490956 Test RE 0.7102980848010407\n",
      "132 Train Loss 8713.243 Test MSE 4064.098905366905 Test RE 0.7102912858928191\n",
      "133 Train Loss 8713.237 Test MSE 4065.374452220096 Test RE 0.7104027421783801\n",
      "134 Train Loss 8713.236 Test MSE 4065.6611363517045 Test RE 0.7104277900067267\n",
      "135 Train Loss 8713.234 Test MSE 4065.847013654401 Test RE 0.71044402978762\n",
      "136 Train Loss 8713.234 Test MSE 4065.878543800449 Test RE 0.7104467844855359\n",
      "137 Train Loss 8713.234 Test MSE 4065.8911230358926 Test RE 0.7104478834940728\n",
      "138 Train Loss 8713.232 Test MSE 4065.7897487434825 Test RE 0.7104390266902096\n",
      "139 Train Loss 8713.23 Test MSE 4065.601509674311 Test RE 0.7104225804476241\n",
      "140 Train Loss 8713.23 Test MSE 4065.6490901621682 Test RE 0.7104267375390148\n",
      "141 Train Loss 8713.23 Test MSE 4065.584713660093 Test RE 0.7104211129796423\n",
      "142 Train Loss 8713.228 Test MSE 4065.4580464905644 Test RE 0.7104100459697519\n",
      "143 Train Loss 8713.228 Test MSE 4065.344132103487 Test RE 0.7104000930332155\n",
      "144 Train Loss 8713.228 Test MSE 4065.2664968831637 Test RE 0.7103933098029085\n",
      "145 Train Loss 8713.226 Test MSE 4065.1761065285423 Test RE 0.7103854120352977\n",
      "146 Train Loss 8713.225 Test MSE 4065.1321494740077 Test RE 0.7103815712995101\n",
      "147 Train Loss 8713.224 Test MSE 4065.115337875212 Test RE 0.7103801023851084\n",
      "148 Train Loss 8713.224 Test MSE 4065.111887870508 Test RE 0.7103798009403758\n",
      "149 Train Loss 8713.224 Test MSE 4065.101971127578 Test RE 0.7103789344626058\n",
      "150 Train Loss 8713.224 Test MSE 4065.098903704863 Test RE 0.7103786664456032\n",
      "151 Train Loss 8713.223 Test MSE 4065.1031882454904 Test RE 0.7103790408086296\n",
      "152 Train Loss 8713.223 Test MSE 4065.095372740644 Test RE 0.7103783579263941\n",
      "153 Train Loss 8713.223 Test MSE 4065.106297967022 Test RE 0.7103793125213602\n",
      "154 Train Loss 8713.223 Test MSE 4065.1174926121703 Test RE 0.7103802906555426\n",
      "155 Train Loss 8713.223 Test MSE 4065.135893173725 Test RE 0.7103818984050724\n",
      "156 Train Loss 8713.223 Test MSE 4065.1603873437016 Test RE 0.7103840385781458\n",
      "157 Train Loss 8713.223 Test MSE 4065.176158956282 Test RE 0.710385416616145\n",
      "158 Train Loss 8713.223 Test MSE 4065.1911972797766 Test RE 0.7103867305808297\n",
      "159 Train Loss 8713.221 Test MSE 4065.1211941311217 Test RE 0.7103806140761467\n",
      "160 Train Loss 8713.221 Test MSE 4065.22224799588 Test RE 0.7103894436112266\n",
      "161 Train Loss 8713.221 Test MSE 4065.230190788881 Test RE 0.7103901376044699\n",
      "162 Train Loss 8713.221 Test MSE 4065.2473008211196 Test RE 0.7103916325733641\n",
      "163 Train Loss 8713.221 Test MSE 4065.258881221383 Test RE 0.7103926443953988\n",
      "164 Train Loss 8713.221 Test MSE 4065.2747399531895 Test RE 0.7103940300286102\n",
      "165 Train Loss 8713.217 Test MSE 4065.405354451613 Test RE 0.7104054421742289\n",
      "166 Train Loss 8713.217 Test MSE 4065.447430720393 Test RE 0.710409118453761\n",
      "167 Train Loss 8713.217 Test MSE 4065.4864636599054 Test RE 0.7104125288151124\n",
      "168 Train Loss 8713.217 Test MSE 4065.532523217548 Test RE 0.7104165530806508\n",
      "169 Train Loss 8713.213 Test MSE 4065.804434141434 Test RE 0.7104403097214351\n",
      "170 Train Loss 8713.199 Test MSE 4065.51153097298 Test RE 0.710414718971934\n",
      "171 Train Loss 8713.195 Test MSE 4064.974391192388 Test RE 0.7103677870411927\n",
      "172 Train Loss 8713.195 Test MSE 4064.949350313875 Test RE 0.7103655990494445\n",
      "173 Train Loss 8713.195 Test MSE 4064.971846651299 Test RE 0.7103675647076516\n",
      "174 Train Loss 8713.195 Test MSE 4065.0030770596472 Test RE 0.7103702935120993\n",
      "175 Train Loss 8713.195 Test MSE 4065.077432467225 Test RE 0.7103767903867838\n",
      "176 Train Loss 8713.193 Test MSE 4065.234083419347 Test RE 0.7103904777187439\n",
      "177 Train Loss 8713.193 Test MSE 4065.374706281453 Test RE 0.7104027643763207\n",
      "178 Train Loss 8713.193 Test MSE 4065.4328292496034 Test RE 0.7104078426990643\n",
      "179 Train Loss 8713.193 Test MSE 4065.4769623140037 Test RE 0.7104116986710235\n",
      "180 Train Loss 8713.193 Test MSE 4065.514304743664 Test RE 0.710414961318705\n",
      "181 Train Loss 8713.193 Test MSE 4065.540245829098 Test RE 0.7104172278100301\n",
      "182 Train Loss 8713.193 Test MSE 4065.5572220498057 Test RE 0.7104187110307506\n",
      "183 Train Loss 8713.193 Test MSE 4065.5572220498057 Test RE 0.7104187110307506\n",
      "184 Train Loss 8713.193 Test MSE 4065.5660960542036 Test RE 0.71041948635563\n",
      "185 Train Loss 8713.192 Test MSE 4065.551237499424 Test RE 0.7104181881580052\n",
      "186 Train Loss 8713.192 Test MSE 4065.5340812270188 Test RE 0.7104166892049598\n",
      "187 Train Loss 8713.192 Test MSE 4065.5000712995447 Test RE 0.7104137177293648\n",
      "188 Train Loss 8713.192 Test MSE 4065.4468120268634 Test RE 0.7104090643975283\n",
      "189 Train Loss 8713.192 Test MSE 4065.372894657898 Test RE 0.7104026060904776\n",
      "190 Train Loss 8713.191 Test MSE 4065.281455089429 Test RE 0.7103946167528823\n",
      "191 Train Loss 8713.188 Test MSE 4064.8120783458176 Test RE 0.710353604544879\n",
      "192 Train Loss 8713.188 Test MSE 4064.727752479491 Test RE 0.7103462362468348\n",
      "193 Train Loss 8713.188 Test MSE 4064.6576888860277 Test RE 0.7103401141117971\n",
      "194 Train Loss 8713.1875 Test MSE 4064.603402472157 Test RE 0.7103353705455325\n",
      "195 Train Loss 8713.1875 Test MSE 4064.5680253434116 Test RE 0.7103322792623189\n",
      "196 Train Loss 8713.1875 Test MSE 4064.5525971373186 Test RE 0.7103309311285038\n",
      "197 Train Loss 8713.187 Test MSE 4064.602621816157 Test RE 0.7103353023313009\n",
      "198 Train Loss 8713.186 Test MSE 4064.6442176513942 Test RE 0.7103389369934506\n",
      "199 Train Loss 8713.187 Test MSE 4064.6929927411707 Test RE 0.7103431989582906\n",
      "Training time: 11.45\n",
      "Training time: 11.45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 15539.162 Test MSE 11844.540139942574 Test RE 1.2125885258013502\n",
      "1 Train Loss 11936.85 Test MSE 9300.286458548177 Test RE 1.0744903392285976\n",
      "2 Train Loss 10456.319 Test MSE 6854.767711171278 Test RE 0.9224667551198653\n",
      "3 Train Loss 8644.054 Test MSE 5641.311660120749 Test RE 0.8368437926531056\n",
      "4 Train Loss 7511.327 Test MSE 4655.345827978338 Test RE 0.7602043084826077\n",
      "5 Train Loss 6742.9487 Test MSE 4204.038626354001 Test RE 0.7224165739534719\n",
      "6 Train Loss 5876.809 Test MSE 3434.132388270186 Test RE 0.6529243556040668\n",
      "7 Train Loss 5344.557 Test MSE 3290.571120181041 Test RE 0.639131162532026\n",
      "8 Train Loss 4717.6807 Test MSE 3225.907325115799 Test RE 0.6328201446879597\n",
      "9 Train Loss 4412.335 Test MSE 3008.427184654649 Test RE 0.6111166334183384\n",
      "10 Train Loss 4194.4595 Test MSE 2756.4219409518228 Test RE 0.584961389671754\n",
      "11 Train Loss 4042.0645 Test MSE 2639.2630803098323 Test RE 0.5723948183995704\n",
      "12 Train Loss 3859.0156 Test MSE 2430.465762330178 Test RE 0.5492867286720499\n",
      "13 Train Loss 3759.6387 Test MSE 2334.024926545231 Test RE 0.5382785790308353\n",
      "14 Train Loss 3717.4736 Test MSE 2293.7330612343044 Test RE 0.5336122482231048\n",
      "15 Train Loss 3676.1792 Test MSE 2222.4897425813456 Test RE 0.5252598858749478\n",
      "16 Train Loss 3652.7114 Test MSE 2251.7812073804375 Test RE 0.5287099060231308\n",
      "17 Train Loss 3618.801 Test MSE 2291.1724035209836 Test RE 0.5333143103533046\n",
      "18 Train Loss 3598.2004 Test MSE 2276.8499892776845 Test RE 0.5316447888902064\n",
      "19 Train Loss 3582.3044 Test MSE 2256.9908413806397 Test RE 0.5293211540929076\n",
      "20 Train Loss 3564.7124 Test MSE 2249.7403456673796 Test RE 0.528470258316611\n",
      "21 Train Loss 3554.0068 Test MSE 2250.642325249237 Test RE 0.528576186455344\n",
      "22 Train Loss 3541.9917 Test MSE 2285.864744285784 Test RE 0.5326962224540045\n",
      "23 Train Loss 3527.8103 Test MSE 2350.6558302788794 Test RE 0.5401929049873951\n",
      "24 Train Loss 3507.3093 Test MSE 2371.7510975691475 Test RE 0.5426113920396549\n",
      "25 Train Loss 3453.2222 Test MSE 2408.384117229929 Test RE 0.5467858027029533\n",
      "26 Train Loss 3379.7886 Test MSE 2451.366929359568 Test RE 0.5516435108199957\n",
      "27 Train Loss 3272.547 Test MSE 2490.787392569912 Test RE 0.5560613141723556\n",
      "28 Train Loss 3186.8345 Test MSE 2333.824607901214 Test RE 0.5382554795455842\n",
      "29 Train Loss 3042.8262 Test MSE 2248.3533768736706 Test RE 0.5283073317898845\n",
      "30 Train Loss 2934.9424 Test MSE 2320.448643503074 Test RE 0.5367107979626242\n",
      "31 Train Loss 2687.4893 Test MSE 2173.0421567320136 Test RE 0.5193838342867289\n",
      "32 Train Loss 2537.6636 Test MSE 2216.855415270854 Test RE 0.5245936591373959\n",
      "33 Train Loss 2399.2346 Test MSE 2149.224266399107 Test RE 0.5165296071711555\n",
      "34 Train Loss 2317.4077 Test MSE 2133.7949405164736 Test RE 0.5146721791205339\n",
      "35 Train Loss 2263.2578 Test MSE 2227.5709694084894 Test RE 0.525859987827184\n",
      "36 Train Loss 2229.2437 Test MSE 2268.514758825676 Test RE 0.5306707578905028\n",
      "37 Train Loss 2157.3123 Test MSE 2274.17782884547 Test RE 0.5313327223851999\n",
      "38 Train Loss 2064.528 Test MSE 2130.1190781122027 Test RE 0.5142286783058223\n",
      "39 Train Loss 1945.5763 Test MSE 1922.4975063011066 Test RE 0.48852550789660254\n",
      "40 Train Loss 1813.6523 Test MSE 1901.9286135900184 Test RE 0.4859051012044972\n",
      "41 Train Loss 1750.6753 Test MSE 1921.9937030460726 Test RE 0.48846149302356745\n",
      "42 Train Loss 1719.9078 Test MSE 1931.8889672304726 Test RE 0.4897172854560116\n",
      "43 Train Loss 1683.5782 Test MSE 1924.8948560986846 Test RE 0.4888300080690692\n",
      "44 Train Loss 1634.1986 Test MSE 1880.905508760818 Test RE 0.4832121453247501\n",
      "45 Train Loss 1602.1569 Test MSE 1865.9844027818083 Test RE 0.48129168312301185\n",
      "46 Train Loss 1582.8933 Test MSE 1858.625419588519 Test RE 0.4803416976036401\n",
      "47 Train Loss 1545.9935 Test MSE 1856.1048357513137 Test RE 0.48001587824451347\n",
      "48 Train Loss 1483.5319 Test MSE 1763.8029210296468 Test RE 0.4679283746297333\n",
      "49 Train Loss 1443.786 Test MSE 1730.3008767346985 Test RE 0.46346310433713445\n",
      "50 Train Loss 1425.4814 Test MSE 1728.4562799322136 Test RE 0.46321599976221506\n",
      "51 Train Loss 1407.4064 Test MSE 1732.0685767484904 Test RE 0.4636997841570668\n",
      "52 Train Loss 1377.6992 Test MSE 1727.51801147279 Test RE 0.4630902575130403\n",
      "53 Train Loss 1318.7075 Test MSE 1620.8262846942262 Test RE 0.4485621119094579\n",
      "54 Train Loss 1234.0264 Test MSE 1533.2384974347021 Test RE 0.43627387768365017\n",
      "55 Train Loss 1182.928 Test MSE 1521.8442488653827 Test RE 0.43464977190950577\n",
      "56 Train Loss 1137.3754 Test MSE 1425.7388962923155 Test RE 0.4207017817456328\n",
      "57 Train Loss 1030.9271 Test MSE 1256.6485635835104 Test RE 0.3949674189318725\n",
      "58 Train Loss 972.99146 Test MSE 1172.524279299267 Test RE 0.3815182123824263\n",
      "59 Train Loss 937.3023 Test MSE 1156.0422251482469 Test RE 0.3788272409452824\n",
      "60 Train Loss 915.0879 Test MSE 1149.1118829111153 Test RE 0.3776900207999324\n",
      "61 Train Loss 872.2237 Test MSE 1046.2497397739871 Test RE 0.36038942081937275\n",
      "62 Train Loss 837.75024 Test MSE 988.746982300546 Test RE 0.35034581806172654\n",
      "63 Train Loss 810.9072 Test MSE 964.4920478114087 Test RE 0.34602197288193653\n",
      "64 Train Loss 796.5446 Test MSE 961.2629278639417 Test RE 0.3454422463588297\n",
      "65 Train Loss 773.67725 Test MSE 946.3844139663149 Test RE 0.3427584277118289\n",
      "66 Train Loss 749.6974 Test MSE 893.2367125745646 Test RE 0.33299494026855764\n",
      "67 Train Loss 729.9327 Test MSE 839.4437461055387 Test RE 0.3228123573761983\n",
      "68 Train Loss 682.8924 Test MSE 718.8691497750139 Test RE 0.29873030032948356\n",
      "69 Train Loss 622.6843 Test MSE 652.833768285134 Test RE 0.2846791481474577\n",
      "70 Train Loss 576.0654 Test MSE 590.6032614739818 Test RE 0.27077107726876226\n",
      "71 Train Loss 545.14734 Test MSE 517.0226589358327 Test RE 0.2533431351901836\n",
      "72 Train Loss 489.16162 Test MSE 453.34857402986177 Test RE 0.23723047551174667\n",
      "73 Train Loss 448.07935 Test MSE 422.8859203352429 Test RE 0.2291215640678716\n",
      "74 Train Loss 395.38782 Test MSE 348.5516041677202 Test RE 0.20801176319579423\n",
      "75 Train Loss 362.17902 Test MSE 335.3782273239092 Test RE 0.2040430397240216\n",
      "76 Train Loss 327.09918 Test MSE 295.58760780702085 Test RE 0.19155675161140218\n",
      "77 Train Loss 302.33755 Test MSE 275.7430659646821 Test RE 0.18501487747476517\n",
      "78 Train Loss 278.69177 Test MSE 274.9696492568256 Test RE 0.1847552261998288\n",
      "79 Train Loss 262.90643 Test MSE 253.38458655231875 Test RE 0.17735541338802263\n",
      "80 Train Loss 238.08296 Test MSE 220.79147053453332 Test RE 0.16555621861977715\n",
      "81 Train Loss 207.13849 Test MSE 131.4976307853874 Test RE 0.12776541690451232\n",
      "82 Train Loss 168.00882 Test MSE 116.03446759154606 Test RE 0.12001840733249655\n",
      "83 Train Loss 148.42912 Test MSE 110.8836081887219 Test RE 0.11732431496870716\n",
      "84 Train Loss 131.35234 Test MSE 91.20178933886983 Test RE 0.10640352895004802\n",
      "85 Train Loss 115.584755 Test MSE 82.99228824208195 Test RE 0.10150167797641005\n",
      "86 Train Loss 103.1498 Test MSE 70.24297239837287 Test RE 0.09338041351656995\n",
      "87 Train Loss 95.269554 Test MSE 57.78434190535573 Test RE 0.08469532485426072\n",
      "88 Train Loss 88.51901 Test MSE 43.26653769915913 Test RE 0.07328758720443643\n",
      "89 Train Loss 82.82532 Test MSE 36.45625345309776 Test RE 0.06727293410203936\n",
      "90 Train Loss 78.39609 Test MSE 30.272224515786768 Test RE 0.061302264865484166\n",
      "91 Train Loss 73.321236 Test MSE 27.813344882520493 Test RE 0.05875988847900907\n",
      "92 Train Loss 68.99809 Test MSE 25.86217309289201 Test RE 0.05666134239103907\n",
      "93 Train Loss 66.302574 Test MSE 25.43135888294469 Test RE 0.056187425812563266\n",
      "94 Train Loss 61.50614 Test MSE 24.726514029896553 Test RE 0.05540332112004766\n",
      "95 Train Loss 56.085304 Test MSE 18.409970765280246 Test RE 0.04780583429343539\n",
      "96 Train Loss 52.961487 Test MSE 12.17626667156702 Test RE 0.0388786725163057\n",
      "97 Train Loss 50.804974 Test MSE 9.967759683885694 Test RE 0.03517654098938967\n",
      "98 Train Loss 49.05394 Test MSE 8.873529033046209 Test RE 0.033189639839615974\n",
      "99 Train Loss 46.326443 Test MSE 7.987745978689658 Test RE 0.03148955149094692\n",
      "100 Train Loss 40.39333 Test MSE 6.027260054474897 Test RE 0.027353589015087644\n",
      "101 Train Loss 32.636597 Test MSE 2.6591494176017645 Test RE 0.01816877818628498\n",
      "102 Train Loss 30.2262 Test MSE 1.7831831525146131 Test RE 0.014878266327087723\n",
      "103 Train Loss 28.862371 Test MSE 1.4468843066734474 Test RE 0.013402050666081708\n",
      "104 Train Loss 27.225115 Test MSE 1.3026949590215209 Test RE 0.012716737851468467\n",
      "105 Train Loss 25.968882 Test MSE 1.0503403234605984 Test RE 0.011418771218791245\n",
      "106 Train Loss 25.217989 Test MSE 0.857132163465799 Test RE 0.010315214144835699\n",
      "107 Train Loss 24.313395 Test MSE 0.7553695926617223 Test RE 0.009683538900400848\n",
      "108 Train Loss 23.10257 Test MSE 1.0435002116322942 Test RE 0.011381529361266567\n",
      "109 Train Loss 22.326757 Test MSE 0.9758815300580496 Test RE 0.011006592849655626\n",
      "110 Train Loss 21.359404 Test MSE 0.9025955622942281 Test RE 0.010585245850992915\n",
      "111 Train Loss 20.586836 Test MSE 0.7792003746811506 Test RE 0.009835103366632621\n",
      "112 Train Loss 19.71381 Test MSE 0.7325188859334019 Test RE 0.00953594561303805\n",
      "113 Train Loss 19.167654 Test MSE 0.8644965535698066 Test RE 0.010359432988810586\n",
      "114 Train Loss 17.93528 Test MSE 1.1491139030181254 Test RE 0.011943617650702999\n",
      "115 Train Loss 16.818325 Test MSE 1.5714970792598624 Test RE 0.01396725755084598\n",
      "116 Train Loss 16.251966 Test MSE 1.221365970483668 Test RE 0.01231337937093722\n",
      "117 Train Loss 15.641406 Test MSE 1.0184885241301247 Test RE 0.011244299952549313\n",
      "118 Train Loss 14.792575 Test MSE 1.1050864872840396 Test RE 0.011712577743992094\n",
      "119 Train Loss 14.002835 Test MSE 0.7764077765449934 Test RE 0.009817463395575597\n",
      "120 Train Loss 13.685366 Test MSE 0.6949982713223825 Test RE 0.00928851345489439\n",
      "121 Train Loss 13.231364 Test MSE 0.5609634955561219 Test RE 0.0083449099137782\n",
      "122 Train Loss 12.37991 Test MSE 0.2576470586035434 Test RE 0.005655447129892312\n",
      "123 Train Loss 11.697871 Test MSE 0.20133640671148245 Test RE 0.004999372639246801\n",
      "124 Train Loss 11.446501 Test MSE 0.1335451046841464 Test RE 0.004071630311010588\n",
      "125 Train Loss 10.770749 Test MSE 0.09644264413159968 Test RE 0.003460102041612474\n",
      "126 Train Loss 9.213372 Test MSE 0.1271528768370334 Test RE 0.003972989777550049\n",
      "127 Train Loss 8.817788 Test MSE 0.0983324629932856 Test RE 0.0034938383780100998\n",
      "128 Train Loss 8.640625 Test MSE 0.16515311462815827 Test RE 0.004527909485721672\n",
      "129 Train Loss 8.474198 Test MSE 0.19357619374539187 Test RE 0.004902079220458702\n",
      "130 Train Loss 8.275253 Test MSE 0.17841937473154848 Test RE 0.00470625395894889\n",
      "131 Train Loss 8.030554 Test MSE 0.20101905639543033 Test RE 0.004995431031777764\n",
      "132 Train Loss 7.6149545 Test MSE 0.11721677800552366 Test RE 0.003814602087672313\n",
      "133 Train Loss 6.652358 Test MSE 0.1337243759471839 Test RE 0.0040743622775277644\n",
      "134 Train Loss 6.263261 Test MSE 0.0857097501488846 Test RE 0.0032618911684187623\n",
      "135 Train Loss 6.1287036 Test MSE 0.08929734285783786 Test RE 0.0033294586106104715\n",
      "136 Train Loss 6.000215 Test MSE 0.07479637355576225 Test RE 0.003047155541851061\n",
      "137 Train Loss 5.917094 Test MSE 0.09713152457321511 Test RE 0.0034724376392532242\n",
      "138 Train Loss 5.815067 Test MSE 0.13490165004924776 Test RE 0.00409225778193362\n",
      "139 Train Loss 5.7228885 Test MSE 0.2064078492609909 Test RE 0.005061945402961072\n",
      "140 Train Loss 5.5882177 Test MSE 0.18421600548604952 Test RE 0.004782093164817741\n",
      "141 Train Loss 5.5201645 Test MSE 0.12584703332893563 Test RE 0.003952536083679004\n",
      "142 Train Loss 5.4459515 Test MSE 0.17002103675271826 Test RE 0.0045941554107891336\n",
      "143 Train Loss 5.3031797 Test MSE 0.23657902290076518 Test RE 0.005419290965813905\n",
      "144 Train Loss 5.0482774 Test MSE 0.2729705719554858 Test RE 0.00582119660267483\n",
      "145 Train Loss 4.8179917 Test MSE 0.36774381419204794 Test RE 0.0067565818224169134\n",
      "146 Train Loss 4.721522 Test MSE 0.379067002171077 Test RE 0.006859814039108779\n",
      "147 Train Loss 4.537567 Test MSE 0.2565868657728543 Test RE 0.0056437993250259945\n",
      "148 Train Loss 4.3980613 Test MSE 0.2791638333669638 Test RE 0.00588686300022197\n",
      "149 Train Loss 4.310326 Test MSE 0.3041154149496531 Test RE 0.006144316370856685\n",
      "150 Train Loss 4.2746367 Test MSE 0.3039375329572531 Test RE 0.006142519153330135\n",
      "151 Train Loss 4.1111484 Test MSE 0.21732649266249282 Test RE 0.0051941045597826115\n",
      "152 Train Loss 3.8592505 Test MSE 0.05945171237079637 Test RE 0.00271666780718785\n",
      "153 Train Loss 3.793887 Test MSE 0.04418842646539081 Test RE 0.0023421171852761233\n",
      "154 Train Loss 3.7509854 Test MSE 0.037015979395417904 Test RE 0.002143625796491025\n",
      "155 Train Loss 3.7224543 Test MSE 0.0376879939059549 Test RE 0.0021629967298790846\n",
      "156 Train Loss 3.666183 Test MSE 0.04818257428258136 Test RE 0.0024456784238747523\n",
      "157 Train Loss 3.630423 Test MSE 0.02891520246077939 Test RE 0.0018945997301569228\n",
      "158 Train Loss 3.5732636 Test MSE 0.04146312082767587 Test RE 0.0022687432276563444\n",
      "159 Train Loss 3.510672 Test MSE 0.05331462195471608 Test RE 0.002572631123351804\n",
      "160 Train Loss 3.4842489 Test MSE 0.04848485848609504 Test RE 0.0024533381853452953\n",
      "161 Train Loss 3.4490576 Test MSE 0.058195921610892355 Test RE 0.0026878227619390018\n",
      "162 Train Loss 3.4138904 Test MSE 0.06740299805748277 Test RE 0.0028926371495068357\n",
      "163 Train Loss 3.3830407 Test MSE 0.036589696760148255 Test RE 0.002131246864869713\n",
      "164 Train Loss 3.3491268 Test MSE 0.04273022586458554 Test RE 0.0023031485302901326\n",
      "165 Train Loss 3.3135953 Test MSE 0.06628703074651363 Test RE 0.0028685910244036785\n",
      "166 Train Loss 3.2854724 Test MSE 0.04403596326784049 Test RE 0.0023380731940097865\n",
      "167 Train Loss 3.2574208 Test MSE 0.032327461027783895 Test RE 0.0020032730603850263\n",
      "168 Train Loss 3.2157626 Test MSE 0.011542230542043402 Test RE 0.0011970139856331099\n",
      "169 Train Loss 3.1988587 Test MSE 0.007219920873424234 Test RE 0.0009467178623756592\n",
      "170 Train Loss 3.1723263 Test MSE 0.014781059748004444 Test RE 0.001354587733739374\n",
      "171 Train Loss 3.1435483 Test MSE 0.029486963347463757 Test RE 0.001913239670753036\n",
      "172 Train Loss 3.1152728 Test MSE 0.05054652377439303 Test RE 0.0025049554070302547\n",
      "173 Train Loss 3.0669606 Test MSE 0.07544890107222438 Test RE 0.003060418451092609\n",
      "174 Train Loss 3.0464792 Test MSE 0.0852981934530329 Test RE 0.0032540503535719877\n",
      "175 Train Loss 3.02518 Test MSE 0.10639341114015329 Test RE 0.0036342242251107063\n",
      "176 Train Loss 2.9991562 Test MSE 0.08511968183577925 Test RE 0.003250643540339239\n",
      "177 Train Loss 2.9815 Test MSE 0.0909996094166222 Test RE 0.003361043369692083\n",
      "178 Train Loss 2.959881 Test MSE 0.1312642695532918 Test RE 0.004036710603445517\n",
      "179 Train Loss 2.9275513 Test MSE 0.11015471861427349 Test RE 0.003697906321652753\n",
      "180 Train Loss 2.85736 Test MSE 0.1092325139112589 Test RE 0.003682394529689003\n",
      "181 Train Loss 2.8248272 Test MSE 0.15050813582928846 Test RE 0.004322493418550206\n",
      "182 Train Loss 2.7957869 Test MSE 0.13893903430940596 Test RE 0.004153043598584223\n",
      "183 Train Loss 2.7312477 Test MSE 0.11156373597585668 Test RE 0.003721481607650029\n",
      "184 Train Loss 2.6496356 Test MSE 0.10050358569058418 Test RE 0.0035321987343503885\n",
      "185 Train Loss 2.5839741 Test MSE 0.09301130199805023 Test RE 0.00339799092171082\n",
      "186 Train Loss 2.537325 Test MSE 0.03752496989063105 Test RE 0.002158313506814171\n",
      "187 Train Loss 2.4824228 Test MSE 0.033069499976216235 Test RE 0.002026134009757304\n",
      "188 Train Loss 2.433342 Test MSE 0.03741648453147926 Test RE 0.0021551913871783114\n",
      "189 Train Loss 2.3839467 Test MSE 0.030270991908018487 Test RE 0.00193850836025523\n",
      "190 Train Loss 2.349373 Test MSE 0.02871014464310237 Test RE 0.0018878698148964731\n",
      "191 Train Loss 2.3251274 Test MSE 0.02552826672058043 Test RE 0.0017801845056899378\n",
      "192 Train Loss 2.3052158 Test MSE 0.01621864971981033 Test RE 0.0014189323802738588\n",
      "193 Train Loss 2.262074 Test MSE 0.024175499020458086 Test RE 0.0017323756711793894\n",
      "194 Train Loss 2.2160923 Test MSE 0.03331961222533643 Test RE 0.0020337816360230356\n",
      "195 Train Loss 2.186692 Test MSE 0.028318858658634417 Test RE 0.001874960942390216\n",
      "196 Train Loss 2.151037 Test MSE 0.028881353606952518 Test RE 0.0018934904726917903\n",
      "197 Train Loss 2.1247532 Test MSE 0.03139710427940503 Test RE 0.001974236377740077\n",
      "198 Train Loss 2.1077125 Test MSE 0.04070114006138913 Test RE 0.0022477998580934834\n",
      "199 Train Loss 2.093965 Test MSE 0.048732851768544506 Test RE 0.002459604423991641\n",
      "Training time: 26.66\n",
      "Training time: 26.66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 13535.013 Test MSE 6899.421738015765 Test RE 0.9254664912561114\n",
      "1 Train Loss 10904.333 Test MSE 6609.804713459572 Test RE 0.9058341020146999\n",
      "2 Train Loss 10005.857 Test MSE 5524.501426694962 Test RE 0.8281345375638202\n",
      "3 Train Loss 9700.676 Test MSE 4607.130637353296 Test RE 0.7562573627529641\n",
      "4 Train Loss 9413.517 Test MSE 4563.8738748366895 Test RE 0.7526987058328842\n",
      "5 Train Loss 9088.393 Test MSE 3642.019235275526 Test RE 0.6723965399225982\n",
      "6 Train Loss 8942.535 Test MSE 3322.482962191872 Test RE 0.6422228205926362\n",
      "7 Train Loss 8871.979 Test MSE 3176.6081095208333 Test RE 0.6279660609352352\n",
      "8 Train Loss 8712.45 Test MSE 3210.7185217695505 Test RE 0.6313286075080825\n",
      "9 Train Loss 8099.8257 Test MSE 2765.0714814220228 Test RE 0.5858784633809342\n",
      "10 Train Loss 7828.0073 Test MSE 2653.789681327618 Test RE 0.5739678978594132\n",
      "11 Train Loss 7754.612 Test MSE 2641.8432194073857 Test RE 0.5726745361537418\n",
      "12 Train Loss 7733.7524 Test MSE 2660.8455016877297 Test RE 0.5747304160985374\n",
      "13 Train Loss 7705.8496 Test MSE 2719.384190827716 Test RE 0.581018066201012\n",
      "14 Train Loss 7692.593 Test MSE 2746.6819232892467 Test RE 0.5839269732317526\n",
      "15 Train Loss 7682.6133 Test MSE 2768.202075417851 Test RE 0.5862100332433366\n",
      "16 Train Loss 7668.0107 Test MSE 2747.0276176354764 Test RE 0.5839637182768319\n",
      "17 Train Loss 7652.4556 Test MSE 2727.311525001221 Test RE 0.581864318923236\n",
      "18 Train Loss 7629.2803 Test MSE 2731.823312797079 Test RE 0.5823454087198814\n",
      "19 Train Loss 7593.654 Test MSE 2880.0595750546754 Test RE 0.5979365317465906\n",
      "20 Train Loss 7578.9556 Test MSE 2844.481371804235 Test RE 0.5942318139619657\n",
      "21 Train Loss 7549.503 Test MSE 2752.6409974077565 Test RE 0.5845600605213216\n",
      "22 Train Loss 7513.3594 Test MSE 2767.096625824923 Test RE 0.5860929734454468\n",
      "23 Train Loss 7476.3413 Test MSE 2764.820851142993 Test RE 0.5858519103223032\n",
      "24 Train Loss 7441.4272 Test MSE 2704.1805004013618 Test RE 0.5793915949666202\n",
      "25 Train Loss 7422.647 Test MSE 2646.490057657104 Test RE 0.5731779643585031\n",
      "26 Train Loss 7401.4053 Test MSE 2554.923676694337 Test RE 0.5631749353135116\n",
      "27 Train Loss 7393.875 Test MSE 2581.6178390471878 Test RE 0.5661093515492984\n",
      "28 Train Loss 7386.111 Test MSE 2625.6389368257996 Test RE 0.5709155268366619\n",
      "29 Train Loss 7382.379 Test MSE 2686.460488815317 Test RE 0.5774901500970872\n",
      "30 Train Loss 7380.1187 Test MSE 2762.213831265827 Test RE 0.5855756378499836\n",
      "31 Train Loss 7378.5557 Test MSE 2772.105733515602 Test RE 0.5866232179204645\n",
      "32 Train Loss 7377.312 Test MSE 2753.417327242856 Test RE 0.5846424867118633\n",
      "33 Train Loss 7376.1313 Test MSE 2746.305283857626 Test RE 0.5838869362945585\n",
      "34 Train Loss 7335.979 Test MSE 2838.999387401786 Test RE 0.5936589255950852\n",
      "35 Train Loss 6954.5215 Test MSE 2788.1194087179774 Test RE 0.5883151566502912\n",
      "36 Train Loss 5686.1045 Test MSE 3308.195232347161 Test RE 0.6408404519906572\n",
      "37 Train Loss 4914.0107 Test MSE 3268.9760123352535 Test RE 0.6370304898309855\n",
      "38 Train Loss 4728.288 Test MSE 3222.8853766630414 Test RE 0.6325236702802219\n",
      "39 Train Loss 4422.4966 Test MSE 3027.7888286004154 Test RE 0.6130799925912672\n",
      "40 Train Loss 3895.222 Test MSE 2727.3785240397615 Test RE 0.5818714659084909\n",
      "41 Train Loss 3653.987 Test MSE 2599.1389034332706 Test RE 0.5680271539615347\n",
      "42 Train Loss 3520.8657 Test MSE 2399.5276049113445 Test RE 0.5457795106863153\n",
      "43 Train Loss 3364.5916 Test MSE 2223.323920309236 Test RE 0.5253584507824227\n",
      "44 Train Loss 3216.5933 Test MSE 2064.581689397828 Test RE 0.5062562385177163\n",
      "45 Train Loss 2939.8645 Test MSE 1720.9511411967676 Test RE 0.4622092394434809\n",
      "46 Train Loss 2762.5754 Test MSE 1560.8030524688645 Test RE 0.44017807338320225\n",
      "47 Train Loss 2481.251 Test MSE 1540.086955828391 Test RE 0.43724713610295235\n",
      "48 Train Loss 2211.6875 Test MSE 1224.1835492513046 Test RE 0.38983212196458966\n",
      "49 Train Loss 2019.7421 Test MSE 1036.9678262413229 Test RE 0.35878724329120243\n",
      "50 Train Loss 1882.5863 Test MSE 911.9900935932598 Test RE 0.3364723743307306\n",
      "51 Train Loss 1717.7686 Test MSE 703.7237808447295 Test RE 0.29556667501741096\n",
      "52 Train Loss 1575.3553 Test MSE 511.19153856716946 Test RE 0.25191044822783587\n",
      "53 Train Loss 1427.9623 Test MSE 357.68448750187594 Test RE 0.21071934376878773\n",
      "54 Train Loss 1277.5858 Test MSE 269.7495247130496 Test RE 0.18299309243224404\n",
      "55 Train Loss 1169.3484 Test MSE 221.51170658485032 Test RE 0.165826026310291\n",
      "56 Train Loss 1079.1227 Test MSE 166.411744699728 Test RE 0.14372964049070613\n",
      "57 Train Loss 970.99414 Test MSE 141.2184799185651 Test RE 0.13240369908463592\n",
      "58 Train Loss 923.7703 Test MSE 112.27281334526236 Test RE 0.11805697609754275\n",
      "59 Train Loss 851.4321 Test MSE 63.49405018733339 Test RE 0.08878117076692318\n",
      "60 Train Loss 783.53424 Test MSE 36.95783621205424 Test RE 0.06773413992265956\n",
      "61 Train Loss 697.8951 Test MSE 52.52272852982039 Test RE 0.08074729676199004\n",
      "62 Train Loss 634.4235 Test MSE 74.90148739868043 Test RE 0.09642720382476874\n",
      "63 Train Loss 549.2609 Test MSE 62.29998440938813 Test RE 0.08794240156727805\n",
      "64 Train Loss 514.5349 Test MSE 42.275057521161166 Test RE 0.07244300483464806\n",
      "65 Train Loss 487.4001 Test MSE 43.0149966534235 Test RE 0.07307423862858091\n",
      "66 Train Loss 463.00275 Test MSE 38.423290494513786 Test RE 0.06906398434636933\n",
      "67 Train Loss 448.27414 Test MSE 32.415704965968665 Test RE 0.06343545917199866\n",
      "68 Train Loss 436.50278 Test MSE 28.534331984875607 Test RE 0.059516612867296266\n",
      "69 Train Loss 418.08374 Test MSE 26.852245366824018 Test RE 0.057735729270017785\n",
      "70 Train Loss 409.3075 Test MSE 29.809103873783844 Test RE 0.06083154019987991\n",
      "71 Train Loss 398.23193 Test MSE 23.83957029744978 Test RE 0.05440058424298349\n",
      "72 Train Loss 382.86615 Test MSE 18.3766967460571 Test RE 0.04776261283288531\n",
      "73 Train Loss 357.17856 Test MSE 18.538676635331072 Test RE 0.04797265082829604\n",
      "74 Train Loss 333.04123 Test MSE 20.51918838107876 Test RE 0.05047013212477902\n",
      "75 Train Loss 309.65518 Test MSE 21.955725638122267 Test RE 0.05220694134871513\n",
      "76 Train Loss 288.6858 Test MSE 19.649555296853986 Test RE 0.049389054864266875\n",
      "77 Train Loss 274.47394 Test MSE 20.084150884603496 Test RE 0.04993224468673795\n",
      "78 Train Loss 261.01434 Test MSE 25.21868195247016 Test RE 0.05595199093757906\n",
      "79 Train Loss 234.10667 Test MSE 28.65206894020289 Test RE 0.05963927372666557\n",
      "80 Train Loss 224.43874 Test MSE 27.83929948530076 Test RE 0.05878729859355937\n",
      "81 Train Loss 218.906 Test MSE 23.83688534504766 Test RE 0.054397520700093106\n",
      "82 Train Loss 211.3577 Test MSE 19.62721962738288 Test RE 0.049360976588423665\n",
      "83 Train Loss 198.99368 Test MSE 16.135716947062757 Test RE 0.04475571357222947\n",
      "84 Train Loss 188.68613 Test MSE 13.456465504055084 Test RE 0.04087143193711229\n",
      "85 Train Loss 180.40805 Test MSE 8.225981419582109 Test RE 0.031955691104481\n",
      "86 Train Loss 176.34155 Test MSE 6.85988464979788 Test RE 0.029181845839860884\n",
      "87 Train Loss 171.58861 Test MSE 6.7255989311396105 Test RE 0.028894809465644673\n",
      "88 Train Loss 165.76582 Test MSE 4.310715309686822 Test RE 0.023132843690415475\n",
      "89 Train Loss 161.51389 Test MSE 3.4686074847122903 Test RE 0.020750660777233497\n",
      "90 Train Loss 157.97366 Test MSE 2.468314094427127 Test RE 0.01750469563838742\n",
      "91 Train Loss 154.3098 Test MSE 2.0414631607643976 Test RE 0.01591934247883676\n",
      "92 Train Loss 150.29964 Test MSE 2.1204729373936737 Test RE 0.016224477497145968\n",
      "93 Train Loss 148.11334 Test MSE 1.8011500428758784 Test RE 0.014953033239963252\n",
      "94 Train Loss 146.71439 Test MSE 1.8129684098730963 Test RE 0.015002010695141144\n",
      "95 Train Loss 143.70183 Test MSE 1.6704040774531534 Test RE 0.014400087235999668\n",
      "96 Train Loss 137.69223 Test MSE 1.9005936758391644 Test RE 0.015360275041898684\n",
      "97 Train Loss 135.13252 Test MSE 1.5669817325222122 Test RE 0.013947177214999254\n",
      "98 Train Loss 132.53563 Test MSE 3.891481166492704 Test RE 0.02197919685814634\n",
      "99 Train Loss 129.56906 Test MSE 3.9177981443746845 Test RE 0.02205339115243933\n",
      "100 Train Loss 127.018166 Test MSE 2.904625136564049 Test RE 0.01898888210195819\n",
      "101 Train Loss 124.58918 Test MSE 3.215996227428232 Test RE 0.01998076526207035\n",
      "102 Train Loss 121.81723 Test MSE 1.5127410463971864 Test RE 0.013703662304924176\n",
      "103 Train Loss 118.61698 Test MSE 1.7740353047611552 Test RE 0.014840054009982668\n",
      "104 Train Loss 114.46972 Test MSE 2.2797525367925884 Test RE 0.016822797070744338\n",
      "105 Train Loss 109.63632 Test MSE 2.3315816029158203 Test RE 0.017012951436147117\n",
      "106 Train Loss 104.75238 Test MSE 2.3757898452357074 Test RE 0.01717348215712948\n",
      "107 Train Loss 101.29735 Test MSE 3.34224463384924 Test RE 0.020369176420710625\n",
      "108 Train Loss 95.66966 Test MSE 3.2118444225625877 Test RE 0.01996786365651956\n",
      "109 Train Loss 90.561195 Test MSE 1.2035621336377285 Test RE 0.012223303918286764\n",
      "110 Train Loss 87.4352 Test MSE 1.363807148514206 Test RE 0.013011603888312082\n",
      "111 Train Loss 85.129524 Test MSE 1.9887405378208591 Test RE 0.01571243215753374\n",
      "112 Train Loss 83.97785 Test MSE 1.9716598692854368 Test RE 0.015644812077417254\n",
      "113 Train Loss 82.44447 Test MSE 3.245348639180025 Test RE 0.02007174041724816\n",
      "114 Train Loss 79.926926 Test MSE 3.5539717158955484 Test RE 0.021004451058333175\n",
      "115 Train Loss 77.51693 Test MSE 3.7376290394699887 Test RE 0.021540334839813696\n",
      "116 Train Loss 75.48005 Test MSE 3.8516032594854943 Test RE 0.021866291083856758\n",
      "117 Train Loss 73.1489 Test MSE 4.699205174982402 Test RE 0.02415274833029089\n",
      "118 Train Loss 70.64853 Test MSE 7.636633240251863 Test RE 0.030789690197982462\n",
      "119 Train Loss 67.494644 Test MSE 6.46664581825248 Test RE 0.028333086654504885\n",
      "120 Train Loss 65.55214 Test MSE 4.099414034636919 Test RE 0.022558761054461387\n",
      "121 Train Loss 63.455906 Test MSE 4.0655886393287455 Test RE 0.022465498995044225\n",
      "122 Train Loss 62.473038 Test MSE 3.669324323499804 Test RE 0.02134260379741698\n",
      "123 Train Loss 61.980106 Test MSE 4.412315764741446 Test RE 0.02340386825964893\n",
      "124 Train Loss 61.527283 Test MSE 5.513340971238061 Test RE 0.02616144803048871\n",
      "125 Train Loss 61.175816 Test MSE 5.640691746571185 Test RE 0.026461870262172036\n",
      "126 Train Loss 60.458885 Test MSE 4.910778577541802 Test RE 0.024690479753786198\n",
      "127 Train Loss 59.112278 Test MSE 6.234692793883069 Test RE 0.027820304675582448\n",
      "128 Train Loss 57.98144 Test MSE 8.082053525449721 Test RE 0.03167489716012905\n",
      "129 Train Loss 57.474674 Test MSE 7.149808568054863 Test RE 0.029792130340144937\n",
      "130 Train Loss 56.76508 Test MSE 6.674149819515522 Test RE 0.028784078341896037\n",
      "131 Train Loss 56.142952 Test MSE 7.2525718296100035 Test RE 0.030005465707163215\n",
      "132 Train Loss 55.633392 Test MSE 7.527963610605366 Test RE 0.030569835933147316\n",
      "133 Train Loss 55.054085 Test MSE 7.7462315973649964 Test RE 0.031009844685479803\n",
      "134 Train Loss 54.369934 Test MSE 8.265389526894134 Test RE 0.03203214451459328\n",
      "135 Train Loss 53.544266 Test MSE 9.105420176225282 Test RE 0.03362051394514384\n",
      "136 Train Loss 52.971527 Test MSE 8.351674637598302 Test RE 0.03219890744976242\n",
      "137 Train Loss 52.59267 Test MSE 7.8622339879231555 Test RE 0.031241173209422282\n",
      "138 Train Loss 52.328644 Test MSE 8.064745709505674 Test RE 0.031640962893932124\n",
      "139 Train Loss 52.134304 Test MSE 8.416318660996524 Test RE 0.032323280989364774\n",
      "140 Train Loss 51.858692 Test MSE 9.195509265203807 Test RE 0.03378642536954202\n",
      "141 Train Loss 51.65475 Test MSE 9.035576410959967 Test RE 0.03349132146592764\n",
      "142 Train Loss 51.324635 Test MSE 9.19987617109014 Test RE 0.03379444692783497\n",
      "143 Train Loss 51.130413 Test MSE 9.664755884456682 Test RE 0.03463775984816249\n",
      "144 Train Loss 50.530315 Test MSE 10.634208571283386 Test RE 0.03633347523205047\n",
      "145 Train Loss 49.876858 Test MSE 10.784232536043229 Test RE 0.036588868077806036\n",
      "146 Train Loss 49.400105 Test MSE 10.523972314464572 Test RE 0.03614466474035085\n",
      "147 Train Loss 48.98949 Test MSE 10.821213203258516 Test RE 0.0366515486050328\n",
      "148 Train Loss 48.580452 Test MSE 11.58357933497753 Test RE 0.037920647213211194\n",
      "149 Train Loss 48.188126 Test MSE 13.228565221707488 Test RE 0.04052385230130154\n",
      "150 Train Loss 47.85939 Test MSE 13.331116705821085 Test RE 0.0406806250882343\n",
      "151 Train Loss 47.56551 Test MSE 12.71623523490965 Test RE 0.03973137809636201\n",
      "152 Train Loss 47.289303 Test MSE 11.779443217025177 Test RE 0.0382398987628471\n",
      "153 Train Loss 47.11231 Test MSE 10.883435709268332 Test RE 0.03675677166236481\n",
      "154 Train Loss 46.93106 Test MSE 10.259759305881417 Test RE 0.03568805984669914\n",
      "155 Train Loss 46.614197 Test MSE 9.084427134422185 Test RE 0.03358173461788975\n",
      "156 Train Loss 46.47065 Test MSE 9.126272176285482 Test RE 0.03365898850419153\n",
      "157 Train Loss 46.312824 Test MSE 8.77185230496302 Test RE 0.0329989413755358\n",
      "158 Train Loss 45.833652 Test MSE 8.089012538443288 Test RE 0.031688530984220975\n",
      "159 Train Loss 45.62718 Test MSE 7.724748466446444 Test RE 0.03096681401421377\n",
      "160 Train Loss 45.530956 Test MSE 7.647535966169495 Test RE 0.030811661386892144\n",
      "161 Train Loss 45.42375 Test MSE 7.715075100935105 Test RE 0.030947418745220074\n",
      "162 Train Loss 45.32554 Test MSE 7.760178115639881 Test RE 0.031037747600169314\n",
      "163 Train Loss 45.17862 Test MSE 8.071506270216632 Test RE 0.03165422219853536\n",
      "164 Train Loss 45.08603 Test MSE 7.837943000369566 Test RE 0.031192874849695428\n",
      "165 Train Loss 44.964798 Test MSE 7.532220219351733 Test RE 0.030578477409690295\n",
      "166 Train Loss 44.87276 Test MSE 7.728058643786654 Test RE 0.03097344818926307\n",
      "167 Train Loss 44.818005 Test MSE 7.72964667456611 Test RE 0.030976630376715414\n",
      "168 Train Loss 44.712486 Test MSE 7.449186106552696 Test RE 0.030409463954478255\n",
      "169 Train Loss 44.63022 Test MSE 7.476695334630333 Test RE 0.03046556202824047\n",
      "170 Train Loss 44.590908 Test MSE 7.6436389027420955 Test RE 0.03080380981873747\n",
      "171 Train Loss 44.560696 Test MSE 7.572226043245486 Test RE 0.030659575485505502\n",
      "172 Train Loss 44.520546 Test MSE 7.576604538325153 Test RE 0.030668438361456128\n",
      "173 Train Loss 44.464096 Test MSE 7.41088098776439 Test RE 0.030331177586733458\n",
      "174 Train Loss 44.398556 Test MSE 7.241208837105484 Test RE 0.029981950908444254\n",
      "175 Train Loss 44.250797 Test MSE 7.229366146606501 Test RE 0.029957423770349132\n",
      "176 Train Loss 44.079678 Test MSE 7.335245025610336 Test RE 0.030175999587450774\n",
      "177 Train Loss 44.023216 Test MSE 7.336249457732438 Test RE 0.03017806555155092\n",
      "178 Train Loss 43.966667 Test MSE 7.2985433246619795 Test RE 0.03010041251876954\n",
      "179 Train Loss 43.897175 Test MSE 7.027466901452018 Test RE 0.02953614128308592\n",
      "180 Train Loss 43.833626 Test MSE 6.955470340376389 Test RE 0.0293844525436405\n",
      "181 Train Loss 43.77556 Test MSE 6.938422991791921 Test RE 0.029348420881400977\n",
      "182 Train Loss 43.729237 Test MSE 6.990032726735847 Test RE 0.02945736912785781\n",
      "183 Train Loss 43.704388 Test MSE 7.051772966859937 Test RE 0.029587175866556195\n",
      "184 Train Loss 43.681423 Test MSE 6.988418420276824 Test RE 0.02945396742939956\n",
      "185 Train Loss 43.6484 Test MSE 6.863895839561725 Test RE 0.029190376363406382\n",
      "186 Train Loss 43.55547 Test MSE 7.102582110578663 Test RE 0.029693574705004666\n",
      "187 Train Loss 43.493835 Test MSE 6.845545949617085 Test RE 0.02915133157894767\n",
      "188 Train Loss 43.353695 Test MSE 6.374542325415782 Test RE 0.028130591030211965\n",
      "189 Train Loss 43.25257 Test MSE 6.80805783926162 Test RE 0.029071401606093217\n",
      "190 Train Loss 43.166084 Test MSE 6.935870335093865 Test RE 0.029343021719735147\n",
      "191 Train Loss 43.084682 Test MSE 6.92537196011638 Test RE 0.029320805999952525\n",
      "192 Train Loss 42.98221 Test MSE 6.976021551834201 Test RE 0.02942783139891734\n",
      "193 Train Loss 42.872257 Test MSE 7.0581392266933705 Test RE 0.029600528335299497\n",
      "194 Train Loss 42.809006 Test MSE 7.1883351095932495 Test RE 0.029872289527804075\n",
      "195 Train Loss 42.700428 Test MSE 8.079714358625273 Test RE 0.03167031303863864\n",
      "196 Train Loss 42.57221 Test MSE 8.59557823025398 Test RE 0.03266569486881888\n",
      "197 Train Loss 42.453968 Test MSE 8.26821726376282 Test RE 0.03203762342940607\n",
      "198 Train Loss 42.323055 Test MSE 8.305653085399522 Test RE 0.032110069532955796\n",
      "199 Train Loss 42.214638 Test MSE 8.233367860013203 Test RE 0.03197003503703603\n",
      "Training time: 27.54\n",
      "Training time: 27.54\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 14207.169 Test MSE 9902.686606650823 Test RE 1.1087429461549003\n",
      "1 Train Loss 10751.785 Test MSE 8423.525435404352 Test RE 1.0225894272079787\n",
      "2 Train Loss 8769.103 Test MSE 5688.453422823215 Test RE 0.8403330713525573\n",
      "3 Train Loss 7581.8423 Test MSE 4000.1253977857305 Test RE 0.7046787176492464\n",
      "4 Train Loss 6304.069 Test MSE 3741.3304041698993 Test RE 0.6815023912009881\n",
      "5 Train Loss 5611.8003 Test MSE 4027.7018943535672 Test RE 0.7071035408323391\n",
      "6 Train Loss 5301.4 Test MSE 3812.1034967545875 Test RE 0.687918032545317\n",
      "7 Train Loss 5166.2783 Test MSE 3571.2892085111066 Test RE 0.6658353721191732\n",
      "8 Train Loss 4903.0117 Test MSE 3353.1799040239043 Test RE 0.6451827981329159\n",
      "9 Train Loss 4524.6055 Test MSE 3291.9383650874825 Test RE 0.639263929465421\n",
      "10 Train Loss 4170.0396 Test MSE 2953.32249007519 Test RE 0.6054939229106456\n",
      "11 Train Loss 3543.991 Test MSE 2095.8563571985565 Test RE 0.5100762581762661\n",
      "12 Train Loss 3244.5762 Test MSE 1594.6551286797885 Test RE 0.44492595299376403\n",
      "13 Train Loss 3097.1526 Test MSE 1517.0442053532622 Test RE 0.433963766903904\n",
      "14 Train Loss 2931.353 Test MSE 1360.8979489464173 Test RE 0.4110239533615212\n",
      "15 Train Loss 2811.5186 Test MSE 1360.479069309394 Test RE 0.41096069262442403\n",
      "16 Train Loss 2718.7278 Test MSE 1312.1318234194816 Test RE 0.40359249960687693\n",
      "17 Train Loss 2571.4246 Test MSE 1077.4826051110044 Test RE 0.36572907381551273\n",
      "18 Train Loss 2499.593 Test MSE 946.8767130265031 Test RE 0.34284756575706143\n",
      "19 Train Loss 2410.2974 Test MSE 709.096520308902 Test RE 0.2966928152059685\n",
      "20 Train Loss 2364.8374 Test MSE 672.2286718106267 Test RE 0.2888769355287253\n",
      "21 Train Loss 2339.2312 Test MSE 685.9642840235308 Test RE 0.2918133150821221\n",
      "22 Train Loss 2309.5615 Test MSE 623.4641623315637 Test RE 0.27820190509275905\n",
      "23 Train Loss 2292.5286 Test MSE 554.9257992840277 Test RE 0.26246524930754145\n",
      "24 Train Loss 2275.2847 Test MSE 462.65515381603103 Test RE 0.2396531018969999\n",
      "25 Train Loss 2262.7178 Test MSE 441.92630186948554 Test RE 0.23422285874592713\n",
      "26 Train Loss 2231.358 Test MSE 456.4443415725943 Test RE 0.2380390816807561\n",
      "27 Train Loss 2201.964 Test MSE 459.2268029914326 Test RE 0.23876351637762652\n",
      "28 Train Loss 2170.589 Test MSE 354.7688602602141 Test RE 0.20985875822345024\n",
      "29 Train Loss 2136.2395 Test MSE 307.33412808945326 Test RE 0.19532586086020262\n",
      "30 Train Loss 2116.2512 Test MSE 292.91851527664295 Test RE 0.1906899322401153\n",
      "31 Train Loss 2090.157 Test MSE 257.97650981810995 Test RE 0.17895524587686013\n",
      "32 Train Loss 2053.31 Test MSE 254.2033836190885 Test RE 0.1776417389445904\n",
      "33 Train Loss 2025.41 Test MSE 276.3384351738213 Test RE 0.185214506731774\n",
      "34 Train Loss 2008.6914 Test MSE 249.9605819462687 Test RE 0.176153029204695\n",
      "35 Train Loss 1993.6573 Test MSE 248.819697790502 Test RE 0.17575056565793754\n",
      "36 Train Loss 1972.037 Test MSE 264.99176889985483 Test RE 0.18137212630555666\n",
      "37 Train Loss 1942.2443 Test MSE 233.99799479459165 Test RE 0.17043564176300605\n",
      "38 Train Loss 1903.137 Test MSE 190.75355908284425 Test RE 0.15388301162394266\n",
      "39 Train Loss 1879.3625 Test MSE 183.98723967636897 Test RE 0.15112913765363828\n",
      "40 Train Loss 1833.9146 Test MSE 227.11332592075416 Test RE 0.16790965179073142\n",
      "41 Train Loss 1790.8228 Test MSE 286.8320412870279 Test RE 0.1886983854176232\n",
      "42 Train Loss 1754.8645 Test MSE 222.48756868130315 Test RE 0.16619089528475536\n",
      "43 Train Loss 1718.2899 Test MSE 196.9562577578451 Test RE 0.1563648902297024\n",
      "44 Train Loss 1655.5753 Test MSE 243.24381111447676 Test RE 0.17377018040079606\n",
      "45 Train Loss 1609.9232 Test MSE 233.54124389999248 Test RE 0.17026922012957496\n",
      "46 Train Loss 1573.8433 Test MSE 241.7594572627726 Test RE 0.17323916761999664\n",
      "47 Train Loss 1555.4272 Test MSE 237.17731629240598 Test RE 0.17158958649790496\n",
      "48 Train Loss 1541.7467 Test MSE 208.9881659321158 Test RE 0.16107020064125369\n",
      "49 Train Loss 1528.84 Test MSE 217.8843147534585 Test RE 0.1644626697101327\n",
      "50 Train Loss 1521.5854 Test MSE 212.57944229794546 Test RE 0.16244823010959877\n",
      "51 Train Loss 1511.1279 Test MSE 210.47131697349312 Test RE 0.1616407331635179\n",
      "52 Train Loss 1498.6582 Test MSE 232.32907792194445 Test RE 0.16982676494321255\n",
      "53 Train Loss 1468.1185 Test MSE 189.6506627791038 Test RE 0.1534375073980597\n",
      "54 Train Loss 1436.5121 Test MSE 152.8411780006362 Test RE 0.13774458676723395\n",
      "55 Train Loss 1398.6123 Test MSE 178.0264746199425 Test RE 0.14866086252700025\n",
      "56 Train Loss 1380.105 Test MSE 208.9375001599835 Test RE 0.1610506750362595\n",
      "57 Train Loss 1365.7389 Test MSE 201.02771858920377 Test RE 0.15797280307212772\n",
      "58 Train Loss 1352.7284 Test MSE 197.63117472033227 Test RE 0.15663257165257397\n",
      "59 Train Loss 1342.765 Test MSE 184.9143844692643 Test RE 0.15150944260289015\n",
      "60 Train Loss 1333.8109 Test MSE 163.88154436974955 Test RE 0.14263278964749226\n",
      "61 Train Loss 1319.7515 Test MSE 170.79627544800348 Test RE 0.14561078736574984\n",
      "62 Train Loss 1308.9253 Test MSE 167.78895901042955 Test RE 0.1443231642696751\n",
      "63 Train Loss 1301.4246 Test MSE 167.5539306154324 Test RE 0.14422204936777733\n",
      "64 Train Loss 1295.9058 Test MSE 175.19810012265137 Test RE 0.14747521856898463\n",
      "65 Train Loss 1291.7794 Test MSE 171.48064165349314 Test RE 0.14590222076462933\n",
      "66 Train Loss 1288.5436 Test MSE 176.4227712130229 Test RE 0.14798976213987483\n",
      "67 Train Loss 1286.712 Test MSE 182.744078218976 Test RE 0.15061769903823208\n",
      "68 Train Loss 1283.813 Test MSE 190.67851915491545 Test RE 0.15385274087558454\n",
      "69 Train Loss 1282.1776 Test MSE 189.04443787181458 Test RE 0.15319207695795206\n",
      "70 Train Loss 1281.6038 Test MSE 187.8203756490404 Test RE 0.15269531237316772\n",
      "71 Train Loss 1281.0798 Test MSE 188.2546945447502 Test RE 0.15287175799178965\n",
      "72 Train Loss 1280.3047 Test MSE 184.7137018502401 Test RE 0.1514272057184193\n",
      "73 Train Loss 1279.6423 Test MSE 185.6014967433671 Test RE 0.15179067401915625\n",
      "74 Train Loss 1278.6886 Test MSE 190.15563665010782 Test RE 0.15364164700562505\n",
      "75 Train Loss 1277.3251 Test MSE 193.37437677114693 Test RE 0.154936526679897\n",
      "76 Train Loss 1276.0886 Test MSE 192.89899906112439 Test RE 0.1547459670663382\n",
      "77 Train Loss 1267.1168 Test MSE 239.03481311372295 Test RE 0.1722601934219535\n",
      "78 Train Loss 1258.7413 Test MSE 255.85762597547514 Test RE 0.1782188082825049\n",
      "79 Train Loss 1246.7181 Test MSE 255.40523520990286 Test RE 0.17806118113905484\n",
      "80 Train Loss 1218.6243 Test MSE 181.93490095509867 Test RE 0.1502838670660684\n",
      "81 Train Loss 1162.2603 Test MSE 195.2388732087019 Test RE 0.15568167608669295\n",
      "82 Train Loss 1112.6384 Test MSE 209.1430815329941 Test RE 0.16112988742890938\n",
      "83 Train Loss 1049.445 Test MSE 154.05666557093892 Test RE 0.1382912172038129\n",
      "84 Train Loss 990.4317 Test MSE 94.03585025358659 Test RE 0.1080441059718182\n",
      "85 Train Loss 958.02747 Test MSE 54.251354546790736 Test RE 0.08206531586372642\n",
      "86 Train Loss 909.9324 Test MSE 48.074842849926185 Test RE 0.07725263274774863\n",
      "87 Train Loss 883.3355 Test MSE 37.515433118334634 Test RE 0.068243192386206\n",
      "88 Train Loss 862.4755 Test MSE 28.3840983049354 Test RE 0.05935972817119422\n",
      "89 Train Loss 844.9671 Test MSE 25.66361709319089 Test RE 0.05644341548915709\n",
      "90 Train Loss 817.24176 Test MSE 22.795379693755244 Test RE 0.05319585181858793\n",
      "91 Train Loss 804.04016 Test MSE 21.581079851565686 Test RE 0.05175960318826032\n",
      "92 Train Loss 797.49164 Test MSE 19.536432302994722 Test RE 0.04924668263049955\n",
      "93 Train Loss 788.3128 Test MSE 26.378935190631204 Test RE 0.057224628612702666\n",
      "94 Train Loss 774.00415 Test MSE 28.43077665448181 Test RE 0.059408517388989515\n",
      "95 Train Loss 766.1969 Test MSE 29.661825034449546 Test RE 0.060681077905722185\n",
      "96 Train Loss 759.8827 Test MSE 32.035600261754354 Test RE 0.06306244216869615\n",
      "97 Train Loss 750.36066 Test MSE 36.924763687820594 Test RE 0.06770382645470076\n",
      "98 Train Loss 742.5496 Test MSE 36.239637828618456 Test RE 0.067072775304729\n",
      "99 Train Loss 738.2159 Test MSE 35.62057328340664 Test RE 0.06649742139160111\n",
      "100 Train Loss 730.3957 Test MSE 40.57458918814868 Test RE 0.07097108063483715\n",
      "101 Train Loss 724.8836 Test MSE 43.53512976126892 Test RE 0.07351471433476976\n",
      "102 Train Loss 719.72577 Test MSE 42.91211835611175 Test RE 0.0729868010575079\n",
      "103 Train Loss 715.9546 Test MSE 45.73047616421029 Test RE 0.07534548175443172\n",
      "104 Train Loss 709.9724 Test MSE 48.79567522752409 Test RE 0.07782963941964195\n",
      "105 Train Loss 703.8439 Test MSE 47.57810161767268 Test RE 0.0768524836359652\n",
      "106 Train Loss 698.43195 Test MSE 49.252915887187186 Test RE 0.07819344109856989\n",
      "107 Train Loss 696.6692 Test MSE 51.24681630503205 Test RE 0.07976048707328998\n",
      "108 Train Loss 691.36444 Test MSE 51.834134989250465 Test RE 0.08021623607402667\n",
      "109 Train Loss 688.6214 Test MSE 50.92453209871263 Test RE 0.0795092901270765\n",
      "110 Train Loss 686.6687 Test MSE 51.64989984601302 Test RE 0.0800735520574873\n",
      "111 Train Loss 683.68726 Test MSE 57.3878341898739 Test RE 0.08440424117604683\n",
      "112 Train Loss 679.4257 Test MSE 63.53019043254061 Test RE 0.0888064338965308\n",
      "113 Train Loss 675.2061 Test MSE 65.13096086244535 Test RE 0.08991830154786513\n",
      "114 Train Loss 672.7134 Test MSE 62.45932361543379 Test RE 0.08805479103470654\n",
      "115 Train Loss 671.2398 Test MSE 64.48630872142594 Test RE 0.089472199011596\n",
      "116 Train Loss 669.68317 Test MSE 66.93299842552966 Test RE 0.09115374008956861\n",
      "117 Train Loss 668.7959 Test MSE 68.56373623635197 Test RE 0.09225748050325497\n",
      "118 Train Loss 665.43744 Test MSE 81.76646135375896 Test RE 0.10074928062286773\n",
      "119 Train Loss 662.9083 Test MSE 90.27389595918588 Test RE 0.10586086667982353\n",
      "120 Train Loss 661.0754 Test MSE 99.89505480630321 Test RE 0.11135926276303025\n",
      "121 Train Loss 658.8954 Test MSE 104.72534391230447 Test RE 0.11401979345911306\n",
      "122 Train Loss 656.98566 Test MSE 105.96466811366933 Test RE 0.114692466758662\n",
      "123 Train Loss 656.4966 Test MSE 104.99723621781452 Test RE 0.11416770898675821\n",
      "124 Train Loss 655.853 Test MSE 106.49068852084498 Test RE 0.11497678743116793\n",
      "125 Train Loss 654.65485 Test MSE 106.58176399286315 Test RE 0.11502594349990108\n",
      "126 Train Loss 652.4179 Test MSE 106.70423852103694 Test RE 0.11509201344868512\n",
      "127 Train Loss 649.9235 Test MSE 111.7603969659154 Test RE 0.11778726026484396\n",
      "128 Train Loss 648.6736 Test MSE 117.8380378132047 Test RE 0.1209475578116321\n",
      "129 Train Loss 648.27045 Test MSE 119.67102289161798 Test RE 0.12188460492348903\n",
      "130 Train Loss 648.0202 Test MSE 119.03802882678141 Test RE 0.1215618261771842\n",
      "131 Train Loss 647.4506 Test MSE 119.83687093562847 Test RE 0.12196903356834582\n",
      "132 Train Loss 646.5611 Test MSE 120.98214537566832 Test RE 0.12255047337558785\n",
      "133 Train Loss 645.71594 Test MSE 121.64954132663426 Test RE 0.12288803228422966\n",
      "134 Train Loss 644.8649 Test MSE 121.77033034981028 Test RE 0.1229490265239713\n",
      "135 Train Loss 644.1507 Test MSE 120.96690476891133 Test RE 0.1225427540448044\n",
      "136 Train Loss 642.86304 Test MSE 123.14821063459725 Test RE 0.12364267865854872\n",
      "137 Train Loss 642.1491 Test MSE 123.12423378271447 Test RE 0.12363064151042127\n",
      "138 Train Loss 641.4356 Test MSE 120.8285794013575 Test RE 0.12247267033020923\n",
      "139 Train Loss 640.69 Test MSE 119.38342819270655 Test RE 0.12173805962409705\n",
      "140 Train Loss 639.6897 Test MSE 118.51304945345181 Test RE 0.12129347509146923\n",
      "141 Train Loss 639.1367 Test MSE 119.0814090257252 Test RE 0.12158397412397103\n",
      "142 Train Loss 637.84357 Test MSE 123.4700827045589 Test RE 0.12380415544426697\n",
      "143 Train Loss 637.3919 Test MSE 123.55357205030639 Test RE 0.12384600599206888\n",
      "144 Train Loss 636.85126 Test MSE 126.89918878536108 Test RE 0.12551157380083533\n",
      "145 Train Loss 636.5324 Test MSE 128.3131469064469 Test RE 0.12620888515440218\n",
      "146 Train Loss 635.75916 Test MSE 128.1863623387924 Test RE 0.12614651705745514\n",
      "147 Train Loss 634.9293 Test MSE 128.72070061582312 Test RE 0.12640916128064694\n",
      "148 Train Loss 634.02936 Test MSE 129.00901512719798 Test RE 0.1265506506063318\n",
      "149 Train Loss 633.35016 Test MSE 130.9567022061687 Test RE 0.12750235822305514\n",
      "150 Train Loss 632.6596 Test MSE 133.76208527970462 Test RE 0.1288608131758907\n",
      "151 Train Loss 632.0793 Test MSE 132.7369974029031 Test RE 0.12836610009272686\n",
      "152 Train Loss 631.7784 Test MSE 129.2875613454637 Test RE 0.12668719609600104\n",
      "153 Train Loss 631.51575 Test MSE 128.8742438691399 Test RE 0.1264845317889926\n",
      "154 Train Loss 631.30475 Test MSE 128.6625952138069 Test RE 0.12638062708145156\n",
      "155 Train Loss 631.03265 Test MSE 126.86918806854924 Test RE 0.12549673659109875\n",
      "156 Train Loss 630.3876 Test MSE 124.8450352090778 Test RE 0.12449158331323344\n",
      "157 Train Loss 628.76605 Test MSE 123.91053330382229 Test RE 0.12402478002555216\n",
      "158 Train Loss 627.17975 Test MSE 121.05439376331125 Test RE 0.1225870603967528\n",
      "159 Train Loss 626.8817 Test MSE 120.93292817855165 Test RE 0.12252554323261333\n",
      "160 Train Loss 626.55225 Test MSE 119.91361704962793 Test RE 0.12200808311574678\n",
      "161 Train Loss 626.1509 Test MSE 119.0491678033851 Test RE 0.12156751361453368\n",
      "162 Train Loss 625.7763 Test MSE 119.49546107147657 Test RE 0.12179516749598722\n",
      "163 Train Loss 625.1103 Test MSE 121.57569599628808 Test RE 0.12285072805430275\n",
      "164 Train Loss 624.4765 Test MSE 124.924678370345 Test RE 0.12453128582308894\n",
      "165 Train Loss 624.2519 Test MSE 126.6958104233153 Test RE 0.12541095623833481\n",
      "166 Train Loss 624.0376 Test MSE 126.78273845961405 Test RE 0.12545397209970444\n",
      "167 Train Loss 623.7695 Test MSE 126.46396723670692 Test RE 0.12529615769307695\n",
      "168 Train Loss 622.79913 Test MSE 133.0692653605951 Test RE 0.12852666302718335\n",
      "169 Train Loss 621.717 Test MSE 137.24835012456523 Test RE 0.13052927282570503\n",
      "170 Train Loss 620.8837 Test MSE 138.15431933183024 Test RE 0.13095937269051014\n",
      "171 Train Loss 620.5649 Test MSE 140.1136089458678 Test RE 0.13188472924368275\n",
      "172 Train Loss 620.36017 Test MSE 139.05863764493802 Test RE 0.13138728471967404\n",
      "173 Train Loss 620.21594 Test MSE 138.64919638053686 Test RE 0.13119371518028827\n",
      "174 Train Loss 620.09344 Test MSE 138.035022240757 Test RE 0.1309028183735781\n",
      "175 Train Loss 620.02844 Test MSE 137.86798074984296 Test RE 0.13082358912842096\n",
      "176 Train Loss 619.81445 Test MSE 137.29693576058102 Test RE 0.13055237432959266\n",
      "177 Train Loss 619.19727 Test MSE 136.4808621425565 Test RE 0.13016380361850205\n",
      "178 Train Loss 618.5931 Test MSE 135.84904833560216 Test RE 0.1298621690670614\n",
      "179 Train Loss 618.3238 Test MSE 132.82573537354736 Test RE 0.1284090008826275\n",
      "180 Train Loss 617.74243 Test MSE 131.3617944838313 Test RE 0.12769940938079227\n",
      "181 Train Loss 617.04095 Test MSE 127.25953931344019 Test RE 0.12568965255646244\n",
      "182 Train Loss 616.51263 Test MSE 123.53994958060207 Test RE 0.12383917844778213\n",
      "183 Train Loss 616.00134 Test MSE 122.5682392812152 Test RE 0.12335118501829959\n",
      "184 Train Loss 615.8651 Test MSE 121.16339892903738 Test RE 0.12264224061628615\n",
      "185 Train Loss 615.7413 Test MSE 120.06250823168396 Test RE 0.12208380550955297\n",
      "186 Train Loss 615.55963 Test MSE 120.8049480316804 Test RE 0.1224606932860109\n",
      "187 Train Loss 615.2951 Test MSE 120.49958906386667 Test RE 0.1223058232581426\n",
      "188 Train Loss 614.97424 Test MSE 121.29415830995114 Test RE 0.12270840044365945\n",
      "189 Train Loss 614.67346 Test MSE 121.6367090484328 Test RE 0.12288155065269676\n",
      "190 Train Loss 614.3586 Test MSE 119.45374024011252 Test RE 0.12177390376258877\n",
      "191 Train Loss 614.22723 Test MSE 119.15559081716482 Test RE 0.12162183861044118\n",
      "192 Train Loss 614.1173 Test MSE 120.348006061968 Test RE 0.12222887146888678\n",
      "193 Train Loss 614.0052 Test MSE 121.22167092649252 Test RE 0.12267172868502299\n",
      "194 Train Loss 613.93414 Test MSE 122.04252223602813 Test RE 0.12308636312649571\n",
      "195 Train Loss 613.8604 Test MSE 122.71943229737683 Test RE 0.12342724097711262\n",
      "196 Train Loss 613.7993 Test MSE 123.4405191530453 Test RE 0.1237893327861573\n",
      "197 Train Loss 613.7993 Test MSE 123.4405191530453 Test RE 0.1237893327861573\n",
      "198 Train Loss 613.7993 Test MSE 123.5470549830562 Test RE 0.12384273970288039\n",
      "199 Train Loss 613.7059 Test MSE 124.33347888718242 Test RE 0.1242362674826624\n",
      "Training time: 29.59\n",
      "Training time: 29.59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 15721.609 Test MSE 11337.061575024327 Test RE 1.1863275198295662\n",
      "1 Train Loss 13241.679 Test MSE 12260.213628476784 Test RE 1.2336824060519\n",
      "2 Train Loss 12634.398 Test MSE 11915.55380231445 Test RE 1.2162181166707038\n",
      "3 Train Loss 11677.393 Test MSE 9271.73409185403 Test RE 1.072839700549544\n",
      "4 Train Loss 10804.618 Test MSE 7979.657258447523 Test RE 0.9952827369097033\n",
      "5 Train Loss 10402.887 Test MSE 6300.6478325337 Test RE 0.8843963780437378\n",
      "6 Train Loss 9979.573 Test MSE 5289.189675275638 Test RE 0.8103057544629131\n",
      "7 Train Loss 9481.874 Test MSE 4687.3234893169065 Test RE 0.7628107693000681\n",
      "8 Train Loss 8909.182 Test MSE 3548.7223549373007 Test RE 0.6637283428847692\n",
      "9 Train Loss 8332.217 Test MSE 3172.7496302304207 Test RE 0.6275845643546692\n",
      "10 Train Loss 7636.3955 Test MSE 3811.8719582602575 Test RE 0.6878971409399008\n",
      "11 Train Loss 7038.9663 Test MSE 3680.8546177999206 Test RE 0.6759719650847996\n",
      "12 Train Loss 6609.0396 Test MSE 3150.1087598659324 Test RE 0.6253413207357794\n",
      "13 Train Loss 6337.996 Test MSE 3075.252145291012 Test RE 0.6178665974589508\n",
      "14 Train Loss 5853.562 Test MSE 2894.906943385597 Test RE 0.5994758005253188\n",
      "15 Train Loss 5631.4365 Test MSE 2879.1675028230657 Test RE 0.5978439218763987\n",
      "16 Train Loss 5398.092 Test MSE 2622.8298550400796 Test RE 0.5706100435572015\n",
      "17 Train Loss 5122.196 Test MSE 2353.188787334646 Test RE 0.5404838699621197\n",
      "18 Train Loss 4991.7427 Test MSE 2252.1624914137233 Test RE 0.5287546661694414\n",
      "19 Train Loss 4758.7915 Test MSE 1963.6350493126747 Test RE 0.49372456972602924\n",
      "20 Train Loss 4573.5894 Test MSE 1849.1475384074233 Test RE 0.4791154041699469\n",
      "21 Train Loss 4267.0083 Test MSE 1891.6300883817696 Test RE 0.4845877808978027\n",
      "22 Train Loss 4101.8726 Test MSE 1830.0552719954412 Test RE 0.4766355768624851\n",
      "23 Train Loss 3927.9766 Test MSE 1749.646904319828 Test RE 0.46604683043177353\n",
      "24 Train Loss 3728.5925 Test MSE 1606.028590190746 Test RE 0.44650979304844896\n",
      "25 Train Loss 3456.5984 Test MSE 1459.1461038850484 Test RE 0.42560208049286813\n",
      "26 Train Loss 3224.604 Test MSE 1281.8005792847396 Test RE 0.3989005031546286\n",
      "27 Train Loss 3012.8044 Test MSE 1142.6207310653108 Test RE 0.37662175435772505\n",
      "28 Train Loss 2873.5908 Test MSE 1079.2359399100774 Test RE 0.366026519386454\n",
      "29 Train Loss 2751.8105 Test MSE 1017.711649603441 Test RE 0.3554403478692591\n",
      "30 Train Loss 2554.2744 Test MSE 824.6108427892412 Test RE 0.31994761185358017\n",
      "31 Train Loss 2444.2214 Test MSE 771.5570304317047 Test RE 0.30948411931956027\n",
      "32 Train Loss 2320.5596 Test MSE 644.0415344799957 Test RE 0.28275564913245105\n",
      "33 Train Loss 2257.9397 Test MSE 617.0002690852677 Test RE 0.27675598981731636\n",
      "34 Train Loss 2175.3823 Test MSE 613.1680888027652 Test RE 0.2758951872822426\n",
      "35 Train Loss 2093.4436 Test MSE 602.5357560021429 Test RE 0.27349271617285814\n",
      "36 Train Loss 2031.0452 Test MSE 605.5696156119066 Test RE 0.27418039043379444\n",
      "37 Train Loss 1964.3387 Test MSE 514.5826516849377 Test RE 0.25274462163533207\n",
      "38 Train Loss 1918.6736 Test MSE 471.64152619769544 Test RE 0.2419693569791351\n",
      "39 Train Loss 1856.1497 Test MSE 427.40504247005174 Test RE 0.2303425514760657\n",
      "40 Train Loss 1781.0841 Test MSE 389.2489743830637 Test RE 0.21982044910438164\n",
      "41 Train Loss 1725.3727 Test MSE 356.2925102633384 Test RE 0.21030892275905935\n",
      "42 Train Loss 1677.2365 Test MSE 312.32977505562303 Test RE 0.1969069506121025\n",
      "43 Train Loss 1626.114 Test MSE 277.67416674365 Test RE 0.18566160093479192\n",
      "44 Train Loss 1600.033 Test MSE 234.0318190202794 Test RE 0.1704479594867243\n",
      "45 Train Loss 1585.0533 Test MSE 214.23650734783124 Test RE 0.16308014619456437\n",
      "46 Train Loss 1564.5955 Test MSE 205.4454927621441 Test RE 0.15969917082451182\n",
      "47 Train Loss 1522.021 Test MSE 207.56895020848262 Test RE 0.16052236394484762\n",
      "48 Train Loss 1468.2869 Test MSE 246.6992437201285 Test RE 0.17500008571759365\n",
      "49 Train Loss 1437.842 Test MSE 276.547131988833 Test RE 0.1852844325500083\n",
      "50 Train Loss 1417.6758 Test MSE 249.39162602092344 Test RE 0.17595243676409766\n",
      "51 Train Loss 1389.5096 Test MSE 176.5590179969863 Test RE 0.1480468954612935\n",
      "52 Train Loss 1376.046 Test MSE 157.3528905635197 Test RE 0.13976283935812234\n",
      "53 Train Loss 1366.0284 Test MSE 163.7158482750817 Test RE 0.1425606653787924\n",
      "54 Train Loss 1360.4789 Test MSE 162.87135023530166 Test RE 0.1421925035279258\n",
      "55 Train Loss 1351.0361 Test MSE 170.40503292024826 Test RE 0.14544391664639597\n",
      "56 Train Loss 1342.4165 Test MSE 177.94549748347904 Test RE 0.14862704873552615\n",
      "57 Train Loss 1333.5262 Test MSE 175.8957701795036 Test RE 0.14776856312256792\n",
      "58 Train Loss 1325.5111 Test MSE 166.20967874149127 Test RE 0.14364235191233965\n",
      "59 Train Loss 1320.9235 Test MSE 163.61999274600004 Test RE 0.1425189246768947\n",
      "60 Train Loss 1307.701 Test MSE 188.1083339498611 Test RE 0.15281232055786434\n",
      "61 Train Loss 1300.8838 Test MSE 179.57233568027726 Test RE 0.14930490245676428\n",
      "62 Train Loss 1296.8284 Test MSE 170.2716898609062 Test RE 0.1453870000990035\n",
      "63 Train Loss 1292.5406 Test MSE 187.6680199657924 Test RE 0.15263336829950658\n",
      "64 Train Loss 1288.1255 Test MSE 201.29251700077103 Test RE 0.15807681156783998\n",
      "65 Train Loss 1283.4783 Test MSE 187.51468807828422 Test RE 0.15257100193358095\n",
      "66 Train Loss 1276.08 Test MSE 185.59905373046954 Test RE 0.15178967502992088\n",
      "67 Train Loss 1272.1447 Test MSE 185.98374515948174 Test RE 0.1519469009417654\n",
      "68 Train Loss 1270.0143 Test MSE 193.91461144560873 Test RE 0.15515280069415358\n",
      "69 Train Loss 1268.456 Test MSE 203.098881039139 Test RE 0.15878450434285113\n",
      "70 Train Loss 1266.4391 Test MSE 199.3127654608368 Test RE 0.15729753245853934\n",
      "71 Train Loss 1265.1619 Test MSE 196.97040118459705 Test RE 0.15637050440945874\n",
      "72 Train Loss 1263.449 Test MSE 203.89210594847785 Test RE 0.1590942773049915\n",
      "73 Train Loss 1262.2124 Test MSE 194.92662439406092 Test RE 0.15555713410936267\n",
      "74 Train Loss 1261.0625 Test MSE 200.07813360977323 Test RE 0.1575992571533218\n",
      "75 Train Loss 1257.8993 Test MSE 197.3690444418829 Test RE 0.15652866151998843\n",
      "76 Train Loss 1256.3809 Test MSE 183.31230748483563 Test RE 0.1508516846159165\n",
      "77 Train Loss 1255.4822 Test MSE 191.33281617076622 Test RE 0.15411648107390247\n",
      "78 Train Loss 1254.0336 Test MSE 208.63752908861585 Test RE 0.1609350234758892\n",
      "79 Train Loss 1252.9117 Test MSE 210.69667559875137 Test RE 0.16172724706055805\n",
      "80 Train Loss 1252.4664 Test MSE 215.15649973858754 Test RE 0.1634299273075551\n",
      "81 Train Loss 1251.6538 Test MSE 221.84792083722223 Test RE 0.16595182538117798\n",
      "82 Train Loss 1250.8944 Test MSE 212.01662072882104 Test RE 0.16223304005236408\n",
      "83 Train Loss 1249.3534 Test MSE 193.06558362087048 Test RE 0.15481277074570324\n",
      "84 Train Loss 1248.0817 Test MSE 188.18307803651305 Test RE 0.15284267722179193\n",
      "85 Train Loss 1246.2189 Test MSE 192.2809215919428 Test RE 0.15449785345664652\n",
      "86 Train Loss 1244.502 Test MSE 200.47071645275037 Test RE 0.15775379788986715\n",
      "87 Train Loss 1244.0519 Test MSE 195.9038207678523 Test RE 0.15594656226424553\n",
      "88 Train Loss 1243.6116 Test MSE 188.33620890276555 Test RE 0.1529048511760065\n",
      "89 Train Loss 1243.0918 Test MSE 191.92752862028186 Test RE 0.1543558124138022\n",
      "90 Train Loss 1242.5824 Test MSE 195.87668984917158 Test RE 0.15593576329161485\n",
      "91 Train Loss 1241.7157 Test MSE 195.14733402178658 Test RE 0.15564517555628457\n",
      "92 Train Loss 1241.2191 Test MSE 195.0823973315923 Test RE 0.155619277371364\n",
      "93 Train Loss 1240.8721 Test MSE 197.51538830762593 Test RE 0.15658668167413936\n",
      "94 Train Loss 1240.4227 Test MSE 196.10047436811175 Test RE 0.15602481433827628\n",
      "95 Train Loss 1240.048 Test MSE 200.18207896567094 Test RE 0.15764019012150468\n",
      "96 Train Loss 1239.8252 Test MSE 203.53388877865146 Test RE 0.1589544598387782\n",
      "97 Train Loss 1239.5522 Test MSE 206.5056293302099 Test RE 0.1601106792050008\n",
      "98 Train Loss 1239.4319 Test MSE 204.212893144232 Test RE 0.15921938109181963\n",
      "99 Train Loss 1239.3699 Test MSE 201.29684384621555 Test RE 0.15807851051389793\n",
      "100 Train Loss 1239.301 Test MSE 202.84760445722685 Test RE 0.158686248813857\n",
      "101 Train Loss 1239.2046 Test MSE 202.5521815447416 Test RE 0.15857065308139376\n",
      "102 Train Loss 1239.1058 Test MSE 200.78394502486066 Test RE 0.15787699221787413\n",
      "103 Train Loss 1239.0312 Test MSE 200.61988192764872 Test RE 0.15781247739411422\n",
      "104 Train Loss 1238.9524 Test MSE 199.46081326330966 Test RE 0.15735594123912558\n",
      "105 Train Loss 1238.8043 Test MSE 200.46925181170107 Test RE 0.15775322161340594\n",
      "106 Train Loss 1238.6493 Test MSE 202.93501136028738 Test RE 0.15872043403323155\n",
      "107 Train Loss 1238.5725 Test MSE 201.05430032430326 Test RE 0.157983247035848\n",
      "108 Train Loss 1238.559 Test MSE 200.26287362469077 Test RE 0.15767199916406172\n",
      "109 Train Loss 1238.5128 Test MSE 201.42199259819182 Test RE 0.15812764256683345\n",
      "110 Train Loss 1238.3777 Test MSE 201.78917908937206 Test RE 0.15827170800895615\n",
      "111 Train Loss 1238.3186 Test MSE 201.3842601421114 Test RE 0.15811283081835903\n",
      "112 Train Loss 1238.3043 Test MSE 201.7399472690574 Test RE 0.15825239954145248\n",
      "113 Train Loss 1238.2928 Test MSE 201.05078655427738 Test RE 0.15798186651520615\n",
      "114 Train Loss 1238.2545 Test MSE 199.36185587702406 Test RE 0.15731690233158147\n",
      "115 Train Loss 1238.222 Test MSE 201.3025752726812 Test RE 0.15808076094389087\n",
      "116 Train Loss 1238.1948 Test MSE 201.60025734404894 Test RE 0.15819760103925753\n",
      "117 Train Loss 1238.1808 Test MSE 201.6601994722016 Test RE 0.15822111786465243\n",
      "118 Train Loss 1238.1761 Test MSE 202.41672618928663 Test RE 0.15851762270611247\n",
      "119 Train Loss 1238.1659 Test MSE 202.80632301968137 Test RE 0.15867010090368397\n",
      "120 Train Loss 1238.1239 Test MSE 202.0524775304717 Test RE 0.15837493234735547\n",
      "121 Train Loss 1238.0629 Test MSE 201.92624504092635 Test RE 0.15832545216842578\n",
      "122 Train Loss 1238.0172 Test MSE 202.10713601675283 Test RE 0.15839635239827146\n",
      "123 Train Loss 1238.0013 Test MSE 202.79953355120608 Test RE 0.15866744493455934\n",
      "124 Train Loss 1237.9808 Test MSE 203.18624140765516 Test RE 0.15881865022638567\n",
      "125 Train Loss 1237.9379 Test MSE 202.3846391025848 Test RE 0.1585050581063682\n",
      "126 Train Loss 1237.9006 Test MSE 203.20124622730327 Test RE 0.15882451430751876\n",
      "127 Train Loss 1237.8611 Test MSE 204.47968415116728 Test RE 0.1593233520840897\n",
      "128 Train Loss 1237.8239 Test MSE 203.17628441402434 Test RE 0.15881475878262552\n",
      "129 Train Loss 1237.7648 Test MSE 201.63751774505025 Test RE 0.15821221965580756\n",
      "130 Train Loss 1237.7391 Test MSE 201.369275736509 Test RE 0.15810694835550002\n",
      "131 Train Loss 1237.7244 Test MSE 200.08965410813153 Test RE 0.1576037943703965\n",
      "132 Train Loss 1237.7094 Test MSE 199.73913621015083 Test RE 0.1574656883651516\n",
      "133 Train Loss 1237.6902 Test MSE 201.757732114788 Test RE 0.15825937493855066\n",
      "134 Train Loss 1237.6649 Test MSE 202.128337944761 Test RE 0.15840466041761153\n",
      "135 Train Loss 1237.6312 Test MSE 201.69697133394052 Test RE 0.15823554267402\n",
      "136 Train Loss 1237.5579 Test MSE 201.47235513297267 Test RE 0.1581474100486678\n",
      "137 Train Loss 1237.5359 Test MSE 201.30754522139057 Test RE 0.158082712355649\n",
      "138 Train Loss 1237.501 Test MSE 200.4395154683606 Test RE 0.15774152112096151\n",
      "139 Train Loss 1237.4432 Test MSE 200.68820461295314 Test RE 0.15783934724942048\n",
      "140 Train Loss 1237.427 Test MSE 201.28599384922092 Test RE 0.15807425020249977\n",
      "141 Train Loss 1237.3945 Test MSE 200.7754578745248 Test RE 0.1578736554472789\n",
      "142 Train Loss 1237.344 Test MSE 200.67848764613478 Test RE 0.15783552605258366\n",
      "143 Train Loss 1237.3217 Test MSE 199.78488319339698 Test RE 0.15748371980337098\n",
      "144 Train Loss 1237.2982 Test MSE 198.12808853107435 Test RE 0.15682936253037802\n",
      "145 Train Loss 1237.2742 Test MSE 197.43152352796412 Test RE 0.15655343489287812\n",
      "146 Train Loss 1237.2521 Test MSE 198.1211353406609 Test RE 0.1568266105884508\n",
      "147 Train Loss 1237.2341 Test MSE 198.25248050388683 Test RE 0.15687858637566782\n",
      "148 Train Loss 1237.2184 Test MSE 198.26345653023432 Test RE 0.15688292901910134\n",
      "149 Train Loss 1237.1725 Test MSE 198.05660900824452 Test RE 0.15680106997644774\n",
      "150 Train Loss 1237.1155 Test MSE 196.99015272827637 Test RE 0.15637834437273668\n",
      "151 Train Loss 1237.0583 Test MSE 196.44882946746102 Test RE 0.15616333497010043\n",
      "152 Train Loss 1237.0244 Test MSE 197.6205457653258 Test RE 0.15662835960722205\n",
      "153 Train Loss 1237.0076 Test MSE 198.37115658335333 Test RE 0.15692553396032133\n",
      "154 Train Loss 1236.9889 Test MSE 200.29385701515403 Test RE 0.1576841956937759\n",
      "155 Train Loss 1236.972 Test MSE 201.40947130916118 Test RE 0.15812272753083725\n",
      "156 Train Loss 1236.9492 Test MSE 202.70591261237428 Test RE 0.15863081686724675\n",
      "157 Train Loss 1236.9094 Test MSE 204.02670229705507 Test RE 0.15914678050495268\n",
      "158 Train Loss 1236.8734 Test MSE 202.8122480563508 Test RE 0.15867241867979126\n",
      "159 Train Loss 1236.8357 Test MSE 203.59755479556134 Test RE 0.15897931861320888\n",
      "160 Train Loss 1236.8059 Test MSE 204.82331009603968 Test RE 0.15945716649266276\n",
      "161 Train Loss 1236.7306 Test MSE 204.28569710352062 Test RE 0.1592477602215505\n",
      "162 Train Loss 1236.6974 Test MSE 204.13744072136944 Test RE 0.15918996424704132\n",
      "163 Train Loss 1236.656 Test MSE 204.1008190471413 Test RE 0.1591756844939583\n",
      "164 Train Loss 1236.5946 Test MSE 202.7826811978171 Test RE 0.1586608522778639\n",
      "165 Train Loss 1236.546 Test MSE 203.85122555048525 Test RE 0.15907832729215973\n",
      "166 Train Loss 1236.5084 Test MSE 202.81834104724047 Test RE 0.15867480212149565\n",
      "167 Train Loss 1236.4788 Test MSE 203.01371629248047 Test RE 0.15875120957545671\n",
      "168 Train Loss 1236.4429 Test MSE 202.7203563160504 Test RE 0.15863646834447748\n",
      "169 Train Loss 1236.4198 Test MSE 201.1946195439828 Test RE 0.15803836701932694\n",
      "170 Train Loss 1236.4043 Test MSE 201.36459409673546 Test RE 0.1581051104284442\n",
      "171 Train Loss 1236.3998 Test MSE 200.96388987439536 Test RE 0.15794772195003917\n",
      "172 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "173 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "174 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "175 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "176 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "177 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "178 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "179 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "180 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "181 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "182 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "183 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "184 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "185 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "186 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "187 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "188 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "189 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "190 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "191 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "192 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "193 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "194 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "195 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "196 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "197 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "198 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "199 Train Loss 1236.3989 Test MSE 200.9107096850533 Test RE 0.1579268220621751\n",
      "Training time: 29.06\n",
      "Training time: 29.06\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 16967.557 Test MSE 11562.844255805283 Test RE 1.1980824054866543\n",
      "1 Train Loss 13911.819 Test MSE 12281.028404892551 Test RE 1.2347292040284696\n",
      "2 Train Loss 11757.54 Test MSE 11723.052917587162 Test RE 1.2063538513067424\n",
      "3 Train Loss 10297.592 Test MSE 11915.723447627255 Test RE 1.2162267744709154\n",
      "4 Train Loss 9175.846 Test MSE 11498.854310175866 Test RE 1.1947626517531247\n",
      "5 Train Loss 8206.476 Test MSE 9763.291853471394 Test RE 1.100911702622652\n",
      "6 Train Loss 7537.0635 Test MSE 9143.836104515629 Test RE 1.065414416052163\n",
      "7 Train Loss 6865.5796 Test MSE 8620.833536826285 Test RE 1.0344963958860265\n",
      "8 Train Loss 6647.8325 Test MSE 8367.593866027706 Test RE 1.0191888147733157\n",
      "9 Train Loss 6346.2593 Test MSE 7717.023008731967 Test RE 0.9787668458704967\n",
      "10 Train Loss 6013.0063 Test MSE 6448.372782302635 Test RE 0.8947040854653184\n",
      "11 Train Loss 5653.7495 Test MSE 5829.043529237612 Test RE 0.8506541039686376\n",
      "12 Train Loss 5296.4067 Test MSE 5259.865329101234 Test RE 0.8080563822114724\n",
      "13 Train Loss 5084.927 Test MSE 4859.8497257215095 Test RE 0.7767222972267029\n",
      "14 Train Loss 4856.3877 Test MSE 4120.049982829376 Test RE 0.715163917581573\n",
      "15 Train Loss 4604.813 Test MSE 3645.4764198551493 Test RE 0.6727156002301795\n",
      "16 Train Loss 4390.6055 Test MSE 3409.2231762137108 Test RE 0.6505520779886895\n",
      "17 Train Loss 4198.5537 Test MSE 2992.021529938413 Test RE 0.6094480748208355\n",
      "18 Train Loss 4074.2585 Test MSE 2732.3669266804363 Test RE 0.5824033471854317\n",
      "19 Train Loss 4017.3462 Test MSE 2577.2813206552414 Test RE 0.56563368559707\n",
      "20 Train Loss 3969.37 Test MSE 2423.92347882669 Test RE 0.5485469504967395\n",
      "21 Train Loss 3904.1877 Test MSE 2314.692332442451 Test RE 0.5360446783530328\n",
      "22 Train Loss 3862.745 Test MSE 2206.6842163346537 Test RE 0.5233888262076006\n",
      "23 Train Loss 3818.251 Test MSE 2296.711602366283 Test RE 0.533958598549285\n",
      "24 Train Loss 3763.863 Test MSE 2217.0390786723488 Test RE 0.5246153896164497\n",
      "25 Train Loss 3713.414 Test MSE 2137.489860416529 Test RE 0.5151175944482883\n",
      "26 Train Loss 3637.501 Test MSE 2046.722537848162 Test RE 0.5040618607522067\n",
      "27 Train Loss 3595.5066 Test MSE 1846.4653531617887 Test RE 0.47876780004972175\n",
      "28 Train Loss 3551.3088 Test MSE 1770.4435733341265 Test RE 0.4688084135307012\n",
      "29 Train Loss 3470.0217 Test MSE 1767.924307969616 Test RE 0.4684747476453065\n",
      "30 Train Loss 3378.2097 Test MSE 1774.450874606853 Test RE 0.4693386746254434\n",
      "31 Train Loss 3294.3923 Test MSE 1759.8397777655057 Test RE 0.46740237763461306\n",
      "32 Train Loss 3175.1104 Test MSE 1728.0525755747742 Test RE 0.46316190142018093\n",
      "33 Train Loss 3085.6653 Test MSE 1780.6250621211864 Test RE 0.47015449564852635\n",
      "34 Train Loss 3022.197 Test MSE 1755.0033358865496 Test RE 0.4667596714812258\n",
      "35 Train Loss 2940.2078 Test MSE 1798.9207241111687 Test RE 0.4725637072171926\n",
      "36 Train Loss 2869.642 Test MSE 1784.048292305794 Test RE 0.470606211818927\n",
      "37 Train Loss 2822.361 Test MSE 1742.5718264151894 Test RE 0.4651035950463022\n",
      "38 Train Loss 2786.4817 Test MSE 1678.7870376694027 Test RE 0.4565119558236556\n",
      "39 Train Loss 2752.4453 Test MSE 1592.035217988143 Test RE 0.44456031110301664\n",
      "40 Train Loss 2706.9 Test MSE 1554.915024490047 Test RE 0.43934701729313225\n",
      "41 Train Loss 2662.7036 Test MSE 1494.4705899533312 Test RE 0.43072297589249087\n",
      "42 Train Loss 2625.2717 Test MSE 1456.2105628987583 Test RE 0.42517374731940233\n",
      "43 Train Loss 2573.2715 Test MSE 1463.9227082736381 Test RE 0.42629812859425653\n",
      "44 Train Loss 2450.9324 Test MSE 1368.023587336121 Test RE 0.41209860567851403\n",
      "45 Train Loss 2304.2422 Test MSE 1291.599008175628 Test RE 0.40042225197323433\n",
      "46 Train Loss 2158.3298 Test MSE 1208.0151023723367 Test RE 0.38724920445717564\n",
      "47 Train Loss 2049.3997 Test MSE 1150.131639320597 Test RE 0.37785757037204293\n",
      "48 Train Loss 1943.3807 Test MSE 1144.0443787661184 Test RE 0.37685630715892493\n",
      "49 Train Loss 1783.5815 Test MSE 975.0623834887685 Test RE 0.34791291728524587\n",
      "50 Train Loss 1700.3353 Test MSE 947.0985206475249 Test RE 0.3428877197438044\n",
      "51 Train Loss 1597.5013 Test MSE 963.6185974384647 Test RE 0.34586525750050695\n",
      "52 Train Loss 1539.2396 Test MSE 923.2662639696904 Test RE 0.3385461160484924\n",
      "53 Train Loss 1500.9102 Test MSE 885.1599718592234 Test RE 0.33148603388678566\n",
      "54 Train Loss 1447.9836 Test MSE 863.0450810333913 Test RE 0.32731890765542837\n",
      "55 Train Loss 1408.6703 Test MSE 847.8692855229987 Test RE 0.3244283545336325\n",
      "56 Train Loss 1376.5613 Test MSE 843.9806811207669 Test RE 0.3236835325590255\n",
      "57 Train Loss 1351.7867 Test MSE 831.7885342746259 Test RE 0.3213370609222824\n",
      "58 Train Loss 1333.1932 Test MSE 829.0613888842179 Test RE 0.3208098521871465\n",
      "59 Train Loss 1315.7456 Test MSE 832.0191875955977 Test RE 0.3213816109008858\n",
      "60 Train Loss 1299.0063 Test MSE 821.4456064794073 Test RE 0.3193329682987117\n",
      "61 Train Loss 1282.7234 Test MSE 827.3297348592569 Test RE 0.3204746405452554\n",
      "62 Train Loss 1264.1809 Test MSE 824.8407607393032 Test RE 0.3199922126327145\n",
      "63 Train Loss 1244.3568 Test MSE 808.3905783557948 Test RE 0.31678526604289875\n",
      "64 Train Loss 1221.7806 Test MSE 789.6373168154745 Test RE 0.31308927028966177\n",
      "65 Train Loss 1206.1705 Test MSE 786.1871930089861 Test RE 0.31240453869237167\n",
      "66 Train Loss 1186.0026 Test MSE 785.4372900362752 Test RE 0.3122555099456438\n",
      "67 Train Loss 1160.9437 Test MSE 748.5515993428295 Test RE 0.30483527660429244\n",
      "68 Train Loss 1144.204 Test MSE 716.1795033899942 Test RE 0.29817092743440715\n",
      "69 Train Loss 1120.7401 Test MSE 694.42617101932 Test RE 0.2936076670774573\n",
      "70 Train Loss 1096.5969 Test MSE 682.9169609477386 Test RE 0.2911644188725846\n",
      "71 Train Loss 1077.7782 Test MSE 652.6157754257503 Test RE 0.28463161445208046\n",
      "72 Train Loss 1058.7136 Test MSE 632.7347815164155 Test RE 0.2802626386387029\n",
      "73 Train Loss 1047.9441 Test MSE 625.0687740160538 Test RE 0.27855967960041306\n",
      "74 Train Loss 1034.9122 Test MSE 612.6874019411035 Test RE 0.2757870234722673\n",
      "75 Train Loss 1020.01385 Test MSE 592.6047758389901 Test RE 0.2712295016059492\n",
      "76 Train Loss 1001.4051 Test MSE 551.0835567313476 Test RE 0.2615550313764283\n",
      "77 Train Loss 978.753 Test MSE 527.1445574281294 Test RE 0.2558110002362417\n",
      "78 Train Loss 961.755 Test MSE 500.0489785403045 Test RE 0.24914984687015498\n",
      "79 Train Loss 942.7664 Test MSE 473.21052246147264 Test RE 0.24237149904913383\n",
      "80 Train Loss 910.5567 Test MSE 422.4992371536091 Test RE 0.2290167867348338\n",
      "81 Train Loss 895.9221 Test MSE 405.328470801039 Test RE 0.22431478902231408\n",
      "82 Train Loss 882.935 Test MSE 384.3757223530107 Test RE 0.2184400800380171\n",
      "83 Train Loss 860.7226 Test MSE 379.82030885570896 Test RE 0.21714180502422162\n",
      "84 Train Loss 847.64545 Test MSE 369.26577279747283 Test RE 0.2141035556532392\n",
      "85 Train Loss 835.6054 Test MSE 356.723427366008 Test RE 0.21043606313367838\n",
      "86 Train Loss 803.4992 Test MSE 340.4482113581865 Test RE 0.20557953564864606\n",
      "87 Train Loss 757.0294 Test MSE 297.52324086134587 Test RE 0.19218292560815387\n",
      "88 Train Loss 723.00824 Test MSE 239.1091155237904 Test RE 0.17228696431960944\n",
      "89 Train Loss 701.65405 Test MSE 216.61361005945588 Test RE 0.1639823940255045\n",
      "90 Train Loss 685.93365 Test MSE 202.57013024743432 Test RE 0.15857767861535252\n",
      "91 Train Loss 673.615 Test MSE 177.39425563703972 Test RE 0.14839666078267116\n",
      "92 Train Loss 651.1631 Test MSE 156.90710873922464 Test RE 0.13956472439938955\n",
      "93 Train Loss 640.8784 Test MSE 147.33924346608248 Test RE 0.13524261830419523\n",
      "94 Train Loss 626.22546 Test MSE 135.79354528194446 Test RE 0.12983563784220792\n",
      "95 Train Loss 614.9053 Test MSE 132.47264832810546 Test RE 0.1282382142276764\n",
      "96 Train Loss 604.1741 Test MSE 126.02496856431402 Test RE 0.12507849622725556\n",
      "97 Train Loss 598.5084 Test MSE 116.82299641303902 Test RE 0.12042551798581691\n",
      "98 Train Loss 592.4905 Test MSE 120.9138321509849 Test RE 0.12251586909522626\n",
      "99 Train Loss 587.154 Test MSE 125.69912128769052 Test RE 0.12491669152022737\n",
      "100 Train Loss 578.99603 Test MSE 118.14686674884817 Test RE 0.12110594327542828\n",
      "101 Train Loss 574.8976 Test MSE 124.80926173401619 Test RE 0.12447374593740632\n",
      "102 Train Loss 569.4453 Test MSE 129.34352243546314 Test RE 0.1267146109010702\n",
      "103 Train Loss 564.818 Test MSE 126.10681393690768 Test RE 0.12511910498397294\n",
      "104 Train Loss 561.0561 Test MSE 130.04652447248012 Test RE 0.1270585010085437\n",
      "105 Train Loss 556.29535 Test MSE 134.25672417088555 Test RE 0.12909885055645517\n",
      "106 Train Loss 553.2949 Test MSE 132.75036743089893 Test RE 0.12837256481307566\n",
      "107 Train Loss 549.2664 Test MSE 137.09570947085862 Test RE 0.13045666861504432\n",
      "108 Train Loss 543.84534 Test MSE 141.07114836272768 Test RE 0.13233461346081976\n",
      "109 Train Loss 539.80554 Test MSE 139.23088214631275 Test RE 0.13146863074100817\n",
      "110 Train Loss 536.74225 Test MSE 138.35936453539642 Test RE 0.1310565199793608\n",
      "111 Train Loss 532.818 Test MSE 136.88752993332014 Test RE 0.1303575819008155\n",
      "112 Train Loss 527.73615 Test MSE 130.6361851952442 Test RE 0.12734623138862802\n",
      "113 Train Loss 520.0878 Test MSE 123.5157865115841 Test RE 0.12382706705807599\n",
      "114 Train Loss 518.3093 Test MSE 120.27550734701242 Test RE 0.12219205004011459\n",
      "115 Train Loss 514.638 Test MSE 113.01053596799613 Test RE 0.11844420564721851\n",
      "116 Train Loss 508.58615 Test MSE 109.1718912976616 Test RE 0.11641522165785224\n",
      "117 Train Loss 504.00623 Test MSE 109.87491726081481 Test RE 0.11678945528833128\n",
      "118 Train Loss 501.7599 Test MSE 105.63408404877079 Test RE 0.1145134206645209\n",
      "119 Train Loss 494.06488 Test MSE 98.19655422355322 Test RE 0.11040849158891301\n",
      "120 Train Loss 483.42496 Test MSE 101.55027603692824 Test RE 0.11227806165989067\n",
      "121 Train Loss 473.16888 Test MSE 94.40672981239145 Test RE 0.10825696052350248\n",
      "122 Train Loss 458.89133 Test MSE 91.26126731111029 Test RE 0.10643821924889457\n",
      "123 Train Loss 449.81873 Test MSE 92.78772445165525 Test RE 0.10732468300193689\n",
      "124 Train Loss 443.90817 Test MSE 88.11561733139744 Test RE 0.10458774430378802\n",
      "125 Train Loss 437.78552 Test MSE 81.98362315763099 Test RE 0.1008829808435486\n",
      "126 Train Loss 429.50284 Test MSE 72.14224549628881 Test RE 0.09463443211902918\n",
      "127 Train Loss 421.422 Test MSE 69.00875784558963 Test RE 0.09255640067082235\n",
      "128 Train Loss 417.2944 Test MSE 68.48947029712015 Test RE 0.09220750186166438\n",
      "129 Train Loss 409.8122 Test MSE 64.92984166035929 Test RE 0.08977936394328283\n",
      "130 Train Loss 404.9852 Test MSE 64.40831203661382 Test RE 0.08941807398514376\n",
      "131 Train Loss 401.81018 Test MSE 59.403762866939246 Test RE 0.08587392831830953\n",
      "132 Train Loss 399.36725 Test MSE 57.10773728326536 Test RE 0.08419801031864421\n",
      "133 Train Loss 397.49442 Test MSE 54.691376780016604 Test RE 0.08239745169568934\n",
      "134 Train Loss 395.35858 Test MSE 51.217722638418735 Test RE 0.07973784318406124\n",
      "135 Train Loss 393.13193 Test MSE 48.85068084921582 Test RE 0.0778734943503117\n",
      "136 Train Loss 391.81473 Test MSE 49.22195564358309 Test RE 0.07816886114729703\n",
      "137 Train Loss 390.60788 Test MSE 49.855590298345206 Test RE 0.0786703864816097\n",
      "138 Train Loss 388.78403 Test MSE 49.64906319489715 Test RE 0.07850727108868323\n",
      "139 Train Loss 386.20654 Test MSE 49.96087724055468 Test RE 0.07875341223586116\n",
      "140 Train Loss 384.9916 Test MSE 50.982103343335865 Test RE 0.07955422088646297\n",
      "141 Train Loss 383.79227 Test MSE 50.959343646089785 Test RE 0.07953646139846506\n",
      "142 Train Loss 382.44336 Test MSE 51.78279530127125 Test RE 0.08017650070673311\n",
      "143 Train Loss 380.4404 Test MSE 53.273344272219134 Test RE 0.08132224001562403\n",
      "144 Train Loss 377.4051 Test MSE 51.879802807667595 Test RE 0.08025156505157043\n",
      "145 Train Loss 374.2011 Test MSE 55.27504921706256 Test RE 0.08283596221267442\n",
      "146 Train Loss 372.72318 Test MSE 56.91286051211462 Test RE 0.08405422718926488\n",
      "147 Train Loss 370.58484 Test MSE 55.028636142810456 Test RE 0.08265111693454512\n",
      "148 Train Loss 368.7099 Test MSE 54.04734954664153 Test RE 0.08191087268582782\n",
      "149 Train Loss 365.55188 Test MSE 53.33055543685744 Test RE 0.08136589497745642\n",
      "150 Train Loss 363.18506 Test MSE 55.6747521738902 Test RE 0.08313492294969405\n",
      "151 Train Loss 361.27377 Test MSE 56.729256747401095 Test RE 0.08391853607151215\n",
      "152 Train Loss 360.29144 Test MSE 57.18127744280874 Test RE 0.08425220562808754\n",
      "153 Train Loss 359.09753 Test MSE 59.00993922412661 Test RE 0.08558879973223889\n",
      "154 Train Loss 358.037 Test MSE 56.50076706888463 Test RE 0.08374936528717414\n",
      "155 Train Loss 357.37537 Test MSE 57.70350019672163 Test RE 0.08463605870208478\n",
      "156 Train Loss 356.32556 Test MSE 58.639651222676484 Test RE 0.08531984182172518\n",
      "157 Train Loss 353.9101 Test MSE 56.18534112107338 Test RE 0.08351526496758846\n",
      "158 Train Loss 350.74652 Test MSE 60.24370539250588 Test RE 0.08647890668216351\n",
      "159 Train Loss 348.53104 Test MSE 63.02699077202021 Test RE 0.08845403287751775\n",
      "160 Train Loss 347.30948 Test MSE 60.89957168713153 Test RE 0.08694837533571424\n",
      "161 Train Loss 345.48178 Test MSE 60.6586277807537 Test RE 0.08677620299426335\n",
      "162 Train Loss 343.71735 Test MSE 58.49300755052802 Test RE 0.08521309283377819\n",
      "163 Train Loss 342.05133 Test MSE 55.69926779586796 Test RE 0.08315322460305664\n",
      "164 Train Loss 341.05057 Test MSE 57.18147230960119 Test RE 0.08425234918856582\n",
      "165 Train Loss 340.36703 Test MSE 57.32016182719208 Test RE 0.08435446129360849\n",
      "166 Train Loss 339.41827 Test MSE 54.600272085462834 Test RE 0.082328794405316\n",
      "167 Train Loss 338.47025 Test MSE 52.33689415251176 Test RE 0.08060432132372586\n",
      "168 Train Loss 336.6749 Test MSE 48.65663698115308 Test RE 0.07771867655178208\n",
      "169 Train Loss 335.11337 Test MSE 48.03549702984235 Test RE 0.07722101339986538\n",
      "170 Train Loss 333.65137 Test MSE 46.90302507587778 Test RE 0.0763053132162348\n",
      "171 Train Loss 332.42087 Test MSE 46.24886666372867 Test RE 0.0757713281360314\n",
      "172 Train Loss 330.9733 Test MSE 44.27703717820705 Test RE 0.07413847156873477\n",
      "173 Train Loss 329.86 Test MSE 42.73541254350904 Test RE 0.07283637156254806\n",
      "174 Train Loss 328.98547 Test MSE 42.553063607337684 Test RE 0.07268081166115876\n",
      "175 Train Loss 327.83337 Test MSE 42.06460629136403 Test RE 0.07226246409070095\n",
      "176 Train Loss 325.34543 Test MSE 41.11050912160311 Test RE 0.07143824551234472\n",
      "177 Train Loss 324.06134 Test MSE 41.23130486230368 Test RE 0.07154312266243372\n",
      "178 Train Loss 322.09622 Test MSE 39.05736218739691 Test RE 0.06963150898428824\n",
      "179 Train Loss 319.98517 Test MSE 35.3615860856838 Test RE 0.06625523832713924\n",
      "180 Train Loss 317.125 Test MSE 33.86805739284793 Test RE 0.06484096891715153\n",
      "181 Train Loss 315.5134 Test MSE 35.02849802158504 Test RE 0.06594245478143274\n",
      "182 Train Loss 314.9676 Test MSE 34.48291779921686 Test RE 0.06542690186241734\n",
      "183 Train Loss 314.10336 Test MSE 34.291757617330404 Test RE 0.06524529889766778\n",
      "184 Train Loss 312.94284 Test MSE 32.117329357405126 Test RE 0.06314283325350735\n",
      "185 Train Loss 311.954 Test MSE 29.526309937591385 Test RE 0.06054230330349259\n",
      "186 Train Loss 310.27863 Test MSE 28.66866650231961 Test RE 0.059656545136305195\n",
      "187 Train Loss 309.1795 Test MSE 29.215663591115664 Test RE 0.06022297835092157\n",
      "188 Train Loss 307.11966 Test MSE 29.118912972253067 Test RE 0.06012317842231386\n",
      "189 Train Loss 306.0116 Test MSE 29.69360284447661 Test RE 0.06071357414579223\n",
      "190 Train Loss 304.72348 Test MSE 29.317777491844737 Test RE 0.060328131518104997\n",
      "191 Train Loss 302.9166 Test MSE 30.427042733238917 Test RE 0.061458820984324584\n",
      "192 Train Loss 300.077 Test MSE 29.696449704359228 Test RE 0.06071648451838762\n",
      "193 Train Loss 297.7479 Test MSE 27.155230946477957 Test RE 0.0580605442726208\n",
      "194 Train Loss 295.07623 Test MSE 25.407814217206795 Test RE 0.056161410283863\n",
      "195 Train Loss 292.07742 Test MSE 23.64480289674969 Test RE 0.054177904258994755\n",
      "196 Train Loss 288.10904 Test MSE 20.641200250877027 Test RE 0.050619963298221965\n",
      "197 Train Loss 285.86545 Test MSE 20.75603321975467 Test RE 0.05076057475447283\n",
      "198 Train Loss 284.85965 Test MSE 20.597977803028336 Test RE 0.050566936699298494\n",
      "199 Train Loss 283.88208 Test MSE 18.905646528130436 Test RE 0.048445129285477596\n",
      "Training time: 31.41\n",
      "Training time: 31.41\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 16456.924 Test MSE 10436.146960007665 Test RE 1.1382153688626433\n",
      "1 Train Loss 14950.006 Test MSE 10847.430298096184 Test RE 1.1604268966832811\n",
      "2 Train Loss 13827.881 Test MSE 10391.683735728995 Test RE 1.1357880963645985\n",
      "3 Train Loss 13236.781 Test MSE 10008.152314062225 Test RE 1.114631482612487\n",
      "4 Train Loss 12133.445 Test MSE 8388.088543879712 Test RE 1.0204361967707352\n",
      "5 Train Loss 11403.672 Test MSE 7422.561499204153 Test RE 0.9599116325737439\n",
      "6 Train Loss 10726.203 Test MSE 6461.943116632341 Test RE 0.895645024590719\n",
      "7 Train Loss 10416.3125 Test MSE 5675.9467202745755 Test RE 0.8394087798023101\n",
      "8 Train Loss 10005.326 Test MSE 4699.244402482646 Test RE 0.7637801526448589\n",
      "9 Train Loss 9810.35 Test MSE 3900.6291964124784 Test RE 0.6958597006751204\n",
      "10 Train Loss 9490.383 Test MSE 3464.6956345065564 Test RE 0.655823382476132\n",
      "11 Train Loss 9228.48 Test MSE 3481.5086769681006 Test RE 0.6574127056129203\n",
      "12 Train Loss 8712.965 Test MSE 2484.662277971393 Test RE 0.5553771859816649\n",
      "13 Train Loss 8100.3687 Test MSE 2063.8645609299306 Test RE 0.5061683073173482\n",
      "14 Train Loss 7810.897 Test MSE 2097.0335822213247 Test RE 0.5102194908543722\n",
      "15 Train Loss 7623.41 Test MSE 2021.4767744658266 Test RE 0.5009434821513292\n",
      "16 Train Loss 7458.029 Test MSE 2125.2160706702175 Test RE 0.5136365237244175\n",
      "17 Train Loss 7353.0635 Test MSE 2260.464080575696 Test RE 0.5297282785253603\n",
      "18 Train Loss 7276.371 Test MSE 2278.3731933799563 Test RE 0.5318225933423238\n",
      "19 Train Loss 7099.69 Test MSE 2206.215163593858 Test RE 0.5233331974935528\n",
      "20 Train Loss 6878.3276 Test MSE 1873.3269116944912 Test RE 0.48223767680171997\n",
      "21 Train Loss 6717.6313 Test MSE 1725.1433183092352 Test RE 0.46277185983506464\n",
      "22 Train Loss 6595.8677 Test MSE 1693.8195322182598 Test RE 0.4585512911728525\n",
      "23 Train Loss 6476.8765 Test MSE 1622.2044878864401 Test RE 0.4487527795889289\n",
      "24 Train Loss 6368.391 Test MSE 1511.0949146846763 Test RE 0.4331120076900581\n",
      "25 Train Loss 6215.2104 Test MSE 1518.2039934661893 Test RE 0.4341296189793618\n",
      "26 Train Loss 5888.5786 Test MSE 1606.9231350100224 Test RE 0.4466341268931918\n",
      "27 Train Loss 5657.8433 Test MSE 1672.0681052103375 Test RE 0.45559750149220624\n",
      "28 Train Loss 5388.3486 Test MSE 1748.1114871659274 Test RE 0.4658422939178348\n",
      "29 Train Loss 5184.032 Test MSE 1677.4712180640097 Test RE 0.45633301557760086\n",
      "30 Train Loss 5022.523 Test MSE 1634.250630885249 Test RE 0.45041586886523005\n",
      "31 Train Loss 4823.5938 Test MSE 1714.2569660262461 Test RE 0.4613094101915061\n",
      "32 Train Loss 4694.438 Test MSE 1723.3720170066786 Test RE 0.4625342219218447\n",
      "33 Train Loss 4550.63 Test MSE 1763.2916223243576 Test RE 0.46786054717844483\n",
      "34 Train Loss 4468.095 Test MSE 1806.81769669203 Test RE 0.47359981070639684\n",
      "35 Train Loss 4351.943 Test MSE 1812.6050739901286 Test RE 0.47435769277620315\n",
      "36 Train Loss 4213.927 Test MSE 1726.5452308529973 Test RE 0.46295985404961926\n",
      "37 Train Loss 4135.005 Test MSE 1641.208916637002 Test RE 0.45137373702912137\n",
      "38 Train Loss 4065.6687 Test MSE 1623.749817001152 Test RE 0.44896647202644646\n",
      "39 Train Loss 4001.7327 Test MSE 1646.9108543782913 Test RE 0.45215714534001805\n",
      "40 Train Loss 3957.3035 Test MSE 1609.6430585830472 Test RE 0.44701195985939074\n",
      "41 Train Loss 3731.0469 Test MSE 1527.9646901237286 Test RE 0.4355229161442217\n",
      "42 Train Loss 3318.1326 Test MSE 1526.797121235616 Test RE 0.4353564855361045\n",
      "43 Train Loss 3157.6597 Test MSE 1502.1994355991153 Test RE 0.4318353090614072\n",
      "44 Train Loss 3030.5234 Test MSE 1461.353921718388 Test RE 0.42592394568688885\n",
      "45 Train Loss 2976.0906 Test MSE 1454.012498091753 Test RE 0.42485273866625517\n",
      "46 Train Loss 2927.6003 Test MSE 1471.0699203647364 Test RE 0.4273375049639028\n",
      "47 Train Loss 2859.3503 Test MSE 1523.1742317564822 Test RE 0.4348396568193533\n",
      "48 Train Loss 2808.391 Test MSE 1529.0860815476497 Test RE 0.4356827045509824\n",
      "49 Train Loss 2728.6975 Test MSE 1531.233244773612 Test RE 0.43598849299513864\n",
      "50 Train Loss 2671.5278 Test MSE 1524.1358290605956 Test RE 0.4349768947858263\n",
      "51 Train Loss 2607.8484 Test MSE 1535.0191219515327 Test RE 0.4365271372219776\n",
      "52 Train Loss 2556.8743 Test MSE 1527.1049173562797 Test RE 0.43540036637745994\n",
      "53 Train Loss 2523.064 Test MSE 1515.870559049339 Test RE 0.4337958685279096\n",
      "54 Train Loss 2479.068 Test MSE 1550.352321150208 Test RE 0.43870193932989165\n",
      "55 Train Loss 2435.9985 Test MSE 1536.7916733988368 Test RE 0.4367791026702831\n",
      "56 Train Loss 2396.5781 Test MSE 1496.2216645387675 Test RE 0.430975241563751\n",
      "57 Train Loss 2344.1045 Test MSE 1502.6887082693077 Test RE 0.43190562862365106\n",
      "58 Train Loss 2316.7344 Test MSE 1525.2250864010878 Test RE 0.43513229994840014\n",
      "59 Train Loss 2256.4812 Test MSE 1547.536726233065 Test RE 0.438303394993119\n",
      "60 Train Loss 2212.1528 Test MSE 1517.281275127701 Test RE 0.4339976735208014\n",
      "61 Train Loss 2183.8599 Test MSE 1517.4084570317964 Test RE 0.43401586246663765\n",
      "62 Train Loss 2124.6768 Test MSE 1510.8656871027704 Test RE 0.4330791556889404\n",
      "63 Train Loss 1994.1793 Test MSE 1632.0020260748681 Test RE 0.45010589318077115\n",
      "64 Train Loss 1927.2627 Test MSE 1739.6698896034732 Test RE 0.46471616090666135\n",
      "65 Train Loss 1851.1879 Test MSE 1748.6971611466538 Test RE 0.46592032351281043\n",
      "66 Train Loss 1741.6206 Test MSE 1785.3449561116322 Test RE 0.4707772013617717\n",
      "67 Train Loss 1629.908 Test MSE 1764.487519429417 Test RE 0.46801917614003546\n",
      "68 Train Loss 1544.1106 Test MSE 1743.7153288487254 Test RE 0.4652561740854491\n",
      "69 Train Loss 1502.4626 Test MSE 1735.882970813736 Test RE 0.4642100875638053\n",
      "70 Train Loss 1478.2075 Test MSE 1753.6590580347586 Test RE 0.4665808755569187\n",
      "71 Train Loss 1455.3717 Test MSE 1808.1508836248827 Test RE 0.4737745047698165\n",
      "72 Train Loss 1435.7229 Test MSE 1818.6445930431453 Test RE 0.47514730489544843\n",
      "73 Train Loss 1416.4318 Test MSE 1769.9963890675836 Test RE 0.4687492032317951\n",
      "74 Train Loss 1399.1085 Test MSE 1760.0506070695333 Test RE 0.4674303742647769\n",
      "75 Train Loss 1354.9558 Test MSE 1749.8112473599165 Test RE 0.46606871763492447\n",
      "76 Train Loss 1300.1985 Test MSE 1689.2041755830858 Test RE 0.4579261297079934\n",
      "77 Train Loss 1282.5417 Test MSE 1660.9626781048767 Test RE 0.45408200281848676\n",
      "78 Train Loss 1251.2413 Test MSE 1593.984393023718 Test RE 0.44483237191689057\n",
      "79 Train Loss 1167.7081 Test MSE 1468.1169503597982 Test RE 0.4269083789471588\n",
      "80 Train Loss 1107.7896 Test MSE 1438.2517335757393 Test RE 0.42254386982208253\n",
      "81 Train Loss 1086.1519 Test MSE 1440.3738787010486 Test RE 0.4228554873455386\n",
      "82 Train Loss 1056.0767 Test MSE 1403.1832653366207 Test RE 0.41736069857319574\n",
      "83 Train Loss 1030.8462 Test MSE 1373.0713536960423 Test RE 0.4128581913164108\n",
      "84 Train Loss 1009.28485 Test MSE 1327.3142754863425 Test RE 0.40592073384025606\n",
      "85 Train Loss 958.779 Test MSE 1212.528890530427 Test RE 0.3879720145797518\n",
      "86 Train Loss 907.8836 Test MSE 1069.401989304695 Test RE 0.3643550943805428\n",
      "87 Train Loss 868.505 Test MSE 972.3371695021382 Test RE 0.3474263840224101\n",
      "88 Train Loss 825.10156 Test MSE 930.9468303471848 Test RE 0.3399513664269259\n",
      "89 Train Loss 800.75134 Test MSE 894.2575549728556 Test RE 0.33318516883825794\n",
      "90 Train Loss 782.1326 Test MSE 858.9931100234144 Test RE 0.3265496273835499\n",
      "91 Train Loss 758.5918 Test MSE 836.8091886040041 Test RE 0.322305393056202\n",
      "92 Train Loss 720.06635 Test MSE 786.1100306465723 Test RE 0.31238920744304516\n",
      "93 Train Loss 691.04285 Test MSE 732.9325604685896 Test RE 0.3016382136477124\n",
      "94 Train Loss 634.64777 Test MSE 586.9044993098332 Test RE 0.26992186862209583\n",
      "95 Train Loss 599.3136 Test MSE 479.80129569544374 Test RE 0.24405351138705444\n",
      "96 Train Loss 558.7069 Test MSE 384.84609593351445 Test RE 0.2185736954325799\n",
      "97 Train Loss 526.3402 Test MSE 322.7415732384931 Test RE 0.20016208129716012\n",
      "98 Train Loss 506.5324 Test MSE 301.0928607307774 Test RE 0.1933323728912718\n",
      "99 Train Loss 494.12686 Test MSE 288.98384204157253 Test RE 0.18940486619225091\n",
      "100 Train Loss 471.87338 Test MSE 266.9653677693178 Test RE 0.1820462827177079\n",
      "101 Train Loss 439.8885 Test MSE 230.6907119685439 Test RE 0.16922690319091183\n",
      "102 Train Loss 422.67413 Test MSE 218.05723048876104 Test RE 0.16452791659012853\n",
      "103 Train Loss 402.31622 Test MSE 217.50611770320617 Test RE 0.1643198730361279\n",
      "104 Train Loss 385.54355 Test MSE 186.47530196962646 Test RE 0.1521475669920093\n",
      "105 Train Loss 368.59232 Test MSE 184.00498664164422 Test RE 0.15113642625389404\n",
      "106 Train Loss 359.55084 Test MSE 199.02712126840015 Test RE 0.1571847769200674\n",
      "107 Train Loss 343.95187 Test MSE 196.212448409492 Test RE 0.15606935333244143\n",
      "108 Train Loss 328.2202 Test MSE 185.00867801617252 Test RE 0.15154806734799608\n",
      "109 Train Loss 312.36368 Test MSE 183.52793222490553 Test RE 0.15094037968531823\n",
      "110 Train Loss 306.1447 Test MSE 183.11993741409012 Test RE 0.15077251108155848\n",
      "111 Train Loss 298.71817 Test MSE 175.2983280641464 Test RE 0.14751739660676474\n",
      "112 Train Loss 289.0851 Test MSE 170.878405738035 Test RE 0.1456457928681633\n",
      "113 Train Loss 278.54703 Test MSE 163.02321887735908 Test RE 0.1422587814546257\n",
      "114 Train Loss 261.35632 Test MSE 146.25896566368485 Test RE 0.13474591295091337\n",
      "115 Train Loss 254.7477 Test MSE 143.78267378766927 Test RE 0.13360036052608618\n",
      "116 Train Loss 249.09279 Test MSE 143.31536376051304 Test RE 0.1333830756562276\n",
      "117 Train Loss 231.66508 Test MSE 128.56615351686435 Test RE 0.1263332526017825\n",
      "118 Train Loss 203.43616 Test MSE 98.956266552661 Test RE 0.11083476460076923\n",
      "119 Train Loss 180.67273 Test MSE 73.40668723050776 Test RE 0.09546016154369166\n",
      "120 Train Loss 166.79747 Test MSE 61.33672087881969 Test RE 0.08725988365089411\n",
      "121 Train Loss 155.97195 Test MSE 48.399720237738705 Test RE 0.07751321992676634\n",
      "122 Train Loss 145.58104 Test MSE 26.238839297579414 Test RE 0.05707246917113174\n",
      "123 Train Loss 140.7302 Test MSE 25.445647128547293 Test RE 0.05620320764734348\n",
      "124 Train Loss 138.11205 Test MSE 22.18191647692703 Test RE 0.05247517374342585\n",
      "125 Train Loss 132.86038 Test MSE 14.396112476358272 Test RE 0.04227435284184681\n",
      "126 Train Loss 128.87099 Test MSE 14.832855632853828 Test RE 0.04291081244381063\n",
      "127 Train Loss 125.47411 Test MSE 12.440356008552868 Test RE 0.03929802791128549\n",
      "128 Train Loss 121.22269 Test MSE 11.031671336876547 Test RE 0.03700624413790755\n",
      "129 Train Loss 118.9007 Test MSE 13.77742876189585 Test RE 0.04135599169224659\n",
      "130 Train Loss 116.30029 Test MSE 17.314882445642162 Test RE 0.0463622095993746\n",
      "131 Train Loss 114.31429 Test MSE 16.151119888783516 Test RE 0.04477707008253442\n",
      "132 Train Loss 112.81661 Test MSE 14.940782763006958 Test RE 0.04306664376119185\n",
      "133 Train Loss 110.70984 Test MSE 15.2226233935953 Test RE 0.04347094726504833\n",
      "134 Train Loss 106.417114 Test MSE 15.352144768749993 Test RE 0.043655491375296965\n",
      "135 Train Loss 103.79327 Test MSE 12.925566388044004 Test RE 0.04005706670619169\n",
      "136 Train Loss 102.18604 Test MSE 13.754693267542729 Test RE 0.041321854802424764\n",
      "137 Train Loss 101.18755 Test MSE 14.017266441151657 Test RE 0.04171440147230925\n",
      "138 Train Loss 98.59124 Test MSE 12.068292612702033 Test RE 0.03870590873077484\n",
      "139 Train Loss 97.105064 Test MSE 10.670434808636719 Test RE 0.036395308984836665\n",
      "140 Train Loss 95.99658 Test MSE 9.898843309028825 Test RE 0.03505472602969694\n",
      "141 Train Loss 93.95789 Test MSE 8.246685367360314 Test RE 0.03199588042346861\n",
      "142 Train Loss 91.44144 Test MSE 6.533160982348114 Test RE 0.02847842927748881\n",
      "143 Train Loss 88.58278 Test MSE 6.538510354431123 Test RE 0.028490086004091145\n",
      "144 Train Loss 86.476524 Test MSE 7.984872359056671 Test RE 0.031483886743123364\n",
      "145 Train Loss 85.2613 Test MSE 8.18646629292388 Test RE 0.03187884597091727\n",
      "146 Train Loss 83.5141 Test MSE 8.682922131980604 Test RE 0.032831241484536366\n",
      "147 Train Loss 80.92615 Test MSE 10.168768385247363 Test RE 0.0355294537209138\n",
      "148 Train Loss 79.54834 Test MSE 8.821181214776772 Test RE 0.03309159681787767\n",
      "149 Train Loss 77.511246 Test MSE 8.541382289988986 Test RE 0.03256255186983683\n",
      "150 Train Loss 74.582695 Test MSE 5.9332573724514726 Test RE 0.02713944400031767\n",
      "151 Train Loss 73.93269 Test MSE 6.464866831883772 Test RE 0.028329189143847425\n",
      "152 Train Loss 73.27593 Test MSE 6.385906766949537 Test RE 0.02815565526883827\n",
      "153 Train Loss 72.60309 Test MSE 6.266267646180494 Test RE 0.027890662003654792\n",
      "154 Train Loss 72.04927 Test MSE 7.075757677148558 Test RE 0.029637449567684434\n",
      "155 Train Loss 71.71601 Test MSE 7.3307809385588625 Test RE 0.030166815927600184\n",
      "156 Train Loss 71.25937 Test MSE 8.242034846142722 Test RE 0.03198685749499648\n",
      "157 Train Loss 70.858795 Test MSE 9.09066644521615 Test RE 0.0335932648394457\n",
      "158 Train Loss 70.24605 Test MSE 9.934781622285607 Test RE 0.03511830246514441\n",
      "159 Train Loss 69.42414 Test MSE 8.69043984633186 Test RE 0.03284545113026705\n",
      "160 Train Loss 68.772415 Test MSE 7.459756603685001 Test RE 0.030431032028809212\n",
      "161 Train Loss 68.408745 Test MSE 7.171532400754874 Test RE 0.029837355914040024\n",
      "162 Train Loss 67.83371 Test MSE 5.916563839395198 Test RE 0.027101237978021595\n",
      "163 Train Loss 67.46311 Test MSE 5.692894735870247 Test RE 0.02658403678066583\n",
      "164 Train Loss 67.23462 Test MSE 6.281693851408532 Test RE 0.027924971311184363\n",
      "165 Train Loss 66.91803 Test MSE 5.997028479728566 Test RE 0.027284902612173364\n",
      "166 Train Loss 66.42026 Test MSE 6.2562516915085205 Test RE 0.02786836297815398\n",
      "167 Train Loss 65.8508 Test MSE 5.925956632230469 Test RE 0.02712274162196318\n",
      "168 Train Loss 65.338745 Test MSE 4.694852116885764 Test RE 0.024141558919264977\n",
      "169 Train Loss 64.75733 Test MSE 4.798210649464422 Test RE 0.02440585392032247\n",
      "170 Train Loss 64.34529 Test MSE 5.143038950055289 Test RE 0.025267615469874233\n",
      "171 Train Loss 64.15791 Test MSE 4.8632044472921265 Test RE 0.024570591755863066\n",
      "172 Train Loss 63.91477 Test MSE 4.783092338457637 Test RE 0.024367374326610645\n",
      "173 Train Loss 63.698994 Test MSE 4.922630249853959 Test RE 0.02472025579937837\n",
      "174 Train Loss 63.16061 Test MSE 5.225712923349085 Test RE 0.02546989334143441\n",
      "175 Train Loss 62.104496 Test MSE 6.7218141517026 Test RE 0.02888667815484276\n",
      "176 Train Loss 61.15092 Test MSE 8.256984302951503 Test RE 0.03201585333859743\n",
      "177 Train Loss 60.78318 Test MSE 8.450323130316479 Test RE 0.03238851307525219\n",
      "178 Train Loss 60.587387 Test MSE 8.556251997278414 Test RE 0.032590883646091355\n",
      "179 Train Loss 60.447014 Test MSE 8.567533921245019 Test RE 0.03261236307111945\n",
      "180 Train Loss 60.2245 Test MSE 8.995815271098147 Test RE 0.033417550780106456\n",
      "181 Train Loss 59.875618 Test MSE 9.803260900452868 Test RE 0.03488507273568462\n",
      "182 Train Loss 59.564667 Test MSE 8.844755429284364 Test RE 0.033135785225123345\n",
      "183 Train Loss 59.26718 Test MSE 7.550272987778944 Test RE 0.030615099798942426\n",
      "184 Train Loss 58.93563 Test MSE 7.448282218468435 Test RE 0.030407618948487748\n",
      "185 Train Loss 58.54658 Test MSE 7.3170535176354194 Test RE 0.030138557913253355\n",
      "186 Train Loss 58.290592 Test MSE 7.199134380529971 Test RE 0.029894720165175925\n",
      "187 Train Loss 58.048504 Test MSE 7.997181499120602 Test RE 0.03150814450928609\n",
      "188 Train Loss 57.739895 Test MSE 7.258923902356398 Test RE 0.030018602783964128\n",
      "189 Train Loss 57.445675 Test MSE 6.639219023142609 Test RE 0.028708655267143328\n",
      "190 Train Loss 57.094666 Test MSE 7.084308114922348 Test RE 0.02965535130126119\n",
      "191 Train Loss 56.65883 Test MSE 7.254945301301158 Test RE 0.030010375089617142\n",
      "192 Train Loss 56.363102 Test MSE 7.59312099480259 Test RE 0.030701847665940956\n",
      "193 Train Loss 56.001343 Test MSE 8.304675651469658 Test RE 0.032108180073176576\n",
      "194 Train Loss 55.417244 Test MSE 8.287542743741385 Test RE 0.03207504268611457\n",
      "195 Train Loss 55.10527 Test MSE 7.618771779377801 Test RE 0.030753661834602406\n",
      "196 Train Loss 54.6922 Test MSE 7.807108839657214 Test RE 0.031131458614067475\n",
      "197 Train Loss 54.259117 Test MSE 8.082182819673271 Test RE 0.03167515052178042\n",
      "198 Train Loss 54.03317 Test MSE 7.785463390455018 Test RE 0.031088272196470958\n",
      "199 Train Loss 53.881714 Test MSE 8.226077233094077 Test RE 0.0319558772086016\n",
      "Training time: 24.95\n",
      "Training time: 24.95\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 15891.688 Test MSE 6721.257108441754 Test RE 0.9134391189097033\n",
      "1 Train Loss 12381.03 Test MSE 6166.014030418097 Test RE 0.8748963539489114\n",
      "2 Train Loss 9895.438 Test MSE 5507.140648258267 Test RE 0.826832304847005\n",
      "3 Train Loss 9319.617 Test MSE 5323.86757619097 Test RE 0.8129577481258361\n",
      "4 Train Loss 8601.4 Test MSE 5076.130399667126 Test RE 0.7938176252510718\n",
      "5 Train Loss 8331.095 Test MSE 4952.444210486356 Test RE 0.7840868102344205\n",
      "6 Train Loss 8037.97 Test MSE 4754.6112382988595 Test RE 0.7682664332890373\n",
      "7 Train Loss 7818.726 Test MSE 4497.37073184282 Test RE 0.7471945525165382\n",
      "8 Train Loss 7549.264 Test MSE 3956.4902808688657 Test RE 0.7008247067315394\n",
      "9 Train Loss 7407.6553 Test MSE 3752.881568915277 Test RE 0.6825536321628608\n",
      "10 Train Loss 7260.6304 Test MSE 3652.717329436373 Test RE 0.6733833670532421\n",
      "11 Train Loss 7130.5864 Test MSE 3523.010291745697 Test RE 0.6613194688952311\n",
      "12 Train Loss 6989.744 Test MSE 3477.346941710355 Test RE 0.6570196582283067\n",
      "13 Train Loss 6784.3584 Test MSE 3245.6255242616053 Test RE 0.6347512391883198\n",
      "14 Train Loss 6400.3843 Test MSE 3234.601588004019 Test RE 0.633672339440458\n",
      "15 Train Loss 5895.705 Test MSE 3011.8187991508917 Test RE 0.6114610140642579\n",
      "16 Train Loss 5559.922 Test MSE 2874.9504640019013 Test RE 0.5974059385253297\n",
      "17 Train Loss 5282.4614 Test MSE 2704.8184416557237 Test RE 0.5794599328612816\n",
      "18 Train Loss 4909.2397 Test MSE 2522.3548440176837 Test RE 0.5595738924788338\n",
      "19 Train Loss 4402.7427 Test MSE 2437.849144164142 Test RE 0.5501204203698988\n",
      "20 Train Loss 4230.137 Test MSE 2264.573301820652 Test RE 0.5302095474699896\n",
      "21 Train Loss 3953.8337 Test MSE 2051.5647865617125 Test RE 0.5046577771298204\n",
      "22 Train Loss 3782.5273 Test MSE 1906.1184427129901 Test RE 0.4864400159603013\n",
      "23 Train Loss 3437.1462 Test MSE 1695.8859295157865 Test RE 0.45883091373984985\n",
      "24 Train Loss 3302.148 Test MSE 1615.6303555525915 Test RE 0.44784255057627254\n",
      "25 Train Loss 3081.493 Test MSE 1444.116860343447 Test RE 0.42340455083846956\n",
      "26 Train Loss 2943.6057 Test MSE 1391.8231459331753 Test RE 0.4156677968647475\n",
      "27 Train Loss 2647.125 Test MSE 1109.0900864525968 Test RE 0.37105455223599587\n",
      "28 Train Loss 2465.7522 Test MSE 1008.3555441716585 Test RE 0.35380274459850264\n",
      "29 Train Loss 2225.9458 Test MSE 869.0917714299537 Test RE 0.3284635416702316\n",
      "30 Train Loss 2014.3533 Test MSE 992.9787920056984 Test RE 0.3510947527623878\n",
      "31 Train Loss 1709.3909 Test MSE 1126.8338594166248 Test RE 0.3740109320737873\n",
      "32 Train Loss 1587.9027 Test MSE 1096.6578173714174 Test RE 0.3689690361554538\n",
      "33 Train Loss 1508.5522 Test MSE 1025.818852169007 Test RE 0.3568532779498285\n",
      "34 Train Loss 1470.2327 Test MSE 976.9256745823889 Test RE 0.34824517994239623\n",
      "35 Train Loss 1449.7092 Test MSE 931.2496489686291 Test RE 0.34000665166490346\n",
      "36 Train Loss 1413.3431 Test MSE 846.3885534034428 Test RE 0.32414493737405486\n",
      "37 Train Loss 1330.12 Test MSE 728.9251022632533 Test RE 0.30081244912588007\n",
      "38 Train Loss 1244.7673 Test MSE 661.2984181019414 Test RE 0.2865187806612588\n",
      "39 Train Loss 1170.2789 Test MSE 630.3543843349732 Test RE 0.2797349570157598\n",
      "40 Train Loss 1133.4957 Test MSE 589.0199965093627 Test RE 0.27040789771513596\n",
      "41 Train Loss 1097.8828 Test MSE 521.1786136082872 Test RE 0.25435931426627584\n",
      "42 Train Loss 1057.1434 Test MSE 440.6068210937785 Test RE 0.23387293208239568\n",
      "43 Train Loss 996.95935 Test MSE 388.1254872093403 Test RE 0.21950298658970147\n",
      "44 Train Loss 917.33844 Test MSE 320.8536560746004 Test RE 0.19957578608398127\n",
      "45 Train Loss 901.0417 Test MSE 321.8340021294665 Test RE 0.1998804485171873\n",
      "46 Train Loss 852.7884 Test MSE 313.0461712634842 Test RE 0.19713264570544636\n",
      "47 Train Loss 784.7954 Test MSE 246.89204965149662 Test RE 0.175068457359245\n",
      "48 Train Loss 763.1644 Test MSE 226.16749222406676 Test RE 0.16755964964836317\n",
      "49 Train Loss 744.77734 Test MSE 236.7294836488417 Test RE 0.17142751424094996\n",
      "50 Train Loss 712.70575 Test MSE 206.01696755342496 Test RE 0.15992112914381898\n",
      "51 Train Loss 693.0073 Test MSE 163.79845745679245 Test RE 0.14259662809955836\n",
      "52 Train Loss 679.84216 Test MSE 166.4250655561092 Test RE 0.14373539298007781\n",
      "53 Train Loss 651.93915 Test MSE 166.68626351847655 Test RE 0.14384814244017116\n",
      "54 Train Loss 631.7305 Test MSE 172.2360192653229 Test RE 0.14622321958286505\n",
      "55 Train Loss 621.4044 Test MSE 189.35670786338963 Test RE 0.15331854867699823\n",
      "56 Train Loss 614.1739 Test MSE 190.59452185138406 Test RE 0.15381884969850732\n",
      "57 Train Loss 604.15295 Test MSE 191.02045260036306 Test RE 0.15399062697475477\n",
      "58 Train Loss 588.487 Test MSE 201.20551501444578 Test RE 0.15804264615723948\n",
      "59 Train Loss 575.7391 Test MSE 190.1106950988277 Test RE 0.15362349003140985\n",
      "60 Train Loss 558.3724 Test MSE 178.39918647102152 Test RE 0.14881639752722817\n",
      "61 Train Loss 552.7607 Test MSE 168.0006681556385 Test RE 0.1444141860564677\n",
      "62 Train Loss 543.9716 Test MSE 161.184046316802 Test RE 0.14145404771704104\n",
      "63 Train Loss 533.9843 Test MSE 148.63131423431093 Test RE 0.13583431948345406\n",
      "64 Train Loss 527.1194 Test MSE 131.74416805853414 Test RE 0.12788513080064706\n",
      "65 Train Loss 518.2232 Test MSE 122.4466674160798 Test RE 0.12328999561844041\n",
      "66 Train Loss 508.1835 Test MSE 133.82974404305799 Test RE 0.12889339887097545\n",
      "67 Train Loss 465.0449 Test MSE 117.82219250759222 Test RE 0.12093942582182102\n",
      "68 Train Loss 443.65732 Test MSE 105.43517827508697 Test RE 0.11440555721719964\n",
      "69 Train Loss 437.18176 Test MSE 111.05666763145204 Test RE 0.11741583509857537\n",
      "70 Train Loss 423.73877 Test MSE 107.59807266759037 Test RE 0.11557305635334035\n",
      "71 Train Loss 411.63913 Test MSE 101.28481033800125 Test RE 0.11213121085870505\n",
      "72 Train Loss 405.1751 Test MSE 110.71983851148816 Test RE 0.1172376418104823\n",
      "73 Train Loss 393.88187 Test MSE 115.9201964083574 Test RE 0.11995929548445099\n",
      "74 Train Loss 385.5091 Test MSE 104.95719028864943 Test RE 0.11414593513741549\n",
      "75 Train Loss 378.16846 Test MSE 119.77810416585733 Test RE 0.12193912372082029\n",
      "76 Train Loss 365.5599 Test MSE 119.7553450214714 Test RE 0.12192753828963525\n",
      "77 Train Loss 346.1365 Test MSE 94.73976790294678 Test RE 0.10844774115351402\n",
      "78 Train Loss 334.31128 Test MSE 93.05780960759976 Test RE 0.10748076906272085\n",
      "79 Train Loss 328.58453 Test MSE 88.78451689925012 Test RE 0.10498396482491529\n",
      "80 Train Loss 316.73352 Test MSE 75.29453343871593 Test RE 0.0966798739745895\n",
      "81 Train Loss 305.65176 Test MSE 72.5099876115432 Test RE 0.09487532307986891\n",
      "82 Train Loss 301.13977 Test MSE 74.49054934730087 Test RE 0.09616232185437806\n",
      "83 Train Loss 290.47336 Test MSE 65.25021847595333 Test RE 0.09000058605302566\n",
      "84 Train Loss 274.9142 Test MSE 62.93649046408355 Test RE 0.08839050459532638\n",
      "85 Train Loss 253.77556 Test MSE 46.03821560941879 Test RE 0.0755985722645842\n",
      "86 Train Loss 239.39197 Test MSE 34.73190348005396 Test RE 0.06566268615914839\n",
      "87 Train Loss 223.4275 Test MSE 38.707351144517524 Test RE 0.0693188068012296\n",
      "88 Train Loss 214.47864 Test MSE 34.25691518621716 Test RE 0.06521214395408202\n",
      "89 Train Loss 207.11711 Test MSE 36.24966027123857 Test RE 0.06708204949468138\n",
      "90 Train Loss 199.66556 Test MSE 41.568606008489596 Test RE 0.07183516319902428\n",
      "91 Train Loss 192.72194 Test MSE 36.15946540912055 Test RE 0.06699854216701381\n",
      "92 Train Loss 186.43407 Test MSE 30.621276513302025 Test RE 0.06165467289396369\n",
      "93 Train Loss 181.3353 Test MSE 27.398603475967253 Test RE 0.05832014108193514\n",
      "94 Train Loss 172.03851 Test MSE 19.758430598540258 Test RE 0.049525694602319995\n",
      "95 Train Loss 159.84515 Test MSE 10.971091825822391 Test RE 0.03690449589508151\n",
      "96 Train Loss 151.59427 Test MSE 10.416686871587803 Test RE 0.035959956443638884\n",
      "97 Train Loss 148.40526 Test MSE 10.169997596312607 Test RE 0.03553160107427391\n",
      "98 Train Loss 142.20746 Test MSE 7.187460236075078 Test RE 0.029870471633265585\n",
      "99 Train Loss 135.46437 Test MSE 6.667505598905877 Test RE 0.028769747274047318\n",
      "100 Train Loss 130.54823 Test MSE 6.390414103049689 Test RE 0.0281655900064093\n",
      "101 Train Loss 126.759125 Test MSE 4.714965673535024 Test RE 0.024193216952648137\n",
      "102 Train Loss 117.97795 Test MSE 2.4416789674742456 Test RE 0.017409994481610413\n",
      "103 Train Loss 114.00427 Test MSE 2.226177873695147 Test RE 0.0166239522708904\n",
      "104 Train Loss 108.65594 Test MSE 1.8653001204294408 Test RE 0.015216988467698148\n",
      "105 Train Loss 106.06564 Test MSE 2.178318368448391 Test RE 0.01644428629225197\n",
      "106 Train Loss 102.18791 Test MSE 1.8988178321978333 Test RE 0.015353097331627394\n",
      "107 Train Loss 99.4613 Test MSE 1.9508181056547067 Test RE 0.015561904333643895\n",
      "108 Train Loss 97.811844 Test MSE 2.5010507005296376 Test RE 0.017620393391224756\n",
      "109 Train Loss 96.4149 Test MSE 2.914638719537778 Test RE 0.01902158565896852\n",
      "110 Train Loss 93.48483 Test MSE 2.7296034222412295 Test RE 0.018407895039091283\n",
      "111 Train Loss 88.91226 Test MSE 2.171206400951776 Test RE 0.01641741996140403\n",
      "112 Train Loss 84.761284 Test MSE 1.2451040004932954 Test RE 0.01243246274779854\n",
      "113 Train Loss 81.34381 Test MSE 0.9659760844281311 Test RE 0.010950590519907513\n",
      "114 Train Loss 78.38072 Test MSE 1.0447168461596623 Test RE 0.011388162387130932\n",
      "115 Train Loss 76.642845 Test MSE 1.0321740018704164 Test RE 0.011319592958747833\n",
      "116 Train Loss 75.58252 Test MSE 1.1290801094880165 Test RE 0.011839046618922024\n",
      "117 Train Loss 74.22025 Test MSE 1.3590907420297091 Test RE 0.012989085615962266\n",
      "118 Train Loss 72.62588 Test MSE 1.7886392341577055 Test RE 0.014901010775766338\n",
      "119 Train Loss 70.23422 Test MSE 2.1254733510959127 Test RE 0.0162435961865731\n",
      "120 Train Loss 69.26292 Test MSE 1.6076060835811632 Test RE 0.014126812235905282\n",
      "121 Train Loss 68.353516 Test MSE 1.8334774415863213 Test RE 0.015086626471610203\n",
      "122 Train Loss 66.59571 Test MSE 2.932295313718785 Test RE 0.019079114110950333\n",
      "123 Train Loss 64.824295 Test MSE 3.228177514446514 Test RE 0.020018570250047114\n",
      "124 Train Loss 63.918987 Test MSE 3.6327919948200447 Test RE 0.021236092985250594\n",
      "125 Train Loss 63.155457 Test MSE 3.9688126758416766 Test RE 0.02219650785557196\n",
      "126 Train Loss 62.45465 Test MSE 4.398744461223848 Test RE 0.023367847989814578\n",
      "127 Train Loss 61.754044 Test MSE 4.733087662670751 Test RE 0.024239665726260417\n",
      "128 Train Loss 61.47078 Test MSE 4.669246313824408 Test RE 0.024075634672506452\n",
      "129 Train Loss 61.334274 Test MSE 4.869278290953286 Test RE 0.024585930548055232\n",
      "130 Train Loss 61.129383 Test MSE 4.904452974348977 Test RE 0.024674572652466777\n",
      "131 Train Loss 60.764656 Test MSE 4.5599335771471425 Test RE 0.023792145691954023\n",
      "132 Train Loss 60.375168 Test MSE 4.803265647670564 Test RE 0.024418706531471233\n",
      "133 Train Loss 59.785046 Test MSE 5.095167658272777 Test RE 0.025149745345029104\n",
      "134 Train Loss 58.855995 Test MSE 5.730882996480537 Test RE 0.026672585949947394\n",
      "135 Train Loss 58.00006 Test MSE 6.640067881532287 Test RE 0.02871049048329605\n",
      "136 Train Loss 57.178467 Test MSE 5.848185904628154 Test RE 0.026944177895524862\n",
      "137 Train Loss 56.496124 Test MSE 4.942685875898673 Test RE 0.02477056185873242\n",
      "138 Train Loss 56.148827 Test MSE 5.098775659712564 Test RE 0.02515864831597885\n",
      "139 Train Loss 55.877243 Test MSE 4.563462608010712 Test RE 0.02380135053848136\n",
      "140 Train Loss 55.71295 Test MSE 4.46513304425438 Test RE 0.023543528638519117\n",
      "141 Train Loss 55.364567 Test MSE 5.024708161334857 Test RE 0.02497524594719485\n",
      "142 Train Loss 55.015415 Test MSE 5.144337803542707 Test RE 0.025270805885014038\n",
      "143 Train Loss 54.653553 Test MSE 5.544441992463348 Test RE 0.02623513325359319\n",
      "144 Train Loss 54.32971 Test MSE 5.462990111235602 Test RE 0.026041713672329242\n",
      "145 Train Loss 54.053085 Test MSE 5.644808879544954 Test RE 0.026471525741559775\n",
      "146 Train Loss 53.777916 Test MSE 5.704486752896278 Test RE 0.026611088562636942\n",
      "147 Train Loss 53.500767 Test MSE 5.220042106895341 Test RE 0.025456069936093242\n",
      "148 Train Loss 53.249374 Test MSE 5.524902050716085 Test RE 0.02618886300365704\n",
      "149 Train Loss 52.80627 Test MSE 5.396516995085527 Test RE 0.025882792276835185\n",
      "150 Train Loss 52.383747 Test MSE 5.660019783584877 Test RE 0.02650716777612782\n",
      "151 Train Loss 51.97136 Test MSE 6.067797266682915 Test RE 0.027445420134276078\n",
      "152 Train Loss 51.397408 Test MSE 4.524047312131715 Test RE 0.023698339748480676\n",
      "153 Train Loss 50.831856 Test MSE 4.302692837005186 Test RE 0.023111307933765448\n",
      "154 Train Loss 50.17553 Test MSE 4.977198794093185 Test RE 0.024856893178907893\n",
      "155 Train Loss 49.79234 Test MSE 5.065021381912063 Test RE 0.02507523396375062\n",
      "156 Train Loss 49.546913 Test MSE 5.517547759975978 Test RE 0.026171426979718682\n",
      "157 Train Loss 49.466606 Test MSE 5.407390372652914 Test RE 0.02590885461960514\n",
      "158 Train Loss 49.373898 Test MSE 5.337438771071917 Test RE 0.025740726807759195\n",
      "159 Train Loss 49.269573 Test MSE 5.809990724336141 Test RE 0.0268560459847397\n",
      "160 Train Loss 49.153713 Test MSE 6.051597971633561 Test RE 0.027408759912099803\n",
      "161 Train Loss 49.055466 Test MSE 6.18608757100618 Test RE 0.02771164993390964\n",
      "162 Train Loss 48.91695 Test MSE 6.904399535028942 Test RE 0.02927637555843967\n",
      "163 Train Loss 48.83764 Test MSE 6.795050367332377 Test RE 0.029043616425418816\n",
      "164 Train Loss 48.776093 Test MSE 6.717438253133666 Test RE 0.028877274015582485\n",
      "165 Train Loss 48.669365 Test MSE 7.10220468280552 Test RE 0.029692785743434567\n",
      "166 Train Loss 48.434822 Test MSE 6.835347832140587 Test RE 0.029129609461393913\n",
      "167 Train Loss 48.300606 Test MSE 6.390673619750724 Test RE 0.028166161907281075\n",
      "168 Train Loss 48.229477 Test MSE 6.27496087897951 Test RE 0.027910001744478382\n",
      "169 Train Loss 48.081577 Test MSE 6.2224383036945365 Test RE 0.027792950373540765\n",
      "170 Train Loss 47.90571 Test MSE 6.024106182399536 Test RE 0.027346431450267588\n",
      "171 Train Loss 47.6431 Test MSE 5.307698263253625 Test RE 0.025668912243478413\n",
      "172 Train Loss 47.381546 Test MSE 4.519260802906873 Test RE 0.023685799833096956\n",
      "173 Train Loss 47.18879 Test MSE 4.130409743280231 Test RE 0.022643883957519064\n",
      "174 Train Loss 47.014187 Test MSE 4.2645741266888475 Test RE 0.02300870554365245\n",
      "175 Train Loss 46.86524 Test MSE 4.805133507155845 Test RE 0.024423453955685164\n",
      "176 Train Loss 46.79028 Test MSE 5.19133010760054 Test RE 0.025385964900283404\n",
      "177 Train Loss 46.742504 Test MSE 5.428903014719036 Test RE 0.025960341068921915\n",
      "178 Train Loss 46.690796 Test MSE 5.271221225367407 Test RE 0.025580555661267615\n",
      "179 Train Loss 46.615177 Test MSE 5.157736387258924 Test RE 0.025303693774461948\n",
      "180 Train Loss 46.54105 Test MSE 5.101229847589134 Test RE 0.02516470237932636\n",
      "181 Train Loss 46.44532 Test MSE 5.106797139648977 Test RE 0.02517843054371022\n",
      "182 Train Loss 46.390182 Test MSE 5.01773411928845 Test RE 0.0249579077367498\n",
      "183 Train Loss 46.34792 Test MSE 5.028024618548417 Test RE 0.024983486791137818\n",
      "184 Train Loss 46.273834 Test MSE 4.920472348718334 Test RE 0.02471483697726126\n",
      "185 Train Loss 46.192284 Test MSE 5.040877546014036 Test RE 0.02501539852777238\n",
      "186 Train Loss 46.14735 Test MSE 5.042408680622802 Test RE 0.025019197373711093\n",
      "187 Train Loss 46.07281 Test MSE 4.710172951927867 Test RE 0.02418091772901246\n",
      "188 Train Loss 45.975037 Test MSE 4.77271044833274 Test RE 0.024340914788554446\n",
      "189 Train Loss 45.905384 Test MSE 4.7757343420204155 Test RE 0.02434862452545463\n",
      "190 Train Loss 45.76169 Test MSE 4.330219719650127 Test RE 0.02318511845408273\n",
      "191 Train Loss 45.616707 Test MSE 4.169454328866316 Test RE 0.02275065804869873\n",
      "192 Train Loss 45.498817 Test MSE 4.358286766085456 Test RE 0.023260136210144753\n",
      "193 Train Loss 45.434364 Test MSE 4.698285289343582 Test RE 0.02415038422264852\n",
      "194 Train Loss 45.374588 Test MSE 5.110851064059467 Test RE 0.025188422247181177\n",
      "195 Train Loss 45.338917 Test MSE 5.113226729134226 Test RE 0.025194275705064318\n",
      "196 Train Loss 45.30825 Test MSE 5.14898134082787 Test RE 0.02528220866076458\n",
      "197 Train Loss 45.25166 Test MSE 5.428251749891452 Test RE 0.02595878388839317\n",
      "198 Train Loss 45.19196 Test MSE 5.40290700536053 Test RE 0.0258981116372477\n",
      "199 Train Loss 45.136894 Test MSE 5.483002999382925 Test RE 0.026089370125717493\n",
      "Training time: 27.45\n",
      "Training time: 27.45\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 16854.246 Test MSE 10766.947366380227 Test RE 1.1561139655134378\n",
      "1 Train Loss 14169.627 Test MSE 8866.67500717865 Test RE 1.0491431455530482\n",
      "2 Train Loss 12326.434 Test MSE 8178.48482077904 Test RE 1.007606077498869\n",
      "3 Train Loss 10134.234 Test MSE 6920.343534938869 Test RE 0.926868620760012\n",
      "4 Train Loss 9292.279 Test MSE 6970.087992154797 Test RE 0.9301938904843098\n",
      "5 Train Loss 8836.081 Test MSE 6548.242303427595 Test RE 0.9016058541416069\n",
      "6 Train Loss 8278.734 Test MSE 4901.045636912143 Test RE 0.7800074048813487\n",
      "7 Train Loss 7938.1562 Test MSE 4126.157001977677 Test RE 0.7156937536875063\n",
      "8 Train Loss 7712.3965 Test MSE 3609.6212801729835 Test RE 0.6693991730441264\n",
      "9 Train Loss 7576.4507 Test MSE 2908.4136994217283 Test RE 0.6008726590443816\n",
      "10 Train Loss 7508.471 Test MSE 2741.2432880695774 Test RE 0.5833485772775188\n",
      "11 Train Loss 7468.6997 Test MSE 2619.6265802528296 Test RE 0.5702614927000034\n",
      "12 Train Loss 7435.1484 Test MSE 2765.357754010451 Test RE 0.5859087910965934\n",
      "13 Train Loss 7415.893 Test MSE 2911.5535068999216 Test RE 0.6011969106393669\n",
      "14 Train Loss 7401.515 Test MSE 2919.9827356117676 Test RE 0.6020665432481233\n",
      "15 Train Loss 7392.675 Test MSE 2888.987070431176 Test RE 0.5988625447670466\n",
      "16 Train Loss 7382.333 Test MSE 2872.2225264215035 Test RE 0.5971224427047777\n",
      "17 Train Loss 7375.0273 Test MSE 2876.7872588087894 Test RE 0.5975967482328475\n",
      "18 Train Loss 7369.382 Test MSE 2914.438928315005 Test RE 0.6014947373605889\n",
      "19 Train Loss 7366.2754 Test MSE 2882.457946718932 Test RE 0.5981854459730335\n",
      "20 Train Loss 7361.9863 Test MSE 2847.9793866111277 Test RE 0.5945970814313439\n",
      "21 Train Loss 7359.538 Test MSE 2885.2591670505317 Test RE 0.5984760386470769\n",
      "22 Train Loss 7356.997 Test MSE 2882.7423520155744 Test RE 0.5982149560155129\n",
      "23 Train Loss 7354.683 Test MSE 2873.7132255209235 Test RE 0.5972773775007058\n",
      "24 Train Loss 7352.659 Test MSE 2894.493561903568 Test RE 0.5994329975877812\n",
      "25 Train Loss 7350.6743 Test MSE 2913.0570332615075 Test RE 0.60135211966028\n",
      "26 Train Loss 7346.5166 Test MSE 2902.115253610731 Test RE 0.6002216830393677\n",
      "27 Train Loss 7343.2314 Test MSE 2879.7266242490637 Test RE 0.5979019683636325\n",
      "28 Train Loss 7341.3027 Test MSE 2930.669640451953 Test RE 0.6031672948612745\n",
      "29 Train Loss 7340.027 Test MSE 2944.6769648542 Test RE 0.6046070150803576\n",
      "30 Train Loss 7338.768 Test MSE 2922.624587256728 Test RE 0.6023388412422395\n",
      "31 Train Loss 7338.0312 Test MSE 2935.1645211275863 Test RE 0.6036296680715432\n",
      "32 Train Loss 7337.457 Test MSE 2938.8818444314006 Test RE 0.6040117891769762\n",
      "33 Train Loss 7336.503 Test MSE 2939.241966452493 Test RE 0.6040487949660314\n",
      "34 Train Loss 7335.8403 Test MSE 2935.6097457840783 Test RE 0.6036754475532365\n",
      "35 Train Loss 7334.363 Test MSE 2924.542264467521 Test RE 0.6025364208523902\n",
      "36 Train Loss 7332.854 Test MSE 2939.3479795375597 Test RE 0.604059688335751\n",
      "37 Train Loss 7330.4795 Test MSE 2993.639311910629 Test RE 0.6096128164275704\n",
      "38 Train Loss 7323.8774 Test MSE 3027.811797131689 Test RE 0.61308231797145\n",
      "39 Train Loss 6909.361 Test MSE 2769.6180139091935 Test RE 0.5863599376241126\n",
      "40 Train Loss 6118.1978 Test MSE 2454.2226278871217 Test RE 0.5519647334445511\n",
      "41 Train Loss 6019.6074 Test MSE 2306.5017960148803 Test RE 0.5350954411197933\n",
      "42 Train Loss 5975.741 Test MSE 2181.1359412283714 Test RE 0.5203501923714798\n",
      "43 Train Loss 5905.462 Test MSE 2104.1178448293267 Test RE 0.5110805837236495\n",
      "44 Train Loss 5838.774 Test MSE 1939.8522988439024 Test RE 0.4907255656162534\n",
      "45 Train Loss 5783.0747 Test MSE 1810.2718457983415 Test RE 0.4740522922350241\n",
      "46 Train Loss 5713.5137 Test MSE 1668.3735990159225 Test RE 0.45509389204150785\n",
      "47 Train Loss 5645.089 Test MSE 1625.2942188286936 Test RE 0.449179934665757\n",
      "48 Train Loss 5597.1445 Test MSE 1595.2298430811206 Test RE 0.4450061215246219\n",
      "49 Train Loss 5546.881 Test MSE 1490.3399339947912 Test RE 0.43012731361313605\n",
      "50 Train Loss 5491.5474 Test MSE 1385.6347555267605 Test RE 0.4147426864169451\n",
      "51 Train Loss 5460.265 Test MSE 1300.4028750926238 Test RE 0.40178462423713296\n",
      "52 Train Loss 5422.1006 Test MSE 1170.4544830357331 Test RE 0.3811813264940146\n",
      "53 Train Loss 5409.3447 Test MSE 1169.3856287279984 Test RE 0.3810072401171011\n",
      "54 Train Loss 5396.5415 Test MSE 1147.6934232720196 Test RE 0.37745683920596795\n",
      "55 Train Loss 5387.7085 Test MSE 1127.2607115005412 Test RE 0.3740817642680924\n",
      "56 Train Loss 5379.0547 Test MSE 1147.7528602116975 Test RE 0.37746661297850614\n",
      "57 Train Loss 5372.558 Test MSE 1152.6939221127845 Test RE 0.3782782349665904\n",
      "58 Train Loss 5363.483 Test MSE 1110.731774656235 Test RE 0.37132907034570745\n",
      "59 Train Loss 5350.8755 Test MSE 1101.442893756649 Test RE 0.36977312621511893\n",
      "60 Train Loss 5337.0327 Test MSE 1116.4212854399161 Test RE 0.37227888660851477\n",
      "61 Train Loss 5326.482 Test MSE 1087.0265242132036 Test RE 0.36734524533193363\n",
      "62 Train Loss 5314.2573 Test MSE 1050.6500347647182 Test RE 0.36114648473934413\n",
      "63 Train Loss 5300.2153 Test MSE 1032.5845443771339 Test RE 0.35802814015409595\n",
      "64 Train Loss 5289.395 Test MSE 993.2758180143554 Test RE 0.35114725966210125\n",
      "65 Train Loss 5281.054 Test MSE 966.480034359884 Test RE 0.34637839517185504\n",
      "66 Train Loss 5267.9404 Test MSE 934.0237547244059 Test RE 0.3405126991129846\n",
      "67 Train Loss 5244.2524 Test MSE 856.8346811026856 Test RE 0.3261391016904463\n",
      "68 Train Loss 5228.973 Test MSE 820.4961845140231 Test RE 0.3191483733684096\n",
      "69 Train Loss 5221.777 Test MSE 803.7935241454876 Test RE 0.3158832544818736\n",
      "70 Train Loss 5216.1924 Test MSE 788.6680286509328 Test RE 0.3128970510871387\n",
      "71 Train Loss 5207.7935 Test MSE 797.5055585312099 Test RE 0.314645273074506\n",
      "72 Train Loss 5203.731 Test MSE 781.8744696500964 Test RE 0.31154649422020964\n",
      "73 Train Loss 5197.7925 Test MSE 776.2186883532974 Test RE 0.310417644922872\n",
      "74 Train Loss 5192.067 Test MSE 776.8535363083714 Test RE 0.3105445600129076\n",
      "75 Train Loss 5186.8423 Test MSE 765.112926156643 Test RE 0.30818899169055286\n",
      "76 Train Loss 5183.7886 Test MSE 772.0225010681036 Test RE 0.30957745917914775\n",
      "77 Train Loss 5181.868 Test MSE 777.8487666467989 Test RE 0.3107434163164946\n",
      "78 Train Loss 5180.4463 Test MSE 763.2936792608981 Test RE 0.3078223755163936\n",
      "79 Train Loss 5179.3745 Test MSE 747.8081392400193 Test RE 0.3046838580734359\n",
      "80 Train Loss 5178.538 Test MSE 748.3757703033573 Test RE 0.3047994727653908\n",
      "81 Train Loss 5177.263 Test MSE 739.1710323651348 Test RE 0.3029192143449302\n",
      "82 Train Loss 5175.612 Test MSE 726.895424070045 Test RE 0.3003933538875248\n",
      "83 Train Loss 5174.919 Test MSE 728.0686171992098 Test RE 0.3006356702665487\n",
      "84 Train Loss 5173.998 Test MSE 727.7504459750425 Test RE 0.30056997311274253\n",
      "85 Train Loss 5172.356 Test MSE 719.9568653503882 Test RE 0.2989562182033089\n",
      "86 Train Loss 5171.765 Test MSE 719.4917018868774 Test RE 0.29885962493081447\n",
      "87 Train Loss 5170.326 Test MSE 718.3704982555 Test RE 0.29862667357103034\n",
      "88 Train Loss 5169.2925 Test MSE 713.3374639747839 Test RE 0.29757871842714523\n",
      "89 Train Loss 5168.036 Test MSE 726.2720491915588 Test RE 0.30026451978783236\n",
      "90 Train Loss 5166.806 Test MSE 729.4439943719697 Test RE 0.30091949814714797\n",
      "91 Train Loss 5165.405 Test MSE 719.1708848547238 Test RE 0.2987929876450548\n",
      "92 Train Loss 5164.55 Test MSE 721.5166813038014 Test RE 0.29927989341265776\n",
      "93 Train Loss 5163.9697 Test MSE 717.4569742259398 Test RE 0.29843673716205127\n",
      "94 Train Loss 5162.889 Test MSE 712.6034407510041 Test RE 0.29742557498441985\n",
      "95 Train Loss 5161.3135 Test MSE 719.9389881880686 Test RE 0.2989525065073213\n",
      "96 Train Loss 5159.366 Test MSE 713.0003909734062 Test RE 0.29750840275679985\n",
      "97 Train Loss 5158.595 Test MSE 710.2484408132691 Test RE 0.2969337047330342\n",
      "98 Train Loss 5158.033 Test MSE 710.5515072535607 Test RE 0.29699704949939537\n",
      "99 Train Loss 5157.377 Test MSE 707.1256865704416 Test RE 0.29628022040809415\n",
      "100 Train Loss 5156.592 Test MSE 711.563127621096 Test RE 0.2972083933635969\n",
      "101 Train Loss 5156.1274 Test MSE 705.8839418571007 Test RE 0.29601996536396835\n",
      "102 Train Loss 5155.814 Test MSE 702.831537895179 Test RE 0.2953792428649696\n",
      "103 Train Loss 5154.628 Test MSE 716.277190812868 Test RE 0.29819126211038716\n",
      "104 Train Loss 5152.5557 Test MSE 703.9421821849214 Test RE 0.2956125361578314\n",
      "105 Train Loss 5149.732 Test MSE 710.6535276997027 Test RE 0.2970183700396075\n",
      "106 Train Loss 5148.248 Test MSE 726.762567066417 Test RE 0.30036590070557956\n",
      "107 Train Loss 5138.7114 Test MSE 726.332256917964 Test RE 0.3002769654474318\n",
      "108 Train Loss 4553.1196 Test MSE 513.4160056285356 Test RE 0.25245795162104984\n",
      "109 Train Loss 3287.9805 Test MSE 567.4664869674428 Test RE 0.26541438766356273\n",
      "110 Train Loss 3023.6091 Test MSE 466.07891895539694 Test RE 0.24053821418168414\n",
      "111 Train Loss 2782.159 Test MSE 504.6074240504572 Test RE 0.2502828952699399\n",
      "112 Train Loss 2570.63 Test MSE 479.6730921142463 Test RE 0.2440209034879004\n",
      "113 Train Loss 2376.8281 Test MSE 515.110658112201 Test RE 0.2528742573398928\n",
      "114 Train Loss 2278.037 Test MSE 514.5907295945354 Test RE 0.25274660541790406\n",
      "115 Train Loss 2099.7837 Test MSE 313.89372158933554 Test RE 0.19739932665710294\n",
      "116 Train Loss 1934.8871 Test MSE 253.3937071626064 Test RE 0.17735860532458403\n",
      "117 Train Loss 1725.8315 Test MSE 150.70266716944002 Test RE 0.13677755044282439\n",
      "118 Train Loss 1678.736 Test MSE 110.91246574479862 Test RE 0.11733958085335836\n",
      "119 Train Loss 1644.0011 Test MSE 110.31692552041223 Test RE 0.11702413164926907\n",
      "120 Train Loss 1554.5587 Test MSE 82.80863634239151 Test RE 0.10138931030731851\n",
      "121 Train Loss 1468.9136 Test MSE 64.27986397875554 Test RE 0.08932886725349348\n",
      "122 Train Loss 1398.0258 Test MSE 52.997425447595745 Test RE 0.08111137033575756\n",
      "123 Train Loss 1356.5743 Test MSE 53.71358514378433 Test RE 0.08165756450484372\n",
      "124 Train Loss 1289.8228 Test MSE 43.57419578342931 Test RE 0.07354769096176823\n",
      "125 Train Loss 1242.8907 Test MSE 42.94013732605636 Test RE 0.07301062511182223\n",
      "126 Train Loss 1142.7657 Test MSE 52.70932058479321 Test RE 0.08089060087628823\n",
      "127 Train Loss 1072.2225 Test MSE 74.9615922154481 Test RE 0.09646588514729491\n",
      "128 Train Loss 1020.14276 Test MSE 82.8711612469963 Test RE 0.10142758023331219\n",
      "129 Train Loss 982.12616 Test MSE 105.3110912686876 Test RE 0.11433821526025598\n",
      "130 Train Loss 944.08923 Test MSE 117.30862085618004 Test RE 0.12067555833325389\n",
      "131 Train Loss 926.3463 Test MSE 100.87576777065817 Test RE 0.1119045587067124\n",
      "132 Train Loss 906.5368 Test MSE 106.22137674176246 Test RE 0.11483130896004237\n",
      "133 Train Loss 893.2779 Test MSE 100.00167010125601 Test RE 0.11141867228300613\n",
      "134 Train Loss 871.99286 Test MSE 96.95522824986297 Test RE 0.10970842212853121\n",
      "135 Train Loss 860.02216 Test MSE 105.50395231595078 Test RE 0.11444286378765901\n",
      "136 Train Loss 843.3789 Test MSE 97.85806542311057 Test RE 0.11021803531651256\n",
      "137 Train Loss 823.32007 Test MSE 94.10394626995571 Test RE 0.10808321893624334\n",
      "138 Train Loss 812.6548 Test MSE 93.77373422594964 Test RE 0.10789341953554608\n",
      "139 Train Loss 804.25226 Test MSE 82.36288599545742 Test RE 0.10111605798981303\n",
      "140 Train Loss 794.7844 Test MSE 80.74552731381408 Test RE 0.10011832839391452\n",
      "141 Train Loss 787.2097 Test MSE 76.44234156216011 Test RE 0.09741399250613686\n",
      "142 Train Loss 779.6726 Test MSE 65.35812147014337 Test RE 0.09007497140680136\n",
      "143 Train Loss 770.02234 Test MSE 56.97352981809594 Test RE 0.08409901630443252\n",
      "144 Train Loss 750.6742 Test MSE 48.79963325156205 Test RE 0.0778327959016013\n",
      "145 Train Loss 727.384 Test MSE 43.05264459362866 Test RE 0.0731062099535231\n",
      "146 Train Loss 675.867 Test MSE 39.378602427034856 Test RE 0.06991727631972003\n",
      "147 Train Loss 649.738 Test MSE 34.43974512485991 Test RE 0.06538593173603918\n",
      "148 Train Loss 623.6325 Test MSE 41.305079652197676 Test RE 0.07160709977843782\n",
      "149 Train Loss 614.0241 Test MSE 48.977247606746374 Test RE 0.07797430993448125\n",
      "150 Train Loss 597.20825 Test MSE 59.79833478089616 Test RE 0.0861586523789773\n",
      "151 Train Loss 577.4576 Test MSE 58.03903251564717 Test RE 0.08488177144405178\n",
      "152 Train Loss 560.8729 Test MSE 42.157758225298096 Test RE 0.0723424323387758\n",
      "153 Train Loss 536.60565 Test MSE 35.99746092732844 Test RE 0.06684828761263639\n",
      "154 Train Loss 511.99615 Test MSE 25.372720704802408 Test RE 0.0561226115474034\n",
      "155 Train Loss 488.87823 Test MSE 18.17742218576889 Test RE 0.04750294110540447\n",
      "156 Train Loss 474.57098 Test MSE 20.875142539221567 Test RE 0.05090601218860248\n",
      "157 Train Loss 461.2514 Test MSE 26.063310724305968 Test RE 0.05688125150300138\n",
      "158 Train Loss 451.16742 Test MSE 30.846073515357986 Test RE 0.06188056879499367\n",
      "159 Train Loss 438.97086 Test MSE 29.4146961086786 Test RE 0.060427765517535884\n",
      "160 Train Loss 431.0175 Test MSE 28.13641524737483 Test RE 0.059100170632246256\n",
      "161 Train Loss 421.2534 Test MSE 29.467512014104773 Test RE 0.06048199208113211\n",
      "162 Train Loss 408.83414 Test MSE 26.305883336384564 Test RE 0.05714533687081083\n",
      "163 Train Loss 405.603 Test MSE 23.223241050319118 Test RE 0.05369276476548059\n",
      "164 Train Loss 402.06592 Test MSE 23.91371737818841 Test RE 0.05448511833727985\n",
      "165 Train Loss 393.9014 Test MSE 21.981889248184444 Test RE 0.05223803837084125\n",
      "166 Train Loss 385.02512 Test MSE 16.267517860100053 Test RE 0.04493813022714404\n",
      "167 Train Loss 378.10034 Test MSE 14.85372432856548 Test RE 0.042940987952785385\n",
      "168 Train Loss 371.5034 Test MSE 14.67778912510834 Test RE 0.04268592277204617\n",
      "169 Train Loss 366.3066 Test MSE 13.365884741801535 Test RE 0.04073363881830779\n",
      "170 Train Loss 361.47968 Test MSE 12.172349897559483 Test RE 0.038872418907295696\n",
      "171 Train Loss 358.96237 Test MSE 11.785019395523383 Test RE 0.038248948735251635\n",
      "172 Train Loss 354.99765 Test MSE 11.187200388558862 Test RE 0.03726619576350781\n",
      "173 Train Loss 349.45273 Test MSE 11.854027370156151 Test RE 0.03836076992748822\n",
      "174 Train Loss 345.53662 Test MSE 12.533778724875592 Test RE 0.0394453091335002\n",
      "175 Train Loss 342.32388 Test MSE 12.350589993945926 Test RE 0.039155989612985644\n",
      "176 Train Loss 340.8915 Test MSE 12.86337133852739 Test RE 0.03996057749379236\n",
      "177 Train Loss 338.27072 Test MSE 13.031655854977028 Test RE 0.040221119420679935\n",
      "178 Train Loss 336.28662 Test MSE 11.415626693477334 Test RE 0.03764473389362438\n",
      "179 Train Loss 334.7105 Test MSE 10.98484525973877 Test RE 0.036927620511205975\n",
      "180 Train Loss 333.23563 Test MSE 11.263958631208103 Test RE 0.037393823665237115\n",
      "181 Train Loss 331.6993 Test MSE 11.155272588340505 Test RE 0.03721297968821676\n",
      "182 Train Loss 330.16928 Test MSE 11.873547065320698 Test RE 0.038392340739344784\n",
      "183 Train Loss 327.77444 Test MSE 13.0182554244909 Test RE 0.04020043444594224\n",
      "184 Train Loss 325.48654 Test MSE 12.985388504412734 Test RE 0.04014965577324077\n",
      "185 Train Loss 323.47238 Test MSE 11.892956356458884 Test RE 0.03842370726520556\n",
      "186 Train Loss 322.54404 Test MSE 11.326690996943178 Test RE 0.03749780779916031\n",
      "187 Train Loss 321.9022 Test MSE 10.959870353603035 Test RE 0.036885617704575234\n",
      "188 Train Loss 320.2287 Test MSE 9.275382973453887 Test RE 0.03393284532823792\n",
      "189 Train Loss 318.84958 Test MSE 9.33504610998561 Test RE 0.0340418055052397\n",
      "190 Train Loss 317.71533 Test MSE 9.53966986685227 Test RE 0.034412880403095245\n",
      "191 Train Loss 316.4254 Test MSE 8.945353751397128 Test RE 0.033323692035572464\n",
      "192 Train Loss 314.43463 Test MSE 10.211844942302045 Test RE 0.035604628464744374\n",
      "193 Train Loss 313.3012 Test MSE 10.652145910667285 Test RE 0.036364105216284866\n",
      "194 Train Loss 311.19968 Test MSE 8.917548525705 Test RE 0.033271860998400106\n",
      "195 Train Loss 307.61057 Test MSE 8.536711426256048 Test RE 0.0325536472197191\n",
      "196 Train Loss 304.89926 Test MSE 8.458004477975663 Test RE 0.03240323031824803\n",
      "197 Train Loss 302.96362 Test MSE 7.198637875919306 Test RE 0.029893689268852927\n",
      "198 Train Loss 301.31442 Test MSE 7.156450601424881 Test RE 0.029805965283177978\n",
      "199 Train Loss 299.95663 Test MSE 7.132184692272273 Test RE 0.0297553897228818\n",
      "Training time: 30.37\n",
      "Training time: 30.37\n"
     ]
    }
   ],
   "source": [
    " \n",
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers)\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "e199619a-d416-48f4-91f7-2c23d1e79435"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27261/2488343543.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_tanh_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_tanh_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_FODE_tanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tanh_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
