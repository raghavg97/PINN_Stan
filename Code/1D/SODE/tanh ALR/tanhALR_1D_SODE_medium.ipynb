{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(2.0*x) + np.exp(-3.0*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"medium\"\n",
    "label = \"1D_SODE_tanhALR_\" + level\n",
    "\n",
    "u_coeff = 6.0\n",
    "fo_val = -1.0\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "            \n",
    "        self.lambdas = torch.ones((2,),device = device)\n",
    "        \n",
    "        self.lambda_alpha = 0.1\n",
    "\n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.lambdas[1]*self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def lambda_update(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc1.backward()\n",
    "        bc1_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc1_grads.append(param.grad.view(-1))\n",
    "        bc1_grads = torch.cat(bc1_grads)\n",
    "        bc1_grads = torch.mean(torch.abs(bc1_grads))\n",
    "        \n",
    "        \n",
    "        loss_bc2 = self.lambdas[1]*self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_bc2.backward()\n",
    "        bc2_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc2_grads.append(param.grad.view(-1))\n",
    "        bc2_grads = torch.cat(bc2_grads)\n",
    "        bc2_grads = torch.mean(torch.abs(bc2_grads))\n",
    "        \n",
    "    \n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        loss_f.backward()\n",
    "        f_grads = []\n",
    "        for param in self.parameters():\n",
    "            f_grads.append(param.grad.view(-1))   \n",
    "        f_grads = torch.cat(f_grads)\n",
    "        f_grads = torch.max(torch.abs(f_grads))\n",
    "    \n",
    "        self.lambdas[0] = (1.0-self.lambda_alpha)*self.lambdas[0] + self.lambda_alpha*f_grads/bc1_grads\n",
    "        self.lambdas[1] = (1.0-self.lambda_alpha)*self.lambdas[1] + self.lambda_alpha*f_grads/bc2_grads\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    PINN.lambda_update(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        print\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 8.567006 Test MSE 384.7808846347728 Test RE 0.9999293751063201\n",
      "1 Train Loss 10.137734 Test MSE 385.14023735798406 Test RE 1.0003961907696532\n",
      "2 Train Loss 8.320732 Test MSE 385.3736087236702 Test RE 1.0006992342420633\n",
      "3 Train Loss 7.8856044 Test MSE 383.96196827599454 Test RE 0.9988647501376681\n",
      "4 Train Loss 7.200137 Test MSE 382.98076460054165 Test RE 0.9975876487653722\n",
      "5 Train Loss 6.693535 Test MSE 382.86861867124344 Test RE 0.9974415793078224\n",
      "6 Train Loss 6.1921167 Test MSE 383.03903622175005 Test RE 0.9976635387890116\n",
      "7 Train Loss 5.7063518 Test MSE 383.1807465372162 Test RE 0.9978480710789184\n",
      "8 Train Loss 5.217752 Test MSE 383.2176923243015 Test RE 0.9978961755232358\n",
      "9 Train Loss 4.7905626 Test MSE 383.2872561532298 Test RE 0.9979867432739633\n",
      "10 Train Loss 4.4084454 Test MSE 383.3314599956591 Test RE 0.9980442896392409\n",
      "11 Train Loss 4.059435 Test MSE 383.38764343283253 Test RE 0.9981174267412312\n",
      "12 Train Loss 3.739053 Test MSE 383.4296286073024 Test RE 0.9981720776771541\n",
      "13 Train Loss 3.4383936 Test MSE 383.48083962752094 Test RE 0.9982387335899167\n",
      "14 Train Loss 3.1569548 Test MSE 383.5217234268225 Test RE 0.998291944467905\n",
      "15 Train Loss 2.8856723 Test MSE 383.57025946387034 Test RE 0.9983551111661122\n",
      "16 Train Loss 2.646853 Test MSE 383.61317813264185 Test RE 0.9984109638720338\n",
      "17 Train Loss 2.426712 Test MSE 383.65952716480905 Test RE 0.9984712772121743\n",
      "18 Train Loss 2.2397184 Test MSE 383.7015331270491 Test RE 0.9985259358298243\n",
      "19 Train Loss 2.168081 Test MSE 383.74490520629143 Test RE 0.9985823689145262\n",
      "20 Train Loss 2.33332 Test MSE 383.78746742787337 Test RE 0.9986377451619264\n",
      "21 Train Loss 2.3559713 Test MSE 383.76407248340945 Test RE 0.9986073071817636\n",
      "22 Train Loss 2.172076 Test MSE 383.773982539838 Test RE 0.9986202007687172\n",
      "23 Train Loss 2.1884596 Test MSE 383.8294442291821 Test RE 0.9986923567315936\n",
      "24 Train Loss 2.0901244 Test MSE 383.8318817691244 Test RE 0.9986955278648684\n",
      "25 Train Loss 1.9631014 Test MSE 383.85007840127065 Test RE 0.9987192005724137\n",
      "26 Train Loss 1.8537256 Test MSE 383.85959694287436 Test RE 0.9987315833904242\n",
      "27 Train Loss 1.7794092 Test MSE 383.87497439539567 Test RE 0.9987515878319183\n",
      "28 Train Loss 1.7207936 Test MSE 383.8891798861308 Test RE 0.9987700673188871\n",
      "29 Train Loss 1.6503757 Test MSE 383.90264990295555 Test RE 0.9987875897346035\n",
      "30 Train Loss 1.6090864 Test MSE 383.9170744557152 Test RE 0.9988063535135968\n",
      "31 Train Loss 1.5638119 Test MSE 383.92589773095307 Test RE 0.9988178308524797\n",
      "32 Train Loss 1.531382 Test MSE 383.9347039142958 Test RE 0.998829285826681\n",
      "33 Train Loss 1.5172743 Test MSE 383.94067885254316 Test RE 0.9988370578775309\n",
      "34 Train Loss 1.490079 Test MSE 383.9440192481441 Test RE 0.9988414029545712\n",
      "35 Train Loss 1.4623886 Test MSE 383.94956333255584 Test RE 0.998848614476022\n",
      "36 Train Loss 1.4390317 Test MSE 383.9548134859704 Test RE 0.9988554436158853\n",
      "37 Train Loss 1.404267 Test MSE 383.95944455786616 Test RE 0.9988614674463753\n",
      "38 Train Loss 1.4118743 Test MSE 383.9647086323128 Test RE 0.9988683146058592\n",
      "39 Train Loss 1.3562348 Test MSE 383.9647086323128 Test RE 0.9988683146058592\n",
      "40 Train Loss 1.3541994 Test MSE 383.97391680015494 Test RE 0.9988802918680171\n",
      "41 Train Loss 1.2764981 Test MSE 383.97618088586563 Test RE 0.998883236791048\n",
      "42 Train Loss 1.3039991 Test MSE 383.9878312330466 Test RE 0.9988983903979767\n",
      "43 Train Loss 1.2736117 Test MSE 383.9878312330466 Test RE 0.9988983903979767\n",
      "44 Train Loss 1.3312393 Test MSE 383.9878312330466 Test RE 0.9988983903979767\n",
      "45 Train Loss 1.5243493 Test MSE 383.9878312330466 Test RE 0.9988983903979767\n",
      "46 Train Loss 2.9367898 Test MSE 383.9878312330466 Test RE 0.9988983903979767\n",
      "47 Train Loss 4.345244 Test MSE 383.76613971088113 Test RE 0.9986099967843433\n",
      "48 Train Loss 4.3206253 Test MSE 383.7849467664145 Test RE 0.9986344657012579\n",
      "49 Train Loss 4.0007176 Test MSE 383.6632413724758 Test RE 0.9984761103004138\n",
      "50 Train Loss 3.6727817 Test MSE 383.52844659956065 Test RE 0.9983006945065104\n",
      "51 Train Loss 3.3674994 Test MSE 383.5206686072925 Test RE 0.9982905716401105\n",
      "52 Train Loss 3.0723572 Test MSE 383.657990821235 Test RE 0.9984692780483878\n",
      "53 Train Loss 2.7941506 Test MSE 383.71919699065614 Test RE 0.9985489193488215\n",
      "54 Train Loss 2.5922608 Test MSE 383.7373684669059 Test RE 0.9985725628012457\n",
      "55 Train Loss 2.4074442 Test MSE 383.77350741804474 Test RE 0.9986195826101278\n",
      "56 Train Loss 2.2408984 Test MSE 383.80161331800724 Test RE 0.9986561492147624\n",
      "57 Train Loss 2.1120408 Test MSE 383.8263851308686 Test RE 0.9986883769637082\n",
      "58 Train Loss 1.9845083 Test MSE 383.8465498247635 Test RE 0.9987146101536466\n",
      "59 Train Loss 1.8727643 Test MSE 383.8651696908696 Test RE 0.9987388329932391\n",
      "60 Train Loss 1.7950094 Test MSE 383.8810698293594 Test RE 0.9987595172367889\n",
      "61 Train Loss 1.732294 Test MSE 383.8928556100899 Test RE 0.9987748488997056\n",
      "62 Train Loss 1.661813 Test MSE 383.90271229920546 Test RE 0.998787670901792\n",
      "63 Train Loss 1.6091834 Test MSE 383.91245589124674 Test RE 0.998800345620596\n",
      "64 Train Loss 1.5772489 Test MSE 383.9195132218351 Test RE 0.9988095258799607\n",
      "65 Train Loss 1.5524044 Test MSE 383.92417336177243 Test RE 0.99881558779903\n",
      "66 Train Loss 1.5143843 Test MSE 383.92855199935417 Test RE 0.9988212835057653\n",
      "67 Train Loss 1.4746014 Test MSE 383.9337950115405 Test RE 0.9988281035433162\n",
      "68 Train Loss 1.4807554 Test MSE 383.9382130832541 Test RE 0.9988338504735854\n",
      "69 Train Loss 1.3946636 Test MSE 383.9425162248593 Test RE 0.9988394478735173\n",
      "70 Train Loss 1.3829255 Test MSE 383.9508879504863 Test RE 0.998850337477908\n",
      "71 Train Loss 1.3988512 Test MSE 383.95202009553674 Test RE 0.9988518101175963\n",
      "72 Train Loss 1.3120633 Test MSE 383.95202009553674 Test RE 0.9988518101175963\n",
      "73 Train Loss 1.3336742 Test MSE 383.96211586490443 Test RE 0.9988649421115584\n",
      "74 Train Loss 1.2103083 Test MSE 383.96211586490443 Test RE 0.9988649421115584\n",
      "75 Train Loss 1.2385672 Test MSE 383.9775024563585 Test RE 0.9988849557693874\n",
      "76 Train Loss 1.1777674 Test MSE 383.9775024563585 Test RE 0.9988849557693874\n",
      "77 Train Loss 1.4717134 Test MSE 383.9775024563585 Test RE 0.9988849557693874\n",
      "78 Train Loss 2.5888278 Test MSE 383.9775024563585 Test RE 0.9988849557693874\n",
      "79 Train Loss 3.3077645 Test MSE 383.76472329739704 Test RE 0.9986081539355046\n",
      "80 Train Loss 3.4112327 Test MSE 383.86134179187195 Test RE 0.9987338532748242\n",
      "81 Train Loss 3.1787734 Test MSE 383.73108488502606 Test RE 0.9985643871078375\n",
      "82 Train Loss 2.9380105 Test MSE 383.72847104162116 Test RE 0.9985609861644615\n",
      "83 Train Loss 2.674878 Test MSE 383.73217375237726 Test RE 0.9985658038596082\n",
      "84 Train Loss 2.4582343 Test MSE 383.7439090134956 Test RE 0.9985810727654519\n",
      "85 Train Loss 2.2673414 Test MSE 383.7729726428634 Test RE 0.9986188868388666\n",
      "86 Train Loss 2.100018 Test MSE 383.8055549972246 Test RE 0.9986612773486021\n",
      "87 Train Loss 1.9587829 Test MSE 383.84159335684456 Test RE 0.9987081621174358\n",
      "88 Train Loss 1.8659599 Test MSE 383.8726545371704 Test RE 0.998748569967065\n",
      "89 Train Loss 1.7891043 Test MSE 383.8923468586485 Test RE 0.9987741870896395\n",
      "90 Train Loss 1.7371194 Test MSE 383.9061644241077 Test RE 0.9987921615343522\n",
      "91 Train Loss 1.694128 Test MSE 383.9142797201189 Test RE 0.998802718086918\n",
      "92 Train Loss 1.6406075 Test MSE 383.920367949032 Test RE 0.9988106377135114\n",
      "93 Train Loss 1.6071053 Test MSE 383.92587566631556 Test RE 0.9988178021509075\n",
      "94 Train Loss 1.5794641 Test MSE 383.9291465466112 Test RE 0.9988220568869343\n",
      "95 Train Loss 1.5426607 Test MSE 383.9317394125946 Test RE 0.9988254296542607\n",
      "96 Train Loss 1.530196 Test MSE 383.93417850086354 Test RE 0.9988286023790824\n",
      "97 Train Loss 1.4978086 Test MSE 383.9354542737625 Test RE 0.9988302618789061\n",
      "98 Train Loss 1.4817656 Test MSE 383.93758369745547 Test RE 0.9988330317844359\n",
      "99 Train Loss 1.4637235 Test MSE 383.938886967269 Test RE 0.9988347270441468\n",
      "100 Train Loss 1.4531255 Test MSE 383.94020637109 Test RE 0.9988364432876271\n",
      "101 Train Loss 1.4587448 Test MSE 383.94089134981704 Test RE 0.9988373342875783\n",
      "102 Train Loss 1.4066348 Test MSE 383.94172278385685 Test RE 0.9988384157911756\n",
      "103 Train Loss 1.4226066 Test MSE 383.9439819690537 Test RE 0.9988413544632573\n",
      "104 Train Loss 1.3364326 Test MSE 383.9439819690537 Test RE 0.9988413544632573\n",
      "105 Train Loss 1.3408296 Test MSE 383.95032107886834 Test RE 0.9988496001178265\n",
      "106 Train Loss 1.3148893 Test MSE 383.95032107886834 Test RE 0.9988496001178265\n",
      "107 Train Loss 1.4253571 Test MSE 383.95098259274766 Test RE 0.9988504605840809\n",
      "108 Train Loss 1.3931913 Test MSE 383.9455892195316 Test RE 0.9988434451153314\n",
      "109 Train Loss 1.3471825 Test MSE 383.9455892195316 Test RE 0.9988434451153314\n",
      "110 Train Loss 1.3827657 Test MSE 383.94931717148916 Test RE 0.9988482942807367\n",
      "111 Train Loss 1.3104204 Test MSE 383.94931717148916 Test RE 0.9988482942807367\n",
      "112 Train Loss 1.611722 Test MSE 383.94931717148916 Test RE 0.9988482942807367\n",
      "113 Train Loss 2.5844345 Test MSE 383.94931717148916 Test RE 0.9988482942807367\n",
      "114 Train Loss 3.7109752 Test MSE 383.84968498976394 Test RE 0.9987186887739948\n",
      "115 Train Loss 3.4230292 Test MSE 383.9989250619027 Test RE 0.9989128199278308\n",
      "116 Train Loss 3.29896 Test MSE 383.8605907005123 Test RE 0.9987328761762562\n",
      "117 Train Loss 3.1093934 Test MSE 383.7804366554069 Test RE 0.9986285978766251\n",
      "118 Train Loss 2.8498664 Test MSE 383.74929179223295 Test RE 0.9985880762930527\n",
      "119 Train Loss 2.6064513 Test MSE 383.75713102715315 Test RE 0.9985982758252836\n",
      "120 Train Loss 2.372877 Test MSE 383.803843539792 Test RE 0.9986590507417321\n",
      "121 Train Loss 2.1865304 Test MSE 383.81575198219195 Test RE 0.9986745435276124\n",
      "122 Train Loss 2.0437005 Test MSE 383.831091401172 Test RE 0.9986944996316973\n",
      "123 Train Loss 1.9103954 Test MSE 383.84732909831916 Test RE 0.9987156239330993\n",
      "124 Train Loss 1.7933149 Test MSE 383.8615776157147 Test RE 0.9987341600590628\n",
      "125 Train Loss 1.7113724 Test MSE 383.87359297570094 Test RE 0.9987497907671874\n",
      "126 Train Loss 1.6423663 Test MSE 383.8832048294716 Test RE 0.9987622945926993\n",
      "127 Train Loss 1.569964 Test MSE 383.89243050511925 Test RE 0.9987742959013048\n",
      "128 Train Loss 1.5140626 Test MSE 383.9014948956676 Test RE 0.9987860872601958\n",
      "129 Train Loss 1.4854369 Test MSE 383.9076555950518 Test RE 0.9987941012901339\n",
      "130 Train Loss 1.453188 Test MSE 383.9107139245657 Test RE 0.9987980796366847\n",
      "131 Train Loss 1.4327719 Test MSE 383.913709833376 Test RE 0.9988019767695597\n",
      "132 Train Loss 1.4265805 Test MSE 383.9153668175006 Test RE 0.9988041321982292\n",
      "133 Train Loss 1.3622404 Test MSE 383.9188663894778 Test RE 0.9988086844762679\n",
      "134 Train Loss 1.5734686 Test MSE 383.9188663894778 Test RE 0.9988086844762679\n",
      "135 Train Loss 2.2241304 Test MSE 383.9188663894778 Test RE 0.9988086844762679\n",
      "136 Train Loss 3.2378447 Test MSE 383.8039206455157 Test RE 0.998659151056419\n",
      "137 Train Loss 3.2004578 Test MSE 383.63861652143765 Test RE 0.9984440669387261\n",
      "138 Train Loss 2.9158719 Test MSE 383.69674565292286 Test RE 0.9985197064671804\n",
      "139 Train Loss 2.6643398 Test MSE 383.724861610054 Test RE 0.9985562898149688\n",
      "140 Train Loss 2.4528878 Test MSE 383.74723217282786 Test RE 0.9985853965302711\n",
      "141 Train Loss 2.2656715 Test MSE 383.7777359146987 Test RE 0.9986250840945325\n",
      "142 Train Loss 2.1225233 Test MSE 383.7991292857376 Test RE 0.9986529174694692\n",
      "143 Train Loss 2.0173175 Test MSE 383.8183607698362 Test RE 0.9986779375068452\n",
      "144 Train Loss 1.9134519 Test MSE 383.8346806755347 Test RE 0.9986991691077559\n",
      "145 Train Loss 1.8246399 Test MSE 383.8505442902879 Test RE 0.9987198066582162\n",
      "146 Train Loss 1.7712643 Test MSE 383.8637441859066 Test RE 0.9987369785550179\n",
      "147 Train Loss 1.7265024 Test MSE 383.87227130975094 Test RE 0.9987480714320323\n",
      "148 Train Loss 1.6752024 Test MSE 383.87990347381805 Test RE 0.9987579999575142\n",
      "149 Train Loss 1.6410632 Test MSE 383.88774512590754 Test RE 0.9987682008988639\n",
      "150 Train Loss 1.6225721 Test MSE 383.8928533153274 Test RE 0.9987748459145613\n",
      "151 Train Loss 1.6053472 Test MSE 383.89608611476507 Test RE 0.9987790512962645\n",
      "152 Train Loss 1.5867981 Test MSE 383.8991719555813 Test RE 0.9987830654905748\n",
      "153 Train Loss 1.5729781 Test MSE 383.90231684670863 Test RE 0.9987871564834676\n",
      "154 Train Loss 1.5468202 Test MSE 383.90504137976495 Test RE 0.9987907006451938\n",
      "155 Train Loss 1.5204903 Test MSE 383.9092201802953 Test RE 0.9987961365411865\n",
      "156 Train Loss 1.4985186 Test MSE 383.91311714057673 Test RE 0.9988012057851525\n",
      "157 Train Loss 1.5047181 Test MSE 383.9159485719616 Test RE 0.9988048889516569\n",
      "158 Train Loss 1.4688479 Test MSE 383.9159485719616 Test RE 0.9988048889516569\n",
      "159 Train Loss 1.4447103 Test MSE 383.92172780775144 Test RE 0.9988124066222036\n",
      "160 Train Loss 1.4605342 Test MSE 383.92457960838175 Test RE 0.9988161162436642\n",
      "161 Train Loss 1.3651731 Test MSE 383.92457960838175 Test RE 0.9988161162436642\n",
      "162 Train Loss 1.3895081 Test MSE 383.93721737146456 Test RE 0.9988325552765307\n",
      "163 Train Loss 1.2758652 Test MSE 383.93721737146456 Test RE 0.9988325552765307\n",
      "164 Train Loss 2.0769503 Test MSE 383.93721737146456 Test RE 0.9988325552765307\n",
      "165 Train Loss 4.403983 Test MSE 383.93721737146456 Test RE 0.9988325552765307\n",
      "166 Train Loss 8.148218 Test MSE 383.9344506024408 Test RE 0.9988289563235931\n",
      "167 Train Loss 9.944557 Test MSE 382.6100627405113 Test RE 0.997104730088735\n",
      "168 Train Loss 8.238813 Test MSE 383.35464942182193 Test RE 0.9980744772533109\n",
      "169 Train Loss 7.686823 Test MSE 383.69815718343796 Test RE 0.9985215431256289\n",
      "170 Train Loss 7.2037125 Test MSE 383.87185921090764 Test RE 0.9987475353383024\n",
      "171 Train Loss 6.86782 Test MSE 383.76007323423926 Test RE 0.9986021038678845\n",
      "172 Train Loss 6.3191605 Test MSE 383.3873917930471 Test RE 0.9981170991796877\n",
      "173 Train Loss 5.8375816 Test MSE 383.3433313295943 Test RE 0.9980597436608276\n",
      "174 Train Loss 5.3500776 Test MSE 383.4203760807281 Test RE 0.9981600341772497\n",
      "175 Train Loss 4.901455 Test MSE 383.52499041334283 Test RE 0.9982961963774857\n",
      "176 Train Loss 4.4920278 Test MSE 383.5643633267575 Test RE 0.9983474379157768\n",
      "177 Train Loss 4.117093 Test MSE 383.6035612118478 Test RE 0.9983984490525696\n",
      "178 Train Loss 3.7851326 Test MSE 383.6460931759505 Test RE 0.9984537961274036\n",
      "179 Train Loss 3.4645238 Test MSE 383.68712030743876 Test RE 0.9985071820484398\n",
      "180 Train Loss 3.1851132 Test MSE 383.71520268053047 Test RE 0.9985437221571377\n",
      "181 Train Loss 2.931039 Test MSE 383.74254093488526 Test RE 0.9985792927520212\n",
      "182 Train Loss 2.719019 Test MSE 383.7696971655522 Test RE 0.9986146252562138\n",
      "183 Train Loss 2.5272532 Test MSE 383.79568137994414 Test RE 0.9986484316998957\n",
      "184 Train Loss 2.3751583 Test MSE 383.82113382897325 Test RE 0.998681545187275\n",
      "185 Train Loss 2.2567346 Test MSE 383.84205584554564 Test RE 0.9987087637863401\n",
      "186 Train Loss 2.1295998 Test MSE 383.8608499297871 Test RE 0.9987332134090458\n",
      "187 Train Loss 2.0196698 Test MSE 383.8810163658359 Test RE 0.998759447687638\n",
      "188 Train Loss 1.9432482 Test MSE 383.8981334609929 Test RE 0.9987817145739988\n",
      "189 Train Loss 1.8473748 Test MSE 383.911337830584 Test RE 0.9987988912262774\n",
      "190 Train Loss 1.7863094 Test MSE 383.9261853215164 Test RE 0.9988182049487968\n",
      "191 Train Loss 1.7259045 Test MSE 383.9364825246849 Test RE 0.9988315994050956\n",
      "192 Train Loss 1.6706892 Test MSE 383.9464558458825 Test RE 0.9988445723890721\n",
      "193 Train Loss 1.6113797 Test MSE 383.9558095400707 Test RE 0.9988567392285201\n",
      "194 Train Loss 1.6032385 Test MSE 383.9647574260088 Test RE 0.9988683780732487\n",
      "195 Train Loss 1.5862913 Test MSE 383.96676719531445 Test RE 0.9988709922355395\n",
      "196 Train Loss 1.5584313 Test MSE 383.96991691140784 Test RE 0.9988750891442516\n",
      "197 Train Loss 1.5234394 Test MSE 383.97424142330544 Test RE 0.998880714109717\n",
      "198 Train Loss 1.5178368 Test MSE 383.97861702641575 Test RE 0.9988864054981442\n",
      "199 Train Loss 1.4643586 Test MSE 383.9847034467781 Test RE 0.9988943221088573\n",
      "Training time: 47.50\n",
      "Training time: 47.50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 10.685892 Test MSE 384.7090677714284 Test RE 0.9998360555765978\n",
      "1 Train Loss 11.217582 Test MSE 385.5336676391099 Test RE 1.000907025075202\n",
      "2 Train Loss 8.701988 Test MSE 387.39839904789187 Test RE 1.0033246756049292\n",
      "3 Train Loss 7.4796944 Test MSE 384.73862752601485 Test RE 0.9998744668634666\n",
      "4 Train Loss 6.953229 Test MSE 384.2401170108232 Test RE 0.9992264821462059\n",
      "5 Train Loss 6.3882675 Test MSE 383.9232324491994 Test RE 0.9988143638610945\n",
      "6 Train Loss 5.9023614 Test MSE 383.8088231324064 Test RE 0.9986655291801155\n",
      "7 Train Loss 5.421688 Test MSE 383.69015745226096 Test RE 0.9985111339727504\n",
      "8 Train Loss 4.9539433 Test MSE 383.55424598937475 Test RE 0.998334271045458\n",
      "9 Train Loss 4.525603 Test MSE 383.45861037448975 Test RE 0.9982098006932965\n",
      "10 Train Loss 4.1512313 Test MSE 383.4191876460091 Test RE 0.9981584872472572\n",
      "11 Train Loss 3.8551884 Test MSE 383.4438073360796 Test RE 0.9981905330588864\n",
      "12 Train Loss 3.66918 Test MSE 383.51155463905195 Test RE 0.9982787099030991\n",
      "13 Train Loss 3.523607 Test MSE 383.59924094817643 Test RE 0.9983928268984372\n",
      "14 Train Loss 3.2604482 Test MSE 383.66401593558373 Test RE 0.9984771181926033\n",
      "15 Train Loss 2.9769464 Test MSE 383.71227445574596 Test RE 0.9985399120838937\n",
      "16 Train Loss 2.7692924 Test MSE 383.6412894728227 Test RE 0.9984475451962429\n",
      "17 Train Loss 2.61482 Test MSE 383.58089350010795 Test RE 0.9983689501833283\n",
      "18 Train Loss 2.5198944 Test MSE 383.5506557044324 Test RE 0.9983295985474657\n",
      "19 Train Loss 2.566057 Test MSE 383.4671277788985 Test RE 0.9982208867780984\n",
      "20 Train Loss 2.510707 Test MSE 383.0088007255066 Test RE 0.9976241623226177\n",
      "21 Train Loss 2.4411743 Test MSE 382.365488945596 Test RE 0.9967859921683037\n",
      "22 Train Loss 2.2498608 Test MSE 381.3804227600421 Test RE 0.9955011829704723\n",
      "23 Train Loss 2.0789542 Test MSE 381.1062383798874 Test RE 0.995143272687156\n",
      "24 Train Loss 1.9488921 Test MSE 380.8714399647041 Test RE 0.9948366730570896\n",
      "25 Train Loss 1.871914 Test MSE 380.63185469722833 Test RE 0.994523725327061\n",
      "26 Train Loss 1.9959769 Test MSE 380.69075811213247 Test RE 0.9946006744535026\n",
      "27 Train Loss 2.0491164 Test MSE 379.75994238041807 Test RE 0.9933839959117546\n",
      "28 Train Loss 2.5355258 Test MSE 371.16031819439246 Test RE 0.9820720513983672\n",
      "29 Train Loss 3.0755458 Test MSE 359.82479886532093 Test RE 0.966959151881312\n",
      "30 Train Loss 4.380478 Test MSE 353.7475242064668 Test RE 0.9587586319511036\n",
      "31 Train Loss 4.9364843 Test MSE 333.41261722219946 Test RE 0.9307940487529848\n",
      "32 Train Loss 4.36027 Test MSE 302.7244337650578 Test RE 0.8869238229640398\n",
      "33 Train Loss 7.818543 Test MSE 262.43370737617363 Test RE 0.825795268856961\n",
      "34 Train Loss 7.7801123 Test MSE 254.0894724293588 Test RE 0.8125608958984329\n",
      "35 Train Loss 6.5337687 Test MSE 227.8506510483304 Test RE 0.7694629611009419\n",
      "36 Train Loss 6.027333 Test MSE 215.9478390617062 Test RE 0.7490951992300737\n",
      "37 Train Loss 5.267096 Test MSE 199.8369779931857 Test RE 0.7206103728376034\n",
      "38 Train Loss 4.6808224 Test MSE 168.29967787651532 Test RE 0.6613086827891256\n",
      "39 Train Loss 4.24387 Test MSE 158.0593741898387 Test RE 0.640874086746472\n",
      "40 Train Loss 4.202936 Test MSE 146.65933393433005 Test RE 0.6173300768321159\n",
      "41 Train Loss 3.8045 Test MSE 135.19424954818265 Test RE 0.5927092325376687\n",
      "42 Train Loss 3.5216448 Test MSE 132.88098560963715 Test RE 0.5876165281586863\n",
      "43 Train Loss 3.478876 Test MSE 130.07430768041493 Test RE 0.5813776660015423\n",
      "44 Train Loss 3.2700644 Test MSE 123.40980275005182 Test RE 0.5662880689294162\n",
      "45 Train Loss 3.0260458 Test MSE 118.62427997337129 Test RE 0.5551998974244007\n",
      "46 Train Loss 2.7946773 Test MSE 113.73383348991757 Test RE 0.5436350148785679\n",
      "47 Train Loss 2.5617232 Test MSE 112.58641014202296 Test RE 0.54088578559088\n",
      "48 Train Loss 2.4044204 Test MSE 110.26348185427402 Test RE 0.5352768161721714\n",
      "49 Train Loss 2.2321086 Test MSE 109.16536984575693 Test RE 0.5326047407037315\n",
      "50 Train Loss 2.207257 Test MSE 109.64188975875214 Test RE 0.5337659166544289\n",
      "51 Train Loss 2.2265742 Test MSE 107.98002930097351 Test RE 0.5297052813421536\n",
      "52 Train Loss 2.3258 Test MSE 96.15309192203533 Test RE 0.49985519439397297\n",
      "53 Train Loss 2.1167724 Test MSE 87.17792854243896 Test RE 0.4759549580380435\n",
      "54 Train Loss 1.9545078 Test MSE 84.23879945303587 Test RE 0.46786296301868646\n",
      "55 Train Loss 1.8739573 Test MSE 82.89277425677625 Test RE 0.46410999343886755\n",
      "56 Train Loss 1.738063 Test MSE 74.36956178244627 Test RE 0.4396025406707671\n",
      "57 Train Loss 1.5542586 Test MSE 67.31747642080288 Test RE 0.41824089569589495\n",
      "58 Train Loss 1.4372025 Test MSE 64.81809104125294 Test RE 0.4104031644326841\n",
      "59 Train Loss 1.3589844 Test MSE 63.824536706347644 Test RE 0.40724561619348715\n",
      "60 Train Loss 1.4893147 Test MSE 61.748279502130536 Test RE 0.4005668573452923\n",
      "61 Train Loss 1.4918778 Test MSE 55.88926406457316 Test RE 0.3810893201275192\n",
      "62 Train Loss 1.3774322 Test MSE 51.266670818724286 Test RE 0.36498930638009613\n",
      "63 Train Loss 1.4535016 Test MSE 43.2481969356612 Test RE 0.33523286255402046\n",
      "64 Train Loss 1.4362223 Test MSE 38.147019858625875 Test RE 0.31484216507526197\n",
      "65 Train Loss 1.4091985 Test MSE 35.72784572729872 Test RE 0.3046954701903761\n",
      "66 Train Loss 1.3305266 Test MSE 32.63444021052087 Test RE 0.29120623291014164\n",
      "67 Train Loss 1.2875813 Test MSE 31.274775416668895 Test RE 0.28507536062790007\n",
      "68 Train Loss 1.2428112 Test MSE 30.1486331220441 Test RE 0.2798958092174205\n",
      "69 Train Loss 1.2640078 Test MSE 28.313979313240033 Test RE 0.27124580967820205\n",
      "70 Train Loss 1.2558277 Test MSE 26.961263910399474 Test RE 0.26468705769938194\n",
      "71 Train Loss 1.239862 Test MSE 24.932134450918575 Test RE 0.25453195465805734\n",
      "72 Train Loss 1.1686864 Test MSE 23.45484126044396 Test RE 0.24687597692933208\n",
      "73 Train Loss 1.107183 Test MSE 22.92001224577949 Test RE 0.24404505110664176\n",
      "74 Train Loss 1.0523779 Test MSE 22.51552733571041 Test RE 0.24188205186873363\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 112.41\n",
      "Training time: 112.41\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 15.371443 Test MSE 386.4293879107944 Test RE 1.0020690670151315\n",
      "1 Train Loss 16.67219 Test MSE 385.447921530702 Test RE 1.0007957135841294\n",
      "2 Train Loss 11.936294 Test MSE 383.1187145243618 Test RE 0.9977672984536271\n",
      "3 Train Loss 11.244299 Test MSE 383.22599170792665 Test RE 0.9979069812330251\n",
      "4 Train Loss 10.717485 Test MSE 383.08535020308227 Test RE 0.9977238516677517\n",
      "5 Train Loss 10.147635 Test MSE 382.6625141208661 Test RE 0.9971730734652605\n",
      "6 Train Loss 9.395817 Test MSE 382.48554779037494 Test RE 0.9969424701790339\n",
      "7 Train Loss 8.673571 Test MSE 382.30033227240887 Test RE 0.9967010603059054\n",
      "8 Train Loss 7.972848 Test MSE 382.2426178716069 Test RE 0.9966258234164418\n",
      "9 Train Loss 7.338703 Test MSE 382.23560051489113 Test RE 0.9966166751547273\n",
      "10 Train Loss 6.764461 Test MSE 382.4469914834766 Test RE 0.9968922207136572\n",
      "11 Train Loss 6.1919236 Test MSE 382.5116538069314 Test RE 0.9969764920560729\n",
      "12 Train Loss 5.648949 Test MSE 382.64013049304 Test RE 0.9971439085006446\n",
      "13 Train Loss 5.154623 Test MSE 382.6817951349442 Test RE 0.997198195165421\n",
      "14 Train Loss 4.701023 Test MSE 382.69817094805154 Test RE 0.9972195311118757\n",
      "15 Train Loss 4.282941 Test MSE 382.69552655214216 Test RE 0.9972160857755709\n",
      "16 Train Loss 3.8998928 Test MSE 382.67820268727644 Test RE 0.997193514526332\n",
      "17 Train Loss 3.5516276 Test MSE 382.6512729132591 Test RE 0.9971584267315861\n",
      "18 Train Loss 3.2350945 Test MSE 382.6225109325972 Test RE 0.9971209503237252\n",
      "19 Train Loss 2.9488 Test MSE 382.5968405392767 Test RE 0.9970875010158731\n",
      "20 Train Loss 2.697539 Test MSE 382.5805620121207 Test RE 0.997066289015545\n",
      "21 Train Loss 2.515599 Test MSE 382.5814878443616 Test RE 0.9970674954484507\n",
      "22 Train Loss 2.465324 Test MSE 382.61508339508805 Test RE 0.997111272130479\n",
      "23 Train Loss 2.5814986 Test MSE 382.8832508831914 Test RE 0.9974606388969894\n",
      "24 Train Loss 2.461185 Test MSE 383.1224450675117 Test RE 0.9977721562232408\n",
      "25 Train Loss 2.3024855 Test MSE 382.9398454211215 Test RE 0.9975343542370647\n",
      "26 Train Loss 2.2419431 Test MSE 382.828537863786 Test RE 0.9973893690870288\n",
      "27 Train Loss 2.3804195 Test MSE 381.31846529178875 Test RE 0.9954203172069463\n",
      "28 Train Loss 2.3548014 Test MSE 377.645440640432 Test RE 0.9906145565470189\n",
      "29 Train Loss 2.3832207 Test MSE 375.3785634748138 Test RE 0.9876369202194029\n",
      "30 Train Loss 2.7152672 Test MSE 363.47594632268704 Test RE 0.9718526439044508\n",
      "31 Train Loss 4.114129 Test MSE 350.7182217438939 Test RE 0.9546446603818798\n",
      "32 Train Loss 4.7827 Test MSE 334.4842201175994 Test RE 0.9322886553998367\n",
      "33 Train Loss 4.521353 Test MSE 326.99648630699585 Test RE 0.9217945276419433\n",
      "34 Train Loss 4.752571 Test MSE 308.01303550901076 Test RE 0.8946375672335942\n",
      "35 Train Loss 4.460451 Test MSE 300.86729168679847 Test RE 0.8841991047805018\n",
      "36 Train Loss 4.140608 Test MSE 301.002612582934 Test RE 0.8843979252700592\n",
      "37 Train Loss 4.134566 Test MSE 286.73640023146515 Test RE 0.8631852227756884\n",
      "38 Train Loss 3.7907531 Test MSE 261.9381058497677 Test RE 0.825015150317385\n",
      "39 Train Loss 3.4876018 Test MSE 242.52768085316987 Test RE 0.7938587563727452\n",
      "40 Train Loss 3.3328686 Test MSE 238.02630972147085 Test RE 0.7864571484591169\n",
      "41 Train Loss 3.9386494 Test MSE 216.2800508400641 Test RE 0.7496711776995227\n",
      "42 Train Loss 3.5257068 Test MSE 199.2775863114062 Test RE 0.7196010853079041\n",
      "43 Train Loss 3.2752798 Test MSE 197.52371123802678 Test RE 0.716427422668908\n",
      "44 Train Loss 3.2568197 Test MSE 197.18489979292804 Test RE 0.7158127167476412\n",
      "45 Train Loss 3.2466125 Test MSE 197.4927715894102 Test RE 0.7163713107199838\n",
      "46 Train Loss 3.3497584 Test MSE 192.67349150304275 Test RE 0.707576769720492\n",
      "47 Train Loss 3.1556652 Test MSE 189.20114645116158 Test RE 0.7011718374665658\n",
      "48 Train Loss 3.4647608 Test MSE 179.3295391625784 Test RE 0.6826349168983391\n",
      "49 Train Loss 3.4547637 Test MSE 170.48195036424318 Test RE 0.6655823321738897\n",
      "50 Train Loss 3.4476752 Test MSE 161.83775839025205 Test RE 0.6484888446669718\n",
      "51 Train Loss 3.1736448 Test MSE 154.6288701153427 Test RE 0.633881203430765\n",
      "52 Train Loss 3.1494458 Test MSE 151.68981152625787 Test RE 0.6278281559014155\n",
      "53 Train Loss 3.1251435 Test MSE 137.09128120924169 Test RE 0.5968531635554017\n",
      "54 Train Loss 2.9242733 Test MSE 130.015480821664 Test RE 0.5812461854263973\n",
      "55 Train Loss 2.728219 Test MSE 128.96029860901817 Test RE 0.5788827356759957\n",
      "56 Train Loss 2.7564626 Test MSE 129.12168345753045 Test RE 0.5792448381750517\n",
      "57 Train Loss 2.781527 Test MSE 125.53207738646681 Test RE 0.5711365324400067\n",
      "58 Train Loss 2.640824 Test MSE 119.97655896090262 Test RE 0.5583554806957033\n",
      "59 Train Loss 2.5763934 Test MSE 118.31771150377564 Test RE 0.5544820136388632\n",
      "60 Train Loss 2.9893875 Test MSE 115.10528650335544 Test RE 0.5469028891051654\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 127.01\n",
      "Training time: 127.01\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 42.01782 Test MSE 385.809223122481 Test RE 1.0012646542237245\n",
      "1 Train Loss 18.138433 Test MSE 386.3641919540464 Test RE 1.0019845320271346\n",
      "2 Train Loss 16.311129 Test MSE 385.92073247941016 Test RE 1.0014093401263469\n",
      "3 Train Loss 14.846779 Test MSE 382.2205582230886 Test RE 0.9965970648066639\n",
      "4 Train Loss 13.812766 Test MSE 381.7505003222956 Test RE 0.9959840647583686\n",
      "5 Train Loss 12.806166 Test MSE 381.8171880543544 Test RE 0.9960710548447345\n",
      "6 Train Loss 11.855364 Test MSE 381.9832228225661 Test RE 0.9962876040945964\n",
      "7 Train Loss 10.958849 Test MSE 382.12498892162125 Test RE 0.9964724639215714\n",
      "8 Train Loss 10.105595 Test MSE 382.30941140851763 Test RE 0.996712895413145\n",
      "9 Train Loss 9.311384 Test MSE 382.5345140124534 Test RE 0.9970062829745636\n",
      "10 Train Loss 8.58335 Test MSE 382.7759749482435 Test RE 0.997320895230407\n",
      "11 Train Loss 7.8924923 Test MSE 382.9806072786009 Test RE 0.9975874438693886\n",
      "12 Train Loss 7.240104 Test MSE 383.1589380319352 Test RE 0.9978196747088371\n",
      "13 Train Loss 6.620515 Test MSE 383.27265072930163 Test RE 0.9979677286079575\n",
      "14 Train Loss 6.049193 Test MSE 383.3434555475026 Test RE 0.9980599053655885\n",
      "15 Train Loss 5.521096 Test MSE 383.3594309500235 Test RE 0.9980807016546407\n",
      "16 Train Loss 5.034112 Test MSE 383.3465694482167 Test RE 0.9980639589800375\n",
      "17 Train Loss 4.594688 Test MSE 383.30054099529593 Test RE 0.9980040383720591\n",
      "18 Train Loss 4.226059 Test MSE 383.25040108816347 Test RE 0.9979387613100723\n",
      "19 Train Loss 3.9084282 Test MSE 383.21260537938264 Test RE 0.9978895523168612\n",
      "20 Train Loss 3.5861685 Test MSE 383.2231643328421 Test RE 0.9979033000336797\n",
      "21 Train Loss 3.3890467 Test MSE 383.31330815873923 Test RE 0.9980206592389931\n",
      "22 Train Loss 3.1413248 Test MSE 383.4532212517034 Test RE 0.99820278625427\n",
      "23 Train Loss 2.921703 Test MSE 383.58139400296045 Test RE 0.9983696015274809\n",
      "24 Train Loss 2.6734324 Test MSE 383.6718488980959 Test RE 0.9984873106964517\n",
      "25 Train Loss 2.5455399 Test MSE 383.737090705547 Test RE 0.9985722014018291\n",
      "26 Train Loss 2.3232477 Test MSE 383.764647351889 Test RE 0.9986080551252142\n",
      "27 Train Loss 2.1310341 Test MSE 383.78593472295876 Test RE 0.9986357510654043\n",
      "28 Train Loss 1.9684014 Test MSE 383.8318591239927 Test RE 0.9986954984045846\n",
      "29 Train Loss 1.8418093 Test MSE 383.86824209947224 Test RE 0.9987428298753276\n",
      "30 Train Loss 1.7275169 Test MSE 383.8955312198694 Test RE 0.9987783294634331\n",
      "31 Train Loss 1.6199286 Test MSE 383.91861431332137 Test RE 0.9988083565737897\n",
      "32 Train Loss 1.5481335 Test MSE 383.94052252912877 Test RE 0.9988368545366978\n",
      "33 Train Loss 1.4597825 Test MSE 383.958067237737 Test RE 0.9988596759118024\n",
      "34 Train Loss 1.3979939 Test MSE 383.97778122933784 Test RE 0.9988853183714709\n",
      "35 Train Loss 1.3242851 Test MSE 383.99779886630813 Test RE 0.9989113551163841\n",
      "36 Train Loss 1.272074 Test MSE 384.0152384184927 Test RE 0.9989340380184334\n",
      "37 Train Loss 1.2274144 Test MSE 384.0233368918168 Test RE 0.9989445711915983\n",
      "38 Train Loss 1.1816416 Test MSE 384.03136145232895 Test RE 0.9989550081214851\n",
      "39 Train Loss 1.1439854 Test MSE 384.04165024011513 Test RE 0.9989683897984495\n",
      "40 Train Loss 1.1251354 Test MSE 384.0509362207642 Test RE 0.998980467062799\n",
      "41 Train Loss 1.0825621 Test MSE 384.05789068733264 Test RE 0.9989895118849239\n",
      "42 Train Loss 1.0841471 Test MSE 384.0663174083387 Test RE 0.9990004713781835\n",
      "43 Train Loss 1.0476348 Test MSE 384.0701134729898 Test RE 0.9990054083654087\n",
      "44 Train Loss 1.0294052 Test MSE 384.0772532239487 Test RE 0.9990146939312778\n",
      "45 Train Loss 1.0199449 Test MSE 384.0817570901262 Test RE 0.9990205513665497\n",
      "46 Train Loss 0.99102354 Test MSE 384.0853587499605 Test RE 0.9990252354262479\n",
      "47 Train Loss 1.0111992 Test MSE 384.0902193953067 Test RE 0.99903155679712\n",
      "48 Train Loss 1.0491943 Test MSE 384.09485266393045 Test RE 0.9990375824225763\n",
      "49 Train Loss 1.2984626 Test MSE 384.09485266393045 Test RE 0.9990375824225763\n",
      "50 Train Loss 1.721673 Test MSE 383.98702344806566 Test RE 0.9988973397194446\n",
      "51 Train Loss 1.6798198 Test MSE 383.8513468768235 Test RE 0.9987208507607486\n",
      "52 Train Loss 1.539867 Test MSE 383.96900206440444 Test RE 0.9988738991832858\n",
      "53 Train Loss 1.6109613 Test MSE 383.9299458021102 Test RE 0.998823096549608\n",
      "54 Train Loss 1.5663809 Test MSE 383.96576486224467 Test RE 0.9988696884741637\n",
      "55 Train Loss 1.476 Test MSE 383.96858664403425 Test RE 0.9988733588367019\n",
      "56 Train Loss 1.781112 Test MSE 383.98072279174517 Test RE 0.9988891444755034\n",
      "57 Train Loss 2.3142622 Test MSE 383.98982669529084 Test RE 0.9989009858727183\n",
      "58 Train Loss 2.937932 Test MSE 384.08872697630426 Test RE 0.9990296158792672\n",
      "59 Train Loss 2.8759995 Test MSE 384.1432734377875 Test RE 0.9991005520875508\n",
      "60 Train Loss 2.7883997 Test MSE 383.9109969668392 Test RE 0.9987984478238919\n",
      "61 Train Loss 2.8020978 Test MSE 383.7377339995562 Test RE 0.9985730384009898\n",
      "62 Train Loss 2.5974877 Test MSE 383.5604593426862 Test RE 0.9983423572268686\n",
      "63 Train Loss 2.4965873 Test MSE 383.4707007805383 Test RE 0.9982255372895747\n",
      "64 Train Loss 2.3130276 Test MSE 383.52229973174326 Test RE 0.9982926945171315\n",
      "65 Train Loss 2.122053 Test MSE 383.5785043554748 Test RE 0.9983658409936189\n",
      "66 Train Loss 1.9605026 Test MSE 383.6089030354796 Test RE 0.9984054005650183\n",
      "67 Train Loss 1.8087211 Test MSE 383.6400764994658 Test RE 0.9984459667800749\n",
      "68 Train Loss 1.669463 Test MSE 383.6658559122407 Test RE 0.9984795124390157\n",
      "69 Train Loss 1.5390592 Test MSE 383.67596600174846 Test RE 0.998492667963003\n",
      "70 Train Loss 1.4196811 Test MSE 383.67610021322054 Test RE 0.9984928426014622\n",
      "71 Train Loss 1.3057355 Test MSE 383.6750700093359 Test RE 0.9984915020802579\n",
      "72 Train Loss 1.2443863 Test MSE 383.6763968933075 Test RE 0.9984932286469915\n",
      "73 Train Loss 1.1913462 Test MSE 383.67154147117463 Test RE 0.9984869106645723\n",
      "74 Train Loss 1.1787237 Test MSE 383.6670115401606 Test RE 0.9984810161823323\n",
      "75 Train Loss 1.1580304 Test MSE 383.66547455648134 Test RE 0.9984790162051165\n",
      "76 Train Loss 1.1646985 Test MSE 383.6638477662152 Test RE 0.9984768993640477\n",
      "77 Train Loss 1.1321137 Test MSE 383.6638477662152 Test RE 0.9984768993640477\n",
      "78 Train Loss 1.158788 Test MSE 383.662107026267 Test RE 0.9984746342423696\n",
      "79 Train Loss 1.0751438 Test MSE 383.662107026267 Test RE 0.9984746342423696\n",
      "80 Train Loss 1.4820766 Test MSE 383.6617559598526 Test RE 0.998474177419838\n",
      "81 Train Loss 2.5643651 Test MSE 383.66060708791804 Test RE 0.9984726824574127\n",
      "82 Train Loss 2.6544263 Test MSE 383.4518652181637 Test RE 0.9982010212441209\n",
      "83 Train Loss 2.5008767 Test MSE 383.3292805964835 Test RE 0.9980414524862534\n",
      "84 Train Loss 2.2877433 Test MSE 383.38444799835577 Test RE 0.9981132672103521\n",
      "85 Train Loss 2.085109 Test MSE 383.39566375574327 Test RE 0.9981278668040975\n",
      "86 Train Loss 1.9137344 Test MSE 383.37192972803126 Test RE 0.9980969718784023\n",
      "87 Train Loss 1.7841026 Test MSE 383.34902450047537 Test RE 0.9980671549069731\n",
      "88 Train Loss 1.7177192 Test MSE 383.33861616321684 Test RE 0.9980536055180285\n",
      "89 Train Loss 1.6561435 Test MSE 383.33395639682936 Test RE 0.9980475394571351\n",
      "90 Train Loss 1.6035327 Test MSE 383.3318099147202 Test RE 0.9980447451649118\n",
      "91 Train Loss 1.5751585 Test MSE 383.3326724687922 Test RE 0.9980458680394717\n",
      "92 Train Loss 1.5448635 Test MSE 383.33503110292304 Test RE 0.9980489385074964\n",
      "93 Train Loss 1.5178691 Test MSE 383.33895292529303 Test RE 0.9980540439118096\n",
      "94 Train Loss 1.4848667 Test MSE 383.3443074995833 Test RE 0.9980610144216171\n",
      "95 Train Loss 1.429577 Test MSE 383.3542322261313 Test RE 0.998073934162879\n",
      "96 Train Loss 1.3583992 Test MSE 383.3759588360149 Test RE 0.9981022166936852\n",
      "97 Train Loss 1.2789106 Test MSE 383.41260082355524 Test RE 0.9981499134445039\n",
      "98 Train Loss 1.210842 Test MSE 383.4609108243785 Test RE 0.9982127949254235\n",
      "99 Train Loss 1.1470354 Test MSE 383.50321713267266 Test RE 0.9982678585998618\n",
      "100 Train Loss 1.08353 Test MSE 383.5413164284275 Test RE 0.9983174440480747\n",
      "101 Train Loss 1.0260755 Test MSE 383.5764114800077 Test RE 0.9983631173552996\n",
      "102 Train Loss 0.97535187 Test MSE 383.6124398698706 Test RE 0.9984100031516498\n",
      "103 Train Loss 1.0467588 Test MSE 383.63789481513015 Test RE 0.9984431277948437\n",
      "104 Train Loss 1.2584956 Test MSE 383.638797993034 Test RE 0.9984443030844234\n",
      "105 Train Loss 1.3956494 Test MSE 383.5202404449008 Test RE 0.9982900143942656\n",
      "106 Train Loss 1.322291 Test MSE 383.50496083676694 Test RE 0.9982701280485858\n",
      "107 Train Loss 1.2196481 Test MSE 383.527601693887 Test RE 0.9982995948874432\n",
      "108 Train Loss 1.2436846 Test MSE 383.5695276569487 Test RE 0.9983541587936184\n",
      "109 Train Loss 1.145676 Test MSE 383.5695276569487 Test RE 0.9983541587936184\n",
      "110 Train Loss 1.5954047 Test MSE 383.57812758570935 Test RE 0.9983653506713617\n",
      "111 Train Loss 2.7002196 Test MSE 383.5802211774616 Test RE 0.9983680752357486\n",
      "112 Train Loss 2.902162 Test MSE 382.4386155784689 Test RE 0.9968813042723629\n",
      "113 Train Loss 2.680264 Test MSE 382.5805453440828 Test RE 0.9970662672957551\n",
      "114 Train Loss 2.4626381 Test MSE 382.65128525737646 Test RE 0.9971584428154743\n",
      "115 Train Loss 2.3199553 Test MSE 382.91517136851326 Test RE 0.9975022165372153\n",
      "116 Train Loss 2.116762 Test MSE 383.06661578671196 Test RE 0.9976994550123052\n",
      "117 Train Loss 2.031667 Test MSE 383.2579832402771 Test RE 0.9979486327753645\n",
      "118 Train Loss 1.9913057 Test MSE 383.34271328107235 Test RE 0.9980589390953799\n",
      "119 Train Loss 1.9547317 Test MSE 383.38612746149505 Test RE 0.998115453387457\n",
      "120 Train Loss 1.9229188 Test MSE 383.4221961377067 Test RE 0.9981624032558033\n",
      "121 Train Loss 1.9105234 Test MSE 383.44719384056424 Test RE 0.998194940965845\n",
      "122 Train Loss 1.890794 Test MSE 383.4601002326713 Test RE 0.9982117398720682\n",
      "123 Train Loss 1.8858272 Test MSE 383.47373088357375 Test RE 0.9982294811635778\n",
      "124 Train Loss 1.7743847 Test MSE 383.50128648725973 Test RE 0.9982653458390797\n",
      "125 Train Loss 1.7618349 Test MSE 383.5581306816569 Test RE 0.9983393266688261\n",
      "126 Train Loss 1.7410866 Test MSE 383.5673848927421 Test RE 0.9983513701980834\n",
      "127 Train Loss 1.7045156 Test MSE 383.58246915374446 Test RE 0.9983710007052362\n",
      "128 Train Loss 1.640944 Test MSE 383.60413162873147 Test RE 0.9983991913594429\n",
      "129 Train Loss 1.5386689 Test MSE 383.6280513684713 Test RE 0.9984303186004874\n",
      "130 Train Loss 1.4415365 Test MSE 383.64906306026796 Test RE 0.998457660739327\n",
      "131 Train Loss 1.353894 Test MSE 383.6634076692207 Test RE 0.9984763266924095\n",
      "132 Train Loss 1.2846217 Test MSE 383.6718308759059 Test RE 0.9984872872455152\n",
      "133 Train Loss 1.224471 Test MSE 383.6742627602738 Test RE 0.9984904516709201\n",
      "134 Train Loss 1.2043782 Test MSE 383.67482471498806 Test RE 0.9984911828982468\n",
      "135 Train Loss 1.1960691 Test MSE 383.67499219219854 Test RE 0.998491400823022\n",
      "136 Train Loss 1.1909287 Test MSE 383.67518089729475 Test RE 0.9984916463698995\n",
      "137 Train Loss 1.1038468 Test MSE 383.6767884903779 Test RE 0.998493738199998\n",
      "138 Train Loss 1.1177824 Test MSE 383.6787949428909 Test RE 0.9984963490272762\n",
      "139 Train Loss 1.0472517 Test MSE 383.6787949428909 Test RE 0.9984963490272762\n",
      "140 Train Loss 1.0862896 Test MSE 383.69172412540416 Test RE 0.9985131725173279\n",
      "141 Train Loss 1.0742887 Test MSE 383.69172412540416 Test RE 0.9985131725173279\n",
      "142 Train Loss 0.99446505 Test MSE 383.69172412540416 Test RE 0.9985131725173279\n",
      "143 Train Loss 1.417041 Test MSE 383.69172412540416 Test RE 0.9985131725173279\n",
      "144 Train Loss 2.5036645 Test MSE 383.7140086904125 Test RE 0.9985421685931196\n",
      "145 Train Loss 4.305744 Test MSE 383.86517182180455 Test RE 0.998738835765368\n",
      "146 Train Loss 4.7426085 Test MSE 384.54492778126854 Test RE 0.999622737769802\n",
      "147 Train Loss 4.3657527 Test MSE 382.5342678364826 Test RE 0.9970059621681787\n",
      "148 Train Loss 4.0578084 Test MSE 382.24462255117186 Test RE 0.9966284368257128\n",
      "149 Train Loss 3.7626724 Test MSE 382.60373666902507 Test RE 0.9970964869941468\n",
      "150 Train Loss 3.4446447 Test MSE 382.8433354324702 Test RE 0.9974086450730338\n",
      "151 Train Loss 3.1534364 Test MSE 383.01963983403226 Test RE 0.9976382785518527\n",
      "152 Train Loss 2.8728437 Test MSE 383.0829154616318 Test RE 0.9977206810903902\n",
      "153 Train Loss 2.656402 Test MSE 383.0748288199699 Test RE 0.9977101504038469\n",
      "154 Train Loss 2.446288 Test MSE 383.1819080230481 Test RE 0.9978495834011438\n",
      "155 Train Loss 2.2745864 Test MSE 383.2830429014468 Test RE 0.9979812581177088\n",
      "156 Train Loss 2.1269135 Test MSE 383.35201701764817 Test RE 0.9980710504787379\n",
      "157 Train Loss 1.9857045 Test MSE 383.39241623267736 Test RE 0.9981236395130236\n",
      "158 Train Loss 1.8499379 Test MSE 383.427327244677 Test RE 0.9981690821348324\n",
      "159 Train Loss 1.7218531 Test MSE 383.45693571438176 Test RE 0.9982076209744005\n",
      "160 Train Loss 1.6287631 Test MSE 383.47932075988575 Test RE 0.9982367567062639\n",
      "161 Train Loss 1.537767 Test MSE 383.49259291549953 Test RE 0.9982540309609956\n",
      "162 Train Loss 1.463512 Test MSE 383.5016594163111 Test RE 0.9982658312117121\n",
      "163 Train Loss 1.4162425 Test MSE 383.5086018346005 Test RE 0.9982748668278948\n",
      "164 Train Loss 1.379819 Test MSE 383.51437623217623 Test RE 0.9982823821929284\n",
      "165 Train Loss 1.3639708 Test MSE 383.51938871840144 Test RE 0.9982889058862366\n",
      "166 Train Loss 1.3440112 Test MSE 383.52229521317633 Test RE 0.99829268863631\n",
      "167 Train Loss 1.3346835 Test MSE 383.52560296040303 Test RE 0.9982969935917111\n",
      "168 Train Loss 1.3031187 Test MSE 383.52838947865376 Test RE 0.9983006201654234\n",
      "169 Train Loss 1.2873001 Test MSE 383.53471637028446 Test RE 0.9983088543847976\n",
      "170 Train Loss 1.2716662 Test MSE 383.5386110172535 Test RE 0.9983139230924236\n",
      "171 Train Loss 1.2559116 Test MSE 383.54274187156426 Test RE 0.9983192991851434\n",
      "172 Train Loss 1.2404945 Test MSE 383.5471491303205 Test RE 0.9983250349719972\n",
      "173 Train Loss 1.2241573 Test MSE 383.55179024536045 Test RE 0.9983310750733623\n",
      "174 Train Loss 1.2099699 Test MSE 383.5567526664334 Test RE 0.9983375332926517\n",
      "175 Train Loss 1.190767 Test MSE 383.56165495016216 Test RE 0.9983439132066715\n",
      "176 Train Loss 1.1845573 Test MSE 383.56730863173266 Test RE 0.9983512709517837\n",
      "177 Train Loss 1.1456388 Test MSE 383.5819272698513 Test RE 0.9983702955096146\n",
      "178 Train Loss 1.1657196 Test MSE 383.5819272698513 Test RE 0.9983702955096146\n",
      "179 Train Loss 1.0741143 Test MSE 383.5819272698513 Test RE 0.9983702955096146\n",
      "180 Train Loss 1.0366577 Test MSE 383.6493228517998 Test RE 0.9984579987967163\n",
      "181 Train Loss 1.0460203 Test MSE 383.6715210685002 Test RE 0.9984868841160778\n",
      "182 Train Loss 0.9971729 Test MSE 383.6715210685002 Test RE 0.9984868841160778\n",
      "183 Train Loss 1.0121202 Test MSE 383.6980639267303 Test RE 0.9985214217817608\n",
      "184 Train Loss 0.9374579 Test MSE 383.6980639267303 Test RE 0.9985214217817608\n",
      "185 Train Loss 0.9516044 Test MSE 383.7393232269792 Test RE 0.9985751061648203\n",
      "186 Train Loss 0.88822466 Test MSE 383.7393232269792 Test RE 0.9985751061648203\n",
      "187 Train Loss 0.88283956 Test MSE 383.77717752054787 Test RE 0.9986243575977137\n",
      "188 Train Loss 0.8405622 Test MSE 383.79323897102483 Test RE 0.9986452540824343\n",
      "189 Train Loss 1.1050615 Test MSE 383.7871684536205 Test RE 0.9986373561874844\n",
      "190 Train Loss 2.0502791 Test MSE 383.7871684536205 Test RE 0.9986373561874844\n",
      "191 Train Loss 4.193953 Test MSE 383.7871684536205 Test RE 0.9986373561874844\n",
      "192 Train Loss 6.6482472 Test MSE 383.7871684536205 Test RE 0.9986373561874844\n",
      "193 Train Loss 9.015984 Test MSE 383.79712867422995 Test RE 0.9986503146507419\n",
      "194 Train Loss 10.901955 Test MSE 381.8941370616429 Test RE 0.996171420700339\n",
      "195 Train Loss 9.122955 Test MSE 377.9580108889734 Test RE 0.9910244285607973\n",
      "196 Train Loss 8.343029 Test MSE 380.9623495939732 Test RE 0.9949553940053216\n",
      "197 Train Loss 7.659935 Test MSE 381.84804839837045 Test RE 0.9961113077134927\n",
      "198 Train Loss 7.0354304 Test MSE 381.9693529542157 Test RE 0.9962695162539252\n",
      "199 Train Loss 6.5063915 Test MSE 382.1440765225762 Test RE 0.996497351107427\n",
      "Training time: 56.24\n",
      "Training time: 56.24\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 14.149864 Test MSE 386.5620577391544 Test RE 1.00224106858457\n",
      "1 Train Loss 10.616251 Test MSE 385.40362715213456 Test RE 1.0007382078935343\n",
      "2 Train Loss 10.21407 Test MSE 387.89432340941016 Test RE 1.0039666684620656\n",
      "3 Train Loss 9.997821 Test MSE 386.96858879867386 Test RE 1.0027679374911336\n",
      "4 Train Loss 9.199507 Test MSE 383.4945534034194 Test RE 0.9982565825910705\n",
      "5 Train Loss 8.780101 Test MSE 382.98989402588 Test RE 0.9975995388503649\n",
      "6 Train Loss 8.072786 Test MSE 383.01744532705527 Test RE 0.9976354205687743\n",
      "7 Train Loss 7.54582 Test MSE 382.5709616989192 Test RE 0.9970537789592872\n",
      "8 Train Loss 6.9472656 Test MSE 382.716900126052 Test RE 0.9972439326834189\n",
      "9 Train Loss 6.4430094 Test MSE 382.88481321758195 Test RE 0.9974626739369995\n",
      "10 Train Loss 5.9379063 Test MSE 383.1771877121256 Test RE 0.9978434372670298\n",
      "11 Train Loss 5.463424 Test MSE 383.37045017261715 Test RE 0.9980950458881447\n",
      "12 Train Loss 4.9979715 Test MSE 383.44078368246386 Test RE 0.9981865974256767\n",
      "13 Train Loss 4.574202 Test MSE 383.5325514625119 Test RE 0.9983060368437043\n",
      "14 Train Loss 4.182339 Test MSE 383.60258156365 Test RE 0.998397174194924\n",
      "15 Train Loss 3.8229606 Test MSE 383.66382997124214 Test RE 0.9984768762085305\n",
      "16 Train Loss 3.4952788 Test MSE 383.7155861047675 Test RE 0.9985442210502836\n",
      "17 Train Loss 3.1935606 Test MSE 383.7592717788162 Test RE 0.9986010611128593\n",
      "18 Train Loss 2.9232585 Test MSE 383.8004236291612 Test RE 0.9986546014216303\n",
      "19 Train Loss 2.6904001 Test MSE 383.83177024953125 Test RE 0.9986953827829559\n",
      "20 Train Loss 2.4741993 Test MSE 383.8587557022306 Test RE 0.9987304890136428\n",
      "21 Train Loss 2.3047903 Test MSE 383.88204456546276 Test RE 0.9987607852419323\n",
      "22 Train Loss 2.1380064 Test MSE 383.90166335821067 Test RE 0.998786306402382\n",
      "23 Train Loss 1.9921037 Test MSE 383.91680775142146 Test RE 0.9988060065819194\n",
      "24 Train Loss 1.8927281 Test MSE 383.93055053219535 Test RE 0.9988238831750652\n",
      "25 Train Loss 1.814228 Test MSE 383.94260404547555 Test RE 0.9988395621076631\n",
      "26 Train Loss 1.7301483 Test MSE 383.9532979398641 Test RE 0.9988534722732703\n",
      "27 Train Loss 1.6629555 Test MSE 383.9620181851383 Test RE 0.9988648150561846\n",
      "28 Train Loss 1.6232377 Test MSE 383.9684972663664 Test RE 0.9988732425811286\n",
      "29 Train Loss 1.5834599 Test MSE 383.9738093774408 Test RE 0.998880152141808\n",
      "30 Train Loss 1.5470573 Test MSE 383.9788882067413 Test RE 0.998886758223896\n",
      "31 Train Loss 1.50849 Test MSE 383.982951644596 Test RE 0.9988920435451107\n",
      "32 Train Loss 1.4807798 Test MSE 383.98609495087163 Test RE 0.9988961320302766\n",
      "33 Train Loss 1.4717913 Test MSE 383.98834825504525 Test RE 0.9988990628831783\n",
      "34 Train Loss 1.4397346 Test MSE 383.9903162474135 Test RE 0.9989016226264917\n",
      "35 Train Loss 1.4441053 Test MSE 383.99352311868455 Test RE 0.9989057937502058\n",
      "36 Train Loss 1.3953127 Test MSE 383.99902518474636 Test RE 0.9989129501547391\n",
      "37 Train Loss 1.550664 Test MSE 383.99902518474636 Test RE 0.9989129501547391\n",
      "38 Train Loss 2.1638806 Test MSE 383.99902518474636 Test RE 0.9989129501547391\n",
      "39 Train Loss 3.4784646 Test MSE 383.8003120166008 Test RE 0.998654456212821\n",
      "40 Train Loss 3.551106 Test MSE 383.6721997079692 Test RE 0.9984877671791564\n",
      "41 Train Loss 3.2530007 Test MSE 383.71967990134357 Test RE 0.9985495476856331\n",
      "42 Train Loss 3.0094583 Test MSE 383.74174337981606 Test RE 0.9985782550479544\n",
      "43 Train Loss 2.7621753 Test MSE 383.76878247152797 Test RE 0.9986134351839111\n",
      "44 Train Loss 2.532901 Test MSE 383.78200700142025 Test RE 0.998630640959966\n",
      "45 Train Loss 2.3552215 Test MSE 383.7908588861026 Test RE 0.9986421575398751\n",
      "46 Train Loss 2.2190228 Test MSE 383.7947533956558 Test RE 0.998647224377016\n",
      "47 Train Loss 2.1201985 Test MSE 383.7976476358859 Test RE 0.9986509898265146\n",
      "48 Train Loss 2.0450883 Test MSE 383.80019875372136 Test RE 0.998654308856912\n",
      "49 Train Loss 1.9841061 Test MSE 383.80350830651923 Test RE 0.9986586146025157\n",
      "50 Train Loss 1.9077789 Test MSE 383.8066118718664 Test RE 0.9986626523404952\n",
      "51 Train Loss 1.8638858 Test MSE 383.8112336578921 Test RE 0.9986686652530571\n",
      "52 Train Loss 1.8180178 Test MSE 383.8148568648827 Test RE 0.9986733789956899\n",
      "53 Train Loss 1.7760061 Test MSE 383.8196920058365 Test RE 0.99867966941314\n",
      "54 Train Loss 1.7264702 Test MSE 383.82532476766414 Test RE 0.9986869974687331\n",
      "55 Train Loss 1.6879265 Test MSE 383.8318624917735 Test RE 0.9986955027859139\n",
      "56 Train Loss 1.6267194 Test MSE 383.8378197910232 Test RE 0.9987032529305295\n",
      "57 Train Loss 1.5621051 Test MSE 383.8473103666365 Test RE 0.9987155995645248\n",
      "58 Train Loss 1.4983739 Test MSE 383.85933217550445 Test RE 0.9987312389525328\n",
      "59 Train Loss 1.4245251 Test MSE 383.8741762285537 Test RE 0.9987505495110217\n",
      "60 Train Loss 1.3225259 Test MSE 383.89347485682595 Test RE 0.9987756544471478\n",
      "61 Train Loss 1.218705 Test MSE 383.9244752603688 Test RE 0.9988159805080408\n",
      "62 Train Loss 1.2093934 Test MSE 383.9692362510597 Test RE 0.9988742037949871\n",
      "63 Train Loss 1.1836463 Test MSE 383.9730816195446 Test RE 0.9988792055365385\n",
      "64 Train Loss 1.1421199 Test MSE 384.04562570556743 Test RE 0.9989735602715502\n",
      "65 Train Loss 1.4186018 Test MSE 384.0486473176115 Test RE 0.9989774901491505\n",
      "66 Train Loss 2.92849 Test MSE 384.05665706106674 Test RE 0.9989879074644437\n",
      "67 Train Loss 2.6854029 Test MSE 383.6514286641008 Test RE 0.9984607390104029\n",
      "68 Train Loss 2.730964 Test MSE 383.5568357096508 Test RE 0.9983376413668229\n",
      "69 Train Loss 2.5684626 Test MSE 383.5569734255116 Test RE 0.9983378205930844\n",
      "70 Train Loss 2.4685705 Test MSE 383.5547945002665 Test RE 0.9983349848910628\n",
      "71 Train Loss 2.2585368 Test MSE 383.61326168627437 Test RE 0.9984110726024722\n",
      "72 Train Loss 2.0734103 Test MSE 383.67961796430956 Test RE 0.998497419953598\n",
      "73 Train Loss 1.91978 Test MSE 383.70266300261704 Test RE 0.9985274059949536\n",
      "74 Train Loss 1.773374 Test MSE 383.7455321792305 Test RE 0.9985831846698092\n",
      "75 Train Loss 1.6284685 Test MSE 383.78115604208244 Test RE 0.9986295338281508\n",
      "76 Train Loss 1.4852765 Test MSE 383.82271851650074 Test RE 0.9986836068201757\n",
      "77 Train Loss 1.3483578 Test MSE 383.86837290739373 Test RE 0.9987430000423906\n",
      "78 Train Loss 1.2249063 Test MSE 383.920055103685 Test RE 0.9988102307628125\n",
      "79 Train Loss 1.1518656 Test MSE 383.97852343961034 Test RE 0.998886283769239\n",
      "80 Train Loss 1.2235321 Test MSE 384.0200154235616 Test RE 0.9989402511808884\n",
      "81 Train Loss 1.5484653 Test MSE 384.0200154235616 Test RE 0.9989402511808884\n",
      "82 Train Loss 1.4996283 Test MSE 383.868753910453 Test RE 0.9987434956863025\n",
      "83 Train Loss 1.6936357 Test MSE 383.86304618288705 Test RE 0.9987360705222144\n",
      "84 Train Loss 1.6699946 Test MSE 383.96339486935483 Test RE 0.9988666057543886\n",
      "85 Train Loss 1.5809252 Test MSE 383.96105681634094 Test RE 0.9988635645704316\n",
      "86 Train Loss 1.610684 Test MSE 383.93893636614234 Test RE 0.9988347913008688\n",
      "87 Train Loss 1.4820988 Test MSE 383.93893636614234 Test RE 0.9988347913008688\n",
      "88 Train Loss 1.9168262 Test MSE 383.9140658469551 Test RE 0.9988024398775124\n",
      "89 Train Loss 1.8523122 Test MSE 383.9871749611147 Test RE 0.998897536791165\n",
      "90 Train Loss 1.7481959 Test MSE 383.99645917258977 Test RE 0.998909612611038\n",
      "91 Train Loss 1.5919263 Test MSE 383.97080649202724 Test RE 0.9988762462393348\n",
      "92 Train Loss 1.6287793 Test MSE 383.93517781812204 Test RE 0.9988299022711825\n",
      "93 Train Loss 1.5333449 Test MSE 383.93517781812204 Test RE 0.9988299022711825\n",
      "94 Train Loss 2.0197864 Test MSE 383.93517781812204 Test RE 0.9988299022711825\n",
      "95 Train Loss 3.628606 Test MSE 383.93517781812204 Test RE 0.9988299022711825\n",
      "96 Train Loss 7.23625 Test MSE 383.94517077385456 Test RE 0.998842900817067\n",
      "97 Train Loss 8.271541 Test MSE 382.10726711750146 Test RE 0.996449356960395\n",
      "98 Train Loss 7.07921 Test MSE 383.6917294671034 Test RE 0.9985131794679041\n",
      "99 Train Loss 6.750265 Test MSE 383.65771152582414 Test RE 0.9984689146154022\n",
      "100 Train Loss 6.2649727 Test MSE 383.4010810351516 Test RE 0.9981349184206788\n",
      "101 Train Loss 5.8893833 Test MSE 383.46313855031934 Test RE 0.9982156944925565\n",
      "102 Train Loss 5.5334835 Test MSE 383.305214682575 Test RE 0.9980101228202417\n",
      "103 Train Loss 5.134444 Test MSE 383.3309002944034 Test RE 0.9980435610180547\n",
      "104 Train Loss 4.71119 Test MSE 383.342355661576 Test RE 0.9980584735518776\n",
      "105 Train Loss 4.3256283 Test MSE 383.33861125267026 Test RE 0.9980535991255227\n",
      "106 Train Loss 3.960421 Test MSE 383.35204162034444 Test RE 0.9980710825057489\n",
      "107 Train Loss 3.726055 Test MSE 383.36539555226705 Test RE 0.9980884660798194\n",
      "108 Train Loss 3.4905941 Test MSE 383.40227944302836 Test RE 0.9981364783690888\n",
      "109 Train Loss 3.2903147 Test MSE 383.4975953897103 Test RE 0.9982605418087311\n",
      "110 Train Loss 3.0637352 Test MSE 383.62765913852456 Test RE 0.9984298081915519\n",
      "111 Train Loss 2.807995 Test MSE 383.6692854989228 Test RE 0.9984839751300956\n",
      "112 Train Loss 2.6014326 Test MSE 383.73383496623154 Test RE 0.9985679653014493\n",
      "113 Train Loss 2.426746 Test MSE 383.7628299163451 Test RE 0.9986056905145928\n",
      "114 Train Loss 2.2652857 Test MSE 383.7939697187235 Test RE 0.9986462047992521\n",
      "115 Train Loss 2.1439984 Test MSE 383.8155130689713 Test RE 0.9986742327058351\n",
      "116 Train Loss 2.0203562 Test MSE 383.831517668594 Test RE 0.9986950541865799\n",
      "117 Train Loss 1.9453838 Test MSE 383.8463550729976 Test RE 0.9987143567952946\n",
      "118 Train Loss 1.8774463 Test MSE 383.8552086096123 Test RE 0.998725874558877\n",
      "119 Train Loss 1.810638 Test MSE 383.8633408361859 Test RE 0.9987364538370764\n",
      "120 Train Loss 1.7506813 Test MSE 383.8711836599687 Test RE 0.9987466565227342\n",
      "121 Train Loss 1.7274988 Test MSE 383.8777093747785 Test RE 0.9987551457092456\n",
      "122 Train Loss 1.6775328 Test MSE 383.8810134224486 Test RE 0.9987594438586704\n",
      "123 Train Loss 1.6481179 Test MSE 383.8865341871119 Test RE 0.998766625636132\n",
      "124 Train Loss 1.6225692 Test MSE 383.889832133613 Test RE 0.9987709157994107\n",
      "125 Train Loss 1.5902714 Test MSE 383.8929184791263 Test RE 0.9987749306829542\n",
      "126 Train Loss 1.5775424 Test MSE 383.8963954007254 Test RE 0.9987794536294571\n",
      "127 Train Loss 1.5506539 Test MSE 383.89809932875124 Test RE 0.9987816701733406\n",
      "128 Train Loss 1.5291524 Test MSE 383.9011288800846 Test RE 0.9987856111336845\n",
      "129 Train Loss 1.536574 Test MSE 383.9031446006717 Test RE 0.9987882332542306\n",
      "130 Train Loss 1.4900256 Test MSE 383.9031446006717 Test RE 0.9987882332542306\n",
      "131 Train Loss 1.5025268 Test MSE 383.90756710384755 Test RE 0.9987939861784703\n",
      "132 Train Loss 1.4221197 Test MSE 383.90756710384755 Test RE 0.9987939861784703\n",
      "133 Train Loss 1.4339498 Test MSE 383.9151945740854 Test RE 0.9988039081417456\n",
      "134 Train Loss 1.353181 Test MSE 383.9151945740854 Test RE 0.9988039081417456\n",
      "135 Train Loss 1.4080032 Test MSE 383.9226220057867 Test RE 0.99881356979624\n",
      "136 Train Loss 1.5043621 Test MSE 383.9226220057867 Test RE 0.99881356979624\n",
      "137 Train Loss 1.5359099 Test MSE 383.911436552353 Test RE 0.9987990196454943\n",
      "138 Train Loss 1.5574447 Test MSE 383.90759632102987 Test RE 0.9987940241849437\n",
      "139 Train Loss 1.5424931 Test MSE 383.9042108798782 Test RE 0.9987896203051059\n",
      "140 Train Loss 1.4295766 Test MSE 383.9042108798782 Test RE 0.9987896203051059\n",
      "141 Train Loss 2.1501684 Test MSE 383.9042108798782 Test RE 0.9987896203051059\n",
      "142 Train Loss 4.3160787 Test MSE 383.9042108798782 Test RE 0.9987896203051059\n",
      "143 Train Loss 7.0406394 Test MSE 383.5705012325026 Test RE 0.9983554258032691\n",
      "144 Train Loss 7.132076 Test MSE 382.31270044893785 Test RE 0.9967171828068787\n",
      "145 Train Loss 6.245369 Test MSE 383.238511460356 Test RE 0.997923281597021\n",
      "146 Train Loss 5.757799 Test MSE 383.383049987556 Test RE 0.9981114473994468\n",
      "147 Train Loss 5.2793236 Test MSE 383.31366008384225 Test RE 0.9980211173869822\n",
      "148 Train Loss 4.911961 Test MSE 383.2598406605918 Test RE 0.9979510510000313\n",
      "149 Train Loss 4.508527 Test MSE 383.3028552682347 Test RE 0.9980070512170796\n",
      "150 Train Loss 4.1117063 Test MSE 383.4187605756118 Test RE 0.9981579313490732\n",
      "151 Train Loss 3.7708557 Test MSE 383.5034001699672 Test RE 0.9982680968250162\n",
      "152 Train Loss 3.450134 Test MSE 383.4904523935524 Test RE 0.9982512450041304\n",
      "153 Train Loss 3.1935685 Test MSE 383.4546656082601 Test RE 0.9982046662220229\n",
      "154 Train Loss 2.9628718 Test MSE 383.48111831029036 Test RE 0.9982390963093222\n",
      "155 Train Loss 2.764906 Test MSE 383.5096173543165 Test RE 0.9982761885285468\n",
      "156 Train Loss 2.5849953 Test MSE 383.52175533372974 Test RE 0.9982919859941162\n",
      "157 Train Loss 2.4369426 Test MSE 383.52512931274265 Test RE 0.9982963771515339\n",
      "158 Train Loss 2.3310661 Test MSE 383.5295295105272 Test RE 0.9983021038804649\n",
      "159 Train Loss 2.2362797 Test MSE 383.53777838695873 Test RE 0.9983128394637572\n",
      "160 Train Loss 2.1354797 Test MSE 383.5477626821828 Test RE 0.9983258334708789\n",
      "161 Train Loss 2.041017 Test MSE 383.5600687595895 Test RE 0.9983418489161983\n",
      "162 Train Loss 1.9381969 Test MSE 383.57317665628807 Test RE 0.9983589075871736\n",
      "163 Train Loss 1.8320618 Test MSE 383.5882336882085 Test RE 0.9983785025110827\n",
      "164 Train Loss 1.716246 Test MSE 383.60283895051083 Test RE 0.998397509143493\n",
      "165 Train Loss 1.5934023 Test MSE 383.6194790610862 Test RE 0.9984191633951052\n",
      "166 Train Loss 1.5251178 Test MSE 383.63549308265283 Test RE 0.9984400024557253\n",
      "167 Train Loss 1.4914573 Test MSE 383.64424369844585 Test RE 0.998451389456133\n",
      "168 Train Loss 1.5342072 Test MSE 383.6516290407386 Test RE 0.9984609997525308\n",
      "169 Train Loss 1.8740454 Test MSE 383.6516290407386 Test RE 0.9984609997525308\n",
      "170 Train Loss 2.0496535 Test MSE 383.5963196862212 Test RE 0.9983890253104479\n",
      "171 Train Loss 2.1389246 Test MSE 383.5761349440501 Test RE 0.9983627574747879\n",
      "172 Train Loss 2.1818025 Test MSE 383.5682344614235 Test RE 0.9983524758285681\n",
      "173 Train Loss 2.164221 Test MSE 383.56530355299407 Test RE 0.998348661532944\n",
      "174 Train Loss 2.0589297 Test MSE 383.56530355299407 Test RE 0.998348661532944\n",
      "175 Train Loss 2.000475 Test MSE 383.6607332169361 Test RE 0.9984728465821184\n",
      "176 Train Loss 1.9058424 Test MSE 383.71415306419846 Test RE 0.9985423564456566\n",
      "177 Train Loss 2.0116844 Test MSE 383.76143524951345 Test RE 0.9986038759518066\n",
      "178 Train Loss 1.8494287 Test MSE 383.7295898451 Test RE 0.9985624418717849\n",
      "179 Train Loss 1.9715054 Test MSE 383.80036729695394 Test RE 0.9986545281329932\n",
      "180 Train Loss 1.8227624 Test MSE 383.7619478556327 Test RE 0.9986045428899606\n",
      "181 Train Loss 1.8551241 Test MSE 383.8251383920466 Test RE 0.9986867550004584\n",
      "182 Train Loss 1.725774 Test MSE 383.77813415565987 Test RE 0.9986256022242638\n",
      "183 Train Loss 2.4585457 Test MSE 383.75381481191266 Test RE 0.9985939611510952\n",
      "184 Train Loss 4.566898 Test MSE 383.7627298997738 Test RE 0.9986055603858832\n",
      "185 Train Loss 6.237024 Test MSE 383.37492767610905 Test RE 0.9981008744033611\n",
      "186 Train Loss 6.241476 Test MSE 383.38515846813897 Test RE 0.9981141920378872\n",
      "187 Train Loss 5.701202 Test MSE 383.5920507935258 Test RE 0.9983834699554348\n",
      "188 Train Loss 5.205466 Test MSE 383.27478944555855 Test RE 0.9979705130054659\n",
      "189 Train Loss 4.7710514 Test MSE 383.32594181143037 Test RE 0.9980371060231624\n",
      "190 Train Loss 4.354452 Test MSE 383.3748364744546 Test RE 0.9981007556834739\n",
      "191 Train Loss 3.9686203 Test MSE 383.4367461398402 Test RE 0.9981813420750276\n",
      "192 Train Loss 3.6177406 Test MSE 383.48721174992943 Test RE 0.9982470271893905\n",
      "193 Train Loss 3.3000484 Test MSE 383.5351080523501 Test RE 0.9983093641425297\n",
      "194 Train Loss 3.0271118 Test MSE 383.58314071308786 Test RE 0.998371874656908\n",
      "195 Train Loss 2.821328 Test MSE 383.6334066583219 Test RE 0.9984372874145153\n",
      "196 Train Loss 2.714245 Test MSE 383.6918446881578 Test RE 0.9985133293926012\n",
      "197 Train Loss 2.627597 Test MSE 383.7788445006762 Test RE 0.9986265264149984\n",
      "198 Train Loss 2.3865998 Test MSE 383.8366422010429 Test RE 0.9987017209503736\n",
      "199 Train Loss 2.9575574 Test MSE 383.83146211250437 Test RE 0.9986949819106054\n",
      "Training time: 64.99\n",
      "Training time: 64.99\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 10.128061 Test MSE 386.46744182550384 Test RE 1.0021184055401806\n",
      "1 Train Loss 9.296504 Test MSE 386.94312299921364 Test RE 1.0027349416510578\n",
      "2 Train Loss 9.343943 Test MSE 389.33640606308785 Test RE 1.0058311708459446\n",
      "3 Train Loss 8.577847 Test MSE 388.2374444471368 Test RE 1.0044106114615956\n",
      "4 Train Loss 7.8936415 Test MSE 385.4329268023944 Test RE 1.000776246874194\n",
      "5 Train Loss 7.355656 Test MSE 383.9683347707467 Test RE 0.9988730312193307\n",
      "6 Train Loss 7.2847586 Test MSE 383.8432365349791 Test RE 0.9987102997878801\n",
      "7 Train Loss 6.7667546 Test MSE 383.4190646294272 Test RE 0.9981583271221787\n",
      "8 Train Loss 6.27982 Test MSE 383.37289678954744 Test RE 0.998098230734995\n",
      "9 Train Loss 5.7960443 Test MSE 383.42060343719874 Test RE 0.9981603301162804\n",
      "10 Train Loss 5.330738 Test MSE 383.4394597569507 Test RE 0.9981848741793501\n",
      "11 Train Loss 4.9001226 Test MSE 383.45576164571213 Test RE 0.9982060928168925\n",
      "12 Train Loss 4.4866433 Test MSE 383.51695272024494 Test RE 0.9982857354679118\n",
      "13 Train Loss 4.12177 Test MSE 383.6128834351966 Test RE 0.9984105803747587\n",
      "14 Train Loss 3.7995281 Test MSE 383.69894848353493 Test RE 0.9985225727497903\n",
      "15 Train Loss 3.493855 Test MSE 383.7557767770278 Test RE 0.9985965138345299\n",
      "16 Train Loss 3.223192 Test MSE 383.78991417826734 Test RE 0.9986409284516496\n",
      "17 Train Loss 2.9453866 Test MSE 383.8202440500061 Test RE 0.9986803876085611\n",
      "18 Train Loss 2.708162 Test MSE 383.85687867798777 Test RE 0.9987280471732474\n",
      "19 Train Loss 2.4602735 Test MSE 383.89577023654596 Test RE 0.9987786403873958\n",
      "20 Train Loss 2.2362115 Test MSE 383.9402498863257 Test RE 0.998836499890975\n",
      "21 Train Loss 2.0382497 Test MSE 383.9768449334338 Test RE 0.9988841005239179\n",
      "22 Train Loss 1.8561035 Test MSE 384.0139043327014 Test RE 0.9989323028465824\n",
      "23 Train Loss 1.7194269 Test MSE 384.0455105824465 Test RE 0.9989734105432951\n",
      "24 Train Loss 1.6341472 Test MSE 384.07034173437575 Test RE 0.999005705230899\n",
      "25 Train Loss 1.5311905 Test MSE 384.0858492701999 Test RE 0.9990258733598867\n",
      "26 Train Loss 1.4610144 Test MSE 384.10990034529635 Test RE 0.999057151875112\n",
      "27 Train Loss 1.380494 Test MSE 384.1285512295383 Test RE 0.9990814067473365\n",
      "28 Train Loss 1.314209 Test MSE 384.15595428142143 Test RE 0.9991170424626226\n",
      "29 Train Loss 1.2317876 Test MSE 384.1803372324023 Test RE 0.9991487496834106\n",
      "30 Train Loss 1.1517074 Test MSE 384.21404377350046 Test RE 0.9991925795029913\n",
      "31 Train Loss 1.0617315 Test MSE 384.24836405058966 Test RE 0.9992372054100604\n",
      "32 Train Loss 1.0898781 Test MSE 384.2867621483694 Test RE 0.9992871312562102\n",
      "33 Train Loss 1.0898376 Test MSE 384.2867621483694 Test RE 0.9992871312562102\n",
      "34 Train Loss 1.1627971 Test MSE 384.2867621483694 Test RE 0.9992871312562102\n",
      "35 Train Loss 1.72669 Test MSE 384.2773819906634 Test RE 0.9992749352492064\n",
      "36 Train Loss 2.0735624 Test MSE 384.19714564885095 Test RE 0.9991706065081409\n",
      "37 Train Loss 2.1582851 Test MSE 384.1935471258657 Test RE 0.9991659272089143\n",
      "38 Train Loss 2.0757253 Test MSE 384.3186681876178 Test RE 0.999328614122402\n",
      "39 Train Loss 2.5392559 Test MSE 384.1778473191041 Test RE 0.9991455118839339\n",
      "40 Train Loss 3.123179 Test MSE 384.1894497284145 Test RE 0.9991605991771584\n",
      "41 Train Loss 2.9172897 Test MSE 383.8412382645918 Test RE 0.9987077001643552\n",
      "42 Train Loss 2.722047 Test MSE 383.7477164310101 Test RE 0.9985860265973513\n",
      "43 Train Loss 2.5595775 Test MSE 383.74375247608134 Test RE 0.9985808690940563\n",
      "44 Train Loss 2.490416 Test MSE 383.72025303270624 Test RE 0.9985502934121089\n",
      "45 Train Loss 2.4355369 Test MSE 383.718974806616 Test RE 0.9985486302550431\n",
      "46 Train Loss 2.3648057 Test MSE 383.7220926100596 Test RE 0.9985526869635174\n",
      "47 Train Loss 2.267706 Test MSE 383.7307909401853 Test RE 0.9985640046487178\n",
      "48 Train Loss 2.0888138 Test MSE 383.7553265785594 Test RE 0.9985959280886202\n",
      "49 Train Loss 1.97156 Test MSE 383.88038070656347 Test RE 0.9987586207765125\n",
      "50 Train Loss 2.5064886 Test MSE 383.9065891046895 Test RE 0.9987927139708046\n",
      "51 Train Loss 2.654266 Test MSE 384.05395101752487 Test RE 0.9989843880494205\n",
      "52 Train Loss 2.4938228 Test MSE 383.59046396514634 Test RE 0.998381404916732\n",
      "53 Train Loss 2.3508546 Test MSE 383.4030134484094 Test RE 0.9981374338109771\n",
      "54 Train Loss 2.1741793 Test MSE 383.41442959181836 Test RE 0.9981522938862303\n",
      "55 Train Loss 2.0798156 Test MSE 383.4504801578854 Test RE 0.998199218449614\n",
      "56 Train Loss 2.03274 Test MSE 383.44336933584344 Test RE 0.9981899629521255\n",
      "57 Train Loss 2.0089657 Test MSE 383.43788952058753 Test RE 0.9981828303263358\n",
      "58 Train Loss 1.9777445 Test MSE 383.4353128835944 Test RE 0.9981794765118096\n",
      "59 Train Loss 1.9601923 Test MSE 383.4339572598614 Test RE 0.9981777119938603\n",
      "60 Train Loss 1.947201 Test MSE 383.4339738749749 Test RE 0.9981777336205775\n",
      "61 Train Loss 1.9195855 Test MSE 383.4346092470615 Test RE 0.9981785606391126\n",
      "62 Train Loss 1.8863933 Test MSE 383.43745050257763 Test RE 0.9981822588904171\n",
      "63 Train Loss 1.8173437 Test MSE 383.4447623863629 Test RE 0.9981917761635339\n",
      "64 Train Loss 1.7505145 Test MSE 383.4647401449721 Test RE 0.9982177790935114\n",
      "65 Train Loss 1.6246922 Test MSE 383.498903682785 Test RE 0.998262244578521\n",
      "66 Train Loss 1.5461292 Test MSE 383.6076144307901 Test RE 0.9984037236605572\n",
      "67 Train Loss 1.4236403 Test MSE 383.7552469481049 Test RE 0.9985958244826945\n",
      "68 Train Loss 1.479725 Test MSE 383.7774766652476 Test RE 0.998624746798978\n",
      "69 Train Loss 1.5680702 Test MSE 383.78838886898865 Test RE 0.9986389439834139\n",
      "70 Train Loss 1.625548 Test MSE 383.8622951700004 Test RE 0.9987350935279011\n",
      "71 Train Loss 1.6996163 Test MSE 383.86594508483256 Test RE 0.9987398417011548\n",
      "72 Train Loss 1.7876046 Test MSE 383.8700159546426 Test RE 0.9987451374680008\n",
      "73 Train Loss 1.8407139 Test MSE 383.8680254607658 Test RE 0.9987425480515641\n",
      "74 Train Loss 1.8434734 Test MSE 383.8625772407787 Test RE 0.9987354604745079\n",
      "75 Train Loss 1.7594151 Test MSE 383.8589618546347 Test RE 0.9987307571990893\n",
      "76 Train Loss 1.7647157 Test MSE 383.7255976044891 Test RE 0.9985572474431987\n",
      "77 Train Loss 1.7375728 Test MSE 383.6957463260988 Test RE 0.9985184061588143\n",
      "78 Train Loss 1.9152236 Test MSE 383.6957463260988 Test RE 0.9985184061588143\n",
      "79 Train Loss 2.4903197 Test MSE 383.70304281056895 Test RE 0.9985279001908399\n",
      "80 Train Loss 5.0117116 Test MSE 383.70304281056895 Test RE 0.9985279001908399\n",
      "81 Train Loss 7.784961 Test MSE 383.24661215301865 Test RE 0.9979338283281632\n",
      "82 Train Loss 6.82177 Test MSE 383.60091001342784 Test RE 0.9983949989321435\n",
      "83 Train Loss 6.283696 Test MSE 383.5895125794544 Test RE 0.9983801668171677\n",
      "84 Train Loss 5.888561 Test MSE 383.4696212784417 Test RE 0.9982241322443961\n",
      "85 Train Loss 5.456005 Test MSE 382.9189449056672 Test RE 0.9975071315976297\n",
      "86 Train Loss 5.662802 Test MSE 382.87524375112747 Test RE 0.9974502090325296\n",
      "87 Train Loss 5.503071 Test MSE 382.7765791501552 Test RE 0.9973216823526313\n",
      "88 Train Loss 5.1638956 Test MSE 382.7428802046836 Test RE 0.9972777802037458\n",
      "89 Train Loss 4.771784 Test MSE 382.86881641567516 Test RE 0.9974418368876856\n",
      "90 Train Loss 4.3540926 Test MSE 382.9363511977439 Test RE 0.9975298031099703\n",
      "91 Train Loss 3.9646232 Test MSE 382.9444064290733 Test RE 0.997540294789646\n",
      "92 Train Loss 3.6320302 Test MSE 382.94921668772963 Test RE 0.9975465599441816\n",
      "93 Train Loss 3.3205352 Test MSE 382.99977059623996 Test RE 0.9976124018510202\n",
      "94 Train Loss 3.030539 Test MSE 383.1003627406381 Test RE 0.9977434011233017\n",
      "95 Train Loss 2.7725005 Test MSE 383.24604197792206 Test RE 0.9979330859899265\n",
      "96 Train Loss 2.5522184 Test MSE 383.38548042751717 Test RE 0.9981146111362144\n",
      "97 Train Loss 2.3399603 Test MSE 383.4848341065946 Test RE 0.9982439325893664\n",
      "98 Train Loss 2.1540098 Test MSE 383.5338502222036 Test RE 0.9983077271285811\n",
      "99 Train Loss 2.0099595 Test MSE 383.5904945753034 Test RE 0.9983814447516781\n",
      "100 Train Loss 1.8941075 Test MSE 383.6404665145756 Test RE 0.9984464742986296\n",
      "101 Train Loss 1.7798533 Test MSE 383.68053542466356 Test RE 0.9984986137637534\n",
      "102 Train Loss 1.7074039 Test MSE 383.7166600479466 Test RE 0.9985456184120846\n",
      "103 Train Loss 1.6447284 Test MSE 383.7404202500739 Test RE 0.9985765335128975\n",
      "104 Train Loss 1.5798956 Test MSE 383.7618491574596 Test RE 0.9986044144764342\n",
      "105 Train Loss 1.5243921 Test MSE 383.78364244714135 Test RE 0.9986327687362022\n",
      "106 Train Loss 1.5005271 Test MSE 383.8005942186368 Test RE 0.9986548233598246\n",
      "107 Train Loss 1.4616818 Test MSE 383.8091753528175 Test RE 0.9986659874164577\n",
      "108 Train Loss 1.4191628 Test MSE 383.8222593777811 Test RE 0.998683009494343\n",
      "109 Train Loss 1.3870639 Test MSE 383.8361834997266 Test RE 0.9987011242044138\n",
      "110 Train Loss 1.3765033 Test MSE 383.8458785030391 Test RE 0.9987137368110208\n",
      "111 Train Loss 1.388286 Test MSE 383.8483002685888 Test RE 0.9987168873550836\n",
      "112 Train Loss 1.3290038 Test MSE 383.8483002685888 Test RE 0.9987168873550836\n",
      "113 Train Loss 1.3190328 Test MSE 383.8643398451232 Test RE 0.9987377534480162\n",
      "114 Train Loss 1.3298407 Test MSE 383.86710577823817 Test RE 0.9987413516421729\n",
      "115 Train Loss 1.2710729 Test MSE 383.86710577823817 Test RE 0.9987413516421729\n",
      "116 Train Loss 1.2687278 Test MSE 383.8842230115817 Test RE 0.9987636191117374\n",
      "117 Train Loss 1.2216454 Test MSE 383.88685148868166 Test RE 0.9987670384015256\n",
      "118 Train Loss 1.2297305 Test MSE 383.89990144338265 Test RE 0.9987840144372901\n",
      "119 Train Loss 1.1802526 Test MSE 383.89990144338265 Test RE 0.9987840144372901\n",
      "120 Train Loss 1.2161452 Test MSE 383.9128847635336 Test RE 0.9988009035051634\n",
      "121 Train Loss 1.2075008 Test MSE 383.9128847635336 Test RE 0.9988009035051634\n",
      "122 Train Loss 1.1396637 Test MSE 383.9128847635336 Test RE 0.9988009035051634\n",
      "123 Train Loss 1.5195326 Test MSE 383.9128847635336 Test RE 0.9988009035051634\n",
      "124 Train Loss 2.9073296 Test MSE 383.9128847635336 Test RE 0.9988009035051634\n",
      "125 Train Loss 3.6120253 Test MSE 383.89520920010125 Test RE 0.9987779105650515\n",
      "126 Train Loss 3.3341315 Test MSE 384.1285560885795 Test RE 0.999081413066286\n",
      "127 Train Loss 3.1446111 Test MSE 384.1677608727815 Test RE 0.999132395701165\n",
      "128 Train Loss 3.074369 Test MSE 384.1358668341286 Test RE 0.9990909202939129\n",
      "129 Train Loss 3.329381 Test MSE 384.06654958066247 Test RE 0.9990007733315381\n",
      "130 Train Loss 3.1028402 Test MSE 383.7495937130251 Test RE 0.9985884691204145\n",
      "131 Train Loss 2.8465939 Test MSE 383.6035031084427 Test RE 0.9983983734401956\n",
      "132 Train Loss 2.635571 Test MSE 383.54303528321265 Test RE 0.9983196810440905\n",
      "133 Train Loss 2.400241 Test MSE 383.61344510098075 Test RE 0.9984113112845906\n",
      "134 Train Loss 2.1899033 Test MSE 383.69144993466267 Test RE 0.9985128157424761\n",
      "135 Train Loss 2.0232704 Test MSE 383.7096847022556 Test RE 0.9985365424020278\n",
      "136 Train Loss 1.8621156 Test MSE 383.7368297303653 Test RE 0.998571861843037\n",
      "137 Train Loss 1.7493911 Test MSE 383.76340424099095 Test RE 0.9986064377516884\n",
      "138 Train Loss 1.6701941 Test MSE 383.7790508535673 Test RE 0.9986267948892068\n",
      "139 Train Loss 1.5716329 Test MSE 383.7902099470982 Test RE 0.998641313254366\n",
      "140 Train Loss 1.5033298 Test MSE 383.8040656139354 Test RE 0.9986593396605702\n",
      "141 Train Loss 1.4474608 Test MSE 383.8130623862815 Test RE 0.9986710444064067\n",
      "142 Train Loss 1.3786111 Test MSE 383.8198622909401 Test RE 0.9986798909497832\n",
      "143 Train Loss 1.3433319 Test MSE 383.82754039060524 Test RE 0.9986898799135414\n",
      "144 Train Loss 1.2995965 Test MSE 383.83168243058486 Test RE 0.9986952685344906\n",
      "145 Train Loss 1.2795962 Test MSE 383.83675876963486 Test RE 0.9987018725998409\n",
      "146 Train Loss 1.2866493 Test MSE 383.83879052541596 Test RE 0.9987045158011129\n",
      "147 Train Loss 1.2483835 Test MSE 383.83879052541596 Test RE 0.9987045158011129\n",
      "148 Train Loss 1.2339534 Test MSE 383.84367625514153 Test RE 0.9987108718351217\n",
      "149 Train Loss 1.220223 Test MSE 383.8458255785583 Test RE 0.9987136679599393\n",
      "150 Train Loss 1.2549013 Test MSE 383.8467413874177 Test RE 0.9987148593631261\n",
      "151 Train Loss 1.2265445 Test MSE 383.8467413874177 Test RE 0.9987148593631261\n",
      "152 Train Loss 1.2179545 Test MSE 383.8467413874177 Test RE 0.9987148593631261\n",
      "153 Train Loss 1.2786195 Test MSE 383.8467413874177 Test RE 0.9987148593631261\n",
      "154 Train Loss 1.3945191 Test MSE 383.84463341937146 Test RE 0.9987121170422018\n",
      "155 Train Loss 2.1477356 Test MSE 383.84463341937146 Test RE 0.9987121170422018\n",
      "156 Train Loss 2.7782269 Test MSE 383.350657813052 Test RE 0.9980692811076359\n",
      "157 Train Loss 2.762525 Test MSE 383.3181813064368 Test RE 0.9980270032486017\n",
      "158 Train Loss 2.5386727 Test MSE 383.14792944887716 Test RE 0.9978053403705551\n",
      "159 Train Loss 2.4099615 Test MSE 383.3671837140717 Test RE 0.9980907938089422\n",
      "160 Train Loss 2.2085931 Test MSE 383.4327172121689 Test RE 0.9981760979102017\n",
      "161 Train Loss 2.07582 Test MSE 383.4924113443225 Test RE 0.9982537946406801\n",
      "162 Train Loss 1.9642617 Test MSE 383.5237713455001 Test RE 0.9982946097901866\n",
      "163 Train Loss 1.8595759 Test MSE 383.54712139343593 Test RE 0.9983249988741839\n",
      "164 Train Loss 1.7660102 Test MSE 383.5686979093837 Test RE 0.9983530789602109\n",
      "165 Train Loss 1.6778089 Test MSE 383.5894568760754 Test RE 0.9983800943267201\n",
      "166 Train Loss 1.6233143 Test MSE 383.608443797408 Test RE 0.9984048029434506\n",
      "167 Train Loss 1.5770746 Test MSE 383.62094486757286 Test RE 0.9984210708684843\n",
      "168 Train Loss 1.5274798 Test MSE 383.63188487917546 Test RE 0.9984353071352652\n",
      "169 Train Loss 1.4871252 Test MSE 383.64269540489244 Test RE 0.9984493747023154\n",
      "170 Train Loss 1.4719051 Test MSE 383.6504706093772 Test RE 0.9984594923310567\n",
      "171 Train Loss 1.4451638 Test MSE 383.65415187900953 Test RE 0.9984642826155378\n",
      "172 Train Loss 1.4118414 Test MSE 383.65999672889427 Test RE 0.9984718882306365\n",
      "173 Train Loss 1.3928597 Test MSE 383.6662394740041 Test RE 0.9984800115431983\n",
      "174 Train Loss 1.3809327 Test MSE 383.66970719708087 Test RE 0.9984845238562424\n",
      "175 Train Loss 1.3524736 Test MSE 383.67259336516736 Test RE 0.9984882794156389\n",
      "176 Train Loss 1.3305502 Test MSE 383.67788621871347 Test RE 0.9984951665820611\n",
      "177 Train Loss 1.3314117 Test MSE 383.6812527442013 Test RE 0.9984995471473409\n",
      "178 Train Loss 1.3005087 Test MSE 383.68198561114264 Test RE 0.9985005007604696\n",
      "179 Train Loss 1.2924409 Test MSE 383.6871181126399 Test RE 0.9985071791925682\n",
      "180 Train Loss 1.2912598 Test MSE 383.68828183419106 Test RE 0.9985086934256338\n",
      "181 Train Loss 1.258264 Test MSE 383.68951849838174 Test RE 0.9985103025690568\n",
      "182 Train Loss 1.2851944 Test MSE 383.69404625857607 Test RE 0.9985161940537678\n",
      "183 Train Loss 1.1730381 Test MSE 383.69404625857607 Test RE 0.9985161940537678\n",
      "184 Train Loss 1.7993456 Test MSE 383.69404625857607 Test RE 0.9985161940537678\n",
      "185 Train Loss 3.2368393 Test MSE 383.68374101626176 Test RE 0.9985027849058705\n",
      "186 Train Loss 5.9237475 Test MSE 383.0771409108327 Test RE 0.9977131612947594\n",
      "187 Train Loss 5.4623814 Test MSE 382.52658396915825 Test RE 0.9969959488168924\n",
      "188 Train Loss 5.019618 Test MSE 382.69817451450655 Test RE 0.9972195357585381\n",
      "189 Train Loss 4.7421103 Test MSE 383.01058489033187 Test RE 0.9976264859296249\n",
      "190 Train Loss 4.3520555 Test MSE 383.115323650575 Test RE 0.9977628829678579\n",
      "191 Train Loss 3.9840195 Test MSE 383.01259849513883 Test RE 0.997629108341285\n",
      "192 Train Loss 3.6511312 Test MSE 382.9897643737742 Test RE 0.9975993699935704\n",
      "193 Train Loss 3.3317962 Test MSE 383.0579069809782 Test RE 0.9976881138776819\n",
      "194 Train Loss 3.0599992 Test MSE 383.10101813242204 Test RE 0.9977442545713948\n",
      "195 Train Loss 2.814084 Test MSE 383.1350618328928 Test RE 0.9977885851139545\n",
      "196 Train Loss 2.5914276 Test MSE 383.16906753751465 Test RE 0.9978328642134499\n",
      "197 Train Loss 2.3883147 Test MSE 383.19988114442305 Test RE 0.9978729851602065\n",
      "198 Train Loss 2.2257879 Test MSE 383.22734042508455 Test RE 0.9979087372374619\n",
      "199 Train Loss 2.0968902 Test MSE 383.2460439126542 Test RE 0.9979330885088477\n",
      "Training time: 62.05\n",
      "Training time: 62.05\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 8.263834 Test MSE 385.89467121288146 Test RE 1.0013755269179134\n",
      "1 Train Loss 21.251196 Test MSE 390.01959111280024 Test RE 1.0067132712877624\n",
      "2 Train Loss 14.850789 Test MSE 390.00784145333216 Test RE 1.0066981071428367\n",
      "3 Train Loss 13.831453 Test MSE 388.1096392738967 Test RE 1.0042452752217232\n",
      "4 Train Loss 13.145004 Test MSE 387.8947217781887 Test RE 1.0039671840005109\n",
      "5 Train Loss 12.3438015 Test MSE 385.8318699640463 Test RE 1.001294040702688\n",
      "6 Train Loss 11.797705 Test MSE 385.6447982949282 Test RE 1.0010512711540045\n",
      "7 Train Loss 11.71422 Test MSE 385.7938327918216 Test RE 1.00124468328101\n",
      "8 Train Loss 11.847039 Test MSE 385.0724639272175 Test RE 1.000308166644442\n",
      "9 Train Loss 11.128847 Test MSE 383.28442517778575 Test RE 0.9979830576815841\n",
      "10 Train Loss 10.617372 Test MSE 382.64465867213323 Test RE 0.9971498086042685\n",
      "11 Train Loss 10.24749 Test MSE 382.5395017369515 Test RE 0.9970127827494476\n",
      "12 Train Loss 9.803985 Test MSE 382.5650669332777 Test RE 0.997046097481094\n",
      "13 Train Loss 9.073731 Test MSE 382.6351929353725 Test RE 0.9971374749472328\n",
      "14 Train Loss 8.421351 Test MSE 382.7457962054928 Test RE 0.9972815791735316\n",
      "15 Train Loss 7.749539 Test MSE 382.8147342851233 Test RE 0.9973713875817889\n",
      "16 Train Loss 7.122945 Test MSE 382.9296971448523 Test RE 0.9975211363369092\n",
      "17 Train Loss 6.541198 Test MSE 383.0856312033747 Test RE 0.9977242175922674\n",
      "18 Train Loss 6.00202 Test MSE 383.17765862028784 Test RE 0.9978440504200174\n",
      "19 Train Loss 5.4881597 Test MSE 383.3023961897314 Test RE 0.9980064535647084\n",
      "20 Train Loss 5.0139465 Test MSE 383.38524781910695 Test RE 0.9981143083471157\n",
      "21 Train Loss 4.5889187 Test MSE 383.4563419367446 Test RE 0.9982068481189154\n",
      "22 Train Loss 4.195769 Test MSE 383.5125120029021 Test RE 0.9982799559090422\n",
      "23 Train Loss 3.8407063 Test MSE 383.5522116507559 Test RE 0.9983316235025401\n",
      "24 Train Loss 3.527136 Test MSE 383.5832005824322 Test RE 0.9983719525694398\n",
      "25 Train Loss 3.2449462 Test MSE 383.61494702506496 Test RE 0.9984132657736028\n",
      "26 Train Loss 2.9668958 Test MSE 383.6494732501289 Test RE 0.9984581945046076\n",
      "27 Train Loss 2.7330375 Test MSE 383.67646058370826 Test RE 0.9984933115220803\n",
      "28 Train Loss 2.544333 Test MSE 383.6973809002909 Test RE 0.9985205330401967\n",
      "29 Train Loss 2.3934164 Test MSE 383.7147393429246 Test RE 0.9985431192842334\n",
      "30 Train Loss 2.2500522 Test MSE 383.73164805671297 Test RE 0.9985651198644555\n",
      "31 Train Loss 2.1468158 Test MSE 383.7490660477548 Test RE 0.9985877825781428\n",
      "32 Train Loss 2.0651255 Test MSE 383.76325893011546 Test RE 0.998606248691987\n",
      "33 Train Loss 1.9765991 Test MSE 383.77634166997973 Test RE 0.998623270116175\n",
      "34 Train Loss 1.9006401 Test MSE 383.78863395279785 Test RE 0.9986392628442814\n",
      "35 Train Loss 1.8507594 Test MSE 383.79885181246556 Test RE 0.998652556473936\n",
      "36 Train Loss 1.8073229 Test MSE 383.8066273778568 Test RE 0.9986626725137449\n",
      "37 Train Loss 1.7577757 Test MSE 383.8141409962771 Test RE 0.9986724476622098\n",
      "38 Train Loss 1.7156674 Test MSE 383.8223880417717 Test RE 0.998683176882408\n",
      "39 Train Loss 1.6642612 Test MSE 383.82914542905036 Test RE 0.9986919680049465\n",
      "40 Train Loss 1.6271147 Test MSE 383.8364828275478 Test RE 0.9987015136139926\n",
      "41 Train Loss 1.5661662 Test MSE 383.84259216601146 Test RE 0.9987094615053028\n",
      "42 Train Loss 1.4999195 Test MSE 383.8515870773016 Test RE 0.998721163242638\n",
      "43 Train Loss 1.4341629 Test MSE 383.86090981519163 Test RE 0.9987332913142817\n",
      "44 Train Loss 1.3622913 Test MSE 383.8706917097972 Test RE 0.9987460165505674\n",
      "45 Train Loss 1.2927752 Test MSE 383.88192439688487 Test RE 0.9987606289182982\n",
      "46 Train Loss 1.2267514 Test MSE 383.8935709644835 Test RE 0.9987757794687866\n",
      "47 Train Loss 1.1635647 Test MSE 383.90540931853656 Test RE 0.9987911792710203\n",
      "48 Train Loss 1.0995482 Test MSE 383.9177255687352 Test RE 0.9988072004875772\n",
      "49 Train Loss 1.0382758 Test MSE 383.9313946669421 Test RE 0.9988249812141262\n",
      "50 Train Loss 0.9810747 Test MSE 383.94545173570293 Test RE 0.9988432662816147\n",
      "51 Train Loss 0.96009225 Test MSE 383.95962305577444 Test RE 0.9988616996254043\n",
      "52 Train Loss 0.91156465 Test MSE 383.9637861067505 Test RE 0.9988671146490843\n",
      "53 Train Loss 0.8879537 Test MSE 383.97636541698273 Test RE 0.9988834768124693\n",
      "54 Train Loss 0.9198116 Test MSE 383.9835287563894 Test RE 0.9988927941932313\n",
      "55 Train Loss 1.2766079 Test MSE 383.9835287563894 Test RE 0.9988927941932313\n",
      "56 Train Loss 1.4342886 Test MSE 383.88388478924935 Test RE 0.9987631791298172\n",
      "57 Train Loss 1.5814981 Test MSE 383.8581975016661 Test RE 0.9987297628453355\n",
      "58 Train Loss 1.6748221 Test MSE 383.83387278571007 Test RE 0.998698118083237\n",
      "59 Train Loss 1.7136511 Test MSE 383.8161075704528 Test RE 0.9986750061413275\n",
      "60 Train Loss 1.7134031 Test MSE 383.80889461335676 Test RE 0.9986656221763591\n",
      "61 Train Loss 1.6804105 Test MSE 383.8079640638909 Test RE 0.9986644115369792\n",
      "62 Train Loss 1.5727084 Test MSE 383.8079640638909 Test RE 0.9986644115369792\n",
      "63 Train Loss 1.472522 Test MSE 383.8222137731285 Test RE 0.9986829501640258\n",
      "64 Train Loss 1.375222 Test MSE 383.83887803796017 Test RE 0.9987046296499084\n",
      "65 Train Loss 1.2699476 Test MSE 383.8589686606446 Test RE 0.9987307660530854\n",
      "66 Train Loss 1.1896898 Test MSE 383.8875749973984 Test RE 0.9987679795855166\n",
      "67 Train Loss 1.1572193 Test MSE 383.9129388885454 Test RE 0.9988009739119025\n",
      "68 Train Loss 1.1752422 Test MSE 383.92572813932674 Test RE 0.9988176102485037\n",
      "69 Train Loss 1.337414 Test MSE 383.92572813932674 Test RE 0.9988176102485037\n",
      "70 Train Loss 1.7922662 Test MSE 384.0060776426087 Test RE 0.9989221230414933\n",
      "71 Train Loss 1.9579508 Test MSE 383.95406398825594 Test RE 0.9988544687091891\n",
      "72 Train Loss 1.9127945 Test MSE 383.9505326948093 Test RE 0.9988498753780065\n",
      "73 Train Loss 1.7728649 Test MSE 383.95851832788287 Test RE 0.9988602626628866\n",
      "74 Train Loss 1.707679 Test MSE 383.9594784374357 Test RE 0.9988615115148263\n",
      "75 Train Loss 1.6955377 Test MSE 383.9621928116688 Test RE 0.9988650421988043\n",
      "76 Train Loss 1.7103777 Test MSE 383.9636519465403 Test RE 0.9988669401427394\n",
      "77 Train Loss 1.6244719 Test MSE 383.9636519465403 Test RE 0.9988669401427394\n",
      "78 Train Loss 1.622515 Test MSE 383.97671783805237 Test RE 0.9988839352098269\n",
      "79 Train Loss 1.5760391 Test MSE 383.97755756968843 Test RE 0.9988850274557152\n",
      "80 Train Loss 1.5933067 Test MSE 383.98166553225246 Test RE 0.9988903706994059\n",
      "81 Train Loss 1.4840915 Test MSE 383.98166553225246 Test RE 0.9988903706994059\n",
      "82 Train Loss 1.5135686 Test MSE 383.99207834906076 Test RE 0.9989039145647267\n",
      "83 Train Loss 1.4180562 Test MSE 383.99207834906076 Test RE 0.9989039145647267\n",
      "84 Train Loss 2.0218043 Test MSE 383.99207834906076 Test RE 0.9989039145647267\n",
      "85 Train Loss 4.146315 Test MSE 383.99207834906076 Test RE 0.9989039145647267\n",
      "86 Train Loss 8.250369 Test MSE 383.99196344097226 Test RE 0.9989037651057214\n",
      "87 Train Loss 12.626893 Test MSE 384.00425031173137 Test RE 0.9989197463038356\n",
      "88 Train Loss 12.951233 Test MSE 379.51491973048246 Test RE 0.9930634765184403\n",
      "89 Train Loss 11.596128 Test MSE 381.97276769141604 Test RE 0.9962739694789667\n",
      "90 Train Loss 10.762204 Test MSE 382.67307073817517 Test RE 0.9971868280159921\n",
      "91 Train Loss 10.101627 Test MSE 382.9674158995413 Test RE 0.9975702632769695\n",
      "92 Train Loss 9.338774 Test MSE 383.0815923422635 Test RE 0.9977189580891236\n",
      "93 Train Loss 8.587171 Test MSE 383.10614079399545 Test RE 0.9977509252520056\n",
      "94 Train Loss 7.891802 Test MSE 383.17219185136446 Test RE 0.9978369323089022\n",
      "95 Train Loss 7.230092 Test MSE 383.2834959167396 Test RE 0.9979818478915674\n",
      "96 Train Loss 6.615928 Test MSE 383.36367769885476 Test RE 0.998086229869121\n",
      "97 Train Loss 6.0519896 Test MSE 383.42392314239316 Test RE 0.9981646512075711\n",
      "98 Train Loss 5.525716 Test MSE 383.45835537604614 Test RE 0.998209468790477\n",
      "99 Train Loss 5.137782 Test MSE 383.4732006003661 Test RE 0.9982287909669991\n",
      "100 Train Loss 4.8892922 Test MSE 383.22096015590205 Test RE 0.9979004302194177\n",
      "101 Train Loss 4.4654016 Test MSE 383.22232924139075 Test RE 0.9979022127547171\n",
      "102 Train Loss 4.0626235 Test MSE 383.31877135108186 Test RE 0.9980277713836537\n",
      "103 Train Loss 3.7129564 Test MSE 383.3864748843564 Test RE 0.9981159056313225\n",
      "104 Train Loss 3.4232483 Test MSE 383.42161445582207 Test RE 0.9981616461097462\n",
      "105 Train Loss 3.1707845 Test MSE 383.4596472253797 Test RE 0.9982111502444508\n",
      "106 Train Loss 2.9529085 Test MSE 383.4977740744575 Test RE 0.9982607743707004\n",
      "107 Train Loss 2.754113 Test MSE 383.5347026890524 Test RE 0.9983088365792447\n",
      "108 Train Loss 2.5602217 Test MSE 383.5744779870962 Test RE 0.9983606011285645\n",
      "109 Train Loss 2.3715582 Test MSE 383.6182682381383 Test RE 0.9984175877324308\n",
      "110 Train Loss 2.1583543 Test MSE 383.67409283259093 Test RE 0.9984902305573297\n",
      "111 Train Loss 2.0398488 Test MSE 383.7782877321557 Test RE 0.9986258020342472\n",
      "112 Train Loss 1.8917997 Test MSE 383.86173729715284 Test RE 0.9987343677892705\n",
      "113 Train Loss 1.751486 Test MSE 383.9279443258456 Test RE 0.9988204930494805\n",
      "114 Train Loss 1.6233908 Test MSE 383.95252125554094 Test RE 0.9988524620016701\n",
      "115 Train Loss 1.5644323 Test MSE 383.97161870569914 Test RE 0.9988773027005307\n",
      "116 Train Loss 1.5747545 Test MSE 383.9851175002495 Test RE 0.998894860666183\n",
      "117 Train Loss 1.4923557 Test MSE 383.9841169371383 Test RE 0.9988935592381394\n",
      "118 Train Loss 1.4824885 Test MSE 384.00825766370485 Test RE 0.9989249585020991\n",
      "119 Train Loss 1.5027817 Test MSE 384.0104274077484 Test RE 0.9989277805877885\n",
      "120 Train Loss 1.4113209 Test MSE 384.0104274077484 Test RE 0.9989277805877885\n",
      "121 Train Loss 1.4391102 Test MSE 384.0321815798305 Test RE 0.9989560747922311\n",
      "122 Train Loss 1.3736546 Test MSE 384.0321815798305 Test RE 0.9989560747922311\n",
      "123 Train Loss 1.7659597 Test MSE 384.0321815798305 Test RE 0.9989560747922311\n",
      "124 Train Loss 3.5597148 Test MSE 384.0269715987913 Test RE 0.9989492985894666\n",
      "125 Train Loss 6.014144 Test MSE 383.9253296189144 Test RE 0.9988170918548664\n",
      "126 Train Loss 5.5738688 Test MSE 384.17070645580907 Test RE 0.9991362260873731\n",
      "127 Train Loss 5.4660683 Test MSE 383.8999948074561 Test RE 0.9987841358889213\n",
      "128 Train Loss 5.079656 Test MSE 383.43945851269035 Test RE 0.9981848725597958\n",
      "129 Train Loss 4.7149324 Test MSE 383.43909833375335 Test RE 0.9981844037436075\n",
      "130 Train Loss 4.3114147 Test MSE 383.5085292222219 Test RE 0.9982747723226922\n",
      "131 Train Loss 3.956082 Test MSE 383.5077570051584 Test RE 0.9982737672795936\n",
      "132 Train Loss 3.6820955 Test MSE 383.50826877958593 Test RE 0.9982744333558411\n",
      "133 Train Loss 3.3910913 Test MSE 383.563755147428 Test RE 0.9983466464260372\n",
      "134 Train Loss 3.1516206 Test MSE 383.64259571846225 Test RE 0.9984492449828373\n",
      "135 Train Loss 2.9264412 Test MSE 383.6734517244637 Test RE 0.9984893963330738\n",
      "136 Train Loss 2.7239363 Test MSE 383.7020668086096 Test RE 0.9985266302428618\n",
      "137 Train Loss 2.5732431 Test MSE 383.7285925656273 Test RE 0.9985611442829373\n",
      "138 Train Loss 2.4522717 Test MSE 383.74715925556376 Test RE 0.9985853016577709\n",
      "139 Train Loss 2.3276567 Test MSE 383.7611055160433 Test RE 0.9986034469441448\n",
      "140 Train Loss 2.2183232 Test MSE 383.7746272756687 Test RE 0.9986210396035307\n",
      "141 Train Loss 2.1456902 Test MSE 383.7868840316758 Test RE 0.9986369861458899\n",
      "142 Train Loss 2.0151305 Test MSE 383.79855120486377 Test RE 0.9986521653802585\n",
      "143 Train Loss 1.9159812 Test MSE 383.81650327045804 Test RE 0.9986755209394246\n",
      "144 Train Loss 1.8526181 Test MSE 383.83299993571364 Test RE 0.9986969825475196\n",
      "145 Train Loss 1.7935293 Test MSE 383.84610689720444 Test RE 0.9987140339359468\n",
      "146 Train Loss 1.7380812 Test MSE 383.8587248427976 Test RE 0.9987304488683331\n",
      "147 Train Loss 1.7353534 Test MSE 383.869062187136 Test RE 0.998743896720858\n",
      "148 Train Loss 1.5772223 Test MSE 383.8727703963291 Test RE 0.9987487206865274\n",
      "149 Train Loss 2.9105778 Test MSE 383.87693743391765 Test RE 0.9987541415088508\n",
      "150 Train Loss 4.002072 Test MSE 384.23084331167155 Test RE 0.999214423824752\n",
      "151 Train Loss 3.7105932 Test MSE 383.7270970852919 Test RE 0.9985591984675369\n",
      "152 Train Loss 3.5048165 Test MSE 383.6098889687843 Test RE 0.9984066835911625\n",
      "153 Train Loss 3.2167373 Test MSE 383.62484808239526 Test RE 0.9984261501558149\n",
      "154 Train Loss 2.95198 Test MSE 383.65928664173623 Test RE 0.9984709642323052\n",
      "155 Train Loss 2.705121 Test MSE 383.6397268105294 Test RE 0.9984455117369118\n",
      "156 Train Loss 2.462253 Test MSE 383.67149361069534 Test RE 0.9984868483872615\n",
      "157 Train Loss 2.241272 Test MSE 383.7029859288295 Test RE 0.9985278261778668\n",
      "158 Train Loss 2.04508 Test MSE 383.7480728002731 Test RE 0.9985864902682327\n",
      "159 Train Loss 1.8889247 Test MSE 383.7956370004878 Test RE 0.9986483739615233\n",
      "160 Train Loss 1.8335024 Test MSE 383.8393439867599 Test RE 0.9987052358223275\n",
      "161 Train Loss 1.8144059 Test MSE 383.8579189734062 Test RE 0.998729400505134\n",
      "162 Train Loss 1.7909751 Test MSE 383.86592700998176 Test RE 0.9987398181876419\n",
      "163 Train Loss 1.8414106 Test MSE 383.87199764684965 Test RE 0.9987477154277518\n",
      "164 Train Loss 1.8293442 Test MSE 383.87199764684965 Test RE 0.9987477154277518\n",
      "165 Train Loss 1.7292196 Test MSE 383.87199764684965 Test RE 0.9987477154277518\n",
      "166 Train Loss 2.321884 Test MSE 383.87199764684965 Test RE 0.9987477154277518\n",
      "167 Train Loss 4.643989 Test MSE 383.8768383231521 Test RE 0.998754012577826\n",
      "168 Train Loss 6.878668 Test MSE 383.75693696355296 Test RE 0.9985980233327754\n",
      "169 Train Loss 6.3161244 Test MSE 383.55248627562486 Test RE 0.9983319809071304\n",
      "170 Train Loss 6.004657 Test MSE 383.41131205925086 Test RE 0.9981482359030549\n",
      "171 Train Loss 5.6940928 Test MSE 383.3053632378029 Test RE 0.9980103162165238\n",
      "172 Train Loss 5.3041224 Test MSE 383.25873852350384 Test RE 0.997949616099294\n",
      "173 Train Loss 4.8689995 Test MSE 383.26071813573185 Test RE 0.9979521934061018\n",
      "174 Train Loss 4.454963 Test MSE 383.289595330397 Test RE 0.997989788593373\n",
      "175 Train Loss 4.1149306 Test MSE 383.3426091722012 Test RE 0.9980588035680917\n",
      "176 Train Loss 3.800824 Test MSE 383.38294858612034 Test RE 0.9981113154035999\n",
      "177 Train Loss 3.4939597 Test MSE 383.4280020409 Test RE 0.9981699604765442\n",
      "178 Train Loss 3.2446647 Test MSE 383.4742220199555 Test RE 0.9982301204077024\n",
      "179 Train Loss 3.0091512 Test MSE 383.5125589092067 Test RE 0.9982800169574054\n",
      "180 Train Loss 2.8192956 Test MSE 383.5479470017388 Test RE 0.9983260733509801\n",
      "181 Train Loss 2.6283329 Test MSE 383.57819924546175 Test RE 0.9983654439282571\n",
      "182 Train Loss 2.4482565 Test MSE 383.60957693776174 Test RE 0.9984062775355178\n",
      "183 Train Loss 2.272558 Test MSE 383.6397060837395 Test RE 0.9984454847655516\n",
      "184 Train Loss 2.1070662 Test MSE 383.6722523708226 Test RE 0.9984878357053791\n",
      "185 Train Loss 1.9814422 Test MSE 383.704911871176 Test RE 0.9985303321586406\n",
      "186 Train Loss 1.8400662 Test MSE 383.7332265132315 Test RE 0.9985671736304267\n",
      "187 Train Loss 1.7156721 Test MSE 383.7665451151161 Test RE 0.9986105242417881\n",
      "188 Train Loss 1.5962709 Test MSE 383.79683212358105 Test RE 0.9986499288343379\n",
      "189 Train Loss 1.5496455 Test MSE 383.824299839385 Test RE 0.9986856640715299\n",
      "190 Train Loss 1.4895053 Test MSE 383.83552500621755 Test RE 0.9987002675388387\n",
      "191 Train Loss 1.4124204 Test MSE 383.84983784962895 Test RE 0.998718887633073\n",
      "192 Train Loss 1.3735887 Test MSE 383.8672781198332 Test RE 0.9987415758404121\n",
      "193 Train Loss 1.297418 Test MSE 383.8767388103158 Test RE 0.9987538831237395\n",
      "194 Train Loss 1.2572864 Test MSE 383.8932086810743 Test RE 0.9987753081923609\n",
      "195 Train Loss 1.1808549 Test MSE 383.90250778887804 Test RE 0.9987874048676978\n",
      "196 Train Loss 1.1412021 Test MSE 383.9184167967055 Test RE 0.9988080996426791\n",
      "197 Train Loss 1.0615631 Test MSE 383.9276265153107 Test RE 0.9988200796441196\n",
      "198 Train Loss 1.0428458 Test MSE 383.9436294982727 Test RE 0.9988408959816957\n",
      "199 Train Loss 1.0205567 Test MSE 383.94793547775976 Test RE 0.9988464970335422\n",
      "Training time: 66.88\n",
      "Training time: 66.88\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 17.468903 Test MSE 386.6643176399248 Test RE 1.002373624655494\n",
      "1 Train Loss 11.855728 Test MSE 386.52354216057574 Test RE 1.0021911375897354\n",
      "2 Train Loss 10.243059 Test MSE 387.0432163488788 Test RE 1.0028646255804792\n",
      "3 Train Loss 9.958637 Test MSE 384.89208113487916 Test RE 1.0000738477392648\n",
      "4 Train Loss 9.583906 Test MSE 384.4381885699615 Test RE 0.999483994101463\n",
      "5 Train Loss 8.929153 Test MSE 384.25483874012576 Test RE 0.9992456240840606\n",
      "6 Train Loss 8.462076 Test MSE 383.8996879423069 Test RE 0.9987837367067015\n",
      "7 Train Loss 7.884094 Test MSE 383.26622915044857 Test RE 0.9979593682993192\n",
      "8 Train Loss 7.332193 Test MSE 382.8453260904034 Test RE 0.9974112381661705\n",
      "9 Train Loss 6.7430134 Test MSE 382.67708595463677 Test RE 0.997192059518769\n",
      "10 Train Loss 6.2030206 Test MSE 382.67498822713895 Test RE 0.9971893263526777\n",
      "11 Train Loss 5.77999 Test MSE 382.85213375586767 Test RE 0.9974201059926693\n",
      "12 Train Loss 5.28253 Test MSE 383.0434349332762 Test RE 0.9976692672149595\n",
      "13 Train Loss 4.8975506 Test MSE 383.25486477294055 Test RE 0.9979445727470264\n",
      "14 Train Loss 4.484197 Test MSE 383.25842582874606 Test RE 0.9979492089935377\n",
      "15 Train Loss 4.110247 Test MSE 383.26994868395116 Test RE 0.9979642108004534\n",
      "16 Train Loss 3.8051834 Test MSE 383.34991442024346 Test RE 0.9980683133802164\n",
      "17 Train Loss 3.5518217 Test MSE 383.39458970978177 Test RE 0.9981264687236591\n",
      "18 Train Loss 3.3178818 Test MSE 383.4212534346306 Test RE 0.9981611761863279\n",
      "19 Train Loss 3.0913632 Test MSE 383.45610154919353 Test RE 0.9982065352325307\n",
      "20 Train Loss 2.9121184 Test MSE 383.49561300118353 Test RE 0.9982579616845975\n",
      "21 Train Loss 2.7208726 Test MSE 383.5242506892714 Test RE 0.9982952336448068\n",
      "22 Train Loss 2.4948347 Test MSE 383.5623527039845 Test RE 0.998344821271849\n",
      "23 Train Loss 2.285861 Test MSE 383.607652417791 Test RE 0.9984037730943546\n",
      "24 Train Loss 2.1579251 Test MSE 383.6550897875072 Test RE 0.9984655030735444\n",
      "25 Train Loss 2.28906 Test MSE 383.6984654088811 Test RE 0.9985219441826547\n",
      "26 Train Loss 2.2846777 Test MSE 383.68712577262653 Test RE 0.998507189159741\n",
      "27 Train Loss 2.257186 Test MSE 383.77386889541015 Test RE 0.9986200529113392\n",
      "28 Train Loss 2.1594863 Test MSE 383.787766809863 Test RE 0.998638134666694\n",
      "29 Train Loss 2.387462 Test MSE 383.8064227015846 Test RE 0.9986624062304583\n",
      "30 Train Loss 2.266278 Test MSE 383.7734873638817 Test RE 0.998619556518592\n",
      "31 Train Loss 2.4189818 Test MSE 383.7806597249697 Test RE 0.9986288880993555\n",
      "32 Train Loss 2.3197367 Test MSE 383.7650837807063 Test RE 0.9986086229487638\n",
      "33 Train Loss 2.4155328 Test MSE 383.77201780410377 Test RE 0.9986176445411016\n",
      "34 Train Loss 2.3070107 Test MSE 383.7611282554155 Test RE 0.9986034765297578\n",
      "35 Train Loss 2.2371104 Test MSE 383.7798099385808 Test RE 0.9986277824916536\n",
      "36 Train Loss 2.1594172 Test MSE 383.799824523678 Test RE 0.9986538219804885\n",
      "37 Train Loss 2.0999517 Test MSE 383.81997493110606 Test RE 0.998680037491783\n",
      "38 Train Loss 2.0221207 Test MSE 383.8353363166911 Test RE 0.9987000220635097\n",
      "39 Train Loss 1.9809706 Test MSE 383.8521523162833 Test RE 0.9987218985736158\n",
      "40 Train Loss 1.9268407 Test MSE 383.86133461818093 Test RE 0.9987338439425377\n",
      "41 Train Loss 1.9079562 Test MSE 383.87186909136165 Test RE 0.9987475481916528\n",
      "42 Train Loss 1.8960224 Test MSE 383.87566998470805 Test RE 0.9987524927106701\n",
      "43 Train Loss 1.8557577 Test MSE 383.87890663270724 Test RE 0.9987567031929903\n",
      "44 Train Loss 1.8144063 Test MSE 383.8877779010444 Test RE 0.998768243534718\n",
      "45 Train Loss 1.7838871 Test MSE 383.8971412756951 Test RE 0.9987804238967504\n",
      "46 Train Loss 1.7749223 Test MSE 383.90383884841214 Test RE 0.9987891363546226\n",
      "47 Train Loss 1.7810695 Test MSE 383.90560205054607 Test RE 0.9987914299825267\n",
      "48 Train Loss 1.7104826 Test MSE 383.90612427696624 Test RE 0.9987921093098052\n",
      "49 Train Loss 1.7359002 Test MSE 383.9213062886649 Test RE 0.9988118583091251\n",
      "50 Train Loss 1.5991224 Test MSE 383.9213062886649 Test RE 0.9988118583091251\n",
      "51 Train Loss 2.7751412 Test MSE 383.9213062886649 Test RE 0.9988118583091251\n",
      "52 Train Loss 2.8968008 Test MSE 383.4153710606091 Test RE 0.9981535193600045\n",
      "53 Train Loss 2.8169832 Test MSE 383.53097480156634 Test RE 0.9983039848773828\n",
      "54 Train Loss 2.8594718 Test MSE 383.63081187132667 Test RE 0.9984339108362187\n",
      "55 Train Loss 2.6627822 Test MSE 383.6359570915029 Test RE 0.9984406062643739\n",
      "56 Train Loss 2.5255814 Test MSE 383.7013444140858 Test RE 0.9985256902811419\n",
      "57 Train Loss 2.404768 Test MSE 383.7389869100155 Test RE 0.9985746685789372\n",
      "58 Train Loss 2.3496363 Test MSE 383.77262780939657 Test RE 0.9986184381917307\n",
      "59 Train Loss 2.3293507 Test MSE 383.78742630965974 Test RE 0.9986376916659098\n",
      "60 Train Loss 2.3240695 Test MSE 383.79241428519015 Test RE 0.9986441811492069\n",
      "61 Train Loss 2.1729827 Test MSE 383.8001431474784 Test RE 0.9986542365127389\n",
      "62 Train Loss 2.1622937 Test MSE 383.8356975783996 Test RE 0.9987004920462823\n",
      "63 Train Loss 2.1781802 Test MSE 383.8369724589543 Test RE 0.9987021505980899\n",
      "64 Train Loss 2.0779772 Test MSE 383.8369724589543 Test RE 0.9987021505980899\n",
      "65 Train Loss 2.1137462 Test MSE 383.85474222520446 Test RE 0.9987252678322953\n",
      "66 Train Loss 1.941285 Test MSE 383.85474222520446 Test RE 0.9987252678322953\n",
      "67 Train Loss 3.168797 Test MSE 383.85474222520446 Test RE 0.9987252678322953\n",
      "68 Train Loss 6.8073964 Test MSE 383.85474222520446 Test RE 0.9987252678322953\n",
      "69 Train Loss 12.006182 Test MSE 383.5195906058977 Test RE 0.9982891686396037\n",
      "70 Train Loss 10.323919 Test MSE 381.92469201861206 Test RE 0.9962112712284514\n",
      "71 Train Loss 9.487349 Test MSE 382.2044605962653 Test RE 0.9965760782110759\n",
      "72 Train Loss 8.758006 Test MSE 382.72737133487635 Test RE 0.9972575749840846\n",
      "73 Train Loss 8.080424 Test MSE 382.87516195831523 Test RE 0.9974501024909561\n",
      "74 Train Loss 7.4626985 Test MSE 382.91685604957246 Test RE 0.9975044108499093\n",
      "75 Train Loss 6.8841043 Test MSE 383.0122766130609 Test RE 0.9976286891396723\n",
      "76 Train Loss 6.3236556 Test MSE 383.11401521026403 Test RE 0.9977611791541354\n",
      "77 Train Loss 5.816167 Test MSE 383.18440416267606 Test RE 0.9978528335126173\n",
      "78 Train Loss 5.343426 Test MSE 383.21364409751527 Test RE 0.9978909047322767\n",
      "79 Train Loss 4.902067 Test MSE 383.24074099962485 Test RE 0.9979261843662381\n",
      "80 Train Loss 4.5070786 Test MSE 383.26157423406124 Test RE 0.9979533079799261\n",
      "81 Train Loss 4.1523943 Test MSE 383.28756828991624 Test RE 0.9979871496378676\n",
      "82 Train Loss 3.8395088 Test MSE 383.3224069982747 Test RE 0.9980325043481376\n",
      "83 Train Loss 3.5314558 Test MSE 383.3799526242341 Test RE 0.9981074155049318\n",
      "84 Train Loss 3.214542 Test MSE 383.45995655673005 Test RE 0.998211552865617\n",
      "85 Train Loss 3.0901132 Test MSE 383.5344169767541 Test RE 0.9983084647365366\n",
      "86 Train Loss 2.8929992 Test MSE 383.577993898947 Test RE 0.9983651766934503\n",
      "87 Train Loss 2.7260103 Test MSE 383.5968358165592 Test RE 0.9983896969783775\n",
      "88 Train Loss 3.3836145 Test MSE 383.59654015483943 Test RE 0.9983893122180716\n",
      "89 Train Loss 3.4423099 Test MSE 383.4009674095019 Test RE 0.9981347705158572\n",
      "90 Train Loss 3.306808 Test MSE 383.48690948493413 Test RE 0.9982466337796713\n",
      "91 Train Loss 3.1022644 Test MSE 383.59975244008143 Test RE 0.9983934925275944\n",
      "92 Train Loss 3.0088322 Test MSE 383.63733339474885 Test RE 0.9984423972276419\n",
      "93 Train Loss 2.8761268 Test MSE 383.6141670790382 Test RE 0.9984122508120357\n",
      "94 Train Loss 2.866816 Test MSE 383.5960983450697 Test RE 0.998388737267267\n",
      "95 Train Loss 2.8210394 Test MSE 383.59842569136765 Test RE 0.9983917659644005\n",
      "96 Train Loss 2.964772 Test MSE 383.60040161207377 Test RE 0.9983943373258692\n",
      "97 Train Loss 2.8936057 Test MSE 383.60040161207377 Test RE 0.9983943373258692\n",
      "98 Train Loss 2.7319202 Test MSE 383.60040161207377 Test RE 0.9983943373258692\n",
      "99 Train Loss 3.2814145 Test MSE 383.61470103588704 Test RE 0.9984129456623823\n",
      "100 Train Loss 4.2359905 Test MSE 383.61470103588704 Test RE 0.9984129456623823\n",
      "101 Train Loss 4.817148 Test MSE 383.35223820496014 Test RE 0.9980713384133401\n",
      "102 Train Loss 4.695384 Test MSE 383.19881895487845 Test RE 0.9978716021600565\n",
      "103 Train Loss 4.312592 Test MSE 383.4193392258408 Test RE 0.9981586845517813\n",
      "104 Train Loss 3.938446 Test MSE 383.43785965562324 Test RE 0.9981827914534231\n",
      "105 Train Loss 3.5976288 Test MSE 383.4254663513527 Test RE 0.9981666599177611\n",
      "106 Train Loss 3.3344903 Test MSE 383.4233821140679 Test RE 0.9981639469798126\n",
      "107 Train Loss 3.1382446 Test MSE 383.42701396558573 Test RE 0.9981686743579933\n",
      "108 Train Loss 2.9674249 Test MSE 383.424847289022 Test RE 0.9981658541188736\n",
      "109 Train Loss 2.781722 Test MSE 383.4267718842197 Test RE 0.9981683592549025\n",
      "110 Train Loss 2.5452404 Test MSE 383.4464731723633 Test RE 0.9981940029387818\n",
      "111 Train Loss 2.425109 Test MSE 383.5852864216135 Test RE 0.9983746670268273\n",
      "112 Train Loss 2.2628286 Test MSE 383.63920649568036 Test RE 0.9984448346613046\n",
      "113 Train Loss 2.0641015 Test MSE 383.691808023278 Test RE 0.9985132816845608\n",
      "114 Train Loss 1.9111059 Test MSE 383.72505465639443 Test RE 0.9985565409944368\n",
      "115 Train Loss 1.7961905 Test MSE 383.75297905575627 Test RE 0.9985928737592925\n",
      "116 Train Loss 1.7000564 Test MSE 383.7757524479065 Test RE 0.998622503509384\n",
      "117 Train Loss 1.6556354 Test MSE 383.7927784553766 Test RE 0.9986446549422493\n",
      "118 Train Loss 1.635748 Test MSE 383.80152287682927 Test RE 0.9986560315502704\n",
      "119 Train Loss 1.6027917 Test MSE 383.80729363457505 Test RE 0.9986635393114741\n",
      "120 Train Loss 1.6078328 Test MSE 383.8138290123502 Test RE 0.9986720417758941\n",
      "121 Train Loss 1.4939057 Test MSE 383.82231341279055 Test RE 0.9986830797923033\n",
      "122 Train Loss 1.4472303 Test MSE 383.8387346719453 Test RE 0.9987044431389475\n",
      "123 Train Loss 1.4489442 Test MSE 383.8439501691477 Test RE 0.9987112281792065\n",
      "124 Train Loss 1.3833168 Test MSE 383.8457504872645 Test RE 0.9987135702713622\n",
      "125 Train Loss 1.3898721 Test MSE 383.8585955340563 Test RE 0.9987302806494286\n",
      "126 Train Loss 1.3339547 Test MSE 383.8585955340563 Test RE 0.9987302806494286\n",
      "127 Train Loss 1.3461272 Test MSE 383.8695303805882 Test RE 0.9987445057894914\n",
      "128 Train Loss 1.2369576 Test MSE 383.8695303805882 Test RE 0.9987445057894914\n",
      "129 Train Loss 1.2749983 Test MSE 383.88533215905176 Test RE 0.9987650619625693\n",
      "130 Train Loss 1.3882351 Test MSE 383.88533215905176 Test RE 0.9987650619625693\n",
      "131 Train Loss 1.5199693 Test MSE 383.86878311740753 Test RE 0.9987435336813919\n",
      "132 Train Loss 1.5806018 Test MSE 383.8527981769396 Test RE 0.9987227387863197\n",
      "133 Train Loss 1.6046803 Test MSE 383.84887970885416 Test RE 0.9987176411640226\n",
      "134 Train Loss 1.5985589 Test MSE 383.8489144000731 Test RE 0.9987176862947149\n",
      "135 Train Loss 1.5437202 Test MSE 383.8489144000731 Test RE 0.9987176862947149\n",
      "136 Train Loss 1.7681395 Test MSE 383.8489144000731 Test RE 0.9987176862947149\n",
      "137 Train Loss 2.8334768 Test MSE 383.8489144000731 Test RE 0.9987176862947149\n",
      "138 Train Loss 3.0602553 Test MSE 383.6181053991133 Test RE 0.9984173758272934\n",
      "139 Train Loss 2.8015347 Test MSE 383.5821770864623 Test RE 0.9983706206154466\n",
      "140 Train Loss 2.5983076 Test MSE 383.6972028494804 Test RE 0.9985203013635946\n",
      "141 Train Loss 2.3599017 Test MSE 383.6664979332217 Test RE 0.9984803478593665\n",
      "142 Train Loss 2.1774535 Test MSE 383.6756713579656 Test RE 0.9984922845669352\n",
      "143 Train Loss 2.0307996 Test MSE 383.69280512142575 Test RE 0.9985145790996686\n",
      "144 Train Loss 1.8949356 Test MSE 383.7049790014577 Test RE 0.9985304195065186\n",
      "145 Train Loss 1.8561466 Test MSE 383.7341270403067 Test RE 0.9985683453249617\n",
      "146 Train Loss 1.8644185 Test MSE 383.7468850580988 Test RE 0.9985849448999417\n",
      "147 Train Loss 1.8164409 Test MSE 383.7468850580988 Test RE 0.9985849448999417\n",
      "148 Train Loss 1.8197428 Test MSE 383.7635357506478 Test RE 0.9986066088550003\n",
      "149 Train Loss 1.7881044 Test MSE 383.7634823526107 Test RE 0.9986065393804027\n",
      "150 Train Loss 1.7444516 Test MSE 383.7781686101997 Test RE 0.9986256470511853\n",
      "151 Train Loss 1.7037017 Test MSE 383.8042472665475 Test RE 0.9986595759908654\n",
      "152 Train Loss 1.5754755 Test MSE 383.8093448917666 Test RE 0.9986662079853945\n",
      "153 Train Loss 1.5274829 Test MSE 383.84562178404195 Test RE 0.9987134028373531\n",
      "154 Train Loss 1.5687362 Test MSE 383.8460101431315 Test RE 0.9987139080656372\n",
      "155 Train Loss 1.5539662 Test MSE 383.8460101431315 Test RE 0.9987139080656372\n",
      "156 Train Loss 1.4134473 Test MSE 383.8444846945837 Test RE 0.9987119235612343\n",
      "157 Train Loss 2.630435 Test MSE 383.8428294967941 Test RE 0.9987097702574663\n",
      "158 Train Loss 2.9849973 Test MSE 383.35347719648996 Test RE 0.9980729512915394\n",
      "159 Train Loss 2.769105 Test MSE 383.3411852762437 Test RE 0.9980569499609251\n",
      "160 Train Loss 2.582207 Test MSE 383.2604168534805 Test RE 0.9979518011596121\n",
      "161 Train Loss 2.424957 Test MSE 383.21252273251395 Test RE 0.9978894447102086\n",
      "162 Train Loss 2.2539945 Test MSE 383.22943051392525 Test RE 0.9979114584878161\n",
      "163 Train Loss 2.065937 Test MSE 383.3177495386322 Test RE 0.9980264411619716\n",
      "164 Train Loss 1.9170697 Test MSE 383.3962638467113 Test RE 0.9981286479387581\n",
      "165 Train Loss 1.784364 Test MSE 383.44589473092174 Test RE 0.9981932500344831\n",
      "166 Train Loss 1.6766691 Test MSE 383.47143368469006 Test RE 0.9982264912128987\n",
      "167 Train Loss 1.5534799 Test MSE 383.4783858124198 Test RE 0.9982355398225309\n",
      "168 Train Loss 1.4473957 Test MSE 383.4681971898744 Test RE 0.9982222786935341\n",
      "169 Train Loss 1.416549 Test MSE 383.4504471842121 Test RE 0.9981991755310398\n",
      "170 Train Loss 1.384836 Test MSE 383.44492479318114 Test RE 0.9981919875539986\n",
      "171 Train Loss 1.3524783 Test MSE 383.43866957042525 Test RE 0.998183845656302\n",
      "172 Train Loss 1.3326688 Test MSE 383.433093867598 Test RE 0.998176588176599\n",
      "173 Train Loss 1.3397162 Test MSE 383.4302777992304 Test RE 0.9981729226887718\n",
      "174 Train Loss 1.2851228 Test MSE 383.4302777992304 Test RE 0.9981729226887718\n",
      "175 Train Loss 1.2826399 Test MSE 383.4252992641109 Test RE 0.998166442429687\n",
      "176 Train Loss 1.220283 Test MSE 383.424844900149 Test RE 0.9981658510094099\n",
      "177 Train Loss 1.2219787 Test MSE 383.4214542323768 Test RE 0.9981614375548439\n",
      "178 Train Loss 1.186589 Test MSE 383.4202357870873 Test RE 0.9981598515636918\n",
      "179 Train Loss 1.23163 Test MSE 383.41921625337403 Test RE 0.9981585244841568\n",
      "180 Train Loss 1.3652418 Test MSE 383.41921625337403 Test RE 0.9981585244841568\n",
      "181 Train Loss 1.4614366 Test MSE 383.42048944162343 Test RE 0.9981601817337097\n",
      "182 Train Loss 1.5423815 Test MSE 383.41954855682377 Test RE 0.9981589570282694\n",
      "183 Train Loss 1.633705 Test MSE 383.4169305994616 Test RE 0.998155549348535\n",
      "184 Train Loss 1.6853784 Test MSE 383.41117640504746 Test RE 0.9981480593263453\n",
      "185 Train Loss 1.7518488 Test MSE 383.4086931021328 Test RE 0.9981448268853641\n",
      "186 Train Loss 1.793297 Test MSE 383.4018110913277 Test RE 0.9981358687234437\n",
      "187 Train Loss 1.8165941 Test MSE 383.39619548897065 Test RE 0.9981285589579453\n",
      "188 Train Loss 1.8214846 Test MSE 383.39206588757156 Test RE 0.998123183468776\n",
      "189 Train Loss 1.6836596 Test MSE 383.38134240350405 Test RE 0.9981092246080535\n",
      "190 Train Loss 1.622264 Test MSE 383.4053220449171 Test RE 0.9981404388644641\n",
      "191 Train Loss 1.552662 Test MSE 383.41429395490735 Test RE 0.9981521173327474\n",
      "192 Train Loss 1.5109615 Test MSE 383.42223662856503 Test RE 0.9981624559606961\n",
      "193 Train Loss 1.4670882 Test MSE 383.42646561824654 Test RE 0.9981679606063373\n",
      "194 Train Loss 1.4341296 Test MSE 383.429637564933 Test RE 0.9981720893367341\n",
      "195 Train Loss 1.4251827 Test MSE 383.43093600633205 Test RE 0.9981737794341341\n",
      "196 Train Loss 1.3730756 Test MSE 383.43167549685387 Test RE 0.998174741979959\n",
      "197 Train Loss 1.3719907 Test MSE 383.43191519778827 Test RE 0.9981750539825869\n",
      "198 Train Loss 1.3179104 Test MSE 383.43214394938303 Test RE 0.9981753517331032\n",
      "199 Train Loss 1.322399 Test MSE 383.43019460930924 Test RE 0.9981728144058115\n",
      "Training time: 61.64\n",
      "Training time: 61.64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 9.181678 Test MSE 385.13679785240225 Test RE 1.0003917237267028\n",
      "1 Train Loss 10.810655 Test MSE 387.44184468214354 Test RE 1.0033809340393236\n",
      "2 Train Loss 10.311722 Test MSE 386.7556553385659 Test RE 1.002492007823754\n",
      "3 Train Loss 8.6057825 Test MSE 383.1708896674999 Test RE 0.9978352367679885\n",
      "4 Train Loss 7.912804 Test MSE 383.01614402227517 Test RE 0.9976337258302447\n",
      "5 Train Loss 7.3100686 Test MSE 383.0831144730847 Test RE 0.9977209402481451\n",
      "6 Train Loss 6.7460475 Test MSE 383.14732304691665 Test RE 0.9978045507651477\n",
      "7 Train Loss 6.2149816 Test MSE 383.2271821293267 Test RE 0.9979085311395147\n",
      "8 Train Loss 5.716451 Test MSE 383.30242362527764 Test RE 0.9980064892817456\n",
      "9 Train Loss 5.2545376 Test MSE 383.38424903074736 Test RE 0.9981130082115369\n",
      "10 Train Loss 4.8243647 Test MSE 383.4606843025755 Test RE 0.9982125000883366\n",
      "11 Train Loss 4.427799 Test MSE 383.533691525195 Test RE 0.9983075205907929\n",
      "12 Train Loss 4.064144 Test MSE 383.59990010691405 Test RE 0.9983936846935036\n",
      "13 Train Loss 3.731978 Test MSE 383.6580843893342 Test RE 0.9984693998037908\n",
      "14 Train Loss 3.4296148 Test MSE 383.70901497839355 Test RE 0.9985356709827387\n",
      "15 Train Loss 3.1506734 Test MSE 383.75364763437574 Test RE 0.9985937436386035\n",
      "16 Train Loss 2.9216862 Test MSE 383.7928266125951 Test RE 0.9986447175957827\n",
      "17 Train Loss 2.7055347 Test MSE 383.8267298966907 Test RE 0.9986888254914216\n",
      "18 Train Loss 2.510933 Test MSE 383.85541298039556 Test RE 0.9987261404278263\n",
      "19 Train Loss 2.3581104 Test MSE 383.8788075336611 Test RE 0.9987565742775418\n",
      "20 Train Loss 2.2361336 Test MSE 383.8961671984555 Test RE 0.9987791567736191\n",
      "21 Train Loss 2.1101558 Test MSE 383.91033934448603 Test RE 0.9987975923750091\n",
      "22 Train Loss 2.0035245 Test MSE 383.9248510146148 Test RE 0.9988164692880981\n",
      "23 Train Loss 1.9377923 Test MSE 383.93636392231565 Test RE 0.998831445129833\n",
      "24 Train Loss 1.8808179 Test MSE 383.9436243526634 Test RE 0.9988408892884666\n",
      "25 Train Loss 1.8145883 Test MSE 383.9511190665664 Test RE 0.9988506381027364\n",
      "26 Train Loss 1.7639848 Test MSE 383.96047653969674 Test RE 0.9988628097837078\n",
      "27 Train Loss 1.7471298 Test MSE 383.96646288172616 Test RE 0.9988705964069133\n",
      "28 Train Loss 1.6999525 Test MSE 383.9681712742789 Test RE 0.9988728185556617\n",
      "29 Train Loss 1.6782943 Test MSE 383.9760847275985 Test RE 0.9988831117170305\n",
      "30 Train Loss 1.6450287 Test MSE 383.9792522065371 Test RE 0.9988872316802512\n",
      "31 Train Loss 1.6483119 Test MSE 383.9843869868735 Test RE 0.998893910490811\n",
      "32 Train Loss 1.5798916 Test MSE 383.9859056641455 Test RE 0.9988958858263065\n",
      "33 Train Loss 1.4961691 Test MSE 384.00253459177054 Test RE 0.9989175147289754\n",
      "34 Train Loss 1.4579457 Test MSE 384.01202642576595 Test RE 0.9989298603514388\n",
      "35 Train Loss 1.4572953 Test MSE 384.01441121789026 Test RE 0.9989329621245622\n",
      "36 Train Loss 1.4721545 Test MSE 384.01648430604416 Test RE 0.9989356584729736\n",
      "37 Train Loss 1.6781322 Test MSE 384.01648430604416 Test RE 0.9989356584729736\n",
      "38 Train Loss 2.2475777 Test MSE 383.99087254832324 Test RE 0.9989023461990097\n",
      "39 Train Loss 2.8180673 Test MSE 383.9441397644015 Test RE 0.9988415597178129\n",
      "40 Train Loss 2.7821362 Test MSE 383.86438949091536 Test RE 0.9987378180321937\n",
      "41 Train Loss 2.6818376 Test MSE 383.86438949091536 Test RE 0.9987378180321937\n",
      "42 Train Loss 3.0089214 Test MSE 383.85417142531725 Test RE 0.9987245252695243\n",
      "43 Train Loss 3.7077281 Test MSE 383.8536617949558 Test RE 0.9987238622827086\n",
      "44 Train Loss 5.467616 Test MSE 383.77620262261104 Test RE 0.9986230892087873\n",
      "45 Train Loss 5.6929684 Test MSE 383.5529171953316 Test RE 0.9983325417179961\n",
      "46 Train Loss 5.267415 Test MSE 383.4014667628056 Test RE 0.9981354205164771\n",
      "47 Train Loss 4.8562884 Test MSE 383.43231853840916 Test RE 0.9981755789837987\n",
      "48 Train Loss 4.465025 Test MSE 383.50294238046285 Test RE 0.9982675010065784\n",
      "49 Train Loss 4.143386 Test MSE 383.55055437881674 Test RE 0.9983294666791369\n",
      "50 Train Loss 3.8247113 Test MSE 383.5987530035152 Test RE 0.998392191912034\n",
      "51 Train Loss 3.5569932 Test MSE 383.6404108610474 Test RE 0.9984464018778662\n",
      "52 Train Loss 3.306268 Test MSE 383.675912696154 Test RE 0.9984925986007654\n",
      "53 Train Loss 3.1094828 Test MSE 383.71615947558087 Test RE 0.998544967092299\n",
      "54 Train Loss 2.8635998 Test MSE 383.7509130872578 Test RE 0.9985901857486328\n",
      "55 Train Loss 2.6468635 Test MSE 383.789832274628 Test RE 0.9986408218929206\n",
      "56 Train Loss 2.481581 Test MSE 383.81616517205765 Test RE 0.9986750810799241\n",
      "57 Train Loss 2.3458536 Test MSE 383.8292883108322 Test RE 0.99869215388827\n",
      "58 Train Loss 2.2208126 Test MSE 383.84366424466856 Test RE 0.9987108562102842\n",
      "59 Train Loss 2.116491 Test MSE 383.86060940226287 Test RE 0.99873290050547\n",
      "60 Train Loss 2.0612228 Test MSE 383.87574639149165 Test RE 0.998752592106735\n",
      "61 Train Loss 2.0049486 Test MSE 383.8840352382474 Test RE 0.9987633748438218\n",
      "62 Train Loss 1.9514141 Test MSE 383.8938164183883 Test RE 0.9987760987674076\n",
      "63 Train Loss 1.9413891 Test MSE 383.9015771718188 Test RE 0.9987861942880036\n",
      "64 Train Loss 1.8738734 Test MSE 383.9022306742908 Test RE 0.9987870443873624\n",
      "65 Train Loss 1.8286259 Test MSE 383.9137917091688 Test RE 0.9988020832748724\n",
      "66 Train Loss 1.8040261 Test MSE 383.917142505564 Test RE 0.9988064420335182\n",
      "67 Train Loss 1.7825025 Test MSE 383.91731176441135 Test RE 0.9988066622070787\n",
      "68 Train Loss 1.754141 Test MSE 383.91749766036475 Test RE 0.9988069040222931\n",
      "69 Train Loss 1.7452016 Test MSE 383.91913221803827 Test RE 0.9988090302678558\n",
      "70 Train Loss 1.7146465 Test MSE 383.91876390032047 Test RE 0.9988085511576477\n",
      "71 Train Loss 1.710953 Test MSE 383.92124488307104 Test RE 0.9988117784325508\n",
      "72 Train Loss 1.6588765 Test MSE 383.92059564811507 Test RE 0.9988109339054452\n",
      "73 Train Loss 1.6559327 Test MSE 383.92655154162225 Test RE 0.9988186813258134\n",
      "74 Train Loss 1.5245682 Test MSE 383.9269822851382 Test RE 0.9988192416342216\n",
      "75 Train Loss 1.7428372 Test MSE 383.93223934120914 Test RE 0.9988260799537791\n",
      "76 Train Loss 1.9376203 Test MSE 383.9200323136569 Test RE 0.99881020111743\n",
      "77 Train Loss 2.1423528 Test MSE 383.9004228539582 Test RE 0.9987846927083305\n",
      "78 Train Loss 2.0633907 Test MSE 383.8799718718257 Test RE 0.9987580889346314\n",
      "79 Train Loss 2.0190485 Test MSE 383.87996398282814 Test RE 0.9987580786720485\n",
      "80 Train Loss 1.9855468 Test MSE 383.8814407366881 Test RE 0.9987599997392669\n",
      "81 Train Loss 1.9773327 Test MSE 383.8832994025713 Test RE 0.9987624176197543\n",
      "82 Train Loss 1.9745799 Test MSE 383.8838710934764 Test RE 0.9987631613134483\n",
      "83 Train Loss 1.8977082 Test MSE 383.884984521162 Test RE 0.9987646097329216\n",
      "84 Train Loss 1.9049381 Test MSE 383.89042248300245 Test RE 0.9987716837587629\n",
      "85 Train Loss 1.8542721 Test MSE 383.89042248300245 Test RE 0.9987716837587629\n",
      "86 Train Loss 1.8817952 Test MSE 383.8952496845626 Test RE 0.9987779632291426\n",
      "87 Train Loss 1.7163337 Test MSE 383.8952496845626 Test RE 0.9987779632291426\n",
      "88 Train Loss 3.0583403 Test MSE 383.8952496845626 Test RE 0.9987779632291426\n",
      "89 Train Loss 7.0834427 Test MSE 383.8952496845626 Test RE 0.9987779632291426\n",
      "90 Train Loss 7.5598316 Test MSE 383.0033991126659 Test RE 0.9976171274992989\n",
      "91 Train Loss 7.1664896 Test MSE 383.122119566419 Test RE 0.9977717323691956\n",
      "92 Train Loss 6.5962954 Test MSE 383.31031522749765 Test RE 0.9980167629314846\n",
      "93 Train Loss 6.1123853 Test MSE 383.36944068904216 Test RE 0.9980937318050984\n",
      "94 Train Loss 5.6071997 Test MSE 383.4429592131779 Test RE 0.9981894291308749\n",
      "95 Train Loss 5.129034 Test MSE 383.4947653163352 Test RE 0.9982568584012903\n",
      "96 Train Loss 4.6912794 Test MSE 383.53589206903797 Test RE 0.9983103845064868\n",
      "97 Train Loss 4.2851925 Test MSE 383.56815520083853 Test RE 0.9983523726787266\n",
      "98 Train Loss 3.919146 Test MSE 383.59554224311233 Test RE 0.9983880135814227\n",
      "99 Train Loss 3.5836337 Test MSE 383.6195962551657 Test RE 0.998419315901446\n",
      "100 Train Loss 3.2798963 Test MSE 383.64177445281325 Test RE 0.9984481762895858\n",
      "101 Train Loss 3.0033243 Test MSE 383.66418572540914 Test RE 0.9984773391297119\n",
      "102 Train Loss 2.7391083 Test MSE 383.6857118734669 Test RE 0.9985053493928041\n",
      "103 Train Loss 2.500212 Test MSE 383.7083652489356 Test RE 0.998534825578683\n",
      "104 Train Loss 2.2973924 Test MSE 383.726094027939 Test RE 0.9985578933566803\n",
      "105 Train Loss 2.0993297 Test MSE 383.7376804488693 Test RE 0.9985729687254415\n",
      "106 Train Loss 1.9231404 Test MSE 383.74447908837675 Test RE 0.9985818144915896\n",
      "107 Train Loss 1.8168055 Test MSE 383.74609531674173 Test RE 0.9985839173681672\n",
      "108 Train Loss 1.7332058 Test MSE 383.74620155382877 Test RE 0.9985840555932082\n",
      "109 Train Loss 1.697656 Test MSE 383.7466048716586 Test RE 0.9985845803497356\n",
      "110 Train Loss 1.6551604 Test MSE 383.74756845761624 Test RE 0.9985858340695898\n",
      "111 Train Loss 1.5643042 Test MSE 383.7513176250179 Test RE 0.9985907120891793\n",
      "112 Train Loss 1.6768802 Test MSE 383.7750012661574 Test RE 0.9986215261842648\n",
      "113 Train Loss 1.5729618 Test MSE 383.80763146131665 Test RE 0.9986639788226309\n",
      "114 Train Loss 1.6495658 Test MSE 383.8546944014072 Test RE 0.9987252056175681\n",
      "115 Train Loss 1.7852644 Test MSE 383.8433089461911 Test RE 0.9987103939901648\n",
      "116 Train Loss 1.8755499 Test MSE 383.81100890310086 Test RE 0.9986683728494217\n",
      "117 Train Loss 1.9124113 Test MSE 383.7986139064405 Test RE 0.9986522469556873\n",
      "118 Train Loss 1.9117291 Test MSE 383.79000008530943 Test RE 0.9986410402188955\n",
      "119 Train Loss 1.8749076 Test MSE 383.78935410958906 Test RE 0.9986401997877525\n",
      "120 Train Loss 1.7728189 Test MSE 383.78935410958906 Test RE 0.9986401997877525\n",
      "121 Train Loss 1.6141026 Test MSE 383.8096297005907 Test RE 0.998666578519488\n",
      "122 Train Loss 1.4932295 Test MSE 383.8471888362998 Test RE 0.9987154414622673\n",
      "123 Train Loss 1.3985618 Test MSE 383.8826112999079 Test RE 0.9987615224891395\n",
      "124 Train Loss 1.2983661 Test MSE 383.914202158693 Test RE 0.9988026171938655\n",
      "125 Train Loss 1.1859641 Test MSE 383.9497099615385 Test RE 0.9988488052043836\n",
      "126 Train Loss 1.1205094 Test MSE 383.98910498552505 Test RE 0.9989000471539229\n",
      "127 Train Loss 1.041202 Test MSE 384.0117090062013 Test RE 0.9989294474998547\n",
      "128 Train Loss 0.999922 Test MSE 384.0407265702644 Test RE 0.998967188473622\n",
      "129 Train Loss 0.9765217 Test MSE 384.0545367849464 Test RE 0.9989851498854649\n",
      "130 Train Loss 1.0307105 Test MSE 384.059074775704 Test RE 0.9989910518753539\n",
      "131 Train Loss 1.4480218 Test MSE 384.059074775704 Test RE 0.9989910518753539\n",
      "132 Train Loss 2.0759833 Test MSE 383.92730404981444 Test RE 0.9988196601834474\n",
      "133 Train Loss 2.2678187 Test MSE 383.7397149717893 Test RE 0.9985756158682723\n",
      "134 Train Loss 2.0831149 Test MSE 383.72623843109136 Test RE 0.9985580812444682\n",
      "135 Train Loss 1.9257797 Test MSE 383.756229534144 Test RE 0.9985971029091075\n",
      "136 Train Loss 1.7982422 Test MSE 383.8238077395168 Test RE 0.9986850238655279\n",
      "137 Train Loss 1.7026156 Test MSE 383.8687321888316 Test RE 0.9987434674288207\n",
      "138 Train Loss 1.6840563 Test MSE 383.8942204964603 Test RE 0.9987766244119961\n",
      "139 Train Loss 1.6851186 Test MSE 383.89915321483727 Test RE 0.9987830411118587\n",
      "140 Train Loss 1.6432511 Test MSE 383.90064915310097 Test RE 0.9987849870868631\n",
      "141 Train Loss 1.6695608 Test MSE 383.91170637776094 Test RE 0.9987993706396041\n",
      "142 Train Loss 1.5282869 Test MSE 383.91170637776094 Test RE 0.9987993706396041\n",
      "143 Train Loss 2.6197817 Test MSE 383.91170637776094 Test RE 0.9987993706396041\n",
      "144 Train Loss 5.8565145 Test MSE 383.9084167782383 Test RE 0.9987950914565045\n",
      "145 Train Loss 10.094974 Test MSE 383.88141218764326 Test RE 0.998759962600659\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 85.56\n",
      "Training time: 85.56\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 9.327874 Test MSE 386.45715724609187 Test RE 1.002105071383438\n",
      "1 Train Loss 16.214315 Test MSE 390.1344570595462 Test RE 1.0068615055851327\n",
      "2 Train Loss 12.502842 Test MSE 386.06131020981417 Test RE 1.0015917131148526\n",
      "3 Train Loss 11.45918 Test MSE 386.91385271152853 Test RE 1.002697015023678\n",
      "4 Train Loss 11.155843 Test MSE 386.1465412028424 Test RE 1.001702268022801\n",
      "5 Train Loss 10.491942 Test MSE 384.0577909444721 Test RE 0.9989893821621916\n",
      "6 Train Loss 9.774824 Test MSE 382.84341805051326 Test RE 0.9974087526940087\n",
      "7 Train Loss 9.091922 Test MSE 382.8556940482984 Test RE 0.9974247436826346\n",
      "8 Train Loss 8.50161 Test MSE 382.9803901644749 Test RE 0.9975871611000359\n",
      "9 Train Loss 7.8957596 Test MSE 382.9567287473716 Test RE 0.9975563439993232\n",
      "10 Train Loss 7.3257155 Test MSE 383.03744270525596 Test RE 0.9976614635501876\n",
      "11 Train Loss 6.753997 Test MSE 383.08738478569916 Test RE 0.9977265011411767\n",
      "12 Train Loss 6.2097235 Test MSE 383.1576169325856 Test RE 0.9978179545087728\n",
      "13 Train Loss 5.6905837 Test MSE 383.20573499508987 Test RE 0.9978806070012072\n",
      "14 Train Loss 5.203103 Test MSE 383.246768524994 Test RE 0.9979340319162228\n",
      "15 Train Loss 4.7583323 Test MSE 383.300491225955 Test RE 0.9980039735795535\n",
      "16 Train Loss 4.3470364 Test MSE 383.3444221250926 Test RE 0.9980611636389671\n",
      "17 Train Loss 3.9727566 Test MSE 383.3944580743129 Test RE 0.9981262973742706\n",
      "18 Train Loss 3.6269789 Test MSE 383.44375522345035 Test RE 0.9981904652284328\n",
      "19 Train Loss 3.3115222 Test MSE 383.49687969947087 Test RE 0.9982596103222394\n",
      "20 Train Loss 3.035784 Test MSE 383.54223585422375 Test RE 0.9983186406313653\n",
      "21 Train Loss 2.7961273 Test MSE 383.58852264523193 Test RE 0.9983788785502841\n",
      "22 Train Loss 2.5723763 Test MSE 383.6298004754646 Test RE 0.9984325947107141\n",
      "23 Train Loss 2.3883593 Test MSE 383.6661368673859 Test RE 0.998479878027849\n",
      "24 Train Loss 2.222032 Test MSE 383.69447654499737 Test RE 0.9985167539371482\n",
      "25 Train Loss 2.0694845 Test MSE 383.7200994351266 Test RE 0.998550093559583\n",
      "26 Train Loss 1.947986 Test MSE 383.74222723852574 Test RE 0.9985788845997843\n",
      "27 Train Loss 1.8297552 Test MSE 383.7596507303435 Test RE 0.9986015541580204\n",
      "28 Train Loss 1.7175411 Test MSE 383.77665013906875 Test RE 0.9986236714493409\n",
      "29 Train Loss 1.6388397 Test MSE 383.7903534574755 Test RE 0.9986414999649366\n",
      "30 Train Loss 1.5526258 Test MSE 383.79980769982535 Test RE 0.9986538000925094\n",
      "31 Train Loss 1.4755447 Test MSE 383.8108630430642 Test RE 0.9986681830869919\n",
      "32 Train Loss 1.4307165 Test MSE 383.819062066804 Test RE 0.9986788498778532\n",
      "33 Train Loss 1.3925213 Test MSE 383.8232766998689 Test RE 0.9986843329996719\n",
      "34 Train Loss 1.3494072 Test MSE 383.82753750923916 Test RE 0.9986898761649946\n",
      "35 Train Loss 1.3166239 Test MSE 383.83297381693154 Test RE 0.9986969485682246\n",
      "36 Train Loss 1.3052064 Test MSE 383.83660156587297 Test RE 0.9987016680861979\n",
      "37 Train Loss 1.2782999 Test MSE 383.8379771282965 Test RE 0.9987034576175384\n",
      "38 Train Loss 1.2549808 Test MSE 383.841673498734 Test RE 0.9987082663770529\n",
      "39 Train Loss 1.2292473 Test MSE 383.8451214810664 Test RE 0.9987127519774479\n",
      "40 Train Loss 1.213607 Test MSE 383.8487269998196 Test RE 0.9987174425009157\n",
      "41 Train Loss 1.2082413 Test MSE 383.8504969426512 Test RE 0.9987197450625971\n",
      "42 Train Loss 1.2026839 Test MSE 383.85088303434014 Test RE 0.9987202473379613\n",
      "43 Train Loss 1.1649866 Test MSE 383.8520430859031 Test RE 0.9987217564736174\n",
      "44 Train Loss 1.1821976 Test MSE 383.85740648023324 Test RE 0.9987287337972911\n",
      "45 Train Loss 1.0973661 Test MSE 383.85604195221197 Test RE 0.9987269586660432\n",
      "46 Train Loss 1.0851362 Test MSE 383.87066784076126 Test RE 0.9987459854996102\n",
      "47 Train Loss 1.0733515 Test MSE 383.87091933935983 Test RE 0.9987463126712276\n",
      "48 Train Loss 1.0996733 Test MSE 383.87122486455434 Test RE 0.9987467101252745\n",
      "49 Train Loss 1.0393536 Test MSE 383.87122486455434 Test RE 0.9987467101252745\n",
      "50 Train Loss 1.3550687 Test MSE 383.86861223576784 Test RE 0.998743311382837\n",
      "51 Train Loss 2.3465822 Test MSE 383.8600710126401 Test RE 0.9987322001111019\n",
      "52 Train Loss 4.6760793 Test MSE 383.8480445203937 Test RE 0.998716554645412\n",
      "53 Train Loss 6.4806623 Test MSE 383.09005317844793 Test RE 0.9977299759639331\n",
      "54 Train Loss 6.032621 Test MSE 383.6037242262219 Test RE 0.9983986611899133\n",
      "55 Train Loss 5.528023 Test MSE 384.2127172967258 Test RE 0.9991908546741939\n",
      "56 Train Loss 5.067036 Test MSE 383.412496035499 Test RE 0.9981497770454962\n",
      "57 Train Loss 4.627556 Test MSE 383.19308321041666 Test RE 0.9978641340290886\n",
      "58 Train Loss 4.233152 Test MSE 383.22830308692915 Test RE 0.9979099906032334\n",
      "59 Train Loss 3.8787255 Test MSE 383.2820972599433 Test RE 0.9979800270000048\n",
      "60 Train Loss 3.553699 Test MSE 383.3263233312244 Test RE 0.9980376026903255\n",
      "61 Train Loss 3.2581189 Test MSE 383.3677924271949 Test RE 0.9980915861964349\n",
      "62 Train Loss 2.9888017 Test MSE 383.4064132504507 Test RE 0.9981418592615384\n",
      "63 Train Loss 2.7557588 Test MSE 383.4416412284986 Test RE 0.9981877136221226\n",
      "64 Train Loss 2.5388076 Test MSE 383.4750667892295 Test RE 0.9982312199257681\n",
      "65 Train Loss 2.3423383 Test MSE 383.5098665752671 Test RE 0.9982765128897741\n",
      "66 Train Loss 2.173071 Test MSE 383.5412477152183 Test RE 0.9983173546214661\n",
      "67 Train Loss 2.012243 Test MSE 383.5714027517665 Test RE 0.9983565990375466\n",
      "68 Train Loss 1.8661995 Test MSE 383.60182551146846 Test RE 0.998396190311121\n",
      "69 Train Loss 1.7244488 Test MSE 383.6322061602796 Test RE 0.9984357252161696\n",
      "70 Train Loss 1.6095113 Test MSE 383.6623587067939 Test RE 0.9984749617396337\n",
      "71 Train Loss 1.4804559 Test MSE 383.6965280748692 Test RE 0.9985194233581788\n",
      "72 Train Loss 1.3596153 Test MSE 383.72980859776493 Test RE 0.9985627264969088\n",
      "73 Train Loss 1.2981647 Test MSE 383.77752574383544 Test RE 0.9986248106525049\n",
      "74 Train Loss 1.2955619 Test MSE 383.88002344687374 Test RE 0.9987581560272104\n",
      "75 Train Loss 1.3113176 Test MSE 383.95349979971064 Test RE 0.9988537348421599\n",
      "76 Train Loss 1.3957547 Test MSE 383.9860757031291 Test RE 0.9988961069948701\n",
      "77 Train Loss 1.5050122 Test MSE 383.98857156923447 Test RE 0.99889935334551\n",
      "78 Train Loss 1.422416 Test MSE 383.9772098741914 Test RE 0.9988845752054498\n",
      "79 Train Loss 1.7487063 Test MSE 383.9783086207509 Test RE 0.9988860043530359\n",
      "80 Train Loss 2.5171719 Test MSE 383.98566589889896 Test RE 0.9988955739651783\n",
      "81 Train Loss 3.138511 Test MSE 383.9810207272331 Test RE 0.9988895320007739\n",
      "82 Train Loss 2.9005132 Test MSE 384.04972017982874 Test RE 0.9989788854990158\n",
      "83 Train Loss 2.7734902 Test MSE 383.93056648861256 Test RE 0.9988239039309681\n",
      "84 Train Loss 2.5493524 Test MSE 383.94770558459953 Test RE 0.9988461979981899\n",
      "85 Train Loss 2.3429165 Test MSE 384.0099219542472 Test RE 0.9989271231685177\n",
      "86 Train Loss 2.1416128 Test MSE 384.0023681801086 Test RE 0.9989172982830843\n",
      "87 Train Loss 1.9702065 Test MSE 384.01074641025303 Test RE 0.9989281954989148\n",
      "88 Train Loss 1.837021 Test MSE 384.00381035371333 Test RE 0.9989191740668394\n",
      "89 Train Loss 1.7112775 Test MSE 383.99389430965545 Test RE 0.9989062765509555\n",
      "90 Train Loss 1.6289015 Test MSE 383.9813771654034 Test RE 0.9988899956203998\n",
      "91 Train Loss 1.5690941 Test MSE 383.9701290890387 Test RE 0.9988753651280092\n",
      "92 Train Loss 1.536669 Test MSE 383.96091084730017 Test RE 0.9988633747032982\n",
      "93 Train Loss 1.5103073 Test MSE 383.9550637941596 Test RE 0.9988557692032303\n",
      "94 Train Loss 1.4808987 Test MSE 383.9499020961177 Test RE 0.9988490551243155\n",
      "95 Train Loss 1.4628844 Test MSE 383.94469775787786 Test RE 0.9988422855354696\n",
      "96 Train Loss 1.455161 Test MSE 383.9417590277046 Test RE 0.9988384629360215\n",
      "97 Train Loss 1.4507859 Test MSE 383.94065494999506 Test RE 0.9988370267858121\n",
      "98 Train Loss 1.3739877 Test MSE 383.93996118864334 Test RE 0.9988361243614012\n",
      "99 Train Loss 1.4053644 Test MSE 383.9301362657641 Test RE 0.9988233443024535\n",
      "100 Train Loss 1.2993884 Test MSE 383.9301362657641 Test RE 0.9988233443024535\n",
      "101 Train Loss 1.7726022 Test MSE 383.93442419678416 Test RE 0.9988289219756272\n",
      "102 Train Loss 2.8309598 Test MSE 383.93442419678416 Test RE 0.9988289219756272\n",
      "103 Train Loss 4.1777644 Test MSE 383.9935649115972 Test RE 0.9989058481094317\n",
      "104 Train Loss 4.2008348 Test MSE 383.59640026931584 Test RE 0.9983891301775557\n",
      "105 Train Loss 3.8638332 Test MSE 383.86262516037385 Test RE 0.9987355228132202\n",
      "106 Train Loss 3.5644546 Test MSE 383.88741650214297 Test RE 0.9987677734053579\n",
      "107 Train Loss 3.2755525 Test MSE 383.89696971330136 Test RE 0.9987802007208509\n",
      "108 Train Loss 3.0152996 Test MSE 383.87599048773956 Test RE 0.9987529096466208\n",
      "109 Train Loss 2.7776895 Test MSE 383.87600118178494 Test RE 0.9987529235582868\n",
      "110 Train Loss 2.5311942 Test MSE 383.90455539505297 Test RE 0.9987900684613041\n",
      "111 Train Loss 2.3053293 Test MSE 383.91496133037754 Test RE 0.9988036047352047\n",
      "112 Train Loss 2.1103823 Test MSE 383.9102298105456 Test RE 0.9987974498909022\n",
      "113 Train Loss 1.9331961 Test MSE 383.9047752773763 Test RE 0.998790354491056\n",
      "114 Train Loss 1.7876604 Test MSE 383.8964428096267 Test RE 0.99877951530109\n",
      "115 Train Loss 1.6493793 Test MSE 383.8792460450583 Test RE 0.9987571447258283\n",
      "116 Train Loss 1.5696363 Test MSE 383.8544397475873 Test RE 0.9987248743343577\n",
      "117 Train Loss 1.5559517 Test MSE 383.8299221624469 Test RE 0.998692978502744\n",
      "118 Train Loss 1.50595 Test MSE 383.8257644909491 Test RE 0.9986875695333847\n",
      "119 Train Loss 1.405132 Test MSE 383.82927475099086 Test RE 0.9986921362474757\n",
      "120 Train Loss 1.294092 Test MSE 383.83967577838047 Test RE 0.9987056674637971\n",
      "121 Train Loss 1.3162671 Test MSE 383.8479923448915 Test RE 0.9987164867688912\n",
      "122 Train Loss 1.2152581 Test MSE 383.8479923448915 Test RE 0.9987164867688912\n",
      "123 Train Loss 1.2896522 Test MSE 383.85821703284176 Test RE 0.998729788253633\n",
      "124 Train Loss 1.2060893 Test MSE 383.8574851019325 Test RE 0.9987288360771286\n",
      "125 Train Loss 1.2759529 Test MSE 383.8632299216988 Test RE 0.9987363095482923\n",
      "126 Train Loss 1.1813288 Test MSE 383.8646557817745 Test RE 0.9987381644497214\n",
      "127 Train Loss 1.2077696 Test MSE 383.8774899616468 Test RE 0.9987548602797713\n",
      "128 Train Loss 1.1275308 Test MSE 383.8774899616468 Test RE 0.9987548602797713\n",
      "129 Train Loss 1.2162372 Test MSE 383.9526491131947 Test RE 0.9988526283124958\n",
      "130 Train Loss 1.1618615 Test MSE 384.0743661622348 Test RE 0.9990109391886183\n",
      "131 Train Loss 1.2145823 Test MSE 384.12489960428155 Test RE 0.9990766579730562\n",
      "132 Train Loss 1.2430892 Test MSE 384.12489960428155 Test RE 0.9990766579730562\n",
      "133 Train Loss 1.4182229 Test MSE 384.12489960428155 Test RE 0.9990766579730562\n",
      "134 Train Loss 1.3206464 Test MSE 384.1435407909979 Test RE 0.9991008997608177\n",
      "135 Train Loss 1.592263 Test MSE 384.170036201537 Test RE 0.9991353545013766\n",
      "136 Train Loss 1.5209428 Test MSE 384.07373397457746 Test RE 0.9990101170006505\n",
      "137 Train Loss 1.5831293 Test MSE 384.0748908707623 Test RE 0.9990116215947172\n",
      "138 Train Loss 1.5076053 Test MSE 384.0748908707623 Test RE 0.9990116215947172\n",
      "139 Train Loss 1.5614821 Test MSE 384.0761335384247 Test RE 0.9990132377358157\n",
      "140 Train Loss 1.4631296 Test MSE 384.0761335384247 Test RE 0.9990132377358157\n",
      "141 Train Loss 1.8281742 Test MSE 384.06794628518617 Test RE 0.9990025898235395\n",
      "142 Train Loss 2.5481539 Test MSE 384.06794628518617 Test RE 0.9990025898235395\n",
      "143 Train Loss 3.6338296 Test MSE 383.97403015274614 Test RE 0.998880439307278\n",
      "144 Train Loss 3.9866023 Test MSE 384.0072882287033 Test RE 0.9989236976002688\n",
      "145 Train Loss 3.7175455 Test MSE 383.25442207658483 Test RE 0.9979439963857147\n",
      "146 Train Loss 3.4020581 Test MSE 383.12999666956085 Test RE 0.9977819895561971\n",
      "147 Train Loss 3.117575 Test MSE 383.1918779196304 Test RE 0.9978625646930995\n",
      "148 Train Loss 2.8433475 Test MSE 383.24435707146483 Test RE 0.9979308923263732\n",
      "149 Train Loss 2.5941904 Test MSE 383.30073159024835 Test RE 0.9980042864991661\n",
      "150 Train Loss 2.3760242 Test MSE 383.34187829413446 Test RE 0.9980578521220235\n",
      "151 Train Loss 2.184156 Test MSE 383.3924776427256 Test RE 0.9981237194504661\n",
      "152 Train Loss 2.0098557 Test MSE 383.45834172904756 Test RE 0.9982094510277094\n",
      "153 Train Loss 1.854499 Test MSE 383.532805770193 Test RE 0.9983063678154174\n",
      "154 Train Loss 1.726772 Test MSE 383.6310815013891 Test RE 0.9984342617044781\n",
      "155 Train Loss 1.6371819 Test MSE 383.75672093174506 Test RE 0.9985977422577696\n",
      "156 Train Loss 1.5229847 Test MSE 383.8683392742465 Test RE 0.9987429562892796\n",
      "157 Train Loss 1.4067367 Test MSE 383.9532674188651 Test RE 0.9988534325731212\n",
      "158 Train Loss 1.3414885 Test MSE 384.0109966818559 Test RE 0.9989285210149609\n",
      "159 Train Loss 1.2929446 Test MSE 384.0456866677681 Test RE 0.9989736395585149\n",
      "160 Train Loss 1.2421057 Test MSE 384.0751751642757 Test RE 0.9990119913305134\n",
      "161 Train Loss 1.1900413 Test MSE 384.1062684330884 Test RE 0.9990524286221573\n",
      "162 Train Loss 1.1414814 Test MSE 384.13599363673586 Test RE 0.9990910851930201\n",
      "163 Train Loss 1.1168482 Test MSE 384.16026650626446 Test RE 0.99912265008785\n",
      "164 Train Loss 1.0847465 Test MSE 384.17558886384955 Test RE 0.9991425750556346\n",
      "165 Train Loss 1.0630152 Test MSE 384.1934282990561 Test RE 0.9991657726934242\n",
      "166 Train Loss 1.0651526 Test MSE 384.2041232731977 Test RE 0.9991796797216914\n",
      "167 Train Loss 1.0160712 Test MSE 384.20981669512986 Test RE 0.9991870829874078\n",
      "168 Train Loss 1.0064011 Test MSE 384.2324110039559 Test RE 0.9992164622596827\n",
      "169 Train Loss 1.0121136 Test MSE 384.2361109497017 Test RE 0.9992212731992243\n",
      "170 Train Loss 0.97854257 Test MSE 384.2361109497017 Test RE 0.9992212731992243\n",
      "171 Train Loss 1.0195214 Test MSE 384.2478931497927 Test RE 0.9992365931215194\n",
      "172 Train Loss 1.0604061 Test MSE 384.2478931497927 Test RE 0.9992365931215194\n",
      "173 Train Loss 1.1163211 Test MSE 384.2350028537713 Test RE 0.999219832374438\n",
      "174 Train Loss 1.159172 Test MSE 384.219080727782 Test RE 0.999199129069474\n",
      "175 Train Loss 1.1843574 Test MSE 384.2033078176293 Test RE 0.9991786193646875\n",
      "176 Train Loss 1.1850513 Test MSE 384.19018749528544 Test RE 0.9991615585309817\n",
      "177 Train Loss 1.1567618 Test MSE 384.1872598771531 Test RE 0.9991577516025856\n",
      "178 Train Loss 1.1206174 Test MSE 384.1872598771531 Test RE 0.9991577516025856\n",
      "179 Train Loss 1.3029535 Test MSE 384.188554002215 Test RE 0.9991594344199682\n",
      "180 Train Loss 1.3012437 Test MSE 384.16516104469207 Test RE 0.9991290149166139\n",
      "181 Train Loss 1.2829397 Test MSE 384.1647134001589 Test RE 0.9991284328040004\n",
      "182 Train Loss 1.1869358 Test MSE 384.16548378329406 Test RE 0.9991294346025541\n",
      "183 Train Loss 1.5796931 Test MSE 384.16715118559324 Test RE 0.9991316028724521\n",
      "184 Train Loss 2.4250507 Test MSE 384.11601059852916 Test RE 0.9990650981268356\n",
      "185 Train Loss 2.5468032 Test MSE 383.778170763803 Test RE 0.9986256498531211\n",
      "186 Train Loss 2.329446 Test MSE 383.5921393883733 Test RE 0.9983835852493078\n",
      "187 Train Loss 2.265236 Test MSE 383.5646816411172 Test RE 0.9983478521725353\n",
      "188 Train Loss 2.062938 Test MSE 383.6090448211864 Test RE 0.9984055850753374\n",
      "189 Train Loss 1.9462576 Test MSE 383.696145205265 Test RE 0.9985189251743228\n",
      "190 Train Loss 1.8547655 Test MSE 383.7362177794042 Test RE 0.9985710656238489\n",
      "191 Train Loss 1.7699156 Test MSE 383.76625788156036 Test RE 0.9986101505321604\n",
      "192 Train Loss 1.6793507 Test MSE 383.79451701925353 Test RE 0.9986469168471813\n",
      "193 Train Loss 1.5920537 Test MSE 383.82690887191495 Test RE 0.9986890583315573\n",
      "194 Train Loss 1.5064272 Test MSE 383.86355284857484 Test RE 0.9987367296441799\n",
      "195 Train Loss 1.4281832 Test MSE 383.90503706246903 Test RE 0.9987906950291241\n",
      "196 Train Loss 1.3588586 Test MSE 383.9482289204119 Test RE 0.99884687873127\n",
      "197 Train Loss 1.3319759 Test MSE 383.9868053958557 Test RE 0.9988970561007414\n",
      "198 Train Loss 1.310834 Test MSE 384.0046936684366 Test RE 0.9989203229610463\n",
      "199 Train Loss 1.2841719 Test MSE 384.02118621642046 Test RE 0.9989417739546687\n",
      "Training time: 60.29\n",
      "Training time: 60.29\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    \n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "    \n",
    "    \n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "   \n",
    "\n",
    "    start_time = time.time()\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    " \n",
    "    \n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"label\": label, \"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4f6808bcd0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.plot(u_pred,'r')\n",
    "plt.plot(y_true,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
