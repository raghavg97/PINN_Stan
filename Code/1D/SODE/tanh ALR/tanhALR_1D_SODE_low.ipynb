{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(1*x) + np.exp(-2.0*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"low\"\n",
    "label = \"1D_SODE_tanhALR_\" + level\n",
    "\n",
    "u_coeff = 2.0\n",
    "fo_val = -1.0\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "            \n",
    "        self.lambdas = torch.ones((2,),device = device)\n",
    "        \n",
    "        self.lambda_alpha = 0.1\n",
    "\n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.lambdas[1]*self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def lambda_update(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc1.backward()\n",
    "        bc1_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc1_grads.append(param.grad.view(-1))\n",
    "        bc1_grads = torch.cat(bc1_grads)\n",
    "        bc1_grads = torch.mean(torch.abs(bc1_grads))\n",
    "        \n",
    "        \n",
    "        loss_bc2 = self.lambdas[1]*self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_bc2.backward()\n",
    "        bc2_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc2_grads.append(param.grad.view(-1))\n",
    "        bc2_grads = torch.cat(bc2_grads)\n",
    "        bc2_grads = torch.mean(torch.abs(bc2_grads))\n",
    "        \n",
    "    \n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        loss_f.backward()\n",
    "        f_grads = []\n",
    "        for param in self.parameters():\n",
    "            f_grads.append(param.grad.view(-1))   \n",
    "        f_grads = torch.cat(f_grads)\n",
    "        f_grads = torch.max(torch.abs(f_grads))\n",
    "    \n",
    "        self.lambdas[0] = (1.0-self.lambda_alpha)*self.lambdas[0] + self.lambda_alpha*f_grads/bc1_grads\n",
    "        self.lambdas[1] = (1.0-self.lambda_alpha)*self.lambdas[1] + self.lambda_alpha*f_grads/bc2_grads\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    PINN.lambda_update(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        print\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 9.936979 Test MSE 15.269473729692322 Test RE 1.0247246876774714\n",
      "1 Train Loss 4.106591 Test MSE 11.190090489000617 Test RE 0.8772269469905963\n",
      "2 Train Loss 4.481102 Test MSE 9.431272991928129 Test RE 0.8053419514558446\n",
      "3 Train Loss 4.151112 Test MSE 8.77847188582219 Test RE 0.776970672212078\n",
      "4 Train Loss 2.4906647 Test MSE 5.115789035525094 Test RE 0.5931321679078303\n",
      "5 Train Loss 0.27391624 Test MSE 0.30164292390823555 Test RE 0.14402627738811072\n",
      "6 Train Loss 0.047585115 Test MSE 0.0005235593156358805 Test RE 0.006000371097287972\n",
      "7 Train Loss 0.0101151345 Test MSE 0.00048386522439261385 Test RE 0.0057684265879690486\n",
      "8 Train Loss 0.009070944 Test MSE 0.0002596612995558085 Test RE 0.004225701133709247\n",
      "9 Train Loss 0.0038301938 Test MSE 3.1939457134866656e-05 Test RE 0.00148203660320752\n",
      "10 Train Loss 0.0016481447 Test MSE 8.382618399116016e-05 Test RE 0.0024009604873965265\n",
      "11 Train Loss 0.0009954056 Test MSE 1.8945431359499202e-05 Test RE 0.0011414250876499272\n",
      "12 Train Loss 0.00036262945 Test MSE 1.6574302887407193e-07 Test RE 0.00010676104112626029\n",
      "13 Train Loss 0.00035320866 Test MSE 1.2429559549215997e-07 Test RE 9.245343137542977e-05\n",
      "14 Train Loss 0.0003445954 Test MSE 1.4165126045861878e-07 Test RE 9.869732599079201e-05\n",
      "15 Train Loss 0.00033715353 Test MSE 1.9555009306996992e-07 Test RE 0.00011596426462084705\n",
      "16 Train Loss 0.00033214266 Test MSE 2.0691094788894028e-07 Test RE 0.00011928529252781218\n",
      "17 Train Loss 0.0003266623 Test MSE 2.2860258369849158e-07 Test RE 0.00012538215560137036\n",
      "18 Train Loss 0.00032057104 Test MSE 2.2621612143918026e-07 Test RE 0.00012472598453943038\n",
      "19 Train Loss 0.00014435219 Test MSE 5.408849062741732e-07 Test RE 0.00019286241292607603\n",
      "20 Train Loss 0.00013868428 Test MSE 5.407972900204229e-07 Test RE 0.00019284679170400275\n",
      "21 Train Loss 0.00013429808 Test MSE 4.467024607449561e-07 Test RE 0.00017526868861850848\n",
      "22 Train Loss 0.00013065606 Test MSE 4.0556779563868496e-07 Test RE 0.00016700400870781399\n",
      "23 Train Loss 0.0001273881 Test MSE 2.2707740601638363e-07 Test RE 0.00012496319687770762\n",
      "24 Train Loss 0.00012426359 Test MSE 1.6220818405499806e-07 Test RE 0.00010561644517258437\n",
      "25 Train Loss 0.000121204605 Test MSE 4.023355974158571e-08 Test RE 5.2600442111025244e-05\n",
      "26 Train Loss 0.000118234224 Test MSE 2.4798026922052852e-08 Test RE 4.129559504063054e-05\n",
      "27 Train Loss 0.000115399525 Test MSE 6.397449245235243e-08 Test RE 6.632825767741392e-05\n",
      "28 Train Loss 0.00011296575 Test MSE 1.7009387210259075e-07 Test RE 0.00010815323111674394\n",
      "29 Train Loss 0.00011050718 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "30 Train Loss 0.000110507404 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "31 Train Loss 0.0001105076 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "32 Train Loss 0.00011050778 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "33 Train Loss 0.000110507935 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "34 Train Loss 0.00011050807 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "35 Train Loss 0.00011050818 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "36 Train Loss 0.00011050829 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "37 Train Loss 0.00011050839 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "38 Train Loss 0.000110508474 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "39 Train Loss 0.00011050856 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "40 Train Loss 0.00011050862 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "41 Train Loss 0.00011050868 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "42 Train Loss 0.00011050873 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "43 Train Loss 0.00011050878 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "44 Train Loss 0.000110508816 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "45 Train Loss 0.00011050885 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "46 Train Loss 0.000110508896 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "47 Train Loss 0.00011050891 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "48 Train Loss 0.00011050893 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "49 Train Loss 0.000110508954 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "50 Train Loss 0.00011050899 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "51 Train Loss 0.000110509 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "52 Train Loss 0.00011050901 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "53 Train Loss 0.00011050903 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "54 Train Loss 0.00011050904 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "55 Train Loss 0.000110509056 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "56 Train Loss 0.00011050906 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "57 Train Loss 0.00011050907 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "58 Train Loss 0.00011050907 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "59 Train Loss 0.000110509085 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "60 Train Loss 0.000110509085 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "61 Train Loss 0.000110509085 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "62 Train Loss 0.0001105091 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "63 Train Loss 0.00011050911 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "64 Train Loss 0.0001105091 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "65 Train Loss 0.00011050911 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "66 Train Loss 0.00011050911 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "67 Train Loss 0.00011050911 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "68 Train Loss 0.000110509114 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "69 Train Loss 0.00011050912 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "70 Train Loss 0.00011050912 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "71 Train Loss 0.000110509114 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "72 Train Loss 0.000110509114 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "73 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "74 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "75 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "76 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "77 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "78 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "79 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "80 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "81 Train Loss 0.00011050912 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "82 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "83 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "84 Train Loss 0.00011050912 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "85 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "86 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "87 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "88 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "89 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "90 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "91 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "92 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "93 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "94 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "95 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "96 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "97 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "98 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "99 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "100 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "101 Train Loss 0.00011050914 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "102 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "103 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "104 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "105 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "106 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "107 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "108 Train Loss 0.00011050914 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "109 Train Loss 0.00011050914 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "110 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "111 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "112 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "113 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "114 Train Loss 0.00011050914 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "115 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "116 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "117 Train Loss 0.00011050914 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "118 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "119 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "120 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "121 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "122 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "123 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "124 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "125 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "126 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "127 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "128 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "129 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "130 Train Loss 0.00011050914 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "131 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "132 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "133 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "134 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "135 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "136 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "137 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "138 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "139 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "140 Train Loss 0.00011050914 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "141 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "142 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "143 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "144 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "145 Train Loss 0.00011050914 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "146 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "147 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "148 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "149 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "150 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "151 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "152 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "153 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "154 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "155 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "156 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "157 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "158 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "159 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "160 Train Loss 0.00011050914 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "161 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "162 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "163 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "164 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "165 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "166 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "167 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "168 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "169 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "170 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "171 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "172 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "173 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "174 Train Loss 0.00011050914 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "175 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "176 Train Loss 0.00011050914 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "177 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "178 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "179 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "180 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "181 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "182 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "183 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "184 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "185 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "186 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "187 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "188 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "189 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "190 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "191 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "192 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "193 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "194 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "195 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "196 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "197 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "198 Train Loss 0.00011050913 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "199 Train Loss 0.000110509136 Test MSE 2.5550206292223644e-07 Test RE 0.00013255385733555746\n",
      "Training time: 14.41\n",
      "Training time: 14.41\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 6.3856115 Test MSE 14.828705592748355 Test RE 1.009826553227393\n",
      "1 Train Loss 4.568949 Test MSE 12.23930622401301 Test RE 0.9174313260804609\n",
      "2 Train Loss 4.373544 Test MSE 11.639612780751975 Test RE 0.8946732060548648\n",
      "3 Train Loss 4.619268 Test MSE 10.00660472109009 Test RE 0.82954230131943\n",
      "4 Train Loss 4.1026115 Test MSE 8.814679898317552 Test RE 0.7785713844254574\n",
      "5 Train Loss 2.4863834 Test MSE 3.350732718597606 Test RE 0.48002632823984004\n",
      "6 Train Loss 0.26850736 Test MSE 0.2756906080028688 Test RE 0.13769118905851616\n",
      "7 Train Loss 0.05205541 Test MSE 0.022006613959028448 Test RE 0.03890198636935366\n",
      "8 Train Loss 0.027408993 Test MSE 5.750160159978323e-05 Test RE 0.001988543681793325\n",
      "9 Train Loss 0.011213094 Test MSE 0.0009735191706448114 Test RE 0.008182149658494824\n",
      "10 Train Loss 0.0064353985 Test MSE 0.0002094545626645186 Test RE 0.0037952472777856567\n",
      "11 Train Loss 0.005833233 Test MSE 2.207028351649929e-06 Test RE 0.00038958221356846524\n",
      "12 Train Loss 0.0028766214 Test MSE 2.8476147554880108e-05 Test RE 0.0013993803849134138\n",
      "13 Train Loss 0.0026808383 Test MSE 9.48756286726977e-07 Test RE 0.00025543034980256914\n",
      "14 Train Loss 0.0026734762 Test MSE 1.665053646806879e-06 Test RE 0.0003383835794805635\n",
      "15 Train Loss 0.0026672236 Test MSE 2.850620418502982e-06 Test RE 0.00044275641325159244\n",
      "16 Train Loss 0.002661527 Test MSE 4.004091755441634e-06 Test RE 0.0005247436300034022\n",
      "17 Train Loss 0.0026555625 Test MSE 5.4915034287821985e-06 Test RE 0.000614526752999086\n",
      "18 Train Loss 0.0026486556 Test MSE 7.087001397699089e-06 Test RE 0.0006981141230549129\n",
      "19 Train Loss 0.0026404122 Test MSE 9.288351504924915e-06 Test RE 0.0007992165819640746\n",
      "20 Train Loss 0.0026304359 Test MSE 1.175364804559836e-05 Test RE 0.0008990451567042614\n",
      "21 Train Loss 0.0025376924 Test MSE 2.5474550024697375e-05 Test RE 0.0013235746039035828\n",
      "22 Train Loss 0.0025305792 Test MSE 2.477994549717805e-05 Test RE 0.001305405199570398\n",
      "23 Train Loss 0.0025254241 Test MSE 2.380018270537706e-05 Test RE 0.0012793380307020766\n",
      "24 Train Loss 0.0025215042 Test MSE 2.276348598771433e-05 Test RE 0.0012511648935453867\n",
      "25 Train Loss 0.002518335 Test MSE 2.174892784709669e-05 Test RE 0.0012229651770771864\n",
      "26 Train Loss 0.002515607 Test MSE 2.0832937192023622e-05 Test RE 0.0011969345880709708\n",
      "27 Train Loss 0.0025129905 Test MSE 1.984883494757936e-05 Test RE 0.0011683223235358028\n",
      "28 Train Loss 0.002510124 Test MSE 1.8717122408910503e-05 Test RE 0.0011345266583549665\n",
      "29 Train Loss 0.002506793 Test MSE 1.729505395189371e-05 Test RE 0.001090576475364451\n",
      "30 Train Loss 0.0025022882 Test MSE 1.497165092935589e-05 Test RE 0.0010146821283515048\n",
      "31 Train Loss 0.0024957713 Test MSE 1.1257899168527266e-05 Test RE 0.0008798808021881112\n",
      "32 Train Loss 0.002475376 Test MSE 3.079448331350286e-06 Test RE 0.0004601841174942852\n",
      "33 Train Loss 0.0015279041 Test MSE 9.336441634661385e-05 Test RE 0.002533878917585283\n",
      "34 Train Loss 0.00039160182 Test MSE 1.1643347856801392e-06 Test RE 0.00028296589930060375\n",
      "35 Train Loss 0.00023434963 Test MSE 1.0118834744480764e-05 Test RE 0.000834181235625547\n",
      "36 Train Loss 0.00010090038 Test MSE 6.225959544194491e-07 Test RE 0.00020691801903576103\n",
      "37 Train Loss 9.673547e-05 Test MSE 3.730041296418403e-07 Test RE 0.00016015923466100498\n",
      "38 Train Loss 9.370938e-05 Test MSE 1.9450242914143992e-07 Test RE 0.00011565320688637133\n",
      "39 Train Loss 9.126004e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "40 Train Loss 9.126377e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "41 Train Loss 9.126712e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "42 Train Loss 9.127013e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "43 Train Loss 9.127284e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "44 Train Loss 9.127527e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "45 Train Loss 9.127745e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "46 Train Loss 9.1279406e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "47 Train Loss 9.128116e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "48 Train Loss 9.128274e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "49 Train Loss 9.128416e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "50 Train Loss 9.128542e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "51 Train Loss 9.1286565e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "52 Train Loss 9.128759e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "53 Train Loss 9.128851e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "54 Train Loss 9.128933e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "55 Train Loss 9.129008e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "56 Train Loss 9.129074e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "57 Train Loss 9.129134e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "58 Train Loss 9.129188e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "59 Train Loss 9.129236e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "60 Train Loss 9.1292786e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "61 Train Loss 9.129317e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "62 Train Loss 9.129352e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "63 Train Loss 9.1293834e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "64 Train Loss 9.129411e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "65 Train Loss 9.1294365e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "66 Train Loss 9.129459e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "67 Train Loss 9.1294794e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "68 Train Loss 9.1294976e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "69 Train Loss 9.129514e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "70 Train Loss 9.129528e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "71 Train Loss 9.129541e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "72 Train Loss 9.129553e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "73 Train Loss 9.129564e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "74 Train Loss 9.129573e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "75 Train Loss 9.129581e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "76 Train Loss 9.129589e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "77 Train Loss 9.129596e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "78 Train Loss 9.1296024e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "79 Train Loss 9.1296075e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "80 Train Loss 9.1296126e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "81 Train Loss 9.129617e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "82 Train Loss 9.129621e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "83 Train Loss 9.129625e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "84 Train Loss 9.129627e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "85 Train Loss 9.129631e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "86 Train Loss 9.129633e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "87 Train Loss 9.129636e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "88 Train Loss 9.129638e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "89 Train Loss 9.129639e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "90 Train Loss 9.129641e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "91 Train Loss 9.1296424e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "92 Train Loss 9.129644e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "93 Train Loss 9.129645e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "94 Train Loss 9.129646e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "95 Train Loss 9.1296475e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "96 Train Loss 9.129648e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "97 Train Loss 9.129649e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "98 Train Loss 9.12965e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "99 Train Loss 9.12965e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "100 Train Loss 9.1296504e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "101 Train Loss 9.1296504e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "102 Train Loss 9.129652e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "103 Train Loss 9.129652e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "104 Train Loss 9.1296526e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "105 Train Loss 9.1296526e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "106 Train Loss 9.129653e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "107 Train Loss 9.129653e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "108 Train Loss 9.129653e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "109 Train Loss 9.129654e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "110 Train Loss 9.129653e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "111 Train Loss 9.129654e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "112 Train Loss 9.129654e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "113 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "114 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "115 Train Loss 9.129654e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "116 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "117 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "118 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "119 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "120 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "121 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "122 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "123 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "124 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "125 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "126 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "127 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "128 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "129 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "130 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "131 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "132 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "133 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "134 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "135 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "136 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "137 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "138 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "139 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "140 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "141 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "142 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "143 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "144 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "145 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "146 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "147 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "148 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "149 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "150 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "151 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "152 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "153 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "154 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "155 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "156 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "157 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "158 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "159 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "160 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "161 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "162 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "163 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "164 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "165 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "166 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "167 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "168 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "169 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "170 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "171 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "172 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "173 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "174 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "175 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "176 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "177 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "178 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "179 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "180 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "181 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "182 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "183 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "184 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "185 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "186 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "187 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "188 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "189 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "190 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "191 Train Loss 9.129655e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "192 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "193 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "194 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "195 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "196 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "197 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "198 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "199 Train Loss 9.1296555e-05 Test MSE 8.519330116718229e-08 Test RE 7.654166204101829e-05\n",
      "Training time: 14.51\n",
      "Training time: 14.51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 7.20412 Test MSE 14.960240448421294 Test RE 1.0142953901758112\n",
      "1 Train Loss 3.2443807 Test MSE 11.701724441001474 Test RE 0.8970571213658302\n",
      "2 Train Loss 3.289406 Test MSE 11.0673914368192 Test RE 0.8724043051468319\n",
      "3 Train Loss 3.2930207 Test MSE 10.31740873596811 Test RE 0.8423265363679986\n",
      "4 Train Loss 3.04383 Test MSE 9.034076266904943 Test RE 0.7882011081261254\n",
      "5 Train Loss 2.5370905 Test MSE 4.183845694814978 Test RE 0.5363928673616634\n",
      "6 Train Loss 1.4800042 Test MSE 3.023338973610896 Test RE 0.4559724319660632\n",
      "7 Train Loss 0.7927077 Test MSE 1.6260672130721119 Test RE 0.3343985698089364\n",
      "8 Train Loss 0.30437037 Test MSE 0.27198765723440044 Test RE 0.13676336029136318\n",
      "9 Train Loss 0.25124747 Test MSE 0.1703634330230967 Test RE 0.10823889658697704\n",
      "10 Train Loss 0.065844655 Test MSE 0.060125340919804655 Test RE 0.06430191999544467\n",
      "11 Train Loss 0.048621714 Test MSE 0.02319834608505925 Test RE 0.039941436141229504\n",
      "12 Train Loss 0.044671297 Test MSE 0.003531144382504133 Test RE 0.015583065729866539\n",
      "13 Train Loss 0.028003879 Test MSE 0.002254315527028363 Test RE 0.012450950769928406\n",
      "14 Train Loss 0.0229378 Test MSE 0.002697478401573441 Test RE 0.01361990733505676\n",
      "15 Train Loss 0.022062598 Test MSE 0.001120115967944949 Test RE 0.008776607143501777\n",
      "16 Train Loss 0.021656688 Test MSE 0.0003466305156226693 Test RE 0.004882346087898983\n",
      "17 Train Loss 0.02009652 Test MSE 2.1875909425396266e-05 Test RE 0.0012265301352417555\n",
      "18 Train Loss 0.014485167 Test MSE 0.000986082105354032 Test RE 0.00823477435983768\n",
      "19 Train Loss 0.009687528 Test MSE 0.00012019917343084226 Test RE 0.0028750533330438367\n",
      "20 Train Loss 0.006705442 Test MSE 0.0004277192670598996 Test RE 0.005423436651810109\n",
      "21 Train Loss 0.004372895 Test MSE 5.4322656072897e-05 Test RE 0.0019327944192944768\n",
      "22 Train Loss 0.004197965 Test MSE 5.9929467091389074e-05 Test RE 0.0020300903776919667\n",
      "23 Train Loss 0.0037714506 Test MSE 0.0002080378980431205 Test RE 0.0037823907550615724\n",
      "24 Train Loss 0.0031999205 Test MSE 3.3225190372286546e-05 Test RE 0.001511572227119789\n",
      "25 Train Loss 0.0030894878 Test MSE 9.973082298972197e-06 Test RE 0.0008281516400168609\n",
      "26 Train Loss 0.0030811052 Test MSE 8.819410968853659e-06 Test RE 0.000778780296266702\n",
      "27 Train Loss 0.0030643148 Test MSE 9.533482072473208e-06 Test RE 0.0008096940388340379\n",
      "28 Train Loss 0.0030581364 Test MSE 9.682571489641182e-06 Test RE 0.0008160006804391975\n",
      "29 Train Loss 0.003051898 Test MSE 1.030984927594747e-05 Test RE 0.0008420178977978302\n",
      "30 Train Loss 0.003044349 Test MSE 1.1969121538817474e-05 Test RE 0.0009072485928676698\n",
      "31 Train Loss 0.003035393 Test MSE 1.3378118646125945e-05 Test RE 0.0009591635941992195\n",
      "32 Train Loss 0.0030263052 Test MSE 1.4958260611587249e-05 Test RE 0.0010142282720761841\n",
      "33 Train Loss 0.002975634 Test MSE 2.440939921523248e-05 Test RE 0.0012956082654183574\n",
      "34 Train Loss 0.0025783298 Test MSE 2.46565009993243e-05 Test RE 0.0013021496177110948\n",
      "35 Train Loss 0.0020398165 Test MSE 1.7227739387527522e-05 Test RE 0.0010884520746017661\n",
      "36 Train Loss 0.0015447458 Test MSE 8.995030418300087e-06 Test RE 0.0007864959361628137\n",
      "37 Train Loss 0.0013563649 Test MSE 4.242837432792978e-07 Test RE 0.00017081395983876513\n",
      "38 Train Loss 0.0012251145 Test MSE 4.443386657333402e-06 Test RE 0.0005527798683160563\n",
      "39 Train Loss 0.0012153332 Test MSE 4.241660862390893e-06 Test RE 0.0005400862686935591\n",
      "40 Train Loss 0.0012082517 Test MSE 3.901471536451095e-06 Test RE 0.0005179757002559442\n",
      "41 Train Loss 0.0011997418 Test MSE 4.284726351056267e-06 Test RE 0.0005428210865420804\n",
      "42 Train Loss 0.0011904276 Test MSE 3.6475019447830067e-06 Test RE 0.0005008329930219829\n",
      "43 Train Loss 0.0009921334 Test MSE 5.606751054693471e-06 Test RE 0.0006209416645013969\n",
      "44 Train Loss 0.0006864525 Test MSE 1.5485959093908132e-05 Test RE 0.0010319632192951342\n",
      "45 Train Loss 0.00035029426 Test MSE 2.754068712088694e-07 Test RE 0.0001376203159263581\n",
      "46 Train Loss 0.00031802262 Test MSE 3.285193032615446e-07 Test RE 0.00015030575565586266\n",
      "47 Train Loss 0.0002994912 Test MSE 9.718527774445801e-07 Test RE 0.0002585207486216536\n",
      "48 Train Loss 0.00029217076 Test MSE 1.1017982757647068e-06 Test RE 0.0002752619670055098\n",
      "49 Train Loss 0.00028762792 Test MSE 1.0902388882004495e-06 Test RE 0.0002738142204338462\n",
      "50 Train Loss 0.00028336848 Test MSE 9.040499509260661e-07 Test RE 0.0002493396688023388\n",
      "51 Train Loss 0.00027988938 Test MSE 7.65299082633578e-07 Test RE 0.00022940916341062295\n",
      "52 Train Loss 0.00027665976 Test MSE 4.848858532746778e-07 Test RE 0.00018260594881825827\n",
      "53 Train Loss 0.00027666998 Test MSE 4.848858532746778e-07 Test RE 0.00018260594881825827\n",
      "54 Train Loss 0.00027667804 Test MSE 4.848858532746778e-07 Test RE 0.00018260594881825827\n",
      "55 Train Loss 0.00027668462 Test MSE 4.848858532746778e-07 Test RE 0.00018260594881825827\n",
      "56 Train Loss 0.0002766899 Test MSE 4.848858532746778e-07 Test RE 0.00018260594881825827\n",
      "57 Train Loss 0.0002766943 Test MSE 4.848858532746778e-07 Test RE 0.00018260594881825827\n",
      "58 Train Loss 0.0002766919 Test MSE 4.850636788037503e-07 Test RE 0.00018263942991759006\n",
      "59 Train Loss 0.00027669355 Test MSE 4.850636788037503e-07 Test RE 0.00018263942991759006\n",
      "60 Train Loss 0.00027669533 Test MSE 4.850636788037503e-07 Test RE 0.00018263942991759006\n",
      "61 Train Loss 0.0002726385 Test MSE 1.0395900372025624e-07 Test RE 8.455245446555068e-05\n",
      "62 Train Loss 0.00027261922 Test MSE 1.0395900372025624e-07 Test RE 8.455245446555068e-05\n",
      "63 Train Loss 0.0002703422 Test MSE 1.88780007471448e-07 Test RE 0.0001139391995909577\n",
      "64 Train Loss 0.00027034013 Test MSE 1.88780007471448e-07 Test RE 0.0001139391995909577\n",
      "65 Train Loss 0.00026801098 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "66 Train Loss 0.0002680093 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "67 Train Loss 0.00026800792 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "68 Train Loss 0.00026800684 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "69 Train Loss 0.000268006 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "70 Train Loss 0.00026800536 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "71 Train Loss 0.00026800486 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "72 Train Loss 0.00026800454 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "73 Train Loss 0.0002680043 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "74 Train Loss 0.0002680042 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "75 Train Loss 0.00026800417 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "76 Train Loss 0.0002680042 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "77 Train Loss 0.00026800425 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "78 Train Loss 0.00026800437 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "79 Train Loss 0.0002680045 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "80 Train Loss 0.00026800466 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "81 Train Loss 0.00026800486 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "82 Train Loss 0.00026800504 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "83 Train Loss 0.00026800524 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "84 Train Loss 0.00026800545 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "85 Train Loss 0.00026800562 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "86 Train Loss 0.00026800582 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "87 Train Loss 0.00026800603 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "88 Train Loss 0.0002680062 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "89 Train Loss 0.00026800638 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "90 Train Loss 0.00026800655 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "91 Train Loss 0.0002680067 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "92 Train Loss 0.00026800684 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "93 Train Loss 0.000268007 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "94 Train Loss 0.00026800713 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "95 Train Loss 0.00026800725 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "96 Train Loss 0.0002680074 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "97 Train Loss 0.00026800748 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "98 Train Loss 0.0002680076 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "99 Train Loss 0.0002680077 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "100 Train Loss 0.00026800777 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "101 Train Loss 0.00026800786 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "102 Train Loss 0.00026800795 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "103 Train Loss 0.000268008 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "104 Train Loss 0.00026800807 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "105 Train Loss 0.00026800815 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "106 Train Loss 0.00026800818 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "107 Train Loss 0.00026800824 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "108 Train Loss 0.0002680083 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "109 Train Loss 0.00026800833 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "110 Train Loss 0.00026800839 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "111 Train Loss 0.0002680084 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "112 Train Loss 0.00026800844 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "113 Train Loss 0.00026800847 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "114 Train Loss 0.0002680085 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "115 Train Loss 0.00026800853 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "116 Train Loss 0.00026800856 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "117 Train Loss 0.00026800856 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "118 Train Loss 0.0002680086 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "119 Train Loss 0.00026800862 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "120 Train Loss 0.00026800862 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "121 Train Loss 0.00026800865 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "122 Train Loss 0.00026800865 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "123 Train Loss 0.00026800868 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "124 Train Loss 0.00026800868 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "125 Train Loss 0.00026800868 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "126 Train Loss 0.0002680087 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "127 Train Loss 0.0002680087 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "128 Train Loss 0.0002680087 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "129 Train Loss 0.0002680087 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "130 Train Loss 0.00026800873 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "131 Train Loss 0.00026800873 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "132 Train Loss 0.00026800873 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "133 Train Loss 0.00026800873 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "134 Train Loss 0.00026800873 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "135 Train Loss 0.00026800873 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "136 Train Loss 0.00026800873 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "137 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "138 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "139 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "140 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "141 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "142 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "143 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "144 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "145 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "146 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "147 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "148 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "149 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "150 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "151 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "152 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "153 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "154 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "155 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "156 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "157 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "158 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "159 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "160 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "161 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "162 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "163 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "164 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "165 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "166 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "167 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "168 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "169 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "170 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "171 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "172 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "173 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "174 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "175 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "176 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "177 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "178 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "179 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "180 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "181 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "182 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "183 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "184 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "185 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "186 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "187 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "188 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "189 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "190 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "191 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "192 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "193 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "194 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "195 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "196 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "197 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "198 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "199 Train Loss 0.00026800876 Test MSE 2.6246680646872326e-07 Test RE 0.00013434835659299874\n",
      "Training time: 22.50\n",
      "Training time: 22.50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 6.167931 Test MSE 14.981362921735322 Test RE 1.0150111831603144\n",
      "1 Train Loss 4.0442467 Test MSE 13.629844942425853 Test RE 0.9681454804209537\n",
      "2 Train Loss 3.8350108 Test MSE 10.80044984471161 Test RE 0.8618190447373171\n",
      "3 Train Loss 3.4485009 Test MSE 10.191036413242811 Test RE 0.8371520430746207\n",
      "4 Train Loss 3.2960567 Test MSE 8.896617393806185 Test RE 0.782181647317438\n",
      "5 Train Loss 2.9266033 Test MSE 6.970595837664239 Test RE 0.6923570456860519\n",
      "6 Train Loss 1.2526546 Test MSE 2.1690744073133787 Test RE 0.38621789268686524\n",
      "7 Train Loss 0.18301862 Test MSE 0.004552996337844658 Test RE 0.017694724909836507\n",
      "8 Train Loss 0.018405583 Test MSE 0.0016982868023562305 Test RE 0.010806888785128636\n",
      "9 Train Loss 0.0096648205 Test MSE 0.0008307000469546179 Test RE 0.0075581809008346094\n",
      "10 Train Loss 0.0025351255 Test MSE 1.0515368583914986e-05 Test RE 0.0008503689905352391\n",
      "11 Train Loss 0.0005686599 Test MSE 6.61110692490778e-07 Test RE 0.0002132221191906492\n",
      "12 Train Loss 0.00044486573 Test MSE 1.0639407345298333e-06 Test RE 0.00027049166251641774\n",
      "13 Train Loss 0.00043809123 Test MSE 7.04565877770319e-07 Test RE 0.00022011820773205212\n",
      "14 Train Loss 0.00043256156 Test MSE 4.4893589625285314e-07 Test RE 0.00017570629896209927\n",
      "15 Train Loss 0.0004274921 Test MSE 2.832209945678775e-07 Test RE 0.00013955901210837115\n",
      "16 Train Loss 0.00042383204 Test MSE 1.8915607997686602e-07 Test RE 0.00011405263342796127\n",
      "17 Train Loss 0.00042070643 Test MSE 1.4288217502986222e-07 Test RE 9.912522614393615e-05\n",
      "18 Train Loss 0.00041767975 Test MSE 1.2576130981526148e-07 Test RE 9.299694688058581e-05\n",
      "19 Train Loss 0.00041440912 Test MSE 1.5341198493346312e-07 Test RE 0.00010271285697429777\n",
      "20 Train Loss 0.00041061602 Test MSE 2.4920860251563025e-07 Test RE 0.00013091116257655394\n",
      "21 Train Loss 0.000405944 Test MSE 4.280434099807284e-07 Test RE 0.00017156909971957653\n",
      "22 Train Loss 0.0004001822 Test MSE 7.358142638120553e-07 Test RE 0.00022494651333328727\n",
      "23 Train Loss 0.00039319508 Test MSE 1.154594597175761e-06 Test RE 0.00028177984458393264\n",
      "24 Train Loss 0.00038359227 Test MSE 1.7555330729660426e-06 Test RE 0.00034745588558534446\n",
      "25 Train Loss 8.087092e-05 Test MSE 2.5436869883528657e-07 Test RE 0.00013225953729950767\n",
      "26 Train Loss 3.7729627e-05 Test MSE 7.980133445075462e-07 Test RE 0.00023426113421814887\n",
      "27 Train Loss 3.139526e-05 Test MSE 8.430565624757992e-07 Test RE 0.00024078172499134674\n",
      "28 Train Loss 2.721708e-05 Test MSE 7.804381614989712e-07 Test RE 0.00023166712729044247\n",
      "29 Train Loss 2.4403818e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "30 Train Loss 2.4404062e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "31 Train Loss 2.4404271e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "32 Train Loss 2.4404455e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "33 Train Loss 2.4404617e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "34 Train Loss 2.4404757e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "35 Train Loss 2.440488e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "36 Train Loss 2.4404988e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "37 Train Loss 2.440508e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "38 Train Loss 2.440516e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "39 Train Loss 2.4405232e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "40 Train Loss 2.4405295e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "41 Train Loss 2.4405348e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "42 Train Loss 2.4405397e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "43 Train Loss 2.4405437e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "44 Train Loss 2.4405472e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "45 Train Loss 2.4405503e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "46 Train Loss 2.4405532e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "47 Train Loss 2.4405557e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "48 Train Loss 2.4405577e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "49 Train Loss 2.4405594e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "50 Train Loss 2.440561e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "51 Train Loss 2.4405625e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "52 Train Loss 2.4405635e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "53 Train Loss 2.4405645e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "54 Train Loss 2.4405654e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "55 Train Loss 2.4405665e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "56 Train Loss 2.440567e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "57 Train Loss 2.4405676e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "58 Train Loss 2.4405681e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "59 Train Loss 2.4405685e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "60 Train Loss 2.440569e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "61 Train Loss 2.4405692e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "62 Train Loss 2.4405697e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "63 Train Loss 2.4405701e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "64 Train Loss 2.4405701e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "65 Train Loss 2.4405703e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "66 Train Loss 2.4405705e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "67 Train Loss 2.4405706e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "68 Train Loss 2.4405708e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "69 Train Loss 2.4405708e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "70 Train Loss 2.4405712e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "71 Train Loss 2.4405712e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "72 Train Loss 2.4405712e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "73 Train Loss 2.4405712e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "74 Train Loss 2.4405712e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "75 Train Loss 2.4405714e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "76 Train Loss 2.4405714e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "77 Train Loss 2.4405714e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "78 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "79 Train Loss 2.4405714e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "80 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "81 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "82 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "83 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "84 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "85 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "86 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "87 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "88 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "89 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "90 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "91 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "92 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "93 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "94 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "95 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "96 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "97 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "98 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "99 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "100 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "101 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "102 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "103 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "104 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "105 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "106 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "107 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "108 Train Loss 2.4405716e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "109 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "110 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "111 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "112 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "113 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "114 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "115 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "116 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "117 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "118 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "119 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "120 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "121 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "122 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "123 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "124 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "125 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "126 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "127 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "128 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "129 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "130 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "131 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "132 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "133 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "134 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "135 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "136 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "137 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "138 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "139 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "140 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "141 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "142 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "143 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "144 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "145 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "146 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "147 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "148 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "149 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "150 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "151 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "152 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "153 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "154 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "155 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "156 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "157 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "158 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "159 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "160 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "161 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "162 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "163 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "164 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "165 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "166 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "167 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "168 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "169 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "170 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "171 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "172 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "173 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "174 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "175 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "176 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "177 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "178 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "179 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "180 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "181 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "182 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "183 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "184 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "185 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "186 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "187 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "188 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "189 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "190 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "191 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "192 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "193 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "194 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "195 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "196 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "197 Train Loss 2.440572e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "198 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "199 Train Loss 2.4405717e-05 Test MSE 6.562073004914138e-07 Test RE 0.00021242992396386883\n",
      "Training time: 15.18\n",
      "Training time: 15.18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 7.88294 Test MSE 14.694908368304013 Test RE 1.0052604720612115\n",
      "1 Train Loss 4.518045 Test MSE 13.85477943315983 Test RE 0.9761014837094496\n",
      "2 Train Loss 5.0904517 Test MSE 12.326841893083735 Test RE 0.9207062210702895\n",
      "3 Train Loss 4.470063 Test MSE 9.165140874400729 Test RE 0.7938980535687981\n",
      "4 Train Loss 3.1094537 Test MSE 6.111438009644039 Test RE 0.6482863393269046\n",
      "5 Train Loss 1.4667475 Test MSE 2.3566645060308486 Test RE 0.40257244496879596\n",
      "6 Train Loss 0.32157072 Test MSE 0.20034450973796683 Test RE 0.11737723843406846\n",
      "7 Train Loss 0.09675896 Test MSE 0.004175887046347035 Test RE 0.016946091079028003\n",
      "8 Train Loss 0.0592049 Test MSE 0.0008993118051094641 Test RE 0.007864123261628279\n",
      "9 Train Loss 0.050678723 Test MSE 0.0029579532920696234 Test RE 0.014262341161807565\n",
      "10 Train Loss 0.049492005 Test MSE 0.0024840184810028644 Test RE 0.013069909371044991\n",
      "11 Train Loss 0.035450835 Test MSE 0.0001837604685972293 Test RE 0.003554849423800937\n",
      "12 Train Loss 0.018502338 Test MSE 0.0016691310104531554 Test RE 0.010713722114482935\n",
      "13 Train Loss 0.01241389 Test MSE 0.0003944480895614024 Test RE 0.005208229262142986\n",
      "14 Train Loss 0.0076569594 Test MSE 0.00032740789414079845 Test RE 0.004745038472786378\n",
      "15 Train Loss 0.0047302665 Test MSE 2.2782617152202023e-05 Test RE 0.0012516905426992186\n",
      "16 Train Loss 0.0028800808 Test MSE 2.9163333613919994e-06 Test RE 0.00044783058190010316\n",
      "17 Train Loss 0.0021977127 Test MSE 6.228950779895643e-06 Test RE 0.0006544893957717735\n",
      "18 Train Loss 0.0013093378 Test MSE 2.178550879631631e-06 Test RE 0.0003870606471674679\n",
      "19 Train Loss 0.0003461452 Test MSE 1.4468305622162068e-06 Test RE 0.00031543073056075106\n",
      "20 Train Loss 0.00033708045 Test MSE 1.047693180669252e-06 Test RE 0.00026841836297349233\n",
      "21 Train Loss 0.00033098814 Test MSE 8.357090954556103e-07 Test RE 0.00023973018979416762\n",
      "22 Train Loss 0.00032666247 Test MSE 6.70914884379711e-07 Test RE 0.00021479732980193736\n",
      "23 Train Loss 0.0003235622 Test MSE 5.99422028437934e-07 Test RE 0.0002030306075880162\n",
      "24 Train Loss 0.00032119476 Test MSE 5.628692723422007e-07 Test RE 0.00019674283952997166\n",
      "25 Train Loss 0.00031861177 Test MSE 5.631291938173043e-07 Test RE 0.00019678826018922427\n",
      "26 Train Loss 0.000315533 Test MSE 5.099656944442316e-07 Test RE 0.0001872688940838221\n",
      "27 Train Loss 0.00031204856 Test MSE 4.581683110211055e-07 Test RE 0.00017750381389558114\n",
      "28 Train Loss 0.00030791 Test MSE 4.018379374954475e-07 Test RE 0.0001662342976500328\n",
      "29 Train Loss 0.00030253571 Test MSE 3.10304039455758e-07 Test RE 0.00014607936736563736\n",
      "30 Train Loss 0.00029638445 Test MSE 2.673903540664499e-07 Test RE 0.0001356026050960867\n",
      "31 Train Loss 0.0002884492 Test MSE 2.2613015116090245e-07 Test RE 0.00012470228210283914\n",
      "32 Train Loss 0.00027952078 Test MSE 2.490067340405785e-07 Test RE 0.00013085813031694314\n",
      "33 Train Loss 0.00025940058 Test MSE 4.245577211141868e-07 Test RE 0.00017086910181274645\n",
      "34 Train Loss 0.0002502568 Test MSE 5.30793964228633e-07 Test RE 0.0001910548877372737\n",
      "35 Train Loss 0.00024299948 Test MSE 6.375340389566077e-07 Test RE 0.00020938562058723603\n",
      "36 Train Loss 0.00023702107 Test MSE 6.512770504397274e-07 Test RE 0.00021163039972357112\n",
      "37 Train Loss 0.00023249784 Test MSE 7.196499171897815e-07 Test RE 0.00022246198326567192\n",
      "38 Train Loss 0.00022943103 Test MSE 6.57059086867856e-07 Test RE 0.00021256775101522872\n",
      "39 Train Loss 0.0002294253 Test MSE 6.57059086867856e-07 Test RE 0.00021256775101522872\n",
      "40 Train Loss 0.0002269784 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "41 Train Loss 0.00022697836 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "42 Train Loss 0.00022697831 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "43 Train Loss 0.0002269783 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "44 Train Loss 0.00022697827 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "45 Train Loss 0.00022697823 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "46 Train Loss 0.00022697824 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "47 Train Loss 0.00022697823 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "48 Train Loss 0.00022697818 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "49 Train Loss 0.0002269782 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "50 Train Loss 0.00022697815 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "51 Train Loss 0.00022697815 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "52 Train Loss 0.00022697814 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "53 Train Loss 0.00022697814 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "54 Train Loss 0.00022697813 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "55 Train Loss 0.00022697813 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "56 Train Loss 0.00022697813 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "57 Train Loss 0.00022697811 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "58 Train Loss 0.0002269781 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "59 Train Loss 0.00022697811 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "60 Train Loss 0.00022697811 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "61 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "62 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "63 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "64 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "65 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "66 Train Loss 0.0002269781 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "67 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "68 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "69 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "70 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "71 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "72 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "73 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "74 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "75 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "76 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "77 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "78 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "79 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "80 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "81 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "82 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "83 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "84 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "85 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "86 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "87 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "88 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "89 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "90 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "91 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "92 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "93 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "94 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "95 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "96 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "97 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "98 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "99 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "100 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "101 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "102 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "103 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "104 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "105 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "106 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "107 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "108 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "109 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "110 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "111 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "112 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "113 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "114 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "115 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "116 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "117 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "118 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "119 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "120 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "121 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "122 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "123 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "124 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "125 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "126 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "127 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "128 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "129 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "130 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "131 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "132 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "133 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "134 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "135 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "136 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "137 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "138 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "139 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "140 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "141 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "142 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "143 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "144 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "145 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "146 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "147 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "148 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "149 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "150 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "151 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "152 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "153 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "154 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "155 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "156 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "157 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "158 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "159 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "160 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "161 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "162 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "163 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "164 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "165 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "166 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "167 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "168 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "169 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "170 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "171 Train Loss 0.00022697805 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "172 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "173 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "174 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "175 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "176 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "177 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "178 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "179 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "180 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "181 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "182 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "183 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "184 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "185 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "186 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "187 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "188 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "189 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "190 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "191 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "192 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "193 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "194 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "195 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "196 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "197 Train Loss 0.00022697808 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "198 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "199 Train Loss 0.00022697807 Test MSE 2.5977157427172176e-07 Test RE 0.00013365677503149578\n",
      "Training time: 17.03\n",
      "Training time: 17.03\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 12.648303 Test MSE 15.002296869190424 Test RE 1.0157200897320797\n",
      "1 Train Loss 5.827589 Test MSE 13.297306017332492 Test RE 0.9562622167674723\n",
      "2 Train Loss 4.5157466 Test MSE 10.821000555318895 Test RE 0.8626385743440855\n",
      "3 Train Loss 3.0773377 Test MSE 5.495655046392909 Test RE 0.6147590025195107\n",
      "4 Train Loss 1.2078774 Test MSE 1.4404736793956334 Test RE 0.314737019911242\n",
      "5 Train Loss 0.22721958 Test MSE 0.1670047225126194 Test RE 0.10716662184094009\n",
      "6 Train Loss 0.110402465 Test MSE 0.013899161404052795 Test RE 0.03091643888829136\n",
      "7 Train Loss 0.008814079 Test MSE 0.0005068578838459735 Test RE 0.005903890144247045\n",
      "8 Train Loss 0.0034484537 Test MSE 0.002046386321111853 Test RE 0.011862848302962754\n",
      "9 Train Loss 0.001682812 Test MSE 9.727895567845094e-05 Test RE 0.002586453140757801\n",
      "10 Train Loss 0.0012124893 Test MSE 0.00015410632445630212 Test RE 0.0032554077718234676\n",
      "11 Train Loss 0.00017499125 Test MSE 1.2706440607738608e-05 Test RE 0.00093477506732728\n",
      "12 Train Loss 0.00016618316 Test MSE 8.130297905126017e-06 Test RE 0.0007477361788923415\n",
      "13 Train Loss 0.00015978652 Test MSE 4.003052105070284e-06 Test RE 0.0005246755015287922\n",
      "14 Train Loss 0.00015634655 Test MSE 2.7704936980471698e-06 Test RE 0.00043648944686821217\n",
      "15 Train Loss 0.00015392095 Test MSE 1.7127159364299892e-06 Test RE 0.0003431925361928888\n",
      "16 Train Loss 0.00015392007 Test MSE 1.7127159364299892e-06 Test RE 0.0003431925361928888\n",
      "17 Train Loss 0.0001508083 Test MSE 3.0172113745889193e-07 Test RE 0.00014404494859755426\n",
      "18 Train Loss 0.00015080537 Test MSE 3.0172113745889193e-07 Test RE 0.00014404494859755426\n",
      "19 Train Loss 0.0001497038 Test MSE 2.0984868589725216e-07 Test RE 0.0001201291189163963\n",
      "20 Train Loss 0.0001497004 Test MSE 2.0984868589725216e-07 Test RE 0.0001201291189163963\n",
      "21 Train Loss 0.00014876101 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "22 Train Loss 0.00014877324 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "23 Train Loss 0.00014878402 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "24 Train Loss 0.00014879362 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "25 Train Loss 0.00014880212 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "26 Train Loss 0.00014880969 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "27 Train Loss 0.00014881641 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "28 Train Loss 0.00014882238 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "29 Train Loss 0.00014882772 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "30 Train Loss 0.00014883245 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "31 Train Loss 0.00014883668 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "32 Train Loss 0.00014884045 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "33 Train Loss 0.0001488438 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "34 Train Loss 0.00014884683 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "35 Train Loss 0.0001488495 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "36 Train Loss 0.00014885189 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "37 Train Loss 0.00014885401 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "38 Train Loss 0.00014885592 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "39 Train Loss 0.00014885762 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "40 Train Loss 0.00014885915 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "41 Train Loss 0.0001488605 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "42 Train Loss 0.00014886171 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "43 Train Loss 0.00014886282 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "44 Train Loss 0.00014886378 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "45 Train Loss 0.00014886464 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "46 Train Loss 0.00014886542 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "47 Train Loss 0.00014886612 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "48 Train Loss 0.00014886673 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "49 Train Loss 0.0001488673 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "50 Train Loss 0.00014886778 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "51 Train Loss 0.00014886825 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "52 Train Loss 0.00014886864 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "53 Train Loss 0.000148869 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "54 Train Loss 0.00014886931 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "55 Train Loss 0.00014886961 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "56 Train Loss 0.00014886985 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "57 Train Loss 0.00014887008 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "58 Train Loss 0.00014887028 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "59 Train Loss 0.00014887047 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "60 Train Loss 0.00014887065 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "61 Train Loss 0.00014887078 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "62 Train Loss 0.00014887092 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "63 Train Loss 0.00014887104 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "64 Train Loss 0.00014887114 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "65 Train Loss 0.00014887123 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "66 Train Loss 0.00014887133 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "67 Train Loss 0.0001488714 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "68 Train Loss 0.00014887146 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "69 Train Loss 0.00014887152 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "70 Train Loss 0.00014887158 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "71 Train Loss 0.00014887164 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "72 Train Loss 0.0001488717 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "73 Train Loss 0.00014887172 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "74 Train Loss 0.00014887175 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "75 Train Loss 0.0001488718 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "76 Train Loss 0.00014887183 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "77 Train Loss 0.00014887186 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "78 Train Loss 0.00014887187 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "79 Train Loss 0.00014887188 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "80 Train Loss 0.00014887191 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "81 Train Loss 0.00014887191 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "82 Train Loss 0.00014887194 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "83 Train Loss 0.00014887196 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "84 Train Loss 0.00014887197 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "85 Train Loss 0.00014887199 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "86 Train Loss 0.00014887197 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "87 Train Loss 0.00014887199 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "88 Train Loss 0.000148872 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "89 Train Loss 0.00014887202 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "90 Train Loss 0.00014887202 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "91 Train Loss 0.00014887202 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "92 Train Loss 0.00014887202 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "93 Train Loss 0.00014887203 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "94 Train Loss 0.00014887204 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "95 Train Loss 0.00014887203 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "96 Train Loss 0.00014887203 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "97 Train Loss 0.00014887203 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "98 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "99 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "100 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "101 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "102 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "103 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "104 Train Loss 0.00014887204 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "105 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "106 Train Loss 0.00014887204 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "107 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "108 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "109 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "110 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "111 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "112 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "113 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "114 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "115 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "116 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "117 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "118 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "119 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "120 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "121 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "122 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "123 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "124 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "125 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "126 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "127 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "128 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "129 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "130 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "131 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "132 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "133 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "134 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "135 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "136 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "137 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "138 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "139 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "140 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "141 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "142 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "143 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "144 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "145 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "146 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "147 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "148 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "149 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "150 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "151 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "152 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "153 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "154 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "155 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "156 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "157 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "158 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "159 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "160 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "161 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "162 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "163 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "164 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "165 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "166 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "167 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "168 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "169 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "170 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "171 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "172 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "173 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "174 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "175 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "176 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "177 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "178 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "179 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "180 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "181 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "182 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "183 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "184 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "185 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "186 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "187 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "188 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "189 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "190 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "191 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "192 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "193 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "194 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "195 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "196 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "197 Train Loss 0.00014887207 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "198 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "199 Train Loss 0.00014887206 Test MSE 3.2297039198786527e-08 Test RE 4.7127729835706327e-05\n",
      "Training time: 13.49\n",
      "Training time: 13.49\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 7.498259 Test MSE 15.143952407877034 Test RE 1.0205041680713143\n",
      "1 Train Loss 4.4770365 Test MSE 13.094166977042443 Test RE 0.9489298367614153\n",
      "2 Train Loss 4.9933476 Test MSE 10.85769811615822 Test RE 0.8641000814028952\n",
      "3 Train Loss 4.5581822 Test MSE 9.447352274949683 Test RE 0.8060281688193706\n",
      "4 Train Loss 4.576156 Test MSE 9.579139489321612 Test RE 0.8116306020717656\n",
      "5 Train Loss 4.471196 Test MSE 9.645420260156635 Test RE 0.8144337122043843\n",
      "6 Train Loss 4.196973 Test MSE 7.6527660734558545 Test RE 0.7254448198322903\n",
      "7 Train Loss 3.3540397 Test MSE 4.694862819283483 Test RE 0.5682070505044936\n",
      "8 Train Loss 2.2310648 Test MSE 2.5530986826018727 Test RE 0.4190144166044629\n",
      "9 Train Loss 1.6342299 Test MSE 1.8025024605529887 Test RE 0.35207330564142164\n",
      "10 Train Loss 0.22216555 Test MSE 0.027722055711457975 Test RE 0.04366242782798744\n",
      "11 Train Loss 0.020619787 Test MSE 0.002316671623234959 Test RE 0.012621977577229049\n",
      "12 Train Loss 0.01671929 Test MSE 0.0023566665942439087 Test RE 0.01273046413339637\n",
      "13 Train Loss 0.003793879 Test MSE 7.275674294499318e-05 Test RE 0.002236823873618053\n",
      "14 Train Loss 0.0027025242 Test MSE 0.00010459097166450812 Test RE 0.002681898044592342\n",
      "15 Train Loss 0.0013086366 Test MSE 3.454398332613189e-05 Test RE 0.0015412793950271223\n",
      "16 Train Loss 0.0012528392 Test MSE 4.2314508944672784e-06 Test RE 0.0005394358647644814\n",
      "17 Train Loss 0.0012454097 Test MSE 9.068234043123243e-07 Test RE 0.00024972183927196025\n",
      "18 Train Loss 0.0012421006 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "19 Train Loss 0.0012420941 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "20 Train Loss 0.0012420883 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "21 Train Loss 0.0012420831 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "22 Train Loss 0.0012420785 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "23 Train Loss 0.0012420745 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "24 Train Loss 0.0012420707 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "25 Train Loss 0.0012420674 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "26 Train Loss 0.0012420644 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "27 Train Loss 0.0012420617 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "28 Train Loss 0.0012420594 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "29 Train Loss 0.0012420573 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "30 Train Loss 0.0012420554 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "31 Train Loss 0.0012420538 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "32 Train Loss 0.0012420523 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "33 Train Loss 0.0012420508 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "34 Train Loss 0.0012420496 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "35 Train Loss 0.0012420485 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "36 Train Loss 0.0012420474 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "37 Train Loss 0.0012420466 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "38 Train Loss 0.0012420458 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "39 Train Loss 0.0012420451 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "40 Train Loss 0.0012420445 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "41 Train Loss 0.001242044 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "42 Train Loss 0.0012420435 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "43 Train Loss 0.0012420431 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "44 Train Loss 0.0012420425 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "45 Train Loss 0.0012420423 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "46 Train Loss 0.0012420418 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "47 Train Loss 0.0012420416 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "48 Train Loss 0.0012420414 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "49 Train Loss 0.0012420411 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "50 Train Loss 0.0012420409 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "51 Train Loss 0.0012420407 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "52 Train Loss 0.0012420407 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "53 Train Loss 0.0012420403 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "54 Train Loss 0.0012420403 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "55 Train Loss 0.0012420401 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "56 Train Loss 0.00124204 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "57 Train Loss 0.0012420398 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "58 Train Loss 0.0012420398 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "59 Train Loss 0.0012420397 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "60 Train Loss 0.0012420397 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "61 Train Loss 0.0012420396 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "62 Train Loss 0.0012420396 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "63 Train Loss 0.0012420395 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "64 Train Loss 0.0012420395 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "65 Train Loss 0.0012420394 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "66 Train Loss 0.0012420395 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "67 Train Loss 0.0012420394 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "68 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "69 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "70 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "71 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "72 Train Loss 0.0012420394 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "73 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "74 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "75 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "76 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "77 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "78 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "79 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "80 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "81 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "82 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "83 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "84 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "85 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "86 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "87 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "88 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "89 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "90 Train Loss 0.0012420393 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "91 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "92 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "93 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "94 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "95 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "96 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "97 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "98 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "99 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "100 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "101 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "102 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "103 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "104 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "105 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "106 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "107 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "108 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "109 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "110 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "111 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "112 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "113 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "114 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "115 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "116 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "117 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "118 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "119 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "120 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "121 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "122 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "123 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "124 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "125 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "126 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "127 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "128 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "129 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "130 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "131 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "132 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "133 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "134 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "135 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "136 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "137 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "138 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "139 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "140 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "141 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "142 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "143 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "144 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "145 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "146 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "147 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "148 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "149 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "150 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "151 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "152 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "153 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "154 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "155 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "156 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "157 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "158 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "159 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "160 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "161 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "162 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "163 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "164 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "165 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "166 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "167 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "168 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "169 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "170 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "171 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "172 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "173 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "174 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "175 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "176 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "177 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "178 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "179 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "180 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "181 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "182 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "183 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "184 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "185 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "186 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "187 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "188 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "189 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "190 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "191 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "192 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "193 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "194 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "195 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "196 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "197 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "198 Train Loss 0.001242039 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "199 Train Loss 0.0012420391 Test MSE 7.536957484686613e-07 Test RE 0.00022766338955043338\n",
      "Training time: 15.48\n",
      "Training time: 15.48\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 9.133265 Test MSE 15.417204205141463 Test RE 1.0296698048105135\n",
      "1 Train Loss 4.0563793 Test MSE 12.762458157621687 Test RE 0.9368333236375563\n",
      "2 Train Loss 3.7308679 Test MSE 9.92617933812695 Test RE 0.8262019649097948\n",
      "3 Train Loss 2.8082752 Test MSE 7.914374403458994 Test RE 0.7377402193835897\n",
      "4 Train Loss 1.2541283 Test MSE 2.438634395975734 Test RE 0.40951377256980986\n",
      "5 Train Loss 0.4018746 Test MSE 0.41417455576526957 Test RE 0.16876674426167473\n",
      "6 Train Loss 0.06507713 Test MSE 8.865354079476665e-05 Test RE 0.0024691257447055854\n",
      "7 Train Loss 0.022365859 Test MSE 0.007231992766223602 Test RE 0.022300990686503763\n",
      "8 Train Loss 0.0064151436 Test MSE 0.00019051313720119204 Test RE 0.0036195754100152833\n",
      "9 Train Loss 0.0034279956 Test MSE 0.00013735560017316158 Test RE 0.003073394786571181\n",
      "10 Train Loss 0.001485769 Test MSE 3.8019869999887485e-07 Test RE 0.00016169644753438847\n",
      "11 Train Loss 0.00077741616 Test MSE 1.265720732941024e-05 Test RE 0.0009329623367156644\n",
      "12 Train Loss 0.0007250537 Test MSE 3.1855310600383908e-06 Test RE 0.0004680433582396605\n",
      "13 Train Loss 0.0007178202 Test MSE 1.933419196912914e-06 Test RE 0.0003646348533257982\n",
      "14 Train Loss 0.00071132655 Test MSE 1.0773045107546218e-06 Test RE 0.00027218513549193666\n",
      "15 Train Loss 0.00070523814 Test MSE 4.262589338181652e-07 Test RE 0.0001712110977995733\n",
      "16 Train Loss 0.0006987287 Test MSE 1.1129126296068493e-07 Test RE 8.748340945078545e-05\n",
      "17 Train Loss 0.0006912342 Test MSE 1.432768760224532e-07 Test RE 9.926204461891101e-05\n",
      "18 Train Loss 0.00068202004 Test MSE 5.7759502867672e-07 Test RE 0.00019929981157836138\n",
      "19 Train Loss 0.0003112962 Test MSE 4.756234372143921e-05 Test RE 0.0018085344603780767\n",
      "20 Train Loss 5.726034e-05 Test MSE 1.3154388834794239e-08 Test RE 3.007672205112783e-05\n",
      "21 Train Loss 5.2206346e-05 Test MSE 1.350917237641098e-07 Test RE 9.638501880662945e-05\n",
      "22 Train Loss 4.837767e-05 Test MSE 3.137502934512141e-07 Test RE 0.00014688831033286858\n",
      "23 Train Loss 4.5941564e-05 Test MSE 5.145044483685816e-07 Test RE 0.00018810040550154417\n",
      "24 Train Loss 4.5938155e-05 Test MSE 5.145044483685816e-07 Test RE 0.00018810040550154417\n",
      "25 Train Loss 4.171522e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "26 Train Loss 4.171641e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "27 Train Loss 4.1717496e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "28 Train Loss 4.1718482e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "29 Train Loss 4.171938e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "30 Train Loss 4.1720203e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "31 Train Loss 4.1720952e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "32 Train Loss 4.172163e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "33 Train Loss 4.172225e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "34 Train Loss 4.1722815e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "35 Train Loss 4.1723324e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "36 Train Loss 4.1723782e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "37 Train Loss 4.1724197e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "38 Train Loss 4.172456e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "39 Train Loss 4.1724885e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "40 Train Loss 4.172517e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "41 Train Loss 4.1725416e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "42 Train Loss 4.1725627e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "43 Train Loss 4.1725805e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "44 Train Loss 4.1725965e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "45 Train Loss 4.172609e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "46 Train Loss 4.17262e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "47 Train Loss 4.1726293e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "48 Train Loss 4.172637e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "49 Train Loss 4.172643e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "50 Train Loss 4.1726486e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "51 Train Loss 4.172653e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "52 Train Loss 4.1726566e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "53 Train Loss 4.1726595e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "54 Train Loss 4.172662e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "55 Train Loss 4.172664e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "56 Train Loss 4.1726656e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "57 Train Loss 4.172667e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "58 Train Loss 4.1726682e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "59 Train Loss 4.1726693e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "60 Train Loss 4.17267e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "61 Train Loss 4.1726707e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "62 Train Loss 4.172671e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "63 Train Loss 4.1726715e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "64 Train Loss 4.1726722e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "65 Train Loss 4.1726722e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "66 Train Loss 4.1726726e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "67 Train Loss 4.172673e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "68 Train Loss 4.172673e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "69 Train Loss 4.1726733e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "70 Train Loss 4.1726733e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "71 Train Loss 4.1726733e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "72 Train Loss 4.1726733e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "73 Train Loss 4.1726733e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "74 Train Loss 4.1726733e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "75 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "76 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "77 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "78 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "79 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "80 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "81 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "82 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "83 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "84 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "85 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "86 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "87 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "88 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "89 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "90 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "91 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "92 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "93 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "94 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "95 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "96 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "97 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "98 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "99 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "100 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "101 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "102 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "103 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "104 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "105 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "106 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "107 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "108 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "109 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "110 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "111 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "112 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "113 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "114 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "115 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "116 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "117 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "118 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "119 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "120 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "121 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "122 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "123 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "124 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "125 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "126 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "127 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "128 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "129 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "130 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "131 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "132 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "133 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "134 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "135 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "136 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "137 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "138 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "139 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "140 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "141 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "142 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "143 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "144 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "145 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "146 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "147 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "148 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "149 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "150 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "151 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "152 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "153 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "154 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "155 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "156 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "157 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "158 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "159 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "160 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "161 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "162 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "163 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "164 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "165 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "166 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "167 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "168 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "169 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "170 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "171 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "172 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "173 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "174 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "175 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "176 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "177 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "178 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "179 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "180 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "181 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "182 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "183 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "184 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "185 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "186 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "187 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "188 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "189 Train Loss 4.172674e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "190 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "191 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "192 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "193 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "194 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "195 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "196 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "197 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "198 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "199 Train Loss 4.1726737e-05 Test MSE 1.0307858276796966e-06 Test RE 0.0002662437270512648\n",
      "Training time: 14.72\n",
      "Training time: 14.72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 5.3677006 Test MSE 15.323090935236632 Test RE 1.0265222194094743\n",
      "1 Train Loss 3.065059 Test MSE 11.576656577898836 Test RE 0.8922503764301454\n",
      "2 Train Loss 2.5870788 Test MSE 8.83568978311659 Test RE 0.779498698842794\n",
      "3 Train Loss 1.9043554 Test MSE 4.727412088937256 Test RE 0.570173325142105\n",
      "4 Train Loss 1.3956199 Test MSE 0.8699494860347111 Test RE 0.24459196310805645\n",
      "5 Train Loss 0.48450863 Test MSE 0.4590912434669031 Test RE 0.17768250544465725\n",
      "6 Train Loss 0.04749882 Test MSE 0.08629765073224176 Test RE 0.0770361644108364\n",
      "7 Train Loss 0.012060138 Test MSE 0.00017463281655848782 Test RE 0.003465437686938199\n",
      "8 Train Loss 0.006958389 Test MSE 5.247733407341529e-06 Test RE 0.0006007323875047834\n",
      "9 Train Loss 0.0040326375 Test MSE 3.4386787719623815e-05 Test RE 0.00153776852877828\n",
      "10 Train Loss 0.003932132 Test MSE 2.503345372014132e-05 Test RE 0.0013120656029829783\n",
      "11 Train Loss 0.003925965 Test MSE 2.480737521269287e-05 Test RE 0.0013061274971596123\n",
      "12 Train Loss 0.0039209677 Test MSE 2.481188851945061e-05 Test RE 0.0013062463063022562\n",
      "13 Train Loss 0.003914907 Test MSE 2.5046707344603033e-05 Test RE 0.0013124128847423985\n",
      "14 Train Loss 0.0039068903 Test MSE 2.5205893012449544e-05 Test RE 0.0013165768337816328\n",
      "15 Train Loss 0.0032499025 Test MSE 4.869404149319588e-06 Test RE 0.0005786728084184368\n",
      "16 Train Loss 0.0009757208 Test MSE 4.362363365220322e-06 Test RE 0.0005477168269908639\n",
      "17 Train Loss 0.0003831566 Test MSE 1.5256267621926796e-06 Test RE 0.00032390623947165474\n",
      "18 Train Loss 0.0002101389 Test MSE 2.073848055434856e-07 Test RE 0.00011942180517789213\n",
      "19 Train Loss 0.00016403763 Test MSE 7.48008706139486e-08 Test RE 7.172135586453782e-05\n",
      "20 Train Loss 0.00015456053 Test MSE 5.6310676222564613e-08 Test RE 6.222867245782051e-05\n",
      "21 Train Loss 0.00014700169 Test MSE 5.851583428099586e-08 Test RE 6.343542669125799e-05\n",
      "22 Train Loss 0.00013926107 Test MSE 4.0126366504945876e-08 Test RE 5.253032437529914e-05\n",
      "23 Train Loss 0.00013351373 Test MSE 5.955216256885251e-08 Test RE 6.399468906910697e-05\n",
      "24 Train Loss 0.00012920296 Test MSE 5.130326800858468e-08 Test RE 5.9397433506303284e-05\n",
      "25 Train Loss 0.00012583323 Test MSE 4.698699555473025e-08 Test RE 5.684391781962181e-05\n",
      "26 Train Loss 0.00012257861 Test MSE 5.274848137144625e-08 Test RE 6.0228236238036505e-05\n",
      "27 Train Loss 0.000119322525 Test MSE 8.195970686207652e-08 Test RE 7.507500382696562e-05\n",
      "28 Train Loss 0.00011587563 Test MSE 3.834354163594795e-08 Test RE 5.1350098026276496e-05\n",
      "29 Train Loss 0.00011337177 Test MSE 7.019256889020978e-08 Test RE 6.947694813511046e-05\n",
      "30 Train Loss 0.0001108852 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "31 Train Loss 0.000110887544 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "32 Train Loss 0.000110888956 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "33 Train Loss 0.00011088988 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "34 Train Loss 0.000110890505 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "35 Train Loss 0.00011089095 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "36 Train Loss 0.000110891255 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "37 Train Loss 0.00011089148 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "38 Train Loss 0.00011089164 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "39 Train Loss 0.00011089174 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "40 Train Loss 0.00011089184 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "41 Train Loss 0.00011089188 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "42 Train Loss 0.00011089193 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "43 Train Loss 0.00011089195 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "44 Train Loss 0.00011089198 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "45 Train Loss 0.00011089199 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "46 Train Loss 0.000110892004 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "47 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "48 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "49 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "50 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "51 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "52 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "53 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "54 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "55 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "56 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "57 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "58 Train Loss 0.00011089203 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "59 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "60 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "61 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "62 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "63 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "64 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "65 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "66 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "67 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "68 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "69 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "70 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "71 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "72 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "73 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "74 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "75 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "76 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "77 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "78 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "79 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "80 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "81 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "82 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "83 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "84 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "85 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "86 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "87 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "88 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "89 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "90 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "91 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "92 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "93 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "94 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "95 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "96 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "97 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "98 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "99 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "100 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "101 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "102 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "103 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "104 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "105 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "106 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "107 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "108 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "109 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "110 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "111 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "112 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "113 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "114 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "115 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "116 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "117 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "118 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "119 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "120 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "121 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "122 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "123 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "124 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "125 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "126 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "127 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "128 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "129 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "130 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "131 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "132 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "133 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "134 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "135 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "136 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "137 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "138 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "139 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "140 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "141 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "142 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "143 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "144 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "145 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "146 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "147 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "148 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "149 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "150 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "151 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "152 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "153 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "154 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "155 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "156 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "157 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "158 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "159 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "160 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "161 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "162 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "163 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "164 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "165 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "166 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "167 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "168 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "169 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "170 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "171 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "172 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "173 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "174 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "175 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "176 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "177 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "178 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "179 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "180 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "181 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "182 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "183 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "184 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "185 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "186 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "187 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "188 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "189 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "190 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "191 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "192 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "193 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "194 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "195 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "196 Train Loss 0.00011089201 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "197 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "198 Train Loss 0.000110892026 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "199 Train Loss 0.00011089202 Test MSE 4.8044901104466515e-08 Test RE 5.748027227863259e-05\n",
      "Training time: 15.14\n",
      "Training time: 15.14\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 9.99929 Test MSE 15.153055488486109 Test RE 1.0208108362333266\n",
      "1 Train Loss 5.1987457 Test MSE 13.542220899247175 Test RE 0.9650284381561034\n",
      "2 Train Loss 4.367309 Test MSE 10.364610234184601 Test RE 0.844251133203573\n",
      "3 Train Loss 2.3826756 Test MSE 3.7742885470663903 Test RE 0.5094630771507281\n",
      "4 Train Loss 0.82270104 Test MSE 1.1463181976715433 Test RE 0.28076809686056287\n",
      "5 Train Loss 0.46407518 Test MSE 0.35734572200332415 Test RE 0.1567615173192502\n",
      "6 Train Loss 0.042675197 Test MSE 0.011909179469023501 Test RE 0.028617789496190375\n",
      "7 Train Loss 0.031335957 Test MSE 0.00114182455256728 Test RE 0.008861247227545724\n",
      "8 Train Loss 0.012883699 Test MSE 1.9869854002885992e-05 Test RE 0.0011689407611879712\n",
      "9 Train Loss 0.012057888 Test MSE 0.00026413567445100696 Test RE 0.004261953386969503\n",
      "10 Train Loss 0.007385187 Test MSE 0.00033335369929130313 Test RE 0.004787930131309288\n",
      "11 Train Loss 0.0018519891 Test MSE 3.581190543446149e-05 Test RE 0.0015693104954924663\n",
      "12 Train Loss 0.00095207896 Test MSE 3.31811219121392e-05 Test RE 0.0015105694523816341\n",
      "13 Train Loss 0.0002479505 Test MSE 5.594825840726062e-06 Test RE 0.0006202809606684211\n",
      "14 Train Loss 0.00019706377 Test MSE 9.856694812989921e-07 Test RE 0.0002603519409746576\n",
      "15 Train Loss 0.00018927621 Test MSE 4.699670436653685e-07 Test RE 0.00017977482178283094\n",
      "16 Train Loss 0.00018244045 Test MSE 1.6584418411532909e-07 Test RE 0.00010679361501997579\n",
      "17 Train Loss 0.00017504513 Test MSE 6.257464524887157e-08 Test RE 6.559856859439352e-05\n",
      "18 Train Loss 0.00016782865 Test MSE 1.6124091982766006e-07 Test RE 0.000105301073411903\n",
      "19 Train Loss 0.00015909254 Test MSE 4.851341539755542e-07 Test RE 0.00018265269732790088\n",
      "20 Train Loss 0.00015142017 Test MSE 1.048353001003324e-06 Test RE 0.0002685028724563476\n",
      "21 Train Loss 0.00014149044 Test MSE 1.7340005424618757e-06 Test RE 0.00034531844716274894\n",
      "22 Train Loss 0.00013371342 Test MSE 2.5257730425983312e-06 Test RE 0.0004167660430997186\n",
      "23 Train Loss 0.000115105235 Test MSE 3.710496899715011e-06 Test RE 0.0005051393502977391\n",
      "24 Train Loss 9.731578e-05 Test MSE 4.024979846675823e-06 Test RE 0.0005261105611036641\n",
      "25 Train Loss 8.862889e-05 Test MSE 3.629837470727053e-06 Test RE 0.000499618780010116\n",
      "26 Train Loss 8.3655475e-05 Test MSE 3.248063944710977e-06 Test RE 0.000472614944300915\n",
      "27 Train Loss 7.80086e-05 Test MSE 2.1018662893823347e-06 Test RE 0.0003801873891817225\n",
      "28 Train Loss 7.3067735e-05 Test MSE 1.4473347349885172e-06 Test RE 0.00031548568438124255\n",
      "29 Train Loss 6.888571e-05 Test MSE 7.805144414560951e-07 Test RE 0.00023167844857611595\n",
      "30 Train Loss 6.576975e-05 Test MSE 4.4849116934820425e-07 Test RE 0.00017561924791440527\n",
      "31 Train Loss 6.338084e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "32 Train Loss 6.3378146e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "33 Train Loss 6.337583e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "34 Train Loss 6.337384e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "35 Train Loss 6.337213e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "36 Train Loss 6.337068e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "37 Train Loss 6.336944e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "38 Train Loss 6.3368396e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "39 Train Loss 6.33675e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "40 Train Loss 6.336675e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "41 Train Loss 6.336612e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "42 Train Loss 6.336558e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "43 Train Loss 6.336513e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "44 Train Loss 6.336476e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "45 Train Loss 6.336444e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "46 Train Loss 6.336418e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "47 Train Loss 6.336397e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "48 Train Loss 6.336379e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "49 Train Loss 6.336363e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "50 Train Loss 6.3363506e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "51 Train Loss 6.336341e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "52 Train Loss 6.336334e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "53 Train Loss 6.3363266e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "54 Train Loss 6.336321e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "55 Train Loss 6.336318e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "56 Train Loss 6.3363135e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "57 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "58 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "59 Train Loss 6.336307e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "60 Train Loss 6.336306e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "61 Train Loss 6.3363055e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "62 Train Loss 6.336305e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "63 Train Loss 6.336305e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "64 Train Loss 6.336304e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "65 Train Loss 6.336304e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "66 Train Loss 6.336304e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "67 Train Loss 6.336303e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "68 Train Loss 6.3363055e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "69 Train Loss 6.336305e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "70 Train Loss 6.336304e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "71 Train Loss 6.3363055e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "72 Train Loss 6.3363055e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "73 Train Loss 6.336306e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "74 Train Loss 6.336306e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "75 Train Loss 6.336306e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "76 Train Loss 6.336306e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "77 Train Loss 6.336307e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "78 Train Loss 6.336307e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "79 Train Loss 6.336307e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "80 Train Loss 6.336308e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "81 Train Loss 6.336308e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "82 Train Loss 6.336308e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "83 Train Loss 6.3363084e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "84 Train Loss 6.3363084e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "85 Train Loss 6.3363084e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "86 Train Loss 6.3363084e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "87 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "88 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "89 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "90 Train Loss 6.3363084e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "91 Train Loss 6.3363084e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "92 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "93 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "94 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "95 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "96 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "97 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "98 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "99 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "100 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "101 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "102 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "103 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "104 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "105 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "106 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "107 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "108 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "109 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "110 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "111 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "112 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "113 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "114 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "115 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "116 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "117 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "118 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "119 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "120 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "121 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "122 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "123 Train Loss 6.336309e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "124 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "125 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "126 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "127 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "128 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "129 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "130 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "131 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "132 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "133 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "134 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "135 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "136 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "137 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "138 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "139 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "140 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "141 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "142 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "143 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "144 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "145 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "146 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "147 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "148 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "149 Train Loss 6.336311e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "150 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "151 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "152 Train Loss 6.336311e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "153 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "154 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "155 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "156 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "157 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "158 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "159 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "160 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "161 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "162 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "163 Train Loss 6.336311e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "164 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "165 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "166 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "167 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "168 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "169 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "170 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "171 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "172 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "173 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "174 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "175 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "176 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "177 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "178 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "179 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "180 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "181 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "182 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "183 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "184 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "185 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "186 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "187 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "188 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "189 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "190 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "191 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "192 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "193 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "194 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "195 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "196 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "197 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "198 Train Loss 6.3363106e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "199 Train Loss 6.33631e-05 Test MSE 2.0829269877514718e-07 Test RE 0.00011968292325770489\n",
      "Training time: 15.03\n",
      "Training time: 15.03\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    \n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "    \n",
    "    \n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "   \n",
    "\n",
    "    start_time = time.time()\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    " \n",
    "    \n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"label\": label, \"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5a906f2d90>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5PElEQVR4nO3dd3hUVeLG8XcyKSQhCTWEQOglQOg9dFBcBMuqKAoK1h8uIshasGMNrF1XUFBZFRF1KWIBld5D6KGGEnoIBEgmQDJJZu7vj2jcSEuZ5GYm38/zzLNPZu4wL2eBeb333HMshmEYAgAAcAEvswMAAADPQbEAAAAuQ7EAAAAuQ7EAAAAuQ7EAAAAuQ7EAAAAuQ7EAAAAuQ7EAAAAu413aH+h0OnX8+HEFBQXJYrGU9scDAIAiMAxD6enpCg8Pl5fX5c9LlHqxOH78uCIiIkr7YwEAgAscOXJEtWvXvuzrpV4sgoKCJOUGCw4OLu2PBwAARWCz2RQREZH3PX45pV4s/rj8ERwcTLEAAMDNXG0aA5M3AQCAy1AsAACAy1AsAACAy1AsAACAy1AsAACAy1AsAACAy1AsAACAy1AsAACAy1AsAACAy1AsAACAy1AsAACAy1AsAACAy1AsAADwEC90+VUf3vyr7GfOm5ah1Hc3BQAArpe4+IBiYvsoRz5qM3unuj3Y3JQcnLEAAMADvPp/h5UjH/Wvvsm0UiFRLAAAcHv7Fu7T5/u7S5JeeiPA1CwUCwAA3NzLI4/LIW9dX2ODugyPNDULxQIAADe2e36CvjrUTZL08rshJqehWAAA4NZeGnVSTll1U3ic2g9pbHYcigUAAO5q+3e79M3RaEnSS+9XNjlNLooFAABu6qUxZ2TIS7dFxKr1rY3MjiOJYgEAgFvaOnOH/pvUTRY59eKHoWbHyUOxAADADb3wmE2SdEe99Yq6ob7Jaf5EsQAAwM3EfrxF8092lZccmjCtltlx8qFYAADgTgxDz43PkSQNb7pOTa+JMDlQfhQLAADcyLI3N2hRagf5KEsvTG9gdpyLUCwAAHAThtPQsy/5SpIear1e9brWNDnRxSgWAAC4iQUvrtOa863lrwt69ktzl+6+HIoFAABuwJnt0HNv5i7Z/UiXDarZsprJiS6NYgEAgBuY8/gabc5sriDZ9OSXrcyOc1kUCwAAyjhHZrZemJI7n+KxPltVrVElcwNdAcUCAIAybsbDq7Qru5GqWM5o3JdtzY5zRRQLAADKMHtqhl74MnfX0qdv3KGQWhVNTnRlFAsAAMqwj4av0WFHbdWyJmnUfzqZHeeqClUs6tWrJ4vFctFj1KhRJZUPAIByK/1Iql79obUk6cW7E+Vfyc/kRFfnXZiD4+Li5HA48n7evn27rr32Wg0ePNjlwQAAKO/eGbZRKUY/NfFN1L0fdTY7ToEUqlhUr149388TJ05Uw4YN1atXL5eGAgCgvDu1PVlvrugoSXrl0VPy9is7O5heSaGKxf/KysrSjBkzNG7cOFkslsseZ7fbZbfb83622WxF/UgAAMqNmGE7lK6+ahewW7dN7Gh2nAIr8uTNefPmKTU1VSNGjLjicTExMQoJCcl7RESUrV3YAAAoaw6vOqQPt3aTJMVMsMvLevn/gC9rLIZhGEV543XXXSdfX1/98MMPVzzuUmcsIiIilJaWpuDg4KJ8NAAAHu2+hss1/UAv9a68VUtOt9YVLgyUGpvNppCQkKt+fxfpUsihQ4e0aNEizZkz56rH+vn5yc+v7M9iBQCgLNj+3S59fqC7JCnmHb8yUSoKo0iXQqZPn67Q0FANHDjQ1XkAACjXnv5Hmpyy6taIWHUZXjZ3ML2SQhcLp9Op6dOna/jw4fL2LvLcTwAA8Bcr3t6gH1O6yKocvT493Ow4RVLoYrFo0SIdPnxY9913X0nkAQCgXDIcTj31gq8k6cGW69Skn3ve7FDoUw79+/dXEed7AgCAy5j7xBqtO99dATqvF2e63yWQP7BXCAAAJss+n6Wn/5176eOfvTcpLKqayYmKjmIBAIDJPr1vtRKyG6i6V4oen9nO7DjFQrEAAMBE55NsmvBdC0nS84N3K7hmoMmJiodiAQCAid68I07JRqga+BzW/33qHhuNXQnFAgAAkyRtPK43VuaWiZgxJ+Qb6GNyouKjWAAAYJIX70rQeVVU56AdGjzJfTYauxKKBQAAJtgxe7c+TeghSXrrTcni5WZrd18GxQIAABM8NTJVTln191rr1e2hFmbHcRmKBQAApWzJpDj9lNJF3srWxM9rmh3HpSgWAACUIme2Q49PyL2ldGSbWLdduvtyKBYAAJSirx5epc2ZzRUsm174xnMugfyBYgEAQCm5cPKcnpneWJL09PVbVb1JZZMTuR7FAgCAUvL2HbE66gxXHe9jGvNVJ7PjlAiKBQAApSBp43FNXJa7GNbER47Kv5KfyYlKBsUCAIBS8PyQ3MWwugRt15C3PPNshUSxAACgxG35aoc+29dTkvT2O14esxjWpVAsAAAoQYbT0D9HZcqQl+6ou05d729udqQSRbEAAKAE/fjsWi1Jay8/ZWrizDpmxylxFAsAAEpI9jm7Hn8rTJL0WPR61YsONzlRyaNYAABQQiYPXa2E7AYK9Tqlp79rZ3acUkGxAACgBKTsPKkJ89tKkl69J0HB4RVNTlQ6KBYAAJSAF27boVRVVmv/BN03tavZcUoNxQIAABeL/3aXPt6Ve3vpe29kyepTfr5uy8/vFACAUmA4DY196IKcsuq2iFj1GhVldqRSRbEAAMCFvn9qTd7tpW/M8qwt0QuCYgEAgIvYUzP0z3drS5Ie71E+bi/9K4oFAAAu8u7ta3Qgp65qeiVr/H87mB3HFBQLAABc4HjcMb36W+7mYhMfOqCKoQEmJzIHxQIAABcYf/t+nVOQOgft0LB/dzE7jmkoFgAAFNOaDzfry4M9ZZFTH0zxlpfVc3cvvRqKBQAAxeCw52j0E36SpPsi16rj0KYmJzIXxQIAgGL4dMRKbcporhBLml6f28zsOKajWAAAUERn953WM9+0kiS9dGu8QiOrmJzIfBQLAACK6IWbt+m0UVXN/fbrH1+Wn/1AroRiAQBAEcR/u0uTd+TuB/J+zHn5VLCanKhsoFgAAFBIhsOpUQ/Y5ZRVt9aOVb/HWpkdqcygWAAAUEhfPbxSK9PbyF8X9PbsumbHKVMoFgAAFELaobN64pNISdLzAzaoTqcwkxOVLRQLAAAKYcJNm3XCqKHGvgc17lsmbP4VxQIAgAKK/2anPtiaO2Hzg1fS5FfRx+REZQ/FAgCAAjAcTo160C6HvHVr7Vhd92RrsyOVSRQLAAAKIHfCZlsF6DwTNq+AYgEAwFWkHfxzwuZzAzYyYfMKKBYAAFzFc4O26IRRQ018E5mweRUUCwAArmDj5/F5K2xOnpjOhM2roFgAAHAZDnuOHv6HRU5ZdWf9taywWQAUCwAALmPq3SsVdyFKwbLp7fmNzY7jFigWAABcQvLWE3r6u7aSpNfu2KawqGomJ3IPFAsAAC7hiZsSlKZKah+4Sw9/GW12HLdBsQAA4C+WvblBXx7qKYucmvKRl6w+fF0WVKFH6tixYxo2bJiqVq2qgIAAtWnTRhs3biyJbAAAlDp7aoZGPlNZkjSy5Rp1HNbU5ETuxbswB589e1bdunVTnz59tGDBAoWGhmr//v2qVKlSCcUDAKB0TbppjfZk91OYV7Je/5G7QAqrUMVi0qRJioiI0PTp0/Oeq1evnqszAQBgioSf9uq1Fd0lSe89dkiV6nQyOZH7KdSlkPnz56tDhw4aPHiwQkND1bZtW02bNu2K77Hb7bLZbPkeAACUNYbDqZFDbcqSnwaEbtDgf3U0O5JbKlSxOHDggKZMmaLGjRvrl19+0ciRI/Xoo4/qiy++uOx7YmJiFBISkveIiIgodmgAAFztiwdXamlae/nrgj6cXVMWL4vZkdySxTAMo6AH+/r6qkOHDlqzZk3ec48++qji4uK0du3aS77HbrfLbrfn/Wyz2RQREaG0tDQFBwcXIzoAAK6RsvOkIqOsOm1U1aRBK/XkDz3MjlTm2Gw2hYSEXPX7u1BnLGrWrKnmzZvne65Zs2Y6fPjwZd/j5+en4ODgfA8AAMqSJ27YpdNGVbWssFePsclYsRSqWHTr1k179uzJ91xCQoLq1mVfegCAe1o8MU7/OdBLFjn18WSHfPwLdV8D/qJQxeKxxx7TunXr9Prrr2vfvn2aOXOmpk6dqlGjRpVUPgAASkzGqXP6v+erS5IebrVaXe+NNDmR+ytUsejYsaPmzp2rr7/+WlFRUXrllVf07rvvaujQoSWVDwCAEvPS9bHan1NPtaxJilnQ1uw4HqHQ53sGDRqkQYMGlUQWAABKzeYZO/Tmhl6SpMnPHVdweHuTE3kGFj8HAJQ7ORnZevAhySFvDa4TqxsnUCpchWIBACh33rttpTZmtFAlS6re/6mh2XE8CsUCAFCuHFicqOd/7iJJevO+XQqLqmZyIs9CsQAAlBuGw6n/u+20MhSgPpW36L6pXcyO5HEoFgCAcmP6vcu1KLWDKihDH/+3Kst2lwCKBQCgXDged0zjvsy9pfSVGzeocV/2rioJFAsAgMcznIb+Meiw0lRJHQJ3aey30WZH8lgUCwCAx/v20VX6/mRX+ShLn33lJ28/q9mRPBbFAgDg0VJ2ntToyblLdT/TN1Ytb2pgciLPRrEAAHi0sQP26JRRXVEV9uqZ+dwFUtIoFgAAj/XjM2v01eEe8pJDn051yjfQx+xIHo9iAQDwSGf3ndZDk3Ive4zrvEad7m5qcqLygWIBAPBIY6/doSRnmJr6HtDLCzuZHafcoFgAADzOD0+v0RcHe8pLDk2fYpd/JT+zI5UbFAsAgEc5u++0/u9ff14C6XpfM5MTlS8UCwCAR3ns2u1cAjERxQIA4DF+enaNPj/YSxY5uQRiEooFAMAjnElI0YMTf78E0mk1l0BMQrEAALg/w9Doa3bmXQJ55RcugZiFYgEAcHv/HbtKM4/k3gXyxSfZXAIxEcUCAODWkree0MMf5F72eLonC2GZjWIBAHBbhtPQyOsOKMWoplb+CXrhZ/YCMRvFAgDgtmY8uFzzkqPloyx9McPKXiBlAMUCAOCWjq49otGftZEkTRgQq9a3NDQ3ECRRLAAAbsiZ7dCI65OVpkrqVHGnnpwbbXYk/I5iAQBwO/++bZkWp3aQvy7oy3lB8vazmh0Jv6NYAADcys65e/TU/NwzFG8O3aIm/SJMToT/RbEAALiNrHS77r7LoUz567rqm/TwF13NjoS/oFgAANzGy/1XaVNmc1WxnNFni+rI4mUxOxL+gmIBAHALaydvVsy63pKkj57Yr/BW1cwNhEuiWAAAyrz0o2m6e0xlOWXVsIZrNXhSR7Mj4TIoFgCAMm9Mry3an1NPEdbj+mBplNlxcAUUCwBAmfbfMSs1/UAvWeTUjPfPqFJEkNmRcAUUCwBAmXV07RE99H7uGYrx3Ver5z84W1HWUSwAAGXSH6trnlVldQjcpQm/cGupO6BYAADKpHduWqrFqR0UoPP66vuK8g3wNjsSCoBiAQAoc7Z8tV1PL+gpSXr33m2srulGKBYAgDLlfJJNQ+71V7Z8dVN4nB74pIvZkVAIFAsAQJkytudG7cluqHDrCX2yogmra7oZigUAoMz4bvRyfbKvT+6tpe+kqFrDELMjoZAoFgCAMuHQ8oN68N+tJUlP91itPqO5tdQdUSwAAKbLuZCluwalKU2V1Dlohyb8Gm12JBQRxQIAYLpXrl2hNedaK1g2fb2gsnwqWM2OhCKiWAAATLXsX+v16po+kqSPxu5W/W7hJidCcVAsAACmObU9WXc9XUdOWXVv0zW6851OZkdCMVEsAACmcGY7dE+vQ0pyhqmZ3359sKqt2ZHgAhQLAIAp3rphqRae6aQKytA333opsJq/2ZHgAhQLAECpW/fRFj3zSy9J0nsjNqvljfVNTgRXoVgAAEpV6oEzuvORKsqRj26vG6sHP+PWUk9CsQAAlBrD4dR90bt10FFHDXwOa+rqFrKwYrdHKVSxmDBhgiwWS75HWFhYSWUDAHiY929eornJ0fKVXd/8J1MhtSqaHQkuVujN7Vu0aKFFixbl/Wy1sogJAODqYj/eosd/zJ1X8dadG9XhLi6BeKJCFwtvb2/OUgAACuXMnlO6fVQ15chHg+vEatSMrmZHQgkp9ByLvXv3Kjw8XPXr19eQIUN04MCBKx5vt9tls9nyPQAA5YeR49CIHvt02FFbjXwO6ZO1LdgK3YMVqlh07txZX3zxhX755RdNmzZNJ06cUHR0tE6fPn3Z98TExCgkJCTvERERUezQAAD38dbAJfrhVFf5KVPffZ2j4HDmVXgyi2EYRlHffP78eTVs2FBPPvmkxo0bd8lj7Ha77HZ73s82m00RERFKS0tTcHBwUT8aAOAGVr6zQX3GtZFD3vp4xBo9NJ15Fe7KZrMpJCTkqt/fhZ5j8b8CAwPVsmVL7d2797LH+Pn5yc/PrzgfAwBwQyc2Hdcdj9eWQ94a2nAd61WUE8Vax8Jut2vXrl2qWbOmq/IAADxAzoUsDelzQknOMLWosE8fr2vNehXlRKGKxeOPP67ly5crMTFRsbGxuu2222Sz2TR8+PCSygcAcEPP9Vyh5bZ2qqh0zf7Bj31AypFCXQo5evSo7rzzTqWkpKh69erq0qWL1q1bp7p165ZUPgCAm5n3z5WatPEaSdL0p/ao6TUdTE6E0lSsyZtFUdDJHwAA97Nv4T61H1BdNoVobMdVemd9d7MjwUUK+v3NXiEAAJc4n2TTLTc7ZFOIuoXE61/Lu5gdCSagWAAAis1wGnqo8xbF25uqhtdJfbMsTD7+xbrxEG6KYgEAKLb3b1qsmUd6yqocffthimq1qW52JJiEYgEAKJYVb8X9ubnY7evVc2RzkxPBTBQLAECRHYs9qtufqKMc+eiuBuv06NdsLlbeUSwAAEWSlZahwf1OK9mooVb+CZq6vg2bi4FiAQAoAsPQ6I7rtPZ8a1WypGrOLxUVWLWC2alQBlAsAACF9vEdSzR1bx9Z5NTM1w6qYY9wsyOhjKBYAAAKZdW7GzT6ux6SpNcHrdWAp9uYGwhlCsUCAFBgR9cc1m3jIpQtX91eN1ZPfc+OpciPYgEAKJDM0+d1yzW2vMman21oxWRNXIRiAQC4KsNpaGSHDYrLiFIVyxnN+60iO5bikigWAICremfQIn1+sFfuyppvH1P9bkzWxKVRLAAAV7Tg+TV6YkFfSdI7Q9ar39iWJidCWUaxAABc1u7v92jIqy3klFUPNF+jR2YyWRNXRrEAAFzS2b0puvE2H9kUou4h8fowrpMszNXEVVAsAAAXybmQpTs6JWpvTgPV8T6m2bG15RvANui4OooFACA/w9C4jiv1W2pHBei8vp+VqdCmlc1OBTdBsQAA5DP51sX6YGc/SdKXz+xWm1sbmpwI7oRiAQDI89vLa/Xo3N6SpNcHrtYtr7U3NxDcDsUCACBJ2jVvjwa/2EwOeeuexms1fj53gKDwKBYAAKXsPKlBgysoTZXULSReUzd1YLluFAnFAgDKOXtqhm7tclQHcuqqnvdRzY2LkF9FH7NjwU1RLACgHDMcTj3QOk4r0tspSOn6YW6OqjeuZHYsuDGKBQCUYy/3WqwZh3vKqhz9982DihpUz+xIcHMUCwAop2bcv1QTVl8rSZpyb5z6/5M9QFB8FAsAKIdWvBWn+z7rJkl6MnqVHvysq8mJ4CkoFgBQziT8mKC/P9FQ2fLVrXXWK2ZFN7MjwYNQLACgHDm5NUkDbvbTGaOKOgXt1JdbW8vLym2lcB2KBQCUE+eTbBrU9bQOOOqqvs8R/RBXU/6V/MyOBQ9DsQCAcsCRma27Wu9QXEaUqljOaMECCxuLoURQLADAwxlOQ4+2Xan5p7rKT5maP+2kmvarbXYseCiKBQB4uDeuW6TJu/vKIqe+Gr9d3e6PNDsSPBjFAgA82IwHlumpRblrVbw9eJ1ujelgciJ4OooFAHioX19ep3s/zb2V9LFOqzT2W3YrRcmjWACAB9r0+Tbd+mIL5chHQ+qv05trWKsCpYNiAQAeZv+v+zXg3jCdU5D6Vt2i/2xrz1oVKDUUCwDwICe3ndDfBnrppBGq1gEJmhvfmC3QUaooFgDgIdIPn9X1XU5rX0591fM+ogWxVRVcM9DsWChnKBYA4AEyz1zQza32a2NGC1XzOq2FCy2qGVXV7FgohygWAODmHJnZGtZis5akdVBFpWvBV2dZAAumoVgAgBszHE79o9UqzT7RTb6ya947B9VhSCOzY6Eco1gAgLsyDD3fbbGm7u2Tt6pmv7EtzU6Fco5iAQBu6u2Bi/RabO6qmlNGxOq2mPYmJwIoFgDglj4dulj/XJBbKl4dsFr/N72ryYmAXBQLAHAz3z2yXA/N7C1JeiJ6tZ75iVU1UXZQLADAjSx8YY2GfthVTln1YIs1mrQyWhYW1UQZQrEAADex6t0NuuWVNsqWr+6oF6spm7vI4kWrQNlCsQAANxD3yVZd/1gTZShA19fYqC92tJfVh3/CUfbwpxIAyrhtX+/QdQ/WUbqC1bvyVn23K0q+Ad5mxwIuqVjFIiYmRhaLRWPHjnVRHADA/9o9P0HXDq2us6qsLkE7NH9XYwVU9jM7FnBZRS4WcXFxmjp1qlq1auXKPACA3x1YdED9/h6kk0ao2gbs0YIddRRUI8DsWMAVFalYnDt3TkOHDtW0adNUuXJlV2cCgHLvyKpD6vc3bx131lTzCvv167YwVYoIMjsWcFVFKhajRo3SwIEDdc0111z1WLvdLpvNlu8BALi8Y+uOqE8fQwcdddTI95AWxVVStYYhZscCCqTQs39mzZqlTZs2KS4urkDHx8TE6KWXXip0MAAoj5I2HFPfntnan9NA9X2OaMkaf7Y/h1sp1BmLI0eOaMyYMZoxY4YqVKhQoPc8/fTTSktLy3scOXKkSEEBwNMlb0lSv+gMJWQ3UB3vY1q60kcR7UPNjgUUisUwDKOgB8+bN09///vfZbVa855zOByyWCzy8vKS3W7P99ql2Gw2hYSEKC0tTcHBwUVPDgAeJGVHsvq0S9X2rKaqbT2u5cukBt3DzY4F5Cno93ehLoX069dP8fHx+Z679957FRkZqaeeeuqqpQIAcLGUHcnq1/6stmdFqqY1WUt+c6pB99pmxwKKpFDFIigoSFFRUfmeCwwMVNWqVS96HgBwdX+Uim32SIV5JWvJz3Y17lPH7FhAkbHyJgCY5K+lYukCuyL7Uyrg3oq9JuyyZctcEAMAypeUHcnq2z5V8fZIhXmdpFTAY3DGAgBK2antf5SKpgrzOqllCzMpFfAYFAsAKEUnNh1X7/a2fKWi6bWUCngOtscDgFJyfP1R9e1u157sxqplTdKSX3LUpB+lAp6FYgEApeDIqkPq28epfTkNVcf7mJYslhr2jDA7FuByXAoBgBJ2cGmievWW9uXUV33vI1q+wksNe9YyOxZQIigWAFCCEn7aq57X+CrRUVeNfA5p+Vpf1eta0+xYQImhWABACdn+7U71vCFYR5y1FOl3QMs3BCqiQw2zYwElimIBACVgw6db1WtImJKNGmrtn6DlWysrvFU1s2MBJY5iAQAutuq9jer7QH2dMaqoc9AOLd0VptCmlc2OBZQKigUAuNBvr8bqurGRSlewelXeqt8S6qlyXXZyRvnB7aYA4CKzx67Une91VrZ8dV31TZqzu7kCqlQwOxZQqjhjAQAu8NndS3X7e9HKlq8G14nV/MSWlAqUSxQLACgOw9Bb1y/S/TP6yCmrHmi+Wl/v6yjfQB+zkwGmoFgAQBEZTkPPRS/W4wuukSQ90XWlpsZHy+rDP60ov5hjAQBF4MjM1j9ar9LUhNxSEXP9So3/qYfJqQDzUSwAoJAyz1zQXc23aG5yH3nJoSnDY/XQfygVgESxAIBCSTt4Vje1TtRyW7T8lKmZ4+N1S0y02bGAMoNiAQAFdGJzkv4Wnaatme0UJJvmv39IvUd3NDsWUKZQLACgAPb8uFd/u9lPBx2RquF1Ugtm2dR2cEuzYwFlDlOXAeAq1n20Rd1urKKDjjpq5HNIq5dkqe3gRmbHAsokigUAXMH8p1ar78NNdNqoqo4Vd2p1fLAa9qptdiygzOJSCABcxtQhS/TwN73klFXX19igb7e3UGA1f7NjAWUaZywA4C+cOU4903mR/u+bvnLKqvsi1+j7Q20pFUABcMYCAP6HPTVDI1pu1KyjuQtfvdhvlV78tZssXhaTkwHugWIBAL87k5Cimzsc0cr07vJWtqb930aN+Ki72bEAt0KxAABJBxYn6voBTu3Jbqtg2TTn7YPq91gXs2MBbodiAaDcW/3BJt08po5SjGqKsB7Xz3MyFXVjK7NjAW6JYgGgXPvqoeW6b1oXZclP7QJ264c1VRXeOtzsWIDbolgAKJcMh1MTei3Vy6v7SZJurrVeM7a05M4PoJgoFgDKnYzTF3R/2436+khuqXiy60rFrOgmL2/uwAeKi2IBoFxJ2nhcN/c8o/UXeshb2fro/g26/xO2PAdchXoOoNzY9Hm8OnaS1l+IUmXLWf3y7m7d/0lXs2MBHoUzFgDKhe8eXanhH7RXhgLUzG+/5i/0U6Pe7E4KuBrFAoBHc2Y79HKfpXppde5KmgNCN+jrjU0VUjvI5GSAZ6JYAPBY6UfTdE+HHZqXnFsqHuuwUm+s6SarD1eBgZLC3y4AHmnfL/vVtWGy5iVHy1d2TX9ord6O60GpAEoYf8MAeJxfX4lVx79V1Y6sJqrplawV/zmgER8zSRMoDVwKAeAxDIdTb1y/VE//2ltOWdUlaLtmr6yh8NbNzI4GlBsUCwAeIf1omu7ttEOzk3IXvbovcrUmr+8ovyBfk5MB5QuXQgC4vYSf96lLw5OanRQtH2Vpyt2r9cnObpQKwAQUCwBubf74Neo4sLp2ZjVWuPWEln+yTyO/6CaLxexkQPnEpRAAbiknI1vP91qhiXG5lz56hGzTt6vCFRbV3ORkQPlGsQDgdpK3ntCdvY5paVpuqRjTfqXeWNlVPv78kwaYjUshANzKqg82q207aWlae1VUur55fL3e3dCDUgGUEfxNBOAWDIdTb9+wVOMX9FSOfNTcb79mz7Mq8m+dzI4G4H9QLACUeWcSUjSi+z79cCr30sed9ddq6rrWqhgaYHIyAH/FpRAAZdq6j7eqbfNM/XCqi/yUqY/uWaOv9nelVABlFGcsAJRJhsOpd25cqqd+zr300cjnoL6dka22t0ebHQ3AFVAsAJQ5p3ac1L29D+inlNxLH4PrxOqTtS0UHF7R5GQAroZLIQDKlGVvblCbVg79lJJ76WPy0NX6JrETpQJwE4UqFlOmTFGrVq0UHBys4OBgde3aVQsWLCipbADKkZyMbL3YfbH6PtFOx5011cxvv9bPOaaHZ3STxYtlNAF3UahLIbVr19bEiRPVqFEjSdLnn3+um266SZs3b1aLFi1KJCAAz3dw2UENvSFNa87lXvq4P3K13lvZToHV/E1OBqCwLIZhGMX5BapUqaI33nhD999/f4GOt9lsCgkJUVpamoKDg4vz0QDcnWFo5sgVenhqG9kUomDZ9NGYXbrz3c5mJwPwFwX9/i7y5E2Hw6HvvvtO58+fV9euXS97nN1ul91uzxcMAGyHzmpUr3jNONRLktQtOF4zFlRVvWhKBeDOCj15Mz4+XhUrVpSfn59GjhypuXPnqnnzy2/6ExMTo5CQkLxHREREsQIDcH+rP9ikNg3TNeNQT3nJoQl9V2jZyeaqFx1udjQAxVToSyFZWVk6fPiwUlNTNXv2bH3yySdavnz5ZcvFpc5YREREcCkEKIeybJmacO1qTVrfW05ZVc/7iGZ8aFO3h5ijBZR1Bb0UUuw5Ftdcc40aNmyojz/+2KXBAHiWHXP2aNhQp7ZkNpMkDW+8Ru8va8VtpICbKOj3d7HXsTAMI98ZCQD4X85sh965YYna31pXWzKbqarltP77VJz+kxBNqQA8UKEmbz7zzDMaMGCAIiIilJ6erlmzZmnZsmVauHBhSeUD4MYOLE7UvX9P1Yr0vpKkAaEb9OmieqrZsqPJyQCUlEIVi+TkZN19991KSkpSSEiIWrVqpYULF+raa68tqXwA3JDhcOrju5br8W876rzqK1Dn9NbdW/XQf6JZ7ArwcIUqFp9++mlJ5QDgIQ6vOqwHb0zWr2f7SJJ6Vtqq6fOrqUGPbiYnA1Aa2CsEgEsYDqc+HrJUUT0q6dezHVVBGXrn1pVaeqqlGvSoZXY8AKWE3U0BFNvBZQf1wN9TtDg19yxFdHC8PvsuWE379zA5GYDSxhkLAEXmzHbo37csUVSfalqc2kH+uqB3blmpFSkt1LR/XbPjATABZywAFMnOeQl64O5MrT2Xe8dHj5Bt+mxuZTXqw1kKoDyjWAAolKx0uyYOWqXXVnRXlvxUUemaOGSrHv4yWl7enAQFyjuKBYACWzt5sx4aF6jt9tztzQfW2KApP9RWRMfuJicDUFZQLABcVWriWT19/VZ9tLu3JKma5bTeH7NPQ97qxLoUAPLhvCWAyzKchr55ZKUiG2bnlYp7m67WrgSr7nynM6UCwEU4YwHgkvb9ekCj70rRwtO5kzGb+h7QR2+eV+/RLHQF4PIoFgDyyTxzQRNvWquJq7rJrgbylV3P9I3V+Hld5Bfka3Y8AGUcxQJAnoUT1umR18K0Pyd3cmb/ahv171nV1bhfT5OTAXAXFAsASlx6UOPuTNK85K6SpFrWJL3z2BHdNqkj8ygAFArFAijHMlLOa9Lf12nSqmhlqp6sytGYjms1YX47BYV1MjseADdEsQDKIcNpaO7jq/XP9+vooCP3skffKpv1/ueV1GIQK2cCKDqKBVDObJ25Q2MftmuZLXdRqwjrcb39z6O6NYbLHgCKj2IBlBMn45P1/G279ElCDzllVQVl6PFeGzT+vx0UWC3c7HgAPAQLZAEeLvPMBb0xYLEat6qgqQm95ZRVt9ddp91rU/XKsh4KrOZvdkQAHoQzFoCHMhxOffPoao3/uJ4O/T6Pol3Abr37lkM9RnYxOR0AT0WxADzQqg8265/jfbT+Qu5EzFrWJL324CENe7+TrD6cqARQcigWgAfZOXePnh55RvNP5q5HEahzGt9/s8Z93VEBVWqanA5AeUCxADzAsdijenHYfk3f111OWeUlh+5vvk4vf9NUYVHcPgqg9FAsADd2JiFF/xq6Ve9tiFamakuS/l5rvV7/tIYir2OzMAClj2IBuKH0o2l6d9gGvbm8g2zKnZjZLSRe/3rLW9H3s2ImAPNQLAA3kpFyXh+NWKeYn1vplJFbKFr7J+jV8ec08Lm2LHAFwHQUC8ANZJ65oGn3r1PM/OZKcuYWisa+B/XKIyc1+F8d5WWlUAAoGygWQBlmT83QZw+u1WtzInXM2VeSVMf7mJ6/+5CGT+4snwr1zA0IAH9BsQDKoMzT5/XJg7Ga9H1THf29UNS2HtdzQw/q3skd5RtYy+SEAHBpFAugDLmQnK6P71+vfy2I0onfC0W49YSeuX2/Hvi4o/yC2NMDQNlGsQDKgNQDZzT5wc16d+mfkzIjrMf19JBE3Tu5oyoEh5mcEAAKhmIBmCh5S5LefWinJsf9edtofZ8jembYEd3z707yDeAMBQD3QrEATLDvl/16e+xhTd/dRZm/F4rmFfZr/P0pGvJmB/lUiDA5IQAUDcUCKC2GofXTtuqNCec1J6mLnGooSeoUtFPPPJapG15oKy9rQ5NDAkDxUCyAEuaw5+jH52P19kcBWpHeNu/5AaEb9fizfuozOkoWlqEA4CEoFkAJOXc0VdNHb9J7PzbQ/pzcfTu8la27Gsfp8TdrquWN7U1OCACuR7EAXOzAogOa/ESiPtnSXmnKvWW0suWsHuq6XY/8O1K120abnBAASg7FAnABZ7ZDi2Li9MEH0k8pnWSogSSpiW+ixgxO0vD32imwKtuXA/B8FAugGM7uTdEXj2/VlAX1tCe7S97z11XfpNGPWjTg6TbystY3MSEAlC6KBVBIhtNQ3Cdb9dGkVM060EkZv98uGqR0jWi7VaPeqKem/dqZnBIAzEGxAAooLfGMZj65RdN+DNPmzDZ5z7f036uRt5zS3W+1UVCN7uYFBIAygGIBXIHhcGr1B5s07b0L+u5gB2X8PhnTT5m6vdEmjRxfWV3vayaLpbHJSQGgbKBYAJdwZNUhffniPv1nRQPtzemQ93yLCvv0wKBk3T0pSlUbcHcHAPwVxQL43fkkm+a9uFmf/zdAi862l6G6kqRAndOQyK16YHxVdb4nUhZLI5OTAkDZRbFAuZaTka0lb2zUjM+yNOdQO51Xr7zXelXeqnvvyNCtL7dWxerdTEwJAO6DYoFyx8hxaN3UbZo15ay+3dFCJ4w/bxNt4HNYw7of0vCXG6pB99YmpgQA90SxQLlgOJzaPGO7vvnglL7Z0kSHHH/u2VHVclp3tNqlYWOrq8s9TWTxqmNiUgBwbxQLeCxntkPrP43X7GmnNXtrIyU6WuW9VlHpurnhdt1xj5+ue6KVfPy5TRQAXIFiAY+Sfc6uFR9s1fczz2vuziY66myT95q/LmhgRLyGDLXq+qdayr9SV/OCAoCHoljA7aUdPKtf39mu7+dJPx2OUqo65b1WUekaVG+Hbhvirb89HqXAqp3NCwoA5QDFAm7HcBraPT9BP009qp9WV9YqW0vl6M8Nvqp5ndYNjffo5iF+6j+upSoEd7nCrwYAcCWKBdxCWuIZLf73Tv3yU45+3ddABx1NJTXNe72pX6JuaHNUN91XVV3vjZTVh8WrAMAMhSoWMTExmjNnjnbv3i1/f39FR0dr0qRJatq06dXfDBSCPTVD6z7bqSVz07RoS1XFnmshh/6cYOkru3pX36GBvS9o4OgGatijviR2EQUAsxWqWCxfvlyjRo1Sx44dlZOTo2effVb9+/fXzp07FRgYWFIZUQ5k2TK14ctdWjHvjJZsDNGqs82Vofb5jmnim6jrmh/VdbcEqvfDzRRYjR1EAaCssRiGYRT1zadOnVJoaKiWL1+unj17Fug9NptNISEhSktLU3BwcFE/+iILXo5T1dr+andXpLwrcIWnrLMdOqvYGXu1+pdzWrGtktalRSpDAfmOCfU6pb519qlvb6eufaiB6nWtaVJaAEBBv7+L9Q2clpYmSapSpcplj7Hb7bLb7fmClYRRr9RQYk4dBd+fpl41dqtP5wz1vStMLW9tIi9vrxL5TBSMw56jPT/vV9wPJ7R2raE1iTW13d5Yxv/cvSFJ1Syn1TN8n3p2zVa/e2qpxcB6snhVNyk1AKAoinzGwjAM3XTTTTp79qxWrlx52eMmTJigl1566aLnXXnGIuNMhu5ssU3Lk5sq1aiU77UQpalrtQR1a31e3a4PUadhTRQYymWbkuKw52jvr4navDBZm2KzFbe3kjbaGumcgi46toHPYXWtfVQ9uzvV867aatq/rixeFhNSAwCupqBnLIpcLEaNGqWffvpJq1atUu3atS973KXOWERERLj8UogkObIc2vJdgpZ8fVJL1wdoxalmOq+K+Y7xkkMtKuxXh4hkdWxvqMPfqqnlTQ1UoVIFl2YpD87sO6MdCw4rfmWq4rdbtOVwFW0730AXdHFxC9Q5tQvZr85NUxXd119dhzZQWFQ1E1IDAIqiRIvF6NGjNW/ePK1YsUL16xduJn5JzbG4lJzMHG2dvVer557U6vW+Wn28no45Lr5Ob1WOmvgeUqsayWoVmaWWnQPUrHcN1etWq9zP13BmO3RsQ5L2LD+h3RvOaU+CtPtokHamheu489JzHgJ0Xq2CEtW27ll17OyljjfWVLMB9WT14ZIUALirEikWhmFo9OjRmjt3rpYtW6bGjRuXWLCSYBjSsQ1J2jj3sDaszFDcroracKa+ThtVL3m8j7LU2O+wmlZNUeOITDVoZFX9FgFq0Kma6nQJl2+gT6nmLwmG01DK7hQd2nBKh+PTdGivXYmJFh1I8tf+tKpKzKoluy5/Nqeu91FFVUlSVIMLat3RV20G1FSTa+pQIgDAw5RIsfjHP/6hmTNn6vvvv8+3dkVISIj8/f1dGqy0GE5DSVuSte3no9q25py27fJR/IlqSsiso0xd/vdkkVM1vE6pVoUzqh1sU63qdoXXcKp6TatCa/sptJ6/qjcIVpV6wQqJCJa3n7XUfk92m12ph21KPZKuU4nndOrQBaUkZenUCaeST1p0PMVXSbYAHc+orKSc6lf8fUqSt7LVyDe3YEXWzVRkC6siu1ZW8wF1FRxe8YrvBQB4hhIpFhbLpSfWTZ8+XSNGjHBpMLM5c5w6Entcu5ed0J6N57T/gHQgKUCJaZWVaA+/5DyCK6modFWypivIO0OB3nYFeGcr0DdbAb458vV2ysfbkI+3Uz7ekrf1j/9Lcv/XMCzKcUjZORZlZXspK8dL9hwvXcjy1vksX13I8dH5HD/ZHIFKcwZdtSj8lUVO1fRKVp2AFNWpnK66NbPUsLFVDVsFqmHXUEV0qlmqxQgAUPaU+OTNonKXYnElhtPQqZ2ndGxrio7uStex/Zk6csip5BSrTqb56eT5QJ20B+tUTuVL3g1RWkKUpmreqapewabqgRdULThLNarmqGa4l8Lr+ahmo4qq2aySarWrIb9gP9NyAgDKvlJZx6K8snhZFBoVqtCoULW9yrHZF7JlO5p7WSL1+AWlJWfqgi1bF2wOnbc5dOGcU1l2Q9nZhrKzpJyc3MdfTw55e0u+vrkPH1+LfP0sCgzyUkCwtwJDvBUQ4qPg0AqqVCtQIRHBCqpZUVbfEEkhJTUMAABchGJRwnwCfFS1SVVVbXLpCaIAAHgSpu4DAACXoVgAAACXoVgAAACXoVgAAACXoVgAAACXoVgAAACXoVgAAACXoVgAAACXoVgAAACXoVgAAACXoVgAAACXoVgAAACXoVgAAACXKfXdTQ3DkJS7rzsAAHAPf3xv//E9fjmlXizS09MlSREREaX90QAAoJjS09MVEhJy2dctxtWqh4s5nU4dP35cQUFBslgsLvt1bTabIiIidOTIEQUHB7vs18XFGOvSw1iXHsa6dDHepcdVY20YhtLT0xUeHi4vr8vPpCj1MxZeXl6qXbt2if36wcHB/CEtJYx16WGsSw9jXboY79LjirG+0pmKPzB5EwAAuAzFAgAAuIzHFAs/Pz+9+OKL8vPzMzuKx2OsSw9jXXoY69LFeJee0h7rUp+8CQAAPJfHnLEAAADmo1gAAACXoVgAAACXoVgAAACX8ZhiMXnyZNWvX18VKlRQ+/bttXLlSrMjubWYmBh17NhRQUFBCg0N1c0336w9e/bkO8YwDE2YMEHh4eHy9/dX7969tWPHDpMSe46YmBhZLBaNHTs27znG2rWOHTumYcOGqWrVqgoICFCbNm20cePGvNcZb9fIycnRc889p/r168vf318NGjTQyy+/LKfTmXcMY100K1as0A033KDw8HBZLBbNmzcv3+sFGVe73a7Ro0erWrVqCgwM1I033qijR48WP5zhAWbNmmX4+PgY06ZNM3bu3GmMGTPGCAwMNA4dOmR2NLd13XXXGdOnTze2b99ubNmyxRg4cKBRp04d49y5c3nHTJw40QgKCjJmz55txMfHG3fccYdRs2ZNw2azmZjcva1fv96oV6+e0apVK2PMmDF5zzPWrnPmzBmjbt26xogRI4zY2FgjMTHRWLRokbFv3768Yxhv13j11VeNqlWrGj/++KORmJhofPfdd0bFihWNd999N+8Yxrpofv75Z+PZZ581Zs+ebUgy5s6dm+/1gozryJEjjVq1ahm//fabsWnTJqNPnz5G69atjZycnGJl84hi0alTJ2PkyJH5nouMjDTGjx9vUiLPc/LkSUOSsXz5csMwDMPpdBphYWHGxIkT847JzMw0QkJCjI8++sismG4tPT3daNy4sfHbb78ZvXr1yisWjLVrPfXUU0b37t0v+zrj7ToDBw407rvvvnzP3XLLLcawYcMMw2CsXeWvxaIg45qammr4+PgYs2bNyjvm2LFjhpeXl7Fw4cJi5XH7SyFZWVnauHGj+vfvn+/5/v37a82aNSal8jxpaWmSpCpVqkiSEhMTdeLEiXzj7ufnp169ejHuRTRq1CgNHDhQ11xzTb7nGWvXmj9/vjp06KDBgwcrNDRUbdu21bRp0/JeZ7xdp3v37lq8eLESEhIkSVu3btWqVat0/fXXS2KsS0pBxnXjxo3Kzs7Od0x4eLiioqKKPfalvgmZq6WkpMjhcKhGjRr5nq9Ro4ZOnDhhUirPYhiGxo0bp+7duysqKkqS8sb2UuN+6NChUs/o7mbNmqVNmzYpLi7uotcYa9c6cOCApkyZonHjxumZZ57R+vXr9eijj8rPz0/33HMP4+1CTz31lNLS0hQZGSmr1SqHw6HXXntNd955pyT+bJeUgozriRMn5Ovrq8qVK190THG/O92+WPzhr1uwG4bh0m3Zy7NHHnlE27Zt06pVqy56jXEvviNHjmjMmDH69ddfVaFChcsex1i7htPpVIcOHfT6669Lktq2basdO3ZoypQpuueee/KOY7yL75tvvtGMGTM0c+ZMtWjRQlu2bNHYsWMVHh6u4cOH5x3HWJeMooyrK8be7S+FVKtWTVar9aKGdfLkyYvaGgpv9OjRmj9/vpYuXZpvu/uwsDBJYtxdYOPGjTp58qTat28vb29veXt7a/ny5Xr//ffl7e2dN56MtWvUrFlTzZs3z/dcs2bNdPjwYUn82XalJ554QuPHj9eQIUPUsmVL3X333XrssccUExMjibEuKQUZ17CwMGVlZens2bOXPaao3L5Y+Pr6qn379vrtt9/yPf/bb78pOjrapFTuzzAMPfLII5ozZ46WLFmi+vXr53u9fv36CgsLyzfuWVlZWr58OeNeSP369VN8fLy2bNmS9+jQoYOGDh2qLVu2qEGDBoy1C3Xr1u2iW6cTEhJUt25dSfzZdqULFy7Iyyv/14zVas273ZSxLhkFGdf27dvLx8cn3zFJSUnavn178ce+WFM/y4g/bjf99NNPjZ07dxpjx441AgMDjYMHD5odzW09/PDDRkhIiLFs2TIjKSkp73HhwoW8YyZOnGiEhIQYc+bMMeLj440777yT28Rc5H/vCjEMxtqV1q9fb3h7exuvvfaasXfvXuOrr74yAgICjBkzZuQdw3i7xvDhw41atWrl3W46Z84co1q1asaTTz6ZdwxjXTTp6enG5s2bjc2bNxuSjLffftvYvHlz3jILBRnXkSNHGrVr1zYWLVpkbNq0yejbty+3m/6vDz/80Khbt67h6+trtGvXLu+2SBSNpEs+pk+fnneM0+k0XnzxRSMsLMzw8/MzevbsacTHx5sX2oP8tVgw1q71ww8/GFFRUYafn58RGRlpTJ06Nd/rjLdr2Gw2Y8yYMUadOnWMChUqGA0aNDCeffZZw2635x3DWBfN0qVLL/lv9PDhww3DKNi4ZmRkGI888ohRpUoVw9/f3xg0aJBx+PDhYmdj23QAAOAybj/HAgAAlB0UCwAA4DIUCwAA4DIUCwAA4DIUCwAA4DIUCwAA4DIUCwAA4DIUCwAA4DIUCwAA4DIUCwAA4DIUCwAA4DIUCwAA4DL/DxxF0VRFEwstAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.plot(u_pred,'r')\n",
    "plt.plot(y_true,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001407728616938681\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
