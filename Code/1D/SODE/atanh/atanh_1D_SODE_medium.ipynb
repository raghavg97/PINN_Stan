{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(2.0*x) + np.exp(-3.0*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"medium\"\n",
    "label = \"1D_SODE_atanh\" + level\n",
    "loss_thresh = 0.005\n",
    "\n",
    "u_coeff = 6.0\n",
    "fo_val = -1.0\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(1.0)\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0  #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "    \n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,0)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 3.9807725 Test MSE 385.3544938842184 Test RE 1.0006744161928136\n",
      "1 Train Loss 3.1397421 Test MSE 385.9872698914982 Test RE 1.0014956639599313\n",
      "2 Train Loss 2.4115098 Test MSE 384.4957674817714 Test RE 0.999558839743465\n",
      "3 Train Loss 2.3830526 Test MSE 383.8205552454022 Test RE 0.9986807924656271\n",
      "4 Train Loss 2.3823967 Test MSE 383.7974463087662 Test RE 0.998650727897403\n",
      "5 Train Loss 2.381151 Test MSE 383.7857860808925 Test RE 0.9986355576772645\n",
      "6 Train Loss 2.381058 Test MSE 383.7901872747797 Test RE 0.9986412837571127\n",
      "7 Train Loss 2.381051 Test MSE 383.7872875680669 Test RE 0.9986375111589586\n",
      "8 Train Loss 2.3810458 Test MSE 383.7863037212478 Test RE 0.9986362311439604\n",
      "9 Train Loss 2.3810458 Test MSE 383.7863037212478 Test RE 0.9986362311439604\n",
      "10 Train Loss 2.3810394 Test MSE 383.77470531202766 Test RE 0.9986211411328405\n",
      "11 Train Loss 2.3810396 Test MSE 383.77470531202766 Test RE 0.9986211411328405\n",
      "12 Train Loss 2.3810396 Test MSE 383.77470531202766 Test RE 0.9986211411328405\n",
      "13 Train Loss 2.3810387 Test MSE 383.7805595731163 Test RE 0.9986287577976612\n",
      "14 Train Loss 2.3810387 Test MSE 383.7805595731163 Test RE 0.9986287577976612\n",
      "15 Train Loss 2.3810387 Test MSE 383.7805595731163 Test RE 0.9986287577976612\n",
      "16 Train Loss 2.3810387 Test MSE 383.7805595731163 Test RE 0.9986287577976612\n",
      "17 Train Loss 2.3810387 Test MSE 383.7805595731163 Test RE 0.9986287577976612\n",
      "18 Train Loss 2.3810387 Test MSE 383.7805595731163 Test RE 0.9986287577976612\n",
      "19 Train Loss 2.3810387 Test MSE 383.7805595731163 Test RE 0.9986287577976612\n",
      "20 Train Loss 2.3810387 Test MSE 383.7805595731163 Test RE 0.9986287577976612\n",
      "21 Train Loss 2.3810372 Test MSE 383.7822152948119 Test RE 0.9986309119577345\n",
      "22 Train Loss 2.381035 Test MSE 383.7778230526894 Test RE 0.9986251974650727\n",
      "23 Train Loss 2.381035 Test MSE 383.7778230526894 Test RE 0.9986251974650727\n",
      "24 Train Loss 2.381035 Test MSE 383.7778230526894 Test RE 0.9986251974650727\n",
      "25 Train Loss 2.380388 Test MSE 383.651631659812 Test RE 0.9984610031606261\n",
      "26 Train Loss 2.379597 Test MSE 383.39755658703194 Test RE 0.9981303306886732\n",
      "27 Train Loss 2.3792021 Test MSE 383.2269919371546 Test RE 0.9979082835130106\n",
      "28 Train Loss 2.3785245 Test MSE 382.9978159204007 Test RE 0.9976098561427765\n",
      "29 Train Loss 2.3779228 Test MSE 382.9951200355201 Test RE 0.9976063450965658\n",
      "30 Train Loss 2.3778772 Test MSE 382.97313983853826 Test RE 0.9975777182323511\n",
      "31 Train Loss 2.3778772 Test MSE 382.97313983853826 Test RE 0.9975777182323511\n",
      "32 Train Loss 2.3778505 Test MSE 382.9525709384948 Test RE 0.9975509286879201\n",
      "33 Train Loss 2.3767278 Test MSE 382.4705615509097 Test RE 0.9969229392908394\n",
      "34 Train Loss 2.376149 Test MSE 382.2823467979568 Test RE 0.9966776149269928\n",
      "35 Train Loss 2.3737085 Test MSE 382.14616763635206 Test RE 0.9965000775483375\n",
      "36 Train Loss 2.3706486 Test MSE 381.5433390320499 Test RE 0.9957137869943719\n",
      "37 Train Loss 2.3592026 Test MSE 380.07173433287636 Test RE 0.9937917081970747\n",
      "38 Train Loss 2.3178883 Test MSE 371.02078316737226 Test RE 0.9818874326162481\n",
      "39 Train Loss 2.1951597 Test MSE 348.5585460202607 Test RE 0.9517008346365001\n",
      "40 Train Loss 2.0590663 Test MSE 327.9030340297769 Test RE 0.9230714104035058\n",
      "41 Train Loss 2.0067334 Test MSE 313.6032126473472 Test RE 0.9027195210818507\n",
      "42 Train Loss 1.9438851 Test MSE 308.4961862880862 Test RE 0.8953389587580598\n",
      "43 Train Loss 1.9025201 Test MSE 290.9922751481409 Test RE 0.8695675258546821\n",
      "44 Train Loss 1.7841394 Test MSE 276.22350957299807 Test RE 0.8472135673589258\n",
      "45 Train Loss 1.6764388 Test MSE 259.0484739760731 Test RE 0.8204518557329493\n",
      "46 Train Loss 1.6286016 Test MSE 255.512608296815 Test RE 0.8148332644809746\n",
      "47 Train Loss 1.5775948 Test MSE 242.2917264941556 Test RE 0.7934724911536185\n",
      "48 Train Loss 1.4800678 Test MSE 232.1849087499456 Test RE 0.7767469861684493\n",
      "49 Train Loss 1.420592 Test MSE 215.70968433034747 Test RE 0.7486820212598131\n",
      "50 Train Loss 1.3804461 Test MSE 214.5382098183862 Test RE 0.7466462852706125\n",
      "51 Train Loss 1.3205332 Test MSE 198.24831951332249 Test RE 0.7177403131711286\n",
      "52 Train Loss 1.2529459 Test MSE 194.48472352414686 Test RE 0.7108947868283695\n",
      "53 Train Loss 1.2240115 Test MSE 191.01612488248927 Test RE 0.7045269289740844\n",
      "54 Train Loss 1.2106682 Test MSE 188.47825379609677 Test RE 0.6998310499838666\n",
      "55 Train Loss 1.1998966 Test MSE 189.49110199831426 Test RE 0.7017089135712935\n",
      "56 Train Loss 1.1866913 Test MSE 185.53918883479375 Test RE 0.6943531487960256\n",
      "57 Train Loss 1.1693907 Test MSE 181.3718361163477 Test RE 0.6865110110309649\n",
      "58 Train Loss 1.1336358 Test MSE 173.86565790324693 Test RE 0.6721550821206086\n",
      "59 Train Loss 1.061651 Test MSE 163.61387327747767 Test RE 0.6520376079362945\n",
      "60 Train Loss 1.0011122 Test MSE 154.6105847984404 Test RE 0.6338437231680112\n",
      "61 Train Loss 0.967151 Test MSE 150.43058019712603 Test RE 0.6252168122504802\n",
      "62 Train Loss 0.94195944 Test MSE 146.27086243937512 Test RE 0.6165119422212861\n",
      "63 Train Loss 0.92109287 Test MSE 141.2798899002735 Test RE 0.6059025167284505\n",
      "64 Train Loss 0.9139238 Test MSE 137.26583385262455 Test RE 0.5972330168722473\n",
      "65 Train Loss 0.90624374 Test MSE 135.32457990266067 Test RE 0.5929948563581857\n",
      "66 Train Loss 0.8904072 Test MSE 132.654705645508 Test RE 0.5871159956683933\n",
      "67 Train Loss 0.8733983 Test MSE 130.59861555969673 Test RE 0.5825482059164133\n",
      "68 Train Loss 0.8543049 Test MSE 128.74498193046523 Test RE 0.5783992722385001\n",
      "69 Train Loss 0.8299964 Test MSE 122.91712852168921 Test RE 0.565156576379727\n",
      "70 Train Loss 0.8132981 Test MSE 122.29873602458044 Test RE 0.5637331406605814\n",
      "71 Train Loss 0.75554854 Test MSE 116.05666822092176 Test RE 0.5491584010249667\n",
      "72 Train Loss 0.7415897 Test MSE 113.269882280736 Test RE 0.5425250643065384\n",
      "73 Train Loss 0.7279053 Test MSE 110.74790318045898 Test RE 0.536451345259738\n",
      "74 Train Loss 0.725193 Test MSE 111.510765634803 Test RE 0.5382957877167428\n",
      "75 Train Loss 0.70870405 Test MSE 108.51400210315745 Test RE 0.5310133908069439\n",
      "76 Train Loss 0.70336235 Test MSE 107.47169050252882 Test RE 0.5284569606702169\n",
      "77 Train Loss 0.69999397 Test MSE 104.65824012837079 Test RE 0.5214939763254601\n",
      "78 Train Loss 0.6744869 Test MSE 101.90533479150832 Test RE 0.5145896448349998\n",
      "79 Train Loss 0.6522518 Test MSE 97.35619358207578 Test RE 0.5029726559353539\n",
      "80 Train Loss 0.64642614 Test MSE 96.34188810307764 Test RE 0.5003456855012905\n",
      "81 Train Loss 0.63419336 Test MSE 95.57547784640889 Test RE 0.4983515593844686\n",
      "82 Train Loss 0.6214993 Test MSE 93.11518301015627 Test RE 0.4918954814115994\n",
      "83 Train Loss 0.60156226 Test MSE 91.34618978438488 Test RE 0.48720058484036466\n",
      "84 Train Loss 0.5975097 Test MSE 90.5355714778229 Test RE 0.4850340259671344\n",
      "85 Train Loss 0.59345204 Test MSE 90.62748043895083 Test RE 0.4852801594185784\n",
      "86 Train Loss 0.58552885 Test MSE 90.6494887011829 Test RE 0.4853390793214038\n",
      "87 Train Loss 0.5613715 Test MSE 87.44956730301365 Test RE 0.4766958982122668\n",
      "88 Train Loss 0.551881 Test MSE 84.90113391131017 Test RE 0.46969866716807723\n",
      "89 Train Loss 0.54024845 Test MSE 83.07462467448542 Test RE 0.46461879748817686\n",
      "90 Train Loss 0.5361047 Test MSE 80.54054314715229 Test RE 0.45747762685824866\n",
      "91 Train Loss 0.5299834 Test MSE 77.87852663567205 Test RE 0.44985385431860936\n",
      "92 Train Loss 0.516239 Test MSE 76.72717437379234 Test RE 0.44651616382512976\n",
      "93 Train Loss 0.5102114 Test MSE 76.21605459121612 Test RE 0.44502644003273806\n",
      "94 Train Loss 0.4985401 Test MSE 73.1351119774035 Test RE 0.4359388235693031\n",
      "95 Train Loss 0.48586637 Test MSE 70.51812458137408 Test RE 0.4280681930246407\n",
      "96 Train Loss 0.48293936 Test MSE 70.19850878304074 Test RE 0.4270970048523104\n",
      "97 Train Loss 0.48076788 Test MSE 70.39196554992368 Test RE 0.4276851082179396\n",
      "98 Train Loss 0.47842786 Test MSE 70.38491109936312 Test RE 0.427663677085692\n",
      "99 Train Loss 0.47733343 Test MSE 70.80106423358646 Test RE 0.42892610168064343\n",
      "100 Train Loss 0.47460756 Test MSE 69.76271598884185 Test RE 0.4257692304590451\n",
      "101 Train Loss 0.46707195 Test MSE 67.9133732608313 Test RE 0.42008795922383774\n",
      "102 Train Loss 0.4566822 Test MSE 68.02550067651646 Test RE 0.4204346063469266\n",
      "103 Train Loss 0.4553388 Test MSE 67.56021059917337 Test RE 0.41899426624285985\n",
      "104 Train Loss 0.4544165 Test MSE 67.18186757349842 Test RE 0.417819417045016\n",
      "105 Train Loss 0.44494212 Test MSE 67.3859520139897 Test RE 0.418453559744314\n",
      "106 Train Loss 0.44181055 Test MSE 67.30029355127715 Test RE 0.4181875140350136\n",
      "107 Train Loss 0.44132644 Test MSE 67.24867914243278 Test RE 0.418027123639924\n",
      "108 Train Loss 0.44009918 Test MSE 67.00501749279178 Test RE 0.41726911908158504\n",
      "109 Train Loss 0.4360453 Test MSE 66.96805157856926 Test RE 0.41715400186319546\n",
      "110 Train Loss 0.43150207 Test MSE 66.16233252198724 Test RE 0.41463693578875094\n",
      "111 Train Loss 0.42926842 Test MSE 66.44215313177494 Test RE 0.41551282346819135\n",
      "112 Train Loss 0.42853457 Test MSE 66.37671827711002 Test RE 0.4153081663534167\n",
      "113 Train Loss 0.42530477 Test MSE 65.9815648520862 Test RE 0.41407011614793315\n",
      "114 Train Loss 0.4225525 Test MSE 64.79183493146326 Test RE 0.41032003423077096\n",
      "115 Train Loss 0.4185143 Test MSE 63.82980990448705 Test RE 0.40726243921000854\n",
      "116 Train Loss 0.41522494 Test MSE 63.45233429517088 Test RE 0.40605642280454385\n",
      "117 Train Loss 0.4092624 Test MSE 62.329189372187194 Test RE 0.4024466548441029\n",
      "118 Train Loss 0.40208334 Test MSE 61.54204560677256 Test RE 0.39989736859690755\n",
      "119 Train Loss 0.39628044 Test MSE 59.87939435326662 Test RE 0.3944584665288572\n",
      "120 Train Loss 0.39282826 Test MSE 58.36416109972635 Test RE 0.3894356507183205\n",
      "121 Train Loss 0.39172807 Test MSE 57.35600871762815 Test RE 0.386057544083473\n",
      "122 Train Loss 0.39163268 Test MSE 57.44890912507666 Test RE 0.3863700692483288\n",
      "123 Train Loss 0.39097726 Test MSE 57.720002194233615 Test RE 0.38728060849367885\n",
      "124 Train Loss 0.39015257 Test MSE 57.42027545469715 Test RE 0.38627377001264274\n",
      "125 Train Loss 0.39015257 Test MSE 57.42027545469715 Test RE 0.38627377001264274\n",
      "126 Train Loss 0.39015257 Test MSE 57.42027545469715 Test RE 0.38627377001264274\n",
      "127 Train Loss 0.3901523 Test MSE 57.38458592495917 Test RE 0.38615370726549286\n",
      "128 Train Loss 0.39009938 Test MSE 57.371452350302434 Test RE 0.38610951535683763\n",
      "129 Train Loss 0.38911384 Test MSE 57.4634759317803 Test RE 0.38641905034713503\n",
      "130 Train Loss 0.3882847 Test MSE 57.81545031991385 Test RE 0.3876006876483956\n",
      "131 Train Loss 0.38690016 Test MSE 58.27852177213214 Test RE 0.38914983104889433\n",
      "132 Train Loss 0.383969 Test MSE 57.569756529408025 Test RE 0.3867762326697575\n",
      "133 Train Loss 0.3810507 Test MSE 56.781855650866035 Test RE 0.38412040066130365\n",
      "134 Train Loss 0.3782545 Test MSE 56.3973367064554 Test RE 0.3828175859394426\n",
      "135 Train Loss 0.375897 Test MSE 55.95450250722118 Test RE 0.38131167430650215\n",
      "136 Train Loss 0.3746755 Test MSE 55.71542844854034 Test RE 0.380496196465975\n",
      "137 Train Loss 0.37287137 Test MSE 55.34759481255173 Test RE 0.37923809729943064\n",
      "138 Train Loss 0.36943164 Test MSE 54.48379154715072 Test RE 0.3762670979864475\n",
      "139 Train Loss 0.36848754 Test MSE 54.05565831712533 Test RE 0.37478583026646445\n",
      "140 Train Loss 0.36683857 Test MSE 53.60084395990635 Test RE 0.37320581025855515\n",
      "141 Train Loss 0.3637701 Test MSE 53.372300738494665 Test RE 0.37240932306807545\n",
      "142 Train Loss 0.36114237 Test MSE 53.033055548857085 Test RE 0.3712238816699698\n",
      "143 Train Loss 0.3543739 Test MSE 52.00229572463705 Test RE 0.3675985933685665\n",
      "144 Train Loss 0.34564108 Test MSE 51.2898818675113 Test RE 0.36507192171064234\n",
      "145 Train Loss 0.33160946 Test MSE 49.427315551485066 Test RE 0.3583819222754426\n",
      "146 Train Loss 0.3263084 Test MSE 47.57647423441008 Test RE 0.3516079691750537\n",
      "147 Train Loss 0.3204719 Test MSE 46.878463755386605 Test RE 0.34901915928924465\n",
      "148 Train Loss 0.313074 Test MSE 47.14086869609817 Test RE 0.3499946237107636\n",
      "149 Train Loss 0.3063843 Test MSE 47.23140231506163 Test RE 0.3503305432861196\n",
      "150 Train Loss 0.30428678 Test MSE 47.09441671566984 Test RE 0.3498221412032831\n",
      "151 Train Loss 0.2994187 Test MSE 45.73322385251795 Test RE 0.3447295329922302\n",
      "152 Train Loss 0.29753748 Test MSE 45.37228524328794 Test RE 0.34336649030316685\n",
      "153 Train Loss 0.29331505 Test MSE 43.63641248155584 Test RE 0.33673410268173104\n",
      "154 Train Loss 0.28700307 Test MSE 43.235363532592395 Test RE 0.3351831206230879\n",
      "155 Train Loss 0.27960128 Test MSE 42.511950908472635 Test RE 0.3323671555203978\n",
      "156 Train Loss 0.273397 Test MSE 41.62686906610833 Test RE 0.3288890815444999\n",
      "157 Train Loss 0.26855674 Test MSE 41.49425487063585 Test RE 0.32836477891681987\n",
      "158 Train Loss 0.26528594 Test MSE 41.06078006611139 Test RE 0.3266451245848143\n",
      "159 Train Loss 0.26155773 Test MSE 40.04087336585835 Test RE 0.32256285424826336\n",
      "160 Train Loss 0.25803268 Test MSE 39.23284147108737 Test RE 0.3192915787281879\n",
      "161 Train Loss 0.2556649 Test MSE 38.45260558989879 Test RE 0.316100708478221\n",
      "162 Train Loss 0.2549008 Test MSE 37.99207092431202 Test RE 0.31420208757695367\n",
      "163 Train Loss 0.25373647 Test MSE 37.29614160548198 Test RE 0.3113110491557853\n",
      "164 Train Loss 0.2535795 Test MSE 37.13642808412313 Test RE 0.3106437693014398\n",
      "165 Train Loss 0.25357747 Test MSE 37.096097041269736 Test RE 0.31047504022257405\n",
      "166 Train Loss 0.25356966 Test MSE 37.0310095933377 Test RE 0.31020254659820773\n",
      "167 Train Loss 0.2534677 Test MSE 36.94014775000834 Test RE 0.30982174566593973\n",
      "168 Train Loss 0.25125796 Test MSE 37.20871536482426 Test RE 0.3109459614816251\n",
      "169 Train Loss 0.25042453 Test MSE 37.207711221224656 Test RE 0.31094176573742155\n",
      "170 Train Loss 0.2502923 Test MSE 37.244894762578994 Test RE 0.3110970968296441\n",
      "171 Train Loss 0.2492083 Test MSE 36.85650759846967 Test RE 0.30947079657163906\n",
      "172 Train Loss 0.24584779 Test MSE 35.94749090918523 Test RE 0.3056306279996145\n",
      "173 Train Loss 0.24255094 Test MSE 34.71447690252526 Test RE 0.30034326335932027\n",
      "174 Train Loss 0.23912442 Test MSE 34.10430036278597 Test RE 0.2976919938199171\n",
      "175 Train Loss 0.23358981 Test MSE 33.56134982229439 Test RE 0.2953128142592016\n",
      "176 Train Loss 0.23006731 Test MSE 33.59757468321712 Test RE 0.2954721460586382\n",
      "177 Train Loss 0.22790937 Test MSE 33.730212777239565 Test RE 0.29605481101194997\n",
      "178 Train Loss 0.2225727 Test MSE 34.51355725080567 Test RE 0.299472842161648\n",
      "179 Train Loss 0.2201813 Test MSE 34.48366732895272 Test RE 0.29934313720774297\n",
      "180 Train Loss 0.21662937 Test MSE 34.00443111943378 Test RE 0.297255801449331\n",
      "181 Train Loss 0.21467559 Test MSE 33.80785216979074 Test RE 0.296395341090496\n",
      "182 Train Loss 0.21349637 Test MSE 33.456128546999985 Test RE 0.2948495196591543\n",
      "183 Train Loss 0.20944405 Test MSE 32.339049130486366 Test RE 0.28988530843227583\n",
      "184 Train Loss 0.19923945 Test MSE 30.711147546762 Test RE 0.2824948954857387\n",
      "185 Train Loss 0.19480336 Test MSE 30.063146990210484 Test RE 0.27949870671235655\n",
      "186 Train Loss 0.19156553 Test MSE 28.93744693280315 Test RE 0.27421593497479957\n",
      "187 Train Loss 0.18894124 Test MSE 27.591685867225237 Test RE 0.2677637002783297\n",
      "188 Train Loss 0.18381739 Test MSE 27.420291451428387 Test RE 0.2669307556110234\n",
      "189 Train Loss 0.18338653 Test MSE 27.163740880086642 Test RE 0.2656790881496271\n",
      "190 Train Loss 0.1832096 Test MSE 27.043029863527494 Test RE 0.26508811466828475\n",
      "191 Train Loss 0.18206497 Test MSE 26.420607103419293 Test RE 0.2620197204311876\n",
      "192 Train Loss 0.18100291 Test MSE 25.912451321134085 Test RE 0.25948773316678597\n",
      "193 Train Loss 0.17992161 Test MSE 25.740952909598494 Test RE 0.2586276136338076\n",
      "194 Train Loss 0.17991342 Test MSE 25.747152074471067 Test RE 0.2586587542583607\n",
      "195 Train Loss 0.17977491 Test MSE 25.79865584250657 Test RE 0.2589173313025678\n",
      "196 Train Loss 0.17977403 Test MSE 25.79901630706607 Test RE 0.25891914012152983\n",
      "197 Train Loss 0.17976947 Test MSE 25.80157824224611 Test RE 0.2589319956036715\n",
      "198 Train Loss 0.1797518 Test MSE 25.79571698939804 Test RE 0.25890258360253504\n",
      "199 Train Loss 0.1797518 Test MSE 25.79571698939804 Test RE 0.25890258360253504\n",
      "Training time: 77.33\n",
      "Training time: 77.33\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 3.9209442 Test MSE 385.4176885135749 Test RE 1.0007564635770676\n",
      "1 Train Loss 3.165286 Test MSE 387.80737743909924 Test RE 1.0038541432935337\n",
      "2 Train Loss 2.45279 Test MSE 384.7739268283044 Test RE 0.9999203344460331\n",
      "3 Train Loss 2.3945165 Test MSE 385.14263087378305 Test RE 1.0003992993261417\n",
      "4 Train Loss 2.3907533 Test MSE 384.32289860467404 Test RE 0.9993341142002413\n",
      "5 Train Loss 2.3857396 Test MSE 383.8097181578912 Test RE 0.9986666936017291\n",
      "6 Train Loss 2.3803167 Test MSE 383.69455457561685 Test RE 0.9985168554695935\n",
      "7 Train Loss 2.378359 Test MSE 382.92917249554534 Test RE 0.9975204529882998\n",
      "8 Train Loss 2.3744183 Test MSE 381.86856748452044 Test RE 0.9961380710022516\n",
      "9 Train Loss 2.3602524 Test MSE 377.79578989119227 Test RE 0.9908117300322179\n",
      "10 Train Loss 2.3262837 Test MSE 364.3069474765467 Test RE 0.9729629644101209\n",
      "11 Train Loss 2.2293136 Test MSE 352.85734802358803 Test RE 0.9575515539713239\n",
      "12 Train Loss 2.1834226 Test MSE 345.80620354233145 Test RE 0.9479359031456985\n",
      "13 Train Loss 2.0844858 Test MSE 329.9034764743939 Test RE 0.9258828260899007\n",
      "14 Train Loss 2.0252204 Test MSE 320.4209345508904 Test RE 0.9124793059577134\n",
      "15 Train Loss 1.9253634 Test MSE 305.03090859252893 Test RE 0.8902961733641623\n",
      "16 Train Loss 1.8184601 Test MSE 284.5702985328409 Test RE 0.8599186484083906\n",
      "17 Train Loss 1.7850823 Test MSE 277.4058495942597 Test RE 0.8490248268166894\n",
      "18 Train Loss 1.6829008 Test MSE 263.99529660540867 Test RE 0.8282485366803383\n",
      "19 Train Loss 1.593962 Test MSE 249.88286115939798 Test RE 0.8058065950629186\n",
      "20 Train Loss 1.5277803 Test MSE 239.69354249218733 Test RE 0.789206674513301\n",
      "21 Train Loss 1.4920273 Test MSE 226.11048296733625 Test RE 0.7665190123552543\n",
      "22 Train Loss 1.3848794 Test MSE 201.6208933622528 Test RE 0.7238196181460262\n",
      "23 Train Loss 1.2617438 Test MSE 200.8014425861859 Test RE 0.7223472051506744\n",
      "24 Train Loss 1.231242 Test MSE 194.533075118598 Test RE 0.7109831504789392\n",
      "25 Train Loss 1.218152 Test MSE 189.79009431857338 Test RE 0.702262298077882\n",
      "26 Train Loss 1.1718042 Test MSE 180.1306961598882 Test RE 0.6841580577185866\n",
      "27 Train Loss 1.1603789 Test MSE 180.03878964894022 Test RE 0.6839834994564292\n",
      "28 Train Loss 1.1125844 Test MSE 169.30695992000057 Test RE 0.6632847134159773\n",
      "29 Train Loss 1.0389574 Test MSE 158.14340611338557 Test RE 0.641044423768916\n",
      "30 Train Loss 0.96706635 Test MSE 145.78100449030345 Test RE 0.6154787338794317\n",
      "31 Train Loss 0.88431096 Test MSE 132.49315984775566 Test RE 0.5867583942748653\n",
      "32 Train Loss 0.8444966 Test MSE 123.26214746165903 Test RE 0.5659491961173033\n",
      "33 Train Loss 0.8377036 Test MSE 118.40364506714008 Test RE 0.5546833358502656\n",
      "34 Train Loss 0.81168085 Test MSE 105.88035393062037 Test RE 0.5245299304418225\n",
      "35 Train Loss 0.80049574 Test MSE 105.61410195968749 Test RE 0.5238700108705896\n",
      "36 Train Loss 0.7822865 Test MSE 102.17092320636199 Test RE 0.5152597771522514\n",
      "37 Train Loss 0.73026437 Test MSE 106.98851158648792 Test RE 0.5272676851487901\n",
      "38 Train Loss 0.71978354 Test MSE 109.3819398110067 Test RE 0.5331327883760251\n",
      "39 Train Loss 0.71674734 Test MSE 108.97450905557226 Test RE 0.532138943571999\n",
      "40 Train Loss 0.71155226 Test MSE 109.49681010182772 Test RE 0.5334126565539952\n",
      "41 Train Loss 0.68493724 Test MSE 104.91122484875105 Test RE 0.5221238855280698\n",
      "42 Train Loss 0.678428 Test MSE 102.53209549077928 Test RE 0.5161696905217366\n",
      "43 Train Loss 0.67091364 Test MSE 100.1990789171024 Test RE 0.510263433661436\n",
      "44 Train Loss 0.6695074 Test MSE 98.69651124032221 Test RE 0.5064230718011145\n",
      "45 Train Loss 0.6464145 Test MSE 95.93639063791545 Test RE 0.4992916120937002\n",
      "46 Train Loss 0.61617494 Test MSE 91.00062419671993 Test RE 0.48627816384883715\n",
      "47 Train Loss 0.59923804 Test MSE 88.84769272745632 Test RE 0.4804914450143422\n",
      "48 Train Loss 0.59139276 Test MSE 85.90497383882915 Test RE 0.4724672799991805\n",
      "49 Train Loss 0.57924765 Test MSE 83.17024219103364 Test RE 0.46488610486255844\n",
      "50 Train Loss 0.5704478 Test MSE 81.15608516046842 Test RE 0.459222466782985\n",
      "51 Train Loss 0.56021154 Test MSE 77.28663982274033 Test RE 0.4481411203036517\n",
      "52 Train Loss 0.5547394 Test MSE 75.88401517145641 Test RE 0.44405599088482545\n",
      "53 Train Loss 0.5434437 Test MSE 72.20923458113027 Test RE 0.4331705806516471\n",
      "54 Train Loss 0.51743054 Test MSE 68.18531060979745 Test RE 0.4209281728068986\n",
      "55 Train Loss 0.47968486 Test MSE 64.9619148007 Test RE 0.4108582304376459\n",
      "56 Train Loss 0.46360424 Test MSE 62.789368353464 Test RE 0.4039295629278027\n",
      "57 Train Loss 0.44748735 Test MSE 60.91750031927524 Test RE 0.39786306105081626\n",
      "58 Train Loss 0.42258444 Test MSE 62.45488250864771 Test RE 0.4028522377351963\n",
      "59 Train Loss 0.4184492 Test MSE 62.53414424652534 Test RE 0.40310778736355213\n",
      "60 Train Loss 0.3999887 Test MSE 60.17514466880265 Test RE 0.3954314015551132\n",
      "61 Train Loss 0.39166167 Test MSE 58.59410372148581 Test RE 0.3902020442224654\n",
      "62 Train Loss 0.3896895 Test MSE 57.44594225288963 Test RE 0.3863600923364073\n",
      "63 Train Loss 0.3884469 Test MSE 57.4192907850229 Test RE 0.38627045799702703\n",
      "64 Train Loss 0.38293618 Test MSE 55.526990145790805 Test RE 0.3798522026261412\n",
      "65 Train Loss 0.3667384 Test MSE 51.85972082666528 Test RE 0.36709432424018856\n",
      "66 Train Loss 0.34871468 Test MSE 50.525999156993 Test RE 0.36234313520240424\n",
      "67 Train Loss 0.33958295 Test MSE 48.47209272518064 Test RE 0.354902017086262\n",
      "68 Train Loss 0.3354861 Test MSE 47.38991670842338 Test RE 0.3509179270544362\n",
      "69 Train Loss 0.3263264 Test MSE 46.27834037549438 Test RE 0.3467779464916823\n",
      "70 Train Loss 0.31568372 Test MSE 44.62779687055396 Test RE 0.34053778459995937\n",
      "71 Train Loss 0.31061023 Test MSE 44.12467886424005 Test RE 0.33861279249900517\n",
      "72 Train Loss 0.3061855 Test MSE 43.52432248703332 Test RE 0.33630133573785054\n",
      "73 Train Loss 0.29906803 Test MSE 43.3424600531362 Test RE 0.33559799794588857\n",
      "74 Train Loss 0.2952026 Test MSE 43.071727613523855 Test RE 0.3345482237617737\n",
      "75 Train Loss 0.28828412 Test MSE 41.68459559133403 Test RE 0.32911704784026696\n",
      "76 Train Loss 0.2832001 Test MSE 41.15177988814894 Test RE 0.3270068833881678\n",
      "77 Train Loss 0.27772176 Test MSE 40.39733360000829 Test RE 0.3239954661281266\n",
      "78 Train Loss 0.27558976 Test MSE 40.57359939224036 Test RE 0.3247015418967888\n",
      "79 Train Loss 0.26856834 Test MSE 38.99109608205526 Test RE 0.31830635136359603\n",
      "80 Train Loss 0.25636736 Test MSE 37.87647547537797 Test RE 0.3137237245943644\n",
      "81 Train Loss 0.2506053 Test MSE 37.274335399380625 Test RE 0.3112200276027543\n",
      "82 Train Loss 0.24204296 Test MSE 35.50979752648957 Test RE 0.3037642640540712\n",
      "83 Train Loss 0.23540065 Test MSE 34.84637275973046 Test RE 0.3009132917618084\n",
      "84 Train Loss 0.22746383 Test MSE 33.36161348163436 Test RE 0.29443274353208465\n",
      "85 Train Loss 0.21954523 Test MSE 31.952051699388242 Test RE 0.28814557702883203\n",
      "86 Train Loss 0.2128608 Test MSE 30.48946238165469 Test RE 0.28147346914472254\n",
      "87 Train Loss 0.20888814 Test MSE 29.146620621721226 Test RE 0.27520523229657085\n",
      "88 Train Loss 0.20760284 Test MSE 28.74132040453662 Test RE 0.27328509169461346\n",
      "89 Train Loss 0.202295 Test MSE 28.604532106052634 Test RE 0.27263399448478387\n",
      "90 Train Loss 0.19602919 Test MSE 27.63098934474783 Test RE 0.2679543428418406\n",
      "91 Train Loss 0.18897747 Test MSE 26.40634192629508 Test RE 0.2619489752289312\n",
      "92 Train Loss 0.18343252 Test MSE 26.064021973988343 Test RE 0.26024554217474716\n",
      "93 Train Loss 0.17799479 Test MSE 24.80123735241979 Test RE 0.253862911662088\n",
      "94 Train Loss 0.17220175 Test MSE 23.550616844457203 Test RE 0.24737951055080049\n",
      "95 Train Loss 0.16815466 Test MSE 23.03498914599562 Test RE 0.2446564042205114\n",
      "96 Train Loss 0.16437712 Test MSE 22.179374018266834 Test RE 0.24006963095200842\n",
      "97 Train Loss 0.16083242 Test MSE 20.960637272369535 Test RE 0.2333806385503787\n",
      "98 Train Loss 0.15848912 Test MSE 20.525123650239106 Test RE 0.23094335655038356\n",
      "99 Train Loss 0.15672347 Test MSE 19.747770079192957 Test RE 0.22652785549133705\n",
      "100 Train Loss 0.15525782 Test MSE 19.456418134980172 Test RE 0.22485058822729215\n",
      "101 Train Loss 0.15325937 Test MSE 18.773994975021054 Test RE 0.22087213601140346\n",
      "102 Train Loss 0.14664426 Test MSE 18.635405748196185 Test RE 0.22005538924054516\n",
      "103 Train Loss 0.14040169 Test MSE 18.24470131432867 Test RE 0.21773636156900542\n",
      "104 Train Loss 0.13545004 Test MSE 17.68564769300123 Test RE 0.21437447175328678\n",
      "105 Train Loss 0.13220781 Test MSE 17.78591877739155 Test RE 0.21498132481336088\n",
      "106 Train Loss 0.12980685 Test MSE 17.384541499090613 Test RE 0.21254172600147048\n",
      "107 Train Loss 0.12779626 Test MSE 17.26171937011101 Test RE 0.21178958943620943\n",
      "108 Train Loss 0.12622888 Test MSE 16.982060832229102 Test RE 0.21006697359068977\n",
      "109 Train Loss 0.12535419 Test MSE 16.821708278707728 Test RE 0.20907284600938328\n",
      "110 Train Loss 0.124431886 Test MSE 16.63530620871355 Test RE 0.2079112465306054\n",
      "111 Train Loss 0.12350373 Test MSE 16.52538853382347 Test RE 0.20722322202984822\n",
      "112 Train Loss 0.1225941 Test MSE 16.522372287657607 Test RE 0.2072043097733842\n",
      "113 Train Loss 0.12188443 Test MSE 16.48043027883412 Test RE 0.20694114879703773\n",
      "114 Train Loss 0.12176587 Test MSE 16.43499030022883 Test RE 0.20665566195142962\n",
      "115 Train Loss 0.12175781 Test MSE 16.421031427894956 Test RE 0.20656788298936915\n",
      "116 Train Loss 0.12152933 Test MSE 16.23978547288323 Test RE 0.20542473078559456\n",
      "117 Train Loss 0.12142012 Test MSE 16.266534704290464 Test RE 0.20559384301891837\n",
      "118 Train Loss 0.11891356 Test MSE 16.351145020527508 Test RE 0.2061278472968852\n",
      "119 Train Loss 0.118158914 Test MSE 16.600911829770205 Test RE 0.20769620154757862\n",
      "120 Train Loss 0.11784124 Test MSE 16.608845676684197 Test RE 0.20774582632272412\n",
      "121 Train Loss 0.11605579 Test MSE 16.577473756956504 Test RE 0.20754953134700557\n",
      "122 Train Loss 0.11487619 Test MSE 16.213377612025432 Test RE 0.20525764006668498\n",
      "123 Train Loss 0.11363276 Test MSE 16.08656124885852 Test RE 0.20445333118263742\n",
      "124 Train Loss 0.11314188 Test MSE 15.743359847926943 Test RE 0.20226060113842598\n",
      "125 Train Loss 0.11188493 Test MSE 15.824470926193557 Test RE 0.20278096334667092\n",
      "126 Train Loss 0.1103762 Test MSE 15.704149510967095 Test RE 0.20200856946905058\n",
      "127 Train Loss 0.10718166 Test MSE 14.747674383905638 Test RE 0.19576017862466136\n",
      "128 Train Loss 0.10541907 Test MSE 13.981385994840984 Test RE 0.190606495039088\n",
      "129 Train Loss 0.10478923 Test MSE 13.952121133141539 Test RE 0.19040690843567892\n",
      "130 Train Loss 0.103613436 Test MSE 14.038308953516749 Test RE 0.19099411271440686\n",
      "131 Train Loss 0.10246583 Test MSE 13.825457828837806 Test RE 0.18954064031668638\n",
      "132 Train Loss 0.09962585 Test MSE 13.473189285785443 Test RE 0.18711034009769248\n",
      "133 Train Loss 0.09442094 Test MSE 12.84381465509768 Test RE 0.1826878216810608\n",
      "134 Train Loss 0.08653894 Test MSE 12.063381991818192 Test RE 0.1770504857466509\n",
      "135 Train Loss 0.07913728 Test MSE 11.309810852148592 Test RE 0.17143135325127437\n",
      "136 Train Loss 0.07348083 Test MSE 9.922873545492914 Test RE 0.16057624981814936\n",
      "137 Train Loss 0.0723498 Test MSE 9.813170914485802 Test RE 0.159686155050639\n",
      "138 Train Loss 0.0723498 Test MSE 9.813170914485802 Test RE 0.159686155050639\n",
      "139 Train Loss 0.0723498 Test MSE 9.813170914485802 Test RE 0.159686155050639\n",
      "140 Train Loss 0.0723498 Test MSE 9.813170914485802 Test RE 0.159686155050639\n",
      "141 Train Loss 0.0723498 Test MSE 9.813170914485802 Test RE 0.159686155050639\n",
      "142 Train Loss 0.0723498 Test MSE 9.813170914485802 Test RE 0.159686155050639\n",
      "143 Train Loss 0.07234473 Test MSE 9.813261921273536 Test RE 0.1596868955090724\n",
      "144 Train Loss 0.072344735 Test MSE 9.813261921273536 Test RE 0.1596868955090724\n",
      "145 Train Loss 0.072344735 Test MSE 9.813261921273536 Test RE 0.1596868955090724\n",
      "146 Train Loss 0.0723443 Test MSE 9.815559043555133 Test RE 0.15970558444576666\n",
      "147 Train Loss 0.07228991 Test MSE 9.808825034823478 Test RE 0.15965079167672902\n",
      "148 Train Loss 0.07223475 Test MSE 9.819459569986591 Test RE 0.1597373133558083\n",
      "149 Train Loss 0.07087282 Test MSE 9.901400165923404 Test RE 0.16040240994091648\n",
      "150 Train Loss 0.06967798 Test MSE 9.96834696422299 Test RE 0.16094376455510193\n",
      "151 Train Loss 0.06863011 Test MSE 10.07234980294454 Test RE 0.16178117395535413\n",
      "152 Train Loss 0.06755595 Test MSE 9.905743454667522 Test RE 0.16043758666274358\n",
      "153 Train Loss 0.066474214 Test MSE 9.733592083325838 Test RE 0.1590373583735666\n",
      "154 Train Loss 0.065786615 Test MSE 9.806368508814206 Test RE 0.15963079892129392\n",
      "155 Train Loss 0.06578475 Test MSE 9.809408267896163 Test RE 0.15965553802694746\n",
      "156 Train Loss 0.06553334 Test MSE 9.625464033207253 Test RE 0.15815153821288452\n",
      "157 Train Loss 0.06480821 Test MSE 9.51003975623335 Test RE 0.1572004369192011\n",
      "158 Train Loss 0.06474082 Test MSE 9.485385035344216 Test RE 0.1569965340854456\n",
      "159 Train Loss 0.06450525 Test MSE 9.420572766726933 Test RE 0.1564592473685079\n",
      "160 Train Loss 0.06423545 Test MSE 9.2407581732775 Test RE 0.1549588501399453\n",
      "161 Train Loss 0.06422739 Test MSE 9.197430594762828 Test RE 0.15459514187180662\n",
      "162 Train Loss 0.06421786 Test MSE 9.190567706526236 Test RE 0.15453745363156576\n",
      "163 Train Loss 0.06420894 Test MSE 9.189822790337354 Test RE 0.15453119070051505\n",
      "164 Train Loss 0.06418943 Test MSE 9.202210944410622 Test RE 0.154635311940141\n",
      "165 Train Loss 0.06418943 Test MSE 9.202210944410622 Test RE 0.154635311940141\n",
      "166 Train Loss 0.06418943 Test MSE 9.202210944410622 Test RE 0.154635311940141\n",
      "167 Train Loss 0.06418943 Test MSE 9.202210944410622 Test RE 0.154635311940141\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 96.47\n",
      "Training time: 96.47\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 4.3639517 Test MSE 386.390902233779 Test RE 1.0020191662209328\n",
      "1 Train Loss 2.67059 Test MSE 383.70698000043194 Test RE 0.9985330231419279\n",
      "2 Train Loss 2.4019618 Test MSE 383.4805668382081 Test RE 0.9982383785410088\n",
      "3 Train Loss 2.3814173 Test MSE 383.676421772619 Test RE 0.9984932610203974\n",
      "4 Train Loss 2.3800504 Test MSE 383.5759588832043 Test RE 0.9983625283512898\n",
      "5 Train Loss 2.3771317 Test MSE 382.7918278286689 Test RE 0.9973415473170538\n",
      "6 Train Loss 2.375038 Test MSE 381.530768566818 Test RE 0.9956973842854845\n",
      "7 Train Loss 2.3597636 Test MSE 374.260195691091 Test RE 0.9861645862334929\n",
      "8 Train Loss 2.3192282 Test MSE 369.92865219777826 Test RE 0.980441233341142\n",
      "9 Train Loss 2.277045 Test MSE 364.0259638802039 Test RE 0.9725876773483909\n",
      "10 Train Loss 2.2400289 Test MSE 356.5417828770549 Test RE 0.9625378103510828\n",
      "11 Train Loss 2.1706283 Test MSE 345.9893369476176 Test RE 0.9481868757287057\n",
      "12 Train Loss 2.0885258 Test MSE 326.9088969438237 Test RE 0.9216710633136157\n",
      "13 Train Loss 1.9843464 Test MSE 313.09486462196816 Test RE 0.9019875741743646\n",
      "14 Train Loss 1.9374545 Test MSE 307.30588704101467 Test RE 0.8936100050196636\n",
      "15 Train Loss 1.8881294 Test MSE 297.2416685158041 Test RE 0.8788554045285047\n",
      "16 Train Loss 1.7705271 Test MSE 282.4168459878481 Test RE 0.8566588025307308\n",
      "17 Train Loss 1.7058858 Test MSE 267.93938308922753 Test RE 0.8344126107112236\n",
      "18 Train Loss 1.6631279 Test MSE 260.9661694184482 Test RE 0.8234830946803016\n",
      "19 Train Loss 1.64687 Test MSE 248.5831731966999 Test RE 0.8037082869244745\n",
      "20 Train Loss 1.6026156 Test MSE 235.8777044715431 Test RE 0.7828995236953614\n",
      "21 Train Loss 1.5558746 Test MSE 239.90602103031833 Test RE 0.7895563967726782\n",
      "22 Train Loss 1.5165056 Test MSE 232.68732045260333 Test RE 0.7775869113338164\n",
      "23 Train Loss 1.4792619 Test MSE 228.67309037106614 Test RE 0.7708504194151528\n",
      "24 Train Loss 1.4559524 Test MSE 230.41333627766045 Test RE 0.773778019555759\n",
      "25 Train Loss 1.4374415 Test MSE 221.86860339640143 Test RE 0.7592949428317769\n",
      "26 Train Loss 1.3838007 Test MSE 217.75739443019674 Test RE 0.7522272087573522\n",
      "27 Train Loss 1.3455409 Test MSE 208.69550184519304 Test RE 0.7364090664873587\n",
      "28 Train Loss 1.3295951 Test MSE 203.14299220952518 Test RE 0.7265466507559306\n",
      "29 Train Loss 1.2819692 Test MSE 200.5634674130332 Test RE 0.7219190417365025\n",
      "30 Train Loss 1.2400515 Test MSE 188.26333730481466 Test RE 0.699431937272168\n",
      "31 Train Loss 1.2059813 Test MSE 184.5129539684896 Test RE 0.6924302195432371\n",
      "32 Train Loss 1.1746583 Test MSE 179.46625570432556 Test RE 0.6828950795705565\n",
      "33 Train Loss 1.1542908 Test MSE 171.9984866759605 Test RE 0.6685361491225863\n",
      "34 Train Loss 1.1450664 Test MSE 168.03779747710018 Test RE 0.6607939723431574\n",
      "35 Train Loss 1.072995 Test MSE 155.63998213869522 Test RE 0.6359502884978911\n",
      "36 Train Loss 1.0074822 Test MSE 156.17410221999887 Test RE 0.6370405703579758\n",
      "37 Train Loss 0.9852982 Test MSE 152.01113625127792 Test RE 0.6284927687246075\n",
      "38 Train Loss 0.92132294 Test MSE 141.01527251511857 Test RE 0.6053348227494967\n",
      "39 Train Loss 0.8913054 Test MSE 139.79975383624063 Test RE 0.6027202539919492\n",
      "40 Train Loss 0.8785652 Test MSE 137.3323363841899 Test RE 0.5973776730369449\n",
      "41 Train Loss 0.8473492 Test MSE 132.769689133465 Test RE 0.5873703930608835\n",
      "42 Train Loss 0.83406234 Test MSE 130.2274405358728 Test RE 0.581719785196877\n",
      "43 Train Loss 0.829933 Test MSE 127.44112032409227 Test RE 0.5754629568235362\n",
      "44 Train Loss 0.77726746 Test MSE 118.22149511706078 Test RE 0.5542565144057409\n",
      "45 Train Loss 0.77252626 Test MSE 117.77436553465836 Test RE 0.5532073851668601\n",
      "46 Train Loss 0.75945616 Test MSE 115.4886495403351 Test RE 0.5478128736794282\n",
      "47 Train Loss 0.7279713 Test MSE 113.58939991476251 Test RE 0.5432897170433041\n",
      "48 Train Loss 0.701857 Test MSE 108.29441426296482 Test RE 0.53047584205373\n",
      "49 Train Loss 0.6683874 Test MSE 103.61075012480444 Test RE 0.5188776823611699\n",
      "50 Train Loss 0.64553696 Test MSE 97.1402055209426 Test RE 0.5024144150833189\n",
      "51 Train Loss 0.634219 Test MSE 92.18175306160079 Test RE 0.48942377676478216\n",
      "52 Train Loss 0.6282569 Test MSE 88.88246060271132 Test RE 0.4805854487645415\n",
      "53 Train Loss 0.5875181 Test MSE 82.35609305544739 Test RE 0.4626051362236761\n",
      "54 Train Loss 0.54375845 Test MSE 80.23127597907748 Test RE 0.4565984492060156\n",
      "55 Train Loss 0.5287192 Test MSE 77.59980417607382 Test RE 0.4490481331198359\n",
      "56 Train Loss 0.51139265 Test MSE 76.8493493708106 Test RE 0.4468715230056307\n",
      "57 Train Loss 0.504297 Test MSE 76.90579732719776 Test RE 0.44703561257852475\n",
      "58 Train Loss 0.5007235 Test MSE 75.911155913498 Test RE 0.4441353945091137\n",
      "59 Train Loss 0.4695815 Test MSE 73.0756318682579 Test RE 0.4357615150074895\n",
      "60 Train Loss 0.46032044 Test MSE 70.21541647171034 Test RE 0.4271484360618167\n",
      "61 Train Loss 0.45192212 Test MSE 69.01430016099528 Test RE 0.4234792416793078\n",
      "62 Train Loss 0.4448113 Test MSE 68.83498184468262 Test RE 0.4229287255156032\n",
      "63 Train Loss 0.4359878 Test MSE 66.8723013986965 Test RE 0.41685567409832375\n",
      "64 Train Loss 0.4141426 Test MSE 61.433861151728 Test RE 0.3995457251959596\n",
      "65 Train Loss 0.40994498 Test MSE 59.23733545105347 Test RE 0.3923379695751602\n",
      "66 Train Loss 0.3874477 Test MSE 55.378180180863176 Test RE 0.37934286729828687\n",
      "67 Train Loss 0.3757177 Test MSE 54.55135483272017 Test RE 0.3765003229914186\n",
      "68 Train Loss 0.37108403 Test MSE 54.78558476088928 Test RE 0.37730775648802717\n",
      "69 Train Loss 0.36959696 Test MSE 54.66006555804528 Test RE 0.37687528390971414\n",
      "70 Train Loss 0.3646646 Test MSE 52.246226256724015 Test RE 0.36845974393556574\n",
      "71 Train Loss 0.3554876 Test MSE 49.18739150925432 Test RE 0.3575110572860704\n",
      "72 Train Loss 0.35257334 Test MSE 47.756247125450436 Test RE 0.35227163733901673\n",
      "73 Train Loss 0.35202792 Test MSE 47.533417990643144 Test RE 0.3514488322763146\n",
      "74 Train Loss 0.3489898 Test MSE 46.74462474054595 Test RE 0.34852057459186003\n",
      "75 Train Loss 0.34521997 Test MSE 45.223439559286696 Test RE 0.3428028135484513\n",
      "76 Train Loss 0.3420174 Test MSE 45.01480882996828 Test RE 0.34201116791106034\n",
      "77 Train Loss 0.33367628 Test MSE 45.710965219633344 Test RE 0.3446456318220391\n",
      "78 Train Loss 0.33187747 Test MSE 46.06498614147154 Test RE 0.34597765834819033\n",
      "79 Train Loss 0.32798204 Test MSE 45.008500560692035 Test RE 0.34198720275169686\n",
      "80 Train Loss 0.32472825 Test MSE 43.29045451436737 Test RE 0.33539659967319935\n",
      "81 Train Loss 0.32349744 Test MSE 42.57917897968789 Test RE 0.3326298531323051\n",
      "82 Train Loss 0.32086745 Test MSE 42.48096467137953 Test RE 0.3322460050603108\n",
      "83 Train Loss 0.31967735 Test MSE 42.698070132409114 Test RE 0.333093920079092\n",
      "84 Train Loss 0.3191837 Test MSE 42.16001440785871 Test RE 0.33098854047484266\n",
      "85 Train Loss 0.31861532 Test MSE 41.557088060065226 Test RE 0.3286133000878168\n",
      "86 Train Loss 0.31572473 Test MSE 41.53063595291718 Test RE 0.3285086982218038\n",
      "87 Train Loss 0.30839658 Test MSE 39.85057422651129 Test RE 0.32179543167132557\n",
      "88 Train Loss 0.30452412 Test MSE 37.92094436938026 Test RE 0.3139078343155425\n",
      "89 Train Loss 0.30165055 Test MSE 36.38800621990774 Test RE 0.30749758738534455\n",
      "90 Train Loss 0.299716 Test MSE 34.94889385956983 Test RE 0.30135562336876937\n",
      "91 Train Loss 0.29252693 Test MSE 32.93661260922634 Test RE 0.2925513108538096\n",
      "92 Train Loss 0.2877939 Test MSE 31.96658215346492 Test RE 0.28821108784824556\n",
      "93 Train Loss 0.28457284 Test MSE 31.059960412917075 Test RE 0.28409463442440336\n",
      "94 Train Loss 0.2809232 Test MSE 29.812116661006456 Test RE 0.27832933922376946\n",
      "95 Train Loss 0.28004143 Test MSE 29.53215394808106 Test RE 0.2770193745380189\n",
      "96 Train Loss 0.27712515 Test MSE 29.87412948714013 Test RE 0.278618668269436\n",
      "97 Train Loss 0.27341795 Test MSE 29.726832461854716 Test RE 0.2779309425633857\n",
      "98 Train Loss 0.24912916 Test MSE 29.649285064606342 Test RE 0.27756819124042575\n",
      "99 Train Loss 0.23571628 Test MSE 28.953059352010584 Test RE 0.27428989790677194\n",
      "100 Train Loss 0.22826819 Test MSE 28.33331115960535 Test RE 0.2713383927007834\n",
      "101 Train Loss 0.22616778 Test MSE 28.005095387047575 Test RE 0.2697622098610222\n",
      "102 Train Loss 0.2240807 Test MSE 27.768741372599298 Test RE 0.26862144461390336\n",
      "103 Train Loss 0.22235113 Test MSE 26.938677986006052 Test RE 0.264576167972015\n",
      "104 Train Loss 0.22146016 Test MSE 26.583820266004306 Test RE 0.262827787123826\n",
      "105 Train Loss 0.22097751 Test MSE 26.70336144874001 Test RE 0.2634180616353834\n",
      "106 Train Loss 0.22093916 Test MSE 26.70878562026736 Test RE 0.26344481392650654\n",
      "107 Train Loss 0.22039944 Test MSE 26.795393842523282 Test RE 0.26387160270998583\n",
      "108 Train Loss 0.2201172 Test MSE 26.63180529280336 Test RE 0.2630648883416559\n",
      "109 Train Loss 0.22006619 Test MSE 26.558156910821435 Test RE 0.2627008928052984\n",
      "110 Train Loss 0.2187163 Test MSE 26.46940469282596 Test RE 0.2622615777128934\n",
      "111 Train Loss 0.21194741 Test MSE 25.90169875960919 Test RE 0.25943388941247597\n",
      "112 Train Loss 0.20247257 Test MSE 24.524998959977815 Test RE 0.2524451790299895\n",
      "113 Train Loss 0.18851972 Test MSE 22.795426987427714 Test RE 0.24338087507867645\n",
      "114 Train Loss 0.18315844 Test MSE 21.975085015030075 Test RE 0.23896146079085007\n",
      "115 Train Loss 0.18076836 Test MSE 21.280486408081746 Test RE 0.23515453452217355\n",
      "116 Train Loss 0.17870237 Test MSE 21.382263711582432 Test RE 0.2357161957051958\n",
      "117 Train Loss 0.1776179 Test MSE 21.524569827240512 Test RE 0.23649927999921214\n",
      "118 Train Loss 0.17642684 Test MSE 21.658636967858683 Test RE 0.23723466202358642\n",
      "119 Train Loss 0.17175013 Test MSE 20.767968569881468 Test RE 0.23230555311799986\n",
      "120 Train Loss 0.1676034 Test MSE 19.88018614513509 Test RE 0.2272860629187699\n",
      "121 Train Loss 0.15959385 Test MSE 19.034030280175795 Test RE 0.22239650628789862\n",
      "122 Train Loss 0.15659937 Test MSE 19.063934020281774 Test RE 0.22257113765040965\n",
      "123 Train Loss 0.15236783 Test MSE 18.40728173731653 Test RE 0.21870434553474866\n",
      "124 Train Loss 0.14844754 Test MSE 17.620476093284775 Test RE 0.21397912231024474\n",
      "125 Train Loss 0.14590757 Test MSE 17.244267154114258 Test RE 0.21168249893435856\n",
      "126 Train Loss 0.14461613 Test MSE 16.757696415550228 Test RE 0.2086746730584044\n",
      "127 Train Loss 0.14371982 Test MSE 16.54806765699002 Test RE 0.207365367845276\n",
      "128 Train Loss 0.1428094 Test MSE 16.316258144617276 Test RE 0.20590783223097728\n",
      "129 Train Loss 0.13953255 Test MSE 15.722688267472833 Test RE 0.20212776991001574\n",
      "130 Train Loss 0.13151437 Test MSE 15.78065599564201 Test RE 0.20250003792118104\n",
      "131 Train Loss 0.12708914 Test MSE 15.897785852806333 Test RE 0.20325016360302947\n",
      "132 Train Loss 0.12528321 Test MSE 15.725433277167621 Test RE 0.2021454137907343\n",
      "133 Train Loss 0.12230426 Test MSE 15.42585950145137 Test RE 0.2002106927211844\n",
      "134 Train Loss 0.11803429 Test MSE 14.954000734082738 Test RE 0.1971248070972082\n",
      "135 Train Loss 0.11377867 Test MSE 14.541396734539926 Test RE 0.19438629593409518\n",
      "136 Train Loss 0.11034039 Test MSE 14.109828989017888 Test RE 0.1914800171026168\n",
      "137 Train Loss 0.10917265 Test MSE 13.757739824484895 Test RE 0.18907587923143093\n",
      "138 Train Loss 0.1085311 Test MSE 13.51316297861201 Test RE 0.18738770396373725\n",
      "139 Train Loss 0.108500786 Test MSE 13.514603571287866 Test RE 0.18739769208273235\n",
      "140 Train Loss 0.10849971 Test MSE 13.514603839348258 Test RE 0.18739769394123668\n",
      "141 Train Loss 0.10849137 Test MSE 13.523806365201262 Test RE 0.18746148562434586\n",
      "142 Train Loss 0.10846627 Test MSE 13.543826155121547 Test RE 0.18760018739152431\n",
      "143 Train Loss 0.10846627 Test MSE 13.543826155121547 Test RE 0.18760018739152431\n",
      "144 Train Loss 0.10846626 Test MSE 13.543826155121547 Test RE 0.18760018739152431\n",
      "145 Train Loss 0.10846627 Test MSE 13.543826155121547 Test RE 0.18760018739152431\n",
      "146 Train Loss 0.1084649 Test MSE 13.54382694684668 Test RE 0.1876001928747526\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 106.19\n",
      "Training time: 106.19\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 3.595709 Test MSE 386.30372848608414 Test RE 1.001906126948032\n",
      "1 Train Loss 3.0653033 Test MSE 388.77473494023906 Test RE 1.0051053843351643\n",
      "2 Train Loss 2.3952835 Test MSE 384.61957544118275 Test RE 0.9997197561828116\n",
      "3 Train Loss 2.3836355 Test MSE 384.25004744500313 Test RE 0.9992393942397922\n",
      "4 Train Loss 2.3827276 Test MSE 384.019891393958 Test RE 0.9989400898635503\n",
      "5 Train Loss 2.3824792 Test MSE 383.98867468908486 Test RE 0.998899487472347\n",
      "6 Train Loss 2.381605 Test MSE 383.76050874828775 Test RE 0.9986026705046347\n",
      "7 Train Loss 2.3808804 Test MSE 383.6587636191476 Test RE 0.9984702836505174\n",
      "8 Train Loss 2.3801613 Test MSE 383.399107815082 Test RE 0.998132349906289\n",
      "9 Train Loss 2.379964 Test MSE 383.30661157557347 Test RE 0.9980119413607018\n",
      "10 Train Loss 2.3799574 Test MSE 383.30535022398414 Test RE 0.9980102992745155\n",
      "11 Train Loss 2.3799531 Test MSE 383.3048338506991 Test RE 0.9980096270349682\n",
      "12 Train Loss 2.3799489 Test MSE 383.301683015811 Test RE 0.9980055251169436\n",
      "13 Train Loss 2.379941 Test MSE 383.30346888865876 Test RE 0.9980078500596351\n",
      "14 Train Loss 2.3799314 Test MSE 383.28548170349103 Test RE 0.9979844331536332\n",
      "15 Train Loss 2.3795764 Test MSE 383.29305747652074 Test RE 0.9979942958624428\n",
      "16 Train Loss 2.379309 Test MSE 383.2953093955519 Test RE 0.99799722756053\n",
      "17 Train Loss 2.3792744 Test MSE 383.2666754512057 Test RE 0.9979599493443712\n",
      "18 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "19 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "20 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "21 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "22 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "23 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "24 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "25 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "26 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "27 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "28 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "29 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "30 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "31 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "32 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "33 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "34 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "35 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "36 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "37 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "38 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "39 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "40 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "41 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "42 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "43 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "44 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "45 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "46 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "47 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "48 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "49 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "50 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "51 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "52 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "53 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "54 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "55 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "56 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "57 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "58 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "59 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "60 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "61 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "62 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "63 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "64 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "65 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "66 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "67 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "68 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "69 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "70 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "71 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "72 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "73 Train Loss 2.3792686 Test MSE 383.2604460609577 Test RE 0.9979518391855243\n",
      "74 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "75 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "76 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "77 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "78 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "79 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "80 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "81 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "82 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "83 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "84 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "85 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "86 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "87 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "88 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "89 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "90 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "91 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "92 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "93 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "94 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "95 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "96 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "97 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "98 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "99 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "100 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "101 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "102 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "103 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "104 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "105 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "106 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "107 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "108 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "109 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "110 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "111 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "112 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "113 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "114 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "115 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "116 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "117 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "118 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "119 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "120 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "121 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "122 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "123 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "124 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "125 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "126 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "127 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "128 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "129 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "130 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "131 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "132 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "133 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "134 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "135 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "136 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "137 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "138 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "139 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "140 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "141 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "142 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "143 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "144 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "145 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "146 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "147 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "148 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "149 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "150 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "151 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "152 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "153 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "154 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "155 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "156 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "157 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "158 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "159 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "160 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "161 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "162 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "163 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "164 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "165 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "166 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "167 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "168 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "169 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "170 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "171 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "172 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "173 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "174 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "175 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "176 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "177 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "178 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "179 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "180 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "181 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "182 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "183 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "184 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "185 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "186 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "187 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "188 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "189 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "190 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "191 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "192 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "193 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "194 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "195 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "196 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "197 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "198 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "199 Train Loss 2.3792682 Test MSE 383.2604437455902 Test RE 0.9979518361710922\n",
      "Training time: 26.94\n",
      "Training time: 26.94\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 4.2385035 Test MSE 387.40501411302006 Test RE 1.0033332417602843\n",
      "1 Train Loss 3.3945117 Test MSE 387.4986087491878 Test RE 1.0034544339689149\n",
      "2 Train Loss 2.9611785 Test MSE 389.07428636432303 Test RE 1.0054925272597635\n",
      "3 Train Loss 2.5076466 Test MSE 385.5144801047777 Test RE 1.0008821178122618\n",
      "4 Train Loss 2.429464 Test MSE 385.6121875740625 Test RE 1.00100894503697\n",
      "5 Train Loss 2.3872662 Test MSE 384.42589481146274 Test RE 0.9994680129717952\n",
      "6 Train Loss 2.3812401 Test MSE 383.79692480434767 Test RE 0.9986500494132845\n",
      "7 Train Loss 2.3810084 Test MSE 383.7015426384509 Test RE 0.9985259482058253\n",
      "8 Train Loss 2.3810036 Test MSE 383.7097219338959 Test RE 0.9985365908464038\n",
      "9 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "10 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "11 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "12 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "13 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "14 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "15 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "16 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "17 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "18 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "19 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "20 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "21 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "22 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "23 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "24 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "25 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "26 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "27 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "28 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "29 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "30 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "31 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "32 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "33 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "34 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "35 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "36 Train Loss 2.3809972 Test MSE 383.7000430197896 Test RE 0.9985239969371407\n",
      "37 Train Loss 2.3809917 Test MSE 383.69518269821054 Test RE 0.9985176727743128\n",
      "38 Train Loss 2.379844 Test MSE 383.5746716601463 Test RE 0.9983608531728598\n",
      "39 Train Loss 2.3792768 Test MSE 383.5216778521401 Test RE 0.9982918851533515\n",
      "40 Train Loss 2.379271 Test MSE 383.52210443283514 Test RE 0.9982924403396063\n",
      "41 Train Loss 2.3792653 Test MSE 383.52335319843615 Test RE 0.9982940655813197\n",
      "42 Train Loss 2.3769224 Test MSE 382.6565152717504 Test RE 0.9971652572903894\n",
      "43 Train Loss 2.375563 Test MSE 382.0743186302002 Test RE 0.9964063949316772\n",
      "44 Train Loss 2.375563 Test MSE 382.0743186302002 Test RE 0.9964063949316772\n",
      "45 Train Loss 2.375561 Test MSE 382.0813718023281 Test RE 0.9964155918248424\n",
      "46 Train Loss 2.375561 Test MSE 382.0813718023281 Test RE 0.9964155918248424\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 137.18\n",
      "Training time: 137.18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 3.892226 Test MSE 388.7204004307782 Test RE 1.0050351459537101\n",
      "1 Train Loss 3.5149627 Test MSE 386.4460603926449 Test RE 1.0020906838986472\n",
      "2 Train Loss 2.8365698 Test MSE 388.14212653999147 Test RE 1.0042873052275172\n",
      "3 Train Loss 2.6139936 Test MSE 389.33746050880075 Test RE 1.0058325328989552\n",
      "4 Train Loss 2.5698004 Test MSE 389.6848760659626 Test RE 1.0062811976000114\n",
      "5 Train Loss 2.426035 Test MSE 386.3925865887143 Test RE 1.0020213502191568\n",
      "6 Train Loss 2.3976574 Test MSE 384.3050319642111 Test RE 0.999310885099268\n",
      "7 Train Loss 2.3937466 Test MSE 383.4483781889932 Test RE 0.9981964825206096\n",
      "8 Train Loss 2.383946 Test MSE 383.32143661744635 Test RE 0.9980312410874942\n",
      "9 Train Loss 2.3807328 Test MSE 383.16901434567626 Test RE 0.9978327949534667\n",
      "10 Train Loss 2.3805513 Test MSE 383.21666646103404 Test RE 0.9978948398519752\n",
      "11 Train Loss 2.3805466 Test MSE 383.2169482064302 Test RE 0.9978952066839141\n",
      "12 Train Loss 2.3805435 Test MSE 383.22383874359105 Test RE 0.9979041781074478\n",
      "13 Train Loss 2.3805435 Test MSE 383.22383874359105 Test RE 0.9979041781074478\n",
      "14 Train Loss 2.3805254 Test MSE 383.2238800962188 Test RE 0.9979042319479905\n",
      "15 Train Loss 2.380138 Test MSE 383.35411345235246 Test RE 0.9980737795473668\n",
      "16 Train Loss 2.3800895 Test MSE 383.391242038978 Test RE 0.9981221110641856\n",
      "17 Train Loss 2.3796365 Test MSE 383.30969785115076 Test RE 0.9980159592064518\n",
      "18 Train Loss 2.377715 Test MSE 383.0997811540141 Test RE 0.997742643783329\n",
      "19 Train Loss 2.377155 Test MSE 382.7691293842596 Test RE 0.9973119771491107\n",
      "20 Train Loss 2.3761978 Test MSE 382.71847861895606 Test RE 0.9972459892176978\n",
      "21 Train Loss 2.375092 Test MSE 382.2489099598039 Test RE 0.9966340261017015\n",
      "22 Train Loss 2.37494 Test MSE 382.01937170441545 Test RE 0.9963347446870583\n",
      "23 Train Loss 2.3749306 Test MSE 381.98192466109316 Test RE 0.9962859111625445\n",
      "24 Train Loss 2.3722107 Test MSE 381.8036137114692 Test RE 0.9960533485567042\n",
      "25 Train Loss 2.3666754 Test MSE 380.36732363000226 Test RE 0.9941780788129005\n",
      "26 Train Loss 2.348321 Test MSE 375.346608632927 Test RE 0.9875948820526376\n",
      "27 Train Loss 2.3409016 Test MSE 370.3650472738354 Test RE 0.9810193632247234\n",
      "28 Train Loss 2.3358853 Test MSE 369.18350289951354 Test RE 0.9794532815239209\n",
      "29 Train Loss 2.3236754 Test MSE 362.7644381878892 Test RE 0.9709009718667182\n",
      "30 Train Loss 2.2919261 Test MSE 358.7119359859994 Test RE 0.965462692672388\n",
      "31 Train Loss 2.2369168 Test MSE 349.07670948986225 Test RE 0.9524079661575922\n",
      "32 Train Loss 2.0928195 Test MSE 323.6713226871586 Test RE 0.9170957773875752\n",
      "33 Train Loss 2.0558167 Test MSE 321.4002603997679 Test RE 0.9138726805959451\n",
      "34 Train Loss 2.055716 Test MSE 321.3359539382016 Test RE 0.9137812512078117\n",
      "35 Train Loss 2.055708 Test MSE 321.3362834116653 Test RE 0.9137817196686127\n",
      "36 Train Loss 2.055708 Test MSE 321.3362834116653 Test RE 0.9137817196686127\n",
      "37 Train Loss 2.0557017 Test MSE 321.35842164357894 Test RE 0.9138131962933518\n",
      "38 Train Loss 2.0539432 Test MSE 319.4922763629675 Test RE 0.9111560524522698\n",
      "39 Train Loss 2.0373218 Test MSE 317.1314078238163 Test RE 0.9077833444713034\n",
      "40 Train Loss 2.011089 Test MSE 310.28757010470343 Test RE 0.8979347348844697\n",
      "41 Train Loss 1.9912415 Test MSE 310.0898294113586 Test RE 0.8976485704488775\n",
      "42 Train Loss 1.9687115 Test MSE 302.96628605808723 Test RE 0.8872780423638812\n",
      "43 Train Loss 1.909966 Test MSE 299.89845222040174 Test RE 0.8827743275460085\n",
      "44 Train Loss 1.8472257 Test MSE 289.7684077037374 Test RE 0.8677369673874048\n",
      "45 Train Loss 1.7668626 Test MSE 266.86028997254556 Test RE 0.8327306681461484\n",
      "46 Train Loss 1.7595962 Test MSE 261.3265423970775 Test RE 0.8240514799930803\n",
      "47 Train Loss 1.7446072 Test MSE 256.160174232927 Test RE 0.8158651594833383\n",
      "48 Train Loss 1.7009392 Test MSE 259.6524789242996 Test RE 0.821407793526272\n",
      "49 Train Loss 1.6559104 Test MSE 250.10234076940824 Test RE 0.8061603994385096\n",
      "50 Train Loss 1.5865058 Test MSE 243.5266698000465 Test RE 0.7954920568150915\n",
      "51 Train Loss 1.5632758 Test MSE 237.2859336508441 Test RE 0.785233066240041\n",
      "52 Train Loss 1.5278456 Test MSE 237.469320351348 Test RE 0.7855364417642107\n",
      "53 Train Loss 1.522047 Test MSE 233.18373276941972 Test RE 0.7784159166806167\n",
      "54 Train Loss 1.520475 Test MSE 232.88223874660244 Test RE 0.7779125289612089\n",
      "55 Train Loss 1.520475 Test MSE 232.88223874660244 Test RE 0.7779125289612089\n",
      "56 Train Loss 1.5204749 Test MSE 232.88223874660244 Test RE 0.7779125289612089\n",
      "57 Train Loss 1.5204749 Test MSE 232.88223874660244 Test RE 0.7779125289612089\n",
      "58 Train Loss 1.5204749 Test MSE 232.88223874660244 Test RE 0.7779125289612089\n",
      "59 Train Loss 1.5204749 Test MSE 232.88223874660244 Test RE 0.7779125289612089\n",
      "60 Train Loss 1.5204749 Test MSE 232.88223874660244 Test RE 0.7779125289612089\n",
      "61 Train Loss 1.5204749 Test MSE 232.88223874660244 Test RE 0.7779125289612089\n",
      "62 Train Loss 1.5204749 Test MSE 232.88223874660244 Test RE 0.7779125289612089\n",
      "63 Train Loss 1.5204749 Test MSE 232.88223874660244 Test RE 0.7779125289612089\n",
      "64 Train Loss 1.5204749 Test MSE 232.88223874660244 Test RE 0.7779125289612089\n",
      "65 Train Loss 1.5204685 Test MSE 232.88194427281377 Test RE 0.7779120371355475\n",
      "66 Train Loss 1.520468 Test MSE 232.8819471656171 Test RE 0.7779120419670653\n",
      "67 Train Loss 1.520468 Test MSE 232.8819471656171 Test RE 0.7779120419670653\n",
      "68 Train Loss 1.520468 Test MSE 232.8819471656171 Test RE 0.7779120419670653\n",
      "69 Train Loss 1.5204676 Test MSE 232.88194952625025 Test RE 0.7779120459097604\n",
      "70 Train Loss 1.5204663 Test MSE 232.8819442322755 Test RE 0.7779120370678411\n",
      "71 Train Loss 1.5204663 Test MSE 232.8819442322755 Test RE 0.7779120370678411\n",
      "72 Train Loss 1.5204536 Test MSE 232.88193637933017 Test RE 0.7779120239519667\n",
      "73 Train Loss 1.5204535 Test MSE 232.88193785573512 Test RE 0.7779120264178366\n",
      "74 Train Loss 1.5204535 Test MSE 232.88193785573512 Test RE 0.7779120264178366\n",
      "75 Train Loss 1.5204535 Test MSE 232.88193785573512 Test RE 0.7779120264178366\n",
      "76 Train Loss 1.5204535 Test MSE 232.88193785573512 Test RE 0.7779120264178366\n",
      "77 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "78 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "79 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "80 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "81 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "82 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "83 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "84 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "85 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "86 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "87 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "88 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "89 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "90 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "91 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "92 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "93 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "94 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "95 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "96 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "97 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "98 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "99 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "100 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "101 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "102 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "103 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "104 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "105 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "106 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "107 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "108 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "109 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "110 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "111 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "112 Train Loss 1.5204533 Test MSE 232.88193780531353 Test RE 0.7779120263336232\n",
      "113 Train Loss 1.520448 Test MSE 232.88195052913298 Test RE 0.7779120475847603\n",
      "114 Train Loss 1.520448 Test MSE 232.88195052913298 Test RE 0.7779120475847603\n",
      "115 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "116 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "117 Train Loss 1.520448 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "118 Train Loss 1.520448 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "119 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "120 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "121 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "122 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "123 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "124 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "125 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "126 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "127 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "128 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "129 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "130 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "131 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "132 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "133 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "134 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "135 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "136 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "137 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "138 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "139 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "140 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "141 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "142 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "143 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "144 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "145 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "146 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "147 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "148 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "149 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "150 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "151 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "152 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "153 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "154 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "155 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "156 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "157 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "158 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "159 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "160 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "161 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "162 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "163 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "164 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "165 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "166 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "167 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "168 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "169 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "170 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "171 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "172 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "173 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "174 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "175 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "176 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "177 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "178 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "179 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "180 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "181 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "182 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "183 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "184 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "185 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "186 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "187 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "188 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "189 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "190 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "191 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "192 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "193 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "194 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "195 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "196 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "197 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "198 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "199 Train Loss 1.5204479 Test MSE 232.8819504570473 Test RE 0.7779120474643639\n",
      "Training time: 58.80\n",
      "Training time: 58.80\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 4.380278 Test MSE 387.7878833956198 Test RE 1.0038289124400437\n",
      "1 Train Loss 3.2573946 Test MSE 387.49510406451805 Test RE 1.0034498961470437\n",
      "2 Train Loss 2.737275 Test MSE 388.7990699446264 Test RE 1.005136840676074\n",
      "3 Train Loss 2.5913744 Test MSE 385.6399738345943 Test RE 1.0010450095017331\n",
      "4 Train Loss 2.386877 Test MSE 383.83661182917103 Test RE 0.9987016814381983\n",
      "5 Train Loss 2.3825076 Test MSE 384.0669758426676 Test RE 0.99900132770936\n",
      "6 Train Loss 2.3825076 Test MSE 384.0669758426676 Test RE 0.99900132770936\n",
      "7 Train Loss 2.3825076 Test MSE 384.0669758426676 Test RE 0.99900132770936\n",
      "8 Train Loss 2.3825037 Test MSE 384.06904230118613 Test RE 0.9990040152510608\n",
      "9 Train Loss 2.3825018 Test MSE 384.0660741692455 Test RE 0.9990001550317658\n",
      "10 Train Loss 2.3824968 Test MSE 384.0680172490677 Test RE 0.9990026821159307\n",
      "11 Train Loss 2.3820393 Test MSE 383.89170496239785 Test RE 0.9987733520773252\n",
      "12 Train Loss 2.3820393 Test MSE 383.89170496239785 Test RE 0.9987733520773252\n",
      "13 Train Loss 2.3820376 Test MSE 383.888698305753 Test RE 0.9987694408513507\n",
      "14 Train Loss 2.3820364 Test MSE 383.87053855317 Test RE 0.9987458173108366\n",
      "15 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "16 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "17 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "18 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "19 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "20 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "21 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "22 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "23 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "24 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "25 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "26 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "27 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "28 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "29 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "30 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "31 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "32 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "33 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "34 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "35 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "36 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "37 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "38 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "39 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "40 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "41 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "42 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "43 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "44 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "45 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "46 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "47 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "48 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "49 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "50 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "51 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "52 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "53 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "54 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "55 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "56 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "57 Train Loss 2.3820317 Test MSE 383.8635850574985 Test RE 0.9987367715447903\n",
      "58 Train Loss 2.382027 Test MSE 383.88095179549674 Test RE 0.9987593636899458\n",
      "59 Train Loss 2.3813136 Test MSE 383.8427303939248 Test RE 0.9987096413309858\n",
      "60 Train Loss 2.3808973 Test MSE 383.7652711903675 Test RE 0.9986088667813698\n",
      "61 Train Loss 2.3807116 Test MSE 383.75514161031964 Test RE 0.9985956874293503\n",
      "62 Train Loss 2.380693 Test MSE 383.75243187112056 Test RE 0.9985921618236169\n",
      "63 Train Loss 2.3806744 Test MSE 383.74811571983247 Test RE 0.9985865461107162\n",
      "64 Train Loss 2.3806705 Test MSE 383.7483785008746 Test RE 0.9985868880141128\n",
      "65 Train Loss 2.3806665 Test MSE 383.74220292115257 Test RE 0.9985788529602958\n",
      "66 Train Loss 2.3806612 Test MSE 383.74079757777196 Test RE 0.9985770244573904\n",
      "67 Train Loss 2.3806536 Test MSE 383.73494318694475 Test RE 0.9985694072291643\n",
      "68 Train Loss 2.3806458 Test MSE 383.73216906746615 Test RE 0.9985657977639608\n",
      "69 Train Loss 2.3806179 Test MSE 383.7321961970692 Test RE 0.9985658330629209\n",
      "70 Train Loss 2.3806179 Test MSE 383.7321961970692 Test RE 0.9985658330629209\n",
      "71 Train Loss 2.3806179 Test MSE 383.7321961970692 Test RE 0.9985658330629209\n",
      "72 Train Loss 2.3806179 Test MSE 383.7321961970692 Test RE 0.9985658330629209\n",
      "73 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "74 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "75 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "76 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "77 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "78 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "79 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "80 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "81 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "82 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "83 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "84 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "85 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "86 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "87 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "88 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "89 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "90 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "91 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "92 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "93 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "94 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "95 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "96 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "97 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "98 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "99 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "100 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "101 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "102 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "103 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "104 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "105 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "106 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "107 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "108 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "109 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "110 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "111 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "112 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "113 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "114 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "115 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "116 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "117 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "118 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "119 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "120 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "121 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "122 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "123 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "124 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "125 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "126 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "127 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "128 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "129 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "130 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "131 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "132 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "133 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "134 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "135 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "136 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "137 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "138 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "139 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "140 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "141 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "142 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "143 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "144 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "145 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "146 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "147 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "148 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "149 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "150 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "151 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "152 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "153 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "154 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "155 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "156 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "157 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "158 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "159 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "160 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "161 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "162 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "163 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "164 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "165 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "166 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "167 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "168 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "169 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "170 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "171 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "172 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "173 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "174 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "175 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "176 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "177 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "178 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "179 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "180 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "181 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "182 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "183 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "184 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "185 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "186 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "187 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "188 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "189 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "190 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "191 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "192 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "193 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "194 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "195 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "196 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "197 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "198 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "199 Train Loss 2.3806174 Test MSE 383.7321965130174 Test RE 0.9985658334740086\n",
      "Training time: 33.68\n",
      "Training time: 33.68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 4.148699 Test MSE 385.54132039592065 Test RE 1.0009169589158566\n",
      "1 Train Loss 3.010566 Test MSE 387.72559882166837 Test RE 1.003748294182555\n",
      "2 Train Loss 2.6901886 Test MSE 387.7551192563601 Test RE 1.0037865048682413\n",
      "3 Train Loss 2.3996756 Test MSE 385.6854650153988 Test RE 1.0011040508093265\n",
      "4 Train Loss 2.3927462 Test MSE 385.35497533437274 Test RE 1.00067504129867\n",
      "5 Train Loss 2.3818483 Test MSE 383.66713618801555 Test RE 0.9984811783783288\n",
      "6 Train Loss 2.380846 Test MSE 383.4125711555467 Test RE 0.99814987482668\n",
      "7 Train Loss 2.3797896 Test MSE 383.395965221642 Test RE 0.9981282592204491\n",
      "8 Train Loss 2.377336 Test MSE 383.08942457571857 Test RE 0.9977291573887207\n",
      "9 Train Loss 2.375623 Test MSE 382.6881779838279 Test RE 0.9972065113943708\n",
      "10 Train Loss 2.3697844 Test MSE 380.9485822192273 Test RE 0.994937415788397\n",
      "11 Train Loss 2.3469114 Test MSE 377.0606533778891 Test RE 0.989847271749561\n",
      "12 Train Loss 2.2295308 Test MSE 352.61076466088866 Test RE 0.9572169179654346\n",
      "13 Train Loss 2.1668746 Test MSE 343.62680617075205 Test RE 0.9449440621191597\n",
      "14 Train Loss 2.0281758 Test MSE 318.3491222617051 Test RE 0.9095245182360104\n",
      "15 Train Loss 2.0007534 Test MSE 315.93387547573315 Test RE 0.9060677652262199\n",
      "16 Train Loss 1.9568801 Test MSE 308.9434997494562 Test RE 0.8959878356541451\n",
      "17 Train Loss 1.9164559 Test MSE 299.8217069782375 Test RE 0.8826613675358927\n",
      "18 Train Loss 1.8925941 Test MSE 294.6106888595083 Test RE 0.8749572463614725\n",
      "19 Train Loss 1.8818517 Test MSE 296.031283328143 Test RE 0.8770642042974441\n",
      "20 Train Loss 1.832547 Test MSE 292.2003678849387 Test RE 0.8713707182726516\n",
      "21 Train Loss 1.767729 Test MSE 275.14321592788093 Test RE 0.845555243543291\n",
      "22 Train Loss 1.6759454 Test MSE 259.3471310466582 Test RE 0.8209246691022773\n",
      "23 Train Loss 1.5969665 Test MSE 248.37190984122927 Test RE 0.8033666905919579\n",
      "24 Train Loss 1.5725214 Test MSE 245.74529789610736 Test RE 0.7991074708732958\n",
      "25 Train Loss 1.5256306 Test MSE 236.2284638466035 Test RE 0.7834814085653302\n",
      "26 Train Loss 1.5035149 Test MSE 234.7486774115471 Test RE 0.7810236045586404\n",
      "27 Train Loss 1.493872 Test MSE 237.075991163458 Test RE 0.7848856156749019\n",
      "28 Train Loss 1.4751707 Test MSE 233.96917542395568 Test RE 0.779725800243079\n",
      "29 Train Loss 1.4572123 Test MSE 227.63078487384337 Test RE 0.7690916220040505\n",
      "30 Train Loss 1.4508972 Test MSE 226.43534688796487 Test RE 0.7670694622719421\n",
      "31 Train Loss 1.4251508 Test MSE 221.8471270905633 Test RE 0.7592581930510549\n",
      "32 Train Loss 1.4023498 Test MSE 217.9796169121204 Test RE 0.7526109366489533\n",
      "33 Train Loss 1.3774118 Test MSE 211.56454932573112 Test RE 0.74145369041886\n",
      "34 Train Loss 1.3498008 Test MSE 206.55080447865006 Test RE 0.7326153736694859\n",
      "35 Train Loss 1.3434248 Test MSE 203.51010044014637 Test RE 0.7272028409116585\n",
      "36 Train Loss 1.3343841 Test MSE 202.0515866971286 Test RE 0.724592300912429\n",
      "37 Train Loss 1.3209841 Test MSE 194.28466074799653 Test RE 0.7105290507013057\n",
      "38 Train Loss 1.2888533 Test MSE 187.77430337743237 Test RE 0.6985229223619457\n",
      "39 Train Loss 1.2542388 Test MSE 182.32269153452762 Test RE 0.688308201298537\n",
      "40 Train Loss 1.2253842 Test MSE 178.4391851222699 Test RE 0.680938199674402\n",
      "41 Train Loss 1.1984507 Test MSE 174.79366812285141 Test RE 0.6739465131196085\n",
      "42 Train Loss 1.167361 Test MSE 175.59731450289695 Test RE 0.6754940335902199\n",
      "43 Train Loss 1.1332349 Test MSE 178.78745387894205 Test RE 0.6816023864634023\n",
      "44 Train Loss 1.1198533 Test MSE 176.84955032728286 Test RE 0.677898327565816\n",
      "45 Train Loss 1.0981609 Test MSE 173.04039856203212 Test RE 0.6705579810538538\n",
      "46 Train Loss 1.0770549 Test MSE 170.71436348626204 Test RE 0.6660358622462248\n",
      "47 Train Loss 1.0464643 Test MSE 164.5264320251163 Test RE 0.6538534540804679\n",
      "48 Train Loss 1.0279676 Test MSE 160.62606395303442 Test RE 0.6460566352451876\n",
      "49 Train Loss 1.0186353 Test MSE 158.5503710345766 Test RE 0.6418687229829794\n",
      "50 Train Loss 1.0096295 Test MSE 155.91710644433354 Test RE 0.6365162063930625\n",
      "51 Train Loss 0.99850214 Test MSE 151.79697008120928 Test RE 0.6280498757380217\n",
      "52 Train Loss 0.978161 Test MSE 147.35565975846413 Test RE 0.6187938563024172\n",
      "53 Train Loss 0.96780306 Test MSE 149.84807263728737 Test RE 0.6240051345210761\n",
      "54 Train Loss 0.95342004 Test MSE 147.5054871304518 Test RE 0.6191083630630299\n",
      "55 Train Loss 0.89102244 Test MSE 139.90247997464007 Test RE 0.6029416555064582\n",
      "56 Train Loss 0.8470478 Test MSE 127.21415447130352 Test RE 0.574950294015749\n",
      "57 Train Loss 0.8257917 Test MSE 122.4942481741616 Test RE 0.5641835650376705\n",
      "58 Train Loss 0.81938946 Test MSE 120.66243338053042 Test RE 0.5599491919197354\n",
      "59 Train Loss 0.8023711 Test MSE 120.50279454156744 Test RE 0.5595786572718733\n",
      "60 Train Loss 0.7951041 Test MSE 117.80836280110394 Test RE 0.5532872250442261\n",
      "61 Train Loss 0.769794 Test MSE 114.59952446851041 Test RE 0.5457000458754813\n",
      "62 Train Loss 0.757504 Test MSE 113.02903260755524 Test RE 0.5419479624495487\n",
      "63 Train Loss 0.75399786 Test MSE 113.40104801460751 Test RE 0.5428390935426961\n",
      "64 Train Loss 0.7389837 Test MSE 106.74469130876055 Test RE 0.5266665370471295\n",
      "65 Train Loss 0.69141424 Test MSE 100.87233762159792 Test RE 0.511974847351262\n",
      "66 Train Loss 0.6751816 Test MSE 96.64626671467549 Test RE 0.5011354480305541\n",
      "67 Train Loss 0.6724602 Test MSE 95.6574893834867 Test RE 0.4985653266315719\n",
      "68 Train Loss 0.6495525 Test MSE 96.28021212143571 Test RE 0.5001855046476253\n",
      "69 Train Loss 0.61834043 Test MSE 90.30095938056722 Test RE 0.48440516448582704\n",
      "70 Train Loss 0.60859954 Test MSE 88.5511105935647 Test RE 0.47968881133529345\n",
      "71 Train Loss 0.60379964 Test MSE 88.83263381139315 Test RE 0.4804507237151182\n",
      "72 Train Loss 0.59062034 Test MSE 88.55351742137356 Test RE 0.47969533028529887\n",
      "73 Train Loss 0.5728043 Test MSE 85.88477912963461 Test RE 0.4724117424690921\n",
      "74 Train Loss 0.5672517 Test MSE 83.45328826563647 Test RE 0.46567648626271885\n",
      "75 Train Loss 0.5641309 Test MSE 81.12209282058069 Test RE 0.45912628372376685\n",
      "76 Train Loss 0.5568901 Test MSE 80.38798720583611 Test RE 0.4570441556694366\n",
      "77 Train Loss 0.5519673 Test MSE 79.02257564948087 Test RE 0.45314602319407243\n",
      "78 Train Loss 0.54361176 Test MSE 78.94982549410895 Test RE 0.452937386394716\n",
      "79 Train Loss 0.5391163 Test MSE 80.55432220433921 Test RE 0.45751675833508015\n",
      "80 Train Loss 0.5364812 Test MSE 80.60489142050046 Test RE 0.45766034239934517\n",
      "81 Train Loss 0.53258276 Test MSE 80.04997400928302 Test RE 0.45608226012171404\n",
      "82 Train Loss 0.52967316 Test MSE 79.79000782258741 Test RE 0.4553410832115131\n",
      "83 Train Loss 0.529031 Test MSE 79.69634471131775 Test RE 0.45507374907371506\n",
      "84 Train Loss 0.5286303 Test MSE 79.65102901754382 Test RE 0.45494435220486473\n",
      "85 Train Loss 0.5278506 Test MSE 79.22755232831146 Test RE 0.45373335036541607\n",
      "86 Train Loss 0.5268864 Test MSE 79.51827971524347 Test RE 0.4545650807089601\n",
      "87 Train Loss 0.523015 Test MSE 79.52764476407211 Test RE 0.45459184750308224\n",
      "88 Train Loss 0.5123751 Test MSE 78.12698735563521 Test RE 0.45057088128202627\n",
      "89 Train Loss 0.499037 Test MSE 74.44400952959079 Test RE 0.4398225179817017\n",
      "90 Train Loss 0.49422267 Test MSE 73.48188911287039 Test RE 0.43697112416298645\n",
      "91 Train Loss 0.4788503 Test MSE 69.11956632631151 Test RE 0.42380208093296967\n",
      "92 Train Loss 0.45844546 Test MSE 67.66627941388852 Test RE 0.4193230455274622\n",
      "93 Train Loss 0.44669434 Test MSE 65.54577643561731 Test RE 0.41270044646720627\n",
      "94 Train Loss 0.43751276 Test MSE 64.91551615926787 Test RE 0.4107114777676977\n",
      "95 Train Loss 0.4236177 Test MSE 60.53277327271875 Test RE 0.3966047106283014\n",
      "96 Train Loss 0.41595986 Test MSE 58.49330769964939 Test RE 0.38986627884282854\n",
      "97 Train Loss 0.41271868 Test MSE 56.584544252191684 Test RE 0.38345242944796903\n",
      "98 Train Loss 0.40985036 Test MSE 56.21081456484708 Test RE 0.38218401797053775\n",
      "99 Train Loss 0.40672874 Test MSE 56.77931276026133 Test RE 0.38411179943576396\n",
      "100 Train Loss 0.40423936 Test MSE 55.81009573056905 Test RE 0.38081931390319784\n",
      "101 Train Loss 0.40300784 Test MSE 54.7167725253575 Test RE 0.37707072745811077\n",
      "102 Train Loss 0.39608288 Test MSE 53.20095863623298 Test RE 0.3718110662014203\n",
      "103 Train Loss 0.38959908 Test MSE 51.15741190125674 Test RE 0.36460016850947896\n",
      "104 Train Loss 0.38300857 Test MSE 49.98307089732096 Test RE 0.3603910939612067\n",
      "105 Train Loss 0.37427813 Test MSE 48.48737799370943 Test RE 0.3549579703650548\n",
      "106 Train Loss 0.36827308 Test MSE 47.270215708768994 Test RE 0.35047445945496103\n",
      "107 Train Loss 0.36128187 Test MSE 46.93243224408474 Test RE 0.3492200043783432\n",
      "108 Train Loss 0.35300463 Test MSE 46.01964962967921 Test RE 0.3458073632635219\n",
      "109 Train Loss 0.34525144 Test MSE 45.267432698193915 Test RE 0.3429695114605327\n",
      "110 Train Loss 0.33963376 Test MSE 44.898706306342994 Test RE 0.3415698242973645\n",
      "111 Train Loss 0.3372029 Test MSE 44.62794322859642 Test RE 0.340538343000846\n",
      "112 Train Loss 0.33452958 Test MSE 44.56281072990818 Test RE 0.34028975198133327\n",
      "113 Train Loss 0.3304093 Test MSE 44.57613266461336 Test RE 0.3403406125422726\n",
      "114 Train Loss 0.326405 Test MSE 45.007900847232804 Test RE 0.3419849243486283\n",
      "115 Train Loss 0.32316175 Test MSE 45.08671830878784 Test RE 0.3422842339461458\n",
      "116 Train Loss 0.32232216 Test MSE 45.11840897159354 Test RE 0.34240450560528385\n",
      "117 Train Loss 0.3213877 Test MSE 44.87691896597006 Test RE 0.34148693993765994\n",
      "118 Train Loss 0.31913632 Test MSE 44.073886522332 Test RE 0.33841784616183107\n",
      "119 Train Loss 0.31804973 Test MSE 43.69554992598157 Test RE 0.3369622017718768\n",
      "120 Train Loss 0.31582376 Test MSE 43.232033922333315 Test RE 0.33517021393567464\n",
      "121 Train Loss 0.31429374 Test MSE 42.8788739069654 Test RE 0.3337984134858239\n",
      "122 Train Loss 0.31337935 Test MSE 42.41359014589254 Test RE 0.3319824305424473\n",
      "123 Train Loss 0.30802366 Test MSE 41.746545853133085 Test RE 0.3293615184569201\n",
      "124 Train Loss 0.3062656 Test MSE 41.026854865253696 Test RE 0.32651015647989784\n",
      "125 Train Loss 0.30351746 Test MSE 40.16147798314587 Test RE 0.32304827472431247\n",
      "126 Train Loss 0.2994259 Test MSE 39.79447284575059 Test RE 0.3215688411309201\n",
      "127 Train Loss 0.2953024 Test MSE 39.05923070745651 Test RE 0.31858434069930697\n",
      "128 Train Loss 0.29290175 Test MSE 38.43965917165744 Test RE 0.31604749080371375\n",
      "129 Train Loss 0.29184023 Test MSE 38.159570941030246 Test RE 0.3148939552935799\n",
      "130 Train Loss 0.2895888 Test MSE 37.51095398939296 Test RE 0.31220628188294497\n",
      "131 Train Loss 0.28809407 Test MSE 36.99609442170196 Test RE 0.3100562728473155\n",
      "132 Train Loss 0.28665996 Test MSE 36.8377210433675 Test RE 0.30939191455586634\n",
      "133 Train Loss 0.28387856 Test MSE 36.548857669549065 Test RE 0.3081764771875989\n",
      "134 Train Loss 0.27254903 Test MSE 36.05072882222209 Test RE 0.30606918498611785\n",
      "135 Train Loss 0.26196063 Test MSE 35.36349146080848 Test RE 0.3031378393821393\n",
      "136 Train Loss 0.24861312 Test MSE 34.14393211111481 Test RE 0.2978649137814442\n",
      "137 Train Loss 0.24597561 Test MSE 34.27838230674802 Test RE 0.2984507960474969\n",
      "138 Train Loss 0.24250054 Test MSE 33.90855499954218 Test RE 0.2968364465421868\n",
      "139 Train Loss 0.24136671 Test MSE 33.7366431178095 Test RE 0.2960830296678963\n",
      "140 Train Loss 0.24052146 Test MSE 33.67719277246468 Test RE 0.2958220374915066\n",
      "141 Train Loss 0.24043156 Test MSE 33.69545764098711 Test RE 0.29590224634760853\n",
      "142 Train Loss 0.24043156 Test MSE 33.69545764098711 Test RE 0.29590224634760853\n",
      "143 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "144 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "145 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "146 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "147 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "148 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "149 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "150 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "151 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "152 Train Loss 0.24041364 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "153 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "154 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "155 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "156 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "157 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "158 Train Loss 0.24041365 Test MSE 33.69540460281126 Test RE 0.2959020134657507\n",
      "159 Train Loss 0.24041158 Test MSE 33.69199926307879 Test RE 0.29588706079853466\n",
      "160 Train Loss 0.24040309 Test MSE 33.681659831683895 Test RE 0.2958416562695782\n",
      "161 Train Loss 0.24000907 Test MSE 33.519707933483026 Test RE 0.2951295498737848\n",
      "162 Train Loss 0.24000722 Test MSE 33.51621741365793 Test RE 0.29511418305784126\n",
      "163 Train Loss 0.23996441 Test MSE 33.509022174441064 Test RE 0.2950825038994676\n",
      "164 Train Loss 0.23937264 Test MSE 33.58993236523822 Test RE 0.2954385391608192\n",
      "165 Train Loss 0.23932223 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "166 Train Loss 0.23932223 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "167 Train Loss 0.23932223 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "168 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "169 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "170 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "171 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "172 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "173 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "174 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "175 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "176 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "177 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "178 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "179 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "180 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "181 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "182 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "183 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "184 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "185 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "186 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "187 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "188 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "189 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "190 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "191 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "192 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "193 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "194 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "195 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "196 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "197 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "198 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "199 Train Loss 0.23932222 Test MSE 33.57996999804973 Test RE 0.2953947241652503\n",
      "Training time: 89.36\n",
      "Training time: 89.36\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 4.2847524 Test MSE 384.5635496539422 Test RE 0.999646941212164\n",
      "1 Train Loss 3.3201675 Test MSE 385.9789017465363 Test RE 1.0014848077646987\n",
      "2 Train Loss 2.3847535 Test MSE 384.0836098145487 Test RE 0.9990229608894025\n",
      "3 Train Loss 2.382714 Test MSE 384.06453744621683 Test RE 0.9989981564328492\n",
      "4 Train Loss 2.3807938 Test MSE 383.76278499527655 Test RE 0.9986056320690732\n",
      "5 Train Loss 2.3805683 Test MSE 383.6135100836723 Test RE 0.9984113958481694\n",
      "6 Train Loss 2.3805623 Test MSE 383.60843670390767 Test RE 0.9984047937124431\n",
      "7 Train Loss 2.3805528 Test MSE 383.60375435285454 Test RE 0.9983987003949405\n",
      "8 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "9 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "10 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "11 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "12 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "13 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "14 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "15 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "16 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "17 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "18 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "19 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "20 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "21 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "22 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "23 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "24 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "25 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "26 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "27 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "28 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "29 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "30 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "31 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "32 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "33 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "34 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "35 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "36 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "37 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "38 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "39 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "40 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "41 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "42 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "43 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "44 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "45 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "46 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "47 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "48 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "49 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "50 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "51 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "52 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "53 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "54 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "55 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "56 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "57 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "58 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "59 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "60 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "61 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "62 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "63 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "64 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "65 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "66 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "67 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "68 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "69 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "70 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "71 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "72 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "73 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "74 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "75 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "76 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "77 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "78 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "79 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "80 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "81 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "82 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "83 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "84 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "85 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "86 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "87 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "88 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "89 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "90 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "91 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "92 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "93 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "94 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "95 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "96 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "97 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "98 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "99 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "100 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "101 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "102 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "103 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "104 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "105 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "106 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "107 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "108 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "109 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "110 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "111 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "112 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "113 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "114 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "115 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "116 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "117 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "118 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "119 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "120 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "121 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "122 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "123 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "124 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "125 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "126 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "127 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "128 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "129 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "130 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "131 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "132 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "133 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "134 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "135 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "136 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "137 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "138 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "139 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "140 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "141 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "142 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "143 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "144 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "145 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "146 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "147 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "148 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "149 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "150 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "151 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "152 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "153 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "154 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "155 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "156 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "157 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "158 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "159 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "160 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "161 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "162 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "163 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "164 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "165 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "166 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "167 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "168 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "169 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "170 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "171 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "172 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "173 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "174 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "175 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "176 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "177 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "178 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "179 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "180 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "181 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "182 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "183 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "184 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "185 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "186 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "187 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "188 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "189 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "190 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "191 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "192 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "193 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "194 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "195 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "196 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "197 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "198 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "199 Train Loss 2.3805234 Test MSE 383.60039005402666 Test RE 0.9983943222848413\n",
      "Training time: 10.89\n",
      "Training time: 10.89\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 4.2912297 Test MSE 387.6472097717854 Test RE 1.0036468218362573\n",
      "1 Train Loss 3.392138 Test MSE 385.2525037779021 Test RE 1.0005419853460478\n",
      "2 Train Loss 2.8308501 Test MSE 388.2609028550061 Test RE 1.00444095567262\n",
      "3 Train Loss 2.4350796 Test MSE 384.46777678827647 Test RE 0.9995224559173046\n",
      "4 Train Loss 2.396577 Test MSE 384.48517101917014 Test RE 0.9995450660406892\n",
      "5 Train Loss 2.3892198 Test MSE 384.7617817715049 Test RE 0.9999045535104745\n",
      "6 Train Loss 2.3839636 Test MSE 384.207404653637 Test RE 0.9991839465702979\n",
      "7 Train Loss 2.382626 Test MSE 383.7808499914955 Test RE 0.998629135643911\n",
      "8 Train Loss 2.3813071 Test MSE 383.47923943303175 Test RE 0.9982366508551076\n",
      "9 Train Loss 2.3804305 Test MSE 383.6375449464298 Test RE 0.9984426725164626\n",
      "10 Train Loss 2.3804305 Test MSE 383.6375449464298 Test RE 0.9984426725164626\n",
      "11 Train Loss 2.3804305 Test MSE 383.6375449464298 Test RE 0.9984426725164626\n",
      "12 Train Loss 2.3804262 Test MSE 383.63587601393084 Test RE 0.9984405007592159\n",
      "13 Train Loss 2.3804185 Test MSE 383.63699086961327 Test RE 0.998441951504997\n",
      "14 Train Loss 2.3801658 Test MSE 383.6074564444157 Test RE 0.9984035180674004\n",
      "15 Train Loss 2.3801658 Test MSE 383.6074564444157 Test RE 0.9984035180674004\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 124.34\n",
      "Training time: 124.34\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    alpha_val = []\n",
    "    \n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "    \n",
    "    \n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.5, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "   \n",
    "\n",
    "    start_time = time.time()\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    alpha_full.append(alpha_val)    \n",
    "    \n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"alpha\": alpha_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
