{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(3.0*x) + np.exp(-4.0*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"high\"\n",
    "label = \"1D_SODE_atanh_\" + level\n",
    "loss_thresh = 0.005\n",
    "\n",
    "u_coeff = 12.0\n",
    "fo_val = -1.0\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(1.0)\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "    \n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,0)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 4.787052 Test MSE 14259.161147363857 Test RE 1.0000289032122887\n",
      "1 Train Loss 4.43851 Test MSE 14260.739226219757 Test RE 1.0000842388940412\n",
      "2 Train Loss 3.962456 Test MSE 14266.236446134662 Test RE 1.0002769762128703\n",
      "3 Train Loss 3.0558054 Test MSE 14260.697583232066 Test RE 1.0000827787128612\n",
      "4 Train Loss 2.888949 Test MSE 14264.134949746807 Test RE 1.0002033003040913\n",
      "5 Train Loss 2.8503926 Test MSE 14263.521196964013 Test RE 1.000181781853633\n",
      "6 Train Loss 2.8300574 Test MSE 14261.754860086796 Test RE 1.0001198506993918\n",
      "7 Train Loss 2.829384 Test MSE 14261.859386189459 Test RE 1.0001235156915218\n",
      "8 Train Loss 2.8293 Test MSE 14261.895784112918 Test RE 1.0001247919064586\n",
      "9 Train Loss 2.8292973 Test MSE 14261.904271243238 Test RE 1.000125089489203\n",
      "10 Train Loss 2.8292973 Test MSE 14261.904271243238 Test RE 1.000125089489203\n",
      "11 Train Loss 2.8292973 Test MSE 14261.904271243238 Test RE 1.000125089489203\n",
      "12 Train Loss 2.8292902 Test MSE 14261.902936891522 Test RE 1.0001250427030715\n",
      "13 Train Loss 2.8292816 Test MSE 14261.894024582365 Test RE 1.00012473021234\n",
      "14 Train Loss 2.8292735 Test MSE 14261.90204992703 Test RE 1.0001250116035956\n",
      "15 Train Loss 2.8289201 Test MSE 14261.875892943697 Test RE 1.0001240944655745\n",
      "16 Train Loss 2.8288915 Test MSE 14261.862004708144 Test RE 1.0001236075043045\n",
      "17 Train Loss 2.8288836 Test MSE 14261.860533739682 Test RE 1.0001235559279282\n",
      "18 Train Loss 2.8288836 Test MSE 14261.860533739682 Test RE 1.0001235559279282\n",
      "19 Train Loss 2.8288836 Test MSE 14261.860533739682 Test RE 1.0001235559279282\n",
      "20 Train Loss 2.8288836 Test MSE 14261.860533739682 Test RE 1.0001235559279282\n",
      "21 Train Loss 2.8288836 Test MSE 14261.860533739682 Test RE 1.0001235559279282\n",
      "22 Train Loss 2.8288836 Test MSE 14261.860533739682 Test RE 1.0001235559279282\n",
      "23 Train Loss 2.8288836 Test MSE 14261.860533739682 Test RE 1.0001235559279282\n",
      "24 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "25 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "26 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "27 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "28 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "29 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "30 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "31 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "32 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "33 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "34 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "35 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "36 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "37 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "38 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "39 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "40 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "41 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "42 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "43 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "44 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "45 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "46 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "47 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "48 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "49 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "50 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "51 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "52 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "53 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "54 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "55 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "56 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "57 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "58 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "59 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "60 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "61 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "62 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "63 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "64 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "65 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "66 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "67 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "68 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "69 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "70 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "71 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "72 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "73 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "74 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "75 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "76 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "77 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "78 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "79 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "80 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "81 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "82 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "83 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "84 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "85 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "86 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "87 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "88 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "89 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "90 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "91 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "92 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "93 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "94 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "95 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "96 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "97 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "98 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "99 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "100 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "101 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "102 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "103 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "104 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "105 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "106 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "107 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "108 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "109 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "110 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "111 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "112 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "113 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "114 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "115 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "116 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "117 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "118 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "119 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "120 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "121 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "122 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "123 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "124 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "125 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "126 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "127 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "128 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "129 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "130 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "131 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "132 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "133 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "134 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "135 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "136 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "137 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "138 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "139 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "140 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "141 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "142 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "143 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "144 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "145 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "146 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "147 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "148 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "149 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "150 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "151 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "152 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "153 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "154 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "155 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "156 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "157 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "158 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "159 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "160 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "161 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "162 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "163 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "164 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "165 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "166 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "167 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "168 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "169 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "170 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "171 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "172 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "173 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "174 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "175 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "176 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "177 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "178 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "179 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "180 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "181 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "182 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "183 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "184 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "185 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "186 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "187 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "188 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "189 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "190 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "191 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "192 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "193 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "194 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "195 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "196 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "197 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "198 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "199 Train Loss 2.8288834 Test MSE 14261.860595523347 Test RE 1.0001235580942407\n",
      "Training time: 35.92\n",
      "Training time: 35.92\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 4.862779 Test MSE 14258.655231772256 Test RE 1.0000111625227541\n",
      "1 Train Loss 4.418073 Test MSE 14259.522893735755 Test RE 1.0000415881987836\n",
      "2 Train Loss 3.9042985 Test MSE 14260.930239416644 Test RE 1.0000909366060227\n",
      "3 Train Loss 3.3658555 Test MSE 14255.916657919715 Test RE 0.9999151248569698\n",
      "4 Train Loss 2.981505 Test MSE 14254.43804734314 Test RE 0.9998632683733237\n",
      "5 Train Loss 2.842021 Test MSE 14258.345643781331 Test RE 1.000000306199974\n",
      "6 Train Loss 2.8345828 Test MSE 14258.11494823427 Test RE 0.9999922163220661\n",
      "7 Train Loss 2.8308585 Test MSE 14257.173123412533 Test RE 0.999959188357015\n",
      "8 Train Loss 2.8279908 Test MSE 14258.498634608684 Test RE 1.0000056711443943\n",
      "9 Train Loss 2.8277423 Test MSE 14258.564753108418 Test RE 1.0000079897194332\n",
      "10 Train Loss 2.8277423 Test MSE 14258.564753108418 Test RE 1.0000079897194332\n",
      "11 Train Loss 2.8277423 Test MSE 14258.564753108418 Test RE 1.0000079897194332\n",
      "12 Train Loss 2.8277423 Test MSE 14258.564753108418 Test RE 1.0000079897194332\n",
      "13 Train Loss 2.8277423 Test MSE 14258.564753108418 Test RE 1.0000079897194332\n",
      "14 Train Loss 2.8277364 Test MSE 14258.598144122723 Test RE 1.0000091606388815\n",
      "15 Train Loss 2.8277364 Test MSE 14258.598144122723 Test RE 1.0000091606388815\n",
      "16 Train Loss 2.8277364 Test MSE 14258.598144122723 Test RE 1.0000091606388815\n",
      "17 Train Loss 2.827736 Test MSE 14258.598154202993 Test RE 1.000009160992365\n",
      "18 Train Loss 2.827736 Test MSE 14258.598154202993 Test RE 1.000009160992365\n",
      "19 Train Loss 2.827736 Test MSE 14258.598154202993 Test RE 1.000009160992365\n",
      "20 Train Loss 2.8277354 Test MSE 14258.59817941825 Test RE 1.0000091618765852\n",
      "21 Train Loss 2.8277354 Test MSE 14258.59817941825 Test RE 1.0000091618765852\n",
      "22 Train Loss 2.8277354 Test MSE 14258.59817941825 Test RE 1.0000091618765852\n",
      "23 Train Loss 2.8277354 Test MSE 14258.59817941825 Test RE 1.0000091618765852\n",
      "24 Train Loss 2.8277354 Test MSE 14258.59817941825 Test RE 1.0000091618765852\n",
      "25 Train Loss 2.827734 Test MSE 14258.643803941588 Test RE 1.000010761785085\n",
      "26 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "27 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "28 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "29 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "30 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "31 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "32 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "33 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "34 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "35 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "36 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "37 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "38 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "39 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "40 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "41 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "42 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "43 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "44 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "45 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "46 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "47 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "48 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "49 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "50 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "51 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "52 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "53 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "54 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "55 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "56 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "57 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "58 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "59 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "60 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "61 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "62 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "63 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "64 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "65 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "66 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "67 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "68 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "69 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "70 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "71 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "72 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "73 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "74 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "75 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "76 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "77 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "78 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "79 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "80 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "81 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "82 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "83 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "84 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "85 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "86 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "87 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "88 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "89 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "90 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "91 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "92 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "93 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "94 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "95 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "96 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "97 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "98 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "99 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "100 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "101 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "102 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "103 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "104 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "105 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "106 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "107 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "108 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "109 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "110 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "111 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "112 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "113 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "114 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "115 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "116 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "117 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "118 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "119 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "120 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "121 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "122 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "123 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "124 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "125 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "126 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "127 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "128 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "129 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "130 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "131 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "132 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "133 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "134 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "135 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "136 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "137 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "138 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "139 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "140 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "141 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "142 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "143 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "144 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "145 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "146 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "147 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "148 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "149 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "150 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "151 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "152 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "153 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "154 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "155 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "156 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "157 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "158 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "159 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "160 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "161 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "162 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "163 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "164 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "165 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "166 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "167 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "168 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "169 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "170 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "171 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "172 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "173 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "174 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "175 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "176 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "177 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "178 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "179 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "180 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "181 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "182 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "183 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "184 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "185 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "186 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "187 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "188 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "189 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "190 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "191 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "192 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "193 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "194 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "195 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "196 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "197 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "198 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "199 Train Loss 2.8277328 Test MSE 14258.650383180906 Test RE 1.0000109924980987\n",
      "Training time: 40.85\n",
      "Training time: 40.85\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 4.9131975 Test MSE 14261.891528272441 Test RE 1.0001246426846453\n",
      "1 Train Loss 4.546164 Test MSE 14255.630095709383 Test RE 0.999905075018185\n",
      "2 Train Loss 3.978397 Test MSE 14261.683185644366 Test RE 1.0001173375751855\n",
      "3 Train Loss 3.1179771 Test MSE 14257.565424818302 Test RE 0.9999729457370163\n",
      "4 Train Loss 2.8366694 Test MSE 14257.811035795497 Test RE 0.9999815588230277\n",
      "5 Train Loss 2.8295796 Test MSE 14257.408992193048 Test RE 0.9999674599188734\n",
      "6 Train Loss 2.8278737 Test MSE 14257.710109662117 Test RE 0.9999780195542531\n",
      "7 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "8 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "9 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "10 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "11 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "12 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "13 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "14 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "15 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "16 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "17 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "18 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "19 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "20 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "21 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "22 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "23 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "24 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "25 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "26 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "27 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "28 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "29 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "30 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "31 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "32 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "33 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "34 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "35 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "36 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "37 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "38 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "39 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "40 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "41 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "42 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "43 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "44 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "45 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "46 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "47 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "48 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "49 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "50 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "51 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "52 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "53 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "54 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "55 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "56 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "57 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "58 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "59 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "60 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "61 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "62 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "63 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "64 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "65 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "66 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "67 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "68 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "69 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "70 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "71 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "72 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "73 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "74 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "75 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "76 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "77 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "78 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "79 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "80 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "81 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "82 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "83 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "84 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "85 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "86 Train Loss 2.8277051 Test MSE 14257.779020698697 Test RE 0.9999804361217839\n",
      "87 Train Loss 2.827704 Test MSE 14257.77653199874 Test RE 0.999980348848325\n",
      "88 Train Loss 2.8277035 Test MSE 14257.77834690121 Test RE 0.999980412493128\n",
      "89 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "90 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "91 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "92 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "93 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "94 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "95 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "96 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "97 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "98 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "99 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "100 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "101 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "102 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "103 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "104 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "105 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "106 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "107 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "108 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "109 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "110 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "111 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "112 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "113 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "114 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "115 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "116 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "117 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "118 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "119 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "120 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "121 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "122 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "123 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "124 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "125 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "126 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "127 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "128 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "129 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "130 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "131 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "132 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "133 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "134 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "135 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "136 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "137 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "138 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "139 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "140 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "141 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "142 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "143 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "144 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "145 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "146 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "147 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "148 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "149 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "150 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "151 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "152 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "153 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "154 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "155 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "156 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "157 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "158 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "159 Train Loss 2.8276997 Test MSE 14257.768783847774 Test RE 0.9999800771369631\n",
      "160 Train Loss 2.827677 Test MSE 14257.729176139506 Test RE 0.9999786881767662\n",
      "161 Train Loss 2.8275127 Test MSE 14257.588570669484 Test RE 0.9999737574189166\n",
      "162 Train Loss 2.8275127 Test MSE 14257.588570669484 Test RE 0.9999737574189166\n",
      "163 Train Loss 2.8275096 Test MSE 14257.574041239259 Test RE 0.9999732478989312\n",
      "164 Train Loss 2.8275096 Test MSE 14257.574041239259 Test RE 0.9999732478989312\n",
      "165 Train Loss 2.8275096 Test MSE 14257.574041239259 Test RE 0.9999732478989312\n",
      "166 Train Loss 2.8275096 Test MSE 14257.574041239259 Test RE 0.9999732478989312\n",
      "167 Train Loss 2.8275092 Test MSE 14257.574020489224 Test RE 0.9999732471712661\n",
      "168 Train Loss 2.8275092 Test MSE 14257.574020489224 Test RE 0.9999732471712661\n",
      "169 Train Loss 2.8275092 Test MSE 14257.574020489224 Test RE 0.9999732471712661\n",
      "170 Train Loss 2.8275092 Test MSE 14257.574020489224 Test RE 0.9999732471712661\n",
      "171 Train Loss 2.8275092 Test MSE 14257.574020489224 Test RE 0.9999732471712661\n",
      "172 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "173 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "174 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "175 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "176 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "177 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "178 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "179 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "180 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "181 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "182 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "183 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "184 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "185 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "186 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "187 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "188 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "189 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "190 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "191 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "192 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "193 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "194 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "195 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "196 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "197 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "198 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "199 Train Loss 2.827509 Test MSE 14257.574038134288 Test RE 0.9999732477900458\n",
      "Training time: 16.06\n",
      "Training time: 16.06\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 4.5952935 Test MSE 14253.013893935986 Test RE 0.999813319219098\n",
      "1 Train Loss 4.312798 Test MSE 14260.447012431045 Test RE 1.0000739925843338\n",
      "2 Train Loss 4.054251 Test MSE 14267.688911635254 Test RE 1.0003278947163845\n",
      "3 Train Loss 3.6219966 Test MSE 14266.743871519458 Test RE 1.0002947651167007\n",
      "4 Train Loss 3.3570137 Test MSE 14257.318341357992 Test RE 0.9999642809391087\n",
      "5 Train Loss 2.867294 Test MSE 14259.88122094274 Test RE 1.000054153130327\n",
      "6 Train Loss 2.8549123 Test MSE 14259.262964705913 Test RE 1.0000324735521595\n",
      "7 Train Loss 2.844226 Test MSE 14260.214861218596 Test RE 1.0000658522597488\n",
      "8 Train Loss 2.840104 Test MSE 14260.185528487482 Test RE 1.000064823710105\n",
      "9 Train Loss 2.8392391 Test MSE 14259.767814899726 Test RE 1.000050176504995\n",
      "10 Train Loss 2.8363445 Test MSE 14258.593412115848 Test RE 1.0000089947021402\n",
      "11 Train Loss 2.8314867 Test MSE 14259.100222989968 Test RE 1.0000267668243465\n",
      "12 Train Loss 2.8301432 Test MSE 14259.310359696836 Test RE 1.0000341355065938\n",
      "13 Train Loss 2.8297236 Test MSE 14259.618869872229 Test RE 1.0000449536678515\n",
      "14 Train Loss 2.8285768 Test MSE 14258.669544287226 Test RE 1.0000116644168988\n",
      "15 Train Loss 2.8282096 Test MSE 14258.602555521014 Test RE 1.0000093153328533\n",
      "16 Train Loss 2.8281872 Test MSE 14258.57624640983 Test RE 1.00000839275407\n",
      "17 Train Loss 2.8281786 Test MSE 14258.52821598543 Test RE 1.0000067084741275\n",
      "18 Train Loss 2.8281713 Test MSE 14258.49785422375 Test RE 1.000005643778632\n",
      "19 Train Loss 2.828166 Test MSE 14258.479615189284 Test RE 1.0000050041901065\n",
      "20 Train Loss 2.8281574 Test MSE 14258.466340204146 Test RE 1.0000045386757244\n",
      "21 Train Loss 2.8281503 Test MSE 14258.465414511536 Test RE 1.00000450621442\n",
      "22 Train Loss 2.8281453 Test MSE 14258.467947682979 Test RE 1.0000045950452539\n",
      "23 Train Loss 2.828136 Test MSE 14258.466123838112 Test RE 1.0000045310884071\n",
      "24 Train Loss 2.8281312 Test MSE 14258.465866384673 Test RE 1.0000045220602758\n",
      "25 Train Loss 2.8281245 Test MSE 14258.45775237984 Test RE 1.0000042375260643\n",
      "26 Train Loss 2.8281016 Test MSE 14258.451841317117 Test RE 1.000004030242483\n",
      "27 Train Loss 2.828097 Test MSE 14258.449135900693 Test RE 1.0000039353714727\n",
      "28 Train Loss 2.8279295 Test MSE 14258.69575511191 Test RE 1.0000125835460747\n",
      "29 Train Loss 2.8279257 Test MSE 14258.695926520257 Test RE 1.0000125895568104\n",
      "30 Train Loss 2.8279257 Test MSE 14258.695926520257 Test RE 1.0000125895568104\n",
      "31 Train Loss 2.8279257 Test MSE 14258.695926520257 Test RE 1.0000125895568104\n",
      "32 Train Loss 2.8279202 Test MSE 14258.695940872803 Test RE 1.0000125900601076\n",
      "33 Train Loss 2.827918 Test MSE 14258.69313283224 Test RE 1.0000124915912132\n",
      "34 Train Loss 2.827918 Test MSE 14258.69313283224 Test RE 1.0000124915912132\n",
      "35 Train Loss 2.827918 Test MSE 14258.69313283224 Test RE 1.0000124915912132\n",
      "36 Train Loss 2.827918 Test MSE 14258.69313283224 Test RE 1.0000124915912132\n",
      "37 Train Loss 2.827918 Test MSE 14258.69313283224 Test RE 1.0000124915912132\n",
      "38 Train Loss 2.827916 Test MSE 14258.693137972326 Test RE 1.0000124917714595\n",
      "39 Train Loss 2.8279104 Test MSE 14258.74937851844 Test RE 1.000014463943546\n",
      "40 Train Loss 2.8278818 Test MSE 14258.696233035966 Test RE 1.0000126003053236\n",
      "41 Train Loss 2.8278759 Test MSE 14258.677746408915 Test RE 1.0000119520389716\n",
      "42 Train Loss 2.8278608 Test MSE 14258.750969838633 Test RE 1.000014519745886\n",
      "43 Train Loss 2.8278608 Test MSE 14258.750969838633 Test RE 1.000014519745886\n",
      "44 Train Loss 2.827853 Test MSE 14258.761446338622 Test RE 1.00001488712204\n",
      "45 Train Loss 2.8278503 Test MSE 14258.78921407929 Test RE 1.0000158608440786\n",
      "46 Train Loss 2.8278437 Test MSE 14258.78162093449 Test RE 1.0000155945779137\n",
      "47 Train Loss 2.8276374 Test MSE 14258.399988159945 Test RE 1.0000022119029508\n",
      "48 Train Loss 2.8276079 Test MSE 14258.265246819425 Test RE 0.9999974869002509\n",
      "49 Train Loss 2.8276055 Test MSE 14258.249499073067 Test RE 0.9999969346692866\n",
      "50 Train Loss 2.8275993 Test MSE 14258.188380763855 Test RE 0.9999947914122421\n",
      "51 Train Loss 2.8275993 Test MSE 14258.188380763855 Test RE 0.9999947914122421\n",
      "52 Train Loss 2.8275993 Test MSE 14258.188380763855 Test RE 0.9999947914122421\n",
      "53 Train Loss 2.8275993 Test MSE 14258.188380763855 Test RE 0.9999947914122421\n",
      "54 Train Loss 2.8275993 Test MSE 14258.188380763855 Test RE 0.9999947914122421\n",
      "55 Train Loss 2.8275983 Test MSE 14258.179967616052 Test RE 0.9999944963850971\n",
      "56 Train Loss 2.8275983 Test MSE 14258.179967616052 Test RE 0.9999944963850971\n",
      "57 Train Loss 2.8275983 Test MSE 14258.179967616052 Test RE 0.9999944963850971\n",
      "58 Train Loss 2.827597 Test MSE 14258.179983838614 Test RE 0.9999944969539801\n",
      "59 Train Loss 2.827597 Test MSE 14258.179983838614 Test RE 0.9999944969539801\n",
      "60 Train Loss 2.827597 Test MSE 14258.179983838614 Test RE 0.9999944969539801\n",
      "61 Train Loss 2.827597 Test MSE 14258.179983838614 Test RE 0.9999944969539801\n",
      "62 Train Loss 2.827597 Test MSE 14258.179983838614 Test RE 0.9999944969539801\n",
      "63 Train Loss 2.827597 Test MSE 14258.179983838614 Test RE 0.9999944969539801\n",
      "64 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "65 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "66 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "67 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "68 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "69 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "70 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "71 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "72 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "73 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "74 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "75 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "76 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "77 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "78 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "79 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "80 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "81 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "82 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "83 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "84 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "85 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "86 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "87 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "88 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "89 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "90 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "91 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "92 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "93 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "94 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "95 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "96 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "97 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "98 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "99 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "100 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "101 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "102 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "103 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "104 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "105 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "106 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "107 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "108 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "109 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "110 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "111 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "112 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "113 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "114 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "115 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "116 Train Loss 2.827596 Test MSE 14258.17996853147 Test RE 0.9999944964171986\n",
      "117 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "118 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "119 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "120 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "121 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "122 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "123 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "124 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "125 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "126 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "127 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "128 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "129 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "130 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "131 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "132 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "133 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "134 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "135 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "136 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "137 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "138 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "139 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "140 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "141 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "142 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "143 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "144 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "145 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "146 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "147 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "148 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "149 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "150 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "151 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "152 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "153 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "154 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "155 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "156 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "157 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "158 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "159 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "160 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "161 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "162 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "163 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "164 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "165 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "166 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "167 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "168 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "169 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "170 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "171 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "172 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "173 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "174 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "175 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "176 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "177 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "178 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "179 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "180 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "181 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "182 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "183 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "184 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "185 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "186 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "187 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "188 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "189 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "190 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "191 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "192 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "193 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "194 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "195 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "196 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "197 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "198 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "199 Train Loss 2.8275955 Test MSE 14258.17996987699 Test RE 0.9999944964643824\n",
      "Training time: 49.75\n",
      "Training time: 49.75\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 4.827873 Test MSE 14262.127595231328 Test RE 1.0001329198267577\n",
      "1 Train Loss 4.2449603 Test MSE 14259.075174533336 Test RE 1.0000258884681488\n",
      "2 Train Loss 3.963505 Test MSE 14267.106325617566 Test RE 1.0003074715421283\n",
      "3 Train Loss 3.919793 Test MSE 14268.738091333304 Test RE 1.0003646737782028\n",
      "4 Train Loss 3.0261672 Test MSE 14260.303739543353 Test RE 1.000068968763952\n",
      "5 Train Loss 2.8479364 Test MSE 14259.61765316633 Test RE 1.0000449110032956\n",
      "6 Train Loss 2.8297222 Test MSE 14258.985999588025 Test RE 1.0000227614282728\n",
      "7 Train Loss 2.8283901 Test MSE 14258.531638322604 Test RE 1.0000068284851087\n",
      "8 Train Loss 2.8283854 Test MSE 14258.531958463322 Test RE 1.0000068397114719\n",
      "9 Train Loss 2.8283854 Test MSE 14258.531958463322 Test RE 1.0000068397114719\n",
      "10 Train Loss 2.8283854 Test MSE 14258.531958463322 Test RE 1.0000068397114719\n",
      "11 Train Loss 2.82838 Test MSE 14258.51357512083 Test RE 1.0000061950632635\n",
      "12 Train Loss 2.8276196 Test MSE 14258.098868032712 Test RE 0.99999165242982\n",
      "13 Train Loss 2.827581 Test MSE 14258.085287750693 Test RE 0.9999911762032201\n",
      "14 Train Loss 2.827581 Test MSE 14258.085287750693 Test RE 0.9999911762032201\n",
      "15 Train Loss 2.827581 Test MSE 14258.085287750693 Test RE 0.9999911762032201\n",
      "16 Train Loss 2.827576 Test MSE 14258.08603257359 Test RE 0.9999912023223063\n",
      "17 Train Loss 2.827576 Test MSE 14258.08603257359 Test RE 0.9999912023223063\n",
      "18 Train Loss 2.827576 Test MSE 14258.08603257359 Test RE 0.9999912023223063\n",
      "19 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "20 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "21 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "22 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "23 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "24 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "25 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "26 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "27 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "28 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "29 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "30 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "31 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "32 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "33 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "34 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "35 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "36 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "37 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "38 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "39 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "40 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "41 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "42 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "43 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "44 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "45 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "46 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "47 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "48 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "49 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "50 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "51 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "52 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "53 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "54 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "55 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "56 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "57 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "58 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "59 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "60 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "61 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "62 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "63 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "64 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "65 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "66 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "67 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "68 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "69 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "70 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "71 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "72 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "73 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "74 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "75 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "76 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "77 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "78 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "79 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "80 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "81 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "82 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "83 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "84 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "85 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "86 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "87 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "88 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "89 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "90 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "91 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "92 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "93 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "94 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "95 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "96 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "97 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "98 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "99 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "100 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "101 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "102 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "103 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "104 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "105 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "106 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "107 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "108 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "109 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "110 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "111 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "112 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "113 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "114 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "115 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "116 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "117 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "118 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "119 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "120 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "121 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "122 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "123 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "124 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "125 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "126 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "127 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "128 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "129 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "130 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "131 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "132 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "133 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "134 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "135 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "136 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "137 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "138 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "139 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "140 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "141 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "142 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "143 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "144 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "145 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "146 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "147 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "148 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "149 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "150 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "151 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "152 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "153 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "154 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "155 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "156 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "157 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "158 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "159 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "160 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "161 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "162 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "163 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "164 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "165 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "166 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "167 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "168 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "169 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "170 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "171 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "172 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "173 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "174 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "175 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "176 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "177 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "178 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "179 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "180 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "181 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "182 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "183 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "184 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "185 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "186 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "187 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "188 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "189 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "190 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "191 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "192 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "193 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "194 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "195 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "196 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "197 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "198 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "199 Train Loss 2.8275747 Test MSE 14258.086030824894 Test RE 0.9999912022609839\n",
      "Training time: 35.58\n",
      "Training time: 35.58\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 4.564295 Test MSE 14265.298402482118 Test RE 1.0002440902132455\n",
      "1 Train Loss 4.2871695 Test MSE 14260.514219496958 Test RE 1.0000763491710345\n",
      "2 Train Loss 4.080372 Test MSE 14267.704125146322 Test RE 1.000328428036656\n",
      "3 Train Loss 3.4291706 Test MSE 14267.550145076879 Test RE 1.0003230301444983\n",
      "4 Train Loss 3.206759 Test MSE 14263.730399576603 Test RE 1.0001891166439598\n",
      "5 Train Loss 3.0707982 Test MSE 14252.667767302166 Test RE 0.9998011791860419\n",
      "6 Train Loss 2.921042 Test MSE 14241.051146169359 Test RE 0.999393652706815\n",
      "7 Train Loss 2.8520153 Test MSE 14242.459822899787 Test RE 0.9994430798086532\n",
      "8 Train Loss 2.8495953 Test MSE 14241.784001296113 Test RE 0.9994193671478405\n",
      "9 Train Loss 2.8405645 Test MSE 14240.464567991548 Test RE 0.9993730703587025\n",
      "10 Train Loss 2.83291 Test MSE 14232.381699795504 Test RE 0.9990894087081151\n",
      "11 Train Loss 2.8308964 Test MSE 14233.560815550589 Test RE 0.9991307938286441\n",
      "12 Train Loss 2.8308804 Test MSE 14233.592722764028 Test RE 0.9991319136981567\n",
      "13 Train Loss 2.8308759 Test MSE 14233.610208532626 Test RE 0.9991325274077246\n",
      "14 Train Loss 2.830873 Test MSE 14233.62788678098 Test RE 0.9991331478724984\n",
      "15 Train Loss 2.8308544 Test MSE 14233.67742743507 Test RE 0.9991348866304239\n",
      "16 Train Loss 2.8308477 Test MSE 14233.70877988221 Test RE 0.9991359870244237\n",
      "17 Train Loss 2.8308287 Test MSE 14233.792377801776 Test RE 0.9991389211004446\n",
      "18 Train Loss 2.8284879 Test MSE 14240.269957063563 Test RE 0.9993662415932443\n",
      "19 Train Loss 2.8265898 Test MSE 14246.6818094862 Test RE 0.9995912045940495\n",
      "20 Train Loss 2.8265707 Test MSE 14247.127521197663 Test RE 0.9996068407270086\n",
      "21 Train Loss 2.826563 Test MSE 14247.38073631757 Test RE 0.9996157237260904\n",
      "22 Train Loss 2.8265567 Test MSE 14247.580158631326 Test RE 0.9996227195727874\n",
      "23 Train Loss 2.8265567 Test MSE 14247.580158631326 Test RE 0.9996227195727874\n",
      "24 Train Loss 2.8265567 Test MSE 14247.580158631326 Test RE 0.9996227195727874\n",
      "25 Train Loss 2.826542 Test MSE 14247.60498628221 Test RE 0.9996235905372884\n",
      "26 Train Loss 2.8265343 Test MSE 14247.608740906939 Test RE 0.999623722251047\n",
      "27 Train Loss 2.8260968 Test MSE 14247.744771208649 Test RE 0.9996284942375057\n",
      "28 Train Loss 2.8256745 Test MSE 14245.84340542639 Test RE 0.9995617916519545\n",
      "29 Train Loss 2.8251398 Test MSE 14244.405379761047 Test RE 0.999511340732856\n",
      "30 Train Loss 2.825047 Test MSE 14244.493142778614 Test RE 0.9995144198363325\n",
      "31 Train Loss 2.8250244 Test MSE 14244.571900827437 Test RE 0.9995171829987655\n",
      "32 Train Loss 2.8250206 Test MSE 14244.58611841803 Test RE 0.9995176818106164\n",
      "33 Train Loss 2.8250184 Test MSE 14244.588594293089 Test RE 0.9995177686745228\n",
      "34 Train Loss 2.8250089 Test MSE 14244.575535576676 Test RE 0.9995173105208179\n",
      "35 Train Loss 2.8229861 Test MSE 14228.601490373687 Test RE 0.9989567177048714\n",
      "36 Train Loss 2.82165 Test MSE 14219.229014516368 Test RE 0.9986276537398856\n",
      "37 Train Loss 2.8212054 Test MSE 14207.49247857015 Test RE 0.9982154355792162\n",
      "38 Train Loss 2.8212054 Test MSE 14207.49247857015 Test RE 0.9982154355792162\n",
      "39 Train Loss 2.8212054 Test MSE 14207.49247857015 Test RE 0.9982154355792162\n",
      "40 Train Loss 2.8212054 Test MSE 14207.49247857015 Test RE 0.9982154355792162\n",
      "41 Train Loss 2.8212054 Test MSE 14207.49247857015 Test RE 0.9982154355792162\n",
      "42 Train Loss 2.8211882 Test MSE 14207.25549430141 Test RE 0.9982071103120416\n",
      "43 Train Loss 2.8211849 Test MSE 14208.398360723299 Test RE 0.9982472586168042\n",
      "44 Train Loss 2.8211849 Test MSE 14208.398360723299 Test RE 0.9982472586168042\n",
      "45 Train Loss 2.8211849 Test MSE 14208.398360723299 Test RE 0.9982472586168042\n",
      "46 Train Loss 2.8211849 Test MSE 14208.398360723299 Test RE 0.9982472586168042\n",
      "47 Train Loss 2.8211849 Test MSE 14208.398360723299 Test RE 0.9982472586168042\n",
      "48 Train Loss 2.8211849 Test MSE 14208.398360723299 Test RE 0.9982472586168042\n",
      "49 Train Loss 2.821181 Test MSE 14208.39844470949 Test RE 0.998247261567136\n",
      "50 Train Loss 2.8211777 Test MSE 14208.398264943533 Test RE 0.9982472552521784\n",
      "51 Train Loss 2.8211715 Test MSE 14208.31996397212 Test RE 0.9982445046311713\n",
      "52 Train Loss 2.8211715 Test MSE 14208.31996397212 Test RE 0.9982445046311713\n",
      "53 Train Loss 2.8211715 Test MSE 14208.31996397212 Test RE 0.9982445046311713\n",
      "54 Train Loss 2.8211715 Test MSE 14208.31996397212 Test RE 0.9982445046311713\n",
      "55 Train Loss 2.8211715 Test MSE 14208.31996397212 Test RE 0.9982445046311713\n",
      "56 Train Loss 2.8211715 Test MSE 14208.31996397212 Test RE 0.9982445046311713\n",
      "57 Train Loss 2.8211715 Test MSE 14208.31996397212 Test RE 0.9982445046311713\n",
      "58 Train Loss 2.8211715 Test MSE 14208.31996397212 Test RE 0.9982445046311713\n",
      "59 Train Loss 2.8211715 Test MSE 14208.31996397212 Test RE 0.9982445046311713\n",
      "60 Train Loss 2.8211691 Test MSE 14208.191748425637 Test RE 0.9982400005534989\n",
      "61 Train Loss 2.8211644 Test MSE 14208.172359487891 Test RE 0.9982393194386822\n",
      "62 Train Loss 2.8205128 Test MSE 14201.27809498194 Test RE 0.9979971010592034\n",
      "63 Train Loss 2.8179317 Test MSE 14193.744312042636 Test RE 0.9977323470379417\n",
      "64 Train Loss 2.815703 Test MSE 14188.357033437735 Test RE 0.9975429829020407\n",
      "65 Train Loss 2.8075945 Test MSE 14128.332983792568 Test RE 0.995430686500509\n",
      "66 Train Loss 2.799537 Test MSE 14082.423964772504 Test RE 0.9938120797289801\n",
      "67 Train Loss 2.7956295 Test MSE 14063.884715658785 Test RE 0.9931576967318894\n",
      "68 Train Loss 2.7939534 Test MSE 14048.293573950823 Test RE 0.9926070396204955\n",
      "69 Train Loss 2.7938871 Test MSE 14046.607031326355 Test RE 0.9925474550054546\n",
      "70 Train Loss 2.7938495 Test MSE 14046.582907737396 Test RE 0.9925466027064953\n",
      "71 Train Loss 2.7938435 Test MSE 14046.897184742007 Test RE 0.9925577062193747\n",
      "72 Train Loss 2.7938037 Test MSE 14047.930431498455 Test RE 0.9925942103013272\n",
      "73 Train Loss 2.7938037 Test MSE 14047.930431498455 Test RE 0.9925942103013272\n",
      "74 Train Loss 2.7938037 Test MSE 14047.930431498455 Test RE 0.9925942103013272\n",
      "75 Train Loss 2.7938037 Test MSE 14047.930431498455 Test RE 0.9925942103013272\n",
      "76 Train Loss 2.7938015 Test MSE 14048.574976482709 Test RE 0.9926169810676141\n",
      "77 Train Loss 2.7937956 Test MSE 14049.258586962644 Test RE 0.9926411313859685\n",
      "78 Train Loss 2.7937796 Test MSE 14049.903483109641 Test RE 0.9926639134812325\n",
      "79 Train Loss 2.7937796 Test MSE 14049.903483109641 Test RE 0.9926639134812325\n",
      "80 Train Loss 2.7937796 Test MSE 14049.903483109641 Test RE 0.9926639134812325\n",
      "81 Train Loss 2.7937796 Test MSE 14049.903483109641 Test RE 0.9926639134812325\n",
      "82 Train Loss 2.7937777 Test MSE 14049.903918393524 Test RE 0.9926639288582274\n",
      "83 Train Loss 2.7937777 Test MSE 14049.903918393524 Test RE 0.9926639288582274\n",
      "84 Train Loss 2.7937777 Test MSE 14049.903918393524 Test RE 0.9926639288582274\n",
      "85 Train Loss 2.7937777 Test MSE 14049.903918393524 Test RE 0.9926639288582274\n",
      "86 Train Loss 2.7937777 Test MSE 14049.903918393524 Test RE 0.9926639288582274\n",
      "87 Train Loss 2.7937777 Test MSE 14049.903918393524 Test RE 0.9926639288582274\n",
      "88 Train Loss 2.7937756 Test MSE 14050.355285504798 Test RE 0.9926798738872518\n",
      "89 Train Loss 2.7937756 Test MSE 14050.355285504798 Test RE 0.9926798738872518\n",
      "90 Train Loss 2.7937756 Test MSE 14050.355285504798 Test RE 0.9926798738872518\n",
      "91 Train Loss 2.7937696 Test MSE 14050.363497174918 Test RE 0.9926801639709651\n",
      "92 Train Loss 2.7937696 Test MSE 14050.363497174918 Test RE 0.9926801639709651\n",
      "93 Train Loss 2.7937696 Test MSE 14050.363497174918 Test RE 0.9926801639709651\n",
      "94 Train Loss 2.7937672 Test MSE 14050.367555938808 Test RE 0.9926803073499643\n",
      "95 Train Loss 2.7937524 Test MSE 14050.648198914421 Test RE 0.9926902212316849\n",
      "96 Train Loss 2.7931857 Test MSE 14045.991546249901 Test RE 0.9925257093683408\n",
      "97 Train Loss 2.7922392 Test MSE 14043.47672622383 Test RE 0.9924368535814336\n",
      "98 Train Loss 2.791016 Test MSE 14038.431769467332 Test RE 0.9922585768324803\n",
      "99 Train Loss 2.7887063 Test MSE 14012.183644349996 Test RE 0.9913305133078734\n",
      "100 Train Loss 2.7851703 Test MSE 13983.343738780566 Test RE 0.9903098085692943\n",
      "101 Train Loss 2.7816343 Test MSE 13956.611834050522 Test RE 0.9893627700040408\n",
      "102 Train Loss 2.7764833 Test MSE 13921.213666583093 Test RE 0.9881073125911484\n",
      "103 Train Loss 2.7728891 Test MSE 13890.81141129708 Test RE 0.9870277691427708\n",
      "104 Train Loss 2.770598 Test MSE 13911.35171729832 Test RE 0.9877572572418812\n",
      "105 Train Loss 2.7663808 Test MSE 13904.609721055294 Test RE 0.98751787494073\n",
      "106 Train Loss 2.7607007 Test MSE 13881.359498841679 Test RE 0.9866919036794697\n",
      "107 Train Loss 2.7577884 Test MSE 13873.54955682668 Test RE 0.9864142979179441\n",
      "108 Train Loss 2.7575512 Test MSE 13875.09081835921 Test RE 0.9864690885172834\n",
      "109 Train Loss 2.7570567 Test MSE 13869.296606472491 Test RE 0.9862630931891805\n",
      "110 Train Loss 2.7570481 Test MSE 13868.742841916592 Test RE 0.986243403546257\n",
      "111 Train Loss 2.7561321 Test MSE 13855.672473593715 Test RE 0.985778559571414\n",
      "112 Train Loss 2.7540226 Test MSE 13841.132806351414 Test RE 0.9852612027147344\n",
      "113 Train Loss 2.7470093 Test MSE 13810.963906913508 Test RE 0.9841868520315125\n",
      "114 Train Loss 2.7371902 Test MSE 13775.707556675221 Test RE 0.9829298431246035\n",
      "115 Train Loss 2.7320304 Test MSE 13747.537275514858 Test RE 0.9819243201738651\n",
      "116 Train Loss 2.72606 Test MSE 13710.196314047716 Test RE 0.9805898655250366\n",
      "117 Train Loss 2.7243526 Test MSE 13693.904348046206 Test RE 0.980007069872838\n",
      "118 Train Loss 2.7218263 Test MSE 13689.051572334249 Test RE 0.9798334095422999\n",
      "119 Train Loss 2.7184966 Test MSE 13661.409525680949 Test RE 0.9788436299598596\n",
      "120 Train Loss 2.7158575 Test MSE 13651.96151118279 Test RE 0.9785050950411929\n",
      "121 Train Loss 2.7133973 Test MSE 13630.89293468218 Test RE 0.9777497578156021\n",
      "122 Train Loss 2.7074397 Test MSE 13593.177475638444 Test RE 0.9763961478644931\n",
      "123 Train Loss 2.702106 Test MSE 13577.085958300964 Test RE 0.9758180509414064\n",
      "124 Train Loss 2.6943173 Test MSE 13527.682413864282 Test RE 0.9740410567653821\n",
      "125 Train Loss 2.6908727 Test MSE 13504.033105701685 Test RE 0.9731892673409032\n",
      "126 Train Loss 2.687349 Test MSE 13475.321855709499 Test RE 0.9721541562856197\n",
      "127 Train Loss 2.6853523 Test MSE 13458.931313526318 Test RE 0.9715627425090588\n",
      "128 Train Loss 2.6848664 Test MSE 13451.300210643354 Test RE 0.9712872694308725\n",
      "129 Train Loss 2.6848438 Test MSE 13450.316865668114 Test RE 0.9712517662491277\n",
      "130 Train Loss 2.68474 Test MSE 13448.742075909442 Test RE 0.9711949065438062\n",
      "131 Train Loss 2.6840436 Test MSE 13455.49253742181 Test RE 0.9714386167482867\n",
      "132 Train Loss 2.6766214 Test MSE 13449.018107551272 Test RE 0.971204873243573\n",
      "133 Train Loss 2.6719432 Test MSE 13418.652663278028 Test RE 0.9701078514234692\n",
      "134 Train Loss 2.6625152 Test MSE 13336.484625303212 Test RE 0.9671331019045563\n",
      "135 Train Loss 2.6551003 Test MSE 13264.63248563317 Test RE 0.96452430224069\n",
      "136 Train Loss 2.6527495 Test MSE 13285.41473535708 Test RE 0.9652795866314514\n",
      "137 Train Loss 2.6479993 Test MSE 13274.945140224696 Test RE 0.9648991665061573\n",
      "138 Train Loss 2.6439824 Test MSE 13248.746583477165 Test RE 0.9639465655782571\n",
      "139 Train Loss 2.6439412 Test MSE 13248.155704386716 Test RE 0.9639250698761138\n",
      "140 Train Loss 2.6439366 Test MSE 13248.115012487686 Test RE 0.9639235895201828\n",
      "141 Train Loss 2.6439366 Test MSE 13248.115012487686 Test RE 0.9639235895201828\n",
      "142 Train Loss 2.6439116 Test MSE 13247.69976966327 Test RE 0.9639084830129587\n",
      "143 Train Loss 2.6439116 Test MSE 13247.69976966327 Test RE 0.9639084830129587\n",
      "144 Train Loss 2.6439116 Test MSE 13247.69976966327 Test RE 0.9639084830129587\n",
      "145 Train Loss 2.6439116 Test MSE 13247.69976966327 Test RE 0.9639084830129587\n",
      "146 Train Loss 2.6439116 Test MSE 13247.69976966327 Test RE 0.9639084830129587\n",
      "147 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "148 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "149 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "150 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "151 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "152 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "153 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "154 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "155 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "156 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "157 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "158 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "159 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "160 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "161 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "162 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "163 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "164 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "165 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "166 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "167 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "168 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "169 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "170 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "171 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "172 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "173 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "174 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "175 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "176 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "177 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "178 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "179 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "180 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "181 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "182 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "183 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "184 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "185 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "186 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "187 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "188 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "189 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "190 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "191 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "192 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "193 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "194 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "195 Train Loss 2.6439114 Test MSE 13247.699772188924 Test RE 0.9639084831048423\n",
      "196 Train Loss 2.6439066 Test MSE 13247.459265231286 Test RE 0.9638997333689301\n",
      "197 Train Loss 2.6439066 Test MSE 13247.459265231286 Test RE 0.9638997333689301\n",
      "198 Train Loss 2.6439066 Test MSE 13247.459265231286 Test RE 0.9638997333689301\n",
      "199 Train Loss 2.6439066 Test MSE 13247.459265231286 Test RE 0.9638997333689301\n",
      "Training time: 54.15\n",
      "Training time: 54.15\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 4.840443 Test MSE 14262.331790628612 Test RE 1.000140079410998\n",
      "1 Train Loss 4.477203 Test MSE 14263.56903383682 Test RE 1.0001834590526888\n",
      "2 Train Loss 3.9655194 Test MSE 14260.032618875373 Test RE 1.0000594619308383\n",
      "3 Train Loss 3.6862502 Test MSE 14263.746426232494 Test RE 1.000189678547538\n",
      "4 Train Loss 3.389795 Test MSE 14268.099627096113 Test RE 1.0003422925343548\n",
      "5 Train Loss 3.2099895 Test MSE 14265.938507678982 Test RE 1.0002665311829328\n",
      "6 Train Loss 3.0008874 Test MSE 14266.792259715185 Test RE 1.0002964614539402\n",
      "7 Train Loss 2.8943772 Test MSE 14271.516341397648 Test RE 1.0004620589824114\n",
      "8 Train Loss 2.8628983 Test MSE 14269.785121372312 Test RE 1.0004013761355808\n",
      "9 Train Loss 2.8296053 Test MSE 14262.504990434576 Test RE 1.0001461521747061\n",
      "10 Train Loss 2.8291283 Test MSE 14260.701579772354 Test RE 1.0000829188487428\n",
      "11 Train Loss 2.8291025 Test MSE 14260.568053349602 Test RE 1.0000782368277896\n",
      "12 Train Loss 2.8290963 Test MSE 14260.558195331403 Test RE 1.0000778911616452\n",
      "13 Train Loss 2.8290927 Test MSE 14260.556969182035 Test RE 1.0000778481673636\n",
      "14 Train Loss 2.8290927 Test MSE 14260.556969182035 Test RE 1.0000778481673636\n",
      "15 Train Loss 2.8290927 Test MSE 14260.556969182035 Test RE 1.0000778481673636\n",
      "16 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "17 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "18 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "19 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "20 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "21 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "22 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "23 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "24 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "25 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "26 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "27 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "28 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "29 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "30 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "31 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "32 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "33 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "34 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "35 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "36 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "37 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "38 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "39 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "40 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "41 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "42 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "43 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "44 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "45 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "46 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "47 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "48 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "49 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "50 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "51 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "52 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "53 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "54 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "55 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "56 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "57 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "58 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "59 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "60 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "61 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "62 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "63 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "64 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "65 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "66 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "67 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "68 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "69 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "70 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "71 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "72 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "73 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "74 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "75 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "76 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "77 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "78 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "79 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "80 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "81 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "82 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "83 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "84 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "85 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "86 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "87 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "88 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "89 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "90 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "91 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "92 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "93 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "94 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "95 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "96 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "97 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "98 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "99 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "100 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "101 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "102 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "103 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "104 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "105 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "106 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "107 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "108 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "109 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "110 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "111 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "112 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "113 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "114 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "115 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "116 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "117 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "118 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "119 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "120 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "121 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "122 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "123 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "124 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "125 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "126 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "127 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "128 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "129 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "130 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "131 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "132 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "133 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "134 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "135 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "136 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "137 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "138 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "139 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "140 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "141 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "142 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "143 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "144 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "145 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "146 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "147 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "148 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "149 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "150 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "151 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "152 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "153 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "154 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "155 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "156 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "157 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "158 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "159 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "160 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "161 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "162 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "163 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "164 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "165 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "166 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "167 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "168 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "169 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "170 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "171 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "172 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "173 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "174 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "175 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "176 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "177 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "178 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "179 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "180 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "181 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "182 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "183 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "184 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "185 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "186 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "187 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "188 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "189 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "190 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "191 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "192 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "193 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "194 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "195 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "196 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "197 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "198 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "199 Train Loss 2.8290896 Test MSE 14260.556974599162 Test RE 1.000077848357312\n",
      "Training time: 36.66\n",
      "Training time: 36.66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 4.7568054 Test MSE 14256.602009855716 Test RE 0.9999391599838207\n",
      "1 Train Loss 4.4062967 Test MSE 14259.011476189058 Test RE 1.0000236548006884\n",
      "2 Train Loss 3.952086 Test MSE 14269.289445680142 Test RE 1.0003840009983027\n",
      "3 Train Loss 3.6091933 Test MSE 14268.037113431223 Test RE 1.0003401011026651\n",
      "4 Train Loss 3.3057559 Test MSE 14263.386311335773 Test RE 1.00017705264038\n",
      "5 Train Loss 3.0667996 Test MSE 14262.532403350477 Test RE 1.0001471133280662\n",
      "6 Train Loss 2.8360877 Test MSE 14258.479625837797 Test RE 1.0000050045635183\n",
      "7 Train Loss 2.8305955 Test MSE 14258.25435736354 Test RE 0.9999971050364543\n",
      "8 Train Loss 2.8281436 Test MSE 14257.491200231201 Test RE 0.9999703428145186\n",
      "9 Train Loss 2.8281436 Test MSE 14257.491200231201 Test RE 0.9999703428145186\n",
      "10 Train Loss 2.8281436 Test MSE 14257.491200231201 Test RE 0.9999703428145186\n",
      "11 Train Loss 2.8281436 Test MSE 14257.491200231201 Test RE 0.9999703428145186\n",
      "12 Train Loss 2.8281436 Test MSE 14257.491200231201 Test RE 0.9999703428145186\n",
      "13 Train Loss 2.8281436 Test MSE 14257.491200231201 Test RE 0.9999703428145186\n",
      "14 Train Loss 2.8281426 Test MSE 14257.491083440595 Test RE 0.9999703387188773\n",
      "15 Train Loss 2.828122 Test MSE 14257.51414552656 Test RE 0.9999711474653971\n",
      "16 Train Loss 2.827722 Test MSE 14257.080448895093 Test RE 0.9999559383829482\n",
      "17 Train Loss 2.827636 Test MSE 14256.828897121963 Test RE 0.9999471167381588\n",
      "18 Train Loss 2.827636 Test MSE 14256.828897121963 Test RE 0.9999471167381588\n",
      "19 Train Loss 2.8276346 Test MSE 14256.821364614165 Test RE 0.9999468525801717\n",
      "20 Train Loss 2.8276308 Test MSE 14256.845539493237 Test RE 0.9999477003702709\n",
      "21 Train Loss 2.8276308 Test MSE 14256.845539493237 Test RE 0.9999477003702709\n",
      "22 Train Loss 2.8276296 Test MSE 14256.845550378954 Test RE 0.9999477007520223\n",
      "23 Train Loss 2.8276296 Test MSE 14256.845550378954 Test RE 0.9999477007520223\n",
      "24 Train Loss 2.8276277 Test MSE 14256.848320824392 Test RE 0.9999477979088723\n",
      "25 Train Loss 2.827502 Test MSE 14257.073601076296 Test RE 0.999955698238484\n",
      "26 Train Loss 2.827483 Test MSE 14257.01017780557 Test RE 0.9999534740607432\n",
      "27 Train Loss 2.8274746 Test MSE 14256.978445077359 Test RE 0.9999523612303156\n",
      "28 Train Loss 2.8274662 Test MSE 14256.951501368992 Test RE 0.9999514163443556\n",
      "29 Train Loss 2.827445 Test MSE 14256.861386543955 Test RE 0.9999482561109313\n",
      "30 Train Loss 2.8274384 Test MSE 14256.871437142892 Test RE 0.9999486085755038\n",
      "31 Train Loss 2.8273892 Test MSE 14256.80114531681 Test RE 0.999946143508023\n",
      "32 Train Loss 2.8273826 Test MSE 14256.77239756382 Test RE 0.9999451353499185\n",
      "33 Train Loss 2.8273757 Test MSE 14256.735198389555 Test RE 0.9999438308064859\n",
      "34 Train Loss 2.8273578 Test MSE 14256.641729416246 Test RE 0.9999405529215033\n",
      "35 Train Loss 2.8273253 Test MSE 14256.516463506898 Test RE 0.9999361599255864\n",
      "36 Train Loss 2.827317 Test MSE 14256.480555200702 Test RE 0.9999349006405254\n",
      "37 Train Loss 2.8273087 Test MSE 14256.423854963141 Test RE 0.9999329121903404\n",
      "38 Train Loss 2.8273025 Test MSE 14256.379046954595 Test RE 0.9999313407921366\n",
      "39 Train Loss 2.8272822 Test MSE 14256.301688900807 Test RE 0.9999286278715863\n",
      "40 Train Loss 2.8272803 Test MSE 14256.259121986706 Test RE 0.999927135061294\n",
      "41 Train Loss 2.8272781 Test MSE 14256.258280979746 Test RE 0.9999271055673826\n",
      "42 Train Loss 2.8272645 Test MSE 14256.228272452927 Test RE 0.999926053175003\n",
      "43 Train Loss 2.8272552 Test MSE 14256.208377400062 Test RE 0.9999253554593011\n",
      "44 Train Loss 2.8272533 Test MSE 14256.19719048045 Test RE 0.9999249631359545\n",
      "45 Train Loss 2.8272533 Test MSE 14256.19719048045 Test RE 0.9999249631359545\n",
      "46 Train Loss 2.8272533 Test MSE 14256.19719048045 Test RE 0.9999249631359545\n",
      "47 Train Loss 2.8272533 Test MSE 14256.19719048045 Test RE 0.9999249631359545\n",
      "48 Train Loss 2.8272533 Test MSE 14256.19719048045 Test RE 0.9999249631359545\n",
      "49 Train Loss 2.8272521 Test MSE 14256.197174841951 Test RE 0.9999249625875146\n",
      "50 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "51 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "52 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "53 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "54 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "55 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "56 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "57 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "58 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "59 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "60 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "61 Train Loss 2.827251 Test MSE 14256.197155140631 Test RE 0.9999249618965927\n",
      "62 Train Loss 2.8272507 Test MSE 14256.197087035105 Test RE 0.9999249595081429\n",
      "63 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "64 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "65 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "66 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "67 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "68 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "69 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "70 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "71 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "72 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "73 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "74 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "75 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "76 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "77 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "78 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "79 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "80 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "81 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "82 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "83 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "84 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "85 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "86 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "87 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "88 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "89 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "90 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "91 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "92 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "93 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "94 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "95 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "96 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "97 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "98 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "99 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "100 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "101 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "102 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "103 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "104 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "105 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "106 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "107 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "108 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "109 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "110 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "111 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "112 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "113 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "114 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "115 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "116 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "117 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "118 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "119 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "120 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "121 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "122 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "123 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "124 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "125 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "126 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "127 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "128 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "129 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "130 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "131 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "132 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "133 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "134 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "135 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "136 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "137 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "138 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "139 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "140 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "141 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "142 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "143 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "144 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "145 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "146 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "147 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "148 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "149 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "150 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "151 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "152 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "153 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "154 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "155 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "156 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "157 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "158 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "159 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "160 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "161 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "162 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "163 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "164 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "165 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "166 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "167 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "168 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "169 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "170 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "171 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "172 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "173 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "174 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "175 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "176 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "177 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "178 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "179 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "180 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "181 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "182 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "183 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "184 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "185 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "186 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "187 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "188 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "189 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "190 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "191 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "192 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "193 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "194 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "195 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "196 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "197 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "198 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "199 Train Loss 2.827249 Test MSE 14256.197070158601 Test RE 0.9999249589162871\n",
      "Training time: 34.92\n",
      "Training time: 34.92\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 4.7350955 Test MSE 14256.563667044084 Test RE 0.9999378153259347\n",
      "1 Train Loss 4.320995 Test MSE 14264.360622356702 Test RE 1.000211212371568\n",
      "2 Train Loss 3.2627265 Test MSE 14257.712646345688 Test RE 0.9999781085106033\n",
      "3 Train Loss 2.8337133 Test MSE 14258.058550860509 Test RE 0.9999902386065423\n",
      "4 Train Loss 2.8302977 Test MSE 14257.543431875389 Test RE 0.9999721744848515\n",
      "5 Train Loss 2.8279297 Test MSE 14258.145328055309 Test RE 0.9999932816651532\n",
      "6 Train Loss 2.827924 Test MSE 14258.145114019482 Test RE 0.9999932741594649\n",
      "7 Train Loss 2.827924 Test MSE 14258.145114019482 Test RE 0.9999932741594649\n",
      "8 Train Loss 2.827924 Test MSE 14258.145114019482 Test RE 0.9999932741594649\n",
      "9 Train Loss 2.8279223 Test MSE 14258.144126358395 Test RE 0.9999932395247193\n",
      "10 Train Loss 2.827801 Test MSE 14258.004485160312 Test RE 0.9999883426533346\n",
      "11 Train Loss 2.8277948 Test MSE 14257.994588791444 Test RE 0.9999879956112494\n",
      "12 Train Loss 2.82779 Test MSE 14257.986855271562 Test RE 0.9999877244150425\n",
      "13 Train Loss 2.827786 Test MSE 14257.980066193542 Test RE 0.9999874863381119\n",
      "14 Train Loss 2.827779 Test MSE 14257.969911714736 Test RE 0.9999871302444192\n",
      "15 Train Loss 2.827736 Test MSE 14257.925559804873 Test RE 0.9999855749257509\n",
      "16 Train Loss 2.8276706 Test MSE 14257.933423325045 Test RE 0.9999858506813517\n",
      "17 Train Loss 2.8276656 Test MSE 14257.943670540797 Test RE 0.9999862100275703\n",
      "18 Train Loss 2.8276656 Test MSE 14257.943670540797 Test RE 0.9999862100275703\n",
      "19 Train Loss 2.827662 Test MSE 14257.930610149237 Test RE 0.9999857520297428\n",
      "20 Train Loss 2.827657 Test MSE 14257.953226344089 Test RE 0.9999865451274323\n",
      "21 Train Loss 2.827652 Test MSE 14257.978920377165 Test RE 0.9999874461570326\n",
      "22 Train Loss 2.827652 Test MSE 14257.978920377165 Test RE 0.9999874461570326\n",
      "23 Train Loss 2.827652 Test MSE 14257.978920377165 Test RE 0.9999874461570326\n",
      "24 Train Loss 2.827652 Test MSE 14257.978920377165 Test RE 0.9999874461570326\n",
      "25 Train Loss 2.827652 Test MSE 14257.978920377165 Test RE 0.9999874461570326\n",
      "26 Train Loss 2.827652 Test MSE 14257.978920377165 Test RE 0.9999874461570326\n",
      "27 Train Loss 2.827652 Test MSE 14257.978920377165 Test RE 0.9999874461570326\n",
      "28 Train Loss 2.8276517 Test MSE 14257.978915674717 Test RE 0.9999874459921286\n",
      "29 Train Loss 2.8276517 Test MSE 14257.978915674717 Test RE 0.9999874459921286\n",
      "30 Train Loss 2.8276517 Test MSE 14257.978915674717 Test RE 0.9999874459921286\n",
      "31 Train Loss 2.8276076 Test MSE 14257.926447399817 Test RE 0.9999856060516717\n",
      "32 Train Loss 2.8276029 Test MSE 14257.898488782797 Test RE 0.9999846256065701\n",
      "33 Train Loss 2.8276029 Test MSE 14257.898488782797 Test RE 0.9999846256065701\n",
      "34 Train Loss 2.8276029 Test MSE 14257.898488782797 Test RE 0.9999846256065701\n",
      "35 Train Loss 2.8276029 Test MSE 14257.898488782797 Test RE 0.9999846256065701\n",
      "36 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "37 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "38 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "39 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "40 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "41 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "42 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "43 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "44 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "45 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "46 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "47 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "48 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "49 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "50 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "51 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "52 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "53 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "54 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "55 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "56 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "57 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "58 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "59 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "60 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "61 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "62 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "63 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "64 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "65 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "66 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "67 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "68 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "69 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "70 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "71 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "72 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "73 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "74 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "75 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "76 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "77 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "78 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "79 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "80 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "81 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "82 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "83 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "84 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "85 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "86 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "87 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "88 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "89 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "90 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "91 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "92 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "93 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "94 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "95 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "96 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "97 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "98 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "99 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "100 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "101 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "102 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "103 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "104 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "105 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "106 Train Loss 2.8276024 Test MSE 14257.898472380466 Test RE 0.9999846250313774\n",
      "107 Train Loss 2.8276021 Test MSE 14257.898459764463 Test RE 0.9999846245889626\n",
      "108 Train Loss 2.8276021 Test MSE 14257.898459764463 Test RE 0.9999846245889626\n",
      "109 Train Loss 2.8276021 Test MSE 14257.898459764463 Test RE 0.9999846245889626\n",
      "110 Train Loss 2.8276021 Test MSE 14257.898459764463 Test RE 0.9999846245889626\n",
      "111 Train Loss 2.8276021 Test MSE 14257.898459764463 Test RE 0.9999846245889626\n",
      "112 Train Loss 2.8276021 Test MSE 14257.898459764463 Test RE 0.9999846245889626\n",
      "113 Train Loss 2.827602 Test MSE 14257.898448570084 Test RE 0.9999846241964011\n",
      "114 Train Loss 2.827602 Test MSE 14257.898448570084 Test RE 0.9999846241964011\n",
      "115 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "116 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "117 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "118 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "119 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "120 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "121 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "122 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "123 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "124 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "125 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "126 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "127 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "128 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "129 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "130 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "131 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "132 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "133 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "134 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "135 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "136 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "137 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "138 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "139 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "140 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "141 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "142 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "143 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "144 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "145 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "146 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "147 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "148 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "149 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "150 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "151 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "152 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "153 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "154 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "155 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "156 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "157 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "158 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "159 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "160 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "161 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "162 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "163 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "164 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "165 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "166 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "167 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "168 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "169 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "170 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "171 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "172 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "173 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "174 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "175 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "176 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "177 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "178 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "179 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "180 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "181 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "182 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "183 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "184 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "185 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "186 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "187 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "188 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "189 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "190 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "191 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "192 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "193 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "194 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "195 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "196 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "197 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "198 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "199 Train Loss 2.8276017 Test MSE 14257.898457379373 Test RE 0.9999846245053231\n",
      "Training time: 32.82\n",
      "Training time: 32.82\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 4.740629 Test MSE 14262.963499967014 Test RE 1.0001622283429321\n",
      "1 Train Loss 4.2714067 Test MSE 14259.089059027741 Test RE 1.0000263753458147\n",
      "2 Train Loss 3.8711061 Test MSE 14269.397989186617 Test RE 1.000387805847213\n",
      "3 Train Loss 3.7387822 Test MSE 14266.105220418238 Test RE 1.0002723757576213\n",
      "4 Train Loss 3.5898557 Test MSE 14266.886851731893 Test RE 1.0002997775428353\n",
      "5 Train Loss 3.2036827 Test MSE 14264.923003918408 Test RE 1.00023092916135\n",
      "6 Train Loss 2.8982618 Test MSE 14269.520436686604 Test RE 1.0003920980648369\n",
      "7 Train Loss 2.855278 Test MSE 14264.739783509132 Test RE 1.0002245055967565\n",
      "8 Train Loss 2.8517883 Test MSE 14262.393746249974 Test RE 1.0001422517147167\n",
      "9 Train Loss 2.837656 Test MSE 14262.762300641112 Test RE 1.0001551739647938\n",
      "10 Train Loss 2.8330762 Test MSE 14261.768536861764 Test RE 1.0001203302480515\n",
      "11 Train Loss 2.8296075 Test MSE 14260.097860248801 Test RE 1.0000617496247002\n",
      "12 Train Loss 2.8289268 Test MSE 14259.178506668475 Test RE 1.0000295119367744\n",
      "13 Train Loss 2.8280685 Test MSE 14258.398585896983 Test RE 1.000002162729618\n",
      "14 Train Loss 2.8277526 Test MSE 14258.308481096457 Test RE 0.9999990030080964\n",
      "15 Train Loss 2.8275914 Test MSE 14258.240031482488 Test RE 0.9999966026662896\n",
      "16 Train Loss 2.8275914 Test MSE 14258.240031482488 Test RE 0.9999966026662896\n",
      "17 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "18 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "19 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "20 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "21 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "22 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "23 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "24 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "25 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "26 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "27 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "28 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "29 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "30 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "31 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "32 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "33 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "34 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "35 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "36 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "37 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "38 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "39 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "40 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "41 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "42 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "43 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "44 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "45 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "46 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "47 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "48 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "49 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "50 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "51 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "52 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "53 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "54 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "55 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "56 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "57 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "58 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "59 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "60 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "61 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "62 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "63 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "64 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "65 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "66 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "67 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "68 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "69 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "70 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "71 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "72 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "73 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "74 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "75 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "76 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "77 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "78 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "79 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "80 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "81 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "82 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "83 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "84 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "85 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "86 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "87 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "88 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "89 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "90 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "91 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "92 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "93 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "94 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "95 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "96 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "97 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "98 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "99 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "100 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "101 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "102 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "103 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "104 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "105 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "106 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "107 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "108 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "109 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "110 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "111 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "112 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "113 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "114 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "115 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "116 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "117 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "118 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "119 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "120 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "121 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "122 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "123 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "124 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "125 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "126 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "127 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "128 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "129 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "130 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "131 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "132 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "133 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "134 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "135 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "136 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "137 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "138 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "139 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "140 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "141 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "142 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "143 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "144 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "145 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "146 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "147 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "148 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "149 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "150 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "151 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "152 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "153 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "154 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "155 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "156 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "157 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "158 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "159 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "160 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "161 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "162 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "163 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "164 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "165 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "166 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "167 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "168 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "169 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "170 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "171 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "172 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "173 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "174 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "175 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "176 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "177 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "178 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "179 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "180 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "181 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "182 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "183 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "184 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "185 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "186 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "187 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "188 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "189 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "190 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "191 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "192 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "193 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "194 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "195 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "196 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "197 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "198 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "199 Train Loss 2.8275912 Test MSE 14258.24002167108 Test RE 0.99999660232223\n",
      "Training time: 51.63\n",
      "Training time: 51.63\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    alpha_val = []\n",
    "    \n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "    \n",
    "    \n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.5, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "   \n",
    "\n",
    "    start_time = time.time()\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    alpha_full.append(alpha_val)    \n",
    "    \n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"alpha\": alpha_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9963977264577835\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
