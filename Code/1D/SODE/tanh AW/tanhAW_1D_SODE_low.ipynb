{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(1*x) + np.exp(-2.0*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"low\"\n",
    "label = \"1D_SODE_tanhAW_\" + level\n",
    "\n",
    "u_coeff = 2.0\n",
    "fo_val = -1.0\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.m_lambda = nn.Sigmoid()\n",
    "        \n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "            \n",
    "        self.lambdas_bc1 = Parameter(torch.ones(1,1))\n",
    "        self.lambdas_bc1.requiresGrad = True\n",
    "        \n",
    "        self.lambdas_bc2 = Parameter(torch.ones(1,1))\n",
    "        self.lambdas_bc2.requiresGrad = True\n",
    "        \n",
    "        self.lambdas_f = Parameter(torch.ones(N_f+1,1))\n",
    "        self.lambdas_f.requiresGrad = True\n",
    "             \n",
    "\n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "\n",
    "                        \n",
    "    def loss_BC1(self,x,y,lambda_ind):\n",
    "        \n",
    "        m = self.m_lambda(self.lambdas_bc1)\n",
    "        u_pred = self.forward(x)\n",
    "        \n",
    "        if(lambda_ind):\n",
    "            u_pred = u_pred.detach()\n",
    "        else:\n",
    "            m = m.detach()\n",
    "            \n",
    "        loss_bc1 = torch.sum(m*torch.square(u_pred - y))/2.0\n",
    "        \n",
    "        # loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val,lambda_ind):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        m = self.m_lambda(self.lambdas_bc2)\n",
    "        \n",
    "        if(lambda_ind):\n",
    "            bc2 = bc2.detach()\n",
    "        else:\n",
    "            m = m.detach()\n",
    "        \n",
    "        loss_bc2 = torch.sum(m*torch.square(bc2 - bc2_val))/2.0\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat,lambda_ind):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "\n",
    "        m = self.m_lambda(self.lambdas_f)\n",
    "        \n",
    "        if(lambda_ind):\n",
    "            f = f.detach()\n",
    "        else:\n",
    "            m = m.detach()\n",
    "        \n",
    "        #loss_f  = torch.sum(m*(torch.square(f)))/2.0\n",
    "        loss_f = (N_f+1)*self.loss_function(m*(torch.square(f)),f_hat)/2.0\n",
    "        \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        lambda_ind = False\n",
    "        \n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1,lambda_ind)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val,lambda_ind)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat,lambda_ind)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def loss_lambdas(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        lambda_ind = True        \n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1,lambda_ind)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val,lambda_ind)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat,lambda_ind)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return -1.0*loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    for i in range(20):\n",
    "        optimizer_lambda.zero_grad()\n",
    "        loss = PINN.loss_lambdas(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        optimizer_lambda.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (m_lambda): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 2.182372 Test MSE 14.855696483584985 Test RE 1.0107451676882602\n",
      "1 Train Loss 1.8521547 Test MSE 14.71850947649758 Test RE 1.0060674094738566\n",
      "2 Train Loss 1.8729638 Test MSE 14.487966339643343 Test RE 0.9981570509160387\n",
      "3 Train Loss 1.8604479 Test MSE 14.59308366041638 Test RE 1.0017715666350853\n",
      "4 Train Loss 1.799806 Test MSE 15.112401921569951 Test RE 1.0194405689131536\n",
      "5 Train Loss 1.66496 Test MSE 14.54129326537439 Test RE 0.9999923587487864\n",
      "6 Train Loss 1.4807501 Test MSE 14.860127730092284 Test RE 1.010895902022845\n",
      "7 Train Loss 0.8309629 Test MSE 14.637160198994525 Test RE 1.0032832873084276\n",
      "8 Train Loss 0.7857149 Test MSE 14.327693954254714 Test RE 0.9926206662223028\n",
      "9 Train Loss 0.77211106 Test MSE 13.905786647072228 Test RE 0.9778966215169853\n",
      "10 Train Loss 0.7453038 Test MSE 13.46746941200254 Test RE 0.9623613300571037\n",
      "11 Train Loss 0.73644793 Test MSE 13.28889767698021 Test RE 0.9559598303420129\n",
      "12 Train Loss 0.7371303 Test MSE 13.254215555692568 Test RE 0.9547115561762983\n",
      "13 Train Loss 0.73072666 Test MSE 12.894220113045124 Test RE 0.9416569250760851\n",
      "14 Train Loss 0.72634745 Test MSE 12.475518578596716 Test RE 0.9262419967177696\n",
      "15 Train Loss 0.67275363 Test MSE 11.486819762207462 Test RE 0.8887816267852579\n",
      "16 Train Loss 0.52946126 Test MSE 8.795967431821289 Test RE 0.7777445403783673\n",
      "17 Train Loss 0.42080486 Test MSE 7.180040119502606 Test RE 0.7026816303365253\n",
      "18 Train Loss 0.3321996 Test MSE 5.562358261997697 Test RE 0.6184785521581326\n",
      "19 Train Loss 0.25433698 Test MSE 3.655750984402782 Test RE 0.5013990047824348\n",
      "20 Train Loss 0.20883018 Test MSE 2.565198727207388 Test RE 0.42000617225307785\n",
      "21 Train Loss 0.08231518 Test MSE 1.0150406288040026 Test RE 0.2642024726328194\n",
      "22 Train Loss 0.020369884 Test MSE 0.167017902186839 Test RE 0.10717085044381004\n",
      "23 Train Loss 0.006237925 Test MSE 0.013482878813171204 Test RE 0.030449942740375397\n",
      "24 Train Loss 0.0020388924 Test MSE 0.0007285159379596988 Test RE 0.007078067394437312\n",
      "25 Train Loss 0.0008988632 Test MSE 0.001572768787348055 Test RE 0.010399862697841067\n",
      "26 Train Loss 0.0008993327 Test MSE 0.0016033700006528563 Test RE 0.010500549863768078\n",
      "27 Train Loss 0.0008837517 Test MSE 0.0016184723301971998 Test RE 0.010549886911787798\n",
      "28 Train Loss 0.0008942221 Test MSE 0.0016184723301971998 Test RE 0.010549886911787798\n",
      "29 Train Loss 0.00089705974 Test MSE 0.0016184723301971998 Test RE 0.010549886911787798\n",
      "30 Train Loss 0.0008915282 Test MSE 0.0016346377008899596 Test RE 0.010602442366631167\n",
      "31 Train Loss 0.0008957761 Test MSE 0.0016346377008899596 Test RE 0.010602442366631167\n",
      "32 Train Loss 0.00089111284 Test MSE 0.0015722050557357254 Test RE 0.010397998705861918\n",
      "33 Train Loss 0.00088296825 Test MSE 0.0014574160293868402 Test RE 0.01001121839665136\n",
      "34 Train Loss 0.00088074274 Test MSE 0.0013417904209178638 Test RE 0.009605887771736363\n",
      "35 Train Loss 0.0008781401 Test MSE 0.0011952694196855362 Test RE 0.009066257902633417\n",
      "36 Train Loss 0.00089116726 Test MSE 0.0011952694196855362 Test RE 0.009066257902633417\n",
      "37 Train Loss 0.0008813064 Test MSE 0.0011952694196855362 Test RE 0.009066257902633417\n",
      "38 Train Loss 0.00087726855 Test MSE 0.0011952694196855362 Test RE 0.009066257902633417\n",
      "39 Train Loss 0.00087587617 Test MSE 0.0007648867703694914 Test RE 0.007252600230953585\n",
      "40 Train Loss 0.0008818612 Test MSE 0.0007648867703694914 Test RE 0.007252600230953585\n",
      "41 Train Loss 0.0008731522 Test MSE 0.0007301619467886519 Test RE 0.00708605897528066\n",
      "42 Train Loss 0.0008749206 Test MSE 0.0007301619467886519 Test RE 0.00708605897528066\n",
      "43 Train Loss 0.000866382 Test MSE 0.0006843918446902062 Test RE 0.0068603706092057355\n",
      "44 Train Loss 0.00086562533 Test MSE 0.0006843918446902062 Test RE 0.0068603706092057355\n",
      "45 Train Loss 0.00086451886 Test MSE 0.00046837266803599023 Test RE 0.0056753276143440695\n",
      "46 Train Loss 0.0008802504 Test MSE 0.00046837266803599023 Test RE 0.0056753276143440695\n",
      "47 Train Loss 0.0008598495 Test MSE 0.0006415958037815843 Test RE 0.006642413724205935\n",
      "48 Train Loss 0.00086943293 Test MSE 0.0006415958037815843 Test RE 0.006642413724205935\n",
      "49 Train Loss 0.0008522575 Test MSE 0.0008452853555196981 Test RE 0.007624244888437017\n",
      "50 Train Loss 0.0008496375 Test MSE 0.0008452853555196981 Test RE 0.007624244888437017\n",
      "51 Train Loss 0.0008446584 Test MSE 0.0004888164234862262 Test RE 0.005797864472863754\n",
      "52 Train Loss 0.0008415254 Test MSE 0.0004888164234862262 Test RE 0.005797864472863754\n",
      "53 Train Loss 0.00084242504 Test MSE 0.0004888164234862262 Test RE 0.005797864472863754\n",
      "54 Train Loss 0.00081716507 Test MSE 0.0003480875749924523 Test RE 0.004892596783796723\n",
      "55 Train Loss 0.0004866458 Test MSE 0.0002100537219219057 Test RE 0.0038006716849464392\n",
      "56 Train Loss 0.00046962316 Test MSE 0.00016287049355330946 Test RE 0.0033466968197360595\n",
      "57 Train Loss 0.0004695876 Test MSE 0.00012222945433909883 Test RE 0.002899232879683399\n",
      "58 Train Loss 0.0004609403 Test MSE 8.147089757587141e-05 Test RE 0.0023669899573074246\n",
      "59 Train Loss 0.0004012365 Test MSE 1.1826695283189495e-06 Test RE 0.00028518512439323386\n",
      "60 Train Loss 0.00039568284 Test MSE 1.2258236103081862e-06 Test RE 0.0002903415264468474\n",
      "61 Train Loss 0.000386386 Test MSE 1.4722189684595178e-06 Test RE 0.0003181862214567808\n",
      "62 Train Loss 0.00038663376 Test MSE 2.4700918764768673e-06 Test RE 0.0004121465971569867\n",
      "63 Train Loss 0.00038080738 Test MSE 3.1432337023690797e-06 Test RE 0.0004649256436677914\n",
      "64 Train Loss 0.00037891231 Test MSE 3.1154022623187544e-06 Test RE 0.0004628627489069424\n",
      "65 Train Loss 0.00037469907 Test MSE 3.1495949923639094e-06 Test RE 0.0004653958651456796\n",
      "66 Train Loss 0.00037147175 Test MSE 3.2390735501133555e-06 Test RE 0.0004719604099052821\n",
      "67 Train Loss 0.00036531297 Test MSE 4.2577522847012385e-06 Test RE 0.0005411097509647264\n",
      "68 Train Loss 0.00035888897 Test MSE 4.4548112513747786e-06 Test RE 0.000553490050875784\n",
      "69 Train Loss 0.00035529202 Test MSE 4.797242996968477e-06 Test RE 0.0005743690417374805\n",
      "70 Train Loss 0.00035482823 Test MSE 6.170482216264478e-06 Test RE 0.0006514104440026321\n",
      "71 Train Loss 0.0003515693 Test MSE 9.476664486733963e-06 Test RE 0.0008072776284389154\n",
      "72 Train Loss 0.00034544323 Test MSE 1.1484330868906514e-05 Test RE 0.0008886853337067208\n",
      "73 Train Loss 0.0003402252 Test MSE 1.6308743671638983e-05 Test RE 0.0010590230632933054\n",
      "74 Train Loss 0.00033015053 Test MSE 2.194032742151676e-05 Test RE 0.0012283346895530247\n",
      "75 Train Loss 0.00013116025 Test MSE 0.0001574035143639032 Test RE 0.0032900490834115257\n",
      "76 Train Loss 6.382918e-05 Test MSE 1.8006925441153123e-05 Test RE 0.0011127944423105882\n",
      "77 Train Loss 5.7959143e-05 Test MSE 9.625838879822154e-06 Test RE 0.0008136065922845364\n",
      "78 Train Loss 5.389651e-05 Test MSE 2.02102395792146e-06 Test RE 0.0003728042851968647\n",
      "79 Train Loss 4.7271773e-05 Test MSE 8.400670669483619e-06 Test RE 0.0007600674680467091\n",
      "80 Train Loss 4.5078785e-05 Test MSE 4.751902342369579e-06 Test RE 0.0005716483024677104\n",
      "81 Train Loss 4.0640436e-05 Test MSE 1.153816679381732e-06 Test RE 0.00028168490282242515\n",
      "82 Train Loss 3.675649e-05 Test MSE 2.2480180860853673e-07 Test RE 0.00012433547713013498\n",
      "83 Train Loss 3.3359942e-05 Test MSE 5.704897264129858e-07 Test RE 0.00019807017201234735\n",
      "84 Train Loss 3.017755e-05 Test MSE 1.5396582021725091e-06 Test RE 0.0003253923397649963\n",
      "85 Train Loss 2.6881275e-05 Test MSE 3.544788763909973e-06 Test RE 0.0004937309417741366\n",
      "86 Train Loss 2.4308436e-05 Test MSE 4.874960940097735e-06 Test RE 0.0005790028946854769\n",
      "87 Train Loss 2.3316836e-05 Test MSE 4.874960940097735e-06 Test RE 0.0005790028946854769\n",
      "88 Train Loss 1.7553006e-05 Test MSE 1.185383592188909e-05 Test RE 0.0009028687479962189\n",
      "89 Train Loss 1.7820428e-05 Test MSE 1.185383592188909e-05 Test RE 0.0009028687479962189\n",
      "90 Train Loss 1.5659041e-05 Test MSE 5.235880615321554e-06 Test RE 0.0006000535819481343\n",
      "91 Train Loss 1.5977703e-05 Test MSE 5.235880615321554e-06 Test RE 0.0006000535819481343\n",
      "92 Train Loss 1.348962e-05 Test MSE 1.8559319716195721e-06 Test RE 0.0003572532525535946\n",
      "93 Train Loss 1.352988e-05 Test MSE 1.8559319716195721e-06 Test RE 0.0003572532525535946\n",
      "94 Train Loss 1.3511221e-05 Test MSE 1.8559319716195721e-06 Test RE 0.0003572532525535946\n",
      "95 Train Loss 1.1870752e-05 Test MSE 1.8848693259088504e-06 Test RE 0.00036002759404515477\n",
      "96 Train Loss 1.1942286e-05 Test MSE 1.8848693259088504e-06 Test RE 0.00036002759404515477\n",
      "97 Train Loss 1.1653576e-05 Test MSE 1.8848693259088504e-06 Test RE 0.00036002759404515477\n",
      "98 Train Loss 1.0820406e-05 Test MSE 3.556502891726822e-06 Test RE 0.0004945460618660806\n",
      "99 Train Loss 1.0843993e-05 Test MSE 3.556502891726822e-06 Test RE 0.0004945460618660806\n",
      "100 Train Loss 1.1033374e-05 Test MSE 3.556502891726822e-06 Test RE 0.0004945460618660806\n",
      "101 Train Loss 1.0726142e-05 Test MSE 3.556502891726822e-06 Test RE 0.0004945460618660806\n",
      "102 Train Loss 1.0422792e-05 Test MSE 5.51035481328733e-06 Test RE 0.0006155806315257363\n",
      "103 Train Loss 1.0502862e-05 Test MSE 5.51035481328733e-06 Test RE 0.0006155806315257363\n",
      "104 Train Loss 1.05203e-05 Test MSE 5.51035481328733e-06 Test RE 0.0006155806315257363\n",
      "105 Train Loss 1.0327784e-05 Test MSE 4.241536026918729e-06 Test RE 0.0005400783210496258\n",
      "106 Train Loss 1.0032949e-05 Test MSE 4.241536026918729e-06 Test RE 0.0005400783210496258\n",
      "107 Train Loss 9.83631e-06 Test MSE 5.066258166426476e-06 Test RE 0.0005902538427936954\n",
      "108 Train Loss 9.720612e-06 Test MSE 5.066258166426476e-06 Test RE 0.0005902538427936954\n",
      "109 Train Loss 8.8435245e-06 Test MSE 5.159558401277963e-05 Test RE 0.0018836552965674272\n",
      "110 Train Loss 8.865422e-06 Test MSE 5.159558401277963e-05 Test RE 0.0018836552965674272\n",
      "111 Train Loss 7.78181e-06 Test MSE 1.7370152212144054e-05 Test RE 0.0010929416510414669\n",
      "112 Train Loss 8.10649e-06 Test MSE 1.7370152212144054e-05 Test RE 0.0010929416510414669\n",
      "113 Train Loss 7.510206e-06 Test MSE 2.5386624472482555e-05 Test RE 0.0013212884669623487\n",
      "114 Train Loss 7.688875e-06 Test MSE 2.5386624472482555e-05 Test RE 0.0013212884669623487\n",
      "115 Train Loss 7.5404355e-06 Test MSE 2.5386624472482555e-05 Test RE 0.0013212884669623487\n",
      "116 Train Loss 7.450703e-06 Test MSE 2.5386624472482555e-05 Test RE 0.0013212884669623487\n",
      "117 Train Loss 6.5802546e-06 Test MSE 2.9350707978272953e-05 Test RE 0.0014207067881555624\n",
      "118 Train Loss 6.5408476e-06 Test MSE 2.9350707978272953e-05 Test RE 0.0014207067881555624\n",
      "119 Train Loss 6.6455764e-06 Test MSE 2.9350707978272953e-05 Test RE 0.0014207067881555624\n",
      "120 Train Loss 6.5967547e-06 Test MSE 2.9350707978272953e-05 Test RE 0.0014207067881555624\n",
      "121 Train Loss 4.384008e-06 Test MSE 2.177226277897322e-06 Test RE 0.00038694295903676654\n",
      "122 Train Loss 4.328436e-06 Test MSE 2.177226277897322e-06 Test RE 0.00038694295903676654\n",
      "123 Train Loss 4.3625323e-06 Test MSE 2.177226277897322e-06 Test RE 0.00038694295903676654\n",
      "124 Train Loss 4.4576295e-06 Test MSE 2.177226277897322e-06 Test RE 0.00038694295903676654\n",
      "125 Train Loss 4.425959e-06 Test MSE 2.177226277897322e-06 Test RE 0.00038694295903676654\n",
      "126 Train Loss 4.136175e-06 Test MSE 1.0104819108628993e-06 Test RE 0.00026360851615394036\n",
      "127 Train Loss 4.0481586e-06 Test MSE 1.0104819108628993e-06 Test RE 0.00026360851615394036\n",
      "128 Train Loss 3.9209426e-06 Test MSE 1.0104819108628993e-06 Test RE 0.00026360851615394036\n",
      "129 Train Loss 4.0756167e-06 Test MSE 1.0104819108628993e-06 Test RE 0.00026360851615394036\n",
      "130 Train Loss 3.995106e-06 Test MSE 1.7241669280880457e-06 Test RE 0.0003443378948492651\n",
      "131 Train Loss 3.8942726e-06 Test MSE 1.7241669280880457e-06 Test RE 0.0003443378948492651\n",
      "132 Train Loss 3.915777e-06 Test MSE 1.7241669280880457e-06 Test RE 0.0003443378948492651\n",
      "133 Train Loss 4.011498e-06 Test MSE 1.7241669280880457e-06 Test RE 0.0003443378948492651\n",
      "134 Train Loss 3.8826443e-06 Test MSE 2.5330279083981324e-07 Test RE 0.00013198213584179633\n",
      "135 Train Loss 3.5850553e-06 Test MSE 3.632563564628499e-07 Test RE 0.00015805264789402963\n",
      "136 Train Loss 3.6027964e-06 Test MSE 3.632563564628499e-07 Test RE 0.00015805264789402963\n",
      "137 Train Loss 3.4779328e-06 Test MSE 6.446591799841336e-07 Test RE 0.000210552426362993\n",
      "138 Train Loss 3.3433198e-06 Test MSE 6.446591799841336e-07 Test RE 0.000210552426362993\n",
      "139 Train Loss 3.3066847e-06 Test MSE 6.446591799841336e-07 Test RE 0.000210552426362993\n",
      "140 Train Loss 3.1265827e-06 Test MSE 9.000502375271684e-08 Test RE 7.867351247706073e-05\n",
      "141 Train Loss 3.1365762e-06 Test MSE 9.000502375271684e-08 Test RE 7.867351247706073e-05\n",
      "142 Train Loss 3.2105213e-06 Test MSE 9.000502375271684e-08 Test RE 7.867351247706073e-05\n",
      "143 Train Loss 3.1291893e-06 Test MSE 9.000502375271684e-08 Test RE 7.867351247706073e-05\n",
      "144 Train Loss 3.0847282e-06 Test MSE 9.000502375271684e-08 Test RE 7.867351247706073e-05\n",
      "145 Train Loss 3.153193e-06 Test MSE 9.000502375271684e-08 Test RE 7.867351247706073e-05\n",
      "146 Train Loss 2.9796322e-06 Test MSE 8.047742730616022e-08 Test RE 7.439302302868104e-05\n",
      "147 Train Loss 2.985962e-06 Test MSE 8.047742730616022e-08 Test RE 7.439302302868104e-05\n",
      "148 Train Loss 3.0833155e-06 Test MSE 8.047742730616022e-08 Test RE 7.439302302868104e-05\n",
      "149 Train Loss 2.9007015e-06 Test MSE 8.047742730616022e-08 Test RE 7.439302302868104e-05\n",
      "150 Train Loss 2.6994264e-06 Test MSE 7.427574453031209e-08 Test RE 7.146915900767412e-05\n",
      "151 Train Loss 3.0353597e-06 Test MSE 7.427574453031209e-08 Test RE 7.146915900767412e-05\n",
      "152 Train Loss 2.983538e-06 Test MSE 7.427574453031209e-08 Test RE 7.146915900767412e-05\n",
      "153 Train Loss 2.6459234e-06 Test MSE 9.312688891770165e-08 Test RE 8.0026295270506e-05\n",
      "154 Train Loss 2.7317951e-06 Test MSE 9.312688891770165e-08 Test RE 8.0026295270506e-05\n",
      "155 Train Loss 2.7048072e-06 Test MSE 9.312688891770165e-08 Test RE 8.0026295270506e-05\n",
      "156 Train Loss 2.6203097e-06 Test MSE 9.312688891770165e-08 Test RE 8.0026295270506e-05\n",
      "157 Train Loss 2.6764735e-06 Test MSE 9.312688891770165e-08 Test RE 8.0026295270506e-05\n",
      "158 Train Loss 2.535585e-06 Test MSE 9.312688891770165e-08 Test RE 8.0026295270506e-05\n",
      "159 Train Loss 2.4624508e-06 Test MSE 1.4440305000168176e-08 Test RE 3.151253549934282e-05\n",
      "160 Train Loss 2.6192113e-06 Test MSE 1.4440305000168176e-08 Test RE 3.151253549934282e-05\n",
      "161 Train Loss 2.558991e-06 Test MSE 1.4440305000168176e-08 Test RE 3.151253549934282e-05\n",
      "162 Train Loss 2.495319e-06 Test MSE 1.4440305000168176e-08 Test RE 3.151253549934282e-05\n",
      "163 Train Loss 2.6367386e-06 Test MSE 1.4440305000168176e-08 Test RE 3.151253549934282e-05\n",
      "164 Train Loss 2.5778768e-06 Test MSE 1.4440305000168176e-08 Test RE 3.151253549934282e-05\n",
      "165 Train Loss 2.5294958e-06 Test MSE 1.4440305000168176e-08 Test RE 3.151253549934282e-05\n",
      "166 Train Loss 2.3914356e-06 Test MSE 6.43133664463953e-07 Test RE 0.00021030315414975354\n",
      "167 Train Loss 2.453108e-06 Test MSE 6.43133664463953e-07 Test RE 0.00021030315414975354\n",
      "168 Train Loss 2.3841928e-06 Test MSE 6.43133664463953e-07 Test RE 0.00021030315414975354\n",
      "169 Train Loss 2.5134673e-06 Test MSE 6.43133664463953e-07 Test RE 0.00021030315414975354\n",
      "170 Train Loss 2.5157162e-06 Test MSE 6.43133664463953e-07 Test RE 0.00021030315414975354\n",
      "171 Train Loss 2.4319527e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "172 Train Loss 2.3781604e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "173 Train Loss 2.3257473e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "174 Train Loss 2.453484e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "175 Train Loss 2.381505e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "176 Train Loss 2.429875e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "177 Train Loss 2.6287034e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "178 Train Loss 2.5460743e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "179 Train Loss 2.3427986e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "180 Train Loss 2.3784307e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "181 Train Loss 2.486074e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "182 Train Loss 2.5655584e-06 Test MSE 3.0249512863165655e-08 Test RE 4.560939982481674e-05\n",
      "183 Train Loss 2.4042124e-06 Test MSE 3.031553442627096e-08 Test RE 4.565914546262263e-05\n",
      "184 Train Loss 2.207707e-06 Test MSE 3.031553442627096e-08 Test RE 4.565914546262263e-05\n",
      "185 Train Loss 2.597943e-06 Test MSE 3.031553442627096e-08 Test RE 4.565914546262263e-05\n",
      "186 Train Loss 2.4195865e-06 Test MSE 3.031553442627096e-08 Test RE 4.565914546262263e-05\n",
      "187 Train Loss 2.3490356e-06 Test MSE 3.031553442627096e-08 Test RE 4.565914546262263e-05\n",
      "188 Train Loss 2.351203e-06 Test MSE 3.031553442627096e-08 Test RE 4.565914546262263e-05\n",
      "189 Train Loss 2.264465e-06 Test MSE 1.5062195398069593e-06 Test RE 0.0003218394693086419\n",
      "190 Train Loss 2.2728668e-06 Test MSE 1.5062195398069593e-06 Test RE 0.0003218394693086419\n",
      "191 Train Loss 2.2773702e-06 Test MSE 1.5062195398069593e-06 Test RE 0.0003218394693086419\n",
      "192 Train Loss 2.0831887e-06 Test MSE 5.638371535348063e-07 Test RE 0.00019691192133378506\n",
      "193 Train Loss 2.143132e-06 Test MSE 5.638371535348063e-07 Test RE 0.00019691192133378506\n",
      "194 Train Loss 2.179777e-06 Test MSE 5.638371535348063e-07 Test RE 0.00019691192133378506\n",
      "195 Train Loss 2.4332185e-06 Test MSE 5.638371535348063e-07 Test RE 0.00019691192133378506\n",
      "196 Train Loss 2.235778e-06 Test MSE 5.638371535348063e-07 Test RE 0.00019691192133378506\n",
      "197 Train Loss 2.1188498e-06 Test MSE 5.638371535348063e-07 Test RE 0.00019691192133378506\n",
      "198 Train Loss 2.199796e-06 Test MSE 5.638371535348063e-07 Test RE 0.00019691192133378506\n",
      "199 Train Loss 2.4198919e-06 Test MSE 5.638371535348063e-07 Test RE 0.00019691192133378506\n",
      "Training time: 90.91\n",
      "Training time: 90.91\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (m_lambda): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 2.1959727 Test MSE 14.794580430253122 Test RE 1.0086639317242856\n",
      "1 Train Loss 1.8841966 Test MSE 14.650354032304358 Test RE 1.0037353617084472\n",
      "2 Train Loss 1.8986604 Test MSE 14.357336885104955 Test RE 0.993646964748595\n",
      "3 Train Loss 1.8597097 Test MSE 14.535847896513365 Test RE 0.9998051045261359\n",
      "4 Train Loss 1.7569911 Test MSE 15.150871096187622 Test RE 1.0207372559676982\n",
      "5 Train Loss 1.7107768 Test MSE 14.58114817839127 Test RE 1.0013618152557526\n",
      "6 Train Loss 1.53164 Test MSE 15.143982720024246 Test RE 1.0205051893917814\n",
      "7 Train Loss 0.88326675 Test MSE 15.200623911322298 Test RE 1.0224118437880647\n",
      "8 Train Loss 0.82485664 Test MSE 14.71279589063135 Test RE 1.0058721176033376\n",
      "9 Train Loss 0.8084472 Test MSE 14.188428277990013 Test RE 0.9877847327198591\n",
      "10 Train Loss 0.7560645 Test MSE 13.517222491736675 Test RE 0.9641373244424587\n",
      "11 Train Loss 0.73348415 Test MSE 13.15074392468652 Test RE 0.9509776831718852\n",
      "12 Train Loss 0.726164 Test MSE 12.999023257715587 Test RE 0.9454760348685936\n",
      "13 Train Loss 0.7147239 Test MSE 12.425840173913155 Test RE 0.9243959762949812\n",
      "14 Train Loss 0.59017044 Test MSE 9.7482433707008 Test RE 0.8187632596308465\n",
      "15 Train Loss 0.39787704 Test MSE 5.483658882744906 Test RE 0.6140876741320461\n",
      "16 Train Loss 0.1960698 Test MSE 2.8214405715616198 Test RE 0.4404844873270479\n",
      "17 Train Loss 0.108797304 Test MSE 1.44478463699116 Test RE 0.31520763049325373\n",
      "18 Train Loss 0.08322292 Test MSE 0.7717069066263501 Test RE 0.2303675790785637\n",
      "19 Train Loss 0.0110159945 Test MSE 0.1263957220810902 Test RE 0.09323121680627806\n",
      "20 Train Loss 0.002928286 Test MSE 0.028690236143542033 Test RE 0.04441832999075624\n",
      "21 Train Loss 0.0024444284 Test MSE 0.010115660445560169 Test RE 0.026374988942241048\n",
      "22 Train Loss 0.0016858596 Test MSE 0.005944679868433555 Test RE 0.020218987362816583\n",
      "23 Train Loss 0.00077055005 Test MSE 0.004395141944504538 Test RE 0.01738527711418782\n",
      "24 Train Loss 0.0005279931 Test MSE 0.0002584858505830857 Test RE 0.004216125717281636\n",
      "25 Train Loss 0.00052206125 Test MSE 0.0001771330978546081 Test RE 0.003490157484186645\n",
      "26 Train Loss 0.0005197632 Test MSE 0.00013028108363221841 Test RE 0.0029932007536622516\n",
      "27 Train Loss 0.00050761475 Test MSE 0.00010284068308722553 Test RE 0.0026593631165953836\n",
      "28 Train Loss 0.00051208766 Test MSE 7.02365248513305e-05 Test RE 0.0021977418213013516\n",
      "29 Train Loss 0.00050808047 Test MSE 7.02365248513305e-05 Test RE 0.0021977418213013516\n",
      "30 Train Loss 0.00051297375 Test MSE 7.02365248513305e-05 Test RE 0.0021977418213013516\n",
      "31 Train Loss 0.0005105855 Test MSE 4.97376878123902e-05 Test RE 0.001849430267006093\n",
      "32 Train Loss 0.0005135135 Test MSE 4.97376878123902e-05 Test RE 0.001849430267006093\n",
      "33 Train Loss 0.00050381816 Test MSE 0.0001447401328840396 Test RE 0.003154929422618024\n",
      "34 Train Loss 0.00050532474 Test MSE 0.0001447401328840396 Test RE 0.003154929422618024\n",
      "35 Train Loss 0.00051435013 Test MSE 0.0001447401328840396 Test RE 0.003154929422618024\n",
      "36 Train Loss 0.00048752423 Test MSE 0.00016858181084083515 Test RE 0.0034048698991020754\n",
      "37 Train Loss 0.00025169243 Test MSE 0.00019022178570635116 Test RE 0.0036168066450415694\n",
      "38 Train Loss 5.2530184e-05 Test MSE 8.976003142790853e-06 Test RE 0.0007856636545369838\n",
      "39 Train Loss 4.4258373e-05 Test MSE 1.112597256039153e-05 Test RE 0.0008747101319025087\n",
      "40 Train Loss 3.5452722e-05 Test MSE 3.453054530158881e-05 Test RE 0.0015409795777649622\n",
      "41 Train Loss 3.0298579e-05 Test MSE 3.7103159318871735e-05 Test RE 0.0015973519283828978\n",
      "42 Train Loss 2.4952253e-05 Test MSE 3.233521328972112e-05 Test RE 0.0014911901619656688\n",
      "43 Train Loss 2.0934245e-05 Test MSE 2.7649785029921374e-05 Test RE 0.0013789262665445438\n",
      "44 Train Loss 1.786542e-05 Test MSE 2.356282478271073e-05 Test RE 0.00127294266141522\n",
      "45 Train Loss 1.5322341e-05 Test MSE 2.0899042422253994e-05 Test RE 0.0011988320874044714\n",
      "46 Train Loss 1.5399102e-05 Test MSE 2.0899042422253994e-05 Test RE 0.0011988320874044714\n",
      "47 Train Loss 8.481995e-06 Test MSE 7.23706369712957e-06 Test RE 0.0007054664460740321\n",
      "48 Train Loss 8.387759e-06 Test MSE 7.23706369712957e-06 Test RE 0.0007054664460740321\n",
      "49 Train Loss 8.475061e-06 Test MSE 7.23706369712957e-06 Test RE 0.0007054664460740321\n",
      "50 Train Loss 7.4347895e-06 Test MSE 1.3181650465633982e-05 Test RE 0.0009520945090484\n",
      "51 Train Loss 7.4802433e-06 Test MSE 1.3181650465633982e-05 Test RE 0.0009520945090484\n",
      "52 Train Loss 7.459526e-06 Test MSE 1.3181650465633982e-05 Test RE 0.0009520945090484\n",
      "53 Train Loss 6.487029e-06 Test MSE 3.4834693081112066e-05 Test RE 0.0015477512342553445\n",
      "54 Train Loss 6.568699e-06 Test MSE 3.4834693081112066e-05 Test RE 0.0015477512342553445\n",
      "55 Train Loss 6.541227e-06 Test MSE 3.4834693081112066e-05 Test RE 0.0015477512342553445\n",
      "56 Train Loss 4.389583e-06 Test MSE 3.679601712459498e-05 Test RE 0.0015907267010012687\n",
      "57 Train Loss 4.3889722e-06 Test MSE 3.679601712459498e-05 Test RE 0.0015907267010012687\n",
      "58 Train Loss 3.206015e-06 Test MSE 9.040836467675554e-06 Test RE 0.0007884959584873415\n",
      "59 Train Loss 3.2407518e-06 Test MSE 9.040836467675554e-06 Test RE 0.0007884959584873415\n",
      "60 Train Loss 3.2438345e-06 Test MSE 9.040836467675554e-06 Test RE 0.0007884959584873415\n",
      "61 Train Loss 2.2097306e-06 Test MSE 2.9262850007798624e-06 Test RE 0.0004485940153684319\n",
      "62 Train Loss 2.213844e-06 Test MSE 2.9262850007798624e-06 Test RE 0.0004485940153684319\n",
      "63 Train Loss 2.220309e-06 Test MSE 2.9262850007798624e-06 Test RE 0.0004485940153684319\n",
      "64 Train Loss 1.5503487e-06 Test MSE 1.4656000083203218e-06 Test RE 0.0003174701478077706\n",
      "65 Train Loss 1.5498687e-06 Test MSE 1.4656000083203218e-06 Test RE 0.0003174701478077706\n",
      "66 Train Loss 1.5160153e-06 Test MSE 1.4656000083203218e-06 Test RE 0.0003174701478077706\n",
      "67 Train Loss 1.2949823e-06 Test MSE 4.254226464686434e-07 Test RE 0.000171043063817567\n",
      "68 Train Loss 1.2952991e-06 Test MSE 4.254226464686434e-07 Test RE 0.000171043063817567\n",
      "69 Train Loss 1.2971534e-06 Test MSE 4.254226464686434e-07 Test RE 0.000171043063817567\n",
      "70 Train Loss 8.0404743e-07 Test MSE 3.945661086981139e-07 Test RE 0.0001647233075814913\n",
      "71 Train Loss 8.2064196e-07 Test MSE 3.945661086981139e-07 Test RE 0.0001647233075814913\n",
      "72 Train Loss 7.9850435e-07 Test MSE 3.945661086981139e-07 Test RE 0.0001647233075814913\n",
      "73 Train Loss 8.109775e-07 Test MSE 3.945661086981139e-07 Test RE 0.0001647233075814913\n",
      "74 Train Loss 6.9939944e-07 Test MSE 1.7605521705852602e-07 Test RE 0.00011003215387373246\n",
      "75 Train Loss 7.028075e-07 Test MSE 1.7605521705852602e-07 Test RE 0.00011003215387373246\n",
      "76 Train Loss 6.989616e-07 Test MSE 1.7605521705852602e-07 Test RE 0.00011003215387373246\n",
      "77 Train Loss 7.0478427e-07 Test MSE 1.7605521705852602e-07 Test RE 0.00011003215387373246\n",
      "78 Train Loss 6.517407e-07 Test MSE 1.4102027036232397e-06 Test RE 0.0003114124248894252\n",
      "79 Train Loss 6.4389184e-07 Test MSE 1.4102027036232397e-06 Test RE 0.0003114124248894252\n",
      "80 Train Loss 6.477235e-07 Test MSE 1.4102027036232397e-06 Test RE 0.0003114124248894252\n",
      "81 Train Loss 6.547663e-07 Test MSE 1.4102027036232397e-06 Test RE 0.0003114124248894252\n",
      "82 Train Loss 6.417713e-07 Test MSE 1.4102027036232397e-06 Test RE 0.0003114124248894252\n",
      "83 Train Loss 6.464344e-07 Test MSE 1.4102027036232397e-06 Test RE 0.0003114124248894252\n",
      "84 Train Loss 5.281143e-07 Test MSE 2.068568178084841e-06 Test RE 0.00037716387104730066\n",
      "85 Train Loss 5.407544e-07 Test MSE 2.068568178084841e-06 Test RE 0.00037716387104730066\n",
      "86 Train Loss 5.413863e-07 Test MSE 2.068568178084841e-06 Test RE 0.00037716387104730066\n",
      "87 Train Loss 5.234781e-07 Test MSE 2.068568178084841e-06 Test RE 0.00037716387104730066\n",
      "88 Train Loss 5.30379e-07 Test MSE 2.068568178084841e-06 Test RE 0.00037716387104730066\n",
      "89 Train Loss 5.378166e-07 Test MSE 2.068568178084841e-06 Test RE 0.00037716387104730066\n",
      "90 Train Loss 5.394018e-07 Test MSE 2.068568178084841e-06 Test RE 0.00037716387104730066\n",
      "91 Train Loss 5.418316e-07 Test MSE 2.068568178084841e-06 Test RE 0.00037716387104730066\n",
      "92 Train Loss 3.8704795e-07 Test MSE 8.036972195312524e-06 Test RE 0.0007434322515539184\n",
      "93 Train Loss 3.8748894e-07 Test MSE 8.036972195312524e-06 Test RE 0.0007434322515539184\n",
      "94 Train Loss 3.8941062e-07 Test MSE 8.036972195312524e-06 Test RE 0.0007434322515539184\n",
      "95 Train Loss 3.8410167e-07 Test MSE 8.036972195312524e-06 Test RE 0.0007434322515539184\n",
      "96 Train Loss 3.9260578e-07 Test MSE 8.036972195312524e-06 Test RE 0.0007434322515539184\n",
      "97 Train Loss 3.9125248e-07 Test MSE 8.036972195312524e-06 Test RE 0.0007434322515539184\n",
      "98 Train Loss 3.0722668e-07 Test MSE 2.335029699014327e-06 Test RE 0.0004007203233630771\n",
      "99 Train Loss 3.097269e-07 Test MSE 2.335029699014327e-06 Test RE 0.0004007203233630771\n",
      "100 Train Loss 3.0585068e-07 Test MSE 2.335029699014327e-06 Test RE 0.0004007203233630771\n",
      "101 Train Loss 3.0319893e-07 Test MSE 2.335029699014327e-06 Test RE 0.0004007203233630771\n",
      "102 Train Loss 3.0603266e-07 Test MSE 2.335029699014327e-06 Test RE 0.0004007203233630771\n",
      "103 Train Loss 3.070293e-07 Test MSE 2.335029699014327e-06 Test RE 0.0004007203233630771\n",
      "104 Train Loss 3.1041517e-07 Test MSE 2.335029699014327e-06 Test RE 0.0004007203233630771\n",
      "105 Train Loss 3.1513935e-07 Test MSE 2.335029699014327e-06 Test RE 0.0004007203233630771\n",
      "106 Train Loss 3.128076e-07 Test MSE 2.335029699014327e-06 Test RE 0.0004007203233630771\n",
      "107 Train Loss 2.6215997e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "108 Train Loss 2.6274662e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "109 Train Loss 2.5699256e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "110 Train Loss 2.5837184e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "111 Train Loss 2.5755403e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "112 Train Loss 2.6092405e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "113 Train Loss 2.6226832e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "114 Train Loss 2.6196764e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "115 Train Loss 2.6285298e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "116 Train Loss 2.5671514e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "117 Train Loss 2.6248279e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "118 Train Loss 2.598174e-07 Test MSE 3.968109639488529e-06 Test RE 0.0005223805477378169\n",
      "119 Train Loss 2.0769299e-07 Test MSE 2.507093728142418e-06 Test RE 0.00041522208990292465\n",
      "120 Train Loss 2.0916697e-07 Test MSE 2.507093728142418e-06 Test RE 0.00041522208990292465\n",
      "121 Train Loss 2.1134397e-07 Test MSE 2.507093728142418e-06 Test RE 0.00041522208990292465\n",
      "122 Train Loss 2.0707692e-07 Test MSE 2.507093728142418e-06 Test RE 0.00041522208990292465\n",
      "123 Train Loss 2.1314729e-07 Test MSE 2.507093728142418e-06 Test RE 0.00041522208990292465\n",
      "124 Train Loss 2.1044107e-07 Test MSE 2.507093728142418e-06 Test RE 0.00041522208990292465\n",
      "125 Train Loss 2.0803523e-07 Test MSE 2.507093728142418e-06 Test RE 0.00041522208990292465\n",
      "126 Train Loss 2.0866004e-07 Test MSE 2.507093728142418e-06 Test RE 0.00041522208990292465\n",
      "127 Train Loss 2.09485e-07 Test MSE 2.507093728142418e-06 Test RE 0.00041522208990292465\n",
      "128 Train Loss 1.377234e-07 Test MSE 1.3953229914816154e-06 Test RE 0.0003097651385449431\n",
      "129 Train Loss 1.4062681e-07 Test MSE 1.3953229914816154e-06 Test RE 0.0003097651385449431\n",
      "130 Train Loss 1.4207913e-07 Test MSE 1.3953229914816154e-06 Test RE 0.0003097651385449431\n",
      "131 Train Loss 1.4034939e-07 Test MSE 1.3953229914816154e-06 Test RE 0.0003097651385449431\n",
      "132 Train Loss 1.4057767e-07 Test MSE 1.3953229914816154e-06 Test RE 0.0003097651385449431\n",
      "133 Train Loss 9.943808e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "134 Train Loss 9.973336e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "135 Train Loss 1.01073326e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "136 Train Loss 1.0117421e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "137 Train Loss 1.0152239e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "138 Train Loss 9.912248e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "139 Train Loss 1.00931416e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "140 Train Loss 9.997256e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "141 Train Loss 1.010144e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "142 Train Loss 1.0152481e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "143 Train Loss 9.95736e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "144 Train Loss 9.965526e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "145 Train Loss 1.0050428e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "146 Train Loss 1.0051683e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "147 Train Loss 1.0220514e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "148 Train Loss 1.01145275e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "149 Train Loss 1.0149471e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "150 Train Loss 1.00068334e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "151 Train Loss 1.0189648e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "152 Train Loss 1.0155614e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "153 Train Loss 1.01310725e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "154 Train Loss 1.0059533e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "155 Train Loss 1.013892e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "156 Train Loss 1.000355e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "157 Train Loss 1.0029875e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "158 Train Loss 1.0076842e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "159 Train Loss 1.0018803e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "160 Train Loss 9.976541e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "161 Train Loss 1.0169592e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "162 Train Loss 9.9213494e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "163 Train Loss 1.00810816e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "164 Train Loss 9.9437734e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "165 Train Loss 1.0029498e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "166 Train Loss 1.0083538e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "167 Train Loss 1.0093054e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "168 Train Loss 1.0034372e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "169 Train Loss 1.00970354e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "170 Train Loss 1.00395006e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "171 Train Loss 1.0196542e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "172 Train Loss 9.9297004e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "173 Train Loss 9.929322e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "174 Train Loss 1.0142204e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "175 Train Loss 1.0021237e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "176 Train Loss 1.01315756e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "177 Train Loss 9.968441e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "178 Train Loss 1.01665215e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "179 Train Loss 9.908533e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "180 Train Loss 1.0021379e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "181 Train Loss 1.00491256e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "182 Train Loss 1.00285725e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "183 Train Loss 9.995308e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "184 Train Loss 1.01198445e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "185 Train Loss 1.0010513e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "186 Train Loss 1.0132839e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "187 Train Loss 1.00823094e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "188 Train Loss 9.9863456e-08 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "189 Train Loss 1.0033633e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "190 Train Loss 1.00499e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "191 Train Loss 1.01659225e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "192 Train Loss 1.0043986e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "193 Train Loss 1.012232e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "194 Train Loss 1.0081517e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "195 Train Loss 1.00621456e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "196 Train Loss 1.0042424e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "197 Train Loss 1.0241684e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "198 Train Loss 1.0134004e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "199 Train Loss 1.0219617e-07 Test MSE 5.4338672011207254e-08 Test RE 6.112933552135906e-05\n",
      "Training time: 83.49\n",
      "Training time: 83.49\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (m_lambda): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 1.8794563 Test MSE 14.24084573374684 Test RE 0.9896076770412727\n",
      "1 Train Loss 1.8221953 Test MSE 14.609290525359793 Test RE 1.0023276886863026\n",
      "2 Train Loss 1.7453878 Test MSE 14.651682411231743 Test RE 1.003780866092757\n",
      "3 Train Loss 1.6945288 Test MSE 14.92815156933016 Test RE 1.0132070027869151\n",
      "4 Train Loss 1.6252518 Test MSE 14.26076962281485 Test RE 0.9902996985151636\n",
      "5 Train Loss 0.88813734 Test MSE 13.948492960343687 Test RE 0.9793970883867262\n",
      "6 Train Loss 0.7291193 Test MSE 13.34276957110181 Test RE 0.9578955544400444\n",
      "7 Train Loss 0.71325696 Test MSE 13.275599037355878 Test RE 0.9554813802947684\n",
      "8 Train Loss 0.7159211 Test MSE 13.285459274621385 Test RE 0.9558361486317992\n",
      "9 Train Loss 0.71839094 Test MSE 13.17962939186781 Test RE 0.9520215164059098\n",
      "10 Train Loss 0.67713284 Test MSE 12.108930059390339 Test RE 0.9125318891596182\n",
      "11 Train Loss 0.64461774 Test MSE 11.702156949826097 Test RE 0.8970736993299632\n",
      "12 Train Loss 0.56565416 Test MSE 10.062655189348634 Test RE 0.8318623342902146\n",
      "13 Train Loss 0.5430166 Test MSE 9.639545635018289 Test RE 0.814185655543239\n",
      "14 Train Loss 0.5099044 Test MSE 8.430723731577181 Test RE 0.7614258097059496\n",
      "15 Train Loss 0.45351812 Test MSE 7.244318437611159 Test RE 0.7058199522902363\n",
      "16 Train Loss 0.38269144 Test MSE 6.110621805500282 Test RE 0.6482430474155922\n",
      "17 Train Loss 0.21854171 Test MSE 3.0761740470535948 Test RE 0.4599394024987551\n",
      "18 Train Loss 0.19063048 Test MSE 2.8797099683689584 Test RE 0.44500976367884715\n",
      "19 Train Loss 0.14062539 Test MSE 2.2315203317014696 Test RE 0.3917378981879875\n",
      "20 Train Loss 0.08117539 Test MSE 1.2561713247767907 Test RE 0.2939135459979149\n",
      "21 Train Loss 0.060519703 Test MSE 0.8182153058848669 Test RE 0.23720779935583505\n",
      "22 Train Loss 0.039601713 Test MSE 0.3587997560103426 Test RE 0.15708012359619883\n",
      "23 Train Loss 0.01950081 Test MSE 0.17225695403040034 Test RE 0.1088387503008842\n",
      "24 Train Loss 0.007289789 Test MSE 0.04211868937405582 Test RE 0.053818623910994706\n",
      "25 Train Loss 0.0027725806 Test MSE 0.018450700746816574 Test RE 0.035620630084580295\n",
      "26 Train Loss 0.0025263638 Test MSE 0.018362451464642607 Test RE 0.035535341647268744\n",
      "27 Train Loss 0.001930137 Test MSE 0.010097574826065069 Test RE 0.02635140069428483\n",
      "28 Train Loss 0.0012216405 Test MSE 0.0014327009265304408 Test RE 0.00992596948360798\n",
      "29 Train Loss 0.00077550346 Test MSE 0.00041365003639875255 Test RE 0.005333492616850899\n",
      "30 Train Loss 0.0005043847 Test MSE 1.8706447189874022e-05 Test RE 0.0011342030763502983\n",
      "31 Train Loss 0.00019499302 Test MSE 0.00043513222111776057 Test RE 0.0054702325143157335\n",
      "32 Train Loss 6.7513734e-05 Test MSE 2.423520712695843e-05 Test RE 0.0012909770824207699\n",
      "33 Train Loss 6.0532984e-05 Test MSE 1.243900267325155e-05 Test RE 0.0009248854458514624\n",
      "34 Train Loss 5.524041e-05 Test MSE 8.108366724251688e-06 Test RE 0.0007467270023980768\n",
      "35 Train Loss 5.081967e-05 Test MSE 4.121620447500397e-06 Test RE 0.0005323891091764814\n",
      "36 Train Loss 4.674536e-05 Test MSE 1.789094174859387e-06 Test RE 0.0003507613764349197\n",
      "37 Train Loss 4.3663164e-05 Test MSE 6.773876642446825e-07 Test RE 0.00021583099186562438\n",
      "38 Train Loss 4.2700314e-05 Test MSE 6.773876642446825e-07 Test RE 0.00021583099186562438\n",
      "39 Train Loss 4.3462696e-05 Test MSE 6.773876642446825e-07 Test RE 0.00021583099186562438\n",
      "40 Train Loss 4.0299557e-05 Test MSE 8.938490357034465e-08 Test RE 7.8402020090758e-05\n",
      "41 Train Loss 4.0419454e-05 Test MSE 8.938490357034465e-08 Test RE 7.8402020090758e-05\n",
      "42 Train Loss 3.8981005e-05 Test MSE 4.001474068843878e-07 Test RE 0.00016588425558980088\n",
      "43 Train Loss 3.9098682e-05 Test MSE 4.001474068843878e-07 Test RE 0.00016588425558980088\n",
      "44 Train Loss 3.354715e-05 Test MSE 2.1624366426230796e-07 Test RE 0.00012194580381978615\n",
      "45 Train Loss 3.3515134e-05 Test MSE 2.1624366426230796e-07 Test RE 0.00012194580381978615\n",
      "46 Train Loss 3.381592e-05 Test MSE 2.1624366426230796e-07 Test RE 0.00012194580381978615\n",
      "47 Train Loss 3.293579e-05 Test MSE 2.965717427826441e-07 Test RE 0.00014281047032420417\n",
      "48 Train Loss 3.3012584e-05 Test MSE 2.965717427826441e-07 Test RE 0.00014281047032420417\n",
      "49 Train Loss 3.0759817e-05 Test MSE 7.826131864516327e-08 Test RE 7.33615916801486e-05\n",
      "50 Train Loss 3.0619336e-05 Test MSE 7.826131864516327e-08 Test RE 7.33615916801486e-05\n",
      "51 Train Loss 3.0526855e-05 Test MSE 7.826131864516327e-08 Test RE 7.33615916801486e-05\n",
      "52 Train Loss 2.9936915e-05 Test MSE 1.1742484717751384e-06 Test RE 0.0002841679973372985\n",
      "53 Train Loss 2.9842698e-05 Test MSE 1.1742484717751384e-06 Test RE 0.0002841679973372985\n",
      "54 Train Loss 2.9110346e-05 Test MSE 2.1851188916840033e-06 Test RE 0.0003876436736640608\n",
      "55 Train Loss 2.9180535e-05 Test MSE 2.1851188916840033e-06 Test RE 0.0003876436736640608\n",
      "56 Train Loss 2.9468523e-05 Test MSE 2.1851188916840033e-06 Test RE 0.0003876436736640608\n",
      "57 Train Loss 2.8928198e-05 Test MSE 1.6335803363091022e-06 Test RE 0.0003351702114318614\n",
      "58 Train Loss 2.8694132e-05 Test MSE 1.6335803363091022e-06 Test RE 0.0003351702114318614\n",
      "59 Train Loss 2.9009063e-05 Test MSE 1.6335803363091022e-06 Test RE 0.0003351702114318614\n",
      "60 Train Loss 2.8891847e-05 Test MSE 1.706237874980349e-06 Test RE 0.0003425428871419522\n",
      "61 Train Loss 2.9200317e-05 Test MSE 1.706237874980349e-06 Test RE 0.0003425428871419522\n",
      "62 Train Loss 2.8950668e-05 Test MSE 1.706237874980349e-06 Test RE 0.0003425428871419522\n",
      "63 Train Loss 2.9182374e-05 Test MSE 1.706237874980349e-06 Test RE 0.0003425428871419522\n",
      "64 Train Loss 2.8696675e-05 Test MSE 7.979252498898133e-07 Test RE 0.00023424820353548038\n",
      "65 Train Loss 2.8576387e-05 Test MSE 7.979252498898133e-07 Test RE 0.00023424820353548038\n",
      "66 Train Loss 2.8716942e-05 Test MSE 7.979252498898133e-07 Test RE 0.00023424820353548038\n",
      "67 Train Loss 2.8529885e-05 Test MSE 4.6225551480614983e-07 Test RE 0.0001782937893605782\n",
      "68 Train Loss 2.8494052e-05 Test MSE 4.6225551480614983e-07 Test RE 0.0001782937893605782\n",
      "69 Train Loss 2.8351284e-05 Test MSE 4.6225551480614983e-07 Test RE 0.0001782937893605782\n",
      "70 Train Loss 2.8676506e-05 Test MSE 4.6225551480614983e-07 Test RE 0.0001782937893605782\n",
      "71 Train Loss 2.8581784e-05 Test MSE 4.6225551480614983e-07 Test RE 0.0001782937893605782\n",
      "72 Train Loss 2.8241555e-05 Test MSE 5.790567237209676e-08 Test RE 6.310383003504343e-05\n",
      "73 Train Loss 2.8643695e-05 Test MSE 5.790567237209676e-08 Test RE 6.310383003504343e-05\n",
      "74 Train Loss 2.8440956e-05 Test MSE 5.790567237209676e-08 Test RE 6.310383003504343e-05\n",
      "75 Train Loss 2.8080018e-05 Test MSE 2.8016418519649775e-06 Test RE 0.00043893627429022753\n",
      "76 Train Loss 2.8005572e-05 Test MSE 2.8016418519649775e-06 Test RE 0.00043893627429022753\n",
      "77 Train Loss 2.6940606e-05 Test MSE 2.186721464425236e-07 Test RE 0.0001226286363182669\n",
      "78 Train Loss 2.7063827e-05 Test MSE 2.186721464425236e-07 Test RE 0.0001226286363182669\n",
      "79 Train Loss 2.553369e-05 Test MSE 1.7222575027897623e-06 Test RE 0.00034414717386655657\n",
      "80 Train Loss 2.5946141e-05 Test MSE 1.7222575027897623e-06 Test RE 0.00034414717386655657\n",
      "81 Train Loss 2.600126e-05 Test MSE 1.7222575027897623e-06 Test RE 0.00034414717386655657\n",
      "82 Train Loss 2.501022e-05 Test MSE 8.430805011429296e-08 Test RE 7.614294801161076e-05\n",
      "83 Train Loss 2.509992e-05 Test MSE 8.430805011429296e-08 Test RE 7.614294801161076e-05\n",
      "84 Train Loss 2.5105948e-05 Test MSE 8.430805011429296e-08 Test RE 7.614294801161076e-05\n",
      "85 Train Loss 2.5096764e-05 Test MSE 8.430805011429296e-08 Test RE 7.614294801161076e-05\n",
      "86 Train Loss 2.402432e-05 Test MSE 3.733832728380897e-06 Test RE 0.0005067253062834387\n",
      "87 Train Loss 2.3818066e-05 Test MSE 3.733832728380897e-06 Test RE 0.0005067253062834387\n",
      "88 Train Loss 2.285651e-05 Test MSE 9.982207408453287e-06 Test RE 0.0008285304219389133\n",
      "89 Train Loss 2.298244e-05 Test MSE 9.982207408453287e-06 Test RE 0.0008285304219389133\n",
      "90 Train Loss 2.207906e-05 Test MSE 9.957281971851987e-06 Test RE 0.0008274953607847529\n",
      "91 Train Loss 2.2003353e-05 Test MSE 9.957281971851987e-06 Test RE 0.0008274953607847529\n",
      "92 Train Loss 2.1919803e-05 Test MSE 1.2228384487920242e-05 Test RE 0.0009170219001308461\n",
      "93 Train Loss 2.1905122e-05 Test MSE 1.2228384487920242e-05 Test RE 0.0009170219001308461\n",
      "94 Train Loss 2.1695847e-05 Test MSE 1.2228384487920242e-05 Test RE 0.0009170219001308461\n",
      "95 Train Loss 2.1816582e-05 Test MSE 1.2228384487920242e-05 Test RE 0.0009170219001308461\n",
      "96 Train Loss 2.1778646e-05 Test MSE 1.6579324651035127e-06 Test RE 0.00033765919652914596\n",
      "97 Train Loss 2.181342e-05 Test MSE 1.6579324651035127e-06 Test RE 0.00033765919652914596\n",
      "98 Train Loss 2.1746828e-05 Test MSE 1.6579324651035127e-06 Test RE 0.00033765919652914596\n",
      "99 Train Loss 2.1595137e-05 Test MSE 5.318240155113378e-06 Test RE 0.0006047545397667537\n",
      "100 Train Loss 2.1721284e-05 Test MSE 5.318240155113378e-06 Test RE 0.0006047545397667537\n",
      "101 Train Loss 2.1528693e-05 Test MSE 5.318240155113378e-06 Test RE 0.0006047545397667537\n",
      "102 Train Loss 2.1653826e-05 Test MSE 5.318240155113378e-06 Test RE 0.0006047545397667537\n",
      "103 Train Loss 2.163773e-05 Test MSE 5.318240155113378e-06 Test RE 0.0006047545397667537\n",
      "104 Train Loss 2.1734064e-05 Test MSE 5.318240155113378e-06 Test RE 0.0006047545397667537\n",
      "105 Train Loss 2.1796252e-05 Test MSE 5.318240155113378e-06 Test RE 0.0006047545397667537\n",
      "106 Train Loss 2.1521246e-05 Test MSE 4.3809171897135645e-06 Test RE 0.0005488803544804863\n",
      "107 Train Loss 2.1389402e-05 Test MSE 4.3809171897135645e-06 Test RE 0.0005488803544804863\n",
      "108 Train Loss 2.147618e-05 Test MSE 4.3809171897135645e-06 Test RE 0.0005488803544804863\n",
      "109 Train Loss 2.1326081e-05 Test MSE 3.243241219451407e-06 Test RE 0.0004722639446330147\n",
      "110 Train Loss 2.1479269e-05 Test MSE 3.243241219451407e-06 Test RE 0.0004722639446330147\n",
      "111 Train Loss 2.135431e-05 Test MSE 3.243241219451407e-06 Test RE 0.0004722639446330147\n",
      "112 Train Loss 2.1531754e-05 Test MSE 3.243241219451407e-06 Test RE 0.0004722639446330147\n",
      "113 Train Loss 2.0387704e-05 Test MSE 8.225223130635168e-08 Test RE 7.520886053456097e-05\n",
      "114 Train Loss 2.0362637e-05 Test MSE 8.225223130635168e-08 Test RE 7.520886053456097e-05\n",
      "115 Train Loss 1.9264624e-05 Test MSE 6.134595877245376e-06 Test RE 0.0006495134428395668\n",
      "116 Train Loss 1.9103996e-05 Test MSE 6.134595877245376e-06 Test RE 0.0006495134428395668\n",
      "117 Train Loss 1.9194345e-05 Test MSE 6.134595877245376e-06 Test RE 0.0006495134428395668\n",
      "118 Train Loss 1.9290914e-05 Test MSE 6.134595877245376e-06 Test RE 0.0006495134428395668\n",
      "119 Train Loss 1.9305922e-05 Test MSE 6.134595877245376e-06 Test RE 0.0006495134428395668\n",
      "120 Train Loss 1.9506679e-05 Test MSE 6.134595877245376e-06 Test RE 0.0006495134428395668\n",
      "121 Train Loss 1.9318186e-05 Test MSE 6.134595877245376e-06 Test RE 0.0006495134428395668\n",
      "122 Train Loss 1.8476507e-05 Test MSE 1.6004588474488742e-06 Test RE 0.0003317549569240645\n",
      "123 Train Loss 1.8500034e-05 Test MSE 1.6004588474488742e-06 Test RE 0.0003317549569240645\n",
      "124 Train Loss 1.7819357e-05 Test MSE 2.648999204951929e-06 Test RE 0.00042681146682057837\n",
      "125 Train Loss 1.7873568e-05 Test MSE 2.648999204951929e-06 Test RE 0.00042681146682057837\n",
      "126 Train Loss 1.7746888e-05 Test MSE 2.648999204951929e-06 Test RE 0.00042681146682057837\n",
      "127 Train Loss 1.7898903e-05 Test MSE 2.648999204951929e-06 Test RE 0.00042681146682057837\n",
      "128 Train Loss 1.7316694e-05 Test MSE 1.0089661283650647e-07 Test RE 8.329778599303825e-05\n",
      "129 Train Loss 1.730255e-05 Test MSE 1.0089661283650647e-07 Test RE 8.329778599303825e-05\n",
      "130 Train Loss 1.6420838e-05 Test MSE 1.2475989132594094e-05 Test RE 0.0009262594646395071\n",
      "131 Train Loss 1.6434507e-05 Test MSE 1.2475989132594094e-05 Test RE 0.0009262594646395071\n",
      "132 Train Loss 1.6449841e-05 Test MSE 1.2475989132594094e-05 Test RE 0.0009262594646395071\n",
      "133 Train Loss 1.31972765e-05 Test MSE 4.638627216353064e-06 Test RE 0.0005647937740928931\n",
      "134 Train Loss 1.3275971e-05 Test MSE 4.638627216353064e-06 Test RE 0.0005647937740928931\n",
      "135 Train Loss 1.070357e-05 Test MSE 3.2051538620383477e-06 Test RE 0.00046948271349361013\n",
      "136 Train Loss 1.0668355e-05 Test MSE 3.2051538620383477e-06 Test RE 0.00046948271349361013\n",
      "137 Train Loss 9.39364e-06 Test MSE 1.4898457988161e-06 Test RE 0.00032008537045626745\n",
      "138 Train Loss 9.360046e-06 Test MSE 1.4898457988161e-06 Test RE 0.00032008537045626745\n",
      "139 Train Loss 9.379671e-06 Test MSE 1.4898457988161e-06 Test RE 0.00032008537045626745\n",
      "140 Train Loss 7.920227e-06 Test MSE 5.187734765501011e-07 Test RE 0.0001888791617419299\n",
      "141 Train Loss 7.9488e-06 Test MSE 5.187734765501011e-07 Test RE 0.0001888791617419299\n",
      "142 Train Loss 7.939622e-06 Test MSE 5.187734765501011e-07 Test RE 0.0001888791617419299\n",
      "143 Train Loss 7.956063e-06 Test MSE 5.187734765501011e-07 Test RE 0.0001888791617419299\n",
      "144 Train Loss 7.88546e-06 Test MSE 5.187734765501011e-07 Test RE 0.0001888791617419299\n",
      "145 Train Loss 7.118381e-06 Test MSE 2.6271509209428445e-06 Test RE 0.00042504770532108844\n",
      "146 Train Loss 7.1244003e-06 Test MSE 2.6271509209428445e-06 Test RE 0.00042504770532108844\n",
      "147 Train Loss 7.1346085e-06 Test MSE 2.6271509209428445e-06 Test RE 0.00042504770532108844\n",
      "148 Train Loss 7.132987e-06 Test MSE 2.6271509209428445e-06 Test RE 0.00042504770532108844\n",
      "149 Train Loss 6.557557e-06 Test MSE 1.9310085247650764e-07 Test RE 0.00011523575732180888\n",
      "150 Train Loss 6.6430616e-06 Test MSE 1.9310085247650764e-07 Test RE 0.00011523575732180888\n",
      "151 Train Loss 5.115228e-06 Test MSE 1.449259720600047e-06 Test RE 0.0003156954159624517\n",
      "152 Train Loss 5.192763e-06 Test MSE 1.449259720600047e-06 Test RE 0.0003156954159624517\n",
      "153 Train Loss 4.528452e-06 Test MSE 7.258229822390683e-07 Test RE 0.00022341407113904608\n",
      "154 Train Loss 4.5417596e-06 Test MSE 7.258229822390683e-07 Test RE 0.00022341407113904608\n",
      "155 Train Loss 3.7267603e-06 Test MSE 1.302248809128819e-07 Test RE 9.463290003003622e-05\n",
      "156 Train Loss 3.7487557e-06 Test MSE 1.302248809128819e-07 Test RE 9.463290003003622e-05\n",
      "157 Train Loss 3.7116592e-06 Test MSE 1.302248809128819e-07 Test RE 9.463290003003622e-05\n",
      "158 Train Loss 3.686606e-06 Test MSE 1.302248809128819e-07 Test RE 9.463290003003622e-05\n",
      "159 Train Loss 3.7058728e-06 Test MSE 1.302248809128819e-07 Test RE 9.463290003003622e-05\n",
      "160 Train Loss 3.5862172e-06 Test MSE 4.744004852546863e-07 Test RE 0.00018062078568434196\n",
      "161 Train Loss 3.616139e-06 Test MSE 4.744004852546863e-07 Test RE 0.00018062078568434196\n",
      "162 Train Loss 3.5583057e-06 Test MSE 4.744004852546863e-07 Test RE 0.00018062078568434196\n",
      "163 Train Loss 3.6178128e-06 Test MSE 4.744004852546863e-07 Test RE 0.00018062078568434196\n",
      "164 Train Loss 3.4128977e-06 Test MSE 1.870359810098284e-07 Test RE 0.0001134116700556883\n",
      "165 Train Loss 3.397631e-06 Test MSE 1.870359810098284e-07 Test RE 0.0001134116700556883\n",
      "166 Train Loss 3.392804e-06 Test MSE 1.870359810098284e-07 Test RE 0.0001134116700556883\n",
      "167 Train Loss 3.417116e-06 Test MSE 1.870359810098284e-07 Test RE 0.0001134116700556883\n",
      "168 Train Loss 3.4010282e-06 Test MSE 1.870359810098284e-07 Test RE 0.0001134116700556883\n",
      "169 Train Loss 3.410262e-06 Test MSE 1.870359810098284e-07 Test RE 0.0001134116700556883\n",
      "170 Train Loss 2.7019794e-06 Test MSE 1.0662379051886485e-07 Test RE 8.56292664656082e-05\n",
      "171 Train Loss 2.7002397e-06 Test MSE 1.0662379051886485e-07 Test RE 8.56292664656082e-05\n",
      "172 Train Loss 2.712131e-06 Test MSE 1.0662379051886485e-07 Test RE 8.56292664656082e-05\n",
      "173 Train Loss 2.5761171e-06 Test MSE 1.1325868790596624e-06 Test RE 0.00027908142241808633\n",
      "174 Train Loss 2.5744687e-06 Test MSE 1.1325868790596624e-06 Test RE 0.00027908142241808633\n",
      "175 Train Loss 2.5673808e-06 Test MSE 1.1325868790596624e-06 Test RE 0.00027908142241808633\n",
      "176 Train Loss 2.580476e-06 Test MSE 1.1325868790596624e-06 Test RE 0.00027908142241808633\n",
      "177 Train Loss 2.2231854e-06 Test MSE 1.3657249904898783e-07 Test RE 9.691182965964015e-05\n",
      "178 Train Loss 2.2198838e-06 Test MSE 1.3657249904898783e-07 Test RE 9.691182965964015e-05\n",
      "179 Train Loss 2.2189997e-06 Test MSE 1.3657249904898783e-07 Test RE 9.691182965964015e-05\n",
      "180 Train Loss 2.222008e-06 Test MSE 1.3657249904898783e-07 Test RE 9.691182965964015e-05\n",
      "181 Train Loss 2.2261195e-06 Test MSE 1.3657249904898783e-07 Test RE 9.691182965964015e-05\n",
      "182 Train Loss 2.2204183e-06 Test MSE 1.3657249904898783e-07 Test RE 9.691182965964015e-05\n",
      "183 Train Loss 2.2179129e-06 Test MSE 1.3657249904898783e-07 Test RE 9.691182965964015e-05\n",
      "184 Train Loss 2.1661333e-06 Test MSE 2.4179447637123758e-08 Test RE 4.077728931634384e-05\n",
      "185 Train Loss 2.1594503e-06 Test MSE 2.4179447637123758e-08 Test RE 4.077728931634384e-05\n",
      "186 Train Loss 2.158127e-06 Test MSE 2.4179447637123758e-08 Test RE 4.077728931634384e-05\n",
      "187 Train Loss 2.1604592e-06 Test MSE 2.4179447637123758e-08 Test RE 4.077728931634384e-05\n",
      "188 Train Loss 2.156494e-06 Test MSE 2.4179447637123758e-08 Test RE 4.077728931634384e-05\n",
      "189 Train Loss 2.1637925e-06 Test MSE 2.4179447637123758e-08 Test RE 4.077728931634384e-05\n",
      "190 Train Loss 2.1512183e-06 Test MSE 2.4179447637123758e-08 Test RE 4.077728931634384e-05\n",
      "191 Train Loss 2.1574178e-06 Test MSE 2.4179447637123758e-08 Test RE 4.077728931634384e-05\n",
      "192 Train Loss 1.9811168e-06 Test MSE 1.2651749311780098e-07 Test RE 9.327611598753836e-05\n",
      "193 Train Loss 1.9883646e-06 Test MSE 1.2651749311780098e-07 Test RE 9.327611598753836e-05\n",
      "194 Train Loss 1.9814224e-06 Test MSE 1.2651749311780098e-07 Test RE 9.327611598753836e-05\n",
      "195 Train Loss 1.9889842e-06 Test MSE 1.2651749311780098e-07 Test RE 9.327611598753836e-05\n",
      "196 Train Loss 1.9176605e-06 Test MSE 3.0368370796482164e-07 Test RE 0.00014451266549378233\n",
      "197 Train Loss 1.927721e-06 Test MSE 3.0368370796482164e-07 Test RE 0.00014451266549378233\n",
      "198 Train Loss 1.9232928e-06 Test MSE 3.0368370796482164e-07 Test RE 0.00014451266549378233\n",
      "199 Train Loss 1.9178992e-06 Test MSE 3.0368370796482164e-07 Test RE 0.00014451266549378233\n",
      "Training time: 85.18\n",
      "Training time: 85.18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (m_lambda): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 1.850299 Test MSE 14.618030986562308 Test RE 1.0026274806678428\n",
      "1 Train Loss 1.8572567 Test MSE 14.29667303105122 Test RE 0.9915455213111468\n",
      "2 Train Loss 1.8104322 Test MSE 14.539707500288568 Test RE 0.9999378314046704\n",
      "3 Train Loss 1.7570381 Test MSE 15.256346699914143 Test RE 1.0242841196518695\n",
      "4 Train Loss 1.7116251 Test MSE 15.753787023417265 Test RE 1.0408488093606898\n",
      "5 Train Loss 1.6397388 Test MSE 15.643647943151464 Test RE 1.0372039968280327\n",
      "6 Train Loss 1.5811828 Test MSE 15.386873411550408 Test RE 1.0286564538379128\n",
      "7 Train Loss 1.1005453 Test MSE 15.516462567322192 Test RE 1.032979074254552\n",
      "8 Train Loss 0.848366 Test MSE 15.067187076764089 Test RE 1.0179143927266237\n",
      "9 Train Loss 0.84221935 Test MSE 14.945601946295191 Test RE 1.0137990278624402\n",
      "10 Train Loss 0.8357321 Test MSE 14.451873189677 Test RE 0.996912946080498\n",
      "11 Train Loss 0.83692515 Test MSE 14.431097719560753 Test RE 0.9961961260647716\n",
      "12 Train Loss 0.82275385 Test MSE 14.408870307008435 Test RE 0.9954286378378462\n",
      "13 Train Loss 0.79732287 Test MSE 13.989774303360921 Test RE 0.980845307815642\n",
      "14 Train Loss 0.7595706 Test MSE 13.294168863554573 Test RE 0.9561494075043575\n",
      "15 Train Loss 0.7490022 Test MSE 13.05705766087853 Test RE 0.9475842329393099\n",
      "16 Train Loss 0.7468061 Test MSE 12.920794196009473 Test RE 0.9426267700645257\n",
      "17 Train Loss 0.7392638 Test MSE 12.610973420066168 Test RE 0.9312568278615381\n",
      "18 Train Loss 0.7294328 Test MSE 12.3920969907069 Test RE 0.923139994117104\n",
      "19 Train Loss 0.71126217 Test MSE 11.781708510108931 Test RE 0.9001176996951129\n",
      "20 Train Loss 0.6376604 Test MSE 10.167593795657188 Test RE 0.8361886310445773\n",
      "21 Train Loss 0.6205711 Test MSE 9.878784819122819 Test RE 0.8242271719624272\n",
      "22 Train Loss 0.5880279 Test MSE 9.82562311889207 Test RE 0.8220064318901629\n",
      "23 Train Loss 0.54966426 Test MSE 9.274130324361387 Test RE 0.7986045165653403\n",
      "24 Train Loss 0.5323346 Test MSE 8.703276327438283 Test RE 0.7736357866955889\n",
      "25 Train Loss 0.5094625 Test MSE 7.92119201963581 Test RE 0.7380579038085038\n",
      "26 Train Loss 0.49425963 Test MSE 7.613952675447732 Test RE 0.7236028210823773\n",
      "27 Train Loss 0.43405733 Test MSE 6.687768404306022 Test RE 0.6781656328014498\n",
      "28 Train Loss 0.31577563 Test MSE 4.987347249276183 Test RE 0.585638970530516\n",
      "29 Train Loss 0.25819135 Test MSE 3.9569573028421887 Test RE 0.5216459583070837\n",
      "30 Train Loss 0.20217162 Test MSE 2.764326258852181 Test RE 0.43600333820413084\n",
      "31 Train Loss 0.18617693 Test MSE 2.720865571673662 Test RE 0.43256234152328665\n",
      "32 Train Loss 0.14646718 Test MSE 2.1474307638823604 Test RE 0.3842861655999066\n",
      "33 Train Loss 0.06754845 Test MSE 1.0234697630836518 Test RE 0.26529720410242036\n",
      "34 Train Loss 0.034706682 Test MSE 0.34260878753705365 Test RE 0.15349506382502598\n",
      "35 Train Loss 0.011363905 Test MSE 0.12485826094724019 Test RE 0.09266245572919554\n",
      "36 Train Loss 0.0043016872 Test MSE 0.05055532759682539 Test RE 0.05896287200243677\n",
      "37 Train Loss 0.002222673 Test MSE 0.011154017594718735 Test RE 0.027695603139333683\n",
      "38 Train Loss 0.00042148033 Test MSE 0.001075255761521684 Test RE 0.008599061478947095\n",
      "39 Train Loss 0.00011243248 Test MSE 0.00038963320041874965 Test RE 0.005176344149087498\n",
      "40 Train Loss 3.001723e-05 Test MSE 2.8768153007266216e-05 Test RE 0.0014065369794679721\n",
      "41 Train Loss 2.3363738e-05 Test MSE 1.67712098537686e-05 Test RE 0.0010739334296004947\n",
      "42 Train Loss 1.8930416e-05 Test MSE 7.638926746076429e-06 Test RE 0.0007247885727103216\n",
      "43 Train Loss 1.5292648e-05 Test MSE 3.854783966195319e-06 Test RE 0.0005148671538640966\n",
      "44 Train Loss 1.2416862e-05 Test MSE 1.7273294230662876e-06 Test RE 0.00034465354525202056\n",
      "45 Train Loss 1.0233299e-05 Test MSE 6.180159586847689e-07 Test RE 0.00020615553982539716\n",
      "46 Train Loss 1.012827e-05 Test MSE 6.180159586847689e-07 Test RE 0.00020615553982539716\n",
      "47 Train Loss 4.5250626e-06 Test MSE 2.5593861340299683e-05 Test RE 0.0013266704967722384\n",
      "48 Train Loss 4.561601e-06 Test MSE 2.5593861340299683e-05 Test RE 0.0013266704967722384\n",
      "49 Train Loss 3.2607036e-06 Test MSE 5.030110324311262e-06 Test RE 0.0005881443373853399\n",
      "50 Train Loss 3.2561704e-06 Test MSE 5.030110324311262e-06 Test RE 0.0005881443373853399\n",
      "51 Train Loss 3.3690194e-06 Test MSE 5.030110324311262e-06 Test RE 0.0005881443373853399\n",
      "52 Train Loss 3.3350727e-06 Test MSE 5.030110324311262e-06 Test RE 0.0005881443373853399\n",
      "53 Train Loss 2.8146153e-06 Test MSE 3.389724994585956e-07 Test RE 0.00015267832882861102\n",
      "54 Train Loss 2.793939e-06 Test MSE 3.389724994585956e-07 Test RE 0.00015267832882861102\n",
      "55 Train Loss 2.4599242e-06 Test MSE 9.140465494499706e-07 Test RE 0.0002507144247061472\n",
      "56 Train Loss 2.52317e-06 Test MSE 9.140465494499706e-07 Test RE 0.0002507144247061472\n",
      "57 Train Loss 2.4980511e-06 Test MSE 9.140465494499706e-07 Test RE 0.0002507144247061472\n",
      "58 Train Loss 2.5009674e-06 Test MSE 9.140465494499706e-07 Test RE 0.0002507144247061472\n",
      "59 Train Loss 1.8756217e-06 Test MSE 7.618263414650389e-07 Test RE 0.00022888807008631092\n",
      "60 Train Loss 1.8995539e-06 Test MSE 7.618263414650389e-07 Test RE 0.00022888807008631092\n",
      "61 Train Loss 1.9532197e-06 Test MSE 7.618263414650389e-07 Test RE 0.00022888807008631092\n",
      "62 Train Loss 1.449681e-06 Test MSE 1.635836054115627e-07 Test RE 0.00010606327980935921\n",
      "63 Train Loss 1.4758215e-06 Test MSE 1.635836054115627e-07 Test RE 0.00010606327980935921\n",
      "64 Train Loss 1.4577977e-06 Test MSE 1.635836054115627e-07 Test RE 0.00010606327980935921\n",
      "65 Train Loss 1.1922789e-06 Test MSE 2.757648303717177e-07 Test RE 0.0001377097226577164\n",
      "66 Train Loss 1.2197411e-06 Test MSE 2.757648303717177e-07 Test RE 0.0001377097226577164\n",
      "67 Train Loss 1.2164569e-06 Test MSE 2.757648303717177e-07 Test RE 0.0001377097226577164\n",
      "68 Train Loss 1.0321079e-06 Test MSE 1.4943548821528063e-06 Test RE 0.0003205693806855724\n",
      "69 Train Loss 1.0249688e-06 Test MSE 1.4943548821528063e-06 Test RE 0.0003205693806855724\n",
      "70 Train Loss 1.0158417e-06 Test MSE 1.4943548821528063e-06 Test RE 0.0003205693806855724\n",
      "71 Train Loss 1.0177581e-06 Test MSE 1.4943548821528063e-06 Test RE 0.0003205693806855724\n",
      "72 Train Loss 9.2806073e-07 Test MSE 2.7958701493876398e-06 Test RE 0.00043848391173219027\n",
      "73 Train Loss 9.3014575e-07 Test MSE 2.7958701493876398e-06 Test RE 0.00043848391173219027\n",
      "74 Train Loss 9.3082343e-07 Test MSE 2.7958701493876398e-06 Test RE 0.00043848391173219027\n",
      "75 Train Loss 9.195948e-07 Test MSE 2.7958701493876398e-06 Test RE 0.00043848391173219027\n",
      "76 Train Loss 9.2669245e-07 Test MSE 2.7958701493876398e-06 Test RE 0.00043848391173219027\n",
      "77 Train Loss 9.16963e-07 Test MSE 2.7958701493876398e-06 Test RE 0.00043848391173219027\n",
      "78 Train Loss 7.6080505e-07 Test MSE 5.582969963816017e-07 Test RE 0.00019594212355583107\n",
      "79 Train Loss 7.4518664e-07 Test MSE 5.582969963816017e-07 Test RE 0.00019594212355583107\n",
      "80 Train Loss 7.6221625e-07 Test MSE 5.582969963816017e-07 Test RE 0.00019594212355583107\n",
      "81 Train Loss 7.5022905e-07 Test MSE 5.582969963816017e-07 Test RE 0.00019594212355583107\n",
      "82 Train Loss 5.756865e-07 Test MSE 2.1259299391269702e-08 Test RE 3.823575224252378e-05\n",
      "83 Train Loss 5.810487e-07 Test MSE 2.1259299391269702e-08 Test RE 3.823575224252378e-05\n",
      "84 Train Loss 5.796349e-07 Test MSE 2.1259299391269702e-08 Test RE 3.823575224252378e-05\n",
      "85 Train Loss 5.850072e-07 Test MSE 2.1259299391269702e-08 Test RE 3.823575224252378e-05\n",
      "86 Train Loss 4.261802e-07 Test MSE 1.3863829571234405e-08 Test RE 3.087711890761571e-05\n",
      "87 Train Loss 4.2910312e-07 Test MSE 1.3863829571234405e-08 Test RE 3.087711890761571e-05\n",
      "88 Train Loss 4.28992e-07 Test MSE 1.3863829571234405e-08 Test RE 3.087711890761571e-05\n",
      "89 Train Loss 4.208288e-07 Test MSE 1.3863829571234405e-08 Test RE 3.087711890761571e-05\n",
      "90 Train Loss 4.2655304e-07 Test MSE 1.3863829571234405e-08 Test RE 3.087711890761571e-05\n",
      "91 Train Loss 4.290495e-07 Test MSE 1.3863829571234405e-08 Test RE 3.087711890761571e-05\n",
      "92 Train Loss 4.3171943e-07 Test MSE 1.3863829571234405e-08 Test RE 3.087711890761571e-05\n",
      "93 Train Loss 4.001093e-07 Test MSE 4.721468528305548e-08 Test RE 5.698147858927455e-05\n",
      "94 Train Loss 3.9562295e-07 Test MSE 4.721468528305548e-08 Test RE 5.698147858927455e-05\n",
      "95 Train Loss 3.982546e-07 Test MSE 4.721468528305548e-08 Test RE 5.698147858927455e-05\n",
      "96 Train Loss 3.999029e-07 Test MSE 4.721468528305548e-08 Test RE 5.698147858927455e-05\n",
      "97 Train Loss 3.981655e-07 Test MSE 4.721468528305548e-08 Test RE 5.698147858927455e-05\n",
      "98 Train Loss 3.9636296e-07 Test MSE 4.721468528305548e-08 Test RE 5.698147858927455e-05\n",
      "99 Train Loss 3.7272824e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "100 Train Loss 3.776519e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "101 Train Loss 3.8079858e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "102 Train Loss 3.69265e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "103 Train Loss 3.7467248e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "104 Train Loss 3.760013e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "105 Train Loss 3.8175958e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "106 Train Loss 3.7449445e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "107 Train Loss 3.7420915e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "108 Train Loss 3.7219627e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "109 Train Loss 3.725076e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "110 Train Loss 3.7777505e-07 Test MSE 4.617081038363778e-08 Test RE 5.634805287304329e-05\n",
      "111 Train Loss 3.3080872e-07 Test MSE 1.2131546389604482e-08 Test RE 2.8883727990412108e-05\n",
      "112 Train Loss 3.3166424e-07 Test MSE 1.2131546389604482e-08 Test RE 2.8883727990412108e-05\n",
      "113 Train Loss 3.3202468e-07 Test MSE 1.2131546389604482e-08 Test RE 2.8883727990412108e-05\n",
      "114 Train Loss 3.289432e-07 Test MSE 1.2131546389604482e-08 Test RE 2.8883727990412108e-05\n",
      "115 Train Loss 3.3019057e-07 Test MSE 1.2131546389604482e-08 Test RE 2.8883727990412108e-05\n",
      "116 Train Loss 3.2990033e-07 Test MSE 1.2131546389604482e-08 Test RE 2.8883727990412108e-05\n",
      "117 Train Loss 3.2746075e-07 Test MSE 1.2115080900454298e-08 Test RE 2.8864120177216123e-05\n",
      "118 Train Loss 3.2605178e-07 Test MSE 1.2115080900454298e-08 Test RE 2.8864120177216123e-05\n",
      "119 Train Loss 3.30492e-07 Test MSE 1.2115080900454298e-08 Test RE 2.8864120177216123e-05\n",
      "120 Train Loss 3.2905794e-07 Test MSE 1.2116554286840793e-08 Test RE 2.8865875291735585e-05\n",
      "121 Train Loss 3.310971e-07 Test MSE 1.2116554286840793e-08 Test RE 2.8865875291735585e-05\n",
      "122 Train Loss 3.3126773e-07 Test MSE 1.2116554286840793e-08 Test RE 2.8865875291735585e-05\n",
      "123 Train Loss 3.2638303e-07 Test MSE 1.2116554286840793e-08 Test RE 2.8865875291735585e-05\n",
      "124 Train Loss 3.3404143e-07 Test MSE 1.2116554286840793e-08 Test RE 2.8865875291735585e-05\n",
      "125 Train Loss 3.2998264e-07 Test MSE 1.2116554286840793e-08 Test RE 2.8865875291735585e-05\n",
      "126 Train Loss 3.3218865e-07 Test MSE 1.2116554286840793e-08 Test RE 2.8865875291735585e-05\n",
      "127 Train Loss 3.2812216e-07 Test MSE 1.2116554286840793e-08 Test RE 2.8865875291735585e-05\n",
      "128 Train Loss 3.2568462e-07 Test MSE 1.210318055768679e-08 Test RE 2.8849940440439798e-05\n",
      "129 Train Loss 3.2878816e-07 Test MSE 1.2102873936125813e-08 Test RE 2.8849574996424624e-05\n",
      "130 Train Loss 3.3222892e-07 Test MSE 1.2102873936125813e-08 Test RE 2.8849574996424624e-05\n",
      "131 Train Loss 3.2880354e-07 Test MSE 1.2102873936125813e-08 Test RE 2.8849574996424624e-05\n",
      "132 Train Loss 3.3239462e-07 Test MSE 1.2102873936125813e-08 Test RE 2.8849574996424624e-05\n",
      "133 Train Loss 3.3087434e-07 Test MSE 1.2102873936125813e-08 Test RE 2.8849574996424624e-05\n",
      "134 Train Loss 3.3245033e-07 Test MSE 1.2102873936125813e-08 Test RE 2.8849574996424624e-05\n",
      "135 Train Loss 3.2850383e-07 Test MSE 1.213469286970198e-08 Test RE 2.888747343968281e-05\n",
      "136 Train Loss 2.9604576e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "137 Train Loss 2.9807396e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "138 Train Loss 2.9772764e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "139 Train Loss 2.97647e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "140 Train Loss 2.9782757e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "141 Train Loss 2.9613668e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "142 Train Loss 2.965411e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "143 Train Loss 2.9680572e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "144 Train Loss 2.9795197e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "145 Train Loss 2.967976e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "146 Train Loss 2.9694712e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "147 Train Loss 2.947543e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "148 Train Loss 2.9914025e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "149 Train Loss 2.972705e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "150 Train Loss 2.9705612e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "151 Train Loss 2.9827146e-07 Test MSE 1.8471670672170508e-08 Test RE 3.564086643893381e-05\n",
      "152 Train Loss 2.8151413e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "153 Train Loss 2.7990535e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "154 Train Loss 2.7909638e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "155 Train Loss 2.8099208e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "156 Train Loss 2.8023717e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "157 Train Loss 2.796726e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "158 Train Loss 2.7936747e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "159 Train Loss 2.797362e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "160 Train Loss 2.7975815e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "161 Train Loss 2.8009183e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "162 Train Loss 2.7977993e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "163 Train Loss 2.8075732e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "164 Train Loss 2.8016038e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "165 Train Loss 2.805616e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "166 Train Loss 2.7851127e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "167 Train Loss 2.7882538e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "168 Train Loss 2.8103628e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "169 Train Loss 2.8048095e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "170 Train Loss 2.7937162e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "171 Train Loss 2.795776e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "172 Train Loss 2.7970773e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "173 Train Loss 2.79358e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "174 Train Loss 2.8022802e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "175 Train Loss 2.805119e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "176 Train Loss 2.8010527e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "177 Train Loss 2.8013037e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "178 Train Loss 2.7983518e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "179 Train Loss 2.7926617e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "180 Train Loss 2.818157e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "181 Train Loss 2.7977134e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "182 Train Loss 2.8049888e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "183 Train Loss 2.8041939e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "184 Train Loss 2.788315e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "185 Train Loss 2.7980832e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "186 Train Loss 2.8054652e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "187 Train Loss 2.803633e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "188 Train Loss 2.802372e-07 Test MSE 3.896649751492939e-08 Test RE 5.176555211167439e-05\n",
      "189 Train Loss 2.6758173e-07 Test MSE 1.4474352756858423e-08 Test RE 3.154966419707707e-05\n",
      "190 Train Loss 2.682244e-07 Test MSE 1.4474352756858423e-08 Test RE 3.154966419707707e-05\n",
      "191 Train Loss 2.6875708e-07 Test MSE 1.4474352756858423e-08 Test RE 3.154966419707707e-05\n",
      "192 Train Loss 2.675037e-07 Test MSE 1.4474352756858423e-08 Test RE 3.154966419707707e-05\n",
      "193 Train Loss 2.6783346e-07 Test MSE 1.4474352756858423e-08 Test RE 3.154966419707707e-05\n",
      "194 Train Loss 2.680076e-07 Test MSE 1.4474352756858423e-08 Test RE 3.154966419707707e-05\n",
      "195 Train Loss 2.6512572e-07 Test MSE 8.192924691079843e-08 Test RE 7.506105188915526e-05\n",
      "196 Train Loss 2.6478537e-07 Test MSE 8.192924691079843e-08 Test RE 7.506105188915526e-05\n",
      "197 Train Loss 2.6336608e-07 Test MSE 8.192924691079843e-08 Test RE 7.506105188915526e-05\n",
      "198 Train Loss 2.6326524e-07 Test MSE 8.192924691079843e-08 Test RE 7.506105188915526e-05\n",
      "199 Train Loss 2.6337764e-07 Test MSE 8.192924691079843e-08 Test RE 7.506105188915526e-05\n",
      "Training time: 89.56\n",
      "Training time: 89.56\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (m_lambda): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 2.0295627 Test MSE 14.364303270436979 Test RE 0.9938880013774846\n",
      "1 Train Loss 1.8446975 Test MSE 14.48470284684105 Test RE 0.998044624446489\n",
      "2 Train Loss 1.7888674 Test MSE 14.604297537314999 Test RE 1.002156392283001\n",
      "3 Train Loss 1.737411 Test MSE 15.330713520444403 Test RE 1.0267775132088712\n",
      "4 Train Loss 1.6774845 Test MSE 15.757396617244783 Test RE 1.0409680450164802\n",
      "5 Train Loss 1.5551639 Test MSE 16.526212124990327 Test RE 1.0660604367088042\n",
      "6 Train Loss 1.4868566 Test MSE 16.5776228812363 Test RE 1.0677173322752602\n",
      "7 Train Loss 1.424246 Test MSE 15.851780890901395 Test RE 1.0440810060993806\n",
      "8 Train Loss 0.9026145 Test MSE 14.112396783320916 Test RE 0.9851345578069193\n",
      "9 Train Loss 0.8037258 Test MSE 14.011175158618057 Test RE 0.9815952451064115\n",
      "10 Train Loss 0.7580764 Test MSE 13.685153328009278 Test RE 0.9701078047248521\n",
      "11 Train Loss 0.7507352 Test MSE 13.377738182355056 Test RE 0.9591499551516747\n",
      "12 Train Loss 0.7421585 Test MSE 13.176008195597076 Test RE 0.9518907201028362\n",
      "13 Train Loss 0.7384446 Test MSE 13.040210861406154 Test RE 0.9469727278596604\n",
      "14 Train Loss 0.7220426 Test MSE 12.640808844576954 Test RE 0.9323577749475972\n",
      "15 Train Loss 0.64955056 Test MSE 10.968916472269933 Test RE 0.8685144120312559\n",
      "16 Train Loss 0.6263455 Test MSE 10.22490997491971 Test RE 0.8385421762939289\n",
      "17 Train Loss 0.481172 Test MSE 7.474144871395381 Test RE 0.7169286243969125\n",
      "18 Train Loss 0.36490676 Test MSE 5.918170208956601 Test RE 0.6379533033018441\n",
      "19 Train Loss 0.30086786 Test MSE 4.927120124021216 Test RE 0.5820921467605867\n",
      "20 Train Loss 0.26497507 Test MSE 4.235443380154992 Test RE 0.5396902907577034\n",
      "21 Train Loss 0.21148255 Test MSE 2.9354274805053477 Test RE 0.4492942313983366\n",
      "22 Train Loss 0.13368462 Test MSE 1.9950499979299963 Test RE 0.37040092007609093\n",
      "23 Train Loss 0.051553946 Test MSE 0.729885013108853 Test RE 0.22403836156621765\n",
      "24 Train Loss 0.019415868 Test MSE 0.1842457113216889 Test RE 0.11256253328697664\n",
      "25 Train Loss 0.007017038 Test MSE 0.04724407480384554 Test RE 0.056999210337525696\n",
      "26 Train Loss 0.004708848 Test MSE 0.03578682626401118 Test RE 0.049608575581644006\n",
      "27 Train Loss 0.002657188 Test MSE 0.015491013936917493 Test RE 0.03263886794256618\n",
      "28 Train Loss 0.0013138038 Test MSE 0.003579857103115409 Test RE 0.015690183054082034\n",
      "29 Train Loss 0.0009923611 Test MSE 0.0010003647702953862 Test RE 0.008294197246342169\n",
      "30 Train Loss 0.00026236515 Test MSE 1.4638533158812658e-06 Test RE 0.0003172809119926412\n",
      "31 Train Loss 4.620237e-05 Test MSE 6.006253017997488e-06 Test RE 0.0006426832428965033\n",
      "32 Train Loss 3.855642e-05 Test MSE 5.6997639812015826e-06 Test RE 0.0006260710196219615\n",
      "33 Train Loss 3.2879456e-05 Test MSE 5.746835567016444e-06 Test RE 0.0006286509124778971\n",
      "34 Train Loss 2.7853925e-05 Test MSE 6.546265684369686e-06 Test RE 0.0006709528137525517\n",
      "35 Train Loss 2.4043638e-05 Test MSE 5.639571852219215e-06 Test RE 0.0006227564465923035\n",
      "36 Train Loss 2.07657e-05 Test MSE 5.072791435314411e-06 Test RE 0.0005906343055048614\n",
      "37 Train Loss 1.8397164e-05 Test MSE 5.281423110404871e-06 Test RE 0.0006026576108315769\n",
      "38 Train Loss 1.5989985e-05 Test MSE 5.237744202090465e-06 Test RE 0.0006001603598248696\n",
      "39 Train Loss 1.5959795e-05 Test MSE 5.237744202090465e-06 Test RE 0.0006001603598248696\n",
      "40 Train Loss 1.601251e-05 Test MSE 5.237744202090465e-06 Test RE 0.0006001603598248696\n",
      "41 Train Loss 1.1100494e-05 Test MSE 3.4704575666494507e-06 Test RE 0.0004885269580770359\n",
      "42 Train Loss 1.1096508e-05 Test MSE 3.4704575666494507e-06 Test RE 0.0004885269580770359\n",
      "43 Train Loss 1.0670203e-05 Test MSE 3.1206495179269206e-06 Test RE 0.0004632523835551167\n",
      "44 Train Loss 1.07009155e-05 Test MSE 3.1206495179269206e-06 Test RE 0.0004632523835551167\n",
      "45 Train Loss 1.0712783e-05 Test MSE 3.1206495179269206e-06 Test RE 0.0004632523835551167\n",
      "46 Train Loss 1.0726408e-05 Test MSE 3.1206495179269206e-06 Test RE 0.0004632523835551167\n",
      "47 Train Loss 1.0344079e-05 Test MSE 1.393002296723509e-06 Test RE 0.00030950743137178735\n",
      "48 Train Loss 1.03160455e-05 Test MSE 1.393002296723509e-06 Test RE 0.00030950743137178735\n",
      "49 Train Loss 1.0308224e-05 Test MSE 1.393002296723509e-06 Test RE 0.00030950743137178735\n",
      "50 Train Loss 1.0298512e-05 Test MSE 1.393002296723509e-06 Test RE 0.00030950743137178735\n",
      "51 Train Loss 1.0322078e-05 Test MSE 1.393002296723509e-06 Test RE 0.00030950743137178735\n",
      "52 Train Loss 9.95949e-06 Test MSE 3.467705334512684e-08 Test RE 4.8833320750610586e-05\n",
      "53 Train Loss 9.961349e-06 Test MSE 3.467705334512684e-08 Test RE 4.8833320750610586e-05\n",
      "54 Train Loss 1.0000276e-05 Test MSE 3.467705334512684e-08 Test RE 4.8833320750610586e-05\n",
      "55 Train Loss 9.967033e-06 Test MSE 3.467705334512684e-08 Test RE 4.8833320750610586e-05\n",
      "56 Train Loss 9.990935e-06 Test MSE 3.467705334512684e-08 Test RE 4.8833320750610586e-05\n",
      "57 Train Loss 9.937778e-06 Test MSE 1.0402373128276453e-06 Test RE 0.0002674615632480015\n",
      "58 Train Loss 9.995275e-06 Test MSE 1.0402373128276453e-06 Test RE 0.0002674615632480015\n",
      "59 Train Loss 9.966558e-06 Test MSE 1.0402373128276453e-06 Test RE 0.0002674615632480015\n",
      "60 Train Loss 9.7049015e-06 Test MSE 1.8417595504891048e-07 Test RE 0.0001125412229236135\n",
      "61 Train Loss 9.733695e-06 Test MSE 1.8417595504891048e-07 Test RE 0.0001125412229236135\n",
      "62 Train Loss 9.737509e-06 Test MSE 1.8417595504891048e-07 Test RE 0.0001125412229236135\n",
      "63 Train Loss 9.7373195e-06 Test MSE 1.8417595504891048e-07 Test RE 0.0001125412229236135\n",
      "64 Train Loss 9.754041e-06 Test MSE 1.8417595504891048e-07 Test RE 0.0001125412229236135\n",
      "65 Train Loss 9.604342e-06 Test MSE 1.5900560987417887e-06 Test RE 0.0003306750198268682\n",
      "66 Train Loss 9.609896e-06 Test MSE 1.5900560987417887e-06 Test RE 0.0003306750198268682\n",
      "67 Train Loss 9.582649e-06 Test MSE 1.5900560987417887e-06 Test RE 0.0003306750198268682\n",
      "68 Train Loss 9.61815e-06 Test MSE 1.5900560987417887e-06 Test RE 0.0003306750198268682\n",
      "69 Train Loss 9.508858e-06 Test MSE 9.791827150701108e-07 Test RE 0.0002594938288025841\n",
      "70 Train Loss 9.522658e-06 Test MSE 9.791827150701108e-07 Test RE 0.0002594938288025841\n",
      "71 Train Loss 9.535856e-06 Test MSE 9.791827150701108e-07 Test RE 0.0002594938288025841\n",
      "72 Train Loss 9.470492e-06 Test MSE 3.19656524563871e-07 Test RE 0.0001482644228883785\n",
      "73 Train Loss 9.437624e-06 Test MSE 3.19656524563871e-07 Test RE 0.0001482644228883785\n",
      "74 Train Loss 9.4778e-06 Test MSE 3.19656524563871e-07 Test RE 0.0001482644228883785\n",
      "75 Train Loss 9.41823e-06 Test MSE 9.801425927159877e-07 Test RE 0.00025962098653764884\n",
      "76 Train Loss 9.397671e-06 Test MSE 9.801425927159877e-07 Test RE 0.00025962098653764884\n",
      "77 Train Loss 9.4663255e-06 Test MSE 9.801425927159877e-07 Test RE 0.00025962098653764884\n",
      "78 Train Loss 9.318317e-06 Test MSE 9.433842037857535e-08 Test RE 8.054516301592774e-05\n",
      "79 Train Loss 9.303295e-06 Test MSE 9.433842037857535e-08 Test RE 8.054516301592774e-05\n",
      "80 Train Loss 9.268913e-06 Test MSE 9.433842037857535e-08 Test RE 8.054516301592774e-05\n",
      "81 Train Loss 9.3002745e-06 Test MSE 9.433842037857535e-08 Test RE 8.054516301592774e-05\n",
      "82 Train Loss 9.320363e-06 Test MSE 9.433842037857535e-08 Test RE 8.054516301592774e-05\n",
      "83 Train Loss 9.180588e-06 Test MSE 3.5962382804314624e-06 Test RE 0.0004973010710637879\n",
      "84 Train Loss 9.18354e-06 Test MSE 3.5962382804314624e-06 Test RE 0.0004973010710637879\n",
      "85 Train Loss 9.221859e-06 Test MSE 3.5962382804314624e-06 Test RE 0.0004973010710637879\n",
      "86 Train Loss 9.223259e-06 Test MSE 3.5962382804314624e-06 Test RE 0.0004973010710637879\n",
      "87 Train Loss 9.2018545e-06 Test MSE 3.5962382804314624e-06 Test RE 0.0004973010710637879\n",
      "88 Train Loss 9.193318e-06 Test MSE 3.5962382804314624e-06 Test RE 0.0004973010710637879\n",
      "89 Train Loss 9.0356825e-06 Test MSE 5.928513486176151e-07 Test RE 0.00020191476175049827\n",
      "90 Train Loss 9.04574e-06 Test MSE 5.928513486176151e-07 Test RE 0.00020191476175049827\n",
      "91 Train Loss 9.023441e-06 Test MSE 5.928513486176151e-07 Test RE 0.00020191476175049827\n",
      "92 Train Loss 8.98242e-06 Test MSE 5.928513486176151e-07 Test RE 0.00020191476175049827\n",
      "93 Train Loss 8.991137e-06 Test MSE 5.928513486176151e-07 Test RE 0.00020191476175049827\n",
      "94 Train Loss 8.543039e-06 Test MSE 4.069982846337617e-06 Test RE 0.0005290435868923127\n",
      "95 Train Loss 8.5340525e-06 Test MSE 4.069982846337617e-06 Test RE 0.0005290435868923127\n",
      "96 Train Loss 7.757139e-06 Test MSE 1.8777510012781092e-06 Test RE 0.000359347117825541\n",
      "97 Train Loss 7.750692e-06 Test MSE 1.8777510012781092e-06 Test RE 0.000359347117825541\n",
      "98 Train Loss 7.250285e-06 Test MSE 5.012650988982802e-07 Test RE 0.0001856645111877164\n",
      "99 Train Loss 7.257446e-06 Test MSE 5.012650988982802e-07 Test RE 0.0001856645111877164\n",
      "100 Train Loss 5.6393083e-06 Test MSE 5.625418663068063e-06 Test RE 0.0006219745143012806\n",
      "101 Train Loss 5.6366002e-06 Test MSE 5.625418663068063e-06 Test RE 0.0006219745143012806\n",
      "102 Train Loss 4.6663176e-06 Test MSE 3.346427676759087e-08 Test RE 4.7971785874962516e-05\n",
      "103 Train Loss 4.655978e-06 Test MSE 3.346427676759087e-08 Test RE 4.7971785874962516e-05\n",
      "104 Train Loss 4.0630466e-06 Test MSE 2.7205022257783853e-07 Test RE 0.00013677908923045992\n",
      "105 Train Loss 4.1151047e-06 Test MSE 2.7205022257783853e-07 Test RE 0.00013677908923045992\n",
      "106 Train Loss 4.053161e-06 Test MSE 2.7205022257783853e-07 Test RE 0.00013677908923045992\n",
      "107 Train Loss 4.0881177e-06 Test MSE 2.7205022257783853e-07 Test RE 0.00013677908923045992\n",
      "108 Train Loss 3.7896698e-06 Test MSE 5.90805368061463e-07 Test RE 0.00020156604810036581\n",
      "109 Train Loss 3.7992484e-06 Test MSE 5.90805368061463e-07 Test RE 0.00020156604810036581\n",
      "110 Train Loss 3.4592688e-06 Test MSE 2.1315195135502275e-08 Test RE 3.8285984680113005e-05\n",
      "111 Train Loss 3.478962e-06 Test MSE 2.1315195135502275e-08 Test RE 3.8285984680113005e-05\n",
      "112 Train Loss 3.4781374e-06 Test MSE 2.1315195135502275e-08 Test RE 3.8285984680113005e-05\n",
      "113 Train Loss 3.4725263e-06 Test MSE 2.1315195135502275e-08 Test RE 3.8285984680113005e-05\n",
      "114 Train Loss 3.2920639e-06 Test MSE 1.1743321385587067e-08 Test RE 2.841781208330531e-05\n",
      "115 Train Loss 3.281192e-06 Test MSE 1.1743321385587067e-08 Test RE 2.841781208330531e-05\n",
      "116 Train Loss 3.2782448e-06 Test MSE 1.1743321385587067e-08 Test RE 2.841781208330531e-05\n",
      "117 Train Loss 3.2636956e-06 Test MSE 1.1743321385587067e-08 Test RE 2.841781208330531e-05\n",
      "118 Train Loss 3.2693324e-06 Test MSE 1.1743321385587067e-08 Test RE 2.841781208330531e-05\n",
      "119 Train Loss 3.2741455e-06 Test MSE 1.1743321385587067e-08 Test RE 2.841781208330531e-05\n",
      "120 Train Loss 2.897785e-06 Test MSE 3.2380870733059505e-08 Test RE 4.718885354255683e-05\n",
      "121 Train Loss 2.9096516e-06 Test MSE 3.2380870733059505e-08 Test RE 4.718885354255683e-05\n",
      "122 Train Loss 2.2976594e-06 Test MSE 9.88461692699661e-07 Test RE 0.00026072044358470904\n",
      "123 Train Loss 2.275688e-06 Test MSE 9.88461692699661e-07 Test RE 0.00026072044358470904\n",
      "124 Train Loss 2.3091113e-06 Test MSE 9.88461692699661e-07 Test RE 0.00026072044358470904\n",
      "125 Train Loss 2.1960905e-06 Test MSE 1.9796284513500597e-07 Test RE 0.00011667747129036522\n",
      "126 Train Loss 2.198338e-06 Test MSE 1.9796284513500597e-07 Test RE 0.00011667747129036522\n",
      "127 Train Loss 2.1707801e-06 Test MSE 1.9796284513500597e-07 Test RE 0.00011667747129036522\n",
      "128 Train Loss 2.1784322e-06 Test MSE 1.9796284513500597e-07 Test RE 0.00011667747129036522\n",
      "129 Train Loss 2.1850453e-06 Test MSE 1.9796284513500597e-07 Test RE 0.00011667747129036522\n",
      "130 Train Loss 2.2020902e-06 Test MSE 1.9796284513500597e-07 Test RE 0.00011667747129036522\n",
      "131 Train Loss 2.077469e-06 Test MSE 4.86748355256108e-07 Test RE 0.00018295631784883963\n",
      "132 Train Loss 2.0647124e-06 Test MSE 4.86748355256108e-07 Test RE 0.00018295631784883963\n",
      "133 Train Loss 2.0761524e-06 Test MSE 4.86748355256108e-07 Test RE 0.00018295631784883963\n",
      "134 Train Loss 2.0491382e-06 Test MSE 4.86748355256108e-07 Test RE 0.00018295631784883963\n",
      "135 Train Loss 2.0753082e-06 Test MSE 4.86748355256108e-07 Test RE 0.00018295631784883963\n",
      "136 Train Loss 2.0413247e-06 Test MSE 4.86748355256108e-07 Test RE 0.00018295631784883963\n",
      "137 Train Loss 2.0722496e-06 Test MSE 4.86748355256108e-07 Test RE 0.00018295631784883963\n",
      "138 Train Loss 2.011141e-06 Test MSE 6.697214193914343e-07 Test RE 0.0002146061973614668\n",
      "139 Train Loss 1.9826628e-06 Test MSE 6.697214193914343e-07 Test RE 0.0002146061973614668\n",
      "140 Train Loss 2.015555e-06 Test MSE 6.697214193914343e-07 Test RE 0.0002146061973614668\n",
      "141 Train Loss 2.0015614e-06 Test MSE 6.697214193914343e-07 Test RE 0.0002146061973614668\n",
      "142 Train Loss 1.9983402e-06 Test MSE 6.697214193914343e-07 Test RE 0.0002146061973614668\n",
      "143 Train Loss 1.8996096e-06 Test MSE 1.6729557636806092e-06 Test RE 0.00033918559014193325\n",
      "144 Train Loss 1.8942354e-06 Test MSE 1.6729557636806092e-06 Test RE 0.00033918559014193325\n",
      "145 Train Loss 1.9109393e-06 Test MSE 1.6729557636806092e-06 Test RE 0.00033918559014193325\n",
      "146 Train Loss 1.8924943e-06 Test MSE 1.6729557636806092e-06 Test RE 0.00033918559014193325\n",
      "147 Train Loss 1.905239e-06 Test MSE 1.6729557636806092e-06 Test RE 0.00033918559014193325\n",
      "148 Train Loss 1.8215019e-06 Test MSE 1.7577981238510608e-07 Test RE 0.00010994605807338426\n",
      "149 Train Loss 1.8097336e-06 Test MSE 1.7577981238510608e-07 Test RE 0.00010994605807338426\n",
      "150 Train Loss 1.804038e-06 Test MSE 1.7577981238510608e-07 Test RE 0.00010994605807338426\n",
      "151 Train Loss 1.8051045e-06 Test MSE 1.7577981238510608e-07 Test RE 0.00010994605807338426\n",
      "152 Train Loss 1.8134322e-06 Test MSE 1.7577981238510608e-07 Test RE 0.00010994605807338426\n",
      "153 Train Loss 1.716449e-06 Test MSE 3.912933875023341e-06 Test RE 0.0005187360362438866\n",
      "154 Train Loss 1.7293604e-06 Test MSE 3.912933875023341e-06 Test RE 0.0005187360362438866\n",
      "155 Train Loss 1.7406169e-06 Test MSE 3.912933875023341e-06 Test RE 0.0005187360362438866\n",
      "156 Train Loss 1.7261448e-06 Test MSE 3.912933875023341e-06 Test RE 0.0005187360362438866\n",
      "157 Train Loss 1.7188496e-06 Test MSE 3.912933875023341e-06 Test RE 0.0005187360362438866\n",
      "158 Train Loss 1.7194131e-06 Test MSE 3.912933875023341e-06 Test RE 0.0005187360362438866\n",
      "159 Train Loss 1.7126831e-06 Test MSE 3.912933875023341e-06 Test RE 0.0005187360362438866\n",
      "160 Train Loss 1.7204518e-06 Test MSE 3.912933875023341e-06 Test RE 0.0005187360362438866\n",
      "161 Train Loss 1.7338398e-06 Test MSE 3.912933875023341e-06 Test RE 0.0005187360362438866\n",
      "162 Train Loss 1.6533684e-06 Test MSE 6.725116278126889e-08 Test RE 6.800566060082653e-05\n",
      "163 Train Loss 1.6640303e-06 Test MSE 6.725116278126889e-08 Test RE 6.800566060082653e-05\n",
      "164 Train Loss 1.6679168e-06 Test MSE 6.725116278126889e-08 Test RE 6.800566060082653e-05\n",
      "165 Train Loss 1.6823989e-06 Test MSE 6.725116278126889e-08 Test RE 6.800566060082653e-05\n",
      "166 Train Loss 1.659398e-06 Test MSE 6.725116278126889e-08 Test RE 6.800566060082653e-05\n",
      "167 Train Loss 1.5734493e-06 Test MSE 2.0136215485055032e-06 Test RE 0.0003721209232993643\n",
      "168 Train Loss 1.5549498e-06 Test MSE 2.0136215485055032e-06 Test RE 0.0003721209232993643\n",
      "169 Train Loss 1.578727e-06 Test MSE 2.0136215485055032e-06 Test RE 0.0003721209232993643\n",
      "170 Train Loss 1.5711031e-06 Test MSE 2.0136215485055032e-06 Test RE 0.0003721209232993643\n",
      "171 Train Loss 1.5716325e-06 Test MSE 2.0136215485055032e-06 Test RE 0.0003721209232993643\n",
      "172 Train Loss 1.5607933e-06 Test MSE 2.0136215485055032e-06 Test RE 0.0003721209232993643\n",
      "173 Train Loss 1.5603462e-06 Test MSE 2.0136215485055032e-06 Test RE 0.0003721209232993643\n",
      "174 Train Loss 1.5815908e-06 Test MSE 2.0136215485055032e-06 Test RE 0.0003721209232993643\n",
      "175 Train Loss 1.4663747e-06 Test MSE 1.4799624342194092e-06 Test RE 0.00031902190991235516\n",
      "176 Train Loss 1.4815853e-06 Test MSE 1.4799624342194092e-06 Test RE 0.00031902190991235516\n",
      "177 Train Loss 1.4701465e-06 Test MSE 1.4799624342194092e-06 Test RE 0.00031902190991235516\n",
      "178 Train Loss 1.4711477e-06 Test MSE 1.4799624342194092e-06 Test RE 0.00031902190991235516\n",
      "179 Train Loss 1.4740247e-06 Test MSE 1.4799624342194092e-06 Test RE 0.00031902190991235516\n",
      "180 Train Loss 1.4691499e-06 Test MSE 1.4799624342194092e-06 Test RE 0.00031902190991235516\n",
      "181 Train Loss 1.4802002e-06 Test MSE 1.4799624342194092e-06 Test RE 0.00031902190991235516\n",
      "182 Train Loss 1.3942148e-06 Test MSE 1.700306391380314e-06 Test RE 0.0003419469689451506\n",
      "183 Train Loss 1.4040437e-06 Test MSE 1.700306391380314e-06 Test RE 0.0003419469689451506\n",
      "184 Train Loss 1.3943807e-06 Test MSE 1.700306391380314e-06 Test RE 0.0003419469689451506\n",
      "185 Train Loss 1.405195e-06 Test MSE 1.700306391380314e-06 Test RE 0.0003419469689451506\n",
      "186 Train Loss 1.3253801e-06 Test MSE 9.942305357646659e-09 Test RE 2.6148014283708762e-05\n",
      "187 Train Loss 1.3251237e-06 Test MSE 9.942305357646659e-09 Test RE 2.6148014283708762e-05\n",
      "188 Train Loss 1.3108005e-06 Test MSE 9.942305357646659e-09 Test RE 2.6148014283708762e-05\n",
      "189 Train Loss 1.3192168e-06 Test MSE 9.942305357646659e-09 Test RE 2.6148014283708762e-05\n",
      "190 Train Loss 1.3246976e-06 Test MSE 9.942305357646659e-09 Test RE 2.6148014283708762e-05\n",
      "191 Train Loss 1.3260628e-06 Test MSE 9.942305357646659e-09 Test RE 2.6148014283708762e-05\n",
      "192 Train Loss 1.2271993e-06 Test MSE 1.994784808127945e-07 Test RE 0.00011712327046989348\n",
      "193 Train Loss 1.2228683e-06 Test MSE 1.994784808127945e-07 Test RE 0.00011712327046989348\n",
      "194 Train Loss 1.2239946e-06 Test MSE 1.994784808127945e-07 Test RE 0.00011712327046989348\n",
      "195 Train Loss 1.2350071e-06 Test MSE 1.994784808127945e-07 Test RE 0.00011712327046989348\n",
      "196 Train Loss 1.1425701e-06 Test MSE 1.2796382388063754e-07 Test RE 9.380776081427153e-05\n",
      "197 Train Loss 1.1455272e-06 Test MSE 1.2796382388063754e-07 Test RE 9.380776081427153e-05\n",
      "198 Train Loss 1.1470803e-06 Test MSE 1.2796382388063754e-07 Test RE 9.380776081427153e-05\n",
      "199 Train Loss 1.1473218e-06 Test MSE 1.2796382388063754e-07 Test RE 9.380776081427153e-05\n",
      "Training time: 86.80\n",
      "Training time: 86.80\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (m_lambda): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 1.7413919 Test MSE 14.675824568009093 Test RE 1.004607510432223\n",
      "1 Train Loss 1.7607205 Test MSE 14.93814056918337 Test RE 1.0135459339682622\n",
      "2 Train Loss 1.767495 Test MSE 14.83521113891535 Test RE 1.0100480409645134\n",
      "3 Train Loss 1.6931813 Test MSE 15.386230988040104 Test RE 1.0286349796901078\n",
      "4 Train Loss 1.6711309 Test MSE 15.557393429477845 Test RE 1.0343406242070567\n",
      "5 Train Loss 1.6242328 Test MSE 15.366065560504786 Test RE 1.0279606863854376\n",
      "6 Train Loss 1.5263723 Test MSE 15.449459635678638 Test RE 1.0307463647705073\n",
      "7 Train Loss 1.141039 Test MSE 15.51359725671416 Test RE 1.0328836935406658\n",
      "8 Train Loss 0.9413753 Test MSE 15.341908222519697 Test RE 1.0271523284695219\n",
      "9 Train Loss 0.74286175 Test MSE 13.14760308473194 Test RE 0.9508641136627076\n",
      "10 Train Loss 0.73661435 Test MSE 12.985626216306857 Test RE 0.9449886964498936\n",
      "11 Train Loss 0.6252729 Test MSE 8.994717159261715 Test RE 0.7864822408725094\n",
      "12 Train Loss 0.40177536 Test MSE 6.535649573221678 Test RE 0.6704085492704961\n",
      "13 Train Loss 0.21304065 Test MSE 3.119982107992123 Test RE 0.46320284326325556\n",
      "14 Train Loss 0.14506844 Test MSE 2.040916784037841 Test RE 0.3746345383502824\n",
      "15 Train Loss 0.075736925 Test MSE 1.1985751095574455 Test RE 0.2870964299644182\n",
      "16 Train Loss 0.04459662 Test MSE 0.704414327341921 Test RE 0.22009453300993873\n",
      "17 Train Loss 0.017455015 Test MSE 0.2640977147354592 Test RE 0.13476511505328506\n",
      "18 Train Loss 0.0013424207 Test MSE 0.014523503196932958 Test RE 0.0316031852673497\n",
      "19 Train Loss 0.00039439785 Test MSE 0.0003911775053101556 Test RE 0.005186592182829798\n",
      "20 Train Loss 0.0003672729 Test MSE 0.00022172211960892714 Test RE 0.0039048079211094987\n",
      "21 Train Loss 0.00036275978 Test MSE 0.00017670708119263935 Test RE 0.003485957929338196\n",
      "22 Train Loss 0.00035135358 Test MSE 0.00014516191496126288 Test RE 0.003159522912473699\n",
      "23 Train Loss 0.0003476204 Test MSE 0.00012344666575034484 Test RE 0.00291363299740109\n",
      "24 Train Loss 0.0003414917 Test MSE 0.00010202223023653908 Test RE 0.0026487597683073705\n",
      "25 Train Loss 0.0003319536 Test MSE 8.416793214480759e-05 Test RE 0.0024058497068708048\n",
      "26 Train Loss 0.00032177055 Test MSE 7.097034813334713e-05 Test RE 0.0022091928684206995\n",
      "27 Train Loss 0.0003156853 Test MSE 6.351085846590541e-05 Test RE 0.0020898694446304504\n",
      "28 Train Loss 0.00030862493 Test MSE 5.899077452748687e-05 Test RE 0.002014128681678576\n",
      "29 Train Loss 0.00030252704 Test MSE 5.6637292467365627e-05 Test RE 0.001973542151902454\n",
      "30 Train Loss 0.0002992426 Test MSE 5.316340292298056e-05 Test RE 0.0019120601518215897\n",
      "31 Train Loss 0.0002970612 Test MSE 5.3473744724712983e-05 Test RE 0.0019176328643965505\n",
      "32 Train Loss 0.00029135763 Test MSE 5.125282659788748e-05 Test RE 0.0018773881646503721\n",
      "33 Train Loss 0.0002869688 Test MSE 5.218237513049438e-05 Test RE 0.0018943363200772344\n",
      "34 Train Loss 0.0002797241 Test MSE 5.390361028965194e-05 Test RE 0.0019253251843987442\n",
      "35 Train Loss 0.00027784836 Test MSE 5.451845723179108e-05 Test RE 0.0019362745785079108\n",
      "36 Train Loss 0.00027275062 Test MSE 5.4623149856066394e-05 Test RE 0.0019381328156263355\n",
      "37 Train Loss 0.00026452352 Test MSE 5.003528464074564e-05 Test RE 0.001854954888043362\n",
      "38 Train Loss 0.0002550162 Test MSE 4.666862036346375e-05 Test RE 0.0017914621875764574\n",
      "39 Train Loss 0.00024550114 Test MSE 3.4887403677054443e-05 Test RE 0.0015489217921672129\n",
      "40 Train Loss 0.0002449076 Test MSE 2.901217977124312e-05 Test RE 0.0014124898793251672\n",
      "41 Train Loss 0.00023847108 Test MSE 2.246196202816187e-05 Test RE 0.0012428508370987727\n",
      "42 Train Loss 0.00023455193 Test MSE 1.7415110618667995e-05 Test RE 0.0010943551435889656\n",
      "43 Train Loss 0.00022886592 Test MSE 1.3359336555988997e-05 Test RE 0.0009584900531343225\n",
      "44 Train Loss 0.00022878975 Test MSE 1.0712897213582367e-05 Test RE 0.0008583188172064914\n",
      "45 Train Loss 0.00022124712 Test MSE 1.0023473518347456e-05 Test RE 0.0008302412141305307\n",
      "46 Train Loss 0.00022183936 Test MSE 9.841625288650547e-06 Test RE 0.0008226755261045899\n",
      "47 Train Loss 0.00021728138 Test MSE 8.883963237168956e-06 Test RE 0.0007816251790151033\n",
      "48 Train Loss 0.00021715618 Test MSE 8.883963237168956e-06 Test RE 0.0007816251790151033\n",
      "49 Train Loss 0.00021448421 Test MSE 8.883963237168956e-06 Test RE 0.0007816251790151033\n",
      "50 Train Loss 0.00021418756 Test MSE 1.2798434640170565e-05 Test RE 0.0009381528284083694\n",
      "51 Train Loss 0.00021388248 Test MSE 1.2798434640170565e-05 Test RE 0.0009381528284083694\n",
      "52 Train Loss 0.00020781303 Test MSE 3.064384641292498e-05 Test RE 0.0014516663279426662\n",
      "53 Train Loss 0.00020587344 Test MSE 3.064384641292498e-05 Test RE 0.0014516663279426662\n",
      "54 Train Loss 0.00019906853 Test MSE 8.422628918666118e-05 Test RE 0.0024066835989538025\n",
      "55 Train Loss 0.00020071639 Test MSE 8.422628918666118e-05 Test RE 0.0024066835989538025\n",
      "56 Train Loss 0.0001842992 Test MSE 2.3245278325998623e-05 Test RE 0.0012643361050834092\n",
      "57 Train Loss 0.00018437096 Test MSE 2.3245675728662344e-05 Test RE 0.0012643469126199223\n",
      "58 Train Loss 0.00017161886 Test MSE 8.803637693666622e-07 Test RE 0.0002460516294266557\n",
      "59 Train Loss 0.0001730423 Test MSE 8.803637693666622e-07 Test RE 0.0002460516294266557\n",
      "60 Train Loss 0.00016457353 Test MSE 4.017643448631696e-05 Test RE 0.0016621907487168715\n",
      "61 Train Loss 0.00016698003 Test MSE 4.017643448631696e-05 Test RE 0.0016621907487168715\n",
      "62 Train Loss 0.00015883821 Test MSE 1.2543422767678805e-06 Test RE 0.0002936994916708408\n",
      "63 Train Loss 0.0001534394 Test MSE 3.0214139574027694e-06 Test RE 0.0004558272457837025\n",
      "64 Train Loss 0.00014476356 Test MSE 4.199962029358955e-06 Test RE 0.0005374249773635869\n",
      "65 Train Loss 0.00012178689 Test MSE 4.158555416594096e-06 Test RE 0.0005347692311105916\n",
      "66 Train Loss 0.00011342005 Test MSE 3.2795150027488954e-06 Test RE 0.0004748976011061013\n",
      "67 Train Loss 0.0001063697 Test MSE 2.366592020317221e-06 Test RE 0.00040341947763776595\n",
      "68 Train Loss 9.889419e-05 Test MSE 2.1922780878528148e-06 Test RE 0.0003882781809419504\n",
      "69 Train Loss 9.427633e-05 Test MSE 2.7602541566476234e-06 Test RE 0.0004356820837066483\n",
      "70 Train Loss 8.993595e-05 Test MSE 4.202502848330969e-06 Test RE 0.0005375875137284938\n",
      "71 Train Loss 8.720891e-05 Test MSE 6.4547791608221905e-06 Test RE 0.0006662479088265981\n",
      "72 Train Loss 8.65218e-05 Test MSE 6.4547791608221905e-06 Test RE 0.0006662479088265981\n",
      "73 Train Loss 8.620188e-05 Test MSE 6.4547791608221905e-06 Test RE 0.0006662479088265981\n",
      "74 Train Loss 8.226531e-05 Test MSE 2.645180828428268e-05 Test RE 0.0013487232618780735\n",
      "75 Train Loss 8.246684e-05 Test MSE 2.645180828428268e-05 Test RE 0.0013487232618780735\n",
      "76 Train Loss 8.266712e-05 Test MSE 2.645180828428268e-05 Test RE 0.0013487232618780735\n",
      "77 Train Loss 8.0829595e-05 Test MSE 4.5826982231943334e-05 Test RE 0.0017752347658747385\n",
      "78 Train Loss 8.125426e-05 Test MSE 4.5826982231943334e-05 Test RE 0.0017752347658747385\n",
      "79 Train Loss 7.9175894e-05 Test MSE 0.00010665391762638315 Test RE 0.002708217693455138\n",
      "80 Train Loss 7.929005e-05 Test MSE 0.00010665391762638315 Test RE 0.002708217693455138\n",
      "81 Train Loss 7.951052e-05 Test MSE 0.00010665391762638315 Test RE 0.002708217693455138\n",
      "82 Train Loss 7.517729e-05 Test MSE 3.140674979700671e-05 Test RE 0.0014696254431140845\n",
      "83 Train Loss 7.634546e-05 Test MSE 3.140674979700671e-05 Test RE 0.0014696254431140845\n",
      "84 Train Loss 6.4034655e-05 Test MSE 9.854923706561886e-07 Test RE 0.00026032854917240654\n",
      "85 Train Loss 6.4445114e-05 Test MSE 9.854923706561886e-07 Test RE 0.00026032854917240654\n",
      "86 Train Loss 6.427535e-05 Test MSE 9.854923706561886e-07 Test RE 0.00026032854917240654\n",
      "87 Train Loss 6.115955e-05 Test MSE 1.2817288712365709e-05 Test RE 0.0009388435961529425\n",
      "88 Train Loss 6.13967e-05 Test MSE 1.2817288712365709e-05 Test RE 0.0009388435961529425\n",
      "89 Train Loss 6.103673e-05 Test MSE 1.2817288712365709e-05 Test RE 0.0009388435961529425\n",
      "90 Train Loss 6.061986e-05 Test MSE 1.1007049914111476e-05 Test RE 0.0008700227975172303\n",
      "91 Train Loss 6.0881895e-05 Test MSE 1.1007049914111476e-05 Test RE 0.0008700227975172303\n",
      "92 Train Loss 6.072565e-05 Test MSE 1.1007049914111476e-05 Test RE 0.0008700227975172303\n",
      "93 Train Loss 6.1031147e-05 Test MSE 1.1007049914111476e-05 Test RE 0.0008700227975172303\n",
      "94 Train Loss 5.8228423e-05 Test MSE 5.171912793601284e-07 Test RE 0.00018859091234185328\n",
      "95 Train Loss 5.8413014e-05 Test MSE 5.171912793601284e-07 Test RE 0.00018859091234185328\n",
      "96 Train Loss 5.6173732e-05 Test MSE 2.1345723877574247e-06 Test RE 0.0003831339246903721\n",
      "97 Train Loss 5.6200806e-05 Test MSE 2.1345723877574247e-06 Test RE 0.0003831339246903721\n",
      "98 Train Loss 5.6597928e-05 Test MSE 2.1345723877574247e-06 Test RE 0.0003831339246903721\n",
      "99 Train Loss 5.582331e-05 Test MSE 2.1345723877574247e-06 Test RE 0.0003831339246903721\n",
      "100 Train Loss 5.5550543e-05 Test MSE 2.0614315154389025e-07 Test RE 0.00011906376743531504\n",
      "101 Train Loss 5.490467e-05 Test MSE 2.0614315154389025e-07 Test RE 0.00011906376743531504\n",
      "102 Train Loss 5.5433924e-05 Test MSE 2.0614315154389025e-07 Test RE 0.00011906376743531504\n",
      "103 Train Loss 5.486375e-05 Test MSE 6.22635949030119e-06 Test RE 0.0006543532453957508\n",
      "104 Train Loss 5.4843887e-05 Test MSE 6.22635949030119e-06 Test RE 0.0006543532453957508\n",
      "105 Train Loss 5.5296085e-05 Test MSE 6.22635949030119e-06 Test RE 0.0006543532453957508\n",
      "106 Train Loss 5.499321e-05 Test MSE 2.301168552893085e-06 Test RE 0.00039780421460453496\n",
      "107 Train Loss 5.380906e-05 Test MSE 2.301168552893085e-06 Test RE 0.00039780421460453496\n",
      "108 Train Loss 5.405226e-05 Test MSE 2.301168552893085e-06 Test RE 0.00039780421460453496\n",
      "109 Train Loss 5.458437e-05 Test MSE 2.301168552893085e-06 Test RE 0.00039780421460453496\n",
      "110 Train Loss 5.1212923e-05 Test MSE 8.38142637972986e-06 Test RE 0.0007591963861030364\n",
      "111 Train Loss 5.09844e-05 Test MSE 8.38142637972986e-06 Test RE 0.0007591963861030364\n",
      "112 Train Loss 5.1398656e-05 Test MSE 8.38142637972986e-06 Test RE 0.0007591963861030364\n",
      "113 Train Loss 5.0738505e-05 Test MSE 2.4952814111813536e-06 Test RE 0.00041424276356867996\n",
      "114 Train Loss 5.068431e-05 Test MSE 2.4952814111813536e-06 Test RE 0.00041424276356867996\n",
      "115 Train Loss 5.042986e-05 Test MSE 2.4952814111813536e-06 Test RE 0.00041424276356867996\n",
      "116 Train Loss 5.005985e-05 Test MSE 2.4952814111813536e-06 Test RE 0.00041424276356867996\n",
      "117 Train Loss 5.042103e-05 Test MSE 2.4952814111813536e-06 Test RE 0.00041424276356867996\n",
      "118 Train Loss 4.5411067e-05 Test MSE 9.124801821318198e-08 Test RE 7.921490126978865e-05\n",
      "119 Train Loss 4.5692566e-05 Test MSE 9.124801821318198e-08 Test RE 7.921490126978865e-05\n",
      "120 Train Loss 4.4848934e-05 Test MSE 3.7492529667669245e-06 Test RE 0.0005077705826369082\n",
      "121 Train Loss 4.5074346e-05 Test MSE 3.7492529667669245e-06 Test RE 0.0005077705826369082\n",
      "122 Train Loss 4.387316e-05 Test MSE 1.9883364745685653e-05 Test RE 0.0011693381112183052\n",
      "123 Train Loss 4.438265e-05 Test MSE 1.9883364745685653e-05 Test RE 0.0011693381112183052\n",
      "124 Train Loss 4.389843e-05 Test MSE 1.9883364745685653e-05 Test RE 0.0011693381112183052\n",
      "125 Train Loss 4.3993732e-05 Test MSE 1.9883364745685653e-05 Test RE 0.0011693381112183052\n",
      "126 Train Loss 4.159749e-05 Test MSE 2.878584681967682e-06 Test RE 0.00044492280833080506\n",
      "127 Train Loss 4.148641e-05 Test MSE 2.878584681967682e-06 Test RE 0.00044492280833080506\n",
      "128 Train Loss 4.020667e-05 Test MSE 2.8902075111300468e-06 Test RE 0.0004458201333859586\n",
      "129 Train Loss 3.992453e-05 Test MSE 2.8902075111300468e-06 Test RE 0.0004458201333859586\n",
      "130 Train Loss 3.995202e-05 Test MSE 2.8902075111300468e-06 Test RE 0.0004458201333859586\n",
      "131 Train Loss 3.8678467e-05 Test MSE 8.342117086190103e-06 Test RE 0.000757413959916118\n",
      "132 Train Loss 3.8599268e-05 Test MSE 8.342117086190103e-06 Test RE 0.000757413959916118\n",
      "133 Train Loss 3.5647015e-05 Test MSE 2.0921967593862714e-06 Test RE 0.0003793118646020648\n",
      "134 Train Loss 3.5684796e-05 Test MSE 2.0921967593862714e-06 Test RE 0.0003793118646020648\n",
      "135 Train Loss 3.2506654e-05 Test MSE 3.297091803589387e-06 Test RE 0.00047616852471637675\n",
      "136 Train Loss 3.2734224e-05 Test MSE 3.297091803589387e-06 Test RE 0.00047616852471637675\n",
      "137 Train Loss 3.1680487e-05 Test MSE 1.4572929613215438e-05 Test RE 0.001001079570084412\n",
      "138 Train Loss 3.1695585e-05 Test MSE 1.4572929613215438e-05 Test RE 0.001001079570084412\n",
      "139 Train Loss 3.171823e-05 Test MSE 1.4572929613215438e-05 Test RE 0.001001079570084412\n",
      "140 Train Loss 2.8630728e-05 Test MSE 8.855400082330271e-07 Test RE 0.00024677391913198503\n",
      "141 Train Loss 2.8864339e-05 Test MSE 8.855400082330271e-07 Test RE 0.00024677391913198503\n",
      "142 Train Loss 2.6907572e-05 Test MSE 1.4612050458797948e-07 Test RE 0.00010024223622455357\n",
      "143 Train Loss 2.7246468e-05 Test MSE 1.4612050458797948e-07 Test RE 0.00010024223622455357\n",
      "144 Train Loss 2.6958214e-05 Test MSE 1.4612050458797948e-07 Test RE 0.00010024223622455357\n",
      "145 Train Loss 2.7385355e-05 Test MSE 1.4612050458797948e-07 Test RE 0.00010024223622455357\n",
      "146 Train Loss 2.7384696e-05 Test MSE 1.4612050458797948e-07 Test RE 0.00010024223622455357\n",
      "147 Train Loss 2.7586839e-05 Test MSE 1.4612050458797948e-07 Test RE 0.00010024223622455357\n",
      "148 Train Loss 2.6729997e-05 Test MSE 7.385924317674738e-07 Test RE 0.00022537077149919788\n",
      "149 Train Loss 2.694631e-05 Test MSE 7.385924317674738e-07 Test RE 0.00022537077149919788\n",
      "150 Train Loss 2.544206e-05 Test MSE 1.2124776874555666e-07 Test RE 9.131288038356956e-05\n",
      "151 Train Loss 2.5632136e-05 Test MSE 1.2124776874555666e-07 Test RE 9.131288038356956e-05\n",
      "152 Train Loss 2.4690798e-05 Test MSE 1.3062649140652468e-07 Test RE 9.4778710525146e-05\n",
      "153 Train Loss 2.4737838e-05 Test MSE 1.3062649140652468e-07 Test RE 9.4778710525146e-05\n",
      "154 Train Loss 2.4871753e-05 Test MSE 1.3062649140652468e-07 Test RE 9.4778710525146e-05\n",
      "155 Train Loss 2.4322835e-05 Test MSE 5.674792817804293e-06 Test RE 0.0006246980783416044\n",
      "156 Train Loss 2.4082728e-05 Test MSE 5.674792817804293e-06 Test RE 0.0006246980783416044\n",
      "157 Train Loss 2.4205921e-05 Test MSE 5.674792817804293e-06 Test RE 0.0006246980783416044\n",
      "158 Train Loss 2.2446045e-05 Test MSE 2.4385557573516044e-07 Test RE 0.0001294975374493451\n",
      "159 Train Loss 2.2312634e-05 Test MSE 2.4385557573516044e-07 Test RE 0.0001294975374493451\n",
      "160 Train Loss 2.0809983e-05 Test MSE 4.138173493499105e-07 Test RE 0.00016869395180414562\n",
      "161 Train Loss 2.1084752e-05 Test MSE 4.138173493499105e-07 Test RE 0.00016869395180414562\n",
      "162 Train Loss 1.9817013e-05 Test MSE 2.4537619635314424e-07 Test RE 0.00012990066663327166\n",
      "163 Train Loss 1.9740204e-05 Test MSE 2.4537619635314424e-07 Test RE 0.00012990066663327166\n",
      "164 Train Loss 1.940941e-05 Test MSE 1.2902461899154362e-07 Test RE 9.41957823274096e-05\n",
      "165 Train Loss 1.938677e-05 Test MSE 1.2902461899154362e-07 Test RE 9.41957823274096e-05\n",
      "166 Train Loss 1.9344201e-05 Test MSE 1.2902461899154362e-07 Test RE 9.41957823274096e-05\n",
      "167 Train Loss 1.9004074e-05 Test MSE 6.305830360718626e-07 Test RE 0.00020824103152449982\n",
      "168 Train Loss 1.8997192e-05 Test MSE 6.305830360718626e-07 Test RE 0.00020824103152449982\n",
      "169 Train Loss 1.9054069e-05 Test MSE 6.305830360718626e-07 Test RE 0.00020824103152449982\n",
      "170 Train Loss 1.899792e-05 Test MSE 6.305830360718626e-07 Test RE 0.00020824103152449982\n",
      "171 Train Loss 1.8991192e-05 Test MSE 6.305830360718626e-07 Test RE 0.00020824103152449982\n",
      "172 Train Loss 1.844222e-05 Test MSE 1.4959660934549942e-06 Test RE 0.00032074215285191884\n",
      "173 Train Loss 1.8516172e-05 Test MSE 1.4959660934549942e-06 Test RE 0.00032074215285191884\n",
      "174 Train Loss 1.85921e-05 Test MSE 1.4959660934549942e-06 Test RE 0.00032074215285191884\n",
      "175 Train Loss 1.8503177e-05 Test MSE 1.4959660934549942e-06 Test RE 0.00032074215285191884\n",
      "176 Train Loss 1.8609275e-05 Test MSE 1.4959660934549942e-06 Test RE 0.00032074215285191884\n",
      "177 Train Loss 1.8105957e-05 Test MSE 7.137952263887812e-07 Test RE 0.0002215552187893341\n",
      "178 Train Loss 1.8088014e-05 Test MSE 7.137952263887812e-07 Test RE 0.0002215552187893341\n",
      "179 Train Loss 1.81375e-05 Test MSE 7.137952263887812e-07 Test RE 0.0002215552187893341\n",
      "180 Train Loss 1.7231137e-05 Test MSE 7.089812624491705e-07 Test RE 0.00022080685066473599\n",
      "181 Train Loss 1.7208542e-05 Test MSE 7.089812624491705e-07 Test RE 0.00022080685066473599\n",
      "182 Train Loss 1.7225148e-05 Test MSE 7.089812624491705e-07 Test RE 0.00022080685066473599\n",
      "183 Train Loss 1.725517e-05 Test MSE 7.089812624491705e-07 Test RE 0.00022080685066473599\n",
      "184 Train Loss 1.7167558e-05 Test MSE 7.089812624491705e-07 Test RE 0.00022080685066473599\n",
      "185 Train Loss 1.6838867e-05 Test MSE 3.483908981391078e-07 Test RE 0.00015478489074842328\n",
      "186 Train Loss 1.6799533e-05 Test MSE 3.483908981391078e-07 Test RE 0.00015478489074842328\n",
      "187 Train Loss 1.6891034e-05 Test MSE 3.483908981391078e-07 Test RE 0.00015478489074842328\n",
      "188 Train Loss 1.6571463e-05 Test MSE 1.4810922657573528e-06 Test RE 0.00031914366038423946\n",
      "189 Train Loss 1.644951e-05 Test MSE 1.4810922657573528e-06 Test RE 0.00031914366038423946\n",
      "190 Train Loss 1.6612588e-05 Test MSE 1.4810922657573528e-06 Test RE 0.00031914366038423946\n",
      "191 Train Loss 1.658294e-05 Test MSE 1.4810922657573528e-06 Test RE 0.00031914366038423946\n",
      "192 Train Loss 1.6569618e-05 Test MSE 1.4810922657573528e-06 Test RE 0.00031914366038423946\n",
      "193 Train Loss 1.6285348e-05 Test MSE 1.1325935733720851e-06 Test RE 0.00027908224719166747\n",
      "194 Train Loss 1.6187198e-05 Test MSE 1.1325935733720851e-06 Test RE 0.00027908224719166747\n",
      "195 Train Loss 1.6412618e-05 Test MSE 1.1325935733720851e-06 Test RE 0.00027908224719166747\n",
      "196 Train Loss 1.608747e-05 Test MSE 4.140806317338321e-07 Test RE 0.0001687476072196498\n",
      "197 Train Loss 1.6102706e-05 Test MSE 4.140806317338321e-07 Test RE 0.0001687476072196498\n",
      "198 Train Loss 1.6059248e-05 Test MSE 4.140806317338321e-07 Test RE 0.0001687476072196498\n",
      "199 Train Loss 1.6109243e-05 Test MSE 4.140806317338321e-07 Test RE 0.0001687476072196498\n",
      "Training time: 83.71\n",
      "Training time: 83.71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (m_lambda): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 8.9937525 Test MSE 13.822046570056711 Test RE 0.9749477486360273\n",
      "1 Train Loss 2.2889628 Test MSE 14.148956770894253 Test RE 0.986409791615754\n",
      "2 Train Loss 1.8947629 Test MSE 14.369937346679935 Test RE 0.9940828974227552\n",
      "3 Train Loss 1.7884922 Test MSE 14.97919617109227 Test RE 1.0149377801037553\n",
      "4 Train Loss 1.7450153 Test MSE 15.074646518385139 Test RE 1.018166335354989\n",
      "5 Train Loss 1.6683155 Test MSE 15.967544728286448 Test RE 1.0478864762043634\n",
      "6 Train Loss 1.614118 Test MSE 15.987431074102656 Test RE 1.0485388040670984\n",
      "7 Train Loss 1.5982909 Test MSE 15.912725163563827 Test RE 1.046086134608924\n",
      "8 Train Loss 1.0671586 Test MSE 14.638260879709842 Test RE 1.0033210088948554\n",
      "9 Train Loss 0.8039317 Test MSE 14.270607228211563 Test RE 0.9906412122751818\n",
      "10 Train Loss 0.7504644 Test MSE 13.70569964319717 Test RE 0.9708357711763544\n",
      "11 Train Loss 0.7459228 Test MSE 13.510783094248636 Test RE 0.9639076469680625\n",
      "12 Train Loss 0.73885065 Test MSE 13.345496623296077 Test RE 0.9579934388297355\n",
      "13 Train Loss 0.7402961 Test MSE 13.302973784313233 Test RE 0.9564659909003466\n",
      "14 Train Loss 0.7423029 Test MSE 13.270817451157514 Test RE 0.9553092928420478\n",
      "15 Train Loss 0.7399472 Test MSE 13.127265901418037 Test RE 0.9501284137184274\n",
      "16 Train Loss 0.73666483 Test MSE 12.892116984904638 Test RE 0.9415801268703007\n",
      "17 Train Loss 0.73187846 Test MSE 12.80820076641453 Test RE 0.9385106991966145\n",
      "18 Train Loss 0.7260331 Test MSE 12.579078527739972 Test RE 0.9300784437917178\n",
      "19 Train Loss 0.69404256 Test MSE 11.350291564887813 Test RE 0.8834839692671296\n",
      "20 Train Loss 0.43403274 Test MSE 7.006213660121482 Test RE 0.6941236686090231\n",
      "21 Train Loss 0.28778103 Test MSE 4.703970353985671 Test RE 0.5687579141122565\n",
      "22 Train Loss 0.14225066 Test MSE 1.9501366491463061 Test RE 0.3662078814465898\n",
      "23 Train Loss 0.090362296 Test MSE 1.2447935290055931 Test RE 0.29257945445761574\n",
      "24 Train Loss 0.07894162 Test MSE 0.8156360397490487 Test RE 0.23683362830093438\n",
      "25 Train Loss 0.046600975 Test MSE 0.48369181075958845 Test RE 0.18238097456697389\n",
      "26 Train Loss 0.039023384 Test MSE 0.4445246934372399 Test RE 0.17484093099336837\n",
      "27 Train Loss 0.017383702 Test MSE 0.23502007004297285 Test RE 0.127129881002173\n",
      "28 Train Loss 0.0049012857 Test MSE 0.06553235629592313 Test RE 0.06713099074341723\n",
      "29 Train Loss 0.0005903198 Test MSE 0.001763939576141455 Test RE 0.011013795716158964\n",
      "30 Train Loss 0.00021633386 Test MSE 6.796055338873418e-06 Test RE 0.0006836339436532146\n",
      "31 Train Loss 9.10578e-05 Test MSE 5.454047960414592e-06 Test RE 0.0006124274399145302\n",
      "32 Train Loss 8.232816e-05 Test MSE 1.93748289995215e-06 Test RE 0.00036501785096494915\n",
      "33 Train Loss 7.620663e-05 Test MSE 1.6048213102724166e-07 Test RE 0.00010505301138276275\n",
      "34 Train Loss 7.053027e-05 Test MSE 8.135960328795547e-07 Test RE 0.00023653726774111226\n",
      "35 Train Loss 6.7022396e-05 Test MSE 2.687593907466137e-06 Test RE 0.00042990944716840546\n",
      "36 Train Loss 6.48549e-05 Test MSE 5.0812544936630065e-06 Test RE 0.000591126784801696\n",
      "37 Train Loss 6.4877386e-05 Test MSE 5.0812544936630065e-06 Test RE 0.000591126784801696\n",
      "38 Train Loss 6.0765786e-05 Test MSE 1.7560262305150316e-05 Test RE 0.0010989063026189529\n",
      "39 Train Loss 6.07636e-05 Test MSE 1.7560262305150316e-05 Test RE 0.0010989063026189529\n",
      "40 Train Loss 5.9182406e-05 Test MSE 2.6401875576105543e-06 Test RE 0.0004261010013525585\n",
      "41 Train Loss 5.9192982e-05 Test MSE 2.6401875576105543e-06 Test RE 0.0004261010013525585\n",
      "42 Train Loss 5.8266152e-05 Test MSE 2.7027828995543476e-06 Test RE 0.0004311225566338431\n",
      "43 Train Loss 5.8220194e-05 Test MSE 2.7027828995543476e-06 Test RE 0.0004311225566338431\n",
      "44 Train Loss 5.8069934e-05 Test MSE 2.7027828995543476e-06 Test RE 0.0004311225566338431\n",
      "45 Train Loss 5.641123e-05 Test MSE 1.8841758961405547e-06 Test RE 0.00035996136218139306\n",
      "46 Train Loss 5.65257e-05 Test MSE 1.8841758961405547e-06 Test RE 0.00035996136218139306\n",
      "47 Train Loss 5.6334822e-05 Test MSE 1.8841758961405547e-06 Test RE 0.00035996136218139306\n",
      "48 Train Loss 5.3569373e-05 Test MSE 5.595366099101503e-07 Test RE 0.0001961595327768692\n",
      "49 Train Loss 5.324918e-05 Test MSE 5.595366099101503e-07 Test RE 0.0001961595327768692\n",
      "50 Train Loss 5.3623597e-05 Test MSE 5.595366099101503e-07 Test RE 0.0001961595327768692\n",
      "51 Train Loss 5.125647e-05 Test MSE 8.411492535485714e-08 Test RE 7.60556875459334e-05\n",
      "52 Train Loss 5.1487816e-05 Test MSE 8.411492535485714e-08 Test RE 7.60556875459334e-05\n",
      "53 Train Loss 5.1055835e-05 Test MSE 8.411492535485714e-08 Test RE 7.60556875459334e-05\n",
      "54 Train Loss 5.1270472e-05 Test MSE 8.411492535485714e-08 Test RE 7.60556875459334e-05\n",
      "55 Train Loss 5.1246512e-05 Test MSE 8.411492535485714e-08 Test RE 7.60556875459334e-05\n",
      "56 Train Loss 5.053145e-05 Test MSE 8.411492535485714e-08 Test RE 7.60556875459334e-05\n",
      "57 Train Loss 4.989047e-05 Test MSE 2.0989688180475816e-06 Test RE 0.0003799252502510624\n",
      "58 Train Loss 5.0181156e-05 Test MSE 2.0989688180475816e-06 Test RE 0.0003799252502510624\n",
      "59 Train Loss 5.017999e-05 Test MSE 2.0989688180475816e-06 Test RE 0.0003799252502510624\n",
      "60 Train Loss 4.9288315e-05 Test MSE 8.957204175272675e-08 Test RE 7.848404926775951e-05\n",
      "61 Train Loss 4.9827024e-05 Test MSE 8.957204175272675e-08 Test RE 7.848404926775951e-05\n",
      "62 Train Loss 4.984641e-05 Test MSE 3.8682250242383906e-08 Test RE 5.1576400532048184e-05\n",
      "63 Train Loss 4.8788952e-05 Test MSE 3.8682250242383906e-08 Test RE 5.1576400532048184e-05\n",
      "64 Train Loss 5.0135346e-05 Test MSE 3.8682250242383906e-08 Test RE 5.1576400532048184e-05\n",
      "65 Train Loss 4.9609505e-05 Test MSE 3.8682250242383906e-08 Test RE 5.1576400532048184e-05\n",
      "66 Train Loss 4.9459562e-05 Test MSE 3.8682250242383906e-08 Test RE 5.1576400532048184e-05\n",
      "67 Train Loss 4.9244045e-05 Test MSE 3.8682250242383906e-08 Test RE 5.1576400532048184e-05\n",
      "68 Train Loss 4.906625e-05 Test MSE 3.8682250242383906e-08 Test RE 5.1576400532048184e-05\n",
      "69 Train Loss 4.932227e-05 Test MSE 3.8682250242383906e-08 Test RE 5.1576400532048184e-05\n",
      "70 Train Loss 4.8966318e-05 Test MSE 2.2384598063981204e-07 Test RE 0.000124070866442301\n",
      "71 Train Loss 4.976554e-05 Test MSE 2.2384598063981204e-07 Test RE 0.000124070866442301\n",
      "72 Train Loss 4.8720474e-05 Test MSE 2.2384598063981204e-07 Test RE 0.000124070866442301\n",
      "73 Train Loss 4.9336697e-05 Test MSE 2.2384598063981204e-07 Test RE 0.000124070866442301\n",
      "74 Train Loss 4.8909762e-05 Test MSE 2.2384598063981204e-07 Test RE 0.000124070866442301\n",
      "75 Train Loss 4.8891638e-05 Test MSE 2.2384598063981204e-07 Test RE 0.000124070866442301\n",
      "76 Train Loss 4.8822345e-05 Test MSE 4.806924268420606e-08 Test RE 5.749483140379828e-05\n",
      "77 Train Loss 4.94023e-05 Test MSE 4.806924268420606e-08 Test RE 5.749483140379828e-05\n",
      "78 Train Loss 4.9783222e-05 Test MSE 4.806924268420606e-08 Test RE 5.749483140379828e-05\n",
      "79 Train Loss 4.9033995e-05 Test MSE 4.806924268420606e-08 Test RE 5.749483140379828e-05\n",
      "80 Train Loss 4.8890808e-05 Test MSE 4.806924268420606e-08 Test RE 5.749483140379828e-05\n",
      "81 Train Loss 4.8849593e-05 Test MSE 4.806924268420606e-08 Test RE 5.749483140379828e-05\n",
      "82 Train Loss 4.90764e-05 Test MSE 4.806924268420606e-08 Test RE 5.749483140379828e-05\n",
      "83 Train Loss 4.9200014e-05 Test MSE 5.096068002579652e-07 Test RE 0.00018720298617359203\n",
      "84 Train Loss 4.881182e-05 Test MSE 5.096068002579652e-07 Test RE 0.00018720298617359203\n",
      "85 Train Loss 4.906603e-05 Test MSE 5.096068002579652e-07 Test RE 0.00018720298617359203\n",
      "86 Train Loss 4.9276503e-05 Test MSE 5.096068002579652e-07 Test RE 0.00018720298617359203\n",
      "87 Train Loss 4.8950187e-05 Test MSE 5.096068002579652e-07 Test RE 0.00018720298617359203\n",
      "88 Train Loss 4.8674916e-05 Test MSE 5.096068002579652e-07 Test RE 0.00018720298617359203\n",
      "89 Train Loss 4.8796974e-05 Test MSE 5.096068002579652e-07 Test RE 0.00018720298617359203\n",
      "90 Train Loss 4.9436745e-05 Test MSE 5.096068002579652e-07 Test RE 0.00018720298617359203\n",
      "91 Train Loss 4.9420523e-05 Test MSE 5.096068002579652e-07 Test RE 0.00018720298617359203\n",
      "92 Train Loss 4.8974223e-05 Test MSE 9.538609875593932e-07 Test RE 0.00025611658838975686\n",
      "93 Train Loss 4.8782345e-05 Test MSE 9.538609875593932e-07 Test RE 0.00025611658838975686\n",
      "94 Train Loss 4.853702e-05 Test MSE 9.538609875593932e-07 Test RE 0.00025611658838975686\n",
      "95 Train Loss 4.8671845e-05 Test MSE 9.538609875593932e-07 Test RE 0.00025611658838975686\n",
      "96 Train Loss 4.9044447e-05 Test MSE 6.941183067093038e-07 Test RE 0.00021848011419214745\n",
      "97 Train Loss 4.821307e-05 Test MSE 6.941183067093038e-07 Test RE 0.00021848011419214745\n",
      "98 Train Loss 4.8168087e-05 Test MSE 6.941183067093038e-07 Test RE 0.00021848011419214745\n",
      "99 Train Loss 4.856377e-05 Test MSE 6.941183067093038e-07 Test RE 0.00021848011419214745\n",
      "100 Train Loss 4.835129e-05 Test MSE 6.941183067093038e-07 Test RE 0.00021848011419214745\n",
      "101 Train Loss 4.7695685e-05 Test MSE 1.4325405372019585e-06 Test RE 0.0003138691454033345\n",
      "102 Train Loss 4.832215e-05 Test MSE 1.4325405372019585e-06 Test RE 0.0003138691454033345\n",
      "103 Train Loss 4.7749923e-05 Test MSE 1.4325405372019585e-06 Test RE 0.0003138691454033345\n",
      "104 Train Loss 4.8052967e-05 Test MSE 1.4325405372019585e-06 Test RE 0.0003138691454033345\n",
      "105 Train Loss 4.8509457e-05 Test MSE 1.4325405372019585e-06 Test RE 0.0003138691454033345\n",
      "106 Train Loss 4.8658407e-05 Test MSE 1.4325405372019585e-06 Test RE 0.0003138691454033345\n",
      "107 Train Loss 4.64663e-05 Test MSE 2.5841078181323006e-07 Test RE 0.00013330624024393808\n",
      "108 Train Loss 4.6879908e-05 Test MSE 2.5841078181323006e-07 Test RE 0.00013330624024393808\n",
      "109 Train Loss 4.572738e-05 Test MSE 2.5841078181323006e-07 Test RE 0.00013330624024393808\n",
      "110 Train Loss 4.6526213e-05 Test MSE 2.5841078181323006e-07 Test RE 0.00013330624024393808\n",
      "111 Train Loss 4.5594534e-05 Test MSE 2.819985448922627e-07 Test RE 0.00013925750134024617\n",
      "112 Train Loss 4.568715e-05 Test MSE 2.819985448922627e-07 Test RE 0.00013925750134024617\n",
      "113 Train Loss 4.56537e-05 Test MSE 2.819985448922627e-07 Test RE 0.00013925750134024617\n",
      "114 Train Loss 4.607724e-05 Test MSE 2.819985448922627e-07 Test RE 0.00013925750134024617\n",
      "115 Train Loss 4.617861e-05 Test MSE 2.819985448922627e-07 Test RE 0.00013925750134024617\n",
      "116 Train Loss 4.5940877e-05 Test MSE 2.819985448922627e-07 Test RE 0.00013925750134024617\n",
      "117 Train Loss 4.6247947e-05 Test MSE 2.819985448922627e-07 Test RE 0.00013925750134024617\n",
      "118 Train Loss 4.6290377e-05 Test MSE 2.819985448922627e-07 Test RE 0.00013925750134024617\n",
      "119 Train Loss 4.4647735e-05 Test MSE 3.822263878696976e-07 Test RE 0.0001621270564971122\n",
      "120 Train Loss 4.4799785e-05 Test MSE 3.822263878696976e-07 Test RE 0.0001621270564971122\n",
      "121 Train Loss 4.2924166e-05 Test MSE 2.3108284200438675e-05 Test RE 0.0012606049695344053\n",
      "122 Train Loss 4.2219206e-05 Test MSE 2.3108284200438675e-05 Test RE 0.0012606049695344053\n",
      "123 Train Loss 4.2004696e-05 Test MSE 2.909509391371452e-06 Test RE 0.00044730633246338475\n",
      "124 Train Loss 4.1975374e-05 Test MSE 2.909509391371452e-06 Test RE 0.00044730633246338475\n",
      "125 Train Loss 4.1919466e-05 Test MSE 2.909509391371452e-06 Test RE 0.00044730633246338475\n",
      "126 Train Loss 4.1703726e-05 Test MSE 2.909509391371452e-06 Test RE 0.00044730633246338475\n",
      "127 Train Loss 4.1510764e-05 Test MSE 2.909509391371452e-06 Test RE 0.00044730633246338475\n",
      "128 Train Loss 4.06922e-05 Test MSE 7.980855496746118e-06 Test RE 0.0007408322647880648\n",
      "129 Train Loss 4.1149455e-05 Test MSE 7.980855496746118e-06 Test RE 0.0007408322647880648\n",
      "130 Train Loss 4.1231542e-05 Test MSE 7.980855496746118e-06 Test RE 0.0007408322647880648\n",
      "131 Train Loss 4.1622647e-05 Test MSE 7.980855496746118e-06 Test RE 0.0007408322647880648\n",
      "132 Train Loss 4.1352694e-05 Test MSE 7.980855496746118e-06 Test RE 0.0007408322647880648\n",
      "133 Train Loss 4.1201118e-05 Test MSE 7.980855496746118e-06 Test RE 0.0007408322647880648\n",
      "134 Train Loss 4.1026906e-05 Test MSE 7.980855496746118e-06 Test RE 0.0007408322647880648\n",
      "135 Train Loss 4.1137846e-05 Test MSE 7.980855496746118e-06 Test RE 0.0007408322647880648\n",
      "136 Train Loss 4.01925e-05 Test MSE 1.3156579590590698e-06 Test RE 0.00030079226462805046\n",
      "137 Train Loss 4.0664894e-05 Test MSE 1.3156579590590698e-06 Test RE 0.00030079226462805046\n",
      "138 Train Loss 3.9920655e-05 Test MSE 1.3156579590590698e-06 Test RE 0.00030079226462805046\n",
      "139 Train Loss 4.0192866e-05 Test MSE 1.3156579590590698e-06 Test RE 0.00030079226462805046\n",
      "140 Train Loss 3.9746363e-05 Test MSE 1.3156579590590698e-06 Test RE 0.00030079226462805046\n",
      "141 Train Loss 4.0081944e-05 Test MSE 1.3156579590590698e-06 Test RE 0.00030079226462805046\n",
      "142 Train Loss 4.021654e-05 Test MSE 1.3156579590590698e-06 Test RE 0.00030079226462805046\n",
      "143 Train Loss 3.9347506e-05 Test MSE 1.3156579590590698e-06 Test RE 0.00030079226462805046\n",
      "144 Train Loss 3.941142e-05 Test MSE 2.2854539040757988e-05 Test RE 0.001253664701559926\n",
      "145 Train Loss 4.003547e-05 Test MSE 2.2854539040757988e-05 Test RE 0.001253664701559926\n",
      "146 Train Loss 3.9849263e-05 Test MSE 2.2854539040757988e-05 Test RE 0.001253664701559926\n",
      "147 Train Loss 4.0334264e-05 Test MSE 2.2854539040757988e-05 Test RE 0.001253664701559926\n",
      "148 Train Loss 4.0131457e-05 Test MSE 2.2854539040757988e-05 Test RE 0.001253664701559926\n",
      "149 Train Loss 3.996025e-05 Test MSE 2.2854539040757988e-05 Test RE 0.001253664701559926\n",
      "150 Train Loss 3.961127e-05 Test MSE 2.2854539040757988e-05 Test RE 0.001253664701559926\n",
      "151 Train Loss 4.0893658e-05 Test MSE 2.2854539040757988e-05 Test RE 0.001253664701559926\n",
      "152 Train Loss 4.063906e-05 Test MSE 2.2854539040757988e-05 Test RE 0.001253664701559926\n",
      "153 Train Loss 4.026881e-05 Test MSE 2.2854539040757988e-05 Test RE 0.001253664701559926\n",
      "154 Train Loss 4.0768264e-05 Test MSE 2.2854539040757988e-05 Test RE 0.001253664701559926\n",
      "155 Train Loss 4.032824e-05 Test MSE 3.7236548725488856e-06 Test RE 0.0005060342072382509\n",
      "156 Train Loss 3.991802e-05 Test MSE 3.7236548725488856e-06 Test RE 0.0005060342072382509\n",
      "157 Train Loss 3.958169e-05 Test MSE 3.7236548725488856e-06 Test RE 0.0005060342072382509\n",
      "158 Train Loss 3.9772138e-05 Test MSE 3.7236548725488856e-06 Test RE 0.0005060342072382509\n",
      "159 Train Loss 3.954079e-05 Test MSE 3.7236548725488856e-06 Test RE 0.0005060342072382509\n",
      "160 Train Loss 3.947261e-05 Test MSE 3.7236548725488856e-06 Test RE 0.0005060342072382509\n",
      "161 Train Loss 4.052015e-05 Test MSE 3.7236548725488856e-06 Test RE 0.0005060342072382509\n",
      "162 Train Loss 3.9269733e-05 Test MSE 3.7236548725488856e-06 Test RE 0.0005060342072382509\n",
      "163 Train Loss 3.981034e-05 Test MSE 1.1639727895825776e-05 Test RE 0.0008946776301761581\n",
      "164 Train Loss 3.921111e-05 Test MSE 1.1639727895825776e-05 Test RE 0.0008946776301761581\n",
      "165 Train Loss 3.9546398e-05 Test MSE 1.1639727895825776e-05 Test RE 0.0008946776301761581\n",
      "166 Train Loss 3.9361625e-05 Test MSE 1.1639727895825776e-05 Test RE 0.0008946776301761581\n",
      "167 Train Loss 3.869672e-05 Test MSE 4.317871554899006e-06 Test RE 0.000544916582633537\n",
      "168 Train Loss 3.8652368e-05 Test MSE 4.317871554899006e-06 Test RE 0.000544916582633537\n",
      "169 Train Loss 3.916317e-05 Test MSE 4.317871554899006e-06 Test RE 0.000544916582633537\n",
      "170 Train Loss 3.906572e-05 Test MSE 4.317871554899006e-06 Test RE 0.000544916582633537\n",
      "171 Train Loss 3.9089176e-05 Test MSE 4.317871554899006e-06 Test RE 0.000544916582633537\n",
      "172 Train Loss 3.8193597e-05 Test MSE 4.317871554899006e-06 Test RE 0.000544916582633537\n",
      "173 Train Loss 3.823482e-05 Test MSE 4.317871554899006e-06 Test RE 0.000544916582633537\n",
      "174 Train Loss 3.8725604e-05 Test MSE 4.317871554899006e-06 Test RE 0.000544916582633537\n",
      "175 Train Loss 3.8062997e-05 Test MSE 1.820789726827994e-06 Test RE 0.00035385477624201827\n",
      "176 Train Loss 3.8730737e-05 Test MSE 1.820789726827994e-06 Test RE 0.00035385477624201827\n",
      "177 Train Loss 3.8494072e-05 Test MSE 1.1829001438797837e-05 Test RE 0.000901922470558272\n",
      "178 Train Loss 3.8079143e-05 Test MSE 1.1829001438797837e-05 Test RE 0.000901922470558272\n",
      "179 Train Loss 3.773764e-05 Test MSE 1.1829001438797837e-05 Test RE 0.000901922470558272\n",
      "180 Train Loss 3.7951646e-05 Test MSE 1.1829001438797837e-05 Test RE 0.000901922470558272\n",
      "181 Train Loss 3.8556103e-05 Test MSE 1.1829001438797837e-05 Test RE 0.000901922470558272\n",
      "182 Train Loss 3.7497295e-05 Test MSE 1.2829761695358662e-06 Test RE 0.00029703283453267243\n",
      "183 Train Loss 3.7563655e-05 Test MSE 1.2829761695358662e-06 Test RE 0.00029703283453267243\n",
      "184 Train Loss 3.7415317e-05 Test MSE 1.2829761695358662e-06 Test RE 0.00029703283453267243\n",
      "185 Train Loss 3.8444836e-05 Test MSE 1.2829761695358662e-06 Test RE 0.00029703283453267243\n",
      "186 Train Loss 3.775303e-05 Test MSE 1.2829761695358662e-06 Test RE 0.00029703283453267243\n",
      "187 Train Loss 3.7689522e-05 Test MSE 1.2829761695358662e-06 Test RE 0.00029703283453267243\n",
      "188 Train Loss 3.7156955e-05 Test MSE 9.327857446340805e-06 Test RE 0.0008009144236971471\n",
      "189 Train Loss 3.6748734e-05 Test MSE 9.327857446340805e-06 Test RE 0.0008009144236971471\n",
      "190 Train Loss 3.6892132e-05 Test MSE 9.327857446340805e-06 Test RE 0.0008009144236971471\n",
      "191 Train Loss 3.7201997e-05 Test MSE 9.327857446340805e-06 Test RE 0.0008009144236971471\n",
      "192 Train Loss 3.6626257e-05 Test MSE 9.327857446340805e-06 Test RE 0.0008009144236971471\n",
      "193 Train Loss 3.66247e-05 Test MSE 8.613035503456793e-08 Test RE 7.696145744679862e-05\n",
      "194 Train Loss 3.67327e-05 Test MSE 8.613035503456793e-08 Test RE 7.696145744679862e-05\n",
      "195 Train Loss 3.6999478e-05 Test MSE 8.613035503456793e-08 Test RE 7.696145744679862e-05\n",
      "196 Train Loss 3.6295543e-05 Test MSE 8.613035503456793e-08 Test RE 7.696145744679862e-05\n",
      "197 Train Loss 3.6545094e-05 Test MSE 1.4254297487119435e-06 Test RE 0.0003130891906499201\n",
      "198 Train Loss 3.6510617e-05 Test MSE 1.4254297487119435e-06 Test RE 0.0003130891906499201\n",
      "199 Train Loss 3.6906808e-05 Test MSE 1.4254297487119435e-06 Test RE 0.0003130891906499201\n",
      "Training time: 83.18\n",
      "Training time: 83.18\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (m_lambda): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 1.863012 Test MSE 14.672264414509362 Test RE 1.0044856510484534\n",
      "1 Train Loss 1.8753912 Test MSE 14.506277713134581 Test RE 0.9987876382081851\n",
      "2 Train Loss 1.8128793 Test MSE 14.54724347285334 Test RE 1.0001969331747147\n",
      "3 Train Loss 1.8169706 Test MSE 14.60313598279473 Test RE 1.002116538177341\n",
      "4 Train Loss 1.7215244 Test MSE 15.194750803437783 Test RE 1.0222143086334328\n",
      "5 Train Loss 1.6474367 Test MSE 15.82299413043019 Test RE 1.0431325521779136\n",
      "6 Train Loss 1.5905278 Test MSE 15.784120776068585 Test RE 1.0418503992196755\n",
      "7 Train Loss 1.4621596 Test MSE 15.459946398487588 Test RE 1.0310961297221124\n",
      "8 Train Loss 0.8796836 Test MSE 14.944654642404366 Test RE 1.0137668983106989\n",
      "9 Train Loss 0.8320322 Test MSE 15.02459683925855 Test RE 1.016474711404351\n",
      "10 Train Loss 0.8041055 Test MSE 14.317355349960096 Test RE 0.9922624730525448\n",
      "11 Train Loss 0.7673276 Test MSE 13.576162904133874 Test RE 0.9662370472068751\n",
      "12 Train Loss 0.7534351 Test MSE 13.258875519961203 Test RE 0.9548793718703591\n",
      "13 Train Loss 0.7287458 Test MSE 12.925114852923532 Test RE 0.9427843620200878\n",
      "14 Train Loss 0.7061008 Test MSE 12.464293189213292 Test RE 0.9258251897150045\n",
      "15 Train Loss 0.63843447 Test MSE 10.752214153293483 Test RE 0.8598924140748789\n",
      "16 Train Loss 0.43668774 Test MSE 6.987830186925565 Test RE 0.6932124213989123\n",
      "17 Train Loss 0.35687882 Test MSE 5.195918691926032 Test RE 0.5977592949976133\n",
      "18 Train Loss 0.24764186 Test MSE 3.69483357429897 Test RE 0.5040720364149026\n",
      "19 Train Loss 0.17636904 Test MSE 1.6551414015289394 Test RE 0.33737485887569163\n",
      "20 Train Loss 0.08390476 Test MSE 1.0509281160547435 Test RE 0.26883243783815175\n",
      "21 Train Loss 0.04057303 Test MSE 0.4858008108612681 Test RE 0.18277815218822496\n",
      "22 Train Loss 0.0130974315 Test MSE 0.07611227036586282 Test RE 0.07234732920063497\n",
      "23 Train Loss 0.0075436556 Test MSE 0.027220351832798365 Test RE 0.043265530377421216\n",
      "24 Train Loss 0.002485283 Test MSE 0.010371197171774036 Test RE 0.026706047078231435\n",
      "25 Train Loss 0.000499328 Test MSE 0.00024383526019800753 Test RE 0.004094901114059381\n",
      "26 Train Loss 0.000109519075 Test MSE 1.114168081039441e-05 Test RE 0.0008753273956518466\n",
      "27 Train Loss 4.9189744e-05 Test MSE 1.2302686772275e-05 Test RE 0.0009198036916190539\n",
      "28 Train Loss 4.9311708e-05 Test MSE 1.2302686772275e-05 Test RE 0.0009198036916190539\n",
      "29 Train Loss 4.7348625e-05 Test MSE 1.3220715047679567e-05 Test RE 0.0009535042588702326\n",
      "30 Train Loss 4.7424975e-05 Test MSE 1.3220715047679567e-05 Test RE 0.0009535042588702326\n",
      "31 Train Loss 4.7163157e-05 Test MSE 1.3220715047679567e-05 Test RE 0.0009535042588702326\n",
      "32 Train Loss 4.732693e-05 Test MSE 1.3220715047679567e-05 Test RE 0.0009535042588702326\n",
      "33 Train Loss 4.7571957e-05 Test MSE 1.3220715047679567e-05 Test RE 0.0009535042588702326\n",
      "34 Train Loss 4.6962847e-05 Test MSE 1.3220715047679567e-05 Test RE 0.0009535042588702326\n",
      "35 Train Loss 4.7629354e-05 Test MSE 1.3220715047679567e-05 Test RE 0.0009535042588702326\n",
      "36 Train Loss 4.7970687e-05 Test MSE 1.3220715047679567e-05 Test RE 0.0009535042588702326\n",
      "37 Train Loss 4.7479578e-05 Test MSE 1.3220715047679567e-05 Test RE 0.0009535042588702326\n",
      "38 Train Loss 4.6825175e-05 Test MSE 1.3220715047679567e-05 Test RE 0.0009535042588702326\n",
      "39 Train Loss 4.7000754e-05 Test MSE 1.3220715047679567e-05 Test RE 0.0009535042588702326\n",
      "40 Train Loss 4.7007063e-05 Test MSE 1.1143158812078314e-05 Test RE 0.0008753854520835656\n",
      "41 Train Loss 4.651264e-05 Test MSE 1.1143158812078314e-05 Test RE 0.0008753854520835656\n",
      "42 Train Loss 4.6487992e-05 Test MSE 1.1910138631346094e-05 Test RE 0.0009050104065261479\n",
      "43 Train Loss 4.6002413e-05 Test MSE 1.1910138631346094e-05 Test RE 0.0009050104065261479\n",
      "44 Train Loss 4.6302357e-05 Test MSE 1.1910138631346094e-05 Test RE 0.0009050104065261479\n",
      "45 Train Loss 4.6681e-05 Test MSE 1.1910138631346094e-05 Test RE 0.0009050104065261479\n",
      "46 Train Loss 4.5982546e-05 Test MSE 1.1132900001328136e-05 Test RE 0.0008749824029250445\n",
      "47 Train Loss 4.5795587e-05 Test MSE 1.1132900001328136e-05 Test RE 0.0008749824029250445\n",
      "48 Train Loss 4.574881e-05 Test MSE 1.1132900001328136e-05 Test RE 0.0008749824029250445\n",
      "49 Train Loss 4.5318375e-05 Test MSE 1.1132900001328136e-05 Test RE 0.0008749824029250445\n",
      "50 Train Loss 4.5506145e-05 Test MSE 1.1132900001328136e-05 Test RE 0.0008749824029250445\n",
      "51 Train Loss 4.548552e-05 Test MSE 1.1132900001328136e-05 Test RE 0.0008749824029250445\n",
      "52 Train Loss 4.570001e-05 Test MSE 1.1132900001328136e-05 Test RE 0.0008749824029250445\n",
      "53 Train Loss 4.4952983e-05 Test MSE 2.1485772941217167e-05 Test RE 0.001215543920956821\n",
      "54 Train Loss 4.4278688e-05 Test MSE 2.1485772941217167e-05 Test RE 0.001215543920956821\n",
      "55 Train Loss 4.365328e-05 Test MSE 3.2258677913940704e-05 Test RE 0.001489424340718219\n",
      "56 Train Loss 4.3708027e-05 Test MSE 3.2258677913940704e-05 Test RE 0.001489424340718219\n",
      "57 Train Loss 4.3214615e-05 Test MSE 3.321626499895345e-05 Test RE 0.001511369184601871\n",
      "58 Train Loss 4.3256972e-05 Test MSE 3.321626499895345e-05 Test RE 0.001511369184601871\n",
      "59 Train Loss 4.172499e-05 Test MSE 9.479031159942651e-06 Test RE 0.0008073784256692209\n",
      "60 Train Loss 4.186258e-05 Test MSE 9.479031159942651e-06 Test RE 0.0008073784256692209\n",
      "61 Train Loss 4.2524338e-05 Test MSE 9.479031159942651e-06 Test RE 0.0008073784256692209\n",
      "62 Train Loss 4.1479052e-05 Test MSE 2.4661888862051835e-06 Test RE 0.00041182085216838753\n",
      "63 Train Loss 4.1672953e-05 Test MSE 2.4661888862051835e-06 Test RE 0.00041182085216838753\n",
      "64 Train Loss 4.149014e-05 Test MSE 2.4661888862051835e-06 Test RE 0.00041182085216838753\n",
      "65 Train Loss 4.136959e-05 Test MSE 2.4661888862051835e-06 Test RE 0.00041182085216838753\n",
      "66 Train Loss 4.160395e-05 Test MSE 2.4661888862051835e-06 Test RE 0.00041182085216838753\n",
      "67 Train Loss 4.1714076e-05 Test MSE 2.4661888862051835e-06 Test RE 0.00041182085216838753\n",
      "68 Train Loss 4.1673225e-05 Test MSE 2.4661888862051835e-06 Test RE 0.00041182085216838753\n",
      "69 Train Loss 4.0921524e-05 Test MSE 4.585863809453463e-07 Test RE 0.00017758477986745582\n",
      "70 Train Loss 4.063583e-05 Test MSE 4.585863809453463e-07 Test RE 0.00017758477986745582\n",
      "71 Train Loss 4.098594e-05 Test MSE 4.585863809453463e-07 Test RE 0.00017758477986745582\n",
      "72 Train Loss 4.1183157e-05 Test MSE 4.585863809453463e-07 Test RE 0.00017758477986745582\n",
      "73 Train Loss 3.960026e-05 Test MSE 8.364898288700267e-08 Test RE 7.584474527661835e-05\n",
      "74 Train Loss 3.9263112e-05 Test MSE 8.364898288700267e-08 Test RE 7.584474527661835e-05\n",
      "75 Train Loss 3.9671184e-05 Test MSE 8.364898288700267e-08 Test RE 7.584474527661835e-05\n",
      "76 Train Loss 3.855404e-05 Test MSE 4.092452331678524e-07 Test RE 0.00016775944456364319\n",
      "77 Train Loss 3.8517308e-05 Test MSE 4.092452331678524e-07 Test RE 0.00016775944456364319\n",
      "78 Train Loss 3.8596012e-05 Test MSE 4.092452331678524e-07 Test RE 0.00016775944456364319\n",
      "79 Train Loss 3.841192e-05 Test MSE 4.092452331678524e-07 Test RE 0.00016775944456364319\n",
      "80 Train Loss 3.8677907e-05 Test MSE 4.092452331678524e-07 Test RE 0.00016775944456364319\n",
      "81 Train Loss 3.8766688e-05 Test MSE 4.092452331678524e-07 Test RE 0.00016775944456364319\n",
      "82 Train Loss 3.8982093e-05 Test MSE 4.092452331678524e-07 Test RE 0.00016775944456364319\n",
      "83 Train Loss 3.888903e-05 Test MSE 4.092452331678524e-07 Test RE 0.00016775944456364319\n",
      "84 Train Loss 3.852515e-05 Test MSE 4.092452331678524e-07 Test RE 0.00016775944456364319\n",
      "85 Train Loss 3.8791204e-05 Test MSE 4.092452331678524e-07 Test RE 0.00016775944456364319\n",
      "86 Train Loss 3.8195667e-05 Test MSE 2.6618347420997056e-06 Test RE 0.00042784425954703423\n",
      "87 Train Loss 3.8227325e-05 Test MSE 2.6618347420997056e-06 Test RE 0.00042784425954703423\n",
      "88 Train Loss 3.8166432e-05 Test MSE 2.6618347420997056e-06 Test RE 0.00042784425954703423\n",
      "89 Train Loss 3.8047867e-05 Test MSE 2.6618347420997056e-06 Test RE 0.00042784425954703423\n",
      "90 Train Loss 3.83213e-05 Test MSE 2.6618347420997056e-06 Test RE 0.00042784425954703423\n",
      "91 Train Loss 3.7356134e-05 Test MSE 1.5122102728611016e-06 Test RE 0.0003224788651509144\n",
      "92 Train Loss 3.7494134e-05 Test MSE 1.5122102728611016e-06 Test RE 0.0003224788651509144\n",
      "93 Train Loss 3.7757898e-05 Test MSE 1.5122102728611016e-06 Test RE 0.0003224788651509144\n",
      "94 Train Loss 3.6741054e-05 Test MSE 2.1681326978817307e-07 Test RE 0.00012210630637702726\n",
      "95 Train Loss 3.670297e-05 Test MSE 2.1681326978817307e-07 Test RE 0.00012210630637702726\n",
      "96 Train Loss 3.7009573e-05 Test MSE 2.1681326978817307e-07 Test RE 0.00012210630637702726\n",
      "97 Train Loss 3.638934e-05 Test MSE 8.628513613663205e-08 Test RE 7.703057844533758e-05\n",
      "98 Train Loss 3.648601e-05 Test MSE 8.628513613663205e-08 Test RE 7.703057844533758e-05\n",
      "99 Train Loss 3.624523e-05 Test MSE 8.628513613663205e-08 Test RE 7.703057844533758e-05\n",
      "100 Train Loss 3.6188147e-05 Test MSE 9.385499094299769e-07 Test RE 0.00025405272107494536\n",
      "101 Train Loss 3.59685e-05 Test MSE 9.385499094299769e-07 Test RE 0.00025405272107494536\n",
      "102 Train Loss 3.5998106e-05 Test MSE 9.385499094299769e-07 Test RE 0.00025405272107494536\n",
      "103 Train Loss 3.587324e-05 Test MSE 9.385499094299769e-07 Test RE 0.00025405272107494536\n",
      "104 Train Loss 3.6227648e-05 Test MSE 9.385499094299769e-07 Test RE 0.00025405272107494536\n",
      "105 Train Loss 3.621867e-05 Test MSE 9.385499094299769e-07 Test RE 0.00025405272107494536\n",
      "106 Train Loss 3.5945497e-05 Test MSE 2.704566365610666e-07 Test RE 0.00013637789606227852\n",
      "107 Train Loss 3.5867746e-05 Test MSE 2.704566365610666e-07 Test RE 0.00013637789606227852\n",
      "108 Train Loss 3.5043784e-05 Test MSE 5.723778954163709e-06 Test RE 0.0006273885544361795\n",
      "109 Train Loss 3.5033074e-05 Test MSE 5.723778954163709e-06 Test RE 0.0006273885544361795\n",
      "110 Train Loss 3.3510827e-05 Test MSE 5.625371337501679e-07 Test RE 0.0001966847838360332\n",
      "111 Train Loss 3.3414337e-05 Test MSE 5.625371337501679e-07 Test RE 0.0001966847838360332\n",
      "112 Train Loss 3.384673e-05 Test MSE 5.625371337501679e-07 Test RE 0.0001966847838360332\n",
      "113 Train Loss 3.1907322e-05 Test MSE 8.168615995260074e-06 Test RE 0.0007494961477733452\n",
      "114 Train Loss 3.1930238e-05 Test MSE 8.168615995260074e-06 Test RE 0.0007494961477733452\n",
      "115 Train Loss 2.9395223e-05 Test MSE 6.380180711147337e-06 Test RE 0.0006623867777500224\n",
      "116 Train Loss 2.9395895e-05 Test MSE 6.380180711147337e-06 Test RE 0.0006623867777500224\n",
      "117 Train Loss 2.9522684e-05 Test MSE 6.380180711147337e-06 Test RE 0.0006623867777500224\n",
      "118 Train Loss 2.7103893e-05 Test MSE 2.3695585513925287e-05 Test RE 0.0012765237138231598\n",
      "119 Train Loss 2.7037717e-05 Test MSE 2.3695585513925287e-05 Test RE 0.0012765237138231598\n",
      "120 Train Loss 2.7313254e-05 Test MSE 2.3695585513925287e-05 Test RE 0.0012765237138231598\n",
      "121 Train Loss 2.3144305e-05 Test MSE 4.112496791559236e-07 Test RE 0.00016816977799593183\n",
      "122 Train Loss 2.2986433e-05 Test MSE 4.112496791559236e-07 Test RE 0.00016816977799593183\n",
      "123 Train Loss 2.2979224e-05 Test MSE 4.112496791559236e-07 Test RE 0.00016816977799593183\n",
      "124 Train Loss 1.6567654e-05 Test MSE 6.743582211728355e-07 Test RE 0.00021534782659816772\n",
      "125 Train Loss 1.6586422e-05 Test MSE 6.743582211728355e-07 Test RE 0.00021534782659816772\n",
      "126 Train Loss 1.6566435e-05 Test MSE 6.743582211728355e-07 Test RE 0.00021534782659816772\n",
      "127 Train Loss 1.6616394e-05 Test MSE 6.743582211728355e-07 Test RE 0.00021534782659816772\n",
      "128 Train Loss 1.4535239e-05 Test MSE 5.50862665497136e-06 Test RE 0.000615484094710453\n",
      "129 Train Loss 1.4656239e-05 Test MSE 5.50862665497136e-06 Test RE 0.000615484094710453\n",
      "130 Train Loss 9.456053e-06 Test MSE 5.076576973070003e-06 Test RE 0.0005908546429188591\n",
      "131 Train Loss 9.351816e-06 Test MSE 5.076576973070003e-06 Test RE 0.0005908546429188591\n",
      "132 Train Loss 8.453999e-06 Test MSE 6.372239148460764e-06 Test RE 0.000661974405098841\n",
      "133 Train Loss 8.489564e-06 Test MSE 6.372239148460764e-06 Test RE 0.000661974405098841\n",
      "134 Train Loss 8.579511e-06 Test MSE 6.372239148460764e-06 Test RE 0.000661974405098841\n",
      "135 Train Loss 7.3288006e-06 Test MSE 7.65710374051818e-06 Test RE 0.0007256503855255121\n",
      "136 Train Loss 7.272765e-06 Test MSE 7.65710374051818e-06 Test RE 0.0007256503855255121\n",
      "137 Train Loss 7.346984e-06 Test MSE 7.65710374051818e-06 Test RE 0.0007256503855255121\n",
      "138 Train Loss 6.4354854e-06 Test MSE 8.441836356915589e-06 Test RE 0.0007619274661220284\n",
      "139 Train Loss 6.4186975e-06 Test MSE 8.441836356915589e-06 Test RE 0.0007619274661220284\n",
      "140 Train Loss 6.475458e-06 Test MSE 8.441836356915589e-06 Test RE 0.0007619274661220284\n",
      "141 Train Loss 5.5066766e-06 Test MSE 1.0909493273922528e-07 Test RE 8.661586646619072e-05\n",
      "142 Train Loss 5.5368478e-06 Test MSE 1.0909493273922528e-07 Test RE 8.661586646619072e-05\n",
      "143 Train Loss 5.413693e-06 Test MSE 1.0909493273922528e-07 Test RE 8.661586646619072e-05\n",
      "144 Train Loss 5.5405712e-06 Test MSE 1.0909493273922528e-07 Test RE 8.661586646619072e-05\n",
      "145 Train Loss 5.603096e-06 Test MSE 1.0909493273922528e-07 Test RE 8.661586646619072e-05\n",
      "146 Train Loss 4.9012356e-06 Test MSE 3.5434902023265e-06 Test RE 0.0004936404993240796\n",
      "147 Train Loss 4.8746588e-06 Test MSE 3.5434902023265e-06 Test RE 0.0004936404993240796\n",
      "148 Train Loss 4.930804e-06 Test MSE 3.5434902023265e-06 Test RE 0.0004936404993240796\n",
      "149 Train Loss 4.8570637e-06 Test MSE 3.5434902023265e-06 Test RE 0.0004936404993240796\n",
      "150 Train Loss 4.845772e-06 Test MSE 3.5434902023265e-06 Test RE 0.0004936404993240796\n",
      "151 Train Loss 4.9628316e-06 Test MSE 3.5434902023265e-06 Test RE 0.0004936404993240796\n",
      "152 Train Loss 4.9252667e-06 Test MSE 3.5434902023265e-06 Test RE 0.0004936404993240796\n",
      "153 Train Loss 4.4527787e-06 Test MSE 6.245409684312107e-06 Test RE 0.0006553535117583258\n",
      "154 Train Loss 4.5110874e-06 Test MSE 6.245409684312107e-06 Test RE 0.0006553535117583258\n",
      "155 Train Loss 3.9459333e-06 Test MSE 4.845289896175275e-07 Test RE 0.0001825387397826565\n",
      "156 Train Loss 3.9203974e-06 Test MSE 4.845289896175275e-07 Test RE 0.0001825387397826565\n",
      "157 Train Loss 3.9898373e-06 Test MSE 4.845289896175275e-07 Test RE 0.0001825387397826565\n",
      "158 Train Loss 3.620375e-06 Test MSE 9.131083228650786e-08 Test RE 7.924216188698544e-05\n",
      "159 Train Loss 3.6825406e-06 Test MSE 9.131083228650786e-08 Test RE 7.924216188698544e-05\n",
      "160 Train Loss 3.7275897e-06 Test MSE 9.131083228650786e-08 Test RE 7.924216188698544e-05\n",
      "161 Train Loss 3.6649897e-06 Test MSE 9.131083228650786e-08 Test RE 7.924216188698544e-05\n",
      "162 Train Loss 2.7847602e-06 Test MSE 1.195590378792865e-06 Test RE 0.00028673873870298846\n",
      "163 Train Loss 2.8194763e-06 Test MSE 1.195590378792865e-06 Test RE 0.00028673873870298846\n",
      "164 Train Loss 2.8371194e-06 Test MSE 1.195590378792865e-06 Test RE 0.00028673873870298846\n",
      "165 Train Loss 2.7868405e-06 Test MSE 1.195590378792865e-06 Test RE 0.00028673873870298846\n",
      "166 Train Loss 2.5663833e-06 Test MSE 9.297808780282925e-08 Test RE 7.996233542687637e-05\n",
      "167 Train Loss 2.5548234e-06 Test MSE 9.297808780282925e-08 Test RE 7.996233542687637e-05\n",
      "168 Train Loss 2.5992506e-06 Test MSE 9.297808780282925e-08 Test RE 7.996233542687637e-05\n",
      "169 Train Loss 2.2051784e-06 Test MSE 3.6474420838351264e-08 Test RE 5.008288832968681e-05\n",
      "170 Train Loss 2.196169e-06 Test MSE 3.6474420838351264e-08 Test RE 5.008288832968681e-05\n",
      "171 Train Loss 2.184327e-06 Test MSE 3.6474420838351264e-08 Test RE 5.008288832968681e-05\n",
      "172 Train Loss 2.2169868e-06 Test MSE 3.6474420838351264e-08 Test RE 5.008288832968681e-05\n",
      "173 Train Loss 2.1903993e-06 Test MSE 3.6474420838351264e-08 Test RE 5.008288832968681e-05\n",
      "174 Train Loss 2.206281e-06 Test MSE 3.6474420838351264e-08 Test RE 5.008288832968681e-05\n",
      "175 Train Loss 2.1971684e-06 Test MSE 3.6474420838351264e-08 Test RE 5.008288832968681e-05\n",
      "176 Train Loss 2.2015483e-06 Test MSE 3.6474420838351264e-08 Test RE 5.008288832968681e-05\n",
      "177 Train Loss 2.2238423e-06 Test MSE 3.6474420838351264e-08 Test RE 5.008288832968681e-05\n",
      "178 Train Loss 2.2106146e-06 Test MSE 3.6474420838351264e-08 Test RE 5.008288832968681e-05\n",
      "179 Train Loss 2.018619e-06 Test MSE 1.3351217487988857e-08 Test RE 3.0300905016670984e-05\n",
      "180 Train Loss 2.0091886e-06 Test MSE 1.3351217487988857e-08 Test RE 3.0300905016670984e-05\n",
      "181 Train Loss 2.0458883e-06 Test MSE 1.3351217487988857e-08 Test RE 3.0300905016670984e-05\n",
      "182 Train Loss 2.0705584e-06 Test MSE 1.3351217487988857e-08 Test RE 3.0300905016670984e-05\n",
      "183 Train Loss 2.015343e-06 Test MSE 1.3351217487988857e-08 Test RE 3.0300905016670984e-05\n",
      "184 Train Loss 1.7989721e-06 Test MSE 9.808096759437616e-08 Test RE 8.212729816931924e-05\n",
      "185 Train Loss 1.8569111e-06 Test MSE 9.808096759437616e-08 Test RE 8.212729816931924e-05\n",
      "186 Train Loss 1.8639009e-06 Test MSE 9.808096759437616e-08 Test RE 8.212729816931924e-05\n",
      "187 Train Loss 1.822623e-06 Test MSE 9.808096759437616e-08 Test RE 8.212729816931924e-05\n",
      "188 Train Loss 1.8266915e-06 Test MSE 9.808096759437616e-08 Test RE 8.212729816931924e-05\n",
      "189 Train Loss 1.7192693e-06 Test MSE 6.43885035779024e-07 Test RE 0.00021042596659203464\n",
      "190 Train Loss 1.7106728e-06 Test MSE 6.43885035779024e-07 Test RE 0.00021042596659203464\n",
      "191 Train Loss 1.7295031e-06 Test MSE 6.43885035779024e-07 Test RE 0.00021042596659203464\n",
      "192 Train Loss 1.7028874e-06 Test MSE 6.43885035779024e-07 Test RE 0.00021042596659203464\n",
      "193 Train Loss 1.5995661e-06 Test MSE 3.098707334214216e-08 Test RE 4.616208802744396e-05\n",
      "194 Train Loss 1.602223e-06 Test MSE 3.098707334214216e-08 Test RE 4.616208802744396e-05\n",
      "195 Train Loss 1.6363477e-06 Test MSE 3.098707334214216e-08 Test RE 4.616208802744396e-05\n",
      "196 Train Loss 1.6067119e-06 Test MSE 3.098707334214216e-08 Test RE 4.616208802744396e-05\n",
      "197 Train Loss 1.5982729e-06 Test MSE 3.098707334214216e-08 Test RE 4.616208802744396e-05\n",
      "198 Train Loss 1.6050501e-06 Test MSE 3.098707334214216e-08 Test RE 4.616208802744396e-05\n",
      "199 Train Loss 1.6355481e-06 Test MSE 3.098707334214216e-08 Test RE 4.616208802744396e-05\n",
      "Training time: 82.61\n",
      "Training time: 82.61\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (m_lambda): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 6.070183 Test MSE 15.06301906013792 Test RE 1.017773590812373\n",
      "1 Train Loss 1.9749546 Test MSE 14.824539880010656 Test RE 1.0096847019111737\n",
      "2 Train Loss 1.8930559 Test MSE 14.671087955735864 Test RE 1.0044453791581294\n",
      "3 Train Loss 1.8893497 Test MSE 14.465503365381762 Test RE 0.9973829507667692\n",
      "4 Train Loss 1.8670058 Test MSE 14.802503115380636 Test RE 1.008933971729489\n",
      "5 Train Loss 1.8088112 Test MSE 14.893082523791449 Test RE 1.0120161957782348\n",
      "6 Train Loss 1.7133557 Test MSE 14.754439697423555 Test RE 1.0072946461836059\n",
      "7 Train Loss 1.5619915 Test MSE 13.968442355470781 Test RE 0.9800972141462112\n",
      "8 Train Loss 0.78937054 Test MSE 13.532644266432992 Test RE 0.9646871589258285\n",
      "9 Train Loss 0.75523674 Test MSE 13.428151195369457 Test RE 0.9609554984307749\n",
      "10 Train Loss 0.74500155 Test MSE 13.459103253829099 Test RE 0.9620623682538109\n",
      "11 Train Loss 0.73559624 Test MSE 13.15686320861976 Test RE 0.9511989111758317\n",
      "12 Train Loss 0.73365515 Test MSE 12.934012702342176 Test RE 0.94310881987376\n",
      "13 Train Loss 0.71743244 Test MSE 12.252422721505207 Test RE 0.9179227862667054\n",
      "14 Train Loss 0.53023 Test MSE 8.42928972844 Test RE 0.7613610505305207\n",
      "15 Train Loss 0.42993236 Test MSE 6.82092010327749 Test RE 0.684883409442338\n",
      "16 Train Loss 0.34391543 Test MSE 5.184598783389683 Test RE 0.5971077961567185\n",
      "17 Train Loss 0.28990507 Test MSE 4.538097918394112 Test RE 0.5586400861388003\n",
      "18 Train Loss 0.24047117 Test MSE 3.5809480293038045 Test RE 0.4962427488262201\n",
      "19 Train Loss 0.13143834 Test MSE 1.966939925617263 Test RE 0.36778220541772827\n",
      "20 Train Loss 0.074610285 Test MSE 0.9498997136942555 Test RE 0.25558422388430785\n",
      "21 Train Loss 0.061659034 Test MSE 0.6563240597648482 Test RE 0.2124488220013851\n",
      "22 Train Loss 0.041208066 Test MSE 0.5165184436658311 Test RE 0.18846819952869787\n",
      "23 Train Loss 0.03451586 Test MSE 0.47803717474637936 Test RE 0.18131177113087787\n",
      "24 Train Loss 0.027045835 Test MSE 0.34652957393785366 Test RE 0.15437085768153655\n",
      "25 Train Loss 0.022120472 Test MSE 0.20623849795074656 Test RE 0.11909129924985425\n",
      "26 Train Loss 0.015886173 Test MSE 0.10108552737404806 Test RE 0.08337573114517877\n",
      "27 Train Loss 0.0068242825 Test MSE 0.03537203609949939 Test RE 0.049320241511017236\n",
      "28 Train Loss 0.0017048814 Test MSE 0.011131549844076978 Test RE 0.027667695187225217\n",
      "29 Train Loss 0.00082796504 Test MSE 0.0010567559903712398 Test RE 0.008524767124502078\n",
      "30 Train Loss 0.00017287591 Test MSE 0.0006128453790322792 Test RE 0.006491882081245804\n",
      "31 Train Loss 5.4713768e-05 Test MSE 0.00011310374703453531 Test RE 0.002788904617136078\n",
      "32 Train Loss 4.894539e-05 Test MSE 6.902841072087343e-05 Test RE 0.0021787585381736613\n",
      "33 Train Loss 4.5495886e-05 Test MSE 4.192800645060928e-05 Test RE 0.001698037478254815\n",
      "34 Train Loss 4.293728e-05 Test MSE 2.5609269503359975e-05 Test RE 0.0013270697815735812\n",
      "35 Train Loss 4.352514e-05 Test MSE 2.5609269503359975e-05 Test RE 0.0013270697815735812\n",
      "36 Train Loss 4.329976e-05 Test MSE 2.5609269503359975e-05 Test RE 0.0013270697815735812\n",
      "37 Train Loss 3.96589e-05 Test MSE 1.2446351751874698e-07 Test RE 9.251586209762281e-05\n",
      "38 Train Loss 3.9654828e-05 Test MSE 1.2446351751874698e-07 Test RE 9.251586209762281e-05\n",
      "39 Train Loss 4.040951e-05 Test MSE 1.2446351751874698e-07 Test RE 9.251586209762281e-05\n",
      "40 Train Loss 4.0003837e-05 Test MSE 1.2446351751874698e-07 Test RE 9.251586209762281e-05\n",
      "41 Train Loss 3.980821e-05 Test MSE 1.2446351751874698e-07 Test RE 9.251586209762281e-05\n",
      "42 Train Loss 3.950834e-05 Test MSE 2.089901826537364e-08 Test RE 3.791037737289301e-05\n",
      "43 Train Loss 3.9579932e-05 Test MSE 2.089901826537364e-08 Test RE 3.791037737289301e-05\n",
      "44 Train Loss 3.9697472e-05 Test MSE 2.089901826537364e-08 Test RE 3.791037737289301e-05\n",
      "45 Train Loss 4.0162573e-05 Test MSE 2.089901826537364e-08 Test RE 3.791037737289301e-05\n",
      "46 Train Loss 3.9628452e-05 Test MSE 2.089901826537364e-08 Test RE 3.791037737289301e-05\n",
      "47 Train Loss 3.9040384e-05 Test MSE 5.0601721215666744e-08 Test RE 5.8989920326011635e-05\n",
      "48 Train Loss 3.8912684e-05 Test MSE 5.0601721215666744e-08 Test RE 5.8989920326011635e-05\n",
      "49 Train Loss 3.918692e-05 Test MSE 5.0601721215666744e-08 Test RE 5.8989920326011635e-05\n",
      "50 Train Loss 3.8731763e-05 Test MSE 5.0601721215666744e-08 Test RE 5.8989920326011635e-05\n",
      "51 Train Loss 3.761779e-05 Test MSE 2.3572256019908873e-07 Test RE 0.00012731973894287367\n",
      "52 Train Loss 3.7747533e-05 Test MSE 2.3572256019908873e-07 Test RE 0.00012731973894287367\n",
      "53 Train Loss 3.7903053e-05 Test MSE 2.3572256019908873e-07 Test RE 0.00012731973894287367\n",
      "54 Train Loss 3.7035094e-05 Test MSE 4.240504350063212e-07 Test RE 0.00017076698916091223\n",
      "55 Train Loss 3.659791e-05 Test MSE 4.240504350063212e-07 Test RE 0.00017076698916091223\n",
      "56 Train Loss 3.2396238e-05 Test MSE 4.095033881581688e-06 Test RE 0.0005306692397676822\n",
      "57 Train Loss 3.2211577e-05 Test MSE 4.095033881581688e-06 Test RE 0.0005306692397676822\n",
      "58 Train Loss 3.1426047e-05 Test MSE 5.299146658088297e-06 Test RE 0.0006036679715421504\n",
      "59 Train Loss 3.153753e-05 Test MSE 5.299146658088297e-06 Test RE 0.0006036679715421504\n",
      "60 Train Loss 2.5547042e-05 Test MSE 7.501930865081366e-08 Test RE 7.182600204730614e-05\n",
      "61 Train Loss 2.5345716e-05 Test MSE 7.501930865081366e-08 Test RE 7.182600204730614e-05\n",
      "62 Train Loss 2.5434108e-05 Test MSE 7.501930865081366e-08 Test RE 7.182600204730614e-05\n",
      "63 Train Loss 2.2379834e-05 Test MSE 5.9417944218392805e-06 Test RE 0.0006392253294325106\n",
      "64 Train Loss 2.2486121e-05 Test MSE 5.9417944218392805e-06 Test RE 0.0006392253294325106\n",
      "65 Train Loss 2.2448095e-05 Test MSE 5.9417944218392805e-06 Test RE 0.0006392253294325106\n",
      "66 Train Loss 1.9593173e-05 Test MSE 5.715977314543533e-06 Test RE 0.0006269608362745292\n",
      "67 Train Loss 1.9295758e-05 Test MSE 5.715977314543533e-06 Test RE 0.0006269608362745292\n",
      "68 Train Loss 1.9315052e-05 Test MSE 5.715977314543533e-06 Test RE 0.0006269608362745292\n",
      "69 Train Loss 1.9599194e-05 Test MSE 5.715977314543533e-06 Test RE 0.0006269608362745292\n",
      "70 Train Loss 1.9506946e-05 Test MSE 5.715977314543533e-06 Test RE 0.0006269608362745292\n",
      "71 Train Loss 1.787974e-05 Test MSE 1.6042845747102193e-06 Test RE 0.00033215123278444774\n",
      "72 Train Loss 1.779611e-05 Test MSE 1.6042845747102193e-06 Test RE 0.00033215123278444774\n",
      "73 Train Loss 1.8021938e-05 Test MSE 1.6042845747102193e-06 Test RE 0.00033215123278444774\n",
      "74 Train Loss 1.802786e-05 Test MSE 1.6042845747102193e-06 Test RE 0.00033215123278444774\n",
      "75 Train Loss 1.7059092e-05 Test MSE 1.349010178388621e-07 Test RE 9.63169625062844e-05\n",
      "76 Train Loss 1.717998e-05 Test MSE 1.349010178388621e-07 Test RE 9.63169625062844e-05\n",
      "77 Train Loss 1.7302853e-05 Test MSE 1.349010178388621e-07 Test RE 9.63169625062844e-05\n",
      "78 Train Loss 1.6083308e-05 Test MSE 1.8385021792392364e-06 Test RE 0.00035557174189646554\n",
      "79 Train Loss 1.6131606e-05 Test MSE 1.8385021792392364e-06 Test RE 0.00035557174189646554\n",
      "80 Train Loss 1.3742538e-05 Test MSE 1.6141235694380784e-06 Test RE 0.00033316820910980684\n",
      "81 Train Loss 1.4037898e-05 Test MSE 1.6141235694380784e-06 Test RE 0.00033316820910980684\n",
      "82 Train Loss 1.2615099e-05 Test MSE 1.4658522928218238e-07 Test RE 0.0001004015159282534\n",
      "83 Train Loss 1.2762407e-05 Test MSE 1.4658522928218238e-07 Test RE 0.0001004015159282534\n",
      "84 Train Loss 1.1328181e-05 Test MSE 7.25582473970125e-06 Test RE 0.0007063802641665239\n",
      "85 Train Loss 1.1576867e-05 Test MSE 7.25582473970125e-06 Test RE 0.0007063802641665239\n",
      "86 Train Loss 1.055756e-05 Test MSE 6.500272902733142e-06 Test RE 0.0006685916676206132\n",
      "87 Train Loss 1.0504388e-05 Test MSE 6.500272902733142e-06 Test RE 0.0006685916676206132\n",
      "88 Train Loss 9.395198e-06 Test MSE 5.432054253193881e-08 Test RE 6.111913711722443e-05\n",
      "89 Train Loss 9.408618e-06 Test MSE 5.432054253193881e-08 Test RE 6.111913711722443e-05\n",
      "90 Train Loss 9.613745e-06 Test MSE 5.432054253193881e-08 Test RE 6.111913711722443e-05\n",
      "91 Train Loss 9.370252e-06 Test MSE 5.432054253193881e-08 Test RE 6.111913711722443e-05\n",
      "92 Train Loss 8.844589e-06 Test MSE 6.275716016920929e-07 Test RE 0.00020774319486857568\n",
      "93 Train Loss 8.7789695e-06 Test MSE 6.275716016920929e-07 Test RE 0.00020774319486857568\n",
      "94 Train Loss 8.7994995e-06 Test MSE 6.275716016920929e-07 Test RE 0.00020774319486857568\n",
      "95 Train Loss 9.005214e-06 Test MSE 6.275716016920929e-07 Test RE 0.00020774319486857568\n",
      "96 Train Loss 8.244582e-06 Test MSE 1.1184562353696419e-07 Test RE 8.770102361276367e-05\n",
      "97 Train Loss 8.173105e-06 Test MSE 1.1184562353696419e-07 Test RE 8.770102361276367e-05\n",
      "98 Train Loss 8.245979e-06 Test MSE 1.1184562353696419e-07 Test RE 8.770102361276367e-05\n",
      "99 Train Loss 8.271538e-06 Test MSE 1.1184562353696419e-07 Test RE 8.770102361276367e-05\n",
      "100 Train Loss 7.9962565e-06 Test MSE 8.283214039327556e-08 Test RE 7.547352020677119e-05\n",
      "101 Train Loss 8.022701e-06 Test MSE 8.283214039327556e-08 Test RE 7.547352020677119e-05\n",
      "102 Train Loss 8.0892205e-06 Test MSE 8.283214039327556e-08 Test RE 7.547352020677119e-05\n",
      "103 Train Loss 8.041281e-06 Test MSE 8.283214039327556e-08 Test RE 7.547352020677119e-05\n",
      "104 Train Loss 7.97217e-06 Test MSE 8.283214039327556e-08 Test RE 7.547352020677119e-05\n",
      "105 Train Loss 8.08551e-06 Test MSE 8.283214039327556e-08 Test RE 7.547352020677119e-05\n",
      "106 Train Loss 8.132495e-06 Test MSE 8.283214039327556e-08 Test RE 7.547352020677119e-05\n",
      "107 Train Loss 7.742496e-06 Test MSE 2.685780056359461e-07 Test RE 0.00013590342038423078\n",
      "108 Train Loss 7.838651e-06 Test MSE 2.685780056359461e-07 Test RE 0.00013590342038423078\n",
      "109 Train Loss 7.591948e-06 Test MSE 2.685780056359461e-07 Test RE 0.00013590342038423078\n",
      "110 Train Loss 7.732741e-06 Test MSE 2.685780056359461e-07 Test RE 0.00013590342038423078\n",
      "111 Train Loss 7.672348e-06 Test MSE 2.685780056359461e-07 Test RE 0.00013590342038423078\n",
      "112 Train Loss 7.4945715e-06 Test MSE 5.964587470201247e-08 Test RE 6.404502075436608e-05\n",
      "113 Train Loss 7.476275e-06 Test MSE 5.964587470201247e-08 Test RE 6.404502075436608e-05\n",
      "114 Train Loss 6.7031633e-06 Test MSE 8.730274956999042e-07 Test RE 0.000245024282274137\n",
      "115 Train Loss 6.8788686e-06 Test MSE 8.730274956999042e-07 Test RE 0.000245024282274137\n",
      "116 Train Loss 6.087019e-06 Test MSE 1.7115381756071485e-06 Test RE 0.00034307451655325494\n",
      "117 Train Loss 6.181175e-06 Test MSE 1.7115381756071485e-06 Test RE 0.00034307451655325494\n",
      "118 Train Loss 6.1838373e-06 Test MSE 1.7115381756071485e-06 Test RE 0.00034307451655325494\n",
      "119 Train Loss 6.0717484e-06 Test MSE 1.7115381756071485e-06 Test RE 0.00034307451655325494\n",
      "120 Train Loss 5.5924365e-06 Test MSE 1.2074431443470701e-06 Test RE 0.0002881565592544736\n",
      "121 Train Loss 5.6027666e-06 Test MSE 1.2074431443470701e-06 Test RE 0.0002881565592544736\n",
      "122 Train Loss 5.508633e-06 Test MSE 1.2074431443470701e-06 Test RE 0.0002881565592544736\n",
      "123 Train Loss 5.727718e-06 Test MSE 1.2074431443470701e-06 Test RE 0.0002881565592544736\n",
      "124 Train Loss 5.6283393e-06 Test MSE 1.2074431443470701e-06 Test RE 0.0002881565592544736\n",
      "125 Train Loss 5.2755076e-06 Test MSE 4.733710114604863e-08 Test RE 5.705530012695653e-05\n",
      "126 Train Loss 5.274292e-06 Test MSE 4.733710114604863e-08 Test RE 5.705530012695653e-05\n",
      "127 Train Loss 5.323097e-06 Test MSE 4.733710114604863e-08 Test RE 5.705530012695653e-05\n",
      "128 Train Loss 5.3290823e-06 Test MSE 4.733710114604863e-08 Test RE 5.705530012695653e-05\n",
      "129 Train Loss 5.0671247e-06 Test MSE 1.9536897661954073e-07 Test RE 0.00011591054973606631\n",
      "130 Train Loss 5.0803073e-06 Test MSE 1.9536897661954073e-07 Test RE 0.00011591054973606631\n",
      "131 Train Loss 5.0917697e-06 Test MSE 1.9536897661954073e-07 Test RE 0.00011591054973606631\n",
      "132 Train Loss 5.033359e-06 Test MSE 1.9536897661954073e-07 Test RE 0.00011591054973606631\n",
      "133 Train Loss 5.0084054e-06 Test MSE 1.9536897661954073e-07 Test RE 0.00011591054973606631\n",
      "134 Train Loss 5.027931e-06 Test MSE 1.9536897661954073e-07 Test RE 0.00011591054973606631\n",
      "135 Train Loss 5.0931053e-06 Test MSE 1.9536897661954073e-07 Test RE 0.00011591054973606631\n",
      "136 Train Loss 5.0441104e-06 Test MSE 2.115676056550852e-07 Test RE 0.00012062011837494076\n",
      "137 Train Loss 4.9784726e-06 Test MSE 2.115676056550852e-07 Test RE 0.00012062011837494076\n",
      "138 Train Loss 4.9895093e-06 Test MSE 2.115676056550852e-07 Test RE 0.00012062011837494076\n",
      "139 Train Loss 4.9622417e-06 Test MSE 2.115676056550852e-07 Test RE 0.00012062011837494076\n",
      "140 Train Loss 4.8676566e-06 Test MSE 1.196860303253846e-08 Test RE 2.868909814367529e-05\n",
      "141 Train Loss 4.8864817e-06 Test MSE 1.196860303253846e-08 Test RE 2.868909814367529e-05\n",
      "142 Train Loss 4.8965608e-06 Test MSE 1.196860303253846e-08 Test RE 2.868909814367529e-05\n",
      "143 Train Loss 4.8734273e-06 Test MSE 1.196860303253846e-08 Test RE 2.868909814367529e-05\n",
      "144 Train Loss 4.819033e-06 Test MSE 1.196860303253846e-08 Test RE 2.868909814367529e-05\n",
      "145 Train Loss 4.7519184e-06 Test MSE 4.226624251219731e-08 Test RE 5.391281207499225e-05\n",
      "146 Train Loss 4.744511e-06 Test MSE 4.226624251219731e-08 Test RE 5.391281207499225e-05\n",
      "147 Train Loss 4.4482927e-06 Test MSE 1.645541144303143e-07 Test RE 0.00010637744071442534\n",
      "148 Train Loss 4.4425838e-06 Test MSE 1.645541144303143e-07 Test RE 0.00010637744071442534\n",
      "149 Train Loss 4.5153206e-06 Test MSE 1.645541144303143e-07 Test RE 0.00010637744071442534\n",
      "150 Train Loss 4.4319613e-06 Test MSE 1.645541144303143e-07 Test RE 0.00010637744071442534\n",
      "151 Train Loss 4.356107e-06 Test MSE 1.8524856173578033e-06 Test RE 0.0003569213995019715\n",
      "152 Train Loss 4.3783284e-06 Test MSE 1.8524856173578033e-06 Test RE 0.0003569213995019715\n",
      "153 Train Loss 4.309111e-06 Test MSE 1.8524856173578033e-06 Test RE 0.0003569213995019715\n",
      "154 Train Loss 4.2181377e-06 Test MSE 1.1042327721716006e-06 Test RE 0.00027556590399731003\n",
      "155 Train Loss 4.204051e-06 Test MSE 1.1042327721716006e-06 Test RE 0.00027556590399731003\n",
      "156 Train Loss 4.1272133e-06 Test MSE 1.1042327721716006e-06 Test RE 0.00027556590399731003\n",
      "157 Train Loss 4.039322e-06 Test MSE 2.0567931793498e-06 Test RE 0.00037608886605704504\n",
      "158 Train Loss 4.042589e-06 Test MSE 2.0567931793498e-06 Test RE 0.00037608886605704504\n",
      "159 Train Loss 4.0933946e-06 Test MSE 2.0567931793498e-06 Test RE 0.00037608886605704504\n",
      "160 Train Loss 4.1014705e-06 Test MSE 2.0567931793498e-06 Test RE 0.00037608886605704504\n",
      "161 Train Loss 4.1034086e-06 Test MSE 2.0567931793498e-06 Test RE 0.00037608886605704504\n",
      "162 Train Loss 4.1023413e-06 Test MSE 2.0567931793498e-06 Test RE 0.00037608886605704504\n",
      "163 Train Loss 4.075191e-06 Test MSE 1.7926780377287262e-06 Test RE 0.00035111251830975525\n",
      "164 Train Loss 3.9930624e-06 Test MSE 1.7926780377287262e-06 Test RE 0.00035111251830975525\n",
      "165 Train Loss 4.0069576e-06 Test MSE 1.7926780377287262e-06 Test RE 0.00035111251830975525\n",
      "166 Train Loss 4.0160007e-06 Test MSE 1.7926780377287262e-06 Test RE 0.00035111251830975525\n",
      "167 Train Loss 3.983748e-06 Test MSE 1.7926780377287262e-06 Test RE 0.00035111251830975525\n",
      "168 Train Loss 4.023738e-06 Test MSE 1.7926780377287262e-06 Test RE 0.00035111251830975525\n",
      "169 Train Loss 4.0069144e-06 Test MSE 1.7926780377287262e-06 Test RE 0.00035111251830975525\n",
      "170 Train Loss 3.980263e-06 Test MSE 1.4236864494723798e-06 Test RE 0.0003128976781845366\n",
      "171 Train Loss 3.9671936e-06 Test MSE 1.4236864494723798e-06 Test RE 0.0003128976781845366\n",
      "172 Train Loss 3.912516e-06 Test MSE 1.4236864494723798e-06 Test RE 0.0003128976781845366\n",
      "173 Train Loss 3.891176e-06 Test MSE 1.4236864494723798e-06 Test RE 0.0003128976781845366\n",
      "174 Train Loss 3.975323e-06 Test MSE 1.4236864494723798e-06 Test RE 0.0003128976781845366\n",
      "175 Train Loss 3.940517e-06 Test MSE 1.4236864494723798e-06 Test RE 0.0003128976781845366\n",
      "176 Train Loss 3.9275023e-06 Test MSE 1.5268063345935438e-06 Test RE 0.0003240314329484921\n",
      "177 Train Loss 3.9750457e-06 Test MSE 1.5268063345935438e-06 Test RE 0.0003240314329484921\n",
      "178 Train Loss 3.9095667e-06 Test MSE 1.5268063345935438e-06 Test RE 0.0003240314329484921\n",
      "179 Train Loss 3.9325314e-06 Test MSE 1.5268063345935438e-06 Test RE 0.0003240314329484921\n",
      "180 Train Loss 3.863796e-06 Test MSE 1.5268063345935438e-06 Test RE 0.0003240314329484921\n",
      "181 Train Loss 3.946366e-06 Test MSE 1.5268063345935438e-06 Test RE 0.0003240314329484921\n",
      "182 Train Loss 3.8860053e-06 Test MSE 1.5268063345935438e-06 Test RE 0.0003240314329484921\n",
      "183 Train Loss 3.9236293e-06 Test MSE 1.5268063345935438e-06 Test RE 0.0003240314329484921\n",
      "184 Train Loss 3.7971447e-06 Test MSE 1.6693436758936195e-06 Test RE 0.0003388192235631057\n",
      "185 Train Loss 3.8413223e-06 Test MSE 1.6693436758936195e-06 Test RE 0.0003388192235631057\n",
      "186 Train Loss 3.8233757e-06 Test MSE 1.6693436758936195e-06 Test RE 0.0003388192235631057\n",
      "187 Train Loss 3.8056362e-06 Test MSE 1.6693436758936195e-06 Test RE 0.0003388192235631057\n",
      "188 Train Loss 3.6840524e-06 Test MSE 3.554470316883287e-06 Test RE 0.0004944047228068192\n",
      "189 Train Loss 3.64028e-06 Test MSE 3.554470316883287e-06 Test RE 0.0004944047228068192\n",
      "190 Train Loss 3.6513995e-06 Test MSE 3.554470316883287e-06 Test RE 0.0004944047228068192\n",
      "191 Train Loss 3.6885187e-06 Test MSE 3.554470316883287e-06 Test RE 0.0004944047228068192\n",
      "192 Train Loss 3.6055417e-06 Test MSE 3.554470316883287e-06 Test RE 0.0004944047228068192\n",
      "193 Train Loss 3.6608358e-06 Test MSE 3.554470316883287e-06 Test RE 0.0004944047228068192\n",
      "194 Train Loss 3.6337678e-06 Test MSE 3.554470316883287e-06 Test RE 0.0004944047228068192\n",
      "195 Train Loss 3.65695e-06 Test MSE 3.554470316883287e-06 Test RE 0.0004944047228068192\n",
      "196 Train Loss 3.638731e-06 Test MSE 3.554470316883287e-06 Test RE 0.0004944047228068192\n",
      "197 Train Loss 3.6575095e-06 Test MSE 3.554470316883287e-06 Test RE 0.0004944047228068192\n",
      "198 Train Loss 3.5770697e-06 Test MSE 1.0725757728274293e-06 Test RE 0.00027158711159771355\n",
      "199 Train Loss 3.605827e-06 Test MSE 1.0725757728274293e-06 Test RE 0.00027158711159771355\n",
      "Training time: 84.50\n",
      "Training time: 84.50\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (m_lambda): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 2.0081522 Test MSE 14.412115931227813 Test RE 0.9955407425799984\n",
      "1 Train Loss 1.7969449 Test MSE 14.643312776037305 Test RE 1.003494124967771\n",
      "2 Train Loss 1.7554814 Test MSE 14.695278665556323 Test RE 1.0052731377695066\n",
      "3 Train Loss 1.647274 Test MSE 15.318430399850296 Test RE 1.0263660985922187\n",
      "4 Train Loss 1.597137 Test MSE 15.809117311734537 Test RE 1.0426750364792332\n",
      "5 Train Loss 1.4927542 Test MSE 15.78087235319973 Test RE 1.0417431856200938\n",
      "6 Train Loss 1.2486899 Test MSE 14.721175962170436 Test RE 1.006158537683783\n",
      "7 Train Loss 0.77239496 Test MSE 14.142669436720185 Test RE 0.9861906031192055\n",
      "8 Train Loss 0.74173194 Test MSE 13.683006865855166 Test RE 0.970031722955987\n",
      "9 Train Loss 0.7382884 Test MSE 13.51165382497752 Test RE 0.963938706991746\n",
      "10 Train Loss 0.7232772 Test MSE 12.997673424026077 Test RE 0.9454269439287456\n",
      "11 Train Loss 0.720175 Test MSE 12.959887308402456 Test RE 0.9440516972912809\n",
      "12 Train Loss 0.7175384 Test MSE 12.829857888804808 Test RE 0.9393038182590301\n",
      "13 Train Loss 0.71002674 Test MSE 12.74666644611691 Test RE 0.936253545798078\n",
      "14 Train Loss 0.70332533 Test MSE 12.409800098018373 Test RE 0.9237991486545545\n",
      "15 Train Loss 0.6759543 Test MSE 11.203110689838004 Test RE 0.877737146195802\n",
      "16 Train Loss 0.60074747 Test MSE 10.29063040532577 Test RE 0.841232717468577\n",
      "17 Train Loss 0.5613568 Test MSE 9.054849183523338 Test RE 0.7891067809410587\n",
      "18 Train Loss 0.4344389 Test MSE 6.177763183828466 Test RE 0.6517946522262361\n",
      "19 Train Loss 0.19688106 Test MSE 3.195025099926655 Test RE 0.46874030896017277\n",
      "20 Train Loss 0.08824089 Test MSE 1.1408065954908633 Test RE 0.28009230428745185\n",
      "21 Train Loss 0.059050463 Test MSE 0.7742136408722246 Test RE 0.23074142704196188\n",
      "22 Train Loss 0.023827482 Test MSE 0.21680769010479878 Test RE 0.12210473516574555\n",
      "23 Train Loss 0.0055215484 Test MSE 0.012653093007639454 Test RE 0.02949806409726462\n",
      "24 Train Loss 0.0024256546 Test MSE 8.629919434180084e-05 Test RE 0.002436119204603414\n",
      "25 Train Loss 0.0014391319 Test MSE 0.0024242429714516735 Test RE 0.012911694368819471\n",
      "26 Train Loss 0.0009747287 Test MSE 0.006629116728803238 Test RE 0.02135123487154059\n",
      "27 Train Loss 0.00029868446 Test MSE 0.0003667466428944504 Test RE 0.005022017692006332\n",
      "28 Train Loss 0.00025952555 Test MSE 0.00011685175560278319 Test RE 0.002834737087015563\n",
      "29 Train Loss 0.00024896185 Test MSE 9.900920135863907e-05 Test RE 0.0026093536484305606\n",
      "30 Train Loss 0.0002509641 Test MSE 8.398463830743227e-05 Test RE 0.002403228650630463\n",
      "31 Train Loss 0.00025022947 Test MSE 8.398463830743227e-05 Test RE 0.002403228650630463\n",
      "32 Train Loss 0.0002468189 Test MSE 7.024873693892635e-05 Test RE 0.0021979328746682585\n",
      "33 Train Loss 0.00024610167 Test MSE 7.024873693892635e-05 Test RE 0.0021979328746682585\n",
      "34 Train Loss 0.0002458783 Test MSE 7.024873693892635e-05 Test RE 0.0021979328746682585\n",
      "35 Train Loss 0.00024395727 Test MSE 8.499107945408925e-05 Test RE 0.002417585472989288\n",
      "36 Train Loss 0.00024515542 Test MSE 8.499107945408925e-05 Test RE 0.002417585472989288\n",
      "37 Train Loss 0.00023731586 Test MSE 0.00016107423344749957 Test RE 0.0033281906899736754\n",
      "38 Train Loss 0.00023468999 Test MSE 0.00016107423344749957 Test RE 0.0033281906899736754\n",
      "39 Train Loss 0.00023572866 Test MSE 0.00016107423344749957 Test RE 0.0033281906899736754\n",
      "40 Train Loss 0.00024045966 Test MSE 0.00016107423344749957 Test RE 0.0033281906899736754\n",
      "41 Train Loss 0.00023722173 Test MSE 0.00040694915965532817 Test RE 0.005290116579628119\n",
      "42 Train Loss 0.0002360428 Test MSE 0.00040694915965532817 Test RE 0.005290116579628119\n",
      "43 Train Loss 0.00023631973 Test MSE 0.00040694915965532817 Test RE 0.005290116579628119\n",
      "44 Train Loss 0.00023030605 Test MSE 0.00019942354099217795 Test RE 0.0037032529416366647\n",
      "45 Train Loss 0.00023135645 Test MSE 0.00019942354099217795 Test RE 0.0037032529416366647\n",
      "46 Train Loss 0.00023384328 Test MSE 0.00019942354099217795 Test RE 0.0037032529416366647\n",
      "47 Train Loss 0.00022263882 Test MSE 8.185105927167397e-05 Test RE 0.002372505986169858\n",
      "48 Train Loss 0.00022272038 Test MSE 8.185105927167397e-05 Test RE 0.002372505986169858\n",
      "49 Train Loss 0.00021928351 Test MSE 8.423172346307028e-05 Test RE 0.002406761237260569\n",
      "50 Train Loss 0.00021993849 Test MSE 8.423172346307028e-05 Test RE 0.002406761237260569\n",
      "51 Train Loss 0.0002179897 Test MSE 8.668067721759892e-05 Test RE 0.002441497661515259\n",
      "52 Train Loss 0.00021686837 Test MSE 8.668067721759892e-05 Test RE 0.002441497661515259\n",
      "53 Train Loss 0.00021248254 Test MSE 7.097167736143774e-05 Test RE 0.002209213556690842\n",
      "54 Train Loss 0.00021521421 Test MSE 7.097167736143774e-05 Test RE 0.002209213556690842\n",
      "55 Train Loss 0.00021429248 Test MSE 7.097167736143774e-05 Test RE 0.002209213556690842\n",
      "56 Train Loss 0.00020951573 Test MSE 5.97957511307435e-05 Test RE 0.002027824321553197\n",
      "57 Train Loss 0.00021006513 Test MSE 5.97957511307435e-05 Test RE 0.002027824321553197\n",
      "58 Train Loss 0.00020653642 Test MSE 5.027524134944806e-05 Test RE 0.001859397517789965\n",
      "59 Train Loss 0.00020611811 Test MSE 5.027524134944806e-05 Test RE 0.001859397517789965\n",
      "60 Train Loss 0.00019543551 Test MSE 0.0001152962240202711 Test RE 0.0028158058504115825\n",
      "61 Train Loss 0.00018968097 Test MSE 2.6411648593514933e-05 Test RE 0.0013476990429945347\n",
      "62 Train Loss 0.0001896009 Test MSE 2.6411648593514933e-05 Test RE 0.0013476990429945347\n",
      "63 Train Loss 7.990741e-05 Test MSE 1.2143704946752194e-05 Test RE 0.0009138412716984211\n",
      "64 Train Loss 7.259851e-05 Test MSE 1.3649877617931848e-05 Test RE 0.0009688566925883745\n",
      "65 Train Loss 6.583188e-05 Test MSE 1.4372799278257052e-05 Test RE 0.0009941818837831942\n",
      "66 Train Loss 6.0538674e-05 Test MSE 1.4811840681407027e-05 Test RE 0.0010092521443472939\n",
      "67 Train Loss 5.629356e-05 Test MSE 1.447580229342894e-05 Test RE 0.000997737938329787\n",
      "68 Train Loss 5.3132833e-05 Test MSE 1.3573239703337525e-05 Test RE 0.000966133017188073\n",
      "69 Train Loss 5.370836e-05 Test MSE 1.3573239703337525e-05 Test RE 0.000966133017188073\n",
      "70 Train Loss 4.982485e-05 Test MSE 1.1196083945990278e-05 Test RE 0.0008774618386641616\n",
      "71 Train Loss 5.0279323e-05 Test MSE 1.1196083945990278e-05 Test RE 0.0008774618386641616\n",
      "72 Train Loss 4.9961232e-05 Test MSE 1.1196083945990278e-05 Test RE 0.0008774618386641616\n",
      "73 Train Loss 4.88428e-05 Test MSE 1.0151291527526816e-05 Test RE 0.0008355180082761079\n",
      "74 Train Loss 4.850044e-05 Test MSE 1.0151291527526816e-05 Test RE 0.0008355180082761079\n",
      "75 Train Loss 4.843569e-05 Test MSE 1.0151291527526816e-05 Test RE 0.0008355180082761079\n",
      "76 Train Loss 4.4299944e-05 Test MSE 7.565192883509135e-06 Test RE 0.0007212821215854033\n",
      "77 Train Loss 4.447885e-05 Test MSE 7.565192883509135e-06 Test RE 0.0007212821215854033\n",
      "78 Train Loss 4.191303e-05 Test MSE 8.160834389785809e-06 Test RE 0.000749139069353784\n",
      "79 Train Loss 4.1716587e-05 Test MSE 8.160834389785809e-06 Test RE 0.000749139069353784\n",
      "80 Train Loss 4.1095464e-05 Test MSE 8.160834389785809e-06 Test RE 0.000749139069353784\n",
      "81 Train Loss 4.156842e-05 Test MSE 8.160834389785809e-06 Test RE 0.000749139069353784\n",
      "82 Train Loss 3.9763785e-05 Test MSE 5.790782348157344e-06 Test RE 0.0006310500213080367\n",
      "83 Train Loss 3.9963044e-05 Test MSE 5.790782348157344e-06 Test RE 0.0006310500213080367\n",
      "84 Train Loss 3.7205617e-05 Test MSE 1.2223471021004305e-06 Test RE 0.00028992952125725136\n",
      "85 Train Loss 3.7654925e-05 Test MSE 1.2223471021004305e-06 Test RE 0.00028992952125725136\n",
      "86 Train Loss 3.665682e-05 Test MSE 8.390677083104966e-07 Test RE 0.00024021142995426815\n",
      "87 Train Loss 3.6746947e-05 Test MSE 8.390677083104966e-07 Test RE 0.00024021142995426815\n",
      "88 Train Loss 3.6629845e-05 Test MSE 8.390677083104966e-07 Test RE 0.00024021142995426815\n",
      "89 Train Loss 3.5691104e-05 Test MSE 2.917092447226177e-07 Test RE 0.0001416348937842295\n",
      "90 Train Loss 3.5726407e-05 Test MSE 2.917092447226177e-07 Test RE 0.0001416348937842295\n",
      "91 Train Loss 3.5915124e-05 Test MSE 2.917092447226177e-07 Test RE 0.0001416348937842295\n",
      "92 Train Loss 3.468961e-05 Test MSE 1.1879358461399454e-06 Test RE 0.00028581937058415346\n",
      "93 Train Loss 3.4711018e-05 Test MSE 1.1879358461399454e-06 Test RE 0.00028581937058415346\n",
      "94 Train Loss 3.469338e-05 Test MSE 1.1879358461399454e-06 Test RE 0.00028581937058415346\n",
      "95 Train Loss 3.4540826e-05 Test MSE 1.1879358461399454e-06 Test RE 0.00028581937058415346\n",
      "96 Train Loss 3.4612283e-05 Test MSE 1.0590235517841307e-06 Test RE 0.00026986587706377517\n",
      "97 Train Loss 3.454555e-05 Test MSE 1.0590235517841307e-06 Test RE 0.00026986587706377517\n",
      "98 Train Loss 3.3953795e-05 Test MSE 5.697340919541412e-08 Test RE 6.259379290282376e-05\n",
      "99 Train Loss 3.412429e-05 Test MSE 5.697340919541412e-08 Test RE 6.259379290282376e-05\n",
      "100 Train Loss 3.407219e-05 Test MSE 3.9859722435861825e-08 Test RE 5.235549859810396e-05\n",
      "101 Train Loss 3.3681896e-05 Test MSE 3.9859722435861825e-08 Test RE 5.235549859810396e-05\n",
      "102 Train Loss 3.4171808e-05 Test MSE 3.9859722435861825e-08 Test RE 5.235549859810396e-05\n",
      "103 Train Loss 3.4009754e-05 Test MSE 3.9859722435861825e-08 Test RE 5.235549859810396e-05\n",
      "104 Train Loss 3.405699e-05 Test MSE 3.9859722435861825e-08 Test RE 5.235549859810396e-05\n",
      "105 Train Loss 3.3998775e-05 Test MSE 1.349454315801675e-07 Test RE 9.633281651793528e-05\n",
      "106 Train Loss 3.4127504e-05 Test MSE 1.349454315801675e-07 Test RE 9.633281651793528e-05\n",
      "107 Train Loss 3.3509357e-05 Test MSE 1.349454315801675e-07 Test RE 9.633281651793528e-05\n",
      "108 Train Loss 3.3750133e-05 Test MSE 1.349454315801675e-07 Test RE 9.633281651793528e-05\n",
      "109 Train Loss 3.3484688e-05 Test MSE 1.349454315801675e-07 Test RE 9.633281651793528e-05\n",
      "110 Train Loss 3.3644134e-05 Test MSE 1.349454315801675e-07 Test RE 9.633281651793528e-05\n",
      "111 Train Loss 3.3072563e-05 Test MSE 8.255258819354679e-08 Test RE 7.534605386157366e-05\n",
      "112 Train Loss 3.3117118e-05 Test MSE 8.255258819354679e-08 Test RE 7.534605386157366e-05\n",
      "113 Train Loss 3.3104097e-05 Test MSE 8.255258819354679e-08 Test RE 7.534605386157366e-05\n",
      "114 Train Loss 3.3094013e-05 Test MSE 8.255258819354679e-08 Test RE 7.534605386157366e-05\n",
      "115 Train Loss 3.249104e-05 Test MSE 4.309990519265287e-06 Test RE 0.0005444190610724525\n",
      "116 Train Loss 3.249263e-05 Test MSE 4.309990519265287e-06 Test RE 0.0005444190610724525\n",
      "117 Train Loss 3.2090695e-05 Test MSE 2.1404252559217095e-07 Test RE 0.00012132357476357861\n",
      "118 Train Loss 3.2080257e-05 Test MSE 2.1404252559217095e-07 Test RE 0.00012132357476357861\n",
      "119 Train Loss 3.1959466e-05 Test MSE 2.1404252559217095e-07 Test RE 0.00012132357476357861\n",
      "120 Train Loss 3.1711046e-05 Test MSE 4.945665050283313e-07 Test RE 0.00018441978645658606\n",
      "121 Train Loss 3.1980224e-05 Test MSE 4.945665050283313e-07 Test RE 0.00018441978645658606\n",
      "122 Train Loss 3.167226e-05 Test MSE 4.945665050283313e-07 Test RE 0.00018441978645658606\n",
      "123 Train Loss 3.1895153e-05 Test MSE 4.945665050283313e-07 Test RE 0.00018441978645658606\n",
      "124 Train Loss 3.179743e-05 Test MSE 4.945665050283313e-07 Test RE 0.00018441978645658606\n",
      "125 Train Loss 3.185865e-05 Test MSE 4.945665050283313e-07 Test RE 0.00018441978645658606\n",
      "126 Train Loss 3.1448842e-05 Test MSE 4.4842845461637037e-07 Test RE 0.00017560696863239266\n",
      "127 Train Loss 3.1393283e-05 Test MSE 4.4842845461637037e-07 Test RE 0.00017560696863239266\n",
      "128 Train Loss 3.1322867e-05 Test MSE 4.4842845461637037e-07 Test RE 0.00017560696863239266\n",
      "129 Train Loss 3.1435004e-05 Test MSE 4.4842845461637037e-07 Test RE 0.00017560696863239266\n",
      "130 Train Loss 3.1470383e-05 Test MSE 4.4842845461637037e-07 Test RE 0.00017560696863239266\n",
      "131 Train Loss 3.1565214e-05 Test MSE 4.4842845461637037e-07 Test RE 0.00017560696863239266\n",
      "132 Train Loss 3.1564283e-05 Test MSE 4.4842845461637037e-07 Test RE 0.00017560696863239266\n",
      "133 Train Loss 3.1221185e-05 Test MSE 1.3960169999095004e-06 Test RE 0.00030984216475788074\n",
      "134 Train Loss 3.08386e-05 Test MSE 1.3960169999095004e-06 Test RE 0.00030984216475788074\n",
      "135 Train Loss 3.105344e-05 Test MSE 1.3960169999095004e-06 Test RE 0.00030984216475788074\n",
      "136 Train Loss 3.0693882e-05 Test MSE 6.792013988463036e-08 Test RE 6.83430648135723e-05\n",
      "137 Train Loss 3.0939533e-05 Test MSE 6.792013988463036e-08 Test RE 6.83430648135723e-05\n",
      "138 Train Loss 2.9887195e-05 Test MSE 6.113667546063379e-08 Test RE 6.484045804186099e-05\n",
      "139 Train Loss 2.9662262e-05 Test MSE 6.113667546063379e-08 Test RE 6.484045804186099e-05\n",
      "140 Train Loss 2.9674713e-05 Test MSE 6.113667546063379e-08 Test RE 6.484045804186099e-05\n",
      "141 Train Loss 2.9092587e-05 Test MSE 5.92033387243742e-07 Test RE 0.00020177542202964188\n",
      "142 Train Loss 2.917127e-05 Test MSE 5.92033387243742e-07 Test RE 0.00020177542202964188\n",
      "143 Train Loss 2.7651251e-05 Test MSE 2.1254189941890674e-07 Test RE 0.00012089753429051\n",
      "144 Train Loss 2.7573007e-05 Test MSE 2.1254189941890674e-07 Test RE 0.00012089753429051\n",
      "145 Train Loss 2.7722737e-05 Test MSE 2.1254189941890674e-07 Test RE 0.00012089753429051\n",
      "146 Train Loss 2.7633509e-05 Test MSE 2.1254189941890674e-07 Test RE 0.00012089753429051\n",
      "147 Train Loss 2.7712455e-05 Test MSE 2.1254189941890674e-07 Test RE 0.00012089753429051\n",
      "148 Train Loss 2.7851493e-05 Test MSE 2.1254189941890674e-07 Test RE 0.00012089753429051\n",
      "149 Train Loss 2.6188782e-05 Test MSE 3.086669421939722e-07 Test RE 0.00014569351613984266\n",
      "150 Train Loss 2.612822e-05 Test MSE 3.086669421939722e-07 Test RE 0.00014569351613984266\n",
      "151 Train Loss 2.3423361e-05 Test MSE 6.576783676095503e-07 Test RE 0.0002126679003885146\n",
      "152 Train Loss 2.3398818e-05 Test MSE 6.576783676095503e-07 Test RE 0.0002126679003885146\n",
      "153 Train Loss 2.0163772e-05 Test MSE 1.3432228028652564e-07 Test RE 9.611013620718034e-05\n",
      "154 Train Loss 2.0451935e-05 Test MSE 1.3432228028652564e-07 Test RE 9.611013620718034e-05\n",
      "155 Train Loss 1.3622971e-05 Test MSE 9.32499260077264e-07 Test RE 0.0002532324826322051\n",
      "156 Train Loss 1.3593655e-05 Test MSE 9.32499260077264e-07 Test RE 0.0002532324826322051\n",
      "157 Train Loss 1.2298692e-05 Test MSE 1.0663347230030013e-05 Test RE 0.0008563315408308663\n",
      "158 Train Loss 1.2288499e-05 Test MSE 1.0663347230030013e-05 Test RE 0.0008563315408308663\n",
      "159 Train Loss 1.0149097e-05 Test MSE 5.503255696600192e-07 Test RE 0.00019453825264688718\n",
      "160 Train Loss 1.0106919e-05 Test MSE 5.503255696600192e-07 Test RE 0.00019453825264688718\n",
      "161 Train Loss 1.0148879e-05 Test MSE 5.503255696600192e-07 Test RE 0.00019453825264688718\n",
      "162 Train Loss 1.0200628e-05 Test MSE 5.503255696600192e-07 Test RE 0.00019453825264688718\n",
      "163 Train Loss 7.740385e-06 Test MSE 8.553309030416197e-07 Test RE 0.000242528201641239\n",
      "164 Train Loss 7.787801e-06 Test MSE 8.553309030416197e-07 Test RE 0.000242528201641239\n",
      "165 Train Loss 5.0760414e-06 Test MSE 8.026993358689309e-06 Test RE 0.0007429705793601184\n",
      "166 Train Loss 5.1220163e-06 Test MSE 8.026993358689309e-06 Test RE 0.0007429705793601184\n",
      "167 Train Loss 5.137238e-06 Test MSE 8.026993358689309e-06 Test RE 0.0007429705793601184\n",
      "168 Train Loss 3.2242633e-06 Test MSE 1.5782264708142908e-07 Test RE 0.00010417891413901201\n",
      "169 Train Loss 3.2556354e-06 Test MSE 1.5782264708142908e-07 Test RE 0.00010417891413901201\n",
      "170 Train Loss 3.2450396e-06 Test MSE 1.5782264708142908e-07 Test RE 0.00010417891413901201\n",
      "171 Train Loss 3.2617975e-06 Test MSE 1.5782264708142908e-07 Test RE 0.00010417891413901201\n",
      "172 Train Loss 2.951146e-06 Test MSE 5.0460779425970275e-06 Test RE 0.0005890771025289465\n",
      "173 Train Loss 2.9434482e-06 Test MSE 5.0460779425970275e-06 Test RE 0.0005890771025289465\n",
      "174 Train Loss 2.415273e-06 Test MSE 2.8295510313896596e-06 Test RE 0.0004411171372002547\n",
      "175 Train Loss 2.3881348e-06 Test MSE 2.8295510313896596e-06 Test RE 0.0004411171372002547\n",
      "176 Train Loss 2.4047604e-06 Test MSE 2.8295510313896596e-06 Test RE 0.0004411171372002547\n",
      "177 Train Loss 2.3958967e-06 Test MSE 2.8295510313896596e-06 Test RE 0.0004411171372002547\n",
      "178 Train Loss 2.1153921e-06 Test MSE 4.175487493019497e-06 Test RE 0.000535856814948246\n",
      "179 Train Loss 2.1092342e-06 Test MSE 4.175487493019497e-06 Test RE 0.000535856814948246\n",
      "180 Train Loss 2.1130588e-06 Test MSE 4.175487493019497e-06 Test RE 0.000535856814948246\n",
      "181 Train Loss 2.1373476e-06 Test MSE 4.175487493019497e-06 Test RE 0.000535856814948246\n",
      "182 Train Loss 1.6977665e-06 Test MSE 3.493208169697368e-07 Test RE 0.00015499132763377747\n",
      "183 Train Loss 1.7036308e-06 Test MSE 3.493208169697368e-07 Test RE 0.00015499132763377747\n",
      "184 Train Loss 1.7208614e-06 Test MSE 3.493208169697368e-07 Test RE 0.00015499132763377747\n",
      "185 Train Loss 1.6893067e-06 Test MSE 3.493208169697368e-07 Test RE 0.00015499132763377747\n",
      "186 Train Loss 1.7116477e-06 Test MSE 3.493208169697368e-07 Test RE 0.00015499132763377747\n",
      "187 Train Loss 1.571196e-06 Test MSE 9.490992184283769e-07 Test RE 0.0002554765087854913\n",
      "188 Train Loss 1.5599992e-06 Test MSE 9.490992184283769e-07 Test RE 0.0002554765087854913\n",
      "189 Train Loss 1.5725741e-06 Test MSE 9.490992184283769e-07 Test RE 0.0002554765087854913\n",
      "190 Train Loss 1.5830043e-06 Test MSE 9.490992184283769e-07 Test RE 0.0002554765087854913\n",
      "191 Train Loss 1.5213957e-06 Test MSE 1.6428736044103395e-06 Test RE 0.0003361222335456616\n",
      "192 Train Loss 1.5068283e-06 Test MSE 1.6428736044103395e-06 Test RE 0.0003361222335456616\n",
      "193 Train Loss 1.5194188e-06 Test MSE 1.6428736044103395e-06 Test RE 0.0003361222335456616\n",
      "194 Train Loss 1.5110677e-06 Test MSE 1.6428736044103395e-06 Test RE 0.0003361222335456616\n",
      "195 Train Loss 1.401295e-06 Test MSE 6.339540605199203e-07 Test RE 0.00020879690591694278\n",
      "196 Train Loss 1.4033138e-06 Test MSE 6.339540605199203e-07 Test RE 0.00020879690591694278\n",
      "197 Train Loss 1.4025799e-06 Test MSE 6.339540605199203e-07 Test RE 0.00020879690591694278\n",
      "198 Train Loss 1.1678309e-06 Test MSE 1.0168855312393288e-06 Test RE 0.00026444246622985923\n",
      "199 Train Loss 1.1613624e-06 Test MSE 1.0168855312393288e-06 Test RE 0.00026444246622985923\n",
      "Training time: 82.85\n",
      "Training time: 82.85\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    \n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "    \n",
    "    \n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "    \n",
    "    optimizer_lambda = torch.optim.Adam(PINN.parameters(), lr=5e-3)\n",
    "   \n",
    "\n",
    "    start_time = time.time()\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    " \n",
    "    \n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"label\": label, \"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f69180a2cd0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.plot(u_pred,'r')\n",
    "plt.plot(y_true,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016354511987769397\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
