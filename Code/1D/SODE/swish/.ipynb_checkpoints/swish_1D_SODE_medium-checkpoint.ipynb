{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(2.0*x) + np.exp(-3.0*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"medium\"\n",
    "label = \"1D_SODE_swish_\"+level\n",
    "\n",
    "u_coeff = 6.0\n",
    "fo_val = -1.0\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((layers[1],len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0  #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "    \n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,0)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 4.889628 Test MSE 383.4197442001389 Test RE 0.998159211688084\n",
      "1 Train Loss 4.8892508 Test MSE 383.34710386578075 Test RE 0.9980646546726124\n",
      "2 Train Loss 4.8873396 Test MSE 383.184304628823 Test RE 0.9978527039142536\n",
      "3 Train Loss 4.626774 Test MSE 384.85218844270537 Test RE 1.0000220193516098\n",
      "4 Train Loss 4.3771553 Test MSE 387.28908502366704 Test RE 1.0031831092015744\n",
      "5 Train Loss 3.1975408 Test MSE 387.62626787959545 Test RE 1.0036197114290557\n",
      "6 Train Loss 2.3868103 Test MSE 383.4340714165295 Test RE 0.9981778605835077\n",
      "7 Train Loss 2.3816729 Test MSE 383.27511639928883 Test RE 0.9979709386662728\n",
      "8 Train Loss 2.3801684 Test MSE 383.47253423803556 Test RE 0.998227923654301\n",
      "9 Train Loss 2.3801477 Test MSE 383.4879108635978 Test RE 0.9982479371125922\n",
      "10 Train Loss 2.3801455 Test MSE 383.48974254178705 Test RE 0.9982503211079397\n",
      "11 Train Loss 2.3801398 Test MSE 383.49387467732265 Test RE 0.9982556992107363\n",
      "12 Train Loss 2.3801365 Test MSE 383.4968171450858 Test RE 0.9982595289062984\n",
      "13 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "14 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "15 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "16 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "17 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "18 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "19 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "20 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "21 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "22 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "23 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "24 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "25 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "26 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "27 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "28 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "29 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "30 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "31 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "32 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "33 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "34 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "35 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "36 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "37 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "38 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "39 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "40 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "41 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "42 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "43 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "44 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "45 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "46 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "47 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "48 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "49 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "50 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "51 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "52 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "53 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "54 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "55 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "56 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "57 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "58 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "59 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "60 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "61 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "62 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "63 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "64 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "65 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "66 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "67 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "68 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "69 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "70 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "71 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "72 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "73 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "74 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "75 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "76 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "77 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "78 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "79 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "80 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "81 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "82 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "83 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "84 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "85 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "86 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "87 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "88 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "89 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "90 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "91 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "92 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "93 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "94 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "95 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "96 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "97 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "98 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "99 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "100 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "101 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "102 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "103 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "104 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "105 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "106 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "107 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "108 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "109 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "110 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "111 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "112 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "113 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "114 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "115 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "116 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "117 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "118 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "119 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "120 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "121 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "122 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "123 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "124 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "125 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "126 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "127 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "128 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "129 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "130 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "131 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "132 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "133 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "134 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "135 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "136 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "137 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "138 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "139 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "140 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "141 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "142 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "143 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "144 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "145 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "146 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "147 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "148 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "149 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "150 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "151 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "152 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "153 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "154 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "155 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "156 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "157 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "158 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "159 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "160 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "161 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "162 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "163 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "164 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "165 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "166 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "167 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "168 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "169 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "170 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "171 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "172 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "173 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "174 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "175 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "176 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "177 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "178 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "179 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "180 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "181 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "182 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "183 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "184 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "185 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "186 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "187 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "188 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "189 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "190 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "191 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "192 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "193 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "194 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "195 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "196 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "197 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "198 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "199 Train Loss 2.3801343 Test MSE 383.4990305159666 Test RE 0.9982624096543072\n",
      "Training time: 13.18\n",
      "Training time: 13.18\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 4.8885775 Test MSE 383.4167102283339 Test RE 0.9981552625006181\n",
      "1 Train Loss 4.887718 Test MSE 383.3034653828085 Test RE 0.998007845495541\n",
      "2 Train Loss 4.733595 Test MSE 382.57669057785114 Test RE 0.9970612442135488\n",
      "3 Train Loss 4.166971 Test MSE 387.18132308740996 Test RE 1.0030435332627492\n",
      "4 Train Loss 3.3239064 Test MSE 389.40500040805347 Test RE 1.0059197719767425\n",
      "5 Train Loss 2.387146 Test MSE 384.19560763947595 Test RE 0.9991686065774861\n",
      "6 Train Loss 2.384014 Test MSE 383.9492870728096 Test RE 0.9988482551297162\n",
      "7 Train Loss 2.3807795 Test MSE 383.72375776878863 Test RE 0.9985548535665766\n",
      "8 Train Loss 2.3807266 Test MSE 383.7373277119979 Test RE 0.9985725097744397\n",
      "9 Train Loss 2.3807194 Test MSE 383.739901316587 Test RE 0.9985758583234329\n",
      "10 Train Loss 2.3807175 Test MSE 383.7404077997028 Test RE 0.9985765173136025\n",
      "11 Train Loss 2.3806944 Test MSE 383.74561656367115 Test RE 0.9985832944624602\n",
      "12 Train Loss 2.3806903 Test MSE 383.7457160103316 Test RE 0.99858342385256\n",
      "13 Train Loss 2.3803327 Test MSE 383.5914224618917 Test RE 0.9983826522688161\n",
      "14 Train Loss 2.379996 Test MSE 383.44822365481224 Test RE 0.9981962813781607\n",
      "15 Train Loss 2.3798687 Test MSE 383.2086879718696 Test RE 0.9978844518191673\n",
      "16 Train Loss 2.3759432 Test MSE 379.14670288531596 Test RE 0.9925816095105013\n",
      "17 Train Loss 2.3450253 Test MSE 377.19894747062926 Test RE 0.9900287776687335\n",
      "18 Train Loss 2.2438452 Test MSE 354.6230306011671 Test RE 0.959944337193316\n",
      "19 Train Loss 2.1444879 Test MSE 338.14677273019004 Test RE 0.9373789700579509\n",
      "20 Train Loss 2.0133145 Test MSE 314.30872982227237 Test RE 0.9037343804668206\n",
      "21 Train Loss 1.7917995 Test MSE 262.0787640723313 Test RE 0.8252366331552003\n",
      "22 Train Loss 1.652709 Test MSE 237.00794040604964 Test RE 0.7847729600369577\n",
      "23 Train Loss 1.572789 Test MSE 222.8819168562096 Test RE 0.7610268852362894\n",
      "24 Train Loss 1.4509401 Test MSE 179.93957491616106 Test RE 0.6837950106536052\n",
      "25 Train Loss 1.2742817 Test MSE 131.84732858176883 Test RE 0.5853265851331653\n",
      "26 Train Loss 1.2132555 Test MSE 116.2481234258372 Test RE 0.5496111794403694\n",
      "27 Train Loss 1.1860237 Test MSE 103.01059361819192 Test RE 0.5173727223136615\n",
      "28 Train Loss 1.1524478 Test MSE 89.64507368235849 Test RE 0.48264276105938386\n",
      "29 Train Loss 1.1012732 Test MSE 71.77986266335449 Test RE 0.43188079690492504\n",
      "30 Train Loss 1.0582775 Test MSE 51.509017657318594 Test RE 0.3658509745451545\n",
      "31 Train Loss 1.0475767 Test MSE 40.190263316816214 Test RE 0.3231640247812436\n",
      "32 Train Loss 1.0345808 Test MSE 24.41694347954586 Test RE 0.25188843695083446\n",
      "33 Train Loss 0.773872 Test MSE 3.059354864218892 Test RE 0.08916152954182069\n",
      "34 Train Loss 0.6730061 Test MSE 13.886464538915309 Test RE 0.18995836691198795\n",
      "35 Train Loss 0.57161766 Test MSE 2.5229625981587898 Test RE 0.0809688532922258\n",
      "36 Train Loss 0.5269666 Test MSE 0.19249661878687405 Test RE 0.022365269475434272\n",
      "37 Train Loss 0.5237187 Test MSE 0.037945492402360254 Test RE 0.009929849790773644\n",
      "38 Train Loss 0.5200149 Test MSE 0.08232497445166395 Test RE 0.014626094827860283\n",
      "39 Train Loss 0.4965419 Test MSE 2.112522343717309 Test RE 0.07409062154287388\n",
      "40 Train Loss 0.40980002 Test MSE 3.7165819889558396 Test RE 0.09827305146479005\n",
      "41 Train Loss 0.34615064 Test MSE 0.8254174351008373 Test RE 0.04631262543643809\n",
      "42 Train Loss 0.30375275 Test MSE 1.507446693156889 Test RE 0.0625869177614636\n",
      "43 Train Loss 0.2748388 Test MSE 1.6685150501490968 Test RE 0.06584573452968905\n",
      "44 Train Loss 0.23987724 Test MSE 0.04184622717869421 Test RE 0.010427753028448344\n",
      "45 Train Loss 0.22556347 Test MSE 0.4446189519338423 Test RE 0.03399042288736894\n",
      "46 Train Loss 0.21681781 Test MSE 0.5066727209888947 Test RE 0.03628493453674627\n",
      "47 Train Loss 0.20934695 Test MSE 0.21559070810024406 Test RE 0.02366887423355872\n",
      "48 Train Loss 0.20359878 Test MSE 0.115037055990187 Test RE 0.017289461302348458\n",
      "49 Train Loss 0.20116256 Test MSE 0.3757271597474622 Test RE 0.03124632008240826\n",
      "50 Train Loss 0.19837902 Test MSE 0.7172015726648191 Test RE 0.043170114360332044\n",
      "51 Train Loss 0.1973692 Test MSE 1.0809607204439744 Test RE 0.052998983372079686\n",
      "52 Train Loss 0.19631556 Test MSE 1.5773454880601308 Test RE 0.06402152228379754\n",
      "53 Train Loss 0.18633483 Test MSE 0.8099118204843292 Test RE 0.04587556766409781\n",
      "54 Train Loss 0.17686962 Test MSE 0.3255056912713304 Test RE 0.029083178961235207\n",
      "55 Train Loss 0.16001886 Test MSE 0.4058494530186414 Test RE 0.03247469381260055\n",
      "56 Train Loss 0.1483416 Test MSE 0.004969044133548638 Test RE 0.0035933457725515127\n",
      "57 Train Loss 0.14056028 Test MSE 0.05758041623939196 Test RE 0.01223207069839264\n",
      "58 Train Loss 0.12578902 Test MSE 0.021448690096032376 Test RE 0.007465569961432707\n",
      "59 Train Loss 0.10675778 Test MSE 0.009841370096221724 Test RE 0.005056969853671407\n",
      "60 Train Loss 0.09285965 Test MSE 0.20310310419035144 Test RE 0.02297316665424191\n",
      "61 Train Loss 0.078232795 Test MSE 0.1348009677316126 Test RE 0.018715829818211446\n",
      "62 Train Loss 0.07486952 Test MSE 0.3705547979371455 Test RE 0.03103050210510767\n",
      "63 Train Loss 0.07110794 Test MSE 0.05013610240439058 Test RE 0.01141399996562933\n",
      "64 Train Loss 0.069747545 Test MSE 6.64402338488435e-05 Test RE 0.00041550682206402607\n",
      "65 Train Loss 0.06327814 Test MSE 0.037567394117722225 Test RE 0.009880254194398797\n",
      "66 Train Loss 0.057914436 Test MSE 0.2097797259244457 Test RE 0.023347712635905904\n",
      "67 Train Loss 0.056541912 Test MSE 0.04947152144585632 Test RE 0.01133809824780011\n",
      "68 Train Loss 0.053841345 Test MSE 0.013406605611354826 Test RE 0.005902309778370091\n",
      "69 Train Loss 0.049935255 Test MSE 0.027245732958517774 Test RE 0.008414180619332681\n",
      "70 Train Loss 0.046560653 Test MSE 0.000472690749849351 Test RE 0.0011082841808069102\n",
      "71 Train Loss 0.043449324 Test MSE 0.006360683509032758 Test RE 0.00406550477894483\n",
      "72 Train Loss 0.04049455 Test MSE 0.0026991816333199925 Test RE 0.0026483698652370515\n",
      "73 Train Loss 0.037667606 Test MSE 0.005270498768558721 Test RE 0.00370073886112253\n",
      "74 Train Loss 0.03650486 Test MSE 0.0029810368716041615 Test RE 0.0027832117959686363\n",
      "75 Train Loss 0.035632454 Test MSE 0.0050718958270252025 Test RE 0.003630343712455687\n",
      "76 Train Loss 0.034170154 Test MSE 0.021192723746595622 Test RE 0.007420889606182985\n",
      "77 Train Loss 0.033198792 Test MSE 0.02738635594952855 Test RE 0.008435866665207655\n",
      "78 Train Loss 0.032741833 Test MSE 0.009170384731479651 Test RE 0.004881534473825136\n",
      "79 Train Loss 0.031678412 Test MSE 0.00464839742436874 Test RE 0.003475475316936933\n",
      "80 Train Loss 0.031243278 Test MSE 0.012125208854322412 Test RE 0.005613157089322241\n",
      "81 Train Loss 0.030835463 Test MSE 0.012397453915048262 Test RE 0.005675822872555237\n",
      "82 Train Loss 0.03043166 Test MSE 0.01912346837955353 Test RE 0.007049298703992427\n",
      "83 Train Loss 0.030160874 Test MSE 0.02305947611697422 Test RE 0.007740825917062086\n",
      "84 Train Loss 0.029877005 Test MSE 0.011416473651030833 Test RE 0.005446638754327354\n",
      "85 Train Loss 0.029779937 Test MSE 0.006614528359275073 Test RE 0.004145835098365163\n",
      "86 Train Loss 0.029761212 Test MSE 0.005976776492533958 Test RE 0.003940906128233993\n",
      "87 Train Loss 0.029758556 Test MSE 0.005956589027573419 Test RE 0.003934244996013862\n",
      "88 Train Loss 0.02972336 Test MSE 0.006899738979084192 Test RE 0.004234273565668206\n",
      "89 Train Loss 0.029687315 Test MSE 0.008683423995159431 Test RE 0.004750158336856603\n",
      "90 Train Loss 0.029662993 Test MSE 0.01040017104505367 Test RE 0.005198557159210146\n",
      "91 Train Loss 0.029591896 Test MSE 0.014969390773742076 Test RE 0.0062368406117366765\n",
      "92 Train Loss 0.029583622 Test MSE 0.015283629948787656 Test RE 0.0063019628614854085\n",
      "93 Train Loss 0.029581511 Test MSE 0.01543246105890637 Test RE 0.006332572599147596\n",
      "94 Train Loss 0.029535657 Test MSE 0.020495940189964302 Test RE 0.007297876423076576\n",
      "95 Train Loss 0.029488197 Test MSE 0.020217424954891518 Test RE 0.007248122127527782\n",
      "96 Train Loss 0.029457726 Test MSE 0.018126721267876508 Test RE 0.0068631297724459335\n",
      "97 Train Loss 0.02919273 Test MSE 0.005638712903731853 Test RE 0.003827829402245981\n",
      "98 Train Loss 0.029123025 Test MSE 0.007024425879220112 Test RE 0.0042723615673488985\n",
      "99 Train Loss 0.029093588 Test MSE 0.00892239232456318 Test RE 0.004815077042321323\n",
      "100 Train Loss 0.028683038 Test MSE 0.016660103461387413 Test RE 0.0065796293556386765\n",
      "101 Train Loss 0.0279076 Test MSE 0.01230051116113791 Test RE 0.0056535880745801625\n",
      "102 Train Loss 0.02683497 Test MSE 0.001980370945123411 Test RE 0.0022684847054747627\n",
      "103 Train Loss 0.025959263 Test MSE 0.007140563007853298 Test RE 0.004307534955068158\n",
      "104 Train Loss 0.02570987 Test MSE 0.023631034447978826 Test RE 0.007836171805098126\n",
      "105 Train Loss 0.025597382 Test MSE 0.028902591192057025 Test RE 0.008666245198590617\n",
      "106 Train Loss 0.025573624 Test MSE 0.03028779550016492 Test RE 0.008871486881686192\n",
      "107 Train Loss 0.025556143 Test MSE 0.033405737283613256 Test RE 0.009316936020413306\n",
      "108 Train Loss 0.025535826 Test MSE 0.034856398867064216 Test RE 0.00951708264887099\n",
      "109 Train Loss 0.02552823 Test MSE 0.035001386486651624 Test RE 0.009536855592648323\n",
      "110 Train Loss 0.025523677 Test MSE 0.03551029905095811 Test RE 0.009605937296015239\n",
      "111 Train Loss 0.025521148 Test MSE 0.03576460710078823 Test RE 0.009640272533548617\n",
      "112 Train Loss 0.025519203 Test MSE 0.03600987742248294 Test RE 0.009673272095753983\n",
      "113 Train Loss 0.0255166 Test MSE 0.03612459442801135 Test RE 0.009688667960809328\n",
      "114 Train Loss 0.025496481 Test MSE 0.038056629550192615 Test RE 0.00994438074346905\n",
      "115 Train Loss 0.025472045 Test MSE 0.04028478330084478 Test RE 0.010231353697015536\n",
      "116 Train Loss 0.025208797 Test MSE 0.06148173892526163 Test RE 0.012639667622884213\n",
      "117 Train Loss 0.023856513 Test MSE 0.02931239569509285 Test RE 0.008727467492670464\n",
      "118 Train Loss 0.020303592 Test MSE 0.055689892565154865 Test RE 0.01202958852823724\n",
      "119 Train Loss 0.014870674 Test MSE 0.04948614318612558 Test RE 0.011339773660998032\n",
      "120 Train Loss 0.009065397 Test MSE 0.05690253880724134 Test RE 0.012159855227375733\n",
      "121 Train Loss 0.0067611462 Test MSE 0.01078063670394943 Test RE 0.005292791523911853\n",
      "122 Train Loss 0.006291304 Test MSE 0.01219037321440017 Test RE 0.005628220238400376\n",
      "123 Train Loss 0.005670909 Test MSE 0.009075738224313283 Test RE 0.004856278254620334\n",
      "124 Train Loss 0.0051029017 Test MSE 0.005853253387300751 Test RE 0.0038999698096756053\n",
      "125 Train Loss 0.0042444104 Test MSE 0.005118536906434301 Test RE 0.0036469978060622004\n",
      "126 Train Loss 0.0034551239 Test MSE 0.004063846661396291 Test RE 0.0032496099725093514\n",
      "127 Train Loss 0.0026040762 Test MSE 0.002861544271284683 Test RE 0.0027268598482508184\n",
      "128 Train Loss 0.0021093725 Test MSE 0.0011553256098133591 Test RE 0.0017326657181650793\n",
      "129 Train Loss 0.001774547 Test MSE 0.000720389697583341 Test RE 0.0013681897394380055\n",
      "130 Train Loss 0.0015797724 Test MSE 0.0031330231289594074 Test RE 0.002853279939540274\n",
      "131 Train Loss 0.0014388347 Test MSE 0.0016934812180050703 Test RE 0.002097745386837265\n",
      "132 Train Loss 0.0013187754 Test MSE 0.0013368651203096579 Test RE 0.001863830347295428\n",
      "133 Train Loss 0.0011848571 Test MSE 0.00038893599605863756 Test RE 0.0010053138181651264\n",
      "134 Train Loss 0.0011774353 Test MSE 0.00030815062750862794 Test RE 0.0008948373659657905\n",
      "135 Train Loss 0.0010601799 Test MSE 6.650270466245452e-07 Test RE 4.1570211751252475e-05\n",
      "136 Train Loss 0.0010327417 Test MSE 3.2394617385051206e-07 Test RE 2.9013425679659394e-05\n",
      "137 Train Loss 0.0009609215 Test MSE 4.5309153878582595e-05 Test RE 0.000343127525693854\n",
      "138 Train Loss 0.0009323915 Test MSE 9.35035938997536e-05 Test RE 0.0004929203343435173\n",
      "139 Train Loss 0.00091510796 Test MSE 0.00013443686850995507 Test RE 0.0005910466721272671\n",
      "140 Train Loss 0.0008850476 Test MSE 0.0006387499686553081 Test RE 0.0012883326952705448\n",
      "141 Train Loss 0.00086405076 Test MSE 0.0008097500244473246 Test RE 0.001450567916071216\n",
      "142 Train Loss 0.00080677547 Test MSE 0.001746058145335092 Test RE 0.002130060473900388\n",
      "143 Train Loss 0.00078601035 Test MSE 0.0016114346459055065 Test RE 0.0020462982408892285\n",
      "144 Train Loss 0.0007660679 Test MSE 0.0014155751151192781 Test RE 0.0019179136153520814\n",
      "145 Train Loss 0.0007614253 Test MSE 0.0013346928721690748 Test RE 0.0018623154794347515\n",
      "146 Train Loss 0.0007536106 Test MSE 0.0010572019360399812 Test RE 0.0016574542798479335\n",
      "147 Train Loss 0.000748255 Test MSE 0.0009168423464812628 Test RE 0.0015435116597884925\n",
      "148 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "149 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "150 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "151 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "152 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "153 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "154 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "155 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "156 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "157 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "158 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "159 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "160 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "161 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "162 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "163 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "164 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "165 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "166 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "167 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "168 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "169 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "170 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "171 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "172 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "173 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "174 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "175 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "176 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "177 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "178 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "179 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "180 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "181 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "182 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "183 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "184 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "185 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "186 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "187 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "188 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "189 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "190 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "191 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "192 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "193 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "194 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "195 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "196 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "197 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "198 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "199 Train Loss 0.00074503606 Test MSE 0.000695878885890005 Test RE 0.001344712408103597\n",
      "Training time: 70.25\n",
      "Training time: 70.25\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 4.892319 Test MSE 383.38841196505194 Test RE 0.9981184271451695\n",
      "1 Train Loss 4.8919225 Test MSE 383.3102974824719 Test RE 0.9980167398303149\n",
      "2 Train Loss 4.8881373 Test MSE 383.09403153459886 Test RE 0.9977351566190411\n",
      "3 Train Loss 4.510557 Test MSE 384.3386053185517 Test RE 0.9993545346522746\n",
      "4 Train Loss 4.0175753 Test MSE 387.37902554865605 Test RE 1.003299587539376\n",
      "5 Train Loss 2.6378195 Test MSE 381.53894366380075 Test RE 0.9957080516808157\n",
      "6 Train Loss 2.4558938 Test MSE 382.27891164807704 Test RE 0.9966731368956252\n",
      "7 Train Loss 2.3835182 Test MSE 383.61922400170516 Test RE 0.9984188314825851\n",
      "8 Train Loss 2.3812134 Test MSE 383.7879355843885 Test RE 0.9986383542472452\n",
      "9 Train Loss 2.381149 Test MSE 383.8162283316826 Test RE 0.9986751632493933\n",
      "10 Train Loss 2.3811452 Test MSE 383.81879348384115 Test RE 0.9986785004577774\n",
      "11 Train Loss 2.3811429 Test MSE 383.81995700576044 Test RE 0.9986800141713643\n",
      "12 Train Loss 2.3811362 Test MSE 383.8240754587971 Test RE 0.9986853721596979\n",
      "13 Train Loss 2.381131 Test MSE 383.82739051247535 Test RE 0.9986896849278116\n",
      "14 Train Loss 2.3811262 Test MSE 383.83023269109634 Test RE 0.9986933824872969\n",
      "15 Train Loss 2.3811214 Test MSE 383.832783617307 Test RE 0.9986967011275133\n",
      "16 Train Loss 2.381119 Test MSE 383.8334063977486 Test RE 0.9986975113351697\n",
      "17 Train Loss 2.380679 Test MSE 383.7052374186259 Test RE 0.9985307557509955\n",
      "18 Train Loss 2.3802776 Test MSE 383.4811019321192 Test RE 0.9982390749923261\n",
      "19 Train Loss 2.3802755 Test MSE 383.47913126088713 Test RE 0.9982365100633827\n",
      "20 Train Loss 2.3802695 Test MSE 383.4632311963333 Test RE 0.9982158150787233\n",
      "21 Train Loss 2.3802538 Test MSE 383.43368048157913 Test RE 0.9981773517310858\n",
      "22 Train Loss 2.3802452 Test MSE 383.4179143880582 Test RE 0.9981568299041638\n",
      "23 Train Loss 2.3798637 Test MSE 382.5071020890617 Test RE 0.9969705602508984\n",
      "24 Train Loss 2.3712451 Test MSE 379.25327664422497 Test RE 0.9927211013216967\n",
      "25 Train Loss 2.310603 Test MSE 370.08923655016406 Test RE 0.9806540128013175\n",
      "26 Train Loss 2.1475308 Test MSE 339.4971135694903 Test RE 0.9392487497586838\n",
      "27 Train Loss 2.122266 Test MSE 333.6063699495729 Test RE 0.9310644609742188\n",
      "28 Train Loss 1.9784462 Test MSE 309.503621143274 Test RE 0.896799690718299\n",
      "29 Train Loss 1.9136491 Test MSE 295.63950416037983 Test RE 0.8764836419258869\n",
      "30 Train Loss 1.8762307 Test MSE 289.16794340637836 Test RE 0.8668374295758602\n",
      "31 Train Loss 1.8532794 Test MSE 283.1534673543262 Test RE 0.8577752767161458\n",
      "32 Train Loss 1.8199912 Test MSE 277.38701348453367 Test RE 0.848996001548037\n",
      "33 Train Loss 1.6529701 Test MSE 237.93937810981978 Test RE 0.7863135209942711\n",
      "34 Train Loss 1.6279544 Test MSE 234.90251576003445 Test RE 0.7812794775724144\n",
      "35 Train Loss 1.6261563 Test MSE 231.92268724103698 Test RE 0.7763082468301643\n",
      "36 Train Loss 1.6087918 Test MSE 213.27037861899956 Test RE 0.7444368323759082\n",
      "37 Train Loss 1.4912724 Test MSE 191.56190298366164 Test RE 0.705532710812346\n",
      "38 Train Loss 1.4652306 Test MSE 186.96328296141334 Test RE 0.6970127865791717\n",
      "39 Train Loss 1.4243108 Test MSE 168.1891288742303 Test RE 0.6610914541372793\n",
      "40 Train Loss 1.3615992 Test MSE 133.381511116513 Test RE 0.5887221815201491\n",
      "41 Train Loss 1.331584 Test MSE 105.16567017223147 Test RE 0.5227566658901939\n",
      "42 Train Loss 1.261929 Test MSE 75.1840418277571 Test RE 0.4420032036894162\n",
      "43 Train Loss 1.1935668 Test MSE 51.928009226316874 Test RE 0.3673359379293099\n",
      "44 Train Loss 0.9250992 Test MSE 2.59051864999466 Test RE 0.0820457225697667\n",
      "45 Train Loss 0.832898 Test MSE 0.8199191343462229 Test RE 0.04615811802820582\n",
      "46 Train Loss 0.71607774 Test MSE 1.8574274195431735 Test RE 0.06947339282059739\n",
      "47 Train Loss 0.67177117 Test MSE 8.472113421322971 Test RE 0.14837422488153118\n",
      "48 Train Loss 0.6690526 Test MSE 10.460687442641621 Test RE 0.16487040147222093\n",
      "49 Train Loss 0.61525214 Test MSE 17.902683083677545 Test RE 0.21568584509833655\n",
      "50 Train Loss 0.47630405 Test MSE 5.6763009768493395 Test RE 0.12144937665681134\n",
      "51 Train Loss 0.3957065 Test MSE 0.9691857279915566 Test RE 0.05018409395566635\n",
      "52 Train Loss 0.34844613 Test MSE 0.013891788996169344 Test RE 0.006008162517767073\n",
      "53 Train Loss 0.3160628 Test MSE 0.37333206227880855 Test RE 0.031146570002130013\n",
      "54 Train Loss 0.29715118 Test MSE 0.829117733203144 Test RE 0.04641631775079151\n",
      "55 Train Loss 0.2806688 Test MSE 1.1792483523420922 Test RE 0.05535606639905766\n",
      "56 Train Loss 0.22351076 Test MSE 0.9452545771562163 Test RE 0.04956064810685094\n",
      "57 Train Loss 0.09870666 Test MSE 0.020056547777849078 Test RE 0.007219226598367641\n",
      "58 Train Loss 0.06484326 Test MSE 1.5949887722423473 Test RE 0.06437858065748304\n",
      "59 Train Loss 0.04894528 Test MSE 0.1509741811949031 Test RE 0.01980678210770764\n",
      "60 Train Loss 0.030615974 Test MSE 0.009840171481333116 Test RE 0.005056661891270422\n",
      "61 Train Loss 0.027524967 Test MSE 0.024257763401645035 Test RE 0.007939405072767785\n",
      "62 Train Loss 0.02678378 Test MSE 0.07998087682628524 Test RE 0.0144163614673514\n",
      "63 Train Loss 0.022741795 Test MSE 0.0017873296296953723 Test RE 0.002155087510538077\n",
      "64 Train Loss 0.011549655 Test MSE 4.7036354366706363e-05 Test RE 0.0003496064281635116\n",
      "65 Train Loss 0.0067898566 Test MSE 0.09515036490205081 Test RE 0.015724172936557985\n",
      "66 Train Loss 0.0050727036 Test MSE 0.0046790817056712045 Test RE 0.0034869273339553143\n",
      "67 Train Loss 0.0045266175 Test MSE 0.0002813863094414243 Test RE 0.0008550944039510682\n",
      "68 Train Loss 0.004508682 Test MSE 0.00030624951963454197 Test RE 0.0008920727856619886\n",
      "69 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "70 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "71 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "72 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "73 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "74 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "75 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "76 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "77 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "78 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "79 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "80 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "81 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "82 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "83 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "84 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "85 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "86 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "87 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "88 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "89 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "90 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "91 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "92 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "93 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "94 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "95 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "96 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "97 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "98 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "99 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "100 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "101 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "102 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "103 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "104 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "105 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "106 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "107 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "108 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "109 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "110 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "111 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "112 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "113 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "114 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "115 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "116 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "117 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "118 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "119 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "120 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "121 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "122 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "123 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "124 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "125 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "126 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "127 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "128 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "129 Train Loss 0.0045020343 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "130 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "131 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "132 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "133 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "134 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "135 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "136 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "137 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "138 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "139 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "140 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "141 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "142 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "143 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "144 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "145 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "146 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "147 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "148 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "149 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "150 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "151 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "152 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "153 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "154 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "155 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "156 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "157 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "158 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "159 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "160 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "161 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "162 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "163 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "164 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "165 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "166 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "167 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "168 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "169 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "170 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "171 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "172 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "173 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "174 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "175 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "176 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "177 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "178 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "179 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "180 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "181 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "182 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "183 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "184 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "185 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "186 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "187 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "188 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "189 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "190 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "191 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "192 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "193 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "194 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "195 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "196 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "197 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "198 Train Loss 0.0045020333 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "199 Train Loss 0.004502034 Test MSE 0.0003545723612207623 Test RE 0.000959875755180647\n",
      "Training time: 37.15\n",
      "Training time: 37.15\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 4.8915753 Test MSE 383.40449250283746 Test RE 0.9981393590673203\n",
      "1 Train Loss 4.8911233 Test MSE 383.31922705014733 Test RE 0.9980283646238256\n",
      "2 Train Loss 4.8843703 Test MSE 383.02457474492576 Test RE 0.9976447054287524\n",
      "3 Train Loss 4.5051203 Test MSE 385.73010738720967 Test RE 1.0011619870943853\n",
      "4 Train Loss 3.9272118 Test MSE 389.9701514429609 Test RE 1.0066494627634273\n",
      "5 Train Loss 2.4231436 Test MSE 384.42391087192766 Test RE 0.9994654339485164\n",
      "6 Train Loss 2.3827817 Test MSE 384.04046764217077 Test RE 0.998966851711535\n",
      "7 Train Loss 2.3823245 Test MSE 383.9696595076614 Test RE 0.9988747543338644\n",
      "8 Train Loss 2.3815362 Test MSE 383.86825926731365 Test RE 0.9987428522088476\n",
      "9 Train Loss 2.3814218 Test MSE 383.8618991117299 Test RE 0.9987345782944426\n",
      "10 Train Loss 2.3811784 Test MSE 383.79843223769115 Test RE 0.9986520106026628\n",
      "11 Train Loss 2.3806186 Test MSE 383.67690193180186 Test RE 0.9984938858119288\n",
      "12 Train Loss 2.3803935 Test MSE 383.6165254947776 Test RE 0.9984153198691114\n",
      "13 Train Loss 2.380353 Test MSE 383.58624959870826 Test RE 0.9983759204781999\n",
      "14 Train Loss 2.3803477 Test MSE 383.5820951767577 Test RE 0.9983705140199738\n",
      "15 Train Loss 2.38034 Test MSE 383.57181916206736 Test RE 0.9983571409521103\n",
      "16 Train Loss 2.3803275 Test MSE 383.5536040151886 Test RE 0.9983334355637679\n",
      "17 Train Loss 2.3803234 Test MSE 383.5447456154336 Test RE 0.998321906943477\n",
      "18 Train Loss 2.3803222 Test MSE 383.5427507461448 Test RE 0.9983193107349186\n",
      "19 Train Loss 2.3803203 Test MSE 383.5403901707965 Test RE 0.9983162385720685\n",
      "20 Train Loss 2.3800786 Test MSE 383.2359344571894 Test RE 0.997919926433457\n",
      "21 Train Loss 2.3723578 Test MSE 381.31520729616466 Test RE 0.9954160647483584\n",
      "22 Train Loss 2.288525 Test MSE 346.71925348530664 Test RE 0.9491865201848312\n",
      "23 Train Loss 2.1330402 Test MSE 339.23610598518127 Test RE 0.9388876300701953\n",
      "24 Train Loss 2.056402 Test MSE 322.81393874680134 Test RE 0.9158803088810046\n",
      "25 Train Loss 1.7323405 Test MSE 256.8389904896283 Test RE 0.8169454525412543\n",
      "26 Train Loss 1.5499706 Test MSE 220.9388954279176 Test RE 0.7577024155030171\n",
      "27 Train Loss 1.4269532 Test MSE 192.36625578053895 Test RE 0.7070123963061687\n",
      "28 Train Loss 1.2759736 Test MSE 154.30376616030833 Test RE 0.6332144918444537\n",
      "29 Train Loss 0.95976853 Test MSE 63.45032885619271 Test RE 0.40605000595777985\n",
      "30 Train Loss 0.6423351 Test MSE 15.551148246938569 Test RE 0.20102210355352898\n",
      "31 Train Loss 0.59207237 Test MSE 13.73851337295091 Test RE 0.18894371620058675\n",
      "32 Train Loss 0.57889366 Test MSE 11.536051518447287 Test RE 0.17313751343124759\n",
      "33 Train Loss 0.42550588 Test MSE 0.26880600118142867 Test RE 0.026429081041509365\n",
      "34 Train Loss 0.34325346 Test MSE 0.0029829144070297525 Test RE 0.002784088128001107\n",
      "35 Train Loss 0.29777232 Test MSE 0.6671313963238397 Test RE 0.04163593025871456\n",
      "36 Train Loss 0.27470648 Test MSE 2.935377369298499 Test RE 0.08733625259203315\n",
      "37 Train Loss 0.26522806 Test MSE 3.343297912287268 Test RE 0.09320734151671511\n",
      "38 Train Loss 0.2644785 Test MSE 3.495542842339432 Test RE 0.09530592421021343\n",
      "39 Train Loss 0.26443058 Test MSE 3.5476952687173235 Test RE 0.09601425952486053\n",
      "40 Train Loss 0.26430997 Test MSE 3.6978389613187983 Test RE 0.09802493872895612\n",
      "41 Train Loss 0.26274976 Test MSE 4.918366428633666 Test RE 0.11305063946681189\n",
      "42 Train Loss 0.25123394 Test MSE 6.65553320677241 Test RE 0.1315085562184213\n",
      "43 Train Loss 0.2392413 Test MSE 3.4546874795630758 Test RE 0.09474732678012122\n",
      "44 Train Loss 0.22608544 Test MSE 2.199895058583762 Test RE 0.0756072713288979\n",
      "45 Train Loss 0.21632919 Test MSE 4.6174216425487025 Test RE 0.10953738017970689\n",
      "46 Train Loss 0.19717687 Test MSE 4.204906748934114 Test RE 0.10452995586700106\n",
      "47 Train Loss 0.1692741 Test MSE 0.7153239311182553 Test RE 0.043113567410613306\n",
      "48 Train Loss 0.13833943 Test MSE 0.562491485308466 Test RE 0.038231431435834885\n",
      "49 Train Loss 0.11319236 Test MSE 0.44291983030880533 Test RE 0.033925413124588896\n",
      "50 Train Loss 0.098013096 Test MSE 0.03800523178456758 Test RE 0.009937663232648561\n",
      "51 Train Loss 0.08715964 Test MSE 0.22623681341392587 Test RE 0.02424622997116894\n",
      "52 Train Loss 0.0830884 Test MSE 0.5226482744644104 Test RE 0.036852532933916375\n",
      "53 Train Loss 0.07152169 Test MSE 0.5335664732205558 Test RE 0.037235470760621836\n",
      "54 Train Loss 0.028713133 Test MSE 0.002223285296186706 Test RE 0.0024035888484176563\n",
      "55 Train Loss 0.0134994 Test MSE 0.004770714214791284 Test RE 0.0035209048051792076\n",
      "56 Train Loss 0.012908212 Test MSE 0.009001298914236988 Test RE 0.004836321623979599\n",
      "57 Train Loss 0.012808323 Test MSE 0.014575347222565255 Test RE 0.006154206113427962\n",
      "58 Train Loss 0.012789516 Test MSE 0.013341517084280791 Test RE 0.00588796460846031\n",
      "59 Train Loss 0.012430689 Test MSE 0.006183382901671129 Test RE 0.0040084424514775525\n",
      "60 Train Loss 0.008601017 Test MSE 0.06478067158259135 Test RE 0.01297434092221492\n",
      "61 Train Loss 0.006822809 Test MSE 0.0020221491919644313 Test RE 0.0022922879933144832\n",
      "62 Train Loss 0.005901669 Test MSE 0.010781006671713906 Test RE 0.0052928823416205865\n",
      "63 Train Loss 0.0054507744 Test MSE 0.005656680926604063 Test RE 0.0038339233303328517\n",
      "64 Train Loss 0.005115561 Test MSE 0.009218122407449047 Test RE 0.004894223724779672\n",
      "65 Train Loss 0.004993896 Test MSE 0.014327763402043631 Test RE 0.006101713096223249\n",
      "66 Train Loss 0.0048080357 Test MSE 0.021558356482835064 Test RE 0.007484631223965224\n",
      "67 Train Loss 0.0043769283 Test MSE 0.01652114613206547 Test RE 0.006552132462445252\n",
      "68 Train Loss 0.003855841 Test MSE 0.014388604076839652 Test RE 0.006114654372221333\n",
      "69 Train Loss 0.003350199 Test MSE 0.017398588538690866 Test RE 0.006723874383827299\n",
      "70 Train Loss 0.0025439388 Test MSE 0.011219054731730271 Test RE 0.0053993404941317085\n",
      "71 Train Loss 0.0018549726 Test MSE 0.004334872677230468 Test RE 0.0033562225847920653\n",
      "72 Train Loss 0.0013039805 Test MSE 7.764157541918943e-05 Test RE 0.0004491689760484889\n",
      "73 Train Loss 0.0010857858 Test MSE 0.0007079569209765845 Test RE 0.0013563319694278036\n",
      "74 Train Loss 0.0010686396 Test MSE 0.0009002813926868874 Test RE 0.0015295078827207778\n",
      "75 Train Loss 0.0010600026 Test MSE 0.0007977215477867122 Test RE 0.001439753835433547\n",
      "76 Train Loss 0.0010547382 Test MSE 0.0007426523899256536 Test RE 0.0013891699300993487\n",
      "77 Train Loss 0.0010465971 Test MSE 0.000608864272988191 Test RE 0.0012578325470852768\n",
      "78 Train Loss 0.0010388637 Test MSE 0.0005084760826003939 Test RE 0.0011494705458832708\n",
      "79 Train Loss 0.0010332059 Test MSE 0.00037912233403438654 Test RE 0.0009925497109580872\n",
      "80 Train Loss 0.001025577 Test MSE 0.00017868365343165233 Test RE 0.0006814044953274785\n",
      "81 Train Loss 0.0010196739 Test MSE 7.647169450735154e-05 Test RE 0.00044577215748451256\n",
      "82 Train Loss 0.001017415 Test MSE 4.6466026480367194e-05 Test RE 0.00034748043004023866\n",
      "83 Train Loss 0.001013283 Test MSE 4.463722256457791e-06 Test RE 0.00010769887443422853\n",
      "84 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "85 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "86 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "87 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "88 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "89 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "90 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "91 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "92 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "93 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "94 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "95 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "96 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "97 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "98 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "99 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "100 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "101 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "102 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "103 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "104 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "105 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "106 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "107 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "108 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "109 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "110 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "111 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "112 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "113 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "114 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "115 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "116 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "117 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "118 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "119 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "120 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "121 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "122 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "123 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "124 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "125 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "126 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "127 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "128 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "129 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "130 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "131 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "132 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "133 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "134 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "135 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "136 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "137 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "138 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "139 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "140 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "141 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "142 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "143 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "144 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "145 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "146 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "147 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "148 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "149 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "150 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "151 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "152 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "153 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "154 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "155 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "156 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "157 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "158 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "159 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "160 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "161 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "162 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "163 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "164 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "165 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "166 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "167 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "168 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "169 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "170 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "171 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "172 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "173 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "174 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "175 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "176 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "177 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "178 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "179 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "180 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "181 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "182 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "183 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "184 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "185 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "186 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "187 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "188 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "189 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "190 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "191 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "192 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "193 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "194 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "195 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "196 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "197 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "198 Train Loss 0.0010073301 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "199 Train Loss 0.0010073303 Test MSE 3.768916735167784e-05 Test RE 0.00031294704420237564\n",
      "Training time: 41.85\n",
      "Training time: 41.85\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 4.891959 Test MSE 383.3858361755837 Test RE 0.9981150742174719\n",
      "1 Train Loss 4.891197 Test MSE 383.2806339923715 Test RE 0.9979781219890287\n",
      "2 Train Loss 4.483809 Test MSE 386.0894969856197 Test RE 1.0016282761231525\n",
      "3 Train Loss 3.1481755 Test MSE 383.0542363701425 Test RE 0.9976833337471744\n",
      "4 Train Loss 2.398412 Test MSE 383.15587933449683 Test RE 0.997815691982257\n",
      "5 Train Loss 2.393542 Test MSE 383.52876067742034 Test RE 0.9983011032689948\n",
      "6 Train Loss 2.3823638 Test MSE 383.7546469284605 Test RE 0.9985950438062731\n",
      "7 Train Loss 2.3810177 Test MSE 383.78621717478046 Test RE 0.9986361185442637\n",
      "8 Train Loss 2.3810008 Test MSE 383.79117370140887 Test RE 0.9986425671220275\n",
      "9 Train Loss 2.3809934 Test MSE 383.7944798643787 Test RE 0.9986468685080304\n",
      "10 Train Loss 2.3809886 Test MSE 383.79709991480775 Test RE 0.9986502772343513\n",
      "11 Train Loss 2.380986 Test MSE 383.7992272660754 Test RE 0.9986530449428485\n",
      "12 Train Loss 2.3809836 Test MSE 383.8010564056369 Test RE 0.9986554246683489\n",
      "13 Train Loss 2.3809824 Test MSE 383.8015327125828 Test RE 0.9986560443466429\n",
      "14 Train Loss 2.3809748 Test MSE 383.802512917469 Test RE 0.9986573195980757\n",
      "15 Train Loss 2.3809657 Test MSE 383.8041162093536 Test RE 0.9986594054852836\n",
      "16 Train Loss 2.3805094 Test MSE 383.5749205331698 Test RE 0.9983611770537913\n",
      "17 Train Loss 2.3804579 Test MSE 383.5482335509142 Test RE 0.9983264462762713\n",
      "18 Train Loss 2.3804502 Test MSE 383.5415546981637 Test RE 0.9983177541434767\n",
      "19 Train Loss 2.3804274 Test MSE 383.5157457154746 Test RE 0.9982841645639603\n",
      "20 Train Loss 2.380349 Test MSE 383.40560962380647 Test RE 0.9981408131994676\n",
      "21 Train Loss 2.380347 Test MSE 383.4033783681521 Test RE 0.998137908820244\n",
      "22 Train Loss 2.3803241 Test MSE 383.368729634726 Test RE 0.9980928061976947\n",
      "23 Train Loss 2.37989 Test MSE 382.84314383328837 Test RE 0.9974083954896056\n",
      "24 Train Loss 2.369969 Test MSE 379.0085138093228 Test RE 0.9924007079823214\n",
      "25 Train Loss 2.301634 Test MSE 362.7548981927606 Test RE 0.9708882053845836\n",
      "26 Train Loss 2.1791084 Test MSE 346.28599552549844 Test RE 0.9485932863755107\n",
      "27 Train Loss 2.1421425 Test MSE 339.254319492204 Test RE 0.9389128340603053\n",
      "28 Train Loss 2.0981793 Test MSE 318.89713089980756 Test RE 0.9103070128983072\n",
      "29 Train Loss 1.9485061 Test MSE 249.4939388552323 Test RE 0.8051792647308329\n",
      "30 Train Loss 1.7214372 Test MSE 253.167132420654 Test RE 0.811084764709388\n",
      "31 Train Loss 1.4463264 Test MSE 196.6916466699013 Test RE 0.7149168623027689\n",
      "32 Train Loss 1.1615986 Test MSE 139.97642146565173 Test RE 0.6031009683216197\n",
      "33 Train Loss 1.0751244 Test MSE 125.98679685302808 Test RE 0.5721700218209721\n",
      "34 Train Loss 0.8730095 Test MSE 75.99502159104726 Test RE 0.44438066434669243\n",
      "35 Train Loss 0.33104458 Test MSE 15.161712317362001 Test RE 0.1984891210105364\n",
      "36 Train Loss 0.2058597 Test MSE 3.2616866297060962 Test RE 0.09206269820867445\n",
      "37 Train Loss 0.13016374 Test MSE 0.1904356610890201 Test RE 0.022245220834922384\n",
      "38 Train Loss 0.12152513 Test MSE 0.16292503050991758 Test RE 0.020575788542827312\n",
      "39 Train Loss 0.06464051 Test MSE 0.22408677318889242 Test RE 0.024130742981744138\n",
      "40 Train Loss 0.052675534 Test MSE 0.0986377106810638 Test RE 0.016009732463081006\n",
      "41 Train Loss 0.040892627 Test MSE 0.017387826217767532 Test RE 0.006721794453953282\n",
      "42 Train Loss 0.038493555 Test MSE 0.0013372481741279305 Test RE 0.0018640973511186054\n",
      "43 Train Loss 0.03833524 Test MSE 0.005053486036642049 Test RE 0.003623749075344189\n",
      "44 Train Loss 0.038331777 Test MSE 0.005196988352234553 Test RE 0.00367484016339412\n",
      "45 Train Loss 0.038324356 Test MSE 0.005713585559843987 Test RE 0.003853159174552128\n",
      "46 Train Loss 0.03832163 Test MSE 0.005808857125763441 Test RE 0.003885151243077933\n",
      "47 Train Loss 0.03831326 Test MSE 0.006302693859050052 Test RE 0.004046929966553255\n",
      "48 Train Loss 0.03830995 Test MSE 0.0064175008899276555 Test RE 0.004083622154741246\n",
      "49 Train Loss 0.03829279 Test MSE 0.007137852540381546 Test RE 0.004306717334557117\n",
      "50 Train Loss 0.03826508 Test MSE 0.008042548661622503 Test RE 0.004571507442822562\n",
      "51 Train Loss 0.03795945 Test MSE 0.005485237092158808 Test RE 0.0037753766424184496\n",
      "52 Train Loss 0.034262784 Test MSE 0.0920031533558746 Test RE 0.015461938407450438\n",
      "53 Train Loss 0.03301773 Test MSE 0.15540225108282688 Test RE 0.02009514921108184\n",
      "54 Train Loss 0.032996804 Test MSE 0.1559251178239078 Test RE 0.020128926913474204\n",
      "55 Train Loss 0.032866143 Test MSE 0.15394894956790175 Test RE 0.020000964891178096\n",
      "56 Train Loss 0.032052893 Test MSE 0.17944779768959987 Test RE 0.021593927995631285\n",
      "57 Train Loss 0.031139495 Test MSE 0.20676914077789862 Test RE 0.023179573676043116\n",
      "58 Train Loss 0.029900474 Test MSE 0.14971217886871965 Test RE 0.019723825337999976\n",
      "59 Train Loss 0.028419558 Test MSE 0.10995414839979235 Test RE 0.016903179062729666\n",
      "60 Train Loss 0.026672948 Test MSE 0.15057716650283376 Test RE 0.01978072215515649\n",
      "61 Train Loss 0.02429004 Test MSE 0.08559532742204891 Test RE 0.014913775844097994\n",
      "62 Train Loss 0.021271192 Test MSE 0.03864129981241614 Test RE 0.010020478162085629\n",
      "63 Train Loss 0.017384935 Test MSE 0.015659072287509786 Test RE 0.006378897108014407\n",
      "64 Train Loss 0.010373031 Test MSE 0.025371407894267898 Test RE 0.008119604325821038\n",
      "65 Train Loss 0.0074962955 Test MSE 0.0059713820216451075 Test RE 0.003939127251062938\n",
      "66 Train Loss 0.0046732165 Test MSE 0.025049808880152714 Test RE 0.008067979590152437\n",
      "67 Train Loss 0.003154532 Test MSE 0.003822722984603895 Test RE 0.0031517299334563207\n",
      "68 Train Loss 0.0030406727 Test MSE 2.588314375804036e-05 Test RE 0.00025934094843041433\n",
      "69 Train Loss 0.0029503782 Test MSE 0.0023537337717128774 Test RE 0.0024730975765993543\n",
      "70 Train Loss 0.002701202 Test MSE 0.00014456806703979407 Test RE 0.0006129129107438048\n",
      "71 Train Loss 0.0025607494 Test MSE 3.3733446836399516e-05 Test RE 0.0002960690035673082\n",
      "72 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "73 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "74 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "75 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "76 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "77 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "78 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "79 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "80 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "81 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "82 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "83 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "84 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "85 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "86 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "87 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "88 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "89 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "90 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "91 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "92 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "93 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "94 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "95 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "96 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "97 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "98 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "99 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "100 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "101 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "102 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "103 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "104 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "105 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "106 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "107 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "108 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "109 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "110 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "111 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "112 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "113 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "114 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "115 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "116 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "117 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "118 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "119 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "120 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "121 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "122 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "123 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "124 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "125 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "126 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "127 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "128 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "129 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "130 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "131 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "132 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "133 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "134 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "135 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "136 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "137 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "138 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "139 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "140 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "141 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "142 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "143 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "144 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "145 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "146 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "147 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "148 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "149 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "150 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "151 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "152 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "153 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "154 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "155 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "156 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "157 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "158 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "159 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "160 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "161 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "162 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "163 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "164 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "165 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "166 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "167 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "168 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "169 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "170 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "171 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "172 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "173 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "174 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "175 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "176 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "177 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "178 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "179 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "180 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "181 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "182 Train Loss 0.0025547135 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "183 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "184 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "185 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "186 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "187 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "188 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "189 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "190 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "191 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "192 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "193 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "194 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "195 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "196 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "197 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "198 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "199 Train Loss 0.002554714 Test MSE 5.587773563598044e-05 Test RE 0.0003810500139417156\n",
      "Training time: 40.69\n",
      "Training time: 40.69\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 4.89247 Test MSE 383.3938014721747 Test RE 0.9981254426773288\n",
      "1 Train Loss 4.8914022 Test MSE 383.27195995041643 Test RE 0.9979668292803583\n",
      "2 Train Loss 4.8670626 Test MSE 382.8955216292793 Test RE 0.9974766222132373\n",
      "3 Train Loss 4.018633 Test MSE 386.5434074537955 Test RE 1.002216890956404\n",
      "4 Train Loss 2.7735214 Test MSE 380.83711859991536 Test RE 0.9947918483235721\n",
      "5 Train Loss 2.4129593 Test MSE 382.98712609040825 Test RE 0.9975959339299972\n",
      "6 Train Loss 2.3830087 Test MSE 383.8357835149145 Test RE 0.9987006038452049\n",
      "7 Train Loss 2.3791506 Test MSE 383.3819549925406 Test RE 0.998110022026259\n",
      "8 Train Loss 2.3752794 Test MSE 380.63381902258755 Test RE 0.9945262915411462\n",
      "9 Train Loss 2.3523254 Test MSE 376.60748938360854 Test RE 0.9892522772905294\n",
      "10 Train Loss 2.2331362 Test MSE 341.83872869865036 Test RE 0.9424823261349539\n",
      "11 Train Loss 2.0703948 Test MSE 313.6121706932305 Test RE 0.9027324140383257\n",
      "12 Train Loss 1.9290311 Test MSE 275.83712794595976 Test RE 0.846620818554147\n",
      "13 Train Loss 1.7890545 Test MSE 235.6929761669714 Test RE 0.7825928986400246\n",
      "14 Train Loss 1.3456542 Test MSE 147.10381935630713 Test RE 0.618264850715341\n",
      "15 Train Loss 0.54209346 Test MSE 37.688665771670934 Test RE 0.31294496179363773\n",
      "16 Train Loss 0.08997398 Test MSE 0.055899292003518015 Test RE 0.012052183522550473\n",
      "17 Train Loss 0.048990935 Test MSE 5.49251425549233e-05 Test RE 0.000377788017378154\n",
      "18 Train Loss 0.047995117 Test MSE 0.04997621219997995 Test RE 0.011395785105960144\n",
      "19 Train Loss 0.042400658 Test MSE 0.7924223354283468 Test RE 0.045377538781256166\n",
      "20 Train Loss 0.027681854 Test MSE 0.7696816147669502 Test RE 0.04472168300364471\n",
      "21 Train Loss 0.027069252 Test MSE 0.4681365690996152 Test RE 0.034877782615225526\n",
      "22 Train Loss 0.021285193 Test MSE 0.00021142907810525375 Test RE 0.0007412162647219784\n",
      "23 Train Loss 0.009845489 Test MSE 0.0016424437513857003 Test RE 0.0020658930525776923\n",
      "24 Train Loss 0.0039786655 Test MSE 0.06553021186975881 Test RE 0.013049184409849313\n",
      "25 Train Loss 0.0021909447 Test MSE 0.004519038651690913 Test RE 0.003426775162784925\n",
      "26 Train Loss 0.0010160845 Test MSE 0.007377708515642911 Test RE 0.00437847958300561\n",
      "27 Train Loss 0.0007462553 Test MSE 3.973307405366033e-05 Test RE 0.0003213206714906925\n",
      "28 Train Loss 0.00068515626 Test MSE 0.0016173788258076554 Test RE 0.0020500689083689703\n",
      "29 Train Loss 0.0005794584 Test MSE 0.0008146199097989798 Test RE 0.0014549232788816048\n",
      "30 Train Loss 0.0005577433 Test MSE 0.00018779244888469365 Test RE 0.0006985566723115774\n",
      "31 Train Loss 0.00054980477 Test MSE 2.156415247572394e-05 Test RE 0.0002367166355181425\n",
      "32 Train Loss 0.0005485747 Test MSE 9.814151243867756e-06 Test RE 0.00015969413112287703\n",
      "33 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "34 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "35 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "36 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "37 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "38 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "39 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "40 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "41 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "42 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "43 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "44 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "45 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "46 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "47 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "48 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "49 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "50 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "51 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "52 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "53 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "54 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "55 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "56 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "57 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "58 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "59 Train Loss 0.0005437157 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "60 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "61 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "62 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "63 Train Loss 0.0005437157 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "64 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "65 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "66 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "67 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "68 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "69 Train Loss 0.0005437157 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "70 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "71 Train Loss 0.0005437157 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "72 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "73 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "74 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "75 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "76 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "77 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "78 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "79 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "80 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "81 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "82 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "83 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "84 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "85 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "86 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "87 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "88 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "89 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "90 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "91 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "92 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "93 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "94 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "95 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "96 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "97 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "98 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "99 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "100 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "101 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "102 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "103 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "104 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "105 Train Loss 0.0005437157 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "106 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "107 Train Loss 0.0005437157 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "108 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "109 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "110 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "111 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "112 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "113 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "114 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "115 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "116 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "117 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "118 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "119 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "120 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "121 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "122 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "123 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "124 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "125 Train Loss 0.0005437157 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "126 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "127 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "128 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "129 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "130 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "131 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "132 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "133 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "134 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "135 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "136 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "137 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "138 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "139 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "140 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "141 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "142 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "143 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "144 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "145 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "146 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "147 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "148 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "149 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "150 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "151 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "152 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "153 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "154 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "155 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "156 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "157 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "158 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "159 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "160 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "161 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "162 Train Loss 0.0005437157 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "163 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "164 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "165 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "166 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "167 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "168 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "169 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "170 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "171 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "172 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "173 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "174 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "175 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "176 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "177 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "178 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "179 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "180 Train Loss 0.0005437157 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "181 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "182 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "183 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "184 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "185 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "186 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "187 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "188 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "189 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "190 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "191 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "192 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "193 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "194 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "195 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "196 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "197 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "198 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "199 Train Loss 0.00054371567 Test MSE 1.6925708147550654e-05 Test RE 0.00020971814446631634\n",
      "Training time: 27.81\n",
      "Training time: 27.81\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 4.8954844 Test MSE 383.39531146180195 Test RE 0.9981274082249922\n",
      "1 Train Loss 4.895043 Test MSE 383.2939029166277 Test RE 0.9979953965136581\n",
      "2 Train Loss 4.8895617 Test MSE 383.1842399931666 Test RE 0.9978526197551864\n",
      "3 Train Loss 4.8798504 Test MSE 383.3345792374871 Test RE 0.9980483502701653\n",
      "4 Train Loss 4.71614 Test MSE 382.386482004719 Test RE 0.9968133551242443\n",
      "5 Train Loss 3.7383618 Test MSE 387.29895687423414 Test RE 1.0031958944968766\n",
      "6 Train Loss 2.383208 Test MSE 383.8259829244435 Test RE 0.9986878537076179\n",
      "7 Train Loss 2.3812363 Test MSE 383.8051611861096 Test RE 0.9986607650006086\n",
      "8 Train Loss 2.3812323 Test MSE 383.80488021501355 Test RE 0.9986603994572425\n",
      "9 Train Loss 2.3812246 Test MSE 383.8042946327802 Test RE 0.9986596376143891\n",
      "10 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "11 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "12 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "13 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "14 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "15 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "16 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "17 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "18 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "19 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "20 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "21 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "22 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "23 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "24 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "25 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "26 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "27 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "28 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "29 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "30 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "31 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "32 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "33 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "34 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "35 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "36 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "37 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "38 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "39 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "40 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "41 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "42 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "43 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "44 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "45 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "46 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "47 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "48 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "49 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "50 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "51 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "52 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "53 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "54 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "55 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "56 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "57 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "58 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "59 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "60 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "61 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "62 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "63 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "64 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "65 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "66 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "67 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "68 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "69 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "70 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "71 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "72 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "73 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "74 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "75 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "76 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "77 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "78 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "79 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "80 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "81 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "82 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "83 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "84 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "85 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "86 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "87 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "88 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "89 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "90 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "91 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "92 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "93 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "94 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "95 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "96 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "97 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "98 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "99 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "100 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "101 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "102 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "103 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "104 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "105 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "106 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "107 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "108 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "109 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "110 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "111 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "112 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "113 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "114 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "115 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "116 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "117 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "118 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "119 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "120 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "121 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "122 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "123 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "124 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "125 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "126 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "127 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "128 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "129 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "130 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "131 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "132 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "133 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "134 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "135 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "136 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "137 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "138 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "139 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "140 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "141 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "142 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "143 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "144 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "145 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "146 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "147 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "148 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "149 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "150 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "151 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "152 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "153 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "154 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "155 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "156 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "157 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "158 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "159 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "160 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "161 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "162 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "163 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "164 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "165 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "166 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "167 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "168 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "169 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "170 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "171 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "172 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "173 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "174 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "175 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "176 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "177 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "178 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "179 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "180 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "181 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "182 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "183 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "184 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "185 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "186 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "187 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "188 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "189 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "190 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "191 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "192 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "193 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "194 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "195 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "196 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "197 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "198 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "199 Train Loss 2.3812213 Test MSE 383.80388585569216 Test RE 0.9986591057947967\n",
      "Training time: 14.55\n",
      "Training time: 14.55\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 4.8911877 Test MSE 383.40670129034874 Test RE 0.9981422341960925\n",
      "1 Train Loss 4.8908024 Test MSE 383.32815381079513 Test RE 0.9980399856277216\n",
      "2 Train Loss 4.8867197 Test MSE 383.09632938128675 Test RE 0.9977381488856891\n",
      "3 Train Loss 3.5938706 Test MSE 388.3273461939103 Test RE 1.00452689731049\n",
      "4 Train Loss 2.5185752 Test MSE 382.4065344314289 Test RE 0.9968394913315162\n",
      "5 Train Loss 2.389429 Test MSE 383.0087982346042 Test RE 0.9976241590785876\n",
      "6 Train Loss 2.3806992 Test MSE 383.5767320638703 Test RE 0.9983635345590535\n",
      "7 Train Loss 2.3805172 Test MSE 383.6381119163471 Test RE 0.9984434103049792\n",
      "8 Train Loss 2.380515 Test MSE 383.63967712562845 Test RE 0.9984454470829349\n",
      "9 Train Loss 2.380506 Test MSE 383.64758644752385 Test RE 0.9984557392740258\n",
      "10 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "11 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "12 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "13 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "14 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "15 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "16 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "17 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "18 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "19 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "20 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "21 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "22 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "23 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "24 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "25 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "26 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "27 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "28 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "29 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "30 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "31 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "32 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "33 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "34 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "35 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "36 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "37 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "38 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "39 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "40 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "41 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "42 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "43 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "44 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "45 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "46 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "47 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "48 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "49 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "50 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "51 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "52 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "53 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "54 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "55 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "56 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "57 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "58 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "59 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "60 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "61 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "62 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "63 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "64 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "65 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "66 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "67 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "68 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "69 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "70 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "71 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "72 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "73 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "74 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "75 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "76 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "77 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "78 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "79 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "80 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "81 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "82 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "83 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "84 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "85 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "86 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "87 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "88 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "89 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "90 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "91 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "92 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "93 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "94 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "95 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "96 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "97 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "98 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "99 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "100 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "101 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "102 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "103 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "104 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "105 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "106 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "107 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "108 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "109 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "110 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "111 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "112 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "113 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "114 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "115 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "116 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "117 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "118 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "119 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "120 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "121 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "122 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "123 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "124 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "125 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "126 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "127 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "128 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "129 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "130 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "131 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "132 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "133 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "134 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "135 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "136 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "137 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "138 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "139 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "140 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "141 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "142 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "143 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "144 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "145 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "146 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "147 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "148 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "149 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "150 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "151 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "152 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "153 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "154 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "155 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "156 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "157 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "158 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "159 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "160 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "161 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "162 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "163 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "164 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "165 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "166 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "167 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "168 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "169 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "170 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "171 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "172 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "173 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "174 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "175 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "176 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "177 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "178 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "179 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "180 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "181 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "182 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "183 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "184 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "185 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "186 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "187 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "188 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "189 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "190 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "191 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "192 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "193 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "194 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "195 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "196 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "197 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "198 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "199 Train Loss 2.3805048 Test MSE 383.64829026418823 Test RE 0.9984566551268694\n",
      "Training time: 15.18\n",
      "Training time: 15.18\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 4.8879013 Test MSE 383.4120285246787 Test RE 0.9981491685025194\n",
      "1 Train Loss 4.887367 Test MSE 383.3180666430095 Test RE 0.9980268539767814\n",
      "2 Train Loss 4.514001 Test MSE 386.36391633859085 Test RE 1.0019841746409195\n",
      "3 Train Loss 4.2644434 Test MSE 386.60095375962925 Test RE 1.0022914902539597\n",
      "4 Train Loss 3.1676683 Test MSE 382.6096447209641 Test RE 0.9971041853966031\n",
      "5 Train Loss 2.4015763 Test MSE 384.64392180653437 Test RE 0.9997513967425066\n",
      "6 Train Loss 2.382127 Test MSE 384.0053729237001 Test RE 0.9989212064418972\n",
      "7 Train Loss 2.3820593 Test MSE 383.9841984151478 Test RE 0.9988936652162917\n",
      "8 Train Loss 2.382053 Test MSE 383.9804467070332 Test RE 0.9988887853714455\n",
      "9 Train Loss 2.382049 Test MSE 383.977589676406 Test RE 0.9988850692171648\n",
      "10 Train Loss 2.3820484 Test MSE 383.9771075632923 Test RE 0.9988844421288202\n",
      "11 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "12 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "13 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "14 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "15 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "16 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "17 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "18 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "19 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "20 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "21 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "22 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "23 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "24 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "25 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "26 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "27 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "28 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "29 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "30 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "31 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "32 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "33 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "34 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "35 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "36 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "37 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "38 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "39 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "40 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "41 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "42 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "43 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "44 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "45 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "46 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "47 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "48 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "49 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "50 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "51 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "52 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "53 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "54 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "55 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "56 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "57 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "58 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "59 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "60 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "61 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "62 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "63 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "64 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "65 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "66 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "67 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "68 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "69 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "70 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "71 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "72 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "73 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "74 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "75 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "76 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "77 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "78 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "79 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "80 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "81 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "82 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "83 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "84 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "85 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "86 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "87 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "88 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "89 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "90 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "91 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "92 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "93 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "94 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "95 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "96 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "97 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "98 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "99 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "100 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "101 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "102 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "103 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "104 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "105 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "106 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "107 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "108 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "109 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "110 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "111 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "112 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "113 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "114 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "115 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "116 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "117 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "118 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "119 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "120 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "121 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "122 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "123 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "124 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "125 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "126 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "127 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "128 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "129 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "130 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "131 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "132 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "133 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "134 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "135 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "136 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "137 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "138 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "139 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "140 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "141 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "142 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "143 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "144 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "145 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "146 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "147 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "148 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "149 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "150 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "151 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "152 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "153 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "154 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "155 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "156 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "157 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "158 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "159 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "160 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "161 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "162 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "163 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "164 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "165 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "166 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "167 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "168 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "169 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "170 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "171 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "172 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "173 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "174 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "175 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "176 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "177 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "178 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "179 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "180 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "181 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "182 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "183 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "184 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "185 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "186 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "187 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "188 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "189 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "190 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "191 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "192 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "193 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "194 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "195 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "196 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "197 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "198 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "199 Train Loss 2.382045 Test MSE 383.9747007975536 Test RE 0.998881311623678\n",
      "Training time: 14.80\n",
      "Training time: 14.80\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 4.894333 Test MSE 383.3919313468774 Test RE 0.99812300833709\n",
      "1 Train Loss 4.893962 Test MSE 383.3191759430762 Test RE 0.99802829809141\n",
      "2 Train Loss 4.8915563 Test MSE 383.1666011878172 Test RE 0.997829652825904\n",
      "3 Train Loss 4.7551093 Test MSE 383.3824600260245 Test RE 0.9981106794369808\n",
      "4 Train Loss 4.377372 Test MSE 387.65620362405224 Test RE 1.0036584646375721\n",
      "5 Train Loss 2.6017375 Test MSE 384.0824112043822 Test RE 0.99902140206213\n",
      "6 Train Loss 2.4423862 Test MSE 383.1066044407021 Test RE 0.9977515290060845\n",
      "7 Train Loss 2.3847482 Test MSE 384.05122863924026 Test RE 0.9989808473773129\n",
      "8 Train Loss 2.3815973 Test MSE 383.8998504575454 Test RE 0.9987839481129165\n",
      "9 Train Loss 2.3803544 Test MSE 383.6179142515616 Test RE 0.9984171270837408\n",
      "10 Train Loss 2.379839 Test MSE 383.2969901280771 Test RE 0.9979994156443918\n",
      "11 Train Loss 2.3771462 Test MSE 382.56116695288875 Test RE 0.9970410153781092\n",
      "12 Train Loss 2.3655558 Test MSE 379.6493056144094 Test RE 0.9932392823883576\n",
      "13 Train Loss 2.263591 Test MSE 352.71031526010484 Test RE 0.9573520312439894\n",
      "14 Train Loss 2.1834583 Test MSE 345.7691147932424 Test RE 0.9478850673028936\n",
      "15 Train Loss 2.1576788 Test MSE 338.86342439143687 Test RE 0.9383717617916303\n",
      "16 Train Loss 1.8471429 Test MSE 260.5129077533124 Test RE 0.8227676465196905\n",
      "17 Train Loss 1.2977178 Test MSE 173.83705105261154 Test RE 0.6720997835893723\n",
      "18 Train Loss 1.101432 Test MSE 149.90842869354154 Test RE 0.6241307907829913\n",
      "19 Train Loss 0.60276467 Test MSE 53.36393431357831 Test RE 0.37238013323825236\n",
      "20 Train Loss 0.43294883 Test MSE 7.454809061054988 Test RE 0.1391812859311794\n",
      "21 Train Loss 0.13922997 Test MSE 1.2011215936393014 Test RE 0.05586709250113348\n",
      "22 Train Loss 0.021017058 Test MSE 0.06418279883815874 Test RE 0.012914330849758708\n",
      "23 Train Loss 0.010763812 Test MSE 0.1317996762857474 Test RE 0.01850630665680332\n",
      "24 Train Loss 0.010371062 Test MSE 0.08897200186810307 Test RE 0.015205099402886443\n",
      "25 Train Loss 0.009619788 Test MSE 0.0018439393735144127 Test RE 0.0021889503021242157\n",
      "26 Train Loss 0.009013015 Test MSE 3.9515930987636304e-06 Test RE 0.00010133248467050493\n",
      "27 Train Loss 0.009010116 Test MSE 2.579032099754737e-06 Test RE 8.186362209940415e-05\n",
      "28 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "29 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "30 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "31 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "32 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "33 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "34 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "35 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "36 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "37 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "38 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "39 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "40 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "41 Train Loss 0.00899271 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "42 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "43 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "44 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "45 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "46 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "47 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "48 Train Loss 0.00899271 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "49 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "50 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "51 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "52 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "53 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "54 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "55 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "56 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "57 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "58 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "59 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "60 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "61 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "62 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "63 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "64 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "65 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "66 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "67 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "68 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "69 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "70 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "71 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "72 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "73 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "74 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "75 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "76 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "77 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "78 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "79 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "80 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "81 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "82 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "83 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "84 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "85 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "86 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "87 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "88 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "89 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "90 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "91 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "92 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "93 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "94 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "95 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "96 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "97 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "98 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "99 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "100 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "101 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "102 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "103 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "104 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "105 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "106 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "107 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "108 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "109 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "110 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "111 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "112 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "113 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "114 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "115 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "116 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "117 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "118 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "119 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "120 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "121 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "122 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "123 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "124 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "125 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "126 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "127 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "128 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "129 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "130 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "131 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "132 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "133 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "134 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "135 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "136 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "137 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "138 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "139 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "140 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "141 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "142 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "143 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "144 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "145 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "146 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "147 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "148 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "149 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "150 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "151 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "152 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "153 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "154 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "155 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "156 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "157 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "158 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "159 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "160 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "161 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "162 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "163 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "164 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "165 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "166 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "167 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "168 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "169 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "170 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "171 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "172 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "173 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "174 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "175 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "176 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "177 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "178 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "179 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "180 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "181 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "182 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "183 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "184 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "185 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "186 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "187 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "188 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "189 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "190 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "191 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "192 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "193 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "194 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "195 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "196 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "197 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "198 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "199 Train Loss 0.008992709 Test MSE 0.00017070949389089732 Test RE 0.0006660263629041355\n",
      "Training time: 60.29\n",
      "Training time: 60.29\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    beta_val = []\n",
    "\n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "\n",
    "\n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.05, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    beta_full.append(beta_val)    \n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_SODE_swish_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_SODE_swish_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4031/756705779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_SODE_swish_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m \u001b[0;31m#WRONGLY SAVED AS STAN - DOESN'T MATTER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_SODE_swish_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_SODE_swish_tune\"+str(tune_reps)+\".mat\" #WRONGLY SAVED AS STAN - DOESN'T MATTER\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
