{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(-3*x) + np.exp(4*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"high\"\n",
    "label = \"1D_SODE_tanh\" + level\n",
    "\n",
    "u_coeff = 12.0\n",
    "fo_val = -1.0 \n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "\n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "    \n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,0)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 4.8102355 Test MSE 595472.9562377204 Test RE 1.000009751573058\n",
      "1 Train Loss 4.4884853 Test MSE 595449.9806774308 Test RE 0.999990459340116\n",
      "2 Train Loss 4.408053 Test MSE 595479.7156668487 Test RE 1.000015427293332\n",
      "3 Train Loss 4.1215997 Test MSE 595512.8386954323 Test RE 1.000043239390123\n",
      "4 Train Loss 3.3752081 Test MSE 595482.7675526163 Test RE 1.000017989873433\n",
      "5 Train Loss 2.8850925 Test MSE 595486.1179442508 Test RE 1.0000208030927045\n",
      "6 Train Loss 2.8642063 Test MSE 595482.3210225998 Test RE 1.000017614935519\n",
      "7 Train Loss 2.8569343 Test MSE 595480.6324241373 Test RE 1.0000161970685695\n",
      "8 Train Loss 2.8392692 Test MSE 595483.7792995219 Test RE 1.0000188394065614\n",
      "9 Train Loss 2.8353593 Test MSE 595480.9393883069 Test RE 1.000016454817592\n",
      "10 Train Loss 2.829329 Test MSE 595469.5537712355 Test RE 1.0000068945965241\n",
      "11 Train Loss 2.828158 Test MSE 595463.8100167611 Test RE 1.0000020716732616\n",
      "12 Train Loss 2.8278189 Test MSE 595462.253988425 Test RE 1.0000007651013505\n",
      "13 Train Loss 2.8278155 Test MSE 595462.2405852862 Test RE 1.0000007538469438\n",
      "14 Train Loss 2.8278108 Test MSE 595462.2202833983 Test RE 1.0000007367997643\n",
      "15 Train Loss 2.827808 Test MSE 595462.1999891162 Test RE 1.0000007197589709\n",
      "16 Train Loss 2.8278058 Test MSE 595462.19149119 Test RE 1.0000007126233943\n",
      "17 Train Loss 2.8277998 Test MSE 595462.1592961708 Test RE 1.0000006855897363\n",
      "18 Train Loss 2.8277953 Test MSE 595462.1145849143 Test RE 1.0000006480463868\n",
      "19 Train Loss 2.827788 Test MSE 595462.0672768422 Test RE 1.00000060832253\n",
      "20 Train Loss 2.8276193 Test MSE 595460.7746900739 Test RE 0.9999995229567885\n",
      "21 Train Loss 2.827611 Test MSE 595460.7743944336 Test RE 0.9999995227085435\n",
      "22 Train Loss 2.8276052 Test MSE 595460.7288339913 Test RE 0.9999994844521013\n",
      "23 Train Loss 2.8275998 Test MSE 595460.7053320094 Test RE 0.9999994647178275\n",
      "24 Train Loss 2.827596 Test MSE 595460.6677434563 Test RE 0.9999994331552634\n",
      "25 Train Loss 2.8275921 Test MSE 595460.6443720462 Test RE 0.9999994135306278\n",
      "26 Train Loss 2.8275895 Test MSE 595460.6132046867 Test RE 0.9999993873598456\n",
      "27 Train Loss 2.8275895 Test MSE 595460.6132046867 Test RE 0.9999993873598456\n",
      "28 Train Loss 2.8275895 Test MSE 595460.6132046867 Test RE 0.9999993873598456\n",
      "29 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "30 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "31 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "32 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "33 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "34 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "35 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "36 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "37 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "38 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "39 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "40 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "41 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "42 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "43 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "44 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "45 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "46 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "47 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "48 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "49 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "50 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "51 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "52 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "53 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "54 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "55 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "56 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "57 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "58 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "59 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "60 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "61 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "62 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "63 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "64 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "65 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "66 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "67 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "68 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "69 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "70 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "71 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "72 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "73 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "74 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "75 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "76 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "77 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "78 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "79 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "80 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "81 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "82 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "83 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "84 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "85 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "86 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "87 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "88 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "89 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "90 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "91 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "92 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "93 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "94 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "95 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "96 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "97 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "98 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "99 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "100 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "101 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "102 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "103 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "104 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "105 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "106 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "107 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "108 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "109 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "110 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "111 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "112 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "113 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "114 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "115 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "116 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "117 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "118 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "119 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "120 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "121 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "122 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "123 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "124 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "125 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "126 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "127 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "128 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "129 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "130 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "131 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "132 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "133 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "134 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "135 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "136 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "137 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "138 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "139 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "140 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "141 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "142 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "143 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "144 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "145 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "146 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "147 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "148 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "149 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "150 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "151 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "152 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "153 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "154 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "155 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "156 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "157 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "158 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "159 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "160 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "161 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "162 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "163 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "164 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "165 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "166 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "167 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "168 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "169 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "170 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "171 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "172 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "173 Train Loss 2.8275893 Test MSE 595460.6130338988 Test RE 0.9999993872164377\n",
      "174 Train Loss 2.827589 Test MSE 595460.6123613431 Test RE 0.9999993866517023\n",
      "175 Train Loss 2.8275878 Test MSE 595460.5396512288 Test RE 0.9999993255980656\n",
      "176 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "177 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "178 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "179 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "180 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "181 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "182 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "183 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "184 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "185 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "186 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "187 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "188 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "189 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "190 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "191 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "192 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "193 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "194 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "195 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "196 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "197 Train Loss 2.827584 Test MSE 595460.496174608 Test RE 0.9999992890913707\n",
      "198 Train Loss 2.8275833 Test MSE 595460.497008353 Test RE 0.9999992897914546\n",
      "199 Train Loss 2.8275833 Test MSE 595460.497008353 Test RE 0.9999992897914546\n",
      "Training time: 30.90\n",
      "Training time: 30.90\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 4.884605 Test MSE 595467.8449787246 Test RE 1.0000054597578263\n",
      "1 Train Loss 4.443098 Test MSE 595450.0765345964 Test RE 0.9999905398307116\n",
      "2 Train Loss 4.374735 Test MSE 595476.0498114395 Test RE 1.0000123491720219\n",
      "3 Train Loss 4.080749 Test MSE 595507.3404661146 Test RE 1.0000386227980096\n",
      "4 Train Loss 3.418223 Test MSE 595429.2901324569 Test RE 0.9999730854817042\n",
      "5 Train Loss 2.9507096 Test MSE 595468.6641085551 Test RE 1.0000061475649247\n",
      "6 Train Loss 2.8551626 Test MSE 595460.2761856794 Test RE 0.9999991043698031\n",
      "7 Train Loss 2.8346155 Test MSE 595476.0247534832 Test RE 1.0000123281314897\n",
      "8 Train Loss 2.8336833 Test MSE 595475.8408424885 Test RE 1.0000121737060648\n",
      "9 Train Loss 2.8303492 Test MSE 595467.8102244075 Test RE 1.000005430575304\n",
      "10 Train Loss 2.8283138 Test MSE 595463.5713632114 Test RE 1.000001871279834\n",
      "11 Train Loss 2.827735 Test MSE 595464.2327480274 Test RE 1.0000024266335967\n",
      "12 Train Loss 2.8277252 Test MSE 595464.1736423518 Test RE 1.0000023770035624\n",
      "13 Train Loss 2.8277178 Test MSE 595464.1335658665 Test RE 1.0000023433520153\n",
      "14 Train Loss 2.8277118 Test MSE 595464.0612363938 Test RE 1.0000022826181774\n",
      "15 Train Loss 2.8277054 Test MSE 595464.0194445209 Test RE 1.0000022475262451\n",
      "16 Train Loss 2.8277016 Test MSE 595463.9485376824 Test RE 1.0000021879869636\n",
      "17 Train Loss 2.8276994 Test MSE 595463.9126997703 Test RE 1.0000021578944693\n",
      "18 Train Loss 2.8276944 Test MSE 595463.857553714 Test RE 1.0000021115892477\n",
      "19 Train Loss 2.827693 Test MSE 595463.8337122961 Test RE 1.0000020915700072\n",
      "20 Train Loss 2.8276882 Test MSE 595463.803710188 Test RE 1.0000020663777371\n",
      "21 Train Loss 2.8276865 Test MSE 595463.7984738973 Test RE 1.0000020619809113\n",
      "22 Train Loss 2.8276837 Test MSE 595463.8084628746 Test RE 1.000002070368489\n",
      "23 Train Loss 2.827682 Test MSE 595463.8344125565 Test RE 1.0000020921580042\n",
      "24 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "25 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "26 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "27 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "28 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "29 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "30 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "31 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "32 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "33 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "34 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "35 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "36 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "37 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "38 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "39 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "40 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "41 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "42 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "43 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "44 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "45 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "46 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "47 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "48 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "49 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "50 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "51 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "52 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "53 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "54 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "55 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "56 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "57 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "58 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "59 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "60 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "61 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "62 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "63 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "64 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "65 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "66 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "67 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "68 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "69 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "70 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "71 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "72 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "73 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "74 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "75 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "76 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "77 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "78 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "79 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "80 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "81 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "82 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "83 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "84 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "85 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "86 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "87 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "88 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "89 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "90 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "91 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "92 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "93 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "94 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "95 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "96 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "97 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "98 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "99 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "100 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "101 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "102 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "103 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "104 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "105 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "106 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "107 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "108 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "109 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "110 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "111 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "112 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "113 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "114 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "115 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "116 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "117 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "118 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "119 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "120 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "121 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "122 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "123 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "124 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "125 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "126 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "127 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "128 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "129 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "130 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "131 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "132 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "133 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "134 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "135 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "136 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "137 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "138 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "139 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "140 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "141 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "142 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "143 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "144 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "145 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "146 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "147 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "148 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "149 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "150 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "151 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "152 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "153 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "154 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "155 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "156 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "157 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "158 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "159 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "160 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "161 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "162 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "163 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "164 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "165 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "166 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "167 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "168 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "169 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "170 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "171 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "172 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "173 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "174 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "175 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "176 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "177 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "178 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "179 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "180 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "181 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "182 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "183 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "184 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "185 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "186 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "187 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "188 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "189 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "190 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "191 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "192 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "193 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "194 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "195 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "196 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "197 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "198 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "199 Train Loss 2.8276792 Test MSE 595463.9547822436 Test RE 1.0000021932304168\n",
      "Training time: 8.59\n",
      "Training time: 8.59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 4.969293 Test MSE 595470.391593269 Test RE 1.0000075980980803\n",
      "1 Train Loss 4.759264 Test MSE 595487.5115074179 Test RE 1.0000219732218647\n",
      "2 Train Loss 4.4259205 Test MSE 595455.9885484517 Test RE 0.9999955040951273\n",
      "3 Train Loss 3.8862875 Test MSE 595471.5094994113 Test RE 1.0000085367796063\n",
      "4 Train Loss 3.3786669 Test MSE 595479.124333009 Test RE 1.0000149307666715\n",
      "5 Train Loss 2.8572023 Test MSE 595455.5028454192 Test RE 0.9999950962556252\n",
      "6 Train Loss 2.839464 Test MSE 595462.1811395716 Test RE 1.000000703931301\n",
      "7 Train Loss 2.8300197 Test MSE 595460.6494469214 Test RE 0.9999994177919272\n",
      "8 Train Loss 2.8280554 Test MSE 595456.3459653868 Test RE 0.999995804214096\n",
      "9 Train Loss 2.8278365 Test MSE 595455.9757798515 Test RE 0.9999954933734758\n",
      "10 Train Loss 2.8278291 Test MSE 595455.9850962842 Test RE 0.9999955011963804\n",
      "11 Train Loss 2.827823 Test MSE 595456.0090976822 Test RE 0.9999955213500866\n",
      "12 Train Loss 2.8278189 Test MSE 595456.0233923924 Test RE 0.999995533353195\n",
      "13 Train Loss 2.8278146 Test MSE 595456.0470313053 Test RE 0.9999955532025258\n",
      "14 Train Loss 2.82781 Test MSE 595456.0619440149 Test RE 0.9999955657245608\n",
      "15 Train Loss 2.827806 Test MSE 595456.0853040984 Test RE 0.9999955853397611\n",
      "16 Train Loss 2.8278017 Test MSE 595456.1006401068 Test RE 0.9999955982172353\n",
      "17 Train Loss 2.827797 Test MSE 595456.1249578818 Test RE 0.9999956186365976\n",
      "18 Train Loss 2.827792 Test MSE 595456.1401395467 Test RE 0.9999956313844708\n",
      "19 Train Loss 2.8277843 Test MSE 595456.1646148746 Test RE 0.9999956519361278\n",
      "20 Train Loss 2.8277774 Test MSE 595456.177047554 Test RE 0.9999956623757086\n",
      "21 Train Loss 2.8277698 Test MSE 595456.1986307512 Test RE 0.9999956804988751\n",
      "22 Train Loss 2.8277612 Test MSE 595456.2050677065 Test RE 0.999995685903914\n",
      "23 Train Loss 2.8277533 Test MSE 595456.2209792662 Test RE 0.9999956992646707\n",
      "24 Train Loss 2.8277435 Test MSE 595456.219411558 Test RE 0.999995697948284\n",
      "25 Train Loss 2.8277354 Test MSE 595456.231263408 Test RE 0.9999957079001481\n",
      "26 Train Loss 2.8277264 Test MSE 595456.2235501019 Test RE 0.9999957014233721\n",
      "27 Train Loss 2.8277178 Test MSE 595456.2444883696 Test RE 0.9999957190049982\n",
      "28 Train Loss 2.8277087 Test MSE 595456.2475897559 Test RE 0.9999957216091973\n",
      "29 Train Loss 2.827629 Test MSE 595456.7531265756 Test RE 0.9999961461026436\n",
      "30 Train Loss 2.8275917 Test MSE 595456.8554363273 Test RE 0.9999962320109425\n",
      "31 Train Loss 2.827584 Test MSE 595456.8880039306 Test RE 0.9999962593575753\n",
      "32 Train Loss 2.827578 Test MSE 595456.9490183131 Test RE 0.9999963105906318\n",
      "33 Train Loss 2.8275728 Test MSE 595456.9848694486 Test RE 0.9999963406944055\n",
      "34 Train Loss 2.8275692 Test MSE 595457.0552303563 Test RE 0.9999963997756239\n",
      "35 Train Loss 2.8275657 Test MSE 595457.0956471269 Test RE 0.9999964337131044\n",
      "36 Train Loss 2.827563 Test MSE 595457.1586665112 Test RE 0.9999964866297278\n",
      "37 Train Loss 2.827563 Test MSE 595457.1586665112 Test RE 0.9999964866297278\n",
      "38 Train Loss 2.827563 Test MSE 595457.1586665112 Test RE 0.9999964866297278\n",
      "39 Train Loss 2.8275592 Test MSE 595457.2707306005 Test RE 0.9999965807285968\n",
      "40 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "41 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "42 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "43 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "44 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "45 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "46 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "47 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "48 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "49 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "50 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "51 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "52 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "53 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "54 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "55 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "56 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "57 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "58 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "59 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "60 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "61 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "62 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "63 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "64 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "65 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "66 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "67 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "68 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "69 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "70 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "71 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "72 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "73 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "74 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "75 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "76 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "77 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "78 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "79 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "80 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "81 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "82 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "83 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "84 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "85 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "86 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "87 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "88 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "89 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "90 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "91 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "92 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "93 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "94 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "95 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "96 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "97 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "98 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "99 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "100 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "101 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "102 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "103 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "104 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "105 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "106 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "107 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "108 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "109 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "110 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "111 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "112 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "113 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "114 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "115 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "116 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "117 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "118 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "119 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "120 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "121 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "122 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "123 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "124 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "125 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "126 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "127 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "128 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "129 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "130 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "131 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "132 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "133 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "134 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "135 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "136 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "137 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "138 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "139 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "140 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "141 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "142 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "143 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "144 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "145 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "146 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "147 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "148 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "149 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "150 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "151 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "152 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "153 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "154 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "155 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "156 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "157 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "158 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "159 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "160 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "161 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "162 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "163 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "164 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "165 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "166 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "167 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "168 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "169 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "170 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "171 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "172 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "173 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "174 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "175 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "176 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "177 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "178 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "179 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "180 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "181 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "182 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "183 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "184 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "185 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "186 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "187 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "188 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "189 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "190 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "191 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "192 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "193 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "194 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "195 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "196 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "197 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "198 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "199 Train Loss 2.8275585 Test MSE 595457.333596335 Test RE 0.9999966335161949\n",
      "Training time: 8.49\n",
      "Training time: 8.49\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 4.8923593 Test MSE 595468.4272910584 Test RE 1.000005948714011\n",
      "1 Train Loss 4.3920016 Test MSE 595442.2022838035 Test RE 0.999983927855465\n",
      "2 Train Loss 4.3205695 Test MSE 595471.7220418123 Test RE 1.0000087152467478\n",
      "3 Train Loss 4.1142235 Test MSE 595520.6238686906 Test RE 1.0000497761798726\n",
      "4 Train Loss 3.9866295 Test MSE 595526.8269267699 Test RE 1.0000549845223223\n",
      "5 Train Loss 3.6027482 Test MSE 595510.9179095897 Test RE 1.0000416266033616\n",
      "6 Train Loss 3.3061438 Test MSE 595484.0247801819 Test RE 1.0000190455291025\n",
      "7 Train Loss 2.9126885 Test MSE 595481.2661019148 Test RE 1.0000167291495796\n",
      "8 Train Loss 2.8614788 Test MSE 595477.8371219714 Test RE 1.0000138499303337\n",
      "9 Train Loss 2.846538 Test MSE 595461.4452781823 Test RE 1.000000086039722\n",
      "10 Train Loss 2.8335862 Test MSE 595470.4910923986 Test RE 1.0000076816453756\n",
      "11 Train Loss 2.8320897 Test MSE 595476.7832432191 Test RE 1.000012965015943\n",
      "12 Train Loss 2.8320181 Test MSE 595476.699143433 Test RE 1.000012894399521\n",
      "13 Train Loss 2.8319888 Test MSE 595476.5518414393 Test RE 1.0000127707138236\n",
      "14 Train Loss 2.831981 Test MSE 595476.4796701171 Test RE 1.0000127101134137\n",
      "15 Train Loss 2.8316777 Test MSE 595474.9987235041 Test RE 1.0000114665996833\n",
      "16 Train Loss 2.8297374 Test MSE 595472.0194865778 Test RE 1.000008965004469\n",
      "17 Train Loss 2.8289251 Test MSE 595470.2971314356 Test RE 1.0000075187804884\n",
      "18 Train Loss 2.8285444 Test MSE 595467.6004155494 Test RE 1.0000052544028795\n",
      "19 Train Loss 2.8281996 Test MSE 595465.8023811268 Test RE 1.0000037446270105\n",
      "20 Train Loss 2.8280847 Test MSE 595464.8057375038 Test RE 1.0000029077630226\n",
      "21 Train Loss 2.8280518 Test MSE 595464.2627602706 Test RE 1.0000024518343678\n",
      "22 Train Loss 2.8280473 Test MSE 595464.108085667 Test RE 1.0000023219567225\n",
      "23 Train Loss 2.8280416 Test MSE 595463.9801829533 Test RE 1.0000022145589667\n",
      "24 Train Loss 2.8280394 Test MSE 595463.8505730473 Test RE 1.0000021057276984\n",
      "25 Train Loss 2.8280368 Test MSE 595463.6675102694 Test RE 1.0000019520129286\n",
      "26 Train Loss 2.8280313 Test MSE 595463.4655429057 Test RE 1.000001782424265\n",
      "27 Train Loss 2.8280313 Test MSE 595463.4655429057 Test RE 1.000001782424265\n",
      "28 Train Loss 2.8280313 Test MSE 595463.4655429057 Test RE 1.000001782424265\n",
      "29 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "30 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "31 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "32 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "33 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "34 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "35 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "36 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "37 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "38 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "39 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "40 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "41 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "42 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "43 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "44 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "45 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "46 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "47 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "48 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "49 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "50 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "51 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "52 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "53 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "54 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "55 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "56 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "57 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "58 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "59 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "60 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "61 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "62 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "63 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "64 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "65 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "66 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "67 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "68 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "69 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "70 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "71 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "72 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "73 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "74 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "75 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "76 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "77 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "78 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "79 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "80 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "81 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "82 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "83 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "84 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "85 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "86 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "87 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "88 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "89 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "90 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "91 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "92 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "93 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "94 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "95 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "96 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "97 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "98 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "99 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "100 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "101 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "102 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "103 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "104 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "105 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "106 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "107 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "108 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "109 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "110 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "111 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "112 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "113 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "114 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "115 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "116 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "117 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "118 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "119 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "120 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "121 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "122 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "123 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "124 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "125 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "126 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "127 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "128 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "129 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "130 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "131 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "132 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "133 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "134 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "135 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "136 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "137 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "138 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "139 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "140 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "141 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "142 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "143 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "144 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "145 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "146 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "147 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "148 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "149 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "150 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "151 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "152 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "153 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "154 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "155 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "156 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "157 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "158 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "159 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "160 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "161 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "162 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "163 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "164 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "165 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "166 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "167 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "168 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "169 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "170 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "171 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "172 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "173 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "174 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "175 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "176 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "177 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "178 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "179 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "180 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "181 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "182 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "183 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "184 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "185 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "186 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "187 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "188 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "189 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "190 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "191 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "192 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "193 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "194 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "195 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "196 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "197 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "198 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "199 Train Loss 2.8280308 Test MSE 595463.4657069294 Test RE 1.0000017825619931\n",
      "Training time: 20.93\n",
      "Training time: 20.93\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 4.870314 Test MSE 595471.5039745998 Test RE 1.0000085321405439\n",
      "1 Train Loss 4.72297 Test MSE 595492.721548536 Test RE 1.0000263479099165\n",
      "2 Train Loss 4.2497215 Test MSE 595468.283641212 Test RE 1.0000058280940896\n",
      "3 Train Loss 4.089453 Test MSE 595495.597161479 Test RE 1.0000287624526418\n",
      "4 Train Loss 3.9285102 Test MSE 595523.8466361982 Test RE 1.0000524821512826\n",
      "5 Train Loss 3.59662 Test MSE 595521.0911778804 Test RE 1.0000501685528151\n",
      "6 Train Loss 3.09272 Test MSE 595490.9226497314 Test RE 1.0000248374401028\n",
      "7 Train Loss 2.9732897 Test MSE 595483.4732112939 Test RE 1.0000185823936552\n",
      "8 Train Loss 2.8381104 Test MSE 595471.3425875808 Test RE 1.0000083966274205\n",
      "9 Train Loss 2.8282034 Test MSE 595466.4955736473 Test RE 1.0000043266880723\n",
      "10 Train Loss 2.8277771 Test MSE 595464.577073838 Test RE 1.0000027157580962\n",
      "11 Train Loss 2.827772 Test MSE 595464.4900212227 Test RE 1.0000026426615105\n",
      "12 Train Loss 2.8277671 Test MSE 595464.4118416558 Test RE 1.0000025770154666\n",
      "13 Train Loss 2.8277671 Test MSE 595464.4118416558 Test RE 1.0000025770154666\n",
      "14 Train Loss 2.8277671 Test MSE 595464.4118416558 Test RE 1.0000025770154666\n",
      "15 Train Loss 2.8277671 Test MSE 595464.4118416558 Test RE 1.0000025770154666\n",
      "16 Train Loss 2.8277671 Test MSE 595464.4118416558 Test RE 1.0000025770154666\n",
      "17 Train Loss 2.8277671 Test MSE 595464.4118416558 Test RE 1.0000025770154666\n",
      "18 Train Loss 2.8277671 Test MSE 595464.4118416558 Test RE 1.0000025770154666\n",
      "19 Train Loss 2.8277671 Test MSE 595464.4118416558 Test RE 1.0000025770154666\n",
      "20 Train Loss 2.8277671 Test MSE 595464.4118416558 Test RE 1.0000025770154666\n",
      "21 Train Loss 2.8277671 Test MSE 595464.4118416558 Test RE 1.0000025770154666\n",
      "22 Train Loss 2.8277671 Test MSE 595464.4118416558 Test RE 1.0000025770154666\n",
      "23 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "24 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "25 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "26 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "27 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "28 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "29 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "30 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "31 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "32 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "33 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "34 Train Loss 2.8277655 Test MSE 595464.2099453792 Test RE 1.0000024074865996\n",
      "35 Train Loss 2.8277628 Test MSE 595464.2073555927 Test RE 1.000002405312\n",
      "36 Train Loss 2.8277612 Test MSE 595463.3909332682 Test RE 1.0000017197757762\n",
      "37 Train Loss 2.8277216 Test MSE 595463.2769099413 Test RE 1.0000016240322507\n",
      "38 Train Loss 2.827713 Test MSE 595463.191902207 Test RE 1.000001552652639\n",
      "39 Train Loss 2.8277054 Test MSE 595463.1051014157 Test RE 1.0000014797674206\n",
      "40 Train Loss 2.8277016 Test MSE 595463.0204468683 Test RE 1.0000014086843638\n",
      "41 Train Loss 2.8276987 Test MSE 595462.935732902 Test RE 1.0000013375514087\n",
      "42 Train Loss 2.8276944 Test MSE 595462.8578430604 Test RE 1.000001272148557\n",
      "43 Train Loss 2.8276925 Test MSE 595462.775621381 Test RE 1.0000012031083256\n",
      "44 Train Loss 2.8276925 Test MSE 595462.775621381 Test RE 1.0000012031083256\n",
      "45 Train Loss 2.8276925 Test MSE 595462.775621381 Test RE 1.0000012031083256\n",
      "46 Train Loss 2.8276925 Test MSE 595462.775621381 Test RE 1.0000012031083256\n",
      "47 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "48 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "49 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "50 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "51 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "52 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "53 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "54 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "55 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "56 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "57 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "58 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "59 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "60 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "61 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "62 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "63 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "64 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "65 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "66 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "67 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "68 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "69 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "70 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "71 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "72 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "73 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "74 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "75 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "76 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "77 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "78 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "79 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "80 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "81 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "82 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "83 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "84 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "85 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "86 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "87 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "88 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "89 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "90 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "91 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "92 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "93 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "94 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "95 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "96 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "97 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "98 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "99 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "100 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "101 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "102 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "103 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "104 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "105 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "106 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "107 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "108 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "109 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "110 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "111 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "112 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "113 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "114 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "115 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "116 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "117 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "118 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "119 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "120 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "121 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "122 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "123 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "124 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "125 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "126 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "127 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "128 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "129 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "130 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "131 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "132 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "133 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "134 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "135 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "136 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "137 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "138 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "139 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "140 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "141 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "142 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "143 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "144 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "145 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "146 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "147 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "148 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "149 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "150 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "151 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "152 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "153 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "154 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "155 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "156 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "157 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "158 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "159 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "160 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "161 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "162 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "163 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "164 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "165 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "166 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "167 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "168 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "169 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "170 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "171 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "172 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "173 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "174 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "175 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "176 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "177 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "178 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "179 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "180 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "181 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "182 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "183 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "184 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "185 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "186 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "187 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "188 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "189 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "190 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "191 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "192 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "193 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "194 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "195 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "196 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "197 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "198 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "199 Train Loss 2.8276923 Test MSE 595462.7756393342 Test RE 1.0000012031234005\n",
      "Training time: 18.68\n",
      "Training time: 18.68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 4.660324 Test MSE 595492.8836955882 Test RE 1.0000264840587794\n",
      "1 Train Loss 4.30291 Test MSE 595488.6119899522 Test RE 1.0000228972598886\n",
      "2 Train Loss 4.262522 Test MSE 595476.6088968855 Test RE 1.000012818621817\n",
      "3 Train Loss 4.071864 Test MSE 595526.8894278737 Test RE 1.0000550370006793\n",
      "4 Train Loss 3.8617926 Test MSE 595535.6606885317 Test RE 1.000062401664861\n",
      "5 Train Loss 3.4343612 Test MSE 595512.7990114782 Test RE 1.0000432060695392\n",
      "6 Train Loss 3.2666812 Test MSE 595515.144679755 Test RE 1.0000451756051378\n",
      "7 Train Loss 2.901129 Test MSE 595452.5358116532 Test RE 0.9999926048663456\n",
      "8 Train Loss 2.8722467 Test MSE 595425.4729200929 Test RE 0.9999698801340612\n",
      "9 Train Loss 2.8652892 Test MSE 595425.1463694443 Test RE 0.99996960592606\n",
      "10 Train Loss 2.8446984 Test MSE 595440.476550222 Test RE 0.9999824787583999\n",
      "11 Train Loss 2.834814 Test MSE 595457.8424426909 Test RE 0.9999970607882305\n",
      "12 Train Loss 2.8316374 Test MSE 595463.5645541024 Test RE 1.0000018655623375\n",
      "13 Train Loss 2.829806 Test MSE 595463.2706399253 Test RE 1.0000016187674208\n",
      "14 Train Loss 2.8289442 Test MSE 595460.3897914812 Test RE 0.9999991997629799\n",
      "15 Train Loss 2.8285463 Test MSE 595459.4545106544 Test RE 0.9999984144206954\n",
      "16 Train Loss 2.8283765 Test MSE 595458.906577689 Test RE 0.9999979543287291\n",
      "17 Train Loss 2.828344 Test MSE 595458.7333854662 Test RE 0.9999978089014973\n",
      "18 Train Loss 2.828335 Test MSE 595458.6781259975 Test RE 0.9999977625008435\n",
      "19 Train Loss 2.8283274 Test MSE 595458.6267489861 Test RE 0.9999977193602365\n",
      "20 Train Loss 2.8283198 Test MSE 595458.5877194345 Test RE 0.9999976865876296\n",
      "21 Train Loss 2.8283124 Test MSE 595458.5164891972 Test RE 0.9999976267765225\n",
      "22 Train Loss 2.8283029 Test MSE 595458.469276625 Test RE 0.9999975871327352\n",
      "23 Train Loss 2.8282995 Test MSE 595458.4323070613 Test RE 0.9999975560898694\n",
      "24 Train Loss 2.828293 Test MSE 595458.3926167939 Test RE 0.9999975227624623\n",
      "25 Train Loss 2.828288 Test MSE 595458.3643065984 Test RE 0.9999974989907546\n",
      "26 Train Loss 2.8282826 Test MSE 595458.3337889777 Test RE 0.9999974733654998\n",
      "27 Train Loss 2.8282778 Test MSE 595458.3134283661 Test RE 0.9999974562689546\n",
      "28 Train Loss 2.828272 Test MSE 595458.2941845331 Test RE 0.9999974401101542\n",
      "29 Train Loss 2.8282666 Test MSE 595458.2759585485 Test RE 0.9999974248060278\n",
      "30 Train Loss 2.8282583 Test MSE 595458.2689461504 Test RE 0.9999974189178066\n",
      "31 Train Loss 2.8282518 Test MSE 595458.2434578682 Test RE 0.9999973975156211\n",
      "32 Train Loss 2.8282468 Test MSE 595458.3565986163 Test RE 0.9999974925184609\n",
      "33 Train Loss 2.828237 Test MSE 595458.3345703478 Test RE 0.9999974740216061\n",
      "34 Train Loss 2.8279753 Test MSE 595459.144242453 Test RE 0.9999981538926717\n",
      "35 Train Loss 2.8277242 Test MSE 595461.0954854623 Test RE 0.9999997923239793\n",
      "36 Train Loss 2.8276963 Test MSE 595461.33686483 Test RE 0.9999999950066523\n",
      "37 Train Loss 2.8276894 Test MSE 595461.3649596424 Test RE 1.000000018597447\n",
      "38 Train Loss 2.8276865 Test MSE 595461.4309521592 Test RE 1.0000000740103754\n",
      "39 Train Loss 2.827684 Test MSE 595461.4462775328 Test RE 1.0000000868788619\n",
      "40 Train Loss 2.827684 Test MSE 595461.4462775328 Test RE 1.0000000868788619\n",
      "41 Train Loss 2.827684 Test MSE 595461.4462775328 Test RE 1.0000000868788619\n",
      "42 Train Loss 2.8276827 Test MSE 595461.6241298945 Test RE 1.0000002362188105\n",
      "43 Train Loss 2.8276825 Test MSE 595461.6758035359 Test RE 1.0000002796083847\n",
      "44 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "45 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "46 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "47 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "48 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "49 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "50 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "51 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "52 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "53 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "54 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "55 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "56 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "57 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "58 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "59 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "60 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "61 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "62 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "63 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "64 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "65 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "66 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "67 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "68 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "69 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "70 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "71 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "72 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "73 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "74 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "75 Train Loss 2.8276803 Test MSE 595461.605632571 Test RE 1.0000002206868879\n",
      "76 Train Loss 2.8276794 Test MSE 595461.4980808477 Test RE 1.000000130377327\n",
      "77 Train Loss 2.8276794 Test MSE 595461.4980808477 Test RE 1.000000130377327\n",
      "78 Train Loss 2.8276794 Test MSE 595461.4980808477 Test RE 1.000000130377327\n",
      "79 Train Loss 2.8276794 Test MSE 595461.4980808477 Test RE 1.000000130377327\n",
      "80 Train Loss 2.8276794 Test MSE 595461.4980808477 Test RE 1.000000130377327\n",
      "81 Train Loss 2.8276794 Test MSE 595461.4980808477 Test RE 1.000000130377327\n",
      "82 Train Loss 2.8276794 Test MSE 595461.4980808477 Test RE 1.000000130377327\n",
      "83 Train Loss 2.8276792 Test MSE 595461.526173571 Test RE 1.0000001539663643\n",
      "84 Train Loss 2.827679 Test MSE 595461.5319711098 Test RE 1.00000015883447\n",
      "85 Train Loss 2.8276763 Test MSE 595461.5104102485 Test RE 1.0000001407301395\n",
      "86 Train Loss 2.8276694 Test MSE 595461.3986982901 Test RE 1.0000000469272845\n",
      "87 Train Loss 2.8276672 Test MSE 595461.3557569353 Test RE 1.000000010870071\n",
      "88 Train Loss 2.8276672 Test MSE 595461.3557569353 Test RE 1.000000010870071\n",
      "89 Train Loss 2.8276672 Test MSE 595461.3557569353 Test RE 1.000000010870071\n",
      "90 Train Loss 2.8276672 Test MSE 595461.3557569353 Test RE 1.000000010870071\n",
      "91 Train Loss 2.827661 Test MSE 595461.3439478589 Test RE 1.000000000954166\n",
      "92 Train Loss 2.827661 Test MSE 595461.3439478589 Test RE 1.000000000954166\n",
      "93 Train Loss 2.827661 Test MSE 595461.3439478589 Test RE 1.000000000954166\n",
      "94 Train Loss 2.8276584 Test MSE 595461.3975908222 Test RE 1.0000000459973604\n",
      "95 Train Loss 2.8276563 Test MSE 595461.0268968886 Test RE 0.9999997347311642\n",
      "96 Train Loss 2.8276503 Test MSE 595461.2724088307 Test RE 0.9999999408839103\n",
      "97 Train Loss 2.8276455 Test MSE 595461.2294128458 Test RE 0.9999999047808207\n",
      "98 Train Loss 2.8276367 Test MSE 595461.0331291456 Test RE 0.9999997399642988\n",
      "99 Train Loss 2.8276331 Test MSE 595460.9765427822 Test RE 0.9999996924495608\n",
      "100 Train Loss 2.82763 Test MSE 595460.9465950279 Test RE 0.9999996673028705\n",
      "101 Train Loss 2.827625 Test MSE 595460.924968 Test RE 0.9999996491429718\n",
      "102 Train Loss 2.8276203 Test MSE 595460.9204794868 Test RE 0.999999645374033\n",
      "103 Train Loss 2.8276167 Test MSE 595460.9345170646 Test RE 0.9999996571611816\n",
      "104 Train Loss 2.8276112 Test MSE 595460.9292541073 Test RE 0.9999996527419535\n",
      "105 Train Loss 2.8276062 Test MSE 595461.0087192035 Test RE 0.9999997194676291\n",
      "106 Train Loss 2.827599 Test MSE 595461.0319681228 Test RE 0.9999997389894051\n",
      "107 Train Loss 2.8275945 Test MSE 595461.0501731217 Test RE 0.9999997542758747\n",
      "108 Train Loss 2.827587 Test MSE 595461.0873561412 Test RE 0.9999997854979081\n",
      "109 Train Loss 2.8275805 Test MSE 595461.0243124141 Test RE 0.9999997325610189\n",
      "110 Train Loss 2.8275766 Test MSE 595460.9818524129 Test RE 0.9999996969079795\n",
      "111 Train Loss 2.8275733 Test MSE 595460.9397176873 Test RE 0.9999996615280683\n",
      "112 Train Loss 2.827569 Test MSE 595460.9118257422 Test RE 0.9999996381076102\n",
      "113 Train Loss 2.8275661 Test MSE 595460.7685503367 Test RE 0.9999995178013404\n",
      "114 Train Loss 2.8275607 Test MSE 595460.7799027686 Test RE 0.9999995273338125\n",
      "115 Train Loss 2.8275583 Test MSE 595460.7891722849 Test RE 0.9999995351172907\n",
      "116 Train Loss 2.8275552 Test MSE 595460.7430095064 Test RE 0.9999994963550759\n",
      "117 Train Loss 2.8275526 Test MSE 595460.7062829394 Test RE 0.9999994655163099\n",
      "118 Train Loss 2.8275476 Test MSE 595460.6436248677 Test RE 0.9999994129032328\n",
      "119 Train Loss 2.8275454 Test MSE 595460.6522495066 Test RE 0.9999994201452176\n",
      "120 Train Loss 2.8275454 Test MSE 595460.6522495066 Test RE 0.9999994201452176\n",
      "121 Train Loss 2.8275435 Test MSE 595460.6705610693 Test RE 0.9999994355211722\n",
      "122 Train Loss 2.827542 Test MSE 595460.7263047071 Test RE 0.999999482328298\n",
      "123 Train Loss 2.8275378 Test MSE 595460.7074990609 Test RE 0.9999994665374695\n",
      "124 Train Loss 2.8275378 Test MSE 595460.7074990609 Test RE 0.9999994665374695\n",
      "125 Train Loss 2.8275378 Test MSE 595460.7074990609 Test RE 0.9999994665374695\n",
      "126 Train Loss 2.8275352 Test MSE 595460.5611596057 Test RE 0.9999993436583405\n",
      "127 Train Loss 2.8275352 Test MSE 595460.5611596057 Test RE 0.9999993436583405\n",
      "128 Train Loss 2.8275352 Test MSE 595460.5611596057 Test RE 0.9999993436583405\n",
      "129 Train Loss 2.8275352 Test MSE 595460.5611596057 Test RE 0.9999993436583405\n",
      "130 Train Loss 2.8275352 Test MSE 595460.5611596057 Test RE 0.9999993436583405\n",
      "131 Train Loss 2.8275352 Test MSE 595460.5611596057 Test RE 0.9999993436583405\n",
      "132 Train Loss 2.8275352 Test MSE 595460.5611596057 Test RE 0.9999993436583405\n",
      "133 Train Loss 2.827534 Test MSE 595460.6461355687 Test RE 0.9999994150114322\n",
      "134 Train Loss 2.827532 Test MSE 595460.6108972495 Test RE 0.999999385422324\n",
      "135 Train Loss 2.8275304 Test MSE 595460.6329736663 Test RE 0.9999994039595729\n",
      "136 Train Loss 2.8275287 Test MSE 595460.5410926347 Test RE 0.9999993268083932\n",
      "137 Train Loss 2.8275273 Test MSE 595460.472772079 Test RE 0.9999992694406024\n",
      "138 Train Loss 2.8275273 Test MSE 595460.472772079 Test RE 0.9999992694406024\n",
      "139 Train Loss 2.8275223 Test MSE 595460.2593359228 Test RE 0.9999990902213014\n",
      "140 Train Loss 2.8275223 Test MSE 595460.2593359228 Test RE 0.9999990902213014\n",
      "141 Train Loss 2.8275223 Test MSE 595460.2593359228 Test RE 0.9999990902213014\n",
      "142 Train Loss 2.827521 Test MSE 595460.1225882259 Test RE 0.9999989753961906\n",
      "143 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "144 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "145 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "146 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "147 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "148 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "149 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "150 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "151 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "152 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "153 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "154 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "155 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "156 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "157 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "158 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "159 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "160 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "161 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "162 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "163 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "164 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "165 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "166 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "167 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "168 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "169 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "170 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "171 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "172 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "173 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "174 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "175 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "176 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "177 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "178 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "179 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "180 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "181 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "182 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "183 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "184 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "185 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "186 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "187 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "188 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "189 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "190 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "191 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "192 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "193 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "194 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "195 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "196 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "197 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "198 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "199 Train Loss 2.82752 Test MSE 595460.0857448371 Test RE 0.9999989444593148\n",
      "Training time: 14.90\n",
      "Training time: 14.90\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 4.878017 Test MSE 595467.8030906295 Test RE 1.0000054245852097\n",
      "1 Train Loss 4.8164525 Test MSE 595489.6009679665 Test RE 1.000023727670604\n",
      "2 Train Loss 4.3984647 Test MSE 595480.357442556 Test RE 1.000015966174354\n",
      "3 Train Loss 4.16921 Test MSE 595456.6994677362 Test RE 0.9999961010459428\n",
      "4 Train Loss 3.8115993 Test MSE 595547.4422630079 Test RE 1.0000722938108493\n",
      "5 Train Loss 3.1518915 Test MSE 595512.3659831169 Test RE 1.0000428424777323\n",
      "6 Train Loss 2.9145224 Test MSE 595458.9453260595 Test RE 0.9999979868652233\n",
      "7 Train Loss 2.8402255 Test MSE 595455.5685439701 Test RE 0.9999951514219863\n",
      "8 Train Loss 2.8338494 Test MSE 595448.2863097987 Test RE 0.9999890365903241\n",
      "9 Train Loss 2.8285425 Test MSE 595452.6057049509 Test RE 0.9999926635551364\n",
      "10 Train Loss 2.8275878 Test MSE 595456.5338965342 Test RE 0.9999959620177243\n",
      "11 Train Loss 2.8275812 Test MSE 595456.6392978821 Test RE 0.9999960505220163\n",
      "12 Train Loss 2.8275752 Test MSE 595456.7303136255 Test RE 0.9999961269468761\n",
      "13 Train Loss 2.8275714 Test MSE 595456.7906608555 Test RE 0.9999961776197394\n",
      "14 Train Loss 2.8275695 Test MSE 595456.8418169068 Test RE 0.9999962205748751\n",
      "15 Train Loss 2.8275695 Test MSE 595456.8418169068 Test RE 0.9999962205748751\n",
      "16 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "17 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "18 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "19 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "20 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "21 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "22 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "23 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "24 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "25 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "26 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "27 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "28 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "29 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "30 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "31 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "32 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "33 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "34 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "35 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "36 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "37 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "38 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "39 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "40 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "41 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "42 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "43 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "44 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "45 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "46 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "47 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "48 Train Loss 2.827565 Test MSE 595456.9583150431 Test RE 0.999996318396986\n",
      "49 Train Loss 2.8275642 Test MSE 595456.9611401223 Test RE 0.9999963207691714\n",
      "50 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "51 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "52 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "53 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "54 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "55 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "56 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "57 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "58 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "59 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "60 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "61 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "62 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "63 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "64 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "65 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "66 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "67 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "68 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "69 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "70 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "71 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "72 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "73 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "74 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "75 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "76 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "77 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "78 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "79 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "80 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "81 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "82 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "83 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "84 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "85 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "86 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "87 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "88 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "89 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "90 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "91 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "92 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "93 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "94 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "95 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "96 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "97 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "98 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "99 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "100 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "101 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "102 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "103 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "104 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "105 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "106 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "107 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "108 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "109 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "110 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "111 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "112 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "113 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "114 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "115 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "116 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "117 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "118 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "119 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "120 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "121 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "122 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "123 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "124 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "125 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "126 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "127 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "128 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "129 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "130 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "131 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "132 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "133 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "134 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "135 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "136 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "137 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "138 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "139 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "140 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "141 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "142 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "143 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "144 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "145 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "146 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "147 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "148 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "149 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "150 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "151 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "152 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "153 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "154 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "155 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "156 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "157 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "158 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "159 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "160 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "161 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "162 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "163 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "164 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "165 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "166 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "167 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "168 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "169 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "170 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "171 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "172 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "173 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "174 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "175 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "176 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "177 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "178 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "179 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "180 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "181 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "182 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "183 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "184 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "185 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "186 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "187 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "188 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "189 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "190 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "191 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "192 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "193 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "194 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "195 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "196 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "197 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "198 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "199 Train Loss 2.827564 Test MSE 595456.9290875448 Test RE 0.9999962938550014\n",
      "Training time: 7.93\n",
      "Training time: 7.93\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 4.898553 Test MSE 595473.94628806 Test RE 1.0000105828950954\n",
      "1 Train Loss 4.487222 Test MSE 595471.3519785244 Test RE 1.0000084045127893\n",
      "2 Train Loss 4.375609 Test MSE 595464.7085005397 Test RE 1.0000028261148297\n",
      "3 Train Loss 4.0533676 Test MSE 595509.5166506431 Test RE 1.0000404500354279\n",
      "4 Train Loss 4.014158 Test MSE 595534.4615504366 Test RE 1.0000613948288255\n",
      "5 Train Loss 3.700537 Test MSE 595555.8496416989 Test RE 1.0000793528259857\n",
      "6 Train Loss 3.4703798 Test MSE 595507.7902280388 Test RE 1.0000390004417257\n",
      "7 Train Loss 3.0227566 Test MSE 595470.6539070719 Test RE 1.0000078183573666\n",
      "8 Train Loss 2.8616278 Test MSE 595473.4533751544 Test RE 1.0000101690077818\n",
      "9 Train Loss 2.8339286 Test MSE 595472.1390134811 Test RE 1.0000090653685205\n",
      "10 Train Loss 2.8282812 Test MSE 595464.854339964 Test RE 1.0000029485736635\n",
      "11 Train Loss 2.8282003 Test MSE 595464.2178466144 Test RE 1.000002414121133\n",
      "12 Train Loss 2.8281915 Test MSE 595464.130093726 Test RE 1.000002340436518\n",
      "13 Train Loss 2.8281837 Test MSE 595464.0451673043 Test RE 1.0000022691252337\n",
      "14 Train Loss 2.8281744 Test MSE 595463.9456494818 Test RE 1.00000218556179\n",
      "15 Train Loss 2.827823 Test MSE 595461.6072949943 Test RE 1.0000002220827995\n",
      "16 Train Loss 2.827787 Test MSE 595461.2920120957 Test RE 0.99999995734448\n",
      "17 Train Loss 2.8277826 Test MSE 595461.2513653929 Test RE 0.9999999232140486\n",
      "18 Train Loss 2.827781 Test MSE 595461.2256211672 Test RE 0.9999999015970046\n",
      "19 Train Loss 2.827781 Test MSE 595461.2256211672 Test RE 0.9999999015970046\n",
      "20 Train Loss 2.827781 Test MSE 595461.2256211672 Test RE 0.9999999015970046\n",
      "21 Train Loss 2.827781 Test MSE 595461.2256211672 Test RE 0.9999999015970046\n",
      "22 Train Loss 2.8277788 Test MSE 595461.1400484928 Test RE 0.9999998297428977\n",
      "23 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "24 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "25 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "26 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "27 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "28 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "29 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "30 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "31 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "32 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "33 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "34 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "35 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "36 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "37 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "38 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "39 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "40 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "41 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "42 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "43 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "44 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "45 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "46 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "47 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "48 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "49 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "50 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "51 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "52 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "53 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "54 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "55 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "56 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "57 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "58 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "59 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "60 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "61 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "62 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "63 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "64 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "65 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "66 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "67 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "68 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "69 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "70 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "71 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "72 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "73 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "74 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "75 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "76 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "77 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "78 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "79 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "80 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "81 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "82 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "83 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "84 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "85 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "86 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "87 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "88 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "89 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "90 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "91 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "92 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "93 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "94 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "95 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "96 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "97 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "98 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "99 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "100 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "101 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "102 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "103 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "104 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "105 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "106 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "107 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "108 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "109 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "110 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "111 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "112 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "113 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "114 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "115 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "116 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "117 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "118 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "119 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "120 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "121 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "122 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "123 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "124 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "125 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "126 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "127 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "128 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "129 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "130 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "131 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "132 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "133 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "134 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "135 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "136 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "137 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "138 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "139 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "140 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "141 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "142 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "143 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "144 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "145 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "146 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "147 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "148 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "149 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "150 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "151 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "152 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "153 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "154 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "155 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "156 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "157 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "158 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "159 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "160 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "161 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "162 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "163 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "164 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "165 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "166 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "167 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "168 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "169 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "170 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "171 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "172 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "173 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "174 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "175 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "176 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "177 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "178 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "179 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "180 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "181 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "182 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "183 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "184 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "185 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "186 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "187 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "188 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "189 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "190 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "191 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "192 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "193 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "194 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "195 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "196 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "197 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "198 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "199 Train Loss 2.8277733 Test MSE 595460.8489358203 Test RE 0.9999995852998612\n",
      "Training time: 8.32\n",
      "Training time: 8.32\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 4.8444023 Test MSE 595483.418094697 Test RE 1.0000185361139302\n",
      "1 Train Loss 4.6866565 Test MSE 595452.6350923518 Test RE 0.999992688231479\n",
      "2 Train Loss 4.403357 Test MSE 595481.4538292612 Test RE 1.0000168867787802\n",
      "3 Train Loss 4.248532 Test MSE 595501.4783506115 Test RE 1.0000337006451299\n",
      "4 Train Loss 3.0904644 Test MSE 595491.0473734179 Test RE 1.0000249421661138\n",
      "5 Train Loss 2.8475082 Test MSE 595451.997242134 Test RE 0.9999921526341138\n",
      "6 Train Loss 2.8294404 Test MSE 595458.4428256887 Test RE 0.9999975649222252\n",
      "7 Train Loss 2.8283985 Test MSE 595459.0018736862 Test RE 0.9999980343475158\n",
      "8 Train Loss 2.827726 Test MSE 595461.0932560152 Test RE 0.9999997904519454\n",
      "9 Train Loss 2.8277173 Test MSE 595461.14443248 Test RE 0.9999998334240668\n",
      "10 Train Loss 2.8277087 Test MSE 595461.1941771993 Test RE 0.9999998751939712\n",
      "11 Train Loss 2.8277037 Test MSE 595461.2187345998 Test RE 0.9999998958144559\n",
      "12 Train Loss 2.8276973 Test MSE 595461.2432171702 Test RE 0.999999916372107\n",
      "13 Train Loss 2.8276927 Test MSE 595461.2518875853 Test RE 0.9999999236525255\n",
      "14 Train Loss 2.8276896 Test MSE 595461.2608605856 Test RE 0.9999999311870206\n",
      "15 Train Loss 2.8276837 Test MSE 595461.2626484117 Test RE 0.9999999326882316\n",
      "16 Train Loss 2.8276806 Test MSE 595461.2626381629 Test RE 0.9999999326796258\n",
      "17 Train Loss 2.827672 Test MSE 595461.2726543195 Test RE 0.9999999410900436\n",
      "18 Train Loss 2.8276653 Test MSE 595461.2731659746 Test RE 0.9999999415196725\n",
      "19 Train Loss 2.8276467 Test MSE 595461.268877461 Test RE 0.9999999379186716\n",
      "20 Train Loss 2.827638 Test MSE 595461.1555176778 Test RE 0.9999998427321436\n",
      "21 Train Loss 2.8276336 Test MSE 595461.098826351 Test RE 0.9999997951292743\n",
      "22 Train Loss 2.8276293 Test MSE 595460.9931767578 Test RE 0.9999997064168659\n",
      "23 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "24 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "25 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "26 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "27 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "28 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "29 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "30 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "31 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "32 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "33 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "34 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "35 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "36 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "37 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "38 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "39 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "40 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "41 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "42 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "43 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "44 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "45 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "46 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "47 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "48 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "49 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "50 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "51 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "52 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "53 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "54 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "55 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "56 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "57 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "58 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "59 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "60 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "61 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "62 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "63 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "64 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "65 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "66 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "67 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "68 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "69 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "70 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "71 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "72 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "73 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "74 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "75 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "76 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "77 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "78 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "79 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "80 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "81 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "82 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "83 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "84 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "85 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "86 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "87 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "88 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "89 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "90 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "91 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "92 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "93 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "94 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "95 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "96 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "97 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "98 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "99 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "100 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "101 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "102 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "103 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "104 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "105 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "106 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "107 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "108 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "109 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "110 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "111 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "112 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "113 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "114 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "115 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "116 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "117 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "118 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "119 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "120 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "121 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "122 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "123 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "124 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "125 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "126 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "127 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "128 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "129 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "130 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "131 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "132 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "133 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "134 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "135 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "136 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "137 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "138 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "139 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "140 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "141 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "142 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "143 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "144 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "145 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "146 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "147 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "148 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "149 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "150 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "151 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "152 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "153 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "154 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "155 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "156 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "157 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "158 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "159 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "160 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "161 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "162 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "163 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "164 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "165 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "166 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "167 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "168 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "169 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "170 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "171 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "172 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "173 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "174 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "175 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "176 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "177 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "178 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "179 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "180 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "181 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "182 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "183 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "184 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "185 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "186 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "187 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "188 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "189 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "190 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "191 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "192 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "193 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "194 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "195 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "196 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "197 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "198 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "199 Train Loss 2.8276258 Test MSE 595460.9556157314 Test RE 0.999999674877423\n",
      "Training time: 25.57\n",
      "Training time: 25.57\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 4.7637143 Test MSE 595482.851744887 Test RE 1.0000180605671516\n",
      "1 Train Loss 4.625717 Test MSE 595508.8112679742 Test RE 1.0000398577599132\n",
      "2 Train Loss 4.261043 Test MSE 595467.4788961216 Test RE 1.0000051523653608\n",
      "3 Train Loss 4.085713 Test MSE 595495.889440075 Test RE 1.0000290078675271\n",
      "4 Train Loss 3.8152788 Test MSE 595535.0453872591 Test RE 1.0000618850376728\n",
      "5 Train Loss 3.5516999 Test MSE 595492.0773540208 Test RE 1.0000258070035046\n",
      "6 Train Loss 2.8717296 Test MSE 595480.7515618012 Test RE 1.000016297105062\n",
      "7 Train Loss 2.8477166 Test MSE 595476.5277485602 Test RE 1.0000127504836507\n",
      "8 Train Loss 2.8403604 Test MSE 595481.1591102751 Test RE 1.0000166393117957\n",
      "9 Train Loss 2.8318293 Test MSE 595472.6714187941 Test RE 1.000009512417161\n",
      "10 Train Loss 2.8291922 Test MSE 595466.7071910326 Test RE 1.000004504379247\n",
      "11 Train Loss 2.8282077 Test MSE 595463.3867648785 Test RE 1.0000017162756476\n",
      "12 Train Loss 2.8278418 Test MSE 595463.4883719136 Test RE 1.000001801593408\n",
      "13 Train Loss 2.8278332 Test MSE 595463.4919281593 Test RE 1.000001804579529\n",
      "14 Train Loss 2.827827 Test MSE 595463.4789923285 Test RE 1.0000017937175247\n",
      "15 Train Loss 2.8278227 Test MSE 595463.4742243368 Test RE 1.0000017897139204\n",
      "16 Train Loss 2.827818 Test MSE 595463.4578954752 Test RE 1.0000017760028432\n",
      "17 Train Loss 2.8278139 Test MSE 595463.4442215158 Test RE 1.0000017645210442\n",
      "18 Train Loss 2.8278093 Test MSE 595463.4189626348 Test RE 1.0000017433115762\n",
      "19 Train Loss 2.8278027 Test MSE 595463.3837063442 Test RE 1.0000017137074464\n",
      "20 Train Loss 2.827796 Test MSE 595463.3296716432 Test RE 1.0000016683353914\n",
      "21 Train Loss 2.8276696 Test MSE 595462.2101122625 Test RE 1.0000007282592196\n",
      "22 Train Loss 2.8276517 Test MSE 595461.9916512645 Test RE 1.000000544820898\n",
      "23 Train Loss 2.8276463 Test MSE 595461.8779298561 Test RE 1.0000004493307761\n",
      "24 Train Loss 2.8276415 Test MSE 595461.8025688964 Test RE 1.0000003860513298\n",
      "25 Train Loss 2.827639 Test MSE 595461.7171100255 Test RE 1.0000003142928169\n",
      "26 Train Loss 2.827639 Test MSE 595461.7171100255 Test RE 1.0000003142928169\n",
      "27 Train Loss 2.827635 Test MSE 595461.505470715 Test RE 1.0000001365824875\n",
      "28 Train Loss 2.8276348 Test MSE 595461.5047405395 Test RE 1.0000001359693702\n",
      "29 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "30 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "31 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "32 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "33 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "34 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "35 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "36 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "37 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "38 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "39 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "40 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "41 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "42 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "43 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "44 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "45 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "46 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "47 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "48 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "49 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "50 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "51 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "52 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "53 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "54 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "55 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "56 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "57 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "58 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "59 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "60 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "61 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "62 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "63 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "64 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "65 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "66 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "67 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "68 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "69 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "70 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "71 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "72 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "73 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "74 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "75 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "76 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "77 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "78 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "79 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "80 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "81 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "82 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "83 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "84 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "85 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "86 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "87 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "88 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "89 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "90 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "91 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "92 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "93 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "94 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "95 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "96 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "97 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "98 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "99 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "100 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "101 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "102 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "103 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "104 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "105 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "106 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "107 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "108 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "109 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "110 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "111 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "112 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "113 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "114 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "115 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "116 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "117 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "118 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "119 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "120 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "121 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "122 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "123 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "124 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "125 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "126 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "127 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "128 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "129 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "130 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "131 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "132 Train Loss 2.827632 Test MSE 595461.451599893 Test RE 1.0000000913479679\n",
      "133 Train Loss 2.8276315 Test MSE 595461.4477721872 Test RE 1.0000000881339006\n",
      "134 Train Loss 2.8276315 Test MSE 595461.4477721872 Test RE 1.0000000881339006\n",
      "135 Train Loss 2.8276315 Test MSE 595461.4477721872 Test RE 1.0000000881339006\n",
      "136 Train Loss 2.8276315 Test MSE 595461.4477721872 Test RE 1.0000000881339006\n",
      "137 Train Loss 2.8276315 Test MSE 595461.4477721872 Test RE 1.0000000881339006\n",
      "138 Train Loss 2.8276315 Test MSE 595461.4477721872 Test RE 1.0000000881339006\n",
      "139 Train Loss 2.8276315 Test MSE 595461.4477721872 Test RE 1.0000000881339006\n",
      "140 Train Loss 2.8276315 Test MSE 595461.4477721872 Test RE 1.0000000881339006\n",
      "141 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "142 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "143 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "144 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "145 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "146 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "147 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "148 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "149 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "150 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "151 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "152 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "153 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "154 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "155 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "156 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "157 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "158 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "159 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "160 Train Loss 2.8276312 Test MSE 595461.4467774306 Test RE 1.0000000872986186\n",
      "161 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "162 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "163 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "164 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "165 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "166 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "167 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "168 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "169 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "170 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "171 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "172 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "173 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "174 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "175 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "176 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "177 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "178 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "179 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "180 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "181 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "182 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "183 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "184 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "185 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "186 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "187 Train Loss 2.827631 Test MSE 595461.4349617563 Test RE 1.000000077377174\n",
      "188 Train Loss 2.8276308 Test MSE 595461.4335916146 Test RE 1.0000000762266863\n",
      "189 Train Loss 2.8276298 Test MSE 595461.3674210955 Test RE 1.000000020664292\n",
      "190 Train Loss 2.8276298 Test MSE 595461.3674210955 Test RE 1.000000020664292\n",
      "191 Train Loss 2.8276236 Test MSE 595461.148577452 Test RE 0.9999998369045385\n",
      "192 Train Loss 2.8276215 Test MSE 595461.1401558882 Test RE 0.999999829833076\n",
      "193 Train Loss 2.827615 Test MSE 595461.1342716024 Test RE 0.999999824892128\n",
      "194 Train Loss 2.82761 Test MSE 595461.137110203 Test RE 0.9999998272756591\n",
      "195 Train Loss 2.827606 Test MSE 595461.1298290031 Test RE 0.9999998211617435\n",
      "196 Train Loss 2.8276017 Test MSE 595461.1274687403 Test RE 0.9999998191798656\n",
      "197 Train Loss 2.8276017 Test MSE 595461.1274687403 Test RE 0.9999998191798656\n",
      "198 Train Loss 2.8275976 Test MSE 595461.0922437522 Test RE 0.999999789601963\n",
      "199 Train Loss 2.8275945 Test MSE 595460.8720162284 Test RE 0.9999996046801433\n",
      "Training time: 17.61\n",
      "Training time: 17.61\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    \n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "    \n",
    "    \n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "   \n",
    "\n",
    "    start_time = time.time()\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    " \n",
    "    \n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"label\": label, \"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f23d8045250>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.plot(u_pred,'r')\n",
    "plt.plot(y_true,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999995205395203\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
