{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(1*x) + np.exp(-2.0*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"low\"\n",
    "label = \"1D_SODE_tanh\" + level\n",
    "\n",
    "u_coeff = 2.0\n",
    "fo_val = -1.0\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "\n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "    \n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,0)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 3.0186996 Test MSE 15.269473895029078 Test RE 1.0247246932252934\n",
      "1 Train Loss 1.6129767 Test MSE 12.862489305701121 Test RE 0.9404975707620683\n",
      "2 Train Loss 1.464195 Test MSE 12.091884517006626 Test RE 0.9118893848771473\n",
      "3 Train Loss 1.3675634 Test MSE 10.817006863343893 Test RE 0.8624793732303109\n",
      "4 Train Loss 1.1930999 Test MSE 9.23105921172134 Test RE 0.7967479104222188\n",
      "5 Train Loss 0.69925445 Test MSE 4.421824235186012 Test RE 0.5514369997845291\n",
      "6 Train Loss 0.3199921 Test MSE 2.139432831701288 Test RE 0.38356987666767794\n",
      "7 Train Loss 0.05130168 Test MSE 0.2556222870103036 Test RE 0.13258503965209803\n",
      "8 Train Loss 0.01979002 Test MSE 0.00037791462387451685 Test RE 0.0050979082352335245\n",
      "9 Train Loss 0.01158637 Test MSE 0.006972466233054075 Test RE 0.02189718939103682\n",
      "10 Train Loss 0.0037381572 Test MSE 0.008528838966904151 Test RE 0.024218103008612053\n",
      "11 Train Loss 0.0018955239 Test MSE 0.0007617311940124661 Test RE 0.007237624297276049\n",
      "12 Train Loss 0.0005565381 Test MSE 4.659971784054758e-05 Test RE 0.0017901392230437192\n",
      "13 Train Loss 0.00014807095 Test MSE 0.00013449949802344968 Test RE 0.0030412736314806435\n",
      "14 Train Loss 0.00013000479 Test MSE 4.9523561429286186e-05 Test RE 0.0018454449696371816\n",
      "15 Train Loss 0.00012568671 Test MSE 2.8205049285166245e-05 Test RE 0.001392703273105049\n",
      "16 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "17 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "18 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "19 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "20 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "21 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "22 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "23 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "24 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "25 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "26 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "27 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "28 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "29 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "30 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "31 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "32 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "33 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "34 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "35 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "36 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "37 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "38 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "39 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "40 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "41 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "42 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "43 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "44 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "45 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "46 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "47 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "48 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "49 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "50 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "51 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "52 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "53 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "54 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "55 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "56 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "57 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "58 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "59 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "60 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "61 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "62 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "63 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "64 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "65 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "66 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "67 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "68 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "69 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "70 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "71 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "72 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "73 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "74 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "75 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "76 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "77 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "78 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "79 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "80 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "81 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "82 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "83 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "84 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "85 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "86 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "87 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "88 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "89 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "90 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "91 Train Loss 0.00012298602 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "92 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "93 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "94 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "95 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "96 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "97 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "98 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "99 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "100 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "101 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "102 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "103 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "104 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "105 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "106 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "107 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "108 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "109 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "110 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "111 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "112 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "113 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "114 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "115 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "116 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "117 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "118 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "119 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "120 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "121 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "122 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "123 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "124 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "125 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "126 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "127 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "128 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "129 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "130 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "131 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "132 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "133 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "134 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "135 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "136 Train Loss 0.00012298602 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "137 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "138 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "139 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "140 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "141 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "142 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "143 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "144 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "145 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "146 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "147 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "148 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "149 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "150 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "151 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "152 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "153 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "154 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "155 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "156 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "157 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "158 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "159 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "160 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "161 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "162 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "163 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "164 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "165 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "166 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "167 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "168 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "169 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "170 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "171 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "172 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "173 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "174 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "175 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "176 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "177 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "178 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "179 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "180 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "181 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "182 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "183 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "184 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "185 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "186 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "187 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "188 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "189 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "190 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "191 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "192 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "193 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "194 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "195 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "196 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "197 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "198 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "199 Train Loss 0.000122986 Test MSE 1.5109566291808851e-05 Test RE 0.0010193449225808552\n",
      "Training time: 10.08\n",
      "Training time: 10.08\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 2.960154 Test MSE 14.828705592748355 Test RE 1.009826553227393\n",
      "1 Train Loss 1.7027116 Test MSE 13.471589731650784 Test RE 0.9625085341432946\n",
      "2 Train Loss 1.6176429 Test MSE 12.526663821120412 Test RE 0.9281386881257717\n",
      "3 Train Loss 1.4399956 Test MSE 11.710498275761827 Test RE 0.8973933605336587\n",
      "4 Train Loss 0.8610844 Test MSE 6.38794882319289 Test RE 0.6627898955991808\n",
      "5 Train Loss 0.23911554 Test MSE 0.5668953884243504 Test RE 0.1974452211783566\n",
      "6 Train Loss 0.07474515 Test MSE 0.36190685350246804 Test RE 0.15775879070819004\n",
      "7 Train Loss 0.0077525065 Test MSE 0.0033205860016445802 Test RE 0.015111324481469342\n",
      "8 Train Loss 0.0025521086 Test MSE 0.0003869958233330962 Test RE 0.0051587953980290575\n",
      "9 Train Loss 0.0007279924 Test MSE 0.00018082796395511383 Test RE 0.0035263706723913705\n",
      "10 Train Loss 0.00036539626 Test MSE 1.2335129144876342e-05 Test RE 0.0009210156613291149\n",
      "11 Train Loss 0.00013680985 Test MSE 1.7187835995925856e-06 Test RE 0.00034379991527093553\n",
      "12 Train Loss 0.00013127267 Test MSE 1.6858742656245478e-06 Test RE 0.00034049266093787525\n",
      "13 Train Loss 0.00012752267 Test MSE 1.5645634944528523e-06 Test RE 0.0003280135324014945\n",
      "14 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "15 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "16 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "17 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "18 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "19 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "20 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "21 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "22 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "23 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "24 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "25 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "26 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "27 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "28 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "29 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "30 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "31 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "32 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "33 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "34 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "35 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "36 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "37 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "38 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "39 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "40 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "41 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "42 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "43 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "44 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "45 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "46 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "47 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "48 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "49 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "50 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "51 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "52 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "53 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "54 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "55 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "56 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "57 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "58 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "59 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "60 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "61 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "62 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "63 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "64 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "65 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "66 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "67 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "68 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "69 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "70 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "71 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "72 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "73 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "74 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "75 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "76 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "77 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "78 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "79 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "80 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "81 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "82 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "83 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "84 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "85 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "86 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "87 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "88 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "89 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "90 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "91 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "92 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "93 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "94 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "95 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "96 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "97 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "98 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "99 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "100 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "101 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "102 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "103 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "104 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "105 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "106 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "107 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "108 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "109 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "110 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "111 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "112 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "113 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "114 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "115 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "116 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "117 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "118 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "119 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "120 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "121 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "122 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "123 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "124 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "125 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "126 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "127 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "128 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "129 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "130 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "131 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "132 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "133 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "134 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "135 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "136 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "137 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "138 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "139 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "140 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "141 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "142 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "143 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "144 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "145 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "146 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "147 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "148 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "149 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "150 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "151 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "152 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "153 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "154 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "155 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "156 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "157 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "158 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "159 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "160 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "161 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "162 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "163 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "164 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "165 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "166 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "167 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "168 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "169 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "170 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "171 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "172 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "173 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "174 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "175 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "176 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "177 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "178 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "179 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "180 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "181 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "182 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "183 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "184 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "185 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "186 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "187 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "188 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "189 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "190 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "191 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "192 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "193 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "194 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "195 Train Loss 0.0001248967 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "196 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "197 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "198 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "199 Train Loss 0.00012489672 Test MSE 1.265263941323084e-06 Test RE 0.00029497535361846014\n",
      "Training time: 8.51\n",
      "Training time: 8.51\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 3.2122219 Test MSE 14.960240448421294 Test RE 1.0142953901758112\n",
      "1 Train Loss 1.4949447 Test MSE 12.701565302991487 Test RE 0.9345957192826911\n",
      "2 Train Loss 1.4239637 Test MSE 11.365997371547842 Test RE 0.8840950122313885\n",
      "3 Train Loss 1.2640967 Test MSE 9.264830354687314 Test RE 0.7982040013481377\n",
      "4 Train Loss 0.8010677 Test MSE 6.142366574615389 Test RE 0.6499246822431247\n",
      "5 Train Loss 0.42802376 Test MSE 1.6648750095004734 Test RE 0.33836542704665223\n",
      "6 Train Loss 0.07817219 Test MSE 0.32898073391299204 Test RE 0.1504112766181011\n",
      "7 Train Loss 0.020793237 Test MSE 0.021415313775729364 Test RE 0.03837579502722966\n",
      "8 Train Loss 0.0061663236 Test MSE 0.0021887524971805974 Test RE 0.012268557200382562\n",
      "9 Train Loss 0.0027590843 Test MSE 0.001272478820209074 Test RE 0.009354497128651742\n",
      "10 Train Loss 0.0003662983 Test MSE 2.2968580116127252e-05 Test RE 0.0012567886185353115\n",
      "11 Train Loss 4.549862e-05 Test MSE 2.8543193557916796e-05 Test RE 0.0014010268102363336\n",
      "12 Train Loss 4.0103703e-05 Test MSE 1.9693507258221212e-05 Test RE 0.0011637419732606154\n",
      "13 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "14 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "15 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "16 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "17 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "18 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "19 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "20 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "21 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "22 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "23 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "24 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "25 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "26 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "27 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "28 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "29 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "30 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "31 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "32 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "33 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "34 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "35 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "36 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "37 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "38 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "39 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "40 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "41 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "42 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "43 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "44 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "45 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "46 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "47 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "48 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "49 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "50 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "51 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "52 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "53 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "54 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "55 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "56 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "57 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "58 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "59 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "60 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "61 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "62 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "63 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "64 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "65 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "66 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "67 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "68 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "69 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "70 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "71 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "72 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "73 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "74 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "75 Train Loss 3.6711037e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "76 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "77 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "78 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "79 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "80 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "81 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "82 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "83 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "84 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "85 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "86 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "87 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "88 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "89 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "90 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "91 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "92 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "93 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "94 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "95 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "96 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "97 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "98 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "99 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "100 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "101 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "102 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "103 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "104 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "105 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "106 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "107 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "108 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "109 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "110 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "111 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "112 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "113 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "114 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "115 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "116 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "117 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "118 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "119 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "120 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "121 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "122 Train Loss 3.6711037e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "123 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "124 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "125 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "126 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "127 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "128 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "129 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "130 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "131 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "132 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "133 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "134 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "135 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "136 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "137 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "138 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "139 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "140 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "141 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "142 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "143 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "144 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "145 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "146 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "147 Train Loss 3.6711037e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "148 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "149 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "150 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "151 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "152 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "153 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "154 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "155 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "156 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "157 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "158 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "159 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "160 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "161 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "162 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "163 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "164 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "165 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "166 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "167 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "168 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "169 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "170 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "171 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "172 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "173 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "174 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "175 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "176 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "177 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "178 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "179 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "180 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "181 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "182 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "183 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "184 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "185 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "186 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "187 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "188 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "189 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "190 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "191 Train Loss 3.6711037e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "192 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "193 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "194 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "195 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "196 Train Loss 3.6711044e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "197 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "198 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "199 Train Loss 3.671104e-05 Test MSE 1.2405532192935182e-05 Test RE 0.0009236402812233327\n",
      "Training time: 8.17\n",
      "Training time: 8.17\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 3.0605364 Test MSE 14.981362921735322 Test RE 1.0150111831603144\n",
      "1 Train Loss 2.0355124 Test MSE 15.001956342754841 Test RE 1.01570856211376\n",
      "2 Train Loss 1.5320084 Test MSE 12.853322982880847 Test RE 0.9401623929987314\n",
      "3 Train Loss 1.4289417 Test MSE 11.781020785447796 Test RE 0.9000914283706558\n",
      "4 Train Loss 1.2645944 Test MSE 9.491491506393972 Test RE 0.8079089076785136\n",
      "5 Train Loss 0.796504 Test MSE 5.65723358097942 Test RE 0.623730843026561\n",
      "6 Train Loss 0.2765408 Test MSE 1.628904549680084 Test RE 0.3346901899105743\n",
      "7 Train Loss 0.092543036 Test MSE 0.39700546641729234 Test RE 0.16523171406377082\n",
      "8 Train Loss 0.030646918 Test MSE 0.024446140721161438 Test RE 0.04100155411929857\n",
      "9 Train Loss 0.013370998 Test MSE 0.03988541696222516 Test RE 0.05237237068014117\n",
      "10 Train Loss 0.00393415 Test MSE 0.00019332051409032397 Test RE 0.003646146677286189\n",
      "11 Train Loss 0.0021242748 Test MSE 1.1133839760481442e-05 Test RE 0.000875019331998789\n",
      "12 Train Loss 0.0013870046 Test MSE 0.0015040478434441198 Test RE 0.010170117965685802\n",
      "13 Train Loss 0.00085706916 Test MSE 0.00014293666974587213 Test RE 0.003135212590029378\n",
      "14 Train Loss 0.00058009854 Test MSE 1.072268375934231e-06 Test RE 0.00027154819079652244\n",
      "15 Train Loss 0.000547479 Test MSE 3.059457855369295e-05 Test RE 0.0014504988951511279\n",
      "16 Train Loss 0.00053751 Test MSE 4.948458103888359e-05 Test RE 0.001844718544434081\n",
      "17 Train Loss 0.00030903507 Test MSE 0.00020765964414108404 Test RE 0.003778950624698384\n",
      "18 Train Loss 0.00015263839 Test MSE 8.355050917745396e-06 Test RE 0.00075800088948807\n",
      "19 Train Loss 0.00014623949 Test MSE 4.791783792078069e-06 Test RE 0.0005740421361732044\n",
      "20 Train Loss 0.00014183969 Test MSE 2.7882993363674096e-06 Test RE 0.00043788983370247366\n",
      "21 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "22 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "23 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "24 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "25 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "26 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "27 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "28 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "29 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "30 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "31 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "32 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "33 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "34 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "35 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "36 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "37 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "38 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "39 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "40 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "41 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "42 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "43 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "44 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "45 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "46 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "47 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "48 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "49 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "50 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "51 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "52 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "53 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "54 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "55 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "56 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "57 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "58 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "59 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "60 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "61 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "62 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "63 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "64 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "65 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "66 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "67 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "68 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "69 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "70 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "71 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "72 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "73 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "74 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "75 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "76 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "77 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "78 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "79 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "80 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "81 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "82 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "83 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "84 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "85 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "86 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "87 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "88 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "89 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "90 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "91 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "92 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "93 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "94 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "95 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "96 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "97 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "98 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "99 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "100 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "101 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "102 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "103 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "104 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "105 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "106 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "107 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "108 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "109 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "110 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "111 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "112 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "113 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "114 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "115 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "116 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "117 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "118 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "119 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "120 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "121 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "122 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "123 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "124 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "125 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "126 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "127 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "128 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "129 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "130 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "131 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "132 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "133 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "134 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "135 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "136 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "137 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "138 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "139 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "140 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "141 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "142 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "143 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "144 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "145 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "146 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "147 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "148 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "149 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "150 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "151 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "152 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "153 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "154 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "155 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "156 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "157 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "158 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "159 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "160 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "161 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "162 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "163 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "164 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "165 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "166 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "167 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "168 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "169 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "170 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "171 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "172 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "173 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "174 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "175 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "176 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "177 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "178 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "179 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "180 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "181 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "182 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "183 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "184 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "185 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "186 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "187 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "188 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "189 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "190 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "191 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "192 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "193 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "194 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "195 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "196 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "197 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "198 Train Loss 0.00013880861 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "199 Train Loss 0.0001388086 Test MSE 1.5322192889363e-06 Test RE 0.00032460531566242773\n",
      "Training time: 10.70\n",
      "Training time: 10.70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 3.3627906 Test MSE 14.694908368304013 Test RE 1.0052604720612115\n",
      "1 Train Loss 2.0273578 Test MSE 15.328335723302565 Test RE 1.0266978834085891\n",
      "2 Train Loss 1.7159677 Test MSE 13.01191911611778 Test RE 0.9459449048112\n",
      "3 Train Loss 1.462765 Test MSE 12.017856682744684 Test RE 0.9090937564466017\n",
      "4 Train Loss 1.4222014 Test MSE 11.814680565533001 Test RE 0.9013763454630624\n",
      "5 Train Loss 1.2929983 Test MSE 9.080329224823123 Test RE 0.7902162609606852\n",
      "6 Train Loss 0.6785743 Test MSE 3.8888068999226886 Test RE 0.5171343117973505\n",
      "7 Train Loss 0.2501942 Test MSE 1.4866817764333982 Test RE 0.3197453031978128\n",
      "8 Train Loss 0.18339841 Test MSE 0.5868722216364114 Test RE 0.20089398866632116\n",
      "9 Train Loss 0.06592004 Test MSE 0.12559300239622587 Test RE 0.09293469674791732\n",
      "10 Train Loss 0.023522994 Test MSE 0.026588834551489096 Test RE 0.042760700939887014\n",
      "11 Train Loss 0.0053834287 Test MSE 0.0015127953956198415 Test RE 0.010199649825143467\n",
      "12 Train Loss 0.0010467137 Test MSE 0.0001613568169186326 Test RE 0.0033311088461770856\n",
      "13 Train Loss 0.00071950123 Test MSE 6.074127222066539e-05 Test RE 0.0020437939384029997\n",
      "14 Train Loss 0.00043620233 Test MSE 7.192590462277658e-05 Test RE 0.002224015610120249\n",
      "15 Train Loss 4.61488e-05 Test MSE 4.769348034635775e-07 Test RE 0.00018110259466730744\n",
      "16 Train Loss 4.1479365e-05 Test MSE 2.1880707820039487e-07 Test RE 0.00012266646451452782\n",
      "17 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "18 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "19 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "20 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "21 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "22 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "23 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "24 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "25 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "26 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "27 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "28 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "29 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "30 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "31 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "32 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "33 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "34 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "35 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "36 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "37 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "38 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "39 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "40 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "41 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "42 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "43 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "44 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "45 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "46 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "47 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "48 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "49 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "50 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "51 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "52 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "53 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "54 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "55 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "56 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "57 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "58 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "59 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "60 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "61 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "62 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "63 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "64 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "65 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "66 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "67 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "68 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "69 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "70 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "71 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "72 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "73 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "74 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "75 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "76 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "77 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "78 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "79 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "80 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "81 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "82 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "83 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "84 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "85 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "86 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "87 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "88 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "89 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "90 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "91 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "92 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "93 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "94 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "95 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "96 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "97 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "98 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "99 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "100 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "101 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "102 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "103 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "104 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "105 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "106 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "107 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "108 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "109 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "110 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "111 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "112 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "113 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "114 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "115 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "116 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "117 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "118 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "119 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "120 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "121 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "122 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "123 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "124 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "125 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "126 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "127 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "128 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "129 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "130 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "131 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "132 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "133 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "134 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "135 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "136 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "137 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "138 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "139 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "140 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "141 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "142 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "143 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "144 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "145 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "146 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "147 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "148 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "149 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "150 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "151 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "152 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "153 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "154 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "155 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "156 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "157 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "158 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "159 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "160 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "161 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "162 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "163 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "164 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "165 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "166 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "167 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "168 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "169 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "170 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "171 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "172 Train Loss 3.8797192e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "173 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "174 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "175 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "176 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "177 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "178 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "179 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "180 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "181 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "182 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "183 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "184 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "185 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "186 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "187 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "188 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "189 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "190 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "191 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "192 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "193 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "194 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "195 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "196 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "197 Train Loss 3.87972e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "198 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "199 Train Loss 3.8797196e-05 Test MSE 1.2116388433979925e-07 Test RE 9.12812878351929e-05\n",
      "Training time: 9.55\n",
      "Training time: 9.55\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 3.1809444 Test MSE 15.002296869190424 Test RE 1.0157200897320797\n",
      "1 Train Loss 2.298056 Test MSE 14.61864025695487 Test RE 1.0026483748934143\n",
      "2 Train Loss 1.7437108 Test MSE 14.080758929700593 Test RE 0.9840296770680435\n",
      "3 Train Loss 1.5445197 Test MSE 11.212820004574779 Test RE 0.8781174147109904\n",
      "4 Train Loss 1.4130275 Test MSE 11.209187138505445 Test RE 0.8779751515964549\n",
      "5 Train Loss 1.1873713 Test MSE 9.690432225429827 Test RE 0.8163318457924069\n",
      "6 Train Loss 0.17826211 Test MSE 0.7443259454479844 Test RE 0.22624382972383889\n",
      "7 Train Loss 0.051732786 Test MSE 0.14172107393243136 Test RE 0.0987216447098015\n",
      "8 Train Loss 0.01640157 Test MSE 0.015489572363700662 Test RE 0.03263734924234651\n",
      "9 Train Loss 0.01192438 Test MSE 0.004855356676178002 Test RE 0.01827282665094132\n",
      "10 Train Loss 0.0052015204 Test MSE 0.0010223019616080423 Test RE 0.00838464658795472\n",
      "11 Train Loss 0.00081003 Test MSE 0.00020348879622119291 Test RE 0.0037408079815513316\n",
      "12 Train Loss 0.00062709773 Test MSE 1.4819988547944435e-05 Test RE 0.0010095296966575525\n",
      "13 Train Loss 0.0006218078 Test MSE 2.413240017597164e-05 Test RE 0.0012882359779403155\n",
      "14 Train Loss 0.000618133 Test MSE 3.175951265817374e-05 Test RE 0.0014778558655465786\n",
      "15 Train Loss 0.0006147652 Test MSE 4.073739119883763e-05 Test RE 0.001673754553666856\n",
      "16 Train Loss 0.0006115279 Test MSE 4.924787644419728e-05 Test RE 0.001840301241399049\n",
      "17 Train Loss 0.0006080239 Test MSE 5.430923262186358e-05 Test RE 0.0019325556020486389\n",
      "18 Train Loss 0.00060367753 Test MSE 6.243319425269966e-05 Test RE 0.0020720629361520118\n",
      "19 Train Loss 0.0005982256 Test MSE 7.049907813220633e-05 Test RE 0.0022018457122927894\n",
      "20 Train Loss 0.0005905559 Test MSE 8.18925469651527e-05 Test RE 0.00237310718383568\n",
      "21 Train Loss 0.00027789513 Test MSE 5.7905467948963665e-05 Test RE 0.001995514797538278\n",
      "22 Train Loss 0.0001498495 Test MSE 6.553910344767909e-06 Test RE 0.0006713444652732024\n",
      "23 Train Loss 0.00014275261 Test MSE 3.601909137054684e-06 Test RE 0.0004976930100811063\n",
      "24 Train Loss 0.00013711357 Test MSE 1.195368163584591e-06 Test RE 0.0002867120905002984\n",
      "25 Train Loss 0.00013300439 Test MSE 4.958381580945859e-07 Test RE 0.00018465672873540297\n",
      "26 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "27 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "28 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "29 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "30 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "31 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "32 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "33 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "34 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "35 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "36 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "37 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "38 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "39 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "40 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "41 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "42 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "43 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "44 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "45 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "46 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "47 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "48 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "49 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "50 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "51 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "52 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "53 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "54 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "55 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "56 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "57 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "58 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "59 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "60 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "61 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "62 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "63 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "64 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "65 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "66 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "67 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "68 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "69 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "70 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "71 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "72 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "73 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "74 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "75 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "76 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "77 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "78 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "79 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "80 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "81 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "82 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "83 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "84 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "85 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "86 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "87 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "88 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "89 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "90 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "91 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "92 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "93 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "94 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "95 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "96 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "97 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "98 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "99 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "100 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "101 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "102 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "103 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "104 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "105 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "106 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "107 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "108 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "109 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "110 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "111 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "112 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "113 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "114 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "115 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "116 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "117 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "118 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "119 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "120 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "121 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "122 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "123 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "124 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "125 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "126 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "127 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "128 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "129 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "130 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "131 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "132 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "133 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "134 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "135 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "136 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "137 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "138 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "139 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "140 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "141 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "142 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "143 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "144 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "145 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "146 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "147 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "148 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "149 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "150 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "151 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "152 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "153 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "154 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "155 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "156 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "157 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "158 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "159 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "160 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "161 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "162 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "163 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "164 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "165 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "166 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "167 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "168 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "169 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "170 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "171 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "172 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "173 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "174 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "175 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "176 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "177 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "178 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "179 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "180 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "181 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "182 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "183 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "184 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "185 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "186 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "187 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "188 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "189 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "190 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "191 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "192 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "193 Train Loss 0.00013057781 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "194 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "195 Train Loss 0.00013057778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "196 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "197 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "198 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "199 Train Loss 0.0001305778 Test MSE 1.9160908735940384e-07 Test RE 0.00011478977799558008\n",
      "Training time: 9.12\n",
      "Training time: 9.12\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 3.2340014 Test MSE 15.143952407877034 Test RE 1.0205041680713143\n",
      "1 Train Loss 1.9289942 Test MSE 15.289178192576934 Test RE 1.0253856515084276\n",
      "2 Train Loss 1.5958906 Test MSE 12.164014520742002 Test RE 0.9146051231546064\n",
      "3 Train Loss 1.4567214 Test MSE 12.082530536571285 Test RE 0.911536609191067\n",
      "4 Train Loss 1.4148632 Test MSE 11.751579446602719 Test RE 0.8989660388960674\n",
      "5 Train Loss 1.3168945 Test MSE 8.624008910235734 Test RE 0.7701046807477883\n",
      "6 Train Loss 1.1252882 Test MSE 6.7347426550440845 Test RE 0.6805431507719252\n",
      "7 Train Loss 0.80547476 Test MSE 4.5157041081300155 Test RE 0.5572600419381181\n",
      "8 Train Loss 0.034660563 Test MSE 0.09666393719603107 Test RE 0.08153187030266773\n",
      "9 Train Loss 0.00862418 Test MSE 0.013617689123866829 Test RE 0.03060179295977969\n",
      "10 Train Loss 0.001349768 Test MSE 0.00031042830433816016 Test RE 0.00462036006116634\n",
      "11 Train Loss 0.00066190655 Test MSE 9.527297577258702e-05 Test RE 0.0025596467281682146\n",
      "12 Train Loss 0.0001494048 Test MSE 1.619759231593311e-07 Test RE 0.00010554080362055677\n",
      "13 Train Loss 0.00014281986 Test MSE 3.7657748236560914e-07 Test RE 0.00016092456305442303\n",
      "14 Train Loss 0.00013792934 Test MSE 2.1026370560204868e-07 Test RE 0.00012024785048113605\n",
      "15 Train Loss 0.00013423005 Test MSE 1.6509665468139454e-07 Test RE 0.00010655266134195804\n",
      "16 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "17 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "18 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "19 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "20 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "21 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "22 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "23 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "24 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "25 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "26 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "27 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "28 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "29 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "30 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "31 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "32 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "33 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "34 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "35 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "36 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "37 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "38 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "39 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "40 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "41 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "42 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "43 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "44 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "45 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "46 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "47 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "48 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "49 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "50 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "51 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "52 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "53 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "54 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "55 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "56 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "57 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "58 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "59 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "60 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "61 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "62 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "63 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "64 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "65 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "66 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "67 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "68 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "69 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "70 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "71 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "72 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "73 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "74 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "75 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "76 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "77 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "78 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "79 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "80 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "81 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "82 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "83 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "84 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "85 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "86 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "87 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "88 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "89 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "90 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "91 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "92 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "93 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "94 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "95 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "96 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "97 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "98 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "99 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "100 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "101 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "102 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "103 Train Loss 0.00013144471 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "104 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "105 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "106 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "107 Train Loss 0.00013144474 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "108 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "109 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "110 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "111 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "112 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "113 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "114 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "115 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "116 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "117 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "118 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "119 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "120 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "121 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "122 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "123 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "124 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "125 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "126 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "127 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "128 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "129 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "130 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "131 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "132 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "133 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "134 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "135 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "136 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "137 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "138 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "139 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "140 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "141 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "142 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "143 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "144 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "145 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "146 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "147 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "148 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "149 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "150 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "151 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "152 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "153 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "154 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "155 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "156 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "157 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "158 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "159 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "160 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "161 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "162 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "163 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "164 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "165 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "166 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "167 Train Loss 0.00013144474 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "168 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "169 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "170 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "171 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "172 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "173 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "174 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "175 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "176 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "177 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "178 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "179 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "180 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "181 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "182 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "183 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "184 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "185 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "186 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "187 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "188 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "189 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "190 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "191 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "192 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "193 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "194 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "195 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "196 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "197 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "198 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "199 Train Loss 0.00013144473 Test MSE 7.542911694242224e-08 Test RE 7.202191695653263e-05\n",
      "Training time: 8.79\n",
      "Training time: 8.79\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 2.992848 Test MSE 15.417204205141463 Test RE 1.0296698048105135\n",
      "1 Train Loss 1.7878985 Test MSE 14.705504772302634 Test RE 1.0056228501792777\n",
      "2 Train Loss 1.6744044 Test MSE 12.840768366516198 Test RE 0.9397031241444135\n",
      "3 Train Loss 1.4498926 Test MSE 11.705744427334352 Test RE 0.8972111947131435\n",
      "4 Train Loss 1.254932 Test MSE 10.11678333426018 Test RE 0.834096673781436\n",
      "5 Train Loss 0.62491333 Test MSE 3.6163098608750563 Test RE 0.49868692607080634\n",
      "6 Train Loss 0.101205595 Test MSE 0.37736350109420186 Test RE 0.1610924219820403\n",
      "7 Train Loss 0.0074608284 Test MSE 0.001646158494916593 Test RE 0.01063973934272996\n",
      "8 Train Loss 0.0037121463 Test MSE 0.0020626425000228534 Test RE 0.011909873420883824\n",
      "9 Train Loss 0.0014531222 Test MSE 0.0003222199099795157 Test RE 0.004707294295050501\n",
      "10 Train Loss 0.00050887605 Test MSE 0.00013753125061170753 Test RE 0.003075359288432491\n",
      "11 Train Loss 0.00047421103 Test MSE 3.431275726263871e-05 Test RE 0.0015361123251567336\n",
      "12 Train Loss 0.00046965486 Test MSE 2.2012261176928468e-05 Test RE 0.0012303466563864554\n",
      "13 Train Loss 0.00046641644 Test MSE 1.3252452534475885e-05 Test RE 0.0009546480581632204\n",
      "14 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "15 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "16 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "17 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "18 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "19 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "20 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "21 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "22 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "23 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "24 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "25 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "26 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "27 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "28 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "29 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "30 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "31 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "32 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "33 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "34 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "35 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "36 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "37 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "38 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "39 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "40 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "41 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "42 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "43 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "44 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "45 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "46 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "47 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "48 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "49 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "50 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "51 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "52 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "53 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "54 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "55 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "56 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "57 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "58 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "59 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "60 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "61 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "62 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "63 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "64 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "65 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "66 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "67 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "68 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "69 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "70 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "71 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "72 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "73 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "74 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "75 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "76 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "77 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "78 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "79 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "80 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "81 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "82 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "83 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "84 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "85 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "86 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "87 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "88 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "89 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "90 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "91 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "92 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "93 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "94 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "95 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "96 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "97 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "98 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "99 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "100 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "101 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "102 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "103 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "104 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "105 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "106 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "107 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "108 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "109 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "110 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "111 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "112 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "113 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "114 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "115 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "116 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "117 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "118 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "119 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "120 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "121 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "122 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "123 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "124 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "125 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "126 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "127 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "128 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "129 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "130 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "131 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "132 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "133 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "134 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "135 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "136 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "137 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "138 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "139 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "140 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "141 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "142 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "143 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "144 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "145 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "146 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "147 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "148 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "149 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "150 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "151 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "152 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "153 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "154 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "155 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "156 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "157 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "158 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "159 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "160 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "161 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "162 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "163 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "164 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "165 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "166 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "167 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "168 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "169 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "170 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "171 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "172 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "173 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "174 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "175 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "176 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "177 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "178 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "179 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "180 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "181 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "182 Train Loss 0.0004640122 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "183 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "184 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "185 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "186 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "187 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "188 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "189 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "190 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "191 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "192 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "193 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "194 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "195 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "196 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "197 Train Loss 0.00046401226 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "198 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "199 Train Loss 0.00046401224 Test MSE 7.854507028113972e-06 Test RE 0.0007349446471119166\n",
      "Training time: 8.43\n",
      "Training time: 8.43\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 2.6580229 Test MSE 15.323090935236632 Test RE 1.0265222194094743\n",
      "1 Train Loss 1.5895543 Test MSE 12.82542480980882 Test RE 0.9391415262125601\n",
      "2 Train Loss 1.4802337 Test MSE 12.015518658456847 Test RE 0.9090053219310034\n",
      "3 Train Loss 1.3529783 Test MSE 11.202376058575663 Test RE 0.8777083674156654\n",
      "4 Train Loss 1.2456743 Test MSE 9.52300422020422 Test RE 0.8092489660473084\n",
      "5 Train Loss 0.8763491 Test MSE 5.657340932070148 Test RE 0.6237367609250987\n",
      "6 Train Loss 0.20982373 Test MSE 0.7091341505695128 Test RE 0.22083065730559273\n",
      "7 Train Loss 0.08085558 Test MSE 0.10301280435247753 Test RE 0.08416679112538683\n",
      "8 Train Loss 0.04215852 Test MSE 0.10403899799309979 Test RE 0.08458497888016038\n",
      "9 Train Loss 0.015433721 Test MSE 0.032306571492246514 Test RE 0.04713468406772876\n",
      "10 Train Loss 0.005530561 Test MSE 0.0010179272453498956 Test RE 0.008366687229178143\n",
      "11 Train Loss 0.0027702013 Test MSE 0.001992572146290623 Test RE 0.011705829451493633\n",
      "12 Train Loss 0.0005019071 Test MSE 5.427587436571524e-05 Test RE 0.0019319619959154372\n",
      "13 Train Loss 3.864264e-05 Test MSE 6.444066393393297e-07 Test RE 0.0002105111811161009\n",
      "14 Train Loss 3.4770157e-05 Test MSE 4.2962896743849437e-07 Test RE 0.00017188656894003457\n",
      "15 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "16 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "17 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "18 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "19 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "20 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "21 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "22 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "23 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "24 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "25 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "26 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "27 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "28 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "29 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "30 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "31 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "32 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "33 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "34 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "35 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "36 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "37 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "38 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "39 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "40 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "41 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "42 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "43 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "44 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "45 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "46 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "47 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "48 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "49 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "50 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "51 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "52 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "53 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "54 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "55 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "56 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "57 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "58 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "59 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "60 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "61 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "62 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "63 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "64 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "65 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "66 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "67 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "68 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "69 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "70 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "71 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "72 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "73 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "74 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "75 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "76 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "77 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "78 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "79 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "80 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "81 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "82 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "83 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "84 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "85 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "86 Train Loss 3.2426986e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "87 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "88 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "89 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "90 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "91 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "92 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "93 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "94 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "95 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "96 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "97 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "98 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "99 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "100 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "101 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "102 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "103 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "104 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "105 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "106 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "107 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "108 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "109 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "110 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "111 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "112 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "113 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "114 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "115 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "116 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "117 Train Loss 3.2426986e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "118 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "119 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "120 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "121 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "122 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "123 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "124 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "125 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "126 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "127 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "128 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "129 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "130 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "131 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "132 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "133 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "134 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "135 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "136 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "137 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "138 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "139 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "140 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "141 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "142 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "143 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "144 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "145 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "146 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "147 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "148 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "149 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "150 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "151 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "152 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "153 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "154 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "155 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "156 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "157 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "158 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "159 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "160 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "161 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "162 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "163 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "164 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "165 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "166 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "167 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "168 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "169 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "170 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "171 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "172 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "173 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "174 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "175 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "176 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "177 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "178 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "179 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "180 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "181 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "182 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "183 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "184 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "185 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "186 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "187 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "188 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "189 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "190 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "191 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "192 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "193 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "194 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "195 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "196 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "197 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "198 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "199 Train Loss 3.2426982e-05 Test MSE 3.071977770931127e-07 Test RE 0.00014534637313650444\n",
      "Training time: 8.75\n",
      "Training time: 8.75\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 3.3026912 Test MSE 15.153055488486109 Test RE 1.0208108362333266\n",
      "1 Train Loss 1.9425321 Test MSE 14.939088217927633 Test RE 1.013578082223085\n",
      "2 Train Loss 1.5474653 Test MSE 10.505077656401724 Test RE 0.8499527793632294\n",
      "3 Train Loss 1.2595274 Test MSE 10.251671997919587 Test RE 0.8396388324153311\n",
      "4 Train Loss 0.62309 Test MSE 1.2665084916646123 Test RE 0.2951203911217222\n",
      "5 Train Loss 0.12370273 Test MSE 0.4648941216513217 Test RE 0.17880192584110993\n",
      "6 Train Loss 0.015339131 Test MSE 0.004650794959500396 Test RE 0.017883757049286703\n",
      "7 Train Loss 0.0076746847 Test MSE 0.004562713759570078 Test RE 0.017713597696346128\n",
      "8 Train Loss 0.0020576518 Test MSE 0.0003905764996841642 Test RE 0.005182606307790526\n",
      "9 Train Loss 0.0018836451 Test MSE 3.3289498957901545e-05 Test RE 0.001513034371947055\n",
      "10 Train Loss 0.0009887327 Test MSE 1.8218945546144733e-06 Test RE 0.0003539621168360386\n",
      "11 Train Loss 0.0005816339 Test MSE 9.919459008033687e-06 Test RE 0.0008259222354270248\n",
      "12 Train Loss 0.000575504 Test MSE 8.328916189093503e-06 Test RE 0.0007568144416944894\n",
      "13 Train Loss 0.00057136815 Test MSE 6.995350093792658e-06 Test RE 0.0006935853190658395\n",
      "14 Train Loss 0.00056645705 Test MSE 4.406979584495437e-06 Test RE 0.0005505105980281716\n",
      "15 Train Loss 0.00055969274 Test MSE 1.5276406202404277e-06 Test RE 0.00032411995034856074\n",
      "16 Train Loss 0.0001883443 Test MSE 1.429549850460658e-05 Test RE 0.0009915047908435302\n",
      "17 Train Loss 4.7682373e-05 Test MSE 8.901084872777846e-06 Test RE 0.0007823780107967774\n",
      "18 Train Loss 4.1661064e-05 Test MSE 5.058501588779971e-06 Test RE 0.0005898018224515341\n",
      "19 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "20 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "21 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "22 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "23 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "24 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "25 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "26 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "27 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "28 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "29 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "30 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "31 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "32 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "33 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "34 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "35 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "36 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "37 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "38 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "39 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "40 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "41 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "42 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "43 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "44 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "45 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "46 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "47 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "48 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "49 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "50 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "51 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "52 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "53 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "54 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "55 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "56 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "57 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "58 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "59 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "60 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "61 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "62 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "63 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "64 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "65 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "66 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "67 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "68 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "69 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "70 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "71 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "72 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "73 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "74 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "75 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "76 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "77 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "78 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "79 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "80 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "81 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "82 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "83 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "84 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "85 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "86 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "87 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "88 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "89 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "90 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "91 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "92 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "93 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "94 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "95 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "96 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "97 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "98 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "99 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "100 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "101 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "102 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "103 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "104 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "105 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "106 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "107 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "108 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "109 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "110 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "111 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "112 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "113 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "114 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "115 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "116 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "117 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "118 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "119 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "120 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "121 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "122 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "123 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "124 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "125 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "126 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "127 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "128 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "129 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "130 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "131 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "132 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "133 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "134 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "135 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "136 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "137 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "138 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "139 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "140 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "141 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "142 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "143 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "144 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "145 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "146 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "147 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "148 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "149 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "150 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "151 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "152 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "153 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "154 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "155 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "156 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "157 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "158 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "159 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "160 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "161 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "162 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "163 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "164 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "165 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "166 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "167 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "168 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "169 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "170 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "171 Train Loss 3.8221246e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "172 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "173 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "174 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "175 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "176 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "177 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "178 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "179 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "180 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "181 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "182 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "183 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "184 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "185 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "186 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "187 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "188 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "189 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "190 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "191 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "192 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "193 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "194 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "195 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "196 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "197 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "198 Train Loss 3.8221253e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "199 Train Loss 3.8221257e-05 Test MSE 2.801446925714604e-06 Test RE 0.00043892100437085475\n",
      "Training time: 8.36\n",
      "Training time: 8.36\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    \n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "    \n",
    "    \n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "   \n",
    "\n",
    "    start_time = time.time()\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    " \n",
    "    \n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"label\": label, \"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff6366912d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.plot(u_pred,'r')\n",
    "plt.plot(y_true,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00041598708804916566\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
