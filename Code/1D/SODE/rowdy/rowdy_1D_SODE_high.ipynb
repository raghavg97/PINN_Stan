{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(-4.0*x) + np.exp(3.0*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"high\"\n",
    "label = \"1D_SODE_rowdy_\" + level \n",
    "\n",
    "u_coeff = 12.0\n",
    "fo_val = -1.0\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0  #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    omega_val.append(PINN.omega.cpu().detach().numpy())\n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "    \n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,0)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 4.879704 Test MSE 14263.457948627747 Test RE 1.0001795643120133\n",
      "1 Train Loss 4.8249016 Test MSE 14260.00813088889 Test RE 1.0000586032563266\n",
      "2 Train Loss 4.4515224 Test MSE 14259.003934279921 Test RE 1.0000233903332483\n",
      "3 Train Loss 4.3041954 Test MSE 14260.202232168236 Test RE 1.000065409423335\n",
      "4 Train Loss 3.7082903 Test MSE 14272.082303015904 Test RE 1.0004818963107944\n",
      "5 Train Loss 3.1007516 Test MSE 14268.075338128714 Test RE 1.0003414410792797\n",
      "6 Train Loss 2.8582425 Test MSE 14276.585140902274 Test RE 1.0006397097403827\n",
      "7 Train Loss 2.8574007 Test MSE 14276.639494013367 Test RE 1.0006416145316546\n",
      "8 Train Loss 2.8498936 Test MSE 14275.22229742035 Test RE 1.0005919480438936\n",
      "9 Train Loss 2.8318021 Test MSE 14272.91577608482 Test RE 1.0005111093760233\n",
      "10 Train Loss 2.8313277 Test MSE 14272.599799599784 Test RE 1.0005000345634818\n",
      "11 Train Loss 2.830916 Test MSE 14271.433571449095 Test RE 1.000459157808099\n",
      "12 Train Loss 2.8307333 Test MSE 14270.33351633224 Test RE 1.000420598912838\n",
      "13 Train Loss 2.8295357 Test MSE 14264.469616612687 Test RE 1.0002150336808981\n",
      "14 Train Loss 2.8285813 Test MSE 14260.669585444923 Test RE 1.0000817969895504\n",
      "15 Train Loss 2.828178 Test MSE 14258.566808131467 Test RE 1.0000080617827658\n",
      "16 Train Loss 2.8279123 Test MSE 14257.807104023068 Test RE 0.9999814209442124\n",
      "17 Train Loss 2.8278372 Test MSE 14257.83983238698 Test RE 0.99998256865707\n",
      "18 Train Loss 2.8278177 Test MSE 14257.87035436734 Test RE 0.9999836389956469\n",
      "19 Train Loss 2.8278117 Test MSE 14257.886114080335 Test RE 0.9999841916535964\n",
      "20 Train Loss 2.8278065 Test MSE 14257.898176171117 Test RE 0.9999846146439841\n",
      "21 Train Loss 2.8278003 Test MSE 14257.910916427873 Test RE 0.9999850614159325\n",
      "22 Train Loss 2.827793 Test MSE 14257.92124645037 Test RE 0.999985423666278\n",
      "23 Train Loss 2.8277836 Test MSE 14257.93450853452 Test RE 0.9999858887371507\n",
      "24 Train Loss 2.8276405 Test MSE 14257.969077723355 Test RE 0.999987100998297\n",
      "25 Train Loss 2.8276386 Test MSE 14257.967808265257 Test RE 0.9999870564813768\n",
      "26 Train Loss 2.8276386 Test MSE 14257.967808265257 Test RE 0.9999870564813768\n",
      "27 Train Loss 2.8276386 Test MSE 14257.967808265257 Test RE 0.9999870564813768\n",
      "28 Train Loss 2.8276386 Test MSE 14257.967808265257 Test RE 0.9999870564813768\n",
      "29 Train Loss 2.8276384 Test MSE 14257.95819995405 Test RE 0.9999867195403556\n",
      "30 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "31 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "32 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "33 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "34 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "35 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "36 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "37 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "38 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "39 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "40 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "41 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "42 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "43 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "44 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "45 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "46 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "47 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "48 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "49 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "50 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "51 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "52 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "53 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "54 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "55 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "56 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "57 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "58 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "59 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "60 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "61 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "62 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "63 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "64 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "65 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "66 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "67 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "68 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "69 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "70 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "71 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "72 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "73 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "74 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "75 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "76 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "77 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "78 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "79 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "80 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "81 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "82 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "83 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "84 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "85 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "86 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "87 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "88 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "89 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "90 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "91 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "92 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "93 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "94 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "95 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "96 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "97 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "98 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "99 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "100 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "101 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "102 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "103 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "104 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "105 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "106 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "107 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "108 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "109 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "110 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "111 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "112 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "113 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "114 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "115 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "116 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "117 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "118 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "119 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "120 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "121 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "122 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "123 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "124 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "125 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "126 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "127 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "128 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "129 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "130 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "131 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "132 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "133 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "134 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "135 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "136 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "137 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "138 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "139 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "140 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "141 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "142 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "143 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "144 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "145 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "146 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "147 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "148 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "149 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "150 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "151 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "152 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "153 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "154 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "155 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "156 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "157 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "158 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "159 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "160 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "161 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "162 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "163 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "164 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "165 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "166 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "167 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "168 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "169 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "170 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "171 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "172 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "173 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "174 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "175 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "176 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "177 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "178 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "179 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "180 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "181 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "182 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "183 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "184 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "185 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "186 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "187 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "188 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "189 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "190 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "191 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "192 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "193 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "194 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "195 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "196 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "197 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "198 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "199 Train Loss 2.8276346 Test MSE 14257.973561578736 Test RE 0.9999872582365815\n",
      "Training time: 87.63\n",
      "Training time: 87.63\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 4.9073615 Test MSE 14262.972354387757 Test RE 1.000162538792293\n",
      "1 Train Loss 4.8546376 Test MSE 14260.513909804611 Test RE 1.000076338311819\n",
      "2 Train Loss 4.788871 Test MSE 14262.359344071827 Test RE 1.0001410454973987\n",
      "3 Train Loss 4.383844 Test MSE 14264.548973822375 Test RE 1.000217815914164\n",
      "4 Train Loss 3.735629 Test MSE 14282.810085609772 Test RE 1.0008578378137345\n",
      "5 Train Loss 3.6264722 Test MSE 14281.48048483035 Test RE 1.0008112513113334\n",
      "6 Train Loss 3.515894 Test MSE 14277.936124878051 Test RE 1.0006870535631678\n",
      "7 Train Loss 3.4577422 Test MSE 14276.499887018384 Test RE 1.0006367220319028\n",
      "8 Train Loss 3.3843062 Test MSE 14278.798404643647 Test RE 1.000717270086168\n",
      "9 Train Loss 3.3296034 Test MSE 14280.937372853097 Test RE 1.0007922211503517\n",
      "10 Train Loss 3.2711725 Test MSE 14278.131395934837 Test RE 1.0006938964481842\n",
      "11 Train Loss 3.160036 Test MSE 14269.410604446835 Test RE 1.000388248057519\n",
      "12 Train Loss 2.8488407 Test MSE 14259.185102105084 Test RE 1.000029743213439\n",
      "13 Train Loss 2.8356373 Test MSE 14260.315422919604 Test RE 1.0000693784389438\n",
      "14 Train Loss 2.8356297 Test MSE 14260.328895084993 Test RE 1.0000698508372214\n",
      "15 Train Loss 2.8355813 Test MSE 14260.353394071823 Test RE 1.0000707098878003\n",
      "16 Train Loss 2.8355813 Test MSE 14260.353394071823 Test RE 1.0000707098878003\n",
      "17 Train Loss 2.8355813 Test MSE 14260.353394071823 Test RE 1.0000707098878003\n",
      "18 Train Loss 2.8355813 Test MSE 14260.353394071823 Test RE 1.0000707098878003\n",
      "19 Train Loss 2.8355794 Test MSE 14260.358781319645 Test RE 1.0000708987901399\n",
      "20 Train Loss 2.8355742 Test MSE 14260.362820478915 Test RE 1.0000710404221078\n",
      "21 Train Loss 2.835566 Test MSE 14260.363793877932 Test RE 1.0000710745540637\n",
      "22 Train Loss 2.835566 Test MSE 14260.363793877932 Test RE 1.0000710745540637\n",
      "23 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "24 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "25 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "26 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "27 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "28 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "29 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "30 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "31 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "32 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "33 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "34 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "35 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "36 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "37 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "38 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "39 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "40 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "41 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "42 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "43 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "44 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "45 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "46 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "47 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "48 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "49 Train Loss 2.8355632 Test MSE 14260.363802704303 Test RE 1.000071074863558\n",
      "50 Train Loss 2.8355587 Test MSE 14260.364119712356 Test RE 1.0000710859793538\n",
      "51 Train Loss 2.8355587 Test MSE 14260.364119712356 Test RE 1.0000710859793538\n",
      "52 Train Loss 2.8355587 Test MSE 14260.369768116589 Test RE 1.0000712840389947\n",
      "53 Train Loss 2.8355587 Test MSE 14260.369768116589 Test RE 1.0000712840389947\n",
      "54 Train Loss 2.835552 Test MSE 14260.372508384771 Test RE 1.0000713801256824\n",
      "55 Train Loss 2.8355167 Test MSE 14260.371926245265 Test RE 1.0000713597131348\n",
      "56 Train Loss 2.8342202 Test MSE 14259.702203433179 Test RE 1.0000478758071496\n",
      "57 Train Loss 2.831155 Test MSE 14257.860109580615 Test RE 0.999983279733685\n",
      "58 Train Loss 2.8297937 Test MSE 14256.528152636283 Test RE 0.9999365698567496\n",
      "59 Train Loss 2.8284748 Test MSE 14255.387486905547 Test RE 0.9998965665620627\n",
      "60 Train Loss 2.827769 Test MSE 14254.27584192541 Test RE 0.9998575794889228\n",
      "61 Train Loss 2.827707 Test MSE 14254.073409882174 Test RE 0.999850479726942\n",
      "62 Train Loss 2.827703 Test MSE 14254.011564930408 Test RE 0.9998483106707716\n",
      "63 Train Loss 2.8276782 Test MSE 14253.884355234031 Test RE 0.999843849095754\n",
      "64 Train Loss 2.8276742 Test MSE 14253.834862695505 Test RE 0.9998421132582817\n",
      "65 Train Loss 2.8276715 Test MSE 14253.796013546187 Test RE 0.9998407507112061\n",
      "66 Train Loss 2.82767 Test MSE 14253.795801184275 Test RE 0.9998407432630816\n",
      "67 Train Loss 2.82767 Test MSE 14253.795801184275 Test RE 0.9998407432630816\n",
      "68 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "69 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "70 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "71 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "72 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "73 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "74 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "75 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "76 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "77 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "78 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "79 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "80 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "81 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "82 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "83 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "84 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "85 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "86 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "87 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "88 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "89 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "90 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "91 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "92 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "93 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "94 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "95 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "96 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "97 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "98 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "99 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "100 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "101 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "102 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "103 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "104 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "105 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "106 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "107 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "108 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "109 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "110 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "111 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "112 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "113 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "114 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "115 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "116 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "117 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "118 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "119 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "120 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "121 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "122 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "123 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "124 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "125 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "126 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "127 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "128 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "129 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "130 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "131 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "132 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "133 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "134 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "135 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "136 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "137 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "138 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "139 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "140 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "141 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "142 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "143 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "144 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "145 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "146 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "147 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "148 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "149 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "150 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "151 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "152 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "153 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "154 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "155 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "156 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "157 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "158 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "159 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "160 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "161 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "162 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "163 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "164 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "165 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "166 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "167 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "168 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "169 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "170 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "171 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "172 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "173 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "174 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "175 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "176 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "177 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "178 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "179 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "180 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "181 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "182 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "183 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "184 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "185 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "186 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "187 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "188 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "189 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "190 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "191 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "192 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "193 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "194 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "195 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "196 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "197 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "198 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "199 Train Loss 2.8276691 Test MSE 14253.760310154801 Test RE 0.999839498492921\n",
      "Training time: 68.28\n",
      "Training time: 68.28\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 4.9500303 Test MSE 14259.82411184474 Test RE 1.0000521505804134\n",
      "1 Train Loss 4.833738 Test MSE 14261.050313403495 Test RE 1.0000951468732064\n",
      "2 Train Loss 4.7506337 Test MSE 14261.501830452878 Test RE 1.0001109786817253\n",
      "3 Train Loss 3.7568643 Test MSE 14283.178575507323 Test RE 1.0008707485652317\n",
      "4 Train Loss 3.666623 Test MSE 14283.638790768864 Test RE 1.0008868728571947\n",
      "5 Train Loss 3.448328 Test MSE 14277.969206405056 Test RE 1.0006882128426435\n",
      "6 Train Loss 3.4278646 Test MSE 14273.86097569387 Test RE 1.0005442374021474\n",
      "7 Train Loss 3.3105733 Test MSE 14271.938465019786 Test RE 1.000476854731344\n",
      "8 Train Loss 3.2499652 Test MSE 14274.373405235812 Test RE 1.0005621969375766\n",
      "9 Train Loss 3.1935089 Test MSE 14278.290164525133 Test RE 1.0006994601425219\n",
      "10 Train Loss 2.943951 Test MSE 14277.847145013122 Test RE 1.0006839354256156\n",
      "11 Train Loss 2.8676813 Test MSE 14269.289483067183 Test RE 1.0003840023088584\n",
      "12 Train Loss 2.843983 Test MSE 14265.13551109219 Test RE 1.0002383794453862\n",
      "13 Train Loss 2.8314636 Test MSE 14263.008406596 Test RE 1.0001638028361557\n",
      "14 Train Loss 2.8294208 Test MSE 14262.407766209444 Test RE 1.0001427432854388\n",
      "15 Train Loss 2.8292284 Test MSE 14262.27995926371 Test RE 1.0001382620829034\n",
      "16 Train Loss 2.8292227 Test MSE 14262.275515432202 Test RE 1.0001381062716912\n",
      "17 Train Loss 2.8292198 Test MSE 14262.273515760433 Test RE 1.0001380361584753\n",
      "18 Train Loss 2.8292198 Test MSE 14262.273515760433 Test RE 1.0001380361584753\n",
      "19 Train Loss 2.8292198 Test MSE 14262.273515760433 Test RE 1.0001380361584753\n",
      "20 Train Loss 2.8292198 Test MSE 14262.273515760433 Test RE 1.0001380361584753\n",
      "21 Train Loss 2.8292184 Test MSE 14262.273507089389 Test RE 1.0001380358544478\n",
      "22 Train Loss 2.8292134 Test MSE 14262.255231230412 Test RE 1.0001373950594319\n",
      "23 Train Loss 2.8292086 Test MSE 14262.265384387732 Test RE 1.0001377510532892\n",
      "24 Train Loss 2.8292086 Test MSE 14262.265384387732 Test RE 1.0001377510532892\n",
      "25 Train Loss 2.8292086 Test MSE 14262.265384387732 Test RE 1.0001377510532892\n",
      "26 Train Loss 2.8292086 Test MSE 14262.265384387732 Test RE 1.0001377510532892\n",
      "27 Train Loss 2.8292086 Test MSE 14262.265384387732 Test RE 1.0001377510532892\n",
      "28 Train Loss 2.8292086 Test MSE 14262.265384387732 Test RE 1.0001377510532892\n",
      "29 Train Loss 2.8292086 Test MSE 14262.265384387732 Test RE 1.0001377510532892\n",
      "30 Train Loss 2.8292086 Test MSE 14262.265384387732 Test RE 1.0001377510532892\n",
      "31 Train Loss 2.8292086 Test MSE 14262.265384387732 Test RE 1.0001377510532892\n",
      "32 Train Loss 2.8292017 Test MSE 14262.278290131988 Test RE 1.000138203559212\n",
      "33 Train Loss 2.8292017 Test MSE 14262.278290131988 Test RE 1.000138203559212\n",
      "34 Train Loss 2.8292017 Test MSE 14262.278290131988 Test RE 1.000138203559212\n",
      "35 Train Loss 2.8292007 Test MSE 14262.278267985335 Test RE 1.000138202782698\n",
      "36 Train Loss 2.8291996 Test MSE 14262.279782541504 Test RE 1.0001382558866065\n",
      "37 Train Loss 2.829199 Test MSE 14262.271593251708 Test RE 1.000137968750773\n",
      "38 Train Loss 2.8287349 Test MSE 14262.40868075401 Test RE 1.0001427753513816\n",
      "39 Train Loss 2.8286426 Test MSE 14262.409545497763 Test RE 1.0001428056711972\n",
      "40 Train Loss 2.8286111 Test MSE 14262.424363651104 Test RE 1.0001433252280632\n",
      "41 Train Loss 2.8286045 Test MSE 14262.425471415541 Test RE 1.000143364068696\n",
      "42 Train Loss 2.8286037 Test MSE 14262.425408613757 Test RE 1.0001433618667288\n",
      "43 Train Loss 2.8286037 Test MSE 14262.425408613757 Test RE 1.0001433618667288\n",
      "44 Train Loss 2.8286035 Test MSE 14262.427254190632 Test RE 1.0001434265766693\n",
      "45 Train Loss 2.828598 Test MSE 14262.440143174988 Test RE 1.000143878492386\n",
      "46 Train Loss 2.8285842 Test MSE 14262.453942502169 Test RE 1.000144362326468\n",
      "47 Train Loss 2.8285792 Test MSE 14262.458201631682 Test RE 1.0001445116606595\n",
      "48 Train Loss 2.8285735 Test MSE 14262.473251595944 Test RE 1.000145039344421\n",
      "49 Train Loss 2.828567 Test MSE 14262.479839344915 Test RE 1.000145270324826\n",
      "50 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "51 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "52 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "53 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "54 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "55 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "56 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "57 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "58 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "59 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "60 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "61 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "62 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "63 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "64 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "65 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "66 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "67 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "68 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "69 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "70 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "71 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "72 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "73 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "74 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "75 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "76 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "77 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "78 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "79 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "80 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "81 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "82 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "83 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "84 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "85 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "86 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "87 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "88 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "89 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "90 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "91 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "92 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "93 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "94 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "95 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "96 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "97 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "98 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "99 Train Loss 2.8285573 Test MSE 14262.481295633845 Test RE 1.000145321385387\n",
      "100 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "101 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "102 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "103 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "104 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "105 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "106 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "107 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "108 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "109 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "110 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "111 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "112 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "113 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "114 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "115 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "116 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "117 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "118 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "119 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "120 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "121 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "122 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "123 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "124 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "125 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "126 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "127 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "128 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "129 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "130 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "131 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "132 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "133 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "134 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "135 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "136 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "137 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "138 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "139 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "140 Train Loss 2.828557 Test MSE 14262.481294480744 Test RE 1.000145321344957\n",
      "141 Train Loss 2.8285565 Test MSE 14262.481296459939 Test RE 1.0001453214143516\n",
      "142 Train Loss 2.8285565 Test MSE 14262.481296459939 Test RE 1.0001453214143516\n",
      "143 Train Loss 2.8285565 Test MSE 14262.481296459939 Test RE 1.0001453214143516\n",
      "144 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "145 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "146 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "147 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "148 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "149 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "150 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "151 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "152 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "153 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "154 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "155 Train Loss 2.828556 Test MSE 14262.481301131409 Test RE 1.000145321578143\n",
      "156 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "157 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "158 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "159 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "160 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "161 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "162 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "163 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "164 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "165 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "166 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "167 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "168 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "169 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "170 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "171 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "172 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "173 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "174 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "175 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "176 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "177 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "178 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "179 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "180 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "181 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "182 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "183 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "184 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "185 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "186 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "187 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "188 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "189 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "190 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "191 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "192 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "193 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "194 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "195 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "196 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "197 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "198 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "199 Train Loss 2.828553 Test MSE 14262.48241542689 Test RE 1.000145360647691\n",
      "Training time: 68.25\n",
      "Training time: 68.25\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 4.8846745 Test MSE 14259.682471216911 Test RE 1.000047183886396\n",
      "1 Train Loss 4.1967287 Test MSE 14255.220633920773 Test RE 0.9998907148721341\n",
      "2 Train Loss 3.0187922 Test MSE 14254.862210190342 Test RE 0.99987814450153\n",
      "3 Train Loss 2.9832377 Test MSE 14253.187778536505 Test RE 0.99981941798567\n",
      "4 Train Loss 2.9294333 Test MSE 14255.899424733601 Test RE 0.9999145204858492\n",
      "5 Train Loss 2.8895035 Test MSE 14260.420850949495 Test RE 1.0000730752417957\n",
      "6 Train Loss 2.8650658 Test MSE 14264.230547918365 Test RE 1.0002066519776007\n",
      "7 Train Loss 2.852983 Test MSE 14264.652382220767 Test RE 1.000221441361247\n",
      "8 Train Loss 2.837194 Test MSE 14267.34393232186 Test RE 1.0003158011489381\n",
      "9 Train Loss 2.8319983 Test MSE 14269.577179217606 Test RE 1.0003940870848416\n",
      "10 Train Loss 2.8319252 Test MSE 14269.83769072381 Test RE 1.000403218854399\n",
      "11 Train Loss 2.831917 Test MSE 14269.868596852117 Test RE 1.0004043022084694\n",
      "12 Train Loss 2.8319094 Test MSE 14269.894049968703 Test RE 1.000405194416965\n",
      "13 Train Loss 2.831903 Test MSE 14269.915040990722 Test RE 1.0004059302149906\n",
      "14 Train Loss 2.8318937 Test MSE 14269.932178287567 Test RE 1.000406530928036\n",
      "15 Train Loss 2.8318863 Test MSE 14269.945741156682 Test RE 1.0004070063465402\n",
      "16 Train Loss 2.831411 Test MSE 14269.355018542248 Test RE 1.0003862995698976\n",
      "17 Train Loss 2.8309772 Test MSE 14268.372173746684 Test RE 1.0003518466672252\n",
      "18 Train Loss 2.8304708 Test MSE 14267.262779477176 Test RE 1.0003129562400095\n",
      "19 Train Loss 2.8296869 Test MSE 14265.818914693107 Test RE 1.0002623385000688\n",
      "20 Train Loss 2.8296797 Test MSE 14265.786961535616 Test RE 1.0002612182854453\n",
      "21 Train Loss 2.829676 Test MSE 14265.75297637283 Test RE 1.0002600268313506\n",
      "22 Train Loss 2.8296726 Test MSE 14265.725648767077 Test RE 1.0002590687773032\n",
      "23 Train Loss 2.8296702 Test MSE 14265.698594042691 Test RE 1.000258120289055\n",
      "24 Train Loss 2.8296678 Test MSE 14265.663843688208 Test RE 1.0002569020050298\n",
      "25 Train Loss 2.8296647 Test MSE 14265.625322340275 Test RE 1.00025555151512\n",
      "26 Train Loss 2.8296611 Test MSE 14265.576278250954 Test RE 1.0002538321139838\n",
      "27 Train Loss 2.8296578 Test MSE 14265.52249396574 Test RE 1.0002519465263617\n",
      "28 Train Loss 2.8296516 Test MSE 14265.44788102287 Test RE 1.0002493307147446\n",
      "29 Train Loss 2.829644 Test MSE 14265.35905466104 Test RE 1.0002462165942483\n",
      "30 Train Loss 2.829635 Test MSE 14265.235797156749 Test RE 1.0002418953529049\n",
      "31 Train Loss 2.8290648 Test MSE 14259.022255839547 Test RE 1.0000240328038714\n",
      "32 Train Loss 2.8279078 Test MSE 14255.259662749231 Test RE 0.9998920836526488\n",
      "33 Train Loss 2.8272042 Test MSE 14249.995545647142 Test RE 0.9997074488176161\n",
      "34 Train Loss 2.8271239 Test MSE 14248.698047088254 Test RE 0.9996619348208626\n",
      "35 Train Loss 2.827116 Test MSE 14248.594892085754 Test RE 0.9996583162335475\n",
      "36 Train Loss 2.8271105 Test MSE 14248.517051806666 Test RE 0.9996555856559293\n",
      "37 Train Loss 2.8271053 Test MSE 14248.491750533909 Test RE 0.9996546981049732\n",
      "38 Train Loss 2.827102 Test MSE 14248.465188221582 Test RE 0.9996537663167828\n",
      "39 Train Loss 2.8270974 Test MSE 14248.46022830558 Test RE 0.9996535923261431\n",
      "40 Train Loss 2.8270974 Test MSE 14248.46022830558 Test RE 0.9996535923261431\n",
      "41 Train Loss 2.8270974 Test MSE 14248.46022830558 Test RE 0.9996535923261431\n",
      "42 Train Loss 2.8270974 Test MSE 14248.46022830558 Test RE 0.9996535923261431\n",
      "43 Train Loss 2.8270974 Test MSE 14248.46022830558 Test RE 0.9996535923261431\n",
      "44 Train Loss 2.8270974 Test MSE 14248.46022830558 Test RE 0.9996535923261431\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 263.30\n",
      "Training time: 263.30\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 4.873288 Test MSE 14259.90008223752 Test RE 1.0000548145071524\n",
      "1 Train Loss 4.6639805 Test MSE 14260.981224497273 Test RE 1.000092724346044\n",
      "2 Train Loss 4.3433933 Test MSE 14260.94249386944 Test RE 1.0000913662962436\n",
      "3 Train Loss 3.830227 Test MSE 14264.190304034231 Test RE 1.000205241027712\n",
      "4 Train Loss 3.6334252 Test MSE 14269.469549182106 Test RE 1.0003903142801962\n",
      "5 Train Loss 3.5946975 Test MSE 14273.87650977427 Test RE 1.0005447818424509\n",
      "6 Train Loss 2.9066098 Test MSE 14274.42502017097 Test RE 1.0005640059103686\n",
      "7 Train Loss 2.8552704 Test MSE 14283.510968814397 Test RE 1.0008823944604648\n",
      "8 Train Loss 2.8462484 Test MSE 14290.456928440144 Test RE 1.0011257255201766\n",
      "9 Train Loss 2.8462238 Test MSE 14290.662326957763 Test RE 1.0011329201467067\n",
      "10 Train Loss 2.8455498 Test MSE 14291.10718263635 Test RE 1.0011485022166102\n",
      "11 Train Loss 2.8439083 Test MSE 14286.97560825591 Test RE 1.0010037752039749\n",
      "12 Train Loss 2.843581 Test MSE 14285.399014613575 Test RE 1.0009485423901077\n",
      "13 Train Loss 2.8431869 Test MSE 14284.509767213545 Test RE 1.0009173880366253\n",
      "14 Train Loss 2.8428192 Test MSE 14283.420434061778 Test RE 1.000879222453814\n",
      "15 Train Loss 2.842495 Test MSE 14282.969600320937 Test RE 1.00086342673854\n",
      "16 Train Loss 2.8421693 Test MSE 14282.805583154657 Test RE 1.0008576800605395\n",
      "17 Train Loss 2.8416502 Test MSE 14282.16062143021 Test RE 1.0008350821830088\n",
      "18 Train Loss 2.841056 Test MSE 14281.178172870534 Test RE 1.0008006586135991\n",
      "19 Train Loss 2.840209 Test MSE 14280.38964736702 Test RE 1.0007730289696304\n",
      "20 Train Loss 2.8391747 Test MSE 14279.361501912621 Test RE 1.0007370019848334\n",
      "21 Train Loss 2.8379927 Test MSE 14277.817352903023 Test RE 1.0006828914131247\n",
      "22 Train Loss 2.8368366 Test MSE 14276.334687791039 Test RE 1.0006309326264864\n",
      "23 Train Loss 2.8357952 Test MSE 14274.640168085829 Test RE 1.0005715462648177\n",
      "24 Train Loss 2.8344917 Test MSE 14272.302330008482 Test RE 1.0004896082959722\n",
      "25 Train Loss 2.8335474 Test MSE 14270.031979047211 Test RE 1.0004100292332816\n",
      "26 Train Loss 2.8333085 Test MSE 14268.67664195402 Test RE 1.000362519703538\n",
      "27 Train Loss 2.8332732 Test MSE 14268.393058777885 Test RE 1.0003525787889984\n",
      "28 Train Loss 2.8332624 Test MSE 14268.170534095096 Test RE 1.0003447781905965\n",
      "29 Train Loss 2.8332336 Test MSE 14267.857091804612 Test RE 1.0003337903740495\n",
      "30 Train Loss 2.833232 Test MSE 14267.767063309686 Test RE 1.000330634374972\n",
      "31 Train Loss 2.8332236 Test MSE 14267.676145004101 Test RE 1.0003274471729808\n",
      "32 Train Loss 2.833219 Test MSE 14267.573000667282 Test RE 1.0003238313669949\n",
      "33 Train Loss 2.8332121 Test MSE 14267.482511771324 Test RE 1.0003206591966958\n",
      "34 Train Loss 2.8332121 Test MSE 14267.482511771324 Test RE 1.0003206591966958\n",
      "35 Train Loss 2.8332067 Test MSE 14267.36557081835 Test RE 1.0003165597106525\n",
      "36 Train Loss 2.8332047 Test MSE 14267.254227469639 Test RE 1.0003126564388016\n",
      "37 Train Loss 2.833203 Test MSE 14267.166004075161 Test RE 1.0003095636532835\n",
      "38 Train Loss 2.833203 Test MSE 14267.166004075161 Test RE 1.0003095636532835\n",
      "39 Train Loss 2.8331978 Test MSE 14267.149027536543 Test RE 1.000308968517607\n",
      "40 Train Loss 2.8331978 Test MSE 14267.149027536543 Test RE 1.000308968517607\n",
      "41 Train Loss 2.8331957 Test MSE 14267.046108498578 Test RE 1.0003053605430154\n",
      "42 Train Loss 2.8331919 Test MSE 14267.035549375038 Test RE 1.0003049903770485\n",
      "43 Train Loss 2.8331883 Test MSE 14266.908330238317 Test RE 1.0003005305079824\n",
      "44 Train Loss 2.83291 Test MSE 14265.71158350528 Test RE 1.0002585756755333\n",
      "45 Train Loss 2.83185 Test MSE 14264.9639445611 Test RE 1.0002323645027005\n",
      "46 Train Loss 2.8309221 Test MSE 14265.874894181747 Test RE 1.0002643010274084\n",
      "47 Train Loss 2.8308933 Test MSE 14265.952175733735 Test RE 1.0002670103555595\n",
      "48 Train Loss 2.8308933 Test MSE 14265.952175733735 Test RE 1.0002670103555595\n",
      "49 Train Loss 2.8308933 Test MSE 14265.952175733735 Test RE 1.0002670103555595\n",
      "50 Train Loss 2.8308933 Test MSE 14265.952175733735 Test RE 1.0002670103555595\n",
      "51 Train Loss 2.8308902 Test MSE 14265.979875669034 Test RE 1.000267981455058\n",
      "52 Train Loss 2.8308902 Test MSE 14265.979875669034 Test RE 1.000267981455058\n",
      "53 Train Loss 2.8308902 Test MSE 14265.979875669034 Test RE 1.000267981455058\n",
      "54 Train Loss 2.8308883 Test MSE 14265.998422529115 Test RE 1.0002686316671163\n",
      "55 Train Loss 2.8308809 Test MSE 14266.008220716474 Test RE 1.00026897516981\n",
      "56 Train Loss 2.8308728 Test MSE 14266.009064527525 Test RE 1.0002690047519462\n",
      "57 Train Loss 2.830866 Test MSE 14266.004622465909 Test RE 1.0002688490231482\n",
      "58 Train Loss 2.8308127 Test MSE 14265.81381614034 Test RE 1.000262159754958\n",
      "59 Train Loss 2.8305712 Test MSE 14265.10012047524 Test RE 1.0002371386904256\n",
      "60 Train Loss 2.83005 Test MSE 14263.94898195258 Test RE 1.0001967802379095\n",
      "61 Train Loss 2.829577 Test MSE 14262.76156998775 Test RE 1.0001551483467988\n",
      "62 Train Loss 2.8291569 Test MSE 14261.962841603488 Test RE 1.0001271431289391\n",
      "63 Train Loss 2.8287513 Test MSE 14260.882065556694 Test RE 1.00008924743566\n",
      "64 Train Loss 2.8284295 Test MSE 14259.905964387232 Test RE 1.0000550207663652\n",
      "65 Train Loss 2.828307 Test MSE 14259.511929332404 Test RE 1.0000412037237374\n",
      "66 Train Loss 2.8281224 Test MSE 14258.926426254748 Test RE 1.0000206724034475\n",
      "67 Train Loss 2.8281028 Test MSE 14258.867771988982 Test RE 1.0000186156027857\n",
      "68 Train Loss 2.8280807 Test MSE 14258.778828807739 Test RE 1.0000154966673591\n",
      "69 Train Loss 2.8280585 Test MSE 14258.640379471964 Test RE 1.0000106416997978\n",
      "70 Train Loss 2.8280525 Test MSE 14258.594548298996 Test RE 1.0000090345445465\n",
      "71 Train Loss 2.8280437 Test MSE 14258.556026748978 Test RE 1.0000076837128102\n",
      "72 Train Loss 2.8280404 Test MSE 14258.511683914934 Test RE 1.0000061287443704\n",
      "73 Train Loss 2.8280325 Test MSE 14258.467025533442 Test RE 1.0000045627081966\n",
      "74 Train Loss 2.8280308 Test MSE 14258.418771631857 Test RE 1.000002870585106\n",
      "75 Train Loss 2.8280225 Test MSE 14258.376945497548 Test RE 1.0000014038626834\n",
      "76 Train Loss 2.828021 Test MSE 14258.30281791879 Test RE 0.9999988044160758\n",
      "77 Train Loss 2.8280163 Test MSE 14258.258603691807 Test RE 0.9999972539437312\n",
      "78 Train Loss 2.8280137 Test MSE 14258.224824853227 Test RE 0.9999960694103753\n",
      "79 Train Loss 2.8280103 Test MSE 14258.18766841502 Test RE 0.9999947664320301\n",
      "80 Train Loss 2.8280087 Test MSE 14258.14366846993 Test RE 0.9999932234677424\n",
      "81 Train Loss 2.8280017 Test MSE 14258.098902173393 Test RE 0.9999916536270481\n",
      "82 Train Loss 2.8280008 Test MSE 14258.04398737041 Test RE 0.999989727900558\n",
      "83 Train Loss 2.8279948 Test MSE 14257.98659665983 Test RE 0.9999877153461408\n",
      "84 Train Loss 2.8279903 Test MSE 14257.940041969174 Test RE 0.9999860827819483\n",
      "85 Train Loss 2.8279889 Test MSE 14257.888813731573 Test RE 0.9999842863243078\n",
      "86 Train Loss 2.8279812 Test MSE 14257.831616631933 Test RE 0.9999822805484533\n",
      "87 Train Loss 2.8279772 Test MSE 14257.771599400789 Test RE 0.9999801758724954\n",
      "88 Train Loss 2.8279734 Test MSE 14257.721176663175 Test RE 0.9999784076514853\n",
      "89 Train Loss 2.8279562 Test MSE 14257.631627944533 Test RE 0.9999752673556214\n",
      "90 Train Loss 2.827949 Test MSE 14257.596127189945 Test RE 0.9999740224118752\n",
      "91 Train Loss 2.827948 Test MSE 14257.541097379832 Test RE 0.9999720926183396\n",
      "92 Train Loss 2.82793 Test MSE 14257.489707740171 Test RE 0.9999702904754788\n",
      "93 Train Loss 2.82793 Test MSE 14257.489707740171 Test RE 0.9999702904754788\n",
      "94 Train Loss 2.8279254 Test MSE 14257.466739224934 Test RE 0.9999694850096299\n",
      "95 Train Loss 2.8279233 Test MSE 14257.443574383415 Test RE 0.9999686726583027\n",
      "96 Train Loss 2.8279183 Test MSE 14257.422555324212 Test RE 0.9999679355553157\n",
      "97 Train Loss 2.827916 Test MSE 14257.377181053895 Test RE 0.9999663443542648\n",
      "98 Train Loss 2.827909 Test MSE 14257.363993564642 Test RE 0.9999658818902258\n",
      "99 Train Loss 2.8279052 Test MSE 14257.360200593574 Test RE 0.9999657488767909\n",
      "100 Train Loss 2.8279033 Test MSE 14257.345236346686 Test RE 0.9999652241043908\n",
      "101 Train Loss 2.8279002 Test MSE 14257.334665020322 Test RE 0.9999648533845784\n",
      "102 Train Loss 2.827891 Test MSE 14257.32657367558 Test RE 0.9999645696337341\n",
      "103 Train Loss 2.827888 Test MSE 14257.321579938438 Test RE 0.9999643945111178\n",
      "104 Train Loss 2.8278825 Test MSE 14257.31171535541 Test RE 0.999964048575402\n",
      "105 Train Loss 2.8278792 Test MSE 14257.310375376606 Test RE 0.9999640015844025\n",
      "106 Train Loss 2.8278732 Test MSE 14257.288682614435 Test RE 0.9999632408522253\n",
      "107 Train Loss 2.8278692 Test MSE 14257.2906358333 Test RE 0.9999633093486642\n",
      "108 Train Loss 2.8278654 Test MSE 14257.291720934678 Test RE 0.99996334740153\n",
      "109 Train Loss 2.8278625 Test MSE 14257.295156936929 Test RE 0.999963467896929\n",
      "110 Train Loss 2.8278596 Test MSE 14257.291696751332 Test RE 0.9999633465534568\n",
      "111 Train Loss 2.8278556 Test MSE 14257.294012723194 Test RE 0.9999634277710867\n",
      "112 Train Loss 2.827849 Test MSE 14257.290470975791 Test RE 0.99996330356736\n",
      "113 Train Loss 2.8278427 Test MSE 14257.290670161257 Test RE 0.9999633105524935\n",
      "114 Train Loss 2.8278372 Test MSE 14257.297758065195 Test RE 0.9999635591145511\n",
      "115 Train Loss 2.8278308 Test MSE 14257.300756342816 Test RE 0.999963664259588\n",
      "116 Train Loss 2.8278224 Test MSE 14257.312050920455 Test RE 0.9999640603431525\n",
      "117 Train Loss 2.827819 Test MSE 14257.323915170009 Test RE 0.999964476404071\n",
      "118 Train Loss 2.8278022 Test MSE 14257.349198589149 Test RE 0.9999653630539755\n",
      "119 Train Loss 2.8277988 Test MSE 14257.377156557232 Test RE 0.9999663434952063\n",
      "120 Train Loss 2.8277915 Test MSE 14257.381463262802 Test RE 0.999966494524398\n",
      "121 Train Loss 2.8277829 Test MSE 14257.391286369395 Test RE 0.9999668390047571\n",
      "122 Train Loss 2.8277771 Test MSE 14257.408187785388 Test RE 0.9999674317096282\n",
      "123 Train Loss 2.8277743 Test MSE 14257.426342744024 Test RE 0.9999680683737867\n",
      "124 Train Loss 2.8277566 Test MSE 14257.48645415192 Test RE 0.9999701763778415\n",
      "125 Train Loss 2.8277495 Test MSE 14257.511602775437 Test RE 0.9999710582956495\n",
      "126 Train Loss 2.8277454 Test MSE 14257.53978405232 Test RE 0.9999720465623306\n",
      "127 Train Loss 2.827737 Test MSE 14257.567243176 Test RE 0.9999730095034584\n",
      "128 Train Loss 2.827728 Test MSE 14257.613727147887 Test RE 0.9999746396090224\n",
      "129 Train Loss 2.8277228 Test MSE 14257.646075716302 Test RE 0.9999757740109746\n",
      "130 Train Loss 2.8277068 Test MSE 14257.73037964229 Test RE 0.9999787303811418\n",
      "131 Train Loss 2.8277009 Test MSE 14257.765845162123 Test RE 0.9999799740834173\n",
      "132 Train Loss 2.8276951 Test MSE 14257.790520576675 Test RE 0.9999808393981519\n",
      "133 Train Loss 2.8276906 Test MSE 14257.817378617474 Test RE 0.9999817812521332\n",
      "134 Train Loss 2.8276846 Test MSE 14257.840162193826 Test RE 0.9999825802226753\n",
      "135 Train Loss 2.8276749 Test MSE 14257.868842313965 Test RE 0.9999835859712946\n",
      "136 Train Loss 2.827666 Test MSE 14257.895959711872 Test RE 0.9999845369177582\n",
      "137 Train Loss 2.8276587 Test MSE 14257.908593266191 Test RE 0.9999849799479291\n",
      "138 Train Loss 2.8276544 Test MSE 14257.92249555959 Test RE 0.9999854674696825\n",
      "139 Train Loss 2.8276455 Test MSE 14257.929780340584 Test RE 0.999985722930259\n",
      "140 Train Loss 2.8275573 Test MSE 14257.677861428738 Test RE 0.9999768886733985\n",
      "141 Train Loss 2.8275506 Test MSE 14257.642035522089 Test RE 0.9999756323292199\n",
      "142 Train Loss 2.8275445 Test MSE 14257.613176902807 Test RE 0.9999746203129767\n",
      "143 Train Loss 2.827541 Test MSE 14257.584795434454 Test RE 0.999973625028499\n",
      "144 Train Loss 2.8275259 Test MSE 14257.526206683897 Test RE 0.9999715704285681\n",
      "145 Train Loss 2.8275092 Test MSE 14257.454307360023 Test RE 0.9999690490454961\n",
      "146 Train Loss 2.8274934 Test MSE 14257.41331690298 Test RE 0.9999676115792794\n",
      "147 Train Loss 2.8274858 Test MSE 14257.384648209647 Test RE 0.999966606215313\n",
      "148 Train Loss 2.8274791 Test MSE 14257.346926349004 Test RE 0.9999652833701047\n",
      "149 Train Loss 2.8274696 Test MSE 14257.329870841235 Test RE 0.9999646852602027\n",
      "150 Train Loss 2.8274665 Test MSE 14257.301383747119 Test RE 0.9999636862617017\n",
      "151 Train Loss 2.8274603 Test MSE 14257.250494112019 Test RE 0.9999619016381202\n",
      "152 Train Loss 2.8274548 Test MSE 14257.228324624017 Test RE 0.9999611241862545\n",
      "153 Train Loss 2.827452 Test MSE 14257.19091152339 Test RE 0.9999598121615797\n",
      "154 Train Loss 2.8274422 Test MSE 14257.17018061828 Test RE 0.9999590851572334\n",
      "155 Train Loss 2.8274348 Test MSE 14257.116263586662 Test RE 0.999957194358572\n",
      "156 Train Loss 2.8274345 Test MSE 14257.096300622165 Test RE 0.9999564942830246\n",
      "157 Train Loss 2.8274262 Test MSE 14257.085257819797 Test RE 0.9999561070259052\n",
      "158 Train Loss 2.827426 Test MSE 14257.074508914086 Test RE 0.9999557300752262\n",
      "159 Train Loss 2.8274174 Test MSE 14257.064887114499 Test RE 0.9999553926506287\n",
      "160 Train Loss 2.8274164 Test MSE 14257.069931095895 Test RE 0.9999555695368251\n",
      "161 Train Loss 2.8274112 Test MSE 14257.063514774205 Test RE 0.9999553445243446\n",
      "162 Train Loss 2.8274045 Test MSE 14257.038820041254 Test RE 0.9999544785100751\n",
      "163 Train Loss 2.8273983 Test MSE 14257.037213173102 Test RE 0.9999544221591362\n",
      "164 Train Loss 2.827392 Test MSE 14257.037325778616 Test RE 0.9999544261080766\n",
      "165 Train Loss 2.8273919 Test MSE 14257.027834872168 Test RE 0.9999540932733062\n",
      "166 Train Loss 2.827385 Test MSE 14257.026326079864 Test RE 0.9999540403617491\n",
      "167 Train Loss 2.827378 Test MSE 14257.004465242006 Test RE 0.9999532737277745\n",
      "168 Train Loss 2.8273754 Test MSE 14256.994452899839 Test RE 0.9999529226064674\n",
      "169 Train Loss 2.8273728 Test MSE 14256.98526289744 Test RE 0.9999526003235604\n",
      "170 Train Loss 2.8273678 Test MSE 14256.97519895653 Test RE 0.9999522473925068\n",
      "171 Train Loss 2.8273635 Test MSE 14256.962300056657 Test RE 0.9999517950424589\n",
      "172 Train Loss 2.8273613 Test MSE 14256.953832276187 Test RE 0.9999514980867201\n",
      "173 Train Loss 2.8273547 Test MSE 14256.935702010953 Test RE 0.9999508622779822\n",
      "174 Train Loss 2.8273485 Test MSE 14256.923755729735 Test RE 0.9999504433346359\n",
      "175 Train Loss 2.8273447 Test MSE 14256.885002148114 Test RE 0.999949084286635\n",
      "176 Train Loss 2.8273408 Test MSE 14256.878320949507 Test RE 0.9999488499837277\n",
      "177 Train Loss 2.8273373 Test MSE 14256.863870814606 Test RE 0.9999483432318598\n",
      "178 Train Loss 2.8273323 Test MSE 14256.840576250488 Test RE 0.9999475263141097\n",
      "179 Train Loss 2.8273299 Test MSE 14256.809743112177 Test RE 0.9999464450248546\n",
      "180 Train Loss 2.8273218 Test MSE 14256.777041495596 Test RE 0.9999452982085406\n",
      "181 Train Loss 2.8273137 Test MSE 14256.714353133091 Test RE 0.9999430997803099\n",
      "182 Train Loss 2.8273127 Test MSE 14256.696440649583 Test RE 0.9999424716036676\n",
      "183 Train Loss 2.8273044 Test MSE 14256.675530421267 Test RE 0.9999417382979844\n",
      "184 Train Loss 2.8273003 Test MSE 14256.635216531327 Test RE 0.9999403245192392\n",
      "185 Train Loss 2.8272943 Test MSE 14256.599624210625 Test RE 0.9999390763208253\n",
      "186 Train Loss 2.827288 Test MSE 14256.56412612142 Test RE 0.9999378314254943\n",
      "187 Train Loss 2.8272822 Test MSE 14256.521943745327 Test RE 0.999936352114473\n",
      "188 Train Loss 2.8272746 Test MSE 14256.470614297257 Test RE 0.9999345520180868\n",
      "189 Train Loss 2.8272672 Test MSE 14256.420738989904 Test RE 0.9999328029145362\n",
      "190 Train Loss 2.8272614 Test MSE 14256.378721225057 Test RE 0.999931329368928\n",
      "191 Train Loss 2.8272574 Test MSE 14256.336672423024 Test RE 0.999929854732685\n",
      "192 Train Loss 2.8272421 Test MSE 14256.245447782623 Test RE 0.9999266555101415\n",
      "193 Train Loss 2.8272407 Test MSE 14256.224596522668 Test RE 0.9999259242608678\n",
      "194 Train Loss 2.8272321 Test MSE 14256.19381238905 Test RE 0.9999248446668396\n",
      "195 Train Loss 2.827227 Test MSE 14256.161108459404 Test RE 0.9999236977446331\n",
      "196 Train Loss 2.8272195 Test MSE 14256.0897486726 Test RE 0.9999211951623937\n",
      "197 Train Loss 2.8272152 Test MSE 14256.064685356398 Test RE 0.9999203161923346\n",
      "198 Train Loss 2.8272069 Test MSE 14256.038310240538 Test RE 0.9999193912166496\n",
      "199 Train Loss 2.8272035 Test MSE 14255.991396192689 Test RE 0.9999177459382159\n",
      "Training time: 58.18\n",
      "Training time: 58.18\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 4.562679 Test MSE 14266.437513636998 Test RE 1.0002840251106422\n",
      "1 Train Loss 4.4244857 Test MSE 14263.352791842042 Test RE 1.0001758774128635\n",
      "2 Train Loss 4.191902 Test MSE 14259.777495900886 Test RE 1.0000505159735404\n",
      "3 Train Loss 3.8400245 Test MSE 14262.827956451962 Test RE 1.0001574759706031\n",
      "4 Train Loss 3.7253878 Test MSE 14267.018345302069 Test RE 1.0003043872620854\n",
      "5 Train Loss 3.6985545 Test MSE 14267.181019969059 Test RE 1.000310090055595\n",
      "6 Train Loss 3.3692124 Test MSE 14258.03694064532 Test RE 0.9999894807890473\n",
      "7 Train Loss 3.2073016 Test MSE 14261.297671541004 Test RE 1.000103820168466\n",
      "8 Train Loss 3.1086345 Test MSE 14266.713453809356 Test RE 1.0002936987664293\n",
      "9 Train Loss 3.0115142 Test MSE 14269.134086227517 Test RE 1.0003785550532038\n",
      "10 Train Loss 2.9273822 Test MSE 14272.487057901793 Test RE 1.000496082995545\n",
      "11 Train Loss 2.8759198 Test MSE 14273.21803998979 Test RE 1.0005217034549956\n",
      "12 Train Loss 2.8737705 Test MSE 14272.910810579195 Test RE 1.0005109353385648\n",
      "13 Train Loss 2.851918 Test MSE 14273.112338881747 Test RE 1.0005179987386457\n",
      "14 Train Loss 2.8433979 Test MSE 14273.639142028622 Test RE 1.000536462517056\n",
      "15 Train Loss 2.8384233 Test MSE 14270.478679422913 Test RE 1.0004256872233748\n",
      "16 Train Loss 2.834618 Test MSE 14267.424334164636 Test RE 1.0003186197226281\n",
      "17 Train Loss 2.8342166 Test MSE 14265.994426229314 Test RE 1.0002684915656843\n",
      "18 Train Loss 2.8338811 Test MSE 14265.996374788734 Test RE 1.00026855987787\n",
      "19 Train Loss 2.833092 Test MSE 14265.803624237855 Test RE 1.000261802447049\n",
      "20 Train Loss 2.8319771 Test MSE 14264.305774920054 Test RE 1.000209289429654\n",
      "21 Train Loss 2.8311145 Test MSE 14263.404438109397 Test RE 1.0001776881829105\n",
      "22 Train Loss 2.8301384 Test MSE 14261.336331364624 Test RE 1.0001051757187103\n",
      "23 Train Loss 2.8293872 Test MSE 14258.709135544952 Test RE 1.0000130527544266\n",
      "24 Train Loss 2.829058 Test MSE 14256.937180417463 Test RE 0.9999509141241101\n",
      "25 Train Loss 2.8281894 Test MSE 14255.834177749757 Test RE 0.9999122322583839\n",
      "26 Train Loss 2.8281076 Test MSE 14255.726446054694 Test RE 0.999908454070385\n",
      "27 Train Loss 2.8281028 Test MSE 14255.690694851699 Test RE 0.9999072002601117\n",
      "28 Train Loss 2.8280993 Test MSE 14255.648933409539 Test RE 0.9999057356661406\n",
      "29 Train Loss 2.82803 Test MSE 14255.017118224732 Test RE 0.9998835773403366\n",
      "30 Train Loss 2.8280027 Test MSE 14254.750239769426 Test RE 0.9998742175257755\n",
      "31 Train Loss 2.8279984 Test MSE 14254.666339875126 Test RE 0.9998712750166757\n",
      "32 Train Loss 2.8279886 Test MSE 14254.599564595304 Test RE 0.9998689330901522\n",
      "33 Train Loss 2.827987 Test MSE 14254.534823982021 Test RE 0.9998666625177262\n",
      "34 Train Loss 2.827987 Test MSE 14254.534823982021 Test RE 0.9998666625177262\n",
      "35 Train Loss 2.827987 Test MSE 14254.534823982021 Test RE 0.9998666625177262\n",
      "36 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "37 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "38 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "39 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "40 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "41 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "42 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "43 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "44 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "45 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "46 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "47 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "48 Train Loss 2.8279867 Test MSE 14254.534837981379 Test RE 0.9998666630087102\n",
      "49 Train Loss 2.8279858 Test MSE 14254.534485017706 Test RE 0.9998666506296106\n",
      "50 Train Loss 2.8279858 Test MSE 14254.534485017706 Test RE 0.9998666506296106\n",
      "51 Train Loss 2.8279858 Test MSE 14254.534485017706 Test RE 0.9998666506296106\n",
      "52 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "53 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "54 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "55 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "56 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "57 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "58 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "59 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "60 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "61 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "62 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "63 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "64 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "65 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "66 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "67 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "68 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "69 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "70 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "71 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "72 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "73 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "74 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "75 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "76 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "77 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "78 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "79 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "80 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "81 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "82 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "83 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "84 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "85 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "86 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "87 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "88 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "89 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "90 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "91 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "92 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "93 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "94 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "95 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "96 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "97 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "98 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "99 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "100 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "101 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "102 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "103 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "104 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "105 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "106 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "107 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "108 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "109 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "110 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "111 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "112 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "113 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "114 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "115 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "116 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "117 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "118 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "119 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "120 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "121 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "122 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "123 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "124 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "125 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "126 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "127 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "128 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "129 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "130 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "131 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "132 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "133 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "134 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "135 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "136 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "137 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "138 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "139 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "140 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "141 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "142 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "143 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "144 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "145 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "146 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "147 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "148 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "149 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "150 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "151 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "152 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "153 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "154 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "155 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "156 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "157 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "158 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "159 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "160 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "161 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "162 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "163 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "164 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "165 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "166 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "167 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "168 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "169 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "170 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "171 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "172 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "173 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "174 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "175 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "176 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "177 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "178 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "179 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "180 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "181 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "182 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "183 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "184 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "185 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "186 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "187 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "188 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "189 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "190 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "191 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "192 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "193 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "194 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "195 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "196 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "197 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "198 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "199 Train Loss 2.8279796 Test MSE 14254.489620103435 Test RE 0.9998650771314753\n",
      "Training time: 85.16\n",
      "Training time: 85.16\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 5.836217 Test MSE 14248.243641224966 Test RE 0.9996459945621565\n",
      "1 Train Loss 5.069679 Test MSE 14254.89445337096 Test RE 0.9998792753168582\n",
      "2 Train Loss 4.9791374 Test MSE 14256.194178223202 Test RE 0.9999248574965843\n",
      "3 Train Loss 4.9727426 Test MSE 14256.43277704336 Test RE 0.9999332250836843\n",
      "4 Train Loss 4.972377 Test MSE 14256.443210184647 Test RE 0.9999335909691367\n",
      "5 Train Loss 4.9537 Test MSE 14255.064195618666 Test RE 0.9998852284037414\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 331.90\n",
      "Training time: 331.90\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 4.8811927 Test MSE 14261.169467848027 Test RE 1.0000993248800911\n",
      "1 Train Loss 4.833713 Test MSE 14260.832362568804 Test RE 1.0000875046448972\n",
      "2 Train Loss 4.74446 Test MSE 14261.924597658235 Test RE 1.0001258021903259\n",
      "3 Train Loss 3.6282203 Test MSE 14285.402839918104 Test RE 1.000948676405711\n",
      "4 Train Loss 3.582123 Test MSE 14283.089222176335 Test RE 1.0008676179149125\n",
      "5 Train Loss 3.4690309 Test MSE 14280.381343442043 Test RE 1.000772737999091\n",
      "6 Train Loss 3.435387 Test MSE 14277.216253651855 Test RE 1.0006618267064935\n",
      "7 Train Loss 3.4219093 Test MSE 14274.800625399024 Test RE 1.0005771698241128\n",
      "8 Train Loss 3.3756056 Test MSE 14273.438302471366 Test RE 1.0005294233869149\n",
      "9 Train Loss 3.2203937 Test MSE 14274.867522172814 Test RE 1.0005795143509444\n",
      "10 Train Loss 2.9997444 Test MSE 14279.255775072703 Test RE 1.0007332971638354\n",
      "11 Train Loss 2.8701534 Test MSE 14274.44264632839 Test RE 1.000564623661809\n",
      "12 Train Loss 2.8525152 Test MSE 14272.558910859567 Test RE 1.0004986014253052\n",
      "13 Train Loss 2.842266 Test MSE 14275.064828510354 Test RE 1.000586429301185\n",
      "14 Train Loss 2.8365858 Test MSE 14276.989251032537 Test RE 1.0006538715927444\n",
      "15 Train Loss 2.8364594 Test MSE 14277.212094309176 Test RE 1.0006616809464355\n",
      "16 Train Loss 2.8354847 Test MSE 14277.69094597852 Test RE 1.0006784616910056\n",
      "17 Train Loss 2.8339496 Test MSE 14276.229056200638 Test RE 1.0006272307508075\n",
      "18 Train Loss 2.8339229 Test MSE 14276.115022382523 Test RE 1.0006232344023653\n",
      "19 Train Loss 2.8339145 Test MSE 14276.070973648726 Test RE 1.0006216906973582\n",
      "20 Train Loss 2.8339107 Test MSE 14276.037052131016 Test RE 1.0006205019029546\n",
      "21 Train Loss 2.8339057 Test MSE 14276.000710862687 Test RE 1.0006192283057662\n",
      "22 Train Loss 2.8339007 Test MSE 14275.9708750186 Test RE 1.0006181826930807\n",
      "23 Train Loss 2.8338838 Test MSE 14275.90579174157 Test RE 1.0006159018119702\n",
      "24 Train Loss 2.8337505 Test MSE 14275.691884221094 Test RE 1.0006084052624895\n",
      "25 Train Loss 2.833738 Test MSE 14275.711703036919 Test RE 1.0006090998301145\n",
      "26 Train Loss 2.8337348 Test MSE 14275.724397722346 Test RE 1.000609544726145\n",
      "27 Train Loss 2.833731 Test MSE 14275.736421353165 Test RE 1.0006099661043144\n",
      "28 Train Loss 2.833731 Test MSE 14275.736421353165 Test RE 1.0006099661043144\n",
      "29 Train Loss 2.833731 Test MSE 14275.736421353165 Test RE 1.0006099661043144\n",
      "30 Train Loss 2.8337266 Test MSE 14275.736399186326 Test RE 1.0006099653274592\n",
      "31 Train Loss 2.8337266 Test MSE 14275.736399186326 Test RE 1.0006099653274592\n",
      "32 Train Loss 2.8337266 Test MSE 14275.736399186326 Test RE 1.0006099653274592\n",
      "33 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "34 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "35 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "36 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "37 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "38 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "39 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "40 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "41 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "42 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "43 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "44 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "45 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "46 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "47 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "48 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "49 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "50 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "51 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "52 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "53 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "54 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "55 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "56 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "57 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "58 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "59 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "60 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "61 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "62 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "63 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "64 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "65 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "66 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "67 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "68 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "69 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "70 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "71 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "72 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "73 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "74 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "75 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "76 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "77 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "78 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "79 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "80 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "81 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "82 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "83 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "84 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "85 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "86 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "87 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "88 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "89 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "90 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "91 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "92 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "93 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "94 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "95 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "96 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "97 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "98 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "99 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "100 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "101 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "102 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "103 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "104 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "105 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "106 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "107 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "108 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "109 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "110 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "111 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "112 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "113 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "114 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "115 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "116 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "117 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "118 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "119 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "120 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "121 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "122 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "123 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "124 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "125 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "126 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "127 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "128 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "129 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "130 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "131 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "132 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "133 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "134 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "135 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "136 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "137 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "138 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "139 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "140 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "141 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "142 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "143 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "144 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "145 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "146 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "147 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "148 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "149 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "150 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "151 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "152 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "153 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "154 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "155 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "156 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "157 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "158 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "159 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "160 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "161 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "162 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "163 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "164 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "165 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "166 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "167 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "168 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "169 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "170 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "171 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "172 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "173 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "174 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "175 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "176 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "177 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "178 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "179 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "180 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "181 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "182 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "183 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "184 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "185 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "186 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "187 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "188 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "189 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "190 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "191 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "192 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "193 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "194 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "195 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "196 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "197 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "198 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "199 Train Loss 2.833726 Test MSE 14275.736090321434 Test RE 1.0006099545030336\n",
      "Training time: 74.94\n",
      "Training time: 74.94\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 5.052277 Test MSE 14267.763220012512 Test RE 1.0003304996458253\n",
      "1 Train Loss 4.8403735 Test MSE 14262.405988159999 Test RE 1.0001426809431142\n",
      "2 Train Loss 4.828642 Test MSE 14261.072515549246 Test RE 1.0000959253659922\n",
      "3 Train Loss 4.740089 Test MSE 14261.050989582578 Test RE 1.0000951705826597\n",
      "4 Train Loss 3.5465274 Test MSE 14277.881318193755 Test RE 1.0006851329637345\n",
      "5 Train Loss 3.5282137 Test MSE 14277.124042697824 Test RE 1.000658595259654\n",
      "6 Train Loss 3.3272538 Test MSE 14275.148643943066 Test RE 1.0005893667470898\n",
      "7 Train Loss 3.2867284 Test MSE 14273.970600879255 Test RE 1.0005480795523933\n",
      "8 Train Loss 2.9086704 Test MSE 14261.035558128486 Test RE 1.0000946294960702\n",
      "9 Train Loss 2.8684716 Test MSE 14261.932408347377 Test RE 1.0001260760548603\n",
      "10 Train Loss 2.8567803 Test MSE 14259.966592090655 Test RE 1.0000571466911403\n",
      "11 Train Loss 2.8394186 Test MSE 14263.246620261403 Test RE 1.000172154920229\n",
      "12 Train Loss 2.8350832 Test MSE 14265.231786266482 Test RE 1.0002417547362048\n",
      "13 Train Loss 2.8324463 Test MSE 14265.546921583405 Test RE 1.000252802918466\n",
      "14 Train Loss 2.8312528 Test MSE 14264.167067563429 Test RE 1.0002044263565375\n",
      "15 Train Loss 2.830248 Test MSE 14263.760021185073 Test RE 1.0001901551939814\n",
      "16 Train Loss 2.8302412 Test MSE 14263.768015317395 Test RE 1.0001904354725093\n",
      "17 Train Loss 2.830237 Test MSE 14263.773833408271 Test RE 1.0001906394578184\n",
      "18 Train Loss 2.8302333 Test MSE 14263.777948133975 Test RE 1.0001907837222286\n",
      "19 Train Loss 2.8302333 Test MSE 14263.777948133975 Test RE 1.0001907837222286\n",
      "20 Train Loss 2.8302286 Test MSE 14263.789036882872 Test RE 1.000191172499393\n",
      "21 Train Loss 2.8302286 Test MSE 14263.789036882872 Test RE 1.000191172499393\n",
      "22 Train Loss 2.830228 Test MSE 14263.789014827711 Test RE 1.000191171726128\n",
      "23 Train Loss 2.830228 Test MSE 14263.789014827711 Test RE 1.000191171726128\n",
      "24 Train Loss 2.830228 Test MSE 14263.789014827711 Test RE 1.000191171726128\n",
      "25 Train Loss 2.830228 Test MSE 14263.789014827711 Test RE 1.000191171726128\n",
      "26 Train Loss 2.830228 Test MSE 14263.789014827711 Test RE 1.000191171726128\n",
      "27 Train Loss 2.830228 Test MSE 14263.789014827711 Test RE 1.000191171726128\n",
      "28 Train Loss 2.830228 Test MSE 14263.789014827711 Test RE 1.000191171726128\n",
      "29 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "30 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "31 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "32 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "33 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "34 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "35 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "36 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "37 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "38 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "39 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "40 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "41 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "42 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "43 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "44 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "45 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "46 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "47 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "48 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "49 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "50 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "51 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "52 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "53 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "54 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "55 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "56 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "57 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "58 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "59 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "60 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "61 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "62 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "63 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "64 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "65 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "66 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "67 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "68 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "69 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "70 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "71 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "72 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "73 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "74 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "75 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "76 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "77 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "78 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "79 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "80 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "81 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "82 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "83 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "84 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "85 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "86 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "87 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "88 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "89 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "90 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "91 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "92 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "93 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "94 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "95 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "96 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "97 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "98 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "99 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "100 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "101 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "102 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "103 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "104 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "105 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "106 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "107 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "108 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "109 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "110 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "111 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "112 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "113 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "114 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "115 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "116 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "117 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "118 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "119 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "120 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "121 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "122 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "123 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "124 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "125 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "126 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "127 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "128 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "129 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "130 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "131 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "132 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "133 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "134 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "135 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "136 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "137 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "138 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "139 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "140 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "141 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "142 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "143 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "144 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "145 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "146 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "147 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "148 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "149 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "150 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "151 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "152 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "153 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "154 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "155 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "156 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "157 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "158 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "159 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "160 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "161 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "162 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "163 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "164 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "165 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "166 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "167 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "168 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "169 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "170 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "171 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "172 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "173 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "174 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "175 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "176 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "177 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "178 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "179 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "180 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "181 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "182 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "183 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "184 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "185 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "186 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "187 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "188 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "189 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "190 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "191 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "192 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "193 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "194 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "195 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "196 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "197 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "198 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "199 Train Loss 2.8302279 Test MSE 14263.789841317566 Test RE 1.0001912007032758\n",
      "Training time: 32.86\n",
      "Training time: 32.86\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 4.761026 Test MSE 14261.211840962742 Test RE 1.0001008106380453\n",
      "1 Train Loss 4.58931 Test MSE 14266.691186376862 Test RE 1.0002929181388105\n",
      "2 Train Loss 4.3682313 Test MSE 14261.297745158785 Test RE 1.0001038227497676\n",
      "3 Train Loss 3.8789701 Test MSE 14266.109902670269 Test RE 1.0002725399063823\n",
      "4 Train Loss 3.7130182 Test MSE 14265.483317051372 Test RE 1.0002505730466391\n",
      "5 Train Loss 3.554092 Test MSE 14269.43860314294 Test RE 1.0003892295119599\n",
      "6 Train Loss 3.4937167 Test MSE 14276.541752884854 Test RE 1.0006381892154912\n",
      "7 Train Loss 3.3427176 Test MSE 14275.881793593171 Test RE 1.0006150607816586\n",
      "8 Train Loss 2.8415928 Test MSE 14271.891746684732 Test RE 1.0004752172294984\n",
      "9 Train Loss 2.8375497 Test MSE 14270.171055763096 Test RE 1.0004149042539752\n",
      "10 Train Loss 2.8375318 Test MSE 14270.115392380818 Test RE 1.0004129531024673\n",
      "11 Train Loss 2.8375251 Test MSE 14270.096677366098 Test RE 1.0004122970899274\n",
      "12 Train Loss 2.8375242 Test MSE 14270.078792948958 Test RE 1.0004116701917065\n",
      "13 Train Loss 2.8364859 Test MSE 14269.870590106659 Test RE 1.000404372078081\n",
      "14 Train Loss 2.835324 Test MSE 14270.239328204278 Test RE 1.0004172973817713\n",
      "15 Train Loss 2.834239 Test MSE 14269.836597998741 Test RE 1.0004031805510303\n",
      "16 Train Loss 2.8332644 Test MSE 14269.842725949418 Test RE 1.0004033953544955\n",
      "17 Train Loss 2.8323848 Test MSE 14269.580054690448 Test RE 1.0003941878799052\n",
      "18 Train Loss 2.831523 Test MSE 14269.367968862118 Test RE 1.0003867535259319\n",
      "19 Train Loss 2.8309186 Test MSE 14269.201783784032 Test RE 1.000380928116034\n",
      "20 Train Loss 2.8303685 Test MSE 14268.953240543926 Test RE 1.0003722156805492\n",
      "21 Train Loss 2.8299892 Test MSE 14268.869839149878 Test RE 1.0003692921108287\n",
      "22 Train Loss 2.829904 Test MSE 14268.880690809847 Test RE 1.0003696725076459\n",
      "23 Train Loss 2.8298957 Test MSE 14268.892270833969 Test RE 1.0003700784365632\n",
      "24 Train Loss 2.8298836 Test MSE 14268.901085189422 Test RE 1.0003703874169638\n",
      "25 Train Loss 2.8298836 Test MSE 14268.901085189422 Test RE 1.0003703874169638\n",
      "26 Train Loss 2.8298836 Test MSE 14268.901085189422 Test RE 1.0003703874169638\n",
      "27 Train Loss 2.8298836 Test MSE 14268.901085189422 Test RE 1.0003703874169638\n",
      "28 Train Loss 2.8298836 Test MSE 14268.901085189422 Test RE 1.0003703874169638\n",
      "29 Train Loss 2.8298836 Test MSE 14268.901085189422 Test RE 1.0003703874169638\n",
      "30 Train Loss 2.8298836 Test MSE 14268.901085189422 Test RE 1.0003703874169638\n",
      "31 Train Loss 2.8298836 Test MSE 14268.901085189422 Test RE 1.0003703874169638\n",
      "32 Train Loss 2.8298836 Test MSE 14268.901085189422 Test RE 1.0003703874169638\n",
      "33 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "34 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "35 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "36 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "37 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "38 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "39 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "40 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "41 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "42 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "43 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "44 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "45 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "46 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "47 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "48 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "49 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "50 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "51 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "52 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "53 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "54 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "55 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "56 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "57 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "58 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "59 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "60 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "61 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "62 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "63 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "64 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "65 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "66 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "67 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "68 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "69 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "70 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "71 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "72 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "73 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "74 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "75 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "76 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "77 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "78 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "79 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "80 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "81 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "82 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "83 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "84 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "85 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "86 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "87 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "88 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "89 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "90 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "91 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "92 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "93 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "94 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "95 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "96 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "97 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "98 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "99 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "100 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "101 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "102 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "103 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "104 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "105 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "106 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "107 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "108 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "109 Train Loss 2.829882 Test MSE 14268.902366766379 Test RE 1.0003704323416427\n",
      "110 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "111 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "112 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "113 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "114 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "115 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "116 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "117 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "118 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "119 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "120 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "121 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "122 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "123 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "124 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "125 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "126 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "127 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "128 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "129 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "130 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "131 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "132 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "133 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "134 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "135 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "136 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "137 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "138 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "139 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "140 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "141 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "142 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "143 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "144 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "145 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "146 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "147 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "148 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "149 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "150 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "151 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "152 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "153 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "154 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "155 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "156 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "157 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "158 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "159 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "160 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "161 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "162 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "163 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "164 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "165 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "166 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "167 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "168 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "169 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "170 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "171 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "172 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "173 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "174 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "175 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "176 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "177 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "178 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "179 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "180 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "181 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "182 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "183 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "184 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "185 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "186 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "187 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "188 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "189 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "190 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "191 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "192 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "193 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "194 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "195 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "196 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "197 Train Loss 2.8298807 Test MSE 14268.902725193353 Test RE 1.0003704449060202\n",
      "198 Train Loss 2.82988 Test MSE 14268.906868566017 Test RE 1.000370590148697\n",
      "199 Train Loss 2.82988 Test MSE 14268.906868566017 Test RE 1.000370590148697\n",
      "Training time: 76.37\n",
      "Training time: 76.37\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "omega_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val = 5.0\n",
    "rowdy_terms = 2\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(reps)\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    alpha_val = []\n",
    "    omega_val = []\n",
    "\n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "\n",
    "\n",
    "\n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    alpha_full.append(alpha_val)\n",
    "    omega_full.append(omega_val)  \n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"alpha\": alpha_full, \"omega\": omega_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lrnr_tune' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5081/370070687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlrnr_tune\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lrnr_tune' is not defined"
     ]
    }
   ],
   "source": [
    "lrnr_tune[tune_reps,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tune_reps in range(75):\n",
    "    label = \"1D_SODE_rowdy_tune\"+str(tune_reps)+\".mat\" #WRONGLY SAVED AS STAN - DOESN'T MATTER\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
