{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(2*x) + np.exp(-3*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"medium\"\n",
    "label = \"1D_SODE_rowdy_\" + level \n",
    "\n",
    "u_coeff = 6.0\n",
    "fo_val = -1.0\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    omega_val.append(PINN.omega.cpu().detach().numpy())\n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "    \n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,0)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 4.5189123 Test MSE 385.69185395307636 Test RE 1.0011123424944974\n",
      "1 Train Loss 3.9049952 Test MSE 386.463174106511 Test RE 1.0021128723812436\n",
      "2 Train Loss 2.8610122 Test MSE 389.91993516929887 Test RE 1.0065846477870084\n",
      "3 Train Loss 2.6976812 Test MSE 390.8919643400066 Test RE 1.0078385213783623\n",
      "4 Train Loss 2.6108036 Test MSE 390.11025604032284 Test RE 1.006830276028104\n",
      "5 Train Loss 2.5571113 Test MSE 390.4075287108965 Test RE 1.0072138164799953\n",
      "6 Train Loss 2.5027063 Test MSE 390.095580097651 Test RE 1.0068113373791516\n",
      "7 Train Loss 2.4319232 Test MSE 388.88573210571803 Test RE 1.005248855446798\n",
      "8 Train Loss 2.4229107 Test MSE 389.02626732824865 Test RE 1.0054304770633449\n",
      "9 Train Loss 2.4200013 Test MSE 388.1427160817066 Test RE 1.0042880679236987\n",
      "10 Train Loss 2.4152017 Test MSE 387.01128807858703 Test RE 1.0028232601826947\n",
      "11 Train Loss 2.4080644 Test MSE 386.69300534092224 Test RE 1.0024108084091683\n",
      "12 Train Loss 2.4023497 Test MSE 385.8558475226139 Test RE 1.0013251529764284\n",
      "13 Train Loss 2.379069 Test MSE 380.7567830613698 Test RE 0.9946869197990934\n",
      "14 Train Loss 2.367499 Test MSE 377.8048442547214 Test RE 0.9908236030017981\n",
      "15 Train Loss 2.3600316 Test MSE 378.798952718723 Test RE 0.9921263113361989\n",
      "16 Train Loss 2.3553405 Test MSE 378.81717894127706 Test RE 0.9921501795350302\n",
      "17 Train Loss 2.3336263 Test MSE 373.0783161946897 Test RE 0.984606246165231\n",
      "18 Train Loss 2.315209 Test MSE 370.6916060671626 Test RE 0.9814517608224178\n",
      "19 Train Loss 2.280417 Test MSE 365.81660256075253 Test RE 0.9749768155833468\n",
      "20 Train Loss 2.1761038 Test MSE 348.63440621355994 Test RE 0.9518043929659962\n",
      "21 Train Loss 2.1222417 Test MSE 337.5959240871081 Test RE 0.9366151532262573\n",
      "22 Train Loss 2.081936 Test MSE 326.6892967462385 Test RE 0.9213614462441497\n",
      "23 Train Loss 2.0192876 Test MSE 318.5454980066268 Test RE 0.9098049980721913\n",
      "24 Train Loss 1.9498398 Test MSE 312.5621723921863 Test RE 0.901219937316385\n",
      "25 Train Loss 1.9124652 Test MSE 300.06526945668264 Test RE 0.8830198131424212\n",
      "26 Train Loss 1.8415831 Test MSE 286.5392822011217 Test RE 0.862888471781898\n",
      "27 Train Loss 1.7667228 Test MSE 270.90936762129894 Test RE 0.8390244055742655\n",
      "28 Train Loss 1.6689996 Test MSE 250.39659865007079 Test RE 0.8066345039908465\n",
      "29 Train Loss 1.5502174 Test MSE 236.78862760749726 Test RE 0.7844097853107254\n",
      "30 Train Loss 1.523265 Test MSE 235.40279522561823 Test RE 0.7821109931349288\n",
      "31 Train Loss 1.4213849 Test MSE 221.28679220254784 Test RE 0.758298730920157\n",
      "32 Train Loss 1.2933913 Test MSE 198.3898031461454 Test RE 0.7179963819127024\n",
      "33 Train Loss 1.2806753 Test MSE 198.53153653128314 Test RE 0.71825281114209\n",
      "34 Train Loss 1.2708203 Test MSE 196.70584546895475 Test RE 0.714942666087148\n",
      "35 Train Loss 1.2639922 Test MSE 193.62550083929412 Test RE 0.7093227017579078\n",
      "36 Train Loss 1.2266482 Test MSE 183.08548565100384 Test RE 0.6897465560917898\n",
      "37 Train Loss 1.1225055 Test MSE 167.4182752932988 Test RE 0.6595747390792407\n",
      "38 Train Loss 1.0238869 Test MSE 158.34674930717065 Test RE 0.6414564237013047\n",
      "39 Train Loss 0.9833695 Test MSE 150.7141398707447 Test RE 0.6258057975753462\n",
      "40 Train Loss 0.96423715 Test MSE 148.2746471787814 Test RE 0.6207204192285354\n",
      "41 Train Loss 0.94124156 Test MSE 144.63496243713118 Test RE 0.6130546997002836\n",
      "42 Train Loss 0.9332937 Test MSE 142.7290594677188 Test RE 0.6090020920238524\n",
      "43 Train Loss 0.92971414 Test MSE 142.7971777249525 Test RE 0.6091473995486749\n",
      "44 Train Loss 0.8656639 Test MSE 131.45538472518675 Test RE 0.5844559345417806\n",
      "45 Train Loss 0.81232464 Test MSE 118.2470874799844 Test RE 0.5543165033538906\n",
      "46 Train Loss 0.8004553 Test MSE 114.4850541473674 Test RE 0.5454274353799637\n",
      "47 Train Loss 0.7660519 Test MSE 111.41446590141958 Test RE 0.5380633037182931\n",
      "48 Train Loss 0.7517626 Test MSE 110.75288894998019 Test RE 0.5364634203988079\n",
      "49 Train Loss 0.7292316 Test MSE 107.26446701295899 Test RE 0.5279472379064222\n",
      "50 Train Loss 0.69537336 Test MSE 97.67743729638401 Test RE 0.5038017954589835\n",
      "51 Train Loss 0.6550264 Test MSE 90.33530776024094 Test RE 0.4844972839422158\n",
      "52 Train Loss 0.6314851 Test MSE 90.56840726440862 Test RE 0.4851219749892522\n",
      "53 Train Loss 0.6250726 Test MSE 91.28701217615351 Test RE 0.48704274554547755\n",
      "54 Train Loss 0.60633326 Test MSE 87.43429540576727 Test RE 0.4766542721135427\n",
      "55 Train Loss 0.56998014 Test MSE 75.70554265031029 Test RE 0.44353349319389945\n",
      "56 Train Loss 0.5399496 Test MSE 75.02459833229044 Test RE 0.4415342747933247\n",
      "57 Train Loss 0.51648366 Test MSE 73.2776249093935 Test RE 0.43636335757332595\n",
      "58 Train Loss 0.5064538 Test MSE 69.21790305561518 Test RE 0.42410344638088543\n",
      "59 Train Loss 0.49270886 Test MSE 66.93911922127431 Test RE 0.4170638801394615\n",
      "60 Train Loss 0.45339182 Test MSE 65.82432926628651 Test RE 0.4135764525669679\n",
      "61 Train Loss 0.42434058 Test MSE 63.171517039496045 Test RE 0.4051568964681306\n",
      "62 Train Loss 0.3661771 Test MSE 53.787084630233686 Test RE 0.3738536156250244\n",
      "63 Train Loss 0.3502085 Test MSE 50.28069608347473 Test RE 0.36146247938730036\n",
      "64 Train Loss 0.3422007 Test MSE 50.60665187959388 Test RE 0.3626322171392587\n",
      "65 Train Loss 0.3207308 Test MSE 48.232798123995806 Test RE 0.35402490196541514\n",
      "66 Train Loss 0.30247387 Test MSE 42.71963169039116 Test RE 0.3331780119055846\n",
      "67 Train Loss 0.28980607 Test MSE 41.89574265638918 Test RE 0.3299495414683078\n",
      "68 Train Loss 0.28322408 Test MSE 41.09812983670846 Test RE 0.32679365253944903\n",
      "69 Train Loss 0.27398133 Test MSE 39.195752302282195 Test RE 0.3191406202589389\n",
      "70 Train Loss 0.2701479 Test MSE 39.14808300925509 Test RE 0.3189464941714876\n",
      "71 Train Loss 0.26048693 Test MSE 37.71496960679895 Test RE 0.31305414869033543\n",
      "72 Train Loss 0.2493207 Test MSE 34.05201685744538 Test RE 0.29746371834449314\n",
      "73 Train Loss 0.24577266 Test MSE 33.43191617376082 Test RE 0.2947428082877094\n",
      "74 Train Loss 0.24457632 Test MSE 32.651275261716194 Test RE 0.29128133515970095\n",
      "75 Train Loss 0.2398955 Test MSE 31.39027849638983 Test RE 0.28560129145144186\n",
      "76 Train Loss 0.23506168 Test MSE 31.99225659400123 Test RE 0.288326805149692\n",
      "77 Train Loss 0.22242649 Test MSE 31.096956705498965 Test RE 0.2842637801690351\n",
      "78 Train Loss 0.19774717 Test MSE 26.620716454434035 Test RE 0.2630101157171681\n",
      "79 Train Loss 0.18950996 Test MSE 25.56806764525217 Test RE 0.25775763353679954\n",
      "80 Train Loss 0.17523961 Test MSE 24.554403369708417 Test RE 0.2525964691046488\n",
      "81 Train Loss 0.17308545 Test MSE 24.340508879641064 Test RE 0.2514938731739071\n",
      "82 Train Loss 0.16345547 Test MSE 22.618514123344685 Test RE 0.24243460910073397\n",
      "83 Train Loss 0.1552866 Test MSE 20.29906378197346 Test RE 0.2296680518955521\n",
      "84 Train Loss 0.14787051 Test MSE 18.31612425898538 Test RE 0.21816213400905435\n",
      "85 Train Loss 0.1350183 Test MSE 17.593079712476154 Test RE 0.21381270983860282\n",
      "86 Train Loss 0.12926301 Test MSE 16.427284831380085 Test RE 0.20660721149830788\n",
      "87 Train Loss 0.123685166 Test MSE 14.768487086511836 Test RE 0.19589826351250866\n",
      "88 Train Loss 0.11963314 Test MSE 13.384951140344251 Test RE 0.1864966253321455\n",
      "89 Train Loss 0.11337003 Test MSE 11.56779261786908 Test RE 0.17337554114735654\n",
      "90 Train Loss 0.100268066 Test MSE 11.608583617147797 Test RE 0.17368095542181022\n",
      "91 Train Loss 0.0921411 Test MSE 10.875538903516551 Test RE 0.16810784297254044\n",
      "92 Train Loss 0.08729024 Test MSE 9.206124505277575 Test RE 0.15466819047226135\n",
      "93 Train Loss 0.080324054 Test MSE 8.38217757032541 Test RE 0.14758458925405019\n",
      "94 Train Loss 0.07561977 Test MSE 8.424388602001018 Test RE 0.14795572637896992\n",
      "95 Train Loss 0.07001348 Test MSE 8.47726945030665 Test RE 0.14841936742185485\n",
      "96 Train Loss 0.06629556 Test MSE 7.596858936199694 Test RE 0.14050106416376848\n",
      "97 Train Loss 0.0636505 Test MSE 6.932696656475754 Test RE 0.13421890193092678\n",
      "98 Train Loss 0.06269936 Test MSE 7.105010772278124 Test RE 0.13587668815925588\n",
      "99 Train Loss 0.056811307 Test MSE 5.888994641920752 Test RE 0.12370383457734642\n",
      "100 Train Loss 0.044988446 Test MSE 4.997346140933713 Test RE 0.11395471478245826\n",
      "101 Train Loss 0.040956575 Test MSE 4.942211714377055 Test RE 0.11332435487369043\n",
      "102 Train Loss 0.03859284 Test MSE 4.673003078276023 Test RE 0.11019467695906783\n",
      "103 Train Loss 0.03646461 Test MSE 4.52549678802351 Test RE 0.10844154913119931\n",
      "104 Train Loss 0.03372197 Test MSE 3.990917647112106 Test RE 0.10183544502483767\n",
      "105 Train Loss 0.03145379 Test MSE 2.9902620686902837 Test RE 0.08814896318586588\n",
      "106 Train Loss 0.030608164 Test MSE 2.9968964300318186 Test RE 0.08824669509789237\n",
      "107 Train Loss 0.02560101 Test MSE 2.386154072143899 Test RE 0.07874297586527333\n",
      "108 Train Loss 0.021992795 Test MSE 1.9243703000558434 Test RE 0.07071424442000855\n",
      "109 Train Loss 0.017066576 Test MSE 1.836774833691109 Test RE 0.06908607865319186\n",
      "110 Train Loss 0.014900465 Test MSE 1.6110647366710347 Test RE 0.06470220456917647\n",
      "111 Train Loss 0.011292741 Test MSE 0.9869444113928271 Test RE 0.05064177608108305\n",
      "112 Train Loss 0.010398552 Test MSE 0.7641173011830587 Test RE 0.04455973496853743\n",
      "113 Train Loss 0.010179561 Test MSE 0.8064961036854967 Test RE 0.045778727794194625\n",
      "114 Train Loss 0.0097035635 Test MSE 0.8714838571049341 Test RE 0.04758743054633165\n",
      "115 Train Loss 0.0094888415 Test MSE 0.8518121120021569 Test RE 0.047047276527991795\n",
      "116 Train Loss 0.009438969 Test MSE 0.8320893956298105 Test RE 0.046499424316989287\n",
      "117 Train Loss 0.009438969 Test MSE 0.8320893956298105 Test RE 0.046499424316989287\n",
      "118 Train Loss 0.009436633 Test MSE 0.8270161577098187 Test RE 0.04635745440479501\n",
      "119 Train Loss 0.009432917 Test MSE 0.8225663173371052 Test RE 0.04623257080907515\n",
      "120 Train Loss 0.009426342 Test MSE 0.8189506479327505 Test RE 0.04613084904701659\n",
      "121 Train Loss 0.009425257 Test MSE 0.8154334887351369 Test RE 0.04603168304759018\n",
      "122 Train Loss 0.009424452 Test MSE 0.8121191398423224 Test RE 0.04593803935881022\n",
      "123 Train Loss 0.009420129 Test MSE 0.809222199296782 Test RE 0.045856032512237216\n",
      "124 Train Loss 0.009416033 Test MSE 0.8055914241748288 Test RE 0.045753044658446256\n",
      "125 Train Loss 0.009415213 Test MSE 0.803511099341782 Test RE 0.045693931118032015\n",
      "126 Train Loss 0.009409936 Test MSE 0.8020451059003996 Test RE 0.04565222815619697\n",
      "127 Train Loss 0.009405884 Test MSE 0.8004876983518188 Test RE 0.045607882973639643\n",
      "128 Train Loss 0.009404737 Test MSE 0.8007442144136598 Test RE 0.04561518990506146\n",
      "129 Train Loss 0.009400998 Test MSE 0.8012089831913844 Test RE 0.045628425992355275\n",
      "130 Train Loss 0.009392199 Test MSE 0.8026661480031845 Test RE 0.045669899524859565\n",
      "131 Train Loss 0.009387281 Test MSE 0.8046303881783097 Test RE 0.04572574580504978\n",
      "132 Train Loss 0.009384045 Test MSE 0.8065164110499141 Test RE 0.04577930413886117\n",
      "133 Train Loss 0.009382794 Test MSE 0.8104652836872732 Test RE 0.045891239803791645\n",
      "134 Train Loss 0.009376733 Test MSE 0.8128469027713336 Test RE 0.045958617937709806\n",
      "135 Train Loss 0.009362556 Test MSE 0.8195387926654268 Test RE 0.04614741094023223\n",
      "136 Train Loss 0.009354075 Test MSE 0.8252359282939199 Test RE 0.046307533153083696\n",
      "137 Train Loss 0.009163539 Test MSE 0.8510684994985526 Test RE 0.0470267364457412\n",
      "138 Train Loss 0.009083668 Test MSE 0.8026713052394091 Test RE 0.045670046242198066\n",
      "139 Train Loss 0.009082492 Test MSE 0.7944821649853826 Test RE 0.045436477890218596\n",
      "140 Train Loss 0.009074608 Test MSE 0.7867303994943217 Test RE 0.04521427260378338\n",
      "141 Train Loss 0.009071473 Test MSE 0.7798382238211888 Test RE 0.04501578642900098\n",
      "142 Train Loss 0.009070702 Test MSE 0.768577055142618 Test RE 0.04468958174276393\n",
      "143 Train Loss 0.009065841 Test MSE 0.7624542567095886 Test RE 0.04451121808133357\n",
      "144 Train Loss 0.009056523 Test MSE 0.7582432662581188 Test RE 0.04438813146349463\n",
      "145 Train Loss 0.009054232 Test MSE 0.7523517850212187 Test RE 0.044215349310821106\n",
      "146 Train Loss 0.009050798 Test MSE 0.7461700261273413 Test RE 0.04403332515038036\n",
      "147 Train Loss 0.009049151 Test MSE 0.7461272281307595 Test RE 0.04403206232484673\n",
      "148 Train Loss 0.009046825 Test MSE 0.7401000360483205 Test RE 0.0438538569092852\n",
      "149 Train Loss 0.009045593 Test MSE 0.7333678777429288 Test RE 0.04365394774842466\n",
      "150 Train Loss 0.0090422835 Test MSE 0.727288322820102 Test RE 0.043472627498883025\n",
      "151 Train Loss 0.009040052 Test MSE 0.7208148116227169 Test RE 0.04327872257993534\n",
      "152 Train Loss 0.009032438 Test MSE 0.712997844963213 Test RE 0.04304341210896637\n",
      "153 Train Loss 0.009025529 Test MSE 0.7066722603096484 Test RE 0.04285205014656658\n",
      "154 Train Loss 0.009017265 Test MSE 0.6998367924220288 Test RE 0.042644297842805656\n",
      "155 Train Loss 0.009008156 Test MSE 0.6947479605537421 Test RE 0.04248897191606884\n",
      "156 Train Loss 0.008987707 Test MSE 0.6886347598195264 Test RE 0.04230162518138108\n",
      "157 Train Loss 0.008787494 Test MSE 0.7113953050759854 Test RE 0.04299501253229419\n",
      "158 Train Loss 0.007929085 Test MSE 0.5980303928161937 Test RE 0.03942068899018844\n",
      "159 Train Loss 0.0077557582 Test MSE 0.5853182098306784 Test RE 0.038999460599972315\n",
      "160 Train Loss 0.007732437 Test MSE 0.5850149219566856 Test RE 0.038989355330825634\n",
      "161 Train Loss 0.007725409 Test MSE 0.5849501842146057 Test RE 0.03898719799041675\n",
      "162 Train Loss 0.0077157565 Test MSE 0.5847479250884398 Test RE 0.03898045707591267\n",
      "163 Train Loss 0.007696283 Test MSE 0.5857330363435943 Test RE 0.03901327799414485\n",
      "164 Train Loss 0.0074275844 Test MSE 0.5590993630659213 Test RE 0.038115979200123135\n",
      "165 Train Loss 0.007325058 Test MSE 0.5356687441057143 Test RE 0.03730875318743264\n",
      "166 Train Loss 0.0073163565 Test MSE 0.5339514294951206 Test RE 0.037248900618321895\n",
      "167 Train Loss 0.0073090782 Test MSE 0.5323333848668894 Test RE 0.037192419720249816\n",
      "168 Train Loss 0.0071086865 Test MSE 0.5181134061016124 Test RE 0.03669230521367292\n",
      "169 Train Loss 0.0069964947 Test MSE 0.49775870861323485 Test RE 0.03596433348238548\n",
      "170 Train Loss 0.0065621976 Test MSE 0.3818951025017154 Test RE 0.031501746112402675\n",
      "171 Train Loss 0.006052428 Test MSE 0.28094404872056056 Test RE 0.02701920092671672\n",
      "172 Train Loss 0.005644679 Test MSE 0.2974002935277025 Test RE 0.02779926278666184\n",
      "173 Train Loss 0.0054767993 Test MSE 0.2686950751258288 Test RE 0.0264236273384479\n",
      "174 Train Loss 0.005457556 Test MSE 0.2593760656575049 Test RE 0.025961365513972226\n",
      "175 Train Loss 0.0054505086 Test MSE 0.25529035331085764 Test RE 0.02575608114744511\n",
      "176 Train Loss 0.0054460713 Test MSE 0.2497587110021503 Test RE 0.02547551103801246\n",
      "177 Train Loss 0.0054411488 Test MSE 0.2451382711554983 Test RE 0.025238767445019274\n",
      "178 Train Loss 0.005435862 Test MSE 0.24058881534800178 Test RE 0.02500347085313053\n",
      "179 Train Loss 0.0054330276 Test MSE 0.23732993051411624 Test RE 0.02483355179609424\n",
      "180 Train Loss 0.0054292595 Test MSE 0.23291222966847044 Test RE 0.0246013380645005\n",
      "181 Train Loss 0.005423429 Test MSE 0.22748822764872245 Test RE 0.024313195717609697\n",
      "182 Train Loss 0.005417189 Test MSE 0.22253460866497188 Test RE 0.0240470254842254\n",
      "183 Train Loss 0.0054099225 Test MSE 0.21756667616876077 Test RE 0.023777093796419884\n",
      "184 Train Loss 0.0054015703 Test MSE 0.21223384818090843 Test RE 0.023483882939109104\n",
      "185 Train Loss 0.0053740893 Test MSE 0.19702577971832055 Test RE 0.02262685063408141\n",
      "186 Train Loss 0.0051292903 Test MSE 0.13358012308182102 Test RE 0.01863088573068681\n",
      "187 Train Loss 0.004527529 Test MSE 0.08419905669586686 Test RE 0.014791635475125148\n",
      "188 Train Loss 0.0034673137 Test MSE 0.08570348189365376 Test RE 0.014923195063523092\n",
      "189 Train Loss 0.0030276016 Test MSE 0.08596300760500868 Test RE 0.014945773056615137\n",
      "190 Train Loss 0.002619591 Test MSE 0.02783159556220363 Test RE 0.008504164158648141\n",
      "191 Train Loss 0.0025873946 Test MSE 0.02661913246879026 Test RE 0.008316862687317909\n",
      "192 Train Loss 0.002581434 Test MSE 0.026600739017652364 Test RE 0.008313988772422051\n",
      "193 Train Loss 0.0025763218 Test MSE 0.02675006537279253 Test RE 0.008337291887976783\n",
      "194 Train Loss 0.0025712403 Test MSE 0.02704522124821466 Test RE 0.008383161866714667\n",
      "195 Train Loss 0.0025649064 Test MSE 0.027073811793298312 Test RE 0.008387591777918464\n",
      "196 Train Loss 0.0025637234 Test MSE 0.02741648967181469 Test RE 0.008440506460583632\n",
      "197 Train Loss 0.0025588102 Test MSE 0.027815290008964936 Test RE 0.008501672648291991\n",
      "198 Train Loss 0.0025554914 Test MSE 0.027996268182343534 Test RE 0.008529285564958093\n",
      "199 Train Loss 0.0025513605 Test MSE 0.028266415109021406 Test RE 0.008570337973954786\n",
      "Training time: 104.51\n",
      "Training time: 104.51\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 4.553107 Test MSE 385.52686489425685 Test RE 1.000898194529752\n",
      "1 Train Loss 3.4926686 Test MSE 387.7335695955041 Test RE 1.0037586115430113\n",
      "2 Train Loss 2.6539097 Test MSE 392.9227719177039 Test RE 1.0104531500076348\n",
      "3 Train Loss 2.6507711 Test MSE 392.7721451999033 Test RE 1.0102594531265723\n",
      "4 Train Loss 2.6426451 Test MSE 392.62495858496334 Test RE 1.01007014412883\n",
      "5 Train Loss 2.583057 Test MSE 392.0712019484027 Test RE 1.009357593394432\n",
      "6 Train Loss 2.4805326 Test MSE 393.3252687270805 Test RE 1.01097055456875\n",
      "7 Train Loss 2.4515533 Test MSE 393.3413237896711 Test RE 1.0109911876569218\n",
      "8 Train Loss 2.424037 Test MSE 390.20629749831505 Test RE 1.0069542044501285\n",
      "9 Train Loss 2.4235277 Test MSE 390.0411760937309 Test RE 1.0067411283321468\n",
      "10 Train Loss 2.4221342 Test MSE 389.61530302573846 Test RE 1.0061913645430256\n",
      "11 Train Loss 2.390709 Test MSE 384.57762756971215 Test RE 0.999665238339725\n",
      "12 Train Loss 2.3864279 Test MSE 383.70450292661235 Test RE 0.9985298000522654\n",
      "13 Train Loss 2.3754752 Test MSE 381.1187471157638 Test RE 0.9951596039367696\n",
      "14 Train Loss 2.3728297 Test MSE 379.7283720790292 Test RE 0.9933427039263978\n",
      "15 Train Loss 2.3587778 Test MSE 377.9417923377463 Test RE 0.9910031654145888\n",
      "16 Train Loss 2.3538005 Test MSE 378.4471368950597 Test RE 0.9916654774082534\n",
      "17 Train Loss 2.341641 Test MSE 376.7396343093918 Test RE 0.9894258176571107\n",
      "18 Train Loss 2.3248692 Test MSE 373.9834820695512 Test RE 0.985799952703005\n",
      "19 Train Loss 2.297824 Test MSE 366.5495918909371 Test RE 0.9759531107679817\n",
      "20 Train Loss 2.2707658 Test MSE 362.0187918984253 Test RE 0.969902636549317\n",
      "21 Train Loss 2.252313 Test MSE 360.29210093939605 Test RE 0.9675868398648554\n",
      "22 Train Loss 2.2181084 Test MSE 353.4817604155251 Test RE 0.9583984157143863\n",
      "23 Train Loss 2.1757836 Test MSE 343.82493480667915 Test RE 0.9452164411878695\n",
      "24 Train Loss 2.1120527 Test MSE 337.3020779003928 Test RE 0.9362074458367046\n",
      "25 Train Loss 2.017608 Test MSE 320.4369833481797 Test RE 0.9125021571675878\n",
      "26 Train Loss 1.9734393 Test MSE 312.4050289031577 Test RE 0.9009933605540441\n",
      "27 Train Loss 1.9395099 Test MSE 308.00451021209574 Test RE 0.8946251860958018\n",
      "28 Train Loss 1.849039 Test MSE 293.6762511052416 Test RE 0.8735685621587624\n",
      "29 Train Loss 1.7151178 Test MSE 268.9155708550585 Test RE 0.8359312430444171\n",
      "30 Train Loss 1.6911091 Test MSE 267.97113505478 Test RE 0.8344620499823241\n",
      "31 Train Loss 1.6685239 Test MSE 263.1633623528577 Test RE 0.8269424678856864\n",
      "32 Train Loss 1.6155857 Test MSE 255.254851972106 Test RE 0.8144221665241628\n",
      "33 Train Loss 1.5962044 Test MSE 249.9619151941098 Test RE 0.8059340492323578\n",
      "34 Train Loss 1.5566428 Test MSE 245.30784961939528 Test RE 0.79839591322969\n",
      "35 Train Loss 1.5308981 Test MSE 238.24489540817535 Test RE 0.7868181775134752\n",
      "36 Train Loss 1.5063455 Test MSE 230.40303920883898 Test RE 0.7737607294659831\n",
      "37 Train Loss 1.478282 Test MSE 227.45780369840892 Test RE 0.7687993424314497\n",
      "38 Train Loss 1.4465698 Test MSE 224.3480984338454 Test RE 0.7635259093974778\n",
      "39 Train Loss 1.4018704 Test MSE 213.9303309413317 Test RE 0.7455877501392044\n",
      "40 Train Loss 1.3312907 Test MSE 205.0044039514573 Test RE 0.7298677560727379\n",
      "41 Train Loss 1.269958 Test MSE 196.19706743257618 Test RE 0.7140174708119107\n",
      "42 Train Loss 1.21663 Test MSE 186.53729022200787 Test RE 0.6962182677095002\n",
      "43 Train Loss 1.1632434 Test MSE 178.64543952918757 Test RE 0.6813316276734526\n",
      "44 Train Loss 1.121224 Test MSE 172.17780396558948 Test RE 0.6688845500404637\n",
      "45 Train Loss 1.104829 Test MSE 168.49597118686506 Test RE 0.6616942231647037\n",
      "46 Train Loss 1.0659802 Test MSE 163.27056157120606 Test RE 0.651353162020763\n",
      "47 Train Loss 1.0398916 Test MSE 163.08921347165426 Test RE 0.6509913255842888\n",
      "48 Train Loss 1.0103645 Test MSE 157.92338994954082 Test RE 0.64059834375861\n",
      "49 Train Loss 0.9592578 Test MSE 148.2451972648712 Test RE 0.6206587732525178\n",
      "50 Train Loss 0.8923113 Test MSE 135.5383981909317 Test RE 0.5934631493327163\n",
      "51 Train Loss 0.8317569 Test MSE 128.48185125814464 Test RE 0.5778078999341913\n",
      "52 Train Loss 0.80301017 Test MSE 122.13964391066001 Test RE 0.56336635566449\n",
      "53 Train Loss 0.7909357 Test MSE 119.44487232224633 Test RE 0.5571169063291546\n",
      "54 Train Loss 0.7813287 Test MSE 117.74757999023036 Test RE 0.5531444733288813\n",
      "55 Train Loss 0.76389813 Test MSE 117.73794164323837 Test RE 0.5531218337660245\n",
      "56 Train Loss 0.7444333 Test MSE 115.49830812269433 Test RE 0.5478357806281063\n",
      "57 Train Loss 0.7276584 Test MSE 111.28819473761654 Test RE 0.5377583112725417\n",
      "58 Train Loss 0.7056541 Test MSE 108.9974996827552 Test RE 0.532195073959577\n",
      "59 Train Loss 0.68238413 Test MSE 105.12518023223465 Test RE 0.5226560226683358\n",
      "60 Train Loss 0.6487155 Test MSE 99.70183842422172 Test RE 0.508995761318584\n",
      "61 Train Loss 0.6221445 Test MSE 96.33038363552281 Test RE 0.5003158107361694\n",
      "62 Train Loss 0.59229374 Test MSE 89.67354325029665 Test RE 0.4827193940495973\n",
      "63 Train Loss 0.5689524 Test MSE 83.8760679143009 Test RE 0.4668545693866159\n",
      "64 Train Loss 0.5551567 Test MSE 79.39164087588358 Test RE 0.4542029719454555\n",
      "65 Train Loss 0.5094957 Test MSE 67.33445837712598 Test RE 0.4182936464905122\n",
      "66 Train Loss 0.47433788 Test MSE 61.339894216651665 Test RE 0.3992400431664305\n",
      "67 Train Loss 0.44370478 Test MSE 57.45122161046434 Test RE 0.38637784542860715\n",
      "68 Train Loss 0.38658598 Test MSE 53.27964486918041 Test RE 0.3720859259320945\n",
      "69 Train Loss 0.37081555 Test MSE 53.53746935589069 Test RE 0.3729851162922078\n",
      "70 Train Loss 0.3590291 Test MSE 53.58905625290565 Test RE 0.3731647709547849\n",
      "71 Train Loss 0.34321424 Test MSE 52.96685316867879 Test RE 0.37099210566962054\n",
      "72 Train Loss 0.31875876 Test MSE 47.091106178583225 Test RE 0.34980984548325905\n",
      "73 Train Loss 0.3052853 Test MSE 43.54934771605755 Test RE 0.33639800362459726\n",
      "74 Train Loss 0.29709676 Test MSE 41.47853436920608 Test RE 0.3283025709315309\n",
      "75 Train Loss 0.28452617 Test MSE 39.39133854440743 Test RE 0.31993588296624675\n",
      "76 Train Loss 0.28248522 Test MSE 39.45836421729778 Test RE 0.32020795805301855\n",
      "77 Train Loss 0.2820042 Test MSE 39.743378738870256 Test RE 0.32136233569357237\n",
      "78 Train Loss 0.27916667 Test MSE 39.69731197836343 Test RE 0.3211760353009513\n",
      "79 Train Loss 0.27206302 Test MSE 38.507591839728775 Test RE 0.3163266357337864\n",
      "80 Train Loss 0.2702907 Test MSE 37.769617611601156 Test RE 0.3132808702295789\n",
      "81 Train Loss 0.26795298 Test MSE 36.42335379646904 Test RE 0.30764690384005783\n",
      "82 Train Loss 0.25996462 Test MSE 33.2313788646522 Test RE 0.29385748911205284\n",
      "83 Train Loss 0.24223442 Test MSE 31.16709753646272 Test RE 0.2845841855952057\n",
      "84 Train Loss 0.21816817 Test MSE 27.156596983064652 Test RE 0.2656441498680964\n",
      "85 Train Loss 0.20960623 Test MSE 24.998119680049495 Test RE 0.25486855342474135\n",
      "86 Train Loss 0.20417804 Test MSE 24.095702273884253 Test RE 0.2502259672760958\n",
      "87 Train Loss 0.1980885 Test MSE 22.257218131701617 Test RE 0.2404905544350403\n",
      "88 Train Loss 0.1933249 Test MSE 20.692299635014656 Test RE 0.23188195957369298\n",
      "89 Train Loss 0.19225511 Test MSE 20.4216542500745 Test RE 0.2303605156823616\n",
      "90 Train Loss 0.18522364 Test MSE 19.068205685317093 Test RE 0.22259607206564647\n",
      "91 Train Loss 0.1727576 Test MSE 16.604688413006674 Test RE 0.20771982487007748\n",
      "92 Train Loss 0.1539756 Test MSE 15.490494455197245 Test RE 0.20062969957693932\n",
      "93 Train Loss 0.14853612 Test MSE 14.246905987218195 Test RE 0.19240788324249336\n",
      "94 Train Loss 0.14551121 Test MSE 13.14309759961315 Test RE 0.18480403485360872\n",
      "95 Train Loss 0.14285636 Test MSE 12.477847451485381 Test RE 0.1800662907393036\n",
      "96 Train Loss 0.13398992 Test MSE 9.594656206695085 Test RE 0.15789824081167175\n",
      "97 Train Loss 0.11300292 Test MSE 7.549791724912622 Test RE 0.14006514268146578\n",
      "98 Train Loss 0.09745819 Test MSE 6.885718408047963 Test RE 0.13376337305130437\n",
      "99 Train Loss 0.09312329 Test MSE 6.662215773235597 Test RE 0.1315745610113308\n",
      "100 Train Loss 0.08422536 Test MSE 5.909514757833262 Test RE 0.12391916926123463\n",
      "101 Train Loss 0.07076876 Test MSE 6.353136920994292 Test RE 0.1284862606983912\n",
      "102 Train Loss 0.06915029 Test MSE 6.698406455083294 Test RE 0.1319314485682078\n",
      "103 Train Loss 0.0677685 Test MSE 6.333734161958457 Test RE 0.1282899093272053\n",
      "104 Train Loss 0.06516826 Test MSE 5.427782868548852 Test RE 0.11876099170999364\n",
      "105 Train Loss 0.061645668 Test MSE 5.155935964396613 Test RE 0.11574875807716946\n",
      "106 Train Loss 0.054308824 Test MSE 5.099927574202969 Test RE 0.11511835811678142\n",
      "107 Train Loss 0.047651708 Test MSE 4.579127701324721 Test RE 0.10908221803029186\n",
      "108 Train Loss 0.045217346 Test MSE 4.61036341149779 Test RE 0.10945362826347295\n",
      "109 Train Loss 0.042763837 Test MSE 5.00087143046892 Test RE 0.11399490136649694\n",
      "110 Train Loss 0.04196902 Test MSE 5.166126321362571 Test RE 0.11586308639075751\n",
      "111 Train Loss 0.041156717 Test MSE 5.117328061966158 Test RE 0.11531457755806789\n",
      "112 Train Loss 0.039035235 Test MSE 4.778825320968081 Test RE 0.1114353959706676\n",
      "113 Train Loss 0.03824801 Test MSE 4.567538704611999 Test RE 0.1089440962741417\n",
      "114 Train Loss 0.037428282 Test MSE 4.097408100206442 Test RE 0.10318514846107535\n",
      "115 Train Loss 0.034575768 Test MSE 3.318903258809561 Test RE 0.09286667135651921\n",
      "116 Train Loss 0.032663636 Test MSE 3.3444818186673384 Test RE 0.0932238430373577\n",
      "117 Train Loss 0.029822994 Test MSE 3.252778920136534 Test RE 0.09193690003416227\n",
      "118 Train Loss 0.025772266 Test MSE 2.9828641480037557 Test RE 0.08803985521150487\n",
      "119 Train Loss 0.023430036 Test MSE 2.65876506043384 Test RE 0.08311943146736367\n",
      "120 Train Loss 0.02274552 Test MSE 2.6690545479556618 Test RE 0.08328011329988538\n",
      "121 Train Loss 0.02224034 Test MSE 2.5662017405017172 Test RE 0.08165973761348078\n",
      "122 Train Loss 0.02171167 Test MSE 2.4852590898609623 Test RE 0.08036157095169749\n",
      "123 Train Loss 0.021123495 Test MSE 2.5066797148475657 Test RE 0.08070714895891518\n",
      "124 Train Loss 0.020256478 Test MSE 2.170271347380459 Test RE 0.07509648348002491\n",
      "125 Train Loss 0.019803312 Test MSE 2.0378595040482654 Test RE 0.07276955214901613\n",
      "126 Train Loss 0.019570231 Test MSE 1.9331862265754092 Test RE 0.07087603740239089\n",
      "127 Train Loss 0.0192809 Test MSE 1.8819126298963118 Test RE 0.06992980399760773\n",
      "128 Train Loss 0.018760294 Test MSE 1.831595442723603 Test RE 0.06898860442500669\n",
      "129 Train Loss 0.018043628 Test MSE 1.7299691386732077 Test RE 0.06704737208421793\n",
      "130 Train Loss 0.017502904 Test MSE 1.5595283357222562 Test RE 0.06365891284535612\n",
      "131 Train Loss 0.01697246 Test MSE 1.47943685065383 Test RE 0.06200272808159925\n",
      "132 Train Loss 0.016358014 Test MSE 1.3645484220657362 Test RE 0.059546612228681677\n",
      "133 Train Loss 0.015774287 Test MSE 1.2417865043771006 Test RE 0.05680493279378997\n",
      "134 Train Loss 0.01530194 Test MSE 1.0796360248164725 Test RE 0.052966498822515064\n",
      "135 Train Loss 0.014930915 Test MSE 0.9525404848619027 Test RE 0.04975128519428289\n",
      "136 Train Loss 0.014873782 Test MSE 0.9326626697522825 Test RE 0.049229438197649716\n",
      "137 Train Loss 0.0146998055 Test MSE 0.8464478857958732 Test RE 0.04689890412862163\n",
      "138 Train Loss 0.014544608 Test MSE 0.8169267570539023 Test RE 0.04607381169119288\n",
      "139 Train Loss 0.014166672 Test MSE 0.7190322945314651 Test RE 0.04322517705486522\n",
      "140 Train Loss 0.013656555 Test MSE 0.5323209002489239 Test RE 0.03719198358766156\n",
      "141 Train Loss 0.013088872 Test MSE 0.37617796174186874 Test RE 0.0312650593197366\n",
      "142 Train Loss 0.0128344055 Test MSE 0.3415082873634506 Test RE 0.029789499466008867\n",
      "143 Train Loss 0.012733826 Test MSE 0.30809320688779 Test RE 0.028294605549569186\n",
      "144 Train Loss 0.012724756 Test MSE 0.3014326920082342 Test RE 0.027987090915232427\n",
      "145 Train Loss 0.012673732 Test MSE 0.27224359149130034 Test RE 0.026597536603700747\n",
      "146 Train Loss 0.012380068 Test MSE 0.24311220777089632 Test RE 0.02513425206392\n",
      "147 Train Loss 0.011989899 Test MSE 0.2686914260724712 Test RE 0.0264234479128418\n",
      "148 Train Loss 0.011628003 Test MSE 0.2371942182533473 Test RE 0.024826450501737627\n",
      "149 Train Loss 0.01092896 Test MSE 0.21655903932624082 Test RE 0.023721969360368085\n",
      "150 Train Loss 0.010542899 Test MSE 0.24744440488497918 Test RE 0.025357206162378625\n",
      "151 Train Loss 0.010207118 Test MSE 0.3178832345067123 Test RE 0.02874063731249939\n",
      "152 Train Loss 0.009938681 Test MSE 0.3865458191632132 Test RE 0.031692979717604784\n",
      "153 Train Loss 0.009750176 Test MSE 0.38278187128093555 Test RE 0.031538298777357976\n",
      "154 Train Loss 0.009736568 Test MSE 0.3793883388577155 Test RE 0.031398186988201585\n",
      "155 Train Loss 0.009720673 Test MSE 0.3781660378870868 Test RE 0.03134756735698541\n",
      "156 Train Loss 0.009719753 Test MSE 0.3780233770491283 Test RE 0.031341653959662645\n",
      "157 Train Loss 0.009717408 Test MSE 0.3770848557531717 Test RE 0.03130272370922571\n",
      "158 Train Loss 0.009715469 Test MSE 0.3771734497447855 Test RE 0.03130640069376868\n",
      "159 Train Loss 0.009706933 Test MSE 0.3774138978764256 Test RE 0.031316378021489504\n",
      "160 Train Loss 0.009703391 Test MSE 0.3780154200841167 Test RE 0.031341324104723206\n",
      "161 Train Loss 0.009701096 Test MSE 0.37898395816542724 Test RE 0.031381449249581896\n",
      "162 Train Loss 0.00969807 Test MSE 0.38016857912043006 Test RE 0.03143045675579399\n",
      "163 Train Loss 0.0096961595 Test MSE 0.3819599436931662 Test RE 0.03150442030754424\n",
      "164 Train Loss 0.0096880365 Test MSE 0.38398362785649826 Test RE 0.03158776775595648\n",
      "165 Train Loss 0.00968534 Test MSE 0.3865324928783847 Test RE 0.0316924334003326\n",
      "166 Train Loss 0.009684551 Test MSE 0.38942994464944314 Test RE 0.0318109950430624\n",
      "167 Train Loss 0.00967972 Test MSE 0.39381777305958043 Test RE 0.03198970524895024\n",
      "168 Train Loss 0.009637123 Test MSE 0.4110043514103864 Test RE 0.03268028177771508\n",
      "169 Train Loss 0.009344503 Test MSE 0.4475973215338134 Test RE 0.03410407871529523\n",
      "170 Train Loss 0.008005852 Test MSE 0.2980476429337659 Test RE 0.027829501583381544\n",
      "171 Train Loss 0.0064614 Test MSE 0.10736158022812824 Test RE 0.01670271343592652\n",
      "172 Train Loss 0.0051918873 Test MSE 0.09960492441042604 Test RE 0.016088034452918943\n",
      "173 Train Loss 0.0046649794 Test MSE 0.08163778460525721 Test RE 0.014564922830183714\n",
      "174 Train Loss 0.0044229208 Test MSE 0.027917029922253107 Test RE 0.008517206729385654\n",
      "175 Train Loss 0.004054754 Test MSE 0.012382546466295006 Test RE 0.005672409369663912\n",
      "176 Train Loss 0.003984205 Test MSE 0.009464237437951481 Test RE 0.00495912889263686\n",
      "177 Train Loss 0.003964248 Test MSE 0.007965239048815704 Test RE 0.004549482403575166\n",
      "178 Train Loss 0.0039585503 Test MSE 0.007394255011745363 Test RE 0.0043833867922955586\n",
      "179 Train Loss 0.003950747 Test MSE 0.006774752216956313 Test RE 0.004195746977583644\n",
      "180 Train Loss 0.0039448217 Test MSE 0.0063056133349191626 Test RE 0.0040478671488727\n",
      "181 Train Loss 0.0039397203 Test MSE 0.005844228201426681 Test RE 0.0038969619498933016\n",
      "182 Train Loss 0.0039344807 Test MSE 0.005468543714872515 Test RE 0.003769627409591121\n",
      "183 Train Loss 0.003928504 Test MSE 0.005212709506548261 Test RE 0.003680394255492478\n",
      "184 Train Loss 0.0039269426 Test MSE 0.00502910970044483 Test RE 0.0036149986300142954\n",
      "185 Train Loss 0.00392211 Test MSE 0.004839325174835567 Test RE 0.003546132714673293\n",
      "186 Train Loss 0.0039167963 Test MSE 0.004729691324937739 Test RE 0.0035057341696127513\n",
      "187 Train Loss 0.003908352 Test MSE 0.00468498912936248 Test RE 0.0034891277934647334\n",
      "188 Train Loss 0.0038998553 Test MSE 0.004698331580718624 Test RE 0.0034940926310098965\n",
      "189 Train Loss 0.003891929 Test MSE 0.004992113788184747 Test RE 0.003601677480844571\n",
      "190 Train Loss 0.0038839325 Test MSE 0.005182210460335976 Test RE 0.0036696116495217347\n",
      "191 Train Loss 0.0037884726 Test MSE 0.011513727368248673 Test RE 0.0054697887460512015\n",
      "192 Train Loss 0.003783054 Test MSE 0.011937633084711788 Test RE 0.005569570372052012\n",
      "193 Train Loss 0.0037751535 Test MSE 0.012215023408475129 Test RE 0.005633907786047976\n",
      "194 Train Loss 0.0037709633 Test MSE 0.012248364772742621 Test RE 0.005641591527598999\n",
      "195 Train Loss 0.003764287 Test MSE 0.012255710075836358 Test RE 0.005643282895777327\n",
      "196 Train Loss 0.0037592906 Test MSE 0.012011669272890319 Test RE 0.005586814678045014\n",
      "197 Train Loss 0.0037550505 Test MSE 0.011676750336504553 Test RE 0.005508376030487796\n",
      "198 Train Loss 0.0037503897 Test MSE 0.011067742786050298 Test RE 0.0053628063052990095\n",
      "199 Train Loss 0.0037444266 Test MSE 0.010430466972277863 Test RE 0.005206123408782275\n",
      "Training time: 121.28\n",
      "Training time: 121.28\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 4.542839 Test MSE 385.6985123898966 Test RE 1.0011209838677146\n",
      "1 Train Loss 3.77532 Test MSE 391.29153491464365 Test RE 1.0083534971204582\n",
      "2 Train Loss 2.6580825 Test MSE 393.4744052633035 Test RE 1.0111622004778351\n",
      "3 Train Loss 2.6562066 Test MSE 393.11146233524465 Test RE 1.0106957421348257\n",
      "4 Train Loss 2.6409786 Test MSE 391.974284985025 Test RE 1.009232832995682\n",
      "5 Train Loss 2.506593 Test MSE 390.0870652532579 Test RE 1.0068003491892181\n",
      "6 Train Loss 2.415897 Test MSE 388.2693638250865 Test RE 1.0044518999867544\n",
      "7 Train Loss 2.4154632 Test MSE 388.2190814885387 Test RE 1.0043868577396986\n",
      "8 Train Loss 2.4154408 Test MSE 388.2128659345898 Test RE 1.0043788173753976\n",
      "9 Train Loss 2.4146724 Test MSE 388.10168933091694 Test RE 1.004234989811684\n",
      "10 Train Loss 2.405934 Test MSE 387.47810862018446 Test RE 1.0034278903672629\n",
      "11 Train Loss 2.3954248 Test MSE 385.5517982398578 Test RE 1.0009305597672846\n",
      "12 Train Loss 2.3868728 Test MSE 384.1389223087954 Test RE 0.9990948937460034\n",
      "13 Train Loss 2.370667 Test MSE 381.96924593685065 Test RE 0.9962693766901812\n",
      "14 Train Loss 2.3647578 Test MSE 380.67696289030084 Test RE 0.9945826534470182\n",
      "15 Train Loss 2.362756 Test MSE 379.52893483938567 Test RE 0.9930818127729018\n",
      "16 Train Loss 2.347568 Test MSE 377.30963713786184 Test RE 0.9901740298205741\n",
      "17 Train Loss 2.3374686 Test MSE 376.2783923915586 Test RE 0.9888199556938666\n",
      "18 Train Loss 2.3227258 Test MSE 373.1541421671711 Test RE 0.9847062987946453\n",
      "19 Train Loss 2.3125043 Test MSE 371.7548327317111 Test RE 0.9828582648868233\n",
      "20 Train Loss 2.3065338 Test MSE 371.0368568676178 Test RE 0.9819087014966584\n",
      "21 Train Loss 2.2991037 Test MSE 368.90072571505027 Test RE 0.9790781021140379\n",
      "22 Train Loss 2.269537 Test MSE 361.04936006656476 Test RE 0.9686031393685772\n",
      "23 Train Loss 2.2549224 Test MSE 360.41109673973506 Test RE 0.9677466119841803\n",
      "24 Train Loss 2.2471485 Test MSE 359.78927210294484 Test RE 0.9669114150714636\n",
      "25 Train Loss 2.2417698 Test MSE 358.59629044505505 Test RE 0.9653070518301633\n",
      "26 Train Loss 2.2312114 Test MSE 356.13202506377036 Test RE 0.9619845501285007\n",
      "27 Train Loss 2.2299938 Test MSE 355.44274347109354 Test RE 0.9610531548193939\n",
      "28 Train Loss 2.2290263 Test MSE 354.38148284781835 Test RE 0.9596173535010685\n",
      "29 Train Loss 2.226192 Test MSE 352.90434872847106 Test RE 0.9576153249253091\n",
      "30 Train Loss 2.2191894 Test MSE 349.794345831591 Test RE 0.9533864497296443\n",
      "31 Train Loss 2.216343 Test MSE 347.898586078226 Test RE 0.9507994336810144\n",
      "32 Train Loss 2.2139885 Test MSE 346.2072524244587 Test RE 0.9484854283842297\n",
      "33 Train Loss 2.2000892 Test MSE 344.36434090067195 Test RE 0.9459575969960773\n",
      "34 Train Loss 2.1872363 Test MSE 344.8598182119198 Test RE 0.946637882377951\n",
      "35 Train Loss 2.1790466 Test MSE 345.561254779956 Test RE 0.9476001126698137\n",
      "36 Train Loss 2.1750283 Test MSE 346.33782049347013 Test RE 0.9486642666896333\n",
      "37 Train Loss 2.1690726 Test MSE 344.7929677129945 Test RE 0.9465461258459775\n",
      "38 Train Loss 2.1650393 Test MSE 343.37951940608417 Test RE 0.9446039922953462\n",
      "39 Train Loss 2.1607108 Test MSE 340.85132504327265 Test RE 0.9411201582369261\n",
      "40 Train Loss 2.1389692 Test MSE 335.082024724329 Test RE 0.9331213967106582\n",
      "41 Train Loss 2.1306238 Test MSE 335.03272375335274 Test RE 0.933052748618888\n",
      "42 Train Loss 2.1118882 Test MSE 333.0998761257802 Test RE 0.930357403841049\n",
      "43 Train Loss 2.1059866 Test MSE 333.6848170407112 Test RE 0.9311739238201593\n",
      "44 Train Loss 2.1034517 Test MSE 332.78095596052185 Test RE 0.9299119206510944\n",
      "45 Train Loss 2.0951376 Test MSE 330.8724474451712 Test RE 0.9272415504519904\n",
      "46 Train Loss 2.0827785 Test MSE 327.87286222084265 Test RE 0.9230289414842927\n",
      "47 Train Loss 2.0642734 Test MSE 322.92477003558656 Test RE 0.9160375193847184\n",
      "48 Train Loss 2.04657 Test MSE 322.2502011816062 Test RE 0.9150802477867856\n",
      "49 Train Loss 2.034772 Test MSE 323.3495441308037 Test RE 0.9166397976403873\n",
      "50 Train Loss 1.9981849 Test MSE 319.43514489942515 Test RE 0.9110745825545685\n",
      "51 Train Loss 1.9613957 Test MSE 307.3349586800874 Test RE 0.8936522725033911\n",
      "52 Train Loss 1.877563 Test MSE 291.3550623751795 Test RE 0.8701094126231291\n",
      "53 Train Loss 1.8407532 Test MSE 290.431472003626 Test RE 0.8687292022544427\n",
      "54 Train Loss 1.815679 Test MSE 283.93960830859373 Test RE 0.8589652054131812\n",
      "55 Train Loss 1.8068773 Test MSE 282.0937730672401 Test RE 0.8561686716091849\n",
      "56 Train Loss 1.7974828 Test MSE 283.57814768733823 Test RE 0.8584182916275146\n",
      "57 Train Loss 1.7762702 Test MSE 277.5856954675408 Test RE 0.849299999224441\n",
      "58 Train Loss 1.7137533 Test MSE 267.02223226129547 Test RE 0.8329832981977828\n",
      "59 Train Loss 1.705105 Test MSE 262.26109813291805 Test RE 0.8255236510385114\n",
      "60 Train Loss 1.6852297 Test MSE 259.3466174865136 Test RE 0.8209238563028473\n",
      "61 Train Loss 1.6474934 Test MSE 257.9134316873467 Test RE 0.8186524437092789\n",
      "62 Train Loss 1.5899345 Test MSE 239.435283339527 Test RE 0.7887813923462881\n",
      "63 Train Loss 1.5397279 Test MSE 234.17702192680986 Test RE 0.7800720580443975\n",
      "64 Train Loss 1.495784 Test MSE 231.26251095503483 Test RE 0.7752025647299466\n",
      "65 Train Loss 1.4402764 Test MSE 217.03367732210762 Test RE 0.7509761541533253\n",
      "66 Train Loss 1.4334698 Test MSE 214.89194627716046 Test RE 0.7472615771395305\n",
      "67 Train Loss 1.3842319 Test MSE 206.97869650191492 Test RE 0.7333738265142861\n",
      "68 Train Loss 1.3057948 Test MSE 200.70585660635942 Test RE 0.7221752579690758\n",
      "69 Train Loss 1.2661495 Test MSE 197.16111429545867 Test RE 0.71576954286604\n",
      "70 Train Loss 1.2515553 Test MSE 194.33873668886085 Test RE 0.7106279258610392\n",
      "71 Train Loss 1.213468 Test MSE 187.3397001828156 Test RE 0.6977140892291447\n",
      "72 Train Loss 1.1448961 Test MSE 173.97333913282654 Test RE 0.6723631947617291\n",
      "73 Train Loss 1.0848708 Test MSE 164.05221445750686 Test RE 0.6529104671616591\n",
      "74 Train Loss 1.0280232 Test MSE 157.24521473849813 Test RE 0.6392213934340198\n",
      "75 Train Loss 0.96543247 Test MSE 149.19200408730978 Test RE 0.6226376186741013\n",
      "76 Train Loss 0.92466635 Test MSE 142.4867806266578 Test RE 0.608484989936644\n",
      "77 Train Loss 0.91091615 Test MSE 140.5808252654631 Test RE 0.6044016297977768\n",
      "78 Train Loss 0.8998736 Test MSE 138.53275653901386 Test RE 0.5999828277280499\n",
      "79 Train Loss 0.87726694 Test MSE 135.6426404512261 Test RE 0.5936913210192384\n",
      "80 Train Loss 0.86424565 Test MSE 132.00165431874825 Test RE 0.5856690438701956\n",
      "81 Train Loss 0.80655223 Test MSE 119.80030050947566 Test RE 0.5579451878630635\n",
      "82 Train Loss 0.73166466 Test MSE 111.59070495941648 Test RE 0.5384886986534753\n",
      "83 Train Loss 0.7205483 Test MSE 110.68367727368678 Test RE 0.5362957708886847\n",
      "84 Train Loss 0.6900154 Test MSE 106.37493528642852 Test RE 0.525753578032913\n",
      "85 Train Loss 0.61517596 Test MSE 91.15256238924474 Test RE 0.4866839490379724\n",
      "86 Train Loss 0.6013757 Test MSE 88.79362982823332 Test RE 0.4803452357396733\n",
      "87 Train Loss 0.56437933 Test MSE 83.27406677443791 Test RE 0.46517618188428117\n",
      "88 Train Loss 0.53783476 Test MSE 78.5461056361317 Test RE 0.4517778259716928\n",
      "89 Train Loss 0.5278095 Test MSE 77.02090766268516 Test RE 0.44737004236250255\n",
      "90 Train Loss 0.5171529 Test MSE 73.75366705963691 Test RE 0.4377784626052577\n",
      "91 Train Loss 0.49187207 Test MSE 72.74872261398687 Test RE 0.4347857167434928\n",
      "92 Train Loss 0.47755092 Test MSE 72.27573084100743 Test RE 0.43336998447714464\n",
      "93 Train Loss 0.461254 Test MSE 68.89865134466824 Test RE 0.42312427606198083\n",
      "94 Train Loss 0.4394854 Test MSE 65.50616788657106 Test RE 0.4125757325877962\n",
      "95 Train Loss 0.4274967 Test MSE 63.24698352375689 Test RE 0.40539883018892847\n",
      "96 Train Loss 0.41413796 Test MSE 60.66229455489238 Test RE 0.39702878918060586\n",
      "97 Train Loss 0.40851778 Test MSE 58.8701189535085 Test RE 0.3911200134637038\n",
      "98 Train Loss 0.3906258 Test MSE 56.49721861899038 Test RE 0.38315642851810905\n",
      "99 Train Loss 0.37577012 Test MSE 55.075922670353485 Test RE 0.3783062124909545\n",
      "100 Train Loss 0.36963823 Test MSE 53.4025355083686 Test RE 0.37251479084681854\n",
      "101 Train Loss 0.36539736 Test MSE 52.15352341039842 Test RE 0.3681327113954066\n",
      "102 Train Loss 0.36191627 Test MSE 51.89722464467939 Test RE 0.3672270375515286\n",
      "103 Train Loss 0.3409607 Test MSE 48.91720620689521 Test RE 0.3565278048383128\n",
      "104 Train Loss 0.3181348 Test MSE 45.82915682460926 Test RE 0.34509090707783785\n",
      "105 Train Loss 0.31295 Test MSE 43.45420543179871 Test RE 0.3360303382519878\n",
      "106 Train Loss 0.30005553 Test MSE 42.56715594184983 Test RE 0.33258288764635685\n",
      "107 Train Loss 0.29469597 Test MSE 43.34932685007279 Test RE 0.3356245814858298\n",
      "108 Train Loss 0.28371716 Test MSE 40.89612674838875 Test RE 0.3259895448649781\n",
      "109 Train Loss 0.26445997 Test MSE 37.09550434597384 Test RE 0.31047255993697076\n",
      "110 Train Loss 0.2555542 Test MSE 35.58568302382461 Test RE 0.30408866748166713\n",
      "111 Train Loss 0.24255064 Test MSE 34.36108789528814 Test RE 0.29881062454767654\n",
      "112 Train Loss 0.23050995 Test MSE 31.279720712232066 Test RE 0.2850978983787165\n",
      "113 Train Loss 0.17803921 Test MSE 24.761654331958983 Test RE 0.253660246905346\n",
      "114 Train Loss 0.1564927 Test MSE 21.738494969334262 Test RE 0.23767161599569916\n",
      "115 Train Loss 0.15532517 Test MSE 21.04859078032571 Test RE 0.23386977343536947\n",
      "116 Train Loss 0.14768542 Test MSE 18.71701275597899 Test RE 0.2205366893213777\n",
      "117 Train Loss 0.11932029 Test MSE 13.859883764007195 Test RE 0.1897764754325257\n",
      "118 Train Loss 0.10043496 Test MSE 10.695524876031788 Test RE 0.16671076085903197\n",
      "119 Train Loss 0.092461415 Test MSE 9.843162037375077 Test RE 0.15992998620093465\n",
      "120 Train Loss 0.085380316 Test MSE 8.432631001746389 Test RE 0.1480280884311888\n",
      "121 Train Loss 0.0772216 Test MSE 6.822482189370192 Test RE 0.13314773648528003\n",
      "122 Train Loss 0.07035579 Test MSE 7.14209590931936 Test RE 0.13623083592200605\n",
      "123 Train Loss 0.06760432 Test MSE 6.95787600983715 Test RE 0.13446242059936164\n",
      "124 Train Loss 0.065430716 Test MSE 7.0968256085829955 Test RE 0.13579839880343925\n",
      "125 Train Loss 0.063941054 Test MSE 7.302082846192291 Test RE 0.13774820888450617\n",
      "126 Train Loss 0.06338277 Test MSE 7.226004134780237 Test RE 0.13702874664398232\n",
      "127 Train Loss 0.058882974 Test MSE 6.361347169347941 Test RE 0.12856925619547102\n",
      "128 Train Loss 0.04664506 Test MSE 4.6560675997552705 Test RE 0.10999481688487547\n",
      "129 Train Loss 0.04470263 Test MSE 4.262089933372145 Test RE 0.10523831533468833\n",
      "130 Train Loss 0.04421229 Test MSE 4.113471549846528 Test RE 0.10338721377284761\n",
      "131 Train Loss 0.043828066 Test MSE 4.090148423816599 Test RE 0.10309369761377357\n",
      "132 Train Loss 0.042704895 Test MSE 3.9531074264267585 Test RE 0.10135189910442768\n",
      "133 Train Loss 0.041839577 Test MSE 3.7278542756440065 Test RE 0.09842196830987497\n",
      "134 Train Loss 0.040408656 Test MSE 3.425415968548048 Test RE 0.09434507662078845\n",
      "135 Train Loss 0.03899022 Test MSE 3.17725598525201 Test RE 0.09086333769599461\n",
      "136 Train Loss 0.034058705 Test MSE 3.1439344616750833 Test RE 0.09038561650503979\n",
      "137 Train Loss 0.032115333 Test MSE 3.0979718817337347 Test RE 0.08972249012888843\n",
      "138 Train Loss 0.03164497 Test MSE 3.0391982468505607 Test RE 0.08886732293292203\n",
      "139 Train Loss 0.030424552 Test MSE 2.886148909642563 Test RE 0.0866008091449378\n",
      "140 Train Loss 0.028918242 Test MSE 2.5503042517648793 Test RE 0.08140640570715586\n",
      "141 Train Loss 0.028581703 Test MSE 2.374591210111525 Test RE 0.07855195721335903\n",
      "142 Train Loss 0.02843104 Test MSE 2.4032689475762465 Test RE 0.07902486635352865\n",
      "143 Train Loss 0.028167838 Test MSE 2.4576645018417485 Test RE 0.07991418613333673\n",
      "144 Train Loss 0.027118232 Test MSE 2.2209991470590094 Test RE 0.07596906449535937\n",
      "145 Train Loss 0.024812028 Test MSE 1.8876096004169003 Test RE 0.07003557059341922\n",
      "146 Train Loss 0.023552675 Test MSE 1.64515950223207 Test RE 0.06538326255988045\n",
      "147 Train Loss 0.022559276 Test MSE 1.390226579181543 Test RE 0.0601042768416566\n",
      "148 Train Loss 0.021742068 Test MSE 1.370519779431537 Test RE 0.05967676002720385\n",
      "149 Train Loss 0.021352781 Test MSE 1.4722986723888483 Test RE 0.0618529678266195\n",
      "150 Train Loss 0.020166073 Test MSE 1.1608495343603844 Test RE 0.05492253171161913\n",
      "151 Train Loss 0.016757427 Test MSE 0.7982164118995604 Test RE 0.045543133601883605\n",
      "152 Train Loss 0.016010506 Test MSE 0.9034940714600045 Test RE 0.048453509223527785\n",
      "153 Train Loss 0.015168354 Test MSE 0.8131555285418428 Test RE 0.04596734200845144\n",
      "154 Train Loss 0.014705836 Test MSE 0.8344969637871662 Test RE 0.046566646463677024\n",
      "155 Train Loss 0.014699847 Test MSE 0.8382424288779531 Test RE 0.04667103179360552\n",
      "156 Train Loss 0.014695067 Test MSE 0.8414417858088428 Test RE 0.04676001266517586\n",
      "157 Train Loss 0.0146893095 Test MSE 0.842667936376399 Test RE 0.04679406965232503\n",
      "158 Train Loss 0.01468247 Test MSE 0.8441245354227934 Test RE 0.046834495284436374\n",
      "159 Train Loss 0.014486796 Test MSE 0.7782527615805691 Test RE 0.044970003124368135\n",
      "160 Train Loss 0.014104181 Test MSE 0.6468128029631142 Test RE 0.04099698192002777\n",
      "161 Train Loss 0.013053063 Test MSE 0.6705335124844701 Test RE 0.04174195895139023\n",
      "162 Train Loss 0.011907799 Test MSE 0.5814974184813818 Test RE 0.03887196348138257\n",
      "163 Train Loss 0.010902863 Test MSE 0.47819129774186403 Test RE 0.035250348644482454\n",
      "164 Train Loss 0.009675313 Test MSE 0.39586615484810395 Test RE 0.03207279208214892\n",
      "165 Train Loss 0.008141248 Test MSE 0.2652430217724317 Test RE 0.02625334017995715\n",
      "166 Train Loss 0.0071259253 Test MSE 0.23521197353213324 Test RE 0.024722494870495666\n",
      "167 Train Loss 0.005507122 Test MSE 0.2455161413503543 Test RE 0.025258212196640584\n",
      "168 Train Loss 0.0049905796 Test MSE 0.2710171184035277 Test RE 0.026537557256319993\n",
      "169 Train Loss 0.004537038 Test MSE 0.3206662740255317 Test RE 0.02886617401065501\n",
      "170 Train Loss 0.003946164 Test MSE 0.2227761395397458 Test RE 0.02406007182343567\n",
      "171 Train Loss 0.002984935 Test MSE 0.10717527872663378 Test RE 0.016688215271467594\n",
      "172 Train Loss 0.002452491 Test MSE 0.0913665501168778 Test RE 0.015408352166617175\n",
      "173 Train Loss 0.0019214799 Test MSE 0.02289030217431542 Test RE 0.007712378680699428\n",
      "174 Train Loss 0.0018184944 Test MSE 0.011771229943327808 Test RE 0.0055306159813455985\n",
      "175 Train Loss 0.0018099142 Test MSE 0.011703959569108902 Test RE 0.005514790121305001\n",
      "176 Train Loss 0.0018020836 Test MSE 0.01177599948336129 Test RE 0.005531736332530245\n",
      "177 Train Loss 0.0017944435 Test MSE 0.011931879317469342 Test RE 0.005568227983921396\n",
      "178 Train Loss 0.0017880693 Test MSE 0.01213811148275177 Test RE 0.005616142820303942\n",
      "179 Train Loss 0.0017792541 Test MSE 0.0124517464786969 Test RE 0.005688237451193278\n",
      "180 Train Loss 0.001772047 Test MSE 0.012737445992811488 Test RE 0.005753124339542775\n",
      "181 Train Loss 0.0017627528 Test MSE 0.012858582476083116 Test RE 0.005780416471963321\n",
      "182 Train Loss 0.0017528667 Test MSE 0.013064939864835786 Test RE 0.005826614564349488\n",
      "183 Train Loss 0.0016035794 Test MSE 0.010444670574579729 Test RE 0.00520966690065162\n",
      "184 Train Loss 0.0015948465 Test MSE 0.01010219658335809 Test RE 0.00512354423633808\n",
      "185 Train Loss 0.0015886052 Test MSE 0.009791828994029495 Test RE 0.005044225492826202\n",
      "186 Train Loss 0.0015841012 Test MSE 0.00954212333676953 Test RE 0.004979492646922446\n",
      "187 Train Loss 0.0015801771 Test MSE 0.009392579368649723 Test RE 0.004940319304749592\n",
      "188 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "189 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "190 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "191 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "192 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "193 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "194 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "195 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "196 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "197 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "198 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "199 Train Loss 0.0015772675 Test MSE 0.009209050851843686 Test RE 0.00489181492886908\n",
      "Training time: 128.00\n",
      "Training time: 128.00\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 4.159969 Test MSE 386.96881141506196 Test RE 1.0027682259286845\n",
      "1 Train Loss 2.8300388 Test MSE 391.46002316526443 Test RE 1.0085705698353602\n",
      "2 Train Loss 2.7085187 Test MSE 391.5059005763295 Test RE 1.0086296681446174\n",
      "3 Train Loss 2.6323385 Test MSE 393.14939628281553 Test RE 1.010744505345896\n",
      "4 Train Loss 2.5848393 Test MSE 393.19726132046344 Test RE 1.0108060313864164\n",
      "5 Train Loss 2.5588424 Test MSE 393.5307612111192 Test RE 1.0112346104785204\n",
      "6 Train Loss 2.539893 Test MSE 393.7825464351026 Test RE 1.01155805815381\n",
      "7 Train Loss 2.5265505 Test MSE 394.0423756760992 Test RE 1.0118917309169009\n",
      "8 Train Loss 2.5176141 Test MSE 394.07681857852464 Test RE 1.011935954239989\n",
      "9 Train Loss 2.5120273 Test MSE 394.16396731793174 Test RE 1.0120478411405676\n",
      "10 Train Loss 2.5078323 Test MSE 394.23897511392516 Test RE 1.0121441308489507\n",
      "11 Train Loss 2.5032315 Test MSE 394.3319773390145 Test RE 1.0122635078149373\n",
      "12 Train Loss 2.4979925 Test MSE 394.5109209806981 Test RE 1.0124931589513722\n",
      "13 Train Loss 2.494919 Test MSE 394.5162889663458 Test RE 1.0125000472654446\n",
      "14 Train Loss 2.487235 Test MSE 394.3620157192141 Test RE 1.0123020618491243\n",
      "15 Train Loss 2.4716952 Test MSE 393.99346070076297 Test RE 1.0118289227035018\n",
      "16 Train Loss 2.444459 Test MSE 392.6854389337775 Test RE 1.0101479372503843\n",
      "17 Train Loss 2.4390638 Test MSE 392.057460015517 Test RE 1.0093399044570932\n",
      "18 Train Loss 2.4330115 Test MSE 391.0963972636149 Test RE 1.0081020320956853\n",
      "19 Train Loss 2.431991 Test MSE 390.69968683525127 Test RE 1.007590615908281\n",
      "20 Train Loss 2.4313738 Test MSE 390.9470329920436 Test RE 1.0079095107556462\n",
      "21 Train Loss 2.4312565 Test MSE 391.0152121525789 Test RE 1.0079973940528268\n",
      "22 Train Loss 2.4309134 Test MSE 391.0083213687813 Test RE 1.0079885121442758\n",
      "23 Train Loss 2.430904 Test MSE 391.0017373014278 Test RE 1.0079800255062283\n",
      "24 Train Loss 2.4308968 Test MSE 390.99535115812694 Test RE 1.007971793917264\n",
      "25 Train Loss 2.4308114 Test MSE 390.9623397068156 Test RE 1.007929241858695\n",
      "26 Train Loss 2.4295237 Test MSE 390.7797053185012 Test RE 1.0076937920148306\n",
      "27 Train Loss 2.4234574 Test MSE 390.13800427950594 Test RE 1.0068660829187244\n",
      "28 Train Loss 2.4193213 Test MSE 388.976088813564 Test RE 1.0053656322968674\n",
      "29 Train Loss 2.417807 Test MSE 388.2754474379475 Test RE 1.0044597691017687\n",
      "30 Train Loss 2.4151964 Test MSE 387.43590013772774 Test RE 1.0033732365416352\n",
      "31 Train Loss 2.409323 Test MSE 387.1172931951162 Test RE 1.002960590955006\n",
      "32 Train Loss 2.4074745 Test MSE 387.3313841650485 Test RE 1.003237890793973\n",
      "33 Train Loss 2.4074242 Test MSE 387.36626059968427 Test RE 1.0032830569934503\n",
      "34 Train Loss 2.4074001 Test MSE 387.38479868106367 Test RE 1.0033070636279109\n",
      "35 Train Loss 2.4073892 Test MSE 387.39457958628316 Test RE 1.0033197295732281\n",
      "36 Train Loss 2.4073892 Test MSE 387.39457958628316 Test RE 1.0033197295732281\n",
      "37 Train Loss 2.4073837 Test MSE 387.4063807102329 Test RE 1.0033350114214303\n",
      "38 Train Loss 2.4073782 Test MSE 387.4200920536529 Test RE 1.0033527666132254\n",
      "39 Train Loss 2.406919 Test MSE 387.68186352495485 Test RE 1.0036916813774823\n",
      "40 Train Loss 2.4063873 Test MSE 387.7248457996873 Test RE 1.003747319466289\n",
      "41 Train Loss 2.4052484 Test MSE 387.62105049452543 Test RE 1.0036129571291639\n",
      "42 Train Loss 2.4038126 Test MSE 387.37946929190053 Test RE 1.003300162179789\n",
      "43 Train Loss 2.4028594 Test MSE 387.0510305081604 Test RE 1.0028747491326275\n",
      "44 Train Loss 2.4021878 Test MSE 386.79985511728466 Test RE 1.0025492903203392\n",
      "45 Train Loss 2.4016106 Test MSE 386.6415937512218 Test RE 1.0023441699575637\n",
      "46 Train Loss 2.4002929 Test MSE 386.55699540930885 Test RE 1.0022345060011717\n",
      "47 Train Loss 2.3989952 Test MSE 386.423796628457 Test RE 1.0020618174741833\n",
      "48 Train Loss 2.3980513 Test MSE 386.3899825424472 Test RE 1.0020179737124075\n",
      "49 Train Loss 2.397163 Test MSE 386.22154249859113 Test RE 1.0017995436841325\n",
      "50 Train Loss 2.3958943 Test MSE 385.97975910396053 Test RE 1.0014859200404662\n",
      "51 Train Loss 2.394656 Test MSE 385.6228889203542 Test RE 1.0010228347289822\n",
      "52 Train Loss 2.3928702 Test MSE 385.3686179786526 Test RE 1.0006927544899815\n",
      "53 Train Loss 2.3920202 Test MSE 385.1945054538831 Test RE 1.0004666685837984\n",
      "54 Train Loss 2.3893042 Test MSE 384.7094159144941 Test RE 0.9998365079780877\n",
      "55 Train Loss 2.3866642 Test MSE 384.38054825529065 Test RE 0.9994090630289947\n",
      "56 Train Loss 2.383613 Test MSE 383.9987448216244 Test RE 0.9989125854944328\n",
      "57 Train Loss 2.38193 Test MSE 383.7152242445435 Test RE 0.9985437502151994\n",
      "58 Train Loss 2.377905 Test MSE 383.19013465237254 Test RE 0.9978602948862281\n",
      "59 Train Loss 2.373359 Test MSE 382.5027805531049 Test RE 0.9969649283864576\n",
      "60 Train Loss 2.3692422 Test MSE 381.8301083314376 Test RE 0.9960879076810591\n",
      "61 Train Loss 2.3672729 Test MSE 381.4130019556971 Test RE 0.9955437021105152\n",
      "62 Train Loss 2.3667195 Test MSE 381.2351010367092 Test RE 0.9953115013263715\n",
      "63 Train Loss 2.3665986 Test MSE 381.1737526695235 Test RE 0.9952314153217601\n",
      "64 Train Loss 2.366551 Test MSE 381.13885444431867 Test RE 0.9951858552526046\n",
      "65 Train Loss 2.3665428 Test MSE 381.1283958736674 Test RE 0.9951722010517023\n",
      "66 Train Loss 2.3664913 Test MSE 381.0966636289636 Test RE 0.9951307718306278\n",
      "67 Train Loss 2.3649046 Test MSE 380.7130228859007 Test RE 0.9946297587361673\n",
      "68 Train Loss 2.3585443 Test MSE 379.8577622211542 Test RE 0.9935119272661666\n",
      "69 Train Loss 2.35263 Test MSE 378.8238976444789 Test RE 0.992158977886058\n",
      "70 Train Loss 2.3501947 Test MSE 377.73159709852337 Test RE 0.9907275500656193\n",
      "71 Train Loss 2.346632 Test MSE 376.11758765124506 Test RE 0.9886086441607419\n",
      "72 Train Loss 2.3392708 Test MSE 375.63139530305193 Test RE 0.9879694698639172\n",
      "73 Train Loss 2.323433 Test MSE 372.9616120745053 Test RE 0.9844522348112055\n",
      "74 Train Loss 2.3112576 Test MSE 371.1626093152578 Test RE 0.9820750824905738\n",
      "75 Train Loss 2.296977 Test MSE 369.03816094022216 Test RE 0.9792604645759412\n",
      "76 Train Loss 2.2909622 Test MSE 367.30990522504237 Test RE 0.9769647689318645\n",
      "77 Train Loss 2.2889478 Test MSE 366.1014116870839 Test RE 0.9753562793176916\n",
      "78 Train Loss 2.2866158 Test MSE 365.90072364930893 Test RE 0.9750889091789129\n",
      "79 Train Loss 2.2806506 Test MSE 365.77273367646393 Test RE 0.9749183540111165\n",
      "80 Train Loss 2.2665772 Test MSE 362.1446330947388 Test RE 0.9700711956212574\n",
      "81 Train Loss 2.250939 Test MSE 359.0421641000801 Test RE 0.9659069901007205\n",
      "82 Train Loss 2.2400997 Test MSE 356.4737310259087 Test RE 0.9624459478979389\n",
      "83 Train Loss 2.2240424 Test MSE 350.2013333930527 Test RE 0.9539409235679894\n",
      "84 Train Loss 2.212515 Test MSE 347.78029430672206 Test RE 0.9506377754908322\n",
      "85 Train Loss 2.2010844 Test MSE 346.6708223307335 Test RE 0.9491202247540845\n",
      "86 Train Loss 2.1863813 Test MSE 346.59472557326393 Test RE 0.9490160496536559\n",
      "87 Train Loss 2.173103 Test MSE 345.86899651229453 Test RE 0.948021964367542\n",
      "88 Train Loss 2.160336 Test MSE 343.87736189261784 Test RE 0.945288502649477\n",
      "89 Train Loss 2.1492398 Test MSE 342.6729072754904 Test RE 0.9436315808123892\n",
      "90 Train Loss 2.1371498 Test MSE 340.19704529628865 Test RE 0.9402164627095837\n",
      "91 Train Loss 2.1328585 Test MSE 337.77864124627035 Test RE 0.9368685812123914\n",
      "92 Train Loss 2.1064842 Test MSE 333.0590315009447 Test RE 0.930300361994431\n",
      "93 Train Loss 2.09133 Test MSE 331.40735817563166 Test RE 0.9279907684020733\n",
      "94 Train Loss 2.074507 Test MSE 328.68824274564525 Test RE 0.9241759599958517\n",
      "95 Train Loss 2.0548577 Test MSE 323.6945419267388 Test RE 0.9171286716899076\n",
      "96 Train Loss 2.0157378 Test MSE 314.3625228159566 Test RE 0.9038117128685748\n",
      "97 Train Loss 1.9938303 Test MSE 308.6844681559799 Test RE 0.8956121394090464\n",
      "98 Train Loss 1.9562061 Test MSE 305.7426009901254 Test RE 0.8913341794236219\n",
      "99 Train Loss 1.9439254 Test MSE 306.4022292114658 Test RE 0.8922951714468595\n",
      "100 Train Loss 1.9334973 Test MSE 302.85550503720333 Test RE 0.887115808876391\n",
      "101 Train Loss 1.920351 Test MSE 302.99538581897315 Test RE 0.8873206526477652\n",
      "102 Train Loss 1.9017477 Test MSE 300.85023482791246 Test RE 0.8841740407846246\n",
      "103 Train Loss 1.8856728 Test MSE 295.1599512061425 Test RE 0.8757724871219663\n",
      "104 Train Loss 1.8517892 Test MSE 287.93303602181714 Test RE 0.8649845110852616\n",
      "105 Train Loss 1.804484 Test MSE 280.26723526180996 Test RE 0.8533923535215142\n",
      "106 Train Loss 1.7502638 Test MSE 275.2346533425083 Test RE 0.8456957321297722\n",
      "107 Train Loss 1.7269557 Test MSE 271.69306735521866 Test RE 0.8402371143716084\n",
      "108 Train Loss 1.7048323 Test MSE 266.37805773801546 Test RE 0.8319779312927956\n",
      "109 Train Loss 1.6901953 Test MSE 264.4520254688795 Test RE 0.8289646887192423\n",
      "110 Train Loss 1.6603223 Test MSE 257.383751573084 Test RE 0.8178113731594773\n",
      "111 Train Loss 1.619133 Test MSE 253.21696247082397 Test RE 0.8111645823491631\n",
      "112 Train Loss 1.6036068 Test MSE 251.3405853815431 Test RE 0.8081535660713138\n",
      "113 Train Loss 1.5938263 Test MSE 246.67870604496727 Test RE 0.8006236473706815\n",
      "114 Train Loss 1.5620408 Test MSE 239.30451700537756 Test RE 0.7885659685025243\n",
      "115 Train Loss 1.523307 Test MSE 234.41251112483428 Test RE 0.7804641810269964\n",
      "116 Train Loss 1.5124271 Test MSE 235.22712692892625 Test RE 0.7818191152337172\n",
      "117 Train Loss 1.5090655 Test MSE 235.56736966715653 Test RE 0.7823843394875307\n",
      "118 Train Loss 1.4937042 Test MSE 234.44613216257122 Test RE 0.7805201487625576\n",
      "119 Train Loss 1.4624655 Test MSE 224.47358566995544 Test RE 0.7637394154678812\n",
      "120 Train Loss 1.4040303 Test MSE 217.84921952354972 Test RE 0.7523857936209798\n",
      "121 Train Loss 1.3834264 Test MSE 215.32983119643458 Test RE 0.7480225364484585\n",
      "122 Train Loss 1.3666644 Test MSE 213.29951724320398 Test RE 0.7444876859552159\n",
      "123 Train Loss 1.3570123 Test MSE 210.0466069559948 Test RE 0.7387889953104346\n",
      "124 Train Loss 1.346729 Test MSE 208.89595425727939 Test RE 0.736762642734222\n",
      "125 Train Loss 1.3337384 Test MSE 207.15700257482212 Test RE 0.7336896485258223\n",
      "126 Train Loss 1.3259628 Test MSE 204.70684077096124 Test RE 0.7293378634617859\n",
      "127 Train Loss 1.3186288 Test MSE 202.39358468875074 Test RE 0.7252052739215844\n",
      "128 Train Loss 1.3114208 Test MSE 200.31020670472427 Test RE 0.7214630975787274\n",
      "129 Train Loss 1.3080422 Test MSE 197.83521352696772 Test RE 0.7169921165569287\n",
      "130 Train Loss 1.2918792 Test MSE 194.07474397620874 Test RE 0.7101450979127364\n",
      "131 Train Loss 1.2776929 Test MSE 196.49531506935082 Test RE 0.714559969120813\n",
      "132 Train Loss 1.2657281 Test MSE 194.20630020230544 Test RE 0.7103857479332546\n",
      "133 Train Loss 1.2450211 Test MSE 188.07202274988543 Test RE 0.6990764630623806\n",
      "134 Train Loss 1.2187233 Test MSE 189.46761017485449 Test RE 0.7016654156637866\n",
      "135 Train Loss 1.2083504 Test MSE 187.91626659044192 Test RE 0.6987869249992748\n",
      "136 Train Loss 1.2067682 Test MSE 187.92684346382472 Test RE 0.698806590345346\n",
      "137 Train Loss 1.2005446 Test MSE 187.26680366190106 Test RE 0.6975783308226579\n",
      "138 Train Loss 1.198609 Test MSE 186.69987798099083 Test RE 0.6965216170095383\n",
      "139 Train Loss 1.1984301 Test MSE 186.6639408204867 Test RE 0.6964545783642456\n",
      "140 Train Loss 1.1984301 Test MSE 186.6639408204867 Test RE 0.6964545783642456\n",
      "141 Train Loss 1.1984301 Test MSE 186.6639408204867 Test RE 0.6964545783642456\n",
      "142 Train Loss 1.1984301 Test MSE 186.6639408204867 Test RE 0.6964545783642456\n",
      "143 Train Loss 1.1984301 Test MSE 186.6639408204867 Test RE 0.6964545783642456\n",
      "144 Train Loss 1.1984284 Test MSE 186.6477634599105 Test RE 0.6964243983495321\n",
      "145 Train Loss 1.1958556 Test MSE 185.7260585413835 Test RE 0.6947027270048971\n",
      "146 Train Loss 1.176804 Test MSE 180.7321618965496 Test RE 0.6852993254432294\n",
      "147 Train Loss 1.1713151 Test MSE 180.96862266922741 Test RE 0.685747484303375\n",
      "148 Train Loss 1.1703416 Test MSE 181.46443846377713 Test RE 0.686686243360558\n",
      "149 Train Loss 1.1670552 Test MSE 179.4247354398897 Test RE 0.6828160796930663\n",
      "150 Train Loss 1.1638491 Test MSE 178.1742060075709 Test RE 0.6804324210908828\n",
      "151 Train Loss 1.1619337 Test MSE 179.05292795227928 Test RE 0.6821082403065362\n",
      "152 Train Loss 1.149511 Test MSE 176.10524714265094 Test RE 0.6764702948449808\n",
      "153 Train Loss 1.1402696 Test MSE 172.33248761772643 Test RE 0.6691849438046111\n",
      "154 Train Loss 1.1304152 Test MSE 170.8203222437956 Test RE 0.6662425272968622\n",
      "155 Train Loss 1.0993167 Test MSE 164.056482033954 Test RE 0.6529189593579411\n",
      "156 Train Loss 1.087313 Test MSE 164.41055838319755 Test RE 0.6536231636501759\n",
      "157 Train Loss 1.079957 Test MSE 165.47596016764078 Test RE 0.6557375253680618\n",
      "158 Train Loss 1.0720384 Test MSE 164.98688157425246 Test RE 0.6547677636378677\n",
      "159 Train Loss 1.0658377 Test MSE 163.09823942056155 Test RE 0.6510093394462231\n",
      "160 Train Loss 1.0632565 Test MSE 163.594679527887 Test RE 0.6519993611379632\n",
      "161 Train Loss 1.0583953 Test MSE 164.41229551827928 Test RE 0.6536266166788006\n",
      "162 Train Loss 1.0460128 Test MSE 163.5844357781002 Test RE 0.6519789478125052\n",
      "163 Train Loss 1.0217079 Test MSE 160.2299999383605 Test RE 0.645259635968916\n",
      "164 Train Loss 1.0150974 Test MSE 157.55387888211988 Test RE 0.6398484649621247\n",
      "165 Train Loss 1.0118989 Test MSE 157.0444907618956 Test RE 0.6388132791633501\n",
      "166 Train Loss 1.0047982 Test MSE 155.8185698010806 Test RE 0.6363150415420541\n",
      "167 Train Loss 0.98982394 Test MSE 151.47243529438182 Test RE 0.627378145957801\n",
      "168 Train Loss 0.97404945 Test MSE 150.20465663058997 Test RE 0.6247471461554904\n",
      "169 Train Loss 0.9594774 Test MSE 149.15707413972353 Test RE 0.6225647261197729\n",
      "170 Train Loss 0.95734257 Test MSE 149.13778989873336 Test RE 0.6225244797005096\n",
      "171 Train Loss 0.94930774 Test MSE 145.30562876019562 Test RE 0.6144744104288954\n",
      "172 Train Loss 0.92606604 Test MSE 140.9407728823286 Test RE 0.6051748997174167\n",
      "173 Train Loss 0.91901916 Test MSE 140.95212643451688 Test RE 0.6051992743050544\n",
      "174 Train Loss 0.91682726 Test MSE 139.9468927756733 Test RE 0.603037351461567\n",
      "175 Train Loss 0.9110993 Test MSE 139.66227861209026 Test RE 0.6024238318592043\n",
      "176 Train Loss 0.9074724 Test MSE 139.5672033022417 Test RE 0.6022187464775919\n",
      "177 Train Loss 0.90585417 Test MSE 139.31470725957155 Test RE 0.6016737520866504\n",
      "178 Train Loss 0.90461475 Test MSE 138.96988616748084 Test RE 0.6009286823742624\n",
      "179 Train Loss 0.90302265 Test MSE 138.42229279302782 Test RE 0.5997435717949303\n",
      "180 Train Loss 0.9023428 Test MSE 138.02827207246256 Test RE 0.5988893748476132\n",
      "181 Train Loss 0.9023428 Test MSE 138.02827207246256 Test RE 0.5988893748476132\n",
      "182 Train Loss 0.9008795 Test MSE 137.12799871920626 Test RE 0.5969330865621688\n",
      "183 Train Loss 0.89659005 Test MSE 137.08893518670308 Test RE 0.5968480566042079\n",
      "184 Train Loss 0.8825651 Test MSE 133.95554600739666 Test RE 0.5899876651860253\n",
      "185 Train Loss 0.85695195 Test MSE 128.74395864510427 Test RE 0.5783969736297494\n",
      "186 Train Loss 0.83903885 Test MSE 126.14358584913575 Test RE 0.5725259403465071\n",
      "187 Train Loss 0.8262636 Test MSE 122.18636698344926 Test RE 0.5634740999216752\n",
      "188 Train Loss 0.79096127 Test MSE 119.10022590613141 Test RE 0.5563125727195859\n",
      "189 Train Loss 0.76438785 Test MSE 116.5003158530876 Test RE 0.5502070285590144\n",
      "190 Train Loss 0.76017046 Test MSE 117.25130039313468 Test RE 0.5519775526091256\n",
      "191 Train Loss 0.7578909 Test MSE 116.88401227948141 Test RE 0.5511123434022721\n",
      "192 Train Loss 0.75536454 Test MSE 116.3929209143296 Test RE 0.5499533679840406\n",
      "193 Train Loss 0.75536454 Test MSE 116.3929209143296 Test RE 0.5499533679840406\n",
      "194 Train Loss 0.7553596 Test MSE 116.40338844603701 Test RE 0.5499780968285858\n",
      "195 Train Loss 0.7553567 Test MSE 116.40291599922753 Test RE 0.5499769807285125\n",
      "196 Train Loss 0.7535683 Test MSE 115.83786801305634 Test RE 0.5486404960233461\n",
      "197 Train Loss 0.7512306 Test MSE 114.89577761092514 Test RE 0.5464049397571757\n",
      "198 Train Loss 0.7455084 Test MSE 115.06533603837845 Test RE 0.5468079720012837\n",
      "199 Train Loss 0.7421125 Test MSE 113.65837462401913 Test RE 0.5434546424823168\n",
      "Training time: 138.22\n",
      "Training time: 138.22\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 4.6022463 Test MSE 385.836972181466 Test RE 1.001300661206857\n",
      "1 Train Loss 3.5907934 Test MSE 385.16644660353114 Test RE 1.0004302292585088\n",
      "2 Train Loss 3.2429168 Test MSE 386.01002604425975 Test RE 1.001525185467768\n",
      "3 Train Loss 2.581388 Test MSE 391.3739810854843 Test RE 1.008459722911907\n",
      "4 Train Loss 2.5694566 Test MSE 391.4683020858881 Test RE 1.0085812348216294\n",
      "5 Train Loss 2.489799 Test MSE 390.90123743341167 Test RE 1.0078504757368192\n",
      "6 Train Loss 2.4493291 Test MSE 390.5719782962771 Test RE 1.0074259261903482\n",
      "7 Train Loss 2.4395344 Test MSE 389.86896317743697 Test RE 1.0065188531241243\n",
      "8 Train Loss 2.4203618 Test MSE 388.90730668855315 Test RE 1.0052767396324604\n",
      "9 Train Loss 2.4109104 Test MSE 387.9160606233399 Test RE 1.0039947987171396\n",
      "10 Train Loss 2.410493 Test MSE 387.7649432394678 Test RE 1.003799220521393\n",
      "11 Train Loss 2.407914 Test MSE 386.9885013927188 Test RE 1.0027937373293776\n",
      "12 Train Loss 2.4009047 Test MSE 386.13221204889584 Test RE 1.0016836822300563\n",
      "13 Train Loss 2.3951464 Test MSE 385.6550089630879 Test RE 1.0010645234197282\n",
      "14 Train Loss 2.3912895 Test MSE 384.7948601963297 Test RE 0.9999475340744529\n",
      "15 Train Loss 2.3898866 Test MSE 384.2618919647833 Test RE 0.9992547949139661\n",
      "16 Train Loss 2.3884037 Test MSE 384.0081670269539 Test RE 0.9989248406148971\n",
      "17 Train Loss 2.3875096 Test MSE 383.7340682694929 Test RE 0.9985682688570736\n",
      "18 Train Loss 2.382202 Test MSE 382.7014034491533 Test RE 0.9972237426637861\n",
      "19 Train Loss 2.3758132 Test MSE 381.95768550119027 Test RE 0.9962543003518409\n",
      "20 Train Loss 2.3722935 Test MSE 381.0244607190158 Test RE 0.9950364981883483\n",
      "21 Train Loss 2.3446758 Test MSE 373.58784631374687 Test RE 0.9852783776438954\n",
      "22 Train Loss 2.335413 Test MSE 370.84929268733043 Test RE 0.9816604860183132\n",
      "23 Train Loss 2.3249316 Test MSE 366.0320205440452 Test RE 0.9752638400477021\n",
      "24 Train Loss 2.2330477 Test MSE 353.0737377215297 Test RE 0.9578451181204438\n",
      "25 Train Loss 2.1822512 Test MSE 345.973861092613 Test RE 0.9481656696319679\n",
      "26 Train Loss 2.1280913 Test MSE 338.1608829321924 Test RE 0.9373985273474325\n",
      "27 Train Loss 2.0822475 Test MSE 331.06802462324407 Test RE 0.927515554069941\n",
      "28 Train Loss 2.0811849 Test MSE 330.2857441947171 Test RE 0.9264190930184941\n",
      "29 Train Loss 2.0700362 Test MSE 327.9040240082497 Test RE 0.9230728038339423\n",
      "30 Train Loss 2.055574 Test MSE 324.6061395164638 Test RE 0.9184191853954676\n",
      "31 Train Loss 2.051395 Test MSE 322.79349787244064 Test RE 0.9158513112318178\n",
      "32 Train Loss 2.0213227 Test MSE 312.4702216861606 Test RE 0.9010873654437661\n",
      "33 Train Loss 1.9906206 Test MSE 296.8312900748908 Test RE 0.8782485113505576\n",
      "34 Train Loss 1.9061186 Test MSE 286.52241594574014 Test RE 0.8628630757674494\n",
      "35 Train Loss 1.8740801 Test MSE 287.41116885719987 Test RE 0.8642002805826455\n",
      "36 Train Loss 1.8612139 Test MSE 288.2671758746689 Test RE 0.8654862631555861\n",
      "37 Train Loss 1.856176 Test MSE 288.3422292141275 Test RE 0.8655989249710716\n",
      "38 Train Loss 1.8463866 Test MSE 287.5948578598308 Test RE 0.8644763984739325\n",
      "39 Train Loss 1.8372705 Test MSE 285.21403676046486 Test RE 0.8608907277222164\n",
      "40 Train Loss 1.828593 Test MSE 282.91233424994084 Test RE 0.8574099587990186\n",
      "41 Train Loss 1.822948 Test MSE 283.52872508898434 Test RE 0.8583434848917965\n",
      "42 Train Loss 1.8186047 Test MSE 283.67386622048247 Test RE 0.8585631540013378\n",
      "43 Train Loss 1.7798 Test MSE 276.7091449471619 Test RE 0.8479579938523065\n",
      "44 Train Loss 1.7225237 Test MSE 262.9120326841825 Test RE 0.8265474949292002\n",
      "45 Train Loss 1.6946614 Test MSE 258.9013181225219 Test RE 0.8202187884573202\n",
      "46 Train Loss 1.6800234 Test MSE 253.54786923024272 Test RE 0.8116944287789227\n",
      "47 Train Loss 1.6577286 Test MSE 246.21231498119232 Test RE 0.7998664268051812\n",
      "48 Train Loss 1.6157563 Test MSE 235.70071519885425 Test RE 0.782605746841478\n",
      "49 Train Loss 1.5826663 Test MSE 230.1370170508838 Test RE 0.7733139103859193\n",
      "50 Train Loss 1.5463266 Test MSE 229.50443916743697 Test RE 0.7722503746300965\n",
      "51 Train Loss 1.5198618 Test MSE 228.64087589603972 Test RE 0.7707961204677297\n",
      "52 Train Loss 1.4958608 Test MSE 225.72106829815533 Test RE 0.7658586661976039\n",
      "53 Train Loss 1.4938785 Test MSE 225.98627093001764 Test RE 0.7663084428001593\n",
      "54 Train Loss 1.4857706 Test MSE 226.66024548548438 Test RE 0.7674502995272144\n",
      "55 Train Loss 1.4583514 Test MSE 224.47940208630982 Test RE 0.7637493101680476\n",
      "56 Train Loss 1.4456117 Test MSE 220.46761352637478 Test RE 0.7568938614803303\n",
      "57 Train Loss 1.3867252 Test MSE 208.51930162410355 Test RE 0.7360981282096742\n",
      "58 Train Loss 1.2866555 Test MSE 195.62720093382302 Test RE 0.7129797628227096\n",
      "59 Train Loss 1.147876 Test MSE 168.00012153200777 Test RE 0.660719889507504\n",
      "60 Train Loss 1.0682751 Test MSE 152.34387818104236 Test RE 0.6291802564521162\n",
      "61 Train Loss 1.013051 Test MSE 150.7836548646257 Test RE 0.625950103448351\n",
      "62 Train Loss 0.98637134 Test MSE 148.57056602119758 Test RE 0.6213395112869895\n",
      "63 Train Loss 0.9156025 Test MSE 135.080277206235 Test RE 0.5924593450510129\n",
      "64 Train Loss 0.8621281 Test MSE 131.5622763045074 Test RE 0.5846935083896504\n",
      "65 Train Loss 0.85324657 Test MSE 127.34034567907592 Test RE 0.5752353868525736\n",
      "66 Train Loss 0.84282744 Test MSE 123.1782233196522 Test RE 0.565756497510751\n",
      "67 Train Loss 0.7435612 Test MSE 104.38914639379162 Test RE 0.5208231209725614\n",
      "68 Train Loss 0.52515006 Test MSE 73.73258248881368 Test RE 0.4377158824573638\n",
      "69 Train Loss 0.48997188 Test MSE 69.78807373676993 Test RE 0.42584660393676194\n",
      "70 Train Loss 0.4274495 Test MSE 57.644409363679316 Test RE 0.38702692495442614\n",
      "71 Train Loss 0.38377926 Test MSE 48.559509882400974 Test RE 0.3552218975417986\n",
      "72 Train Loss 0.3130577 Test MSE 45.921550005365795 Test RE 0.3454385895915866\n",
      "73 Train Loss 0.2644266 Test MSE 34.13785541578677 Test RE 0.29783840665763794\n",
      "74 Train Loss 0.24975154 Test MSE 29.71207323738936 Test RE 0.27786193833193734\n",
      "75 Train Loss 0.23070544 Test MSE 28.612703334859866 Test RE 0.27267293229484474\n",
      "76 Train Loss 0.22615004 Test MSE 29.164034259552015 Test RE 0.27528743065375244\n",
      "77 Train Loss 0.2142915 Test MSE 26.775071086630327 Test RE 0.26377151805753835\n",
      "78 Train Loss 0.19403899 Test MSE 23.813511427031873 Test RE 0.248756422343952\n",
      "79 Train Loss 0.16924497 Test MSE 19.18167864854266 Test RE 0.22325741298613136\n",
      "80 Train Loss 0.1405415 Test MSE 16.587116193876774 Test RE 0.20760988409923062\n",
      "81 Train Loss 0.12392105 Test MSE 14.876044501608476 Test RE 0.1966103231346421\n",
      "82 Train Loss 0.116333574 Test MSE 14.02657886096071 Test RE 0.19091430086437433\n",
      "83 Train Loss 0.09447284 Test MSE 10.654639706987279 Test RE 0.16639181793763128\n",
      "84 Train Loss 0.06865664 Test MSE 3.905615354969449 Test RE 0.10074124582283642\n",
      "85 Train Loss 0.04113506 Test MSE 1.9817834832751964 Test RE 0.07176136397822465\n",
      "86 Train Loss 0.028285883 Test MSE 0.9617195372178331 Test RE 0.04999042188510608\n",
      "87 Train Loss 0.02800566 Test MSE 0.7618642019115555 Test RE 0.0444939913815702\n",
      "88 Train Loss 0.027985275 Test MSE 0.7449825197360616 Test RE 0.043998272364685065\n",
      "89 Train Loss 0.027965607 Test MSE 0.7316841473454362 Test RE 0.04360380666827012\n",
      "90 Train Loss 0.027582467 Test MSE 0.7013171858855152 Test RE 0.04268937763153632\n",
      "91 Train Loss 0.027126832 Test MSE 0.6702329477943265 Test RE 0.04173260254713559\n",
      "92 Train Loss 0.0268776 Test MSE 0.561819344444477 Test RE 0.03820858256687175\n",
      "93 Train Loss 0.02681251 Test MSE 0.5363553005881028 Test RE 0.0373326544925412\n",
      "94 Train Loss 0.026770648 Test MSE 0.5310518559873746 Test RE 0.03714762459585526\n",
      "95 Train Loss 0.026602503 Test MSE 0.5107321342606116 Test RE 0.036430000261892456\n",
      "96 Train Loss 0.026248423 Test MSE 0.3855150224992741 Test RE 0.03165069388143629\n",
      "97 Train Loss 0.025185948 Test MSE 0.35589934504541226 Test RE 0.03041068319284944\n",
      "98 Train Loss 0.022023188 Test MSE 0.1956217664089855 Test RE 0.02254608658952747\n",
      "99 Train Loss 0.01469144 Test MSE 0.00016883694184707942 Test RE 0.0006623633913615453\n",
      "100 Train Loss 0.0076351203 Test MSE 0.06770337573395746 Test RE 0.013263793267409143\n",
      "101 Train Loss 0.0033270868 Test MSE 0.014980168290968123 Test RE 0.006239085377867062\n",
      "102 Train Loss 0.001685831 Test MSE 0.009956554030087352 Test RE 0.005086477291542142\n",
      "103 Train Loss 0.0012936302 Test MSE 0.00015810760656168342 Test RE 0.00064097186177448\n",
      "104 Train Loss 0.0012851169 Test MSE 5.7939867047193776e-05 Test RE 0.0003880175147472542\n",
      "105 Train Loss 0.0012787005 Test MSE 9.461808673481065e-06 Test RE 0.00015680130163297303\n",
      "106 Train Loss 0.0012719634 Test MSE 3.0568449053588953e-07 Test RE 2.818378289981185e-05\n",
      "107 Train Loss 0.001264679 Test MSE 2.1488165908371895e-05 Test RE 0.00023629920297082592\n",
      "108 Train Loss 0.0012574253 Test MSE 6.387681964948833e-05 Test RE 0.0004074123830973649\n",
      "109 Train Loss 0.0012401185 Test MSE 0.0002268971197535751 Test RE 0.0007678512118202007\n",
      "110 Train Loss 0.0011480995 Test MSE 6.527137549509111e-05 Test RE 0.0004118356755525594\n",
      "111 Train Loss 0.0011427571 Test MSE 2.7540751370131668e-05 Test RE 0.00026751643902992844\n",
      "112 Train Loss 0.0011396945 Test MSE 6.594827142677414e-06 Test RE 0.00013090742822095876\n",
      "113 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "114 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "115 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "116 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "117 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "118 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "119 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "120 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "121 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "122 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "123 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "124 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "125 Train Loss 0.0011369603 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "126 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "127 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "128 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "129 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "130 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "131 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "132 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "133 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "134 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "135 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "136 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "137 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "138 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "139 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "140 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "141 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "142 Train Loss 0.0011369603 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "143 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "144 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "145 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "146 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "147 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "148 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "149 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "150 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "151 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "152 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "153 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "154 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "155 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "156 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "157 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "158 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "159 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "160 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "161 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "162 Train Loss 0.0011369603 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "163 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "164 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "165 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "166 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "167 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "168 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "169 Train Loss 0.0011369603 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "170 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "171 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "172 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "173 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "174 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "175 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "176 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "177 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "178 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "179 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "180 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "181 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "182 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "183 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "184 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "185 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "186 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "187 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "188 Train Loss 0.0011369603 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "189 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "190 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "191 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "192 Train Loss 0.0011369605 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "193 Train Loss 0.0011369606 Test MSE 5.5891773093339635e-08 Test RE 1.205137293685632e-05\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 94.89\n",
      "Training time: 94.89\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 4.1705456 Test MSE 388.2636116591899 Test RE 1.004444459539604\n",
      "1 Train Loss 3.8109107 Test MSE 386.47966000341546 Test RE 1.0021342464143008\n",
      "2 Train Loss 3.1109803 Test MSE 388.28098384161837 Test RE 1.0044669303515539\n",
      "3 Train Loss 3.033514 Test MSE 387.41288141586665 Test RE 1.0033434294012633\n",
      "4 Train Loss 2.810504 Test MSE 390.1379465883141 Test RE 1.0068660084741612\n",
      "5 Train Loss 2.6405485 Test MSE 388.5388552906399 Test RE 1.0048004264036186\n",
      "6 Train Loss 2.603919 Test MSE 388.2053814107229 Test RE 1.0043691354017659\n",
      "7 Train Loss 2.4957793 Test MSE 389.2080822855616 Test RE 1.0056653981484107\n",
      "8 Train Loss 2.472737 Test MSE 390.31899432910245 Test RE 1.0070996049162702\n",
      "9 Train Loss 2.461891 Test MSE 390.866412893228 Test RE 1.0078055811345967\n",
      "10 Train Loss 2.4401681 Test MSE 389.7725713245778 Test RE 1.0063944187321157\n",
      "11 Train Loss 2.423664 Test MSE 389.96139670555254 Test RE 1.0066381631791657\n",
      "12 Train Loss 2.4165177 Test MSE 388.82108165548846 Test RE 1.005165292992561\n",
      "13 Train Loss 2.3979583 Test MSE 385.3712774865858 Test RE 1.0006962074770742\n",
      "14 Train Loss 2.3889003 Test MSE 384.4401855621152 Test RE 0.9994865900442718\n",
      "15 Train Loss 2.384304 Test MSE 383.8742736067982 Test RE 0.9987506761886874\n",
      "16 Train Loss 2.3811014 Test MSE 382.87906759406326 Test RE 0.9974551898761266\n",
      "17 Train Loss 2.369045 Test MSE 380.512846680832 Test RE 0.9943682397218895\n",
      "18 Train Loss 2.353924 Test MSE 377.0085886176276 Test RE 0.9897789300390213\n",
      "19 Train Loss 2.349078 Test MSE 375.12789276579053 Test RE 0.9873071025155372\n",
      "20 Train Loss 2.3438895 Test MSE 374.38674967096995 Test RE 0.9863313051446424\n",
      "21 Train Loss 2.3380165 Test MSE 372.3596234564879 Test RE 0.9836574232924038\n",
      "22 Train Loss 2.3150728 Test MSE 361.61066797709617 Test RE 0.9693557697811115\n",
      "23 Train Loss 2.2734828 Test MSE 358.2330003338722 Test RE 0.9648179567394595\n",
      "24 Train Loss 2.24714 Test MSE 356.3085059306431 Test RE 0.9622228758448337\n",
      "25 Train Loss 2.224703 Test MSE 352.07649204395557 Test RE 0.9564914598843619\n",
      "26 Train Loss 2.215234 Test MSE 351.1966551668561 Test RE 0.9552955793057547\n",
      "27 Train Loss 2.2017531 Test MSE 351.58734959346936 Test RE 0.9558267986521511\n",
      "28 Train Loss 2.192155 Test MSE 349.12744910292344 Test RE 0.9524771816830695\n",
      "29 Train Loss 2.176382 Test MSE 345.92205464910904 Test RE 0.9480946773754461\n",
      "30 Train Loss 2.157468 Test MSE 342.8506878401277 Test RE 0.9438763296657587\n",
      "31 Train Loss 2.1205647 Test MSE 338.03774610180807 Test RE 0.9372278411457948\n",
      "32 Train Loss 2.0928617 Test MSE 331.1471973532412 Test RE 0.9276264520475225\n",
      "33 Train Loss 2.088549 Test MSE 327.84096302675215 Test RE 0.9229840390252271\n",
      "34 Train Loss 2.0798912 Test MSE 327.86199304015753 Test RE 0.9230136418778803\n",
      "35 Train Loss 2.06645 Test MSE 326.51120376838577 Test RE 0.9211102742983532\n",
      "36 Train Loss 2.0572453 Test MSE 323.3734992163107 Test RE 0.9166737512649659\n",
      "37 Train Loss 2.050448 Test MSE 321.55663749774527 Test RE 0.9140949756537031\n",
      "38 Train Loss 2.0273275 Test MSE 316.54758264998407 Test RE 0.9069473646514941\n",
      "39 Train Loss 2.0046093 Test MSE 312.43952526723 Test RE 0.9010431038906719\n",
      "40 Train Loss 1.9717053 Test MSE 312.1004939104298 Test RE 0.9005541056098677\n",
      "41 Train Loss 1.9599435 Test MSE 312.3364764326594 Test RE 0.90089450057455\n",
      "42 Train Loss 1.9127897 Test MSE 301.0944321794258 Test RE 0.8845328059411396\n",
      "43 Train Loss 1.8852854 Test MSE 298.10515268726346 Test RE 0.8801310120174373\n",
      "44 Train Loss 1.8604782 Test MSE 291.08678918864115 Test RE 0.8697087317816863\n",
      "45 Train Loss 1.8299615 Test MSE 285.1493275415252 Test RE 0.8607930629521005\n",
      "46 Train Loss 1.7875555 Test MSE 278.8081654130165 Test RE 0.8511680766520675\n",
      "47 Train Loss 1.7683108 Test MSE 279.2137979625435 Test RE 0.8517870255074959\n",
      "48 Train Loss 1.7245903 Test MSE 274.4063916675926 Test RE 0.8444223003148049\n",
      "49 Train Loss 1.707475 Test MSE 267.17661779880495 Test RE 0.8332240683952815\n",
      "50 Train Loss 1.6968284 Test MSE 264.9528294274103 Test RE 0.8297492401639561\n",
      "51 Train Loss 1.6762435 Test MSE 258.88755518402155 Test RE 0.8201969871570194\n",
      "52 Train Loss 1.6362896 Test MSE 245.35866453210082 Test RE 0.7984786018144626\n",
      "53 Train Loss 1.5553023 Test MSE 235.81174392312937 Test RE 0.7827900515162793\n",
      "54 Train Loss 1.4786515 Test MSE 229.31003459341858 Test RE 0.7719232332220914\n",
      "55 Train Loss 1.4427664 Test MSE 227.23370732412934 Test RE 0.7684205301900798\n",
      "56 Train Loss 1.428762 Test MSE 227.6936079125049 Test RE 0.769197744160379\n",
      "57 Train Loss 1.3757604 Test MSE 217.7764965583106 Test RE 0.7522602014955346\n",
      "58 Train Loss 1.3476651 Test MSE 210.24393736338564 Test RE 0.7391359452366524\n",
      "59 Train Loss 1.2910502 Test MSE 197.3076443201578 Test RE 0.7160354732179705\n",
      "60 Train Loss 1.2607739 Test MSE 196.3648867659267 Test RE 0.7143227769127172\n",
      "61 Train Loss 1.2500113 Test MSE 194.9447266501724 Test RE 0.7117350088264228\n",
      "62 Train Loss 1.2419904 Test MSE 193.13524060310482 Test RE 0.7084241292026592\n",
      "63 Train Loss 1.2340485 Test MSE 191.2240541211995 Test RE 0.7049102785581285\n",
      "64 Train Loss 1.1975203 Test MSE 185.48915612429403 Test RE 0.6942595224504426\n",
      "65 Train Loss 1.1647727 Test MSE 180.27803552017951 Test RE 0.6844378068338003\n",
      "66 Train Loss 1.1467417 Test MSE 175.3065075283544 Test RE 0.6749344584774857\n",
      "67 Train Loss 1.127381 Test MSE 167.69298784067826 Test RE 0.6601156572925774\n",
      "68 Train Loss 1.1040733 Test MSE 164.30307816627686 Test RE 0.6534094819825937\n",
      "69 Train Loss 1.0881288 Test MSE 165.15324621724506 Test RE 0.6550977982384202\n",
      "70 Train Loss 1.0734589 Test MSE 163.6311413382101 Test RE 0.6520720155562585\n",
      "71 Train Loss 1.0598184 Test MSE 161.5955774801588 Test RE 0.6480034498529497\n",
      "72 Train Loss 1.053387 Test MSE 158.70115165916386 Test RE 0.6421738574572992\n",
      "73 Train Loss 1.0367804 Test MSE 154.56584344720514 Test RE 0.6337520053964871\n",
      "74 Train Loss 1.0177385 Test MSE 154.3272417576772 Test RE 0.6332626582744839\n",
      "75 Train Loss 1.0039531 Test MSE 155.7624613460983 Test RE 0.6362004664034331\n",
      "76 Train Loss 0.981169 Test MSE 152.46594258847566 Test RE 0.6294322689986261\n",
      "77 Train Loss 0.96026826 Test MSE 148.27974680468523 Test RE 0.6207310933888599\n",
      "78 Train Loss 0.95260376 Test MSE 148.25205667865563 Test RE 0.6206731322542819\n",
      "79 Train Loss 0.94207287 Test MSE 145.68259075939378 Test RE 0.6152709503454554\n",
      "80 Train Loss 0.9327567 Test MSE 142.50282775750327 Test RE 0.6085192533374351\n",
      "81 Train Loss 0.9204465 Test MSE 142.9582042891954 Test RE 0.609490758140529\n",
      "82 Train Loss 0.90998703 Test MSE 141.36466553588332 Test RE 0.6060842767360312\n",
      "83 Train Loss 0.8954876 Test MSE 139.5194189035754 Test RE 0.6021156451632677\n",
      "84 Train Loss 0.8745618 Test MSE 136.39985173225648 Test RE 0.5953461255771169\n",
      "85 Train Loss 0.86153585 Test MSE 133.9782976038537 Test RE 0.5900377661029313\n",
      "86 Train Loss 0.8549753 Test MSE 131.95373877537943 Test RE 0.5855627376359751\n",
      "87 Train Loss 0.8535548 Test MSE 131.98301648774054 Test RE 0.585627695956589\n",
      "88 Train Loss 0.84941006 Test MSE 132.61666938716334 Test RE 0.5870318173627331\n",
      "89 Train Loss 0.8460433 Test MSE 131.8953123289868 Test RE 0.5854330856147808\n",
      "90 Train Loss 0.84386414 Test MSE 131.00201526726016 Test RE 0.583447214626368\n",
      "91 Train Loss 0.8361171 Test MSE 130.04809747881333 Test RE 0.5813190887398066\n",
      "92 Train Loss 0.83028865 Test MSE 128.55506002295343 Test RE 0.577972493525613\n",
      "93 Train Loss 0.81571966 Test MSE 125.5352188263959 Test RE 0.5711436787404606\n",
      "94 Train Loss 0.79785115 Test MSE 122.38356103045136 Test RE 0.5639286062057469\n",
      "95 Train Loss 0.7826187 Test MSE 119.16671077617976 Test RE 0.5564678251910736\n",
      "96 Train Loss 0.7757304 Test MSE 117.64873943200806 Test RE 0.5529122622427938\n",
      "97 Train Loss 0.7708839 Test MSE 116.54231835487928 Test RE 0.5503062042089197\n",
      "98 Train Loss 0.7660508 Test MSE 116.63278574025908 Test RE 0.5505197537006301\n",
      "99 Train Loss 0.7589307 Test MSE 113.16640247064775 Test RE 0.5422771907439595\n",
      "100 Train Loss 0.75605386 Test MSE 111.30279972413693 Test RE 0.5377935966648648\n",
      "101 Train Loss 0.73782474 Test MSE 110.6244887487652 Test RE 0.536152358593705\n",
      "102 Train Loss 0.7091349 Test MSE 106.6640842718118 Test RE 0.5264676463763217\n",
      "103 Train Loss 0.68142664 Test MSE 102.43879631864026 Test RE 0.5159347925370322\n",
      "104 Train Loss 0.6595021 Test MSE 99.89089964986724 Test RE 0.5094781284801947\n",
      "105 Train Loss 0.6530647 Test MSE 99.15224446049551 Test RE 0.5075909347979711\n",
      "106 Train Loss 0.6513282 Test MSE 99.65020808741147 Test RE 0.50886395318898\n",
      "107 Train Loss 0.6488309 Test MSE 99.70631195306082 Test RE 0.5090071802739011\n",
      "108 Train Loss 0.64395833 Test MSE 98.44382463206408 Test RE 0.5057743744062128\n",
      "109 Train Loss 0.63755953 Test MSE 97.93335972518975 Test RE 0.5044613635167566\n",
      "110 Train Loss 0.62478656 Test MSE 96.48238681215798 Test RE 0.5007103882982166\n",
      "111 Train Loss 0.6048417 Test MSE 91.97785352473662 Test RE 0.48888219167262664\n",
      "112 Train Loss 0.58040756 Test MSE 88.29812969703457 Test RE 0.479003111849399\n",
      "113 Train Loss 0.57579476 Test MSE 86.3592529420367 Test RE 0.47371487369748794\n",
      "114 Train Loss 0.56864965 Test MSE 85.21676925610888 Test RE 0.4705709521403979\n",
      "115 Train Loss 0.562271 Test MSE 83.2398792870476 Test RE 0.46508068494245813\n",
      "116 Train Loss 0.547053 Test MSE 79.7155393597857 Test RE 0.45512854741350295\n",
      "117 Train Loss 0.5365668 Test MSE 78.92867357991945 Test RE 0.45287670776466293\n",
      "118 Train Loss 0.5292056 Test MSE 77.73819448612048 Test RE 0.44944836756037426\n",
      "119 Train Loss 0.52339697 Test MSE 75.06774546699701 Test RE 0.4416612211613367\n",
      "120 Train Loss 0.5191035 Test MSE 74.86152817611587 Test RE 0.44105416405691755\n",
      "121 Train Loss 0.5122247 Test MSE 74.87332083682664 Test RE 0.44108890150766883\n",
      "122 Train Loss 0.50756145 Test MSE 74.14391861890397 Test RE 0.43893513951864327\n",
      "123 Train Loss 0.5037795 Test MSE 73.17196918050989 Test RE 0.43604865769338885\n",
      "124 Train Loss 0.5025996 Test MSE 72.70577059892703 Test RE 0.43465734555503815\n",
      "125 Train Loss 0.5016238 Test MSE 72.18822382164832 Test RE 0.43310755612935276\n",
      "126 Train Loss 0.500536 Test MSE 71.34235257639071 Test RE 0.43056259286745446\n",
      "127 Train Loss 0.49942237 Test MSE 70.5865397234607 Test RE 0.4282757938834471\n",
      "128 Train Loss 0.49816245 Test MSE 69.85358486686194 Test RE 0.42604643140619924\n",
      "129 Train Loss 0.49648184 Test MSE 68.72939857817644 Test RE 0.42260424418637776\n",
      "130 Train Loss 0.48831585 Test MSE 68.09701248797707 Test RE 0.42065553925018084\n",
      "131 Train Loss 0.47350448 Test MSE 68.01030335252824 Test RE 0.4203876398581292\n",
      "132 Train Loss 0.46685156 Test MSE 67.9494954444467 Test RE 0.42019966385894664\n",
      "133 Train Loss 0.46362644 Test MSE 67.46810001720023 Test RE 0.4187085435601284\n",
      "134 Train Loss 0.45721406 Test MSE 67.13006834540695 Test RE 0.41765831035453443\n",
      "135 Train Loss 0.4495159 Test MSE 65.32177355870085 Test RE 0.41199464045430384\n",
      "136 Train Loss 0.43950102 Test MSE 64.61100749145373 Test RE 0.4097470533684388\n",
      "137 Train Loss 0.4371362 Test MSE 64.43727721487194 Test RE 0.4091958053060186\n",
      "138 Train Loss 0.4314031 Test MSE 63.67432775704403 Test RE 0.40676611431830206\n",
      "139 Train Loss 0.42467812 Test MSE 62.7998589903468 Test RE 0.403963305116177\n",
      "140 Train Loss 0.41426525 Test MSE 61.49759577453355 Test RE 0.3997529260326785\n",
      "141 Train Loss 0.4079643 Test MSE 60.56820004230687 Test RE 0.39672074998840556\n",
      "142 Train Loss 0.40310448 Test MSE 60.696797765796646 Test RE 0.3971416832016978\n",
      "143 Train Loss 0.39889205 Test MSE 59.828400580441695 Test RE 0.39429046875616086\n",
      "144 Train Loss 0.39447758 Test MSE 59.06990339469966 Test RE 0.39178311311699066\n",
      "145 Train Loss 0.38997033 Test MSE 58.26121465199369 Test RE 0.3890920433530208\n",
      "146 Train Loss 0.38247293 Test MSE 56.63217300295328 Test RE 0.38361377667500074\n",
      "147 Train Loss 0.379145 Test MSE 56.59438147531521 Test RE 0.38348575960220654\n",
      "148 Train Loss 0.373164 Test MSE 56.0622511811664 Test RE 0.3816786337578184\n",
      "149 Train Loss 0.36507738 Test MSE 54.1601848499201 Test RE 0.3751480138457814\n",
      "150 Train Loss 0.35767227 Test MSE 53.56605813240935 Test RE 0.37308468921859594\n",
      "151 Train Loss 0.35185814 Test MSE 51.99721701670148 Test RE 0.36758064251224437\n",
      "152 Train Loss 0.34348115 Test MSE 51.05291500068646 Test RE 0.3642276021294894\n",
      "153 Train Loss 0.34048167 Test MSE 50.514521333855456 Test RE 0.3623019767225261\n",
      "154 Train Loss 0.33275363 Test MSE 48.460464029624255 Test RE 0.3548594431552485\n",
      "155 Train Loss 0.3308482 Test MSE 47.781595306985764 Test RE 0.35236511475156873\n",
      "156 Train Loss 0.3279466 Test MSE 47.368415633540465 Test RE 0.3508383112926792\n",
      "157 Train Loss 0.32426596 Test MSE 46.34847891444972 Test RE 0.34704063190362555\n",
      "158 Train Loss 0.31998628 Test MSE 45.13045728169001 Test RE 0.34245021998644054\n",
      "159 Train Loss 0.31648436 Test MSE 44.10139439100474 Test RE 0.33852343818381914\n",
      "160 Train Loss 0.31353718 Test MSE 42.45865434423163 Test RE 0.33215874844298243\n",
      "161 Train Loss 0.31045783 Test MSE 41.824177897860025 Test RE 0.32966761722020765\n",
      "162 Train Loss 0.30830207 Test MSE 41.84587942143059 Test RE 0.3297531342837837\n",
      "163 Train Loss 0.30660087 Test MSE 41.40800184759404 Test RE 0.32802331973729987\n",
      "164 Train Loss 0.30514002 Test MSE 41.172078512868595 Test RE 0.3270875235413213\n",
      "165 Train Loss 0.3037744 Test MSE 41.38314137326325 Test RE 0.3279248358776853\n",
      "166 Train Loss 0.29918146 Test MSE 40.36733350699847 Test RE 0.3238751401253548\n",
      "167 Train Loss 0.29203832 Test MSE 39.287885395171244 Test RE 0.3195154842700946\n",
      "168 Train Loss 0.2895237 Test MSE 39.387789737498835 Test RE 0.31992147096240253\n",
      "169 Train Loss 0.2873674 Test MSE 39.05539808501678 Test RE 0.31856871003499343\n",
      "170 Train Loss 0.2838773 Test MSE 38.595628862231 Test RE 0.3166880262418414\n",
      "171 Train Loss 0.2804005 Test MSE 37.52047496014471 Test RE 0.31224590122032375\n",
      "172 Train Loss 0.26672018 Test MSE 36.82535071790823 Test RE 0.3093399623730385\n",
      "173 Train Loss 0.25640395 Test MSE 35.98034361976565 Test RE 0.3057702552902625\n",
      "174 Train Loss 0.24697664 Test MSE 34.17984395750637 Test RE 0.2980215165386526\n",
      "175 Train Loss 0.24391468 Test MSE 32.53167033696349 Test RE 0.2907473491994714\n",
      "176 Train Loss 0.2382385 Test MSE 31.0937525413803 Test RE 0.2842491348248471\n",
      "177 Train Loss 0.23521861 Test MSE 30.717608696719015 Test RE 0.2825246101990767\n",
      "178 Train Loss 0.22933102 Test MSE 29.949281863389107 Test RE 0.27896889944371256\n",
      "179 Train Loss 0.22580445 Test MSE 30.420210184424914 Test RE 0.281153625239334\n",
      "180 Train Loss 0.21560182 Test MSE 29.43425865409534 Test RE 0.2765598515991333\n",
      "181 Train Loss 0.19783224 Test MSE 27.114690949464958 Test RE 0.2654391096241506\n",
      "182 Train Loss 0.19363235 Test MSE 26.08127404593061 Test RE 0.26033165766583083\n",
      "183 Train Loss 0.1909916 Test MSE 25.317305298858145 Test RE 0.25649052228611036\n",
      "184 Train Loss 0.1854221 Test MSE 25.130193116196146 Test RE 0.25554094442945446\n",
      "185 Train Loss 0.1816409 Test MSE 25.528920349512603 Test RE 0.2575602314529138\n",
      "186 Train Loss 0.17773652 Test MSE 24.939322387147396 Test RE 0.2545686428047412\n",
      "187 Train Loss 0.17543627 Test MSE 24.677579865066864 Test RE 0.2532292481694778\n",
      "188 Train Loss 0.1740784 Test MSE 24.240312737205684 Test RE 0.2509757101848145\n",
      "189 Train Loss 0.17062461 Test MSE 23.518248985559712 Test RE 0.247209453471561\n",
      "190 Train Loss 0.16915858 Test MSE 22.554237151065454 Test RE 0.24208989040739595\n",
      "191 Train Loss 0.16663527 Test MSE 22.15082268950662 Test RE 0.23991506134496207\n",
      "192 Train Loss 0.16134614 Test MSE 21.899554841516782 Test RE 0.23855044221920674\n",
      "193 Train Loss 0.15886831 Test MSE 21.746443264543828 Test RE 0.23771506223067448\n",
      "194 Train Loss 0.15389451 Test MSE 21.13894779489832 Test RE 0.23437121186341933\n",
      "195 Train Loss 0.15008457 Test MSE 19.923995328692342 Test RE 0.22753635577900608\n",
      "196 Train Loss 0.14232317 Test MSE 19.03151736589146 Test RE 0.22238182516687435\n",
      "197 Train Loss 0.13727914 Test MSE 18.683303508049903 Test RE 0.22033800707815945\n",
      "198 Train Loss 0.13602218 Test MSE 18.347801861243234 Test RE 0.21835070741369\n",
      "199 Train Loss 0.13463406 Test MSE 18.105436622097344 Test RE 0.2169037616320678\n",
      "Training time: 149.58\n",
      "Training time: 149.58\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 5.3269215 Test MSE 382.6655435592947 Test RE 0.9971770206358591\n",
      "1 Train Loss 4.9271703 Test MSE 383.2512391289159 Test RE 0.9979398523890259\n",
      "2 Train Loss 4.893234 Test MSE 383.3389216972393 Test RE 0.9980540032594238\n",
      "3 Train Loss 4.8918405 Test MSE 383.35506212672936 Test RE 0.9980750144975107\n",
      "4 Train Loss 4.743426 Test MSE 383.0976684179672 Test RE 0.9977398925813459\n",
      "5 Train Loss 4.29585 Test MSE 386.47482219391463 Test RE 1.0021279742216704\n",
      "6 Train Loss 2.45392 Test MSE 383.92293606745415 Test RE 0.9988139783277685\n",
      "7 Train Loss 2.3875275 Test MSE 384.07957329451347 Test RE 0.9990177112683704\n",
      "8 Train Loss 2.3830116 Test MSE 384.0257110760462 Test RE 0.9989476591221398\n",
      "9 Train Loss 2.374123 Test MSE 382.71635066198405 Test RE 0.9972432168149735\n",
      "10 Train Loss 2.3679094 Test MSE 381.5768359449932 Test RE 0.9957574944878731\n",
      "11 Train Loss 2.3654065 Test MSE 380.927228164601 Test RE 0.994909529812885\n",
      "12 Train Loss 2.3609998 Test MSE 379.84881110963164 Test RE 0.9935002214523925\n",
      "13 Train Loss 2.3502917 Test MSE 377.9024558070009 Test RE 0.9909515918103126\n",
      "14 Train Loss 2.3425632 Test MSE 374.72687183538636 Test RE 0.9867792336313236\n",
      "15 Train Loss 2.2875211 Test MSE 364.07896170297465 Test RE 0.9726584733334567\n",
      "16 Train Loss 2.229841 Test MSE 355.3153612097695 Test RE 0.9608809300426385\n",
      "17 Train Loss 2.1937444 Test MSE 348.9904323370585 Test RE 0.9522902611899843\n",
      "18 Train Loss 2.1642554 Test MSE 339.7896592436947 Test RE 0.9396533393413947\n",
      "19 Train Loss 2.0876338 Test MSE 327.86195253896767 Test RE 0.9230135848673808\n",
      "20 Train Loss 2.0348084 Test MSE 322.72589372832294 Test RE 0.9157554007091663\n",
      "21 Train Loss 1.9532022 Test MSE 311.7495967838738 Test RE 0.9000477130777138\n",
      "22 Train Loss 1.8707254 Test MSE 292.0062781127222 Test RE 0.8710812726444102\n",
      "23 Train Loss 1.7984544 Test MSE 287.0840621486786 Test RE 0.8637083613083164\n",
      "24 Train Loss 1.7574124 Test MSE 273.15797434701034 Test RE 0.8424992525850519\n",
      "25 Train Loss 1.7003841 Test MSE 264.48694811374844 Test RE 0.8290194220564079\n",
      "26 Train Loss 1.6589465 Test MSE 259.7905293203077 Test RE 0.8216261249731378\n",
      "27 Train Loss 1.6231492 Test MSE 255.92333352015964 Test RE 0.81548790573707\n",
      "28 Train Loss 1.5361851 Test MSE 241.84475451280727 Test RE 0.7927402670409306\n",
      "29 Train Loss 1.4499401 Test MSE 227.3557541468359 Test RE 0.7686268611433262\n",
      "30 Train Loss 1.3497062 Test MSE 212.61794163354998 Test RE 0.7432972691668482\n",
      "31 Train Loss 1.1771662 Test MSE 179.32067279082315 Test RE 0.6826180413468044\n",
      "32 Train Loss 1.135791 Test MSE 173.55327935509433 Test RE 0.671550991508029\n",
      "33 Train Loss 1.1024021 Test MSE 165.39324984852092 Test RE 0.6555736253100493\n",
      "34 Train Loss 1.0265063 Test MSE 153.13608783932605 Test RE 0.630814048266464\n",
      "35 Train Loss 0.9821716 Test MSE 144.00917351791827 Test RE 0.6117270168689638\n",
      "36 Train Loss 0.90206075 Test MSE 129.6050400905202 Test RE 0.5803280036592852\n",
      "37 Train Loss 0.82924664 Test MSE 118.35394480985927 Test RE 0.5545669086996537\n",
      "38 Train Loss 0.8110916 Test MSE 117.47868082538682 Test RE 0.5525125066117947\n",
      "39 Train Loss 0.79573655 Test MSE 116.94101656147163 Test RE 0.5512467156461281\n",
      "40 Train Loss 0.77130514 Test MSE 115.3540294674701 Test RE 0.5474934998162854\n",
      "41 Train Loss 0.7506981 Test MSE 110.21906019951129 Test RE 0.535168982296207\n",
      "42 Train Loss 0.71859074 Test MSE 104.02315463541156 Test RE 0.5199093078640895\n",
      "43 Train Loss 0.7056779 Test MSE 101.77757842966705 Test RE 0.514266979104281\n",
      "44 Train Loss 0.6953009 Test MSE 101.14307394611849 Test RE 0.5126614444430843\n",
      "45 Train Loss 0.69109094 Test MSE 100.97462691829445 Test RE 0.5122343648697774\n",
      "46 Train Loss 0.6631591 Test MSE 97.80534554061265 Test RE 0.5041315508383384\n",
      "47 Train Loss 0.6422856 Test MSE 93.27097504098916 Test RE 0.49230680728926024\n",
      "48 Train Loss 0.6230097 Test MSE 88.86957649386828 Test RE 0.48055061546000394\n",
      "49 Train Loss 0.5997422 Test MSE 86.9530301268794 Test RE 0.47534063602807647\n",
      "50 Train Loss 0.5866164 Test MSE 82.79705912617263 Test RE 0.4638419653754424\n",
      "51 Train Loss 0.56859654 Test MSE 74.77874120393523 Test RE 0.44081022274237064\n",
      "52 Train Loss 0.5266715 Test MSE 74.13862728113888 Test RE 0.438919476767317\n",
      "53 Train Loss 0.50477976 Test MSE 71.53275096577673 Test RE 0.43113675252253153\n",
      "54 Train Loss 0.49604973 Test MSE 68.11520160098013 Test RE 0.4207117152849087\n",
      "55 Train Loss 0.4889266 Test MSE 65.21925181633422 Test RE 0.411671203166316\n",
      "56 Train Loss 0.45555946 Test MSE 57.97125217560318 Test RE 0.38812259205789346\n",
      "57 Train Loss 0.42481422 Test MSE 55.384444877131294 Test RE 0.37936432340817744\n",
      "58 Train Loss 0.38831317 Test MSE 54.19616513514884 Test RE 0.3752726043687774\n",
      "59 Train Loss 0.3721907 Test MSE 51.11258423062036 Test RE 0.3644403895282424\n",
      "60 Train Loss 0.3667832 Test MSE 50.143363629215465 Test RE 0.36096850778741263\n",
      "61 Train Loss 0.35540438 Test MSE 49.74879895899316 Test RE 0.35954552083033636\n",
      "62 Train Loss 0.33061042 Test MSE 48.33513475368696 Test RE 0.3544002743231114\n",
      "63 Train Loss 0.3262818 Test MSE 47.94114813211294 Test RE 0.3529529351670674\n",
      "64 Train Loss 0.3131564 Test MSE 45.947374814211344 Test RE 0.34553570773862746\n",
      "65 Train Loss 0.29671544 Test MSE 42.397115649756344 Test RE 0.3319179491527416\n",
      "66 Train Loss 0.28282747 Test MSE 39.449560935912594 Test RE 0.32017223637454556\n",
      "67 Train Loss 0.27257562 Test MSE 38.38762008357801 Test RE 0.31583348795212485\n",
      "68 Train Loss 0.26030487 Test MSE 37.3031682032094 Test RE 0.3113403732949154\n",
      "69 Train Loss 0.25582907 Test MSE 36.40184917412243 Test RE 0.30755607190682116\n",
      "70 Train Loss 0.253141 Test MSE 36.48136563709782 Test RE 0.30789180251921056\n",
      "71 Train Loss 0.250182 Test MSE 36.55573390977087 Test RE 0.3082054657246091\n",
      "72 Train Loss 0.23586269 Test MSE 33.670122515767616 Test RE 0.29579098312865093\n",
      "73 Train Loss 0.22915906 Test MSE 32.786270826022594 Test RE 0.2918828603399785\n",
      "74 Train Loss 0.2215313 Test MSE 32.726976822999454 Test RE 0.2916188056802276\n",
      "75 Train Loss 0.19553071 Test MSE 27.498445743368702 Test RE 0.2673108927101434\n",
      "76 Train Loss 0.17211676 Test MSE 24.142317488911296 Test RE 0.2504678921880783\n",
      "77 Train Loss 0.15210117 Test MSE 22.300469640417518 Test RE 0.2407241085772645\n",
      "78 Train Loss 0.14494696 Test MSE 21.255960135061898 Test RE 0.23501898482305933\n",
      "79 Train Loss 0.14267813 Test MSE 21.1286993709565 Test RE 0.2343143919413762\n",
      "80 Train Loss 0.14185037 Test MSE 20.850794458753835 Test RE 0.2327683275121859\n",
      "81 Train Loss 0.14111622 Test MSE 20.557771071755248 Test RE 0.2311269537223121\n",
      "82 Train Loss 0.13944834 Test MSE 20.45322149722926 Test RE 0.23053848949528755\n",
      "83 Train Loss 0.13745622 Test MSE 20.095737181567948 Test RE 0.2285149161809602\n",
      "84 Train Loss 0.13680667 Test MSE 19.952768955959087 Test RE 0.2277005970400316\n",
      "85 Train Loss 0.13417952 Test MSE 18.96891859808468 Test RE 0.2220157930216922\n",
      "86 Train Loss 0.13017172 Test MSE 17.330212680819496 Test RE 0.21220935668104007\n",
      "87 Train Loss 0.11943945 Test MSE 15.864264978163783 Test RE 0.2030357715323558\n",
      "88 Train Loss 0.11265825 Test MSE 14.985131889310328 Test RE 0.1973298870804604\n",
      "89 Train Loss 0.105359495 Test MSE 13.821267625671844 Test RE 0.1895119152651391\n",
      "90 Train Loss 0.1011139 Test MSE 13.35527828201066 Test RE 0.1862897901228246\n",
      "91 Train Loss 0.09662816 Test MSE 13.076054200822893 Test RE 0.18433208631725517\n",
      "92 Train Loss 0.0930322 Test MSE 13.072788566724558 Test RE 0.18430906718909837\n",
      "93 Train Loss 0.09128403 Test MSE 13.23969469287033 Test RE 0.1854819135589728\n",
      "94 Train Loss 0.088381365 Test MSE 12.965168541003655 Test RE 0.18354884918626105\n",
      "95 Train Loss 0.08578302 Test MSE 12.283751097839218 Test RE 0.17866031133824473\n",
      "96 Train Loss 0.08502831 Test MSE 12.200781948335965 Test RE 0.17805591902341794\n",
      "97 Train Loss 0.08230612 Test MSE 11.580733903416938 Test RE 0.1734724946147642\n",
      "98 Train Loss 0.080195464 Test MSE 10.972784034676499 Test RE 0.16885775008619255\n",
      "99 Train Loss 0.076546304 Test MSE 10.805180060110947 Test RE 0.1675631772958047\n",
      "100 Train Loss 0.07338308 Test MSE 10.676813417308411 Test RE 0.16656486960669545\n",
      "101 Train Loss 0.07045001 Test MSE 10.272085877335268 Test RE 0.16337737100445476\n",
      "102 Train Loss 0.06574841 Test MSE 9.275576945098612 Test RE 0.15525051473154713\n",
      "103 Train Loss 0.061543778 Test MSE 9.057335059098987 Test RE 0.1534132249592186\n",
      "104 Train Loss 0.05900552 Test MSE 8.83667401618409 Test RE 0.1515329226463566\n",
      "105 Train Loss 0.05554588 Test MSE 7.687925653024292 Test RE 0.14134067789015153\n",
      "106 Train Loss 0.053915437 Test MSE 7.075966625942012 Test RE 0.1355986826859828\n",
      "107 Train Loss 0.049690623 Test MSE 6.361142558594252 Test RE 0.12856718848377005\n",
      "108 Train Loss 0.048450805 Test MSE 5.936807376281947 Test RE 0.12420499498217075\n",
      "109 Train Loss 0.047433756 Test MSE 5.976049219531733 Test RE 0.12461481164781887\n",
      "110 Train Loss 0.04638947 Test MSE 5.853690410203388 Test RE 0.12333247798850099\n",
      "111 Train Loss 0.042735036 Test MSE 4.569589919608365 Test RE 0.1089685561304338\n",
      "112 Train Loss 0.03887572 Test MSE 3.723201800123389 Test RE 0.0983605323303949\n",
      "113 Train Loss 0.034932427 Test MSE 3.1022674865508093 Test RE 0.08978467256084606\n",
      "114 Train Loss 0.02810343 Test MSE 2.3601089631670114 Test RE 0.07831205304164048\n",
      "115 Train Loss 0.025242712 Test MSE 1.8048459517626674 Test RE 0.06848298034623156\n",
      "116 Train Loss 0.024297718 Test MSE 1.5436484561123331 Test RE 0.06333398049453355\n",
      "117 Train Loss 0.023263726 Test MSE 1.3585058452617254 Test RE 0.05941462196909012\n",
      "118 Train Loss 0.02286541 Test MSE 1.2824818070460247 Test RE 0.05772822298288095\n",
      "119 Train Loss 0.021713475 Test MSE 1.2043694382708674 Test RE 0.05594257409430757\n",
      "120 Train Loss 0.02064886 Test MSE 1.2314026315686781 Test RE 0.05656693154463682\n",
      "121 Train Loss 0.019374978 Test MSE 1.5761544472589835 Test RE 0.06399734665278672\n",
      "122 Train Loss 0.018917672 Test MSE 1.6458204068995517 Test RE 0.06539639434568871\n",
      "123 Train Loss 0.01754938 Test MSE 1.3269293754146114 Test RE 0.0587200594780328\n",
      "124 Train Loss 0.016350167 Test MSE 1.2120421153176464 Test RE 0.05612048787918044\n",
      "125 Train Loss 0.014444949 Test MSE 1.2137121207907382 Test RE 0.0561591372212822\n",
      "126 Train Loss 0.013846442 Test MSE 1.186083474075728 Test RE 0.055516261139855506\n",
      "127 Train Loss 0.012540141 Test MSE 1.06570236966491 Test RE 0.05262359918191274\n",
      "128 Train Loss 0.011884512 Test MSE 1.037569197374291 Test RE 0.05192435585814008\n",
      "129 Train Loss 0.011501653 Test MSE 0.9765910543581261 Test RE 0.05037545171012784\n",
      "130 Train Loss 0.011018766 Test MSE 0.9690998421419248 Test RE 0.05018187033695545\n",
      "131 Train Loss 0.009706654 Test MSE 0.8516808202428545 Test RE 0.04704365063581866\n",
      "132 Train Loss 0.0086982185 Test MSE 0.7305360148103184 Test RE 0.04356958247198094\n",
      "133 Train Loss 0.008038448 Test MSE 0.6988007258772636 Test RE 0.04261271998405422\n",
      "134 Train Loss 0.007271992 Test MSE 0.6555240907265434 Test RE 0.04127213267067236\n",
      "135 Train Loss 0.0059722043 Test MSE 0.5257700530056473 Test RE 0.03696242917927814\n",
      "136 Train Loss 0.0053547826 Test MSE 0.4429234193821276 Test RE 0.03392555057671927\n",
      "137 Train Loss 0.005152922 Test MSE 0.4107855340670383 Test RE 0.032671581183109255\n",
      "138 Train Loss 0.0048537394 Test MSE 0.39119523279032675 Test RE 0.03188301323082306\n",
      "139 Train Loss 0.0048084212 Test MSE 0.38352484073761467 Test RE 0.031568891440264216\n",
      "140 Train Loss 0.0047884164 Test MSE 0.3787119561904232 Test RE 0.03137018578036594\n",
      "141 Train Loss 0.0047802534 Test MSE 0.3757827668349285 Test RE 0.03124863220242141\n",
      "142 Train Loss 0.0047771316 Test MSE 0.3747862043693676 Test RE 0.03120716956699478\n",
      "143 Train Loss 0.0047740703 Test MSE 0.37366135102112297 Test RE 0.03116030302339066\n",
      "144 Train Loss 0.004771364 Test MSE 0.37307751022332647 Test RE 0.031135949731126156\n",
      "145 Train Loss 0.004763378 Test MSE 0.3727016955957362 Test RE 0.031120263589083787\n",
      "146 Train Loss 0.0047598174 Test MSE 0.37294296287425704 Test RE 0.03113033476217743\n",
      "147 Train Loss 0.0047573787 Test MSE 0.3731900165339414 Test RE 0.031140644099833206\n",
      "148 Train Loss 0.0047505023 Test MSE 0.3743354251365776 Test RE 0.031188396495415077\n",
      "149 Train Loss 0.0047471467 Test MSE 0.3751691737423199 Test RE 0.031223109773031416\n",
      "150 Train Loss 0.004741472 Test MSE 0.37631424545948844 Test RE 0.031270722241414556\n",
      "151 Train Loss 0.0047404417 Test MSE 0.37730167584983176 Test RE 0.031311721795643156\n",
      "152 Train Loss 0.0047320565 Test MSE 0.3783320325535596 Test RE 0.031354446554975775\n",
      "153 Train Loss 0.0047261035 Test MSE 0.37956481873279513 Test RE 0.03140548887825265\n",
      "154 Train Loss 0.0047243116 Test MSE 0.3805401570048585 Test RE 0.03144581311468888\n",
      "155 Train Loss 0.004703994 Test MSE 0.3830888293484118 Test RE 0.03155094174183627\n",
      "156 Train Loss 0.0044035893 Test MSE 0.35991949915870947 Test RE 0.030581956796519025\n",
      "157 Train Loss 0.004323547 Test MSE 0.35123439404066686 Test RE 0.030210721753320516\n",
      "158 Train Loss 0.0043160436 Test MSE 0.3510435304489811 Test RE 0.030202512263430098\n",
      "159 Train Loss 0.0043088 Test MSE 0.3515220144345955 Test RE 0.03022308876762797\n",
      "160 Train Loss 0.0043007694 Test MSE 0.35281811808589075 Test RE 0.030278755571293694\n",
      "161 Train Loss 0.004292541 Test MSE 0.3540499468015232 Test RE 0.030331567118699866\n",
      "162 Train Loss 0.004288464 Test MSE 0.3554507184265727 Test RE 0.030391510153770507\n",
      "163 Train Loss 0.004278769 Test MSE 0.3570414922999969 Test RE 0.030459440877960917\n",
      "164 Train Loss 0.004273018 Test MSE 0.3579555767483026 Test RE 0.030498406522360536\n",
      "165 Train Loss 0.0042705247 Test MSE 0.3595256098140192 Test RE 0.030565218047354285\n",
      "166 Train Loss 0.0042637894 Test MSE 0.36157032985901216 Test RE 0.030652011177380253\n",
      "167 Train Loss 0.0042578336 Test MSE 0.3624389164982284 Test RE 0.030688806172629098\n",
      "168 Train Loss 0.0042487453 Test MSE 0.36326622073937137 Test RE 0.030723811392291543\n",
      "169 Train Loss 0.0042402274 Test MSE 0.3639889096450377 Test RE 0.030754357482445163\n",
      "170 Train Loss 0.004077562 Test MSE 0.3351906613426375 Test RE 0.029512672444908607\n",
      "171 Train Loss 0.004055945 Test MSE 0.329095829515189 Test RE 0.02924312440924996\n",
      "172 Train Loss 0.00403288 Test MSE 0.32465475479422773 Test RE 0.02904513948344237\n",
      "173 Train Loss 0.0039818147 Test MSE 0.3245864422365157 Test RE 0.0290420835415179\n",
      "174 Train Loss 0.003974205 Test MSE 0.32588818888376975 Test RE 0.029100261581818263\n",
      "175 Train Loss 0.0039655734 Test MSE 0.3276582234890783 Test RE 0.02917918238975449\n",
      "176 Train Loss 0.003931281 Test MSE 0.3371283106122401 Test RE 0.029597852030187943\n",
      "177 Train Loss 0.0039111194 Test MSE 0.34465940728943695 Test RE 0.02992661874720265\n",
      "178 Train Loss 0.0039045 Test MSE 0.3473810464040158 Test RE 0.030044545739234506\n",
      "179 Train Loss 0.00389785 Test MSE 0.3499208956220476 Test RE 0.03015417987624729\n",
      "180 Train Loss 0.0038965768 Test MSE 0.351690869301016 Test RE 0.030230346780931942\n",
      "181 Train Loss 0.0038903914 Test MSE 0.35376075461998546 Test RE 0.030319176996807518\n",
      "182 Train Loss 0.0038850452 Test MSE 0.3543974703760593 Test RE 0.030346449692942777\n",
      "183 Train Loss 0.0038795406 Test MSE 0.3549077018979939 Test RE 0.030368286962503155\n",
      "184 Train Loss 0.0038764041 Test MSE 0.35474893367667415 Test RE 0.030361493564912835\n",
      "185 Train Loss 0.0038689433 Test MSE 0.3539877192793426 Test RE 0.030328901476147852\n",
      "186 Train Loss 0.0038651812 Test MSE 0.3530160568243755 Test RE 0.030287247904893407\n",
      "187 Train Loss 0.003857681 Test MSE 0.35079807785651723 Test RE 0.030191951491614216\n",
      "188 Train Loss 0.0038520105 Test MSE 0.3489145440562401 Test RE 0.030110787846715364\n",
      "189 Train Loss 0.0038465196 Test MSE 0.34649476446725386 Test RE 0.030006194562199613\n",
      "190 Train Loss 0.003842856 Test MSE 0.34556790017096006 Test RE 0.029966034800712957\n",
      "191 Train Loss 0.003842115 Test MSE 0.3443460373265954 Test RE 0.029913010768053926\n",
      "192 Train Loss 0.0038405997 Test MSE 0.3429596544532147 Test RE 0.029852733158636912\n",
      "193 Train Loss 0.0038332166 Test MSE 0.3412953502042827 Test RE 0.029780210847365755\n",
      "194 Train Loss 0.0038313046 Test MSE 0.3405310130517936 Test RE 0.02974684549403955\n",
      "195 Train Loss 0.0038269756 Test MSE 0.3397742893208515 Test RE 0.029713775579117817\n",
      "196 Train Loss 0.003825095 Test MSE 0.33980181272189397 Test RE 0.02971497903627478\n",
      "197 Train Loss 0.0038183304 Test MSE 0.33991530659044694 Test RE 0.029719941026241186\n",
      "198 Train Loss 0.0038151888 Test MSE 0.340469310020343 Test RE 0.029744150359638465\n",
      "199 Train Loss 0.0038074816 Test MSE 0.3414332429257063 Test RE 0.02978622625252355\n",
      "Training time: 116.10\n",
      "Training time: 116.10\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 4.249533 Test MSE 387.84503095722533 Test RE 1.003902875892402\n",
      "1 Train Loss 2.661233 Test MSE 392.97694158481636 Test RE 1.0105227998577972\n",
      "2 Train Loss 2.6594427 Test MSE 393.2857416918016 Test RE 1.0109197547906004\n",
      "3 Train Loss 2.6325321 Test MSE 393.6993685270127 Test RE 1.0114512178080866\n",
      "4 Train Loss 2.6230996 Test MSE 393.6864547294537 Test RE 1.0114346292834118\n",
      "5 Train Loss 2.6043713 Test MSE 394.3842440963716 Test RE 1.0123305908580789\n",
      "6 Train Loss 2.5921478 Test MSE 394.33862842683726 Test RE 1.0122720445625102\n",
      "7 Train Loss 2.5828285 Test MSE 394.4711753586628 Test RE 1.0124421550603708\n",
      "8 Train Loss 2.572812 Test MSE 394.3863173146907 Test RE 1.0123332516889805\n",
      "9 Train Loss 2.5492697 Test MSE 393.2360512952392 Test RE 1.010855889533132\n",
      "10 Train Loss 2.5349877 Test MSE 392.3365677617013 Test RE 1.009699117702487\n",
      "11 Train Loss 2.4920852 Test MSE 390.9348554807784 Test RE 1.0078938130728836\n",
      "12 Train Loss 2.4657953 Test MSE 389.8446138937107 Test RE 1.0064874215431063\n",
      "13 Train Loss 2.4554079 Test MSE 389.2715515455661 Test RE 1.0057473931525778\n",
      "14 Train Loss 2.4381957 Test MSE 389.6142668481423 Test RE 1.0061900265647243\n",
      "15 Train Loss 2.4303536 Test MSE 390.30118203471045 Test RE 1.0070766250465097\n",
      "16 Train Loss 2.4300218 Test MSE 390.45609513469435 Test RE 1.0072764628792836\n",
      "17 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "18 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "19 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "20 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "21 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "22 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "23 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "24 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "25 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "26 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "27 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "28 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "29 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "30 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "31 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "32 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "33 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "34 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "35 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "36 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "37 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "38 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "39 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "40 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "41 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "42 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "43 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "44 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "45 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "46 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "47 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "48 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "49 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "50 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "51 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "52 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "53 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "54 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "55 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "56 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "57 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "58 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "59 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "60 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "61 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "62 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "63 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "64 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "65 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "66 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "67 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "68 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "69 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "70 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "71 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "72 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "73 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "74 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "75 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "76 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "77 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "78 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "79 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "80 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "81 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "82 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "83 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "84 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "85 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "86 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "87 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "88 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "89 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "90 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "91 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "92 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "93 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "94 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "95 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "96 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "97 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "98 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "99 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "100 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "101 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "102 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "103 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "104 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "105 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "106 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "107 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "108 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "109 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "110 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "111 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "112 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "113 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "114 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "115 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "116 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "117 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "118 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "119 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "120 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "121 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "122 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "123 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "124 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "125 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "126 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "127 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "128 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "129 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "130 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "131 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "132 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "133 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "134 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "135 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "136 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "137 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "138 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "139 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "140 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "141 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "142 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "143 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "144 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "145 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "146 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "147 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "148 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "149 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "150 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "151 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "152 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "153 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "154 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "155 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "156 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "157 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "158 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "159 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "160 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "161 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "162 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "163 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "164 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "165 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "166 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "167 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "168 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "169 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "170 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "171 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "172 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "173 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "174 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "175 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "176 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "177 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "178 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "179 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "180 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "181 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "182 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "183 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "184 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "185 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "186 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "187 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "188 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "189 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "190 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "191 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "192 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "193 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "194 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "195 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "196 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "197 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "198 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "199 Train Loss 2.4299955 Test MSE 390.45625297486185 Test RE 1.0072766664728137\n",
      "Training time: 76.77\n",
      "Training time: 76.77\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 4.5535593 Test MSE 386.52239041773396 Test RE 1.0021896444499878\n",
      "1 Train Loss 4.4777856 Test MSE 385.7040450194342 Test RE 1.0011281641023866\n",
      "2 Train Loss 3.4236846 Test MSE 392.65250799142797 Test RE 1.010105580420174\n",
      "3 Train Loss 2.6375284 Test MSE 393.0956859034008 Test RE 1.0106754612043516\n",
      "4 Train Loss 2.613416 Test MSE 391.7921945226154 Test RE 1.0089983877426623\n",
      "5 Train Loss 2.5808198 Test MSE 390.88465471815346 Test RE 1.00782909811875\n",
      "6 Train Loss 2.4651449 Test MSE 385.521344671621 Test RE 1.0008910287507218\n",
      "7 Train Loss 2.4145975 Test MSE 385.84046505005875 Test RE 1.0013051934367474\n",
      "8 Train Loss 2.3961935 Test MSE 385.12030166492195 Test RE 1.0003702990975392\n",
      "9 Train Loss 2.3939242 Test MSE 384.6357726820041 Test RE 0.9997408062439681\n",
      "10 Train Loss 2.390482 Test MSE 383.444602766139 Test RE 0.9981915684000864\n",
      "11 Train Loss 2.3790193 Test MSE 382.54997443862 Test RE 0.9970264301583085\n",
      "12 Train Loss 2.3731964 Test MSE 382.1333393806818 Test RE 0.996483351664192\n",
      "13 Train Loss 2.360641 Test MSE 380.2019673502195 Test RE 0.9939619568580907\n",
      "14 Train Loss 2.3497107 Test MSE 378.3955211378973 Test RE 0.9915978493238066\n",
      "15 Train Loss 2.3434088 Test MSE 377.14535031742764 Test RE 0.9899584373224589\n",
      "16 Train Loss 2.3382092 Test MSE 376.1763335235223 Test RE 0.9886858466254421\n",
      "17 Train Loss 2.3220963 Test MSE 373.607056087489 Test RE 0.9853037086759348\n",
      "18 Train Loss 2.2723432 Test MSE 363.7931545839268 Test RE 0.9722766230704596\n",
      "19 Train Loss 2.2418694 Test MSE 358.5590414579892 Test RE 0.9652569151658412\n",
      "20 Train Loss 2.2036912 Test MSE 351.4435456261392 Test RE 0.9556313056350406\n",
      "21 Train Loss 2.1702147 Test MSE 340.4190965028044 Test RE 0.9405232586476568\n",
      "22 Train Loss 2.168625 Test MSE 337.96856599714556 Test RE 0.9371319334572118\n",
      "23 Train Loss 2.159391 Test MSE 331.63619374218337 Test RE 0.9283111002273506\n",
      "24 Train Loss 2.1155634 Test MSE 322.66736624800075 Test RE 0.9156723592063744\n",
      "25 Train Loss 2.0842872 Test MSE 317.4032553069478 Test RE 0.9081723405607138\n",
      "26 Train Loss 2.0488112 Test MSE 313.1137976429589 Test RE 0.9020148456077917\n",
      "27 Train Loss 1.9996719 Test MSE 311.1125706929861 Test RE 0.8991276684677799\n",
      "28 Train Loss 1.9664834 Test MSE 305.12502777121813 Test RE 0.8904335159735155\n",
      "29 Train Loss 1.9567593 Test MSE 298.41197290171874 Test RE 0.8805838262928715\n",
      "30 Train Loss 1.9361897 Test MSE 285.4829490566325 Test RE 0.8612964748632504\n",
      "31 Train Loss 1.9038042 Test MSE 282.91534381987384 Test RE 0.8574145192724536\n",
      "32 Train Loss 1.9007288 Test MSE 284.1522716817666 Test RE 0.8592868164910823\n",
      "33 Train Loss 1.8921314 Test MSE 281.85438420425095 Test RE 0.8558053159358638\n",
      "34 Train Loss 1.8831725 Test MSE 275.46738716875717 Test RE 0.8460532096701605\n",
      "35 Train Loss 1.8801122 Test MSE 274.1732734368826 Test RE 0.8440635403437731\n",
      "36 Train Loss 1.8732681 Test MSE 271.7591071565553 Test RE 0.8403392254066036\n",
      "37 Train Loss 1.866678 Test MSE 267.7216243990638 Test RE 0.8340734714480149\n",
      "38 Train Loss 1.8605947 Test MSE 265.51334853496064 Test RE 0.8306264615637103\n",
      "39 Train Loss 1.8216281 Test MSE 255.13514054109012 Test RE 0.8142311670661656\n",
      "40 Train Loss 1.802858 Test MSE 249.90331992469422 Test RE 0.8058395814600298\n",
      "41 Train Loss 1.7951552 Test MSE 249.80107364385302 Test RE 0.8056747126426451\n",
      "42 Train Loss 1.7787364 Test MSE 257.04707766372627 Test RE 0.8172763241355357\n",
      "43 Train Loss 1.777543 Test MSE 259.1551059148049 Test RE 0.820620699365831\n",
      "44 Train Loss 1.776093 Test MSE 259.8607896241985 Test RE 0.8217372217840806\n",
      "45 Train Loss 1.761558 Test MSE 255.66466644259393 Test RE 0.8150756861911697\n",
      "46 Train Loss 1.7492855 Test MSE 255.62964797074738 Test RE 0.8150198636897468\n",
      "47 Train Loss 1.7385247 Test MSE 254.93813513284226 Test RE 0.8139167475779553\n",
      "48 Train Loss 1.7110533 Test MSE 248.45398995575277 Test RE 0.8034994249720929\n",
      "49 Train Loss 1.6674942 Test MSE 234.44940482318535 Test RE 0.7805255964289611\n",
      "50 Train Loss 1.654533 Test MSE 227.7877096323038 Test RE 0.7693566756169213\n",
      "51 Train Loss 1.6505482 Test MSE 223.64320963077964 Test RE 0.7623254885278393\n",
      "52 Train Loss 1.6449344 Test MSE 221.18278556359826 Test RE 0.7581205066102408\n",
      "53 Train Loss 1.6371952 Test MSE 222.27961665476062 Test RE 0.7599979172154482\n",
      "54 Train Loss 1.6315765 Test MSE 225.1299428202111 Test RE 0.7648551813198196\n",
      "55 Train Loss 1.6300408 Test MSE 227.17306908728628 Test RE 0.7683179952809133\n",
      "56 Train Loss 1.6245302 Test MSE 225.91124973789422 Test RE 0.7661812356368902\n",
      "57 Train Loss 1.602118 Test MSE 216.69784856561634 Test RE 0.7503949148098649\n",
      "58 Train Loss 1.5754743 Test MSE 209.5618094132043 Test RE 0.7379359227520265\n",
      "59 Train Loss 1.547879 Test MSE 201.67146347292774 Test RE 0.7239103858801252\n",
      "60 Train Loss 1.5164734 Test MSE 187.03309584860074 Test RE 0.6971429082068186\n",
      "61 Train Loss 1.460804 Test MSE 164.69766887996693 Test RE 0.6541936264472521\n",
      "62 Train Loss 1.4343545 Test MSE 164.46352620020912 Test RE 0.6537284433976341\n",
      "63 Train Loss 1.425066 Test MSE 170.06888630116856 Test RE 0.6647755169183694\n",
      "64 Train Loss 1.407346 Test MSE 180.04671507796377 Test RE 0.6839985539983772\n",
      "65 Train Loss 1.3119807 Test MSE 173.83508196147275 Test RE 0.6720959770663442\n",
      "66 Train Loss 1.1958466 Test MSE 176.67023144462053 Test RE 0.6775545585248712\n",
      "67 Train Loss 0.9166425 Test MSE 131.88991139946503 Test RE 0.5854210991569277\n",
      "68 Train Loss 0.91224873 Test MSE 131.81458638702097 Test RE 0.5852539023294299\n",
      "69 Train Loss 0.8983188 Test MSE 130.02333934544515 Test RE 0.5812637512882555\n",
      "70 Train Loss 0.8491418 Test MSE 114.47671829851156 Test RE 0.5454075782752026\n",
      "71 Train Loss 0.7840655 Test MSE 107.2805249211055 Test RE 0.5279867543055855\n",
      "72 Train Loss 0.68922466 Test MSE 97.02574087558874 Test RE 0.5021183191527636\n",
      "73 Train Loss 0.5717277 Test MSE 67.27502926750353 Test RE 0.41810901363636094\n",
      "74 Train Loss 0.4526144 Test MSE 48.572467841703094 Test RE 0.3552692893284206\n",
      "75 Train Loss 0.40466517 Test MSE 46.40476804999961 Test RE 0.34725130429400075\n",
      "76 Train Loss 0.373933 Test MSE 42.01022305955556 Test RE 0.3304000286270713\n",
      "77 Train Loss 0.28712487 Test MSE 35.94690320298603 Test RE 0.3056281296089848\n",
      "78 Train Loss 0.2790276 Test MSE 36.54816676342824 Test RE 0.30817356434662097\n",
      "79 Train Loss 0.26492223 Test MSE 36.08304760020781 Test RE 0.30620634679125325\n",
      "80 Train Loss 0.23739854 Test MSE 29.664508006019332 Test RE 0.27763943852475537\n",
      "81 Train Loss 0.23689672 Test MSE 29.701451057730477 Test RE 0.2778122655399044\n",
      "82 Train Loss 0.23689672 Test MSE 29.701451057730477 Test RE 0.2778122655399044\n",
      "83 Train Loss 0.23689641 Test MSE 29.711502023393756 Test RE 0.27785926737408123\n",
      "84 Train Loss 0.23688819 Test MSE 29.719821510670904 Test RE 0.277898166195826\n",
      "85 Train Loss 0.23470943 Test MSE 29.228770781399326 Test RE 0.2755927943081562\n",
      "86 Train Loss 0.19203734 Test MSE 21.64776420190039 Test RE 0.23717510793528715\n",
      "87 Train Loss 0.12905496 Test MSE 10.078164010462045 Test RE 0.16182786085722484\n",
      "88 Train Loss 0.123255745 Test MSE 6.738459983674386 Test RE 0.13232530672941686\n",
      "89 Train Loss 0.120759636 Test MSE 5.896729699119977 Test RE 0.12378504896948546\n",
      "90 Train Loss 0.12042688 Test MSE 6.1944884424141335 Test RE 0.12687185975155946\n",
      "91 Train Loss 0.119672455 Test MSE 5.878056470821967 Test RE 0.12358889793017555\n",
      "92 Train Loss 0.11227008 Test MSE 3.8459533078973998 Test RE 0.09996882468154401\n",
      "93 Train Loss 0.10074675 Test MSE 3.219482882888733 Test RE 0.09146514827096835\n",
      "94 Train Loss 0.09119852 Test MSE 3.860364209901048 Test RE 0.10015594264840137\n",
      "95 Train Loss 0.08528432 Test MSE 3.9180636115754948 Test RE 0.10090166295335871\n",
      "96 Train Loss 0.07974438 Test MSE 2.8434002002309984 Test RE 0.08595706485250018\n",
      "97 Train Loss 0.07509125 Test MSE 2.030796132664079 Test RE 0.07264333036240893\n",
      "98 Train Loss 0.07187732 Test MSE 2.2809095498526766 Test RE 0.07698686133362086\n",
      "99 Train Loss 0.070920095 Test MSE 2.603541602304934 Test RE 0.08225169252971103\n",
      "100 Train Loss 0.0677582 Test MSE 3.0780270756971873 Test RE 0.08943320616414592\n",
      "101 Train Loss 0.06581513 Test MSE 2.4861534783233803 Test RE 0.08037602980567367\n",
      "102 Train Loss 0.06395645 Test MSE 1.4287916898245803 Test RE 0.06093222545242066\n",
      "103 Train Loss 0.061836287 Test MSE 1.6809412037004494 Test RE 0.06609047054953919\n",
      "104 Train Loss 0.058352873 Test MSE 2.2415864567930353 Test RE 0.07632034581736946\n",
      "105 Train Loss 0.054430433 Test MSE 1.6439041275921855 Test RE 0.06535831174086239\n",
      "106 Train Loss 0.049893267 Test MSE 1.253465873371195 Test RE 0.05707144120153517\n",
      "107 Train Loss 0.045708813 Test MSE 1.0709837105400675 Test RE 0.05275383239490158\n",
      "108 Train Loss 0.040479627 Test MSE 0.9848841058000406 Test RE 0.05058888959481896\n",
      "109 Train Loss 0.035522446 Test MSE 0.5457624888644759 Test RE 0.03765862195769619\n",
      "110 Train Loss 0.030493958 Test MSE 0.06764454391011991 Test RE 0.01325802913279553\n",
      "111 Train Loss 0.025113305 Test MSE 0.42807048303605666 Test RE 0.03335187265582689\n",
      "112 Train Loss 0.021846766 Test MSE 0.43297717693271087 Test RE 0.033542473455148145\n",
      "113 Train Loss 0.019139811 Test MSE 0.202344015163147 Test RE 0.022930195860187637\n",
      "114 Train Loss 0.01740418 Test MSE 0.3099493303677615 Test RE 0.028379708723129497\n",
      "115 Train Loss 0.015285884 Test MSE 0.35930857344533956 Test RE 0.03055599093638878\n",
      "116 Train Loss 0.014200823 Test MSE 0.38020026844744015 Test RE 0.03143176668686395\n",
      "117 Train Loss 0.012718396 Test MSE 0.3371286935541565 Test RE 0.029597868840189653\n",
      "118 Train Loss 0.012137454 Test MSE 0.2135133030732448 Test RE 0.02355456304295214\n",
      "119 Train Loss 0.0115235355 Test MSE 0.11837996801552458 Test RE 0.0175388733362533\n",
      "120 Train Loss 0.010961792 Test MSE 0.1939049924264989 Test RE 0.022446936499339248\n",
      "121 Train Loss 0.0107953735 Test MSE 0.20928555140111726 Test RE 0.023320196517265468\n",
      "122 Train Loss 0.010775099 Test MSE 0.2110753039558697 Test RE 0.023419698200193524\n",
      "123 Train Loss 0.010768911 Test MSE 0.21164220267176742 Test RE 0.023451127017499854\n",
      "124 Train Loss 0.010763565 Test MSE 0.21267119869677298 Test RE 0.023508067117660545\n",
      "125 Train Loss 0.010492504 Test MSE 0.22365141448042578 Test RE 0.024107290824167484\n",
      "126 Train Loss 0.010317854 Test MSE 0.18037639601731278 Test RE 0.021649727541323577\n",
      "127 Train Loss 0.010160434 Test MSE 0.1751375498661689 Test RE 0.021333013952194297\n",
      "128 Train Loss 0.010135381 Test MSE 0.19099395121848242 Test RE 0.022277804538587218\n",
      "129 Train Loss 0.010127057 Test MSE 0.19756115619843367 Test RE 0.022657571653404793\n",
      "130 Train Loss 0.010119966 Test MSE 0.20461938996528897 Test RE 0.02305876139088372\n",
      "131 Train Loss 0.010111923 Test MSE 0.21180935930598885 Test RE 0.02346038612958432\n",
      "132 Train Loss 0.010102456 Test MSE 0.2188092658372896 Test RE 0.02384489624274445\n",
      "133 Train Loss 0.0100961905 Test MSE 0.22554786784606462 Test RE 0.024209284018379882\n",
      "134 Train Loss 0.010087808 Test MSE 0.2324394161661974 Test RE 0.024576354932423286\n",
      "135 Train Loss 0.010082579 Test MSE 0.23782657774220098 Test RE 0.024859522117163108\n",
      "136 Train Loss 0.010074809 Test MSE 0.243084021016051 Test RE 0.02513279497226759\n",
      "137 Train Loss 0.010072977 Test MSE 0.24632093362862875 Test RE 0.025299576041383255\n",
      "138 Train Loss 0.010065794 Test MSE 0.24846719179918683 Test RE 0.025409557869307608\n",
      "139 Train Loss 0.010057845 Test MSE 0.24961972156784554 Test RE 0.02546842155632096\n",
      "140 Train Loss 0.010050381 Test MSE 0.24966570390266424 Test RE 0.02547076721145005\n",
      "141 Train Loss 0.010044977 Test MSE 0.24913371609113796 Test RE 0.025443616178377846\n",
      "142 Train Loss 0.010036659 Test MSE 0.24661821708350062 Test RE 0.02531483840118794\n",
      "143 Train Loss 0.009849402 Test MSE 0.17620060358175074 Test RE 0.021397659799824137\n",
      "144 Train Loss 0.009813723 Test MSE 0.16912766438147422 Test RE 0.020963795194875776\n",
      "145 Train Loss 0.009651598 Test MSE 0.18964760807078812 Test RE 0.02219914599040346\n",
      "146 Train Loss 0.0096438965 Test MSE 0.19192964077831148 Test RE 0.022332307943042497\n",
      "147 Train Loss 0.00962471 Test MSE 0.19518920844307247 Test RE 0.0225211458923152\n",
      "148 Train Loss 0.009607293 Test MSE 0.19792670019199568 Test RE 0.022678523422869225\n",
      "149 Train Loss 0.009604174 Test MSE 0.19745748761381612 Test RE 0.022651626186570906\n",
      "150 Train Loss 0.009595906 Test MSE 0.1980056434262735 Test RE 0.02268304564625857\n",
      "151 Train Loss 0.0095912665 Test MSE 0.19657047022397198 Test RE 0.02260069116726699\n",
      "152 Train Loss 0.009583503 Test MSE 0.19453541498387494 Test RE 0.022483396550323408\n",
      "153 Train Loss 0.009577115 Test MSE 0.1916980006653706 Test RE 0.022318827429823305\n",
      "154 Train Loss 0.009568874 Test MSE 0.18737573688327533 Test RE 0.02206577875811203\n",
      "155 Train Loss 0.009566502 Test MSE 0.18430567142591733 Test RE 0.02188426334649679\n",
      "156 Train Loss 0.00955833 Test MSE 0.18036846242800436 Test RE 0.021649251420446793\n",
      "157 Train Loss 0.009551283 Test MSE 0.17711124734228914 Test RE 0.021452882464524474\n",
      "158 Train Loss 0.009542725 Test MSE 0.17280979445630462 Test RE 0.02119077105284912\n",
      "159 Train Loss 0.009535703 Test MSE 0.16944378258325624 Test RE 0.02098337786779052\n",
      "160 Train Loss 0.009516429 Test MSE 0.16229416452607823 Test RE 0.020535913899197882\n",
      "161 Train Loss 0.009327675 Test MSE 0.15293973497920413 Test RE 0.019935298786627673\n",
      "162 Train Loss 0.008994185 Test MSE 0.11911522437609669 Test RE 0.01759325587574413\n",
      "163 Train Loss 0.008560533 Test MSE 0.099000738634823 Test RE 0.016039166654962685\n",
      "164 Train Loss 0.0082129855 Test MSE 0.11250650760543451 Test RE 0.017098239825916572\n",
      "165 Train Loss 0.007738414 Test MSE 0.14937790375985233 Test RE 0.01970179350225721\n",
      "166 Train Loss 0.0071922718 Test MSE 0.13143130887390575 Test RE 0.018480426888183674\n",
      "167 Train Loss 0.0067144767 Test MSE 0.12576766592562044 Test RE 0.018077862676530387\n",
      "168 Train Loss 0.0063299392 Test MSE 0.09283876496888402 Test RE 0.015531995631951713\n",
      "169 Train Loss 0.0060355677 Test MSE 0.08888243198351815 Test RE 0.015197443837593997\n",
      "170 Train Loss 0.005733288 Test MSE 0.08350062556341646 Test RE 0.014730159419316052\n",
      "171 Train Loss 0.005405584 Test MSE 0.06158818528567997 Test RE 0.012650604730251098\n",
      "172 Train Loss 0.005088285 Test MSE 0.06866673330754107 Test RE 0.013357825817934132\n",
      "173 Train Loss 0.0048177564 Test MSE 0.04768326673649689 Test RE 0.01113129219208878\n",
      "174 Train Loss 0.004589434 Test MSE 0.03543425550342894 Test RE 0.009595646464140474\n",
      "175 Train Loss 0.004326463 Test MSE 0.0389046080818152 Test RE 0.010054560805182211\n",
      "176 Train Loss 0.004130338 Test MSE 0.03287491976068066 Test RE 0.009242616497141367\n",
      "177 Train Loss 0.0039797304 Test MSE 0.019168119836892164 Test RE 0.0070575236225549984\n",
      "178 Train Loss 0.0039351443 Test MSE 0.014751817872281732 Test RE 0.006191349969941367\n",
      "179 Train Loss 0.0037079542 Test MSE 0.014468167131209774 Test RE 0.006131536826271276\n",
      "180 Train Loss 0.003493297 Test MSE 0.02762111505579431 Test RE 0.008471946137905365\n",
      "181 Train Loss 0.0034835588 Test MSE 0.02792802225862975 Test RE 0.008518883390321934\n",
      "182 Train Loss 0.0032703374 Test MSE 0.01698083904812426 Test RE 0.006642662009291871\n",
      "183 Train Loss 0.003197308 Test MSE 0.012320652378146082 Test RE 0.005658214856643984\n",
      "184 Train Loss 0.0030200714 Test MSE 0.01898968666469757 Test RE 0.007024598100662166\n",
      "185 Train Loss 0.0029548702 Test MSE 0.028660002884363666 Test RE 0.008629799335864918\n",
      "186 Train Loss 0.0029348724 Test MSE 0.0315511169113306 Test RE 0.009054614218829122\n",
      "187 Train Loss 0.0028994868 Test MSE 0.03633020257373309 Test RE 0.009716201038882748\n",
      "188 Train Loss 0.002876132 Test MSE 0.03809354936019628 Test RE 0.009949203236301602\n",
      "189 Train Loss 0.0028207886 Test MSE 0.03758841763392423 Test RE 0.009883018408371165\n",
      "190 Train Loss 0.0028125662 Test MSE 0.03655773833175349 Test RE 0.009746579791001294\n",
      "191 Train Loss 0.0027935298 Test MSE 0.033908081903547105 Test RE 0.009386727153216473\n",
      "192 Train Loss 0.0027842124 Test MSE 0.031816475768623065 Test RE 0.00909261114986887\n",
      "193 Train Loss 0.0027783532 Test MSE 0.030450846438210614 Test RE 0.008895334155536942\n",
      "194 Train Loss 0.0027716388 Test MSE 0.02927645163915807 Test RE 0.00872211486284602\n",
      "195 Train Loss 0.0027666115 Test MSE 0.028127157909278003 Test RE 0.008549200612804864\n",
      "196 Train Loss 0.0027636148 Test MSE 0.02717443079174014 Test RE 0.008403163438358362\n",
      "197 Train Loss 0.0027586892 Test MSE 0.025958060057975563 Test RE 0.008212940924762314\n",
      "198 Train Loss 0.0027534645 Test MSE 0.02494181246441824 Test RE 0.0080505691973703\n",
      "199 Train Loss 0.0027477648 Test MSE 0.024021777222884514 Test RE 0.007900692335059144\n",
      "Training time: 116.56\n",
      "Training time: 116.56\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 4.462661 Test MSE 386.15900923243373 Test RE 1.0017184395423848\n",
      "1 Train Loss 3.8429093 Test MSE 387.98372966153664 Test RE 1.0040823645679262\n",
      "2 Train Loss 3.2360902 Test MSE 386.65755544866556 Test RE 1.0023648595956092\n",
      "3 Train Loss 2.7061195 Test MSE 392.3287277901457 Test RE 1.009689029359264\n",
      "4 Train Loss 2.6048691 Test MSE 394.4923228082717 Test RE 1.0124692930160033\n",
      "5 Train Loss 2.4927511 Test MSE 393.1626464014599 Test RE 1.010761537512171\n",
      "6 Train Loss 2.4299464 Test MSE 389.1500037751525 Test RE 1.0055903615162824\n",
      "7 Train Loss 2.4213333 Test MSE 386.2368337964331 Test RE 1.0018193751304556\n",
      "8 Train Loss 2.3906589 Test MSE 381.01107195781225 Test RE 0.9950190158158614\n",
      "9 Train Loss 2.3695133 Test MSE 380.46171083524865 Test RE 0.9943014225702007\n",
      "10 Train Loss 2.3675263 Test MSE 380.692453200155 Test RE 0.9946028887623315\n",
      "11 Train Loss 2.3666787 Test MSE 380.86105017009226 Test RE 0.9948231038863514\n",
      "12 Train Loss 2.3605516 Test MSE 380.02987654275677 Test RE 0.9937369829092438\n",
      "13 Train Loss 2.3586233 Test MSE 379.62651865354144 Test RE 0.9932094742944817\n",
      "14 Train Loss 2.3537219 Test MSE 378.68897721752734 Test RE 0.9919822804352872\n",
      "15 Train Loss 2.3458512 Test MSE 374.9634851738913 Test RE 0.9870907248809592\n",
      "16 Train Loss 2.2597234 Test MSE 358.01271554314246 Test RE 0.9645212679858696\n",
      "17 Train Loss 2.2394361 Test MSE 357.6790932063044 Test RE 0.9640717576386041\n",
      "18 Train Loss 2.229835 Test MSE 355.973398070317 Test RE 0.9617702844878885\n",
      "19 Train Loss 2.2129958 Test MSE 355.37660832971414 Test RE 0.960963741905162\n",
      "20 Train Loss 2.1945539 Test MSE 351.7219166114397 Test RE 0.9560096983742001\n",
      "21 Train Loss 2.157389 Test MSE 343.2280655293844 Test RE 0.9443956518044014\n",
      "22 Train Loss 2.1320136 Test MSE 337.94067969523513 Test RE 0.9370932705670069\n",
      "23 Train Loss 2.1040545 Test MSE 336.96104738833026 Test RE 0.9357340481503044\n",
      "24 Train Loss 2.0635943 Test MSE 327.56578623684896 Test RE 0.9225965994859143\n",
      "25 Train Loss 2.0309043 Test MSE 319.56580801730786 Test RE 0.9112608984255977\n",
      "26 Train Loss 2.0128589 Test MSE 314.9738239136608 Test RE 0.9046900503264039\n",
      "27 Train Loss 1.9850054 Test MSE 315.9802529847439 Test RE 0.9061342658885372\n",
      "28 Train Loss 1.9402516 Test MSE 306.09208773084157 Test RE 0.8918434648608011\n",
      "29 Train Loss 1.8731792 Test MSE 291.7178097558413 Test RE 0.8706509026632361\n",
      "30 Train Loss 1.7837715 Test MSE 281.6257871868683 Test RE 0.8554581965775676\n",
      "31 Train Loss 1.7312655 Test MSE 270.4700954815404 Test RE 0.8383439020299538\n",
      "32 Train Loss 1.6838864 Test MSE 258.39731928601026 Test RE 0.8194200464914019\n",
      "33 Train Loss 1.662222 Test MSE 259.295551249119 Test RE 0.8208430309642335\n",
      "34 Train Loss 1.646724 Test MSE 258.8460382487829 Test RE 0.8201312183901737\n",
      "35 Train Loss 1.5729415 Test MSE 247.19423303127894 Test RE 0.8014598113077053\n",
      "36 Train Loss 1.5359464 Test MSE 235.89047623311018 Test RE 0.7829207187267504\n",
      "37 Train Loss 1.4992614 Test MSE 222.47677874415632 Test RE 0.7603349017006428\n",
      "38 Train Loss 1.4183226 Test MSE 219.18087023817884 Test RE 0.7546818510450363\n",
      "39 Train Loss 1.3942751 Test MSE 211.86093536894722 Test RE 0.741972869115147\n",
      "40 Train Loss 1.3675351 Test MSE 210.91353198611435 Test RE 0.7403120267557592\n",
      "41 Train Loss 1.3462803 Test MSE 212.42034246015382 Test RE 0.7429517925204977\n",
      "42 Train Loss 1.2995241 Test MSE 203.79976940303288 Test RE 0.7277201940758181\n",
      "43 Train Loss 1.2435235 Test MSE 191.64856618589903 Test RE 0.705692285365561\n",
      "44 Train Loss 1.2282187 Test MSE 183.4702102093172 Test RE 0.6904708712399933\n",
      "45 Train Loss 1.2029591 Test MSE 184.85043050972766 Test RE 0.6930631621027553\n",
      "46 Train Loss 1.1925509 Test MSE 183.6052413255862 Test RE 0.6907249122197919\n",
      "47 Train Loss 1.1785915 Test MSE 175.44702432692281 Test RE 0.6752049008975651\n",
      "48 Train Loss 1.1254697 Test MSE 163.95457824012334 Test RE 0.6527161473341184\n",
      "49 Train Loss 1.0638236 Test MSE 162.85557708639288 Test RE 0.6505248638003998\n",
      "50 Train Loss 1.0386539 Test MSE 160.2207252195345 Test RE 0.6452409606637264\n",
      "51 Train Loss 1.0274415 Test MSE 159.03967646470545 Test RE 0.6428584018731364\n",
      "52 Train Loss 1.0180714 Test MSE 158.6111714725784 Test RE 0.6419917821678138\n",
      "53 Train Loss 1.0008053 Test MSE 156.10499295285015 Test RE 0.6368996049934208\n",
      "54 Train Loss 0.95512897 Test MSE 148.33429859441378 Test RE 0.6208452656846352\n",
      "55 Train Loss 0.9320272 Test MSE 141.84215969490023 Test RE 0.607107013681299\n",
      "56 Train Loss 0.9221895 Test MSE 141.01284016159804 Test RE 0.6053296020574033\n",
      "57 Train Loss 0.8949728 Test MSE 131.84173344237087 Test RE 0.5853141653950568\n",
      "58 Train Loss 0.8534223 Test MSE 124.26364125029582 Test RE 0.5682436879015779\n",
      "59 Train Loss 0.84587204 Test MSE 126.28495459262011 Test RE 0.5728466645768023\n",
      "60 Train Loss 0.80657643 Test MSE 124.57219675283385 Test RE 0.5689487453410884\n",
      "61 Train Loss 0.7428454 Test MSE 112.50550526672077 Test RE 0.5406914097271707\n",
      "62 Train Loss 0.6915705 Test MSE 104.30740667837811 Test RE 0.5206191712699931\n",
      "63 Train Loss 0.65618837 Test MSE 99.41534902978526 Test RE 0.5082639453666145\n",
      "64 Train Loss 0.64806384 Test MSE 95.4304306216684 Test RE 0.4979732617385027\n",
      "65 Train Loss 0.6394 Test MSE 92.26926527642115 Test RE 0.48965603747178027\n",
      "66 Train Loss 0.6004466 Test MSE 85.63635747509444 Test RE 0.47172802240359174\n",
      "67 Train Loss 0.5428904 Test MSE 79.57596260731925 Test RE 0.45472992252376937\n",
      "68 Train Loss 0.5057058 Test MSE 75.35699495762553 Test RE 0.4425113030292967\n",
      "69 Train Loss 0.45177537 Test MSE 64.6672837387561 Test RE 0.40992545956019316\n",
      "70 Train Loss 0.3905787 Test MSE 59.67460505992802 Test RE 0.3937833590224654\n",
      "71 Train Loss 0.36546028 Test MSE 56.60781189896427 Test RE 0.38353125944298266\n",
      "72 Train Loss 0.33719695 Test MSE 49.25112698898303 Test RE 0.35774260811071146\n",
      "73 Train Loss 0.32949582 Test MSE 47.666509957101226 Test RE 0.35194051078182254\n",
      "74 Train Loss 0.31066746 Test MSE 46.234104413805035 Test RE 0.34661216998209365\n",
      "75 Train Loss 0.27821642 Test MSE 41.65672767866074 Test RE 0.32900701512355496\n",
      "76 Train Loss 0.25877655 Test MSE 37.12229940329607 Test RE 0.31058467093866643\n",
      "77 Train Loss 0.24290231 Test MSE 35.36760861884955 Test RE 0.30315548512379703\n",
      "78 Train Loss 0.24023902 Test MSE 35.953271052554285 Test RE 0.3056551988082383\n",
      "79 Train Loss 0.23219141 Test MSE 34.219541618430306 Test RE 0.2981945325997615\n",
      "80 Train Loss 0.2305556 Test MSE 32.80485744806297 Test RE 0.29196558319329885\n",
      "81 Train Loss 0.22790626 Test MSE 32.017232614378365 Test RE 0.28843933005398464\n",
      "82 Train Loss 0.2142842 Test MSE 31.28022112887105 Test RE 0.2851001788843962\n",
      "83 Train Loss 0.19541444 Test MSE 27.310546935888823 Test RE 0.2663960502010078\n",
      "84 Train Loss 0.18115541 Test MSE 25.982529613805642 Test RE 0.2598383788670706\n",
      "85 Train Loss 0.16597024 Test MSE 24.719646096723782 Test RE 0.25344498781107305\n",
      "86 Train Loss 0.15987855 Test MSE 22.917187344892113 Test RE 0.24403001131701058\n",
      "87 Train Loss 0.1587413 Test MSE 22.698356843802593 Test RE 0.24286212583776745\n",
      "88 Train Loss 0.15873836 Test MSE 22.686617367096936 Test RE 0.2427993141764591\n",
      "89 Train Loss 0.1586683 Test MSE 22.690154679230996 Test RE 0.2428182421521574\n",
      "90 Train Loss 0.15866828 Test MSE 22.690154622472505 Test RE 0.2428182418484575\n",
      "91 Train Loss 0.15866828 Test MSE 22.690154622472505 Test RE 0.2428182418484575\n",
      "92 Train Loss 0.15866826 Test MSE 22.690154622472505 Test RE 0.2428182418484575\n",
      "93 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "94 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "95 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "96 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "97 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "98 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "99 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "100 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "101 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "102 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "103 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "104 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "105 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "106 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "107 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "108 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "109 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "110 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "111 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "112 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "113 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "114 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "115 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "116 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "117 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "118 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "119 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "120 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "121 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "122 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "123 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "124 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "125 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "126 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "127 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "128 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "129 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "130 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "131 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "132 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "133 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "134 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "135 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "136 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "137 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "138 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "139 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "140 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "141 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "142 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "143 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "144 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "145 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "146 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "147 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "148 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "149 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "150 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "151 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "152 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "153 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "154 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "155 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "156 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "157 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "158 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "159 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "160 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "161 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "162 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "163 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "164 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "165 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "166 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "167 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "168 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "169 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "170 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "171 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "172 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "173 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "174 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "175 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "176 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "177 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "178 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "179 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "180 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "181 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "182 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "183 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "184 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "185 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "186 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "187 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "188 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "189 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "190 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "191 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "192 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "193 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "194 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "195 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "196 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "197 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "198 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "199 Train Loss 0.15861335 Test MSE 22.69076727144266 Test RE 0.24282151995176096\n",
      "Training time: 111.57\n",
      "Training time: 111.57\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "omega_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val = 5.0\n",
    "rowdy_terms = 2\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(reps)\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    alpha_val = []\n",
    "    omega_val = []\n",
    "\n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "\n",
    "\n",
    "\n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    alpha_full.append(alpha_val)\n",
    "    omega_full.append(omega_val)  \n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"alpha\": alpha_full, \"omega\": omega_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lrnr_tune' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5306/370070687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlrnr_tune\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lrnr_tune' is not defined"
     ]
    }
   ],
   "source": [
    "lrnr_tune[tune_reps,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tune_reps in range(75):\n",
    "    label = \"1D_SODE_rowdy_tune\"+str(tune_reps)+\".mat\" #WRONGLY SAVED AS STAN - DOESN'T MATTER\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
