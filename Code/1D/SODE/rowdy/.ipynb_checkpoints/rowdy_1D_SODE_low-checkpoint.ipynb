{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(-2.0*x) + np.exp(1.0*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 0.005\n",
    "level = \"low\"\n",
    "label = \"1D_SODE_rowdy_\" + level \n",
    "\n",
    "u_coeff = 2.0\n",
    "fo_val = -1.0\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0  #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    omega_val.append(PINN.omega.cpu().detach().numpy())\n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "    \n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,0)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        train_step(x_coll,f_hat)\n",
    "        \n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 3.1287758 Test MSE 14.408584760363743 Test RE 0.9954187743749322\n",
      "1 Train Loss 1.8633659 Test MSE 15.91518117672277 Test RE 1.0461668593797866\n",
      "2 Train Loss 1.6889899 Test MSE 13.553087266817753 Test RE 0.9654155331188394\n",
      "3 Train Loss 1.1630113 Test MSE 9.549570953703885 Test RE 0.8103769781617708\n",
      "4 Train Loss 0.7520516 Test MSE 5.365603300142852 Test RE 0.6074414800152204\n",
      "5 Train Loss 0.4208591 Test MSE 3.30701795128668 Test RE 0.47688475698169974\n",
      "6 Train Loss 0.1520029 Test MSE 0.937849998764254 Test RE 0.2539579752493158\n",
      "7 Train Loss 0.056415882 Test MSE 0.12288022743181719 Test RE 0.09192553540907879\n",
      "8 Train Loss 0.012620017 Test MSE 0.013726520350652893 Test RE 0.030723832866059852\n",
      "9 Train Loss 0.007932788 Test MSE 1.895783561558555e-05 Test RE 0.0011417986925590909\n",
      "10 Train Loss 0.0024003226 Test MSE 0.00029678897947102065 Test RE 0.004517717288873973\n",
      "11 Train Loss 0.0013926062 Test MSE 0.0004201501291446263 Test RE 0.005375234499338197\n",
      "12 Train Loss 0.0011028196 Test MSE 4.658849799780609e-07 Test RE 0.0001789923703609068\n",
      "13 Train Loss 0.00050755474 Test MSE 7.7152853518877e-05 Test RE 0.002303409540927012\n",
      "14 Train Loss 0.00024253836 Test MSE 3.160182977275294e-05 Test RE 0.0014741825953375727\n",
      "15 Train Loss 0.00023632057 Test MSE 2.8985970667211337e-05 Test RE 0.0014118517256412537\n",
      "16 Train Loss 0.00023033257 Test MSE 2.6885620361886136e-05 Test RE 0.0013597378778425605\n",
      "17 Train Loss 0.0002248394 Test MSE 2.4243017491504537e-05 Test RE 0.0012911850895019855\n",
      "18 Train Loss 0.00021998117 Test MSE 2.3105900052615147e-05 Test RE 0.0012605399377455223\n",
      "19 Train Loss 0.00021522593 Test MSE 2.0125343139464445e-05 Test RE 0.0011764319527003608\n",
      "20 Train Loss 0.00021080275 Test MSE 1.8913560760474764e-05 Test RE 0.0011404646129980747\n",
      "21 Train Loss 0.00020580798 Test MSE 1.535978376124975e-05 Test RE 0.0010277505446692637\n",
      "22 Train Loss 0.00020079344 Test MSE 1.4025353203171445e-05 Test RE 0.0009820917624230768\n",
      "23 Train Loss 0.00019489108 Test MSE 1.0088778204044163e-05 Test RE 0.0008329414066820526\n",
      "24 Train Loss 0.00018937772 Test MSE 8.999690140670926e-06 Test RE 0.0007866996252017701\n",
      "25 Train Loss 0.00018275825 Test MSE 3.7711176529460294e-06 Test RE 0.0005092490245026356\n",
      "26 Train Loss 0.00017565218 Test MSE 8.235920720207561e-06 Test RE 0.0007525775234467649\n",
      "27 Train Loss 0.00016977047 Test MSE 5.499698629199637e-06 Test RE 0.0006149851240487359\n",
      "28 Train Loss 0.00016459673 Test MSE 3.944666388682847e-06 Test RE 0.0005208351721738681\n",
      "29 Train Loss 0.00015934875 Test MSE 1.6996140179271412e-06 Test RE 0.0003418773405794157\n",
      "30 Train Loss 0.0001547146 Test MSE 1.567068639119876e-06 Test RE 0.0003282760313946176\n",
      "31 Train Loss 0.00015068651 Test MSE 4.552489697695576e-07 Test RE 0.0001769374038153813\n",
      "32 Train Loss 0.0001474774 Test MSE 4.1545065731635747e-07 Test RE 0.00016902653553637744\n",
      "33 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "34 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "35 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "36 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "37 Train Loss 0.00014470512 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "38 Train Loss 0.00014470512 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "39 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "40 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "41 Train Loss 0.00014470512 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "42 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "43 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "44 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "45 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "46 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "47 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "48 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "49 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "50 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "51 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "52 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "53 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "54 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "55 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "56 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "57 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "58 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "59 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "60 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "61 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "62 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "63 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "64 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "65 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "66 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "67 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "68 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "69 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "70 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "71 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "72 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "73 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "74 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "75 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "76 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "77 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "78 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "79 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "80 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "81 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "82 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "83 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "84 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "85 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "86 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "87 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "88 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "89 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "90 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "91 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "92 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "93 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "94 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "95 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "96 Train Loss 0.00014470512 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "97 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "98 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "99 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "100 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "101 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "102 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "103 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "104 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "105 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "106 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "107 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "108 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "109 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "110 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "111 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "112 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "113 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "114 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "115 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "116 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "117 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "118 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "119 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "120 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "121 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "122 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "123 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "124 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "125 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "126 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "127 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "128 Train Loss 0.00014470512 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "129 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "130 Train Loss 0.00014470512 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "131 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "132 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "133 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "134 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "135 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "136 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "137 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "138 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "139 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "140 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "141 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "142 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "143 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "144 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "145 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "146 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "147 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "148 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "149 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "150 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "151 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "152 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "153 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "154 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "155 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "156 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "157 Train Loss 0.00014470512 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "158 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "159 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "160 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "161 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "162 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "163 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "164 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "165 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "166 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "167 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "168 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "169 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "170 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "171 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "172 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "173 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "174 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "175 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "176 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "177 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "178 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "179 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "180 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "181 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "182 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "183 Train Loss 0.00014470512 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "184 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "185 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "186 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "187 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "188 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "189 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "190 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "191 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "192 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "193 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "194 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "195 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "196 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "197 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "198 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "199 Train Loss 0.00014470513 Test MSE 1.6655450749755095e-07 Test RE 0.00010702207328427269\n",
      "Training time: 28.84\n",
      "Training time: 28.84\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 2.3354275 Test MSE 17.495796863630634 Test RE 1.0968873516809778\n",
      "1 Train Loss 2.0722513 Test MSE 17.2927210216957 Test RE 1.0905029189418\n",
      "2 Train Loss 2.0514295 Test MSE 16.957437614933415 Test RE 1.0798794552876299\n",
      "3 Train Loss 1.7041658 Test MSE 13.492135713590985 Test RE 0.9632422318343414\n",
      "4 Train Loss 1.5198354 Test MSE 12.76880937220559 Test RE 0.937066401361418\n",
      "5 Train Loss 1.4856462 Test MSE 12.377503672542538 Test RE 0.9225962748354749\n",
      "6 Train Loss 1.174401 Test MSE 9.973166372597492 Test RE 0.8281551306911504\n",
      "7 Train Loss 0.7961271 Test MSE 6.232865566426025 Test RE 0.6546950310316688\n",
      "8 Train Loss 0.48859942 Test MSE 2.72660292842219 Test RE 0.4330181629314995\n",
      "9 Train Loss 0.42728066 Test MSE 2.5935012216153517 Test RE 0.422316834029302\n",
      "10 Train Loss 0.24763593 Test MSE 1.6275456720473849 Test RE 0.33455055683478463\n",
      "11 Train Loss 0.057095002 Test MSE 0.2922079061919848 Test RE 0.14175590075889732\n",
      "12 Train Loss 0.031974554 Test MSE 0.03840248819174718 Test RE 0.05138955381002547\n",
      "13 Train Loss 0.014376873 Test MSE 0.009970637864119995 Test RE 0.02618524467029673\n",
      "14 Train Loss 0.008259979 Test MSE 0.002699156278092153 Test RE 0.013624142581228424\n",
      "15 Train Loss 0.0071370536 Test MSE 0.0013226728995332883 Test RE 0.0095372110314486\n",
      "16 Train Loss 0.0029090408 Test MSE 0.00040777336809578123 Test RE 0.005295470999424368\n",
      "17 Train Loss 0.0022821631 Test MSE 0.00024115483214827213 Test RE 0.0040723317383693555\n",
      "18 Train Loss 0.0009880943 Test MSE 0.00035442033042532337 Test RE 0.004936901676260494\n",
      "19 Train Loss 0.00035752676 Test MSE 6.246342308185835e-06 Test RE 0.0006554024417361742\n",
      "20 Train Loss 0.00018914431 Test MSE 1.6256397951359577e-05 Test RE 0.0010573221389305035\n",
      "21 Train Loss 0.00016840245 Test MSE 5.394018605746659e-06 Test RE 0.0006090478085401448\n",
      "22 Train Loss 0.00016287752 Test MSE 2.3865789733017894e-06 Test RE 0.00040511942705385567\n",
      "23 Train Loss 0.00015853738 Test MSE 7.244952257413327e-07 Test RE 0.00022320963060901968\n",
      "24 Train Loss 0.00015556694 Test MSE 1.1213800397190955e-07 Test RE 8.781558029581842e-05\n",
      "25 Train Loss 0.00015272836 Test MSE 8.696578765329156e-08 Test RE 7.73338055659356e-05\n",
      "26 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "27 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "28 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "29 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "30 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "31 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "32 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "33 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "34 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "35 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "36 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "37 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "38 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "39 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "40 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "41 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "42 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "43 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "44 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "45 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "46 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "47 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "48 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "49 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "50 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "51 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "52 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "53 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "54 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "55 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "56 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "57 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "58 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "59 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "60 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "61 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "62 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "63 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "64 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "65 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "66 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "67 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "68 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "69 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "70 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "71 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "72 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "73 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "74 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "75 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "76 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "77 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "78 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "79 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "80 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "81 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "82 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "83 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "84 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "85 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "86 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "87 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "88 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "89 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "90 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "91 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "92 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "93 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "94 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "95 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "96 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "97 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "98 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "99 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "100 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "101 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "102 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "103 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "104 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "105 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "106 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "107 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "108 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "109 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "110 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "111 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "112 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "113 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "114 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "115 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "116 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "117 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "118 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "119 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "120 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "121 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "122 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "123 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "124 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "125 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "126 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "127 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "128 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "129 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "130 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "131 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "132 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "133 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "134 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "135 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "136 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "137 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "138 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "139 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "140 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "141 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "142 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "143 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "144 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "145 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "146 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "147 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "148 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "149 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "150 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "151 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "152 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "153 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "154 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "155 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "156 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "157 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "158 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "159 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "160 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "161 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "162 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "163 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "164 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "165 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "166 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "167 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "168 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "169 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "170 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "171 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "172 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "173 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "174 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "175 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "176 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "177 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "178 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "179 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "180 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "181 Train Loss 0.00015023732 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "182 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "183 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "184 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "185 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "186 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "187 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "188 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "189 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "190 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "191 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "192 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "193 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "194 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "195 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "196 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "197 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "198 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "199 Train Loss 0.0001502373 Test MSE 2.9748573444997374e-07 Test RE 0.00014303036175165144\n",
      "Training time: 32.24\n",
      "Training time: 32.24\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 3.0121193 Test MSE 15.448119944996021 Test RE 1.0307016735233547\n",
      "1 Train Loss 2.0653934 Test MSE 17.29015955305124 Test RE 1.0904221510720102\n",
      "2 Train Loss 1.7961535 Test MSE 13.40572298144915 Test RE 0.9601526506613284\n",
      "3 Train Loss 1.6006382 Test MSE 13.071439565975968 Test RE 0.9481059552222374\n",
      "4 Train Loss 1.4249961 Test MSE 11.596739102689444 Test RE 0.8930239536653938\n",
      "5 Train Loss 0.82232004 Test MSE 6.839041279998736 Test RE 0.6857925727969287\n",
      "6 Train Loss 0.63836306 Test MSE 4.206954883482307 Test RE 0.5378721922953674\n",
      "7 Train Loss 0.1948759 Test MSE 0.9928926790940199 Test RE 0.26130415713648864\n",
      "8 Train Loss 0.07557392 Test MSE 0.33949994745926304 Test RE 0.15279706792578962\n",
      "9 Train Loss 0.05494896 Test MSE 0.24648464582031823 Test RE 0.13019373923320599\n",
      "10 Train Loss 0.032731526 Test MSE 0.031803503577191174 Test RE 0.046766260854006786\n",
      "11 Train Loss 0.007972433 Test MSE 0.0040950022711969385 Test RE 0.016781170049581507\n",
      "12 Train Loss 0.0029608067 Test MSE 7.69010806907738e-05 Test RE 0.002299648112751859\n",
      "13 Train Loss 0.002411005 Test MSE 0.0008463234578061422 Test RE 0.007628925152591822\n",
      "14 Train Loss 0.001298227 Test MSE 3.3492822974209224e-05 Test RE 0.001517647957650348\n",
      "15 Train Loss 0.0012800327 Test MSE 2.0878200855327707e-06 Test RE 0.0003789149149779536\n",
      "16 Train Loss 0.0012744436 Test MSE 8.45116010422664e-07 Test RE 0.00024107564059789937\n",
      "17 Train Loss 0.0012699884 Test MSE 4.959324740757989e-06 Test RE 0.0005839913821918517\n",
      "18 Train Loss 0.0012662954 Test MSE 1.2367405610136609e-05 Test RE 0.000922219852579388\n",
      "19 Train Loss 0.0012631426 Test MSE 2.1402029694273613e-05 Test RE 0.0012131727477897036\n",
      "20 Train Loss 0.0012604096 Test MSE 3.0566849211244156e-05 Test RE 0.0014498414175805276\n",
      "21 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "22 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "23 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "24 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "25 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "26 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "27 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "28 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "29 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "30 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "31 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "32 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "33 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "34 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "35 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "36 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "37 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "38 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "39 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "40 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "41 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "42 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "43 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "44 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "45 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "46 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "47 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "48 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "49 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "50 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "51 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "52 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "53 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "54 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "55 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "56 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "57 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "58 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "59 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "60 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "61 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "62 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "63 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "64 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "65 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "66 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "67 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "68 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "69 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "70 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "71 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "72 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "73 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "74 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "75 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "76 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "77 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "78 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "79 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "80 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "81 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "82 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "83 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "84 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "85 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "86 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "87 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "88 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "89 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "90 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "91 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "92 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "93 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "94 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "95 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "96 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "97 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "98 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "99 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "100 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "101 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "102 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "103 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "104 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "105 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "106 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "107 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "108 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "109 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "110 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "111 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "112 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "113 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "114 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "115 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "116 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "117 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "118 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "119 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "120 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "121 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "122 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "123 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "124 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "125 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "126 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "127 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "128 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "129 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "130 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "131 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "132 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "133 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "134 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "135 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "136 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "137 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "138 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "139 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "140 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "141 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "142 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "143 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "144 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "145 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "146 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "147 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "148 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "149 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "150 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "151 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "152 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "153 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "154 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "155 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "156 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "157 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "158 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "159 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "160 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "161 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "162 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "163 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "164 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "165 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "166 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "167 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "168 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "169 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "170 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "171 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "172 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "173 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "174 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "175 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "176 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "177 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "178 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "179 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "180 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "181 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "182 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "183 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "184 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "185 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "186 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "187 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "188 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "189 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "190 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "191 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "192 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "193 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "194 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "195 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "196 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "197 Train Loss 0.0012580416 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "198 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "199 Train Loss 0.0012580417 Test MSE 3.841931695301189e-05 Test RE 0.0016254364126400056\n",
      "Training time: 28.16\n",
      "Training time: 28.16\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 2.1643162 Test MSE 17.444260543106463 Test RE 1.0952706425673708\n",
      "1 Train Loss 2.0047219 Test MSE 16.156479820675855 Test RE 1.0540677744773885\n",
      "2 Train Loss 1.6922364 Test MSE 14.178359841601052 Test RE 0.9874341930914157\n",
      "3 Train Loss 1.4947138 Test MSE 12.541141349067821 Test RE 0.928674875325191\n",
      "4 Train Loss 1.4175105 Test MSE 11.813263128023744 Test RE 0.9013222736260034\n",
      "5 Train Loss 1.2810228 Test MSE 10.44780739071443 Test RE 0.8476327800557736\n",
      "6 Train Loss 0.97504413 Test MSE 8.12918687189204 Test RE 0.7476850867836526\n",
      "7 Train Loss 0.49497926 Test MSE 3.868578122138087 Test RE 0.5157875446738188\n",
      "8 Train Loss 0.19953369 Test MSE 1.6373604674136408 Test RE 0.3355577819733764\n",
      "9 Train Loss 0.025620032 Test MSE 0.11096997696338634 Test RE 0.08735704054878939\n",
      "10 Train Loss 0.014525197 Test MSE 0.012620338403856046 Test RE 0.02945985907095196\n",
      "11 Train Loss 0.010556114 Test MSE 0.0024640000230133677 Test RE 0.013017138286605091\n",
      "12 Train Loss 0.010060969 Test MSE 1.6349418758536462e-05 Test RE 0.0010603428777108059\n",
      "13 Train Loss 0.008812829 Test MSE 0.0006394861887534511 Test RE 0.006631484355898837\n",
      "14 Train Loss 0.0075056846 Test MSE 0.0011545902516444189 Test RE 0.008910644307654625\n",
      "15 Train Loss 0.0060747825 Test MSE 0.00011097839692515845 Test RE 0.002762576978587453\n",
      "16 Train Loss 0.005737015 Test MSE 0.0003386375496811607 Test RE 0.00482572668712793\n",
      "17 Train Loss 0.005469921 Test MSE 0.0008771156334950692 Test RE 0.0077664685997963796\n",
      "18 Train Loss 0.0052821133 Test MSE 0.00022935336561027804 Test RE 0.003971437420084943\n",
      "19 Train Loss 0.0045723896 Test MSE 4.2658536858056365e-06 Test RE 0.0005416243022512297\n",
      "20 Train Loss 0.0036393513 Test MSE 0.0011156391108495263 Test RE 0.008759050499489383\n",
      "21 Train Loss 0.0026584987 Test MSE 0.0008148439491860325 Test RE 0.007485699467431797\n",
      "22 Train Loss 0.0024425401 Test MSE 0.00018441876499275843 Test RE 0.003561211108974397\n",
      "23 Train Loss 0.0024371713 Test MSE 0.00016174315231047865 Test RE 0.0033350942862344804\n",
      "24 Train Loss 0.0024334618 Test MSE 0.0001545557438344645 Test RE 0.0032601511794284714\n",
      "25 Train Loss 0.0024300418 Test MSE 0.00013794920675111756 Test RE 0.003080028737076569\n",
      "26 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "27 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "28 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "29 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "30 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "31 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "32 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "33 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "34 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "35 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "36 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "37 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "38 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "39 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "40 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "41 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "42 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "43 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "44 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "45 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "46 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "47 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "48 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "49 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "50 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "51 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "52 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "53 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "54 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "55 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "56 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "57 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "58 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "59 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "60 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "61 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "62 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "63 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "64 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "65 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "66 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "67 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "68 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "69 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "70 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "71 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "72 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "73 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "74 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "75 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "76 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "77 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "78 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "79 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "80 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "81 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "82 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "83 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "84 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "85 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "86 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "87 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "88 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "89 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "90 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "91 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "92 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "93 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "94 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "95 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "96 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "97 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "98 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "99 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "100 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "101 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "102 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "103 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "104 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "105 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "106 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "107 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "108 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "109 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "110 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "111 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "112 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "113 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "114 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "115 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "116 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "117 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "118 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "119 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "120 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "121 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "122 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "123 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "124 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "125 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "126 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "127 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "128 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "129 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "130 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "131 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "132 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "133 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "134 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "135 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "136 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "137 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "138 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "139 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "140 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "141 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "142 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "143 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "144 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "145 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "146 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "147 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "148 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "149 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "150 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "151 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "152 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "153 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "154 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "155 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "156 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "157 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "158 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "159 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "160 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "161 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "162 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "163 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "164 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "165 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "166 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "167 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "168 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "169 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "170 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "171 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "172 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "173 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "174 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "175 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "176 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "177 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "178 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "179 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "180 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "181 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "182 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "183 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "184 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "185 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "186 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "187 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "188 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "189 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "190 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "191 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "192 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "193 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "194 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "195 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "196 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "197 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "198 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "199 Train Loss 0.0024274727 Test MSE 0.00013435612731727838 Test RE 0.0030396522655506794\n",
      "Training time: 32.84\n",
      "Training time: 32.84\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 3.2574801 Test MSE 14.620429427577163 Test RE 1.0027097299202734\n",
      "1 Train Loss 2.1130092 Test MSE 17.450440952737825 Test RE 1.0954646496948977\n",
      "2 Train Loss 2.0529792 Test MSE 16.83773315734894 Test RE 1.0760612097887818\n",
      "3 Train Loss 2.0057118 Test MSE 16.13561983299891 Test RE 1.0533870896109316\n",
      "4 Train Loss 1.7313756 Test MSE 14.458942854779787 Test RE 0.9971567545770195\n",
      "5 Train Loss 1.4754031 Test MSE 12.355281247141072 Test RE 0.9217676934787006\n",
      "6 Train Loss 1.3943248 Test MSE 11.612715116179777 Test RE 0.8936388701664056\n",
      "7 Train Loss 1.1311378 Test MSE 8.637581797175692 Test RE 0.7707104566940179\n",
      "8 Train Loss 0.8896022 Test MSE 6.944685937482107 Test RE 0.6910690924560859\n",
      "9 Train Loss 0.44638795 Test MSE 2.9433501163720233 Test RE 0.449900139062625\n",
      "10 Train Loss 0.29175532 Test MSE 1.9832122089913518 Test RE 0.3693003833548657\n",
      "11 Train Loss 0.22686654 Test MSE 1.2712820336444495 Test RE 0.2956760307593903\n",
      "12 Train Loss 0.08731566 Test MSE 0.3297599338333482 Test RE 0.1505892978920326\n",
      "13 Train Loss 0.043981016 Test MSE 0.18761150165563706 Test RE 0.11358602320383274\n",
      "14 Train Loss 0.025766633 Test MSE 0.08190373689390061 Test RE 0.07504936523360026\n",
      "15 Train Loss 0.012730227 Test MSE 0.011698945846214021 Test RE 0.02836406879936582\n",
      "16 Train Loss 0.005129544 Test MSE 0.0025572956924955086 Test RE 0.013261285907270211\n",
      "17 Train Loss 0.0022376508 Test MSE 0.0017610514672673273 Test RE 0.011004775545476906\n",
      "18 Train Loss 0.0010089042 Test MSE 0.0006777535852340844 Test RE 0.0068270184511501145\n",
      "19 Train Loss 0.0005568258 Test MSE 0.0002442570456809297 Test RE 0.004098441257463059\n",
      "20 Train Loss 0.00015101186 Test MSE 3.74851063913648e-05 Test RE 0.001605552601886057\n",
      "21 Train Loss 6.4848704e-05 Test MSE 2.2052349781522768e-05 Test RE 0.001231466496915649\n",
      "22 Train Loss 5.8826226e-05 Test MSE 2.0285664919465885e-05 Test RE 0.001181108482492483\n",
      "23 Train Loss 5.476228e-05 Test MSE 2.1705359923860877e-05 Test RE 0.0012217396278448116\n",
      "24 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "25 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "26 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "27 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "28 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "29 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "30 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "31 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "32 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "33 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "34 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "35 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "36 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "37 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "38 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "39 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "40 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "41 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "42 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "43 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "44 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "45 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "46 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "47 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "48 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "49 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "50 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "51 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "52 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "53 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "54 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "55 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "56 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "57 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "58 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "59 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "60 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "61 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "62 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "63 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "64 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "65 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "66 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "67 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "68 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "69 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "70 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "71 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "72 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "73 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "74 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "75 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "76 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "77 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "78 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "79 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "80 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "81 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "82 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "83 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "84 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "85 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "86 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "87 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "88 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "89 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "90 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "91 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "92 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "93 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "94 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "95 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "96 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "97 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "98 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "99 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "100 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "101 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "102 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "103 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "104 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "105 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "106 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "107 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "108 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "109 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "110 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "111 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "112 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "113 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "114 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "115 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "116 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "117 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "118 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "119 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "120 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "121 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "122 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "123 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "124 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "125 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "126 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "127 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "128 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "129 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "130 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "131 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "132 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "133 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "134 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "135 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "136 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "137 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "138 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "139 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "140 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "141 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "142 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "143 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "144 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "145 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "146 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "147 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "148 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "149 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "150 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "151 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "152 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "153 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "154 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "155 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "156 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "157 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "158 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "159 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "160 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "161 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "162 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "163 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "164 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "165 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "166 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "167 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "168 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "169 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "170 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "171 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "172 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "173 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "174 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "175 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "176 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "177 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "178 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "179 Train Loss 5.2370622e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "180 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "181 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "182 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "183 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "184 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "185 Train Loss 5.2370615e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "186 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "187 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "188 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "189 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "190 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "191 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "192 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "193 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "194 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "195 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "196 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "197 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "198 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "199 Train Loss 5.237062e-05 Test MSE 1.9705503210781e-05 Test RE 0.0011640963557498765\n",
      "Training time: 31.63\n",
      "Training time: 31.63\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 2.1213138 Test MSE 14.943135683764048 Test RE 1.0137153779124037\n",
      "1 Train Loss 1.9300882 Test MSE 14.055538755756345 Test RE 0.9831480299076886\n",
      "2 Train Loss 1.407115 Test MSE 6.67671225529754 Test RE 0.6776048327511176\n",
      "3 Train Loss 0.5791899 Test MSE 2.340155683613472 Test RE 0.40115992379559684\n",
      "4 Train Loss 0.19338548 Test MSE 1.307730858745621 Test RE 0.29988472899676943\n",
      "5 Train Loss 0.13593903 Test MSE 0.46521693967593847 Test RE 0.17886399424028895\n",
      "6 Train Loss 0.12180914 Test MSE 0.349071979628584 Test RE 0.1549361140610109\n",
      "7 Train Loss 0.049586922 Test MSE 0.0829937737806187 Test RE 0.07554712144029244\n",
      "8 Train Loss 0.03267753 Test MSE 0.04737662567648417 Test RE 0.05707911457020131\n",
      "9 Train Loss 0.030824363 Test MSE 0.016568772089277338 Test RE 0.03375517212019012\n",
      "10 Train Loss 0.027267471 Test MSE 0.00270532455888879 Test RE 0.01363970106899709\n",
      "11 Train Loss 0.022838706 Test MSE 0.007145960629324087 Test RE 0.022167946995450754\n",
      "12 Train Loss 0.01407818 Test MSE 0.0007878428639727441 Test RE 0.007360629664737169\n",
      "13 Train Loss 0.010480981 Test MSE 0.0029827552670768946 Test RE 0.01432201009250918\n",
      "14 Train Loss 0.005968735 Test MSE 0.0005654840623426067 Test RE 0.006235989128809316\n",
      "15 Train Loss 0.0033268102 Test MSE 0.0008333446284355664 Test RE 0.0075702022930139185\n",
      "16 Train Loss 0.0018328229 Test MSE 0.0005445876478790024 Test RE 0.006119684858057284\n",
      "17 Train Loss 0.0012680765 Test MSE 0.0015429665730641918 Test RE 0.010300858551064012\n",
      "18 Train Loss 0.0008736632 Test MSE 0.0003263995254315518 Test RE 0.004737725823683735\n",
      "19 Train Loss 0.0006983495 Test MSE 4.129864109105198e-07 Test RE 0.00016852449935499008\n",
      "20 Train Loss 0.00069300237 Test MSE 3.835737978062783e-07 Test RE 0.0001624125671697121\n",
      "21 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "22 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "23 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "24 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "25 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "26 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "27 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "28 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "29 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "30 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "31 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "32 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "33 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "34 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "35 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "36 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "37 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "38 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "39 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "40 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "41 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "42 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "43 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "44 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "45 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "46 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "47 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "48 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "49 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "50 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "51 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "52 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "53 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "54 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "55 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "56 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "57 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "58 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "59 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "60 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "61 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "62 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "63 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "64 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "65 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "66 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "67 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "68 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "69 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "70 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "71 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "72 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "73 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "74 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "75 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "76 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "77 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "78 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "79 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "80 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "81 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "82 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "83 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "84 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "85 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "86 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "87 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "88 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "89 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "90 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "91 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "92 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "93 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "94 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "95 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "96 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "97 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "98 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "99 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "100 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "101 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "102 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "103 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "104 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "105 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "106 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "107 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "108 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "109 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "110 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "111 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "112 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "113 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "114 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "115 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "116 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "117 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "118 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "119 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "120 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "121 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "122 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "123 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "124 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "125 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "126 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "127 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "128 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "129 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "130 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "131 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "132 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "133 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "134 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "135 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "136 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "137 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "138 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "139 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "140 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "141 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "142 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "143 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "144 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "145 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "146 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "147 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "148 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "149 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "150 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "151 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "152 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "153 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "154 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "155 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "156 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "157 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "158 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "159 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "160 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "161 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "162 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "163 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "164 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "165 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "166 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "167 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "168 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "169 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "170 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "171 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "172 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "173 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "174 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "175 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "176 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "177 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "178 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "179 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "180 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "181 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "182 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "183 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "184 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "185 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "186 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "187 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "188 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "189 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "190 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "191 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "192 Train Loss 0.00068999507 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "193 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "194 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "195 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "196 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "197 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "198 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "199 Train Loss 0.0006899951 Test MSE 3.629212917843747e-07 Test RE 0.00015797973784536097\n",
      "Training time: 30.76\n",
      "Training time: 30.76\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 4.482631 Test MSE 13.041459468522556 Test RE 0.947018063345305\n",
      "1 Train Loss 4.2075243 Test MSE 11.898573286771775 Test RE 0.9045708944562036\n",
      "2 Train Loss 4.189694 Test MSE 12.065835350637867 Test RE 0.9109066280056746\n",
      "3 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "4 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "5 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "6 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "7 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "8 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "9 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "10 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "11 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "12 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "13 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "14 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "15 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "16 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "17 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "18 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "19 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "20 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "21 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "22 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "23 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "24 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "25 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "26 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "27 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "28 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "29 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "30 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "31 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "32 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "33 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "34 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "35 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "36 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "37 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "38 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "39 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "40 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "41 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "42 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "43 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "44 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "45 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "46 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "47 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "48 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "49 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "50 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "51 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "52 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "53 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "54 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "55 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "56 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "57 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "58 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "59 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "60 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "61 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "62 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "63 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "64 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "65 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "66 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "67 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "68 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "69 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "70 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "71 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "72 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "73 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "74 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "75 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "76 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "77 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "78 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "79 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "80 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "81 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "82 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "83 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "84 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "85 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "86 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "87 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "88 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "89 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "90 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "91 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "92 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "93 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "94 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "95 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "96 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "97 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "98 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "99 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "100 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "101 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "102 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "103 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "104 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "105 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "106 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "107 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "108 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "109 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "110 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "111 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "112 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "113 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "114 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "115 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "116 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "117 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "118 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "119 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "120 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "121 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "122 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "123 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "124 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "125 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "126 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "127 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "128 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "129 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "130 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "131 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "132 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "133 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "134 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "135 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "136 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "137 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "138 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "139 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "140 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "141 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "142 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "143 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "144 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "145 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "146 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "147 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "148 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "149 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "150 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "151 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "152 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "153 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "154 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "155 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "156 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "157 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "158 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "159 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "160 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "161 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "162 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "163 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "164 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "165 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "166 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "167 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "168 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "169 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "170 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "171 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "172 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "173 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "174 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "175 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "176 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "177 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "178 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "179 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "180 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "181 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "182 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "183 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "184 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "185 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "186 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "187 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "188 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "189 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "190 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "191 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "192 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "193 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "194 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "195 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "196 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "197 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "198 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "199 Train Loss 4.141527 Test MSE 13.738279463176104 Test RE 0.9719889731678929\n",
      "Training time: 118.39\n",
      "Training time: 118.39\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 2.6648867 Test MSE 16.214250586847243 Test RE 1.0559506092820445\n",
      "1 Train Loss 1.9760678 Test MSE 15.855245605875437 Test RE 1.0441951019690123\n",
      "2 Train Loss 1.6686288 Test MSE 13.385670037120178 Test RE 0.9594342599673832\n",
      "3 Train Loss 1.4195045 Test MSE 12.003599061232643 Test RE 0.9085543357491382\n",
      "4 Train Loss 1.3183135 Test MSE 10.386711044989392 Test RE 0.8451507665774152\n",
      "5 Train Loss 1.1499181 Test MSE 9.122224777040232 Test RE 0.7920371446663903\n",
      "6 Train Loss 0.8445839 Test MSE 7.060040073949388 Test RE 0.6967849278611999\n",
      "7 Train Loss 0.5142261 Test MSE 3.6354327049317643 Test RE 0.5000037018778898\n",
      "8 Train Loss 0.28556526 Test MSE 1.589150277762677 Test RE 0.3305808171625982\n",
      "9 Train Loss 0.17832473 Test MSE 0.8013492264532962 Test RE 0.2347502566852157\n",
      "10 Train Loss 0.10294485 Test MSE 0.2147998591628684 Test RE 0.12153802113076137\n",
      "11 Train Loss 0.03106479 Test MSE 0.015793655955276445 Test RE 0.032956152316379175\n",
      "12 Train Loss 0.012834626 Test MSE 0.0014012544393179774 Test RE 0.009816432068685533\n",
      "13 Train Loss 0.0065945885 Test MSE 0.0006262637198731759 Test RE 0.006562567621152137\n",
      "14 Train Loss 0.00551015 Test MSE 0.0019358894376098998 Test RE 0.01153813032131532\n",
      "15 Train Loss 0.005264638 Test MSE 0.0006320120368532334 Test RE 0.006592616902770016\n",
      "16 Train Loss 0.004277861 Test MSE 0.00013860010110045752 Test RE 0.0030872865318070032\n",
      "17 Train Loss 0.0039893724 Test MSE 0.000237846243025007 Test RE 0.004044299527551724\n",
      "18 Train Loss 0.003981713 Test MSE 0.00023133765440640217 Test RE 0.003988580197289742\n",
      "19 Train Loss 0.0039745956 Test MSE 0.00023413068937419622 Test RE 0.004012585844505399\n",
      "20 Train Loss 0.0039669094 Test MSE 0.00023096509001906763 Test RE 0.00398536714121017\n",
      "21 Train Loss 0.00395803 Test MSE 0.00023419763847636852 Test RE 0.004013159498089586\n",
      "22 Train Loss 0.0036062694 Test MSE 0.00023078293999000916 Test RE 0.003983795306428491\n",
      "23 Train Loss 0.003314763 Test MSE 0.00013447106635900986 Test RE 0.003040952169160238\n",
      "24 Train Loss 0.0029560071 Test MSE 8.592329383937156e-05 Test RE 0.0024308078120290535\n",
      "25 Train Loss 0.002808346 Test MSE 3.154750934169459e-05 Test RE 0.0014729150631112957\n",
      "26 Train Loss 0.0027925125 Test MSE 1.9890829011822295e-05 Test RE 0.0011695575768866985\n",
      "27 Train Loss 0.002787655 Test MSE 1.5317557199681105e-05 Test RE 0.0010263368450786465\n",
      "28 Train Loss 0.0027846363 Test MSE 1.3119811149206366e-05 Test RE 0.0009498585944808444\n",
      "29 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "30 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "31 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "32 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "33 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "34 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "35 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "36 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "37 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "38 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "39 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "40 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "41 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "42 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "43 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "44 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "45 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "46 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "47 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "48 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "49 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "50 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "51 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "52 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "53 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "54 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "55 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "56 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "57 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "58 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "59 Train Loss 0.0027820051 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "60 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "61 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "62 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "63 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "64 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "65 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "66 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "67 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "68 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "69 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "70 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "71 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "72 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "73 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "74 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "75 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "76 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "77 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "78 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "79 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "80 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "81 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "82 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "83 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "84 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "85 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "86 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "87 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "88 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "89 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "90 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "91 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "92 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "93 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "94 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "95 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "96 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "97 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "98 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "99 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "100 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "101 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "102 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "103 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "104 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "105 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "106 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "107 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "108 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "109 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "110 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "111 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "112 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "113 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "114 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "115 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "116 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "117 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "118 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "119 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "120 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "121 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "122 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "123 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "124 Train Loss 0.0027820051 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "125 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "126 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "127 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "128 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "129 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "130 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "131 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "132 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "133 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "134 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "135 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "136 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "137 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "138 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "139 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "140 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "141 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "142 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "143 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "144 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "145 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "146 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "147 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "148 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "149 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "150 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "151 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "152 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "153 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "154 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "155 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "156 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "157 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "158 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "159 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "160 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "161 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "162 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "163 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "164 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "165 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "166 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "167 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "168 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "169 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "170 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "171 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "172 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "173 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "174 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "175 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "176 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "177 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "178 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "179 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "180 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "181 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "182 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "183 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "184 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "185 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "186 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "187 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "188 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "189 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "190 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "191 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "192 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "193 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "194 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "195 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "196 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "197 Train Loss 0.0027820054 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "198 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "199 Train Loss 0.0027820056 Test MSE 1.1719695894794945e-05 Test RE 0.000897745705156874\n",
      "Training time: 32.87\n",
      "Training time: 32.87\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 2.0346732 Test MSE 17.006941373667644 Test RE 1.0814545498004957\n",
      "1 Train Loss 1.9735774 Test MSE 16.20812674644549 Test RE 1.0557511833618438\n",
      "2 Train Loss 1.6142237 Test MSE 12.543265047955394 Test RE 0.928753502232358\n",
      "3 Train Loss 1.485335 Test MSE 12.387027202752904 Test RE 0.9229511397690362\n",
      "4 Train Loss 1.2975335 Test MSE 10.708597642098626 Test RE 0.8581465587878445\n",
      "5 Train Loss 0.5117723 Test MSE 3.487455600475651 Test RE 0.48972188040918746\n",
      "6 Train Loss 0.33855772 Test MSE 1.9752117023658184 Test RE 0.3685547304274205\n",
      "7 Train Loss 0.12603188 Test MSE 0.48493043776809 Test RE 0.18261434379052713\n",
      "8 Train Loss 0.07226417 Test MSE 0.05184415010190105 Test RE 0.05970972135265876\n",
      "9 Train Loss 0.03556435 Test MSE 0.02474618187481494 Test RE 0.04125240426012682\n",
      "10 Train Loss 0.019447569 Test MSE 0.0047108365087563135 Test RE 0.01799882609715562\n",
      "11 Train Loss 0.014143085 Test MSE 0.001209938754771516 Test RE 0.00912172255302337\n",
      "12 Train Loss 0.008050797 Test MSE 6.075672412776142e-05 Test RE 0.0020440538811464367\n",
      "13 Train Loss 0.0066999765 Test MSE 0.004094909849952888 Test RE 0.016780980679068275\n",
      "14 Train Loss 0.00513113 Test MSE 2.7884811041282175e-05 Test RE 0.0013847743728804156\n",
      "15 Train Loss 0.004884251 Test MSE 9.39033351206329e-06 Test RE 0.0008035921273316833\n",
      "16 Train Loss 0.004876779 Test MSE 8.27649443660469e-06 Test RE 0.0007544290075364407\n",
      "17 Train Loss 0.004871692 Test MSE 1.2221532895359994e-05 Test RE 0.0009167649593720422\n",
      "18 Train Loss 0.004868209 Test MSE 2.0499471989781312e-05 Test RE 0.0011873164975161003\n",
      "19 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "20 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "21 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "22 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "23 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "24 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "25 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "26 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "27 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "28 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "29 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "30 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "31 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "32 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "33 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "34 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "35 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "36 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "37 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "38 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "39 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "40 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "41 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "42 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "43 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "44 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "45 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "46 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "47 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "48 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "49 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "50 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "51 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "52 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "53 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "54 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "55 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "56 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "57 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "58 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "59 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "60 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "61 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "62 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "63 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "64 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "65 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "66 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "67 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "68 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "69 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "70 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "71 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "72 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "73 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "74 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "75 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "76 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "77 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "78 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "79 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "80 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "81 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "82 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "83 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "84 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "85 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "86 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "87 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "88 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "89 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "90 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "91 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "92 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "93 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "94 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "95 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "96 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "97 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "98 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "99 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "100 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "101 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "102 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "103 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "104 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "105 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "106 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "107 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "108 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "109 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "110 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "111 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "112 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "113 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "114 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "115 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "116 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "117 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "118 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "119 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "120 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "121 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "122 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "123 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "124 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "125 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "126 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "127 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "128 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "129 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "130 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "131 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "132 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "133 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "134 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "135 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "136 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "137 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "138 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "139 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "140 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "141 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "142 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "143 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "144 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "145 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "146 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "147 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "148 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "149 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "150 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "151 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "152 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "153 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "154 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "155 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "156 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "157 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "158 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "159 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "160 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "161 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "162 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "163 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "164 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "165 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "166 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "167 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "168 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "169 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "170 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "171 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "172 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "173 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "174 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "175 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "176 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "177 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "178 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "179 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "180 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "181 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "182 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "183 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "184 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "185 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "186 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "187 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "188 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "189 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "190 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "191 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "192 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "193 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "194 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "195 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "196 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "197 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "198 Train Loss 0.004866004 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "199 Train Loss 0.0048660045 Test MSE 3.0134578933776732e-05 Test RE 0.0014395532307961993\n",
      "Training time: 28.91\n",
      "Training time: 28.91\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 3.163824 Test MSE 15.283490933709206 Test RE 1.0251949226157866\n",
      "1 Train Loss 2.0554705 Test MSE 17.112391275267687 Test RE 1.0848020961608076\n",
      "2 Train Loss 1.5903848 Test MSE 12.72183607266491 Test RE 0.9353411951920988\n",
      "3 Train Loss 1.5173016 Test MSE 12.368039207767813 Test RE 0.9222434755140942\n",
      "4 Train Loss 1.1946535 Test MSE 10.035907307246138 Test RE 0.8307559979830339\n",
      "5 Train Loss 0.8739945 Test MSE 6.616425158541362 Test RE 0.6745386932759351\n",
      "6 Train Loss 0.63470936 Test MSE 4.57710495246316 Test RE 0.5610358329639996\n",
      "7 Train Loss 0.34380347 Test MSE 2.541953519511271 Test RE 0.4180988445346199\n",
      "8 Train Loss 0.09665884 Test MSE 0.5113117028245311 Test RE 0.18751587088702762\n",
      "9 Train Loss 0.040006448 Test MSE 0.24295977161568408 Test RE 0.12925946382947015\n",
      "10 Train Loss 0.014061369 Test MSE 0.026210106634851554 Test RE 0.04245506974993696\n",
      "11 Train Loss 0.009161213 Test MSE 0.01583986104978205 Test RE 0.03300432450808277\n",
      "12 Train Loss 0.003288651 Test MSE 0.003596001851540613 Test RE 0.015725523723929824\n",
      "13 Train Loss 0.0006594956 Test MSE 0.0002504769158802697 Test RE 0.004150295489604363\n",
      "14 Train Loss 0.00042436263 Test MSE 6.163276345573145e-05 Test RE 0.0020587375470157254\n",
      "15 Train Loss 0.00041448107 Test MSE 9.469417681242258e-05 Test RE 0.0025518597464234244\n",
      "16 Train Loss 0.00011386316 Test MSE 0.0004025129599691387 Test RE 0.005261203482222619\n",
      "17 Train Loss 5.9656806e-05 Test MSE 6.842799997838966e-05 Test RE 0.0021692623971164456\n",
      "18 Train Loss 5.4523105e-05 Test MSE 3.686122815955296e-05 Test RE 0.0015921356444632958\n",
      "19 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "20 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "21 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "22 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "23 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "24 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "25 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "26 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "27 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "28 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "29 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "30 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "31 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "32 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "33 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "34 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "35 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "36 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "37 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "38 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "39 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "40 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "41 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "42 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "43 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "44 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "45 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "46 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "47 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "48 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "49 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "50 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "51 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "52 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "53 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "54 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "55 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "56 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "57 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "58 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "59 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "60 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "61 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "62 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "63 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "64 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "65 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "66 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "67 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "68 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "69 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "70 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "71 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "72 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "73 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "74 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "75 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "76 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "77 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "78 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "79 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "80 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "81 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "82 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "83 Train Loss 5.137666e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "84 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "85 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "86 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "87 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "88 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "89 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "90 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "91 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "92 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "93 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "94 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "95 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "96 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "97 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "98 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "99 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "100 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "101 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "102 Train Loss 5.1376654e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "103 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "104 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "105 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "106 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "107 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "108 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "109 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "110 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "111 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "112 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "113 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "114 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "115 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "116 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "117 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "118 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "119 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "120 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "121 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "122 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "123 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "124 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "125 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "126 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "127 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "128 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "129 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "130 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "131 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "132 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "133 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "134 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "135 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "136 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "137 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "138 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "139 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "140 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "141 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "142 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "143 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "144 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "145 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "146 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "147 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "148 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "149 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "150 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "151 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "152 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "153 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "154 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "155 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "156 Train Loss 5.1376654e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "157 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "158 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "159 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "160 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "161 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "162 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "163 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "164 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "165 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "166 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "167 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "168 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "169 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "170 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "171 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "172 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "173 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "174 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "175 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "176 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "177 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "178 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "179 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "180 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "181 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "182 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "183 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "184 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "185 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "186 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "187 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "188 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "189 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "190 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "191 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "192 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "193 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "194 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "195 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "196 Train Loss 5.1376654e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "197 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "198 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "199 Train Loss 5.1376657e-05 Test MSE 1.9628476686294566e-05 Test RE 0.0011618189693022496\n",
      "Training time: 29.39\n",
      "Training time: 29.39\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "\n",
    "N_f = 1000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "alpha_full = []\n",
    "omega_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val = 5.0\n",
    "rowdy_terms = 2\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(reps)\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    alpha_val = []\n",
    "    omega_val = []\n",
    "\n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "\n",
    "\n",
    "\n",
    "    layers = np.array([1,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    alpha_full.append(alpha_val)\n",
    "    omega_full.append(omega_val)  \n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"alpha\": alpha_full, \"omega\": omega_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lrnr_tune' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31068/370070687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlrnr_tune\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lrnr_tune' is not defined"
     ]
    }
   ],
   "source": [
    "lrnr_tune[tune_reps,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tune_reps in range(75):\n",
    "    label = \"1D_SODE_rowdy_tune\"+str(tune_reps)+\".mat\" #WRONGLY SAVED AS STAN - DOESN'T MATTER\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_re_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
