{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "#     y = xt[:,0]*np.cos(xt[:,1])\n",
    "#     return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 25000\n",
    "level = \"_low\"\n",
    "label = \"Burgers_tanh\" + level\n",
    "\n",
    "x = np.linspace(-1,1,256).reshape(-1,1)\n",
    "t = np.linspace(0,1,100).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "# bound_pts_1 = (X == 0).reshape(-1,)\n",
    "# bound_pts_2 = np.logical_and(Y == 0,X != 0).reshape(-1,)\n",
    "# bound_pts_3 = np.logical_and(X == 1,Y != 0).reshape(-1,) \n",
    "# bound_pts_4 = np.logical_and(Y == 1,X != 1).reshape(-1,) \n",
    "\n",
    "# xy_bound_1 = xy[bound_pts_1,:]\n",
    "# xy_bound_2 = xy[bound_pts_2,:]\n",
    "# xy_bound_3 = xy[bound_pts_3,:]\n",
    "# xy_bound_4 = xy[bound_pts_4,:]\n",
    "\n",
    "# u_bound_1 = 1000*np.ones((np.shape(xy_bound_1)[0],1))\n",
    "# u_bound_2 = 800*np.ones((np.shape(xy_bound_2)[0],1))\n",
    "# u_bound_3 = 500*np.ones((np.shape(xy_bound_3)[0],1))\n",
    "# u_bound_4 = np.zeros((np.shape(xy_bound_4)[0],1))\n",
    "\n",
    "# xy_bound = np.vstack((xy_bound_1,xy_bound_2,xy_bound_3,xy_bound_4))\n",
    "# u_bound = np.vstack((u_bound_1,u_bound_2,u_bound_3,u_bound_4))\n",
    "\n",
    "# xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('burgers_shock.mat') \n",
    "\n",
    "pi = torch.from_numpy(np.array(np.pi)).double().to(device)\n",
    "\n",
    "x = np.array(data['x'])\n",
    "t = np.array(data['t'])\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "u_true = np.array(data['usol'][:])\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "u_true_norm = np.linalg.norm(u_true,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_T,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    x_l = x[0]*np.ones((N_T,1))\n",
    "    t_l = np.random.uniform(t[0],t[-1],(N_T,1))\n",
    "    xt_l = np.hstack((x_l,t_l))\n",
    "    u_l = 0.0*np.ones((N_T,1))\n",
    "    \n",
    "    x_r = x[-1]*np.ones((N_T,1))\n",
    "    t_r = np.random.uniform(t[0],t[-1],(N_T,1))\n",
    "    xt_r = np.hstack((x_r,t_r))\n",
    "    u_r = 0.0*np.ones((N_T,1))\n",
    "    \n",
    "    x_0 = np.random.uniform(x[0],x[-1],(N_T,1))\n",
    "    t_0 = t[0]*np.ones((N_T,1))\n",
    "    xt_0 = np.hstack((x_0,t_0))\n",
    "    u_0 = -1.0*np.sin(np.pi*x_0)\n",
    "    \n",
    "    xt_BC = np.vstack((xt_l,xt_r,xt_0)) #choose indices from  set 'idx' (x,t)\n",
    "    u_BC = np.vstack((u_l,u_r,u_0))\n",
    "    \n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, u_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "        \n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xy):\n",
    "        if torch.is_tensor(xy) != True:         \n",
    "            xy = torch.from_numpy(xy)                \n",
    "        \n",
    "        ubxy = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxy = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xy = 2.0*(xy - lbxy)/(ubxy - lbxy) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xy.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a =self.activation(z)\n",
    "       \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xy,u):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xy), u)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xy_coll, f_hat):\n",
    "        \n",
    "        g = xy_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy = autograd.grad(u_x_y,g,torch.ones(xy_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        du_dx = u_x_y[:,[0]]\n",
    "        du_dt = u_x_y[:,[1]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy[:,[0]]\n",
    "        \n",
    "\n",
    "        f = du_dt + u*du_dx - 0.01*d2u_dx2/pi\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xy_BC,u_BC,xy_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xy_BC,u_BC)\n",
    "        loss_f = self.loss_PDE(xy_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        u_pred = self.forward(xt_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "        \n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xy_BC,u_BC,xy_coll,f_hat,seed):\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xy_BC,u_BC,xy_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xy_coll_np_array, xy_BC_np_array, u_BC_np_array = trainingdata(N_T,N_f,rep*22)\n",
    "        \n",
    "    xy_coll = torch.from_numpy(xy_coll_np_array).float().to(device)\n",
    "    xy_BC = torch.from_numpy(xy_BC_np_array).float().to(device)\n",
    "    u_BC = torch.from_numpy(u_BC_np_array).float().to(device)\n",
    "        \n",
    "    f_hat = torch.zeros(xy_coll.shape[0],1).to(device)\n",
    "    \n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(xy_BC,u_BC,xy_coll,f_hat,i)\n",
    "        loss_np = PINN.loss(xy_BC,u_BC,xy_coll,f_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burgers_tanh_low\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 0.07618364 Test MSE 0.14674618387935842 Test RE 0.6399815770305505\n",
      "1 Train Loss 0.068442374 Test MSE 0.14084095953028677 Test RE 0.626972585609493\n",
      "2 Train Loss 0.060778275 Test MSE 0.1328778211874802 Test RE 0.6089902131033582\n",
      "3 Train Loss 0.053375307 Test MSE 0.11299040167200929 Test RE 0.5615712172449252\n",
      "4 Train Loss 0.05030275 Test MSE 0.10883516841914555 Test RE 0.5511485776153139\n",
      "5 Train Loss 0.04728037 Test MSE 0.1030112206593019 Test RE 0.536199408864169\n",
      "6 Train Loss 0.04438443 Test MSE 0.09564936117459276 Test RE 0.5166841046032645\n",
      "7 Train Loss 0.040863033 Test MSE 0.09180516021357996 Test RE 0.5061947196680249\n",
      "8 Train Loss 0.039058276 Test MSE 0.08954626943549022 Test RE 0.4999284045616858\n",
      "9 Train Loss 0.036711883 Test MSE 0.08520123471355166 Test RE 0.4876486298994427\n",
      "10 Train Loss 0.03524103 Test MSE 0.08330102009674686 Test RE 0.4821800348310715\n",
      "11 Train Loss 0.03300401 Test MSE 0.07982413649355967 Test RE 0.47200997720271376\n",
      "12 Train Loss 0.031298794 Test MSE 0.07643009859528674 Test RE 0.46186629877614155\n",
      "13 Train Loss 0.029848848 Test MSE 0.07370456371213152 Test RE 0.4535563524518846\n",
      "14 Train Loss 0.028438311 Test MSE 0.06873100033222637 Test RE 0.4379861692195194\n",
      "15 Train Loss 0.027007805 Test MSE 0.06342077937309785 Test RE 0.42072648450327127\n",
      "16 Train Loss 0.025816048 Test MSE 0.059874887970772936 Test RE 0.4087957960975756\n",
      "17 Train Loss 0.02443772 Test MSE 0.05588275906594444 Test RE 0.39493259982340023\n",
      "18 Train Loss 0.02278107 Test MSE 0.05210170019470324 Test RE 0.3813379362332275\n",
      "19 Train Loss 0.02155321 Test MSE 0.049900793993363245 Test RE 0.37319669763005503\n",
      "20 Train Loss 0.020277984 Test MSE 0.047568195133924886 Test RE 0.3643698223056085\n",
      "21 Train Loss 0.019216534 Test MSE 0.04636878018411077 Test RE 0.3597467670018938\n",
      "22 Train Loss 0.017696016 Test MSE 0.04562749887357907 Test RE 0.35685960927180277\n",
      "23 Train Loss 0.016573725 Test MSE 0.0407650306996277 Test RE 0.33730901699710475\n",
      "24 Train Loss 0.014959674 Test MSE 0.03475140435406885 Test RE 0.31143702632511844\n",
      "25 Train Loss 0.013929007 Test MSE 0.03297805788276605 Test RE 0.3033867447132445\n",
      "26 Train Loss 0.013172511 Test MSE 0.03126870754556948 Test RE 0.29541941200545396\n",
      "27 Train Loss 0.012488101 Test MSE 0.029377170269013077 Test RE 0.2863446309179982\n",
      "28 Train Loss 0.011368336 Test MSE 0.02824592206082472 Test RE 0.2807772669308694\n",
      "29 Train Loss 0.010540726 Test MSE 0.028889941953518027 Test RE 0.28396015119002027\n",
      "30 Train Loss 0.01001821 Test MSE 0.028811516196919525 Test RE 0.28357446464391595\n",
      "31 Train Loss 0.009210283 Test MSE 0.02807969729865557 Test RE 0.2799498731134905\n",
      "32 Train Loss 0.008723739 Test MSE 0.028236017712883078 Test RE 0.28072803576110106\n",
      "33 Train Loss 0.008234376 Test MSE 0.027752469258252224 Test RE 0.27831388854734324\n",
      "34 Train Loss 0.007895011 Test MSE 0.02779690784618307 Test RE 0.27853662420815944\n",
      "35 Train Loss 0.0076219654 Test MSE 0.02774025991063129 Test RE 0.2782526614760906\n",
      "36 Train Loss 0.007301233 Test MSE 0.02764651472756485 Test RE 0.27778210132610565\n",
      "37 Train Loss 0.0069017895 Test MSE 0.027526195104903794 Test RE 0.27717697837081073\n",
      "38 Train Loss 0.006476056 Test MSE 0.027121081573132918 Test RE 0.2751297582671307\n",
      "39 Train Loss 0.0060756835 Test MSE 0.026434302710336723 Test RE 0.2716239081549437\n",
      "40 Train Loss 0.0056144176 Test MSE 0.026358106539132255 Test RE 0.27123215131549816\n",
      "41 Train Loss 0.005237698 Test MSE 0.02587582324372259 Test RE 0.26873928170271955\n",
      "42 Train Loss 0.005030796 Test MSE 0.025695345257927743 Test RE 0.2678004440894881\n",
      "43 Train Loss 0.004802757 Test MSE 0.025662579007859464 Test RE 0.26762964242504284\n",
      "44 Train Loss 0.0045812083 Test MSE 0.025869239934721736 Test RE 0.268705093297214\n",
      "45 Train Loss 0.004397155 Test MSE 0.025931558947353505 Test RE 0.2690285539658227\n",
      "46 Train Loss 0.0041981894 Test MSE 0.025663839481133 Test RE 0.2676362149497525\n",
      "47 Train Loss 0.0039471076 Test MSE 0.025907995933820045 Test RE 0.2689062982203217\n",
      "48 Train Loss 0.0037608398 Test MSE 0.02610735504617421 Test RE 0.2699389174025811\n",
      "49 Train Loss 0.0035696256 Test MSE 0.02601704912526643 Test RE 0.26947165062590694\n",
      "50 Train Loss 0.0033671577 Test MSE 0.025991402947864218 Test RE 0.26933880270637145\n",
      "51 Train Loss 0.0032043355 Test MSE 0.025802675504410445 Test RE 0.26835916658801934\n",
      "52 Train Loss 0.0030669156 Test MSE 0.025711877781524888 Test RE 0.26788658236063784\n",
      "53 Train Loss 0.002974317 Test MSE 0.025849952980108535 Test RE 0.26860490733749864\n",
      "54 Train Loss 0.0028575135 Test MSE 0.025804128065991253 Test RE 0.2683667201211649\n",
      "55 Train Loss 0.0027622497 Test MSE 0.02616145487097752 Test RE 0.2702184572199792\n",
      "56 Train Loss 0.0026617642 Test MSE 0.026324835199967422 Test RE 0.27106091165396595\n",
      "57 Train Loss 0.0025571065 Test MSE 0.02631267273628886 Test RE 0.27099828734227355\n",
      "58 Train Loss 0.0024956814 Test MSE 0.02654511789147082 Test RE 0.27219264971150475\n",
      "59 Train Loss 0.0024029915 Test MSE 0.026039843671557393 Test RE 0.269589672065553\n",
      "60 Train Loss 0.0022904268 Test MSE 0.026474787730804014 Test RE 0.2718318291349145\n",
      "61 Train Loss 0.00222392 Test MSE 0.026100132077690737 Test RE 0.2699015736125792\n",
      "62 Train Loss 0.0021545487 Test MSE 0.02561358390511559 Test RE 0.2673740405536289\n",
      "63 Train Loss 0.002081621 Test MSE 0.025313312268530053 Test RE 0.2658021885228768\n",
      "64 Train Loss 0.0019983882 Test MSE 0.02554860421400619 Test RE 0.26703467149695126\n",
      "65 Train Loss 0.001934889 Test MSE 0.025276303738858842 Test RE 0.2656078135995779\n",
      "66 Train Loss 0.0018800297 Test MSE 0.02543136761125815 Test RE 0.2664212870173369\n",
      "67 Train Loss 0.0018333822 Test MSE 0.025435981136928264 Test RE 0.2664454517757107\n",
      "68 Train Loss 0.0017889207 Test MSE 0.025467880835032358 Test RE 0.2666124763195169\n",
      "69 Train Loss 0.0017503236 Test MSE 0.02488539175245343 Test RE 0.26354592476527544\n",
      "70 Train Loss 0.0017143451 Test MSE 0.02402209006181383 Test RE 0.25893422608580713\n",
      "71 Train Loss 0.0016725333 Test MSE 0.02338975058194946 Test RE 0.25550350340962147\n",
      "72 Train Loss 0.0016109851 Test MSE 0.023028091898085735 Test RE 0.25352047569388675\n",
      "73 Train Loss 0.0015340132 Test MSE 0.022967247519273162 Test RE 0.2531853307214823\n",
      "74 Train Loss 0.0014531936 Test MSE 0.021704198464373527 Test RE 0.24612511955435815\n",
      "75 Train Loss 0.0013207849 Test MSE 0.01812759728361959 Test RE 0.2249335234956651\n",
      "76 Train Loss 0.0012805909 Test MSE 0.017760407786402196 Test RE 0.22264376150893153\n",
      "77 Train Loss 0.0012403608 Test MSE 0.017340420321702684 Test RE 0.21999553892023566\n",
      "78 Train Loss 0.001183761 Test MSE 0.0178251005854972 Test RE 0.22304888609548132\n",
      "79 Train Loss 0.0011580756 Test MSE 0.017691611943082802 Test RE 0.22221213214895782\n",
      "80 Train Loss 0.0011281939 Test MSE 0.016710955157776833 Test RE 0.21596566007050502\n",
      "81 Train Loss 0.0011072047 Test MSE 0.016764463290686767 Test RE 0.21631114252380293\n",
      "82 Train Loss 0.0010831784 Test MSE 0.01628203937190227 Test RE 0.21317607632068086\n",
      "83 Train Loss 0.001033467 Test MSE 0.011944628315267415 Test RE 0.18258722333942232\n",
      "84 Train Loss 0.0009652396 Test MSE 0.008933684562442729 Test RE 0.15790626861250737\n",
      "85 Train Loss 0.00088622485 Test MSE 0.005503689871499871 Test RE 0.12393987134495173\n",
      "86 Train Loss 0.00083055045 Test MSE 0.0031367780946580407 Test RE 0.09356770176254166\n",
      "87 Train Loss 0.00079565076 Test MSE 0.0027504479169251045 Test RE 0.08761647505188683\n",
      "88 Train Loss 0.000747398 Test MSE 0.0011023435266724738 Test RE 0.05546800450735622\n",
      "89 Train Loss 0.0007163222 Test MSE 0.0012452501487155013 Test RE 0.05895387621930307\n",
      "90 Train Loss 0.0006998539 Test MSE 0.001182333691303508 Test RE 0.057445246417661966\n",
      "91 Train Loss 0.0006829607 Test MSE 0.0012449137517800191 Test RE 0.058945912661593755\n",
      "92 Train Loss 0.0006657115 Test MSE 0.001292517396411838 Test RE 0.060062342015216943\n",
      "93 Train Loss 0.00064824056 Test MSE 0.0012633253759524207 Test RE 0.05938020245571814\n",
      "94 Train Loss 0.00062622747 Test MSE 0.001193350492132157 Test RE 0.05771225878577258\n",
      "95 Train Loss 0.00060711603 Test MSE 0.0012055918664770752 Test RE 0.058007509360981716\n",
      "96 Train Loss 0.0005819523 Test MSE 0.0011835884991518533 Test RE 0.057475721583605685\n",
      "97 Train Loss 0.0005669005 Test MSE 0.0012971366384572835 Test RE 0.06016957270123665\n",
      "98 Train Loss 0.0005491309 Test MSE 0.0011605240615580647 Test RE 0.0569129554423826\n",
      "99 Train Loss 0.00052676856 Test MSE 0.0012041419580155787 Test RE 0.05797261741966121\n",
      "100 Train Loss 0.00051254925 Test MSE 0.0011504897051274046 Test RE 0.05666637515920088\n",
      "101 Train Loss 0.0005005287 Test MSE 0.001164256037984935 Test RE 0.057004391429622006\n",
      "102 Train Loss 0.00048660097 Test MSE 0.0011676365091124793 Test RE 0.057087088884574\n",
      "103 Train Loss 0.00046656403 Test MSE 0.0012019409586673604 Test RE 0.05791961035797692\n",
      "104 Train Loss 0.00045180996 Test MSE 0.001199193501561502 Test RE 0.05785337470565058\n",
      "105 Train Loss 0.00044076552 Test MSE 0.0013153294534845109 Test RE 0.0605900535999043\n",
      "106 Train Loss 0.00043383302 Test MSE 0.0012865208226873523 Test RE 0.05992285183088068\n",
      "107 Train Loss 0.00042378716 Test MSE 0.0012678609522629428 Test RE 0.05948670001650855\n",
      "108 Train Loss 0.00041328065 Test MSE 0.0013146006984330288 Test RE 0.06057326638920082\n",
      "109 Train Loss 0.00040596997 Test MSE 0.001312746346781383 Test RE 0.06053052954322845\n",
      "110 Train Loss 0.0003958682 Test MSE 0.001285554205215717 Test RE 0.05990033631519743\n",
      "111 Train Loss 0.000388349 Test MSE 0.001303866214924013 Test RE 0.060325451391349524\n",
      "112 Train Loss 0.0003798221 Test MSE 0.00134570078506401 Test RE 0.061285582318264184\n",
      "113 Train Loss 0.00036847085 Test MSE 0.0011958846807096294 Test RE 0.05777350490939751\n",
      "114 Train Loss 0.00036171643 Test MSE 0.0013160515652501578 Test RE 0.060606683193000235\n",
      "115 Train Loss 0.00035594316 Test MSE 0.0012765962549335635 Test RE 0.059691273852129016\n",
      "116 Train Loss 0.0003494874 Test MSE 0.0012745421166645249 Test RE 0.05964323066971781\n",
      "117 Train Loss 0.00034300645 Test MSE 0.001229911338151984 Test RE 0.05858965850414127\n",
      "118 Train Loss 0.00033931457 Test MSE 0.0011922361929459504 Test RE 0.057685307884669454\n",
      "119 Train Loss 0.00033480884 Test MSE 0.0012051929528165573 Test RE 0.05799791162602995\n",
      "120 Train Loss 0.00032879272 Test MSE 0.0011191172973640247 Test RE 0.05588842466790258\n",
      "121 Train Loss 0.00032288092 Test MSE 0.001291987457441094 Test RE 0.06005002781386906\n",
      "122 Train Loss 0.00031602848 Test MSE 0.0012701522745037117 Test RE 0.059540428964921004\n",
      "123 Train Loss 0.00030979345 Test MSE 0.0012105012635475693 Test RE 0.058125498114832724\n",
      "124 Train Loss 0.0003015746 Test MSE 0.0012464720984770917 Test RE 0.058982794509756\n",
      "125 Train Loss 0.0002935094 Test MSE 0.0012989861483904371 Test RE 0.06021245352772565\n",
      "126 Train Loss 0.0002883072 Test MSE 0.001292975038512629 Test RE 0.06007297422171459\n",
      "127 Train Loss 0.00028212252 Test MSE 0.0011955430914494785 Test RE 0.05776525318639807\n",
      "128 Train Loss 0.00027604587 Test MSE 0.0011633054375969672 Test RE 0.056981114993685966\n",
      "129 Train Loss 0.00027156773 Test MSE 0.0011634949411276402 Test RE 0.05698575594283131\n",
      "130 Train Loss 0.00026610217 Test MSE 0.0011690647496051978 Test RE 0.05712199237279578\n",
      "131 Train Loss 0.00026173878 Test MSE 0.0011089860947365922 Test RE 0.05563487472315018\n",
      "132 Train Loss 0.00025735187 Test MSE 0.0010545369084749147 Test RE 0.05425190047496498\n",
      "133 Train Loss 0.00025269727 Test MSE 0.0009954933265875902 Test RE 0.05271124094361229\n",
      "134 Train Loss 0.00024863842 Test MSE 0.0010072756809319861 Test RE 0.053022260425621984\n",
      "135 Train Loss 0.00024585024 Test MSE 0.0009758771352875876 Test RE 0.05218931966025478\n",
      "136 Train Loss 0.00024290505 Test MSE 0.0009281855135274828 Test RE 0.05089808669196196\n",
      "137 Train Loss 0.00024003093 Test MSE 0.0010020671605458884 Test RE 0.05288499638551622\n",
      "138 Train Loss 0.00023702864 Test MSE 0.0009892765765637938 Test RE 0.05254639513063025\n",
      "139 Train Loss 0.00023368199 Test MSE 0.0010369851440419895 Test RE 0.05379852038229572\n",
      "140 Train Loss 0.00022999235 Test MSE 0.001011437347230379 Test RE 0.05313168106738121\n",
      "141 Train Loss 0.00022628183 Test MSE 0.0009625397812875043 Test RE 0.0518314559015307\n",
      "142 Train Loss 0.0002230757 Test MSE 0.0008855929050450656 Test RE 0.04971656654452501\n",
      "143 Train Loss 0.0002198113 Test MSE 0.0008644585793660414 Test RE 0.04911975121894977\n",
      "144 Train Loss 0.00021448481 Test MSE 0.000795086343883403 Test RE 0.04710762522043896\n",
      "145 Train Loss 0.00021099456 Test MSE 0.0007685021597288054 Test RE 0.0463133941676729\n",
      "146 Train Loss 0.0002076648 Test MSE 0.0007162219904675959 Test RE 0.044710331479925744\n",
      "147 Train Loss 0.00020430994 Test MSE 0.0006681350150321949 Test RE 0.043183335097835084\n",
      "148 Train Loss 0.00020078174 Test MSE 0.0006726332067841214 Test RE 0.04332845627354786\n",
      "149 Train Loss 0.00019852188 Test MSE 0.0006553169419436778 Test RE 0.04276709605689077\n",
      "150 Train Loss 0.00019620641 Test MSE 0.0006663637947152219 Test RE 0.043126057782776915\n",
      "151 Train Loss 0.00019381393 Test MSE 0.000655412349995164 Test RE 0.042770209189283516\n",
      "152 Train Loss 0.00019106553 Test MSE 0.0006434962688039918 Test RE 0.04237962218463995\n",
      "153 Train Loss 0.00018812 Test MSE 0.0006474915695238903 Test RE 0.042510980625262984\n",
      "154 Train Loss 0.00018507148 Test MSE 0.0006668350074153164 Test RE 0.043141303175021316\n",
      "155 Train Loss 0.00018271705 Test MSE 0.0006634615055902553 Test RE 0.04303203941576578\n",
      "156 Train Loss 0.00018076994 Test MSE 0.0006599507044709836 Test RE 0.04291803331088765\n",
      "157 Train Loss 0.00017810358 Test MSE 0.0006036930336810928 Test RE 0.04104801367023214\n",
      "158 Train Loss 0.00017526194 Test MSE 0.0005991227817495707 Test RE 0.04089234169858185\n",
      "159 Train Loss 0.00017230946 Test MSE 0.0005903952985779228 Test RE 0.040593407580493984\n",
      "160 Train Loss 0.00016936508 Test MSE 0.0005654687589555639 Test RE 0.03972723799407846\n",
      "161 Train Loss 0.00016694571 Test MSE 0.0005642646516524193 Test RE 0.039684917928493386\n",
      "162 Train Loss 0.00016422311 Test MSE 0.0005825732422145671 Test RE 0.040323603049187896\n",
      "163 Train Loss 0.00016138678 Test MSE 0.0005878798643893276 Test RE 0.040506839276036356\n",
      "164 Train Loss 0.00015893466 Test MSE 0.0005888234666668423 Test RE 0.04053933487828029\n",
      "165 Train Loss 0.00015696252 Test MSE 0.0005948841320774325 Test RE 0.04074743320126763\n",
      "166 Train Loss 0.00015517767 Test MSE 0.0005962353598859768 Test RE 0.040793684086006636\n",
      "167 Train Loss 0.00015318449 Test MSE 0.0005707184264212574 Test RE 0.03991122073147274\n",
      "168 Train Loss 0.00015138922 Test MSE 0.0005484503948631077 Test RE 0.039124854984916316\n",
      "169 Train Loss 0.00014970182 Test MSE 0.0005195401643183064 Test RE 0.038079709604820676\n",
      "170 Train Loss 0.00014734938 Test MSE 0.0005276139753286708 Test RE 0.038374454007194296\n",
      "171 Train Loss 0.00014566488 Test MSE 0.0005210851259446333 Test RE 0.038136286576089584\n",
      "172 Train Loss 0.00014404455 Test MSE 0.0005088536088247339 Test RE 0.03768603902966623\n",
      "173 Train Loss 0.00014209069 Test MSE 0.0005058701204680584 Test RE 0.03757539704061066\n",
      "174 Train Loss 0.00014086776 Test MSE 0.0005030931493574267 Test RE 0.0374721201483453\n",
      "175 Train Loss 0.00013910292 Test MSE 0.0005004126015390114 Test RE 0.03737215857575326\n",
      "176 Train Loss 0.00013758753 Test MSE 0.00046995374783907794 Test RE 0.03621692909206719\n",
      "177 Train Loss 0.00013584245 Test MSE 0.00046625413291834775 Test RE 0.03607409223352664\n",
      "178 Train Loss 0.00013345922 Test MSE 0.00046920524171974 Test RE 0.0361880758316156\n",
      "179 Train Loss 0.00013219634 Test MSE 0.0004836364651386978 Test RE 0.03674037487506484\n",
      "180 Train Loss 0.00013044036 Test MSE 0.0004737806795431212 Test RE 0.036364091122607106\n",
      "181 Train Loss 0.00012940327 Test MSE 0.0004933727947708567 Test RE 0.03710835163124219\n",
      "182 Train Loss 0.00012821252 Test MSE 0.0004966778964953309 Test RE 0.03723243848878816\n",
      "183 Train Loss 0.00012699021 Test MSE 0.00047692679493603873 Test RE 0.03648462825469652\n",
      "184 Train Loss 0.00012559808 Test MSE 0.0004853061260438951 Test RE 0.03680373973550362\n",
      "185 Train Loss 0.00012433788 Test MSE 0.0005084976980441881 Test RE 0.037672857228931315\n",
      "186 Train Loss 0.00012395403 Test MSE 0.0004987836397783933 Test RE 0.037311281370841845\n",
      "187 Train Loss 0.00012278657 Test MSE 0.0004841875452562274 Test RE 0.03676130084659654\n",
      "188 Train Loss 0.00012116667 Test MSE 0.00044428661227427 Test RE 0.035214025753412745\n",
      "189 Train Loss 0.00011951322 Test MSE 0.0004149260687450957 Test RE 0.034030585775495226\n",
      "190 Train Loss 0.00011804495 Test MSE 0.0004059681283630545 Test RE 0.033661234072315034\n",
      "191 Train Loss 0.00011679462 Test MSE 0.00041838121626898493 Test RE 0.03417198076024485\n",
      "192 Train Loss 0.00011517155 Test MSE 0.0003849522066501525 Test RE 0.03277837887823941\n",
      "193 Train Loss 0.000113520546 Test MSE 0.00036722842960810597 Test RE 0.032014904586864255\n",
      "194 Train Loss 0.00011244134 Test MSE 0.00033598897659728824 Test RE 0.030622918503659398\n",
      "195 Train Loss 0.00011090799 Test MSE 0.0003326371266242755 Test RE 0.030469787426162326\n",
      "196 Train Loss 0.00010955709 Test MSE 0.00031402143142576306 Test RE 0.029604907507259356\n",
      "197 Train Loss 0.0001075132 Test MSE 0.0003233076966888728 Test RE 0.030039457546770006\n",
      "198 Train Loss 0.00010617817 Test MSE 0.000322723232070426 Test RE 0.030012293111481476\n",
      "199 Train Loss 0.00010484677 Test MSE 0.00031006028487334873 Test RE 0.029417592991374374\n",
      "200 Train Loss 0.00010367078 Test MSE 0.0002958693934100751 Test RE 0.02873651410898021\n",
      "201 Train Loss 0.000102283586 Test MSE 0.0002895652922552032 Test RE 0.028428720704295526\n",
      "202 Train Loss 0.0001012937 Test MSE 0.00028310543200853606 Test RE 0.02810982651502596\n",
      "203 Train Loss 9.998845e-05 Test MSE 0.0002937745115716934 Test RE 0.028634599984874345\n",
      "204 Train Loss 9.884857e-05 Test MSE 0.00030897489621009594 Test RE 0.029366058635939156\n",
      "205 Train Loss 9.7466975e-05 Test MSE 0.0003163506393986722 Test RE 0.029714499694313286\n",
      "206 Train Loss 9.655179e-05 Test MSE 0.0003169016764953624 Test RE 0.029740367616819616\n",
      "207 Train Loss 9.538552e-05 Test MSE 0.0003037980977987206 Test RE 0.02911900890457703\n",
      "208 Train Loss 9.440645e-05 Test MSE 0.00030212830551556427 Test RE 0.029038873951025716\n",
      "209 Train Loss 9.305044e-05 Test MSE 0.00029795229155334 Test RE 0.028837488150770342\n",
      "210 Train Loss 9.196292e-05 Test MSE 0.00029669641001518423 Test RE 0.028776648355048083\n",
      "211 Train Loss 9.085999e-05 Test MSE 0.00028963733528736843 Test RE 0.028432256977324263\n",
      "212 Train Loss 9.013153e-05 Test MSE 0.0002838466670803535 Test RE 0.02814660145184197\n",
      "213 Train Loss 8.908029e-05 Test MSE 0.00026531269579462404 Test RE 0.027212164041144005\n",
      "214 Train Loss 8.825571e-05 Test MSE 0.00025939710975556436 Test RE 0.02690708375020542\n",
      "215 Train Loss 8.704746e-05 Test MSE 0.0002467549686368713 Test RE 0.0262432137210884\n",
      "216 Train Loss 8.583604e-05 Test MSE 0.00024020993243365762 Test RE 0.02589283147126259\n",
      "217 Train Loss 8.497686e-05 Test MSE 0.0002446236478567291 Test RE 0.026129631389299725\n",
      "218 Train Loss 8.414277e-05 Test MSE 0.00024151338030457129 Test RE 0.025962987387131525\n",
      "219 Train Loss 8.361538e-05 Test MSE 0.0002369080115876563 Test RE 0.02571425450148314\n",
      "220 Train Loss 8.338661e-05 Test MSE 0.00023069364287777176 Test RE 0.025374756163357343\n",
      "221 Train Loss 8.3067265e-05 Test MSE 0.0002245253857037858 Test RE 0.0250332242407265\n",
      "222 Train Loss 8.2631625e-05 Test MSE 0.00022106226604760808 Test RE 0.024839415540331446\n",
      "223 Train Loss 8.205774e-05 Test MSE 0.00021744520371587512 Test RE 0.024635363822629704\n",
      "224 Train Loss 8.136303e-05 Test MSE 0.00021967927032206386 Test RE 0.024761594246310904\n",
      "225 Train Loss 8.131927e-05 Test MSE 0.00021941382768246638 Test RE 0.024746629771891307\n",
      "226 Train Loss 8.0484926e-05 Test MSE 0.0002245335567369421 Test RE 0.02503367974700183\n",
      "227 Train Loss 7.9819794e-05 Test MSE 0.00022436293566774292 Test RE 0.025024166503189504\n",
      "228 Train Loss 7.981178e-05 Test MSE 0.00022436309223978438 Test RE 0.025024175234765734\n",
      "229 Train Loss 7.918445e-05 Test MSE 0.00023027269615814844 Test RE 0.025351594932551916\n",
      "230 Train Loss 7.86945e-05 Test MSE 0.00023164064959835758 Test RE 0.02542678502230627\n",
      "231 Train Loss 7.8027755e-05 Test MSE 0.00023411299238314996 Test RE 0.02556211722506174\n",
      "232 Train Loss 7.7360484e-05 Test MSE 0.00023883645640222304 Test RE 0.025818700137815325\n",
      "233 Train Loss 7.730404e-05 Test MSE 0.00024084913594454057 Test RE 0.02592725925854122\n",
      "234 Train Loss 7.637171e-05 Test MSE 0.0002578680892470824 Test RE 0.02682766441984426\n",
      "235 Train Loss 7.5440825e-05 Test MSE 0.00026403813047178677 Test RE 0.027146721571264274\n",
      "236 Train Loss 7.442069e-05 Test MSE 0.0002521041105050578 Test RE 0.026526138173639364\n",
      "237 Train Loss 7.3996955e-05 Test MSE 0.0002468325660252804 Test RE 0.02624733976723622\n",
      "238 Train Loss 7.3205665e-05 Test MSE 0.00023998312723672393 Test RE 0.025880604633754054\n",
      "239 Train Loss 7.251295e-05 Test MSE 0.00023918478961095234 Test RE 0.025837521037316635\n",
      "240 Train Loss 7.222939e-05 Test MSE 0.00023687604752271042 Test RE 0.02571251973569486\n",
      "241 Train Loss 7.147377e-05 Test MSE 0.0002353849074575003 Test RE 0.02563146152246165\n",
      "242 Train Loss 7.079083e-05 Test MSE 0.0002327967619201882 Test RE 0.025490158251119097\n",
      "243 Train Loss 7.016056e-05 Test MSE 0.0002267352416139871 Test RE 0.025156115389492757\n",
      "244 Train Loss 7.015299e-05 Test MSE 0.0002266858429764138 Test RE 0.025153374868189755\n",
      "245 Train Loss 7.009831e-05 Test MSE 0.0002264602115277456 Test RE 0.025140853562739676\n",
      "246 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "247 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "248 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "249 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "250 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "251 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "252 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "253 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "254 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "255 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "256 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "257 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "258 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "259 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "260 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "261 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "262 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "263 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "264 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "265 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "266 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "267 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "268 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "269 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "270 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "271 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "272 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "273 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "274 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "275 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "276 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "277 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "278 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "279 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "280 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "281 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "282 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "283 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "284 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "285 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "286 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "287 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "288 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "289 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "290 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "291 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "292 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "293 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "294 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "295 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "296 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "297 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "298 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "299 Train Loss 7.007662e-05 Test MSE 0.00022644689792763691 Test RE 0.025140114536250008\n",
      "Training time: 106.01\n",
      "Training time: 106.01\n"
     ]
    }
   ],
   "source": [
    "max_reps = 1\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "\n",
    "N_T = 500 #Total number of data points for 'y'\n",
    "N_f = 10000 #Total number of collocation points \n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    " \n",
    "    \n",
    "    torch.manual_seed(reps*36)\n",
    "    \n",
    "    layers = np.array([2,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "   \n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-08, \n",
    "                              tolerance_change = 1e-08, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "    \n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "    \n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1,500).reshape(-1,1)\n",
    "y = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xy = np.hstack((X,Y))\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "\n",
    "u_pred = PINN.forward(xy_test_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "img3 = ax.imshow(np.flip(u_pred.reshape(500,500),axis = 0),cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loss_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31330/1704525943.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_loss_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loss_full' is not defined"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + train_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
