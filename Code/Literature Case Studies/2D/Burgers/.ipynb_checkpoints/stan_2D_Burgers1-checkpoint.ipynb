{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 25000\n",
    "level = \"_low\"\n",
    "label = \"Burgers_stan\" + level\n",
    "\n",
    "x = np.linspace(-1,1,256).reshape(-1,1)\n",
    "t = np.linspace(0,1,100).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "# bound_pts_1 = (X == 0).reshape(-1,)\n",
    "# bound_pts_2 = np.logical_and(Y == 0,X != 0).reshape(-1,)\n",
    "# bound_pts_3 = np.logical_and(X == 1,Y != 0).reshape(-1,) \n",
    "# bound_pts_4 = np.logical_and(Y == 1,X != 1).reshape(-1,) \n",
    "\n",
    "# xy_bound_1 = xy[bound_pts_1,:]\n",
    "# xy_bound_2 = xy[bound_pts_2,:]\n",
    "# xy_bound_3 = xy[bound_pts_3,:]\n",
    "# xy_bound_4 = xy[bound_pts_4,:]\n",
    "\n",
    "# u_bound_1 = 1000*np.ones((np.shape(xy_bound_1)[0],1))\n",
    "# u_bound_2 = 800*np.ones((np.shape(xy_bound_2)[0],1))\n",
    "# u_bound_3 = 500*np.ones((np.shape(xy_bound_3)[0],1))\n",
    "# u_bound_4 = np.zeros((np.shape(xy_bound_4)[0],1))\n",
    "\n",
    "# xy_bound = np.vstack((xy_bound_1,xy_bound_2,xy_bound_3,xy_bound_4))\n",
    "# u_bound = np.vstack((u_bound_1,u_bound_2,u_bound_3,u_bound_4))\n",
    "\n",
    "# xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('burgers_shock.mat') \n",
    "\n",
    "pi = torch.from_numpy(np.array(np.pi)).double().to(device)\n",
    "\n",
    "x = np.array(data['x'])\n",
    "t = np.array(data['t'])\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "u_true = np.array(data['usol'][:])\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "u_true_norm = np.linalg.norm(u_true,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_T,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    x_l = x[0]*np.ones((N_T,1))\n",
    "    t_l = np.random.uniform(t[0],t[-1],(N_T,1))\n",
    "    xt_l = np.hstack((x_l,t_l))\n",
    "    u_l = 0.0*np.ones((N_T,1))\n",
    "    \n",
    "    x_r = x[-1]*np.ones((N_T,1))\n",
    "    t_r = np.random.uniform(t[0],t[-1],(N_T,1))\n",
    "    xt_r = np.hstack((x_r,t_r))\n",
    "    u_r = 0.0*np.ones((N_T,1))\n",
    "    \n",
    "    x_0 = np.random.uniform(x[0],x[-1],(N_T,1))\n",
    "    t_0 = t[0]*np.ones((N_T,1))\n",
    "    xt_0 = np.hstack((x_0,t_0))\n",
    "    u_0 = -1.0*np.sin(np.pi*x_0)\n",
    "    \n",
    "    xt_BC = np.vstack((xt_l,xt_r,xt_0)) #choose indices from  set 'idx' (x,t)\n",
    "    u_BC = np.vstack((u_l,u_r,u_0))\n",
    "    \n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, u_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "        \n",
    "        beta_mean = 1.0*torch.ones((50,len(layers)-2))\n",
    "        beta_std = 0.1*torch.ones((50,len(layers)-2))\n",
    "        \n",
    "        self.beta = Parameter(torch.normal(beta_mean,beta_std))\n",
    "        self.beta.requiresGrad = True\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xy):\n",
    "        if torch.is_tensor(xy) != True:         \n",
    "            xy = torch.from_numpy(xy)                \n",
    "        \n",
    "        ubxy = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxy = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xy = 2.0*(xy - lbxy)/(ubxy - lbxy) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xy.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            z1 =self.activation(z)\n",
    "            a = z1 + self.beta[:,i]*z*z1\n",
    "       \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xy,u):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xy), u)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xy_coll, f_hat):\n",
    "        \n",
    "        g = xy_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy = autograd.grad(u_x_y,g,torch.ones(xy_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        du_dx = u_x_y[:,[0]]\n",
    "        du_dt = u_x_y[:,[1]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy[:,[0]]\n",
    "        \n",
    "\n",
    "        f = du_dt + u*du_dx - 0.01*d2u_dx2/pi\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xy_BC,u_BC,xy_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xy_BC,u_BC)\n",
    "        loss_f = self.loss_PDE(xy_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        u_pred = self.forward(xt_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "        \n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xy_BC,u_BC,xy_coll,f_hat,seed):\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xy_BC,u_BC,xy_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xy_coll_np_array, xy_BC_np_array, u_BC_np_array = trainingdata(N_T,N_f,rep*22)\n",
    "        \n",
    "    xy_coll = torch.from_numpy(xy_coll_np_array).float().to(device)\n",
    "    xy_BC = torch.from_numpy(xy_BC_np_array).float().to(device)\n",
    "    u_BC = torch.from_numpy(u_BC_np_array).float().to(device)\n",
    "        \n",
    "    f_hat = torch.zeros(xy_coll.shape[0],1).to(device)\n",
    "    \n",
    "\n",
    "    for i in range(max_iter):\n",
    "        train_step(xy_BC,u_BC,xy_coll,f_hat,i)\n",
    "        loss_np = PINN.loss(xy_BC,u_BC,xy_coll,f_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burgers_stan_low\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 0.078346655 Test MSE 0.17921248496429038 Test RE 0.7072422465557582\n",
      "1 Train Loss 0.067305386 Test MSE 0.1543420302963453 Test RE 0.6563359132728255\n",
      "2 Train Loss 0.054173615 Test MSE 0.12114476810495077 Test RE 0.5814821607562453\n",
      "3 Train Loss 0.047239438 Test MSE 0.10634107334828952 Test RE 0.5447968450355016\n",
      "4 Train Loss 0.043274533 Test MSE 0.09659927690532345 Test RE 0.5192434201535364\n",
      "5 Train Loss 0.040613115 Test MSE 0.09483992038499339 Test RE 0.514493218199096\n",
      "6 Train Loss 0.039043784 Test MSE 0.09206690716581216 Test RE 0.5069158154085354\n",
      "7 Train Loss 0.03789371 Test MSE 0.08923287239276499 Test RE 0.49905280466220664\n",
      "8 Train Loss 0.036870763 Test MSE 0.08770565623035458 Test RE 0.49476374174999804\n",
      "9 Train Loss 0.03583513 Test MSE 0.0839571164807444 Test RE 0.48407518626669915\n",
      "10 Train Loss 0.033808324 Test MSE 0.0799054147430988 Test RE 0.47225022022703333\n",
      "11 Train Loss 0.032042768 Test MSE 0.07576725989618423 Test RE 0.45985917389456\n",
      "12 Train Loss 0.029603768 Test MSE 0.06397280251859312 Test RE 0.4225535478226034\n",
      "13 Train Loss 0.024759281 Test MSE 0.05320697595506968 Test RE 0.38536152526573836\n",
      "14 Train Loss 0.02265406 Test MSE 0.0496810657081944 Test RE 0.3723741421867401\n",
      "15 Train Loss 0.020478852 Test MSE 0.04734792682982411 Test RE 0.36352522172847557\n",
      "16 Train Loss 0.018501228 Test MSE 0.04535064587221129 Test RE 0.3557753072516602\n",
      "17 Train Loss 0.016822794 Test MSE 0.04377817468613109 Test RE 0.3495528835193181\n",
      "18 Train Loss 0.015157405 Test MSE 0.04054340325410261 Test RE 0.3363908425286413\n",
      "19 Train Loss 0.013942706 Test MSE 0.04044824523298615 Test RE 0.3359958449586305\n",
      "20 Train Loss 0.01264389 Test MSE 0.03848956796695066 Test RE 0.3277597217582187\n",
      "21 Train Loss 0.011245172 Test MSE 0.036126511324481886 Test RE 0.31753900263843376\n",
      "22 Train Loss 0.01039367 Test MSE 0.034859203391944656 Test RE 0.31191969194855373\n",
      "23 Train Loss 0.009744133 Test MSE 0.033795583914853135 Test RE 0.3071242022165287\n",
      "24 Train Loss 0.009033275 Test MSE 0.033240176154145804 Test RE 0.3045900571764234\n",
      "25 Train Loss 0.008349281 Test MSE 0.03504896308242513 Test RE 0.31276752330320884\n",
      "26 Train Loss 0.007856912 Test MSE 0.03494822447217634 Test RE 0.31231771772333766\n",
      "27 Train Loss 0.0071978867 Test MSE 0.03464026530217115 Test RE 0.3109386215156753\n",
      "28 Train Loss 0.006634134 Test MSE 0.033449953588698136 Test RE 0.3055496734232894\n",
      "29 Train Loss 0.0063211448 Test MSE 0.033471247346762004 Test RE 0.30564691220839346\n",
      "30 Train Loss 0.006014291 Test MSE 0.03305499628352777 Test RE 0.3037404418974813\n",
      "31 Train Loss 0.0056946613 Test MSE 0.032662571866245486 Test RE 0.3019320761100788\n",
      "32 Train Loss 0.0053367363 Test MSE 0.032428303454976874 Test RE 0.3008473416281477\n",
      "33 Train Loss 0.005112691 Test MSE 0.032559915974422614 Test RE 0.3014572283422528\n",
      "34 Train Loss 0.004979187 Test MSE 0.03232438106666706 Test RE 0.30036489482159984\n",
      "35 Train Loss 0.004830159 Test MSE 0.03245316451956506 Test RE 0.30096264140383266\n",
      "36 Train Loss 0.004569265 Test MSE 0.03253215492477432 Test RE 0.3013286875670967\n",
      "37 Train Loss 0.0044574942 Test MSE 0.03202710483444664 Test RE 0.2989805281886574\n",
      "38 Train Loss 0.0043176473 Test MSE 0.0319577992567193 Test RE 0.29865686108879785\n",
      "39 Train Loss 0.003940212 Test MSE 0.027407394548431455 Test RE 0.2765781962756263\n",
      "40 Train Loss 0.0037455133 Test MSE 0.02676549905150159 Test RE 0.2733202043723951\n",
      "41 Train Loss 0.0036485028 Test MSE 0.026684361428948002 Test RE 0.2729056149843806\n",
      "42 Train Loss 0.003566794 Test MSE 0.026492711578705995 Test RE 0.2719238307788489\n",
      "43 Train Loss 0.0034716704 Test MSE 0.02644796056508239 Test RE 0.27169406927968226\n",
      "44 Train Loss 0.003336093 Test MSE 0.02647084288808267 Test RE 0.2718115763991435\n",
      "45 Train Loss 0.003249061 Test MSE 0.02647862142772672 Test RE 0.2718515098049532\n",
      "46 Train Loss 0.0031738412 Test MSE 0.0262057891507161 Test RE 0.2704473219678044\n",
      "47 Train Loss 0.0030966918 Test MSE 0.026250397833283045 Test RE 0.27067740794104883\n",
      "48 Train Loss 0.0030470174 Test MSE 0.02615612240477091 Test RE 0.27019091662194994\n",
      "49 Train Loss 0.0029919017 Test MSE 0.026108157589810003 Test RE 0.2699430663501668\n",
      "50 Train Loss 0.0029351776 Test MSE 0.026162838046593827 Test RE 0.2702256004511726\n",
      "51 Train Loss 0.0028949198 Test MSE 0.026090247966008298 Test RE 0.2698504629533581\n",
      "52 Train Loss 0.0028614802 Test MSE 0.02619117361589499 Test RE 0.2703718942920044\n",
      "53 Train Loss 0.002812656 Test MSE 0.026092142694425405 Test RE 0.26986026132819013\n",
      "54 Train Loss 0.002765756 Test MSE 0.026062024486777413 Test RE 0.2697044662619637\n",
      "55 Train Loss 0.0027351058 Test MSE 0.02605754880137305 Test RE 0.26968130681452374\n",
      "56 Train Loss 0.002702019 Test MSE 0.025995224964824527 Test RE 0.2693586050162561\n",
      "57 Train Loss 0.0026661754 Test MSE 0.025842714425022954 Test RE 0.2685672970650339\n",
      "58 Train Loss 0.0026207448 Test MSE 0.025912875656651325 Test RE 0.26893162102848134\n",
      "59 Train Loss 0.0025800518 Test MSE 0.025736216908947875 Test RE 0.2680133444634253\n",
      "60 Train Loss 0.002528687 Test MSE 0.025689522578398884 Test RE 0.2677700999844571\n",
      "61 Train Loss 0.0024936544 Test MSE 0.025489855958089534 Test RE 0.2667274756538516\n",
      "62 Train Loss 0.0024526773 Test MSE 0.0253740687925696 Test RE 0.2661209839898125\n",
      "63 Train Loss 0.0024229952 Test MSE 0.025076717121485008 Test RE 0.2645570897946113\n",
      "64 Train Loss 0.0023855453 Test MSE 0.02516905456389599 Test RE 0.2650437180594755\n",
      "65 Train Loss 0.0023553437 Test MSE 0.02500871456958376 Test RE 0.2641981359028759\n",
      "66 Train Loss 0.002322586 Test MSE 0.024830936782458273 Test RE 0.2632574172504181\n",
      "67 Train Loss 0.0022874316 Test MSE 0.024733317054986253 Test RE 0.2627394258121137\n",
      "68 Train Loss 0.002241822 Test MSE 0.024783275353733165 Test RE 0.2630046428298036\n",
      "69 Train Loss 0.0021995143 Test MSE 0.02439072168037479 Test RE 0.26091340312353\n",
      "70 Train Loss 0.0021549158 Test MSE 0.022745459765022243 Test RE 0.25195989810270647\n",
      "71 Train Loss 0.0021056542 Test MSE 0.022629047585168986 Test RE 0.25131430053748743\n",
      "72 Train Loss 0.0020481208 Test MSE 0.02254510492226223 Test RE 0.2508477410888578\n",
      "73 Train Loss 0.0020110789 Test MSE 0.02235750104476407 Test RE 0.2498018750737299\n",
      "74 Train Loss 0.0019731454 Test MSE 0.022396371012726117 Test RE 0.25001892916780377\n",
      "75 Train Loss 0.0019283805 Test MSE 0.02249429190499858 Test RE 0.2505648965248388\n",
      "76 Train Loss 0.0018855205 Test MSE 0.02221994815149841 Test RE 0.24903224557354572\n",
      "77 Train Loss 0.0018542004 Test MSE 0.022295626164271644 Test RE 0.24945596946503779\n",
      "78 Train Loss 0.0018146891 Test MSE 0.022412006478816207 Test RE 0.25010618617148783\n",
      "79 Train Loss 0.0017800466 Test MSE 0.022377428095891574 Test RE 0.2499131734261124\n",
      "80 Train Loss 0.0017451302 Test MSE 0.02228179552471481 Test RE 0.2493785849862396\n",
      "81 Train Loss 0.0017272967 Test MSE 0.02220271949337593 Test RE 0.24893568091479285\n",
      "82 Train Loss 0.0016978808 Test MSE 0.022077582266264613 Test RE 0.24823317377699342\n",
      "83 Train Loss 0.001672045 Test MSE 0.02188491253398966 Test RE 0.24714764225810287\n",
      "84 Train Loss 0.0016471748 Test MSE 0.021916114558759907 Test RE 0.24732376268274253\n",
      "85 Train Loss 0.0016243283 Test MSE 0.02188513937761055 Test RE 0.24714892313415612\n",
      "86 Train Loss 0.0016025514 Test MSE 0.021882189403628512 Test RE 0.24713226554173898\n",
      "87 Train Loss 0.0015751919 Test MSE 0.02184431910659075 Test RE 0.24691832385375598\n",
      "88 Train Loss 0.0015521167 Test MSE 0.02153568792973431 Test RE 0.24516780497033222\n",
      "89 Train Loss 0.001521655 Test MSE 0.021790098085192104 Test RE 0.24661168847952894\n",
      "90 Train Loss 0.0014907586 Test MSE 0.02181182563979928 Test RE 0.24673460976814543\n",
      "91 Train Loss 0.0014655079 Test MSE 0.021572727944725534 Test RE 0.2453785509158851\n",
      "92 Train Loss 0.0014479075 Test MSE 0.021525172815309527 Test RE 0.2451079442802447\n",
      "93 Train Loss 0.0014207449 Test MSE 0.021611560495316984 Test RE 0.2455993016430794\n",
      "94 Train Loss 0.0013955226 Test MSE 0.021670853251830286 Test RE 0.2459359799024072\n",
      "95 Train Loss 0.0013777512 Test MSE 0.021505626632351275 Test RE 0.2449966324484576\n",
      "96 Train Loss 0.0013550539 Test MSE 0.02146648612013296 Test RE 0.24477358243034494\n",
      "97 Train Loss 0.0013352009 Test MSE 0.021406445166746644 Test RE 0.24443103149038556\n",
      "98 Train Loss 0.001311912 Test MSE 0.02132410888828859 Test RE 0.24396049724245603\n",
      "99 Train Loss 0.0012981093 Test MSE 0.02138362535644935 Test RE 0.24430071192877112\n",
      "100 Train Loss 0.0012789383 Test MSE 0.021231395317783973 Test RE 0.24342957030532966\n",
      "101 Train Loss 0.0012639703 Test MSE 0.02136107126537851 Test RE 0.24417184149462343\n",
      "102 Train Loss 0.0012477124 Test MSE 0.021342610004238507 Test RE 0.2440663061860036\n",
      "103 Train Loss 0.0012302577 Test MSE 0.021319690386313227 Test RE 0.24393522078683597\n",
      "104 Train Loss 0.0012161436 Test MSE 0.02144613235284232 Test RE 0.24465751205854325\n",
      "105 Train Loss 0.0012001265 Test MSE 0.02129970236237406 Test RE 0.24382084467985338\n",
      "106 Train Loss 0.0011880317 Test MSE 0.021160184446167806 Test RE 0.2430209916071251\n",
      "107 Train Loss 0.0011699945 Test MSE 0.021132244959671902 Test RE 0.24286049857083797\n",
      "108 Train Loss 0.0011551572 Test MSE 0.02101302049066037 Test RE 0.24217444109545463\n",
      "109 Train Loss 0.0011463722 Test MSE 0.02114451770786847 Test RE 0.24293101008367832\n",
      "110 Train Loss 0.0011287401 Test MSE 0.021224639143831082 Test RE 0.24339083560708602\n",
      "111 Train Loss 0.0011188216 Test MSE 0.02118379235469888 Test RE 0.2431565201519918\n",
      "112 Train Loss 0.0011090327 Test MSE 0.02108452699517883 Test RE 0.24258614631591566\n",
      "113 Train Loss 0.0010931843 Test MSE 0.0210183055414728 Test RE 0.24220489420806574\n",
      "114 Train Loss 0.0010856182 Test MSE 0.020967457497999747 Test RE 0.24191174254145664\n",
      "115 Train Loss 0.0010722107 Test MSE 0.02098370563293005 Test RE 0.24200545570266857\n",
      "116 Train Loss 0.0010606553 Test MSE 0.021062838063151137 Test RE 0.24246134417545703\n",
      "117 Train Loss 0.0010479245 Test MSE 0.021023375129669994 Test RE 0.24223410220104047\n",
      "118 Train Loss 0.0010367632 Test MSE 0.02113838002780354 Test RE 0.2428957493826387\n",
      "119 Train Loss 0.0010303997 Test MSE 0.021137317694051992 Test RE 0.24288964580245903\n",
      "120 Train Loss 0.0010220669 Test MSE 0.02121046293270693 Test RE 0.24330954008598554\n",
      "121 Train Loss 0.0010131095 Test MSE 0.02117180082478469 Test RE 0.24308768848593987\n",
      "122 Train Loss 0.0010003574 Test MSE 0.021216274700495526 Test RE 0.24334287178885294\n",
      "123 Train Loss 0.000992878 Test MSE 0.02110119834812729 Test RE 0.24268203274832686\n",
      "124 Train Loss 0.0009858382 Test MSE 0.02111977247956562 Test RE 0.24278881854293174\n",
      "125 Train Loss 0.0009792598 Test MSE 0.021175822640259873 Test RE 0.24311077597412442\n",
      "126 Train Loss 0.0009689003 Test MSE 0.021146772349090397 Test RE 0.24294396161269516\n",
      "127 Train Loss 0.0009600774 Test MSE 0.021134784087860146 Test RE 0.24287508848820438\n",
      "128 Train Loss 0.0009553486 Test MSE 0.021079361154408685 Test RE 0.24255642693514184\n",
      "129 Train Loss 0.00094732945 Test MSE 0.0211547623097798 Test RE 0.24298985347153804\n",
      "130 Train Loss 0.0009373031 Test MSE 0.02098947796395866 Test RE 0.24203873961279423\n",
      "131 Train Loss 0.0009248238 Test MSE 0.0209428015995991 Test RE 0.24176946716481307\n",
      "132 Train Loss 0.0009160163 Test MSE 0.02099238601144401 Test RE 0.24205550600811387\n",
      "133 Train Loss 0.0009113772 Test MSE 0.021014176079395423 Test RE 0.2421811000669412\n",
      "134 Train Loss 0.0008996954 Test MSE 0.020933276032970426 Test RE 0.24171447802956225\n",
      "135 Train Loss 0.0008910596 Test MSE 0.02110934651913245 Test RE 0.24272888373312868\n",
      "136 Train Loss 0.0008807304 Test MSE 0.021110819623013005 Test RE 0.24273735293472923\n",
      "137 Train Loss 0.0008740269 Test MSE 0.02101781192480847 Test RE 0.24220205009026358\n",
      "138 Train Loss 0.0008652292 Test MSE 0.021031946324602944 Test RE 0.24228347638858744\n",
      "139 Train Loss 0.0008556789 Test MSE 0.020985438631425705 Test RE 0.24201544884780551\n",
      "140 Train Loss 0.0008462019 Test MSE 0.020996662702918938 Test RE 0.24208016123310191\n",
      "141 Train Loss 0.0008365866 Test MSE 0.02083783522865801 Test RE 0.2411628257391049\n",
      "142 Train Loss 0.0008274596 Test MSE 0.020896447610453152 Test RE 0.24150175734218782\n",
      "143 Train Loss 0.0008219527 Test MSE 0.020780406598614624 Test RE 0.24083027665099135\n",
      "144 Train Loss 0.00081409176 Test MSE 0.020843733382485196 Test RE 0.2411969539196114\n",
      "145 Train Loss 0.0008068355 Test MSE 0.020799574822227603 Test RE 0.24094132415449776\n",
      "146 Train Loss 0.0007990517 Test MSE 0.02070649509069179 Test RE 0.24040160397681207\n",
      "147 Train Loss 0.0007908422 Test MSE 0.020653801228020206 Test RE 0.24009552227391817\n",
      "148 Train Loss 0.00078466494 Test MSE 0.020640667625235153 Test RE 0.24001917263159664\n",
      "149 Train Loss 0.0007752066 Test MSE 0.0205787953398799 Test RE 0.239659162948786\n",
      "150 Train Loss 0.00076615607 Test MSE 0.02043498036807889 Test RE 0.238820265336679\n",
      "151 Train Loss 0.0007556267 Test MSE 0.020500925201460216 Test RE 0.2392052981843872\n",
      "152 Train Loss 0.0007449654 Test MSE 0.02041498112887641 Test RE 0.23870337281479495\n",
      "153 Train Loss 0.00073783833 Test MSE 0.02039369393694195 Test RE 0.23857888948129827\n",
      "154 Train Loss 0.0007306809 Test MSE 0.020250169061716304 Test RE 0.23773788282749328\n",
      "155 Train Loss 0.0007237218 Test MSE 0.02014447655645698 Test RE 0.2371166538162917\n",
      "156 Train Loss 0.00071571884 Test MSE 0.019901099629504964 Test RE 0.23567993029737197\n",
      "157 Train Loss 0.0007071269 Test MSE 0.019775408738381267 Test RE 0.23493450059559082\n",
      "158 Train Loss 0.00069931644 Test MSE 0.01951351167484505 Test RE 0.23337362942273734\n",
      "159 Train Loss 0.0006903825 Test MSE 0.019215781626977263 Test RE 0.23158642119317893\n",
      "160 Train Loss 0.0006818513 Test MSE 0.019099740536906523 Test RE 0.23088610528817505\n",
      "161 Train Loss 0.0006727255 Test MSE 0.0187720293929758 Test RE 0.2288967766254858\n",
      "162 Train Loss 0.00066639856 Test MSE 0.01832129000387069 Test RE 0.22613203376741778\n",
      "163 Train Loss 0.00065606635 Test MSE 0.01640436191100388 Test RE 0.2139753449357439\n",
      "164 Train Loss 0.0006138371 Test MSE 0.014006617407667994 Test RE 0.19772004339937016\n",
      "165 Train Loss 0.00053281465 Test MSE 0.01054011307591454 Test RE 0.17151681331787366\n",
      "166 Train Loss 0.0005117179 Test MSE 0.010324162649054433 Test RE 0.16975066451092996\n",
      "167 Train Loss 0.00049748225 Test MSE 0.010173380820943455 Test RE 0.16850652208405498\n",
      "168 Train Loss 0.0004893653 Test MSE 0.010075782056030458 Test RE 0.16769628687362695\n",
      "169 Train Loss 0.00048295513 Test MSE 0.009943694011244127 Test RE 0.16659345683299473\n",
      "170 Train Loss 0.00047454634 Test MSE 0.009855133085373563 Test RE 0.16584993698001657\n",
      "171 Train Loss 0.00046510366 Test MSE 0.009737441271250862 Test RE 0.16485665734680324\n",
      "172 Train Loss 0.00046104586 Test MSE 0.009755279001625929 Test RE 0.16500758627276943\n",
      "173 Train Loss 0.00045699754 Test MSE 0.009707792871467797 Test RE 0.164605489604323\n",
      "174 Train Loss 0.00045040285 Test MSE 0.009757206749608017 Test RE 0.1650238891036938\n",
      "175 Train Loss 0.00044467382 Test MSE 0.009648955148809259 Test RE 0.16410590479512366\n",
      "176 Train Loss 0.0004386308 Test MSE 0.009625493320195763 Test RE 0.16390626825946802\n",
      "177 Train Loss 0.00043043756 Test MSE 0.009498227302453083 Test RE 0.162819097582385\n",
      "178 Train Loss 0.0004241626 Test MSE 0.009385639435708101 Test RE 0.16185122737234856\n",
      "179 Train Loss 0.0004193972 Test MSE 0.009382353037675557 Test RE 0.16182288864651695\n",
      "180 Train Loss 0.00041472696 Test MSE 0.008718638676955348 Test RE 0.15599418303732127\n",
      "181 Train Loss 0.0003913041 Test MSE 0.005966041370234514 Test RE 0.12904084384220366\n",
      "182 Train Loss 0.00035482828 Test MSE 0.0032539743703169075 Test RE 0.09529961103582506\n",
      "183 Train Loss 0.00034230284 Test MSE 0.0030869969621857784 Test RE 0.09282226575387942\n",
      "184 Train Loss 0.00033427274 Test MSE 0.0027852613872352073 Test RE 0.0881692290500193\n",
      "185 Train Loss 0.0003160672 Test MSE 0.00123520780461886 Test RE 0.05871567766598785\n",
      "186 Train Loss 0.00030799807 Test MSE 0.0011641348267499062 Test RE 0.057001423975595183\n",
      "187 Train Loss 0.0003025933 Test MSE 0.0011887396514631463 Test RE 0.057600657219764366\n",
      "188 Train Loss 0.0002950279 Test MSE 0.0012851639402775752 Test RE 0.059891243437043266\n",
      "189 Train Loss 0.00028888695 Test MSE 0.0012877999645011197 Test RE 0.05995263400810777\n",
      "190 Train Loss 0.00028190884 Test MSE 0.0013772976642048523 Test RE 0.06200089655390654\n",
      "191 Train Loss 0.0002766004 Test MSE 0.0013699503281578073 Test RE 0.06183530033128368\n",
      "192 Train Loss 0.00027241613 Test MSE 0.0013045153325996147 Test RE 0.060340465755515264\n",
      "193 Train Loss 0.00026704132 Test MSE 0.0012580770725685894 Test RE 0.05925673083514691\n",
      "194 Train Loss 0.00026381554 Test MSE 0.0012300700068114145 Test RE 0.0585934376557257\n",
      "195 Train Loss 0.00025756325 Test MSE 0.0011333717071709928 Test RE 0.056243229185497026\n",
      "196 Train Loss 0.00025353828 Test MSE 0.0011203974503210955 Test RE 0.05592038078356677\n",
      "197 Train Loss 0.00025030883 Test MSE 0.0010291298323793741 Test RE 0.05359436725892315\n",
      "198 Train Loss 0.00024502978 Test MSE 0.0009515537961288384 Test RE 0.05153481688023405\n",
      "199 Train Loss 0.00024045407 Test MSE 0.0009208830123662786 Test RE 0.050697470933270684\n",
      "200 Train Loss 0.00023635593 Test MSE 0.0009261148757998152 Test RE 0.05084128213042561\n",
      "201 Train Loss 0.00023176812 Test MSE 0.0009310974752433372 Test RE 0.05097786450237462\n",
      "202 Train Loss 0.00022754504 Test MSE 0.0008901113556123072 Test RE 0.04984323650492714\n",
      "203 Train Loss 0.00022421822 Test MSE 0.0007904194203591422 Test RE 0.04696916777700697\n",
      "204 Train Loss 0.00021959352 Test MSE 0.0005399162535622147 Test RE 0.03881926112714197\n",
      "205 Train Loss 0.00021534374 Test MSE 0.0004221521171327902 Test RE 0.03432563261370646\n",
      "206 Train Loss 0.00021226177 Test MSE 0.0003634544537296383 Test RE 0.031849972494864646\n",
      "207 Train Loss 0.00020931035 Test MSE 0.00029783214313133105 Test RE 0.02883167324658055\n",
      "208 Train Loss 0.00020602842 Test MSE 0.000264963303816754 Test RE 0.02719424020217672\n",
      "209 Train Loss 0.00020329189 Test MSE 0.0002446874474223932 Test RE 0.026133038562864492\n",
      "210 Train Loss 0.000201105 Test MSE 0.00025465240607553167 Test RE 0.026659865624875063\n",
      "211 Train Loss 0.0001988053 Test MSE 0.0002657943157905555 Test RE 0.027236851853235187\n",
      "212 Train Loss 0.00019644963 Test MSE 0.000290604032970467 Test RE 0.02847966540482867\n",
      "213 Train Loss 0.00019519433 Test MSE 0.00033510640777974216 Test RE 0.030582672235796266\n",
      "214 Train Loss 0.00019203566 Test MSE 0.0004391430928418918 Test RE 0.035009595440981166\n",
      "215 Train Loss 0.00018897103 Test MSE 0.0005046863110607823 Test RE 0.03753140535100744\n",
      "216 Train Loss 0.00018567209 Test MSE 0.0005920950295298746 Test RE 0.04065179920566059\n",
      "217 Train Loss 0.00018255544 Test MSE 0.0006200222702785011 Test RE 0.04159946148399584\n",
      "218 Train Loss 0.00018094681 Test MSE 0.0005966174739742017 Test RE 0.04080675387838433\n",
      "219 Train Loss 0.00017894618 Test MSE 0.0005867665751908281 Test RE 0.040468466472764655\n",
      "220 Train Loss 0.00017722034 Test MSE 0.0006318459264194036 Test RE 0.04199423353390677\n",
      "221 Train Loss 0.00017555624 Test MSE 0.0006257588529684406 Test RE 0.04179146209136487\n",
      "222 Train Loss 0.00017332096 Test MSE 0.0006549325574266847 Test RE 0.04275455142402408\n",
      "223 Train Loss 0.0001716624 Test MSE 0.0006849595050020133 Test RE 0.04372366039356715\n",
      "224 Train Loss 0.00016892311 Test MSE 0.0007099889909006117 Test RE 0.0445153581038351\n",
      "225 Train Loss 0.00016741449 Test MSE 0.0006909950649488224 Test RE 0.04391587466558294\n",
      "226 Train Loss 0.0001654726 Test MSE 0.0006611969117770276 Test RE 0.04295853598847209\n",
      "227 Train Loss 0.00016397721 Test MSE 0.000637111077171849 Test RE 0.042168838808021254\n",
      "228 Train Loss 0.00016294631 Test MSE 0.0006059718902915564 Test RE 0.04112541594325639\n",
      "229 Train Loss 0.00016227996 Test MSE 0.0006058865456042388 Test RE 0.0411225198028494\n",
      "230 Train Loss 0.00016181661 Test MSE 0.0006142646861219952 Test RE 0.04140586276809863\n",
      "231 Train Loss 0.00016131526 Test MSE 0.0006180248244428664 Test RE 0.04153239961755622\n",
      "232 Train Loss 0.00016010326 Test MSE 0.0006144444411672545 Test RE 0.04141192071711508\n",
      "233 Train Loss 0.00015894184 Test MSE 0.0006307225892886053 Test RE 0.04195688687579743\n",
      "234 Train Loss 0.00015770076 Test MSE 0.0006292736258998107 Test RE 0.041908665240958924\n",
      "235 Train Loss 0.00015632513 Test MSE 0.0006217024814722083 Test RE 0.04165578897025328\n",
      "236 Train Loss 0.00015513046 Test MSE 0.0006110501659642836 Test RE 0.041297379753645794\n",
      "237 Train Loss 0.00015340213 Test MSE 0.0006089269226767274 Test RE 0.0412255683934015\n",
      "238 Train Loss 0.0001513553 Test MSE 0.0005739635840897116 Test RE 0.04002452933208835\n",
      "239 Train Loss 0.00014989446 Test MSE 0.0005589013740805082 Test RE 0.039495867093819075\n",
      "240 Train Loss 0.00014830311 Test MSE 0.0005359995020342178 Test RE 0.038678200219618035\n",
      "241 Train Loss 0.0001471348 Test MSE 0.0005301270480924087 Test RE 0.038465735926264615\n",
      "242 Train Loss 0.00014622862 Test MSE 0.000543899911177784 Test RE 0.03896220778063379\n",
      "243 Train Loss 0.00014496724 Test MSE 0.0005600027826198884 Test RE 0.039534764542327704\n",
      "244 Train Loss 0.0001441249 Test MSE 0.0005731657569650165 Test RE 0.03999670199198926\n",
      "245 Train Loss 0.00014276174 Test MSE 0.0005736766246490825 Test RE 0.040014522728192885\n",
      "246 Train Loss 0.00014160386 Test MSE 0.0005656597448972023 Test RE 0.03973394632525719\n",
      "247 Train Loss 0.00014031037 Test MSE 0.0005574692416756409 Test RE 0.039445232406920085\n",
      "248 Train Loss 0.00013896203 Test MSE 0.000534377313285962 Test RE 0.038619626577559796\n",
      "249 Train Loss 0.00013761446 Test MSE 0.0005247283925322458 Test RE 0.0382693729371161\n",
      "250 Train Loss 0.00013633107 Test MSE 0.0005528456900448816 Test RE 0.03928131592318634\n",
      "251 Train Loss 0.00013538904 Test MSE 0.0005706734735064008 Test RE 0.03990964888714944\n",
      "252 Train Loss 0.00013413334 Test MSE 0.0005818343908403598 Test RE 0.04029802463287189\n",
      "253 Train Loss 0.00013301446 Test MSE 0.0005611894462685608 Test RE 0.0395766300851276\n",
      "254 Train Loss 0.00013261646 Test MSE 0.0005707748752948276 Test RE 0.03991319446111138\n",
      "255 Train Loss 0.00013181963 Test MSE 0.0005778748096445456 Test RE 0.04016066965574669\n",
      "256 Train Loss 0.0001316109 Test MSE 0.0005747544192354241 Test RE 0.040052093719161304\n",
      "257 Train Loss 0.00013089975 Test MSE 0.0005606835122928363 Test RE 0.039558786131640135\n",
      "258 Train Loss 0.00012990515 Test MSE 0.0005305276318983155 Test RE 0.038480266255543294\n",
      "259 Train Loss 0.00012904727 Test MSE 0.0005599410244436304 Test RE 0.03953258449755618\n",
      "260 Train Loss 0.00012812857 Test MSE 0.0005725724492021912 Test RE 0.039975995505479145\n",
      "261 Train Loss 0.00012706207 Test MSE 0.0005593496895239397 Test RE 0.03951170446570013\n",
      "262 Train Loss 0.00012622174 Test MSE 0.0005360452771633128 Test RE 0.03867985177134738\n",
      "263 Train Loss 0.00012510965 Test MSE 0.0005438919308760836 Test RE 0.038961921945586626\n",
      "264 Train Loss 0.00012445371 Test MSE 0.0005401522403612229 Test RE 0.03882774376896505\n",
      "265 Train Loss 0.00012409381 Test MSE 0.0005461015333220658 Test RE 0.039040984616999876\n",
      "266 Train Loss 0.0001238761 Test MSE 0.0005543741742970186 Test RE 0.03933558009809857\n",
      "267 Train Loss 0.0001235434 Test MSE 0.0005413026460872266 Test RE 0.038869069063612496\n",
      "268 Train Loss 0.00012315132 Test MSE 0.000542635708595287 Test RE 0.03891690093477882\n",
      "269 Train Loss 0.00012223926 Test MSE 0.0005590611359042958 Test RE 0.03950151163254532\n",
      "270 Train Loss 0.000121643636 Test MSE 0.00053724649922638 Test RE 0.038723166294112585\n",
      "271 Train Loss 0.000120810306 Test MSE 0.000494087620811247 Test RE 0.03713522422657371\n",
      "272 Train Loss 0.00012002608 Test MSE 0.0004736855250205789 Test RE 0.03636043924143814\n",
      "273 Train Loss 0.00012001859 Test MSE 0.00047476736686417697 Test RE 0.03640193703725667\n",
      "274 Train Loss 0.00011978633 Test MSE 0.00046662918789973666 Test RE 0.036088598322902087\n",
      "275 Train Loss 0.00011977748 Test MSE 0.00046654654476701126 Test RE 0.03608540241599769\n",
      "276 Train Loss 0.00011931216 Test MSE 0.0004633391024575401 Test RE 0.03596114743890004\n",
      "277 Train Loss 0.000118739365 Test MSE 0.00047131086742249767 Test RE 0.036269184522602665\n",
      "278 Train Loss 0.000118200274 Test MSE 0.0004582179222884191 Test RE 0.03576186010788049\n",
      "279 Train Loss 0.00011803525 Test MSE 0.0004524792896761036 Test RE 0.03553721723710922\n",
      "280 Train Loss 0.00011795903 Test MSE 0.00046235018516853474 Test RE 0.03592275051094786\n",
      "281 Train Loss 0.000117416625 Test MSE 0.00047251368489525827 Test RE 0.03631543574839991\n",
      "282 Train Loss 0.0001168022 Test MSE 0.0004753001415513859 Test RE 0.03642235608258489\n",
      "283 Train Loss 0.000116756775 Test MSE 0.00047476751425488164 Test RE 0.036401942687715315\n",
      "284 Train Loss 0.000115987714 Test MSE 0.0004921740137185848 Test RE 0.037063241884527975\n",
      "285 Train Loss 0.000115520044 Test MSE 0.0004706995876676276 Test RE 0.036245656726913\n",
      "286 Train Loss 0.00011454751 Test MSE 0.00046438841123289115 Test RE 0.03600184442260299\n",
      "287 Train Loss 0.00011377786 Test MSE 0.00048300926600665465 Test RE 0.036716543951751716\n",
      "288 Train Loss 0.00011289801 Test MSE 0.00044715404248459593 Test RE 0.03532747882707036\n",
      "289 Train Loss 0.00011262582 Test MSE 0.00044741357932941405 Test RE 0.035337729715433766\n",
      "290 Train Loss 0.00011174371 Test MSE 0.00043724504233932574 Test RE 0.03493385482374109\n",
      "291 Train Loss 0.00011084082 Test MSE 0.00042625066396262184 Test RE 0.03449185870512568\n",
      "292 Train Loss 0.00010988346 Test MSE 0.00040221684797426253 Test RE 0.033505352644165154\n",
      "293 Train Loss 0.000109080065 Test MSE 0.0003811008175858211 Test RE 0.03261399530533061\n",
      "294 Train Loss 0.00010802431 Test MSE 0.0003734228283057762 Test RE 0.03228378869579877\n",
      "295 Train Loss 0.00010719892 Test MSE 0.0003699030146606067 Test RE 0.0321312779874905\n",
      "296 Train Loss 0.000106325155 Test MSE 0.00037433879975347866 Test RE 0.032323359009782886\n",
      "297 Train Loss 0.00010564387 Test MSE 0.0003847401290893376 Test RE 0.0327693485152223\n",
      "298 Train Loss 0.000105245956 Test MSE 0.00039164810394898 Test RE 0.033062225092298156\n",
      "299 Train Loss 0.00010516131 Test MSE 0.00038914763749370025 Test RE 0.032956513664731\n",
      "Training time: 162.76\n",
      "Training time: 162.76\n"
     ]
    }
   ],
   "source": [
    "max_reps = 1\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "\n",
    "N_T = 500 #Total number of data points for 'y'\n",
    "N_f = 10000 #Total number of collocation points \n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    " \n",
    "    \n",
    "    torch.manual_seed(reps*36)\n",
    "    \n",
    "    layers = np.array([2,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "   \n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-08, \n",
    "                              tolerance_change = 1e-08, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "    \n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "    \n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1,500).reshape(-1,1)\n",
    "y = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xy = np.hstack((X,Y))\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "\n",
    "u_pred = PINN.forward(xy_test_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "img3 = ax.imshow(np.flip(u_pred.reshape(500,500),axis = 0),cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
