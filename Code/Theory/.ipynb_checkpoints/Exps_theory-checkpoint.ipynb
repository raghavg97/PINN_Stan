{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a87318-239e-4518-97ec-508ab5ebed73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a7413c0-df5e-482d-97ad-f2c1f1168b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel_stan(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(1.0*torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) + self.beta[:,i]*z*self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "    \n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "class Sequentialmodel_tanh(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a  \n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "class Sequentialmodel_atanh(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(1.1)\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "class Sequentialmodel_swish(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(1.0*torch.ones((layers[1],len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0  #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "    \n",
    "#--------------------------------------------------------------------------------------------\n",
    "class Sequentialmodel_rowdy(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        n_val = 2.0\n",
    "        self.rowdy_terms = 6\n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(self.rowdy_terms,len(layers)-2))\n",
    "        self.omega = Parameter((1/n_val)*torch.ones(self.rowdy_terms,len(layers)-2))\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0  #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(self.rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f4b13b-0249-4b5c-9598-7591c658d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(np.linspace(-1,1,100).reshape(-1,1)).to(device)\n",
    "ub = np.array([1.0])\n",
    "lb = np.array([-1.0])\n",
    "\n",
    "layers = np.array([1,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "colors = ['r','k','b--','g:','c-.']\n",
    "classes = [Sequentialmodel_stan,Sequentialmodel_tanh,Sequentialmodel_atanh,Sequentialmodel_swish,Sequentialmodel_rowdy]\n",
    "\n",
    "\n",
    "u_pred = np.zeros((5,100)) \n",
    "u_x_pred = np.zeros((5,100))\n",
    "u_xx_pred = np.zeros((5,100))\n",
    "\n",
    "reps = 1000\n",
    "\n",
    "for i in range(reps):\n",
    "    j = 0\n",
    "    for af in classes:\n",
    "        torch.manual_seed(i)\n",
    "        PINN = af(layers)\n",
    "        PINN.to(device)\n",
    "        \n",
    "        u_pred[j,:] = u_pred[j,:] + PINN.forward(x).cpu().detach().numpy().reshape(-1,)\n",
    "        \n",
    "        g = x.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        u = PINN.forward(g) \n",
    "\n",
    "        u_x = autograd.grad(u,g,torch.ones([x.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        u_xx = autograd.grad(u_x,g,torch.ones(x.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        du_dx = u_x[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx[:,[0]]\n",
    "        \n",
    "        u_x_pred[j,:] = u_x_pred[j,:] + du_dx.cpu().detach().numpy().reshape(-1,)\n",
    "        u_xx_pred[j,:] = u_xx_pred[j,:] + d2u_dx2.cpu().detach().numpy().reshape(-1,)\n",
    "    \n",
    "        j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c0149ca-17c2-4c9b-9dcf-7323605ba395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0QAAADsCAYAAABUvmYwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAssUlEQVR4nO3df3BU13338c/KgIyMJOpgAYJdLZYlVk4BC9mAgTwQ04ltGjBEnZgOmgfiJRID2O5Ql5hOScLEtjxunpl2mhBg0Dh05Nq1YYCWDB3i2obSOB5Y4bENUiRiCa3AQN2aXcmAbKHz/EHZWEir3SuttHv3vl8zO87uPffu9yrnftnv/XGOyxhjBAAAAAAOlJHsAAAAAAAgWSiIAAAAADgWBREAAAAAx6IgAgAAAOBYFEQAAAAAHIuCCAAAAIBjURABAAAAcCwKIgAAAACONSLZASRSd3e3zp8/r+zsbLlcrmSHAziaMUbt7e3Kz89XRoY9zr2QQ4DUYcccIpFHgFQSbx5Jq4Lo/PnzcrvdyQ4DwFcEg0FNnjw52WHEhRwCpB475RCJPAKkolh5JK0KouzsbEk3djonJyfJ0QDOFg6H5Xa7I8elHZBDgNRhxxwiJSaPXLlyRY2Njb0+v3btms6ePauCggLdfvvtPZYVFxcrKytrQN8HpKt480haFUQ3L03n5OTwYwZIEXa6ZYQcAqQeO+UQKTF55MyZM1qwYIGldQKBgGbOnDmg7wPSXaw8klYFEQAAgN35fD4FAoFen9fX16uiokK1tbUqKSnptQ6AgaEgAgAASCFZWVn9Xu0pKSnhahCQQPYZtgUAAAAAEoyCCAAAAIBjURABAAAAcCwKIgAAAACORUEEAAAAwLEsF0RNTU2aO3euiouLNWvWLJ0+fbrPdjU1NSoqKlJhYaEqKyvV1dUlSero6NDDDz+scePGady4cT3WOX/+vB5++GFNnTpV06dP13e/+139z//8zwB2C0CqIocAGCzyCIBEslwQVVVVqbKyUo2Njdq0aZP8fn+vNs3NzdqyZYuOHTumM2fO6MKFC6qpqZEkjRw5Ups2bdKbb77Za73bbrtNW7Zs0e9+9zt98MEHKigo0LPPPjuA3QKQqsghAAaLPAIgkSwVRJcuXVJdXZ0qKiokSeXl5WpublZLS0uPdnv27NHy5cs1fvx4uVwurV27Vq+++qokKTMzU4sWLdLYsWN7bX/8+PGaP39+5P3s2bP18ccfW9wlAKmKHAJgsMgjABLNUkEUDAaVn5+vESNuzOfqcrnk8XjU2trao11ra6sKCgoi771eb682sVy/fl0///nPtWTJkqhtOjs7FQ6He7wApC5yCIDBIo8ASDTLt8y5XK4e740xMdtFaxONMUbr1q3T2LFj9eSTT0ZtV11drdzc3MjL7XZb+h4Aw48cAmCwyCMAEslSQeR2u9XW1hZ5KNEYo2AwKI/H06Odx+Ppcen67Nmzvdr056mnnlIwGNQ///M/KyMjeoibN29WKBSKvILBoJXdATDMyCEABos8AiDRLBVEeXl5Ki0tVW1trSRp79698nq98nq9PdqVl5dr3759unjxoowx2r59u1asWBHXdzz11FM6c+aM9u3bp1GjRvXbNjMzUzk5OT1eAFIXOQTAYJFHACScsaihocHMmTPHFBUVmbKyMvPRRx8ZY4zx+/3mwIEDkXY7d+40hYWFZsqUKcbv95svvvgisqy0tNRMmDDBZGRkmEmTJpmKigpjjDHHjh0zkozP5zMzZswwM2bMMMuWLYs7tlAoZCSZUChkdbcAJFi045EcAiAe/R2PTs0jgUDASDKBQCDh2wbSUbzHo8sYizfVprBwOKzc3FyFQiHO0ABJZsfj0Y4xA+nKrsfjUMZdV1ensrIyBQIBzZw5M6HbBtJRvMej5UEVAAAAACBdUBABAAAAcKwRyQ4AANLJlStX1NDQ0Ovzq1evqqWlRV6vV6NHj+613OfzKSsrazhCBAAAX0FBBAAJ1NDQoLKyMsvr8UwAAADJQUEEAAnk8/kUCAR6fV5fX6+KigrV1taqpKSkz/UAAMDwoyACgATKysrq90pPSUkJV4IAAEghDKoAAAAAwLEoiAAAAAA4FgURAAAAAMeiIAIAAADgWBREAAAAAByLgggAAACAY1EQAQAAAHAsCiIAAAAAjsXErAAAAEnS1NSk9vb2uNrW19f3+G8s2dnZKioqGnBsgFNQEAEAACRBU1OTiouLLa9XUVERd9vGxkaKIiAGCiIAAIAkuHllqLa2ViUlJTHbX716VS0tLfJ6vRo9enS/bevr61VRURH31SfAySiIAAAAkqikpEQzZ86Mq+28efOGOBrAeSwPqtDU1KS5c+equLhYs2bN0unTp/tsV1NTo6KiIhUWFqqyslJdXV2SpI6ODj388MMaN26cxo0b12u99957T/fdd5+Ki4u1aNEiffLJJ1ZDBJDCyCEABos8AiCRLBdEVVVVqqysVGNjozZt2iS/39+rTXNzs7Zs2aJjx47pzJkzunDhgmpqaiRJI0eO1KZNm/Tmm2/2Ws8Yo5UrV+rv/u7v1NjYqEcffVQbN24cwG4BSFXkEACDRR4BkEiWCqJLly6prq4u8jBfeXm5mpub1dLS0qPdnj17tHz5co0fP14ul0tr167Vq6++KknKzMzUokWLNHbs2F7bP3HihDIzM7Vw4UJJNxLe/v379eWXX1rfMwAphxwCYLDIIwASzVJBFAwGlZ+frxEjbjx65HK55PF41Nra2qNda2urCgoKIu+9Xm+vNn25db3s7GxlZ2dHvVTd2dmpcDjc4wUgdZFDAAwWeQRAolm+Zc7lcvV4b4yJ2S5am8FsX5Kqq6uVm5sbebnd7ri/B0BykEMADBZ5BEAiWSqI3G632traIg8lGmMUDAbl8Xh6tPN4PD0uXZ89e7ZXm77cul57e7va29s1ceLEPttv3rxZoVAo8goGg1Z2B8AwI4cAGCzyCIBEs1QQ5eXlqbS0VLW1tZKkvXv3yuv1yuv19mhXXl6uffv26eLFizLGaPv27VqxYkXM7ZeVlenatWt65513JEk7duzQsmXLNHLkyD7bZ2ZmKicnp8cLQOoihwAYLPIIgIQzFjU0NJg5c+aYoqIiU1ZWZj766CNjjDF+v98cOHAg0m7nzp2msLDQTJkyxfj9fvPFF19ElpWWlpoJEyaYjIwMM2nSJFNRURFZ9pvf/MZMnz7dFBUVmYULF5q2tra4YwuFQkaSCYVCVncLQIJFOx6dmkMCgYCRZAKBQMK3DaSj/o7HdMkjQ5kXyDlA/MejyxgLN9WmuHA4rNzcXIVCIc7QAElmx+NxKGOuq6tTWVmZAoFA3BMwAk5mxxwiWYt7KPMCOQeI/3i0PKgCAAAAAKQLCiIAAAAAjkVBBAAAAMCxKIgAAAAAOBYFEQAAAADHoiACAAAA4FgURAAAAAAci4IIAAAAgGNREAEAAABwLAoiAAAAAI5FQQQAAADAsSiIAAAAADgWBREAAAAAx6IgAgAAAOBYFEQAAAAAHIuCCAAAAIBjURABAAAAcCwKIgAAAACORUEEAAAAwLEsF0RNTU2aO3euiouLNWvWLJ0+fbrPdjU1NSoqKlJhYaEqKyvV1dUVWXbw4EH5fD7dc889Ki8vV0dHR2RZbW2tpk+frvvuu0+lpaU6dOjQAHYLQKoihwAYrHTJI66uayqdkKHRlxul8+8n9DX6cqNKJ2TI1XVtSGIH0oqx6Jvf/KZ5+eWXjTHGvPHGG2bOnDm92nz88cdm4sSJ5sKFC6a7u9ssWbLEbN++3RhjTHt7u8nLyzP19fXGGGPWr19vnn32WWOMMf/93/9tsrOzzfnz540xxvzHf/yHueuuu+KOLRQKGUkmFApZ3S0ACRbteHRqDgkEAkaSCQQCCd82kI76Ox7TJY+c/vdXjflRzpC+Tv/7q3HHDqSbeI/HEVaKp0uXLqmurk6HDx+WJJWXl2vDhg1qaWmR1+uNtNuzZ4+WL1+u8ePHS5LWrl2rl156SVVVVTp06JDuv/9++Xw+SdK6deu0ePFiVVdXq7u7W8aYyFmay5cva/LkyYMq+ACkDnIIgMFKpzxybYxHM3d06JVXXlHJ/8aSKPUNDVq5cqVqFnsSul0gHVkqiILBoPLz8zVixI3VXC6XPB6PWltbeySh1tZWFRQURN57vV61trZGXXbu3Dl1d3dr3Lhx2r59u2bOnKk777xTV69e1Ztvvhk1ns7OTnV2dkbeh8NhK7sDYJiRQwAMVjrlETPidp280K2rY4ul/PviXi8eVy906+SFbpkRtyd0u0A6svwMkcvl6vHeGBOz3a1tbt3GTeFwWNu2bdOJEyd09uxZ1dTU6M/+7M963PP7VdXV1crNzY283G63lV0BkATkEACDRR4BkEiWCiK32622trZIUjDGKBgMyuPpeTnW4/GopaUl8v7s2bORNrcua2lp0aRJk5SRkaHDhw8rNzdXU6dOlSQtWbJEn332mYLBYJ/xbN68WaFQKPKK1g5AaiCHABgs8giARLNUEOXl5am0tFS1tbWSpL1798rr9fa4RC3duJ933759unjxoowx2r59u1asWCFJeuSRR3T8+HE1NDRIkrZt2xZZdvfdd6uurk6XLl2SJL377rvq7u7WpEmT+ownMzNTOTk5PV4AUhc5BMBgkUcAJJqlZ4gkaceOHVq9erVeeOEF5eTkaPfu3ZKkNWvWaOnSpVq6dKnuvvtubd26VfPmzVN3d7ceeugh+f1+SVJ2drZ27dqlZcuWqaurS9OmTYtsY+bMmdq8ebMWLlyokSNHauTIkXr99dc1atSoBO4ygGQihwAYLPIIgERymWg33tpQOBxWbm6uQqEQZ2iAJLPj8TiUMdfV1amsrEyBQEAzZ85M6LaBdGTHHCJZi3so8wI5B4j/eLQ8qAIAAAAApAsKIgAAAACORUEEAAAAwLEoiAAAAAA4FgURAAAAAMeiIAIAAADgWBREAAAAAByLgggAAACAY1EQAQAAAHAsCiIAAAAAjkVBBAAAAMCxKIgAAAAAOBYFEQAAAADHGpHsAAAAAJzoypUrkqS6urq42l+9elUtLS3yer0aPXp0v23r6+sHHR/gFBREAAAASdDQ0CBJ+v73vz9k35GdnT1k2wbSBQURAABAEixbtkyS5PP5lJWVFbN9fX29KioqVFtbq5KSkpjts7OzVVRUNNgwgbRHQQQAAJAE48aN05o1ayyvV1JSopkzZw5BRIAzMagCAAAAAMeyXBA1NTVp7ty5Ki4u1qxZs3T69Ok+29XU1KioqEiFhYWqrKxUV1dXZNnBgwfl8/l0zz33qLy8XB0dHZFln332mVauXKmioiKVlJTo2WefHcBuAUhV5BAAg0UeAZBIlguiqqoqVVZWqrGxUZs2bZLf7+/Vprm5WVu2bNGxY8d05swZXbhwQTU1NZKkjo4O+f1+7d+/X2fOnNHEiRP1/PPPR9Z94oknVFpaqqamJtXX1+vpp58exO4BSDXkEACDRR4BkFDGgosXL5rc3Fzz5ZdfGmOM6e7uNuPHjzfNzc092r300ktm3bp1kfe/+tWvzIIFC4wxxrz++utm8eLFkWWnTp0yBQUFxhhjmpqajMfjMdevX7cSVkQoFDKSTCgUGtD6ABKnr+PRyTkkEAgYSSYQCCR820A6inY8kkfII0C84j0eLV0hCgaDys/P14gRN8ZicLlc8ng8am1t7dGutbVVBQUFkfderzfSpq9l586dU3d3t06fPi232621a9dq5syZ+ta3vqWTJ09Gjaezs1PhcLjHC0DqIocAGCzyCIBEs3zLnMvl6vHeGBOz3a1tbt3GTV9++aXeffdd/fmf/7nq6ur0l3/5l1qyZEmPe36/qrq6Wrm5uZGX2+22sisAkoAcAmCwyCMAEslSQeR2u9XW1hZJCsYYBYNBeTyeHu08Ho9aWloi78+ePRtpc+uylpYWTZo0SRkZGSooKNCkSZP0zW9+U5L08MMP64svvlBbW1uf8WzevFmhUCjyCgaDVnYHwDAjhwAYLPIIgESzNA9RXl6eSktLVVtbq9WrV2vv3r3yer3yer092pWXl2v+/Pn64Q9/qLy8PG3fvl0rVqyQJD3yyCNav369Ghoa5PP5tG3btsiysrIy5eTk6IMPPtD06dN14sQJSdKkSZP6jCczM1OZmZlW9xlAkqRjDmlqalJ7e3vMdvX19T3+GwsTKgJ9S8c8AiDJrD6c1NDQYObMmWOKiopMWVmZ+eijj4wxxvj9fnPgwIFIu507d5rCwkIzZcoU4/f7zRdffBFZduDAATN16lRTWFholi1b1uNBp+PHj5sHHnjATJs2zTzwwAPm6NGjccfGoApA6oh2PKZTDmlsbDSShuzV2NgYd+xAuunveEynPGIFgyoA1sR7PLqMiXLjrQ2Fw2Hl5uYqFAopJycn2eEAjmbH49FqzHV1dSorK1Ntba1KSkr6bXv16lW1tLTI6/Vq9OjR/batr69XRUWFAoEAs9HDseyYQ6ShjftmziE3APGJ93i0dMscAKC3kpKSuH6czJs3bxiiAQAAVlAQAQAApJArV66ooaGh1+f9PYvo8/mUlZU15LEB6YiCCAAAIIU0NDSorKws6vKKiopen3EbHTBwFEQAAAApxOfzKRAI9Pq8v2cRfT7fcIUHpB0KIgAAgBSSlZUV9WoPzyICiWdpYlYAAAAASCcURAAAAAAci4IIAAAAgGNREAEAAABwLAoiAAAAAI7FKHO3iDYZWqyhLpkMDQAAALAfCqJbxJoMrS9MhgYAAADYEwXRLaJNhlZfX6+KigrV1taqpKSk1zoAAAAA7IeC6Bb9TYYmSSUlJVwNAgAAANIEgyoAAAAAcCwKIgAAAACORUEEAAAAwLEoiAAAAAA4FgURAAAAAMeyXBA1NTVp7ty5Ki4u1qxZs3T69Ok+29XU1KioqEiFhYWqrKxUV1dXZNnBgwfl8/l0zz33qLy8XB0dHb3Wf+KJJ+RyufpcBsC+yCEABos8AiCRLBdEVVVVqqysVGNjozZt2iS/39+rTXNzs7Zs2aJjx47pzJkzunDhgmpqaiRJHR0d8vv92r9/v86cOaOJEyfq+eef77H+v/7rv8rlcg1wlwCkMnIIgMEijwBIKGPBxYsXTW5urvnyyy+NMcZ0d3eb8ePHm+bm5h7tXnrpJbNu3brI+1/96ldmwYIFxhhjXn/9dbN48eLIslOnTpmCgoLI+08//dSUlZWZy5cvG0mmvb097vhCoZCRZEKhkJXdiksgEDCSTCAQSPi2gXTU1/GYbjlkqPIC+QaIfjymWx4BMHTiPR4tTcwaDAaVn5+vESNurOZyueTxeNTa2iqv1xtp19raqoKCgsh7r9er1tbWqMvOnTun7u5uZWRkaP369frxj3+s3NzcmPF0dnaqs7Mz8j4cDlvZHQDDjBwCYLDIIwASzfItc7dePjbGxGx3a5tol6DfeOMNjRo1St/+9rfjiqW6ulq5ubmRl9vtjms9AMlDDgEwWOQRAIlkqSByu91qa2uLPJRojFEwGJTH4+nRzuPxqKWlJfL+7NmzkTa3LmtpadGkSZOUkZGht99+W2+99Za8Xm/kLM/Xv/51ffjhh33Gs3nzZoVCocgrGAxa2R0Awyzdcoir65pKJ2Ro9OVG6fz7CXuNvtyo0gkZcnVdsxQP4ATplkcAJJ/LRDutEsXChQu1evVqrV69Wnv27NFPf/pT/fa3v+3R5uOPP9b8+fN18uRJ5eXl6bHHHtPixYu1du1atbe3q7CwUEePHpXP59OGDRs0ZswYvfjii72Dc7nU3t6uMWPGxBVbOBxWbm6uQqGQcnJyrOxWTHV1dSorK1MgENDMmTMTum0gHUU7HtMph9S/9ZpKjlbFte2BqP8/O1Ty0Ioh2z6Qyvo7HtMpjwAYOvEej5aeIZKkHTt2aPXq1XrhhReUk5Oj3bt3S5LWrFmjpUuXaunSpbr77ru1detWzZs3T93d3XrooYciI8BkZ2dr165dWrZsmbq6ujRt2rTINgCkv3TKIdfGeDRzR4deeeUVlfh8CdtufUODVq5cqZrFntiNAQdKpzwCIPksXyFKZVwhAlKHHc+SWo15qPIC+QawZw6R7Bs3kI7iPR4tD6oAAAAAAOnC8i1zAACkiitXrqihoaHHZ1evXlVLS4u8Xq9Gjx7dax2fz6esrKzhChEAkOIoiAAAttXQ0KCysjJL63ArIgDgqyiIAAC25fP5FAgEenxWX1+viooK1dbWqqSkpM91AAC4iYIIAGALTU1Nam9vH/R2br3FTrox6lhRUdGgtw0AsB8KIgBAymtqalJxcbGldSoqKiy1b2xspCgCHKav5xCl/p9F5DnE9ENBBABIeTevDEW7De6rYg2qcKubt9gl4uoTAHvhOURIFEQAABspKSmJ64fIvHnzhiEaAHbX13OIUv/PIvIcYvqhIAIAAIAjZWVl9XuSJd6TMLA3CiIAAACkPSsDs9TX1/f4bywMzGJvFEQAAABIawMZmEWyNjgLA7PYFwURAAAA0pqVgVkka4OzMDCL/VEQAQAAwBGsPBPE4CzOQUEEAEj5uThcXddUOiFDoy83SuczErrt0ZcbVTohQ66uawndbrrpq4/EOovOfC0A7ICCCEmT6j/AACdJ9bk4bu9oVV3VGOlolXQ0sdsukVRXNUb1Ha2S5iZ242kk1fsIAAwUBRGShn9cgdSR6nNxXBvj0cwdHXrllVdUkuDvrW9o0MqVK1Wz2JPQ7aabvvpIf/3j5joAkOooiJA0qf4DDHCSVJ+Lw4y4XScvdOvq2GIp/76EbvvqhW6dvNAtM+L2hG433fTXR5LdPwBgMCiIkDSp/gMMAAAA6c9yQdTU1KRVq1bp008/1dixY/XLX/5S9957b692NTU1evHFF9Xd3a1FixZp27ZtGjHixtcdPHhQzzzzjLq6ujRjxgzt3r1bY8aM0fnz5/W9731PLS0tyszMlM/n0/bt23XnnXcOfk8BpARySPIxOSFiibePWO0fUmL6CHkEQCJZLoiqqqpUWVmp1atXa8+ePfL7/Xr33Xd7tGlubtaWLVt08uRJ5eXl6bHHHlNNTY2qqqrU0dEhv9+vI0eOyOfzacOGDXr++edVXV2t2267TVu2bNH8+fMlSX/1V3+lZ599Vjt37kzM3t6CHwXA8EunHGJHTE6IWAbSR6z0D2nwfYQ8AqsYqRL9sVQQXbp0SXV1dTp8+LAkqby8XBs2bIiMCHbTnj17tHz5co0fP16StHbtWr300kuqqqrSoUOHdP/990eeBVm3bp0WL16s6upqjR8/PrKOJM2ePVvbt28f7D72iR8FwPBLpxxiV0xOiFis9BEr/UNKTB8hj2AgGKkS/bFUEAWDQeXn50cuN7tcLnk8HrW2tvZIQq2trSooKIi893q9am1tjbrs3Llz6u7uVkbGHyr269ev6+c//7mWLVsWNZ7Ozk51dnZG3ofD4bj3hR8FwPBLpxxid0xOiFji7SPD3T/II6lpIFNpSMM3nQYjVSZfKvcRy7fMuVyuHu+NMTHb3drm1m3cyhijdevWaezYsXryySejtquurtbWrVtjhdwvfhQAwyudcsiVK1ckSXV1dTHbWj2pAiC6dMoj6WIgU2lIwzedBiNVJl8q9xFLBZHb7VZbW5u6uro0YsQIGWMUDAbl8fSsiD0ej1paWiLvz549G2nj8Xj01ltvRZa1tLRo0qRJPc7IPPXUUwoGg9q/f3+Pz2+1efNmbdy4MfI+HA7L7XZb2SUAwyjdcsjNM13f//73417Hiuzs7CHZrh0NVfEpUYDaTbrlEbu69Tnsq1evqra2tle7m89y/eQnP9GUKVN6Lb969Wqv45rnsNPDUPWRoegflgqivLw8lZaWqra2VqtXr9bevXvl9Xp7XKKWbtzPO3/+fP3whz9UXl6etm/frhUrVkiSHnnkEa1fv14NDQ3y+Xzatm1bZJl0IwGdOXNG+/fv16hRo/qNJzMzU5mZmVZ2IS2l8iVIpIZU6SPplkNu3kYTz98p1gSWt+IHQU9DXXxKFKB2kW55xI4G8hz2li1bLLXnOWx7G+o+kuj+YfmWuR07dmj16tV64YUXlJOTo927d0uS1qxZo6VLl2rp0qW6++67tXXrVs2bN0/d3d166KGH5Pf7Jd34B2fXrl1atmyZurq6NG3atMg2/vM//1P/8A//IJ/Pp9mzZ0uSpkyZon379iVqf9NSKl+CvIkR/ZIrlfpIOuWQcePGac2aNZbWSfb8WnYdaWkoi0+JPPJVdugj6ZRH7CjVB95A8g1VHxmq/uEy0W68taFwOKzc3FyFQiHl5OT027aurk5lZWVD8oNvKLfdl2hn/2P9KBiuK0QDHdHPCs4k9S8ZfcTK8ZgqhjLm4c4L0dS/9ZpKjlYN7Xf8nx0qeWhF7IZDJFX+1naVKn3EjjlEsm/cVtjxN5QdY7azVPn/Md7j0fIVIqSerKysfjtFss9IM6Jf8qV6H8HwYaQlxEIfQSx2uIqI5BqqPjJU/YOCCMOGEf2A5Eu3kZb6uvoZ67Zbnp/sX7r1ESQec/oglqHqI0PVPyiIAAC21d/zcdEm0ua2FmBwuIqIWIaqjwxV/6AgAgDYls/nUyAQ6PFZPKMnAhg4riIilqHqI0PVPyiIAMBBrMznI6X+hLLRno/jttuBY84nAE5DQWRD8Q5hbXX4aomhZ9MBQ5yjP8zng1joIwCchoLIZgYyhHW0++ijYQhr+xroEOdW+gj9w96izedz80z/rfqbQbyvqwIUzfZnpY/EmmGePpKeuIqIWIaqjwxV/6AgshkmQ0N/GOIcsUSbTLaurq7fwrivGcQZnCA9DaSPRJthnj6Snux4FTHdbhdOdUPdRxLdPyiIbCreIaxT4T565isYfgxxDqv6GpxA6v9HAYMTOAsDWOCmaFcR+xJrAvC+DMVVRDsWcXY2lH1kKPqHYwsifqQPH+YrAFJff5P3UjRDYgAL/EG0q4j9SfYE4FZ+oEup8SPdzuzWRxxbEPEjffgwXwEAAEimgfxAl5JfyGF4OLYg4kf68GG+AgAAAKQqxxZEdv2Rzq1+6A/9AwAAwBrHFkR2xa1+6A/9AwAAwBoKIpvhVj/0h/4BAABgDQWRzdj1Vj8MD/oHAACANRREGHJMhgYAAIBURUFkM1aKCyuFhTR0xQWToQ0fik8g9V25ciWSF78qnklO45k/BQBgDQWRzdixuGAytOFjx/4BpLOmpia1t7f3+OxmjrPq1pxI7gOcoa88cvMEihV9nWwhj9xguSBqamrSqlWr9Omnn2rs2LH65S9/qXvvvbdXu5qaGr344ovq7u7WokWLtG3bNo0YcePrDh48qGeeeUZdXV2aMWOGdu/erTFjxkiS3nvvPVVVVenKlStyu92qra3VxIkTB7mbvdn1TLqV4sJqYSENzYGRbpOh9XV2N1XO7Nqh+EyXHALE0tTUpOLi4oRtr68iqrGx0ZE/ZsgjcIoPAu9p9beHdmTX1996X/eUTBvS70h1lguiqqoqVVZWavXq1dqzZ4/8fr/efffdHm2am5u1ZcsWnTx5Unl5eXrsscdUU1OjqqoqdXR0yO/368iRI/L5fNqwYYOef/55VVdXyxijlStXateuXVq4cKF++tOfauPGjXr11VcTtsM32fVM+kCKi1QtLOwgUWd3+yo4nFp8pksOAWLp+Oy/VDohQ88995ymTJkSs31nZ6fOnz+v/Px8ZWZm9tu2ublZf/M3f6OOz/5LkvMKIvIIEiXaLaw3T273dZJ7OG9f/f17h25MpzGEWsMtkiiI4nbp0iXV1dXp8OHDkqTy8nJt2LAhcmb8pj179mj58uUaP368JGnt2rV66aWXVFVVpUOHDun++++X73+HBF63bp0WL16s6upqnThxQpmZmVq4cKGkGwkvLy9PX375pUaOHJmA3f2DaGfSo12CvJlYf/KTn/T6hy3ZlyAHcjBLyb8fPdWTUH9nZUonWJv09P8983/7/Hy4zsqkSh9JpxwSTar8rZECPm288UMm+KIUjG+V+6S42pZIWuzQecGckEfsyK65r6GhQWVlZVGX93UCNBAIDNtJxG8s92vfvhu/NW+//Q+jvN48gWJFXydb7rjjDnlKFyUk1lhSuY9YKoiCwaDy8/Mjl5tdLpc8Ho9aW1t7JKHW1lYVFBRE3nu9XrW2tkZddu7cOXV3d/dalp2drezsbH3yySfyeHrPfdLZ2anOzs7I+3A4HPe+RDuTXldX1+/Z/y1btvT6bDgPjL4M5GCW7Bn3cMacTmdlUqWPpFMOiSZV/tZIvvfbrsi/o2NIv+P1x78+pNtPRU7II3Zk19zn8/kUCAR6fd7frfC+BM/z159xE91avu7HfS67b9iiSIxU7iOWb5lzuVw93htjYra7tc2t2xjI9iWpurpaW7dujbp8IFL9wOjLQGK+uV4ypfrfOtpZmZu3qljR1y0zw3lWJpX6CDkkNY9HJN6S73xX1zNG9Tq7mchBFe5x4PNDUvrnETuya+7LysqK+mN73rx5wxxNekvlPmKpIHK73Wpra1NXV5dGjBghY4yCwWCvMyYej6fHbWdnz56NtPF4PHrrrbciy1paWjRp0iRlZGT0Wq+9vV3t7e1RH2TcvHmzNm7cGHkfDofldrut7FIvdjww7BizlPpxRzsrU3DlinaVPtzjs1QZVCGaVPlbk0OS368xfKLdiTCYHwXcVumMPGJH5D7EktJ9xFi0YMEC8/LLLxtjjHnjjTfM7Nmze7X5/e9/byZOnGguXLhguru7zZIlS8wvfvELY4wx4XDY3HXXXaa+vt4YY8z69evND37wA2OMMdevXzd33323efvtt40xxvzt3/6tefzxx+OOLRQKGUkmFApZ3S0ACRbteCSHAIhHf8cjeQRAPOI9Hi0XRA0NDWbOnDmmqKjIlJWVmY8++sgYY4zf7zcHDhyItNu5c6cpLCw0U6ZMMX6/33zxxReRZQcOHDBTp041hYWFZtmyZT2C/M1vfmOmT59uioqKzMKFC01bW1vcsZGEgNQR7XgkhwCIR3/HI3kEQDziPR5dxvRzY6zNhMNh5ebmKhQKKScnJ9nhAI5mx+PRjjED6cqux6Nd4wbSUbzHo7WxgwEAAAAgjVAQAQAAAHAsCiIAAAAAjkVBBAAAAMCxKIgAAAAAOBYFEQAAAADHoiACAAAA4Fgjkh1AIt2cUikcDic5EgA3j0M7TXVGDgFShx1ziEQeAVJJvHkkrQqi9vZ2SZLb7U5yJABuam9vV25ubrLDiAs5BEg9dsohEnkESEWx8ojL2O3USz+6u7t1/vx5ZWdny+VyJXTb4XBYbrdbwWDQNjNP2zFmyZ5x2zFmaWjjNsaovb1d+fn5ysiwx9255JDe7Bi3HWOW7Bk3OaQ38khPdoxZsmfcdoxZSo08klZXiDIyMjR58uQh/Y6cnBxbdTLJnjFL9ozbjjFLQxe3nc7qSuSQ/tgxbjvGLNkzbnLIH5BH+mbHmCV7xm3HmKXk5hH7nHIBAAAAgASjIAIAAADgWBREccrMzNSPfvQjZWZmJjuUuNkxZsmecdsxZsm+cduRXf/WdozbjjFL9ozbjjHbmR3/3naMWbJn3HaMWUqNuNNqUAUAAAAAsIIrRAAAAAAci4IIAAAAgGNREAEAAABwLAoiAAAAAI5FQRTD0aNHtWTJEuXn58vlcmn//v3JDimm6upqPfDAA8rOzlZeXp6WLVum3/3ud8kOq1+/+MUvNH369MikXA8++KAOHTqU7LAsq66ulsvl0l/8xV8kO5SofvzjH8vlcvV4TZgwIdlhpS1yyPBJhzxihxwikUeGG3lkeKRDDpHIIwNBQRTD559/rhkzZuhnP/tZskOJ25EjR7R+/Xr99re/1a9//Wt1dXXpW9/6lj7//PNkhxbV5MmT9eKLL+rEiRM6ceKEHnroIT322GM6depUskOL2/Hjx7Vz505Nnz492aHE9PWvf12ffPJJ5PXhhx8mO6S0RQ4ZPnbPI3bKIRJ5ZDiRR4aH3XOIRB4ZMIO4STL79u1LdhiWXbp0yUgyR44cSXYolvzRH/2R2bVrV7LDiEt7e7spKioyv/71r82CBQvM008/neyQovrRj35kZsyYkewwHIkcMvzskkfslEOMIY8kE3lkeNklhxhDHhkMrhA5QCgUkiTdeeedSY4kPtevX9drr72mzz//XA8++GCyw4nL+vXr9ad/+qf6kz/5k2SHEpempibl5+drypQpWrFihT7++ONkh4QUZrccItkvj9gth0jkEVhjtzxitxwikUcGY0RSvhXDxhijjRs3av78+frjP/7jZIfTrw8//FAPPvigrl27pjFjxmjfvn269957kx1WTK+99prq6up0/PjxZIcSl9mzZ+sf//EfVVxcrIsXL+q5557T3LlzderUKX3ta19LdnhIMXbKIZI984jdcohEHoE1dsojdswhEnlksCiI0tyGDRv0wQcf6NixY8kOJaapU6fq/fff1+XLl7V3716tWrVKR44cSelEFAwG9fTTT+vw4cO6/fbbkx1OXB599NHI/542bZoefPBBFRYWavfu3dq4cWMSI0MqslMOkeyXR+yYQyTyCKyxUx6xWw6RyCOJQEGUxp588kn9y7/8i44eParJkycnO5yYRo0apXvuuUeSdP/99+v48eP6+7//e+3YsSPJkUUXCAR06dIllZWVRT67fv26jh49qp/97Gfq7OzUbbfdlsQIY7vjjjs0bdo0NTU1JTsUpBi75RDJfnkkHXKIRB5BdHbLI3bLIRJ5JBEoiNKQMUZPPvmk9u3bp3feeUdTpkxJdkgDYoxRZ2dnssPo16JFi3qNiPK9731PPp9PP/jBD2yRgDo7O1VfX69vfOMbyQ4FKSJdcoiU+nkkHXKIRB5Bb+mSR1I9h0jkkUSgIIqho6NDZ86cibxvbm7W+++/rzvvvFMejyeJkUW3fv16/dM//ZMOHDig7OxsXbhwQZKUm5ur0aNHJzm6vv31X/+1Hn30UbndbrW3t+u1117TO++8o3/7t39Ldmj9ys7O7nU/9B133KGvfe1rKXuf9DPPPKMlS5bI4/Ho0qVLeu655xQOh7Vq1apkh5aWyCHDx455xI45RCKPDDfyyPCwYw6RyCMJkbTx7Wzi7bffNpJ6vVatWpXs0KLqK15J5uWXX052aFE98cQTpqCgwIwaNcrcddddZtGiRebw4cPJDmtAUn2oy8cff9xMnDjRjBw50uTn55vvfOc75tSpU8kOK22RQ4ZPuuSRVM8hxpBHhht5ZHikSw4xhjxilcsYY4a86gIAAACAFMQ8RAAAAAAci4IIAAAAgGNREAEAAABwLAoiAAAAAI5FQQQAAADAsSiIAAAAADgWBREAAAAAx6IgAgAAAOBYFEQAAAAAHIuCCAAAAIBjURABAAAAcCwKIgAAAACO9f8BkbadeuhJjoUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x250 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,3)\n",
    "\n",
    "plt_data = [np.transpose(np.abs(u_pred))/reps,np.transpose(np.abs(u_x_pred))/reps,np.transpose(np.abs(u_xx_pred))/reps]\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].boxplot(plt_data[i],0,'')\n",
    "    ax[i].figure.set_size_inches(10,2.5)\n",
    "    \n",
    "    ax[i].set_ylim([-0.001,0.013])\n",
    "\n",
    "    ax[i].tick_params(axis='y', labelsize=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
