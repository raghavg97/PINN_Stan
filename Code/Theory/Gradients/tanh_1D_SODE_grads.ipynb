{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_1D_1(x): #True function for 1D_1 dy2/dx2 + dy/dx - 6y = 0; BC1: y(0)=2; BC2: dy/dx at (x=0) = -1;\n",
    "    y = np.exp(-3.0*x) + np.exp(2.0*x)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"medium\"\n",
    "label = \"1D_SODE_Stan\" + level\n",
    "\n",
    "u_coeff = 6.0\n",
    "fo_val = -1.0\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "x = np.linspace(0,2,100).reshape(-1,1)\n",
    "\n",
    "bc1_x = x[0].reshape(-1,1)\n",
    "bc1_y = true_1D_1(x[0]).reshape(-1,1)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "y_bc1_train = torch.from_numpy(bc1_y).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_x = x[0].reshape(-1,1)\n",
    "x_bc2_train = torch.from_numpy(bc2_x).float().to(device)\n",
    "bc2_val = torch.tensor(fo_val,device=device)\n",
    "bc2_val = bc2_val.view(1,1)\n",
    "\n",
    "x_test = x.reshape(-1,1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().to(device)\n",
    "y_true = true_1D_1(x_test)\n",
    "y_true_tensor = torch.from_numpy(y_true).float().to(device)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(x[0]) \n",
    "ub = np.array(x[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    #Collocation Points\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,y)\n",
    "    x01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    \n",
    "    x_coll_train = lb + (ub-lb)*sampling(N_f)\n",
    "    x_coll_train = np.vstack((x_coll_train, bc1_x.reshape(-1,1))) # append training points to collocation points \n",
    "\n",
    "    return x_coll_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "            \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "    \n",
    "\n",
    "   \n",
    "                        \n",
    "    def loss_BC1(self,x,y):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,x_bc2,bc2_val):\n",
    "        g = x_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g)    \n",
    "            \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        bc2 = dy_dx\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self, x_coll,f_hat):\n",
    "             \n",
    "        g = x_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "\n",
    "        y_x = autograd.grad(y,g,torch.ones([x_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_xx = autograd.grad(y_x,g,torch.ones(x_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dy_dx = y_x[:,[0]]\n",
    "        \n",
    "        dy2_d2x = y_xx[:,[0]]\n",
    "        \n",
    "        f = dy2_d2x + dy_dx - u_coeff*y\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,x_bc1,y_bc1,x_bc2,bc2_val,x_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(x_bc1,y_bc1)\n",
    "        loss_bc2 = self.loss_BC2(x_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(x_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def forward_grads(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "\n",
    "        \n",
    "        i =0\n",
    "        z = self.linears[i](a)\n",
    "        a = self.activation(z) \n",
    "\n",
    "        a_np = a.cpu().detach().numpy()\n",
    "        a1_np = 1-np.square(a_np)\n",
    "        a2_np = -2*a_np*(a1_np)\n",
    "\n",
    "        W2 = self.linears[1].weight.cpu().detach().numpy()\n",
    "        W1 = np.transpose(self.linears[0].weight.cpu().detach().numpy())\n",
    "        val = (W2)*np.square(W1)*a2_np\n",
    "         \n",
    "        return val\n",
    "    \n",
    "    def grad_test(self,x_grad):\n",
    "        g = x_grad.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        y = self.forward(g) \n",
    "    \n",
    "        y_x = autograd.grad(y,g,torch.ones([x_grad.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        y_x_w1 = autograd.grad(y_x,self.linears[0].weight,torch.ones([y_x.shape[0],1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "    \n",
    "            \n",
    "        \n",
    "        y_x_w1 = np.transpose(y_x_w1.cpu().detach().numpy())\n",
    "        sd_val = self.forward_grads(x_grad)\n",
    "        \n",
    "        # print(np.mean(y_x_w1))\n",
    "        # print(sd_val/y_x_w1)\n",
    "        return np.mean(np.abs(sd_val)/np.abs(y_x_w1+0.001))\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.forward(x_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    x_grad = torch.zeros((1,1)).float().to(device)\n",
    "    v = PINN.grad_test(x_grad)\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "    \n",
    "    v = np.zeros((max_iter,1))\n",
    "    \n",
    "    x_coll = torch.from_numpy(colloc_pts(N_f,0)).float().to(device)\n",
    "    f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        x_coll = torch.from_numpy(colloc_pts(N_f,i*11)).float().to(device)\n",
    "        f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "        v[i] = train_step(x_coll,f_hat)\n",
    "       \n",
    "        \n",
    "        # print(\"k =\", k[i])\n",
    "        loss_np = PINN.loss(x_bc1_train,y_bc1_train,x_bc2_train,bc2_val,x_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 4.4657817 Test MSE 386.70819064471647 Test RE 1.002430490382989\n",
      "1 Train Loss 4.318592 Test MSE 388.0028901737834 Test RE 1.00410715748249\n",
      "2 Train Loss 3.4866962 Test MSE 385.8633611083951 Test RE 1.0013349020910973\n",
      "3 Train Loss 3.1719036 Test MSE 387.2966501784964 Test RE 1.0031929070486816\n",
      "4 Train Loss 2.964757 Test MSE 391.42081314649835 Test RE 1.0085200575749147\n",
      "5 Train Loss 2.8360186 Test MSE 389.6870986426155 Test RE 1.0062840672698967\n",
      "6 Train Loss 2.6103559 Test MSE 386.7986830110188 Test RE 1.0025477713239133\n",
      "7 Train Loss 2.5262516 Test MSE 390.4136235945093 Test RE 1.0072216785556138\n",
      "8 Train Loss 2.5160425 Test MSE 391.3003848528609 Test RE 1.0083649001472255\n",
      "9 Train Loss 2.5096953 Test MSE 391.739840700533 Test RE 1.0089309710258003\n",
      "10 Train Loss 2.472881 Test MSE 389.6986394131236 Test RE 1.0062989679524503\n",
      "11 Train Loss 2.4617217 Test MSE 388.6407827848522 Test RE 1.004932215119529\n",
      "12 Train Loss 2.4396636 Test MSE 386.08096675003685 Test RE 1.0016172111078876\n",
      "13 Train Loss 2.4209867 Test MSE 385.1885360588378 Test RE 1.0004589163912985\n",
      "14 Train Loss 2.3895104 Test MSE 384.2291499806189 Test RE 0.9992122220198921\n",
      "15 Train Loss 2.3783119 Test MSE 382.54870130123993 Test RE 0.997024771090529\n",
      "16 Train Loss 2.3743057 Test MSE 381.5734978150717 Test RE 0.9957531389101185\n",
      "17 Train Loss 2.3480918 Test MSE 374.26714079104903 Test RE 0.986173736257903\n",
      "18 Train Loss 2.326845 Test MSE 371.77260592271966 Test RE 0.9828817592940984\n",
      "19 Train Loss 2.252415 Test MSE 357.88228003947705 Test RE 0.9643455489779043\n",
      "20 Train Loss 2.162015 Test MSE 336.3276195080988 Test RE 0.9348541261922337\n",
      "21 Train Loss 2.089968 Test MSE 326.8011430790788 Test RE 0.921519152788739\n",
      "22 Train Loss 1.91342 Test MSE 283.1526894779158 Test RE 0.8577740984794502\n",
      "23 Train Loss 1.6615032 Test MSE 249.01883410748908 Test RE 0.8044122585579061\n",
      "24 Train Loss 1.4903423 Test MSE 213.53006863725565 Test RE 0.7448899285851864\n",
      "25 Train Loss 1.4371336 Test MSE 199.08729495566305 Test RE 0.7192574275639221\n",
      "26 Train Loss 1.1330322 Test MSE 158.87682264477272 Test RE 0.6425291797470756\n",
      "27 Train Loss 1.0449748 Test MSE 153.39905688493852 Test RE 0.6313554406201205\n",
      "28 Train Loss 1.0291268 Test MSE 144.3002170810635 Test RE 0.6123448571859103\n",
      "29 Train Loss 0.996274 Test MSE 131.21288335506696 Test RE 0.583916600264851\n",
      "30 Train Loss 0.7746752 Test MSE 109.59534837725509 Test RE 0.5336526167101301\n",
      "31 Train Loss 0.657937 Test MSE 90.56211395004507 Test RE 0.4851051198947241\n",
      "32 Train Loss 0.5882161 Test MSE 72.46350291045864 Test RE 0.4339325660905112\n",
      "33 Train Loss 0.5409967 Test MSE 65.58049439678187 Test RE 0.4128097305587436\n",
      "34 Train Loss 0.51099086 Test MSE 60.95629701891194 Test RE 0.39798973496817486\n",
      "35 Train Loss 0.42150348 Test MSE 47.7720626211677 Test RE 0.35232996362840874\n",
      "36 Train Loss 0.40467906 Test MSE 42.67389415356102 Test RE 0.3329996065449708\n",
      "37 Train Loss 0.36734283 Test MSE 28.075406273107333 Test RE 0.2701006363092335\n",
      "38 Train Loss 0.21376908 Test MSE 25.72351043987534 Test RE 0.2585399737396311\n",
      "39 Train Loss 0.14720497 Test MSE 18.197707184745994 Test RE 0.21745576151579465\n",
      "40 Train Loss 0.121510684 Test MSE 9.56800213285463 Test RE 0.15767876664534058\n",
      "41 Train Loss 0.1111341 Test MSE 8.878895701957182 Test RE 0.1518945038953573\n",
      "42 Train Loss 0.09948005 Test MSE 5.330594524992474 Test RE 0.11769293870096321\n",
      "43 Train Loss 0.08900999 Test MSE 4.855489620056977 Test RE 0.11232569063820345\n",
      "44 Train Loss 0.08749911 Test MSE 6.060551591217145 Test RE 0.12549275648612523\n",
      "45 Train Loss 0.08483939 Test MSE 6.440540659017627 Test RE 0.1293670710790577\n",
      "46 Train Loss 0.05571692 Test MSE 3.153665489747929 Test RE 0.09052538809491975\n",
      "47 Train Loss 0.028797504 Test MSE 0.7369804476048101 Test RE 0.04376133532735566\n",
      "48 Train Loss 0.023330625 Test MSE 0.5945406459535302 Test RE 0.03930550295072614\n",
      "49 Train Loss 0.019678188 Test MSE 0.6022220282516865 Test RE 0.03955859889370053\n",
      "50 Train Loss 0.015762987 Test MSE 0.27895187537359595 Test RE 0.026923233965212113\n",
      "51 Train Loss 0.013533174 Test MSE 0.3347713891007635 Test RE 0.02949420875000939\n",
      "52 Train Loss 0.010496004 Test MSE 0.4015572138717093 Test RE 0.032302512162916665\n",
      "53 Train Loss 0.00848886 Test MSE 0.07252488364933547 Test RE 0.013727963092222026\n",
      "54 Train Loss 0.00810015 Test MSE 0.040501271325017754 Test RE 0.010258808204165507\n",
      "55 Train Loss 0.0056603584 Test MSE 0.05459517536224294 Test RE 0.011910766620976806\n",
      "56 Train Loss 0.0051521305 Test MSE 0.07837509066861012 Test RE 0.01427090814019661\n",
      "57 Train Loss 0.0051020016 Test MSE 0.06557159704326596 Test RE 0.013053304322690456\n",
      "58 Train Loss 0.0050964276 Test MSE 0.06338180290212808 Test RE 0.012833492963517459\n",
      "59 Train Loss 0.005092479 Test MSE 0.06203536092471981 Test RE 0.012696448026040348\n",
      "60 Train Loss 0.0050899233 Test MSE 0.06095749958239823 Test RE 0.012585664623643909\n",
      "61 Train Loss 0.0050874203 Test MSE 0.06027612899262509 Test RE 0.012515126950132863\n",
      "62 Train Loss 0.0050874203 Test MSE 0.06027612899262509 Test RE 0.012515126950132863\n",
      "63 Train Loss 0.0050874203 Test MSE 0.06027612899262509 Test RE 0.012515126950132863\n",
      "64 Train Loss 0.0050874203 Test MSE 0.06027612899262509 Test RE 0.012515126950132863\n",
      "65 Train Loss 0.0050874203 Test MSE 0.06027612899262509 Test RE 0.012515126950132863\n",
      "66 Train Loss 0.0050874203 Test MSE 0.06027612899262509 Test RE 0.012515126950132863\n",
      "67 Train Loss 0.0050874203 Test MSE 0.06027612899262509 Test RE 0.012515126950132863\n",
      "68 Train Loss 0.0050874203 Test MSE 0.06027612899262509 Test RE 0.012515126950132863\n",
      "69 Train Loss 0.0050874203 Test MSE 0.06027612899262509 Test RE 0.012515126950132863\n",
      "70 Train Loss 0.0050874203 Test MSE 0.06027612899262509 Test RE 0.012515126950132863\n",
      "71 Train Loss 0.0050874203 Test MSE 0.06027612899262509 Test RE 0.012515126950132863\n",
      "72 Train Loss 0.0050864476 Test MSE 0.060938143215178604 Test RE 0.012583666246987885\n",
      "73 Train Loss 0.0050831866 Test MSE 0.056721483972024124 Test RE 0.012140494450966235\n",
      "74 Train Loss 0.0050831866 Test MSE 0.056721483972024124 Test RE 0.012140494450966235\n",
      "Training time: 9.42\n",
      "Training time: 9.42\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28803/129217413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training time: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0melapsed_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mmdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_loss_full\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test_mse_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_mse_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_re_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbeta_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Thresh Time\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtime_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Thresh epoch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0msavemat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "N_f = 1000\n",
    "x_coll = torch.from_numpy(colloc_pts(N_f,0)).float().to(device)\n",
    "f_hat = torch.zeros(x_coll.shape[0],1).to(device)\n",
    "\n",
    "max_reps = 1\n",
    "max_iter = 75\n",
    "\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss =[]\n",
    "    beta_val = []\n",
    "    \n",
    "    'Generate Training data'\n",
    "    torch.manual_seed(reps*36)\n",
    "     #Total number of collocation points \n",
    "    \n",
    "    \n",
    "    layers = np.array([1,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers)\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-5, \n",
    "                              tolerance_change = 1e-5, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "   \n",
    "\n",
    "    v = train_model(max_iter,reps)\n",
    "\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    beta_full.append(beta_val)    \n",
    "    \n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full, \"test_re_loss\": test_re_full, \"Time\": elapsed_time, \"beta\": beta_full, \"label\": label, \"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold,\"k\":k}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 0\n",
    "plt.plot(k_mean[:,layer_num,0],'b')\n",
    "plt.fill_between(range(0,75),k_mean[:,layer_num,0] - 0.5*k_std[:,layer_num,0],k_mean[:,layer_num,0] + 0.5*k_std[:,layer_num,0],alpha=0.3)\n",
    "plt.plot(k_mean[:,layer_num,1],'r')\n",
    "plt.fill_between(range(0,75),k_mean[:,layer_num,1] - 0.5*k_std[:,layer_num,1],k_mean[:,layer_num,1] + 0.5*k_std[:,layer_num,1],alpha=0.3)\n",
    "plt.plot(k_mean[:,layer_num,2],'g')\n",
    "plt.fill_between(range(0,75),k_mean[:,layer_num,2] - 0.5*k_std[:,layer_num,2],k_mean[:,layer_num,2] + 0.5*k_std[:,layer_num,2],alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdic = {\"v\":v}\n",
    "savemat('v_tanh.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(v)\n",
    "plt.yscale('log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
