{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "510f67c6-b225-41ba-e78a-d0a6e54ded85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "tstart= 0 \n",
    "tstop= 60 \n",
    "\n",
    "increment = 0.1 \n",
    "# Initial condition\n",
    "x_init= [0,0] \n",
    "\n",
    "t = np.arange(tstart,tstop+1,increment)\n",
    "\n",
    "c = 1 # Damping constant \n",
    "k = 1.0 # Stiffness of the spring\n",
    "m = 5 # Mass \n",
    "F0 = 100\n",
    "\n",
    "def mydiff(x, t):    \n",
    "    F =F0\n",
    "    \n",
    "    dx1dt = x[1] \n",
    "    dx2dt = (F -c*x[1] -k*x[0])/m\n",
    "    dxdt= [dx1dt, dx2dt] \n",
    "    \n",
    "    return dxdt \n",
    "\n",
    "x_full_sol = odeint(mydiff, x_init, t) \n",
    "\n",
    "x_sol = x_full_sol[:,0]\n",
    "v_sol = x_full_sol[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "level = \"low\"\n",
    "label = \"1D_SMD_rowdy_\" + level\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "\n",
    "# bc1_t = t[0].reshape(-1,1)\n",
    "# bc1_x = x_sol[0].reshape(-1,1)\n",
    "# t_bc1_train = torch.from_numpy(bc1_t).float().to(device)\n",
    "# x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "\n",
    "bc1_t = t.reshape(-1,1)\n",
    "bc1_x = x_sol.reshape(-1,1)\n",
    "t_bc1_train = torch.from_numpy(bc1_t).float().to(device)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "\n",
    "\n",
    "bc2_t = t[0].reshape(-1,1)\n",
    "t_bc2_train = torch.from_numpy(bc2_t).float().to(device)\n",
    "bc2_val = v_sol[0].reshape(-1,1)\n",
    "bc2_val =torch.from_numpy(bc2_val).float().to(device)\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "x_true = x_sol\n",
    "x_true_norm = np.linalg.norm(x_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(t[0]) \n",
    "ub = np.array(t[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    \n",
    "    t01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=t01,random_state =seed)\n",
    "\n",
    "    t_coll = lb + (ub-lb)*sampling(N_f)\n",
    "    # t_coll = np.vstack((t_coll,)) # append training points to collocation points \n",
    "\n",
    "    return t_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "            \n",
    "        self.k = Parameter(torch.tensor(0.0))\n",
    "        self.k.requiresGrad = True\n",
    "        self.c = Parameter(torch.tensor(0.0))\n",
    "        self.c.requiresGrad = True\n",
    "        self.m = Parameter(torch.tensor(0.0))\n",
    "        self.m.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = 2.0*(x - l_b)/(u_b - l_b)-1.0  #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,t,x):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(t), x)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,t_bc2,bc2_val):\n",
    "        g = t_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        x = self.forward(g)    \n",
    "            \n",
    "        x_t = autograd.grad(x,g,torch.ones([t_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        bc2 = dx_dt\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self,t_coll,f_hat):\n",
    "             \n",
    "        g = t_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        x = self.forward(g) \n",
    "\n",
    "        x_t = autograd.grad(x,g,torch.ones([t_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        x_tt = autograd.grad(x_t,g,torch.ones(t_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        dx2_d2t = x_tt[:,[0]]\n",
    "        \n",
    "        f = self.m*dx2_d2t + self.c*dx_dt + self.k*x - F0\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,t_bc1,x_bc1,t_bc2,bc2_val,t_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(t_bc1,x_bc1)\n",
    "        loss_bc2 = self.loss_BC2(t_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(t_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        x_pred = self.forward(t_test_tensor)\n",
    "        x_pred = x_pred.cpu().detach().numpy()\n",
    "\n",
    "        return x_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        x_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(x_pred.reshape(-1,1) - x_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(x_pred.reshape(-1,1) - x_true.reshape(-1,1),2)/x_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    m_val.append(PINN.m.cpu().detach().numpy())\n",
    "    k_val.append(PINN.k.cpu().detach().numpy())\n",
    "    c_val.append(PINN.c.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    t_coll = colloc_pts(N_f,rep*11)\n",
    "    t_coll =  torch.from_numpy(t_coll).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(t_coll.shape[0],1).to(device)\n",
    "    for i in range(max_iter):      \n",
    "        train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "         \n",
    "        loss_np = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test RE\",test_re_loss[-1],\"c\",PINN.c.cpu().detach().numpy(),\"k\",PINN.k.cpu().detach().numpy(),\"m\",PINN.m.cpu().detach().numpy())\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "42720d97-b37a-4c42-b7e5-b77a0ef391f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 3930.033 Test RE 0.5051963485365997 c -0.36962095 k 1.2444597 m -3.249228e-05\n",
      "1 Train Loss 956.2251 Test RE 0.28003299100848594 c -0.39378062 k 1.2652538 m -3.209256e-05\n",
      "2 Train Loss 578.70386 Test RE 0.20784159430613983 c -0.3893874 k 1.2522954 m -1.8561968e-05\n",
      "3 Train Loss 469.8708 Test RE 0.17328182173615525 c -0.38367856 k 1.2157497 m 0.000115807416\n",
      "4 Train Loss 386.23788 Test RE 0.16453648162450032 c -0.38308072 k 1.1501596 m 0.00055363134\n",
      "5 Train Loss 313.18338 Test RE 0.14801556888982784 c -0.382552 k 1.0824671 m 0.0011800381\n",
      "6 Train Loss 275.51608 Test RE 0.1280757167470582 c -0.38161075 k 1.0321956 m 0.0020684954\n",
      "7 Train Loss 268.54303 Test RE 0.12234259549908211 c -0.38089085 k 1.0122181 m 0.002908237\n",
      "8 Train Loss 267.1559 Test RE 0.12069546544793408 c -0.38010833 k 1.0035933 m 0.0035304988\n",
      "9 Train Loss 265.18436 Test RE 0.12021270465575593 c -0.37783647 k 1.0011284 m 0.0047490066\n",
      "10 Train Loss 264.37225 Test RE 0.1171144099617454 c -0.3752964 k 0.9980048 m 0.0060126726\n",
      "11 Train Loss 264.16202 Test RE 0.11714925034418112 c -0.3726384 k 0.9951267 m 0.007382906\n",
      "12 Train Loss 263.9746 Test RE 0.1178461282491989 c -0.3691633 k 0.9964156 m 0.009241791\n",
      "13 Train Loss 263.89407 Test RE 0.11762948341787899 c -0.3675213 k 0.9963935 m 0.010184388\n",
      "14 Train Loss 263.60208 Test RE 0.1167606635058968 c -0.36349222 k 0.9951041 m 0.012923975\n",
      "15 Train Loss 263.06543 Test RE 0.11801397443623618 c -0.35758814 k 0.9979211 m 0.017159712\n",
      "16 Train Loss 262.4697 Test RE 0.11656462482386493 c -0.34748322 k 0.9979693 m 0.02421501\n",
      "17 Train Loss 261.7082 Test RE 0.11627898942129271 c -0.33190718 k 0.994305 m 0.034563746\n",
      "18 Train Loss 261.01575 Test RE 0.11618244934821975 c -0.32415172 k 0.9964921 m 0.03912375\n",
      "19 Train Loss 260.45013 Test RE 0.11569392306141894 c -0.31741542 k 1.00026 m 0.0427983\n",
      "20 Train Loss 259.5026 Test RE 0.11658445900817838 c -0.3043677 k 0.99651396 m 0.050984565\n",
      "21 Train Loss 257.77557 Test RE 0.11467677717962893 c -0.27747443 k 0.9924982 m 0.069115505\n",
      "22 Train Loss 256.19037 Test RE 0.11344109884527989 c -0.25276148 k 0.99688244 m 0.08633357\n",
      "23 Train Loss 253.75644 Test RE 0.11267410758284797 c -0.2179179 k 0.99607533 m 0.111232035\n",
      "24 Train Loss 251.83994 Test RE 0.11531332098042343 c -0.18174344 k 0.9928204 m 0.13755809\n",
      "25 Train Loss 247.14052 Test RE 0.1102718033820878 c -0.124819964 k 0.9887791 m 0.17956121\n",
      "26 Train Loss 244.62015 Test RE 0.1107953658128246 c -0.09189191 k 0.9974691 m 0.20211808\n",
      "27 Train Loss 241.35938 Test RE 0.10932310942258866 c -0.05454521 k 0.99078965 m 0.22820558\n",
      "28 Train Loss 237.73943 Test RE 0.10545527252682152 c -0.0031971652 k 0.99308205 m 0.26491058\n",
      "29 Train Loss 234.62549 Test RE 0.10509175211466787 c 0.03705 k 0.9926397 m 0.29512236\n",
      "30 Train Loss 231.17198 Test RE 0.1059594451754731 c 0.10039068 k 0.9924686 m 0.34276843\n",
      "31 Train Loss 226.71521 Test RE 0.10260873519077927 c 0.15896802 k 0.9935037 m 0.38616702\n",
      "32 Train Loss 223.59564 Test RE 0.10317848260430151 c 0.19408037 k 0.9832191 m 0.41297054\n",
      "33 Train Loss 219.93924 Test RE 0.10186276062532387 c 0.24552439 k 0.98553973 m 0.45231935\n",
      "34 Train Loss 216.24716 Test RE 0.09466776744942651 c 0.28832245 k 0.9917151 m 0.4848171\n",
      "35 Train Loss 213.60481 Test RE 0.09480981068494752 c 0.31415746 k 0.99294215 m 0.5040402\n",
      "36 Train Loss 211.90773 Test RE 0.09704913560085313 c 0.34013355 k 0.99366117 m 0.52374107\n",
      "37 Train Loss 207.9148 Test RE 0.0953015167840282 c 0.39690706 k 0.9881293 m 0.5688526\n",
      "38 Train Loss 203.82593 Test RE 0.09092164952118073 c 0.44587272 k 0.9841562 m 0.60802686\n",
      "39 Train Loss 200.28494 Test RE 0.09070632290402299 c 0.48361105 k 0.9885998 m 0.6381428\n",
      "40 Train Loss 194.14697 Test RE 0.09265177218134196 c 0.55895895 k 0.98205346 m 0.69899344\n",
      "41 Train Loss 189.86807 Test RE 0.08573839775884373 c 0.595918 k 0.97785497 m 0.7289576\n",
      "42 Train Loss 186.42584 Test RE 0.08469303871282832 c 0.6423908 k 0.97832495 m 0.7670885\n",
      "43 Train Loss 182.60663 Test RE 0.08473512217304607 c 0.6620499 k 0.9845967 m 0.78340065\n",
      "44 Train Loss 179.90099 Test RE 0.08569291998589618 c 0.67785037 k 0.9864559 m 0.79640806\n",
      "45 Train Loss 172.393 Test RE 0.08757675634202564 c 0.73969376 k 0.97544396 m 0.84983754\n",
      "46 Train Loss 166.452 Test RE 0.08179415022265064 c 0.77159524 k 0.9676659 m 0.8775324\n",
      "47 Train Loss 162.98203 Test RE 0.0807497120658331 c 0.80892456 k 0.9642943 m 0.90944207\n",
      "48 Train Loss 156.77771 Test RE 0.07965786578387725 c 0.8619608 k 0.97730285 m 0.9531398\n",
      "49 Train Loss 152.76605 Test RE 0.07591648629464358 c 0.9008993 k 0.98561025 m 0.98596007\n",
      "50 Train Loss 143.84268 Test RE 0.07430787001132123 c 0.9648862 k 0.97492725 m 1.0417876\n",
      "51 Train Loss 140.04453 Test RE 0.07547455678607917 c 0.9813686 k 0.9687627 m 1.0566351\n",
      "52 Train Loss 135.80081 Test RE 0.07427877758247527 c 1.0024118 k 0.974606 m 1.0754116\n",
      "53 Train Loss 133.88092 Test RE 0.07512958160976829 c 1.0307758 k 0.9799034 m 1.1003377\n",
      "54 Train Loss 130.8934 Test RE 0.07600379128516765 c 1.0599078 k 0.98563105 m 1.1253899\n",
      "55 Train Loss 127.32624 Test RE 0.07407847030657445 c 1.0950166 k 0.9757623 m 1.1558548\n",
      "56 Train Loss 122.7607 Test RE 0.0711649707795112 c 1.1267359 k 0.9700147 m 1.1840223\n",
      "57 Train Loss 120.23919 Test RE 0.07307091482490506 c 1.1399558 k 0.97542095 m 1.1956904\n",
      "58 Train Loss 116.89531 Test RE 0.0708394827165961 c 1.1676424 k 0.9772541 m 1.220192\n",
      "59 Train Loss 115.202705 Test RE 0.07208180135480412 c 1.1817664 k 0.9725088 m 1.2331659\n",
      "60 Train Loss 111.77263 Test RE 0.07287148054393085 c 1.2100387 k 0.9718924 m 1.2573161\n",
      "61 Train Loss 110.33464 Test RE 0.07154312459827677 c 1.2235583 k 0.9754213 m 1.268485\n",
      "62 Train Loss 108.36461 Test RE 0.06969074165495434 c 1.2490685 k 0.97643834 m 1.290616\n",
      "63 Train Loss 106.71443 Test RE 0.06978687962199075 c 1.2738739 k 0.9757426 m 1.3127029\n",
      "64 Train Loss 105.72618 Test RE 0.07053999011197261 c 1.2863932 k 0.9735752 m 1.3244056\n",
      "65 Train Loss 104.57213 Test RE 0.0707755073296124 c 1.3073735 k 0.97135663 m 1.3436894\n",
      "66 Train Loss 102.484344 Test RE 0.07111184655204233 c 1.3460475 k 0.97082996 m 1.3787767\n",
      "67 Train Loss 100.586 Test RE 0.06783903674218321 c 1.3833091 k 0.97634655 m 1.4117963\n",
      "68 Train Loss 98.78227 Test RE 0.07013345239488446 c 1.420233 k 0.9757146 m 1.4449642\n",
      "69 Train Loss 97.29013 Test RE 0.06877057281709557 c 1.4417163 k 0.97080755 m 1.464197\n",
      "70 Train Loss 95.787735 Test RE 0.06959304090273709 c 1.4746212 k 0.96880084 m 1.4940695\n",
      "71 Train Loss 94.655914 Test RE 0.06846113166984953 c 1.5108821 k 0.9672098 m 1.5271964\n",
      "72 Train Loss 93.593445 Test RE 0.0673650348166572 c 1.5363832 k 0.97085845 m 1.5499352\n",
      "73 Train Loss 92.72986 Test RE 0.06847439629629158 c 1.5581886 k 0.9725142 m 1.5692363\n",
      "74 Train Loss 92.10005 Test RE 0.06783760448539736 c 1.5865154 k 0.9693365 m 1.5948867\n",
      "75 Train Loss 91.005455 Test RE 0.06727915630345456 c 1.6222844 k 0.9669427 m 1.6283681\n",
      "76 Train Loss 89.87448 Test RE 0.0675795160439761 c 1.6660335 k 0.96716106 m 1.6695695\n",
      "77 Train Loss 89.392715 Test RE 0.06788969842801157 c 1.6963656 k 0.97008526 m 1.6976753\n",
      "78 Train Loss 88.72601 Test RE 0.06779297934337458 c 1.7261945 k 0.9754531 m 1.7252424\n",
      "79 Train Loss 88.33386 Test RE 0.06800746385379965 c 1.7398541 k 0.9790389 m 1.7385213\n",
      "80 Train Loss 87.57555 Test RE 0.06771828279498335 c 1.7525053 k 0.97705615 m 1.7526742\n",
      "81 Train Loss 86.74729 Test RE 0.06738528497069762 c 1.7587343 k 0.9718142 m 1.7618208\n",
      "82 Train Loss 86.53433 Test RE 0.0678218701636927 c 1.7696006 k 0.9730409 m 1.772362\n",
      "83 Train Loss 86.2914 Test RE 0.06780025918214964 c 1.7932488 k 0.9719932 m 1.7950892\n",
      "84 Train Loss 86.18199 Test RE 0.06775535794222565 c 1.803995 k 0.97078395 m 1.8059118\n",
      "85 Train Loss 86.09334 Test RE 0.06765748373907751 c 1.8141423 k 0.97258556 m 1.8158783\n",
      "86 Train Loss 85.992325 Test RE 0.06749352863107354 c 1.8222128 k 0.9729745 m 1.8244271\n",
      "87 Train Loss 85.91231 Test RE 0.06758085406947936 c 1.8300972 k 0.97139686 m 1.8329525\n",
      "88 Train Loss 85.81625 Test RE 0.06775928348759071 c 1.8420807 k 0.97169334 m 1.845944\n",
      "89 Train Loss 85.67758 Test RE 0.06785703510051212 c 1.8431102 k 0.9731281 m 1.848303\n",
      "90 Train Loss 85.60163 Test RE 0.0674629918822372 c 1.8393021 k 0.97274643 m 1.8452976\n",
      "91 Train Loss 85.539734 Test RE 0.06763055668603958 c 1.8369861 k 0.9727176 m 1.8442255\n",
      "92 Train Loss 85.50908 Test RE 0.0676237853939219 c 1.8345767 k 0.9728914 m 1.8428699\n",
      "93 Train Loss 85.49106 Test RE 0.06759129898126015 c 1.8333905 k 0.97238934 m 1.8425167\n",
      "94 Train Loss 85.417206 Test RE 0.06746641260733378 c 1.8283997 k 0.97303754 m 1.841045\n",
      "95 Train Loss 85.386246 Test RE 0.0674335017294922 c 1.8259144 k 0.9731329 m 1.8400245\n",
      "96 Train Loss 85.324356 Test RE 0.06730958761836257 c 1.8205917 k 0.97123486 m 1.8386767\n",
      "97 Train Loss 85.18731 Test RE 0.06716475216687767 c 1.8152312 k 0.97091997 m 1.841515\n",
      "98 Train Loss 85.014404 Test RE 0.06737609087040212 c 1.809048 k 0.9738914 m 1.8434058\n",
      "99 Train Loss 84.84858 Test RE 0.06721167776172166 c 1.7855755 k 0.9739306 m 1.8287594\n",
      "100 Train Loss 84.575714 Test RE 0.06670932918050688 c 1.7501704 k 0.97365266 m 1.8053705\n",
      "101 Train Loss 84.47923 Test RE 0.06681662907800617 c 1.7553028 k 0.97367597 m 1.8113246\n",
      "102 Train Loss 84.34274 Test RE 0.06686929119341868 c 1.7553164 k 0.971433 m 1.8174933\n",
      "103 Train Loss 84.04826 Test RE 0.06643603620284427 c 1.738221 k 0.9728149 m 1.8160965\n",
      "104 Train Loss 83.66602 Test RE 0.06627283630770384 c 1.740756 k 0.97307974 m 1.8359034\n",
      "105 Train Loss 83.315285 Test RE 0.06605356354394941 c 1.7429875 k 0.971077 m 1.851996\n",
      "106 Train Loss 82.91636 Test RE 0.0656224213246521 c 1.7373364 k 0.9693157 m 1.8567243\n",
      "107 Train Loss 82.392624 Test RE 0.06621504088794562 c 1.7436522 k 0.9703239 m 1.8700674\n",
      "108 Train Loss 82.17243 Test RE 0.06511753677931471 c 1.744679 k 0.9714216 m 1.8767896\n",
      "109 Train Loss 81.68849 Test RE 0.06520351578288604 c 1.7275435 k 0.97310364 m 1.8801308\n",
      "110 Train Loss 81.20373 Test RE 0.06484980822805463 c 1.7241167 k 0.9753897 m 1.8935608\n",
      "111 Train Loss 80.82538 Test RE 0.06501267802327074 c 1.7286111 k 0.9762163 m 1.9154913\n",
      "112 Train Loss 80.61195 Test RE 0.06381923226872736 c 1.732834 k 0.97416544 m 1.9302734\n",
      "113 Train Loss 80.30568 Test RE 0.06407958846780214 c 1.7394271 k 0.9719578 m 1.9445753\n",
      "114 Train Loss 79.98036 Test RE 0.06516020564326662 c 1.7463413 k 0.9752497 m 1.9623752\n",
      "115 Train Loss 79.77736 Test RE 0.0644591488027687 c 1.7498999 k 0.9752799 m 1.9750532\n",
      "116 Train Loss 79.47009 Test RE 0.06388998513981295 c 1.7505686 k 0.97493416 m 1.9848348\n",
      "117 Train Loss 79.058304 Test RE 0.06349291593734385 c 1.7605972 k 0.9757462 m 2.0065026\n",
      "118 Train Loss 78.46092 Test RE 0.06447970245058701 c 1.7698798 k 0.9715636 m 2.0373402\n",
      "119 Train Loss 77.78352 Test RE 0.06499559619792805 c 1.7641562 k 0.9730008 m 2.0558345\n",
      "120 Train Loss 77.217316 Test RE 0.062334158739166465 c 1.7643396 k 0.9769122 m 2.0763032\n",
      "121 Train Loss 76.95009 Test RE 0.06307322510067595 c 1.7623612 k 0.97861457 m 2.0816634\n",
      "122 Train Loss 76.47752 Test RE 0.06298557846845952 c 1.7572976 k 0.9780085 m 2.084658\n",
      "123 Train Loss 76.003525 Test RE 0.061696214581889 c 1.7500622 k 0.9737825 m 2.0933266\n",
      "124 Train Loss 75.72119 Test RE 0.06120082115585967 c 1.7372761 k 0.97157484 m 2.099709\n",
      "125 Train Loss 74.94568 Test RE 0.0621498407404657 c 1.70484 k 0.97697294 m 2.1091216\n",
      "126 Train Loss 74.32889 Test RE 0.06117400933838833 c 1.6874183 k 0.97628415 m 2.1188953\n",
      "127 Train Loss 73.73306 Test RE 0.05968622978370158 c 1.686738 k 0.9711397 m 2.1316738\n",
      "128 Train Loss 72.87903 Test RE 0.06013019025659436 c 1.6876312 k 0.9705367 m 2.1560395\n",
      "129 Train Loss 71.934975 Test RE 0.05999454946105215 c 1.687182 k 0.97650284 m 2.182848\n",
      "130 Train Loss 71.38661 Test RE 0.05882601783254341 c 1.6897134 k 0.97703546 m 2.1933498\n",
      "131 Train Loss 70.61172 Test RE 0.05863722898897431 c 1.676744 k 0.97555876 m 2.196179\n",
      "132 Train Loss 69.9004 Test RE 0.05898626397047285 c 1.6644429 k 0.97932297 m 2.2145467\n",
      "133 Train Loss 68.88964 Test RE 0.05830087277587519 c 1.6601021 k 0.97818226 m 2.2567983\n",
      "134 Train Loss 67.66386 Test RE 0.05648874488846037 c 1.65658 k 0.97881126 m 2.2936835\n",
      "135 Train Loss 66.47125 Test RE 0.05736576705682172 c 1.6563414 k 0.9764104 m 2.3197792\n",
      "136 Train Loss 65.68358 Test RE 0.05685460290922127 c 1.6653016 k 0.97753006 m 2.3477483\n",
      "137 Train Loss 64.75619 Test RE 0.05486627270391021 c 1.6811517 k 0.9784483 m 2.3920417\n",
      "138 Train Loss 64.272896 Test RE 0.05576447194495215 c 1.6951011 k 0.97312164 m 2.4212146\n",
      "139 Train Loss 63.67768 Test RE 0.05598051141972594 c 1.7106129 k 0.9731257 m 2.456661\n",
      "140 Train Loss 62.837284 Test RE 0.05514068812305485 c 1.7216988 k 0.9789646 m 2.499933\n",
      "141 Train Loss 61.743835 Test RE 0.05391052985894362 c 1.7461369 k 0.974247 m 2.5685465\n",
      "142 Train Loss 60.79823 Test RE 0.054244357190619145 c 1.745076 k 0.9755933 m 2.601704\n",
      "143 Train Loss 59.936493 Test RE 0.05395804798142067 c 1.7391636 k 0.980953 m 2.6356366\n",
      "144 Train Loss 59.272816 Test RE 0.05249342930746449 c 1.7358155 k 0.98114043 m 2.6639397\n",
      "145 Train Loss 58.356033 Test RE 0.05240469577845578 c 1.7139186 k 0.98190564 m 2.6844816\n",
      "146 Train Loss 56.88121 Test RE 0.05149732306617915 c 1.6757637 k 0.97936106 m 2.6977518\n",
      "147 Train Loss 55.698006 Test RE 0.05048427042505388 c 1.6421627 k 0.97972906 m 2.6917489\n",
      "148 Train Loss 54.989365 Test RE 0.05001889492860923 c 1.6219673 k 0.97975475 m 2.6821513\n",
      "149 Train Loss 53.905594 Test RE 0.049173760014471324 c 1.6244553 k 0.97463423 m 2.7102232\n",
      "150 Train Loss 52.5544 Test RE 0.04924189257049183 c 1.6059875 k 0.97843087 m 2.7281702\n",
      "151 Train Loss 51.942535 Test RE 0.048916626316798446 c 1.5999111 k 0.97801644 m 2.7339938\n",
      "152 Train Loss 50.923935 Test RE 0.04769694681779795 c 1.5874622 k 0.97923964 m 2.7556772\n",
      "153 Train Loss 49.774822 Test RE 0.0474826064863329 c 1.5657676 k 0.9787277 m 2.7735693\n",
      "154 Train Loss 49.056206 Test RE 0.04734976947866606 c 1.5496546 k 0.9753879 m 2.7844415\n",
      "155 Train Loss 48.28572 Test RE 0.04705676808501547 c 1.5273521 k 0.97666675 m 2.7980535\n",
      "156 Train Loss 47.612396 Test RE 0.04640074095450357 c 1.5120502 k 0.9788403 m 2.8144763\n",
      "157 Train Loss 46.900665 Test RE 0.046034647109802214 c 1.5180559 k 0.97821254 m 2.8544457\n",
      "158 Train Loss 45.372894 Test RE 0.045774066917576656 c 1.5222013 k 0.9806744 m 2.905035\n",
      "159 Train Loss 44.284256 Test RE 0.04356187875693845 c 1.5119331 k 0.9819528 m 2.9218688\n",
      "160 Train Loss 43.27568 Test RE 0.043394499780727125 c 1.5112325 k 0.9788297 m 2.9533694\n",
      "161 Train Loss 42.479828 Test RE 0.04313033406763857 c 1.5124274 k 0.9773792 m 2.9752247\n",
      "162 Train Loss 41.067238 Test RE 0.04306827316535717 c 1.5128983 k 0.980386 m 3.0237725\n",
      "163 Train Loss 40.092743 Test RE 0.041881667840335375 c 1.5085953 k 0.978153 m 3.0646937\n",
      "164 Train Loss 39.026806 Test RE 0.04255249867055883 c 1.4972147 k 0.97943497 m 3.091032\n",
      "165 Train Loss 37.567368 Test RE 0.04153796154350442 c 1.487348 k 0.9819948 m 3.1206727\n",
      "166 Train Loss 36.524273 Test RE 0.03855632416833998 c 1.4671305 k 0.97833323 m 3.1449192\n",
      "167 Train Loss 35.37607 Test RE 0.03852690388780576 c 1.4313785 k 0.97628903 m 3.1664073\n",
      "168 Train Loss 34.5504 Test RE 0.03831397894735605 c 1.4059957 k 0.9781219 m 3.1897357\n",
      "169 Train Loss 33.53271 Test RE 0.036506203763173796 c 1.3941941 k 0.98062307 m 3.2043703\n",
      "170 Train Loss 32.588654 Test RE 0.037005265986476424 c 1.3877883 k 0.9803161 m 3.2196674\n",
      "171 Train Loss 30.799662 Test RE 0.034738597101923945 c 1.3515749 k 0.9829573 m 3.2639592\n",
      "172 Train Loss 29.317799 Test RE 0.03400113925657036 c 1.3350966 k 0.9854583 m 3.3168714\n",
      "173 Train Loss 26.996868 Test RE 0.03271969320323703 c 1.3293436 k 0.98283803 m 3.3758476\n",
      "174 Train Loss 25.941158 Test RE 0.03158551495193122 c 1.3263618 k 0.98321426 m 3.4137974\n",
      "175 Train Loss 25.205822 Test RE 0.030993078191090113 c 1.3283857 k 0.98280483 m 3.4600415\n",
      "176 Train Loss 23.537586 Test RE 0.030124158878310235 c 1.3197135 k 0.98408777 m 3.5441196\n",
      "177 Train Loss 21.830723 Test RE 0.0286770191662556 c 1.3195145 k 0.9824251 m 3.5952096\n",
      "178 Train Loss 20.629457 Test RE 0.029633920743139457 c 1.3224491 k 0.9827698 m 3.622335\n",
      "179 Train Loss 20.033928 Test RE 0.028352574091220863 c 1.3273259 k 0.9829194 m 3.657666\n",
      "180 Train Loss 19.404623 Test RE 0.02831843861111091 c 1.3261721 k 0.9861816 m 3.6942885\n",
      "181 Train Loss 18.468056 Test RE 0.02804476748240015 c 1.3216996 k 0.98933685 m 3.7433128\n",
      "182 Train Loss 17.027075 Test RE 0.02458028247669496 c 1.319585 k 0.9900795 m 3.8300197\n",
      "183 Train Loss 15.915043 Test RE 0.02416841624676427 c 1.3292435 k 0.98593694 m 3.9014788\n",
      "184 Train Loss 14.726963 Test RE 0.022784890272599584 c 1.3280035 k 0.9861601 m 3.9552748\n",
      "185 Train Loss 13.95892 Test RE 0.023201125383897087 c 1.3182611 k 0.985916 m 3.9972558\n",
      "186 Train Loss 13.608321 Test RE 0.022589041335985046 c 1.3107625 k 0.98703206 m 4.000744\n",
      "187 Train Loss 12.926903 Test RE 0.0214713531023977 c 1.2865424 k 0.99041027 m 4.0210156\n",
      "188 Train Loss 12.033388 Test RE 0.019747298968827764 c 1.2656937 k 0.9888284 m 4.074785\n",
      "189 Train Loss 11.405496 Test RE 0.018323479920942253 c 1.2428013 k 0.98748255 m 4.1233945\n",
      "190 Train Loss 10.264248 Test RE 0.019055888644306167 c 1.2194189 k 0.990883 m 4.1794047\n",
      "191 Train Loss 8.934332 Test RE 0.016100059792068567 c 1.2069862 k 0.9939222 m 4.2390327\n",
      "192 Train Loss 7.648884 Test RE 0.014628737580367392 c 1.1805426 k 0.9913192 m 4.306523\n",
      "193 Train Loss 6.6071157 Test RE 0.012438935036830825 c 1.1419706 k 0.9920021 m 4.349822\n",
      "194 Train Loss 5.9950695 Test RE 0.011175204397537069 c 1.1280175 k 0.994073 m 4.366529\n",
      "195 Train Loss 5.569147 Test RE 0.011420408267151402 c 1.1172991 k 0.99454266 m 4.383031\n",
      "196 Train Loss 5.2435484 Test RE 0.010906002155954962 c 1.0945109 k 0.99710923 m 4.414475\n",
      "197 Train Loss 4.786475 Test RE 0.010713156961608997 c 1.0725818 k 0.9964052 m 4.466675\n",
      "198 Train Loss 3.988089 Test RE 0.010186201582741462 c 1.0550187 k 0.9919885 m 4.536602\n",
      "199 Train Loss 3.0232222 Test RE 0.00875816764172062 c 1.0480169 k 0.98953295 m 4.589792\n",
      "Training time: 84.08\n",
      "Training time: 84.08\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 8389.592 Test RE 0.5830891120110022 c -0.3202582 k 0.69357115 m -4.2609125e-05\n",
      "1 Train Loss 5623.5215 Test RE 0.44931249978381926 c -0.32813603 k 0.7205136 m -4.165244e-05\n",
      "2 Train Loss 4010.5103 Test RE 0.3796732344125798 c -0.33990848 k 0.76744366 m -3.5588004e-05\n",
      "3 Train Loss 2430.1484 Test RE 0.28971860715811826 c -0.34647414 k 0.8078896 m -1.8950614e-05\n",
      "4 Train Loss 1299.4651 Test RE 0.21739006130329253 c -0.35583377 k 0.8645952 m 5.673017e-06\n",
      "5 Train Loss 568.81726 Test RE 0.14971034127205846 c -0.3659734 k 0.94355196 m 5.4660573e-05\n",
      "6 Train Loss 308.42993 Test RE 0.12305837506932785 c -0.3707944 k 1.0032593 m 0.00012038776\n",
      "7 Train Loss 273.8648 Test RE 0.1236591167790186 c -0.37233216 k 1.0210327 m 0.00016861927\n",
      "8 Train Loss 268.75198 Test RE 0.12039574349646891 c -0.3723164 k 1.0185797 m 0.00026736318\n",
      "9 Train Loss 266.34808 Test RE 0.12008320585427693 c -0.37141797 k 1.0112557 m 0.00042803935\n",
      "10 Train Loss 265.1842 Test RE 0.11903068694637496 c -0.37099445 k 1.0092205 m 0.0006418831\n",
      "11 Train Loss 264.45743 Test RE 0.1181266785991346 c -0.37025765 k 1.0050527 m 0.0009889605\n",
      "12 Train Loss 264.18192 Test RE 0.11813717399582765 c -0.36987826 k 1.0030094 m 0.0012686584\n",
      "13 Train Loss 263.93716 Test RE 0.11770053288174953 c -0.368952 k 1.0002418 m 0.001742671\n",
      "14 Train Loss 263.74246 Test RE 0.11695162915693498 c -0.36744848 k 0.9973018 m 0.002501267\n",
      "15 Train Loss 263.6656 Test RE 0.11715949952172729 c -0.36676732 k 0.99628556 m 0.002957439\n",
      "16 Train Loss 263.53397 Test RE 0.11701276872974439 c -0.3651685 k 0.996083 m 0.004102608\n",
      "17 Train Loss 263.37964 Test RE 0.11708906497068547 c -0.3635276 k 0.9976588 m 0.0053229104\n",
      "18 Train Loss 263.26666 Test RE 0.1172842737332491 c -0.3615279 k 0.998658 m 0.0067036827\n",
      "19 Train Loss 263.12512 Test RE 0.1168496453161323 c -0.35917792 k 0.9997525 m 0.0082841115\n",
      "20 Train Loss 262.81683 Test RE 0.11619493716842876 c -0.35414883 k 0.99762505 m 0.011060447\n",
      "21 Train Loss 262.54156 Test RE 0.11658082612468706 c -0.3504348 k 0.99821746 m 0.012880083\n",
      "22 Train Loss 262.24057 Test RE 0.11637744276865448 c -0.34468016 k 1.0016567 m 0.016571717\n",
      "23 Train Loss 261.59378 Test RE 0.11621151230369059 c -0.336798 k 0.9983574 m 0.021955624\n",
      "24 Train Loss 261.29376 Test RE 0.11565376067481305 c -0.33285415 k 0.99690914 m 0.02491758\n",
      "25 Train Loss 260.923 Test RE 0.11585295018691794 c -0.3259654 k 0.9983217 m 0.030470312\n",
      "26 Train Loss 260.51547 Test RE 0.11557833706155038 c -0.31869203 k 0.99841374 m 0.036234602\n",
      "27 Train Loss 259.67355 Test RE 0.11564418539538417 c -0.30800337 k 0.99815387 m 0.04339089\n",
      "28 Train Loss 259.29523 Test RE 0.11602545267403355 c -0.3019386 k 0.9984191 m 0.04751494\n",
      "29 Train Loss 258.85602 Test RE 0.11495258979525624 c -0.29668796 k 0.997555 m 0.05166097\n",
      "30 Train Loss 258.08508 Test RE 0.1148831653458635 c -0.2864459 k 0.99594283 m 0.05938903\n",
      "31 Train Loss 257.5689 Test RE 0.11476972283457916 c -0.2770839 k 0.9979484 m 0.066043936\n",
      "32 Train Loss 256.45984 Test RE 0.113953979512228 c -0.2595508 k 1.0019306 m 0.07866426\n",
      "33 Train Loss 255.6897 Test RE 0.11366045558717203 c -0.24520892 k 1.0034704 m 0.08930077\n",
      "34 Train Loss 255.16199 Test RE 0.11346875937827626 c -0.23705393 k 1.0010793 m 0.09539529\n",
      "35 Train Loss 254.55618 Test RE 0.11314237464994245 c -0.2317097 k 0.99729055 m 0.09909734\n",
      "36 Train Loss 253.47482 Test RE 0.11200458773210396 c -0.21643898 k 0.9958949 m 0.10946954\n",
      "37 Train Loss 252.67252 Test RE 0.1124520172063859 c -0.2042607 k 0.9975419 m 0.11816017\n",
      "38 Train Loss 251.9549 Test RE 0.11145308763365956 c -0.19245158 k 0.9976713 m 0.12697242\n",
      "39 Train Loss 250.8404 Test RE 0.11091686818676726 c -0.17496681 k 0.9954143 m 0.13967411\n",
      "40 Train Loss 248.99542 Test RE 0.11171226433518325 c -0.15136069 k 0.9942662 m 0.15730152\n",
      "41 Train Loss 247.22873 Test RE 0.10980603181698569 c -0.13055244 k 0.9925057 m 0.17290738\n",
      "42 Train Loss 246.07611 Test RE 0.10975721680766524 c -0.11757824 k 0.9921023 m 0.18262827\n",
      "43 Train Loss 244.25317 Test RE 0.10937870600952544 c -0.09424532 k 0.99145955 m 0.20051996\n",
      "44 Train Loss 242.87721 Test RE 0.10806378831663387 c -0.07249804 k 0.99331504 m 0.21675745\n",
      "45 Train Loss 241.20813 Test RE 0.10789838469680918 c -0.050952896 k 0.99827546 m 0.23288514\n",
      "46 Train Loss 240.04553 Test RE 0.10720305161716426 c -0.031374343 k 1.0009128 m 0.24697404\n",
      "47 Train Loss 238.04214 Test RE 0.10649353262944243 c -0.010108339 k 0.99763197 m 0.2626784\n",
      "48 Train Loss 237.22916 Test RE 0.104610680034402 c 0.0005587707 k 0.99518585 m 0.27060398\n",
      "49 Train Loss 236.25977 Test RE 0.10453007012450664 c 0.011790295 k 0.99124366 m 0.27908453\n",
      "50 Train Loss 235.58942 Test RE 0.10410163596138743 c 0.018773314 k 0.98963267 m 0.28464293\n",
      "51 Train Loss 234.6427 Test RE 0.1044989669338687 c 0.03463011 k 0.98737687 m 0.29708374\n",
      "52 Train Loss 232.37556 Test RE 0.10384854485525298 c 0.05707226 k 0.9870959 m 0.31481227\n",
      "53 Train Loss 230.37027 Test RE 0.10187718270059729 c 0.07894751 k 0.9902214 m 0.33221304\n",
      "54 Train Loss 229.17838 Test RE 0.10165456571743303 c 0.08997767 k 0.9911007 m 0.3409878\n",
      "55 Train Loss 227.31187 Test RE 0.10095074285021703 c 0.11018861 k 0.99079007 m 0.35724846\n",
      "56 Train Loss 225.17264 Test RE 0.1001681086691723 c 0.13593355 k 0.9919802 m 0.3772112\n",
      "57 Train Loss 223.00732 Test RE 0.10119267808385063 c 0.16216071 k 0.99553454 m 0.39760405\n",
      "58 Train Loss 221.37381 Test RE 0.09996440154467072 c 0.18716706 k 0.99761856 m 0.41706088\n",
      "59 Train Loss 218.91704 Test RE 0.09900467709208502 c 0.21338552 k 0.9981651 m 0.43726993\n",
      "60 Train Loss 216.2677 Test RE 0.09647558224419807 c 0.22982502 k 0.99843705 m 0.44982108\n",
      "61 Train Loss 213.96857 Test RE 0.0964677583320307 c 0.24776965 k 0.9950947 m 0.46382335\n",
      "62 Train Loss 211.95706 Test RE 0.09758208109915277 c 0.2699894 k 0.9917782 m 0.48164037\n",
      "63 Train Loss 209.05777 Test RE 0.09210180464169501 c 0.29038262 k 0.9887671 m 0.49903628\n",
      "64 Train Loss 207.3747 Test RE 0.0955185197303857 c 0.30548698 k 0.98578304 m 0.51180446\n",
      "65 Train Loss 204.61275 Test RE 0.09400688326104294 c 0.3211297 k 0.9855028 m 0.5247394\n",
      "66 Train Loss 201.34329 Test RE 0.09356433194725443 c 0.35312742 k 0.9831257 m 0.55219537\n",
      "67 Train Loss 199.44557 Test RE 0.09214727928999655 c 0.36742103 k 0.98336643 m 0.56402224\n",
      "68 Train Loss 197.8535 Test RE 0.0918276528129165 c 0.37526116 k 0.983896 m 0.5704116\n",
      "69 Train Loss 195.8988 Test RE 0.09182016183374832 c 0.39744368 k 0.9828139 m 0.5896316\n",
      "70 Train Loss 192.94345 Test RE 0.09005879781244755 c 0.42459095 k 0.98225147 m 0.61266357\n",
      "71 Train Loss 190.13162 Test RE 0.09165991780305656 c 0.44340873 k 0.9822926 m 0.6286682\n",
      "72 Train Loss 187.0344 Test RE 0.088806937471489 c 0.46461034 k 0.9809176 m 0.6470385\n",
      "73 Train Loss 184.0104 Test RE 0.08795134313952752 c 0.4955156 k 0.97866446 m 0.67380434\n",
      "74 Train Loss 180.5326 Test RE 0.08677737121069964 c 0.51845026 k 0.97611094 m 0.6933273\n",
      "75 Train Loss 179.2197 Test RE 0.08758491865333277 c 0.52726966 k 0.97442573 m 0.7006756\n",
      "76 Train Loss 177.46915 Test RE 0.084531979447079 c 0.54100525 k 0.9738655 m 0.7123629\n",
      "77 Train Loss 173.84436 Test RE 0.08634351928322653 c 0.5677805 k 0.9746315 m 0.7354944\n",
      "78 Train Loss 171.96655 Test RE 0.08627598963469373 c 0.58677554 k 0.9749884 m 0.7516131\n",
      "79 Train Loss 170.09213 Test RE 0.08302420130133842 c 0.6069048 k 0.97407633 m 0.7683265\n",
      "80 Train Loss 166.87668 Test RE 0.08417857389121906 c 0.6357319 k 0.973007 m 0.79192626\n",
      "81 Train Loss 165.25342 Test RE 0.08328808401362112 c 0.6514276 k 0.97311026 m 0.8047061\n",
      "82 Train Loss 161.78156 Test RE 0.08230595964202163 c 0.68787545 k 0.9724225 m 0.8349054\n",
      "83 Train Loss 159.10281 Test RE 0.08288716990328138 c 0.7109585 k 0.97298884 m 0.8543204\n",
      "84 Train Loss 157.43085 Test RE 0.08064520405904502 c 0.72608006 k 0.97364604 m 0.86686015\n",
      "85 Train Loss 154.19273 Test RE 0.08239181910625422 c 0.7557148 k 0.97553104 m 0.89135766\n",
      "86 Train Loss 149.20096 Test RE 0.08027630231403876 c 0.7912556 k 0.9777081 m 0.9210401\n",
      "87 Train Loss 146.09398 Test RE 0.07861049306275181 c 0.81613564 k 0.9790057 m 0.94194305\n",
      "88 Train Loss 143.87291 Test RE 0.07819905090570049 c 0.83318144 k 0.9796556 m 0.9564272\n",
      "89 Train Loss 142.09668 Test RE 0.07802961287322042 c 0.8511973 k 0.9803859 m 0.9714332\n",
      "90 Train Loss 141.07977 Test RE 0.07790229606305595 c 0.8647276 k 0.9807219 m 0.9825957\n",
      "91 Train Loss 139.84348 Test RE 0.07776421655719806 c 0.8743925 k 0.980114 m 0.9906705\n",
      "92 Train Loss 138.0701 Test RE 0.07884022809675433 c 0.8898513 k 0.9790841 m 1.0036004\n",
      "93 Train Loss 136.4215 Test RE 0.07923481743247608 c 0.91085327 k 0.9784142 m 1.0208427\n",
      "94 Train Loss 135.51083 Test RE 0.07749686708807457 c 0.9155406 k 0.97808444 m 1.0245814\n",
      "95 Train Loss 134.43533 Test RE 0.07641213993716649 c 0.9247638 k 0.978049 m 1.0321332\n",
      "96 Train Loss 133.7477 Test RE 0.07689916674445692 c 0.9337964 k 0.97780627 m 1.0396501\n",
      "97 Train Loss 132.61008 Test RE 0.07671600605648703 c 0.9454213 k 0.9772567 m 1.0493596\n",
      "98 Train Loss 130.76588 Test RE 0.07474307342360613 c 0.96170145 k 0.97596425 m 1.0631862\n",
      "99 Train Loss 128.7862 Test RE 0.07581293051109537 c 0.97869885 k 0.9743364 m 1.0775898\n",
      "100 Train Loss 126.44495 Test RE 0.0756667343482169 c 0.99858385 k 0.9727478 m 1.0944834\n",
      "101 Train Loss 124.67566 Test RE 0.07413229009459518 c 1.0177627 k 0.9714489 m 1.1107048\n",
      "102 Train Loss 122.19843 Test RE 0.07508394348839609 c 1.0421953 k 0.97017395 m 1.1310086\n",
      "103 Train Loss 120.41763 Test RE 0.07385307273739185 c 1.0629804 k 0.96964365 m 1.1483462\n",
      "104 Train Loss 117.934456 Test RE 0.07468909285452233 c 1.0965756 k 0.9689738 m 1.1766115\n",
      "105 Train Loss 116.192856 Test RE 0.07390423344781544 c 1.1144018 k 0.96848834 m 1.1915843\n",
      "106 Train Loss 115.23292 Test RE 0.0734966804686116 c 1.1279511 k 0.9678798 m 1.2029387\n",
      "107 Train Loss 113.83586 Test RE 0.0729043586645143 c 1.1485724 k 0.9669712 m 1.2203047\n",
      "108 Train Loss 110.48851 Test RE 0.07226340203509855 c 1.1868542 k 0.966136 m 1.2524899\n",
      "109 Train Loss 108.58743 Test RE 0.0726995043946056 c 1.2183812 k 0.965599 m 1.2789215\n",
      "110 Train Loss 107.65921 Test RE 0.07113633480953802 c 1.233885 k 0.9654495 m 1.2919303\n",
      "111 Train Loss 106.351364 Test RE 0.07112813260457493 c 1.249338 k 0.9654224 m 1.3050407\n",
      "112 Train Loss 104.30701 Test RE 0.07016965657639622 c 1.2840874 k 0.9656072 m 1.3345155\n",
      "113 Train Loss 102.00744 Test RE 0.07002148966930796 c 1.3163801 k 0.9661553 m 1.3618356\n",
      "114 Train Loss 101.13004 Test RE 0.06953589696338154 c 1.3305997 k 0.9664595 m 1.3738167\n",
      "115 Train Loss 99.51291 Test RE 0.0694480876035019 c 1.3563565 k 0.96607834 m 1.3955586\n",
      "116 Train Loss 98.812836 Test RE 0.06920451416038609 c 1.3674252 k 0.96563154 m 1.4050739\n",
      "117 Train Loss 98.37204 Test RE 0.0693145460727771 c 1.3785766 k 0.9656623 m 1.4146332\n",
      "118 Train Loss 97.39027 Test RE 0.06895565128909575 c 1.4098104 k 0.96608406 m 1.4413606\n",
      "119 Train Loss 96.27386 Test RE 0.06774100158569517 c 1.4370258 k 0.9668692 m 1.4647151\n",
      "120 Train Loss 95.55203 Test RE 0.06936931066062046 c 1.4510272 k 0.967391 m 1.476582\n",
      "121 Train Loss 94.89407 Test RE 0.0688276128274147 c 1.4665757 k 0.9683823 m 1.4897556\n",
      "122 Train Loss 94.38782 Test RE 0.06862035889181012 c 1.4721829 k 0.9693894 m 1.4944067\n",
      "123 Train Loss 93.50996 Test RE 0.0687076747394832 c 1.4786495 k 0.97064877 m 1.4997326\n",
      "124 Train Loss 93.07764 Test RE 0.06788012464243133 c 1.4865781 k 0.9712893 m 1.5064245\n",
      "125 Train Loss 92.595924 Test RE 0.06800596796150146 c 1.505161 k 0.9721736 m 1.522162\n",
      "126 Train Loss 92.03592 Test RE 0.06843853674568062 c 1.5291598 k 0.9727236 m 1.5425628\n",
      "127 Train Loss 91.49294 Test RE 0.06764749627450169 c 1.541725 k 0.97276425 m 1.5532905\n",
      "128 Train Loss 91.01529 Test RE 0.06855814075553349 c 1.5562525 k 0.97287464 m 1.5657326\n",
      "129 Train Loss 90.36124 Test RE 0.06791553988066396 c 1.5798583 k 0.9732799 m 1.5859158\n",
      "130 Train Loss 90.1422 Test RE 0.06762350548394155 c 1.586443 k 0.9735268 m 1.5915931\n",
      "131 Train Loss 89.71197 Test RE 0.06873198418468496 c 1.5962873 k 0.973981 m 1.600164\n",
      "132 Train Loss 89.32584 Test RE 0.06787298236179394 c 1.6100708 k 0.9744161 m 1.6121495\n",
      "133 Train Loss 89.14928 Test RE 0.06770404010166906 c 1.6184964 k 0.9746465 m 1.6194553\n",
      "134 Train Loss 88.85759 Test RE 0.06875191904952853 c 1.6300739 k 0.9748956 m 1.629517\n",
      "135 Train Loss 88.56494 Test RE 0.06773167981163587 c 1.6394985 k 0.97496253 m 1.6376961\n",
      "136 Train Loss 88.45619 Test RE 0.06780165105769831 c 1.6437544 k 0.9750934 m 1.6413966\n",
      "137 Train Loss 88.35687 Test RE 0.06811195667053695 c 1.6474178 k 0.9752488 m 1.6446518\n",
      "138 Train Loss 88.227264 Test RE 0.0680029010487781 c 1.6541991 k 0.9751897 m 1.6506364\n",
      "139 Train Loss 88.05614 Test RE 0.0678449227285976 c 1.665569 k 0.9753495 m 1.6607741\n",
      "140 Train Loss 87.78253 Test RE 0.06839869748872623 c 1.6759005 k 0.97526735 m 1.6702104\n",
      "141 Train Loss 87.63437 Test RE 0.0682758142797594 c 1.6822865 k 0.9750195 m 1.6760397\n",
      "142 Train Loss 87.43683 Test RE 0.06787273933123202 c 1.6887589 k 0.97477 m 1.681914\n",
      "143 Train Loss 87.38141 Test RE 0.06789447678657647 c 1.6904483 k 0.9746982 m 1.6833408\n",
      "144 Train Loss 87.322845 Test RE 0.06800026651329037 c 1.6973948 k 0.97439855 m 1.6895405\n",
      "145 Train Loss 87.27779 Test RE 0.0679331112484068 c 1.7023594 k 0.9742482 m 1.6940249\n",
      "146 Train Loss 87.18005 Test RE 0.06783214320867033 c 1.7073076 k 0.9742025 m 1.6984539\n",
      "147 Train Loss 87.139946 Test RE 0.06787216545505328 c 1.7113597 k 0.97397065 m 1.7021164\n",
      "148 Train Loss 87.05214 Test RE 0.06787312167765068 c 1.7203712 k 0.9733834 m 1.7104111\n",
      "149 Train Loss 86.99022 Test RE 0.0679643825682734 c 1.7249153 k 0.973107 m 1.7146456\n",
      "150 Train Loss 86.9485 Test RE 0.0679396824281877 c 1.7253458 k 0.973129 m 1.7150884\n",
      "151 Train Loss 86.88889 Test RE 0.06774965393347906 c 1.7256509 k 0.97322834 m 1.7154871\n",
      "152 Train Loss 86.81981 Test RE 0.06788065971109436 c 1.7283993 k 0.97312635 m 1.7183894\n",
      "153 Train Loss 86.74341 Test RE 0.06787933219213954 c 1.7306734 k 0.97298366 m 1.7209381\n",
      "154 Train Loss 86.71341 Test RE 0.06768858520563487 c 1.7323987 k 0.97279024 m 1.7226449\n",
      "155 Train Loss 86.686935 Test RE 0.06768296332897936 c 1.7346913 k 0.9726308 m 1.7249271\n",
      "156 Train Loss 86.654816 Test RE 0.06785947290858958 c 1.7379769 k 0.9724903 m 1.728352\n",
      "157 Train Loss 86.531044 Test RE 0.06771547762411222 c 1.7473308 k 0.97228205 m 1.7378908\n",
      "158 Train Loss 86.4604 Test RE 0.06778825998959163 c 1.7526212 k 0.97234404 m 1.7431802\n",
      "159 Train Loss 86.431564 Test RE 0.06794358178517462 c 1.756058 k 0.9723777 m 1.746491\n",
      "160 Train Loss 86.40823 Test RE 0.06769268077439747 c 1.7597066 k 0.9723449 m 1.7500081\n",
      "161 Train Loss 86.35225 Test RE 0.06771001676040143 c 1.7669189 k 0.97218955 m 1.7571647\n",
      "162 Train Loss 86.29526 Test RE 0.06778696240210552 c 1.7689342 k 0.9720023 m 1.7593023\n",
      "163 Train Loss 86.27852 Test RE 0.06774371787105962 c 1.7726623 k 0.9719398 m 1.7629794\n",
      "164 Train Loss 86.24675 Test RE 0.06778605700443231 c 1.7791466 k 0.97196805 m 1.769528\n",
      "165 Train Loss 86.21658 Test RE 0.06788100529451632 c 1.7833284 k 0.97190106 m 1.7742113\n",
      "166 Train Loss 86.162415 Test RE 0.06771249210314091 c 1.7880375 k 0.9716952 m 1.7795178\n",
      "167 Train Loss 86.106125 Test RE 0.06793934487192403 c 1.7889743 k 0.9716368 m 1.7810593\n",
      "168 Train Loss 86.07294 Test RE 0.0677831396347687 c 1.7887777 k 0.9715252 m 1.7816291\n",
      "169 Train Loss 86.058136 Test RE 0.06772599063854272 c 1.7890961 k 0.97145015 m 1.7821752\n",
      "170 Train Loss 86.04523 Test RE 0.06781373802778382 c 1.7898076 k 0.9713897 m 1.783242\n",
      "171 Train Loss 86.03483 Test RE 0.06779604974860007 c 1.7907981 k 0.9713716 m 1.7843788\n",
      "172 Train Loss 86.00197 Test RE 0.06794975146875375 c 1.7929643 k 0.9713709 m 1.786848\n",
      "173 Train Loss 85.96332 Test RE 0.06780192590177735 c 1.7950224 k 0.97140336 m 1.789277\n",
      "174 Train Loss 85.93996 Test RE 0.06777861203491158 c 1.7962474 k 0.97143155 m 1.7909863\n",
      "175 Train Loss 85.92482 Test RE 0.0677410220009433 c 1.7960416 k 0.9714524 m 1.7913408\n",
      "176 Train Loss 85.889885 Test RE 0.06771312046262122 c 1.7984729 k 0.9714846 m 1.7951995\n",
      "177 Train Loss 85.78606 Test RE 0.06768414447838608 c 1.8061968 k 0.97158587 m 1.8052256\n",
      "178 Train Loss 85.72482 Test RE 0.06747657373984632 c 1.8103497 k 0.9716454 m 1.8101591\n",
      "179 Train Loss 85.67761 Test RE 0.06763515391195589 c 1.8157827 k 0.9717166 m 1.8164794\n",
      "180 Train Loss 85.657074 Test RE 0.06774830468417889 c 1.8185351 k 0.97174156 m 1.8197713\n",
      "181 Train Loss 85.63143 Test RE 0.06786377969747967 c 1.8201395 k 0.9718269 m 1.8222802\n",
      "182 Train Loss 85.55968 Test RE 0.06785046811929156 c 1.8201514 k 0.97205436 m 1.8245924\n",
      "183 Train Loss 85.51131 Test RE 0.06756254808839061 c 1.8187853 k 0.97230506 m 1.8253396\n",
      "184 Train Loss 85.46245 Test RE 0.06781897796715716 c 1.8164223 k 0.97264093 m 1.8253597\n",
      "185 Train Loss 85.36747 Test RE 0.06756817861123263 c 1.8149643 k 0.97312695 m 1.827429\n",
      "186 Train Loss 85.26784 Test RE 0.06748122760632722 c 1.8144321 k 0.9735188 m 1.8290915\n",
      "187 Train Loss 85.22293 Test RE 0.06747281596992824 c 1.8131645 k 0.9736463 m 1.8286755\n",
      "188 Train Loss 85.18892 Test RE 0.06756040737862397 c 1.8119677 k 0.97384703 m 1.8288265\n",
      "189 Train Loss 85.10788 Test RE 0.06752373608027219 c 1.808714 k 0.9741819 m 1.8279912\n",
      "190 Train Loss 85.00496 Test RE 0.06722694185089552 c 1.8045616 k 0.9745142 m 1.8265253\n",
      "191 Train Loss 84.97131 Test RE 0.06748489091915139 c 1.803702 k 0.974635 m 1.8268212\n",
      "192 Train Loss 84.93931 Test RE 0.0675413589462992 c 1.8037809 k 0.97480214 m 1.8282529\n",
      "193 Train Loss 84.88664 Test RE 0.06721776985957274 c 1.805726 k 0.97507584 m 1.8319849\n",
      "194 Train Loss 84.84712 Test RE 0.06746642960658354 c 1.8080746 k 0.97535926 m 1.8362209\n",
      "195 Train Loss 84.79436 Test RE 0.06728814240298378 c 1.8116286 k 0.9756193 m 1.8419845\n",
      "196 Train Loss 84.72976 Test RE 0.0674699902254765 c 1.8150487 k 0.9758194 m 1.8471619\n",
      "197 Train Loss 84.687355 Test RE 0.06738569101695854 c 1.8159568 k 0.9759115 m 1.849163\n",
      "198 Train Loss 84.65515 Test RE 0.06724636972917122 c 1.8157396 k 0.97594297 m 1.849763\n",
      "199 Train Loss 84.61369 Test RE 0.06736903876436011 c 1.8158761 k 0.9758933 m 1.8508496\n",
      "Training time: 84.09\n",
      "Training time: 84.09\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 947.42596 Test RE 0.26589114989272133 c 0.02294799 k 0.7505471 m -1.2047503e-05\n",
      "1 Train Loss 555.9335 Test RE 0.22499444758954198 c 0.025319217 k 0.91567874 m -1.7119282e-05\n",
      "2 Train Loss 490.404 Test RE 0.21953863420093656 c 0.02672628 k 1.0157247 m -1.9977688e-05\n",
      "3 Train Loss 486.694 Test RE 0.2179513183560992 c 0.026933437 k 1.0278677 m -2.03696e-05\n",
      "4 Train Loss 483.2994 Test RE 0.21700529775830085 c 0.026849184 k 1.0065064 m -2.0541242e-05\n",
      "5 Train Loss 481.76428 Test RE 0.21693057945589722 c 0.027098626 k 1.0190523 m -2.191182e-05\n",
      "6 Train Loss 478.60876 Test RE 0.21557571148520888 c 0.027444577 k 1.0313438 m -2.5888006e-05\n",
      "7 Train Loss 470.6996 Test RE 0.2124650043403565 c 0.027996896 k 1.0011362 m -3.5486366e-05\n",
      "8 Train Loss 464.26324 Test RE 0.21170192100997348 c 0.028748496 k 1.020526 m -4.5907203e-05\n",
      "9 Train Loss 437.45078 Test RE 0.20205101729440608 c 0.030536821 k 1.044881 m -9.818637e-05\n",
      "10 Train Loss 406.58844 Test RE 0.19057787485946212 c 0.030723227 k 0.99656826 m -0.00011312082\n",
      "11 Train Loss 368.87192 Test RE 0.18385211151726547 c 0.03205344 k 1.0122857 m -0.00012270281\n",
      "12 Train Loss 345.85416 Test RE 0.17152285022701658 c 0.03276491 k 1.0047345 m -0.00010498185\n",
      "13 Train Loss 321.05038 Test RE 0.16130596778219608 c 0.03351967 k 1.0198952 m 3.0126928e-05\n",
      "14 Train Loss 295.42624 Test RE 0.15114756763186046 c 0.034489013 k 1.0168943 m 0.0004021028\n",
      "15 Train Loss 284.66522 Test RE 0.14855554830595016 c 0.03499761 k 1.0021874 m 0.00070532947\n",
      "16 Train Loss 272.21695 Test RE 0.1408134868452987 c 0.036595766 k 1.0197845 m 0.001673884\n",
      "17 Train Loss 257.68756 Test RE 0.12821797622936149 c 0.039323553 k 1.0026698 m 0.004305442\n",
      "18 Train Loss 251.90726 Test RE 0.12071106985466776 c 0.04327449 k 0.9935871 m 0.008119962\n",
      "19 Train Loss 248.9032 Test RE 0.11660145242946514 c 0.0482386 k 0.996661 m 0.012817981\n",
      "20 Train Loss 247.86188 Test RE 0.11441475496938054 c 0.05177818 k 0.9953431 m 0.016407188\n",
      "21 Train Loss 246.27335 Test RE 0.11270453841060266 c 0.0604016 k 0.9914853 m 0.025557078\n",
      "22 Train Loss 244.66652 Test RE 0.10856937800828673 c 0.0749045 k 0.99051815 m 0.04082297\n",
      "23 Train Loss 243.51859 Test RE 0.10967830975930797 c 0.086513735 k 0.99214053 m 0.052970015\n",
      "24 Train Loss 242.51628 Test RE 0.1096215752783436 c 0.09385502 k 0.9940592 m 0.060825124\n",
      "25 Train Loss 241.48793 Test RE 0.10852807621589797 c 0.1030215 k 0.9914494 m 0.0704642\n",
      "26 Train Loss 239.96237 Test RE 0.10854538389831488 c 0.12690559 k 0.9926047 m 0.09573232\n",
      "27 Train Loss 238.41396 Test RE 0.10750629967437511 c 0.14640978 k 0.9881722 m 0.11640287\n",
      "28 Train Loss 236.42255 Test RE 0.10880133104925736 c 0.18508525 k 0.9953532 m 0.15750986\n",
      "29 Train Loss 233.08127 Test RE 0.10837392262298334 c 0.2224105 k 0.99999887 m 0.19763544\n",
      "30 Train Loss 229.77664 Test RE 0.10453908356300817 c 0.24230424 k 0.9830947 m 0.21898994\n",
      "31 Train Loss 224.37717 Test RE 0.09988392925366828 c 0.3105754 k 0.98309547 m 0.29185376\n",
      "32 Train Loss 221.3002 Test RE 0.10201376482089185 c 0.3538023 k 0.9890493 m 0.3380956\n",
      "33 Train Loss 216.46869 Test RE 0.09770635393662629 c 0.41054553 k 0.98703957 m 0.39942354\n",
      "34 Train Loss 212.3114 Test RE 0.0982193874366789 c 0.44303977 k 0.9832142 m 0.43481144\n",
      "35 Train Loss 208.83481 Test RE 0.09579636110214261 c 0.47550222 k 0.9895708 m 0.46985593\n",
      "36 Train Loss 202.66113 Test RE 0.09349112430980515 c 0.52361417 k 0.9815752 m 0.521749\n",
      "37 Train Loss 199.37555 Test RE 0.09085719395892712 c 0.56226563 k 0.97281396 m 0.5639822\n",
      "38 Train Loss 191.30241 Test RE 0.08482494512668455 c 0.662009 k 0.97307205 m 0.67262185\n",
      "39 Train Loss 185.77866 Test RE 0.08753051989097523 c 0.69351393 k 0.9795533 m 0.7074306\n",
      "40 Train Loss 180.9535 Test RE 0.08319235258634783 c 0.72021806 k 0.9678862 m 0.7369462\n",
      "41 Train Loss 175.36176 Test RE 0.08427056544248392 c 0.76832455 k 0.9692765 m 0.7898944\n",
      "42 Train Loss 170.22928 Test RE 0.07940478035532829 c 0.8112946 k 0.9765502 m 0.8369467\n",
      "43 Train Loss 163.82333 Test RE 0.07912180883463427 c 0.89063394 k 0.96901256 m 0.92356503\n",
      "44 Train Loss 156.88858 Test RE 0.07745625103726261 c 0.9532875 k 0.9626359 m 0.99261117\n",
      "45 Train Loss 152.63113 Test RE 0.07747081106330671 c 1.0181074 k 0.9748874 m 1.0642686\n",
      "46 Train Loss 146.97937 Test RE 0.07859470630963665 c 1.07858 k 0.9918161 m 1.1307526\n",
      "47 Train Loss 139.47069 Test RE 0.07457366569269189 c 1.1063564 k 0.98193973 m 1.161188\n",
      "48 Train Loss 128.69711 Test RE 0.0722420045128642 c 1.161499 k 0.9649565 m 1.2221192\n",
      "49 Train Loss 121.99542 Test RE 0.07376176389194092 c 1.2049494 k 0.96947134 m 1.2705555\n",
      "50 Train Loss 117.96161 Test RE 0.0718386369096086 c 1.2128198 k 0.9769939 m 1.2794102\n",
      "51 Train Loss 115.286255 Test RE 0.07097153127036097 c 1.2222488 k 0.9662922 m 1.290249\n",
      "52 Train Loss 113.426605 Test RE 0.06961969483791486 c 1.2370493 k 0.9675161 m 1.3072844\n",
      "53 Train Loss 112.182495 Test RE 0.06754549122679494 c 1.2484195 k 0.97100717 m 1.3202108\n",
      "54 Train Loss 110.35817 Test RE 0.06868322424879951 c 1.2726307 k 0.97527677 m 1.3471807\n",
      "55 Train Loss 108.13209 Test RE 0.06756331755577454 c 1.3201385 k 0.9794178 m 1.4004934\n",
      "56 Train Loss 105.66905 Test RE 0.06536366181731085 c 1.366239 k 0.98311186 m 1.451926\n",
      "57 Train Loss 103.989586 Test RE 0.0678510270129599 c 1.3870702 k 0.9818713 m 1.4747136\n",
      "58 Train Loss 102.8759 Test RE 0.06526877231843714 c 1.3998809 k 0.9787305 m 1.4890454\n",
      "59 Train Loss 100.77829 Test RE 0.06485886414206708 c 1.4417028 k 0.97772706 m 1.5362955\n",
      "60 Train Loss 98.24327 Test RE 0.06577313986957542 c 1.4810797 k 0.9745465 m 1.580689\n",
      "61 Train Loss 97.11876 Test RE 0.06606939535030881 c 1.5063757 k 0.97213477 m 1.6092321\n",
      "62 Train Loss 95.638626 Test RE 0.06636128343368712 c 1.5348231 k 0.9737428 m 1.642017\n",
      "63 Train Loss 94.672554 Test RE 0.06440144037748893 c 1.5806623 k 0.97659254 m 1.6939133\n",
      "64 Train Loss 93.39667 Test RE 0.06566848584944657 c 1.6221448 k 0.97133017 m 1.740734\n",
      "65 Train Loss 92.85184 Test RE 0.06667086541018444 c 1.6309671 k 0.97578263 m 1.7506874\n",
      "66 Train Loss 91.265045 Test RE 0.0655635481703205 c 1.6674218 k 0.9825765 m 1.7923375\n",
      "67 Train Loss 90.33981 Test RE 0.06573079917897871 c 1.6758333 k 0.97577167 m 1.802469\n",
      "68 Train Loss 89.60671 Test RE 0.06532828219457541 c 1.6556196 k 0.9715321 m 1.7801886\n",
      "69 Train Loss 88.69496 Test RE 0.06599665828025911 c 1.6581197 k 0.9731117 m 1.7838485\n",
      "70 Train Loss 88.059586 Test RE 0.06516709358436487 c 1.6903648 k 0.9718572 m 1.8215984\n",
      "71 Train Loss 87.738815 Test RE 0.0652085168921506 c 1.7106016 k 0.97255164 m 1.8454407\n",
      "72 Train Loss 87.34383 Test RE 0.06520110283226402 c 1.7297455 k 0.97293323 m 1.8683255\n",
      "73 Train Loss 86.85466 Test RE 0.06694998596360326 c 1.7441093 k 0.97248757 m 1.8862119\n",
      "74 Train Loss 86.38943 Test RE 0.06645032638626656 c 1.7505232 k 0.9715041 m 1.8951178\n",
      "75 Train Loss 85.660614 Test RE 0.06648429034621803 c 1.7676566 k 0.96997184 m 1.917132\n",
      "76 Train Loss 85.248184 Test RE 0.06538894177103796 c 1.7772427 k 0.9739222 m 1.9289576\n",
      "77 Train Loss 84.64932 Test RE 0.06489568957888668 c 1.8055748 k 0.9732047 m 1.9637086\n",
      "78 Train Loss 84.150986 Test RE 0.06556228985999045 c 1.8249553 k 0.9714888 m 1.9877574\n",
      "79 Train Loss 84.017624 Test RE 0.06513706667787929 c 1.8361869 k 0.9730339 m 2.0015514\n",
      "80 Train Loss 83.81367 Test RE 0.06514546277716966 c 1.8438069 k 0.97435504 m 2.0116205\n",
      "81 Train Loss 83.52786 Test RE 0.06521416637097588 c 1.8304412 k 0.975277 m 1.9964174\n",
      "82 Train Loss 83.1624 Test RE 0.06495104934686645 c 1.8383749 k 0.9729031 m 2.007764\n",
      "83 Train Loss 82.93699 Test RE 0.06512738301247814 c 1.8540797 k 0.9740496 m 2.0282445\n",
      "84 Train Loss 82.730545 Test RE 0.06483300650379992 c 1.8725262 k 0.9751918 m 2.050764\n",
      "85 Train Loss 82.56548 Test RE 0.06531401749874778 c 1.8865176 k 0.9732757 m 2.0679853\n",
      "86 Train Loss 82.36101 Test RE 0.06562743841388875 c 1.899805 k 0.97418755 m 2.0851831\n",
      "87 Train Loss 82.27489 Test RE 0.06544927701609085 c 1.8934336 k 0.9740075 m 2.0782096\n",
      "88 Train Loss 82.10996 Test RE 0.06537040968971544 c 1.8839668 k 0.97472376 m 2.067961\n",
      "89 Train Loss 81.948166 Test RE 0.06512454195102871 c 1.8816042 k 0.9740533 m 2.0666354\n",
      "90 Train Loss 81.743385 Test RE 0.0652033829249452 c 1.8714148 k 0.97434765 m 2.0559795\n",
      "91 Train Loss 81.67325 Test RE 0.06514086965567994 c 1.8721111 k 0.974119 m 2.0570588\n",
      "92 Train Loss 81.596825 Test RE 0.06497454492414126 c 1.8819089 k 0.9739439 m 2.0693667\n",
      "93 Train Loss 81.49968 Test RE 0.06519518714481035 c 1.8865926 k 0.97429734 m 2.0763988\n",
      "94 Train Loss 81.45175 Test RE 0.06515511995745664 c 1.885036 k 0.9730108 m 2.0753417\n",
      "95 Train Loss 81.379395 Test RE 0.06518208438339541 c 1.888804 k 0.97318935 m 2.0802867\n",
      "96 Train Loss 81.32266 Test RE 0.0652903168859926 c 1.8904824 k 0.9730015 m 2.0831664\n",
      "97 Train Loss 81.26978 Test RE 0.06506634699069672 c 1.8844342 k 0.9737296 m 2.0767934\n",
      "98 Train Loss 81.201454 Test RE 0.06469282501161641 c 1.8745564 k 0.9738631 m 2.0663848\n",
      "99 Train Loss 81.09698 Test RE 0.0647938677100812 c 1.8671025 k 0.97296 m 2.0605292\n",
      "100 Train Loss 80.9931 Test RE 0.06499122018053911 c 1.8552161 k 0.9737025 m 2.0489953\n",
      "101 Train Loss 80.897804 Test RE 0.06475701803730852 c 1.8453014 k 0.97474205 m 2.0380495\n",
      "102 Train Loss 80.806694 Test RE 0.06480641723250746 c 1.8316406 k 0.97383374 m 2.0242403\n",
      "103 Train Loss 80.628586 Test RE 0.0646982394549804 c 1.8132503 k 0.97421455 m 2.0071561\n",
      "104 Train Loss 80.56741 Test RE 0.06460112197252713 c 1.8057731 k 0.9739162 m 1.9998937\n",
      "105 Train Loss 80.5241 Test RE 0.06481395073168775 c 1.8055534 k 0.97193694 m 2.000118\n",
      "106 Train Loss 80.44815 Test RE 0.06448875288004122 c 1.8200108 k 0.972616 m 2.0173454\n",
      "107 Train Loss 80.41211 Test RE 0.064762773876329 c 1.8249823 k 0.974061 m 2.0233119\n",
      "108 Train Loss 80.29765 Test RE 0.06455994559337912 c 1.8363174 k 0.9736873 m 2.0373125\n",
      "109 Train Loss 80.251945 Test RE 0.06459177492494339 c 1.8412452 k 0.973255 m 2.043284\n",
      "110 Train Loss 80.20767 Test RE 0.06461206893432375 c 1.8425508 k 0.97398597 m 2.0449657\n",
      "111 Train Loss 80.166306 Test RE 0.06450545110036468 c 1.838738 k 0.9739844 m 2.0420458\n",
      "112 Train Loss 80.1431 Test RE 0.06442988074022062 c 1.836119 k 0.97313124 m 2.0410986\n",
      "113 Train Loss 80.09111 Test RE 0.06477668685975985 c 1.8308012 k 0.9740368 m 2.0380125\n",
      "114 Train Loss 79.99304 Test RE 0.0645831591225661 c 1.8187749 k 0.9750576 m 2.027965\n",
      "115 Train Loss 79.93739 Test RE 0.06461948595831894 c 1.8101282 k 0.9740429 m 2.0212433\n",
      "116 Train Loss 79.86899 Test RE 0.06439471994310622 c 1.8095074 k 0.9750608 m 2.0230367\n",
      "117 Train Loss 79.56277 Test RE 0.06397215836198357 c 1.8325338 k 0.97380644 m 2.0583093\n",
      "118 Train Loss 79.27922 Test RE 0.06415507612399877 c 1.8429517 k 0.9740758 m 2.077368\n",
      "119 Train Loss 79.02629 Test RE 0.06463851318344224 c 1.8464205 k 0.973474 m 2.0919266\n",
      "120 Train Loss 78.862595 Test RE 0.06443257213889161 c 1.8394649 k 0.9747383 m 2.0928152\n",
      "121 Train Loss 78.705765 Test RE 0.06436569125662162 c 1.8308604 k 0.9741113 m 2.084331\n",
      "122 Train Loss 78.552574 Test RE 0.06424614443821892 c 1.8241122 k 0.9717581 m 2.078198\n",
      "123 Train Loss 78.44535 Test RE 0.06405304051039269 c 1.8230356 k 0.974713 m 2.080056\n",
      "124 Train Loss 78.3928 Test RE 0.06429420881642156 c 1.8251075 k 0.9750169 m 2.0852892\n",
      "125 Train Loss 78.31746 Test RE 0.06449510533969981 c 1.8228362 k 0.974146 m 2.0878673\n",
      "126 Train Loss 78.206406 Test RE 0.06437678209854102 c 1.8189082 k 0.97624767 m 2.0875778\n",
      "127 Train Loss 77.95831 Test RE 0.06373560693420942 c 1.8080212 k 0.9744243 m 2.0861957\n",
      "128 Train Loss 77.73215 Test RE 0.06422542010397239 c 1.8054913 k 0.971534 m 2.0914035\n",
      "129 Train Loss 77.46006 Test RE 0.06368694672842926 c 1.8107936 k 0.97300506 m 2.1042647\n",
      "130 Train Loss 77.22137 Test RE 0.06359444116272076 c 1.8151616 k 0.9728278 m 2.117596\n",
      "131 Train Loss 77.10758 Test RE 0.06299511397536547 c 1.8188263 k 0.97311217 m 2.124858\n",
      "132 Train Loss 77.07127 Test RE 0.06323047201131884 c 1.8203814 k 0.97406363 m 2.1245914\n",
      "133 Train Loss 77.02705 Test RE 0.06330008548428863 c 1.8177961 k 0.97340846 m 2.121796\n",
      "134 Train Loss 76.8867 Test RE 0.06347035927122634 c 1.8176804 k 0.9719165 m 2.1320314\n",
      "135 Train Loss 76.478935 Test RE 0.06294776022354605 c 1.8118984 k 0.97252566 m 2.1480176\n",
      "136 Train Loss 76.26599 Test RE 0.0629470503999595 c 1.7973002 k 0.9766223 m 2.1438756\n",
      "137 Train Loss 76.06254 Test RE 0.062492470750840565 c 1.7815169 k 0.9759712 m 2.1370518\n",
      "138 Train Loss 75.5512 Test RE 0.061961078478691464 c 1.7645706 k 0.97348493 m 2.1425505\n",
      "139 Train Loss 75.354256 Test RE 0.06163578238440038 c 1.7711315 k 0.974801 m 2.1587427\n",
      "140 Train Loss 74.99947 Test RE 0.061874722065934154 c 1.7759025 k 0.97578615 m 2.1677253\n",
      "141 Train Loss 74.86926 Test RE 0.06163933198658752 c 1.7687654 k 0.9770017 m 2.1642067\n",
      "142 Train Loss 74.76985 Test RE 0.06138910794301151 c 1.7594249 k 0.97564876 m 2.1644769\n",
      "143 Train Loss 74.72946 Test RE 0.06109605017719945 c 1.7594386 k 0.97417504 m 2.165941\n",
      "144 Train Loss 74.60884 Test RE 0.06063343981852752 c 1.7603947 k 0.97528064 m 2.16921\n",
      "145 Train Loss 74.51547 Test RE 0.0609447313279179 c 1.7528569 k 0.97543365 m 2.169213\n",
      "146 Train Loss 74.446304 Test RE 0.06073396553455727 c 1.7469429 k 0.9742485 m 2.1669805\n",
      "147 Train Loss 74.23238 Test RE 0.06054305203888335 c 1.7491227 k 0.9741421 m 2.1700199\n",
      "148 Train Loss 73.61811 Test RE 0.06079323318492454 c 1.7527885 k 0.97325116 m 2.192712\n",
      "149 Train Loss 72.810684 Test RE 0.06018780694197925 c 1.7541283 k 0.97347885 m 2.2152133\n",
      "150 Train Loss 71.92851 Test RE 0.05976173208856003 c 1.756779 k 0.9767179 m 2.2426107\n",
      "151 Train Loss 71.49358 Test RE 0.059804005861616695 c 1.7549766 k 0.9735671 m 2.2557251\n",
      "152 Train Loss 71.33339 Test RE 0.05946116100225884 c 1.7587922 k 0.9742958 m 2.2681024\n",
      "153 Train Loss 71.05661 Test RE 0.05937731476869521 c 1.7496451 k 0.97722995 m 2.2694051\n",
      "154 Train Loss 70.79642 Test RE 0.059887313323003365 c 1.7300122 k 0.9764654 m 2.257674\n",
      "155 Train Loss 70.66928 Test RE 0.059441782060567445 c 1.7188015 k 0.97624713 m 2.2505414\n",
      "156 Train Loss 70.57484 Test RE 0.059471169246776 c 1.7091128 k 0.97727215 m 2.2435746\n",
      "157 Train Loss 70.43309 Test RE 0.059167905307557174 c 1.7004789 k 0.9767248 m 2.236724\n",
      "158 Train Loss 70.39214 Test RE 0.05893712667157746 c 1.6974852 k 0.9754952 m 2.2353113\n",
      "159 Train Loss 70.21481 Test RE 0.05870947276733702 c 1.6852138 k 0.97226566 m 2.2384663\n",
      "160 Train Loss 69.73135 Test RE 0.05879272916722284 c 1.683561 k 0.97609663 m 2.2604837\n",
      "161 Train Loss 69.49335 Test RE 0.05915566311404338 c 1.6973588 k 0.97956604 m 2.2826614\n",
      "162 Train Loss 68.19441 Test RE 0.057994239006581 c 1.7333701 k 0.9739979 m 2.3682733\n",
      "163 Train Loss 67.026085 Test RE 0.05640294084011711 c 1.7488807 k 0.9752527 m 2.419599\n",
      "164 Train Loss 66.16257 Test RE 0.0571540737637695 c 1.7446392 k 0.97350526 m 2.4486141\n",
      "165 Train Loss 65.26645 Test RE 0.05544337116569822 c 1.731855 k 0.97626 m 2.4553046\n",
      "166 Train Loss 64.743614 Test RE 0.054805063256555285 c 1.7201807 k 0.9768875 m 2.439406\n",
      "167 Train Loss 64.3271 Test RE 0.05593937542497108 c 1.7008321 k 0.9793441 m 2.4295774\n",
      "168 Train Loss 63.79746 Test RE 0.05497262928239407 c 1.6814902 k 0.97608805 m 2.4349885\n",
      "169 Train Loss 62.6149 Test RE 0.054015938270764605 c 1.6522748 k 0.9743571 m 2.4366355\n",
      "170 Train Loss 61.84883 Test RE 0.05487139294100703 c 1.6231586 k 0.97434807 m 2.4323018\n",
      "171 Train Loss 61.173965 Test RE 0.05369041876440556 c 1.596946 k 0.9753921 m 2.430439\n",
      "172 Train Loss 60.654278 Test RE 0.053618310853990096 c 1.5744029 k 0.9755669 m 2.431007\n",
      "173 Train Loss 60.305126 Test RE 0.05337701068919054 c 1.5671408 k 0.9765867 m 2.4419634\n",
      "174 Train Loss 59.858784 Test RE 0.053208197461886764 c 1.5629504 k 0.97654486 m 2.4682925\n",
      "175 Train Loss 59.076683 Test RE 0.052524959954383374 c 1.5574744 k 0.97605395 m 2.502905\n",
      "176 Train Loss 57.507595 Test RE 0.051248089177729106 c 1.5561191 k 0.9804439 m 2.554997\n",
      "177 Train Loss 56.65268 Test RE 0.0523286016086873 c 1.5697852 k 0.9818535 m 2.5921044\n",
      "178 Train Loss 55.70735 Test RE 0.05003354656111397 c 1.5795752 k 0.97558296 m 2.6262395\n",
      "179 Train Loss 55.09131 Test RE 0.04983327658879844 c 1.5783665 k 0.9718431 m 2.640545\n",
      "180 Train Loss 54.131096 Test RE 0.05133268692949944 c 1.567355 k 0.97575486 m 2.6523483\n",
      "181 Train Loss 53.20072 Test RE 0.049921420218307755 c 1.5667459 k 0.9801086 m 2.6788547\n",
      "182 Train Loss 51.416195 Test RE 0.047234870000489114 c 1.5739851 k 0.9771716 m 2.7412522\n",
      "183 Train Loss 50.835854 Test RE 0.047528400456005884 c 1.5737743 k 0.97533387 m 2.7741547\n",
      "184 Train Loss 50.332207 Test RE 0.04650620284237202 c 1.5757917 k 0.9769671 m 2.8064747\n",
      "185 Train Loss 49.286392 Test RE 0.04553667629283294 c 1.5825608 k 0.98529714 m 2.8484676\n",
      "186 Train Loss 48.48223 Test RE 0.04624252986447757 c 1.6002434 k 0.98119324 m 2.8916392\n",
      "187 Train Loss 47.867653 Test RE 0.04616454210837775 c 1.6204566 k 0.9805821 m 2.937517\n",
      "188 Train Loss 47.51355 Test RE 0.04589189497558572 c 1.6322277 k 0.9820037 m 2.9820404\n",
      "189 Train Loss 46.95771 Test RE 0.04607472748364028 c 1.6365793 k 0.9833149 m 3.0131273\n",
      "190 Train Loss 45.87426 Test RE 0.045698332048393214 c 1.6363622 k 0.97865885 m 3.0495796\n",
      "191 Train Loss 43.328964 Test RE 0.044524935823369756 c 1.6318291 k 0.97578067 m 3.1043487\n",
      "192 Train Loss 41.68273 Test RE 0.04273385232956377 c 1.6337123 k 0.9830176 m 3.146164\n",
      "193 Train Loss 40.764168 Test RE 0.04268650880776947 c 1.6174428 k 0.9817388 m 3.153234\n",
      "194 Train Loss 39.983917 Test RE 0.04313803545739431 c 1.595837 k 0.97697794 m 3.160011\n",
      "195 Train Loss 38.29422 Test RE 0.041833317143368146 c 1.5676024 k 0.9798446 m 3.171808\n",
      "196 Train Loss 37.776203 Test RE 0.0417181870852894 c 1.55611 k 0.98627627 m 3.180688\n",
      "197 Train Loss 36.906563 Test RE 0.04140180876830058 c 1.5486698 k 0.98523027 m 3.2037518\n",
      "198 Train Loss 35.262947 Test RE 0.03872659098647708 c 1.5185164 k 0.9777672 m 3.228041\n",
      "199 Train Loss 33.15056 Test RE 0.0396873630383421 c 1.4931704 k 0.9849892 m 3.2866614\n",
      "Training time: 83.61\n",
      "Training time: 83.61\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 6511.4404 Test RE 0.36653136949183474 c -0.009675495 k 0.41061455 m -1.011012e-05\n",
      "1 Train Loss 821.5673 Test RE 0.2369065442972951 c -0.015202872 k 0.78746015 m -1.7641565e-05\n",
      "2 Train Loss 499.41165 Test RE 0.22142477710839073 c -0.0170922 k 0.99467427 m -2.0402464e-05\n",
      "3 Train Loss 496.79138 Test RE 0.22118660924343336 c -0.01721153 k 1.0166495 m -2.0541509e-05\n",
      "4 Train Loss 496.57068 Test RE 0.22112748288652823 c -0.017155452 k 1.0216455 m -2.0416066e-05\n",
      "5 Train Loss 496.26645 Test RE 0.22106820686528095 c -0.01711385 k 1.0168946 m -2.0331185e-05\n",
      "6 Train Loss 496.09515 Test RE 0.22100821299247017 c -0.017179107 k 1.0124006 m -2.043683e-05\n",
      "7 Train Loss 495.26642 Test RE 0.2208245105488371 c -0.017618341 k 1.017261 m -2.1237494e-05\n",
      "8 Train Loss 495.2434 Test RE 0.22081817224415043 c -0.017673275 k 1.0176002 m -2.1345617e-05\n",
      "9 Train Loss 494.3322 Test RE 0.2204424310050081 c -0.016654179 k 1.0130595 m -1.9863697e-05\n",
      "10 Train Loss 492.8593 Test RE 0.22015849593340514 c -0.015978117 k 1.0215265 m -1.8850908e-05\n",
      "11 Train Loss 489.32602 Test RE 0.21919164152825268 c -0.014979732 k 1.018407 m -1.7413768e-05\n",
      "12 Train Loss 486.15356 Test RE 0.21823108107196004 c -0.014317183 k 1.0172724 m -1.5212313e-05\n",
      "13 Train Loss 472.41263 Test RE 0.2145075032242261 c -0.01311441 k 1.0093113 m -5.5276064e-06\n",
      "14 Train Loss 459.20547 Test RE 0.2106068366038753 c -0.012519933 k 1.0147806 m 1.9489469e-06\n",
      "15 Train Loss 449.77466 Test RE 0.20722675780653396 c -0.012618116 k 1.0113478 m 1.3631279e-07\n",
      "16 Train Loss 411.1983 Test RE 0.19200408773862582 c -0.011337285 k 1.0107793 m -1.3162716e-05\n",
      "17 Train Loss 368.6439 Test RE 0.17874251519367768 c -0.011647701 k 1.0246623 m -1.0343805e-05\n",
      "18 Train Loss 320.83917 Test RE 0.1554337419058585 c -0.01023475 k 1.0064195 m 8.630548e-05\n",
      "19 Train Loss 295.91446 Test RE 0.14194983449918772 c -0.009562079 k 1.0042033 m 0.0002317578\n",
      "20 Train Loss 266.66254 Test RE 0.12926262125247098 c -0.007964333 k 0.99830127 m 0.00085594825\n",
      "21 Train Loss 254.12782 Test RE 0.11930756033592066 c -0.0065801963 k 0.9967228 m 0.001865398\n",
      "22 Train Loss 251.8222 Test RE 0.11260101055299727 c -0.0062294398 k 0.9928675 m 0.0023727822\n",
      "23 Train Loss 250.45508 Test RE 0.11214206926079531 c -0.004352206 k 0.99143493 m 0.004297827\n",
      "24 Train Loss 249.63751 Test RE 0.11325646319861706 c -0.0023539735 k 0.99539196 m 0.0064315037\n",
      "25 Train Loss 248.38387 Test RE 0.10999669944990415 c 0.0025658647 k 0.9907383 m 0.011710838\n",
      "26 Train Loss 247.37894 Test RE 0.11030520492764871 c 0.009150202 k 0.99196017 m 0.018698987\n",
      "27 Train Loss 246.60785 Test RE 0.11068119771946772 c 0.01855844 k 0.9948119 m 0.02864213\n",
      "28 Train Loss 245.68015 Test RE 0.10832608714106623 c 0.033786874 k 0.9868159 m 0.04493762\n",
      "29 Train Loss 244.48257 Test RE 0.10809859518579411 c 0.04287438 k 0.9918016 m 0.054672945\n",
      "30 Train Loss 243.9208 Test RE 0.10788397893685171 c 0.05617973 k 0.99206644 m 0.06880392\n",
      "31 Train Loss 242.36023 Test RE 0.10780666737795201 c 0.068411335 k 0.9872909 m 0.08184329\n",
      "32 Train Loss 241.79643 Test RE 0.10782520465562016 c 0.07338523 k 0.99206334 m 0.08722048\n",
      "33 Train Loss 241.03894 Test RE 0.10581296125018817 c 0.08226468 k 0.99039626 m 0.0965652\n",
      "34 Train Loss 239.51349 Test RE 0.10761760422530445 c 0.103019804 k 0.98810303 m 0.118607365\n",
      "35 Train Loss 237.79517 Test RE 0.1050969960095883 c 0.119067594 k 0.9904737 m 0.13588604\n",
      "36 Train Loss 236.60294 Test RE 0.1044830193398353 c 0.13610992 k 0.9891388 m 0.15426369\n",
      "37 Train Loss 233.9602 Test RE 0.10268300550987103 c 0.1659234 k 0.9907991 m 0.18631457\n",
      "38 Train Loss 232.88535 Test RE 0.10283410037718298 c 0.18034638 k 0.9831555 m 0.20174348\n",
      "39 Train Loss 231.66647 Test RE 0.10202426015397217 c 0.19606979 k 0.9912056 m 0.21860896\n",
      "40 Train Loss 229.9375 Test RE 0.10224324039619961 c 0.21162502 k 0.9900987 m 0.23535028\n",
      "41 Train Loss 226.756 Test RE 0.1015293295895852 c 0.23455937 k 0.9838548 m 0.2601157\n",
      "42 Train Loss 225.82666 Test RE 0.0996088081453823 c 0.24326946 k 0.98969215 m 0.26947004\n",
      "43 Train Loss 224.71602 Test RE 0.10023705702665844 c 0.25245062 k 0.9872441 m 0.27936104\n",
      "44 Train Loss 223.65286 Test RE 0.10076560467600434 c 0.26680934 k 0.98585075 m 0.29496008\n",
      "45 Train Loss 221.6815 Test RE 0.09683653176714432 c 0.30187443 k 0.98784816 m 0.3331622\n",
      "46 Train Loss 218.21852 Test RE 0.0977560932884575 c 0.3392028 k 0.9850085 m 0.37378642\n",
      "47 Train Loss 215.70651 Test RE 0.09951088367162955 c 0.37058625 k 0.99284714 m 0.40791917\n",
      "48 Train Loss 213.33926 Test RE 0.09574205336612145 c 0.3885432 k 0.98833936 m 0.4273382\n",
      "49 Train Loss 211.02962 Test RE 0.09178360336882965 c 0.41267475 k 0.9834823 m 0.45345166\n",
      "50 Train Loss 209.27377 Test RE 0.09461480471685342 c 0.43118504 k 0.9875906 m 0.47350717\n",
      "51 Train Loss 205.46814 Test RE 0.09347308528288839 c 0.46151057 k 0.98222756 m 0.5065997\n",
      "52 Train Loss 203.40488 Test RE 0.09115799113489755 c 0.48452744 k 0.9828188 m 0.5315439\n",
      "53 Train Loss 201.2623 Test RE 0.09197009213770789 c 0.5068606 k 0.9834632 m 0.5558221\n",
      "54 Train Loss 197.6219 Test RE 0.0882860698842695 c 0.54337716 k 0.98217285 m 0.59578586\n",
      "55 Train Loss 191.86407 Test RE 0.08347304290738848 c 0.6109171 k 0.9753263 m 0.66943794\n",
      "56 Train Loss 189.61334 Test RE 0.08427033926307405 c 0.62901 k 0.9756505 m 0.6891378\n",
      "57 Train Loss 186.92007 Test RE 0.08597645166237193 c 0.65102524 k 0.98032236 m 0.71357363\n",
      "58 Train Loss 184.68538 Test RE 0.08481272015146449 c 0.6798015 k 0.98207045 m 0.7456981\n",
      "59 Train Loss 175.45828 Test RE 0.08066145513576678 c 0.7803084 k 0.9779233 m 0.8568579\n",
      "60 Train Loss 171.9167 Test RE 0.07991515383130499 c 0.8386805 k 0.97413135 m 0.9209796\n",
      "61 Train Loss 166.01498 Test RE 0.0792154842293206 c 0.8602887 k 0.9825571 m 0.94383955\n",
      "62 Train Loss 160.48737 Test RE 0.08024102590150216 c 0.899573 k 0.97701234 m 0.9867339\n",
      "63 Train Loss 156.75375 Test RE 0.07717628997188951 c 0.94448376 k 0.9815781 m 1.0360875\n",
      "64 Train Loss 150.8422 Test RE 0.07614699642982449 c 1.0145656 k 0.97928816 m 1.1131796\n",
      "65 Train Loss 144.22636 Test RE 0.07306507777496112 c 1.0449313 k 0.97044384 m 1.1471187\n",
      "66 Train Loss 138.3046 Test RE 0.07361528190440479 c 1.0852869 k 0.97349834 m 1.19164\n",
      "67 Train Loss 136.17715 Test RE 0.0712283705533047 c 1.1005529 k 0.9739653 m 1.2085901\n",
      "68 Train Loss 133.29533 Test RE 0.0735565983765711 c 1.1344372 k 0.9685904 m 1.2465682\n",
      "69 Train Loss 131.24992 Test RE 0.07210828010234359 c 1.1419368 k 0.97582394 m 1.2549841\n",
      "70 Train Loss 128.55133 Test RE 0.07369472707013286 c 1.1605089 k 0.9733687 m 1.2756147\n",
      "71 Train Loss 125.66026 Test RE 0.07160164132044186 c 1.1767445 k 0.97317 m 1.2939446\n",
      "72 Train Loss 122.131546 Test RE 0.06978671296702214 c 1.2173605 k 0.9726983 m 1.3398869\n",
      "73 Train Loss 119.25923 Test RE 0.07345789589770599 c 1.2479168 k 0.9738905 m 1.3746302\n",
      "74 Train Loss 116.458725 Test RE 0.06819228785130027 c 1.253628 k 0.9741229 m 1.3813602\n",
      "75 Train Loss 114.69786 Test RE 0.06794409138132279 c 1.266377 k 0.9734652 m 1.3959451\n",
      "76 Train Loss 112.822845 Test RE 0.06674522518501123 c 1.2923737 k 0.96674764 m 1.4259843\n",
      "77 Train Loss 110.00061 Test RE 0.06572402462012059 c 1.3379649 k 0.97155255 m 1.4784777\n",
      "78 Train Loss 106.083084 Test RE 0.0691707506821685 c 1.3747945 k 0.9742705 m 1.5207549\n",
      "79 Train Loss 103.55197 Test RE 0.07052761343421729 c 1.3996147 k 0.9749591 m 1.5488561\n",
      "80 Train Loss 102.81876 Test RE 0.06928384237336847 c 1.4095799 k 0.9733689 m 1.5601962\n",
      "81 Train Loss 101.65666 Test RE 0.06683483482305187 c 1.4227853 k 0.9716262 m 1.575398\n",
      "82 Train Loss 99.82895 Test RE 0.0661491260087596 c 1.4568378 k 0.97348064 m 1.6143159\n",
      "83 Train Loss 98.00376 Test RE 0.06383667696354835 c 1.501286 k 0.97289187 m 1.6650603\n",
      "84 Train Loss 96.750916 Test RE 0.0642076647859394 c 1.505219 k 0.9724845 m 1.6696777\n",
      "85 Train Loss 95.50644 Test RE 0.06440269729805607 c 1.5112389 k 0.97220063 m 1.6767752\n",
      "86 Train Loss 93.91754 Test RE 0.06439647587910703 c 1.5408143 k 0.972433 m 1.7112494\n",
      "87 Train Loss 92.35645 Test RE 0.06435199259084298 c 1.5952523 k 0.97759694 m 1.7745277\n",
      "88 Train Loss 90.55997 Test RE 0.0633050473518021 c 1.6091808 k 0.9767855 m 1.7909422\n",
      "89 Train Loss 88.510925 Test RE 0.0639744016881778 c 1.6300881 k 0.9720466 m 1.8155456\n",
      "90 Train Loss 87.865265 Test RE 0.0645186692620083 c 1.6377385 k 0.9725138 m 1.8245903\n",
      "91 Train Loss 87.27027 Test RE 0.06495497317797518 c 1.6465815 k 0.9720367 m 1.8353212\n",
      "92 Train Loss 86.83874 Test RE 0.06557685245467648 c 1.6645527 k 0.9708932 m 1.8564773\n",
      "93 Train Loss 86.18347 Test RE 0.06474957927609291 c 1.6823686 k 0.9749331 m 1.877698\n",
      "94 Train Loss 85.65155 Test RE 0.06497339634667233 c 1.6979053 k 0.97660416 m 1.8961176\n",
      "95 Train Loss 84.9004 Test RE 0.06411716463871422 c 1.724819 k 0.97509813 m 1.9284297\n",
      "96 Train Loss 84.54127 Test RE 0.06438073816451147 c 1.719995 k 0.97398096 m 1.9235499\n",
      "97 Train Loss 84.312225 Test RE 0.0646401888061092 c 1.7228936 k 0.9747826 m 1.9276476\n",
      "98 Train Loss 84.10663 Test RE 0.06452702724789551 c 1.7312241 k 0.9746042 m 1.9381733\n",
      "99 Train Loss 83.922104 Test RE 0.06411229991803305 c 1.7355667 k 0.9745836 m 1.943905\n",
      "100 Train Loss 83.740875 Test RE 0.06434779388394463 c 1.7350514 k 0.97427285 m 1.9434615\n",
      "101 Train Loss 83.22183 Test RE 0.06367022837962936 c 1.7344308 k 0.97360116 m 1.9430375\n",
      "102 Train Loss 82.88816 Test RE 0.06342986461242801 c 1.7390902 k 0.97353697 m 1.9495624\n",
      "103 Train Loss 82.614716 Test RE 0.06393590168650432 c 1.7487216 k 0.97323155 m 1.9618331\n",
      "104 Train Loss 82.26401 Test RE 0.06395423022354849 c 1.7530997 k 0.97158813 m 1.9688132\n",
      "105 Train Loss 81.61479 Test RE 0.0638159058814825 c 1.7880297 k 0.97009605 m 2.0189168\n",
      "106 Train Loss 81.02409 Test RE 0.06389349729569677 c 1.8171929 k 0.9737944 m 2.0575724\n",
      "107 Train Loss 80.481125 Test RE 0.0640040311193085 c 1.8377793 k 0.9757083 m 2.0872061\n",
      "108 Train Loss 80.17142 Test RE 0.06327796767951081 c 1.8373413 k 0.97317266 m 2.0877302\n",
      "109 Train Loss 79.738525 Test RE 0.06333632124723663 c 1.8400726 k 0.97236234 m 2.0925815\n",
      "110 Train Loss 79.48419 Test RE 0.0643186316392138 c 1.8445529 k 0.9733637 m 2.0990248\n",
      "111 Train Loss 79.28871 Test RE 0.06374712932356671 c 1.850628 k 0.9726307 m 2.110388\n",
      "112 Train Loss 79.150536 Test RE 0.06361626792553278 c 1.8501574 k 0.9747513 m 2.111523\n",
      "113 Train Loss 78.873634 Test RE 0.06407881240092347 c 1.848595 k 0.9738241 m 2.114927\n",
      "114 Train Loss 78.757385 Test RE 0.06372314631673504 c 1.8465052 k 0.9733291 m 2.1128387\n",
      "115 Train Loss 78.499626 Test RE 0.06343646167413532 c 1.8432148 k 0.9746679 m 2.1118813\n",
      "116 Train Loss 78.38324 Test RE 0.06425147602259298 c 1.8465794 k 0.9749553 m 2.1184607\n",
      "117 Train Loss 78.21669 Test RE 0.06377059913270124 c 1.852948 k 0.97436357 m 2.1301706\n",
      "118 Train Loss 78.04897 Test RE 0.06292331124015291 c 1.8557541 k 0.97341657 m 2.1384456\n",
      "119 Train Loss 77.59044 Test RE 0.06342390818400953 c 1.8483399 k 0.9750151 m 2.1397958\n",
      "120 Train Loss 77.456184 Test RE 0.06335199548531326 c 1.8535173 k 0.97391504 m 2.1531806\n",
      "121 Train Loss 77.214905 Test RE 0.06317039183791427 c 1.8627523 k 0.974543 m 2.1766224\n",
      "122 Train Loss 77.04196 Test RE 0.06302227100220739 c 1.853204 k 0.9753772 m 2.172458\n",
      "123 Train Loss 76.8336 Test RE 0.0629353795884818 c 1.8429846 k 0.97515553 m 2.1687117\n",
      "124 Train Loss 76.57549 Test RE 0.06278499346535474 c 1.8385006 k 0.97527355 m 2.1688514\n",
      "125 Train Loss 76.29245 Test RE 0.062396145631362795 c 1.8196642 k 0.9749721 m 2.155226\n",
      "126 Train Loss 75.84183 Test RE 0.06271651816762266 c 1.7765416 k 0.9758415 m 2.127435\n",
      "127 Train Loss 75.25491 Test RE 0.061877495634992334 c 1.7478074 k 0.9734506 m 2.1146588\n",
      "128 Train Loss 74.78035 Test RE 0.0618870086951647 c 1.7414969 k 0.97214425 m 2.1360888\n",
      "129 Train Loss 74.15125 Test RE 0.06104538163191399 c 1.7484738 k 0.9742379 m 2.1667523\n",
      "130 Train Loss 73.9483 Test RE 0.060857389771691445 c 1.7546355 k 0.97367954 m 2.1757972\n",
      "131 Train Loss 73.56264 Test RE 0.06011176452658522 c 1.7544639 k 0.9764837 m 2.2028494\n",
      "132 Train Loss 72.8278 Test RE 0.06012148163534229 c 1.7399396 k 0.974302 m 2.2010288\n",
      "133 Train Loss 72.64708 Test RE 0.05998745331393072 c 1.7350448 k 0.9755679 m 2.2032728\n",
      "134 Train Loss 72.04127 Test RE 0.06029845936351587 c 1.7295265 k 0.97359526 m 2.2149682\n",
      "135 Train Loss 71.42065 Test RE 0.06014930153212659 c 1.7369487 k 0.97253406 m 2.2299807\n",
      "136 Train Loss 70.94349 Test RE 0.059145143713780476 c 1.7268744 k 0.9753888 m 2.2414572\n",
      "137 Train Loss 70.26171 Test RE 0.05892840508275358 c 1.7290201 k 0.97443837 m 2.2806544\n",
      "138 Train Loss 69.502975 Test RE 0.059673402799465286 c 1.7341003 k 0.97359735 m 2.3230636\n",
      "139 Train Loss 68.636 Test RE 0.05614997229758211 c 1.7231593 k 0.9748613 m 2.357282\n",
      "140 Train Loss 67.93685 Test RE 0.056318789137758764 c 1.7348794 k 0.97347116 m 2.3789642\n",
      "141 Train Loss 67.2527 Test RE 0.058234025045962395 c 1.7444421 k 0.9749934 m 2.402053\n",
      "142 Train Loss 66.55569 Test RE 0.05756473807493345 c 1.7552292 k 0.9742097 m 2.4406304\n",
      "143 Train Loss 65.56102 Test RE 0.05731054680618197 c 1.745947 k 0.97609645 m 2.4605415\n",
      "144 Train Loss 64.8492 Test RE 0.056569970924976745 c 1.7349789 k 0.9771329 m 2.469767\n",
      "145 Train Loss 63.288265 Test RE 0.05592812743775411 c 1.6902531 k 0.9785642 m 2.4993207\n",
      "146 Train Loss 61.745644 Test RE 0.05324176221683785 c 1.6917813 k 0.9809966 m 2.542332\n",
      "147 Train Loss 60.504765 Test RE 0.05230073084957121 c 1.7164145 k 0.9791561 m 2.6165464\n",
      "148 Train Loss 59.329407 Test RE 0.0541889663546246 c 1.7087141 k 0.97492456 m 2.6306572\n",
      "149 Train Loss 58.715538 Test RE 0.05346211281551838 c 1.6982883 k 0.97806096 m 2.6540036\n",
      "150 Train Loss 57.979095 Test RE 0.05212004003656485 c 1.6826636 k 0.97640127 m 2.6771414\n",
      "151 Train Loss 56.999855 Test RE 0.05240406506704409 c 1.6638298 k 0.97941506 m 2.68545\n",
      "152 Train Loss 55.254295 Test RE 0.05176342774006083 c 1.6560744 k 0.97802025 m 2.7364316\n",
      "153 Train Loss 54.657402 Test RE 0.05109190190403461 c 1.6480863 k 0.9790193 m 2.7473493\n",
      "154 Train Loss 53.983223 Test RE 0.05002366943984211 c 1.6505812 k 0.97972697 m 2.7853272\n",
      "155 Train Loss 53.33113 Test RE 0.04925200928790365 c 1.6458614 k 0.976819 m 2.8018184\n",
      "156 Train Loss 50.690926 Test RE 0.04749707127635778 c 1.6016817 k 0.97468674 m 2.8594534\n",
      "157 Train Loss 49.39901 Test RE 0.047848144583429196 c 1.5484451 k 0.97528905 m 2.8366568\n",
      "158 Train Loss 47.30823 Test RE 0.045391431517059704 c 1.4957522 k 0.9817487 m 2.8521006\n",
      "159 Train Loss 45.342976 Test RE 0.04414641202037781 c 1.5196494 k 0.9777681 m 2.961604\n",
      "160 Train Loss 43.779045 Test RE 0.044028879170668805 c 1.4902381 k 0.9809584 m 2.9878504\n",
      "161 Train Loss 41.975437 Test RE 0.04256728270737086 c 1.4539022 k 0.98124146 m 3.010045\n",
      "162 Train Loss 41.22798 Test RE 0.04108857357237038 c 1.4371254 k 0.98124045 m 3.0415668\n",
      "163 Train Loss 40.55816 Test RE 0.040961003213034884 c 1.4272642 k 0.9783095 m 3.0837712\n",
      "164 Train Loss 38.545406 Test RE 0.0378565024314816 c 1.4022049 k 0.97729814 m 3.1413512\n",
      "165 Train Loss 34.43213 Test RE 0.03677796583409308 c 1.3801216 k 0.9877268 m 3.2742946\n",
      "166 Train Loss 31.975342 Test RE 0.034880423481634275 c 1.3827487 k 0.9778815 m 3.360964\n",
      "167 Train Loss 30.54195 Test RE 0.034772735691979785 c 1.360212 k 0.98174256 m 3.378985\n",
      "168 Train Loss 28.705791 Test RE 0.03104199268433109 c 1.3273777 k 0.98099303 m 3.4900324\n",
      "169 Train Loss 26.7097 Test RE 0.02794143657679039 c 1.3154273 k 0.9842939 m 3.6068408\n",
      "170 Train Loss 25.655828 Test RE 0.02996288870243451 c 1.3136625 k 0.9860181 m 3.6993673\n",
      "171 Train Loss 22.658733 Test RE 0.0252772808497921 c 1.2923287 k 0.9831121 m 3.8198316\n",
      "172 Train Loss 19.85439 Test RE 0.026326666138956192 c 1.2703547 k 0.9829831 m 3.9024568\n",
      "173 Train Loss 18.690844 Test RE 0.023787175962506762 c 1.261779 k 0.9904255 m 3.9345312\n",
      "174 Train Loss 16.812782 Test RE 0.024924653331800217 c 1.1985545 k 0.9916971 m 3.9370065\n",
      "175 Train Loss 15.416779 Test RE 0.022791782260744745 c 1.1833749 k 0.98773783 m 3.9593997\n",
      "176 Train Loss 14.251211 Test RE 0.020413952811535425 c 1.1758388 k 0.9929878 m 4.007803\n",
      "177 Train Loss 13.23024 Test RE 0.020791945500000228 c 1.1550995 k 0.9891384 m 4.0654736\n",
      "178 Train Loss 12.208603 Test RE 0.017833042136752658 c 1.1305602 k 0.9886375 m 4.1642194\n",
      "179 Train Loss 10.121276 Test RE 0.015567500207048043 c 1.0988903 k 0.99379766 m 4.331768\n",
      "180 Train Loss 9.25013 Test RE 0.014239578223442876 c 1.0962362 k 0.9910377 m 4.3427215\n",
      "181 Train Loss 8.347162 Test RE 0.013796750379302761 c 1.0898408 k 0.99176633 m 4.3992743\n",
      "182 Train Loss 6.8615236 Test RE 0.010888047268922589 c 1.0827627 k 0.9983032 m 4.51952\n",
      "183 Train Loss 6.1667304 Test RE 0.00904030610635737 c 1.0745218 k 0.99546057 m 4.5653024\n",
      "184 Train Loss 5.1528788 Test RE 0.008696331517528097 c 1.0564257 k 0.99604464 m 4.6144953\n",
      "185 Train Loss 4.3937283 Test RE 0.008612462866440846 c 1.0495929 k 0.9964632 m 4.669311\n",
      "186 Train Loss 4.015278 Test RE 0.007492583268343948 c 1.0444161 k 0.99839497 m 4.7303257\n",
      "187 Train Loss 3.6658628 Test RE 0.007007897349795294 c 1.041111 k 0.9973259 m 4.775591\n",
      "188 Train Loss 3.0850236 Test RE 0.005713483860203533 c 1.0331191 k 0.9965998 m 4.826044\n",
      "189 Train Loss 2.6554153 Test RE 0.005341856918302844 c 1.0337405 k 0.9978642 m 4.8614926\n",
      "190 Train Loss 2.431037 Test RE 0.005466376421907829 c 1.0348986 k 0.9966491 m 4.909709\n",
      "191 Train Loss 2.1740959 Test RE 0.004541418038237419 c 1.0315905 k 0.99851906 m 4.9459696\n",
      "192 Train Loss 1.9199845 Test RE 0.00450425633414883 c 1.0199643 k 1.0006157 m 4.95171\n",
      "193 Train Loss 1.8501173 Test RE 0.004550850016525331 c 1.0152185 k 0.99970174 m 4.949385\n",
      "194 Train Loss 1.7357409 Test RE 0.004333596606264502 c 1.0104401 k 1.0001229 m 4.964278\n",
      "195 Train Loss 1.6605768 Test RE 0.004005898104220385 c 1.013315 k 0.9999739 m 4.9810567\n",
      "196 Train Loss 1.5881323 Test RE 0.0038517350026857507 c 1.012321 k 1.0001467 m 4.9754434\n",
      "197 Train Loss 1.5305309 Test RE 0.0038388429953957904 c 1.008424 k 1.0008684 m 4.9658537\n",
      "198 Train Loss 1.4647346 Test RE 0.003622449294129656 c 1.0036577 k 1.000181 m 4.96878\n",
      "199 Train Loss 1.4220166 Test RE 0.003360176883291345 c 1.0032004 k 0.9991394 m 4.9730177\n",
      "Training time: 87.67\n",
      "Training time: 87.67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 694.64624 Test RE 0.23219006589890073 c 0.055875506 k 0.96794564 m 3.537541e-05\n",
      "1 Train Loss 497.96597 Test RE 0.2208615404746107 c 0.057562046 k 1.0080131 m 3.688448e-05\n",
      "2 Train Loss 495.8376 Test RE 0.22046756642069346 c 0.058031872 k 1.0247921 m 3.759793e-05\n",
      "3 Train Loss 489.58826 Test RE 0.21924945206156668 c 0.057676584 k 1.0200374 m 3.7958816e-05\n",
      "4 Train Loss 487.3299 Test RE 0.21842706928192687 c 0.056910004 k 1.0096899 m 3.8249058e-05\n",
      "5 Train Loss 483.56448 Test RE 0.21758462706033527 c 0.05625916 k 1.0138959 m 3.8943497e-05\n",
      "6 Train Loss 480.775 Test RE 0.2166926084023953 c 0.058120362 k 1.0203664 m 3.780751e-05\n",
      "7 Train Loss 477.3763 Test RE 0.21562423136052586 c 0.058735725 k 1.0147768 m 3.7605034e-05\n",
      "8 Train Loss 470.71536 Test RE 0.21413747002647684 c 0.061701793 k 1.0163329 m 3.505365e-05\n",
      "9 Train Loss 463.25482 Test RE 0.2121324443317303 c 0.06408781 k 1.0224305 m 3.2843087e-05\n",
      "10 Train Loss 453.556 Test RE 0.20964520803607437 c 0.06405096 k 1.018609 m 3.446641e-05\n",
      "11 Train Loss 412.38663 Test RE 0.1985601411651729 c 0.06966627 k 1.0279274 m 4.245238e-05\n",
      "12 Train Loss 381.0921 Test RE 0.18941052659794963 c 0.07172959 k 1.0152856 m 7.351907e-05\n",
      "13 Train Loss 359.4162 Test RE 0.1793697260099475 c 0.07659582 k 1.0408858 m 0.0001603202\n",
      "14 Train Loss 344.38 Test RE 0.17463769735032328 c 0.07788674 k 1.0250953 m 0.0002672549\n",
      "15 Train Loss 316.65463 Test RE 0.16626267792580268 c 0.08044797 k 1.0077666 m 0.00047558\n",
      "16 Train Loss 285.19934 Test RE 0.14785457230491153 c 0.08520689 k 1.012993 m 0.0007081743\n",
      "17 Train Loss 273.75977 Test RE 0.13902266734987187 c 0.08736267 k 0.9997867 m 0.0010084631\n",
      "18 Train Loss 265.70056 Test RE 0.1299936744540468 c 0.08829405 k 0.9878443 m 0.001457433\n",
      "19 Train Loss 256.53568 Test RE 0.1241218368436936 c 0.09001663 k 0.9895399 m 0.0022479459\n",
      "20 Train Loss 248.32513 Test RE 0.11722152519119082 c 0.0949717 k 1.0036705 m 0.0035063475\n",
      "21 Train Loss 246.95242 Test RE 0.11640629153225576 c 0.09442066 k 0.9961013 m 0.0033584083\n",
      "22 Train Loss 246.11833 Test RE 0.1135785124770737 c 0.09461414 k 0.99273217 m 0.0037497506\n",
      "23 Train Loss 245.26974 Test RE 0.10889959750799463 c 0.096904874 k 0.9916555 m 0.0060189352\n",
      "24 Train Loss 244.78502 Test RE 0.11038634960235008 c 0.10144308 k 0.9894824 m 0.010168216\n",
      "25 Train Loss 244.13234 Test RE 0.11076840217071286 c 0.10631832 k 0.9925796 m 0.014448826\n",
      "26 Train Loss 243.63763 Test RE 0.10883634446525535 c 0.110047124 k 0.9939865 m 0.017999155\n",
      "27 Train Loss 242.95345 Test RE 0.10903255152676636 c 0.11753907 k 0.9922529 m 0.025033774\n",
      "28 Train Loss 242.41342 Test RE 0.10961754443067002 c 0.1265956 k 0.99051476 m 0.03370304\n",
      "29 Train Loss 241.7327 Test RE 0.10952730519841704 c 0.13482139 k 0.9912682 m 0.04173252\n",
      "30 Train Loss 241.33255 Test RE 0.10805587719089628 c 0.13579135 k 0.98988277 m 0.0426614\n",
      "31 Train Loss 240.94373 Test RE 0.10794270059121593 c 0.13797513 k 0.9896568 m 0.044534005\n",
      "32 Train Loss 240.49033 Test RE 0.1076215332870731 c 0.14290904 k 0.9939816 m 0.049060207\n",
      "33 Train Loss 239.96497 Test RE 0.10806049759354869 c 0.150584 k 0.99632406 m 0.056601446\n",
      "34 Train Loss 239.375 Test RE 0.107795999838373 c 0.15344582 k 0.99002945 m 0.059754655\n",
      "35 Train Loss 238.90363 Test RE 0.10787949869213863 c 0.15816185 k 0.9907666 m 0.06424089\n",
      "36 Train Loss 238.65338 Test RE 0.10776867859723939 c 0.16075002 k 0.9929747 m 0.06662046\n",
      "37 Train Loss 237.70569 Test RE 0.10474089877364723 c 0.17297499 k 0.9871255 m 0.07961246\n",
      "38 Train Loss 236.57742 Test RE 0.10506196516753298 c 0.18624231 k 0.98900735 m 0.09336243\n",
      "39 Train Loss 235.5967 Test RE 0.10610722074659151 c 0.1970361 k 0.9873737 m 0.10485446\n",
      "40 Train Loss 234.40927 Test RE 0.10395299819629455 c 0.21292001 k 0.99184704 m 0.12148663\n",
      "41 Train Loss 233.4967 Test RE 0.10497800066449309 c 0.22043635 k 0.98540956 m 0.1295139\n",
      "42 Train Loss 233.0857 Test RE 0.10437706143430048 c 0.22394276 k 0.9866131 m 0.13293853\n",
      "43 Train Loss 232.8328 Test RE 0.10425781480396723 c 0.22458377 k 0.98715913 m 0.13337798\n",
      "44 Train Loss 231.7146 Test RE 0.10333494795611273 c 0.23836204 k 0.9825271 m 0.14779705\n",
      "45 Train Loss 231.07948 Test RE 0.10383630382973819 c 0.24842648 k 0.98838615 m 0.15800153\n",
      "46 Train Loss 230.65485 Test RE 0.10335087505536251 c 0.24879938 k 0.99288476 m 0.15807663\n",
      "47 Train Loss 230.02402 Test RE 0.10304329600893952 c 0.2577132 k 0.9891413 m 0.16769984\n",
      "48 Train Loss 229.64369 Test RE 0.10245841076816961 c 0.26031402 k 0.9872273 m 0.17049812\n",
      "49 Train Loss 229.24712 Test RE 0.10112432393993988 c 0.26698786 k 0.9835736 m 0.17738308\n",
      "50 Train Loss 228.62317 Test RE 0.1018165901718412 c 0.27462733 k 0.98023665 m 0.18535674\n",
      "51 Train Loss 227.8825 Test RE 0.10164563202560463 c 0.2814724 k 0.98848397 m 0.19180724\n",
      "52 Train Loss 227.24298 Test RE 0.1024186196715879 c 0.28837729 k 0.98936874 m 0.19849119\n",
      "53 Train Loss 226.62086 Test RE 0.10208358137218375 c 0.29924193 k 0.9880944 m 0.20982009\n",
      "54 Train Loss 225.37044 Test RE 0.10003626919389573 c 0.32314786 k 0.9871416 m 0.2346502\n",
      "55 Train Loss 224.90207 Test RE 0.10089378551341843 c 0.3285905 k 0.9921781 m 0.2396467\n",
      "56 Train Loss 223.84001 Test RE 0.10053118584343403 c 0.34327218 k 0.99616516 m 0.25452477\n",
      "57 Train Loss 221.45038 Test RE 0.0987137118810995 c 0.3695634 k 0.9893324 m 0.2826516\n",
      "58 Train Loss 220.39 Test RE 0.10087753960531151 c 0.38455313 k 0.9898739 m 0.2986234\n",
      "59 Train Loss 218.67233 Test RE 0.10020324169818524 c 0.40832862 k 0.99058974 m 0.32348636\n",
      "60 Train Loss 217.71936 Test RE 0.10025480240677971 c 0.42769453 k 0.9848257 m 0.34404942\n",
      "61 Train Loss 215.71265 Test RE 0.10032925547890761 c 0.4412602 k 0.9803846 m 0.358484\n",
      "62 Train Loss 212.92526 Test RE 0.09431915703913532 c 0.45498097 k 0.982301 m 0.3731441\n",
      "63 Train Loss 210.70624 Test RE 0.09369538353168755 c 0.4839085 k 0.98375785 m 0.40428427\n",
      "64 Train Loss 209.62173 Test RE 0.09255939540337027 c 0.501253 k 0.978945 m 0.42331365\n",
      "65 Train Loss 208.70697 Test RE 0.08995916627289163 c 0.51520437 k 0.9706578 m 0.4389503\n",
      "66 Train Loss 207.27371 Test RE 0.09085284464682243 c 0.5246748 k 0.97842395 m 0.44912338\n",
      "67 Train Loss 204.81598 Test RE 0.09351673515198927 c 0.5465077 k 0.98419386 m 0.47335988\n",
      "68 Train Loss 202.86215 Test RE 0.09317408093047579 c 0.56238306 k 0.9825132 m 0.4919284\n",
      "69 Train Loss 200.73064 Test RE 0.08769003018557915 c 0.5911053 k 0.97853005 m 0.5240392\n",
      "70 Train Loss 196.86368 Test RE 0.08667771458464313 c 0.6281031 k 0.98050404 m 0.56412023\n",
      "71 Train Loss 195.94801 Test RE 0.09078659776417476 c 0.6363725 k 0.9826749 m 0.5732154\n",
      "72 Train Loss 193.82523 Test RE 0.08882293128833592 c 0.6510983 k 0.9837266 m 0.59003294\n",
      "73 Train Loss 192.19969 Test RE 0.08628767435652669 c 0.6642249 k 0.9869095 m 0.60395616\n",
      "74 Train Loss 190.98654 Test RE 0.08790826428260248 c 0.672674 k 0.98144734 m 0.6137165\n",
      "75 Train Loss 189.78119 Test RE 0.08483242491985014 c 0.68561935 k 0.9759598 m 0.6288353\n",
      "76 Train Loss 188.72679 Test RE 0.08489405288733853 c 0.702985 k 0.9753928 m 0.64801264\n",
      "77 Train Loss 188.26352 Test RE 0.08543722201571759 c 0.7045503 k 0.9799811 m 0.6488321\n",
      "78 Train Loss 187.89853 Test RE 0.08478683617620142 c 0.7140195 k 0.9811201 m 0.6587332\n",
      "79 Train Loss 187.5885 Test RE 0.0842255771278968 c 0.7191663 k 0.9784295 m 0.6646364\n",
      "80 Train Loss 187.30789 Test RE 0.08422808265138432 c 0.7212231 k 0.97646767 m 0.6667223\n",
      "81 Train Loss 186.5419 Test RE 0.08317965259717369 c 0.7291275 k 0.9706721 m 0.67582643\n",
      "82 Train Loss 185.35803 Test RE 0.08419006956288753 c 0.7354569 k 0.97701454 m 0.682425\n",
      "83 Train Loss 184.64307 Test RE 0.0834244827601568 c 0.7405372 k 0.9788017 m 0.6880876\n",
      "84 Train Loss 183.73596 Test RE 0.0832462644260815 c 0.7509755 k 0.9784121 m 0.7006682\n",
      "85 Train Loss 182.27505 Test RE 0.08289416815320697 c 0.77613807 k 0.98327357 m 0.7293299\n",
      "86 Train Loss 180.80899 Test RE 0.08562011586633894 c 0.7895514 k 0.98327553 m 0.74568826\n",
      "87 Train Loss 179.66266 Test RE 0.08450724584216161 c 0.7965524 k 0.98759353 m 0.75348645\n",
      "88 Train Loss 178.33508 Test RE 0.08366884549331767 c 0.8108652 k 0.98486906 m 0.7692289\n",
      "89 Train Loss 176.89677 Test RE 0.08171849874661971 c 0.83145946 k 0.97916967 m 0.7932876\n",
      "90 Train Loss 175.26024 Test RE 0.08225720814906684 c 0.8438797 k 0.9742989 m 0.80725634\n",
      "91 Train Loss 174.50648 Test RE 0.08194639489965637 c 0.8512269 k 0.9831261 m 0.8145491\n",
      "92 Train Loss 173.7985 Test RE 0.08161581864730705 c 0.8675444 k 0.9876063 m 0.83208483\n",
      "93 Train Loss 173.04703 Test RE 0.08239962322055759 c 0.8756654 k 0.98304254 m 0.84133935\n",
      "94 Train Loss 171.46603 Test RE 0.08336422190082203 c 0.8878276 k 0.9788368 m 0.8557092\n",
      "95 Train Loss 170.20703 Test RE 0.08435287182789522 c 0.8982987 k 0.9843258 m 0.8669856\n",
      "96 Train Loss 169.06674 Test RE 0.08286267957739696 c 0.9109307 k 0.98274463 m 0.881372\n",
      "97 Train Loss 166.24776 Test RE 0.07908066631410723 c 0.94381785 k 0.97503585 m 0.9173508\n",
      "98 Train Loss 165.03876 Test RE 0.08186275490530757 c 0.9695227 k 0.98227733 m 0.9449355\n",
      "99 Train Loss 163.50447 Test RE 0.0808155795714067 c 0.9868924 k 0.9872267 m 0.9640502\n",
      "100 Train Loss 160.76192 Test RE 0.0807469497048471 c 0.9954394 k 0.98692614 m 0.97384053\n",
      "101 Train Loss 157.29333 Test RE 0.07991947241448909 c 1.0288112 k 0.98279715 m 1.0115101\n",
      "102 Train Loss 152.00748 Test RE 0.07494974889220071 c 1.0593846 k 0.9678541 m 1.0477821\n",
      "103 Train Loss 149.34198 Test RE 0.07531754394247071 c 1.0983056 k 0.9739262 m 1.0914726\n",
      "104 Train Loss 147.01924 Test RE 0.07453307083320648 c 1.125555 k 0.9777048 m 1.1218778\n",
      "105 Train Loss 146.30592 Test RE 0.07455139074344137 c 1.1330913 k 0.9757772 m 1.1304263\n",
      "106 Train Loss 145.13812 Test RE 0.07572750594750288 c 1.1437062 k 0.9792283 m 1.1415298\n",
      "107 Train Loss 143.943 Test RE 0.0741233516823075 c 1.1595843 k 0.9854192 m 1.1588072\n",
      "108 Train Loss 142.47385 Test RE 0.07608651942056487 c 1.1696392 k 0.9905961 m 1.1696696\n",
      "109 Train Loss 141.20547 Test RE 0.07540095346674931 c 1.1744148 k 0.9872496 m 1.1745903\n",
      "110 Train Loss 139.21165 Test RE 0.0731183551265358 c 1.1885659 k 0.9768628 m 1.1912795\n",
      "111 Train Loss 137.86032 Test RE 0.07159434498844013 c 1.2012028 k 0.97527844 m 1.2060075\n",
      "112 Train Loss 135.59628 Test RE 0.07444524714829433 c 1.2198701 k 0.97524834 m 1.2270566\n",
      "113 Train Loss 134.66579 Test RE 0.07484204624439517 c 1.2398865 k 0.9850979 m 1.248754\n",
      "114 Train Loss 133.4787 Test RE 0.07275190731648763 c 1.2559693 k 0.98624474 m 1.2671971\n",
      "115 Train Loss 131.91342 Test RE 0.07277852682467813 c 1.2584167 k 0.9772682 m 1.2708148\n",
      "116 Train Loss 128.9672 Test RE 0.0706418281725918 c 1.2917755 k 0.98411393 m 1.3083019\n",
      "117 Train Loss 124.93016 Test RE 0.07009617183857127 c 1.3368884 k 0.97824246 m 1.3600276\n",
      "118 Train Loss 122.44879 Test RE 0.06993648586541684 c 1.3540688 k 0.97958106 m 1.3786678\n",
      "119 Train Loss 121.776825 Test RE 0.07161799854405032 c 1.3581623 k 0.9784964 m 1.3831306\n",
      "120 Train Loss 120.82932 Test RE 0.07288689874825341 c 1.3592162 k 0.9776481 m 1.3841504\n",
      "121 Train Loss 119.79074 Test RE 0.07315089311182613 c 1.3619124 k 0.9780929 m 1.3864955\n",
      "122 Train Loss 119.07214 Test RE 0.07293997234711862 c 1.3636881 k 0.9800059 m 1.3880324\n",
      "123 Train Loss 118.061035 Test RE 0.07241351864111237 c 1.3652545 k 0.98055995 m 1.3899224\n",
      "124 Train Loss 117.24038 Test RE 0.07135966133875125 c 1.3661754 k 0.97377855 m 1.3913834\n",
      "125 Train Loss 115.72159 Test RE 0.06930650624800243 c 1.3763446 k 0.97143304 m 1.4025676\n",
      "126 Train Loss 114.92407 Test RE 0.06956070298900313 c 1.3873225 k 0.9754641 m 1.4145639\n",
      "127 Train Loss 114.43981 Test RE 0.06889516217509184 c 1.3889074 k 0.9709607 m 1.416978\n",
      "128 Train Loss 113.70593 Test RE 0.06824995922205959 c 1.3918889 k 0.9723349 m 1.4206483\n",
      "129 Train Loss 113.244415 Test RE 0.06857304323591777 c 1.3963344 k 0.9769626 m 1.4253746\n",
      "130 Train Loss 112.79426 Test RE 0.06922050648434987 c 1.4042431 k 0.9753108 m 1.4341531\n",
      "131 Train Loss 111.92732 Test RE 0.06649817562930879 c 1.419705 k 0.97568125 m 1.4515333\n",
      "132 Train Loss 110.04558 Test RE 0.06726575172235816 c 1.4300134 k 0.9755934 m 1.463979\n",
      "133 Train Loss 109.20123 Test RE 0.06846947574905948 c 1.4374064 k 0.9772725 m 1.47274\n",
      "134 Train Loss 109.02579 Test RE 0.06807306122037271 c 1.4433678 k 0.9785445 m 1.4795339\n",
      "135 Train Loss 108.80298 Test RE 0.0680723421195374 c 1.451148 k 0.9796598 m 1.4882756\n",
      "136 Train Loss 108.05874 Test RE 0.0689203802672365 c 1.4546258 k 0.97987556 m 1.4918413\n",
      "137 Train Loss 107.51209 Test RE 0.06906455165606927 c 1.4589916 k 0.97657394 m 1.4972495\n",
      "138 Train Loss 106.550415 Test RE 0.06858358593285556 c 1.4806255 k 0.9787777 m 1.522095\n",
      "139 Train Loss 105.90872 Test RE 0.06810126864117741 c 1.4878379 k 0.9792403 m 1.5300827\n",
      "140 Train Loss 103.893845 Test RE 0.06817478801753565 c 1.5226723 k 0.97073746 m 1.5705712\n",
      "141 Train Loss 102.90821 Test RE 0.0693405866452813 c 1.5435584 k 0.9666871 m 1.594851\n",
      "142 Train Loss 101.37425 Test RE 0.06572776269538287 c 1.5663782 k 0.9682998 m 1.6213064\n",
      "143 Train Loss 99.543076 Test RE 0.06703240077741997 c 1.5631009 k 0.9737579 m 1.6178344\n",
      "144 Train Loss 96.54845 Test RE 0.06820339119493708 c 1.5899227 k 0.9679884 m 1.6498519\n",
      "145 Train Loss 95.33605 Test RE 0.06707863876393372 c 1.5934906 k 0.96637446 m 1.6546178\n",
      "146 Train Loss 94.58766 Test RE 0.06569952487546814 c 1.5988126 k 0.9727985 m 1.6605635\n",
      "147 Train Loss 94.2551 Test RE 0.06704040265959796 c 1.6053836 k 0.97191566 m 1.6683321\n",
      "148 Train Loss 93.85128 Test RE 0.06662700199704046 c 1.6156664 k 0.97005 m 1.6806586\n",
      "149 Train Loss 92.909 Test RE 0.06520136857046244 c 1.63354 k 0.9728403 m 1.7017742\n",
      "150 Train Loss 92.62703 Test RE 0.06583783920605668 c 1.639622 k 0.9712745 m 1.709036\n",
      "151 Train Loss 92.4594 Test RE 0.0656267711634167 c 1.6470691 k 0.96975666 m 1.7176788\n",
      "152 Train Loss 91.99799 Test RE 0.0657340237196732 c 1.6580211 k 0.9721455 m 1.7301496\n",
      "153 Train Loss 91.60289 Test RE 0.06626344180289293 c 1.6695048 k 0.97231895 m 1.7433451\n",
      "154 Train Loss 91.27397 Test RE 0.06538329713949012 c 1.6760182 k 0.9743444 m 1.7507373\n",
      "155 Train Loss 91.17473 Test RE 0.06545281153906861 c 1.6728461 k 0.9743266 m 1.7471837\n",
      "156 Train Loss 91.064285 Test RE 0.06565343148983067 c 1.6717608 k 0.97387457 m 1.7460113\n",
      "157 Train Loss 90.99048 Test RE 0.06602006718795862 c 1.675372 k 0.97467947 m 1.7501305\n",
      "158 Train Loss 90.76122 Test RE 0.06636670074551998 c 1.6817884 k 0.97414654 m 1.7577207\n",
      "159 Train Loss 90.49114 Test RE 0.0663497643429599 c 1.6873258 k 0.97487855 m 1.7643211\n",
      "160 Train Loss 90.08432 Test RE 0.06660297249337196 c 1.6872779 k 0.9740128 m 1.7645417\n",
      "161 Train Loss 89.95279 Test RE 0.06601796790565745 c 1.6850095 k 0.97112256 m 1.7622224\n",
      "162 Train Loss 89.87317 Test RE 0.06609247954155124 c 1.6809523 k 0.9708378 m 1.7576251\n",
      "163 Train Loss 89.777985 Test RE 0.0661930558508759 c 1.6781545 k 0.97152877 m 1.754271\n",
      "164 Train Loss 89.71124 Test RE 0.06631584110949515 c 1.6770451 k 0.97090745 m 1.7529261\n",
      "165 Train Loss 89.66379 Test RE 0.06615091027339061 c 1.6783121 k 0.9702027 m 1.7543205\n",
      "166 Train Loss 89.623764 Test RE 0.06614199494163601 c 1.6801144 k 0.97035074 m 1.7562798\n",
      "167 Train Loss 89.43492 Test RE 0.06607330772964831 c 1.6895932 k 0.9716554 m 1.7671049\n",
      "168 Train Loss 88.92691 Test RE 0.06598930767002466 c 1.7143227 k 0.9721879 m 1.7958915\n",
      "169 Train Loss 88.484116 Test RE 0.06708396860409242 c 1.7458141 k 0.96840435 m 1.832745\n",
      "170 Train Loss 87.96209 Test RE 0.06586100930966773 c 1.764368 k 0.9695894 m 1.8541746\n",
      "171 Train Loss 87.21679 Test RE 0.06501354718301079 c 1.7803285 k 0.97104853 m 1.8720322\n",
      "172 Train Loss 86.80037 Test RE 0.06584920563729382 c 1.7786375 k 0.9696947 m 1.8698931\n",
      "173 Train Loss 86.53538 Test RE 0.06641809436030502 c 1.7818744 k 0.9689449 m 1.8735808\n",
      "174 Train Loss 86.28096 Test RE 0.06644891313220998 c 1.7875203 k 0.9708299 m 1.8798511\n",
      "175 Train Loss 85.8197 Test RE 0.06605979658727663 c 1.7910624 k 0.9761796 m 1.8837017\n",
      "176 Train Loss 85.33368 Test RE 0.06612741118476209 c 1.7915529 k 0.97258663 m 1.8848561\n",
      "177 Train Loss 85.09563 Test RE 0.0660425914762024 c 1.7945926 k 0.97140837 m 1.8884989\n",
      "178 Train Loss 84.73511 Test RE 0.06617056941378867 c 1.8014262 k 0.97068983 m 1.8967084\n",
      "179 Train Loss 84.70499 Test RE 0.06600284453174741 c 1.8026626 k 0.97044265 m 1.8982525\n",
      "180 Train Loss 84.64807 Test RE 0.06601572314887855 c 1.8085463 k 0.97163457 m 1.9050452\n",
      "181 Train Loss 84.59119 Test RE 0.06628754271876597 c 1.8198442 k 0.97280586 m 1.9181144\n",
      "182 Train Loss 84.57052 Test RE 0.0662698262784297 c 1.8242569 k 0.972239 m 1.9233388\n",
      "183 Train Loss 84.52069 Test RE 0.06619842534776738 c 1.8258727 k 0.9721538 m 1.9251385\n",
      "184 Train Loss 84.48016 Test RE 0.0663299314535722 c 1.8266102 k 0.97242165 m 1.9259645\n",
      "185 Train Loss 84.466385 Test RE 0.06637899896492207 c 1.8270442 k 0.97268856 m 1.9264469\n",
      "186 Train Loss 84.45522 Test RE 0.06640571007628099 c 1.8271186 k 0.9722414 m 1.9265755\n",
      "187 Train Loss 84.435616 Test RE 0.06626136540993369 c 1.8288141 k 0.97153366 m 1.9287087\n",
      "188 Train Loss 84.39681 Test RE 0.06586413247439545 c 1.8349055 k 0.97218794 m 1.9359211\n",
      "189 Train Loss 84.33722 Test RE 0.0664314954446795 c 1.8385508 k 0.97260976 m 1.9403077\n",
      "190 Train Loss 84.19217 Test RE 0.06684012600113223 c 1.8480641 k 0.97162855 m 1.9519432\n",
      "191 Train Loss 84.07158 Test RE 0.06638353902475792 c 1.8555999 k 0.9720558 m 1.9610827\n",
      "192 Train Loss 83.969284 Test RE 0.06628928320967496 c 1.8547792 k 0.9724692 m 1.9603813\n",
      "193 Train Loss 83.87891 Test RE 0.06648171905655437 c 1.8561187 k 0.9712607 m 1.9622611\n",
      "194 Train Loss 83.769 Test RE 0.06667047351881043 c 1.8678479 k 0.9730337 m 1.9762741\n",
      "195 Train Loss 83.61983 Test RE 0.0668087018115638 c 1.8838464 k 0.97450924 m 1.995416\n",
      "196 Train Loss 83.54384 Test RE 0.06644316923082887 c 1.8850738 k 0.9737569 m 1.9970928\n",
      "197 Train Loss 83.49722 Test RE 0.06651931481491129 c 1.8813161 k 0.97452515 m 1.9926158\n",
      "198 Train Loss 83.4719 Test RE 0.06643860888279678 c 1.8800567 k 0.9747536 m 1.9910896\n",
      "199 Train Loss 83.42956 Test RE 0.06640587008719906 c 1.8832568 k 0.97586507 m 1.9950367\n",
      "Training time: 88.52\n",
      "Training time: 88.52\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 2984.3848 Test RE 0.26355679023844614 c -0.30607182 k 0.6224778 m -4.389142e-05\n",
      "1 Train Loss 498.03857 Test RE 0.22091861687852 c -0.41500297 k 1.0152767 m -5.659978e-05\n",
      "2 Train Loss 495.96432 Test RE 0.2202728820504474 c -0.4138122 k 1.0113533 m -5.639997e-05\n",
      "3 Train Loss 491.52887 Test RE 0.21972275842751118 c -0.41451207 k 1.0204679 m -5.620731e-05\n",
      "4 Train Loss 491.18665 Test RE 0.21953934715585258 c -0.4154994 k 1.0240225 m -5.6287772e-05\n",
      "5 Train Loss 488.5485 Test RE 0.2189412636222409 c -0.41619495 k 1.0153033 m -5.6234083e-05\n",
      "6 Train Loss 488.1023 Test RE 0.2187667626087855 c -0.4179819 k 1.0171175 m -5.638747e-05\n",
      "7 Train Loss 487.1234 Test RE 0.21843436212030337 c -0.42096978 k 1.0245162 m -5.644722e-05\n",
      "8 Train Loss 481.3308 Test RE 0.21665968935699914 c -0.42165545 k 1.0150597 m -5.5235214e-05\n",
      "9 Train Loss 478.70505 Test RE 0.21547290210698167 c -0.4236648 k 1.0143626 m -5.4642373e-05\n",
      "10 Train Loss 478.3049 Test RE 0.21522339859147097 c -0.42490512 k 1.0182573 m -5.4229582e-05\n",
      "11 Train Loss 474.85452 Test RE 0.21399727112926167 c -0.42681623 k 1.0191399 m -5.215628e-05\n",
      "12 Train Loss 469.03964 Test RE 0.2114224965295118 c -0.43028998 k 1.0280572 m -5.069166e-05\n",
      "13 Train Loss 465.5558 Test RE 0.2115622650098796 c -0.42769372 k 1.0183154 m -5.046157e-05\n",
      "14 Train Loss 459.34003 Test RE 0.2101430818225925 c -0.4259385 k 1.0086964 m -5.2834454e-05\n",
      "15 Train Loss 455.12808 Test RE 0.20730697446591706 c -0.4275326 k 1.018287 m -5.5944005e-05\n",
      "16 Train Loss 451.86847 Test RE 0.20667316792665022 c -0.42538553 k 1.0138068 m -5.844721e-05\n",
      "17 Train Loss 448.02997 Test RE 0.20531872829714604 c -0.42677945 k 1.0190952 m -6.4718355e-05\n",
      "18 Train Loss 446.61868 Test RE 0.20518122735531355 c -0.4231201 k 1.0119257 m -7.006572e-05\n",
      "19 Train Loss 441.82578 Test RE 0.2021334553671138 c -0.41726643 k 1.0108163 m -8.264382e-05\n",
      "20 Train Loss 436.2111 Test RE 0.20032592303270177 c -0.4146812 k 1.0224437 m -9.3108276e-05\n",
      "21 Train Loss 432.075 Test RE 0.19926641455906874 c -0.41193417 k 1.0191686 m -9.5197596e-05\n",
      "22 Train Loss 429.07455 Test RE 0.1987609642055069 c -0.41321674 k 1.0186983 m -9.277151e-05\n",
      "23 Train Loss 421.0062 Test RE 0.19577536932326564 c -0.41554952 k 1.0220736 m -9.469545e-05\n",
      "24 Train Loss 413.40497 Test RE 0.193506472873539 c -0.41983062 k 1.0369434 m -9.857497e-05\n",
      "25 Train Loss 401.94397 Test RE 0.19074974975551143 c -0.41152024 k 1.0134848 m -9.782528e-05\n",
      "26 Train Loss 384.95358 Test RE 0.1860572640872756 c -0.41021305 k 1.0176398 m -0.000104694576\n",
      "27 Train Loss 368.7473 Test RE 0.18233890927973265 c -0.40901706 k 1.0191381 m -9.0372836e-05\n",
      "28 Train Loss 355.17014 Test RE 0.17621177557414686 c -0.41220292 k 1.0371863 m -7.612409e-05\n",
      "29 Train Loss 348.92896 Test RE 0.172662869065696 c -0.41283578 k 1.039868 m -7.010513e-05\n",
      "30 Train Loss 342.4461 Test RE 0.17142356063803255 c -0.4100092 k 1.0197293 m -3.5645236e-05\n",
      "31 Train Loss 334.37735 Test RE 0.16856657790883453 c -0.40853179 k 1.0101042 m 5.8804748e-05\n",
      "32 Train Loss 326.35773 Test RE 0.1652255910878594 c -0.40527436 k 1.0050824 m 0.0002032111\n",
      "33 Train Loss 321.6409 Test RE 0.16382906910548478 c -0.40829888 k 1.0202328 m 0.00030337524\n",
      "34 Train Loss 316.03864 Test RE 0.16235405612644818 c -0.4090157 k 1.016796 m 0.00045606162\n",
      "35 Train Loss 313.14053 Test RE 0.16081906186156264 c -0.41000694 k 1.0204473 m 0.0004715324\n",
      "36 Train Loss 309.9821 Test RE 0.15808096618175582 c -0.4115218 k 1.0287324 m 0.0005501886\n",
      "37 Train Loss 304.17493 Test RE 0.15491461711326804 c -0.4128945 k 1.0325774 m 0.0007866254\n",
      "38 Train Loss 300.67215 Test RE 0.1516500024018982 c -0.41370678 k 1.0339785 m 0.00096166006\n",
      "39 Train Loss 293.83066 Test RE 0.1472547885628666 c -0.41045308 k 1.0249352 m 0.0011875719\n",
      "40 Train Loss 290.51575 Test RE 0.14581874305352713 c -0.40641502 k 1.0164869 m 0.0012900436\n",
      "41 Train Loss 287.8321 Test RE 0.14454425156054096 c -0.40733564 k 1.0271997 m 0.0014470059\n",
      "42 Train Loss 283.02887 Test RE 0.1420817792739247 c -0.40439385 k 1.009588 m 0.0016814702\n",
      "43 Train Loss 281.5617 Test RE 0.14093661703043683 c -0.40423968 k 1.0023174 m 0.0017988277\n",
      "44 Train Loss 280.24747 Test RE 0.13940334032963808 c -0.4075553 k 1.0096016 m 0.0020180985\n",
      "45 Train Loss 278.076 Test RE 0.13465843561244709 c -0.40871787 k 1.0110173 m 0.0024584907\n",
      "46 Train Loss 276.8139 Test RE 0.1344233524703413 c -0.407941 k 1.0088992 m 0.0027121068\n",
      "47 Train Loss 275.449 Test RE 0.13217396406809442 c -0.40789944 k 1.0090736 m 0.0031925193\n",
      "48 Train Loss 274.3004 Test RE 0.12961416430620362 c -0.40682104 k 1.0075462 m 0.0035787662\n",
      "49 Train Loss 273.2161 Test RE 0.13046741705830955 c -0.40718186 k 1.0084321 m 0.0038712458\n",
      "50 Train Loss 272.73758 Test RE 0.12988537984898565 c -0.40847558 k 1.0094609 m 0.0042008823\n",
      "51 Train Loss 271.8061 Test RE 0.12828278782686695 c -0.40905526 k 1.0081123 m 0.004617603\n",
      "52 Train Loss 271.0436 Test RE 0.1277872464289514 c -0.40779427 k 1.0047292 m 0.004804466\n",
      "53 Train Loss 270.39227 Test RE 0.12721461929874622 c -0.4081143 k 1.0040526 m 0.0054280274\n",
      "54 Train Loss 269.35858 Test RE 0.12479214213736063 c -0.40764612 k 1.0019833 m 0.0065019894\n",
      "55 Train Loss 268.52936 Test RE 0.12317913928844518 c -0.4072586 k 1.0006391 m 0.007361103\n",
      "56 Train Loss 268.15338 Test RE 0.12213924510721312 c -0.40655693 k 1.0000293 m 0.008292995\n",
      "57 Train Loss 267.81348 Test RE 0.12130300649702151 c -0.40492377 k 0.99895597 m 0.009099288\n",
      "58 Train Loss 267.31586 Test RE 0.12018588436297498 c -0.402299 k 0.99560964 m 0.010907362\n",
      "59 Train Loss 267.15927 Test RE 0.11993141159851728 c -0.40226716 k 0.9980225 m 0.011475914\n",
      "60 Train Loss 267.07062 Test RE 0.12048448928306561 c -0.40225387 k 0.9975001 m 0.011621765\n",
      "61 Train Loss 266.91266 Test RE 0.12047485496876177 c -0.4026731 k 0.9983791 m 0.012316636\n",
      "62 Train Loss 266.57526 Test RE 0.12028539297520799 c -0.40078714 k 0.99977624 m 0.014345691\n",
      "63 Train Loss 266.15048 Test RE 0.12111865048658209 c -0.3966085 k 0.9981617 m 0.016502466\n",
      "64 Train Loss 265.40878 Test RE 0.11910492819801363 c -0.39292565 k 0.99659824 m 0.018415352\n",
      "65 Train Loss 264.97806 Test RE 0.11931030748379257 c -0.3893691 k 0.9965509 m 0.02129602\n",
      "66 Train Loss 264.84875 Test RE 0.11908602640196718 c -0.38770226 k 0.9953099 m 0.022068527\n",
      "67 Train Loss 264.7625 Test RE 0.11856853437692982 c -0.38660777 k 0.9964367 m 0.023199707\n",
      "68 Train Loss 264.5807 Test RE 0.11917611544913018 c -0.38486722 k 0.99636716 m 0.02501031\n",
      "69 Train Loss 264.2108 Test RE 0.11843664481766372 c -0.3812953 k 0.99621636 m 0.028175838\n",
      "70 Train Loss 263.83954 Test RE 0.11795461653315568 c -0.37761638 k 0.99640304 m 0.032289304\n",
      "71 Train Loss 263.62192 Test RE 0.1183286296198841 c -0.3753827 k 0.9969124 m 0.035378717\n",
      "72 Train Loss 263.4082 Test RE 0.1183217806732055 c -0.3735715 k 0.996974 m 0.038386557\n",
      "73 Train Loss 263.28445 Test RE 0.11821876200844464 c -0.37211135 k 0.9972899 m 0.040258385\n",
      "74 Train Loss 263.19907 Test RE 0.1178978172712694 c -0.37079436 k 0.99703854 m 0.041436464\n",
      "75 Train Loss 263.14114 Test RE 0.1176716733912741 c -0.37037602 k 0.9963891 m 0.041773677\n",
      "76 Train Loss 263.08218 Test RE 0.11768215796926743 c -0.37009403 k 0.9963143 m 0.042549953\n",
      "77 Train Loss 263.03653 Test RE 0.11786956501372656 c -0.3695858 k 0.9969361 m 0.043543905\n",
      "78 Train Loss 262.9859 Test RE 0.11807045525574032 c -0.36901644 k 0.9977201 m 0.044716198\n",
      "79 Train Loss 262.61328 Test RE 0.11835111634936209 c -0.3638244 k 0.99699867 m 0.050038096\n",
      "80 Train Loss 260.72754 Test RE 0.11696611616887607 c -0.33683115 k 0.9941762 m 0.073745586\n",
      "81 Train Loss 259.743 Test RE 0.11760901856352382 c -0.3248704 k 1.0015744 m 0.08641076\n",
      "82 Train Loss 259.36142 Test RE 0.11756970609862917 c -0.32267144 k 0.99768084 m 0.08749563\n",
      "83 Train Loss 258.75012 Test RE 0.11676465228441324 c -0.31294078 k 0.9955483 m 0.09561393\n",
      "84 Train Loss 258.33905 Test RE 0.11664435869524192 c -0.30894974 k 0.9961837 m 0.09960917\n",
      "85 Train Loss 258.14313 Test RE 0.11661016505900475 c -0.30748892 k 0.9959126 m 0.101336084\n",
      "86 Train Loss 257.82175 Test RE 0.11697736001368217 c -0.303762 k 0.99548227 m 0.10599165\n",
      "87 Train Loss 257.43326 Test RE 0.11715221452284048 c -0.29714686 k 0.9939413 m 0.11224018\n",
      "88 Train Loss 256.86676 Test RE 0.11751742893066634 c -0.2879456 k 0.9960356 m 0.12035506\n",
      "89 Train Loss 256.55145 Test RE 0.11682918444511801 c -0.28450546 k 0.9991571 m 0.123204954\n",
      "90 Train Loss 256.1788 Test RE 0.11643111143787957 c -0.28096983 k 0.99468464 m 0.12445533\n",
      "91 Train Loss 255.9706 Test RE 0.11536676842518871 c -0.2782313 k 0.99375695 m 0.126992\n",
      "92 Train Loss 255.68506 Test RE 0.11547566640115783 c -0.2722071 k 0.99687064 m 0.13340263\n",
      "93 Train Loss 255.31372 Test RE 0.11587976364362927 c -0.2675907 k 0.995 m 0.13717385\n",
      "94 Train Loss 254.75412 Test RE 0.11459002893198977 c -0.26040643 k 0.9945432 m 0.14255497\n",
      "95 Train Loss 254.43597 Test RE 0.11265782990051719 c -0.25604767 k 0.99605507 m 0.14564882\n",
      "96 Train Loss 253.2822 Test RE 0.11389665760014893 c -0.23806056 k 0.9947036 m 0.15882339\n",
      "97 Train Loss 251.26033 Test RE 0.11275620586703143 c -0.2094665 k 0.9960169 m 0.1806864\n",
      "98 Train Loss 249.78143 Test RE 0.10946111577541583 c -0.19290131 k 0.9916504 m 0.19102193\n",
      "99 Train Loss 248.8104 Test RE 0.11064252517633537 c -0.18331414 k 0.99541116 m 0.19824402\n",
      "100 Train Loss 248.15137 Test RE 0.11214030021689153 c -0.17733173 k 0.9991246 m 0.20447865\n",
      "101 Train Loss 247.82196 Test RE 0.11140975698924284 c -0.17327957 k 0.99363875 m 0.20687069\n",
      "102 Train Loss 246.80978 Test RE 0.10887619755438178 c -0.16295822 k 0.9933677 m 0.21498552\n",
      "103 Train Loss 245.74579 Test RE 0.11155822251218837 c -0.14626554 k 0.9959481 m 0.22883922\n",
      "104 Train Loss 244.89369 Test RE 0.10882001726788239 c -0.13434365 k 0.9934053 m 0.23839815\n",
      "105 Train Loss 244.18307 Test RE 0.10833954919931073 c -0.12610118 k 0.99293137 m 0.24540576\n",
      "106 Train Loss 243.76959 Test RE 0.10805801290582238 c -0.119197965 k 0.99361175 m 0.2524129\n",
      "107 Train Loss 242.80972 Test RE 0.10738302599356665 c -0.112202324 k 0.9898319 m 0.25960255\n",
      "108 Train Loss 241.8555 Test RE 0.10815726364342457 c -0.10274829 k 0.99523866 m 0.27035695\n",
      "109 Train Loss 240.98892 Test RE 0.10719358193296274 c -0.09129612 k 0.9911557 m 0.28036165\n",
      "110 Train Loss 240.55757 Test RE 0.10904728433671602 c -0.084868476 k 0.9893292 m 0.28553188\n",
      "111 Train Loss 239.86824 Test RE 0.10900788599327904 c -0.07746874 k 0.9920693 m 0.29194093\n",
      "112 Train Loss 239.12424 Test RE 0.107005484453406 c -0.06948254 k 0.99318206 m 0.29846284\n",
      "113 Train Loss 238.17998 Test RE 0.10680773250143877 c -0.05985883 k 0.9917311 m 0.30543017\n",
      "114 Train Loss 237.53644 Test RE 0.10754325407975816 c -0.048351955 k 0.9910815 m 0.31484768\n",
      "115 Train Loss 236.98923 Test RE 0.10664213277194846 c -0.04347308 k 0.9939183 m 0.3193393\n",
      "116 Train Loss 236.11139 Test RE 0.10660512866358103 c -0.030438062 k 0.98943734 m 0.32929185\n",
      "117 Train Loss 233.65497 Test RE 0.10543176943860953 c -0.0032965182 k 0.9928586 m 0.3539936\n",
      "118 Train Loss 233.22443 Test RE 0.10635981406545139 c 0.0050995736 k 0.99563617 m 0.36192483\n",
      "119 Train Loss 232.82697 Test RE 0.10404550650489279 c 0.0104696965 k 0.99508524 m 0.36624086\n",
      "120 Train Loss 232.58633 Test RE 0.10450852607038086 c 0.011831385 k 0.9944066 m 0.36703905\n",
      "121 Train Loss 232.07417 Test RE 0.10436043711038091 c 0.018749682 k 0.9961212 m 0.37362677\n",
      "122 Train Loss 231.21823 Test RE 0.10296418980917665 c 0.032219376 k 0.9947506 m 0.386395\n",
      "123 Train Loss 229.7087 Test RE 0.10194320344092066 c 0.049277317 k 0.9889144 m 0.40202424\n",
      "124 Train Loss 228.05579 Test RE 0.10151093314478185 c 0.06464251 k 0.9909463 m 0.41643927\n",
      "125 Train Loss 226.91708 Test RE 0.10221064486560917 c 0.07689792 k 0.990697 m 0.4278383\n",
      "126 Train Loss 225.18451 Test RE 0.09978151531623972 c 0.09398108 k 0.9845309 m 0.4430417\n",
      "127 Train Loss 224.23178 Test RE 0.1004576974299977 c 0.10265629 k 0.9850281 m 0.45230922\n",
      "128 Train Loss 223.16519 Test RE 0.09991511317509906 c 0.11548218 k 0.98920935 m 0.4658926\n",
      "129 Train Loss 222.35962 Test RE 0.1007013565954401 c 0.12757723 k 0.98937464 m 0.47864628\n",
      "130 Train Loss 221.90312 Test RE 0.10031910428157177 c 0.13265139 k 0.9850171 m 0.4840008\n",
      "131 Train Loss 221.45021 Test RE 0.0993896184322189 c 0.13116592 k 0.9865443 m 0.48359707\n",
      "132 Train Loss 220.84949 Test RE 0.09932789734236522 c 0.13390462 k 0.98673064 m 0.48606995\n",
      "133 Train Loss 220.67108 Test RE 0.09888764066228035 c 0.13556948 k 0.9877413 m 0.4876132\n",
      "134 Train Loss 219.74878 Test RE 0.10005783610571352 c 0.14990042 k 0.992745 m 0.50254124\n",
      "135 Train Loss 218.57027 Test RE 0.09851861782924547 c 0.16199987 k 0.9904562 m 0.5130442\n",
      "136 Train Loss 218.00629 Test RE 0.09926352449745007 c 0.16967249 k 0.99139106 m 0.5196261\n",
      "137 Train Loss 217.47414 Test RE 0.09880799344735224 c 0.17014253 k 0.98921573 m 0.518354\n",
      "138 Train Loss 216.88254 Test RE 0.0968131359822246 c 0.17796287 k 0.990313 m 0.5249844\n",
      "139 Train Loss 216.02654 Test RE 0.09963279030841395 c 0.18950036 k 0.99054617 m 0.53566515\n",
      "140 Train Loss 214.85217 Test RE 0.09926775249375872 c 0.20664342 k 0.99029976 m 0.55036\n",
      "141 Train Loss 213.48694 Test RE 0.09793822693508993 c 0.21783006 k 0.98868924 m 0.5601153\n",
      "142 Train Loss 212.38235 Test RE 0.09320095942647776 c 0.22570884 k 0.9855392 m 0.5664703\n",
      "143 Train Loss 210.80989 Test RE 0.09372990688252396 c 0.24459572 k 0.9867859 m 0.5820784\n",
      "144 Train Loss 209.62167 Test RE 0.09470949096002404 c 0.25908202 k 0.9834706 m 0.5932435\n",
      "145 Train Loss 208.88896 Test RE 0.09132299310203468 c 0.26765138 k 0.9826258 m 0.6002344\n",
      "146 Train Loss 208.50061 Test RE 0.09346322808919161 c 0.27328658 k 0.9875367 m 0.6059625\n",
      "147 Train Loss 207.18344 Test RE 0.09473451297013702 c 0.28539675 k 0.9864606 m 0.6176342\n",
      "148 Train Loss 205.9729 Test RE 0.09201066722680139 c 0.29827535 k 0.98190707 m 0.6294801\n",
      "149 Train Loss 205.43347 Test RE 0.09356892795721389 c 0.30487838 k 0.9829208 m 0.6357116\n",
      "150 Train Loss 204.80954 Test RE 0.09322160271904378 c 0.3093124 k 0.98817295 m 0.6405911\n",
      "151 Train Loss 203.38745 Test RE 0.09138596019121957 c 0.32185778 k 0.98391455 m 0.65130824\n",
      "152 Train Loss 202.55064 Test RE 0.09178254351560289 c 0.32957768 k 0.980949 m 0.6586701\n",
      "153 Train Loss 202.06036 Test RE 0.0934873169810731 c 0.33386078 k 0.9869524 m 0.6642917\n",
      "154 Train Loss 201.1557 Test RE 0.09172981266263268 c 0.34068716 k 0.98328996 m 0.669674\n",
      "155 Train Loss 200.86908 Test RE 0.09072311272480976 c 0.34499452 k 0.9834282 m 0.67371243\n",
      "156 Train Loss 200.41203 Test RE 0.0901912794716966 c 0.35179415 k 0.9847034 m 0.6802612\n",
      "157 Train Loss 200.05289 Test RE 0.09045620910905794 c 0.35454127 k 0.98415756 m 0.68269235\n",
      "158 Train Loss 199.37268 Test RE 0.09051118423243426 c 0.3613678 k 0.98520595 m 0.68965364\n",
      "159 Train Loss 198.69266 Test RE 0.09090806023623713 c 0.36879128 k 0.9831773 m 0.69693995\n",
      "160 Train Loss 197.92715 Test RE 0.0908059983469054 c 0.3805068 k 0.98811543 m 0.7103461\n",
      "161 Train Loss 196.19559 Test RE 0.08709420119358396 c 0.39733133 k 0.9823296 m 0.72639257\n",
      "162 Train Loss 194.23645 Test RE 0.09103200976903482 c 0.41751385 k 0.98582745 m 0.7464045\n",
      "163 Train Loss 193.46591 Test RE 0.09211291858155952 c 0.43575954 k 0.99329096 m 0.7651838\n",
      "164 Train Loss 192.7204 Test RE 0.0916692743167901 c 0.44474763 k 0.9899562 m 0.7734133\n",
      "165 Train Loss 190.31842 Test RE 0.0869862136986248 c 0.4610621 k 0.9912472 m 0.79048556\n",
      "166 Train Loss 188.02756 Test RE 0.08683759717163371 c 0.47779477 k 0.98642594 m 0.8068052\n",
      "167 Train Loss 186.05446 Test RE 0.08783245372516332 c 0.4968283 k 0.98833805 m 0.82573587\n",
      "168 Train Loss 185.0134 Test RE 0.08634856183562661 c 0.50709945 k 0.99291414 m 0.836862\n",
      "169 Train Loss 183.6963 Test RE 0.08623497784305739 c 0.5189442 k 0.9840364 m 0.84702915\n",
      "170 Train Loss 181.54881 Test RE 0.08343282940152896 c 0.54458904 k 0.97508705 m 0.86937505\n",
      "171 Train Loss 179.74155 Test RE 0.08610059965326151 c 0.5568378 k 0.98421746 m 0.8824839\n",
      "172 Train Loss 178.49753 Test RE 0.08559254571300272 c 0.572505 k 0.986171 m 0.89732385\n",
      "173 Train Loss 176.89186 Test RE 0.08237251928734432 c 0.5908496 k 0.9811461 m 0.9127618\n",
      "174 Train Loss 175.84766 Test RE 0.08236856308752205 c 0.61878854 k 0.977782 m 0.93764937\n",
      "175 Train Loss 173.26837 Test RE 0.08542786585723874 c 0.64705926 k 0.9823848 m 0.96545196\n",
      "176 Train Loss 170.76025 Test RE 0.08264377228054348 c 0.65731406 k 0.98072594 m 0.97395724\n",
      "177 Train Loss 169.08224 Test RE 0.08040783676590676 c 0.67243195 k 0.9824571 m 0.9876313\n",
      "178 Train Loss 166.51102 Test RE 0.07977407146190124 c 0.7075116 k 0.9779312 m 1.01964\n",
      "179 Train Loss 163.15218 Test RE 0.07896553428212574 c 0.72082496 k 0.980879 m 1.0327017\n",
      "180 Train Loss 161.36703 Test RE 0.07859227246708786 c 0.7409125 k 0.98135406 m 1.0512458\n",
      "181 Train Loss 160.18802 Test RE 0.07948794796167412 c 0.7595764 k 0.97923243 m 1.0680496\n",
      "182 Train Loss 159.67325 Test RE 0.07955191726490915 c 0.7636161 k 0.98553187 m 1.0732907\n",
      "183 Train Loss 157.62592 Test RE 0.07928969430878657 c 0.7650987 k 0.979442 m 1.074605\n",
      "184 Train Loss 155.84277 Test RE 0.07572964124491281 c 0.77035284 k 0.97442085 m 1.080048\n",
      "185 Train Loss 154.24336 Test RE 0.07817156236950802 c 0.78328484 k 0.9785063 m 1.0939071\n",
      "186 Train Loss 153.29126 Test RE 0.07739140049207967 c 0.7931273 k 0.9805503 m 1.1037573\n",
      "187 Train Loss 151.91223 Test RE 0.07591902348777275 c 0.80074275 k 0.9853353 m 1.1125706\n",
      "188 Train Loss 150.20096 Test RE 0.07747431127527922 c 0.80933267 k 0.9789082 m 1.1206317\n",
      "189 Train Loss 149.37866 Test RE 0.075713711322361 c 0.8121206 k 0.9786897 m 1.1241769\n",
      "190 Train Loss 148.65703 Test RE 0.07351016490345001 c 0.81283116 k 0.9779562 m 1.1252007\n",
      "191 Train Loss 148.07506 Test RE 0.07400333388179468 c 0.81916434 k 0.9728901 m 1.1303089\n",
      "192 Train Loss 147.33826 Test RE 0.0752885692809265 c 0.82989764 k 0.97392535 m 1.140656\n",
      "193 Train Loss 146.68579 Test RE 0.07543733091599018 c 0.8326982 k 0.9767789 m 1.1444049\n",
      "194 Train Loss 146.03601 Test RE 0.07499609993331652 c 0.8361687 k 0.9760941 m 1.148267\n",
      "195 Train Loss 144.59813 Test RE 0.07356606308901188 c 0.8467201 k 0.9746265 m 1.1587272\n",
      "196 Train Loss 143.4242 Test RE 0.07579464356445295 c 0.858915 k 0.97766644 m 1.1715556\n",
      "197 Train Loss 142.62936 Test RE 0.07443999531662801 c 0.8639864 k 0.9813611 m 1.1769018\n",
      "198 Train Loss 142.21893 Test RE 0.0738168884727807 c 0.86385804 k 0.9809681 m 1.1759391\n",
      "199 Train Loss 142.00526 Test RE 0.07412592641541244 c 0.86519974 k 0.9804179 m 1.1762807\n",
      "Training time: 87.84\n",
      "Training time: 87.84\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 6254.0107 Test RE 0.3669518145719006 c 0.12603925 k 0.4371229 m -2.2303424e-05\n",
      "1 Train Loss 629.7102 Test RE 0.22442376671804065 c 0.17641848 k 0.8698258 m -4.8762933e-05\n",
      "2 Train Loss 493.25476 Test RE 0.2200395795711166 c 0.18964617 k 1.0012691 m -5.649396e-05\n",
      "3 Train Loss 491.96933 Test RE 0.21982737212150844 c 0.19100042 k 1.0166359 m -5.733852e-05\n",
      "4 Train Loss 491.744 Test RE 0.2196662872094852 c 0.19138782 k 1.0213612 m -5.753653e-05\n",
      "5 Train Loss 491.22116 Test RE 0.21930758513939855 c 0.19064468 k 1.0156157 m -5.6556284e-05\n",
      "6 Train Loss 488.48053 Test RE 0.2186833401838181 c 0.18401161 k 1.0170716 m -4.9519742e-05\n",
      "7 Train Loss 487.56384 Test RE 0.21804414807074649 c 0.18022706 k 1.0164527 m -4.5481705e-05\n",
      "8 Train Loss 482.30396 Test RE 0.21624390799590681 c 0.17642054 k 1.0244622 m -4.0569448e-05\n",
      "9 Train Loss 480.22678 Test RE 0.21634275948842685 c 0.17511824 k 1.0167198 m -3.926481e-05\n",
      "10 Train Loss 479.20218 Test RE 0.2161366805073187 c 0.1749872 k 1.0145221 m -4.0244096e-05\n",
      "11 Train Loss 476.69617 Test RE 0.21454836577336747 c 0.17474228 k 1.016727 m -4.278859e-05\n",
      "12 Train Loss 473.6022 Test RE 0.21329436938188834 c 0.17145951 k 1.009508 m -4.2335112e-05\n",
      "13 Train Loss 469.59933 Test RE 0.21274501959161934 c 0.16950734 k 1.0212127 m -4.2533586e-05\n",
      "14 Train Loss 462.83548 Test RE 0.21069888033542383 c 0.16608688 k 1.0134767 m -4.271784e-05\n",
      "15 Train Loss 453.91934 Test RE 0.20772448130966104 c 0.16268077 k 1.0224221 m -5.241691e-05\n",
      "16 Train Loss 442.27853 Test RE 0.20244424133070257 c 0.16210341 k 1.0220727 m -7.044017e-05\n",
      "17 Train Loss 424.53088 Test RE 0.1949834342337319 c 0.16225334 k 1.0245637 m -8.677748e-05\n",
      "18 Train Loss 388.41898 Test RE 0.18407893553365368 c 0.15862659 k 1.0239389 m -0.00012128415\n",
      "19 Train Loss 314.47653 Test RE 0.1628093537543549 c 0.15510224 k 0.99495065 m -0.00011135456\n",
      "20 Train Loss 273.1337 Test RE 0.14362798160754242 c 0.15558733 k 1.0198176 m 3.1109385e-06\n",
      "21 Train Loss 252.99979 Test RE 0.12443489202036291 c 0.15473485 k 1.0117723 m 0.00078770146\n",
      "22 Train Loss 247.14104 Test RE 0.11825908248528375 c 0.15396869 k 0.99254066 m 0.0020571142\n",
      "23 Train Loss 243.66507 Test RE 0.11032300586722703 c 0.15566151 k 0.9912634 m 0.0039129346\n",
      "24 Train Loss 242.54218 Test RE 0.10933863861816927 c 0.15941274 k 0.9925848 m 0.0080536185\n",
      "25 Train Loss 241.44263 Test RE 0.10881878819395857 c 0.16695134 k 0.9884084 m 0.016171874\n",
      "26 Train Loss 240.716 Test RE 0.10726219839773693 c 0.17525685 k 0.99294394 m 0.02473209\n",
      "27 Train Loss 239.1044 Test RE 0.10672821736062561 c 0.19431269 k 0.99046886 m 0.045279797\n",
      "28 Train Loss 236.49661 Test RE 0.10676456867893162 c 0.23058166 k 0.98939025 m 0.08388596\n",
      "29 Train Loss 234.06882 Test RE 0.10636223088405136 c 0.26097292 k 0.9902177 m 0.11773556\n",
      "30 Train Loss 232.09209 Test RE 0.10425108879539845 c 0.28428018 k 0.9896507 m 0.14551647\n",
      "31 Train Loss 228.98586 Test RE 0.10558213959212862 c 0.31476605 k 0.9903944 m 0.18099898\n",
      "32 Train Loss 227.24852 Test RE 0.10462832547841051 c 0.32816318 k 0.9920044 m 0.1959234\n",
      "33 Train Loss 222.2442 Test RE 0.10403355936164263 c 0.39887378 k 0.99303055 m 0.27710778\n",
      "34 Train Loss 218.62479 Test RE 0.09988138083054066 c 0.4455816 k 0.9825208 m 0.33374032\n",
      "35 Train Loss 212.30666 Test RE 0.0989435846289033 c 0.5187531 k 0.9836221 m 0.42054668\n",
      "36 Train Loss 207.03781 Test RE 0.09941064464551076 c 0.56246334 k 0.9898056 m 0.47343156\n",
      "37 Train Loss 195.49414 Test RE 0.09460472065761041 c 0.71016246 k 0.97714806 m 0.65120393\n",
      "38 Train Loss 183.6181 Test RE 0.09464781483718923 c 0.82528704 k 0.99465847 m 0.7888929\n",
      "39 Train Loss 169.15782 Test RE 0.09475558864321326 c 0.96717113 k 0.98662716 m 0.96267784\n",
      "40 Train Loss 149.83832 Test RE 0.08314744882957538 c 1.1807922 k 0.9888137 m 1.2208811\n",
      "41 Train Loss 127.96592 Test RE 0.07869961705648841 c 1.3187277 k 0.97303915 m 1.3906769\n",
      "42 Train Loss 112.22791 Test RE 0.07124133520643042 c 1.4524444 k 0.991254 m 1.5518284\n",
      "43 Train Loss 103.08258 Test RE 0.07061831810481159 c 1.5364937 k 0.9887934 m 1.6525022\n",
      "44 Train Loss 97.74579 Test RE 0.06717742563703438 c 1.594441 k 0.96726954 m 1.7222178\n",
      "45 Train Loss 95.106865 Test RE 0.0648232835371174 c 1.6729864 k 0.9720249 m 1.8155584\n",
      "46 Train Loss 92.90935 Test RE 0.06723800845835329 c 1.7488669 k 0.9760098 m 1.9071399\n",
      "47 Train Loss 89.987946 Test RE 0.06537266055154733 c 1.7874995 k 0.9786241 m 1.956615\n",
      "48 Train Loss 87.69454 Test RE 0.06305403150659918 c 1.8484976 k 0.97779655 m 2.033627\n",
      "49 Train Loss 86.645584 Test RE 0.06620516051941312 c 1.8649985 k 0.97634757 m 2.0556993\n",
      "50 Train Loss 85.62921 Test RE 0.06607381963933634 c 1.8611716 k 0.97002834 m 2.0550327\n",
      "51 Train Loss 84.82286 Test RE 0.06435376486483566 c 1.8827188 k 0.97149295 m 2.0848935\n",
      "52 Train Loss 84.37457 Test RE 0.06469908662938159 c 1.9043622 k 0.9761143 m 2.1144855\n",
      "53 Train Loss 83.10858 Test RE 0.066176736147333 c 1.9320574 k 0.97677845 m 2.163155\n",
      "54 Train Loss 82.82614 Test RE 0.06579398389002415 c 1.924433 k 0.9726076 m 2.1602578\n",
      "55 Train Loss 82.45082 Test RE 0.06509267753860097 c 1.8859382 k 0.97436345 m 2.125101\n",
      "56 Train Loss 82.1187 Test RE 0.06546005414564812 c 1.8660779 k 0.97725004 m 2.1068752\n",
      "57 Train Loss 81.8495 Test RE 0.06464961628266251 c 1.8695958 k 0.9756528 m 2.1126199\n",
      "58 Train Loss 81.5423 Test RE 0.06387249468779203 c 1.8744466 k 0.97296953 m 2.1319878\n",
      "59 Train Loss 81.081665 Test RE 0.06478747221412891 c 1.9044224 k 0.974618 m 2.1887743\n",
      "60 Train Loss 80.31221 Test RE 0.06374789591176078 c 1.948431 k 0.9733083 m 2.267863\n",
      "61 Train Loss 79.77393 Test RE 0.06373978609406702 c 1.954807 k 0.9742778 m 2.2855167\n",
      "62 Train Loss 79.53533 Test RE 0.063842833221673 c 1.9610406 k 0.9759496 m 2.2996478\n",
      "63 Train Loss 79.22492 Test RE 0.06318046326973309 c 1.949487 k 0.97587657 m 2.2955143\n",
      "64 Train Loss 78.85886 Test RE 0.06331028300145156 c 1.9548303 k 0.9730966 m 2.3142033\n",
      "65 Train Loss 78.26432 Test RE 0.0629760047149766 c 1.9665642 k 0.9730631 m 2.3595464\n",
      "66 Train Loss 77.57668 Test RE 0.06284109962314285 c 1.9724789 k 0.9790346 m 2.3948917\n",
      "67 Train Loss 76.720184 Test RE 0.061924574735187254 c 1.9499024 k 0.9792709 m 2.3912652\n",
      "68 Train Loss 75.60783 Test RE 0.061180415375361855 c 1.8850684 k 0.97658515 m 2.3426218\n",
      "69 Train Loss 75.19014 Test RE 0.06181664212942121 c 1.8596767 k 0.97570974 m 2.3261178\n",
      "70 Train Loss 73.87958 Test RE 0.06251636360893853 c 1.8489487 k 0.980721 m 2.3562624\n",
      "71 Train Loss 71.720505 Test RE 0.061005833827462205 c 1.8497187 k 0.97865564 m 2.3982303\n",
      "72 Train Loss 70.6254 Test RE 0.0606828172772483 c 1.8221982 k 0.97584045 m 2.4124856\n",
      "73 Train Loss 69.96054 Test RE 0.06063249051837847 c 1.8175614 k 0.97851056 m 2.4295592\n",
      "74 Train Loss 68.94466 Test RE 0.0590781743139645 c 1.8342481 k 0.9762718 m 2.500564\n",
      "75 Train Loss 67.7139 Test RE 0.05903862189734659 c 1.8224663 k 0.98068166 m 2.555762\n",
      "76 Train Loss 65.654465 Test RE 0.056722570563456705 c 1.7626436 k 0.97927153 m 2.5714366\n",
      "77 Train Loss 62.955177 Test RE 0.053921398946148835 c 1.8082917 k 0.97668606 m 2.6854687\n",
      "78 Train Loss 61.98745 Test RE 0.0544478349191747 c 1.8612145 k 0.97946197 m 2.7913706\n",
      "79 Train Loss 60.528015 Test RE 0.05272618481021197 c 1.8289973 k 0.9765849 m 2.7920268\n",
      "80 Train Loss 59.2493 Test RE 0.05162744272893674 c 1.7881016 k 0.9725275 m 2.7883754\n",
      "81 Train Loss 57.009098 Test RE 0.05153534617711812 c 1.8024869 k 0.9784683 m 2.9149952\n",
      "82 Train Loss 54.04939 Test RE 0.0509139288795769 c 1.7880237 k 0.97872674 m 2.9773893\n",
      "83 Train Loss 52.84213 Test RE 0.05081642520063779 c 1.7669584 k 0.979361 m 2.9894104\n",
      "84 Train Loss 51.21678 Test RE 0.05157698453322986 c 1.7386358 k 0.9826764 m 3.0247486\n",
      "85 Train Loss 49.907665 Test RE 0.051939284642341745 c 1.7396938 k 0.98133695 m 3.0693793\n",
      "86 Train Loss 48.243244 Test RE 0.049755048795405654 c 1.7142044 k 0.97804946 m 3.079608\n",
      "87 Train Loss 47.15294 Test RE 0.04762084055233801 c 1.7102293 k 0.98634225 m 3.1317\n",
      "88 Train Loss 45.41465 Test RE 0.048487622710710616 c 1.6993492 k 0.9904511 m 3.189103\n",
      "89 Train Loss 43.42356 Test RE 0.045484262597668745 c 1.6725917 k 0.98134387 m 3.196851\n",
      "90 Train Loss 42.407272 Test RE 0.04703018410942224 c 1.6445142 k 0.982286 m 3.187877\n",
      "91 Train Loss 39.66734 Test RE 0.04572263611169047 c 1.6423044 k 0.9815495 m 3.269289\n",
      "92 Train Loss 38.127304 Test RE 0.042897770525210585 c 1.6671706 k 0.9846122 m 3.3651917\n",
      "93 Train Loss 35.948296 Test RE 0.03943529539291422 c 1.6436092 k 0.9807943 m 3.4419553\n",
      "94 Train Loss 33.69202 Test RE 0.03694691229461871 c 1.605788 k 0.98074704 m 3.4867506\n",
      "95 Train Loss 30.748108 Test RE 0.03399320133648212 c 1.5320206 k 0.9871837 m 3.5727212\n",
      "96 Train Loss 27.686022 Test RE 0.0336315680667307 c 1.4831432 k 0.9873345 m 3.6189647\n",
      "97 Train Loss 25.66133 Test RE 0.031645946537005705 c 1.4570404 k 0.98530966 m 3.6931856\n",
      "98 Train Loss 21.249702 Test RE 0.028644375691656922 c 1.4223232 k 0.980076 m 3.840895\n",
      "99 Train Loss 18.279951 Test RE 0.024978547924005792 c 1.3599007 k 0.9835351 m 3.9218948\n",
      "100 Train Loss 16.328365 Test RE 0.024466958321304938 c 1.3299209 k 0.985184 m 3.9492927\n",
      "101 Train Loss 15.143645 Test RE 0.023292836214468957 c 1.3110198 k 0.98141474 m 3.9556491\n",
      "102 Train Loss 12.471985 Test RE 0.020560424199389426 c 1.2730981 k 0.99142283 m 4.06179\n",
      "103 Train Loss 10.1213045 Test RE 0.018426181122951312 c 1.2407631 k 0.9915799 m 4.132714\n",
      "104 Train Loss 9.190715 Test RE 0.014672147824927992 c 1.2118955 k 0.9924109 m 4.1752744\n",
      "105 Train Loss 7.8028593 Test RE 0.01617104277033967 c 1.1824836 k 0.99485034 m 4.2578015\n",
      "106 Train Loss 6.823134 Test RE 0.015323450630969493 c 1.1677245 k 0.98957586 m 4.2968903\n",
      "107 Train Loss 5.5852757 Test RE 0.012148281033027898 c 1.1391917 k 0.9916371 m 4.372741\n",
      "108 Train Loss 5.0339026 Test RE 0.01299460328567875 c 1.1447905 k 0.9957878 m 4.434541\n",
      "109 Train Loss 4.653628 Test RE 0.01267576088986303 c 1.1562926 k 0.99536973 m 4.484908\n",
      "110 Train Loss 4.267538 Test RE 0.011289905577663665 c 1.1546851 k 0.99422145 m 4.5217037\n",
      "111 Train Loss 3.1433914 Test RE 0.009587138076132908 c 1.126013 k 0.99009234 m 4.5757723\n",
      "112 Train Loss 2.7737994 Test RE 0.009505872303860173 c 1.133583 k 0.9929557 m 4.6212153\n",
      "113 Train Loss 2.6085637 Test RE 0.009071525883626039 c 1.1454818 k 0.9942735 m 4.6629734\n",
      "114 Train Loss 2.288359 Test RE 0.008873315437207619 c 1.1295922 k 0.99361235 m 4.68802\n",
      "115 Train Loss 1.9830582 Test RE 0.008631348076056275 c 1.1004468 k 0.99337906 m 4.701489\n",
      "116 Train Loss 1.796727 Test RE 0.008138034087904462 c 1.0769663 k 0.9971975 m 4.7148633\n",
      "117 Train Loss 1.622983 Test RE 0.00710912839578536 c 1.0532384 k 0.99645716 m 4.73685\n",
      "118 Train Loss 1.2388153 Test RE 0.0061668040064014416 c 1.0286995 k 0.9951834 m 4.780884\n",
      "119 Train Loss 1.0870575 Test RE 0.005690198050729743 c 1.0275235 k 0.9985617 m 4.809824\n",
      "120 Train Loss 0.91536283 Test RE 0.004441727587332158 c 1.0301298 k 0.9976356 m 4.847869\n",
      "121 Train Loss 0.81666005 Test RE 0.004142786602150838 c 1.0354234 k 0.9977268 m 4.8581944\n",
      "122 Train Loss 0.6686604 Test RE 0.004369443316100431 c 1.040527 k 0.99939877 m 4.891653\n",
      "123 Train Loss 0.43435127 Test RE 0.003523847801314953 c 1.0368438 k 0.9986345 m 4.9427853\n",
      "124 Train Loss 0.39489797 Test RE 0.0033790944415397414 c 1.0364712 k 0.99847704 m 4.953165\n",
      "125 Train Loss 0.37212935 Test RE 0.003538212878273066 c 1.0362208 k 0.9991513 m 4.9686337\n",
      "126 Train Loss 0.34481984 Test RE 0.003334168896428765 c 1.0293286 k 0.99908763 m 4.9702163\n",
      "127 Train Loss 0.28169754 Test RE 0.0028492263823843384 c 1.0040642 k 0.99923617 m 4.9790125\n",
      "128 Train Loss 0.25087297 Test RE 0.0026518843160199504 c 0.98916054 k 0.99981844 m 4.988087\n",
      "129 Train Loss 0.2175674 Test RE 0.002569635281116085 c 0.98179936 k 1.0000539 m 5.007501\n",
      "130 Train Loss 0.16671139 Test RE 0.0019276953277592148 c 0.98893946 k 1.000341 m 5.03211\n",
      "131 Train Loss 0.1464406 Test RE 0.0015421135257599062 c 0.9941724 k 1.0004262 m 5.0433426\n",
      "132 Train Loss 0.13686986 Test RE 0.001461928802910673 c 0.9897931 k 1.0004102 m 5.044884\n",
      "133 Train Loss 0.1330647 Test RE 0.0014324743139589396 c 0.98418176 k 1.0003946 m 5.042028\n",
      "134 Train Loss 0.12296083 Test RE 0.0013374949073242247 c 0.9823409 k 1.0004677 m 5.03195\n",
      "135 Train Loss 0.09998328 Test RE 0.0013176769455984306 c 0.992484 k 1.000297 m 5.0188885\n",
      "136 Train Loss 0.08355147 Test RE 0.001161100044303461 c 0.9965723 k 1.0002295 m 5.012927\n",
      "137 Train Loss 0.077361904 Test RE 0.0009615917642510298 c 0.9965091 k 1.0002114 m 5.0085487\n",
      "138 Train Loss 0.074826255 Test RE 0.0008917991899469668 c 1.0006124 k 1.0000335 m 5.005854\n",
      "139 Train Loss 0.0743312 Test RE 0.0009132363684091611 c 1.0027643 k 1.0000556 m 5.006044\n",
      "140 Train Loss 0.073396415 Test RE 0.0009003009005216938 c 1.0026748 k 1.0000818 m 5.0097857\n",
      "141 Train Loss 0.072189696 Test RE 0.000899112191941446 c 1.0018773 k 1.0000393 m 5.0121794\n",
      "142 Train Loss 0.06851345 Test RE 0.000849413974844332 c 1.0030195 k 1.0000813 m 5.0011797\n",
      "143 Train Loss 0.06685428 Test RE 0.0008251653962208996 c 1.0033358 k 0.9999582 m 4.9946012\n",
      "144 Train Loss 0.06637409 Test RE 0.0008532768951300525 c 1.002978 k 0.9997507 m 4.9925747\n",
      "145 Train Loss 0.061052673 Test RE 0.0008381414504101997 c 1.0009404 k 0.9995869 m 4.9930067\n",
      "146 Train Loss 0.056788623 Test RE 0.0008129842020014308 c 0.9998209 k 1.0000559 m 4.9895167\n",
      "147 Train Loss 0.055255465 Test RE 0.0008299777294425334 c 0.9997207 k 0.99999064 m 4.988804\n",
      "148 Train Loss 0.053059433 Test RE 0.0008445001221716402 c 0.9995275 k 0.9999422 m 4.9956923\n",
      "149 Train Loss 0.050936297 Test RE 0.0008250221293563106 c 0.99896675 k 1.0002428 m 4.999613\n",
      "150 Train Loss 0.043889325 Test RE 0.0007524232749823729 c 0.99795014 k 0.99991417 m 4.9950233\n",
      "151 Train Loss 0.03861991 Test RE 0.0006950199780907355 c 1.0036533 k 0.9996996 m 4.991109\n",
      "152 Train Loss 0.034766555 Test RE 0.0005521839255241782 c 1.003636 k 0.9999189 m 4.993337\n",
      "153 Train Loss 0.032481138 Test RE 0.0005018947610986549 c 1.001599 k 0.9999605 m 4.999182\n",
      "154 Train Loss 0.031545803 Test RE 0.0005270467386389231 c 1.001491 k 0.9999019 m 4.996904\n",
      "155 Train Loss 0.030962627 Test RE 0.0005232182942798843 c 1.0020163 k 0.9998626 m 4.994924\n",
      "156 Train Loss 0.030549556 Test RE 0.0004930260010864892 c 1.0022345 k 0.99989974 m 4.997127\n",
      "157 Train Loss 0.030090444 Test RE 0.00047896356356294924 c 1.0012954 k 1.0000095 m 4.999174\n",
      "158 Train Loss 0.028337374 Test RE 0.00048383198583171026 c 1.0006689 k 0.99995655 m 5.004331\n",
      "159 Train Loss 0.026468476 Test RE 0.000528659601770867 c 1.002072 k 0.99988335 m 5.009473\n",
      "160 Train Loss 0.023543473 Test RE 0.0005457411536969075 c 1.0018709 k 1.0001112 m 5.0078263\n",
      "161 Train Loss 0.019980803 Test RE 0.00040423108053329397 c 1.0013355 k 0.999941 m 5.0013227\n",
      "162 Train Loss 0.017926272 Test RE 0.00035192160425452906 c 1.0009485 k 0.9998229 m 4.995296\n",
      "163 Train Loss 0.01755168 Test RE 0.0003753148639013295 c 1.0000476 k 0.9999433 m 4.993449\n",
      "164 Train Loss 0.017047606 Test RE 0.00036880642064846686 c 0.9999006 k 0.99992985 m 4.9930034\n",
      "165 Train Loss 0.016626047 Test RE 0.0003729361464882945 c 1.0005015 k 0.99983746 m 4.9933057\n",
      "166 Train Loss 0.016378792 Test RE 0.0003751575468341985 c 1.0009943 k 0.9998524 m 4.994593\n",
      "167 Train Loss 0.01596028 Test RE 0.0003530282197802101 c 1.001775 k 0.9999324 m 4.997547\n",
      "168 Train Loss 0.015419925 Test RE 0.0003540583761870173 c 1.000926 k 0.99993014 m 4.9989276\n",
      "169 Train Loss 0.01501998 Test RE 0.0003191303314982196 c 0.99985576 k 0.9998885 m 5.000512\n",
      "170 Train Loss 0.014747401 Test RE 0.00030125907788156487 c 1.0001183 k 0.99992573 m 5.000725\n",
      "171 Train Loss 0.014516496 Test RE 0.0002970289101953856 c 1.0002787 k 0.9999547 m 4.998566\n",
      "172 Train Loss 0.014432214 Test RE 0.00029458774616476004 c 1.0006051 k 0.9999192 m 4.998315\n",
      "173 Train Loss 0.0143305445 Test RE 0.0002872798309771905 c 1.000504 k 0.9999436 m 4.9993296\n",
      "174 Train Loss 0.014197641 Test RE 0.0002590512140666595 c 0.9999054 k 0.9999391 m 4.999649\n",
      "175 Train Loss 0.014087966 Test RE 0.00023218495719628724 c 1.000146 k 0.9999648 m 5.000017\n",
      "176 Train Loss 0.014040413 Test RE 0.00021458917432450226 c 1.0002434 k 0.99998546 m 5.000784\n",
      "177 Train Loss 0.013934678 Test RE 0.000201147739446893 c 1.0007114 k 0.99994975 m 4.9992085\n",
      "178 Train Loss 0.013841597 Test RE 0.00020496011260033283 c 1.0007739 k 0.99996424 m 4.999371\n",
      "179 Train Loss 0.013357115 Test RE 0.00019539997101219753 c 1.000201 k 1.0000426 m 5.002569\n",
      "180 Train Loss 0.013002275 Test RE 0.00019795139233442442 c 1.0008569 k 0.99998134 m 4.999981\n",
      "181 Train Loss 0.01282635 Test RE 0.00020154904649211602 c 1.0009284 k 1.0000021 m 4.999451\n",
      "182 Train Loss 0.0126985265 Test RE 0.00020112516700719553 c 1.0006782 k 0.9999944 m 5.000048\n",
      "183 Train Loss 0.012640015 Test RE 0.00021249338355924612 c 1.0008496 k 1.0000002 m 5.00001\n",
      "184 Train Loss 0.0126110185 Test RE 0.0002211875934438684 c 1.0008391 k 0.9999994 m 4.9996457\n",
      "185 Train Loss 0.012610093 Test RE 0.00022096401614651997 c 1.0008147 k 0.9999997 m 4.999654\n",
      "186 Train Loss 0.012609308 Test RE 0.00022082335915894126 c 1.0007887 k 0.9999996 m 4.9996443\n",
      "187 Train Loss 0.012608876 Test RE 0.00022034958491290614 c 1.0007539 k 0.9999998 m 4.999656\n",
      "188 Train Loss 0.012608539 Test RE 0.00022018431584336186 c 1.00073 k 0.9999998 m 4.999659\n",
      "189 Train Loss 0.012605929 Test RE 0.00021950395096019616 c 1.0006896 k 1.0000002 m 4.999682\n",
      "190 Train Loss 0.012605929 Test RE 0.00021950395096019616 c 1.0006896 k 1.0000002 m 4.999682\n",
      "191 Train Loss 0.012605929 Test RE 0.00021950395096019616 c 1.0006896 k 1.0000002 m 4.999682\n",
      "192 Train Loss 0.012605929 Test RE 0.00021950395096019616 c 1.0006896 k 1.0000002 m 4.999682\n",
      "193 Train Loss 0.012605929 Test RE 0.00021950395096019616 c 1.0006896 k 1.0000002 m 4.999682\n",
      "194 Train Loss 0.012605929 Test RE 0.00021950395096019616 c 1.0006896 k 1.0000002 m 4.999682\n",
      "195 Train Loss 0.012605929 Test RE 0.00021950395096019616 c 1.0006896 k 1.0000002 m 4.999682\n",
      "196 Train Loss 0.012605929 Test RE 0.00021950395096019616 c 1.0006896 k 1.0000002 m 4.999682\n",
      "197 Train Loss 0.012605929 Test RE 0.00021950395096019616 c 1.0006896 k 1.0000002 m 4.999682\n",
      "198 Train Loss 0.012605929 Test RE 0.00021950395096019616 c 1.0006896 k 1.0000002 m 4.999682\n",
      "199 Train Loss 0.012605929 Test RE 0.00021950395096019616 c 1.0006896 k 1.0000002 m 4.999682\n",
      "Training time: 83.69\n",
      "Training time: 83.69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 2854.7734 Test RE 0.255709689523841 c 0.29204062 k 0.61583704 m 2.6435662e-06\n",
      "1 Train Loss 761.59644 Test RE 0.2245450201519398 c 0.30867368 k 0.7583345 m -1.35004175e-05\n",
      "2 Train Loss 356.68176 Test RE 0.14951346379639988 c 0.32194185 k 0.8685265 m 2.0638625e-05\n",
      "3 Train Loss 264.24097 Test RE 0.11031548395403529 c 0.33305424 k 0.9477584 m 9.034967e-05\n",
      "4 Train Loss 241.39406 Test RE 0.10553038203944494 c 0.33747935 k 0.984186 m 0.00021186168\n",
      "5 Train Loss 239.03546 Test RE 0.10694761322940675 c 0.33839524 k 0.9899576 m 0.00038717085\n",
      "6 Train Loss 237.78511 Test RE 0.10518461547940326 c 0.33891687 k 0.98901415 m 0.0007419275\n",
      "7 Train Loss 236.63809 Test RE 0.10431063610268151 c 0.33942628 k 0.98423177 m 0.0015231984\n",
      "8 Train Loss 235.27103 Test RE 0.10493375784974385 c 0.34138635 k 0.99041694 m 0.0027999491\n",
      "9 Train Loss 234.82709 Test RE 0.10394703452437197 c 0.34202993 k 0.9887862 m 0.0034987754\n",
      "10 Train Loss 234.62524 Test RE 0.10419321226317835 c 0.34246725 k 0.9865618 m 0.004012822\n",
      "11 Train Loss 234.30086 Test RE 0.1040485369962576 c 0.34458822 k 0.98766536 m 0.0057251523\n",
      "12 Train Loss 234.16904 Test RE 0.10459270070785598 c 0.3456413 k 0.9874108 m 0.006774448\n",
      "13 Train Loss 233.95743 Test RE 0.10414902003044685 c 0.34657183 k 0.98778045 m 0.007680383\n",
      "14 Train Loss 233.69144 Test RE 0.10306427935497262 c 0.34799394 k 0.98817164 m 0.008900214\n",
      "15 Train Loss 233.42647 Test RE 0.10402987088834308 c 0.34924445 k 0.9863292 m 0.010414889\n",
      "16 Train Loss 233.11206 Test RE 0.1038405753471037 c 0.35075632 k 0.987853 m 0.011796344\n",
      "17 Train Loss 232.96902 Test RE 0.1033175705793474 c 0.35215393 k 0.9881267 m 0.012953131\n",
      "18 Train Loss 232.84772 Test RE 0.10268628778656168 c 0.35364535 k 0.9861454 m 0.014342988\n",
      "19 Train Loss 232.45018 Test RE 0.10197052520112629 c 0.35949478 k 0.9876724 m 0.018985456\n",
      "20 Train Loss 232.02563 Test RE 0.10356085184432959 c 0.36245 k 0.9893024 m 0.0213165\n",
      "21 Train Loss 231.79865 Test RE 0.10308575464656199 c 0.3633314 k 0.9885076 m 0.022235017\n",
      "22 Train Loss 231.46448 Test RE 0.1029073452369463 c 0.36990103 k 0.99114233 m 0.027792655\n",
      "23 Train Loss 230.73184 Test RE 0.10359398333303356 c 0.37789062 k 0.99095976 m 0.034507446\n",
      "24 Train Loss 230.35388 Test RE 0.10247902776232601 c 0.37910718 k 0.9862951 m 0.03607463\n",
      "25 Train Loss 230.24931 Test RE 0.10257321964959425 c 0.38171718 k 0.98620456 m 0.038453735\n",
      "26 Train Loss 229.74408 Test RE 0.10257331531028573 c 0.39361572 k 0.9896414 m 0.048481718\n",
      "27 Train Loss 229.55939 Test RE 0.10248297907244558 c 0.39559728 k 0.9872959 m 0.050468218\n",
      "28 Train Loss 229.1966 Test RE 0.10216926923824214 c 0.39675364 k 0.983296 m 0.052137755\n",
      "29 Train Loss 228.54913 Test RE 0.10121080421314568 c 0.4047823 k 0.98616916 m 0.059509803\n",
      "30 Train Loss 227.91202 Test RE 0.1016479631005109 c 0.4109148 k 0.98809624 m 0.06490391\n",
      "31 Train Loss 227.20364 Test RE 0.10096090770280675 c 0.41652486 k 0.9808319 m 0.07110599\n",
      "32 Train Loss 226.45496 Test RE 0.10111220677751398 c 0.42375198 k 0.9857703 m 0.077608295\n",
      "33 Train Loss 225.45786 Test RE 0.09935541679867531 c 0.43953183 k 0.984706 m 0.09233404\n",
      "34 Train Loss 224.80492 Test RE 0.09908346153132777 c 0.44961575 k 0.983597 m 0.101429835\n",
      "35 Train Loss 223.71582 Test RE 0.09997138099732028 c 0.45895377 k 0.9857634 m 0.10983032\n",
      "36 Train Loss 223.3761 Test RE 0.09991524771954452 c 0.46325728 k 0.9866379 m 0.11394609\n",
      "37 Train Loss 222.9357 Test RE 0.09944209399243745 c 0.46985483 k 0.9848121 m 0.12025263\n",
      "38 Train Loss 222.00024 Test RE 0.0991871038107484 c 0.48604953 k 0.9822125 m 0.13564336\n",
      "39 Train Loss 220.27014 Test RE 0.10026673787591742 c 0.49768144 k 0.98479986 m 0.14671364\n",
      "40 Train Loss 219.1606 Test RE 0.09887464731230551 c 0.50698304 k 0.98772514 m 0.15528846\n",
      "41 Train Loss 218.50003 Test RE 0.09766212138481213 c 0.5175823 k 0.9864049 m 0.16538773\n",
      "42 Train Loss 217.49988 Test RE 0.09878541748004578 c 0.5236086 k 0.9854398 m 0.1710668\n",
      "43 Train Loss 217.18884 Test RE 0.09845627637388198 c 0.5258198 k 0.985939 m 0.17301507\n",
      "44 Train Loss 216.73355 Test RE 0.09690287460099214 c 0.52740586 k 0.98264265 m 0.17489699\n",
      "45 Train Loss 215.81412 Test RE 0.09783334505109738 c 0.53417635 k 0.984674 m 0.18159194\n",
      "46 Train Loss 215.10226 Test RE 0.09883389337078263 c 0.54035527 k 0.9892983 m 0.18682198\n",
      "47 Train Loss 214.25723 Test RE 0.097461591638423 c 0.54810244 k 0.98931366 m 0.19352481\n",
      "48 Train Loss 213.19704 Test RE 0.09647805885165936 c 0.56072474 k 0.98569685 m 0.20556559\n",
      "49 Train Loss 211.67572 Test RE 0.095491290873159 c 0.566994 k 0.97940975 m 0.21218064\n",
      "50 Train Loss 210.86124 Test RE 0.0957594043369066 c 0.575434 k 0.9831852 m 0.2197151\n",
      "51 Train Loss 210.30899 Test RE 0.09608426588954336 c 0.5842524 k 0.99013567 m 0.22742529\n",
      "52 Train Loss 209.4483 Test RE 0.0949580846313514 c 0.5882589 k 0.9846335 m 0.23191833\n",
      "53 Train Loss 208.41104 Test RE 0.0955642644120706 c 0.59497344 k 0.98214376 m 0.23895158\n",
      "54 Train Loss 208.00676 Test RE 0.09459917451120467 c 0.6004162 k 0.9842548 m 0.24398956\n",
      "55 Train Loss 207.19989 Test RE 0.09547355264107571 c 0.61120784 k 0.98414254 m 0.2543406\n",
      "56 Train Loss 206.84741 Test RE 0.09466798485683696 c 0.61257416 k 0.98409635 m 0.2555349\n",
      "57 Train Loss 206.19727 Test RE 0.09419281038668895 c 0.61735106 k 0.9849367 m 0.260076\n",
      "58 Train Loss 204.84122 Test RE 0.09564932727938169 c 0.63363576 k 0.98418546 m 0.2754339\n",
      "59 Train Loss 204.09747 Test RE 0.09459201878301565 c 0.6400313 k 0.9823023 m 0.28152132\n",
      "60 Train Loss 203.21115 Test RE 0.09418413153557309 c 0.64694536 k 0.9802187 m 0.28775018\n",
      "61 Train Loss 202.45038 Test RE 0.09294928097230466 c 0.649622 k 0.98164725 m 0.28965124\n",
      "62 Train Loss 201.99622 Test RE 0.09206953952746554 c 0.65322423 k 0.9813371 m 0.2929083\n",
      "63 Train Loss 201.20825 Test RE 0.09266996761592221 c 0.6595299 k 0.9832438 m 0.29871175\n",
      "64 Train Loss 200.3146 Test RE 0.09356522830668285 c 0.6662632 k 0.98684263 m 0.3048405\n",
      "65 Train Loss 199.85512 Test RE 0.09388997731865684 c 0.6700575 k 0.98611516 m 0.30845428\n",
      "66 Train Loss 198.73868 Test RE 0.09214846295262097 c 0.67963743 k 0.9833359 m 0.3175598\n",
      "67 Train Loss 198.10681 Test RE 0.09208940973560632 c 0.6819201 k 0.98062897 m 0.32002497\n",
      "68 Train Loss 197.11551 Test RE 0.092128849512395 c 0.6867257 k 0.97857976 m 0.32492742\n",
      "69 Train Loss 195.90308 Test RE 0.09156475356171216 c 0.69214547 k 0.9791385 m 0.33032086\n",
      "70 Train Loss 195.12172 Test RE 0.09202904213154431 c 0.692664 k 0.98100376 m 0.33080032\n",
      "71 Train Loss 194.76772 Test RE 0.09240556487013847 c 0.6932674 k 0.9819642 m 0.33145472\n",
      "72 Train Loss 194.63016 Test RE 0.09204559508606802 c 0.693356 k 0.98264354 m 0.33154145\n",
      "73 Train Loss 194.0455 Test RE 0.09224549512700296 c 0.6980051 k 0.9834004 m 0.33600712\n",
      "74 Train Loss 193.23108 Test RE 0.09233559477562647 c 0.70474905 k 0.97940004 m 0.34277275\n",
      "75 Train Loss 192.04578 Test RE 0.09136593168484784 c 0.7094698 k 0.97743505 m 0.3476684\n",
      "76 Train Loss 190.91869 Test RE 0.09058175730125347 c 0.7148077 k 0.972343 m 0.35380095\n",
      "77 Train Loss 189.96643 Test RE 0.09046662335696673 c 0.7198218 k 0.97397345 m 0.35857177\n",
      "78 Train Loss 188.47162 Test RE 0.09160602894428013 c 0.728304 k 0.97989094 m 0.36606866\n",
      "79 Train Loss 186.8183 Test RE 0.08847627848472428 c 0.7385971 k 0.97970295 m 0.37637967\n",
      "80 Train Loss 184.87027 Test RE 0.09010870327915713 c 0.7477708 k 0.97588426 m 0.38600546\n",
      "81 Train Loss 183.82883 Test RE 0.0887996341868653 c 0.7555358 k 0.97685176 m 0.39356434\n",
      "82 Train Loss 183.13173 Test RE 0.08766019753663351 c 0.7607479 k 0.9784771 m 0.39863205\n",
      "83 Train Loss 182.06958 Test RE 0.0893026414892181 c 0.7711334 k 0.9850876 m 0.40829802\n",
      "84 Train Loss 181.18591 Test RE 0.08976883609787308 c 0.7800464 k 0.9872303 m 0.41701606\n",
      "85 Train Loss 180.20145 Test RE 0.08944865413411243 c 0.7893994 k 0.9815658 m 0.42724505\n",
      "86 Train Loss 179.50497 Test RE 0.08912775015375597 c 0.78932774 k 0.9785471 m 0.42762408\n",
      "87 Train Loss 178.68752 Test RE 0.08814281617115462 c 0.78886026 k 0.97771424 m 0.42740315\n",
      "88 Train Loss 177.20703 Test RE 0.08819767193694872 c 0.7952433 k 0.9766656 m 0.43412492\n",
      "89 Train Loss 176.23073 Test RE 0.08709794006779156 c 0.8042305 k 0.9735811 m 0.44360662\n",
      "90 Train Loss 174.86722 Test RE 0.08761143634450662 c 0.8133117 k 0.97602516 m 0.4523796\n",
      "91 Train Loss 174.26558 Test RE 0.08758177992900298 c 0.81709075 k 0.97663593 m 0.45603806\n",
      "92 Train Loss 173.71393 Test RE 0.08820835881014166 c 0.82286036 k 0.97747654 m 0.46164528\n",
      "93 Train Loss 173.0915 Test RE 0.087857814136383 c 0.8261078 k 0.9758974 m 0.46508315\n",
      "94 Train Loss 172.58774 Test RE 0.08783928661795046 c 0.83044356 k 0.9764109 m 0.46949324\n",
      "95 Train Loss 171.5328 Test RE 0.08694716624825606 c 0.84092647 k 0.9799537 m 0.47956213\n",
      "96 Train Loss 170.56091 Test RE 0.08679759825256514 c 0.8431178 k 0.982041 m 0.48132992\n",
      "97 Train Loss 169.51253 Test RE 0.08627110899909227 c 0.84313875 k 0.9788821 m 0.48169312\n",
      "98 Train Loss 168.95123 Test RE 0.0857252204628614 c 0.84609413 k 0.9757688 m 0.48504487\n",
      "99 Train Loss 167.80624 Test RE 0.08588447558457468 c 0.85601175 k 0.9755591 m 0.49510482\n",
      "100 Train Loss 166.86238 Test RE 0.08569256675882606 c 0.8652579 k 0.97615516 m 0.5045729\n",
      "101 Train Loss 165.75854 Test RE 0.08622586019926913 c 0.87356436 k 0.9760941 m 0.5129487\n",
      "102 Train Loss 164.57193 Test RE 0.08562528885727168 c 0.8778836 k 0.9772379 m 0.5169525\n",
      "103 Train Loss 163.90125 Test RE 0.08595447986085232 c 0.8833342 k 0.9777363 m 0.5222314\n",
      "104 Train Loss 163.22095 Test RE 0.08652801953672537 c 0.8918412 k 0.9802848 m 0.5303186\n",
      "105 Train Loss 162.70355 Test RE 0.08642136791130399 c 0.89598006 k 0.9833487 m 0.534101\n",
      "106 Train Loss 162.47005 Test RE 0.08646074265706848 c 0.89722025 k 0.9829909 m 0.53539693\n",
      "107 Train Loss 161.89111 Test RE 0.08674958620153224 c 0.90018684 k 0.9803501 m 0.53866154\n",
      "108 Train Loss 161.06381 Test RE 0.08608445629922698 c 0.9102833 k 0.97677803 m 0.5492867\n",
      "109 Train Loss 160.51382 Test RE 0.08686570778791142 c 0.9168858 k 0.9735712 m 0.5562979\n",
      "110 Train Loss 160.16205 Test RE 0.08688696970098606 c 0.916931 k 0.9734067 m 0.5562814\n",
      "111 Train Loss 159.73714 Test RE 0.08522680372991896 c 0.9154486 k 0.97490966 m 0.55453676\n",
      "112 Train Loss 158.73706 Test RE 0.08425791111095862 c 0.9180759 k 0.97508264 m 0.5569954\n",
      "113 Train Loss 157.29636 Test RE 0.08447786356167966 c 0.9286329 k 0.9800244 m 0.5667229\n",
      "114 Train Loss 156.4635 Test RE 0.08481861040093466 c 0.9361484 k 0.98109245 m 0.5740229\n",
      "115 Train Loss 155.48105 Test RE 0.08478747074950982 c 0.9449675 k 0.97926265 m 0.5828935\n",
      "116 Train Loss 155.23048 Test RE 0.0848809814473023 c 0.9466809 k 0.9801259 m 0.5844469\n",
      "117 Train Loss 154.68463 Test RE 0.08542736905762612 c 0.951529 k 0.9784759 m 0.58927125\n",
      "118 Train Loss 154.11934 Test RE 0.08526104512751888 c 0.95390797 k 0.97594684 m 0.591865\n",
      "119 Train Loss 153.78043 Test RE 0.08488916799531566 c 0.9556251 k 0.9760707 m 0.59352165\n",
      "120 Train Loss 153.30478 Test RE 0.08427845718475821 c 0.9623432 k 0.973486 m 0.600458\n",
      "121 Train Loss 152.78987 Test RE 0.08360750043897468 c 0.97081673 k 0.96959865 m 0.60924155\n",
      "122 Train Loss 152.50806 Test RE 0.08376668457281006 c 0.97588056 k 0.9682429 m 0.61436284\n",
      "123 Train Loss 152.01245 Test RE 0.08374508237001466 c 0.9792929 k 0.96895903 m 0.61763304\n",
      "124 Train Loss 150.68094 Test RE 0.08465717603128492 c 0.9835068 k 0.9711345 m 0.62153614\n",
      "125 Train Loss 149.62352 Test RE 0.0842538975325699 c 0.9876914 k 0.9700225 m 0.62590474\n",
      "126 Train Loss 149.28366 Test RE 0.08501342953923767 c 0.9909548 k 0.9690062 m 0.6293529\n",
      "127 Train Loss 148.85406 Test RE 0.08507225142613951 c 0.9927367 k 0.97000575 m 0.6309599\n",
      "128 Train Loss 148.55795 Test RE 0.0843012070493403 c 0.9954055 k 0.97076195 m 0.63351035\n",
      "129 Train Loss 148.26273 Test RE 0.08422460577652495 c 0.9989992 k 0.97056437 m 0.63716394\n",
      "130 Train Loss 147.75793 Test RE 0.08369646308985554 c 1.0013952 k 0.9713021 m 0.63950986\n",
      "131 Train Loss 147.4458 Test RE 0.08293473977178942 c 1.0017865 k 0.9718038 m 0.6398162\n",
      "132 Train Loss 147.03952 Test RE 0.08367716269296793 c 1.0047302 k 0.9729143 m 0.6426235\n",
      "133 Train Loss 146.61249 Test RE 0.08300843942313427 c 1.0087929 k 0.973878 m 0.646549\n",
      "134 Train Loss 146.21643 Test RE 0.08261479732042029 c 1.0132613 k 0.9750189 m 0.65080816\n",
      "135 Train Loss 145.9407 Test RE 0.08326815178213362 c 1.0149637 k 0.97485536 m 0.6524887\n",
      "136 Train Loss 145.7052 Test RE 0.08325137828608264 c 1.0205678 k 0.97508335 m 0.65806323\n",
      "137 Train Loss 145.3772 Test RE 0.0824549293039065 c 1.0290217 k 0.974576 m 0.6666665\n",
      "138 Train Loss 145.28094 Test RE 0.08252374170151988 c 1.031279 k 0.9740685 m 0.66897184\n",
      "139 Train Loss 144.82965 Test RE 0.08378467856161247 c 1.0399151 k 0.97425145 m 0.6775191\n",
      "140 Train Loss 144.26492 Test RE 0.082725493658219 c 1.0436134 k 0.97459966 m 0.68115926\n",
      "141 Train Loss 144.04074 Test RE 0.08278395615192485 c 1.0434318 k 0.97572005 m 0.6808181\n",
      "142 Train Loss 143.9026 Test RE 0.08339335633198154 c 1.0426966 k 0.97599846 m 0.68007326\n",
      "143 Train Loss 143.82501 Test RE 0.08354013078856025 c 1.0435071 k 0.97593933 m 0.68092775\n",
      "144 Train Loss 143.08983 Test RE 0.08430476429369144 c 1.052633 k 0.976408 m 0.6900672\n",
      "145 Train Loss 142.15941 Test RE 0.08237204641617195 c 1.0649828 k 0.9786285 m 0.70221925\n",
      "146 Train Loss 141.23447 Test RE 0.08185956693336402 c 1.0730332 k 0.98033863 m 0.71012604\n",
      "147 Train Loss 140.8038 Test RE 0.08264229796791035 c 1.0737693 k 0.98020744 m 0.7109964\n",
      "148 Train Loss 140.47815 Test RE 0.08248502616130714 c 1.0744034 k 0.9802501 m 0.7117015\n",
      "149 Train Loss 139.2963 Test RE 0.08137695909260456 c 1.0758644 k 0.9809142 m 0.71320415\n",
      "150 Train Loss 138.79517 Test RE 0.08222988394072489 c 1.0745727 k 0.9801622 m 0.7120573\n",
      "151 Train Loss 138.3534 Test RE 0.08227433248601183 c 1.0767683 k 0.9782719 m 0.7144488\n",
      "152 Train Loss 137.89578 Test RE 0.08197839676138992 c 1.0814203 k 0.9775993 m 0.7191054\n",
      "153 Train Loss 137.46078 Test RE 0.08169647401467044 c 1.085449 k 0.9792407 m 0.72289115\n",
      "154 Train Loss 136.94154 Test RE 0.08087627401551752 c 1.0891685 k 0.9790988 m 0.7265448\n",
      "155 Train Loss 136.5462 Test RE 0.08100998630188218 c 1.0891769 k 0.9781801 m 0.7266198\n",
      "156 Train Loss 136.36461 Test RE 0.08163139378997546 c 1.0880754 k 0.9777168 m 0.72554076\n",
      "157 Train Loss 136.25499 Test RE 0.08145908671254282 c 1.0882857 k 0.9778881 m 0.72570616\n",
      "158 Train Loss 136.09973 Test RE 0.08159405343615607 c 1.0896207 k 0.9765555 m 0.7271523\n",
      "159 Train Loss 135.821 Test RE 0.0813637674487099 c 1.0926003 k 0.9751674 m 0.73024565\n",
      "160 Train Loss 135.63135 Test RE 0.08044832612233652 c 1.0956438 k 0.97472286 m 0.73335576\n",
      "161 Train Loss 135.48828 Test RE 0.08063519839440884 c 1.0970739 k 0.9736562 m 0.7349261\n",
      "162 Train Loss 135.28064 Test RE 0.08156064115106952 c 1.0988574 k 0.97156155 m 0.73696506\n",
      "163 Train Loss 134.70718 Test RE 0.08218703348318554 c 1.1057674 k 0.9675426 m 0.7442882\n",
      "164 Train Loss 134.03665 Test RE 0.08108970084216587 c 1.1115974 k 0.9661689 m 0.7502085\n",
      "165 Train Loss 133.8009 Test RE 0.08110349032167827 c 1.1125789 k 0.9662239 m 0.7511877\n",
      "166 Train Loss 133.38614 Test RE 0.08093014141985733 c 1.1152066 k 0.9672548 m 0.7536069\n",
      "167 Train Loss 132.94632 Test RE 0.08061292789150015 c 1.1183729 k 0.96961874 m 0.7563306\n",
      "168 Train Loss 132.56734 Test RE 0.08072167204944512 c 1.1244984 k 0.96980506 m 0.7622906\n",
      "169 Train Loss 132.22897 Test RE 0.08090331956738969 c 1.1281458 k 0.9714875 m 0.7657244\n",
      "170 Train Loss 132.08282 Test RE 0.08044900930205819 c 1.130038 k 0.9729775 m 0.7674122\n",
      "171 Train Loss 131.99107 Test RE 0.08013120819895717 c 1.1327096 k 0.97238857 m 0.77009916\n",
      "172 Train Loss 131.87418 Test RE 0.08032986170884274 c 1.1353649 k 0.9730915 m 0.7726438\n",
      "173 Train Loss 131.68869 Test RE 0.07989068474798479 c 1.1396245 k 0.9733462 m 0.7768549\n",
      "174 Train Loss 131.60901 Test RE 0.07969212575753054 c 1.1420362 k 0.97297573 m 0.7793056\n",
      "175 Train Loss 131.43874 Test RE 0.08022319668302813 c 1.1451466 k 0.9740948 m 0.7822565\n",
      "176 Train Loss 131.22589 Test RE 0.07995489328443545 c 1.1481 k 0.97582614 m 0.78493387\n",
      "177 Train Loss 130.98296 Test RE 0.07876321565678412 c 1.1492891 k 0.97656786 m 0.7859768\n",
      "178 Train Loss 130.5029 Test RE 0.07860013913966019 c 1.149815 k 0.9766441 m 0.78650427\n",
      "179 Train Loss 130.11505 Test RE 0.07914241798351733 c 1.1499317 k 0.9778921 m 0.78643095\n",
      "180 Train Loss 129.96988 Test RE 0.0796716670566598 c 1.1497028 k 0.9780898 m 0.7861164\n",
      "181 Train Loss 129.65192 Test RE 0.08096534006447358 c 1.1517798 k 0.97660345 m 0.78819096\n",
      "182 Train Loss 129.51901 Test RE 0.08067352638371232 c 1.1543055 k 0.975971 m 0.7907448\n",
      "183 Train Loss 128.84628 Test RE 0.07958323126624399 c 1.1628004 k 0.9760777 m 0.7989971\n",
      "184 Train Loss 128.46008 Test RE 0.07992477963391544 c 1.1657641 k 0.97507274 m 0.8019347\n",
      "185 Train Loss 128.17581 Test RE 0.07991355293784166 c 1.1676869 k 0.97259647 m 0.8041187\n",
      "186 Train Loss 127.905365 Test RE 0.079598169310002 c 1.170601 k 0.9720144 m 0.8070462\n",
      "187 Train Loss 127.78493 Test RE 0.08003515217006844 c 1.1714215 k 0.9733376 m 0.8076742\n",
      "188 Train Loss 127.66728 Test RE 0.08016692975214622 c 1.1728449 k 0.9740648 m 0.8089661\n",
      "189 Train Loss 127.46907 Test RE 0.07984016398030219 c 1.1752167 k 0.97470367 m 0.81115526\n",
      "190 Train Loss 127.398415 Test RE 0.079923226713064 c 1.1758661 k 0.97583276 m 0.8116716\n",
      "191 Train Loss 127.32173 Test RE 0.07989350900134941 c 1.1758202 k 0.97604877 m 0.8116411\n",
      "192 Train Loss 127.262566 Test RE 0.07999810574127267 c 1.1763424 k 0.97601366 m 0.8121684\n",
      "193 Train Loss 127.17676 Test RE 0.08018460862324028 c 1.1778653 k 0.9763542 m 0.81362563\n",
      "194 Train Loss 127.082 Test RE 0.08022567773047855 c 1.1804131 k 0.9770751 m 0.8160367\n",
      "195 Train Loss 127.036446 Test RE 0.08029305426261595 c 1.1814636 k 0.9776407 m 0.81699747\n",
      "196 Train Loss 126.969345 Test RE 0.0797007627553887 c 1.1817647 k 0.9771538 m 0.8173914\n",
      "197 Train Loss 126.95645 Test RE 0.07961157741679735 c 1.1819046 k 0.9770057 m 0.8175538\n",
      "198 Train Loss 126.95645 Test RE 0.07961157741679735 c 1.1819046 k 0.9770057 m 0.8175538\n",
      "199 Train Loss 126.95645 Test RE 0.07961157741679735 c 1.1819046 k 0.9770057 m 0.8175538\n",
      "Training time: 86.95\n",
      "Training time: 86.95\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 10407.896 Test RE 0.5490483972059299 c 0.045949508 k 0.29993847 m 8.45585e-07\n",
      "1 Train Loss 552.4337 Test RE 0.22602866856397086 c 0.11741162 k 0.9144638 m 1.0158823e-06\n",
      "2 Train Loss 496.44196 Test RE 0.22108221498558567 c 0.12621342 k 1.0112113 m 1.0721936e-06\n",
      "3 Train Loss 495.8501 Test RE 0.22094449358528506 c 0.12724483 k 1.021957 m 1.0095515e-06\n",
      "4 Train Loss 495.25888 Test RE 0.22082035063834485 c 0.12702774 k 1.0187767 m 9.0305724e-07\n",
      "5 Train Loss 495.16486 Test RE 0.22079398531539138 c 0.12685622 k 1.0155743 m 8.7471574e-07\n",
      "6 Train Loss 494.83524 Test RE 0.22071314243014195 c 0.12759951 k 1.0176903 m 8.3107426e-07\n",
      "7 Train Loss 494.40207 Test RE 0.22056847285187073 c 0.12931742 k 1.0243555 m 6.153606e-07\n",
      "8 Train Loss 493.01898 Test RE 0.2202059761183831 c 0.13110277 k 1.0193431 m 1.7719464e-07\n",
      "9 Train Loss 492.72787 Test RE 0.22009629862491925 c 0.13147442 k 1.0143349 m 4.429289e-09\n",
      "10 Train Loss 492.3301 Test RE 0.21979500949441313 c 0.13385276 k 1.0204754 m -4.5044288e-07\n",
      "11 Train Loss 491.16174 Test RE 0.21917138167243524 c 0.13554221 k 1.0068207 m -1.1043976e-06\n",
      "12 Train Loss 487.49313 Test RE 0.21855861452797026 c 0.13906817 k 1.0140538 m -1.7988214e-06\n",
      "13 Train Loss 486.6576 Test RE 0.21836788885547162 c 0.14031594 k 1.0227405 m -1.8547809e-06\n",
      "14 Train Loss 485.60214 Test RE 0.21807198039376952 c 0.13967204 k 1.0151756 m -1.8568675e-06\n",
      "15 Train Loss 484.28806 Test RE 0.2176654023371192 c 0.14002264 k 1.0122237 m -2.0688203e-06\n",
      "16 Train Loss 479.74585 Test RE 0.21612803856672716 c 0.1411011 k 1.012454 m -1.7468597e-06\n",
      "17 Train Loss 474.9881 Test RE 0.2148491739070708 c 0.14318961 k 1.0178739 m -5.2204524e-07\n",
      "18 Train Loss 472.80658 Test RE 0.2145111710071883 c 0.14439356 k 1.0184813 m 9.053092e-07\n",
      "19 Train Loss 470.00543 Test RE 0.21338056555262785 c 0.1449984 k 1.0224801 m 1.7107992e-06\n",
      "20 Train Loss 467.97977 Test RE 0.21265769026643896 c 0.14474152 k 1.009895 m 1.3828962e-06\n",
      "21 Train Loss 461.27673 Test RE 0.20928685507534436 c 0.14975491 k 1.0126255 m -4.3301793e-07\n",
      "22 Train Loss 447.26886 Test RE 0.2058826711190427 c 0.15436928 k 1.0178491 m -3.665551e-06\n",
      "23 Train Loss 435.37613 Test RE 0.20046965331179661 c 0.15521629 k 1.0072361 m -5.1937495e-06\n",
      "24 Train Loss 433.02084 Test RE 0.19836236572090074 c 0.15633781 k 1.0130249 m -8.952016e-06\n",
      "25 Train Loss 422.942 Test RE 0.19548084069862365 c 0.15649602 k 1.0116348 m -2.182901e-05\n",
      "26 Train Loss 412.74393 Test RE 0.19139626019355044 c 0.15405859 k 1.0027179 m -2.7799158e-05\n",
      "27 Train Loss 406.81253 Test RE 0.19144102213412506 c 0.15448174 k 1.0090237 m -3.3091856e-05\n",
      "28 Train Loss 393.1578 Test RE 0.1803345547089828 c 0.15571496 k 1.0132798 m -3.0725238e-05\n",
      "29 Train Loss 369.26627 Test RE 0.17933853106853506 c 0.15594453 k 1.0034715 m -1.1465598e-05\n",
      "30 Train Loss 332.93002 Test RE 0.16590781832095075 c 0.15777548 k 1.0180421 m 1.9057336e-05\n",
      "31 Train Loss 310.00394 Test RE 0.1550331338381047 c 0.15494649 k 0.9898874 m 5.835507e-05\n",
      "32 Train Loss 270.83157 Test RE 0.13670824591274014 c 0.15528786 k 0.98778015 m 0.0001844218\n",
      "33 Train Loss 249.75424 Test RE 0.11763243453763324 c 0.15697226 k 1.0010366 m 0.00037324888\n",
      "34 Train Loss 244.57849 Test RE 0.11050339229853515 c 0.15683246 k 0.99402905 m 0.00047672496\n",
      "35 Train Loss 242.75836 Test RE 0.1110200023206451 c 0.1574139 k 0.9934913 m 0.000648406\n",
      "36 Train Loss 241.99704 Test RE 0.10799353739001236 c 0.15807314 k 0.9943875 m 0.00095830037\n",
      "37 Train Loss 241.65753 Test RE 0.10674155224750516 c 0.15800755 k 0.98888505 m 0.0013413368\n",
      "38 Train Loss 241.46106 Test RE 0.10689356384538382 c 0.15857184 k 0.9892742 m 0.0020396297\n",
      "39 Train Loss 241.3128 Test RE 0.1069027569249725 c 0.15953167 k 0.99043274 m 0.0030546673\n",
      "40 Train Loss 241.19345 Test RE 0.1065700102066001 c 0.16127594 k 0.9881413 m 0.005017818\n",
      "41 Train Loss 240.82086 Test RE 0.10729969380325666 c 0.16492267 k 0.98976296 m 0.008547659\n",
      "42 Train Loss 240.61905 Test RE 0.10678125295641401 c 0.16794677 k 0.9910478 m 0.011497172\n",
      "43 Train Loss 240.53378 Test RE 0.10619344008950445 c 0.16903532 k 0.9891421 m 0.012795771\n",
      "44 Train Loss 240.25992 Test RE 0.10673369496186429 c 0.17202036 k 0.9873798 m 0.016605953\n",
      "45 Train Loss 240.01703 Test RE 0.1071535711954227 c 0.1758124 k 0.98990935 m 0.020745557\n",
      "46 Train Loss 239.61967 Test RE 0.10840698767075452 c 0.18719907 k 0.9908972 m 0.03336634\n",
      "47 Train Loss 237.906 Test RE 0.10878231389433786 c 0.20533593 k 0.98835766 m 0.053701416\n",
      "48 Train Loss 237.0797 Test RE 0.10532008621121895 c 0.21015202 k 0.9895574 m 0.058954444\n",
      "49 Train Loss 236.36539 Test RE 0.10679664645210765 c 0.21667823 k 0.99112076 m 0.066006176\n",
      "50 Train Loss 235.69458 Test RE 0.10587131154226795 c 0.22520462 k 0.99085134 m 0.07503977\n",
      "51 Train Loss 234.02533 Test RE 0.10494352751396295 c 0.24797378 k 0.9935539 m 0.099323034\n",
      "52 Train Loss 232.58514 Test RE 0.10317790872180696 c 0.26844385 k 0.99303275 m 0.121278666\n",
      "53 Train Loss 231.41739 Test RE 0.10340786450218671 c 0.28100598 k 0.98697245 m 0.13568667\n",
      "54 Train Loss 228.09755 Test RE 0.10367340127802782 c 0.31080213 k 0.98363715 m 0.16873683\n",
      "55 Train Loss 226.37926 Test RE 0.10399818220147253 c 0.32216534 k 0.99132586 m 0.18026398\n",
      "56 Train Loss 225.33736 Test RE 0.10241386737676957 c 0.3345946 k 0.9947437 m 0.19347592\n",
      "57 Train Loss 224.35556 Test RE 0.10146878554560075 c 0.34658507 k 0.98646826 m 0.20737822\n",
      "58 Train Loss 223.2844 Test RE 0.10220415841642412 c 0.35594442 k 0.98938173 m 0.21697398\n",
      "59 Train Loss 221.9534 Test RE 0.10236785951841153 c 0.3757294 k 0.9890324 m 0.23843174\n",
      "60 Train Loss 219.28922 Test RE 0.09796419834228225 c 0.41033566 k 0.98927516 m 0.27616662\n",
      "61 Train Loss 217.31244 Test RE 0.09728710323982893 c 0.44258374 k 0.9869682 m 0.3116698\n",
      "62 Train Loss 212.30707 Test RE 0.09579347629239612 c 0.4993568 k 0.984685 m 0.37439165\n",
      "63 Train Loss 207.48184 Test RE 0.09124250601665791 c 0.54612064 k 0.9800975 m 0.42672127\n",
      "64 Train Loss 204.78836 Test RE 0.09338100656839167 c 0.57087207 k 0.9833352 m 0.4533908\n",
      "65 Train Loss 201.61111 Test RE 0.09512188853141357 c 0.5983436 k 0.97677714 m 0.48440093\n",
      "66 Train Loss 199.55835 Test RE 0.09107294199710897 c 0.62053996 k 0.9811653 m 0.50884503\n",
      "67 Train Loss 198.10663 Test RE 0.09105883100695182 c 0.64473176 k 0.98344916 m 0.53574955\n",
      "68 Train Loss 193.94794 Test RE 0.0914026845341245 c 0.68241507 k 0.9886586 m 0.57712233\n",
      "69 Train Loss 189.4624 Test RE 0.08888679030315452 c 0.7027211 k 0.9899517 m 0.5989162\n",
      "70 Train Loss 184.09552 Test RE 0.09237187929351161 c 0.7517867 k 0.98456407 m 0.65284866\n",
      "71 Train Loss 181.15182 Test RE 0.08963223305625231 c 0.780774 k 0.9835132 m 0.68459225\n",
      "72 Train Loss 178.4548 Test RE 0.08855568109960708 c 0.80979365 k 0.98445016 m 0.7159847\n",
      "73 Train Loss 174.21265 Test RE 0.08906851283795107 c 0.84769917 k 0.9878833 m 0.7572723\n",
      "74 Train Loss 168.1789 Test RE 0.08030967152245973 c 0.8872478 k 0.98632544 m 0.8014848\n",
      "75 Train Loss 165.07101 Test RE 0.08129822752355471 c 0.9153991 k 0.9834788 m 0.8332341\n",
      "76 Train Loss 158.6692 Test RE 0.07982763600552295 c 0.9929843 k 0.98902684 m 0.91830933\n",
      "77 Train Loss 155.33563 Test RE 0.07914109745090751 c 0.9976071 k 0.9825514 m 0.9241095\n",
      "78 Train Loss 153.1197 Test RE 0.07956297291682948 c 1.010954 k 0.98343736 m 0.938715\n",
      "79 Train Loss 151.02162 Test RE 0.08194856919892869 c 1.020686 k 0.9862488 m 0.94899446\n",
      "80 Train Loss 149.87906 Test RE 0.08235697290569183 c 1.0277066 k 0.9880206 m 0.9565516\n",
      "81 Train Loss 145.58395 Test RE 0.07628989005289255 c 1.0415084 k 0.97874737 m 0.97318673\n",
      "82 Train Loss 141.24979 Test RE 0.07401731309339778 c 1.0736066 k 0.9645771 m 1.0106757\n",
      "83 Train Loss 138.4529 Test RE 0.07851463317375104 c 1.0876613 k 0.9733244 m 1.0253412\n",
      "84 Train Loss 136.7186 Test RE 0.07493801344103793 c 1.1032041 k 0.97896314 m 1.0425208\n",
      "85 Train Loss 134.34036 Test RE 0.07488028444712322 c 1.1089323 k 0.9731869 m 1.0502555\n",
      "86 Train Loss 132.41852 Test RE 0.07473562108140445 c 1.1290582 k 0.9718655 m 1.0731199\n",
      "87 Train Loss 129.4743 Test RE 0.07571696399806313 c 1.1505626 k 0.97841114 m 1.0965904\n",
      "88 Train Loss 126.97488 Test RE 0.07364186977448314 c 1.1551062 k 0.9705916 m 1.1027318\n",
      "89 Train Loss 124.40851 Test RE 0.07578400073658348 c 1.1835829 k 0.9668056 m 1.1352023\n",
      "90 Train Loss 120.439606 Test RE 0.07581023153096014 c 1.2328655 k 0.9806542 m 1.189174\n",
      "91 Train Loss 117.86009 Test RE 0.0727199582639407 c 1.2708586 k 0.980291 m 1.232202\n",
      "92 Train Loss 112.22919 Test RE 0.06859151720534111 c 1.3162917 k 0.9825463 m 1.2841254\n",
      "93 Train Loss 108.96186 Test RE 0.07297201552950652 c 1.3534275 k 0.9827138 m 1.3264028\n",
      "94 Train Loss 106.15686 Test RE 0.06833126156500112 c 1.3979635 k 0.97955817 m 1.3767561\n",
      "95 Train Loss 104.22911 Test RE 0.07167931821154841 c 1.4241476 k 0.9771815 m 1.4063206\n",
      "96 Train Loss 102.547615 Test RE 0.07151790422838071 c 1.4429154 k 0.9780978 m 1.4273487\n",
      "97 Train Loss 100.15082 Test RE 0.0710740006322048 c 1.4623265 k 0.9779034 m 1.4491147\n",
      "98 Train Loss 98.858284 Test RE 0.07095778453513889 c 1.4710556 k 0.9746148 m 1.4590248\n",
      "99 Train Loss 98.006 Test RE 0.06926523185166228 c 1.478279 k 0.97926366 m 1.4666502\n",
      "100 Train Loss 96.51132 Test RE 0.06926020845773008 c 1.5136317 k 0.98124874 m 1.5065358\n",
      "101 Train Loss 95.75615 Test RE 0.06893750692762314 c 1.5390775 k 0.97653455 m 1.5358928\n",
      "102 Train Loss 93.79991 Test RE 0.06945376835327613 c 1.5820609 k 0.9736617 m 1.5849828\n",
      "103 Train Loss 92.59119 Test RE 0.06904903605327488 c 1.6140093 k 0.9800468 m 1.6204392\n",
      "104 Train Loss 92.06969 Test RE 0.0690601944333756 c 1.6364166 k 0.98263735 m 1.6457324\n",
      "105 Train Loss 91.073135 Test RE 0.06897040281746213 c 1.6568602 k 0.973135 m 1.6701876\n",
      "106 Train Loss 89.971344 Test RE 0.06763979298370447 c 1.6828816 k 0.9723762 m 1.6997979\n",
      "107 Train Loss 88.93988 Test RE 0.06840478568692693 c 1.701644 k 0.97696215 m 1.720607\n",
      "108 Train Loss 88.246185 Test RE 0.06764601386719599 c 1.7131075 k 0.97254807 m 1.7342228\n",
      "109 Train Loss 87.85336 Test RE 0.06735525903724332 c 1.7160192 k 0.9730992 m 1.7374628\n",
      "110 Train Loss 87.74376 Test RE 0.06695645416920432 c 1.720679 k 0.9739068 m 1.7427417\n",
      "111 Train Loss 87.46106 Test RE 0.06721147453046503 c 1.7423695 k 0.9746142 m 1.7677984\n",
      "112 Train Loss 87.08748 Test RE 0.0671463175439801 c 1.7587348 k 0.9749865 m 1.7867562\n",
      "113 Train Loss 86.71347 Test RE 0.06747685459596778 c 1.781379 k 0.9751733 m 1.8126973\n",
      "114 Train Loss 86.517044 Test RE 0.06785977808635549 c 1.7958882 k 0.973743 m 1.8294487\n",
      "115 Train Loss 86.35651 Test RE 0.06761042940793421 c 1.8287473 k 0.97565114 m 1.8672596\n",
      "116 Train Loss 86.14454 Test RE 0.06727004115023538 c 1.8537171 k 0.97323805 m 1.8965192\n",
      "117 Train Loss 85.75751 Test RE 0.0665852107659232 c 1.8607972 k 0.9730389 m 1.9045321\n",
      "118 Train Loss 85.65473 Test RE 0.06707437253059759 c 1.8622718 k 0.9743322 m 1.9059892\n",
      "119 Train Loss 85.54892 Test RE 0.06730728155203926 c 1.8606374 k 0.97361785 m 1.9043133\n",
      "120 Train Loss 85.49155 Test RE 0.06710905162909234 c 1.8567705 k 0.9732008 m 1.9000922\n",
      "121 Train Loss 85.38713 Test RE 0.06743959755760912 c 1.8455863 k 0.97419345 m 1.8873453\n",
      "122 Train Loss 85.309395 Test RE 0.06746837287258922 c 1.8424922 k 0.97273827 m 1.8841754\n",
      "123 Train Loss 85.26987 Test RE 0.06733525821465355 c 1.8477141 k 0.9721783 m 1.8904725\n",
      "124 Train Loss 85.20952 Test RE 0.06734323704533854 c 1.8575886 k 0.97323793 m 1.901954\n",
      "125 Train Loss 85.171776 Test RE 0.0675212540614601 c 1.8586309 k 0.973274 m 1.9034983\n",
      "126 Train Loss 85.1008 Test RE 0.0670950686780502 c 1.8581016 k 0.9727098 m 1.9032415\n",
      "127 Train Loss 85.08066 Test RE 0.06721500274554852 c 1.857589 k 0.97321457 m 1.9026893\n",
      "128 Train Loss 85.0383 Test RE 0.06719673637150253 c 1.8603654 k 0.9731757 m 1.9070439\n",
      "129 Train Loss 84.96463 Test RE 0.06739790387353296 c 1.876154 k 0.9746549 m 1.9265312\n",
      "130 Train Loss 84.88654 Test RE 0.06731807231191869 c 1.8837936 k 0.974092 m 1.9361241\n",
      "131 Train Loss 84.84323 Test RE 0.06741342157209444 c 1.8858486 k 0.9737076 m 1.9400144\n",
      "132 Train Loss 84.80046 Test RE 0.06764107366483577 c 1.8884119 k 0.97449374 m 1.9448755\n",
      "133 Train Loss 84.710815 Test RE 0.06744328834966888 c 1.883853 k 0.9738721 m 1.9423662\n",
      "134 Train Loss 84.62326 Test RE 0.06718230356980542 c 1.8805792 k 0.97309303 m 1.940575\n",
      "135 Train Loss 84.58333 Test RE 0.06715826380428076 c 1.8805494 k 0.97308457 m 1.9417375\n",
      "136 Train Loss 84.56232 Test RE 0.06715205741612358 c 1.8793234 k 0.97321683 m 1.9408821\n",
      "137 Train Loss 84.5226 Test RE 0.06714544550156479 c 1.8771988 k 0.97333384 m 1.9382958\n",
      "138 Train Loss 84.497795 Test RE 0.06709297572288428 c 1.880203 k 0.97330064 m 1.9416962\n",
      "139 Train Loss 84.47998 Test RE 0.06694169722265284 c 1.8834059 k 0.9726236 m 1.9459469\n",
      "140 Train Loss 84.45927 Test RE 0.06711774502163634 c 1.8883418 k 0.9726409 m 1.9523145\n",
      "141 Train Loss 84.35886 Test RE 0.06685664483247226 c 1.8889794 k 0.97362334 m 1.9565998\n",
      "142 Train Loss 84.27008 Test RE 0.0670841433674801 c 1.8783933 k 0.97339064 m 1.948129\n",
      "143 Train Loss 84.19939 Test RE 0.06698910667067406 c 1.8747265 k 0.97336066 m 1.9484737\n",
      "144 Train Loss 84.097534 Test RE 0.06707012032279702 c 1.8698468 k 0.97270554 m 1.9490741\n",
      "145 Train Loss 83.983475 Test RE 0.06686010102952075 c 1.861593 k 0.97335595 m 1.9457195\n",
      "146 Train Loss 83.90572 Test RE 0.06657423372838345 c 1.8508259 k 0.9736207 m 1.9376354\n",
      "147 Train Loss 83.71301 Test RE 0.0664972580255151 c 1.8312597 k 0.97302145 m 1.9249257\n",
      "148 Train Loss 83.5155 Test RE 0.06608008714962285 c 1.813835 k 0.9736497 m 1.9168673\n",
      "149 Train Loss 83.13066 Test RE 0.06646177485360955 c 1.792767 k 0.97306275 m 1.9093184\n",
      "150 Train Loss 82.983154 Test RE 0.06569822914326952 c 1.7850957 k 0.97481793 m 1.910647\n",
      "151 Train Loss 82.8849 Test RE 0.06564335838393903 c 1.7842963 k 0.97410303 m 1.9182855\n",
      "152 Train Loss 82.61013 Test RE 0.06591332163901491 c 1.7988153 k 0.9757495 m 1.9304887\n",
      "153 Train Loss 82.421364 Test RE 0.06602444831441964 c 1.8116764 k 0.97506464 m 1.9382402\n",
      "154 Train Loss 82.32611 Test RE 0.06596509110018875 c 1.8161736 k 0.9745003 m 1.9448124\n",
      "155 Train Loss 82.099686 Test RE 0.06583193598391965 c 1.8132848 k 0.9748108 m 1.9511979\n",
      "156 Train Loss 81.67136 Test RE 0.0656581227865247 c 1.8139908 k 0.97431237 m 1.9625913\n",
      "157 Train Loss 81.594124 Test RE 0.06554667836908112 c 1.8160323 k 0.97405744 m 1.9645659\n",
      "158 Train Loss 81.49864 Test RE 0.06558657497012921 c 1.8190669 k 0.9735473 m 1.9684752\n",
      "159 Train Loss 81.36006 Test RE 0.0657956422544363 c 1.8283752 k 0.97474456 m 1.9823914\n",
      "160 Train Loss 81.28076 Test RE 0.06558373608941537 c 1.8354583 k 0.9748362 m 1.9923245\n",
      "161 Train Loss 81.222176 Test RE 0.06531662417195595 c 1.8375162 k 0.9750965 m 1.9979922\n",
      "162 Train Loss 81.0238 Test RE 0.06528609597265143 c 1.827552 k 0.97653705 m 1.9992504\n",
      "163 Train Loss 80.89621 Test RE 0.06536259072221884 c 1.8177913 k 0.97641695 m 1.9951074\n",
      "164 Train Loss 80.62434 Test RE 0.06535324403888498 c 1.8076981 k 0.97463214 m 1.9918656\n",
      "165 Train Loss 80.403694 Test RE 0.06462957667148835 c 1.8072067 k 0.9743521 m 1.9996668\n",
      "166 Train Loss 80.24345 Test RE 0.06502996743174419 c 1.8019614 k 0.9745483 m 2.0057862\n",
      "167 Train Loss 79.88994 Test RE 0.06428786569790654 c 1.7904499 k 0.9765304 m 2.0091684\n",
      "168 Train Loss 79.78081 Test RE 0.06390047933968282 c 1.7832042 k 0.97584796 m 2.0065207\n",
      "169 Train Loss 79.47479 Test RE 0.06428007481488196 c 1.7853581 k 0.9751195 m 2.0167134\n",
      "170 Train Loss 78.979485 Test RE 0.06433951292716035 c 1.8019277 k 0.9767281 m 2.0464482\n",
      "171 Train Loss 78.495255 Test RE 0.06403878368371922 c 1.8058615 k 0.97580475 m 2.0726516\n",
      "172 Train Loss 78.14589 Test RE 0.06357257619727276 c 1.8095005 k 0.9721591 m 2.083432\n",
      "173 Train Loss 77.77562 Test RE 0.06397457038637035 c 1.830371 k 0.9730716 m 2.1134167\n",
      "174 Train Loss 77.25567 Test RE 0.06399387046648085 c 1.8528286 k 0.97657716 m 2.1500654\n",
      "175 Train Loss 77.15068 Test RE 0.06359946478682801 c 1.8514057 k 0.9750009 m 2.14884\n",
      "176 Train Loss 76.97814 Test RE 0.06353415952599112 c 1.8422197 k 0.97544545 m 2.1476965\n",
      "177 Train Loss 76.84567 Test RE 0.06310585078485811 c 1.8455325 k 0.978428 m 2.1592877\n",
      "178 Train Loss 76.68686 Test RE 0.06264978857398439 c 1.8486562 k 0.9776856 m 2.170392\n",
      "179 Train Loss 76.53604 Test RE 0.06244922347040868 c 1.8389763 k 0.97399414 m 2.1693316\n",
      "180 Train Loss 76.14719 Test RE 0.06309213107565029 c 1.8108194 k 0.9733828 m 2.1565976\n",
      "181 Train Loss 75.50252 Test RE 0.062132105451917934 c 1.7904383 k 0.974345 m 2.150109\n",
      "182 Train Loss 75.31689 Test RE 0.062378387491552834 c 1.786151 k 0.97426784 m 2.1555564\n",
      "183 Train Loss 75.05783 Test RE 0.06283962964552937 c 1.7876368 k 0.9758015 m 2.1652157\n",
      "184 Train Loss 74.80735 Test RE 0.06269496277588421 c 1.7937155 k 0.976051 m 2.17577\n",
      "185 Train Loss 74.66864 Test RE 0.062227494830619366 c 1.7951888 k 0.9736513 m 2.1787417\n",
      "186 Train Loss 74.46454 Test RE 0.06164136722990679 c 1.7860519 k 0.97416747 m 2.1751914\n",
      "187 Train Loss 74.30684 Test RE 0.060980232319697694 c 1.7708288 k 0.9750583 m 2.1715317\n",
      "188 Train Loss 73.615585 Test RE 0.06091497213550073 c 1.7414426 k 0.9745271 m 2.1676753\n",
      "189 Train Loss 72.77381 Test RE 0.06032630104596 c 1.7292129 k 0.9729212 m 2.1892362\n",
      "190 Train Loss 72.092865 Test RE 0.06027235455788954 c 1.7229635 k 0.9714539 m 2.2076712\n",
      "191 Train Loss 71.69194 Test RE 0.06010167314957699 c 1.7263746 k 0.9751027 m 2.2249613\n",
      "192 Train Loss 71.10595 Test RE 0.06033102305531478 c 1.725902 k 0.97649944 m 2.2389786\n",
      "193 Train Loss 69.98009 Test RE 0.05969582649966317 c 1.7220988 k 0.9802717 m 2.267183\n",
      "194 Train Loss 69.19957 Test RE 0.05889165375030056 c 1.7228959 k 0.9777023 m 2.280656\n",
      "195 Train Loss 68.796326 Test RE 0.05907381122675346 c 1.7248412 k 0.9766726 m 2.3003094\n",
      "196 Train Loss 67.62706 Test RE 0.05771994005994434 c 1.744847 k 0.9788474 m 2.3730261\n",
      "197 Train Loss 66.806244 Test RE 0.05636422050274589 c 1.7525002 k 0.975641 m 2.4129488\n",
      "198 Train Loss 65.54874 Test RE 0.05661240617180103 c 1.7607397 k 0.97717977 m 2.4559402\n",
      "199 Train Loss 64.45343 Test RE 0.05596749293399291 c 1.7490232 k 0.9753399 m 2.4782083\n",
      "Training time: 87.23\n",
      "Training time: 87.23\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 6753.5527 Test RE 0.4058668825913921 c 0.13787706 k 0.4497712 m -5.1551415e-05\n",
      "1 Train Loss 2554.9294 Test RE 0.22643449337245683 c 0.12842798 k 0.53045154 m -4.3502554e-05\n",
      "2 Train Loss 892.24646 Test RE 0.2283380496646764 c 0.12503105 k 0.7510484 m 1.0232203e-05\n",
      "3 Train Loss 541.27985 Test RE 0.17104212239359565 c 0.12382052 k 0.79806393 m 6.556077e-05\n",
      "4 Train Loss 361.32733 Test RE 0.13423800318988488 c 0.12181175 k 0.86800754 m 0.0002358954\n",
      "5 Train Loss 286.52612 Test RE 0.1191294436115983 c 0.120846204 k 0.9216459 m 0.00045592987\n",
      "6 Train Loss 253.45285 Test RE 0.1131087243195018 c 0.11996809 k 0.9668337 m 0.00074779283\n",
      "7 Train Loss 245.9372 Test RE 0.10728614320386787 c 0.11974978 k 0.9871304 m 0.00095629826\n",
      "8 Train Loss 244.36295 Test RE 0.10732610927469914 c 0.119837455 k 0.99078834 m 0.001178053\n",
      "9 Train Loss 243.9798 Test RE 0.10812578636274184 c 0.12006338 k 0.99165946 m 0.0015672569\n",
      "10 Train Loss 243.48727 Test RE 0.10757642136509558 c 0.12095625 k 0.99036944 m 0.0027147483\n",
      "11 Train Loss 243.26596 Test RE 0.10753620539153486 c 0.12202461 k 0.9915319 m 0.0040837717\n",
      "12 Train Loss 242.87155 Test RE 0.10785790381660289 c 0.124899834 k 0.99053127 m 0.0076620495\n",
      "13 Train Loss 242.58322 Test RE 0.10751913178232148 c 0.12715322 k 0.9887901 m 0.010407586\n",
      "14 Train Loss 242.11917 Test RE 0.10763425912923776 c 0.13010441 k 0.99016386 m 0.013918277\n",
      "15 Train Loss 241.6746 Test RE 0.10749670743439738 c 0.13436829 k 0.9892411 m 0.018797718\n",
      "16 Train Loss 240.93542 Test RE 0.10718290688180188 c 0.14066981 k 0.9888455 m 0.025918126\n",
      "17 Train Loss 240.19527 Test RE 0.10635284058342118 c 0.14923547 k 0.9872369 m 0.03559291\n",
      "18 Train Loss 239.52313 Test RE 0.1053219715686378 c 0.16053389 k 0.9884444 m 0.04851212\n",
      "19 Train Loss 239.00925 Test RE 0.10652475540674482 c 0.16871938 k 0.9901805 m 0.057898324\n",
      "20 Train Loss 238.2499 Test RE 0.10575554719288471 c 0.17641133 k 0.9868958 m 0.066480055\n",
      "21 Train Loss 236.65924 Test RE 0.10538988320082655 c 0.18916878 k 0.9893257 m 0.08074327\n",
      "22 Train Loss 236.29068 Test RE 0.10549057928709532 c 0.19300756 k 0.98986757 m 0.08498234\n",
      "23 Train Loss 235.6074 Test RE 0.10506274051581202 c 0.19965085 k 0.9862454 m 0.092400745\n",
      "24 Train Loss 234.79193 Test RE 0.10480587955248596 c 0.2075623 k 0.99111897 m 0.10136702\n",
      "25 Train Loss 233.77585 Test RE 0.10500440199405683 c 0.22176027 k 0.9959502 m 0.11730345\n",
      "26 Train Loss 232.08238 Test RE 0.1032570206565626 c 0.24629003 k 0.99122083 m 0.14489505\n",
      "27 Train Loss 230.56227 Test RE 0.10170336559043437 c 0.26004952 k 0.9823549 m 0.1604869\n",
      "28 Train Loss 227.70654 Test RE 0.10371486770086882 c 0.29153314 k 0.991215 m 0.19643435\n",
      "29 Train Loss 224.89096 Test RE 0.10182426343491818 c 0.31941223 k 0.99476564 m 0.2283363\n",
      "30 Train Loss 222.14539 Test RE 0.09949365301353069 c 0.34735662 k 0.9784006 m 0.2599225\n",
      "31 Train Loss 218.42654 Test RE 0.09768333712671769 c 0.38261327 k 0.98852575 m 0.29990488\n",
      "32 Train Loss 215.02602 Test RE 0.0974196719381265 c 0.40937138 k 0.98975414 m 0.33010685\n",
      "33 Train Loss 212.43962 Test RE 0.09686741888876121 c 0.43699816 k 0.9828402 m 0.36127377\n",
      "34 Train Loss 210.6673 Test RE 0.09509996991524114 c 0.4567662 k 0.9828737 m 0.38363236\n",
      "35 Train Loss 207.69002 Test RE 0.09305102121968807 c 0.4911899 k 0.98731756 m 0.42293212\n",
      "36 Train Loss 202.7009 Test RE 0.09377217143869292 c 0.5192106 k 0.98817235 m 0.45482305\n",
      "37 Train Loss 198.14859 Test RE 0.09142925576018379 c 0.55026215 k 0.98219 m 0.4900769\n",
      "38 Train Loss 193.54886 Test RE 0.09317053831565762 c 0.59359074 k 0.99138 m 0.53923494\n",
      "39 Train Loss 184.5332 Test RE 0.0884003844325467 c 0.6578453 k 0.9973533 m 0.6122675\n",
      "40 Train Loss 179.40137 Test RE 0.0871704810789385 c 0.6743706 k 0.98573554 m 0.630801\n",
      "41 Train Loss 172.63838 Test RE 0.08520073398895071 c 0.7155016 k 0.98242885 m 0.67716026\n",
      "42 Train Loss 167.01468 Test RE 0.08622874778634322 c 0.74739885 k 0.99012446 m 0.7134308\n",
      "43 Train Loss 161.72552 Test RE 0.08524642129566505 c 0.7794188 k 0.98255634 m 0.74960744\n",
      "44 Train Loss 158.31494 Test RE 0.08532129184806712 c 0.8051406 k 0.9796817 m 0.77857786\n",
      "45 Train Loss 154.23984 Test RE 0.08342107576411505 c 0.8298312 k 0.97560626 m 0.80631375\n",
      "46 Train Loss 150.20552 Test RE 0.08215391313482139 c 0.85816467 k 0.98089635 m 0.83840364\n",
      "47 Train Loss 146.12274 Test RE 0.08237823455195412 c 0.89581007 k 0.98123336 m 0.8811003\n",
      "48 Train Loss 141.63272 Test RE 0.07889586788386203 c 0.9267853 k 0.9764772 m 0.9161866\n",
      "49 Train Loss 136.45383 Test RE 0.07957086970085792 c 0.9718259 k 0.9824953 m 0.9673518\n",
      "50 Train Loss 131.79893 Test RE 0.07795196970968493 c 1.0196242 k 0.98462665 m 1.0213796\n",
      "51 Train Loss 128.80481 Test RE 0.0757185168658816 c 1.054832 k 0.9821294 m 1.061151\n",
      "52 Train Loss 125.67142 Test RE 0.07644294516618345 c 1.0849049 k 0.9797506 m 1.0951151\n",
      "53 Train Loss 122.2002 Test RE 0.07467675619290144 c 1.117297 k 0.9772105 m 1.1316109\n",
      "54 Train Loss 120.018906 Test RE 0.07342916771694195 c 1.1369349 k 0.97369856 m 1.1537191\n",
      "55 Train Loss 116.53322 Test RE 0.07275663274257241 c 1.1669647 k 0.9674233 m 1.1875322\n",
      "56 Train Loss 113.50505 Test RE 0.07075347473836313 c 1.1819683 k 0.96849555 m 1.2045456\n",
      "57 Train Loss 112.07033 Test RE 0.07215567739245889 c 1.1992263 k 0.9721365 m 1.224072\n",
      "58 Train Loss 109.05019 Test RE 0.07118048790348744 c 1.2426087 k 0.9774075 m 1.2731748\n",
      "59 Train Loss 106.50011 Test RE 0.07217601088505533 c 1.2659822 k 0.9769681 m 1.2995677\n",
      "60 Train Loss 104.57889 Test RE 0.07045729703958864 c 1.2890984 k 0.9737242 m 1.3256805\n",
      "61 Train Loss 101.91283 Test RE 0.07089913350428566 c 1.3207431 k 0.96927744 m 1.3613772\n",
      "62 Train Loss 100.13315 Test RE 0.06913393116097935 c 1.3516884 k 0.97029495 m 1.3963627\n",
      "63 Train Loss 97.417885 Test RE 0.07011915353280049 c 1.4013486 k 0.97571146 m 1.4527336\n",
      "64 Train Loss 95.59378 Test RE 0.06884717935474115 c 1.4366904 k 0.97861886 m 1.4929559\n",
      "65 Train Loss 93.895325 Test RE 0.06780866788194889 c 1.462008 k 0.9748145 m 1.5217994\n",
      "66 Train Loss 92.594635 Test RE 0.0683531916579621 c 1.4806415 k 0.9760848 m 1.5431155\n",
      "67 Train Loss 91.59664 Test RE 0.06813955318988958 c 1.499347 k 0.973171 m 1.5645354\n",
      "68 Train Loss 90.427025 Test RE 0.0674774471728984 c 1.5173678 k 0.970981 m 1.5853024\n",
      "69 Train Loss 89.55621 Test RE 0.06750165747471251 c 1.5412366 k 0.9720915 m 1.6128478\n",
      "70 Train Loss 88.70786 Test RE 0.06674741484882739 c 1.5684081 k 0.9741759 m 1.6441354\n",
      "71 Train Loss 87.72041 Test RE 0.06653200536031906 c 1.5984414 k 0.9740713 m 1.6787096\n",
      "72 Train Loss 86.35893 Test RE 0.06666470633022613 c 1.6382815 k 0.974231 m 1.7248285\n",
      "73 Train Loss 85.66118 Test RE 0.0664232654720963 c 1.6601216 k 0.9725763 m 1.7502068\n",
      "74 Train Loss 85.01531 Test RE 0.06564315410492368 c 1.681635 k 0.97206163 m 1.7752831\n",
      "75 Train Loss 84.35376 Test RE 0.0655732047521263 c 1.7061827 k 0.9728818 m 1.8039538\n",
      "76 Train Loss 84.00459 Test RE 0.06582046414489028 c 1.7166398 k 0.9734294 m 1.8162589\n",
      "77 Train Loss 83.54233 Test RE 0.06598521767404152 c 1.7356225 k 0.9749533 m 1.838692\n",
      "78 Train Loss 83.284615 Test RE 0.06599016233159206 c 1.746824 k 0.97544324 m 1.8519629\n",
      "79 Train Loss 82.99034 Test RE 0.06578290572224484 c 1.7615002 k 0.97376835 m 1.86959\n",
      "80 Train Loss 82.74873 Test RE 0.06598579521053027 c 1.7734631 k 0.9721965 m 1.8842753\n",
      "81 Train Loss 82.36513 Test RE 0.06567102144550865 c 1.7936877 k 0.97387344 m 1.9092618\n",
      "82 Train Loss 82.25409 Test RE 0.06568390048870933 c 1.8033015 k 0.97499394 m 1.9211731\n",
      "83 Train Loss 81.997406 Test RE 0.0657914317392468 c 1.8249685 k 0.97386 m 1.9483784\n",
      "84 Train Loss 81.87477 Test RE 0.06585614233474436 c 1.8329759 k 0.9734464 m 1.9588647\n",
      "85 Train Loss 81.77821 Test RE 0.0659642048521972 c 1.845815 k 0.97231233 m 1.9756515\n",
      "86 Train Loss 81.676956 Test RE 0.06592697746255842 c 1.8603382 k 0.9731127 m 1.9941072\n",
      "87 Train Loss 81.62901 Test RE 0.06580984693098312 c 1.8677189 k 0.9743733 m 2.003616\n",
      "88 Train Loss 81.54116 Test RE 0.06589624988313773 c 1.8753467 k 0.97479683 m 2.0148175\n",
      "89 Train Loss 81.48659 Test RE 0.0658319260841135 c 1.8834516 k 0.97335446 m 2.026615\n",
      "90 Train Loss 81.39819 Test RE 0.06589800305139222 c 1.8916787 k 0.97393745 m 2.0399873\n",
      "91 Train Loss 81.20929 Test RE 0.06563334434315879 c 1.8832783 k 0.9747358 m 2.0359619\n",
      "92 Train Loss 81.07034 Test RE 0.06558326388378002 c 1.872428 k 0.9740269 m 2.0269673\n",
      "93 Train Loss 80.93599 Test RE 0.06575889294605271 c 1.8671638 k 0.9757767 m 2.025401\n",
      "94 Train Loss 80.83891 Test RE 0.06541828915403725 c 1.8691802 k 0.9756931 m 2.031488\n",
      "95 Train Loss 80.67566 Test RE 0.06592756667454609 c 1.8717185 k 0.9740843 m 2.039683\n",
      "96 Train Loss 80.50413 Test RE 0.06506699651994785 c 1.8660272 k 0.9747893 m 2.0380673\n",
      "97 Train Loss 80.344986 Test RE 0.06509026133971511 c 1.8725926 k 0.97578233 m 2.0517979\n",
      "98 Train Loss 80.19002 Test RE 0.0653967223746601 c 1.8781407 k 0.9758496 m 2.0640433\n",
      "99 Train Loss 79.89848 Test RE 0.06482237416128443 c 1.8964096 k 0.97472495 m 2.0997818\n",
      "100 Train Loss 79.743546 Test RE 0.06531487681202072 c 1.904758 k 0.9723866 m 2.1191862\n",
      "101 Train Loss 79.46278 Test RE 0.06473602193432608 c 1.8991799 k 0.9723695 m 2.1199064\n",
      "102 Train Loss 79.04784 Test RE 0.0651888525100737 c 1.898001 k 0.9759739 m 2.134415\n",
      "103 Train Loss 78.64714 Test RE 0.06412646219763575 c 1.8951705 k 0.97697395 m 2.1536021\n",
      "104 Train Loss 77.72093 Test RE 0.06422395441410544 c 1.8826314 k 0.9780634 m 2.1709504\n",
      "105 Train Loss 76.73081 Test RE 0.06309502183922513 c 1.8676888 k 0.97445077 m 2.184711\n",
      "106 Train Loss 75.926414 Test RE 0.0642571874322149 c 1.8540401 k 0.97347784 m 2.1911259\n",
      "107 Train Loss 75.02748 Test RE 0.06246617725348391 c 1.8174006 k 0.97682196 m 2.1742394\n",
      "108 Train Loss 74.46637 Test RE 0.062210132624684694 c 1.7972097 k 0.97538793 m 2.1657403\n",
      "109 Train Loss 74.00676 Test RE 0.06151589527496095 c 1.786177 k 0.972826 m 2.1677973\n",
      "110 Train Loss 73.53538 Test RE 0.06145755975529907 c 1.7794247 k 0.9727347 m 2.1809335\n",
      "111 Train Loss 72.58245 Test RE 0.06170739173670159 c 1.7756062 k 0.9724801 m 2.2090364\n",
      "112 Train Loss 71.949776 Test RE 0.06025176016430244 c 1.7667753 k 0.97401655 m 2.2238162\n",
      "113 Train Loss 71.37854 Test RE 0.0600204980072843 c 1.7601438 k 0.97608835 m 2.2368677\n",
      "114 Train Loss 70.53871 Test RE 0.05956744658946261 c 1.7539713 k 0.9783906 m 2.2624166\n",
      "115 Train Loss 69.78471 Test RE 0.059030238894001524 c 1.7686379 k 0.9758236 m 2.3029416\n",
      "116 Train Loss 68.82283 Test RE 0.058985516420907214 c 1.7774426 k 0.9776647 m 2.3414507\n",
      "117 Train Loss 67.67827 Test RE 0.05901700339568266 c 1.776604 k 0.97913677 m 2.4036412\n",
      "118 Train Loss 66.14444 Test RE 0.05766212188704462 c 1.7842618 k 0.97573566 m 2.4541597\n",
      "119 Train Loss 64.997375 Test RE 0.056629628635053796 c 1.7834725 k 0.9735013 m 2.4905865\n",
      "120 Train Loss 64.11496 Test RE 0.05580539739473555 c 1.7693716 k 0.9753761 m 2.5006013\n",
      "121 Train Loss 63.08564 Test RE 0.05497584695468269 c 1.7584563 k 0.977806 m 2.5176032\n",
      "122 Train Loss 61.62288 Test RE 0.05422201322400875 c 1.7694107 k 0.9788349 m 2.5915945\n",
      "123 Train Loss 60.007957 Test RE 0.055140249607901495 c 1.7775267 k 0.9811301 m 2.648737\n",
      "124 Train Loss 58.79534 Test RE 0.05274237208081823 c 1.765328 k 0.9786023 m 2.6820111\n",
      "125 Train Loss 57.09029 Test RE 0.05458477262559852 c 1.732477 k 0.9801457 m 2.699654\n",
      "126 Train Loss 55.6885 Test RE 0.051498007316477336 c 1.7130297 k 0.9826643 m 2.7153182\n",
      "127 Train Loss 54.066822 Test RE 0.05221773757548841 c 1.6821007 k 0.9770721 m 2.7387526\n",
      "128 Train Loss 51.83328 Test RE 0.049301610457903225 c 1.6488522 k 0.9729947 m 2.7794623\n",
      "129 Train Loss 50.478508 Test RE 0.04779961242168466 c 1.6318636 k 0.9750405 m 2.815568\n",
      "130 Train Loss 48.318405 Test RE 0.0464125982172683 c 1.6039219 k 0.97962075 m 2.8716736\n",
      "131 Train Loss 45.85862 Test RE 0.04555045235262147 c 1.5918689 k 0.9858944 m 2.9335544\n",
      "132 Train Loss 43.52028 Test RE 0.044841674204417085 c 1.5991278 k 0.98176473 m 3.015619\n",
      "133 Train Loss 40.567104 Test RE 0.04179705946478161 c 1.5829947 k 0.97639096 m 3.1303916\n",
      "134 Train Loss 38.061806 Test RE 0.042095089656259056 c 1.5684491 k 0.97665334 m 3.2373788\n",
      "135 Train Loss 35.746544 Test RE 0.03955394495109782 c 1.5576985 k 0.97904336 m 3.2861483\n",
      "136 Train Loss 33.466225 Test RE 0.03700940493805406 c 1.5255446 k 0.9868697 m 3.3575225\n",
      "137 Train Loss 30.60579 Test RE 0.035608543992342326 c 1.4942796 k 0.99361116 m 3.4612334\n",
      "138 Train Loss 27.022732 Test RE 0.030776822340733378 c 1.4597889 k 0.9897573 m 3.5218875\n",
      "139 Train Loss 24.812405 Test RE 0.031684174676844104 c 1.4379088 k 0.9825181 m 3.5554664\n",
      "140 Train Loss 22.686176 Test RE 0.030322357986902 c 1.4226748 k 0.9800396 m 3.6806257\n",
      "141 Train Loss 20.190033 Test RE 0.028537240979955983 c 1.4182143 k 0.9796244 m 3.782171\n",
      "142 Train Loss 18.018597 Test RE 0.028020057744411107 c 1.3919625 k 0.98850435 m 3.8602018\n",
      "143 Train Loss 16.372204 Test RE 0.023097182307232032 c 1.3576814 k 0.99460304 m 3.9308314\n",
      "144 Train Loss 13.420848 Test RE 0.020590596937036736 c 1.3161074 k 0.98853076 m 4.048484\n",
      "145 Train Loss 11.209066 Test RE 0.01938379706533805 c 1.2947298 k 0.9872666 m 4.163284\n",
      "146 Train Loss 8.808583 Test RE 0.018046144526490036 c 1.2629602 k 0.9945034 m 4.294579\n",
      "147 Train Loss 6.5630236 Test RE 0.014475237160238796 c 1.2078394 k 0.9914442 m 4.431054\n",
      "148 Train Loss 5.3705864 Test RE 0.012439610097878098 c 1.1816667 k 0.99082184 m 4.478398\n",
      "149 Train Loss 4.205447 Test RE 0.012003156137803485 c 1.163895 k 0.9936138 m 4.530094\n",
      "150 Train Loss 2.7704997 Test RE 0.009441323366175567 c 1.1113378 k 0.9943098 m 4.6195955\n",
      "151 Train Loss 1.7475154 Test RE 0.006409432493843057 c 1.0522354 k 0.9944998 m 4.6808105\n",
      "152 Train Loss 1.3379905 Test RE 0.006052332599677902 c 1.0279309 k 0.9976361 m 4.6996093\n",
      "153 Train Loss 0.90253997 Test RE 0.004459361042957245 c 1.0026646 k 0.998308 m 4.7549915\n",
      "154 Train Loss 0.6416385 Test RE 0.003907459170416547 c 1.0038182 k 0.99671483 m 4.8066044\n",
      "155 Train Loss 0.38411564 Test RE 0.002705377101782766 c 1.0008925 k 0.9982428 m 4.872918\n",
      "156 Train Loss 0.24346563 Test RE 0.001858896365644991 c 0.99675393 k 0.9984067 m 4.9234376\n",
      "157 Train Loss 0.19482082 Test RE 0.0014393577242273142 c 0.99749076 k 0.9991792 m 4.9495373\n",
      "158 Train Loss 0.15817901 Test RE 0.0012271301586590617 c 0.99305356 k 1.0003005 m 4.980323\n",
      "159 Train Loss 0.1292417 Test RE 0.0012535299751864782 c 0.9894256 k 1.000311 m 4.996868\n",
      "160 Train Loss 0.07616605 Test RE 0.0008779788794967798 c 0.9884345 k 0.9998971 m 5.01627\n",
      "161 Train Loss 0.060525097 Test RE 0.0007337866927802668 c 0.9886261 k 1.0004396 m 5.016502\n",
      "162 Train Loss 0.048584294 Test RE 0.0005095302919966803 c 0.9935698 k 1.0002675 m 5.0111947\n",
      "163 Train Loss 0.04089271 Test RE 0.0004774263812324835 c 0.997359 k 0.99975777 m 4.9998245\n",
      "164 Train Loss 0.029859655 Test RE 0.00044104922136395754 c 1.0013163 k 0.99974304 m 4.98363\n",
      "165 Train Loss 0.027553864 Test RE 0.0003921966703150922 c 1.0021163 k 0.999837 m 4.9858623\n",
      "166 Train Loss 0.018637333 Test RE 0.00037748272934464035 c 1.0045019 k 0.99992174 m 5.003743\n",
      "167 Train Loss 0.015565039 Test RE 0.00045062957727696226 c 1.0068136 k 0.9999949 m 5.0110784\n",
      "168 Train Loss 0.013077384 Test RE 0.0003957908703435025 c 1.0078627 k 1.0002306 m 5.0090733\n",
      "169 Train Loss 0.00977122 Test RE 0.0002609925879969309 c 1.0034513 k 1.000364 m 5.00276\n",
      "170 Train Loss 0.007709615 Test RE 0.00013032468938882838 c 0.9999627 k 1.0001404 m 5.0027094\n",
      "171 Train Loss 0.0073982263 Test RE 9.687837592137006e-05 c 1.0002916 k 1.0000516 m 5.001938\n",
      "172 Train Loss 0.0072501674 Test RE 9.656830148961153e-05 c 1.0006043 k 1.0000114 m 5.000894\n",
      "173 Train Loss 0.007155497 Test RE 0.00010085707560649376 c 1.0005202 k 1.0000162 m 5.001274\n",
      "174 Train Loss 0.0067746327 Test RE 0.00010800279287883186 c 0.99996156 k 1.0000702 m 5.0025787\n",
      "175 Train Loss 0.0064295293 Test RE 7.206756869479322e-05 c 0.99959743 k 1.0000348 m 5.001403\n",
      "176 Train Loss 0.0064002103 Test RE 6.561909784309975e-05 c 0.9997162 k 1.0000114 m 5.0007963\n",
      "177 Train Loss 0.006386436 Test RE 6.92722282983991e-05 c 0.99963814 k 1.0000186 m 5.000715\n",
      "178 Train Loss 0.0063859257 Test RE 6.943840207058267e-05 c 0.99962974 k 1.0000193 m 5.000719\n",
      "179 Train Loss 0.006384182 Test RE 6.976827512195872e-05 c 0.9996097 k 1.0000204 m 5.000733\n",
      "180 Train Loss 0.006382156 Test RE 6.98352080121674e-05 c 0.9995919 k 1.0000211 m 5.000753\n",
      "181 Train Loss 0.006335756 Test RE 6.812876012638144e-05 c 0.9994984 k 1.0000014 m 5.001145\n",
      "182 Train Loss 0.006025071 Test RE 0.00010030957130964181 c 0.999219 k 0.99996185 m 5.002204\n",
      "183 Train Loss 0.005620961 Test RE 8.611818418730997e-05 c 0.9990362 k 0.999989 m 5.0013533\n",
      "184 Train Loss 0.005563277 Test RE 7.714507437465331e-05 c 0.9991453 k 1.0000112 m 5.0010724\n",
      "185 Train Loss 0.0055588805 Test RE 7.694561343350284e-05 c 0.9992187 k 1.0000153 m 5.0010943\n",
      "186 Train Loss 0.005558678 Test RE 7.635511189214537e-05 c 0.9992326 k 1.000016 m 5.001098\n",
      "187 Train Loss 0.005553979 Test RE 7.685751317046937e-05 c 0.9993053 k 1.0000199 m 5.0011506\n",
      "188 Train Loss 0.0055535403 Test RE 7.699092828095486e-05 c 0.99930066 k 1.0000198 m 5.001146\n",
      "189 Train Loss 0.0055529987 Test RE 7.664077745198912e-05 c 0.99929285 k 1.0000196 m 5.001136\n",
      "190 Train Loss 0.0055526216 Test RE 7.690335701762725e-05 c 0.9992859 k 1.0000194 m 5.001124\n",
      "191 Train Loss 0.005551721 Test RE 7.665819253868268e-05 c 0.9992775 k 1.0000191 m 5.001107\n",
      "192 Train Loss 0.005550815 Test RE 7.617226031264963e-05 c 0.9992728 k 1.0000188 m 5.0010943\n",
      "193 Train Loss 0.0055501927 Test RE 7.657940067405998e-05 c 0.9992672 k 1.0000184 m 5.00107\n",
      "194 Train Loss 0.005487451 Test RE 8.192894325873812e-05 c 0.9993027 k 1.0000058 m 5.0009723\n",
      "195 Train Loss 0.005199226 Test RE 8.76696999252433e-05 c 0.99961615 k 0.9999616 m 5.0005746\n",
      "196 Train Loss 0.0049963994 Test RE 7.719865786523862e-05 c 0.9998508 k 0.99998164 m 4.9998083\n",
      "197 Train Loss 0.004958764 Test RE 7.440250473194933e-05 c 0.9999223 k 0.9999991 m 4.9999194\n",
      "198 Train Loss 0.0049525225 Test RE 7.421308664128631e-05 c 0.99992573 k 1.0000069 m 5.0000577\n",
      "199 Train Loss 0.0049516736 Test RE 7.421376348017812e-05 c 0.99992466 k 1.0000077 m 5.0000696\n",
      "Training time: 96.12\n",
      "Training time: 96.12\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "m_full = []\n",
    "k_full = []\n",
    "c_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val = 5.0\n",
    "rowdy_terms = 2\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []   \n",
    "    beta_val = []\n",
    "    m_val = []\n",
    "    k_val = []\n",
    "    c_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "    N_f = 10000 #Total number of collocation points\n",
    "\n",
    "    layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "    PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.25, \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-6, \n",
    "                                tolerance_change = 1e-6, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "    train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    beta_full.append(beta_val)\n",
    "    m_full.append(m_val)\n",
    "    k_full.append(k_val)\n",
    "    c_full.append(c_val)\n",
    "    \n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full,\"m\": m_full,\"k\": k_full,\"c\": c_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "990b2054-f35e-4c8e-c378-69ff2eb19f4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f01e02fb890>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_pred = PINN.test()\n",
    "plt.plot(t,x_true,'b')\n",
    "plt.plot(t,x_pred,'r--')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
