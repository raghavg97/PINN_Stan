{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"high\"\n",
    "label = \"KG_rowdy_\" + level\n",
    "\n",
    "x = np.linspace(-2,2,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,rowdy_terms,n_val):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        self.omega1.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        self.omega.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "                    \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_rowdy_high\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 55747.55 Test MSE 3.0748231243536046 Test RE 1.266910530996972\n",
      "1 Train Loss 9556.1045 Test MSE 3.9494596598161293 Test RE 1.4358356033949815\n",
      "2 Train Loss 1704.7495 Test MSE 4.242468104788718 Test RE 1.4881447270868495\n",
      "3 Train Loss 520.3102 Test MSE 3.295653575217817 Test RE 1.3116158434903915\n",
      "4 Train Loss 169.0393 Test MSE 3.1386434230981983 Test RE 1.27999085365564\n",
      "5 Train Loss 95.58743 Test MSE 3.0536121772750597 Test RE 1.2625332262114293\n",
      "6 Train Loss 58.998947 Test MSE 2.464952007305727 Test RE 1.134331809296488\n",
      "7 Train Loss 44.459724 Test MSE 2.0524880775321592 Test RE 1.0350854371251497\n",
      "8 Train Loss 35.131905 Test MSE 1.8342459967831688 Test RE 0.9785086447732788\n",
      "9 Train Loss 27.835024 Test MSE 1.6379179312833776 Test RE 0.9246597333877836\n",
      "10 Train Loss 22.448769 Test MSE 1.4551249648393667 Test RE 0.871537388329989\n",
      "11 Train Loss 18.422468 Test MSE 1.2138866605124352 Test RE 0.7960217721423868\n",
      "12 Train Loss 15.568688 Test MSE 1.0126616893171936 Test RE 0.7270563418625012\n",
      "13 Train Loss 12.129358 Test MSE 0.7739005676871759 Test RE 0.6355920545460545\n",
      "14 Train Loss 10.35633 Test MSE 0.6820737612252771 Test RE 0.5966938316909725\n",
      "15 Train Loss 8.930312 Test MSE 0.6271648379898608 Test RE 0.5721721666596484\n",
      "16 Train Loss 8.006528 Test MSE 0.5737801931580792 Test RE 0.5472788351838671\n",
      "17 Train Loss 6.7773843 Test MSE 0.4588570493462386 Test RE 0.489411963070855\n",
      "18 Train Loss 5.833246 Test MSE 0.4192506647393425 Test RE 0.46781350695387347\n",
      "19 Train Loss 4.707685 Test MSE 0.3158683021895963 Test RE 0.40605877482720765\n",
      "20 Train Loss 4.066357 Test MSE 0.2467027453418517 Test RE 0.35885819477516623\n",
      "21 Train Loss 3.5367188 Test MSE 0.2058644090971693 Test RE 0.32781325635471903\n",
      "22 Train Loss 2.998188 Test MSE 0.1566208733326071 Test RE 0.28593064078699676\n",
      "23 Train Loss 2.7965517 Test MSE 0.136417653767152 Test RE 0.2668524317942549\n",
      "24 Train Loss 2.4647384 Test MSE 0.12067307871343433 Test RE 0.25098113177354986\n",
      "25 Train Loss 2.1838605 Test MSE 0.10698028950854767 Test RE 0.2363130803740397\n",
      "26 Train Loss 1.982846 Test MSE 0.10351261101218266 Test RE 0.23245158327598905\n",
      "27 Train Loss 1.8379433 Test MSE 0.1027890299592599 Test RE 0.23163770886897617\n",
      "28 Train Loss 1.7113216 Test MSE 0.09605354912876912 Test RE 0.2239198451467431\n",
      "29 Train Loss 1.5624597 Test MSE 0.09366465289234296 Test RE 0.22111781842198894\n",
      "30 Train Loss 1.418313 Test MSE 0.10122010821020909 Test RE 0.22986310851977293\n",
      "31 Train Loss 1.3155478 Test MSE 0.10326025213035613 Test RE 0.23216805734598467\n",
      "32 Train Loss 1.2205523 Test MSE 0.10913126129974583 Test RE 0.23867694162739805\n",
      "33 Train Loss 1.1119132 Test MSE 0.1270466585443728 Test RE 0.25752387609698796\n",
      "34 Train Loss 0.9956514 Test MSE 0.1300137999534122 Test RE 0.26051372139733237\n",
      "35 Train Loss 0.91349655 Test MSE 0.14117078733189953 Test RE 0.27146153175190113\n",
      "36 Train Loss 0.8623288 Test MSE 0.15160875142974112 Test RE 0.28131831823118997\n",
      "37 Train Loss 0.793375 Test MSE 0.16845446734387282 Test RE 0.2965358076272976\n",
      "38 Train Loss 0.76247203 Test MSE 0.17817808214547656 Test RE 0.3049741411168055\n",
      "39 Train Loss 0.7024224 Test MSE 0.17223181725993153 Test RE 0.29984207099765364\n",
      "40 Train Loss 0.6650878 Test MSE 0.16882546167913928 Test RE 0.2968621646588355\n",
      "41 Train Loss 0.63979846 Test MSE 0.16063991832938293 Test RE 0.28957603297121404\n",
      "42 Train Loss 0.6030212 Test MSE 0.162832345308847 Test RE 0.29154541507402315\n",
      "43 Train Loss 0.55225205 Test MSE 0.1471251174874973 Test RE 0.277127285762251\n",
      "44 Train Loss 0.51932085 Test MSE 0.14120897336672142 Test RE 0.27149824380403215\n",
      "45 Train Loss 0.4888498 Test MSE 0.14359006585302145 Test RE 0.27377770224438935\n",
      "46 Train Loss 0.46581638 Test MSE 0.14458339445232551 Test RE 0.2747230410220593\n",
      "47 Train Loss 0.447592 Test MSE 0.13491062729548928 Test RE 0.2653743587286849\n",
      "48 Train Loss 0.4294276 Test MSE 0.1331226754117458 Test RE 0.26361000872381385\n",
      "49 Train Loss 0.39966795 Test MSE 0.12792283780915945 Test RE 0.2584103590289463\n",
      "50 Train Loss 0.38584346 Test MSE 0.12464708683044998 Test RE 0.2550803142499877\n",
      "51 Train Loss 0.36812818 Test MSE 0.12071249403158625 Test RE 0.251022117275876\n",
      "52 Train Loss 0.3530457 Test MSE 0.11498682862575309 Test RE 0.24499652530586558\n",
      "53 Train Loss 0.3354166 Test MSE 0.10890120799712542 Test RE 0.2384252383762721\n",
      "54 Train Loss 0.31875327 Test MSE 0.10225407549524904 Test RE 0.2310341557770477\n",
      "55 Train Loss 0.30432224 Test MSE 0.09365149648717976 Test RE 0.22110228845587593\n",
      "56 Train Loss 0.29277098 Test MSE 0.0881540259330241 Test RE 0.214514647673182\n",
      "57 Train Loss 0.27546915 Test MSE 0.0865791978523609 Test RE 0.21258991377925873\n",
      "58 Train Loss 0.26370102 Test MSE 0.08261000998532742 Test RE 0.20765969615423568\n",
      "59 Train Loss 0.25036055 Test MSE 0.07138463367863422 Test RE 0.1930359709969356\n",
      "60 Train Loss 0.2410531 Test MSE 0.06227773857329217 Test RE 0.18030272644246143\n",
      "61 Train Loss 0.22947085 Test MSE 0.05387549532240079 Test RE 0.16769940236573788\n",
      "62 Train Loss 0.21738806 Test MSE 0.04996538749275325 Test RE 0.16149924887861833\n",
      "63 Train Loss 0.2090547 Test MSE 0.0441701323755658 Test RE 0.15184490608741194\n",
      "64 Train Loss 0.20059744 Test MSE 0.04344077708654132 Test RE 0.15058602507312374\n",
      "65 Train Loss 0.19008103 Test MSE 0.03979411720203478 Test RE 0.14412698916331604\n",
      "66 Train Loss 0.18007807 Test MSE 0.03548350493327732 Test RE 0.13609718189767092\n",
      "67 Train Loss 0.17372942 Test MSE 0.036926819806483706 Test RE 0.13883751457785923\n",
      "68 Train Loss 0.16500498 Test MSE 0.03624904045022426 Test RE 0.13755745567299332\n",
      "69 Train Loss 0.1607224 Test MSE 0.035239190107529565 Test RE 0.13562783716534196\n",
      "70 Train Loss 0.15367626 Test MSE 0.034408853641222925 Test RE 0.13402042131862693\n",
      "71 Train Loss 0.1471576 Test MSE 0.035002245250739576 Test RE 0.13517109396126503\n",
      "72 Train Loss 0.14117123 Test MSE 0.03426623436242707 Test RE 0.13374238614769576\n",
      "73 Train Loss 0.13683486 Test MSE 0.03322960714155214 Test RE 0.1317038529608544\n",
      "74 Train Loss 0.13249347 Test MSE 0.03198077159646354 Test RE 0.12920530504866787\n",
      "75 Train Loss 0.12829596 Test MSE 0.031558350299177106 Test RE 0.1283491577708034\n",
      "76 Train Loss 0.12541829 Test MSE 0.031482643658133774 Test RE 0.12819511425960758\n",
      "77 Train Loss 0.12244265 Test MSE 0.030784906180786553 Test RE 0.1267665859281994\n",
      "78 Train Loss 0.119908236 Test MSE 0.030877743699841646 Test RE 0.12695758595849527\n",
      "79 Train Loss 0.116013445 Test MSE 0.031475126688867226 Test RE 0.12817980906045934\n",
      "80 Train Loss 0.11258243 Test MSE 0.03213735438122988 Test RE 0.12952122336424762\n",
      "81 Train Loss 0.11044703 Test MSE 0.03256539937736963 Test RE 0.1303809320156597\n",
      "82 Train Loss 0.10660714 Test MSE 0.03351856767467111 Test RE 0.13227525360943734\n",
      "83 Train Loss 0.103716634 Test MSE 0.03374349212996892 Test RE 0.1327183243612356\n",
      "84 Train Loss 0.100470476 Test MSE 0.033789621057188884 Test RE 0.13280900944820137\n",
      "85 Train Loss 0.09791111 Test MSE 0.035375718967834875 Test RE 0.13589031784672195\n",
      "86 Train Loss 0.09590627 Test MSE 0.035684814172572944 Test RE 0.13648269724051118\n",
      "87 Train Loss 0.094684884 Test MSE 0.03542883189537011 Test RE 0.13599229210696323\n",
      "88 Train Loss 0.09337146 Test MSE 0.03531561241584227 Test RE 0.13577482378548605\n",
      "89 Train Loss 0.091623254 Test MSE 0.03493656948823747 Test RE 0.135044221631002\n",
      "90 Train Loss 0.08994706 Test MSE 0.035118014421468585 Test RE 0.13539444716771495\n",
      "91 Train Loss 0.08856409 Test MSE 0.035135369189007164 Test RE 0.13542789793317017\n",
      "92 Train Loss 0.086167656 Test MSE 0.03397760334787512 Test RE 0.13317792620761196\n",
      "93 Train Loss 0.08484776 Test MSE 0.03322430190428766 Test RE 0.13169333902254318\n",
      "94 Train Loss 0.083494134 Test MSE 0.03198793336842031 Test RE 0.12921977135271384\n",
      "95 Train Loss 0.081404164 Test MSE 0.03043199945237772 Test RE 0.1260378890060762\n",
      "96 Train Loss 0.07975679 Test MSE 0.029645766794288594 Test RE 0.12439909499500479\n",
      "97 Train Loss 0.07810008 Test MSE 0.029266155789661952 Test RE 0.12360007006656665\n",
      "98 Train Loss 0.074775815 Test MSE 0.02842781176930985 Test RE 0.12181691377425302\n",
      "99 Train Loss 0.07242551 Test MSE 0.027830608930752825 Test RE 0.12053057579689941\n",
      "100 Train Loss 0.07086542 Test MSE 0.027321982331145887 Test RE 0.11942410080162397\n",
      "101 Train Loss 0.06968043 Test MSE 0.026939532667779244 Test RE 0.11858531339516933\n",
      "102 Train Loss 0.06897799 Test MSE 0.026717699823518744 Test RE 0.1180960603696275\n",
      "103 Train Loss 0.06801572 Test MSE 0.026472456140769325 Test RE 0.1175528047463615\n",
      "104 Train Loss 0.06655462 Test MSE 0.026215638605480956 Test RE 0.11698120688478304\n",
      "105 Train Loss 0.06503572 Test MSE 0.025929189169806084 Test RE 0.11634034437010561\n",
      "106 Train Loss 0.06431311 Test MSE 0.025569967183968513 Test RE 0.1155316463636658\n",
      "107 Train Loss 0.06348144 Test MSE 0.025427204792563194 Test RE 0.11520867644652\n",
      "108 Train Loss 0.06263285 Test MSE 0.02518033114408696 Test RE 0.11464802969483845\n",
      "109 Train Loss 0.061531704 Test MSE 0.02483888589314449 Test RE 0.11386806303170974\n",
      "110 Train Loss 0.05997154 Test MSE 0.024366722987517707 Test RE 0.11278061017752257\n",
      "111 Train Loss 0.059023544 Test MSE 0.024025460361357484 Test RE 0.11198806377516336\n",
      "112 Train Loss 0.058086243 Test MSE 0.023823136752460904 Test RE 0.11151552896388942\n",
      "113 Train Loss 0.0568605 Test MSE 0.02359003866933032 Test RE 0.11096862462095342\n",
      "114 Train Loss 0.056172922 Test MSE 0.02343013960762254 Test RE 0.11059189888805146\n",
      "115 Train Loss 0.05505403 Test MSE 0.02329160366662929 Test RE 0.11026446449420535\n",
      "116 Train Loss 0.05439688 Test MSE 0.02318851239710714 Test RE 0.11002017238905598\n",
      "117 Train Loss 0.053596817 Test MSE 0.022908283441566764 Test RE 0.10935336481532663\n",
      "118 Train Loss 0.05253077 Test MSE 0.02252395188927347 Test RE 0.10843217579823386\n",
      "119 Train Loss 0.051784493 Test MSE 0.02232599457610322 Test RE 0.1079546327549608\n",
      "120 Train Loss 0.051217187 Test MSE 0.021993097158751466 Test RE 0.1071467674777375\n",
      "121 Train Loss 0.050449643 Test MSE 0.021800074467937056 Test RE 0.1066755438052044\n",
      "122 Train Loss 0.049707986 Test MSE 0.021417050878137025 Test RE 0.10573425535950548\n",
      "123 Train Loss 0.04884278 Test MSE 0.021251464135145608 Test RE 0.10532471802785526\n",
      "124 Train Loss 0.04774167 Test MSE 0.020821755325401512 Test RE 0.10425443675423912\n",
      "125 Train Loss 0.047076453 Test MSE 0.020468289299248196 Test RE 0.10336574764348498\n",
      "126 Train Loss 0.046149556 Test MSE 0.019945966337707184 Test RE 0.10203834776553598\n",
      "127 Train Loss 0.045379 Test MSE 0.01945698147477243 Test RE 0.10077982725296136\n",
      "128 Train Loss 0.044471055 Test MSE 0.019087377931634047 Test RE 0.09981803432227372\n",
      "129 Train Loss 0.043328583 Test MSE 0.01890379173367818 Test RE 0.09933683961466254\n",
      "130 Train Loss 0.041911773 Test MSE 0.018290890575461835 Test RE 0.09771321496407101\n",
      "131 Train Loss 0.04059424 Test MSE 0.01789478580830135 Test RE 0.09664939262436982\n",
      "132 Train Loss 0.040012304 Test MSE 0.017523835592839345 Test RE 0.09564239919882803\n",
      "133 Train Loss 0.03937619 Test MSE 0.017425573720411903 Test RE 0.09537387314865417\n",
      "134 Train Loss 0.038749415 Test MSE 0.017139031013872038 Test RE 0.09458646814306039\n",
      "135 Train Loss 0.03791987 Test MSE 0.016431313021398046 Test RE 0.09261301258319579\n",
      "136 Train Loss 0.036846768 Test MSE 0.01580586416312862 Test RE 0.0908332805497469\n",
      "137 Train Loss 0.03596268 Test MSE 0.015414227623668213 Test RE 0.08970089181859213\n",
      "138 Train Loss 0.035152458 Test MSE 0.015250185937369841 Test RE 0.08922230655046672\n",
      "139 Train Loss 0.034623377 Test MSE 0.015047520919690567 Test RE 0.08862747058487913\n",
      "140 Train Loss 0.033836927 Test MSE 0.01504637069417004 Test RE 0.08862408319877095\n",
      "141 Train Loss 0.033048764 Test MSE 0.015100766599815211 Test RE 0.08878413634961689\n",
      "142 Train Loss 0.032199435 Test MSE 0.014603623858401393 Test RE 0.0873104438708975\n",
      "143 Train Loss 0.031362634 Test MSE 0.01438884716268227 Test RE 0.08666602477831789\n",
      "144 Train Loss 0.030911388 Test MSE 0.014028133036045779 Test RE 0.0855728142255476\n",
      "145 Train Loss 0.030449152 Test MSE 0.014002551320721928 Test RE 0.0854947532929472\n",
      "146 Train Loss 0.030029887 Test MSE 0.014178887282919333 Test RE 0.08603139239829571\n",
      "147 Train Loss 0.02973633 Test MSE 0.014030049854532864 Test RE 0.08557866040440255\n",
      "148 Train Loss 0.029340336 Test MSE 0.014132664745756014 Test RE 0.08589104868436566\n",
      "149 Train Loss 0.029108852 Test MSE 0.013964794976947685 Test RE 0.08537941187669007\n",
      "150 Train Loss 0.028787855 Test MSE 0.013768579539773392 Test RE 0.08477746881817981\n",
      "151 Train Loss 0.0285362 Test MSE 0.013763830391989055 Test RE 0.08476284655988278\n",
      "152 Train Loss 0.028248984 Test MSE 0.01361441140699316 Test RE 0.08430150189725172\n",
      "153 Train Loss 0.027788164 Test MSE 0.013243190457513678 Test RE 0.08314424410875704\n",
      "154 Train Loss 0.027432233 Test MSE 0.013055140242890177 Test RE 0.08255181908154126\n",
      "155 Train Loss 0.02706195 Test MSE 0.012822534362265133 Test RE 0.08181309317150523\n",
      "156 Train Loss 0.026663981 Test MSE 0.01250141403212846 Test RE 0.08078215718332256\n",
      "157 Train Loss 0.026441198 Test MSE 0.012413493854093283 Test RE 0.08049759284648779\n",
      "158 Train Loss 0.026133504 Test MSE 0.012225012195318208 Test RE 0.07988413324833735\n",
      "159 Train Loss 0.02580507 Test MSE 0.012064178412898315 Test RE 0.07935691065446078\n",
      "160 Train Loss 0.025411189 Test MSE 0.01195169284807675 Test RE 0.07898608506993031\n",
      "161 Train Loss 0.025051812 Test MSE 0.011755694275698744 Test RE 0.07833575227973448\n",
      "162 Train Loss 0.024692394 Test MSE 0.01144620553658456 Test RE 0.07729771340818592\n",
      "163 Train Loss 0.024251197 Test MSE 0.01123523655523282 Test RE 0.07658204993796616\n",
      "164 Train Loss 0.02395207 Test MSE 0.01112640433417508 Test RE 0.07621023415324503\n",
      "165 Train Loss 0.023688806 Test MSE 0.011059426644049228 Test RE 0.07598050628124021\n",
      "166 Train Loss 0.023538113 Test MSE 0.010935172799194124 Test RE 0.07555247607417004\n",
      "167 Train Loss 0.023275208 Test MSE 0.010972508875118778 Test RE 0.07568134597574984\n",
      "168 Train Loss 0.022921223 Test MSE 0.010958236096653456 Test RE 0.07563210771150562\n",
      "169 Train Loss 0.02255067 Test MSE 0.010954122704958946 Test RE 0.07561791137181882\n",
      "170 Train Loss 0.02235468 Test MSE 0.010878433226250919 Test RE 0.0753562107497474\n",
      "171 Train Loss 0.022148537 Test MSE 0.01079794242269573 Test RE 0.07507690842127147\n",
      "172 Train Loss 0.021979997 Test MSE 0.010765334780964022 Test RE 0.0749634640347566\n",
      "173 Train Loss 0.021832138 Test MSE 0.010745921534942976 Test RE 0.07489584231772616\n",
      "174 Train Loss 0.021655237 Test MSE 0.010587641921014312 Test RE 0.07434221546373214\n",
      "175 Train Loss 0.021534083 Test MSE 0.010425147733240875 Test RE 0.0737695248035878\n",
      "176 Train Loss 0.021348692 Test MSE 0.010154197650265312 Test RE 0.07280457704768306\n",
      "177 Train Loss 0.021160802 Test MSE 0.009931713691672579 Test RE 0.07200256577531035\n",
      "178 Train Loss 0.020896485 Test MSE 0.009610301751085387 Test RE 0.07082790383765397\n",
      "179 Train Loss 0.02063286 Test MSE 0.009326782777606648 Test RE 0.06977531534606134\n",
      "180 Train Loss 0.020453071 Test MSE 0.009028211147880003 Test RE 0.06864939760884523\n",
      "181 Train Loss 0.020176994 Test MSE 0.008645918177996766 Test RE 0.0671802224396832\n",
      "182 Train Loss 0.01994457 Test MSE 0.008494773452388188 Test RE 0.06659042358364413\n",
      "183 Train Loss 0.019724865 Test MSE 0.008205156024472882 Test RE 0.06544542596905675\n",
      "184 Train Loss 0.019350836 Test MSE 0.007841021332577008 Test RE 0.06397675299409576\n",
      "185 Train Loss 0.019100405 Test MSE 0.0076206238351396675 Test RE 0.06307120657370748\n",
      "186 Train Loss 0.018820569 Test MSE 0.007278826083365149 Test RE 0.06164055611676353\n",
      "187 Train Loss 0.01862817 Test MSE 0.007074809151374176 Test RE 0.060770560415129356\n",
      "188 Train Loss 0.018383626 Test MSE 0.006991669199318717 Test RE 0.06041243111483517\n",
      "189 Train Loss 0.018224057 Test MSE 0.006729468240659018 Test RE 0.05926881590343893\n",
      "190 Train Loss 0.018079016 Test MSE 0.006623183741700765 Test RE 0.058798910452092255\n",
      "191 Train Loss 0.017934904 Test MSE 0.006450076220412379 Test RE 0.058025421015220804\n",
      "192 Train Loss 0.01773742 Test MSE 0.006449723159952086 Test RE 0.058023832912886514\n",
      "193 Train Loss 0.017546715 Test MSE 0.00638391508067558 Test RE 0.057727058383269914\n",
      "194 Train Loss 0.017363958 Test MSE 0.00615858892606174 Test RE 0.056699141775915785\n",
      "195 Train Loss 0.017093092 Test MSE 0.005826215834808718 Test RE 0.05514792312324273\n",
      "196 Train Loss 0.016887082 Test MSE 0.005795441108928359 Test RE 0.05500208152089632\n",
      "197 Train Loss 0.016647128 Test MSE 0.005684354307404205 Test RE 0.05447239203697273\n",
      "198 Train Loss 0.016418166 Test MSE 0.005646736780874097 Test RE 0.054291851035190936\n",
      "199 Train Loss 0.016118394 Test MSE 0.005431888202898643 Test RE 0.05324897940922777\n",
      "200 Train Loss 0.015857825 Test MSE 0.005301446719357641 Test RE 0.052605733124939734\n",
      "201 Train Loss 0.015478763 Test MSE 0.005336477125376309 Test RE 0.05277924859467271\n",
      "202 Train Loss 0.0151830185 Test MSE 0.00516984889422128 Test RE 0.05194871408465466\n",
      "203 Train Loss 0.014976038 Test MSE 0.005153815215228962 Test RE 0.05186809511164295\n",
      "204 Train Loss 0.014769085 Test MSE 0.005009518726594982 Test RE 0.05113683903518613\n",
      "205 Train Loss 0.014571566 Test MSE 0.004938667523790649 Test RE 0.05077392905941141\n",
      "206 Train Loss 0.0142225865 Test MSE 0.004740202415460289 Test RE 0.049743268762843865\n",
      "207 Train Loss 0.013855788 Test MSE 0.00450912964398701 Test RE 0.04851569285409072\n",
      "208 Train Loss 0.013549098 Test MSE 0.00444375559074732 Test RE 0.04816271482214303\n",
      "209 Train Loss 0.013256608 Test MSE 0.004326018292023086 Test RE 0.04752039616944191\n",
      "210 Train Loss 0.013090295 Test MSE 0.0043613030521644156 Test RE 0.04771380041393696\n",
      "211 Train Loss 0.01290059 Test MSE 0.004265035160996299 Test RE 0.047184263966111535\n",
      "212 Train Loss 0.012835758 Test MSE 0.004173922394538149 Test RE 0.04667755097426496\n",
      "213 Train Loss 0.012714806 Test MSE 0.0039465168041208434 Test RE 0.04538818904604425\n",
      "214 Train Loss 0.012624644 Test MSE 0.003910905743960982 Test RE 0.04518294676024267\n",
      "215 Train Loss 0.012505162 Test MSE 0.003850029374120357 Test RE 0.04482991324285141\n",
      "216 Train Loss 0.012351687 Test MSE 0.003807856725147646 Test RE 0.04458370705982358\n",
      "217 Train Loss 0.012089125 Test MSE 0.0037324087256773476 Test RE 0.04413981157691306\n",
      "218 Train Loss 0.0119414255 Test MSE 0.003724715817338063 Test RE 0.04409429958993441\n",
      "219 Train Loss 0.011788362 Test MSE 0.0035157139987462838 Test RE 0.042839327641923705\n",
      "220 Train Loss 0.011545131 Test MSE 0.0035307925387997653 Test RE 0.04293109611212873\n",
      "221 Train Loss 0.011255798 Test MSE 0.003583580112725119 Test RE 0.04325082896705955\n",
      "222 Train Loss 0.011092769 Test MSE 0.0035260260938589165 Test RE 0.04290210859577785\n",
      "223 Train Loss 0.010944641 Test MSE 0.0034474516786979774 Test RE 0.042421397420669964\n",
      "224 Train Loss 0.010868587 Test MSE 0.0033226486802387777 Test RE 0.04164645970907912\n",
      "225 Train Loss 0.010746744 Test MSE 0.0032721442731563745 Test RE 0.04132873370762091\n",
      "226 Train Loss 0.01064133 Test MSE 0.0031441370683633584 Test RE 0.04051227315924845\n",
      "227 Train Loss 0.010548668 Test MSE 0.003060396089723829 Test RE 0.03996913008541617\n",
      "228 Train Loss 0.010383323 Test MSE 0.002915254088999215 Test RE 0.03900983231446372\n",
      "229 Train Loss 0.010297485 Test MSE 0.0028417310770805083 Test RE 0.03851477501489173\n",
      "230 Train Loss 0.010217386 Test MSE 0.0027623868002009896 Test RE 0.037973280904232395\n",
      "231 Train Loss 0.010119482 Test MSE 0.002791221085350077 Test RE 0.038170952343746324\n",
      "232 Train Loss 0.010045097 Test MSE 0.0028360567520564987 Test RE 0.038476302944208514\n",
      "233 Train Loss 0.009966185 Test MSE 0.0028978231881433745 Test RE 0.03889303357608532\n",
      "234 Train Loss 0.009891391 Test MSE 0.0028662062141872205 Test RE 0.03868027860309373\n",
      "235 Train Loss 0.009805157 Test MSE 0.0027425946336691416 Test RE 0.037836999378213096\n",
      "236 Train Loss 0.009707103 Test MSE 0.002744663419225558 Test RE 0.03785126723265056\n",
      "237 Train Loss 0.009633463 Test MSE 0.0027121562495085708 Test RE 0.03762644867183873\n",
      "238 Train Loss 0.00960172 Test MSE 0.002680109117137167 Test RE 0.03740348898669095\n",
      "239 Train Loss 0.0095282765 Test MSE 0.00272587838015328 Test RE 0.03772151392084732\n",
      "240 Train Loss 0.009428008 Test MSE 0.002665246196538158 Test RE 0.03729963165341125\n",
      "241 Train Loss 0.009354696 Test MSE 0.002641186308218897 Test RE 0.03713089311619456\n",
      "242 Train Loss 0.009323475 Test MSE 0.0026281372937942667 Test RE 0.03703905531272273\n",
      "243 Train Loss 0.009295805 Test MSE 0.002628046378377503 Test RE 0.03703841465930612\n",
      "244 Train Loss 0.009237756 Test MSE 0.0025173679662368353 Test RE 0.036250101557722174\n",
      "245 Train Loss 0.009173168 Test MSE 0.0024686548910639503 Test RE 0.0358976540246085\n",
      "246 Train Loss 0.009128976 Test MSE 0.0023956353340171903 Test RE 0.035362766378150945\n",
      "247 Train Loss 0.009081957 Test MSE 0.002315785737659889 Test RE 0.034768428733156796\n",
      "248 Train Loss 0.009038077 Test MSE 0.002312105393725253 Test RE 0.03474079002420288\n",
      "249 Train Loss 0.008996586 Test MSE 0.002346517993182048 Test RE 0.03499837025002073\n",
      "250 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "251 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "252 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "253 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "254 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "255 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "256 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "257 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "258 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "259 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "260 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "261 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "262 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "263 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "264 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "265 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "266 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "267 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "268 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "269 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "270 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "271 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "272 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "273 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "274 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "275 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "276 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "277 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "278 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "279 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "280 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "281 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "282 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "283 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "284 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "285 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "286 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "287 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "288 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "289 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "290 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "291 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "292 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "293 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "294 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "295 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "296 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "297 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "298 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "299 Train Loss 0.008982886 Test MSE 0.002315133781591941 Test RE 0.03476353426400996\n",
      "Training time: 428.67\n",
      "KG_rowdy_high\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "200 Train Loss nan Test MSE nan Test RE nan\n",
      "201 Train Loss nan Test MSE nan Test RE nan\n",
      "202 Train Loss nan Test MSE nan Test RE nan\n",
      "203 Train Loss nan Test MSE nan Test RE nan\n",
      "204 Train Loss nan Test MSE nan Test RE nan\n",
      "205 Train Loss nan Test MSE nan Test RE nan\n",
      "206 Train Loss nan Test MSE nan Test RE nan\n",
      "207 Train Loss nan Test MSE nan Test RE nan\n",
      "208 Train Loss nan Test MSE nan Test RE nan\n",
      "209 Train Loss nan Test MSE nan Test RE nan\n",
      "210 Train Loss nan Test MSE nan Test RE nan\n",
      "211 Train Loss nan Test MSE nan Test RE nan\n",
      "212 Train Loss nan Test MSE nan Test RE nan\n",
      "213 Train Loss nan Test MSE nan Test RE nan\n",
      "214 Train Loss nan Test MSE nan Test RE nan\n",
      "215 Train Loss nan Test MSE nan Test RE nan\n",
      "216 Train Loss nan Test MSE nan Test RE nan\n",
      "217 Train Loss nan Test MSE nan Test RE nan\n",
      "218 Train Loss nan Test MSE nan Test RE nan\n",
      "219 Train Loss nan Test MSE nan Test RE nan\n",
      "220 Train Loss nan Test MSE nan Test RE nan\n",
      "221 Train Loss nan Test MSE nan Test RE nan\n",
      "222 Train Loss nan Test MSE nan Test RE nan\n",
      "223 Train Loss nan Test MSE nan Test RE nan\n",
      "224 Train Loss nan Test MSE nan Test RE nan\n",
      "225 Train Loss nan Test MSE nan Test RE nan\n",
      "226 Train Loss nan Test MSE nan Test RE nan\n",
      "227 Train Loss nan Test MSE nan Test RE nan\n",
      "228 Train Loss nan Test MSE nan Test RE nan\n",
      "229 Train Loss nan Test MSE nan Test RE nan\n",
      "230 Train Loss nan Test MSE nan Test RE nan\n",
      "231 Train Loss nan Test MSE nan Test RE nan\n",
      "232 Train Loss nan Test MSE nan Test RE nan\n",
      "233 Train Loss nan Test MSE nan Test RE nan\n",
      "234 Train Loss nan Test MSE nan Test RE nan\n",
      "235 Train Loss nan Test MSE nan Test RE nan\n",
      "236 Train Loss nan Test MSE nan Test RE nan\n",
      "237 Train Loss nan Test MSE nan Test RE nan\n",
      "238 Train Loss nan Test MSE nan Test RE nan\n",
      "239 Train Loss nan Test MSE nan Test RE nan\n",
      "240 Train Loss nan Test MSE nan Test RE nan\n",
      "241 Train Loss nan Test MSE nan Test RE nan\n",
      "242 Train Loss nan Test MSE nan Test RE nan\n",
      "243 Train Loss nan Test MSE nan Test RE nan\n",
      "244 Train Loss nan Test MSE nan Test RE nan\n",
      "245 Train Loss nan Test MSE nan Test RE nan\n",
      "246 Train Loss nan Test MSE nan Test RE nan\n",
      "247 Train Loss nan Test MSE nan Test RE nan\n",
      "248 Train Loss nan Test MSE nan Test RE nan\n",
      "249 Train Loss nan Test MSE nan Test RE nan\n",
      "250 Train Loss nan Test MSE nan Test RE nan\n",
      "251 Train Loss nan Test MSE nan Test RE nan\n",
      "252 Train Loss nan Test MSE nan Test RE nan\n",
      "253 Train Loss nan Test MSE nan Test RE nan\n",
      "254 Train Loss nan Test MSE nan Test RE nan\n",
      "255 Train Loss nan Test MSE nan Test RE nan\n",
      "256 Train Loss nan Test MSE nan Test RE nan\n",
      "257 Train Loss nan Test MSE nan Test RE nan\n",
      "258 Train Loss nan Test MSE nan Test RE nan\n",
      "259 Train Loss nan Test MSE nan Test RE nan\n",
      "260 Train Loss nan Test MSE nan Test RE nan\n",
      "261 Train Loss nan Test MSE nan Test RE nan\n",
      "262 Train Loss nan Test MSE nan Test RE nan\n",
      "263 Train Loss nan Test MSE nan Test RE nan\n",
      "264 Train Loss nan Test MSE nan Test RE nan\n",
      "265 Train Loss nan Test MSE nan Test RE nan\n",
      "266 Train Loss nan Test MSE nan Test RE nan\n",
      "267 Train Loss nan Test MSE nan Test RE nan\n",
      "268 Train Loss nan Test MSE nan Test RE nan\n",
      "269 Train Loss nan Test MSE nan Test RE nan\n",
      "270 Train Loss nan Test MSE nan Test RE nan\n",
      "271 Train Loss nan Test MSE nan Test RE nan\n",
      "272 Train Loss nan Test MSE nan Test RE nan\n",
      "273 Train Loss nan Test MSE nan Test RE nan\n",
      "274 Train Loss nan Test MSE nan Test RE nan\n",
      "275 Train Loss nan Test MSE nan Test RE nan\n",
      "276 Train Loss nan Test MSE nan Test RE nan\n",
      "277 Train Loss nan Test MSE nan Test RE nan\n",
      "278 Train Loss nan Test MSE nan Test RE nan\n",
      "279 Train Loss nan Test MSE nan Test RE nan\n",
      "280 Train Loss nan Test MSE nan Test RE nan\n",
      "281 Train Loss nan Test MSE nan Test RE nan\n",
      "282 Train Loss nan Test MSE nan Test RE nan\n",
      "283 Train Loss nan Test MSE nan Test RE nan\n",
      "284 Train Loss nan Test MSE nan Test RE nan\n",
      "285 Train Loss nan Test MSE nan Test RE nan\n",
      "286 Train Loss nan Test MSE nan Test RE nan\n",
      "287 Train Loss nan Test MSE nan Test RE nan\n",
      "288 Train Loss nan Test MSE nan Test RE nan\n",
      "289 Train Loss nan Test MSE nan Test RE nan\n",
      "290 Train Loss nan Test MSE nan Test RE nan\n",
      "291 Train Loss nan Test MSE nan Test RE nan\n",
      "292 Train Loss nan Test MSE nan Test RE nan\n",
      "293 Train Loss nan Test MSE nan Test RE nan\n",
      "294 Train Loss nan Test MSE nan Test RE nan\n",
      "295 Train Loss nan Test MSE nan Test RE nan\n",
      "296 Train Loss nan Test MSE nan Test RE nan\n",
      "297 Train Loss nan Test MSE nan Test RE nan\n",
      "298 Train Loss nan Test MSE nan Test RE nan\n",
      "299 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 25.08\n",
      "KG_rowdy_high\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 51117.676 Test MSE 5.043301203670089 Test RE 1.6225322216621034\n",
      "1 Train Loss 8496.375 Test MSE 7.722270276043167 Test RE 2.0077441803248974\n",
      "2 Train Loss 1295.1088 Test MSE 4.546413804416925 Test RE 1.5405307010602798\n",
      "3 Train Loss 484.45267 Test MSE 3.910563923345247 Test RE 1.4287477898718237\n",
      "4 Train Loss 205.23343 Test MSE 3.147409445239608 Test RE 1.2817770719507362\n",
      "5 Train Loss 116.726875 Test MSE 2.7893637931728845 Test RE 1.206669836168882\n",
      "6 Train Loss 79.444016 Test MSE 2.319829433165337 Test RE 1.1004337561642097\n",
      "7 Train Loss 53.675396 Test MSE 1.767153131351142 Test RE 0.9604460376690678\n",
      "8 Train Loss 33.871513 Test MSE 1.2595039976916664 Test RE 0.8108409093728672\n",
      "9 Train Loss 25.123196 Test MSE 1.0507897608497085 Test RE 0.7406171986279887\n",
      "10 Train Loss 18.487686 Test MSE 0.7773784457158955 Test RE 0.6370186161813881\n",
      "11 Train Loss 15.545635 Test MSE 0.6467432300270938 Test RE 0.5810343693597344\n",
      "12 Train Loss 12.720033 Test MSE 0.5539710608252424 Test RE 0.5377487578616491\n",
      "13 Train Loss 10.694516 Test MSE 0.48118253549782364 Test RE 0.5011766224912766\n",
      "14 Train Loss 8.773555 Test MSE 0.4886299658157327 Test RE 0.5050401734060926\n",
      "15 Train Loss 7.371673 Test MSE 0.45964786648452316 Test RE 0.48983352001670294\n",
      "16 Train Loss 6.0903563 Test MSE 0.4353233959599435 Test RE 0.47669640983451406\n",
      "17 Train Loss 5.334032 Test MSE 0.4301873003769586 Test RE 0.4738759516300393\n",
      "18 Train Loss 4.5531516 Test MSE 0.46110544024770445 Test RE 0.49060955252382416\n",
      "19 Train Loss 4.1327515 Test MSE 0.48051846896769684 Test RE 0.5008306731867475\n",
      "20 Train Loss 3.62736 Test MSE 0.4664628780131922 Test RE 0.49345143995685675\n",
      "21 Train Loss 3.3066905 Test MSE 0.44284606193816517 Test RE 0.48079757705212994\n",
      "22 Train Loss 2.9823525 Test MSE 0.45664507525050274 Test RE 0.48823090417695647\n",
      "23 Train Loss 2.641658 Test MSE 0.4481098197315253 Test RE 0.48364656473584056\n",
      "24 Train Loss 2.3510206 Test MSE 0.46548319361069546 Test RE 0.49293298415154857\n",
      "25 Train Loss 2.0964565 Test MSE 0.4626001589688245 Test RE 0.49140408875709124\n",
      "26 Train Loss 1.8947543 Test MSE 0.4432261665533098 Test RE 0.4810038724165818\n",
      "27 Train Loss 1.7263557 Test MSE 0.4200475348467073 Test RE 0.46825788266993174\n",
      "28 Train Loss 1.5737189 Test MSE 0.4199892357611583 Test RE 0.46822538640298567\n",
      "29 Train Loss 1.3696921 Test MSE 0.3884876078502834 Test RE 0.45032334532391266\n",
      "30 Train Loss 1.2670075 Test MSE 0.3476647993813094 Test RE 0.42600651162931474\n",
      "31 Train Loss 1.1894671 Test MSE 0.3328828922159857 Test RE 0.4168517364572238\n",
      "32 Train Loss 1.1200837 Test MSE 0.3062565053309333 Test RE 0.3998329103559809\n",
      "33 Train Loss 1.0546013 Test MSE 0.2771350648708634 Test RE 0.3803484198769377\n",
      "34 Train Loss 0.9597504 Test MSE 0.23667289618244627 Test RE 0.3514877062108595\n",
      "35 Train Loss 0.8808166 Test MSE 0.219078731793127 Test RE 0.3381707074176736\n",
      "36 Train Loss 0.8459062 Test MSE 0.19910566135296356 Test RE 0.32238711909507073\n",
      "37 Train Loss 0.7867764 Test MSE 0.18237180947201578 Test RE 0.3085423126884986\n",
      "38 Train Loss 0.7514819 Test MSE 0.17316926802864827 Test RE 0.30065697771842936\n",
      "39 Train Loss 0.700786 Test MSE 0.15532100805008897 Test RE 0.2847416367677759\n",
      "40 Train Loss 0.66647834 Test MSE 0.13624644178048828 Test RE 0.2666849216586339\n",
      "41 Train Loss 0.6214176 Test MSE 0.12137258114368282 Test RE 0.2517075084826476\n",
      "42 Train Loss 0.59312904 Test MSE 0.11922417721133499 Test RE 0.24946983734307732\n",
      "43 Train Loss 0.5617894 Test MSE 0.10920753958024221 Test RE 0.2387603397587275\n",
      "44 Train Loss 0.5391493 Test MSE 0.10144968425268404 Test RE 0.2301236356780538\n",
      "45 Train Loss 0.5099438 Test MSE 0.08703444098181362 Test RE 0.21314809180157346\n",
      "46 Train Loss 0.49054426 Test MSE 0.07131066018707005 Test RE 0.192935926734558\n",
      "47 Train Loss 0.48149267 Test MSE 0.06857270198257326 Test RE 0.1891958073689111\n",
      "48 Train Loss 0.46557423 Test MSE 0.06123844751105456 Test RE 0.1787919507853863\n",
      "49 Train Loss 0.44829783 Test MSE 0.05224043898442809 Test RE 0.16513505892840294\n",
      "50 Train Loss 0.43716097 Test MSE 0.053653305809032034 Test RE 0.16735323807387506\n",
      "51 Train Loss 0.425104 Test MSE 0.043282597410070046 Test RE 0.15031161271971216\n",
      "52 Train Loss 0.41059968 Test MSE 0.03302561673169699 Test RE 0.13129897784870276\n",
      "53 Train Loss 0.39822528 Test MSE 0.028681531896316045 Test RE 0.12235931827703066\n",
      "54 Train Loss 0.38819066 Test MSE 0.02567614354859304 Test RE 0.11577126385013224\n",
      "55 Train Loss 0.3776129 Test MSE 0.025624365343065277 Test RE 0.11565447346440579\n",
      "56 Train Loss 0.36293676 Test MSE 0.025721726007680357 Test RE 0.11587398174581053\n",
      "57 Train Loss 0.35111088 Test MSE 0.02470781632875815 Test RE 0.11356723677599947\n",
      "58 Train Loss 0.34006122 Test MSE 0.02079811885552218 Test RE 0.10419524610140307\n",
      "59 Train Loss 0.32975385 Test MSE 0.021977375525244414 Test RE 0.10710846401943229\n",
      "60 Train Loss 0.32157838 Test MSE 0.020486742827855495 Test RE 0.10341233270540008\n",
      "61 Train Loss 0.30850416 Test MSE 0.017125695796817653 Test RE 0.09454966394666799\n",
      "62 Train Loss 0.28984356 Test MSE 0.015315665639828275 Test RE 0.08941364822726931\n",
      "63 Train Loss 0.27520958 Test MSE 0.014663281982875954 Test RE 0.08748860062658394\n",
      "64 Train Loss 0.26611683 Test MSE 0.015287603750358461 Test RE 0.08933169729059688\n",
      "65 Train Loss 0.25587034 Test MSE 0.014848354185506268 Test RE 0.08803898686153441\n",
      "66 Train Loss 0.24958397 Test MSE 0.013822198964773033 Test RE 0.08494238423589145\n",
      "67 Train Loss 0.23239067 Test MSE 0.012038644562762883 Test RE 0.0792728866666416\n",
      "68 Train Loss 0.22355679 Test MSE 0.011196215841867972 Test RE 0.07644894702781456\n",
      "69 Train Loss 0.21871799 Test MSE 0.01073626493200168 Test RE 0.0748621829445867\n",
      "70 Train Loss 0.2113884 Test MSE 0.010773702141079656 Test RE 0.07499259106505092\n",
      "71 Train Loss 0.20314477 Test MSE 0.011080892898699426 Test RE 0.07605420929805927\n",
      "72 Train Loss 0.19893672 Test MSE 0.01029898447740042 Test RE 0.07332179335318169\n",
      "73 Train Loss 0.19536506 Test MSE 0.010130833311178205 Test RE 0.07272076882818956\n",
      "74 Train Loss 0.19191211 Test MSE 0.010000701769587646 Test RE 0.07225220660031843\n",
      "75 Train Loss 0.18766022 Test MSE 0.009349561707021508 Test RE 0.06986046998870195\n",
      "76 Train Loss 0.17827973 Test MSE 0.009015274938242137 Test RE 0.06860019731151124\n",
      "77 Train Loss 0.17181306 Test MSE 0.008760057017377025 Test RE 0.06762220739369772\n",
      "78 Train Loss 0.16754144 Test MSE 0.00953100426985372 Test RE 0.07053508742192428\n",
      "79 Train Loss 0.16312443 Test MSE 0.009027720765096852 Test RE 0.06864753317860216\n",
      "80 Train Loss 0.16040431 Test MSE 0.00886405892354005 Test RE 0.06802243809338294\n",
      "81 Train Loss 0.1569958 Test MSE 0.00843055558401784 Test RE 0.06633824454427281\n",
      "82 Train Loss 0.15331878 Test MSE 0.00815154287494144 Test RE 0.06523126271669703\n",
      "83 Train Loss 0.15067717 Test MSE 0.008919805289879911 Test RE 0.06823600055107049\n",
      "84 Train Loss 0.14845647 Test MSE 0.009754201320671316 Test RE 0.07135620333016646\n",
      "85 Train Loss 0.14607835 Test MSE 0.009288135317954662 Test RE 0.0696306010285852\n",
      "86 Train Loss 0.14304046 Test MSE 0.009731472564954761 Test RE 0.0712730195027682\n",
      "87 Train Loss 0.1396021 Test MSE 0.011475656258387845 Test RE 0.07739709180060378\n",
      "88 Train Loss 0.13565972 Test MSE 0.012582862723717496 Test RE 0.08104488422256605\n",
      "89 Train Loss 0.13290602 Test MSE 0.012209821130249772 Test RE 0.07983448494250084\n",
      "90 Train Loss 0.13022463 Test MSE 0.012324186892083425 Test RE 0.0802075064170877\n",
      "91 Train Loss 0.12740152 Test MSE 0.011629346886499805 Test RE 0.07791364808633652\n",
      "92 Train Loss 0.12559338 Test MSE 0.010326924020637514 Test RE 0.07342118130417333\n",
      "93 Train Loss 0.12409404 Test MSE 0.009600827321524936 Test RE 0.07079298196545829\n",
      "94 Train Loss 0.12207507 Test MSE 0.008595680897797182 Test RE 0.06698476208254557\n",
      "95 Train Loss 0.119318485 Test MSE 0.00843754867325014 Test RE 0.06636575240519989\n",
      "96 Train Loss 0.116102174 Test MSE 0.008729383292574411 Test RE 0.06750371250779418\n",
      "97 Train Loss 0.11412071 Test MSE 0.008456241400693258 Test RE 0.06643922579422448\n",
      "98 Train Loss 0.11186351 Test MSE 0.008310976482030065 Test RE 0.06586609308441538\n",
      "99 Train Loss 0.10956134 Test MSE 0.008604400844592927 Test RE 0.06701873004311584\n",
      "100 Train Loss 0.10768874 Test MSE 0.008964274605696789 Test RE 0.06840588294084465\n",
      "101 Train Loss 0.10626975 Test MSE 0.00939341630996981 Test RE 0.0700241203851332\n",
      "102 Train Loss 0.1051307 Test MSE 0.009159153704868797 Test RE 0.06914544094632961\n",
      "103 Train Loss 0.1042383 Test MSE 0.009008857874227977 Test RE 0.06857577818818808\n",
      "104 Train Loss 0.10241574 Test MSE 0.00830329061844309 Test RE 0.0658356300634973\n",
      "105 Train Loss 0.10048368 Test MSE 0.007694951136927622 Test RE 0.06337804084964316\n",
      "106 Train Loss 0.09853737 Test MSE 0.007585262737902023 Test RE 0.0629247054243716\n",
      "107 Train Loss 0.09630279 Test MSE 0.007629168313092608 Test RE 0.06310655535679588\n",
      "108 Train Loss 0.09408794 Test MSE 0.007965889450389596 Test RE 0.06448415517699199\n",
      "109 Train Loss 0.09240139 Test MSE 0.007886752904329709 Test RE 0.06416304912388861\n",
      "110 Train Loss 0.09019923 Test MSE 0.007744218846508406 Test RE 0.06358060931139672\n",
      "111 Train Loss 0.08852619 Test MSE 0.007480609969951049 Test RE 0.062489116256675324\n",
      "112 Train Loss 0.08739512 Test MSE 0.007222655487171646 Test RE 0.06140225584394203\n",
      "113 Train Loss 0.08632912 Test MSE 0.007069833232434767 Test RE 0.06074918580525834\n",
      "114 Train Loss 0.084885255 Test MSE 0.006474651051502012 Test RE 0.058135854537177095\n",
      "115 Train Loss 0.08333729 Test MSE 0.006240713306105925 Test RE 0.05707592949723117\n",
      "116 Train Loss 0.08183256 Test MSE 0.0067392057963003545 Test RE 0.059311681457195224\n",
      "117 Train Loss 0.08046228 Test MSE 0.006447464857209504 Test RE 0.058013673806059284\n",
      "118 Train Loss 0.07938805 Test MSE 0.006379006981740017 Test RE 0.057704863179478504\n",
      "119 Train Loss 0.07843275 Test MSE 0.005670585002460994 Test RE 0.054406377349983034\n",
      "120 Train Loss 0.0777519 Test MSE 0.0053629525335160255 Test RE 0.05291001119892042\n",
      "121 Train Loss 0.07708129 Test MSE 0.005368262445325811 Test RE 0.05293619807860617\n",
      "122 Train Loss 0.07575391 Test MSE 0.005511251878981725 Test RE 0.053636571165146016\n",
      "123 Train Loss 0.07457287 Test MSE 0.005413871857032762 Test RE 0.05316059864690102\n",
      "124 Train Loss 0.073863976 Test MSE 0.005512907753216776 Test RE 0.05364462820445198\n",
      "125 Train Loss 0.07277653 Test MSE 0.005790460762791548 Test RE 0.05497844326152333\n",
      "126 Train Loss 0.07176387 Test MSE 0.005660901571742329 Test RE 0.054359903706276864\n",
      "127 Train Loss 0.070739836 Test MSE 0.006021104133169295 Test RE 0.05606269177932118\n",
      "128 Train Loss 0.06968018 Test MSE 0.006634666665736737 Test RE 0.0588498595917032\n",
      "129 Train Loss 0.068519965 Test MSE 0.006748334610454429 Test RE 0.059351839162677444\n",
      "130 Train Loss 0.067524254 Test MSE 0.006962127132278257 Test RE 0.060284664963790965\n",
      "131 Train Loss 0.066318296 Test MSE 0.00700542333436758 Test RE 0.06047182411981591\n",
      "132 Train Loss 0.06555961 Test MSE 0.007309871454717276 Test RE 0.061771869721603714\n",
      "133 Train Loss 0.06469091 Test MSE 0.007199222868751871 Test RE 0.061302570587876484\n",
      "134 Train Loss 0.06383913 Test MSE 0.00788309679250221 Test RE 0.06414817516503529\n",
      "135 Train Loss 0.06323549 Test MSE 0.007960655834745214 Test RE 0.0644629685451724\n",
      "136 Train Loss 0.062495664 Test MSE 0.008086841795397296 Test RE 0.06497186756452494\n",
      "137 Train Loss 0.06178009 Test MSE 0.009184542624363804 Test RE 0.06924120924570887\n",
      "138 Train Loss 0.06120589 Test MSE 0.009401011415128913 Test RE 0.07005242388399587\n",
      "139 Train Loss 0.06048992 Test MSE 0.008428476287876744 Test RE 0.06633006327076817\n",
      "140 Train Loss 0.05971686 Test MSE 0.007117961232313144 Test RE 0.06095561060553129\n",
      "141 Train Loss 0.05856817 Test MSE 0.00655484210234188 Test RE 0.05849476414059752\n",
      "142 Train Loss 0.057685845 Test MSE 0.0062257656365230524 Test RE 0.05700753478250539\n",
      "143 Train Loss 0.05704105 Test MSE 0.0061992931584302965 Test RE 0.05688620525765325\n",
      "144 Train Loss 0.056539964 Test MSE 0.005485692696129074 Test RE 0.05351205317009837\n",
      "145 Train Loss 0.055833608 Test MSE 0.005112995233438159 Test RE 0.051662280230817835\n",
      "146 Train Loss 0.055132285 Test MSE 0.004755797500400544 Test RE 0.04982502829900577\n",
      "147 Train Loss 0.0548451 Test MSE 0.004361877031065244 Test RE 0.047716940050574835\n",
      "148 Train Loss 0.05412253 Test MSE 0.004469134405553648 Test RE 0.048300050502272485\n",
      "149 Train Loss 0.053318195 Test MSE 0.004365752177721359 Test RE 0.04773813151109369\n",
      "150 Train Loss 0.05225635 Test MSE 0.0035924650490883037 Test RE 0.04330441266749715\n",
      "151 Train Loss 0.051248375 Test MSE 0.0030550273361665196 Test RE 0.039934056422516226\n",
      "152 Train Loss 0.050447263 Test MSE 0.0029506205158227913 Test RE 0.039245743019769526\n",
      "153 Train Loss 0.04980934 Test MSE 0.003019741886008528 Test RE 0.039702768219944985\n",
      "154 Train Loss 0.04903789 Test MSE 0.00287692849498308 Test RE 0.038752561199333506\n",
      "155 Train Loss 0.04865171 Test MSE 0.0028879823432014654 Test RE 0.038826938134448104\n",
      "156 Train Loss 0.047952026 Test MSE 0.002882678984791853 Test RE 0.038791271748080905\n",
      "157 Train Loss 0.047375247 Test MSE 0.0027390408488559923 Test RE 0.03781247731809875\n",
      "158 Train Loss 0.046811257 Test MSE 0.002906584905585061 Test RE 0.03895178674242405\n",
      "159 Train Loss 0.04624812 Test MSE 0.00300280007377222 Test RE 0.039591238334627514\n",
      "160 Train Loss 0.045616366 Test MSE 0.003157363477563699 Test RE 0.040597395015154684\n",
      "161 Train Loss 0.045203883 Test MSE 0.003148437675248679 Test RE 0.04053997039699415\n",
      "162 Train Loss 0.04481619 Test MSE 0.003135347932354327 Test RE 0.04045560942958846\n",
      "163 Train Loss 0.04421011 Test MSE 0.003191455954178305 Test RE 0.04081598713817172\n",
      "164 Train Loss 0.04356946 Test MSE 0.0037769035741753304 Test RE 0.044402132199413094\n",
      "165 Train Loss 0.043134127 Test MSE 0.004402268023764301 Test RE 0.04793736044779911\n",
      "166 Train Loss 0.042718064 Test MSE 0.00427287952895048 Test RE 0.04722763531968193\n",
      "167 Train Loss 0.042434346 Test MSE 0.004149589439740977 Test RE 0.046541292697659525\n",
      "168 Train Loss 0.041974153 Test MSE 0.004351669516712498 Test RE 0.04766107457823638\n",
      "169 Train Loss 0.04146592 Test MSE 0.00427734743541311 Test RE 0.047252320490948775\n",
      "170 Train Loss 0.040890712 Test MSE 0.003933344334144107 Test RE 0.045312378614991294\n",
      "171 Train Loss 0.040407225 Test MSE 0.003980722116395406 Test RE 0.045584459296019696\n",
      "172 Train Loss 0.040198155 Test MSE 0.003610153711641911 Test RE 0.043410893390054925\n",
      "173 Train Loss 0.039852228 Test MSE 0.0037567452901575388 Test RE 0.04428348099789851\n",
      "174 Train Loss 0.03934499 Test MSE 0.0034486193689833053 Test RE 0.042428581112345154\n",
      "175 Train Loss 0.038809475 Test MSE 0.0033305551961505045 Test RE 0.041695980855382175\n",
      "176 Train Loss 0.038329873 Test MSE 0.0031348301996343792 Test RE 0.04045226912128963\n",
      "177 Train Loss 0.03790995 Test MSE 0.0030122870993878623 Test RE 0.039653731154877254\n",
      "178 Train Loss 0.03757437 Test MSE 0.003131448074410845 Test RE 0.04043044153369991\n",
      "179 Train Loss 0.037379444 Test MSE 0.003012705778026045 Test RE 0.03965648680079778\n",
      "180 Train Loss 0.03719206 Test MSE 0.003207261244288068 Test RE 0.04091693037438303\n",
      "181 Train Loss 0.03690358 Test MSE 0.0032297509719148 Test RE 0.04106013715142642\n",
      "182 Train Loss 0.036663607 Test MSE 0.0031603822441809834 Test RE 0.040616798036392454\n",
      "183 Train Loss 0.036306635 Test MSE 0.0033022668671541995 Test RE 0.041518529227660736\n",
      "184 Train Loss 0.035828616 Test MSE 0.0033082072721491466 Test RE 0.04155585602013496\n",
      "185 Train Loss 0.035478566 Test MSE 0.003025408419072526 Test RE 0.03974000180051646\n",
      "186 Train Loss 0.035097886 Test MSE 0.002927780502564293 Test RE 0.039093552203855214\n",
      "187 Train Loss 0.03449369 Test MSE 0.0025392116299600997 Test RE 0.036407036246419736\n",
      "188 Train Loss 0.034149878 Test MSE 0.002475537332339302 Test RE 0.03594765930019886\n",
      "189 Train Loss 0.033778228 Test MSE 0.002489606917719734 Test RE 0.03604966787480492\n",
      "190 Train Loss 0.0334615 Test MSE 0.0025569283349326376 Test RE 0.036533825899825866\n",
      "191 Train Loss 0.03316035 Test MSE 0.0023703422878169856 Test RE 0.03517559150567373\n",
      "192 Train Loss 0.032889076 Test MSE 0.0022775180347814165 Test RE 0.034479962850023575\n",
      "193 Train Loss 0.032658692 Test MSE 0.002297114810584191 Test RE 0.03462798556903829\n",
      "194 Train Loss 0.03226382 Test MSE 0.0021902944936553832 Test RE 0.03381326690133299\n",
      "195 Train Loss 0.031772546 Test MSE 0.0021129163521687857 Test RE 0.03321062348640498\n",
      "196 Train Loss 0.031560067 Test MSE 0.002089064039119432 Test RE 0.0330226372218334\n",
      "197 Train Loss 0.031218095 Test MSE 0.0021444846321477646 Test RE 0.03345779732684166\n",
      "198 Train Loss 0.030773599 Test MSE 0.0020470710031741546 Test RE 0.0326890523140354\n",
      "199 Train Loss 0.030469757 Test MSE 0.0019084078622255258 Test RE 0.03156250581228741\n",
      "200 Train Loss 0.030187167 Test MSE 0.001824092772106486 Test RE 0.030857400560491473\n",
      "201 Train Loss 0.02987666 Test MSE 0.0017618511804737154 Test RE 0.030326374081735025\n",
      "202 Train Loss 0.029405568 Test MSE 0.001609771645488453 Test RE 0.028987984045965563\n",
      "203 Train Loss 0.029160308 Test MSE 0.0015657761276987273 Test RE 0.028589114932449037\n",
      "204 Train Loss 0.02888755 Test MSE 0.0014638190836161117 Test RE 0.027642643909892458\n",
      "205 Train Loss 0.028658846 Test MSE 0.0014128530442763865 Test RE 0.027157161360721646\n",
      "206 Train Loss 0.028317971 Test MSE 0.001438840172988866 Test RE 0.027405779197621962\n",
      "207 Train Loss 0.02812916 Test MSE 0.0014564395626319164 Test RE 0.027572878726769057\n",
      "208 Train Loss 0.027883481 Test MSE 0.0014139946294214635 Test RE 0.027168130637462776\n",
      "209 Train Loss 0.027628714 Test MSE 0.0013464409154208606 Test RE 0.026511208611958596\n",
      "210 Train Loss 0.027358692 Test MSE 0.0013731457582020984 Test RE 0.02677282484434945\n",
      "211 Train Loss 0.027166633 Test MSE 0.0014002968534363239 Test RE 0.02703621761040161\n",
      "212 Train Loss 0.026920322 Test MSE 0.0013391262410947131 Test RE 0.026439098151634796\n",
      "213 Train Loss 0.026706269 Test MSE 0.0013620183628727587 Test RE 0.026664126332125657\n",
      "214 Train Loss 0.026552768 Test MSE 0.0013340070918066822 Test RE 0.026388514688162747\n",
      "215 Train Loss 0.026345935 Test MSE 0.0013406188283690672 Test RE 0.02645382852958948\n",
      "216 Train Loss 0.026202273 Test MSE 0.0012721693284266145 Test RE 0.025769639151472627\n",
      "217 Train Loss 0.026057499 Test MSE 0.0012697954605754625 Test RE 0.025745584852746608\n",
      "218 Train Loss 0.02579976 Test MSE 0.0012175682462974241 Test RE 0.025210562370548296\n",
      "219 Train Loss 0.02556075 Test MSE 0.0012056572649723387 Test RE 0.025086946902340233\n",
      "220 Train Loss 0.025348147 Test MSE 0.0011987211466790804 Test RE 0.025014680503738417\n",
      "221 Train Loss 0.025153197 Test MSE 0.0011829350696516854 Test RE 0.024849424234039765\n",
      "222 Train Loss 0.024826774 Test MSE 0.0010729678465516382 Test RE 0.023666238167105176\n",
      "223 Train Loss 0.024477763 Test MSE 0.0009503729977556589 Test RE 0.022273215609865765\n",
      "224 Train Loss 0.024267398 Test MSE 0.0008559812877022119 Test RE 0.021138200468552804\n",
      "225 Train Loss 0.02408832 Test MSE 0.000803027057319942 Test RE 0.020473918315228844\n",
      "226 Train Loss 0.023951882 Test MSE 0.0007749101170501379 Test RE 0.020112290920909052\n",
      "227 Train Loss 0.023843165 Test MSE 0.0007960595628594069 Test RE 0.020384903448273862\n",
      "228 Train Loss 0.023705186 Test MSE 0.0007749598251362101 Test RE 0.0201129359811774\n",
      "229 Train Loss 0.023569759 Test MSE 0.0007785276484921347 Test RE 0.020159181603888087\n",
      "230 Train Loss 0.023366226 Test MSE 0.0008014752836764646 Test RE 0.020454126796415853\n",
      "231 Train Loss 0.023164064 Test MSE 0.0008265020769092388 Test RE 0.020771021320489608\n",
      "232 Train Loss 0.023031099 Test MSE 0.000807281010341843 Test RE 0.02052807592180568\n",
      "233 Train Loss 0.022914492 Test MSE 0.0008061463172113298 Test RE 0.02051364398470959\n",
      "234 Train Loss 0.02273104 Test MSE 0.0008033631055549977 Test RE 0.020478201797583973\n",
      "235 Train Loss 0.02255664 Test MSE 0.0007955633075859823 Test RE 0.020378548589059478\n",
      "236 Train Loss 0.022339206 Test MSE 0.0008159137364462457 Test RE 0.020637543387143128\n",
      "237 Train Loss 0.0222 Test MSE 0.0008141660842099077 Test RE 0.020615429172380937\n",
      "238 Train Loss 0.022124056 Test MSE 0.0008154556475337581 Test RE 0.020631749173427177\n",
      "239 Train Loss 0.021983644 Test MSE 0.0008072013907682785 Test RE 0.020527063587233295\n",
      "240 Train Loss 0.021866295 Test MSE 0.0008242200608952979 Test RE 0.020742326554806036\n",
      "241 Train Loss 0.021725714 Test MSE 0.0008160060660693264 Test RE 0.020638711036745243\n",
      "242 Train Loss 0.021613391 Test MSE 0.0008580220446072848 Test RE 0.021163383406752667\n",
      "243 Train Loss 0.021379191 Test MSE 0.0008145781081599885 Test RE 0.020620644924027643\n",
      "244 Train Loss 0.021252096 Test MSE 0.0008114892379179711 Test RE 0.020581511173204392\n",
      "245 Train Loss 0.021044577 Test MSE 0.0008154908965775359 Test RE 0.020632195084601592\n",
      "246 Train Loss 0.020814583 Test MSE 0.0008403171150282742 Test RE 0.020943896422673393\n",
      "247 Train Loss 0.020713191 Test MSE 0.0007913112159719468 Test RE 0.02032401644315431\n",
      "248 Train Loss 0.020514714 Test MSE 0.0007590605347618931 Test RE 0.019905545466146254\n",
      "249 Train Loss 0.02032197 Test MSE 0.000759838678089051 Test RE 0.019915745838191452\n",
      "250 Train Loss 0.020185323 Test MSE 0.0007735153501068956 Test RE 0.020094182631946948\n",
      "251 Train Loss 0.020013828 Test MSE 0.00068589026734635 Test RE 0.018921832646731855\n",
      "252 Train Loss 0.01985316 Test MSE 0.0007145126503279843 Test RE 0.019312604113836115\n",
      "253 Train Loss 0.019750822 Test MSE 0.0007151794508720323 Test RE 0.01932161350778474\n",
      "254 Train Loss 0.019680334 Test MSE 0.0006977233459872845 Test RE 0.019084355780354507\n",
      "255 Train Loss 0.019602025 Test MSE 0.0006924185467591343 Test RE 0.019011668058823993\n",
      "256 Train Loss 0.019483637 Test MSE 0.0006760593222967081 Test RE 0.018785738809408935\n",
      "257 Train Loss 0.019289585 Test MSE 0.0007202362034344816 Test RE 0.01938980095266701\n",
      "258 Train Loss 0.01915512 Test MSE 0.0007079772051347105 Test RE 0.019224077752693105\n",
      "259 Train Loss 0.019007597 Test MSE 0.0006864155386091506 Test RE 0.018929076657348966\n",
      "260 Train Loss 0.018877346 Test MSE 0.0006458230354039796 Test RE 0.018360844081920444\n",
      "261 Train Loss 0.01878912 Test MSE 0.0006296986619144095 Test RE 0.018130186104889274\n",
      "262 Train Loss 0.018550694 Test MSE 0.0006439046304353638 Test RE 0.018333553532331837\n",
      "263 Train Loss 0.01840063 Test MSE 0.0006553526599076868 Test RE 0.018495812329233037\n",
      "264 Train Loss 0.018291656 Test MSE 0.0006777883348651462 Test RE 0.018809745606345317\n",
      "265 Train Loss 0.018160556 Test MSE 0.000692821756823851 Test RE 0.019017202702786493\n",
      "266 Train Loss 0.018011726 Test MSE 0.0007004600548943591 Test RE 0.019121746826976\n",
      "267 Train Loss 0.017886344 Test MSE 0.000667007126524554 Test RE 0.01865954776550994\n",
      "268 Train Loss 0.017762396 Test MSE 0.0006188558328240595 Test RE 0.017973415788653715\n",
      "269 Train Loss 0.017558208 Test MSE 0.0007117552462326725 Test RE 0.01927530307348164\n",
      "270 Train Loss 0.017421098 Test MSE 0.0007576352673857903 Test RE 0.01988684863400349\n",
      "271 Train Loss 0.017339123 Test MSE 0.0007582763321774944 Test RE 0.019895260374692324\n",
      "272 Train Loss 0.01725777 Test MSE 0.0007045375993811256 Test RE 0.019177322181868142\n",
      "273 Train Loss 0.01720253 Test MSE 0.0006506883782298659 Test RE 0.01842987551966052\n",
      "274 Train Loss 0.017129028 Test MSE 0.000570361914107634 Test RE 0.017254847916944788\n",
      "275 Train Loss 0.017061466 Test MSE 0.0005469391017797763 Test RE 0.016896835010980063\n",
      "276 Train Loss 0.016999638 Test MSE 0.0005429419288220353 Test RE 0.016834978559388095\n",
      "277 Train Loss 0.016959894 Test MSE 0.0005156573891099367 Test RE 0.01640652103116971\n",
      "278 Train Loss 0.016900085 Test MSE 0.0004673457008907874 Test RE 0.015619063943297672\n",
      "279 Train Loss 0.016851885 Test MSE 0.00045703885226385226 Test RE 0.015445872198953828\n",
      "280 Train Loss 0.016797043 Test MSE 0.0004942403490304603 Test RE 0.016062198019782408\n",
      "281 Train Loss 0.016768923 Test MSE 0.0004805156317257051 Test RE 0.015837609736324025\n",
      "282 Train Loss 0.01672543 Test MSE 0.0004945190528906822 Test RE 0.01606672614631669\n",
      "283 Train Loss 0.016660517 Test MSE 0.0005318990061580054 Test RE 0.01666289533252505\n",
      "284 Train Loss 0.016582947 Test MSE 0.0005646195671050783 Test RE 0.01716776813882951\n",
      "285 Train Loss 0.01651904 Test MSE 0.0006798190760940378 Test RE 0.01883790274287165\n",
      "286 Train Loss 0.016476564 Test MSE 0.0006515456898653318 Test RE 0.01844201262424369\n",
      "287 Train Loss 0.016437411 Test MSE 0.0006595674497669093 Test RE 0.018555193352837063\n",
      "288 Train Loss 0.01637021 Test MSE 0.0006287694080938986 Test RE 0.01811680370006223\n",
      "289 Train Loss 0.01630723 Test MSE 0.0006934780640797251 Test RE 0.019026208030322744\n",
      "290 Train Loss 0.016236808 Test MSE 0.0006233652818366142 Test RE 0.0180387808422801\n",
      "291 Train Loss 0.016218483 Test MSE 0.0006178194640831212 Test RE 0.01795835986583956\n",
      "292 Train Loss 0.016177487 Test MSE 0.0005688754577173929 Test RE 0.017232348771031584\n",
      "293 Train Loss 0.016136622 Test MSE 0.0005966947006196187 Test RE 0.017648669377163462\n",
      "294 Train Loss 0.01605974 Test MSE 0.0005694410931621436 Test RE 0.01724091374373762\n",
      "295 Train Loss 0.016008807 Test MSE 0.0005744551129399001 Test RE 0.01731665188715718\n",
      "296 Train Loss 0.01595271 Test MSE 0.0006148993054414808 Test RE 0.01791586899566813\n",
      "297 Train Loss 0.015884895 Test MSE 0.0005587967796213702 Test RE 0.017079015166227566\n",
      "298 Train Loss 0.01581721 Test MSE 0.0005653251822969075 Test RE 0.01717849222311303\n",
      "299 Train Loss 0.01576557 Test MSE 0.0005552507417083217 Test RE 0.017024738527406668\n",
      "Training time: 479.91\n",
      "KG_rowdy_high\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 62450.117 Test MSE 2.2250125395991565 Test RE 1.0777104855748456\n",
      "1 Train Loss 14984.604 Test MSE 2.4093515973580675 Test RE 1.1214656285416975\n",
      "2 Train Loss 2474.2205 Test MSE 3.370349912088069 Test RE 1.3263965172747274\n",
      "3 Train Loss 712.2691 Test MSE 3.874352492547494 Test RE 1.4221173741107045\n",
      "4 Train Loss 335.4485 Test MSE 3.6051267034545162 Test RE 1.371816882492475\n",
      "5 Train Loss 188.75327 Test MSE 3.4060452464121838 Test RE 1.3334019421087895\n",
      "6 Train Loss 114.67658 Test MSE 2.8273004884404136 Test RE 1.214847770497559\n",
      "7 Train Loss 77.95682 Test MSE 2.152980631681308 Test RE 1.0601222224315783\n",
      "8 Train Loss 57.896084 Test MSE 1.6973917843587916 Test RE 0.941297542366995\n",
      "9 Train Loss 43.065002 Test MSE 1.4032478086777902 Test RE 0.855860657904926\n",
      "10 Train Loss 29.730783 Test MSE 1.3765987443463619 Test RE 0.8476948826698689\n",
      "11 Train Loss 21.313414 Test MSE 1.2407902676920075 Test RE 0.8047946229435697\n",
      "12 Train Loss 15.347181 Test MSE 0.9220090643672969 Test RE 0.6937507605278517\n",
      "13 Train Loss 11.766107 Test MSE 0.6079935994407079 Test RE 0.5633591864482325\n",
      "14 Train Loss 9.511264 Test MSE 0.4028094523610892 Test RE 0.4585489501782615\n",
      "15 Train Loss 7.793135 Test MSE 0.26900035994537536 Test RE 0.374724688674495\n",
      "16 Train Loss 6.2142477 Test MSE 0.239945850161942 Test RE 0.35390972650546554\n",
      "17 Train Loss 5.032037 Test MSE 0.3073872305563106 Test RE 0.40057033898092664\n",
      "18 Train Loss 4.2574916 Test MSE 0.26320208821054025 Test RE 0.37066411444809017\n",
      "19 Train Loss 3.528164 Test MSE 0.24847442922429505 Test RE 0.3601444510296486\n",
      "20 Train Loss 3.016749 Test MSE 0.2387506884921142 Test RE 0.3530272203764703\n",
      "21 Train Loss 2.620354 Test MSE 0.21252256973185815 Test RE 0.33307221574751833\n",
      "22 Train Loss 2.2602305 Test MSE 0.14279693679522812 Test RE 0.27302054077609667\n",
      "23 Train Loss 2.020882 Test MSE 0.1246709795869775 Test RE 0.2551047603881587\n",
      "24 Train Loss 1.8105983 Test MSE 0.10452935790481095 Test RE 0.2335904149874874\n",
      "25 Train Loss 1.6437608 Test MSE 0.09121353420602409 Test RE 0.218205412362915\n",
      "26 Train Loss 1.4656508 Test MSE 0.08700903108553262 Test RE 0.21311697500338278\n",
      "27 Train Loss 1.3359864 Test MSE 0.07791737762861414 Test RE 0.20167545279938992\n",
      "28 Train Loss 1.2117761 Test MSE 0.06568680908873417 Test RE 0.1851718474736002\n",
      "29 Train Loss 1.1116356 Test MSE 0.06535737890103588 Test RE 0.18470693014488612\n",
      "30 Train Loss 1.0229965 Test MSE 0.06386430615717519 Test RE 0.18258494961686078\n",
      "31 Train Loss 0.9335866 Test MSE 0.06394345993404416 Test RE 0.1826980629812907\n",
      "32 Train Loss 0.8555247 Test MSE 0.06385158090988699 Test RE 0.1825667582786533\n",
      "33 Train Loss 0.80281305 Test MSE 0.06438795901489484 Test RE 0.18333197049498032\n",
      "34 Train Loss 0.7365278 Test MSE 0.05807338572231481 Test RE 0.1741102945078781\n",
      "35 Train Loss 0.6882803 Test MSE 0.05857532062181807 Test RE 0.17486110323843157\n",
      "36 Train Loss 0.6416526 Test MSE 0.05490439053673288 Test RE 0.16929316112156187\n",
      "37 Train Loss 0.60292137 Test MSE 0.055983229216840534 Test RE 0.17094832498581436\n",
      "38 Train Loss 0.56010646 Test MSE 0.057116997555286805 Test RE 0.1726706651189287\n",
      "39 Train Loss 0.5233385 Test MSE 0.055317543469937586 Test RE 0.16992892883435504\n",
      "40 Train Loss 0.49173167 Test MSE 0.051308205248398187 Test RE 0.1636550038207652\n",
      "41 Train Loss 0.4598947 Test MSE 0.04964990992756833 Test RE 0.16098859470486596\n",
      "42 Train Loss 0.4311055 Test MSE 0.046463392342012036 Test RE 0.15573683140101816\n",
      "43 Train Loss 0.40188622 Test MSE 0.044868995221367426 Test RE 0.15304144197197797\n",
      "44 Train Loss 0.38445318 Test MSE 0.04413198355870196 Test RE 0.15177931929264846\n",
      "45 Train Loss 0.37188017 Test MSE 0.0437457263179203 Test RE 0.1511136489684467\n",
      "46 Train Loss 0.34825188 Test MSE 0.03644677882291468 Test RE 0.13793213309105512\n",
      "47 Train Loss 0.33635682 Test MSE 0.03434748283334271 Test RE 0.13390085017073247\n",
      "48 Train Loss 0.32344764 Test MSE 0.035274564877546676 Test RE 0.13569589491682968\n",
      "49 Train Loss 0.30834842 Test MSE 0.033337998343972615 Test RE 0.13191847958247319\n",
      "50 Train Loss 0.29392612 Test MSE 0.029951086840801822 Test RE 0.125038043646201\n",
      "51 Train Loss 0.28223586 Test MSE 0.029627520963287943 Test RE 0.12436080767011527\n",
      "52 Train Loss 0.27270478 Test MSE 0.029057994778004186 Test RE 0.12315972133546339\n",
      "53 Train Loss 0.258046 Test MSE 0.028662229990533198 Test RE 0.1223181390693256\n",
      "54 Train Loss 0.2477845 Test MSE 0.028479158009164496 Test RE 0.1219268768396903\n",
      "55 Train Loss 0.23859528 Test MSE 0.027518436676203795 Test RE 0.11985268172111503\n",
      "56 Train Loss 0.2314134 Test MSE 0.02742528849412834 Test RE 0.11964966286898623\n",
      "57 Train Loss 0.2233921 Test MSE 0.02773770368473068 Test RE 0.12032922763749607\n",
      "58 Train Loss 0.21660222 Test MSE 0.02708458052340079 Test RE 0.11890412840489407\n",
      "59 Train Loss 0.21242084 Test MSE 0.026626028704213305 Test RE 0.11789328654648835\n",
      "60 Train Loss 0.2065501 Test MSE 0.02624559091271065 Test RE 0.11704801541941716\n",
      "61 Train Loss 0.20213029 Test MSE 0.025513364889251065 Test RE 0.11540370370383123\n",
      "62 Train Loss 0.1981892 Test MSE 0.025029967828718636 Test RE 0.11430520913865895\n",
      "63 Train Loss 0.19135746 Test MSE 0.02467197685355403 Test RE 0.11348484043694516\n",
      "64 Train Loss 0.18440442 Test MSE 0.02469048154657552 Test RE 0.11352739090887172\n",
      "65 Train Loss 0.17868802 Test MSE 0.025070067110403667 Test RE 0.1143967338762639\n",
      "66 Train Loss 0.17457537 Test MSE 0.025715701249234654 Test RE 0.11586041046303198\n",
      "67 Train Loss 0.17067684 Test MSE 0.025201281501578826 Test RE 0.11469571409174682\n",
      "68 Train Loss 0.16506319 Test MSE 0.023920371919459945 Test RE 0.11174287495608529\n",
      "69 Train Loss 0.16008572 Test MSE 0.02387427374734633 Test RE 0.11163515032598278\n",
      "70 Train Loss 0.15584366 Test MSE 0.022672559412271243 Test RE 0.10878929220634738\n",
      "71 Train Loss 0.14811066 Test MSE 0.02075896309715421 Test RE 0.10409711785346294\n",
      "72 Train Loss 0.14305286 Test MSE 0.020860279987748028 Test RE 0.1043508385908128\n",
      "73 Train Loss 0.14073414 Test MSE 0.0206759840732093 Test RE 0.10388885777670875\n",
      "74 Train Loss 0.13905449 Test MSE 0.020603561849127996 Test RE 0.10370675127637735\n",
      "75 Train Loss 0.13615951 Test MSE 0.02036640109082164 Test RE 0.10310815674776122\n",
      "76 Train Loss 0.13262814 Test MSE 0.019876051589607906 Test RE 0.10185935799475648\n",
      "77 Train Loss 0.12774053 Test MSE 0.01924698468406461 Test RE 0.10023449975273752\n",
      "78 Train Loss 0.123018645 Test MSE 0.018695375934790995 Test RE 0.09878772365168256\n",
      "79 Train Loss 0.11970536 Test MSE 0.017929864752843337 Test RE 0.0967440765961804\n",
      "80 Train Loss 0.1171218 Test MSE 0.01693658915354041 Test RE 0.09402619316093419\n",
      "81 Train Loss 0.112997316 Test MSE 0.015518113720182887 Test RE 0.09000265935855496\n",
      "82 Train Loss 0.11033501 Test MSE 0.01522348915153095 Test RE 0.08914417661205941\n",
      "83 Train Loss 0.10827112 Test MSE 0.014495582109305067 Test RE 0.08698687058100592\n",
      "84 Train Loss 0.106441 Test MSE 0.014014403772982893 Test RE 0.08553092913397418\n",
      "85 Train Loss 0.10501957 Test MSE 0.013685608665673456 Test RE 0.08452164396295325\n",
      "86 Train Loss 0.10311904 Test MSE 0.013036882657551194 Test RE 0.08249407461555294\n",
      "87 Train Loss 0.100091904 Test MSE 0.012396012634560737 Test RE 0.08044089277974205\n",
      "88 Train Loss 0.09752166 Test MSE 0.011941825520690699 Test RE 0.0789534728491684\n",
      "89 Train Loss 0.095849454 Test MSE 0.011484570057533519 Test RE 0.07742714534157893\n",
      "90 Train Loss 0.09411268 Test MSE 0.0112126661349276 Test RE 0.07650508858481128\n",
      "91 Train Loss 0.092716694 Test MSE 0.011109143905075928 Test RE 0.07615109861160005\n",
      "92 Train Loss 0.09108992 Test MSE 0.011270634560391846 Test RE 0.07670259568365946\n",
      "93 Train Loss 0.08889853 Test MSE 0.011243577509894156 Test RE 0.07661047163132476\n",
      "94 Train Loss 0.08728796 Test MSE 0.011296956896074708 Test RE 0.07679211211713059\n",
      "95 Train Loss 0.08628343 Test MSE 0.010977043140762791 Test RE 0.07569698159229377\n",
      "96 Train Loss 0.0840428 Test MSE 0.010309921825406024 Test RE 0.07336071627668743\n",
      "97 Train Loss 0.08256473 Test MSE 0.009816764462374486 Test RE 0.07158467578833831\n",
      "98 Train Loss 0.08173066 Test MSE 0.009245836230445066 Test RE 0.0694718677763183\n",
      "99 Train Loss 0.08012311 Test MSE 0.008632878142960668 Test RE 0.06712954170223644\n",
      "100 Train Loss 0.078777656 Test MSE 0.007881670960046811 Test RE 0.0641423735943624\n",
      "101 Train Loss 0.07765433 Test MSE 0.00768400417803002 Test RE 0.06333294350444332\n",
      "102 Train Loss 0.0759677 Test MSE 0.007471343528870755 Test RE 0.0624504007542414\n",
      "103 Train Loss 0.074132375 Test MSE 0.007448258100413407 Test RE 0.062353844516632395\n",
      "104 Train Loss 0.07226763 Test MSE 0.007242290419916652 Test RE 0.06148566082540418\n",
      "105 Train Loss 0.0704341 Test MSE 0.008098492227724149 Test RE 0.06501865207778346\n",
      "106 Train Loss 0.068248585 Test MSE 0.008652803361010195 Test RE 0.06720696662496677\n",
      "107 Train Loss 0.0664985 Test MSE 0.008335905144493951 Test RE 0.06596480135260287\n",
      "108 Train Loss 0.06516947 Test MSE 0.00778414388656016 Test RE 0.06374429238244103\n",
      "109 Train Loss 0.06375066 Test MSE 0.0078051420124223584 Test RE 0.06383021122169685\n",
      "110 Train Loss 0.06282916 Test MSE 0.006974596496505197 Test RE 0.060338626572612894\n",
      "111 Train Loss 0.061721638 Test MSE 0.007144635089292118 Test RE 0.06106971637184193\n",
      "112 Train Loss 0.060172103 Test MSE 0.006445712245192961 Test RE 0.05800578835227021\n",
      "113 Train Loss 0.058590956 Test MSE 0.006655094664715345 Test RE 0.05894038870028879\n",
      "114 Train Loss 0.057588395 Test MSE 0.006487580060868507 Test RE 0.05819387033953305\n",
      "115 Train Loss 0.05621173 Test MSE 0.005831479739341118 Test RE 0.055172830187390866\n",
      "116 Train Loss 0.05520803 Test MSE 0.005607845539375201 Test RE 0.05410456359953832\n",
      "117 Train Loss 0.053930875 Test MSE 0.005609328874405936 Test RE 0.05411171874384099\n",
      "118 Train Loss 0.052401256 Test MSE 0.0050574530991908985 Test RE 0.05138091203033817\n",
      "119 Train Loss 0.051095057 Test MSE 0.004746725444613385 Test RE 0.049777483044415274\n",
      "120 Train Loss 0.04990542 Test MSE 0.004449729555064425 Test RE 0.048195077729927614\n",
      "121 Train Loss 0.048915613 Test MSE 0.004024746893781039 Test RE 0.045835836736028965\n",
      "122 Train Loss 0.04764719 Test MSE 0.003568709682299967 Test RE 0.04316099882185244\n",
      "123 Train Loss 0.046708155 Test MSE 0.0034645280087524555 Test RE 0.04252633100895416\n",
      "124 Train Loss 0.045080952 Test MSE 0.003349866148906033 Test RE 0.041816685256755484\n",
      "125 Train Loss 0.044340845 Test MSE 0.003272916230129562 Test RE 0.04133360851142799\n",
      "126 Train Loss 0.04342102 Test MSE 0.0033000906135865495 Test RE 0.04150484624226502\n",
      "127 Train Loss 0.042163786 Test MSE 0.003287677522333219 Test RE 0.0414267137158885\n",
      "128 Train Loss 0.041457646 Test MSE 0.0032808065245227966 Test RE 0.041383401722325824\n",
      "129 Train Loss 0.04066313 Test MSE 0.0031894843962033586 Test RE 0.040803377921888644\n",
      "130 Train Loss 0.040210903 Test MSE 0.0033040731399987863 Test RE 0.041529882571089846\n",
      "131 Train Loss 0.039552692 Test MSE 0.003246647893689922 Test RE 0.041167403142087014\n",
      "132 Train Loss 0.038735047 Test MSE 0.0030937394621136497 Test RE 0.040186274401843775\n",
      "133 Train Loss 0.03801538 Test MSE 0.002972258790109553 Test RE 0.039389383809373096\n",
      "134 Train Loss 0.0372329 Test MSE 0.002868022918731092 Test RE 0.0386925351368459\n",
      "135 Train Loss 0.03664332 Test MSE 0.0026786287850636826 Test RE 0.03739315783414989\n",
      "136 Train Loss 0.03595198 Test MSE 0.002587895755511213 Test RE 0.03675439395469219\n",
      "137 Train Loss 0.035324305 Test MSE 0.002742505948007497 Test RE 0.037836387616924955\n",
      "138 Train Loss 0.03477789 Test MSE 0.002772371433102451 Test RE 0.03804184611736181\n",
      "139 Train Loss 0.034231987 Test MSE 0.002957301037319877 Test RE 0.03929014618754496\n",
      "140 Train Loss 0.03374306 Test MSE 0.0028297527045344955 Test RE 0.03843351618016002\n",
      "141 Train Loss 0.033177566 Test MSE 0.002707663284421811 Test RE 0.037595269717406954\n",
      "142 Train Loss 0.03237643 Test MSE 0.0024985439126880902 Test RE 0.03611431404156744\n",
      "143 Train Loss 0.031590983 Test MSE 0.0023974069915885183 Test RE 0.035375839973510105\n",
      "144 Train Loss 0.030538654 Test MSE 0.0023393258889864025 Test RE 0.03494469388841343\n",
      "145 Train Loss 0.029835824 Test MSE 0.002321031875078223 Test RE 0.03480778832663647\n",
      "146 Train Loss 0.028981615 Test MSE 0.002148040289876521 Test RE 0.033485523150220325\n",
      "147 Train Loss 0.02868139 Test MSE 0.002018671431422656 Test RE 0.03246150831430993\n",
      "148 Train Loss 0.028301336 Test MSE 0.0019562143097758278 Test RE 0.03195538781869749\n",
      "149 Train Loss 0.027875498 Test MSE 0.0019710552468672833 Test RE 0.03207637451640568\n",
      "150 Train Loss 0.027656265 Test MSE 0.0019753131893718075 Test RE 0.032111002078810964\n",
      "151 Train Loss 0.027282912 Test MSE 0.0018419908590157138 Test RE 0.031008418173536768\n",
      "152 Train Loss 0.026609747 Test MSE 0.0014946612112542517 Test RE 0.02793233608783501\n",
      "153 Train Loss 0.026086824 Test MSE 0.0012770266642145142 Test RE 0.02581878848011334\n",
      "154 Train Loss 0.025590438 Test MSE 0.0013419440440283975 Test RE 0.02646690024236687\n",
      "155 Train Loss 0.025085397 Test MSE 0.0013566430452899353 Test RE 0.026611458231298762\n",
      "156 Train Loss 0.024673363 Test MSE 0.0013632229881659246 Test RE 0.0266759151533664\n",
      "157 Train Loss 0.02425202 Test MSE 0.001143310481336237 Test RE 0.024429690748997722\n",
      "158 Train Loss 0.023938429 Test MSE 0.0011747511267573565 Test RE 0.02476331670574114\n",
      "159 Train Loss 0.023484228 Test MSE 0.0009999734171607358 Test RE 0.02284704854245886\n",
      "160 Train Loss 0.023168897 Test MSE 0.0009460440518467038 Test RE 0.022222430500083178\n",
      "161 Train Loss 0.02272453 Test MSE 0.0009222045558152801 Test RE 0.021940650960322897\n",
      "162 Train Loss 0.022261135 Test MSE 0.000925134579653215 Test RE 0.02197547818390012\n",
      "163 Train Loss 0.021786015 Test MSE 0.0008533428727042796 Test RE 0.021105597893764004\n",
      "164 Train Loss 0.021332633 Test MSE 0.0007696334506429296 Test RE 0.020043697719978326\n",
      "165 Train Loss 0.020996824 Test MSE 0.0007523387423485456 Test RE 0.01981721359221867\n",
      "166 Train Loss 0.020639729 Test MSE 0.0006996964763708237 Test RE 0.019111321581139533\n",
      "167 Train Loss 0.020106485 Test MSE 0.0006804252500706733 Test RE 0.018846299463741074\n",
      "168 Train Loss 0.01975977 Test MSE 0.0006854495892578369 Test RE 0.018915753119720484\n",
      "169 Train Loss 0.019433476 Test MSE 0.00070539827529067 Test RE 0.01918903228893735\n",
      "170 Train Loss 0.019252747 Test MSE 0.0007115092407455993 Test RE 0.019271971703499313\n",
      "171 Train Loss 0.018978104 Test MSE 0.0007145305754801275 Test RE 0.019312846362308345\n",
      "172 Train Loss 0.01872421 Test MSE 0.0006848411816148862 Test RE 0.018907356409131472\n",
      "173 Train Loss 0.018534059 Test MSE 0.0006877063160017266 Test RE 0.018946865989900585\n",
      "174 Train Loss 0.01831054 Test MSE 0.0006186016417129437 Test RE 0.01796972417622701\n",
      "175 Train Loss 0.018155897 Test MSE 0.000583700727478073 Test RE 0.01745544778198529\n",
      "176 Train Loss 0.017834501 Test MSE 0.0006047816674424574 Test RE 0.017767862550789895\n",
      "177 Train Loss 0.017437972 Test MSE 0.000578225102117184 Test RE 0.017373381150463087\n",
      "178 Train Loss 0.01718526 Test MSE 0.0005330574901234925 Test RE 0.016681031479926993\n",
      "179 Train Loss 0.016980877 Test MSE 0.0004931587781365351 Test RE 0.01604461353832048\n",
      "180 Train Loss 0.016811075 Test MSE 0.0004965401068609441 Test RE 0.01609952428712204\n",
      "181 Train Loss 0.01667111 Test MSE 0.0004899378095991331 Test RE 0.01599213160198421\n",
      "182 Train Loss 0.016489595 Test MSE 0.0004659673216872881 Test RE 0.015596013671716315\n",
      "183 Train Loss 0.016377758 Test MSE 0.00043375293778249524 Test RE 0.015047248440146323\n",
      "184 Train Loss 0.016250577 Test MSE 0.00042654809259889335 Test RE 0.014921754106069442\n",
      "185 Train Loss 0.016070751 Test MSE 0.00041195924328818646 Test RE 0.014664356253486732\n",
      "186 Train Loss 0.015923334 Test MSE 0.0004185669226439972 Test RE 0.014781493932846742\n",
      "187 Train Loss 0.015667781 Test MSE 0.0005035191964039148 Test RE 0.01621227243495838\n",
      "188 Train Loss 0.0153772915 Test MSE 0.0005481573938700525 Test RE 0.01691564316515828\n",
      "189 Train Loss 0.015173142 Test MSE 0.0005649623464023213 Test RE 0.017172978605271113\n",
      "190 Train Loss 0.014930201 Test MSE 0.0005867431321332186 Test RE 0.017500879894265384\n",
      "191 Train Loss 0.014686161 Test MSE 0.0005211398393902342 Test RE 0.01649350719631075\n",
      "192 Train Loss 0.0145294275 Test MSE 0.0004875398738475461 Test RE 0.015952947912778896\n",
      "193 Train Loss 0.014368353 Test MSE 0.000501781172308881 Test RE 0.016184267864651367\n",
      "194 Train Loss 0.014239108 Test MSE 0.0005627121223610283 Test RE 0.017138744815318144\n",
      "195 Train Loss 0.014127478 Test MSE 0.0005293659945240722 Test RE 0.016623171929017765\n",
      "196 Train Loss 0.01397798 Test MSE 0.0005722862598831668 Test RE 0.01728393149791886\n",
      "197 Train Loss 0.013882667 Test MSE 0.0005743058491762829 Test RE 0.017314402001570126\n",
      "198 Train Loss 0.013788938 Test MSE 0.0005632823847439666 Test RE 0.017147426969251433\n",
      "199 Train Loss 0.013688083 Test MSE 0.000548927456692188 Test RE 0.016927520717512672\n",
      "200 Train Loss 0.013546829 Test MSE 0.0005232410524102109 Test RE 0.016526724297032107\n",
      "201 Train Loss 0.013374652 Test MSE 0.0005124872715435818 Test RE 0.016356011928666293\n",
      "202 Train Loss 0.013122865 Test MSE 0.0004897855552351337 Test RE 0.015989646530435796\n",
      "203 Train Loss 0.012963817 Test MSE 0.0004758591823816187 Test RE 0.015760685537185976\n",
      "204 Train Loss 0.012885557 Test MSE 0.00047082534409308467 Test RE 0.015677102329437625\n",
      "205 Train Loss 0.0128181605 Test MSE 0.0004776812052572062 Test RE 0.015790829847804676\n",
      "206 Train Loss 0.01274295 Test MSE 0.0004846872631294679 Test RE 0.015906208851402388\n",
      "207 Train Loss 0.012665653 Test MSE 0.0004910549913138579 Test RE 0.016010354265593905\n",
      "208 Train Loss 0.012589757 Test MSE 0.00047970549535314314 Test RE 0.0158242532132067\n",
      "209 Train Loss 0.012483862 Test MSE 0.0004824814788843302 Test RE 0.015869973450901863\n",
      "210 Train Loss 0.012341832 Test MSE 0.0005046116721989236 Test RE 0.016229850631250924\n",
      "211 Train Loss 0.01213524 Test MSE 0.0005678283321709065 Test RE 0.017216481727024738\n",
      "212 Train Loss 0.011998903 Test MSE 0.0006160289789294182 Test RE 0.017932318676874396\n",
      "213 Train Loss 0.011893986 Test MSE 0.0006528723832437653 Test RE 0.018460779116029603\n",
      "214 Train Loss 0.011838432 Test MSE 0.00067646033586652 Test RE 0.01879130948874112\n",
      "215 Train Loss 0.011790627 Test MSE 0.0006836435147051348 Test RE 0.018890816352251216\n",
      "216 Train Loss 0.011750725 Test MSE 0.0006704042415943228 Test RE 0.018707004623587733\n",
      "217 Train Loss 0.01172666 Test MSE 0.0007006423361896298 Test RE 0.019124234699070614\n",
      "218 Train Loss 0.0116942255 Test MSE 0.0007213853067519906 Test RE 0.019405262550229237\n",
      "219 Train Loss 0.011635462 Test MSE 0.0007443253178310484 Test RE 0.019711390993895697\n",
      "220 Train Loss 0.011574486 Test MSE 0.00075548958236051 Test RE 0.019858668076756375\n",
      "221 Train Loss 0.011482096 Test MSE 0.0008549215738682947 Test RE 0.021125111759095257\n",
      "222 Train Loss 0.0114160655 Test MSE 0.0008681571233411262 Test RE 0.02128800891481376\n",
      "223 Train Loss 0.011309798 Test MSE 0.000878525156990341 Test RE 0.021414748485779872\n",
      "224 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "225 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "226 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "227 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "228 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "229 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "230 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "231 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "232 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "233 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "234 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "235 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "236 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "237 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "238 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "239 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "240 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "241 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "242 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "243 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "244 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "245 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "246 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "247 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "248 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "249 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "250 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "251 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "252 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "253 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "254 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "255 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "256 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "257 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "258 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "259 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "260 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "261 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "262 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "263 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "264 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "265 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "266 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "267 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "268 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "269 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "270 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "271 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "272 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "273 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "274 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "275 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "276 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "277 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "278 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "279 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "280 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "281 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "282 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "283 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "284 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "285 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "286 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "287 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "288 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "289 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "290 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "291 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "292 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "293 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "294 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "295 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "296 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "297 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "298 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "299 Train Loss 0.011235805 Test MSE 0.0009786548223333193 Test RE 0.02260219654262691\n",
      "Training time: 393.87\n",
      "KG_rowdy_high\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 66394.914 Test MSE 2.2556557252479577 Test RE 1.0851062987998477\n",
      "1 Train Loss 29966.502 Test MSE 1.657912719575765 Test RE 0.9302864785092974\n",
      "2 Train Loss 5262.6934 Test MSE 1.0947550184660826 Test RE 0.7559522243342903\n",
      "3 Train Loss 1502.9019 Test MSE 2.3973085693582363 Test RE 1.118659321366082\n",
      "4 Train Loss 687.15436 Test MSE 1.8618525403258464 Test RE 0.9858447266829293\n",
      "5 Train Loss 374.86115 Test MSE 1.6800080106387796 Test RE 0.9364650058864022\n",
      "6 Train Loss 278.94113 Test MSE 1.5066602086182495 Test RE 0.8868364527842051\n",
      "7 Train Loss 191.54578 Test MSE 1.0469099151954442 Test RE 0.7392486385778114\n",
      "8 Train Loss 140.07016 Test MSE 1.1951391260974686 Test RE 0.7898508850253692\n",
      "9 Train Loss 107.003876 Test MSE 1.1903897543795976 Test RE 0.7882799257868379\n",
      "10 Train Loss 80.098015 Test MSE 0.7776288103597622 Test RE 0.6371211879086607\n",
      "11 Train Loss 63.898933 Test MSE 0.7163849979382985 Test RE 0.6115178214289425\n",
      "12 Train Loss 51.451958 Test MSE 0.6632163652227528 Test RE 0.5883875761051028\n",
      "13 Train Loss 40.46852 Test MSE 0.5908152408950077 Test RE 0.5553435368932437\n",
      "14 Train Loss 35.2293 Test MSE 0.664289871669198 Test RE 0.5888635764706242\n",
      "15 Train Loss 31.993443 Test MSE 0.8366025623685067 Test RE 0.6608387059569646\n",
      "16 Train Loss 27.35559 Test MSE 0.7414817160750814 Test RE 0.6221370994584662\n",
      "17 Train Loss 23.005625 Test MSE 0.7323060651706371 Test RE 0.6182757208203725\n",
      "18 Train Loss 20.06733 Test MSE 0.5825357603093091 Test RE 0.5514386118654805\n",
      "19 Train Loss 18.087936 Test MSE 0.5414935890360617 Test RE 0.5316582243785649\n",
      "20 Train Loss 16.437986 Test MSE 0.4189658989521033 Test RE 0.467654604510028\n",
      "21 Train Loss 13.990229 Test MSE 0.28974504868168566 Test RE 0.3889053239668678\n",
      "22 Train Loss 12.572008 Test MSE 0.2380545418041979 Test RE 0.35251216817163783\n",
      "23 Train Loss 11.838154 Test MSE 0.3139067711848706 Test RE 0.40479600600891896\n",
      "24 Train Loss 9.838788 Test MSE 0.2404204283763053 Test RE 0.3542595447642083\n",
      "25 Train Loss 9.239977 Test MSE 0.2526226202238198 Test RE 0.36313824853011684\n",
      "26 Train Loss 8.785987 Test MSE 0.21257350380678358 Test RE 0.3331121261176872\n",
      "27 Train Loss 7.934882 Test MSE 0.25140353050026626 Test RE 0.362260984480894\n",
      "28 Train Loss 6.2664027 Test MSE 0.2132387215233161 Test RE 0.33363293184988985\n",
      "29 Train Loss 5.985773 Test MSE 0.23704849544905354 Test RE 0.3517665006779501\n",
      "30 Train Loss 5.3992643 Test MSE 0.1964922613578156 Test RE 0.3202643530460573\n",
      "31 Train Loss 4.363208 Test MSE 0.118452574847763 Test RE 0.24866125984998663\n",
      "32 Train Loss 4.1274934 Test MSE 0.12329426293461714 Test RE 0.2536923148430685\n",
      "33 Train Loss 3.591447 Test MSE 0.1340806375921139 Test RE 0.26455678860635184\n",
      "34 Train Loss 3.3272214 Test MSE 0.13523674702696897 Test RE 0.26569491011454505\n",
      "35 Train Loss 3.1046863 Test MSE 0.14069842094526283 Test RE 0.27100698746917234\n",
      "36 Train Loss 2.8597748 Test MSE 0.1407474621811214 Test RE 0.27105421386866907\n",
      "37 Train Loss 2.6864197 Test MSE 0.1347323011036408 Test RE 0.26519891351667174\n",
      "38 Train Loss 2.4167244 Test MSE 0.12564801961072675 Test RE 0.2561024309411428\n",
      "39 Train Loss 2.2777777 Test MSE 0.12157481074520131 Test RE 0.251917117287737\n",
      "40 Train Loss 2.1785865 Test MSE 0.11899680387419098 Test RE 0.24923184090353098\n",
      "41 Train Loss 1.9855946 Test MSE 0.11564514520493596 Test RE 0.24569684502651515\n",
      "42 Train Loss 1.9208797 Test MSE 0.11358720995901458 Test RE 0.24350091244951527\n",
      "43 Train Loss 1.7504336 Test MSE 0.12112380539557507 Test RE 0.2514494154139646\n",
      "44 Train Loss 1.7281067 Test MSE 0.11964822904663222 Test RE 0.24991309577434948\n",
      "45 Train Loss 1.6213808 Test MSE 0.11729501611942011 Test RE 0.24744327583050807\n",
      "46 Train Loss 1.5169841 Test MSE 0.11978114963626085 Test RE 0.25005187499224224\n",
      "47 Train Loss 1.4740727 Test MSE 0.12683961007911912 Test RE 0.25731394666803653\n",
      "48 Train Loss 1.3731631 Test MSE 0.13729270824093928 Test RE 0.2677069295056945\n",
      "49 Train Loss 1.3358186 Test MSE 0.14033404773745958 Test RE 0.2706558403117328\n",
      "50 Train Loss 1.2872311 Test MSE 0.14358459844859442 Test RE 0.27377248994902137\n",
      "51 Train Loss 1.252671 Test MSE 0.15510961117852706 Test RE 0.28454779954240766\n",
      "52 Train Loss 1.1629413 Test MSE 0.15225600778943857 Test RE 0.2819181884257587\n",
      "53 Train Loss 1.1425608 Test MSE 0.15031188532774178 Test RE 0.2801125311682686\n",
      "54 Train Loss 1.1173682 Test MSE 0.1478844004732603 Test RE 0.2778414644613258\n",
      "55 Train Loss 1.0557215 Test MSE 0.13604819805235124 Test RE 0.2664908327052693\n",
      "56 Train Loss 1.0116082 Test MSE 0.1273652519248475 Test RE 0.2578465686868698\n",
      "57 Train Loss 0.99799395 Test MSE 0.1242717995276433 Test RE 0.25469602702360067\n",
      "58 Train Loss 0.9475564 Test MSE 0.1131440995447745 Test RE 0.2430254926162033\n",
      "59 Train Loss 0.9024979 Test MSE 0.10538058832241096 Test RE 0.23453960333329546\n",
      "60 Train Loss 0.89089555 Test MSE 0.10478909676767986 Test RE 0.23388045247718176\n",
      "61 Train Loss 0.8549067 Test MSE 0.09083852674939875 Test RE 0.21775639491948634\n",
      "62 Train Loss 0.8141015 Test MSE 0.08138741209208437 Test RE 0.20611732452310522\n",
      "63 Train Loss 0.80252326 Test MSE 0.08495420092428532 Test RE 0.21058542352504733\n",
      "64 Train Loss 0.7944007 Test MSE 0.08316316604401801 Test RE 0.20835378014596154\n",
      "65 Train Loss 0.7692332 Test MSE 0.0808295500830549 Test RE 0.20540970439871906\n",
      "66 Train Loss 0.7344413 Test MSE 0.07595504138541959 Test RE 0.1991196770606747\n",
      "67 Train Loss 0.7153077 Test MSE 0.07685433753860725 Test RE 0.20029498180608116\n",
      "68 Train Loss 0.7060091 Test MSE 0.07491264145220541 Test RE 0.19774860672197586\n",
      "69 Train Loss 0.65535915 Test MSE 0.07435666515520763 Test RE 0.19701342847025485\n",
      "70 Train Loss 0.6342946 Test MSE 0.07398840865682454 Test RE 0.1965249616507214\n",
      "71 Train Loss 0.6290696 Test MSE 0.07293398693501496 Test RE 0.1951195808416795\n",
      "72 Train Loss 0.624098 Test MSE 0.07278618337762462 Test RE 0.1949217718693052\n",
      "73 Train Loss 0.59169626 Test MSE 0.07121055268708008 Test RE 0.19280045528843542\n",
      "74 Train Loss 0.5660328 Test MSE 0.07181352901633746 Test RE 0.19361500486740446\n",
      "75 Train Loss 0.5537322 Test MSE 0.07437280160586662 Test RE 0.19703480466432202\n",
      "76 Train Loss 0.5480047 Test MSE 0.07610818488725157 Test RE 0.19932031238922218\n",
      "77 Train Loss 0.5335687 Test MSE 0.07914420023440773 Test RE 0.20325695930631285\n",
      "78 Train Loss 0.49934828 Test MSE 0.08195801987042213 Test RE 0.20683860758257322\n",
      "79 Train Loss 0.4760141 Test MSE 0.08724650893148979 Test RE 0.21340761192422916\n",
      "80 Train Loss 0.46765205 Test MSE 0.08725774580030035 Test RE 0.21342135434303391\n",
      "81 Train Loss 0.4635043 Test MSE 0.08681492628598703 Test RE 0.21287912541490706\n",
      "82 Train Loss 0.459134 Test MSE 0.08452754285206313 Test RE 0.2100559555120798\n",
      "83 Train Loss 0.4477637 Test MSE 0.081884970319921 Test RE 0.20674640894466492\n",
      "84 Train Loss 0.42608485 Test MSE 0.07821711445931101 Test RE 0.20206298854090554\n",
      "85 Train Loss 0.40631443 Test MSE 0.07595860423758477 Test RE 0.19912434709732002\n",
      "86 Train Loss 0.40020552 Test MSE 0.0752858550623184 Test RE 0.19824058496192162\n",
      "87 Train Loss 0.39655507 Test MSE 0.07733346410526074 Test RE 0.20091835288196672\n",
      "88 Train Loss 0.39407343 Test MSE 0.07733841840501256 Test RE 0.2009247886068843\n",
      "89 Train Loss 0.39145863 Test MSE 0.07764161954187633 Test RE 0.20131826078622783\n",
      "90 Train Loss 0.3864928 Test MSE 0.07596600034883716 Test RE 0.19913404125896425\n",
      "91 Train Loss 0.37503612 Test MSE 0.07158404963669607 Test RE 0.19330540998284734\n",
      "92 Train Loss 0.35843334 Test MSE 0.06873287084086152 Test RE 0.18941663578153797\n",
      "93 Train Loss 0.3464905 Test MSE 0.06430277348344385 Test RE 0.18321065588575458\n",
      "94 Train Loss 0.3397039 Test MSE 0.06447136430764697 Test RE 0.18345067209955668\n",
      "95 Train Loss 0.33677638 Test MSE 0.06272792657791917 Test RE 0.1809532314654966\n",
      "96 Train Loss 0.334837 Test MSE 0.06228988274786997 Test RE 0.1803203051238879\n",
      "97 Train Loss 0.33003393 Test MSE 0.06091847224417501 Test RE 0.17832423866453853\n",
      "98 Train Loss 0.32321385 Test MSE 0.05792575356159635 Test RE 0.17388884508149816\n",
      "99 Train Loss 0.3066429 Test MSE 0.047130140099570235 Test RE 0.15685025975959407\n",
      "100 Train Loss 0.2888746 Test MSE 0.03432785668876618 Test RE 0.133862589245354\n",
      "101 Train Loss 0.27427086 Test MSE 0.03141567375568922 Test RE 0.12805869330223674\n",
      "102 Train Loss 0.2662902 Test MSE 0.03057547465440472 Test RE 0.1263346497848644\n",
      "103 Train Loss 0.2621244 Test MSE 0.031111754482460837 Test RE 0.12743775976037827\n",
      "104 Train Loss 0.25873652 Test MSE 0.0302063428791084 Test RE 0.12556972722202206\n",
      "105 Train Loss 0.25634915 Test MSE 0.031232691539775048 Test RE 0.1276852064198382\n",
      "106 Train Loss 0.25314307 Test MSE 0.03142453857365844 Test RE 0.1280767597130076\n",
      "107 Train Loss 0.25096926 Test MSE 0.029459261396078015 Test RE 0.12400717212049134\n",
      "108 Train Loss 0.24846388 Test MSE 0.02959577239006 Test RE 0.1242941578732007\n",
      "109 Train Loss 0.24356382 Test MSE 0.027900723509921534 Test RE 0.12068230863580334\n",
      "110 Train Loss 0.23618434 Test MSE 0.027505252839559624 Test RE 0.1198239681081973\n",
      "111 Train Loss 0.23265067 Test MSE 0.024252505378719647 Test RE 0.11251597339270922\n",
      "112 Train Loss 0.22864072 Test MSE 0.021474105325601466 Test RE 0.10587499829412166\n",
      "113 Train Loss 0.22396162 Test MSE 0.020804065136371182 Test RE 0.10421013999450664\n",
      "114 Train Loss 0.21811445 Test MSE 0.02131011177394154 Test RE 0.10546995014348198\n",
      "115 Train Loss 0.21270864 Test MSE 0.020299017787972093 Test RE 0.10293744606570776\n",
      "116 Train Loss 0.20934391 Test MSE 0.019097404005811943 Test RE 0.09984424671335103\n",
      "117 Train Loss 0.2066211 Test MSE 0.01790933684030378 Test RE 0.09668867956095296\n",
      "118 Train Loss 0.20459865 Test MSE 0.01692925231734129 Test RE 0.09400582514297341\n",
      "119 Train Loss 0.20058246 Test MSE 0.015323902339428343 Test RE 0.08943768813472323\n",
      "120 Train Loss 0.19436052 Test MSE 0.013983069961275298 Test RE 0.0854352593587847\n",
      "121 Train Loss 0.18742931 Test MSE 0.01525389552644766 Test RE 0.08923315749911023\n",
      "122 Train Loss 0.18402024 Test MSE 0.013614796584964414 Test RE 0.0843026944149023\n",
      "123 Train Loss 0.17829478 Test MSE 0.015550946490042038 Test RE 0.09009782154324707\n",
      "124 Train Loss 0.17318928 Test MSE 0.016310822530362982 Test RE 0.09227282309689813\n",
      "125 Train Loss 0.16854686 Test MSE 0.017416897423972934 Test RE 0.09535012658403046\n",
      "126 Train Loss 0.16102734 Test MSE 0.01689317435148558 Test RE 0.09390560371136322\n",
      "127 Train Loss 0.1580722 Test MSE 0.018080884886329255 Test RE 0.09715065153239298\n",
      "128 Train Loss 0.15587795 Test MSE 0.018811455546246518 Test RE 0.0990939356165308\n",
      "129 Train Loss 0.1543707 Test MSE 0.0188647936563224 Test RE 0.09923432193359516\n",
      "130 Train Loss 0.15312533 Test MSE 0.01948566259199019 Test RE 0.10085407858605978\n",
      "131 Train Loss 0.15215224 Test MSE 0.01925509524614964 Test RE 0.10025561663210299\n",
      "132 Train Loss 0.14981733 Test MSE 0.020806672301715415 Test RE 0.10421666959706559\n",
      "133 Train Loss 0.14765725 Test MSE 0.021527217303658773 Test RE 0.1060058479338468\n",
      "134 Train Loss 0.14506075 Test MSE 0.02282613240781622 Test RE 0.10915711352592475\n",
      "135 Train Loss 0.14291683 Test MSE 0.02373408470547603 Test RE 0.111306908580243\n",
      "136 Train Loss 0.13971364 Test MSE 0.02568665721866073 Test RE 0.11579496398824235\n",
      "137 Train Loss 0.13610505 Test MSE 0.02655115075299603 Test RE 0.11772739957047687\n",
      "138 Train Loss 0.13287103 Test MSE 0.026875189020937124 Test RE 0.11844361136273146\n",
      "139 Train Loss 0.13123354 Test MSE 0.025424684560917163 Test RE 0.11520296681878826\n",
      "140 Train Loss 0.12790278 Test MSE 0.02714825624472668 Test RE 0.11904381787387652\n",
      "141 Train Loss 0.1259765 Test MSE 0.024979828887240214 Test RE 0.11419066613958766\n",
      "142 Train Loss 0.1250305 Test MSE 0.023549241881380606 Test RE 0.11087262811723687\n",
      "143 Train Loss 0.12416666 Test MSE 0.023998944892156798 Test RE 0.11192624943829921\n",
      "144 Train Loss 0.1234681 Test MSE 0.02225230172630067 Test RE 0.10777631908203633\n",
      "145 Train Loss 0.12258361 Test MSE 0.022720908803797377 Test RE 0.10890522739438338\n",
      "146 Train Loss 0.121043935 Test MSE 0.021146901677707084 Test RE 0.10506528669197468\n",
      "147 Train Loss 0.11778422 Test MSE 0.019280967893039697 Test RE 0.1003229496518933\n",
      "148 Train Loss 0.113313235 Test MSE 0.018655445716955377 Test RE 0.09868217017547079\n",
      "149 Train Loss 0.11085748 Test MSE 0.017878413169012147 Test RE 0.09660516835209325\n",
      "150 Train Loss 0.10928114 Test MSE 0.01875989090956698 Test RE 0.09895802775977805\n",
      "151 Train Loss 0.10830268 Test MSE 0.018710242539712638 Test RE 0.09882699395610749\n",
      "152 Train Loss 0.107679985 Test MSE 0.019914605989070612 Test RE 0.10195810053931739\n",
      "153 Train Loss 0.10702634 Test MSE 0.02003033563265254 Test RE 0.10225392566313213\n",
      "154 Train Loss 0.10600018 Test MSE 0.020602294105783066 Test RE 0.10370356067352958\n",
      "155 Train Loss 0.10550891 Test MSE 0.02020472521129337 Test RE 0.10269808632952364\n",
      "156 Train Loss 0.10502552 Test MSE 0.020277668411448752 Test RE 0.102883299888218\n",
      "157 Train Loss 0.104650185 Test MSE 0.02042640291546328 Test RE 0.103259929452763\n",
      "158 Train Loss 0.10426596 Test MSE 0.019336751219381963 Test RE 0.10046797105083155\n",
      "159 Train Loss 0.10364901 Test MSE 0.01945279900402781 Test RE 0.10076899486012643\n",
      "160 Train Loss 0.10298523 Test MSE 0.019635450208669677 Test RE 0.1012409725779936\n",
      "161 Train Loss 0.101995826 Test MSE 0.021274442823615642 Test RE 0.1053816451644894\n",
      "162 Train Loss 0.10128814 Test MSE 0.022587118756109782 Test RE 0.10858411461991885\n",
      "163 Train Loss 0.099739365 Test MSE 0.02288367392958498 Test RE 0.10929461191743119\n",
      "164 Train Loss 0.09789799 Test MSE 0.023285361567104014 Test RE 0.11024968818485338\n",
      "165 Train Loss 0.09521942 Test MSE 0.02321153144362794 Test RE 0.11007476690598943\n",
      "166 Train Loss 0.09410166 Test MSE 0.022638983139785258 Test RE 0.10870870817943853\n",
      "167 Train Loss 0.092630185 Test MSE 0.021313743569746975 Test RE 0.10547893716822802\n",
      "168 Train Loss 0.091496445 Test MSE 0.02031422029620501 Test RE 0.10297598523288458\n",
      "169 Train Loss 0.08988917 Test MSE 0.021021083440393048 Test RE 0.10475226564917742\n",
      "170 Train Loss 0.0883465 Test MSE 0.020965482499976037 Test RE 0.10461363861442066\n",
      "171 Train Loss 0.086229935 Test MSE 0.02224466771583465 Test RE 0.10775783029521704\n",
      "172 Train Loss 0.08539157 Test MSE 0.022823396251276943 Test RE 0.10915057102683716\n",
      "173 Train Loss 0.08482392 Test MSE 0.022778203682714947 Test RE 0.10904245304812939\n",
      "174 Train Loss 0.0843938 Test MSE 0.0230383532942818 Test RE 0.10966337152894781\n",
      "175 Train Loss 0.08394439 Test MSE 0.023011886281874706 Test RE 0.10960036147216608\n",
      "176 Train Loss 0.083435945 Test MSE 0.023045591586031894 Test RE 0.10968059743761206\n",
      "177 Train Loss 0.08287533 Test MSE 0.022734483380140832 Test RE 0.10893775517735542\n",
      "178 Train Loss 0.08238742 Test MSE 0.021544235380793236 Test RE 0.10604774046637082\n",
      "179 Train Loss 0.08071356 Test MSE 0.02228759585018698 Test RE 0.10786175661745069\n",
      "180 Train Loss 0.07908556 Test MSE 0.023214270795965917 Test RE 0.11008126205420533\n",
      "181 Train Loss 0.078166015 Test MSE 0.022293231366969556 Test RE 0.10787539241567101\n",
      "182 Train Loss 0.077279404 Test MSE 0.021154054783881382 Test RE 0.10508305477023247\n",
      "183 Train Loss 0.07583505 Test MSE 0.019816576956594473 Test RE 0.10170684816303065\n",
      "184 Train Loss 0.07501822 Test MSE 0.019131898448388057 Test RE 0.09993437723145938\n",
      "185 Train Loss 0.07433088 Test MSE 0.019882938365389582 Test RE 0.1018770028927798\n",
      "186 Train Loss 0.07387208 Test MSE 0.019101190096811726 Test RE 0.09985414336396033\n",
      "187 Train Loss 0.07332614 Test MSE 0.01789553233159436 Test RE 0.09665140858229047\n",
      "188 Train Loss 0.073090866 Test MSE 0.017618335584276605 Test RE 0.09589993567311694\n",
      "189 Train Loss 0.072420806 Test MSE 0.016590209649054513 Test RE 0.09305973553720445\n",
      "190 Train Loss 0.071361676 Test MSE 0.015889564910481966 Test RE 0.09107346908612737\n",
      "191 Train Loss 0.07030706 Test MSE 0.014716290271068548 Test RE 0.08764659517474838\n",
      "192 Train Loss 0.06902007 Test MSE 0.013581984798036233 Test RE 0.08420104799530219\n",
      "193 Train Loss 0.06792154 Test MSE 0.011977069406783752 Test RE 0.07906989462791779\n",
      "194 Train Loss 0.06720299 Test MSE 0.010182767240522295 Test RE 0.07290692565289814\n",
      "195 Train Loss 0.06673802 Test MSE 0.010561345506923408 Test RE 0.07424983658141562\n",
      "196 Train Loss 0.06643872 Test MSE 0.01066647299820522 Test RE 0.07461846246648997\n",
      "197 Train Loss 0.06611198 Test MSE 0.010191119483505146 Test RE 0.07293681986178785\n",
      "198 Train Loss 0.06557848 Test MSE 0.009992058813414063 Test RE 0.0722209784100078\n",
      "199 Train Loss 0.06527743 Test MSE 0.009441351591578443 Test RE 0.07020256209552786\n",
      "200 Train Loss 0.064972654 Test MSE 0.009501938641006378 Test RE 0.07042745384907367\n",
      "201 Train Loss 0.06409901 Test MSE 0.0082182465057407 Test RE 0.06549761088141381\n",
      "202 Train Loss 0.06325469 Test MSE 0.007337290336330927 Test RE 0.06188761254343396\n",
      "203 Train Loss 0.06269834 Test MSE 0.006846718697096684 Test RE 0.05978291940954878\n",
      "204 Train Loss 0.061666116 Test MSE 0.006302087739716057 Test RE 0.05735590008522841\n",
      "205 Train Loss 0.061296955 Test MSE 0.005523410285011749 Test RE 0.05369570255225454\n",
      "206 Train Loss 0.060689483 Test MSE 0.005365849431155277 Test RE 0.05292429942845463\n",
      "207 Train Loss 0.06020137 Test MSE 0.005498631587599978 Test RE 0.05357512440750244\n",
      "208 Train Loss 0.059675056 Test MSE 0.004878083374176022 Test RE 0.05046153837280522\n",
      "209 Train Loss 0.059311315 Test MSE 0.004954488211394926 Test RE 0.05085518945834474\n",
      "210 Train Loss 0.058744155 Test MSE 0.005168386346430799 Test RE 0.051941365431646055\n",
      "211 Train Loss 0.05844469 Test MSE 0.004837267331210692 Test RE 0.05024998327522136\n",
      "212 Train Loss 0.057992224 Test MSE 0.004824904936432269 Test RE 0.05018573134368242\n",
      "213 Train Loss 0.057575855 Test MSE 0.004735944985424448 Test RE 0.0497209251958696\n",
      "214 Train Loss 0.05742581 Test MSE 0.004779509414934949 Test RE 0.04994908507702405\n",
      "215 Train Loss 0.057259355 Test MSE 0.004758483950594687 Test RE 0.04983909886862759\n",
      "216 Train Loss 0.0570336 Test MSE 0.004705563338487146 Test RE 0.04956118579046229\n",
      "217 Train Loss 0.056835245 Test MSE 0.004664002139797902 Test RE 0.049341829402227415\n",
      "218 Train Loss 0.056404565 Test MSE 0.005112610089074486 Test RE 0.0516603344231403\n",
      "219 Train Loss 0.055745672 Test MSE 0.005471778289769121 Test RE 0.053444143677683256\n",
      "220 Train Loss 0.05539158 Test MSE 0.005141873921306828 Test RE 0.05180797155970053\n",
      "221 Train Loss 0.055115204 Test MSE 0.004363234901397348 Test RE 0.04772436671287436\n",
      "222 Train Loss 0.05471093 Test MSE 0.004302911335470267 Test RE 0.04739331372716535\n",
      "223 Train Loss 0.054484636 Test MSE 0.004261244187495587 Test RE 0.04716328945437363\n",
      "224 Train Loss 0.054130785 Test MSE 0.004802700965864857 Test RE 0.05007012207377764\n",
      "225 Train Loss 0.053835217 Test MSE 0.004593174156617818 Test RE 0.04896574123871593\n",
      "226 Train Loss 0.053490054 Test MSE 0.004632771024926773 Test RE 0.049176350411996216\n",
      "227 Train Loss 0.05330099 Test MSE 0.004746940958537367 Test RE 0.04977861304646172\n",
      "228 Train Loss 0.053164463 Test MSE 0.00459207485372231 Test RE 0.04895988130390797\n",
      "229 Train Loss 0.053042695 Test MSE 0.004658574800024683 Test RE 0.04931311234588139\n",
      "230 Train Loss 0.052870885 Test MSE 0.004742764092409983 Test RE 0.04975670795411853\n",
      "231 Train Loss 0.05272902 Test MSE 0.004618151070817271 Test RE 0.049098694502184896\n",
      "232 Train Loss 0.052399956 Test MSE 0.004645168907244726 Test RE 0.04924210752041573\n",
      "233 Train Loss 0.052077085 Test MSE 0.004622649383173155 Test RE 0.049122600986016014\n",
      "234 Train Loss 0.05188171 Test MSE 0.0047567167967292575 Test RE 0.04982984365881925\n",
      "235 Train Loss 0.051656727 Test MSE 0.004714094171648342 Test RE 0.049606090802359934\n",
      "236 Train Loss 0.05149827 Test MSE 0.004769129032770372 Test RE 0.04989481460969849\n",
      "237 Train Loss 0.05122598 Test MSE 0.004622852174290112 Test RE 0.04912367845448125\n",
      "238 Train Loss 0.050771527 Test MSE 0.004753994306561946 Test RE 0.049815581649741744\n",
      "239 Train Loss 0.050569773 Test MSE 0.004586997274692127 Test RE 0.04893280569725645\n",
      "240 Train Loss 0.050199058 Test MSE 0.004754173659368293 Test RE 0.049816521331147126\n",
      "241 Train Loss 0.049822718 Test MSE 0.00474063310987405 Test RE 0.04974552854623218\n",
      "242 Train Loss 0.04949286 Test MSE 0.004660396173860025 Test RE 0.04932275143498985\n",
      "243 Train Loss 0.04881531 Test MSE 0.004701289949359229 Test RE 0.04953867601589091\n",
      "244 Train Loss 0.04825752 Test MSE 0.0049132636996045385 Test RE 0.05064317365364559\n",
      "245 Train Loss 0.048010617 Test MSE 0.004838830053457199 Test RE 0.050258099471847055\n",
      "246 Train Loss 0.04761185 Test MSE 0.004760597042531256 Test RE 0.04985016362264535\n",
      "247 Train Loss 0.047322936 Test MSE 0.005068751229619404 Test RE 0.051438271375877836\n",
      "248 Train Loss 0.046595473 Test MSE 0.0061715725249197285 Test RE 0.056758877158102745\n",
      "249 Train Loss 0.046034414 Test MSE 0.0066834780686783396 Test RE 0.05906594280700982\n",
      "250 Train Loss 0.045825966 Test MSE 0.006613273051507936 Test RE 0.05875490171188222\n",
      "251 Train Loss 0.04552196 Test MSE 0.005940633291491709 Test RE 0.05568679833864514\n",
      "252 Train Loss 0.045183934 Test MSE 0.006150037989125472 Test RE 0.05665976593835637\n",
      "253 Train Loss 0.04482513 Test MSE 0.006513025234323429 Test RE 0.05830788080432789\n",
      "254 Train Loss 0.044545904 Test MSE 0.006116686450819215 Test RE 0.056505924672137796\n",
      "255 Train Loss 0.044142876 Test MSE 0.0067943924774248226 Test RE 0.05955403502529039\n",
      "256 Train Loss 0.043852773 Test MSE 0.0070470853322577125 Test RE 0.06065137375122314\n",
      "257 Train Loss 0.043566026 Test MSE 0.007496290931585566 Test RE 0.06255457725928616\n",
      "258 Train Loss 0.043260664 Test MSE 0.007411897894207946 Test RE 0.06220146174891536\n",
      "259 Train Loss 0.043031007 Test MSE 0.00744045399416743 Test RE 0.0623211695237774\n",
      "260 Train Loss 0.042865213 Test MSE 0.007472545454528538 Test RE 0.062455423794620706\n",
      "261 Train Loss 0.042639602 Test MSE 0.007583162585658647 Test RE 0.06291599375449428\n",
      "262 Train Loss 0.042490788 Test MSE 0.00790019928352198 Test RE 0.06421772265526061\n",
      "263 Train Loss 0.042126115 Test MSE 0.007868296940021755 Test RE 0.06408793046868809\n",
      "264 Train Loss 0.041844018 Test MSE 0.007955805537637426 Test RE 0.06444332743794164\n",
      "265 Train Loss 0.041519508 Test MSE 0.008134794091945095 Test RE 0.06516421368903956\n",
      "266 Train Loss 0.04139407 Test MSE 0.008393766558410204 Test RE 0.06619334379331912\n",
      "267 Train Loss 0.041237067 Test MSE 0.008576206990074563 Test RE 0.06690884053805803\n",
      "268 Train Loss 0.040987406 Test MSE 0.00904180575317821 Test RE 0.06870106401258202\n",
      "269 Train Loss 0.04037928 Test MSE 0.008583380634363902 Test RE 0.06693681793490822\n",
      "270 Train Loss 0.03996741 Test MSE 0.008489226310048725 Test RE 0.06656867804311925\n",
      "271 Train Loss 0.03969995 Test MSE 0.007730928889242016 Test RE 0.06352603011943614\n",
      "272 Train Loss 0.038940936 Test MSE 0.008587930424641467 Test RE 0.0669545561751851\n",
      "273 Train Loss 0.0382875 Test MSE 0.008241187775386329 Test RE 0.06558896559954003\n",
      "274 Train Loss 0.037902877 Test MSE 0.008694364116231777 Test RE 0.06736817601536219\n",
      "275 Train Loss 0.03739783 Test MSE 0.008571870769261353 Test RE 0.06689192349128388\n",
      "276 Train Loss 0.03695996 Test MSE 0.008555730645693482 Test RE 0.06682891783948436\n",
      "277 Train Loss 0.036528755 Test MSE 0.008932034932848016 Test RE 0.06828276256289642\n",
      "278 Train Loss 0.036337942 Test MSE 0.009127161590232987 Test RE 0.06902457585328609\n",
      "279 Train Loss 0.03607908 Test MSE 0.009222353236876231 Test RE 0.06938358778834784\n",
      "280 Train Loss 0.03559489 Test MSE 0.009810555961764802 Test RE 0.07156203575269149\n",
      "281 Train Loss 0.035233594 Test MSE 0.009949092116096096 Test RE 0.07206553296759419\n",
      "282 Train Loss 0.03506017 Test MSE 0.010161787503301855 Test RE 0.07283178120702222\n",
      "283 Train Loss 0.034918003 Test MSE 0.009940638695787294 Test RE 0.07203491059058434\n",
      "284 Train Loss 0.034833208 Test MSE 0.009539620902771407 Test RE 0.07056696431727554\n",
      "285 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "286 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "287 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "288 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "289 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "290 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "291 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "292 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "293 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "294 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "295 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "296 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "297 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "298 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "299 Train Loss 0.03476914 Test MSE 0.009558730913953522 Test RE 0.07063760972401587\n",
      "Training time: 472.15\n",
      "KG_rowdy_high\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 56201.39 Test MSE 2.809203966523745 Test RE 1.210953629928238\n",
      "1 Train Loss 8952.232 Test MSE 5.595972346485722 Test RE 1.7091243306904906\n",
      "2 Train Loss 1299.3087 Test MSE 4.141523373771468 Test RE 1.4703337809513672\n",
      "3 Train Loss 580.28754 Test MSE 4.600634278666229 Test RE 1.5496896495690944\n",
      "4 Train Loss 293.045 Test MSE 3.2473326230191404 Test RE 1.3019648655790903\n",
      "5 Train Loss 182.88153 Test MSE 3.4446933184879662 Test RE 1.340945595818833\n",
      "6 Train Loss 137.3335 Test MSE 3.1413807537035434 Test RE 1.280548896424241\n",
      "7 Train Loss 98.1481 Test MSE 3.2941791882246894 Test RE 1.3113224197992004\n",
      "8 Train Loss 76.448875 Test MSE 3.610575401783277 Test RE 1.3728531559531305\n",
      "9 Train Loss 66.046906 Test MSE 3.719117790066379 Test RE 1.3933359529112455\n",
      "10 Train Loss 53.61515 Test MSE 4.114411556148542 Test RE 1.4655132267735134\n",
      "11 Train Loss 44.867603 Test MSE 3.8043960881961505 Test RE 1.4092198116350827\n",
      "12 Train Loss 34.538223 Test MSE 3.3293390154542077 Test RE 1.3183019272308387\n",
      "13 Train Loss 26.837797 Test MSE 3.0200934022830213 Test RE 1.2555848423545188\n",
      "14 Train Loss 23.06932 Test MSE 2.869395837405672 Test RE 1.2238582192918461\n",
      "15 Train Loss 20.357979 Test MSE 2.7599029391405523 Test RE 1.2002805852899545\n",
      "16 Train Loss 16.992989 Test MSE 2.7674202324079067 Test RE 1.2019141075014177\n",
      "17 Train Loss 14.23332 Test MSE 2.6640682138215337 Test RE 1.179257229246919\n",
      "18 Train Loss 12.487032 Test MSE 2.481682387425271 Test RE 1.1381748271493373\n",
      "19 Train Loss 11.31118 Test MSE 2.2424521772965647 Test RE 1.0819257866482712\n",
      "20 Train Loss 9.546172 Test MSE 2.117333021280724 Test RE 1.0513091934688543\n",
      "21 Train Loss 8.228448 Test MSE 1.8631652205826204 Test RE 0.9861921953635799\n",
      "22 Train Loss 7.2975745 Test MSE 1.7495787013708035 Test RE 0.9556582613065022\n",
      "23 Train Loss 6.5295486 Test MSE 1.5769265485974113 Test RE 0.9072805680125925\n",
      "24 Train Loss 5.75491 Test MSE 1.425701427759079 Test RE 0.8626808730152111\n",
      "25 Train Loss 5.1768923 Test MSE 1.3395870453438905 Test RE 0.8362215325992353\n",
      "26 Train Loss 4.7685027 Test MSE 1.2580899401317371 Test RE 0.8103856120023751\n",
      "27 Train Loss 4.160451 Test MSE 1.160149400577387 Test RE 0.7782028856608662\n",
      "28 Train Loss 3.783 Test MSE 1.0718135567813782 Test RE 0.7479894972435975\n",
      "29 Train Loss 3.5593326 Test MSE 1.0276276506404385 Test RE 0.7324091606150185\n",
      "30 Train Loss 3.033338 Test MSE 0.7892634733628604 Test RE 0.641869706140679\n",
      "31 Train Loss 2.7289371 Test MSE 0.7527095038045993 Test RE 0.6268297157897617\n",
      "32 Train Loss 2.5363352 Test MSE 0.6708520236224038 Test RE 0.5917649574609664\n",
      "33 Train Loss 2.195161 Test MSE 0.5772270189342723 Test RE 0.5489201869828478\n",
      "34 Train Loss 2.0299795 Test MSE 0.5718468921852353 Test RE 0.5463560537103008\n",
      "35 Train Loss 1.8420682 Test MSE 0.47110218032358475 Test RE 0.4958992300620872\n",
      "36 Train Loss 1.7059416 Test MSE 0.4071551219674609 Test RE 0.4610158194436714\n",
      "37 Train Loss 1.6149913 Test MSE 0.40350731385961797 Test RE 0.4589459929675508\n",
      "38 Train Loss 1.4962878 Test MSE 0.3961573279515408 Test RE 0.4547468754891089\n",
      "39 Train Loss 1.3253437 Test MSE 0.2901949536003711 Test RE 0.38920714542992124\n",
      "40 Train Loss 1.2253121 Test MSE 0.2680665151542027 Test RE 0.3740736878173578\n",
      "41 Train Loss 1.0956128 Test MSE 0.2305400836537175 Test RE 0.34690383430773103\n",
      "42 Train Loss 1.0519965 Test MSE 0.22046755021180794 Test RE 0.33924090652197003\n",
      "43 Train Loss 0.91476554 Test MSE 0.18038674889266873 Test RE 0.3068585245881899\n",
      "44 Train Loss 0.85853064 Test MSE 0.14567209605965534 Test RE 0.27575542269222986\n",
      "45 Train Loss 0.7711771 Test MSE 0.11814214318664028 Test RE 0.24833520965899838\n",
      "46 Train Loss 0.68442523 Test MSE 0.08843165207985973 Test RE 0.21485217088122752\n",
      "47 Train Loss 0.6452999 Test MSE 0.06633585491658033 Test RE 0.18608443243508246\n",
      "48 Train Loss 0.59552336 Test MSE 0.06289143567923534 Test RE 0.18118891791307085\n",
      "49 Train Loss 0.57324713 Test MSE 0.06482424175351646 Test RE 0.18395203627857204\n",
      "50 Train Loss 0.54978734 Test MSE 0.0621606457950069 Test RE 0.1801331467450808\n",
      "51 Train Loss 0.49546182 Test MSE 0.06835660739190282 Test RE 0.18889746378596803\n",
      "52 Train Loss 0.4845581 Test MSE 0.06350256215650947 Test RE 0.18206711101789944\n",
      "53 Train Loss 0.4706953 Test MSE 0.06362925790282803 Test RE 0.1822486441224041\n",
      "54 Train Loss 0.44741166 Test MSE 0.053285188341367515 Test RE 0.1667781413203435\n",
      "55 Train Loss 0.4189117 Test MSE 0.04256397656565679 Test RE 0.1490585782746309\n",
      "56 Train Loss 0.3717825 Test MSE 0.02727071058944526 Test RE 0.11931199405771255\n",
      "57 Train Loss 0.33622807 Test MSE 0.027172491675678638 Test RE 0.11909694162899713\n",
      "58 Train Loss 0.30990076 Test MSE 0.030291229440249947 Test RE 0.12574604290849858\n",
      "59 Train Loss 0.28174913 Test MSE 0.0333485253127725 Test RE 0.13193930554952535\n",
      "60 Train Loss 0.27354276 Test MSE 0.03221046529384498 Test RE 0.12966846689951322\n",
      "61 Train Loss 0.2660775 Test MSE 0.02993939758505471 Test RE 0.1250136414548262\n",
      "62 Train Loss 0.2556002 Test MSE 0.026127965563762876 Test RE 0.11678543275870228\n",
      "63 Train Loss 0.24378072 Test MSE 0.021107895430788767 Test RE 0.10496834355239737\n",
      "64 Train Loss 0.23414327 Test MSE 0.01933988719941092 Test RE 0.1004761175273031\n",
      "65 Train Loss 0.22827941 Test MSE 0.017925636675123983 Test RE 0.0967326692153261\n",
      "66 Train Loss 0.21713725 Test MSE 0.01699073422886049 Test RE 0.09417637076812425\n",
      "67 Train Loss 0.20718886 Test MSE 0.014926456036027632 Test RE 0.08827022426047537\n",
      "68 Train Loss 0.19718906 Test MSE 0.016338135614791797 Test RE 0.09235004793396343\n",
      "69 Train Loss 0.19282532 Test MSE 0.015713577518213805 Test RE 0.0905677154842788\n",
      "70 Train Loss 0.18801801 Test MSE 0.01568470315162092 Test RE 0.0904844662097895\n",
      "71 Train Loss 0.18139145 Test MSE 0.016090017019791323 Test RE 0.0916461296171185\n",
      "72 Train Loss 0.17706162 Test MSE 0.01402018922586633 Test RE 0.08554858183292008\n",
      "73 Train Loss 0.16699767 Test MSE 0.010810640447866962 Test RE 0.07512103943853128\n",
      "74 Train Loss 0.15877019 Test MSE 0.01058774895241113 Test RE 0.07434259122875678\n",
      "75 Train Loss 0.15217355 Test MSE 0.009377269442200385 Test RE 0.06996391031425454\n",
      "76 Train Loss 0.14729959 Test MSE 0.008747964371783217 Test RE 0.06757551741286494\n",
      "77 Train Loss 0.14426608 Test MSE 0.008752178588186998 Test RE 0.06759179225996874\n",
      "78 Train Loss 0.1419489 Test MSE 0.008458455564195683 Test RE 0.06644792337472213\n",
      "79 Train Loss 0.1375907 Test MSE 0.006715369997065684 Test RE 0.05920669923450343\n",
      "80 Train Loss 0.13185136 Test MSE 0.005340359936778652 Test RE 0.0527984461476627\n",
      "81 Train Loss 0.12562118 Test MSE 0.0048015030934564365 Test RE 0.0500638775294617\n",
      "82 Train Loss 0.11848906 Test MSE 0.004398467375295234 Test RE 0.0479166628897248\n",
      "83 Train Loss 0.11420354 Test MSE 0.004418325086046917 Test RE 0.048024705489504695\n",
      "84 Train Loss 0.10813698 Test MSE 0.00452950015204297 Test RE 0.048625156955452234\n",
      "85 Train Loss 0.10556433 Test MSE 0.004774845864116701 Test RE 0.04992471050986232\n",
      "86 Train Loss 0.10214659 Test MSE 0.004879397047296118 Test RE 0.05046833258880009\n",
      "87 Train Loss 0.09857562 Test MSE 0.004597955556360987 Test RE 0.048991220773839654\n",
      "88 Train Loss 0.096402735 Test MSE 0.004838316392670033 Test RE 0.05025543185386972\n",
      "89 Train Loss 0.09348695 Test MSE 0.005320040382343922 Test RE 0.05269790392078822\n",
      "90 Train Loss 0.09159017 Test MSE 0.005165662997359296 Test RE 0.051927679041087846\n",
      "91 Train Loss 0.08822062 Test MSE 0.0048422073895382604 Test RE 0.05027563562038594\n",
      "92 Train Loss 0.08577702 Test MSE 0.005015036952437606 Test RE 0.05116499612720004\n",
      "93 Train Loss 0.08460114 Test MSE 0.00444058667708873 Test RE 0.048145538955807726\n",
      "94 Train Loss 0.082014926 Test MSE 0.004238120373268473 Test RE 0.04703514862702697\n",
      "95 Train Loss 0.07823753 Test MSE 0.0033699152611190155 Test RE 0.041941636026497975\n",
      "96 Train Loss 0.07349305 Test MSE 0.002763061410999049 Test RE 0.03797791740581\n",
      "97 Train Loss 0.07145595 Test MSE 0.002687257783400634 Test RE 0.03745333900888182\n",
      "98 Train Loss 0.06867675 Test MSE 0.00271636079107565 Test RE 0.03765560272620223\n",
      "99 Train Loss 0.067791924 Test MSE 0.002781012257660134 Test RE 0.038101083704097184\n",
      "100 Train Loss 0.067100756 Test MSE 0.0028255476223912183 Test RE 0.03840494898798825\n",
      "101 Train Loss 0.06642642 Test MSE 0.0027574569498969087 Test RE 0.03793938156271864\n",
      "102 Train Loss 0.065538466 Test MSE 0.0025376209409461743 Test RE 0.036395630866787224\n",
      "103 Train Loss 0.06447998 Test MSE 0.0023832799732794257 Test RE 0.035271457710672006\n",
      "104 Train Loss 0.06250592 Test MSE 0.002249866024405999 Test RE 0.03427000798295006\n",
      "105 Train Loss 0.06011992 Test MSE 0.0022012312088665865 Test RE 0.03389758103940615\n",
      "106 Train Loss 0.058746543 Test MSE 0.0022853474262570827 Test RE 0.034539177643074855\n",
      "107 Train Loss 0.05600863 Test MSE 0.0028246614874007565 Test RE 0.03839892632578101\n",
      "108 Train Loss 0.054853067 Test MSE 0.0032296318073064176 Test RE 0.04105937966883113\n",
      "109 Train Loss 0.054207414 Test MSE 0.0037522900113537198 Test RE 0.04425721440689248\n",
      "110 Train Loss 0.05347381 Test MSE 0.004073269586608729 Test RE 0.04611130932749768\n",
      "111 Train Loss 0.052992065 Test MSE 0.004028380421273337 Test RE 0.04585652228533545\n",
      "112 Train Loss 0.05247722 Test MSE 0.004253587336269517 Test RE 0.04712089753289766\n",
      "113 Train Loss 0.051184908 Test MSE 0.004411582599303126 Test RE 0.0479880479821472\n",
      "114 Train Loss 0.049753338 Test MSE 0.004030237015974161 Test RE 0.04586708821508589\n",
      "115 Train Loss 0.04846167 Test MSE 0.004140871271055609 Test RE 0.046492376028857724\n",
      "116 Train Loss 0.046852227 Test MSE 0.003828581637270697 Test RE 0.04470486965065312\n",
      "117 Train Loss 0.046033055 Test MSE 0.003134729520574658 Test RE 0.04045161952803262\n",
      "118 Train Loss 0.045331303 Test MSE 0.002919194782878353 Test RE 0.03903618917532631\n",
      "119 Train Loss 0.04454688 Test MSE 0.0025853155947506133 Test RE 0.03673606711640087\n",
      "120 Train Loss 0.044154555 Test MSE 0.0023685411730954187 Test RE 0.03516222480420718\n",
      "121 Train Loss 0.043593984 Test MSE 0.002099970941736924 Test RE 0.033108729795152295\n",
      "122 Train Loss 0.043206424 Test MSE 0.0020914087131945216 Test RE 0.03304116360658259\n",
      "123 Train Loss 0.04274098 Test MSE 0.0020122689079400155 Test RE 0.03240998912614173\n",
      "124 Train Loss 0.04189388 Test MSE 0.001644670196799835 Test RE 0.02930051732136487\n",
      "125 Train Loss 0.04073624 Test MSE 0.0014918131100797127 Test RE 0.027905710638306137\n",
      "126 Train Loss 0.0398602 Test MSE 0.0014597296390652696 Test RE 0.02760400453060337\n",
      "127 Train Loss 0.039460782 Test MSE 0.0014921687237198981 Test RE 0.027909036477164032\n",
      "128 Train Loss 0.03899849 Test MSE 0.0014192426245221 Test RE 0.02721850076081571\n",
      "129 Train Loss 0.038661215 Test MSE 0.0014477729002851914 Test RE 0.027490718988538772\n",
      "130 Train Loss 0.038253255 Test MSE 0.001472273794754625 Test RE 0.02772235802117293\n",
      "131 Train Loss 0.03780399 Test MSE 0.0014918383217009264 Test RE 0.027905946440374467\n",
      "132 Train Loss 0.037505776 Test MSE 0.0015420479437374382 Test RE 0.02837166447215296\n",
      "133 Train Loss 0.03686297 Test MSE 0.0016415154865238553 Test RE 0.02927240256270062\n",
      "134 Train Loss 0.035810616 Test MSE 0.0017317610937944605 Test RE 0.030066291664617\n",
      "135 Train Loss 0.034776922 Test MSE 0.0018281228917867082 Test RE 0.030891469662068703\n",
      "136 Train Loss 0.033833534 Test MSE 0.0017183974061164614 Test RE 0.02995005892153059\n",
      "137 Train Loss 0.03349966 Test MSE 0.0016816857757294367 Test RE 0.029628407030238176\n",
      "138 Train Loss 0.03339765 Test MSE 0.0016579384596266454 Test RE 0.029418469852160664\n",
      "139 Train Loss 0.033213098 Test MSE 0.0016054199227307118 Test RE 0.028948775677518822\n",
      "140 Train Loss 0.03311751 Test MSE 0.0016263844793890018 Test RE 0.029137178026032336\n",
      "141 Train Loss 0.032888822 Test MSE 0.0017338032103402252 Test RE 0.030084013734353855\n",
      "142 Train Loss 0.032720804 Test MSE 0.0017678648298598443 Test RE 0.030378085834458207\n",
      "143 Train Loss 0.032628432 Test MSE 0.0017352700952811624 Test RE 0.030096737340004995\n",
      "144 Train Loss 0.032498743 Test MSE 0.0017575550837990947 Test RE 0.030289377610352056\n",
      "145 Train Loss 0.032295458 Test MSE 0.0017731437656312544 Test RE 0.030423407293967773\n",
      "146 Train Loss 0.03193756 Test MSE 0.00173815307045075 Test RE 0.03012172830177567\n",
      "147 Train Loss 0.031553373 Test MSE 0.001680681721177833 Test RE 0.029619560853666453\n",
      "148 Train Loss 0.03124816 Test MSE 0.001766063007538956 Test RE 0.030362601090904197\n",
      "149 Train Loss 0.030818725 Test MSE 0.0017945980240458015 Test RE 0.03060690880374926\n",
      "150 Train Loss 0.030204847 Test MSE 0.0018398667874478995 Test RE 0.030990534507704653\n",
      "151 Train Loss 0.029874226 Test MSE 0.0016970000667741474 Test RE 0.02976300700698871\n",
      "152 Train Loss 0.029519886 Test MSE 0.0017935049549696158 Test RE 0.03059758622538635\n",
      "153 Train Loss 0.029028747 Test MSE 0.0016166226006111425 Test RE 0.02904960288752345\n",
      "154 Train Loss 0.028711485 Test MSE 0.0016275903612983777 Test RE 0.029147977897108032\n",
      "155 Train Loss 0.028398916 Test MSE 0.0017288593605902238 Test RE 0.030041091614100644\n",
      "156 Train Loss 0.028075755 Test MSE 0.0017241334556434215 Test RE 0.03000000426466153\n",
      "157 Train Loss 0.027580766 Test MSE 0.0019587148422814346 Test RE 0.03197580479629162\n",
      "158 Train Loss 0.027089966 Test MSE 0.0019597947299150216 Test RE 0.03198461810525122\n",
      "159 Train Loss 0.026878502 Test MSE 0.0018177147836327288 Test RE 0.030803406463875964\n",
      "160 Train Loss 0.026638899 Test MSE 0.0017412533240310224 Test RE 0.030148579616886852\n",
      "161 Train Loss 0.026382338 Test MSE 0.0016765258747325938 Test RE 0.029582917825525672\n",
      "162 Train Loss 0.026126988 Test MSE 0.0016217413188644068 Test RE 0.02909555647425242\n",
      "163 Train Loss 0.025992034 Test MSE 0.0016170879132491702 Test RE 0.029053783261726945\n",
      "164 Train Loss 0.025809772 Test MSE 0.0015203499082606553 Test RE 0.028171349591048646\n",
      "165 Train Loss 0.02563854 Test MSE 0.0015806852497223577 Test RE 0.028724903424228322\n",
      "166 Train Loss 0.02537173 Test MSE 0.0014968741794531043 Test RE 0.027953006493944638\n",
      "167 Train Loss 0.025183605 Test MSE 0.0013631037189008194 Test RE 0.026674748181265195\n",
      "168 Train Loss 0.024900934 Test MSE 0.0012534172202775802 Test RE 0.025579008451300535\n",
      "169 Train Loss 0.024518907 Test MSE 0.001152767456180699 Test RE 0.024530518648775743\n",
      "170 Train Loss 0.024258865 Test MSE 0.001104535002178546 Test RE 0.02401184981789061\n",
      "171 Train Loss 0.02393565 Test MSE 0.001067194453320391 Test RE 0.023602480993230573\n",
      "172 Train Loss 0.02374415 Test MSE 0.0010832115283775443 Test RE 0.023778941235796245\n",
      "173 Train Loss 0.023572389 Test MSE 0.0010333047200746604 Test RE 0.023224698433613127\n",
      "174 Train Loss 0.023311343 Test MSE 0.0010136447238184728 Test RE 0.023002697009916633\n",
      "175 Train Loss 0.023126166 Test MSE 0.0010490992282793474 Test RE 0.023401525043473606\n",
      "176 Train Loss 0.022901041 Test MSE 0.00105052930781509 Test RE 0.023417469505220632\n",
      "177 Train Loss 0.022722106 Test MSE 0.0010506791205867356 Test RE 0.023419139192548545\n",
      "178 Train Loss 0.022589264 Test MSE 0.0010734119116942564 Test RE 0.02367113498871976\n",
      "179 Train Loss 0.022495717 Test MSE 0.0011234676858796083 Test RE 0.024216767353054638\n",
      "180 Train Loss 0.022320654 Test MSE 0.0011337541311768813 Test RE 0.024327378834178216\n",
      "181 Train Loss 0.022123652 Test MSE 0.0012027057657899133 Test RE 0.025056221141073465\n",
      "182 Train Loss 0.02195011 Test MSE 0.0012067268707610969 Test RE 0.025098072450102565\n",
      "183 Train Loss 0.021831324 Test MSE 0.001284198797904768 Test RE 0.02589118968200598\n",
      "184 Train Loss 0.021689977 Test MSE 0.001274752950286396 Test RE 0.02579579338752912\n",
      "185 Train Loss 0.021606643 Test MSE 0.0012359865421759874 Test RE 0.02540052820666685\n",
      "186 Train Loss 0.021546459 Test MSE 0.0012706090406181577 Test RE 0.025753831354099248\n",
      "187 Train Loss 0.021480529 Test MSE 0.0012990085762237793 Test RE 0.026040054333601417\n",
      "188 Train Loss 0.02141808 Test MSE 0.0013328392919372569 Test RE 0.026376961806847468\n",
      "189 Train Loss 0.021347933 Test MSE 0.0013402374897956467 Test RE 0.02645006587069866\n",
      "190 Train Loss 0.02128089 Test MSE 0.0013746782421007917 Test RE 0.026787760433549565\n",
      "191 Train Loss 0.021199495 Test MSE 0.0013230449796410595 Test RE 0.02627986812022973\n",
      "192 Train Loss 0.02113305 Test MSE 0.0013408399247908107 Test RE 0.02645600983779423\n",
      "193 Train Loss 0.021036988 Test MSE 0.0014664707762700826 Test RE 0.02766766975878161\n",
      "194 Train Loss 0.020914681 Test MSE 0.001493319984597474 Test RE 0.027919800805029996\n",
      "195 Train Loss 0.020775318 Test MSE 0.0015031578775369636 Test RE 0.028011616731225885\n",
      "196 Train Loss 0.020647733 Test MSE 0.001489713390491581 Test RE 0.02788606514815569\n",
      "197 Train Loss 0.020320058 Test MSE 0.0016165965586406026 Test RE 0.029049368908377997\n",
      "198 Train Loss 0.020009276 Test MSE 0.001562568606264835 Test RE 0.028559817254495058\n",
      "199 Train Loss 0.01973459 Test MSE 0.001480505858719411 Test RE 0.027799753308611563\n",
      "200 Train Loss 0.01937908 Test MSE 0.0011970418232758128 Test RE 0.024997152465089656\n",
      "201 Train Loss 0.019106507 Test MSE 0.0011801341159030224 Test RE 0.024819987564371836\n",
      "202 Train Loss 0.018840728 Test MSE 0.001129682648313558 Test RE 0.024283657895094117\n",
      "203 Train Loss 0.018506924 Test MSE 0.0009860794066564398 Test RE 0.0226877705544243\n",
      "204 Train Loss 0.017895408 Test MSE 0.0009323420210381601 Test RE 0.02206091422968595\n",
      "205 Train Loss 0.017636139 Test MSE 0.0008570016558552207 Test RE 0.021150795558526902\n",
      "206 Train Loss 0.01737822 Test MSE 0.0008052681010718162 Test RE 0.020502467153644947\n",
      "207 Train Loss 0.017259791 Test MSE 0.0007954446301625929 Test RE 0.020377028556765354\n",
      "208 Train Loss 0.017069183 Test MSE 0.0007571902284774116 Test RE 0.0198810069567044\n",
      "209 Train Loss 0.016921125 Test MSE 0.0007584448726446045 Test RE 0.01989747129044329\n",
      "210 Train Loss 0.01679855 Test MSE 0.0007527738244049142 Test RE 0.01982294297139393\n",
      "211 Train Loss 0.016651692 Test MSE 0.0007544905895370534 Test RE 0.019845534057491853\n",
      "212 Train Loss 0.016504295 Test MSE 0.0007421628876589978 Test RE 0.019682737185499892\n",
      "213 Train Loss 0.016349863 Test MSE 0.000711281551466986 Test RE 0.019268887855679102\n",
      "214 Train Loss 0.01612632 Test MSE 0.000708205486873344 Test RE 0.019227176830006833\n",
      "215 Train Loss 0.015883515 Test MSE 0.000659236021225438 Test RE 0.01855053083241168\n",
      "216 Train Loss 0.015675439 Test MSE 0.000625558506438879 Test RE 0.018070486457631728\n",
      "217 Train Loss 0.01530878 Test MSE 0.0005828380683824645 Test RE 0.017442544193001206\n",
      "218 Train Loss 0.015128125 Test MSE 0.0005867937027444893 Test RE 0.017501634066812523\n",
      "219 Train Loss 0.01499271 Test MSE 0.0005887812099301717 Test RE 0.017531248579251976\n",
      "220 Train Loss 0.014919477 Test MSE 0.0005876221758671386 Test RE 0.017513984675799746\n",
      "221 Train Loss 0.014835309 Test MSE 0.0005870761855048173 Test RE 0.017505846207315535\n",
      "222 Train Loss 0.014755933 Test MSE 0.0005858717565642215 Test RE 0.017487879737591805\n",
      "223 Train Loss 0.014703225 Test MSE 0.0005858645486185918 Test RE 0.017487772161084988\n",
      "224 Train Loss 0.014665399 Test MSE 0.0005916351311972536 Test RE 0.017573685667482488\n",
      "225 Train Loss 0.014614036 Test MSE 0.0005919247058238066 Test RE 0.017577985843943603\n",
      "226 Train Loss 0.014474461 Test MSE 0.0005748518747445508 Test RE 0.01732263094450428\n",
      "227 Train Loss 0.014356092 Test MSE 0.000581099782036675 Test RE 0.01741651399789829\n",
      "228 Train Loss 0.014241582 Test MSE 0.0005779583425680351 Test RE 0.017369373152580053\n",
      "229 Train Loss 0.014172692 Test MSE 0.0005939470773203236 Test RE 0.01760798873498798\n",
      "230 Train Loss 0.014115524 Test MSE 0.0005898334626919595 Test RE 0.017546907256582773\n",
      "231 Train Loss 0.014004423 Test MSE 0.0005770693452675351 Test RE 0.017356009500637055\n",
      "232 Train Loss 0.013909602 Test MSE 0.0006335106390927298 Test RE 0.018184980231385102\n",
      "233 Train Loss 0.013762603 Test MSE 0.0006651592466961194 Test RE 0.01863368258731569\n",
      "234 Train Loss 0.013664511 Test MSE 0.0007018778284391634 Test RE 0.019141088831015122\n",
      "235 Train Loss 0.013597662 Test MSE 0.0007123473091878321 Test RE 0.01928331834325363\n",
      "236 Train Loss 0.01352898 Test MSE 0.0007671808031972574 Test RE 0.020011734873217606\n",
      "237 Train Loss 0.013431357 Test MSE 0.0007832120676776457 Test RE 0.020219739780616752\n",
      "238 Train Loss 0.013356339 Test MSE 0.0008561432543564895 Test RE 0.021140200232868115\n",
      "239 Train Loss 0.013268183 Test MSE 0.000872573616884228 Test RE 0.02134208845981041\n",
      "240 Train Loss 0.013128576 Test MSE 0.001013629063082015 Test RE 0.023002519314241486\n",
      "241 Train Loss 0.013030366 Test MSE 0.001004271540328939 Test RE 0.02289609691316407\n",
      "242 Train Loss 0.0129329115 Test MSE 0.0009395020696651943 Test RE 0.022145462126520885\n",
      "243 Train Loss 0.012877613 Test MSE 0.0009410667789088757 Test RE 0.02216389571746652\n",
      "244 Train Loss 0.012816219 Test MSE 0.0009687781909956613 Test RE 0.022487856103793297\n",
      "245 Train Loss 0.012747732 Test MSE 0.001099525092097933 Test RE 0.023957331885730453\n",
      "246 Train Loss 0.012684734 Test MSE 0.0011776323042787698 Test RE 0.024793665184206445\n",
      "247 Train Loss 0.012661318 Test MSE 0.0012004377567657804 Test RE 0.025032585039306107\n",
      "248 Train Loss 0.0126570705 Test MSE 0.0012133325048043864 Test RE 0.025166672239531306\n",
      "249 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "250 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "251 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "252 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "253 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "254 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "255 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "256 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "257 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "258 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "259 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "260 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "261 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "262 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "263 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "264 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "265 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "266 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "267 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "268 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "269 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "270 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "271 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "272 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "273 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "274 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "275 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "276 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "277 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "278 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "279 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "280 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "281 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "282 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "283 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "284 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "285 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "286 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "287 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "288 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "289 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "290 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "291 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "292 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "293 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "294 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "295 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "296 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "297 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "298 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "299 Train Loss 0.012656797 Test MSE 0.0012133456926547662 Test RE 0.02516680900888551\n",
      "Training time: 429.75\n",
      "KG_rowdy_high\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 51208.59 Test MSE 2.972970892622297 Test RE 1.24575088820531\n",
      "1 Train Loss 9429.6 Test MSE 6.953619108813473 Test RE 1.9052033037859994\n",
      "2 Train Loss 1445.578 Test MSE 5.7437127353446 Test RE 1.7315388193318157\n",
      "3 Train Loss 478.92038 Test MSE 5.947441619660043 Test RE 1.7619799847751763\n",
      "4 Train Loss 212.55534 Test MSE 4.336921719216048 Test RE 1.5046194394222971\n",
      "5 Train Loss 124.633255 Test MSE 3.6739644909579776 Test RE 1.384851973193444\n",
      "6 Train Loss 99.3895 Test MSE 3.478710714688288 Test RE 1.3475504528230793\n",
      "7 Train Loss 73.26054 Test MSE 2.691776459637845 Test RE 1.1853739320161194\n",
      "8 Train Loss 58.304665 Test MSE 2.1760353431517125 Test RE 1.0657831489289429\n",
      "9 Train Loss 46.232765 Test MSE 2.0549476291521387 Test RE 1.035705436787816\n",
      "10 Train Loss 41.15614 Test MSE 1.9035054522345647 Test RE 0.9968112698827157\n",
      "11 Train Loss 35.00045 Test MSE 1.3765169427223805 Test RE 0.8476696960101768\n",
      "12 Train Loss 30.14616 Test MSE 1.0586117084040827 Test RE 0.7433686187123723\n",
      "13 Train Loss 25.666246 Test MSE 0.8829845893412513 Test RE 0.6789103645553097\n",
      "14 Train Loss 20.49982 Test MSE 0.9842356069335103 Test RE 0.7167792313557189\n",
      "15 Train Loss 17.609089 Test MSE 0.8547287337434063 Test RE 0.6679593430734841\n",
      "16 Train Loss 14.816444 Test MSE 0.7818615349022368 Test RE 0.6388527973302796\n",
      "17 Train Loss 12.732521 Test MSE 0.6603350363316081 Test RE 0.5871080664595901\n",
      "18 Train Loss 11.248963 Test MSE 0.6492297965861726 Test RE 0.5821502639863411\n",
      "19 Train Loss 9.4446535 Test MSE 0.5991500602314093 Test RE 0.5592470225161054\n",
      "20 Train Loss 8.077497 Test MSE 0.6899391355023221 Test RE 0.6001243754217507\n",
      "21 Train Loss 6.4150863 Test MSE 0.7531304637255986 Test RE 0.6270049715183277\n",
      "22 Train Loss 5.320679 Test MSE 0.7577766944626254 Test RE 0.6289360649052445\n",
      "23 Train Loss 4.7521944 Test MSE 0.751003476624578 Test RE 0.6261189534300081\n",
      "24 Train Loss 4.21377 Test MSE 0.7440919109980748 Test RE 0.6232311739607704\n",
      "25 Train Loss 3.545052 Test MSE 0.6926005816939066 Test RE 0.6012807537985296\n",
      "26 Train Loss 2.8743675 Test MSE 0.5269275287177995 Test RE 0.5244587325661195\n",
      "27 Train Loss 2.3759456 Test MSE 0.48291408047385315 Test RE 0.5020775597578797\n",
      "28 Train Loss 1.9636251 Test MSE 0.4074391815170511 Test RE 0.46117660965107105\n",
      "29 Train Loss 1.7976081 Test MSE 0.393496870276396 Test RE 0.45321734064463304\n",
      "30 Train Loss 1.6415769 Test MSE 0.3566927240028317 Test RE 0.4315021879150155\n",
      "31 Train Loss 1.5573165 Test MSE 0.36490674333505063 Test RE 0.43644228554951564\n",
      "32 Train Loss 1.4002109 Test MSE 0.34548700649958664 Test RE 0.42467015057837554\n",
      "33 Train Loss 1.3036065 Test MSE 0.31572694000395934 Test RE 0.40596790186017023\n",
      "34 Train Loss 1.1738929 Test MSE 0.30964539388299217 Test RE 0.40203900447930147\n",
      "35 Train Loss 1.1275907 Test MSE 0.3102379772205798 Test RE 0.40242352132524317\n",
      "36 Train Loss 0.9878924 Test MSE 0.28318132527279816 Test RE 0.38447506749143245\n",
      "37 Train Loss 0.8654041 Test MSE 0.2554432026880746 Test RE 0.3651598770843795\n",
      "38 Train Loss 0.8362068 Test MSE 0.2468974878116918 Test RE 0.3589998047622315\n",
      "39 Train Loss 0.80924255 Test MSE 0.2401403792846419 Test RE 0.3540531584517706\n",
      "40 Train Loss 0.7905069 Test MSE 0.23375037871109045 Test RE 0.349310820192646\n",
      "41 Train Loss 0.7622395 Test MSE 0.23228164407164403 Test RE 0.34821167041585005\n",
      "42 Train Loss 0.7056968 Test MSE 0.2143544461924421 Test RE 0.33450462353964433\n",
      "43 Train Loss 0.6853846 Test MSE 0.2102847590641689 Test RE 0.3313139906042905\n",
      "44 Train Loss 0.6643861 Test MSE 0.20261870440991986 Test RE 0.32521880067979103\n",
      "45 Train Loss 0.6115229 Test MSE 0.17495033425561882 Test RE 0.3021991685939662\n",
      "46 Train Loss 0.5729856 Test MSE 0.15601590830766415 Test RE 0.28537788752520393\n",
      "47 Train Loss 0.56100076 Test MSE 0.1619416786766963 Test RE 0.29074696856491605\n",
      "48 Train Loss 0.54416454 Test MSE 0.15020321692875838 Test RE 0.2800112587912397\n",
      "49 Train Loss 0.50296164 Test MSE 0.135366197835128 Test RE 0.26582204343742716\n",
      "50 Train Loss 0.47697827 Test MSE 0.1099114439601622 Test RE 0.23952857655457196\n",
      "51 Train Loss 0.45322412 Test MSE 0.10429012944028183 Test RE 0.23332296148448445\n",
      "52 Train Loss 0.4442137 Test MSE 0.10202585688254662 Test RE 0.2307761917457743\n",
      "53 Train Loss 0.43196326 Test MSE 0.08773022022202696 Test RE 0.21399838048000827\n",
      "54 Train Loss 0.41071838 Test MSE 0.07009153785190006 Test RE 0.19127960720671605\n",
      "55 Train Loss 0.39036494 Test MSE 0.061666459585732206 Test RE 0.1794156754915579\n",
      "56 Train Loss 0.3828204 Test MSE 0.06210882143832294 Test RE 0.18005804109837442\n",
      "57 Train Loss 0.37724364 Test MSE 0.05725692677576564 Test RE 0.1728820460778691\n",
      "58 Train Loss 0.37375385 Test MSE 0.05210966683486303 Test RE 0.16492824023984937\n",
      "59 Train Loss 0.36547026 Test MSE 0.045052436324514375 Test RE 0.15335396797112014\n",
      "60 Train Loss 0.35413298 Test MSE 0.03823531759697573 Test RE 0.14127594723790793\n",
      "61 Train Loss 0.33647463 Test MSE 0.030506728889100367 Test RE 0.12619254472204056\n",
      "62 Train Loss 0.308658 Test MSE 0.024592212914294496 Test RE 0.11330124497457934\n",
      "63 Train Loss 0.29811215 Test MSE 0.023463867907712516 Test RE 0.11067147023067207\n",
      "64 Train Loss 0.28904104 Test MSE 0.023022173412460815 Test RE 0.10962485636232744\n",
      "65 Train Loss 0.28060314 Test MSE 0.025118861851936805 Test RE 0.11450800692525503\n",
      "66 Train Loss 0.25838998 Test MSE 0.02494038210757208 Test RE 0.11410046868927559\n",
      "67 Train Loss 0.24284875 Test MSE 0.01979379328626734 Test RE 0.10164836375020707\n",
      "68 Train Loss 0.23460397 Test MSE 0.0179215517372273 Test RE 0.0967216467487935\n",
      "69 Train Loss 0.22902475 Test MSE 0.017337365787037602 Test RE 0.0951321764995621\n",
      "70 Train Loss 0.22668469 Test MSE 0.01698351959675323 Test RE 0.0941563739863046\n",
      "71 Train Loss 0.22398894 Test MSE 0.015866555520716967 Test RE 0.09100750428032038\n",
      "72 Train Loss 0.22137214 Test MSE 0.015346399803088669 Test RE 0.08950331708231277\n",
      "73 Train Loss 0.21752176 Test MSE 0.015253952722096223 Test RE 0.08923332479222966\n",
      "74 Train Loss 0.21047087 Test MSE 0.014748401669431022 Test RE 0.08774216685235885\n",
      "75 Train Loss 0.20536329 Test MSE 0.01447046117456688 Test RE 0.08691146350037456\n",
      "76 Train Loss 0.20119728 Test MSE 0.014370665187517558 Test RE 0.08661125118889317\n",
      "77 Train Loss 0.19752766 Test MSE 0.01407996927634403 Test RE 0.0857307711959103\n",
      "78 Train Loss 0.19576396 Test MSE 0.013961873308611745 Test RE 0.08537048001004642\n",
      "79 Train Loss 0.1909716 Test MSE 0.013894257477412972 Test RE 0.08516350915508031\n",
      "80 Train Loss 0.18467736 Test MSE 0.01350933231014798 Test RE 0.08397554272289622\n",
      "81 Train Loss 0.1818893 Test MSE 0.014040689222518866 Test RE 0.08561110256675707\n",
      "82 Train Loss 0.18035121 Test MSE 0.014383851883144234 Test RE 0.08665097984124205\n",
      "83 Train Loss 0.17905056 Test MSE 0.015050654129509367 Test RE 0.08863669715478713\n",
      "84 Train Loss 0.17704414 Test MSE 0.015059421456638055 Test RE 0.08866250977978957\n",
      "85 Train Loss 0.17412104 Test MSE 0.01470995508333211 Test RE 0.08762772773616574\n",
      "86 Train Loss 0.17065516 Test MSE 0.014043000172392666 Test RE 0.08561814762072446\n",
      "87 Train Loss 0.16813739 Test MSE 0.0136187041965579 Test RE 0.0843147914943685\n",
      "88 Train Loss 0.16438569 Test MSE 0.01405439989457857 Test RE 0.08565289180245675\n",
      "89 Train Loss 0.16166866 Test MSE 0.014206306941393972 Test RE 0.08611453757023581\n",
      "90 Train Loss 0.159187 Test MSE 0.014202976798218168 Test RE 0.08610444379468057\n",
      "91 Train Loss 0.15683521 Test MSE 0.014173331872284077 Test RE 0.08601453682538791\n",
      "92 Train Loss 0.1558126 Test MSE 0.013442916652246674 Test RE 0.08376886475494509\n",
      "93 Train Loss 0.15502816 Test MSE 0.013243584421872822 Test RE 0.08314548080565974\n",
      "94 Train Loss 0.15382834 Test MSE 0.013151947451025315 Test RE 0.08285732521543537\n",
      "95 Train Loss 0.15170196 Test MSE 0.013004945737208526 Test RE 0.08239296830582148\n",
      "96 Train Loss 0.14637077 Test MSE 0.012749446579837188 Test RE 0.08157959476476356\n",
      "97 Train Loss 0.14204916 Test MSE 0.012864685022275973 Test RE 0.08194745220068568\n",
      "98 Train Loss 0.13864125 Test MSE 0.013022565014139596 Test RE 0.08244876297004493\n",
      "99 Train Loss 0.1366898 Test MSE 0.013218911614766416 Test RE 0.08306799465499394\n",
      "100 Train Loss 0.13541226 Test MSE 0.013810144821877892 Test RE 0.08490533763530154\n",
      "101 Train Loss 0.13466571 Test MSE 0.014066282174118414 Test RE 0.08568909173230149\n",
      "102 Train Loss 0.13418318 Test MSE 0.014191049019121642 Test RE 0.08606828058333042\n",
      "103 Train Loss 0.13297352 Test MSE 0.014216337359760326 Test RE 0.08614493295837171\n",
      "104 Train Loss 0.13103959 Test MSE 0.014625265827731403 Test RE 0.08737511516135237\n",
      "105 Train Loss 0.1283684 Test MSE 0.014276183346660901 Test RE 0.08632606309531284\n",
      "106 Train Loss 0.12454965 Test MSE 0.014397723442966685 Test RE 0.08669275219145442\n",
      "107 Train Loss 0.11993545 Test MSE 0.014902671254898817 Test RE 0.08819986847772351\n",
      "108 Train Loss 0.117253594 Test MSE 0.015661498339955518 Test RE 0.0904175075894899\n",
      "109 Train Loss 0.11593968 Test MSE 0.015630059789578037 Test RE 0.09032671093388835\n",
      "110 Train Loss 0.11531909 Test MSE 0.015909943863427003 Test RE 0.09113185291354768\n",
      "111 Train Loss 0.11370849 Test MSE 0.015965045145618556 Test RE 0.09128952605638196\n",
      "112 Train Loss 0.11297252 Test MSE 0.01580564034428271 Test RE 0.09083263742540441\n",
      "113 Train Loss 0.11192504 Test MSE 0.015925141387629207 Test RE 0.09117536808775573\n",
      "114 Train Loss 0.10981601 Test MSE 0.015810820516502386 Test RE 0.09084752104125592\n",
      "115 Train Loss 0.10836179 Test MSE 0.01627707882813386 Test RE 0.09217732703315998\n",
      "116 Train Loss 0.10492933 Test MSE 0.016165461350560545 Test RE 0.09186073768417595\n",
      "117 Train Loss 0.10331615 Test MSE 0.015993971526232886 Test RE 0.09137219041791086\n",
      "118 Train Loss 0.101956226 Test MSE 0.01609364713509704 Test RE 0.0916564673083396\n",
      "119 Train Loss 0.098868944 Test MSE 0.016005681771559917 Test RE 0.0914056341120867\n",
      "120 Train Loss 0.09767954 Test MSE 0.016655890317078682 Test RE 0.09324376539858462\n",
      "121 Train Loss 0.09660201 Test MSE 0.016576065054452378 Test RE 0.09302005632446889\n",
      "122 Train Loss 0.095729366 Test MSE 0.016644822424041562 Test RE 0.09321277985824486\n",
      "123 Train Loss 0.09531482 Test MSE 0.016577784450560656 Test RE 0.09302488057482684\n",
      "124 Train Loss 0.09457881 Test MSE 0.017395201846031993 Test RE 0.09529072103457234\n",
      "125 Train Loss 0.092906475 Test MSE 0.017291076243394838 Test RE 0.09500509351698663\n",
      "126 Train Loss 0.091052935 Test MSE 0.016958138049495513 Test RE 0.09408599022395489\n",
      "127 Train Loss 0.08850187 Test MSE 0.017166629416575447 Test RE 0.0946625922076949\n",
      "128 Train Loss 0.08617032 Test MSE 0.016224156026428228 Test RE 0.09202735374291994\n",
      "129 Train Loss 0.0837688 Test MSE 0.015965920768111933 Test RE 0.09129202946510051\n",
      "130 Train Loss 0.0815346 Test MSE 0.01673608598230781 Test RE 0.09346797335729887\n",
      "131 Train Loss 0.08055114 Test MSE 0.016319417350642358 Test RE 0.09229713100296566\n",
      "132 Train Loss 0.07983505 Test MSE 0.01598295079069336 Test RE 0.09134070473368891\n",
      "133 Train Loss 0.07924599 Test MSE 0.015256492587449917 Test RE 0.08924075339780904\n",
      "134 Train Loss 0.078851484 Test MSE 0.015073846147534707 Test RE 0.08870496237970665\n",
      "135 Train Loss 0.0785758 Test MSE 0.015023969524653725 Test RE 0.08855808646677958\n",
      "136 Train Loss 0.07833785 Test MSE 0.015153413976346381 Test RE 0.08893877038190845\n",
      "137 Train Loss 0.07801728 Test MSE 0.015078002010144897 Test RE 0.088717189525568\n",
      "138 Train Loss 0.07769799 Test MSE 0.01532415037602384 Test RE 0.08943841196242115\n",
      "139 Train Loss 0.07719611 Test MSE 0.015844013332419745 Test RE 0.09094283247816637\n",
      "140 Train Loss 0.07658437 Test MSE 0.016447554805550223 Test RE 0.09265877365625044\n",
      "141 Train Loss 0.07608554 Test MSE 0.01736908532060439 Test RE 0.09521916114812357\n",
      "142 Train Loss 0.07547134 Test MSE 0.017740042062605845 Test RE 0.09623060130107959\n",
      "143 Train Loss 0.074795924 Test MSE 0.01771135604936714 Test RE 0.09615276639145988\n",
      "144 Train Loss 0.074068174 Test MSE 0.017563263361522898 Test RE 0.09574993409415933\n",
      "145 Train Loss 0.072881036 Test MSE 0.017360446042631133 Test RE 0.09519547748534139\n",
      "146 Train Loss 0.07153867 Test MSE 0.016769401525415988 Test RE 0.093560957707311\n",
      "147 Train Loss 0.0694659 Test MSE 0.016400888806168145 Test RE 0.0925272317409632\n",
      "148 Train Loss 0.06851719 Test MSE 0.015808192458845724 Test RE 0.09083997043864378\n",
      "149 Train Loss 0.06773703 Test MSE 0.015763639316299805 Test RE 0.09071187034729382\n",
      "150 Train Loss 0.06708184 Test MSE 0.015088144898780298 Test RE 0.08874702429057485\n",
      "151 Train Loss 0.06614379 Test MSE 0.01631035963822319 Test RE 0.0922715137617162\n",
      "152 Train Loss 0.06547037 Test MSE 0.01706477940662194 Test RE 0.09438135676692185\n",
      "153 Train Loss 0.06511122 Test MSE 0.017635330495054675 Test RE 0.09594617778256716\n",
      "154 Train Loss 0.06459644 Test MSE 0.017264390348110028 Test RE 0.09493175294238261\n",
      "155 Train Loss 0.06444957 Test MSE 0.017078504914229874 Test RE 0.0944193054452903\n",
      "156 Train Loss 0.06403892 Test MSE 0.017389234821960232 Test RE 0.09527437598721128\n",
      "157 Train Loss 0.06386643 Test MSE 0.017206146926586386 Test RE 0.09477148602357162\n",
      "158 Train Loss 0.06356738 Test MSE 0.016660346852754523 Test RE 0.09325623895498332\n",
      "159 Train Loss 0.06298797 Test MSE 0.016449885614406787 Test RE 0.09266533883393226\n",
      "160 Train Loss 0.06252758 Test MSE 0.016076354186411693 Test RE 0.09160721071090985\n",
      "161 Train Loss 0.061379008 Test MSE 0.014829994853976285 Test RE 0.08798454187495472\n",
      "162 Train Loss 0.060606528 Test MSE 0.013918088237740326 Test RE 0.08523651203753647\n",
      "163 Train Loss 0.059780728 Test MSE 0.013094490980395418 Test RE 0.08267613910801896\n",
      "164 Train Loss 0.058880232 Test MSE 0.012678165320336884 Test RE 0.08135122222413632\n",
      "165 Train Loss 0.057147168 Test MSE 0.012095012328915297 Test RE 0.07945825708594503\n",
      "166 Train Loss 0.05548593 Test MSE 0.011380931866503331 Test RE 0.07707699750392644\n",
      "167 Train Loss 0.05497688 Test MSE 0.010947861221449928 Test RE 0.07559629631424498\n",
      "168 Train Loss 0.054381475 Test MSE 0.010424519307631754 Test RE 0.0737673013647268\n",
      "169 Train Loss 0.054023165 Test MSE 0.01044292752003568 Test RE 0.07383240389682488\n",
      "170 Train Loss 0.05364379 Test MSE 0.009863486503517552 Test RE 0.07175482411266391\n",
      "171 Train Loss 0.053301696 Test MSE 0.009649285255954524 Test RE 0.07097141262638647\n",
      "172 Train Loss 0.05312583 Test MSE 0.009529238658667007 Test RE 0.0705285538340653\n",
      "173 Train Loss 0.05265683 Test MSE 0.00915493992911878 Test RE 0.069129533532246\n",
      "174 Train Loss 0.05219285 Test MSE 0.008944382663514282 Test RE 0.06832994363521788\n",
      "175 Train Loss 0.051842954 Test MSE 0.008850628401966576 Test RE 0.06797088591239293\n",
      "176 Train Loss 0.051506348 Test MSE 0.008468196784777393 Test RE 0.06648617489825527\n",
      "177 Train Loss 0.050888382 Test MSE 0.008384130510462188 Test RE 0.06615533788761871\n",
      "178 Train Loss 0.050576594 Test MSE 0.008343481391123219 Test RE 0.06599477122938482\n",
      "179 Train Loss 0.050358288 Test MSE 0.008496998271977857 Test RE 0.0665991431793211\n",
      "180 Train Loss 0.050031416 Test MSE 0.008498002061413422 Test RE 0.0666030768944961\n",
      "181 Train Loss 0.049538117 Test MSE 0.00826743343393626 Test RE 0.06569332296084589\n",
      "182 Train Loss 0.048931587 Test MSE 0.008105082395132596 Test RE 0.06504510123988287\n",
      "183 Train Loss 0.048287217 Test MSE 0.008160551435320589 Test RE 0.06526729745956993\n",
      "184 Train Loss 0.04788269 Test MSE 0.008022788270447606 Test RE 0.06471404436829316\n",
      "185 Train Loss 0.047601137 Test MSE 0.007991164492737103 Test RE 0.06458637533562218\n",
      "186 Train Loss 0.047459316 Test MSE 0.007856735331066468 Test RE 0.06404082802793236\n",
      "187 Train Loss 0.047117982 Test MSE 0.007782315244456746 Test RE 0.06373680457483728\n",
      "188 Train Loss 0.04689891 Test MSE 0.007775196048455196 Test RE 0.0637076449603602\n",
      "189 Train Loss 0.046539195 Test MSE 0.007680427672556058 Test RE 0.0633182026885061\n",
      "190 Train Loss 0.04623012 Test MSE 0.0076251233505012445 Test RE 0.0630898236837489\n",
      "191 Train Loss 0.046031397 Test MSE 0.0074866549683409245 Test RE 0.06251435954073073\n",
      "192 Train Loss 0.04587345 Test MSE 0.007417186785170151 Test RE 0.06222365026848943\n",
      "193 Train Loss 0.04563953 Test MSE 0.007516739448666694 Test RE 0.06263983790485343\n",
      "194 Train Loss 0.04536362 Test MSE 0.007544409236906336 Test RE 0.06275502341490848\n",
      "195 Train Loss 0.045172162 Test MSE 0.007594110392909439 Test RE 0.06296139326570871\n",
      "196 Train Loss 0.044990502 Test MSE 0.007636772123691562 Test RE 0.06313799592610175\n",
      "197 Train Loss 0.044892617 Test MSE 0.007610105540648688 Test RE 0.06302766482367847\n",
      "198 Train Loss 0.04471904 Test MSE 0.007551714353370606 Test RE 0.06278539834692816\n",
      "199 Train Loss 0.044386253 Test MSE 0.007493421039358099 Test RE 0.06254260186489459\n",
      "200 Train Loss 0.044206306 Test MSE 0.007410209998356263 Test RE 0.062194378841898934\n",
      "201 Train Loss 0.04385313 Test MSE 0.007215296869211111 Test RE 0.06137096881332973\n",
      "202 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "203 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "204 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "205 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "206 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "207 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "208 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "209 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "210 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "211 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "212 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "213 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "214 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "215 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "216 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "217 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "218 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "219 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "220 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "221 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "222 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "223 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "224 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "225 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "226 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "227 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "228 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "229 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "230 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "231 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "232 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "233 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "234 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "235 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "236 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "237 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "238 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "239 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "240 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "241 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "242 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "243 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "244 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "245 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "246 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "247 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "248 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "249 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "250 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "251 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "252 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "253 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "254 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "255 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "256 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "257 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "258 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "259 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "260 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "261 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "262 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "263 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "264 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "265 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "266 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "267 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "268 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "269 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "270 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "271 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "272 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "273 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "274 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "275 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "276 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "277 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "278 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "279 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "280 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "281 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "282 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "283 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "284 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "285 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "286 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "287 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "288 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "289 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "290 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "291 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "292 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "293 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "294 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "295 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "296 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "297 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "298 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "299 Train Loss 0.043786004 Test MSE 0.007205529237171652 Test RE 0.061329414594284155\n",
      "Training time: 381.70\n",
      "KG_rowdy_high\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 63205.203 Test MSE 3.316905367531619 Test RE 1.3158379795523503\n",
      "1 Train Loss 8985.769 Test MSE 4.227739118230931 Test RE 1.4855592131012194\n",
      "2 Train Loss 958.03986 Test MSE 3.510104261125107 Test RE 1.3536172654558767\n",
      "3 Train Loss 218.57486 Test MSE 2.994162327973458 Test RE 1.2501828812523712\n",
      "4 Train Loss 80.564354 Test MSE 2.6311490102263253 Test RE 1.171948692974327\n",
      "5 Train Loss 46.708263 Test MSE 2.362545590835232 Test RE 1.1105189553664205\n",
      "6 Train Loss 34.297577 Test MSE 2.108191310199802 Test RE 1.0490371934990645\n",
      "7 Train Loss 25.074322 Test MSE 2.018512867697516 Test RE 1.0264827088349353\n",
      "8 Train Loss 19.93798 Test MSE 1.9182095117976976 Test RE 1.0006539106819041\n",
      "9 Train Loss 15.383689 Test MSE 1.8323748967797382 Test RE 0.9780094329203923\n",
      "10 Train Loss 11.690991 Test MSE 1.6811820610481507 Test RE 0.9367921665602028\n",
      "11 Train Loss 9.306599 Test MSE 1.6100562851551388 Test RE 0.9167615837190641\n",
      "12 Train Loss 7.7459893 Test MSE 1.5736626790101338 Test RE 0.9063411522499936\n",
      "13 Train Loss 6.5424633 Test MSE 1.5130515783541743 Test RE 0.8887154767402808\n",
      "14 Train Loss 5.200412 Test MSE 1.4491962651305357 Test RE 0.8697600985880756\n",
      "15 Train Loss 4.4503202 Test MSE 1.4105725165524827 Test RE 0.8580914719724745\n",
      "16 Train Loss 3.910147 Test MSE 1.4117910075349658 Test RE 0.8584620133684443\n",
      "17 Train Loss 3.4893062 Test MSE 1.4000439632857753 Test RE 0.8548830643065827\n",
      "18 Train Loss 3.078004 Test MSE 1.3663918379800692 Test RE 0.844546383354155\n",
      "19 Train Loss 2.7577546 Test MSE 1.323221606314253 Test RE 0.8310978689694807\n",
      "20 Train Loss 2.4733613 Test MSE 1.241955480855691 Test RE 0.8051724213745076\n",
      "21 Train Loss 2.3027635 Test MSE 1.1997300094296177 Test RE 0.7913664565652245\n",
      "22 Train Loss 2.1400626 Test MSE 1.1497764620591577 Test RE 0.7747161039696274\n",
      "23 Train Loss 1.9513053 Test MSE 1.0393269648057044 Test RE 0.7365665198307758\n",
      "24 Train Loss 1.7859164 Test MSE 0.9646385614950712 Test RE 0.7096074825719884\n",
      "25 Train Loss 1.6261789 Test MSE 0.891662715204318 Test RE 0.6822384318166897\n",
      "26 Train Loss 1.5330455 Test MSE 0.8347698717350667 Test RE 0.6601144809993057\n",
      "27 Train Loss 1.4225225 Test MSE 0.7684109895583926 Test RE 0.6333337917448494\n",
      "28 Train Loss 1.320265 Test MSE 0.7507886464610958 Test RE 0.6260293940191458\n",
      "29 Train Loss 1.2094343 Test MSE 0.7035388036507886 Test RE 0.6060101593161314\n",
      "30 Train Loss 1.106418 Test MSE 0.6387617436348141 Test RE 0.5774379537935301\n",
      "31 Train Loss 0.9937843 Test MSE 0.5742990209160631 Test RE 0.5475262115276996\n",
      "32 Train Loss 0.91347486 Test MSE 0.5646048211443833 Test RE 0.5428854072960131\n",
      "33 Train Loss 0.85487205 Test MSE 0.5405034533602695 Test RE 0.5311719262518033\n",
      "34 Train Loss 0.7969186 Test MSE 0.5116472253458086 Test RE 0.5167984334656256\n",
      "35 Train Loss 0.7318009 Test MSE 0.492525825876446 Test RE 0.5070495257494285\n",
      "36 Train Loss 0.6972055 Test MSE 0.46409308439917746 Test RE 0.49219639146002575\n",
      "37 Train Loss 0.65213835 Test MSE 0.4287938580065977 Test RE 0.4731078508343194\n",
      "38 Train Loss 0.61052996 Test MSE 0.4009034342661194 Test RE 0.45746278034233046\n",
      "39 Train Loss 0.5773441 Test MSE 0.38472564659764047 Test RE 0.44813766402096755\n",
      "40 Train Loss 0.53596157 Test MSE 0.357624939517685 Test RE 0.4320656849087603\n",
      "41 Train Loss 0.4920488 Test MSE 0.3293234870813836 Test RE 0.41461711898568465\n",
      "42 Train Loss 0.47001973 Test MSE 0.3215023865078226 Test RE 0.4096641662367808\n",
      "43 Train Loss 0.4362013 Test MSE 0.2872476193792222 Test RE 0.3872256308139927\n",
      "44 Train Loss 0.40505022 Test MSE 0.2641816006476335 Test RE 0.3713531913210556\n",
      "45 Train Loss 0.38134298 Test MSE 0.24142406333366362 Test RE 0.35499820283085015\n",
      "46 Train Loss 0.36064792 Test MSE 0.2297556536790304 Test RE 0.34631314822183684\n",
      "47 Train Loss 0.34637228 Test MSE 0.21081079019323815 Test RE 0.3317281257450755\n",
      "48 Train Loss 0.33332837 Test MSE 0.2084514685408758 Test RE 0.3298666093451141\n",
      "49 Train Loss 0.31832308 Test MSE 0.19814746116166998 Test RE 0.3216104361149086\n",
      "50 Train Loss 0.30979633 Test MSE 0.18812582721505416 Test RE 0.31337192699973754\n",
      "51 Train Loss 0.28508997 Test MSE 0.16301962106242285 Test RE 0.2917130221220821\n",
      "52 Train Loss 0.26844767 Test MSE 0.15927486856433018 Test RE 0.28834306102591534\n",
      "53 Train Loss 0.25621867 Test MSE 0.15176272097873622 Test RE 0.28146113143465434\n",
      "54 Train Loss 0.2425412 Test MSE 0.14110603485177717 Test RE 0.2713992673702652\n",
      "55 Train Loss 0.22743855 Test MSE 0.1319531527834982 Test RE 0.2624495077708908\n",
      "56 Train Loss 0.2183988 Test MSE 0.12435166267469583 Test RE 0.25477785395209107\n",
      "57 Train Loss 0.20780124 Test MSE 0.12018665365218528 Test RE 0.25047477695982995\n",
      "58 Train Loss 0.19637726 Test MSE 0.11140374609688965 Test RE 0.2411491715621964\n",
      "59 Train Loss 0.18940821 Test MSE 0.1100027662315373 Test RE 0.23962806461099176\n",
      "60 Train Loss 0.18185048 Test MSE 0.10313301128625293 Test RE 0.23202497050941473\n",
      "61 Train Loss 0.17584416 Test MSE 0.0984025026966618 Test RE 0.22664124590276918\n",
      "62 Train Loss 0.17193726 Test MSE 0.09264034899005048 Test RE 0.21990543751072048\n",
      "63 Train Loss 0.16694415 Test MSE 0.08580410955671011 Test RE 0.21163618354404315\n",
      "64 Train Loss 0.16321684 Test MSE 0.08316229309756609 Test RE 0.20835268661995077\n",
      "65 Train Loss 0.15807575 Test MSE 0.07522276440775746 Test RE 0.1981575032884564\n",
      "66 Train Loss 0.15257348 Test MSE 0.06922480554577257 Test RE 0.19009327333266146\n",
      "67 Train Loss 0.14774714 Test MSE 0.06293952163699094 Test RE 0.18125817199991176\n",
      "68 Train Loss 0.14339271 Test MSE 0.06157564373615433 Test RE 0.17928351458536645\n",
      "69 Train Loss 0.13819696 Test MSE 0.05756017684291933 Test RE 0.17333925939332337\n",
      "70 Train Loss 0.1341875 Test MSE 0.055463415905056365 Test RE 0.17015283272759674\n",
      "71 Train Loss 0.12980297 Test MSE 0.05249437401253061 Test RE 0.16553592405794695\n",
      "72 Train Loss 0.12382885 Test MSE 0.04659271238188063 Test RE 0.15595340942107738\n",
      "73 Train Loss 0.11747926 Test MSE 0.04165894395549157 Test RE 0.14746535652191972\n",
      "74 Train Loss 0.11267686 Test MSE 0.03818669515146427 Test RE 0.14118609095202322\n",
      "75 Train Loss 0.10854315 Test MSE 0.038179245995751426 Test RE 0.14117231955249562\n",
      "76 Train Loss 0.105007574 Test MSE 0.03475767758577914 Test RE 0.13469803247967954\n",
      "77 Train Loss 0.10020459 Test MSE 0.03199584944921249 Test RE 0.12923575942641444\n",
      "78 Train Loss 0.09722028 Test MSE 0.032891461869630115 Test RE 0.13103202869691452\n",
      "79 Train Loss 0.0955251 Test MSE 0.03209704824923696 Test RE 0.12943997620625342\n",
      "80 Train Loss 0.09361722 Test MSE 0.030504884450874972 Test RE 0.12618872986086221\n",
      "81 Train Loss 0.090919405 Test MSE 0.02904966809030144 Test RE 0.12314207410925788\n",
      "82 Train Loss 0.08899587 Test MSE 0.027857019717255144 Test RE 0.12058775299420697\n",
      "83 Train Loss 0.085881785 Test MSE 0.028544717708436813 Test RE 0.12206713545202302\n",
      "84 Train Loss 0.08246636 Test MSE 0.029301939743488995 Test RE 0.1236756103609556\n",
      "85 Train Loss 0.08039254 Test MSE 0.028503798320262123 Test RE 0.12197961130991447\n",
      "86 Train Loss 0.07883835 Test MSE 0.02761944208323012 Test RE 0.12007243767851351\n",
      "87 Train Loss 0.077869415 Test MSE 0.026373802009460046 Test RE 0.11733355998552908\n",
      "88 Train Loss 0.076453805 Test MSE 0.02547137072995345 Test RE 0.11530868924012182\n",
      "89 Train Loss 0.07491182 Test MSE 0.024385871100284246 Test RE 0.1128249146938095\n",
      "90 Train Loss 0.07363571 Test MSE 0.023364220596326143 Test RE 0.11043621813819382\n",
      "91 Train Loss 0.07220224 Test MSE 0.02310750381752591 Test RE 0.10982782767672875\n",
      "92 Train Loss 0.07008133 Test MSE 0.022242603004719363 Test RE 0.10775282923258478\n",
      "93 Train Loss 0.068830274 Test MSE 0.021999303968977882 Test RE 0.10716188569261807\n",
      "94 Train Loss 0.067704126 Test MSE 0.02125994496714178 Test RE 0.10534573192445511\n",
      "95 Train Loss 0.06653774 Test MSE 0.020570318303442733 Test RE 0.10362305283803835\n",
      "96 Train Loss 0.06551011 Test MSE 0.0201338390829407 Test RE 0.10251777538640387\n",
      "97 Train Loss 0.0640847 Test MSE 0.01881201482345736 Test RE 0.09909540867022058\n",
      "98 Train Loss 0.06256284 Test MSE 0.0177276591185321 Test RE 0.09619700988775343\n",
      "99 Train Loss 0.0605257 Test MSE 0.01678548105457392 Test RE 0.09360580294780542\n",
      "100 Train Loss 0.05882959 Test MSE 0.01530690245979897 Test RE 0.08938806461804698\n",
      "101 Train Loss 0.057458024 Test MSE 0.013973983356555371 Test RE 0.08540749569199622\n",
      "102 Train Loss 0.0563477 Test MSE 0.013324273489979301 Test RE 0.08339838603511782\n",
      "103 Train Loss 0.055318657 Test MSE 0.01316152134702976 Test RE 0.08288747752202368\n",
      "104 Train Loss 0.054414008 Test MSE 0.01256566177520167 Test RE 0.08098947053576935\n",
      "105 Train Loss 0.053282727 Test MSE 0.011596750904578196 Test RE 0.0778043790962575\n",
      "106 Train Loss 0.05230836 Test MSE 0.011257731745664554 Test RE 0.07665867789053898\n",
      "107 Train Loss 0.051430296 Test MSE 0.010896191567879802 Test RE 0.07541769274903747\n",
      "108 Train Loss 0.05076119 Test MSE 0.010722979678301653 Test RE 0.07481585067901404\n",
      "109 Train Loss 0.04982504 Test MSE 0.010230479535831335 Test RE 0.07307753210144968\n",
      "110 Train Loss 0.04879379 Test MSE 0.010012777112952878 Test RE 0.07229581388991775\n",
      "111 Train Loss 0.04804971 Test MSE 0.009834244598856788 Test RE 0.0716483807580089\n",
      "112 Train Loss 0.047164496 Test MSE 0.009131881458759422 Test RE 0.06904242065710486\n",
      "113 Train Loss 0.0460237 Test MSE 0.008763422857804761 Test RE 0.0676351972464019\n",
      "114 Train Loss 0.045341033 Test MSE 0.008466321311472675 Test RE 0.06647881205855573\n",
      "115 Train Loss 0.044479713 Test MSE 0.00829499824922767 Test RE 0.06580274733368362\n",
      "116 Train Loss 0.0435842 Test MSE 0.008408305300337524 Test RE 0.06625064533786752\n",
      "117 Train Loss 0.04286355 Test MSE 0.00832262712868815 Test RE 0.0659122437281252\n",
      "118 Train Loss 0.042184655 Test MSE 0.00820946180639533 Test RE 0.06546259546418892\n",
      "119 Train Loss 0.041071337 Test MSE 0.008000693930944916 Test RE 0.06462487338528987\n",
      "120 Train Loss 0.039814167 Test MSE 0.007708802483517793 Test RE 0.06343505722928758\n",
      "121 Train Loss 0.038848262 Test MSE 0.007409820708817147 Test RE 0.06219274515411727\n",
      "122 Train Loss 0.038268823 Test MSE 0.007225504239478535 Test RE 0.061414363757283014\n",
      "123 Train Loss 0.037579972 Test MSE 0.007069821052378188 Test RE 0.06074913347525179\n",
      "124 Train Loss 0.037134953 Test MSE 0.006884956057517677 Test RE 0.059949623958401775\n",
      "125 Train Loss 0.03652082 Test MSE 0.00663748316537271 Test RE 0.05886234951993878\n",
      "126 Train Loss 0.03571798 Test MSE 0.006251748533910974 Test RE 0.057126369860838536\n",
      "127 Train Loss 0.034615975 Test MSE 0.006168659147927098 Test RE 0.05674547866639703\n",
      "128 Train Loss 0.033970654 Test MSE 0.006096561514019767 Test RE 0.05641289104263758\n",
      "129 Train Loss 0.033159547 Test MSE 0.00569123361291638 Test RE 0.05450534379351477\n",
      "130 Train Loss 0.032592848 Test MSE 0.005468790490545832 Test RE 0.053429550416922725\n",
      "131 Train Loss 0.03196487 Test MSE 0.005203334356208265 Test RE 0.0521166802141876\n",
      "132 Train Loss 0.031473864 Test MSE 0.005290389494373187 Test RE 0.05255084461307207\n",
      "133 Train Loss 0.031085582 Test MSE 0.005327639848260338 Test RE 0.05273552891815827\n",
      "134 Train Loss 0.030771773 Test MSE 0.005240939569008528 Test RE 0.05230466837830722\n",
      "135 Train Loss 0.03048074 Test MSE 0.004951873908804219 Test RE 0.05084177047430083\n",
      "136 Train Loss 0.0300304 Test MSE 0.004782327330210975 Test RE 0.04996380746142433\n",
      "137 Train Loss 0.029673407 Test MSE 0.004659339184744433 Test RE 0.04931715785819771\n",
      "138 Train Loss 0.029414495 Test MSE 0.004565356072472886 Test RE 0.0488172380754174\n",
      "139 Train Loss 0.029004658 Test MSE 0.00437271064449706 Test RE 0.04777616069012491\n",
      "140 Train Loss 0.028404037 Test MSE 0.004167249121685566 Test RE 0.0466402219816069\n",
      "141 Train Loss 0.027877625 Test MSE 0.004113000745084654 Test RE 0.04633565120241407\n",
      "142 Train Loss 0.027544787 Test MSE 0.00413246564229389 Test RE 0.04644516420423339\n",
      "143 Train Loss 0.027256124 Test MSE 0.004185849390778461 Test RE 0.04674419402367954\n",
      "144 Train Loss 0.026860803 Test MSE 0.0042331120342503515 Test RE 0.047007348849617166\n",
      "145 Train Loss 0.026539896 Test MSE 0.0042561855952679825 Test RE 0.04713528698766158\n",
      "146 Train Loss 0.026182007 Test MSE 0.004213189994350108 Test RE 0.04689660447293822\n",
      "147 Train Loss 0.025749154 Test MSE 0.004224169982855674 Test RE 0.046957673298389166\n",
      "148 Train Loss 0.025483884 Test MSE 0.004316396382362923 Test RE 0.04746751942952869\n",
      "149 Train Loss 0.025145134 Test MSE 0.00447730158810443 Test RE 0.04834416366110789\n",
      "150 Train Loss 0.024913548 Test MSE 0.004597038138154495 Test RE 0.04898633298408933\n",
      "151 Train Loss 0.024733797 Test MSE 0.004692811798307419 Test RE 0.04949398765317306\n",
      "152 Train Loss 0.024508934 Test MSE 0.004721502488655894 Test RE 0.04964505410720652\n",
      "153 Train Loss 0.024339842 Test MSE 0.004811660133607792 Test RE 0.050116801808514015\n",
      "154 Train Loss 0.024100725 Test MSE 0.004794483055122087 Test RE 0.0500272661927533\n",
      "155 Train Loss 0.023833496 Test MSE 0.0049576562901296195 Test RE 0.05087144618257361\n",
      "156 Train Loss 0.023705613 Test MSE 0.005103143195314426 Test RE 0.051612483179319796\n",
      "157 Train Loss 0.023542523 Test MSE 0.005037959134270874 Test RE 0.051281792500596085\n",
      "158 Train Loss 0.023361916 Test MSE 0.005012717521577674 Test RE 0.05115316297454653\n",
      "159 Train Loss 0.023012213 Test MSE 0.0049551097591163384 Test RE 0.05085837928688978\n",
      "160 Train Loss 0.022727184 Test MSE 0.004909500107321231 Test RE 0.050623773435840326\n",
      "161 Train Loss 0.022395223 Test MSE 0.004958378044417398 Test RE 0.05087514907624131\n",
      "162 Train Loss 0.02209361 Test MSE 0.004876448907208657 Test RE 0.050453083758437385\n",
      "163 Train Loss 0.0217169 Test MSE 0.00480350273372593 Test RE 0.05007430127831881\n",
      "164 Train Loss 0.021473493 Test MSE 0.004707252097762131 Test RE 0.049570078392485076\n",
      "165 Train Loss 0.021120153 Test MSE 0.004467388648489913 Test RE 0.04829061596946407\n",
      "166 Train Loss 0.020887746 Test MSE 0.0044062883607654865 Test RE 0.047959244663161045\n",
      "167 Train Loss 0.020603111 Test MSE 0.004375608053779964 Test RE 0.047791986590747945\n",
      "168 Train Loss 0.02007748 Test MSE 0.004191665848820056 Test RE 0.04677665950840735\n",
      "169 Train Loss 0.019557575 Test MSE 0.00413229954619214 Test RE 0.04644423081011659\n",
      "170 Train Loss 0.019295953 Test MSE 0.00414568656659794 Test RE 0.046519400472502186\n",
      "171 Train Loss 0.01903869 Test MSE 0.0042527715764266874 Test RE 0.047116378855356474\n",
      "172 Train Loss 0.01890392 Test MSE 0.00426969739610994 Test RE 0.04721004617411574\n",
      "173 Train Loss 0.018700663 Test MSE 0.004182182114075429 Test RE 0.046723712940765855\n",
      "174 Train Loss 0.018453492 Test MSE 0.004131456991381615 Test RE 0.04643949569779592\n",
      "175 Train Loss 0.01828811 Test MSE 0.004002259907083007 Test RE 0.04570761083702541\n",
      "176 Train Loss 0.018088125 Test MSE 0.0038282671300232697 Test RE 0.04470303342309003\n",
      "177 Train Loss 0.017930042 Test MSE 0.0036680303382631146 Test RE 0.04375748337175882\n",
      "178 Train Loss 0.017580267 Test MSE 0.0034906729853657007 Test RE 0.04268649137820039\n",
      "179 Train Loss 0.017367613 Test MSE 0.003404585285690853 Test RE 0.04215683381763954\n",
      "180 Train Loss 0.017218988 Test MSE 0.0033591407021382595 Test RE 0.041874532792533746\n",
      "181 Train Loss 0.017031495 Test MSE 0.0033060640498860116 Test RE 0.04154239285745039\n",
      "182 Train Loss 0.01690362 Test MSE 0.0032484383501102006 Test RE 0.04117875304579103\n",
      "183 Train Loss 0.016699232 Test MSE 0.003079401970664221 Test RE 0.04009304750463519\n",
      "184 Train Loss 0.016472593 Test MSE 0.0030771536146970506 Test RE 0.040078408314377076\n",
      "185 Train Loss 0.016337166 Test MSE 0.00307655846023995 Test RE 0.04007453233030396\n",
      "186 Train Loss 0.016199576 Test MSE 0.0029891590053478146 Test RE 0.0395012087744664\n",
      "187 Train Loss 0.016077174 Test MSE 0.0029899556381786942 Test RE 0.03950647210495194\n",
      "188 Train Loss 0.01592122 Test MSE 0.0030083262000728437 Test RE 0.03962765195045111\n",
      "189 Train Loss 0.015671354 Test MSE 0.002979449673288874 Test RE 0.039437003039180914\n",
      "190 Train Loss 0.01549542 Test MSE 0.0030075829358427253 Test RE 0.039622756265314994\n",
      "191 Train Loss 0.015271501 Test MSE 0.0029470557482174017 Test RE 0.03922202864621567\n",
      "192 Train Loss 0.015015562 Test MSE 0.0028833122543985455 Test RE 0.038795532365469614\n",
      "193 Train Loss 0.014779251 Test MSE 0.0029829107832382074 Test RE 0.03945990260136602\n",
      "194 Train Loss 0.0146270655 Test MSE 0.0029214243501955576 Test RE 0.03905109349075053\n",
      "195 Train Loss 0.01441763 Test MSE 0.0028650579476162453 Test RE 0.03867252973282995\n",
      "196 Train Loss 0.01417927 Test MSE 0.0028435002751704195 Test RE 0.03852676236735245\n",
      "197 Train Loss 0.01388425 Test MSE 0.002635382101528789 Test RE 0.03709007170373331\n",
      "198 Train Loss 0.013573231 Test MSE 0.0025365207215628212 Test RE 0.03638774010596526\n",
      "199 Train Loss 0.013402894 Test MSE 0.002437216381401634 Test RE 0.03566834191776545\n",
      "200 Train Loss 0.013257941 Test MSE 0.0023547368605947323 Test RE 0.03505960897247812\n",
      "201 Train Loss 0.013030508 Test MSE 0.002268390692424233 Test RE 0.03441080283438125\n",
      "202 Train Loss 0.012836572 Test MSE 0.0022402971954653536 Test RE 0.03419705402602429\n",
      "203 Train Loss 0.012731943 Test MSE 0.0022634687917010158 Test RE 0.03437345068697113\n",
      "204 Train Loss 0.012556457 Test MSE 0.0022729628062058463 Test RE 0.03444546417127083\n",
      "205 Train Loss 0.012446756 Test MSE 0.0023132436427138366 Test RE 0.034749340413726126\n",
      "206 Train Loss 0.012330595 Test MSE 0.0022569700619946434 Test RE 0.034324069768208246\n",
      "207 Train Loss 0.012184795 Test MSE 0.0023046253936841394 Test RE 0.03468454872474175\n",
      "208 Train Loss 0.012045972 Test MSE 0.0022950931357536807 Test RE 0.034612744289764796\n",
      "209 Train Loss 0.011952432 Test MSE 0.0022706508365068624 Test RE 0.034427941418499836\n",
      "210 Train Loss 0.011869747 Test MSE 0.0022596594224862593 Test RE 0.03434451361822715\n",
      "211 Train Loss 0.011778767 Test MSE 0.002222695725930279 Test RE 0.03406245015408839\n",
      "212 Train Loss 0.011688481 Test MSE 0.002205103048971271 Test RE 0.03392737989704794\n",
      "213 Train Loss 0.011559486 Test MSE 0.002110614973269411 Test RE 0.03319253212863438\n",
      "214 Train Loss 0.011412436 Test MSE 0.0020064690081558144 Test RE 0.03236324827253591\n",
      "215 Train Loss 0.011285356 Test MSE 0.0019322670382381582 Test RE 0.03175919235274667\n",
      "216 Train Loss 0.011185071 Test MSE 0.00188712678719935 Test RE 0.031386032243553734\n",
      "217 Train Loss 0.011104275 Test MSE 0.001924895297509611 Test RE 0.031698552635032205\n",
      "218 Train Loss 0.011028608 Test MSE 0.0018986154334482979 Test RE 0.03148142485033336\n",
      "219 Train Loss 0.010952129 Test MSE 0.0019032247797571894 Test RE 0.03151961605587929\n",
      "220 Train Loss 0.010869241 Test MSE 0.001901218753459132 Test RE 0.03150300061211045\n",
      "221 Train Loss 0.010749709 Test MSE 0.0019503315463122992 Test RE 0.03190730322780897\n",
      "222 Train Loss 0.010624299 Test MSE 0.0019322925920481164 Test RE 0.03175940235624685\n",
      "223 Train Loss 0.010543885 Test MSE 0.001888567131737985 Test RE 0.03139800761207552\n",
      "224 Train Loss 0.010457985 Test MSE 0.0019184880239405064 Test RE 0.03164575220657972\n",
      "225 Train Loss 0.0103566125 Test MSE 0.0019211768885150332 Test RE 0.03166792105697094\n",
      "226 Train Loss 0.01029159 Test MSE 0.0019361811103543176 Test RE 0.031791342381657144\n",
      "227 Train Loss 0.010232654 Test MSE 0.0019613797417258553 Test RE 0.03199754949815532\n",
      "228 Train Loss 0.010164649 Test MSE 0.0019507800453145436 Test RE 0.03191097172485956\n",
      "229 Train Loss 0.010099684 Test MSE 0.001946555405084998 Test RE 0.03187639954376448\n",
      "230 Train Loss 0.010032994 Test MSE 0.001944293996538384 Test RE 0.0318578779772384\n",
      "231 Train Loss 0.009938404 Test MSE 0.00204474584581846 Test RE 0.032670482175114396\n",
      "232 Train Loss 0.009881768 Test MSE 0.0021338772349594826 Test RE 0.03337494756077893\n",
      "233 Train Loss 0.009828318 Test MSE 0.00214263843764161 Test RE 0.03344339225701038\n",
      "234 Train Loss 0.00973624 Test MSE 0.002130130448941981 Test RE 0.03334563384838788\n",
      "235 Train Loss 0.009658015 Test MSE 0.0021038146288558995 Test RE 0.03313901626637469\n",
      "236 Train Loss 0.009579063 Test MSE 0.002087566851614426 Test RE 0.03301080179208552\n",
      "237 Train Loss 0.009507761 Test MSE 0.002082129525492513 Test RE 0.032967783403594665\n",
      "238 Train Loss 0.009415949 Test MSE 0.0020540758296652816 Test RE 0.03274493351877588\n",
      "239 Train Loss 0.009314143 Test MSE 0.0020485806914474405 Test RE 0.03270110396818491\n",
      "240 Train Loss 0.009245369 Test MSE 0.0020503374708919 Test RE 0.032715122531470985\n",
      "241 Train Loss 0.009167553 Test MSE 0.0019666507200659378 Test RE 0.03204051548437891\n",
      "242 Train Loss 0.009108474 Test MSE 0.0019502810566122937 Test RE 0.03190689022095447\n",
      "243 Train Loss 0.009028318 Test MSE 0.0019127673518126234 Test RE 0.03159853530259158\n",
      "244 Train Loss 0.008980789 Test MSE 0.0018983787003699628 Test RE 0.031479462123492445\n",
      "245 Train Loss 0.00888344 Test MSE 0.0018508067085478783 Test RE 0.03108253342850802\n",
      "246 Train Loss 0.00883484 Test MSE 0.001858155542647947 Test RE 0.03114418062467964\n",
      "247 Train Loss 0.00876743 Test MSE 0.001869591154218751 Test RE 0.031239868649127523\n",
      "248 Train Loss 0.008713789 Test MSE 0.0018326314854069901 Test RE 0.03092953912573616\n",
      "249 Train Loss 0.008649919 Test MSE 0.0018606382092919021 Test RE 0.031164979424078164\n",
      "250 Train Loss 0.008574214 Test MSE 0.001868911610661667 Test RE 0.03123419072837213\n",
      "251 Train Loss 0.008524457 Test MSE 0.0018337574898055773 Test RE 0.030939039521603172\n",
      "252 Train Loss 0.008467812 Test MSE 0.0018507500148510054 Test RE 0.031082057366579166\n",
      "253 Train Loss 0.008419225 Test MSE 0.0018079022419198283 Test RE 0.03072015117561448\n",
      "254 Train Loss 0.008332864 Test MSE 0.0017647224433771527 Test RE 0.03035107524450384\n",
      "255 Train Loss 0.008251206 Test MSE 0.0017082221312081033 Test RE 0.029861254504853784\n",
      "256 Train Loss 0.008192452 Test MSE 0.0016882005100566657 Test RE 0.02968574075650504\n",
      "257 Train Loss 0.0081443405 Test MSE 0.0017179123259821955 Test RE 0.02994583137673432\n",
      "258 Train Loss 0.008086608 Test MSE 0.0016664345216058623 Test RE 0.029493750618876474\n",
      "259 Train Loss 0.007969753 Test MSE 0.0015611880651623161 Test RE 0.028547198060040076\n",
      "260 Train Loss 0.007817738 Test MSE 0.0014297730582002878 Test RE 0.027319291460025465\n",
      "261 Train Loss 0.007711139 Test MSE 0.001388991655683393 Test RE 0.02692685894147166\n",
      "262 Train Loss 0.007569598 Test MSE 0.0012821867467680533 Test RE 0.025870898891058338\n",
      "263 Train Loss 0.0074865418 Test MSE 0.0012102816320604555 Test RE 0.025135012063912603\n",
      "264 Train Loss 0.0074355043 Test MSE 0.0011542193510841183 Test RE 0.0245459617147154\n",
      "265 Train Loss 0.007384311 Test MSE 0.001138093953207885 Test RE 0.024373894940411613\n",
      "266 Train Loss 0.007344942 Test MSE 0.001085162051746069 Test RE 0.023800340804833155\n",
      "267 Train Loss 0.0073014116 Test MSE 0.0010221830256879974 Test RE 0.023099373933989246\n",
      "268 Train Loss 0.00726003 Test MSE 0.0010109351200852455 Test RE 0.022971931841003473\n",
      "269 Train Loss 0.007216179 Test MSE 0.0010041364842238295 Test RE 0.022894557308825454\n",
      "270 Train Loss 0.0071591972 Test MSE 0.0009787460427075623 Test RE 0.022603249892969593\n",
      "271 Train Loss 0.007113595 Test MSE 0.0009799002013232186 Test RE 0.022616573088258655\n",
      "272 Train Loss 0.0070481347 Test MSE 0.0009460360531204574 Test RE 0.02222233655545477\n",
      "273 Train Loss 0.006973871 Test MSE 0.0009523697162369074 Test RE 0.022296601168173887\n",
      "274 Train Loss 0.0069073164 Test MSE 0.000964444773324534 Test RE 0.022437504799014445\n",
      "275 Train Loss 0.006852316 Test MSE 0.000972624887467162 Test RE 0.022532457777306433\n",
      "276 Train Loss 0.006795133 Test MSE 0.000919728822504006 Test RE 0.0219111804349345\n",
      "277 Train Loss 0.0067327423 Test MSE 0.000949676908181342 Test RE 0.02226505723772757\n",
      "278 Train Loss 0.0066971728 Test MSE 0.0009274537989792952 Test RE 0.0220030060988484\n",
      "279 Train Loss 0.006673126 Test MSE 0.0009211024647705179 Test RE 0.021927536828848036\n",
      "280 Train Loss 0.0066415532 Test MSE 0.0009323339482831792 Test RE 0.022060818721419278\n",
      "281 Train Loss 0.0066155703 Test MSE 0.000918245270942004 Test RE 0.021893501590804165\n",
      "282 Train Loss 0.006562695 Test MSE 0.0009409228594529569 Test RE 0.022162200865491113\n",
      "283 Train Loss 0.0065182373 Test MSE 0.0009217803610007296 Test RE 0.021935604259554726\n",
      "284 Train Loss 0.006484064 Test MSE 0.0009099346264427049 Test RE 0.021794202049715522\n",
      "285 Train Loss 0.0064594066 Test MSE 0.000891189965205214 Test RE 0.021568553536049632\n",
      "286 Train Loss 0.0064198957 Test MSE 0.0008767634529150823 Test RE 0.0213932662427552\n",
      "287 Train Loss 0.006381207 Test MSE 0.0008181983663228853 Test RE 0.02066641665326855\n",
      "288 Train Loss 0.0063300775 Test MSE 0.0007699516116159628 Test RE 0.020047840252658284\n",
      "289 Train Loss 0.0062658335 Test MSE 0.0006886620476344141 Test RE 0.01896002700916709\n",
      "290 Train Loss 0.0062417756 Test MSE 0.0006739421951356311 Test RE 0.018756301315941713\n",
      "291 Train Loss 0.0062142084 Test MSE 0.0006738915607812397 Test RE 0.018755596707257325\n",
      "292 Train Loss 0.0061521824 Test MSE 0.0006186052028457413 Test RE 0.017969775899725395\n",
      "293 Train Loss 0.0061011254 Test MSE 0.0006093878741629372 Test RE 0.01783539700866644\n",
      "294 Train Loss 0.0060730414 Test MSE 0.0006026272136675943 Test RE 0.017736186498633604\n",
      "295 Train Loss 0.0060360604 Test MSE 0.0005644012152287093 Test RE 0.01716444822477199\n",
      "296 Train Loss 0.005965519 Test MSE 0.0004994089839623525 Test RE 0.016145966692384512\n",
      "297 Train Loss 0.005919191 Test MSE 0.0004493336433892919 Test RE 0.015315117935230209\n",
      "298 Train Loss 0.005899706 Test MSE 0.0004563265116975639 Test RE 0.015433830540079513\n",
      "299 Train Loss 0.005880047 Test MSE 0.0004525060568900213 Test RE 0.015369087220350634\n",
      "Training time: 550.73\n",
      "KG_rowdy_high\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "200 Train Loss nan Test MSE nan Test RE nan\n",
      "201 Train Loss nan Test MSE nan Test RE nan\n",
      "202 Train Loss nan Test MSE nan Test RE nan\n",
      "203 Train Loss nan Test MSE nan Test RE nan\n",
      "204 Train Loss nan Test MSE nan Test RE nan\n",
      "205 Train Loss nan Test MSE nan Test RE nan\n",
      "206 Train Loss nan Test MSE nan Test RE nan\n",
      "207 Train Loss nan Test MSE nan Test RE nan\n",
      "208 Train Loss nan Test MSE nan Test RE nan\n",
      "209 Train Loss nan Test MSE nan Test RE nan\n",
      "210 Train Loss nan Test MSE nan Test RE nan\n",
      "211 Train Loss nan Test MSE nan Test RE nan\n",
      "212 Train Loss nan Test MSE nan Test RE nan\n",
      "213 Train Loss nan Test MSE nan Test RE nan\n",
      "214 Train Loss nan Test MSE nan Test RE nan\n",
      "215 Train Loss nan Test MSE nan Test RE nan\n",
      "216 Train Loss nan Test MSE nan Test RE nan\n",
      "217 Train Loss nan Test MSE nan Test RE nan\n",
      "218 Train Loss nan Test MSE nan Test RE nan\n",
      "219 Train Loss nan Test MSE nan Test RE nan\n",
      "220 Train Loss nan Test MSE nan Test RE nan\n",
      "221 Train Loss nan Test MSE nan Test RE nan\n",
      "222 Train Loss nan Test MSE nan Test RE nan\n",
      "223 Train Loss nan Test MSE nan Test RE nan\n",
      "224 Train Loss nan Test MSE nan Test RE nan\n",
      "225 Train Loss nan Test MSE nan Test RE nan\n",
      "226 Train Loss nan Test MSE nan Test RE nan\n",
      "227 Train Loss nan Test MSE nan Test RE nan\n",
      "228 Train Loss nan Test MSE nan Test RE nan\n",
      "229 Train Loss nan Test MSE nan Test RE nan\n",
      "230 Train Loss nan Test MSE nan Test RE nan\n",
      "231 Train Loss nan Test MSE nan Test RE nan\n",
      "232 Train Loss nan Test MSE nan Test RE nan\n",
      "233 Train Loss nan Test MSE nan Test RE nan\n",
      "234 Train Loss nan Test MSE nan Test RE nan\n",
      "235 Train Loss nan Test MSE nan Test RE nan\n",
      "236 Train Loss nan Test MSE nan Test RE nan\n",
      "237 Train Loss nan Test MSE nan Test RE nan\n",
      "238 Train Loss nan Test MSE nan Test RE nan\n",
      "239 Train Loss nan Test MSE nan Test RE nan\n",
      "240 Train Loss nan Test MSE nan Test RE nan\n",
      "241 Train Loss nan Test MSE nan Test RE nan\n",
      "242 Train Loss nan Test MSE nan Test RE nan\n",
      "243 Train Loss nan Test MSE nan Test RE nan\n",
      "244 Train Loss nan Test MSE nan Test RE nan\n",
      "245 Train Loss nan Test MSE nan Test RE nan\n",
      "246 Train Loss nan Test MSE nan Test RE nan\n",
      "247 Train Loss nan Test MSE nan Test RE nan\n",
      "248 Train Loss nan Test MSE nan Test RE nan\n",
      "249 Train Loss nan Test MSE nan Test RE nan\n",
      "250 Train Loss nan Test MSE nan Test RE nan\n",
      "251 Train Loss nan Test MSE nan Test RE nan\n",
      "252 Train Loss nan Test MSE nan Test RE nan\n",
      "253 Train Loss nan Test MSE nan Test RE nan\n",
      "254 Train Loss nan Test MSE nan Test RE nan\n",
      "255 Train Loss nan Test MSE nan Test RE nan\n",
      "256 Train Loss nan Test MSE nan Test RE nan\n",
      "257 Train Loss nan Test MSE nan Test RE nan\n",
      "258 Train Loss nan Test MSE nan Test RE nan\n",
      "259 Train Loss nan Test MSE nan Test RE nan\n",
      "260 Train Loss nan Test MSE nan Test RE nan\n",
      "261 Train Loss nan Test MSE nan Test RE nan\n",
      "262 Train Loss nan Test MSE nan Test RE nan\n",
      "263 Train Loss nan Test MSE nan Test RE nan\n",
      "264 Train Loss nan Test MSE nan Test RE nan\n",
      "265 Train Loss nan Test MSE nan Test RE nan\n",
      "266 Train Loss nan Test MSE nan Test RE nan\n",
      "267 Train Loss nan Test MSE nan Test RE nan\n",
      "268 Train Loss nan Test MSE nan Test RE nan\n",
      "269 Train Loss nan Test MSE nan Test RE nan\n",
      "270 Train Loss nan Test MSE nan Test RE nan\n",
      "271 Train Loss nan Test MSE nan Test RE nan\n",
      "272 Train Loss nan Test MSE nan Test RE nan\n",
      "273 Train Loss nan Test MSE nan Test RE nan\n",
      "274 Train Loss nan Test MSE nan Test RE nan\n",
      "275 Train Loss nan Test MSE nan Test RE nan\n",
      "276 Train Loss nan Test MSE nan Test RE nan\n",
      "277 Train Loss nan Test MSE nan Test RE nan\n",
      "278 Train Loss nan Test MSE nan Test RE nan\n",
      "279 Train Loss nan Test MSE nan Test RE nan\n",
      "280 Train Loss nan Test MSE nan Test RE nan\n",
      "281 Train Loss nan Test MSE nan Test RE nan\n",
      "282 Train Loss nan Test MSE nan Test RE nan\n",
      "283 Train Loss nan Test MSE nan Test RE nan\n",
      "284 Train Loss nan Test MSE nan Test RE nan\n",
      "285 Train Loss nan Test MSE nan Test RE nan\n",
      "286 Train Loss nan Test MSE nan Test RE nan\n",
      "287 Train Loss nan Test MSE nan Test RE nan\n",
      "288 Train Loss nan Test MSE nan Test RE nan\n",
      "289 Train Loss nan Test MSE nan Test RE nan\n",
      "290 Train Loss nan Test MSE nan Test RE nan\n",
      "291 Train Loss nan Test MSE nan Test RE nan\n",
      "292 Train Loss nan Test MSE nan Test RE nan\n",
      "293 Train Loss nan Test MSE nan Test RE nan\n",
      "294 Train Loss nan Test MSE nan Test RE nan\n",
      "295 Train Loss nan Test MSE nan Test RE nan\n",
      "296 Train Loss nan Test MSE nan Test RE nan\n",
      "297 Train Loss nan Test MSE nan Test RE nan\n",
      "298 Train Loss nan Test MSE nan Test RE nan\n",
      "299 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 23.62\n",
      "KG_rowdy_high\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 67172.18 Test MSE 1.941305678784786 Test RE 1.006660063205373\n",
      "1 Train Loss 32370.803 Test MSE 3.493117311912368 Test RE 1.3503379163429043\n",
      "2 Train Loss 1932.1519 Test MSE 4.842267993024959 Test RE 1.5898651427542478\n",
      "3 Train Loss 482.50677 Test MSE 5.765412001551885 Test RE 1.7348065403483872\n",
      "4 Train Loss 222.48871 Test MSE 3.8562231934023115 Test RE 1.4187862081153915\n",
      "5 Train Loss 93.534935 Test MSE 2.2911884702383074 Test RE 1.0936195983976378\n",
      "6 Train Loss 56.258 Test MSE 1.8997151913629116 Test RE 0.9958183498469858\n",
      "7 Train Loss 41.394073 Test MSE 1.7480988135834346 Test RE 0.9552540022180075\n",
      "8 Train Loss 30.344751 Test MSE 1.3586031195708783 Test RE 0.8421358981290101\n",
      "9 Train Loss 24.499363 Test MSE 1.2423965832861261 Test RE 0.8053153942859412\n",
      "10 Train Loss 17.424747 Test MSE 0.9381868025383823 Test RE 0.6998106325139853\n",
      "11 Train Loss 12.89853 Test MSE 0.6453664872946219 Test RE 0.5804156067863282\n",
      "12 Train Loss 9.991075 Test MSE 0.35681163755986983 Test RE 0.4315741086198196\n",
      "13 Train Loss 7.9177227 Test MSE 0.2281260656146852 Test RE 0.34508281500508814\n",
      "14 Train Loss 6.299844 Test MSE 0.15726609768049643 Test RE 0.2865190035939684\n",
      "15 Train Loss 5.19732 Test MSE 0.18399388240276388 Test RE 0.309911411902846\n",
      "16 Train Loss 4.5272655 Test MSE 0.17897754897350368 Test RE 0.3056575692438657\n",
      "17 Train Loss 3.7717845 Test MSE 0.2070424736156238 Test RE 0.3287498783141992\n",
      "18 Train Loss 3.3636117 Test MSE 0.2503500645472929 Test RE 0.3615011895773666\n",
      "19 Train Loss 3.0762196 Test MSE 0.27564043137115835 Test RE 0.37932139350296323\n",
      "20 Train Loss 2.8260553 Test MSE 0.2895877750063199 Test RE 0.3887997606928159\n",
      "21 Train Loss 2.4884562 Test MSE 0.28749841269140053 Test RE 0.3873946355401559\n",
      "22 Train Loss 2.2608888 Test MSE 0.2697527877828389 Test RE 0.37524839875013555\n",
      "23 Train Loss 2.053494 Test MSE 0.25600299228821016 Test RE 0.365559771918531\n",
      "24 Train Loss 1.8930271 Test MSE 0.20816392628820696 Test RE 0.3296390184317729\n",
      "25 Train Loss 1.785848 Test MSE 0.20146096369347333 Test RE 0.32428833762731607\n",
      "26 Train Loss 1.6868572 Test MSE 0.21272406916714082 Test RE 0.33323007654038356\n",
      "27 Train Loss 1.5954678 Test MSE 0.21243230034372415 Test RE 0.33300147168840855\n",
      "28 Train Loss 1.5426185 Test MSE 0.20109902074997088 Test RE 0.323996899924121\n",
      "29 Train Loss 1.4494299 Test MSE 0.18558074953876977 Test RE 0.3112449682457219\n",
      "30 Train Loss 1.3711964 Test MSE 0.16371679902079164 Test RE 0.2923361339588261\n",
      "31 Train Loss 1.3250691 Test MSE 0.14917224049719122 Test RE 0.2790486226495726\n",
      "32 Train Loss 1.2524956 Test MSE 0.14279111360902427 Test RE 0.2730149739001862\n",
      "33 Train Loss 1.2217792 Test MSE 0.14008715280927447 Test RE 0.2704176480393981\n",
      "34 Train Loss 1.1191865 Test MSE 0.13806557838307632 Test RE 0.2684593814368995\n",
      "35 Train Loss 1.0884668 Test MSE 0.1267080699698338 Test RE 0.25718048723625786\n",
      "36 Train Loss 0.96789205 Test MSE 0.1260563506268058 Test RE 0.2565182343191887\n",
      "37 Train Loss 0.9235731 Test MSE 0.12411142866132713 Test RE 0.25453163329592393\n",
      "38 Train Loss 0.88588405 Test MSE 0.12684016013828273 Test RE 0.257314504607866\n",
      "39 Train Loss 0.8524495 Test MSE 0.13628668564766916 Test RE 0.2667243048528613\n",
      "40 Train Loss 0.8167142 Test MSE 0.1474802402798372 Test RE 0.27746154174126464\n",
      "41 Train Loss 0.761677 Test MSE 0.15028086066050395 Test RE 0.28008362178919727\n",
      "42 Train Loss 0.74050444 Test MSE 0.15626008894503257 Test RE 0.28560112280618116\n",
      "43 Train Loss 0.7055618 Test MSE 0.15580859173059114 Test RE 0.28518821701367597\n",
      "44 Train Loss 0.6769911 Test MSE 0.16392658062669582 Test RE 0.2925233692060465\n",
      "45 Train Loss 0.6604984 Test MSE 0.16667593977010073 Test RE 0.29496625423572703\n",
      "46 Train Loss 0.6055654 Test MSE 0.17378638820239029 Test RE 0.3011922241845592\n",
      "47 Train Loss 0.5945891 Test MSE 0.17901594225075318 Test RE 0.3056903514743517\n",
      "48 Train Loss 0.5695308 Test MSE 0.18187463590685105 Test RE 0.3081214587962168\n",
      "49 Train Loss 0.5511955 Test MSE 0.18841878910262838 Test RE 0.3136158337477185\n",
      "50 Train Loss 0.53686965 Test MSE 0.17912990793753847 Test RE 0.30578764076454873\n",
      "51 Train Loss 0.5117817 Test MSE 0.1741741070030761 Test RE 0.30152801811123603\n",
      "52 Train Loss 0.5029967 Test MSE 0.1697781543926214 Test RE 0.29769859226175344\n",
      "53 Train Loss 0.4868272 Test MSE 0.1675694882023573 Test RE 0.29575585330275295\n",
      "54 Train Loss 0.45647973 Test MSE 0.1570079298634176 Test RE 0.28628373239120675\n",
      "55 Train Loss 0.4437489 Test MSE 0.15045776547247003 Test RE 0.2802484251023656\n",
      "56 Train Loss 0.43258238 Test MSE 0.1499213392588417 Test RE 0.279748394959449\n",
      "57 Train Loss 0.42297086 Test MSE 0.14635738700687362 Test RE 0.2764032851629542\n",
      "58 Train Loss 0.40897885 Test MSE 0.1316689174665308 Test RE 0.2621666890861828\n",
      "59 Train Loss 0.39766192 Test MSE 0.12685307864316456 Test RE 0.2573276078475865\n",
      "60 Train Loss 0.38809517 Test MSE 0.12136572995834005 Test RE 0.25170040424578827\n",
      "61 Train Loss 0.37728444 Test MSE 0.11706145462757567 Test RE 0.24719679468766903\n",
      "62 Train Loss 0.3718626 Test MSE 0.11434099734962311 Test RE 0.2443075367541404\n",
      "63 Train Loss 0.36566892 Test MSE 0.11449847947344355 Test RE 0.24447572153542357\n",
      "64 Train Loss 0.35873342 Test MSE 0.11409970172459533 Test RE 0.24404961756956578\n",
      "65 Train Loss 0.35252893 Test MSE 0.11310526615836168 Test RE 0.24298378335860044\n",
      "66 Train Loss 0.34395835 Test MSE 0.1124439903386112 Test RE 0.2422724334364072\n",
      "67 Train Loss 0.33285597 Test MSE 0.11504386768724774 Test RE 0.24505728287035147\n",
      "68 Train Loss 0.3255207 Test MSE 0.11690679338951873 Test RE 0.24703344288795537\n",
      "69 Train Loss 0.32029518 Test MSE 0.1160906576324623 Test RE 0.24616965250194467\n",
      "70 Train Loss 0.31361893 Test MSE 0.11203672794968887 Test RE 0.2418332905617201\n",
      "71 Train Loss 0.3083781 Test MSE 0.11269018045305451 Test RE 0.24253750970325383\n",
      "72 Train Loss 0.30340868 Test MSE 0.11195882196939139 Test RE 0.24174919521080415\n",
      "73 Train Loss 0.297032 Test MSE 0.11159613945530067 Test RE 0.24135731305983918\n",
      "74 Train Loss 0.28813577 Test MSE 0.10915637975686886 Test RE 0.23870440787088393\n",
      "75 Train Loss 0.28027838 Test MSE 0.10963401257678673 Test RE 0.23922608425305905\n",
      "76 Train Loss 0.27574685 Test MSE 0.10813098095603443 Test RE 0.23758058553128034\n",
      "77 Train Loss 0.2692237 Test MSE 0.10799171152154234 Test RE 0.23742753792937699\n",
      "78 Train Loss 0.26149794 Test MSE 0.10630654791719836 Test RE 0.23556777757641428\n",
      "79 Train Loss 0.25444728 Test MSE 0.10526404867513915 Test RE 0.23440987961402127\n",
      "80 Train Loss 0.24946325 Test MSE 0.10137618016383347 Test RE 0.23004025398351663\n",
      "81 Train Loss 0.24584164 Test MSE 0.10016722313568244 Test RE 0.22866447268121887\n",
      "82 Train Loss 0.24119581 Test MSE 0.09691673154478303 Test RE 0.22492371944593773\n",
      "83 Train Loss 0.23208423 Test MSE 0.09590166583583985 Test RE 0.22374274009069764\n",
      "84 Train Loss 0.22747861 Test MSE 0.095113824574572 Test RE 0.2228218109173429\n",
      "85 Train Loss 0.22413608 Test MSE 0.09369979966127076 Test RE 0.22115930070860473\n",
      "86 Train Loss 0.2200383 Test MSE 0.09227108125269547 Test RE 0.21946672443158902\n",
      "87 Train Loss 0.21571238 Test MSE 0.09088484572264978 Test RE 0.2178119053265994\n",
      "88 Train Loss 0.20936015 Test MSE 0.08812407302269251 Test RE 0.2144782007620486\n",
      "89 Train Loss 0.19987567 Test MSE 0.08251122561008772 Test RE 0.20753550013066085\n",
      "90 Train Loss 0.19455253 Test MSE 0.08077024786606629 Test RE 0.205334339102711\n",
      "91 Train Loss 0.1915627 Test MSE 0.07940708352907067 Test RE 0.2035942459439278\n",
      "92 Train Loss 0.18826403 Test MSE 0.07853837953413295 Test RE 0.20247753502579932\n",
      "93 Train Loss 0.18456812 Test MSE 0.07806699615299377 Test RE 0.20186899057680738\n",
      "94 Train Loss 0.17849673 Test MSE 0.07740097519070809 Test RE 0.20100603327487726\n",
      "95 Train Loss 0.17225334 Test MSE 0.07347796286031492 Test RE 0.19584587582750798\n",
      "96 Train Loss 0.16935708 Test MSE 0.07052501341781203 Test RE 0.1918701723307759\n",
      "97 Train Loss 0.16756782 Test MSE 0.06756594611661206 Test RE 0.18780182493895584\n",
      "98 Train Loss 0.16566889 Test MSE 0.06700287161339404 Test RE 0.18701764545947383\n",
      "99 Train Loss 0.163976 Test MSE 0.06544456373654313 Test RE 0.1848300859134001\n",
      "100 Train Loss 0.16144386 Test MSE 0.06430648897321162 Test RE 0.18321594887272497\n",
      "101 Train Loss 0.15599672 Test MSE 0.062195581793238294 Test RE 0.180183759534215\n",
      "102 Train Loss 0.15131563 Test MSE 0.0610132183904268 Test RE 0.17846285811358767\n",
      "103 Train Loss 0.14931652 Test MSE 0.05940928457296659 Test RE 0.17610149307154843\n",
      "104 Train Loss 0.14652166 Test MSE 0.058429428699337004 Test RE 0.17464320663253638\n",
      "105 Train Loss 0.14333422 Test MSE 0.055980903150324286 Test RE 0.17094477355344087\n",
      "106 Train Loss 0.13900949 Test MSE 0.05604068224859536 Test RE 0.17103602072196833\n",
      "107 Train Loss 0.13625827 Test MSE 0.0540554876184062 Test RE 0.16797930170987713\n",
      "108 Train Loss 0.13358112 Test MSE 0.052109698988722836 Test RE 0.16492829112367785\n",
      "109 Train Loss 0.13084355 Test MSE 0.04989789692010685 Test RE 0.16139013974828903\n",
      "110 Train Loss 0.12887469 Test MSE 0.04751073448839089 Test RE 0.1574823000524054\n",
      "111 Train Loss 0.12671845 Test MSE 0.045629276653004286 Test RE 0.15433259866655302\n",
      "112 Train Loss 0.12388754 Test MSE 0.043212143167697184 Test RE 0.15018922630456003\n",
      "113 Train Loss 0.12168502 Test MSE 0.04074089306460726 Test RE 0.14583143498201165\n",
      "114 Train Loss 0.11815279 Test MSE 0.038737571731505334 Test RE 0.14220081111327454\n",
      "115 Train Loss 0.116854206 Test MSE 0.03639580328845077 Test RE 0.13783564137559848\n",
      "116 Train Loss 0.11507894 Test MSE 0.036229715415171795 Test RE 0.1375207835706196\n",
      "117 Train Loss 0.11207881 Test MSE 0.03577024604116535 Test RE 0.13664597399809164\n",
      "118 Train Loss 0.11043604 Test MSE 0.03399914895151576 Test RE 0.13322014437183236\n",
      "119 Train Loss 0.10813312 Test MSE 0.03224747956819425 Test RE 0.12974294899888442\n",
      "120 Train Loss 0.10697452 Test MSE 0.029412811762928724 Test RE 0.12390936994023342\n",
      "121 Train Loss 0.105792224 Test MSE 0.028044644250493835 Test RE 0.1209931669996868\n",
      "122 Train Loss 0.10312206 Test MSE 0.026172541192914265 Test RE 0.1168850112292789\n",
      "123 Train Loss 0.0993693 Test MSE 0.02509615372876845 Test RE 0.11445623607109118\n",
      "124 Train Loss 0.09607388 Test MSE 0.022471686497970662 Test RE 0.10830629776473803\n",
      "125 Train Loss 0.093880445 Test MSE 0.021275742515145434 Test RE 0.10538486408638975\n",
      "126 Train Loss 0.09200159 Test MSE 0.020362215558821138 Test RE 0.10309756124139977\n",
      "127 Train Loss 0.090227984 Test MSE 0.019587431059657354 Test RE 0.10111710271048327\n",
      "128 Train Loss 0.08784291 Test MSE 0.01943998360542444 Test RE 0.10073579635751514\n",
      "129 Train Loss 0.084199116 Test MSE 0.019566830609845105 Test RE 0.101063915394121\n",
      "130 Train Loss 0.081711225 Test MSE 0.020319128537910174 Test RE 0.10298842480702544\n",
      "131 Train Loss 0.07941653 Test MSE 0.01864017532791542 Test RE 0.09864177383089004\n",
      "132 Train Loss 0.07756484 Test MSE 0.01783305736088998 Test RE 0.09648255154331963\n",
      "133 Train Loss 0.07618931 Test MSE 0.017627757314389553 Test RE 0.0959255743761349\n",
      "134 Train Loss 0.07415674 Test MSE 0.016977572115822924 Test RE 0.09413988617085692\n",
      "135 Train Loss 0.072829254 Test MSE 0.015877306919955907 Test RE 0.09103833303558855\n",
      "136 Train Loss 0.07164402 Test MSE 0.015547668032420138 Test RE 0.09008832381075467\n",
      "137 Train Loss 0.069929935 Test MSE 0.01475363041985749 Test RE 0.0877577190880131\n",
      "138 Train Loss 0.06823651 Test MSE 0.014024491078286086 Test RE 0.08556170537719701\n",
      "139 Train Loss 0.06738128 Test MSE 0.013652425977959931 Test RE 0.08441911445476949\n",
      "140 Train Loss 0.06646061 Test MSE 0.013210334391893064 Test RE 0.08304104053278329\n",
      "141 Train Loss 0.06537131 Test MSE 0.01278625805806797 Test RE 0.081697282261782\n",
      "142 Train Loss 0.06477351 Test MSE 0.013223928272948087 Test RE 0.08308375556698729\n",
      "143 Train Loss 0.06325557 Test MSE 0.012644507657405973 Test RE 0.08124316590772725\n",
      "144 Train Loss 0.06167895 Test MSE 0.011492350478964151 Test RE 0.07745336808318756\n",
      "145 Train Loss 0.059908524 Test MSE 0.011685624615854236 Test RE 0.07810194374950932\n",
      "146 Train Loss 0.059020687 Test MSE 0.011427364364694196 Test RE 0.07723406876555039\n",
      "147 Train Loss 0.058046885 Test MSE 0.011725766601905331 Test RE 0.07823597506594383\n",
      "148 Train Loss 0.057462577 Test MSE 0.011231853868046003 Test RE 0.07657052046906923\n",
      "149 Train Loss 0.056253996 Test MSE 0.010546330052789286 Test RE 0.07419703594305456\n",
      "150 Train Loss 0.054555617 Test MSE 0.01035849202544638 Test RE 0.07353331496722647\n",
      "151 Train Loss 0.053444616 Test MSE 0.01061631939069806 Test RE 0.07444282828012466\n",
      "152 Train Loss 0.051639948 Test MSE 0.010826299601702382 Test RE 0.07517542595934645\n",
      "153 Train Loss 0.05035741 Test MSE 0.010923980031045897 Test RE 0.07551380005758972\n",
      "154 Train Loss 0.04987292 Test MSE 0.0108663190706215 Test RE 0.07531424095819836\n",
      "155 Train Loss 0.048938043 Test MSE 0.010617184885153747 Test RE 0.0744458626906235\n",
      "156 Train Loss 0.04808472 Test MSE 0.010148139278321274 Test RE 0.07278285484802842\n",
      "157 Train Loss 0.04716442 Test MSE 0.0095845751155933 Test RE 0.07073303768135573\n",
      "158 Train Loss 0.046531565 Test MSE 0.009170537422032518 Test RE 0.06918839730139666\n",
      "159 Train Loss 0.04610648 Test MSE 0.008955546488565221 Test RE 0.0683725729415835\n",
      "160 Train Loss 0.045597598 Test MSE 0.008509943372632115 Test RE 0.06664985547038106\n",
      "161 Train Loss 0.045355752 Test MSE 0.008301655159255409 Test RE 0.0658291460806152\n",
      "162 Train Loss 0.044954445 Test MSE 0.008172744592859328 Test RE 0.06531603910405315\n",
      "163 Train Loss 0.04451708 Test MSE 0.00810159586119356 Test RE 0.06503110962723023\n",
      "164 Train Loss 0.043998476 Test MSE 0.007988290466045427 Test RE 0.06457476002851306\n",
      "165 Train Loss 0.04333424 Test MSE 0.007902060671489323 Test RE 0.06422528746798496\n",
      "166 Train Loss 0.042170867 Test MSE 0.007757716473535806 Test RE 0.06363599344717485\n",
      "167 Train Loss 0.041638095 Test MSE 0.007820274069230717 Test RE 0.0638920560086282\n",
      "168 Train Loss 0.04104524 Test MSE 0.007883528356740645 Test RE 0.06414993105362873\n",
      "169 Train Loss 0.04058981 Test MSE 0.007860467943782352 Test RE 0.06405603862207253\n",
      "170 Train Loss 0.040015046 Test MSE 0.007810962430771397 Test RE 0.0638540063875005\n",
      "171 Train Loss 0.039403684 Test MSE 0.00759728169523236 Test RE 0.06297453823998614\n",
      "172 Train Loss 0.039003216 Test MSE 0.0072870620206400396 Test RE 0.06167541917184785\n",
      "173 Train Loss 0.038425803 Test MSE 0.007169512056431201 Test RE 0.06117594357248152\n",
      "174 Train Loss 0.03786455 Test MSE 0.0070135371375154255 Test RE 0.06050683374478691\n",
      "175 Train Loss 0.0373467 Test MSE 0.006820834784735919 Test RE 0.05966980821121213\n",
      "176 Train Loss 0.036858186 Test MSE 0.006795715242680423 Test RE 0.05955983187724393\n",
      "177 Train Loss 0.036430918 Test MSE 0.006815340086576004 Test RE 0.05964576909775514\n",
      "178 Train Loss 0.036099274 Test MSE 0.006845528309376773 Test RE 0.05977772217933034\n",
      "179 Train Loss 0.035766855 Test MSE 0.006771547925131845 Test RE 0.05945383248498333\n",
      "180 Train Loss 0.03542882 Test MSE 0.006726331917763862 Test RE 0.05925500293924024\n",
      "181 Train Loss 0.03510098 Test MSE 0.006733429746348659 Test RE 0.059286258530298515\n",
      "182 Train Loss 0.034827378 Test MSE 0.006857540931635732 Test RE 0.059830148552614815\n",
      "183 Train Loss 0.03449229 Test MSE 0.006921577525890166 Test RE 0.06010885021608992\n",
      "184 Train Loss 0.034041908 Test MSE 0.007011046533415795 Test RE 0.06049608938381838\n",
      "185 Train Loss 0.033745773 Test MSE 0.007071770518278328 Test RE 0.06075750852466406\n",
      "186 Train Loss 0.033520684 Test MSE 0.007122042154564542 Test RE 0.0609730818627661\n",
      "187 Train Loss 0.03340476 Test MSE 0.007089097706069638 Test RE 0.060831896733548406\n",
      "188 Train Loss 0.033245213 Test MSE 0.0070749885503728115 Test RE 0.0607713309029503\n",
      "189 Train Loss 0.03301144 Test MSE 0.006993546775030998 Test RE 0.06042054228943356\n",
      "190 Train Loss 0.032829706 Test MSE 0.007059243899372332 Test RE 0.06070367310322649\n",
      "191 Train Loss 0.032702163 Test MSE 0.007020640363897271 Test RE 0.06053746628881555\n",
      "192 Train Loss 0.032556914 Test MSE 0.007052450601393112 Test RE 0.06067445769403545\n",
      "193 Train Loss 0.032392047 Test MSE 0.0071311627831369025 Test RE 0.06101211104092493\n",
      "194 Train Loss 0.032299377 Test MSE 0.007193011962282335 Test RE 0.06127612143540995\n",
      "195 Train Loss 0.032222766 Test MSE 0.0073245575878455585 Test RE 0.061833890969877\n",
      "196 Train Loss 0.032158438 Test MSE 0.00755382600067299 Test RE 0.06279417591344685\n",
      "197 Train Loss 0.032043666 Test MSE 0.0076063543228091016 Test RE 0.06301212892589947\n",
      "198 Train Loss 0.03191933 Test MSE 0.007424347299415317 Test RE 0.062253678220136194\n",
      "199 Train Loss 0.031850282 Test MSE 0.007445203190882589 Test RE 0.062341055963438564\n",
      "200 Train Loss 0.031794563 Test MSE 0.007515140915311658 Test RE 0.06263317695863573\n",
      "201 Train Loss 0.031642973 Test MSE 0.0077394232146853785 Test RE 0.06356092001684031\n",
      "202 Train Loss 0.0314991 Test MSE 0.007841898635288662 Test RE 0.0639803319544526\n",
      "203 Train Loss 0.03129129 Test MSE 0.0077787076282090795 Test RE 0.06372202975663976\n",
      "204 Train Loss 0.031141661 Test MSE 0.007591081647447962 Test RE 0.06294883662368173\n",
      "205 Train Loss 0.03085471 Test MSE 0.007555482617238586 Test RE 0.06280106117723398\n",
      "206 Train Loss 0.030587517 Test MSE 0.007224535325374952 Test RE 0.06141024589669999\n",
      "207 Train Loss 0.030275451 Test MSE 0.00692152361363275 Test RE 0.060108616121325814\n",
      "208 Train Loss 0.030111982 Test MSE 0.006625538636574527 Test RE 0.058809362596593244\n",
      "209 Train Loss 0.029935967 Test MSE 0.006598987744879531 Test RE 0.05869140928310222\n",
      "210 Train Loss 0.029825484 Test MSE 0.0065360360123969 Test RE 0.05841079202202351\n",
      "211 Train Loss 0.029665517 Test MSE 0.006625064183287597 Test RE 0.058807256896479324\n",
      "212 Train Loss 0.029531013 Test MSE 0.006605015833332395 Test RE 0.05871821007891454\n",
      "213 Train Loss 0.029468238 Test MSE 0.0065078470267880975 Test RE 0.05828469723498128\n",
      "214 Train Loss 0.02934849 Test MSE 0.0065792275527285626 Test RE 0.058603469808763575\n",
      "215 Train Loss 0.029260578 Test MSE 0.006381013438956559 Test RE 0.05771393772951074\n",
      "216 Train Loss 0.029111559 Test MSE 0.006172133982506486 Test RE 0.05676145891318308\n",
      "217 Train Loss 0.028923329 Test MSE 0.006225120088685412 Test RE 0.05700457915849225\n",
      "218 Train Loss 0.02870354 Test MSE 0.0062158243006726925 Test RE 0.056962001630201126\n",
      "219 Train Loss 0.028447267 Test MSE 0.006147880231185529 Test RE 0.05664982544810478\n",
      "220 Train Loss 0.028231923 Test MSE 0.006301087796373405 Test RE 0.0573513496149702\n",
      "221 Train Loss 0.027592678 Test MSE 0.006049102427726022 Test RE 0.05619288710676784\n",
      "222 Train Loss 0.027172023 Test MSE 0.006094168624776096 Test RE 0.056401818977811984\n",
      "223 Train Loss 0.026986519 Test MSE 0.006123908070603118 Test RE 0.05653927147954218\n",
      "224 Train Loss 0.026801948 Test MSE 0.006064713377970117 Test RE 0.0562653490248716\n",
      "225 Train Loss 0.026684703 Test MSE 0.006221184421397986 Test RE 0.05698655649182494\n",
      "226 Train Loss 0.026569884 Test MSE 0.006199071323895392 Test RE 0.056885187445020656\n",
      "227 Train Loss 0.02640659 Test MSE 0.006246405372600841 Test RE 0.05710195263947292\n",
      "228 Train Loss 0.026296377 Test MSE 0.006297743846131368 Test RE 0.05733612958340456\n",
      "229 Train Loss 0.026090587 Test MSE 0.006247317234168494 Test RE 0.05710612041059873\n",
      "230 Train Loss 0.025961302 Test MSE 0.006456536409446017 Test RE 0.05805447194128399\n",
      "231 Train Loss 0.025612481 Test MSE 0.00645053445581671 Test RE 0.05802748214047888\n",
      "232 Train Loss 0.025341416 Test MSE 0.00645768284866452 Test RE 0.058059625863218646\n",
      "233 Train Loss 0.025215987 Test MSE 0.0061890537456140956 Test RE 0.05683920618492166\n",
      "234 Train Loss 0.025125545 Test MSE 0.006132957643098607 Test RE 0.05658103136109305\n",
      "235 Train Loss 0.024965491 Test MSE 0.005828781683303135 Test RE 0.05516006527895548\n",
      "236 Train Loss 0.024513572 Test MSE 0.005590183625153417 Test RE 0.05401929522420749\n",
      "237 Train Loss 0.024323642 Test MSE 0.005386399865822855 Test RE 0.05302554882115209\n",
      "238 Train Loss 0.024110535 Test MSE 0.005504772199277434 Test RE 0.05360503114267065\n",
      "239 Train Loss 0.023881674 Test MSE 0.0055465964065938116 Test RE 0.05380828619184657\n",
      "240 Train Loss 0.02374093 Test MSE 0.00560209977188363 Test RE 0.0540768388779133\n",
      "241 Train Loss 0.023598777 Test MSE 0.005569046698901875 Test RE 0.05391707289198733\n",
      "242 Train Loss 0.023410585 Test MSE 0.005542011416130575 Test RE 0.05378604178584678\n",
      "243 Train Loss 0.023248842 Test MSE 0.0055794439975754406 Test RE 0.05396738046985978\n",
      "244 Train Loss 0.023139253 Test MSE 0.0055059321848782514 Test RE 0.05361067876863919\n",
      "245 Train Loss 0.022971243 Test MSE 0.005326339751337064 Test RE 0.05272909403478702\n",
      "246 Train Loss 0.022815883 Test MSE 0.005032851293318768 Test RE 0.051255789345381754\n",
      "247 Train Loss 0.022713568 Test MSE 0.004741766491413705 Test RE 0.049751474723987936\n",
      "248 Train Loss 0.022648504 Test MSE 0.004718097208099854 Test RE 0.049627148172525164\n",
      "249 Train Loss 0.022568474 Test MSE 0.004699014745018303 Test RE 0.04952668736470205\n",
      "250 Train Loss 0.02246439 Test MSE 0.004680727342372551 Test RE 0.04943022061094685\n",
      "251 Train Loss 0.022298105 Test MSE 0.004644974997831025 Test RE 0.04924107972056169\n",
      "252 Train Loss 0.022210322 Test MSE 0.00452345779068303 Test RE 0.04859271310833025\n",
      "253 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "254 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "255 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "256 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "257 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "258 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "259 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "260 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "261 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "262 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "263 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "264 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "265 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "266 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "267 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "268 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "269 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "270 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "271 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "272 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "273 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "274 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "275 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "276 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "277 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "278 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "279 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "280 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "281 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "282 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "283 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "284 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "285 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "286 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "287 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "288 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "289 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "290 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "291 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "292 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "293 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "294 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "295 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "296 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "297 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "298 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "299 Train Loss 0.022179753 Test MSE 0.004488721850300861 Test RE 0.048405780172697935\n",
      "Training time: 496.29\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val = 5.0\n",
    "rowdy_terms = 6\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,rowdy_terms,n_val)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7860126ed0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.036912396256784705\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
