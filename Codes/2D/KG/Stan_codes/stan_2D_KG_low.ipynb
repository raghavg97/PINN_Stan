{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"low\"\n",
    "label = \"KG_stan_\" + level\n",
    "\n",
    "x = np.linspace(0,1,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        beta_mean = 1.0*torch.ones((50,len(layers)-2))\n",
    "        beta_std = 0.01*torch.ones((50,len(layers)-2))\n",
    "        \n",
    "        self.beta = Parameter(torch.normal(beta_mean,beta_std))\n",
    "        self.beta.requiresGrad = True\n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            z1 = self.activation(z)\n",
    "            a = z1 + self.beta[:,i]*z*z1            \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_stan_low\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 6381.0493 Test MSE 2.4670306726108975 Test RE 3.6757768528895207\n",
      "1 Train Loss 790.6183 Test MSE 4.024403344037048 Test RE 4.694751556932097\n",
      "2 Train Loss 52.822006 Test MSE 2.0616518003221307 Test RE 3.3602340077270716\n",
      "3 Train Loss 11.249435 Test MSE 0.4277868816963061 Test RE 1.53064894090514\n",
      "4 Train Loss 4.2645025 Test MSE 0.26247268662096146 Test RE 1.198957868886689\n",
      "5 Train Loss 1.6704066 Test MSE 0.06847015169701487 Test RE 0.6123680296267094\n",
      "6 Train Loss 0.90247625 Test MSE 0.02295685315627772 Test RE 0.35458310782715835\n",
      "7 Train Loss 0.57542026 Test MSE 0.01887073029510312 Test RE 0.3214816716054259\n",
      "8 Train Loss 0.40400454 Test MSE 0.021563375586545183 Test RE 0.34365307771358933\n",
      "9 Train Loss 0.2795326 Test MSE 0.01420958221964765 Test RE 0.2789667986977101\n",
      "10 Train Loss 0.16230817 Test MSE 0.0118639298744971 Test RE 0.2549037059360752\n",
      "11 Train Loss 0.12070838 Test MSE 0.00544109391526612 Test RE 0.1726255101630677\n",
      "12 Train Loss 0.09196811 Test MSE 0.0032683801798406094 Test RE 0.13379138456272013\n",
      "13 Train Loss 0.060381018 Test MSE 0.004400387559171684 Test RE 0.155241320458225\n",
      "14 Train Loss 0.048991956 Test MSE 0.001973816751110343 Test RE 0.10397173213149385\n",
      "15 Train Loss 0.03995249 Test MSE 0.001546023345101004 Test RE 0.0920173851510188\n",
      "16 Train Loss 0.03452195 Test MSE 0.0020111973414240793 Test RE 0.10495163463615723\n",
      "17 Train Loss 0.030752102 Test MSE 0.002016749539267573 Test RE 0.10509640178967085\n",
      "18 Train Loss 0.024894344 Test MSE 0.0020589514480523407 Test RE 0.10619031690681234\n",
      "19 Train Loss 0.021270366 Test MSE 0.0018022430669158243 Test RE 0.09935015426475549\n",
      "20 Train Loss 0.01928832 Test MSE 0.001691939428424683 Test RE 0.09626186457779873\n",
      "21 Train Loss 0.017927356 Test MSE 0.0020798897440967527 Test RE 0.10672889689214793\n",
      "22 Train Loss 0.014760857 Test MSE 0.001975027630160471 Test RE 0.10400361905552782\n",
      "23 Train Loss 0.01263229 Test MSE 0.0015708781365221212 Test RE 0.09275409911801126\n",
      "24 Train Loss 0.011990198 Test MSE 0.0016698622873416616 Test RE 0.0956317696361107\n",
      "25 Train Loss 0.010751572 Test MSE 0.0016234107404281923 Test RE 0.09429226574331864\n",
      "26 Train Loss 0.00982884 Test MSE 0.0013368241461582191 Test RE 0.08556556151430315\n",
      "27 Train Loss 0.008830574 Test MSE 0.0012298174902974246 Test RE 0.08206957731198782\n",
      "28 Train Loss 0.008500117 Test MSE 0.0011882047862427423 Test RE 0.08066915592447772\n",
      "29 Train Loss 0.0074434397 Test MSE 0.0009432725461052073 Test RE 0.07187543089197534\n",
      "30 Train Loss 0.007120794 Test MSE 0.0009418910692597376 Test RE 0.07182277875759294\n",
      "31 Train Loss 0.006092838 Test MSE 0.0007740440306209751 Test RE 0.06510955047178749\n",
      "32 Train Loss 0.0057547954 Test MSE 0.0007735194457045632 Test RE 0.06508748371869312\n",
      "33 Train Loss 0.0050615394 Test MSE 0.0007053135190409675 Test RE 0.06215169370400827\n",
      "34 Train Loss 0.0049699405 Test MSE 0.0006459947503735496 Test RE 0.05948073937996756\n",
      "35 Train Loss 0.004699346 Test MSE 0.0006587194236429699 Test RE 0.060063702364077785\n",
      "36 Train Loss 0.0044975327 Test MSE 0.0005431852364774901 Test RE 0.054542600784040295\n",
      "37 Train Loss 0.0042982223 Test MSE 0.0004987641152172508 Test RE 0.05226482057778298\n",
      "38 Train Loss 0.004044786 Test MSE 0.0004477727360609054 Test RE 0.04952114611584436\n",
      "39 Train Loss 0.0039115925 Test MSE 0.0004266333990873449 Test RE 0.04833806815146909\n",
      "40 Train Loss 0.003648541 Test MSE 0.0003765080278678587 Test RE 0.04540973676472797\n",
      "41 Train Loss 0.0035741695 Test MSE 0.0003524844405729337 Test RE 0.0439371456239448\n",
      "42 Train Loss 0.003356824 Test MSE 0.00030194675887039034 Test RE 0.04066558742167405\n",
      "43 Train Loss 0.0033237978 Test MSE 0.0002760471697185176 Test RE 0.038882440259420704\n",
      "44 Train Loss 0.0030198263 Test MSE 0.00023037713262685268 Test RE 0.03552070266355618\n",
      "45 Train Loss 0.0029423325 Test MSE 0.00020562161220842495 Test RE 0.03355801346965132\n",
      "46 Train Loss 0.0028013682 Test MSE 0.000162581093625713 Test RE 0.029839867084266808\n",
      "47 Train Loss 0.0026008224 Test MSE 0.00014501135996704238 Test RE 0.028181420281195337\n",
      "48 Train Loss 0.00255942 Test MSE 0.00015859573630257545 Test RE 0.029471864907395468\n",
      "49 Train Loss 0.0023624664 Test MSE 0.0001655810844630242 Test RE 0.030113915356738057\n",
      "50 Train Loss 0.0022333239 Test MSE 0.0001713183921846078 Test RE 0.030631189282586718\n",
      "51 Train Loss 0.0021950982 Test MSE 0.0001605994933380501 Test RE 0.029657459735467098\n",
      "52 Train Loss 0.0020619314 Test MSE 0.00015446009076277998 Test RE 0.029085062869192865\n",
      "53 Train Loss 0.0019048565 Test MSE 0.00011185535227566963 Test RE 0.024750857455422156\n",
      "54 Train Loss 0.0018613262 Test MSE 0.00010999025769721617 Test RE 0.024543640092037182\n",
      "55 Train Loss 0.0018124036 Test MSE 0.00010875626318718357 Test RE 0.024405572661007645\n",
      "56 Train Loss 0.001518316 Test MSE 0.00013835823181125798 Test RE 0.02752734751808242\n",
      "57 Train Loss 0.0015083473 Test MSE 0.00013520733924089407 Test RE 0.02721209617550782\n",
      "58 Train Loss 0.0014454125 Test MSE 0.00016242158237681937 Test RE 0.029825225275639435\n",
      "59 Train Loss 0.0013034483 Test MSE 0.0001616263187550706 Test RE 0.02975211916094772\n",
      "60 Train Loss 0.0012628462 Test MSE 0.00013662123948131061 Test RE 0.02735400831450502\n",
      "61 Train Loss 0.0012388544 Test MSE 0.00013200189872555448 Test RE 0.026887594707099827\n",
      "62 Train Loss 0.0012015098 Test MSE 0.00015846710892760289 Test RE 0.02945991106280055\n",
      "63 Train Loss 0.0010964542 Test MSE 0.00014694216142602102 Test RE 0.028368415283667008\n",
      "64 Train Loss 0.0010499232 Test MSE 0.0001355070067034886 Test RE 0.027242235317723885\n",
      "65 Train Loss 0.0010383622 Test MSE 0.00013135899599904633 Test RE 0.026822038048019567\n",
      "66 Train Loss 0.0010243916 Test MSE 0.00012986773984979434 Test RE 0.026669354560608975\n",
      "67 Train Loss 0.0009776655 Test MSE 0.00012847856987756125 Test RE 0.026526332611648374\n",
      "68 Train Loss 0.00093939016 Test MSE 0.00013492853031254 Test RE 0.027184024878864087\n",
      "69 Train Loss 0.0009291221 Test MSE 0.00013378809574550395 Test RE 0.027068899533114206\n",
      "70 Train Loss 0.00092274434 Test MSE 0.000126439663323281 Test RE 0.026315009395704986\n",
      "71 Train Loss 0.00091491593 Test MSE 0.00012789209531676284 Test RE 0.026465720116288505\n",
      "72 Train Loss 0.0008787521 Test MSE 0.00011701729577551295 Test RE 0.025315522345875134\n",
      "73 Train Loss 0.00085096876 Test MSE 0.00010973265431884711 Test RE 0.024514881950151574\n",
      "74 Train Loss 0.00084517634 Test MSE 0.00011093394065007491 Test RE 0.024648703702887645\n",
      "75 Train Loss 0.00083670503 Test MSE 0.00011169315920204249 Test RE 0.024732906262781098\n",
      "76 Train Loss 0.00083094777 Test MSE 0.00011047393367658385 Test RE 0.02459754553477089\n",
      "77 Train Loss 0.00080930477 Test MSE 0.00010158955785809126 Test RE 0.023587743643472575\n",
      "78 Train Loss 0.0007826008 Test MSE 7.792884393825632e-05 Test RE 0.020659080163380805\n",
      "79 Train Loss 0.0007653687 Test MSE 7.635124369707371e-05 Test RE 0.020448898624090703\n",
      "80 Train Loss 0.0007574614 Test MSE 7.829323966139355e-05 Test RE 0.02070732482000517\n",
      "81 Train Loss 0.0007439712 Test MSE 7.467115870187959e-05 Test RE 0.02022266135440146\n",
      "82 Train Loss 0.0006851964 Test MSE 6.554158007112351e-05 Test RE 0.018946121479066283\n",
      "83 Train Loss 0.0006280437 Test MSE 6.309081428334925e-05 Test RE 0.01858852502222019\n",
      "84 Train Loss 0.00059675495 Test MSE 6.038690363481789e-05 Test RE 0.018185834932667427\n",
      "85 Train Loss 0.00058465154 Test MSE 6.018584765886019e-05 Test RE 0.01815553515667432\n",
      "86 Train Loss 0.00057431706 Test MSE 5.7674573001389796e-05 Test RE 0.017772726511605757\n",
      "87 Train Loss 0.00056723016 Test MSE 5.2608700147812816e-05 Test RE 0.016974252168656282\n",
      "88 Train Loss 0.00055714126 Test MSE 5.080725412327455e-05 Test RE 0.01668110154464316\n",
      "89 Train Loss 0.00054375076 Test MSE 4.8876835022297744e-05 Test RE 0.016361134012792943\n",
      "90 Train Loss 0.0005273939 Test MSE 4.7529427433240276e-05 Test RE 0.016134040965863208\n",
      "91 Train Loss 0.0005161555 Test MSE 4.630800478478944e-05 Test RE 0.01592538347745324\n",
      "92 Train Loss 0.0005018161 Test MSE 4.433710170385335e-05 Test RE 0.015582800624228278\n",
      "93 Train Loss 0.00048886763 Test MSE 4.3163637690637376e-05 Test RE 0.015375203876903347\n",
      "94 Train Loss 0.00048346005 Test MSE 4.401846550368747e-05 Test RE 0.015526705420847105\n",
      "95 Train Loss 0.00047937967 Test MSE 4.68269619144343e-05 Test RE 0.016014369880588356\n",
      "96 Train Loss 0.00047508487 Test MSE 4.619699408402781e-05 Test RE 0.015906283661276187\n",
      "97 Train Loss 0.0004631273 Test MSE 4.785846077011052e-05 Test RE 0.016189790442795723\n",
      "98 Train Loss 0.0004514353 Test MSE 4.8571793969494364e-05 Test RE 0.016309999064324628\n",
      "99 Train Loss 0.00044213547 Test MSE 4.847080620468395e-05 Test RE 0.01629303482179762\n",
      "100 Train Loss 0.00042450713 Test MSE 5.4437934407392824e-05 Test RE 0.017266832776397883\n",
      "101 Train Loss 0.0004176704 Test MSE 5.6566230124505714e-05 Test RE 0.017601127221509954\n",
      "102 Train Loss 0.00041157915 Test MSE 5.442240306140903e-05 Test RE 0.01726436945474976\n",
      "103 Train Loss 0.00040880626 Test MSE 5.397237946389484e-05 Test RE 0.0171928409906269\n",
      "104 Train Loss 0.00040736469 Test MSE 5.354272691527497e-05 Test RE 0.01712427158562601\n",
      "105 Train Loss 0.00040422633 Test MSE 5.208232592239111e-05 Test RE 0.016889121092040583\n",
      "106 Train Loss 0.00040050107 Test MSE 4.995006985058463e-05 Test RE 0.016539787060565192\n",
      "107 Train Loss 0.0003968357 Test MSE 4.970327644578489e-05 Test RE 0.01649887655886234\n",
      "108 Train Loss 0.00039358437 Test MSE 4.8794250092486495e-05 Test RE 0.016347305843026228\n",
      "109 Train Loss 0.00038963882 Test MSE 4.748609632110274e-05 Test RE 0.016126684835281728\n",
      "110 Train Loss 0.0003822891 Test MSE 4.633731778917173e-05 Test RE 0.01593042307035639\n",
      "111 Train Loss 0.00037512247 Test MSE 4.393841267501862e-05 Test RE 0.015512580413247363\n",
      "112 Train Loss 0.00037193505 Test MSE 4.53333339256321e-05 Test RE 0.015756896912331512\n",
      "113 Train Loss 0.0003695262 Test MSE 4.511901211670865e-05 Test RE 0.015719605947556604\n",
      "114 Train Loss 0.00036730437 Test MSE 4.517975571314444e-05 Test RE 0.015730184018618525\n",
      "115 Train Loss 0.00036376333 Test MSE 4.4505903629159477e-05 Test RE 0.015612436163699641\n",
      "116 Train Loss 0.00036149033 Test MSE 4.527546540985371e-05 Test RE 0.015746836771875744\n",
      "117 Train Loss 0.0003598871 Test MSE 4.594223193031994e-05 Test RE 0.015862363905850278\n",
      "118 Train Loss 0.00035577524 Test MSE 4.516277838498994e-05 Test RE 0.015727228252427863\n",
      "119 Train Loss 0.00034809692 Test MSE 4.7126405427570574e-05 Test RE 0.016065491682359566\n",
      "120 Train Loss 0.00033720658 Test MSE 4.824835174891142e-05 Test RE 0.0162556037718721\n",
      "121 Train Loss 0.00033150168 Test MSE 4.745553034003225e-05 Test RE 0.016121493765374507\n",
      "122 Train Loss 0.00032571715 Test MSE 4.9993062521561307e-05 Test RE 0.01654690353387596\n",
      "123 Train Loss 0.00031988794 Test MSE 4.8578508844837686e-05 Test RE 0.01631112642463712\n",
      "124 Train Loss 0.00031587493 Test MSE 4.7537801212244536e-05 Test RE 0.01613546215848718\n",
      "125 Train Loss 0.00031333376 Test MSE 4.8816439759240173e-05 Test RE 0.016351022469858506\n",
      "126 Train Loss 0.00031066613 Test MSE 4.810972334571083e-05 Test RE 0.01623223396402359\n",
      "127 Train Loss 0.00030623784 Test MSE 4.8057730546711684e-05 Test RE 0.01622346040057521\n",
      "128 Train Loss 0.00030215475 Test MSE 4.787296870349884e-05 Test RE 0.016192244163618284\n",
      "129 Train Loss 0.0002970362 Test MSE 4.679649122906982e-05 Test RE 0.01600915869227773\n",
      "130 Train Loss 0.00028984965 Test MSE 4.326699876256256e-05 Test RE 0.015393601854807152\n",
      "131 Train Loss 0.00028517735 Test MSE 4.337788835564352e-05 Test RE 0.015413315469993864\n",
      "132 Train Loss 0.0002821104 Test MSE 4.305240849607221e-05 Test RE 0.015355380771156779\n",
      "133 Train Loss 0.00027635362 Test MSE 4.389017491017242e-05 Test RE 0.015504062835444305\n",
      "134 Train Loss 0.00027046408 Test MSE 4.445156996259512e-05 Test RE 0.015602903271553158\n",
      "135 Train Loss 0.00026305992 Test MSE 4.517965293892882e-05 Test RE 0.015730166127217636\n",
      "136 Train Loss 0.00026074165 Test MSE 4.550896072987654e-05 Test RE 0.01578738946762664\n",
      "137 Train Loss 0.0002591573 Test MSE 4.657174936898466e-05 Test RE 0.015970670141022773\n",
      "138 Train Loss 0.00025739727 Test MSE 4.718223845375285e-05 Test RE 0.016075005663863433\n",
      "139 Train Loss 0.00025559674 Test MSE 4.598856631632939e-05 Test RE 0.015870360771077882\n",
      "140 Train Loss 0.00025377818 Test MSE 4.6468779495748334e-05 Test RE 0.01595300484068123\n",
      "141 Train Loss 0.00025048663 Test MSE 4.589864266369603e-05 Test RE 0.015854837139489982\n",
      "142 Train Loss 0.00024661934 Test MSE 4.4314299663848805e-05 Test RE 0.015578793085107885\n",
      "143 Train Loss 0.00023715649 Test MSE 4.164648897134142e-05 Test RE 0.015102577081033491\n",
      "144 Train Loss 0.00023224961 Test MSE 4.1863053984054784e-05 Test RE 0.015141793458413244\n",
      "145 Train Loss 0.00022730665 Test MSE 4.094754211232469e-05 Test RE 0.014975308682250776\n",
      "146 Train Loss 0.0002240139 Test MSE 4.045322416380978e-05 Test RE 0.014884643403442217\n",
      "147 Train Loss 0.00022095075 Test MSE 4.059059407830475e-05 Test RE 0.014909894410492829\n",
      "148 Train Loss 0.00021922715 Test MSE 4.040383156663207e-05 Test RE 0.014875553698460798\n",
      "149 Train Loss 0.00021754795 Test MSE 3.762241409797243e-05 Test RE 0.014354404942815743\n",
      "150 Train Loss 0.00021580461 Test MSE 3.703765721649859e-05 Test RE 0.01424241440311519\n",
      "151 Train Loss 0.0002142666 Test MSE 3.663712736244344e-05 Test RE 0.014165195447106373\n",
      "152 Train Loss 0.00021188473 Test MSE 3.4469564657936915e-05 Test RE 0.013739779504786475\n",
      "153 Train Loss 0.00021022423 Test MSE 3.458045493348016e-05 Test RE 0.01376186252987083\n",
      "154 Train Loss 0.00020784297 Test MSE 3.336278281351299e-05 Test RE 0.013517394795303174\n",
      "155 Train Loss 0.00020432504 Test MSE 3.1977506642916763e-05 Test RE 0.01323378768963594\n",
      "156 Train Loss 0.00019895786 Test MSE 2.907282584416769e-05 Test RE 0.01261843478157795\n",
      "157 Train Loss 0.00019548097 Test MSE 3.108280790982633e-05 Test RE 0.013047340195448185\n",
      "158 Train Loss 0.00019245276 Test MSE 2.825566711378645e-05 Test RE 0.012439835766655137\n",
      "159 Train Loss 0.00019049199 Test MSE 2.654620860532692e-05 Test RE 0.012057662274610652\n",
      "160 Train Loss 0.00018997164 Test MSE 2.5804585661987103e-05 Test RE 0.011888041406697034\n",
      "161 Train Loss 0.00018850231 Test MSE 2.5204197090415854e-05 Test RE 0.01174892949321046\n",
      "162 Train Loss 0.00018697718 Test MSE 2.5104075967164995e-05 Test RE 0.011725570555435529\n",
      "163 Train Loss 0.00018637489 Test MSE 2.5498197970752932e-05 Test RE 0.011817255035127332\n",
      "164 Train Loss 0.00018563913 Test MSE 2.562818026648471e-05 Test RE 0.011847337187445128\n",
      "165 Train Loss 0.0001855933 Test MSE 2.55177579212525e-05 Test RE 0.011821786739923264\n",
      "166 Train Loss 0.00018463124 Test MSE 2.4932707965475436e-05 Test RE 0.011685480879889682\n",
      "167 Train Loss 0.0001837955 Test MSE 2.4349919399057402e-05 Test RE 0.011548102448091355\n",
      "168 Train Loss 0.0001820868 Test MSE 2.4349383988572323e-05 Test RE 0.011547975486498168\n",
      "169 Train Loss 0.00018061585 Test MSE 2.3972256343642263e-05 Test RE 0.011458197945123703\n",
      "170 Train Loss 0.00017877476 Test MSE 2.363196271420024e-05 Test RE 0.011376580924584597\n",
      "171 Train Loss 0.00017706897 Test MSE 2.4931164052394247e-05 Test RE 0.011685119073099203\n",
      "172 Train Loss 0.00017424073 Test MSE 2.531892415352312e-05 Test RE 0.011775639127150673\n",
      "173 Train Loss 0.00017059805 Test MSE 2.6592343481139736e-05 Test RE 0.012068135281873693\n",
      "174 Train Loss 0.00016831885 Test MSE 2.7273467867539942e-05 Test RE 0.012221711996780698\n",
      "175 Train Loss 0.00016646255 Test MSE 2.697673597001392e-05 Test RE 0.012155044824150816\n",
      "176 Train Loss 0.00016411778 Test MSE 2.5011701309614455e-05 Test RE 0.011703977571741499\n",
      "177 Train Loss 0.00016195151 Test MSE 2.2739660295301837e-05 Test RE 0.011159734187393706\n",
      "178 Train Loss 0.0001605702 Test MSE 2.2157546440532578e-05 Test RE 0.011015968823692018\n",
      "179 Train Loss 0.00015904324 Test MSE 2.1458512794123547e-05 Test RE 0.01084080852385805\n",
      "180 Train Loss 0.0001577738 Test MSE 2.163935326406308e-05 Test RE 0.010886392852757406\n",
      "181 Train Loss 0.00015770954 Test MSE 2.1697911651373972e-05 Test RE 0.010901112768487639\n",
      "182 Train Loss 0.00015680278 Test MSE 2.166484715843057e-05 Test RE 0.010892803738768523\n",
      "183 Train Loss 0.00015676109 Test MSE 2.154935080933548e-05 Test RE 0.010863729906435233\n",
      "184 Train Loss 0.0001562778 Test MSE 2.1192163668934247e-05 Test RE 0.010773318855162764\n",
      "185 Train Loss 0.00015600598 Test MSE 2.0677787912502406e-05 Test RE 0.010641770833336877\n",
      "186 Train Loss 0.000155824 Test MSE 2.0422304945834093e-05 Test RE 0.010575824673194274\n",
      "187 Train Loss 0.00015576539 Test MSE 2.0205621746176835e-05 Test RE 0.01051956964841731\n",
      "188 Train Loss 0.00015545414 Test MSE 2.0042410082732144e-05 Test RE 0.010476997396229017\n",
      "189 Train Loss 0.00015535072 Test MSE 2.0184147797172096e-05 Test RE 0.010513978215596005\n",
      "190 Train Loss 0.0001553128 Test MSE 2.01273127130921e-05 Test RE 0.01049916500441386\n",
      "191 Train Loss 0.0001552777 Test MSE 2.0208371481636214e-05 Test RE 0.010520285415791144\n",
      "192 Train Loss 0.0001545839 Test MSE 2.01673758435321e-05 Test RE 0.010509609029329495\n",
      "193 Train Loss 0.00015437273 Test MSE 2.0023586488049943e-05 Test RE 0.010472076304432733\n",
      "194 Train Loss 0.00015393227 Test MSE 1.9947598767875248e-05 Test RE 0.010452187120507026\n",
      "195 Train Loss 0.00015376629 Test MSE 1.999887500490509e-05 Test RE 0.010465612416756441\n",
      "196 Train Loss 0.00015368259 Test MSE 1.9982724940992106e-05 Test RE 0.010461385817855452\n",
      "197 Train Loss 0.00015232629 Test MSE 1.8634203525051204e-05 Test RE 0.010102230682915131\n",
      "198 Train Loss 0.0001510091 Test MSE 1.8232037215531405e-05 Test RE 0.00999262209438975\n",
      "199 Train Loss 0.0001507373 Test MSE 1.7969084657847945e-05 Test RE 0.009920300812534397\n",
      "200 Train Loss 0.00014969146 Test MSE 1.6567695073302225e-05 Test RE 0.009525612498352225\n",
      "201 Train Loss 0.00014885509 Test MSE 1.6468309140962455e-05 Test RE 0.009496998502009623\n",
      "202 Train Loss 0.00014771742 Test MSE 1.589224762974121e-05 Test RE 0.009329417440166422\n",
      "203 Train Loss 0.00014626242 Test MSE 1.5979212518846522e-05 Test RE 0.0093549086376554\n",
      "204 Train Loss 0.00014462114 Test MSE 1.728367018791527e-05 Test RE 0.009729260891848418\n",
      "205 Train Loss 0.00014294716 Test MSE 1.764540932706185e-05 Test RE 0.009830548104369017\n",
      "206 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "207 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "208 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "209 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "210 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "211 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "212 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "213 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "214 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "215 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "216 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "217 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "218 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "219 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "220 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "221 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "222 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "223 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "224 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "225 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "226 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "227 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "228 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "229 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "230 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "231 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "232 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "233 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "234 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "235 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "236 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "237 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "238 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "239 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "240 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "241 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "242 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "243 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "244 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "245 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "246 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "247 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "248 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "249 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "250 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "251 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "252 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "253 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "254 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "255 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "256 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "257 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "258 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "259 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "260 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "261 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "262 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "263 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "264 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "265 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "266 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "267 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "268 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "269 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "270 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "271 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "272 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "273 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "274 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "275 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "276 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "277 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "278 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "279 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "280 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "281 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "282 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "283 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "284 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "285 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "286 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "287 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "288 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "289 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "290 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "291 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "292 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "293 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "294 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "295 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "296 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "297 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "298 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "299 Train Loss 0.00014291191 Test MSE 1.7663137369739316e-05 Test RE 0.00983548515688945\n",
      "Training time: 121.36\n",
      "KG_stan_low\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 9218.718 Test MSE 0.5135787099155913 Test RE 1.6771247577580612\n",
      "1 Train Loss 1446.8925 Test MSE 0.4321413216617289 Test RE 1.5384194499282582\n",
      "2 Train Loss 60.430157 Test MSE 0.153806866066387 Test RE 0.9178035340239733\n",
      "3 Train Loss 17.154964 Test MSE 0.18285492102463954 Test RE 1.0007260160508502\n",
      "4 Train Loss 7.0445786 Test MSE 0.1833248287410444 Test RE 1.0020110433990521\n",
      "5 Train Loss 2.9199462 Test MSE 0.16788887311929648 Test RE 0.9588989014714245\n",
      "6 Train Loss 1.3100832 Test MSE 0.186774876377088 Test RE 1.0113956766646566\n",
      "7 Train Loss 0.8161461 Test MSE 0.13336773464857546 Test RE 0.854647942135371\n",
      "8 Train Loss 0.5013718 Test MSE 0.066725474585688 Test RE 0.6045158604144308\n",
      "9 Train Loss 0.35482737 Test MSE 0.0498909926590085 Test RE 0.5227245970829729\n",
      "10 Train Loss 0.2528244 Test MSE 0.05678428360540256 Test RE 0.5576682760385575\n",
      "11 Train Loss 0.18075824 Test MSE 0.06653917978233284 Test RE 0.6036713787506056\n",
      "12 Train Loss 0.13983372 Test MSE 0.053739703922165344 Test RE 0.5425121871218228\n",
      "13 Train Loss 0.099853136 Test MSE 0.03659151562639326 Test RE 0.44766388899791076\n",
      "14 Train Loss 0.08660808 Test MSE 0.03833236658478159 Test RE 0.458189023009923\n",
      "15 Train Loss 0.073691204 Test MSE 0.036558059299980926 Test RE 0.4474591883455071\n",
      "16 Train Loss 0.061562385 Test MSE 0.03406958172779854 Test RE 0.4319617231144057\n",
      "17 Train Loss 0.04727444 Test MSE 0.025194046814562533 Test RE 0.3714589527919885\n",
      "18 Train Loss 0.04367883 Test MSE 0.024610394641219387 Test RE 0.36713108094876107\n",
      "19 Train Loss 0.03930024 Test MSE 0.02296595375360711 Test RE 0.3546533831022663\n",
      "20 Train Loss 0.03691502 Test MSE 0.02130526458413148 Test RE 0.3415901429333934\n",
      "21 Train Loss 0.03331944 Test MSE 0.01912099093808285 Test RE 0.3236063700155658\n",
      "22 Train Loss 0.02844654 Test MSE 0.015378683169878834 Test RE 0.29021605807384454\n",
      "23 Train Loss 0.026603032 Test MSE 0.015377989757220585 Test RE 0.29020951519385424\n",
      "24 Train Loss 0.02470381 Test MSE 0.011655004736585789 Test RE 0.25264929529632524\n",
      "25 Train Loss 0.021862704 Test MSE 0.00916904712959922 Test RE 0.22409076879702108\n",
      "26 Train Loss 0.020782169 Test MSE 0.01028371619930545 Test RE 0.23732140208975422\n",
      "27 Train Loss 0.017440133 Test MSE 0.006931156122898289 Test RE 0.1948339811147279\n",
      "28 Train Loss 0.01683025 Test MSE 0.005931478920036741 Test RE 0.18023675499252687\n",
      "29 Train Loss 0.013895731 Test MSE 0.004083550453805699 Test RE 0.14954807494506842\n",
      "30 Train Loss 0.012690494 Test MSE 0.0029315448906147906 Test RE 0.1267097804723465\n",
      "31 Train Loss 0.0112009775 Test MSE 0.0025604148947810626 Test RE 0.11841781312904248\n",
      "32 Train Loss 0.010230374 Test MSE 0.0026036211726919983 Test RE 0.11941276686679637\n",
      "33 Train Loss 0.009630023 Test MSE 0.0019444087479031217 Test RE 0.10319428521015318\n",
      "34 Train Loss 0.009430234 Test MSE 0.0018172707919096463 Test RE 0.09976350233935181\n",
      "35 Train Loss 0.008104143 Test MSE 0.0016622807538900245 Test RE 0.09541442827397256\n",
      "36 Train Loss 0.0077994238 Test MSE 0.0016868308614239546 Test RE 0.09611643030937071\n",
      "37 Train Loss 0.0074635083 Test MSE 0.0014179429474539419 Test RE 0.08812339951479145\n",
      "38 Train Loss 0.0067996946 Test MSE 0.0014032079595383848 Test RE 0.08766432310950845\n",
      "39 Train Loss 0.0065887948 Test MSE 0.0013739482107231736 Test RE 0.08674551814138642\n",
      "40 Train Loss 0.0062722885 Test MSE 0.0012894811986289977 Test RE 0.0840367737665585\n",
      "41 Train Loss 0.005793904 Test MSE 0.0013002166122803446 Test RE 0.08438586748752784\n",
      "42 Train Loss 0.0055966675 Test MSE 0.0012543408002566253 Test RE 0.0828837970223607\n",
      "43 Train Loss 0.004791624 Test MSE 0.0011537705198934214 Test RE 0.07949166306664074\n",
      "44 Train Loss 0.0047008325 Test MSE 0.0011211764782838815 Test RE 0.07836079853026509\n",
      "45 Train Loss 0.0044386247 Test MSE 0.001036536712227559 Test RE 0.07534496029427314\n",
      "46 Train Loss 0.0042433464 Test MSE 0.0009945120913566687 Test RE 0.07380179042210397\n",
      "47 Train Loss 0.0041493066 Test MSE 0.001014388269131264 Test RE 0.07453563798247598\n",
      "48 Train Loss 0.0038730223 Test MSE 0.0010033467258676358 Test RE 0.0741288705191054\n",
      "49 Train Loss 0.0038353787 Test MSE 0.0010432680349217705 Test RE 0.07558921141385118\n",
      "50 Train Loss 0.0035015051 Test MSE 0.0010412643670437323 Test RE 0.07551658939346183\n",
      "51 Train Loss 0.0034622145 Test MSE 0.0010371910739651903 Test RE 0.0753687390373876\n",
      "52 Train Loss 0.00323607 Test MSE 0.0009251585238149826 Test RE 0.07118195985666047\n",
      "53 Train Loss 0.003105185 Test MSE 0.0008737863860507997 Test RE 0.06917744233515583\n",
      "54 Train Loss 0.0030706748 Test MSE 0.000826716841528331 Test RE 0.06728840850088157\n",
      "55 Train Loss 0.002911412 Test MSE 0.0007809238403236034 Test RE 0.06539826168028323\n",
      "56 Train Loss 0.002716272 Test MSE 0.0007924651642211163 Test RE 0.06587975177942205\n",
      "57 Train Loss 0.0026296747 Test MSE 0.0007265143721373092 Test RE 0.0630788793443757\n",
      "58 Train Loss 0.002592767 Test MSE 0.0006902524245781433 Test RE 0.06148452672919434\n",
      "59 Train Loss 0.002561246 Test MSE 0.0006650327346128673 Test RE 0.060350847816047395\n",
      "60 Train Loss 0.0024853693 Test MSE 0.0006262380659135463 Test RE 0.05856411643211302\n",
      "61 Train Loss 0.002342906 Test MSE 0.0005503139889796737 Test RE 0.05489934214975379\n",
      "62 Train Loss 0.0022080012 Test MSE 0.0005054037104060344 Test RE 0.05261154760027955\n",
      "63 Train Loss 0.0021708943 Test MSE 0.000527299798165789 Test RE 0.05373913437632338\n",
      "64 Train Loss 0.0021338458 Test MSE 0.0005094408295268879 Test RE 0.05282125778830479\n",
      "65 Train Loss 0.00203706 Test MSE 0.0004955275207305472 Test RE 0.05209496538116393\n",
      "66 Train Loss 0.0019435579 Test MSE 0.000498291616698787 Test RE 0.052240058469851615\n",
      "67 Train Loss 0.0018978493 Test MSE 0.00045784397676989596 Test RE 0.05007496064103889\n",
      "68 Train Loss 0.0018695378 Test MSE 0.0004722185961446047 Test RE 0.05085497052309087\n",
      "69 Train Loss 0.0018469237 Test MSE 0.00045092494001778524 Test RE 0.049695148434153145\n",
      "70 Train Loss 0.0018065805 Test MSE 0.00043831932718414496 Test RE 0.04899561060808588\n",
      "71 Train Loss 0.0017497651 Test MSE 0.0004153960709622645 Test RE 0.047697218795826495\n",
      "72 Train Loss 0.001680489 Test MSE 0.0004040206295153388 Test RE 0.04703960156665445\n",
      "73 Train Loss 0.0016351237 Test MSE 0.0003971938461032387 Test RE 0.04664049163188688\n",
      "74 Train Loss 0.0016010959 Test MSE 0.00042665656260548436 Test RE 0.048339380360643724\n",
      "75 Train Loss 0.0015754373 Test MSE 0.0004492046325089785 Test RE 0.04960026276287355\n",
      "76 Train Loss 0.0015631457 Test MSE 0.00045073092017235085 Test RE 0.04968445609765031\n",
      "77 Train Loss 0.0015424216 Test MSE 0.00044225061434990693 Test RE 0.049214841014257195\n",
      "78 Train Loss 0.001520478 Test MSE 0.00043370525225046 Test RE 0.04873704624582131\n",
      "79 Train Loss 0.0014763444 Test MSE 0.0003940146850744973 Test RE 0.04645346011848132\n",
      "80 Train Loss 0.0014060499 Test MSE 0.00035545528448137305 Test RE 0.04412191479690059\n",
      "81 Train Loss 0.0013718808 Test MSE 0.0003259468641439819 Test RE 0.04225083220969058\n",
      "82 Train Loss 0.0013531359 Test MSE 0.0003347271329156042 Test RE 0.04281612137060623\n",
      "83 Train Loss 0.0013397862 Test MSE 0.0003213749311120257 Test RE 0.041953467573145234\n",
      "84 Train Loss 0.0013268059 Test MSE 0.00031700361476048194 Test RE 0.04166716680873673\n",
      "85 Train Loss 0.0013097313 Test MSE 0.0003015620511428251 Test RE 0.0406396733299811\n",
      "86 Train Loss 0.0012766531 Test MSE 0.00028057926060715146 Test RE 0.03920032315762078\n",
      "87 Train Loss 0.0012131095 Test MSE 0.0002711471999457792 Test RE 0.03853580414304696\n",
      "88 Train Loss 0.0011879121 Test MSE 0.0002653411961480369 Test RE 0.03812099303875214\n",
      "89 Train Loss 0.0011790423 Test MSE 0.00026744188980119734 Test RE 0.03827159659217495\n",
      "90 Train Loss 0.0011749169 Test MSE 0.00025802116312286086 Test RE 0.03759148899034304\n",
      "91 Train Loss 0.0011635561 Test MSE 0.0002440994722467068 Test RE 0.036563291449154885\n",
      "92 Train Loss 0.0011431301 Test MSE 0.0002197060429848414 Test RE 0.03468828791332919\n",
      "93 Train Loss 0.0011160517 Test MSE 0.00021542793346877398 Test RE 0.03434890301456215\n",
      "94 Train Loss 0.0010603716 Test MSE 0.00021927602173093595 Test RE 0.03465432433415594\n",
      "95 Train Loss 0.0010271851 Test MSE 0.0002122022813193045 Test RE 0.03409077609703248\n",
      "96 Train Loss 0.0010132546 Test MSE 0.00021034728174059374 Test RE 0.033941444090962516\n",
      "97 Train Loss 0.0010033178 Test MSE 0.00019881310916530735 Test RE 0.03299775339840018\n",
      "98 Train Loss 0.0009987988 Test MSE 0.00019887574088397136 Test RE 0.03300295059911314\n",
      "99 Train Loss 0.0009912576 Test MSE 0.00019021363889251252 Test RE 0.032276221782582784\n",
      "100 Train Loss 0.0009817008 Test MSE 0.00018206721929866357 Test RE 0.03157749999153865\n",
      "101 Train Loss 0.0009690693 Test MSE 0.00018668248631704403 Test RE 0.03197522817071876\n",
      "102 Train Loss 0.0009408581 Test MSE 0.00017237973351796882 Test RE 0.030725925028710323\n",
      "103 Train Loss 0.0009120912 Test MSE 0.0001561054438210859 Test RE 0.029239563715927806\n",
      "104 Train Loss 0.00089071674 Test MSE 0.0001579539049262762 Test RE 0.029412168647757527\n",
      "105 Train Loss 0.0008760556 Test MSE 0.00014167840395541315 Test RE 0.027855675330798278\n",
      "106 Train Loss 0.00086440175 Test MSE 0.00013247719547970194 Test RE 0.02693595803927339\n",
      "107 Train Loss 0.00085867214 Test MSE 0.0001301508593788281 Test RE 0.026698409137179455\n",
      "108 Train Loss 0.00085007225 Test MSE 0.00012558096189299237 Test RE 0.026225499378539723\n",
      "109 Train Loss 0.00084076734 Test MSE 0.00012722169531184706 Test RE 0.02639626339444785\n",
      "110 Train Loss 0.0008216114 Test MSE 0.00012287100985930772 Test RE 0.025940991887982448\n",
      "111 Train Loss 0.0007786855 Test MSE 0.00010405996693512989 Test RE 0.023872819028623916\n",
      "112 Train Loss 0.0007465357 Test MSE 8.74682224166591e-05 Test RE 0.0218870391295814\n",
      "113 Train Loss 0.0007291208 Test MSE 7.594608521794405e-05 Test RE 0.020394570333627383\n",
      "114 Train Loss 0.0007163846 Test MSE 6.56344550155547e-05 Test RE 0.018959540419047526\n",
      "115 Train Loss 0.0007119341 Test MSE 6.404860921061394e-05 Test RE 0.018729091693597485\n",
      "116 Train Loss 0.0007071593 Test MSE 6.444463533486673e-05 Test RE 0.01878690543421819\n",
      "117 Train Loss 0.0007030133 Test MSE 6.274063498075141e-05 Test RE 0.018536866359342166\n",
      "118 Train Loss 0.00069771777 Test MSE 6.113861425534835e-05 Test RE 0.018298675663246684\n",
      "119 Train Loss 0.00068964873 Test MSE 6.027377838601228e-05 Test RE 0.018168792814456273\n",
      "120 Train Loss 0.0006768687 Test MSE 5.472291517254413e-05 Test RE 0.017311969427213834\n",
      "121 Train Loss 0.00064215006 Test MSE 4.660230691720717e-05 Test RE 0.015975908772841895\n",
      "122 Train Loss 0.000627855 Test MSE 4.924817783664752e-05 Test RE 0.016423168444050014\n",
      "123 Train Loss 0.0006178372 Test MSE 5.456193131851558e-05 Test RE 0.017286486498981863\n",
      "124 Train Loss 0.0006042222 Test MSE 4.8882775330890735e-05 Test RE 0.016362128218249058\n",
      "125 Train Loss 0.0005918999 Test MSE 5.276693662577122e-05 Test RE 0.01699976058462121\n",
      "126 Train Loss 0.0005846623 Test MSE 5.467752911719691e-05 Test RE 0.017304788843146738\n",
      "127 Train Loss 0.00058190286 Test MSE 5.821910264883178e-05 Test RE 0.01785642926156077\n",
      "128 Train Loss 0.00057733746 Test MSE 6.560443026244621e-05 Test RE 0.018955203362870515\n",
      "129 Train Loss 0.00057051727 Test MSE 7.062998350128046e-05 Test RE 0.019667828671119113\n",
      "130 Train Loss 0.0005593379 Test MSE 6.849787678926026e-05 Test RE 0.019368697617327346\n",
      "131 Train Loss 0.0005531144 Test MSE 6.712691294230611e-05 Test RE 0.019173888680146352\n",
      "132 Train Loss 0.000544329 Test MSE 6.413909405393146e-05 Test RE 0.01874231681138751\n",
      "133 Train Loss 0.0005334981 Test MSE 6.38298201855086e-05 Test RE 0.018697075189341144\n",
      "134 Train Loss 0.0005289682 Test MSE 6.0854223875437235e-05 Test RE 0.018256067295734906\n",
      "135 Train Loss 0.0005175567 Test MSE 5.1334784738439364e-05 Test RE 0.016767477670644838\n",
      "136 Train Loss 0.0005074107 Test MSE 4.484300754411722e-05 Test RE 0.01567145176045222\n",
      "137 Train Loss 0.00050337473 Test MSE 4.2050605712877254e-05 Test RE 0.015175674119675842\n",
      "138 Train Loss 0.0004984895 Test MSE 4.252656753403031e-05 Test RE 0.015261317563020538\n",
      "139 Train Loss 0.0004970673 Test MSE 4.452381707648109e-05 Test RE 0.0156155778190068\n",
      "140 Train Loss 0.00049535866 Test MSE 4.2945871950529435e-05 Test RE 0.015336369958748871\n",
      "141 Train Loss 0.0004913459 Test MSE 4.0238123588596656e-05 Test RE 0.014845017850174764\n",
      "142 Train Loss 0.0004823382 Test MSE 3.7791079988033664e-05 Test RE 0.014386545238557496\n",
      "143 Train Loss 0.00047608456 Test MSE 3.867002414379172e-05 Test RE 0.014552884603991735\n",
      "144 Train Loss 0.00047032975 Test MSE 3.588020690180754e-05 Test RE 0.01401810579854364\n",
      "145 Train Loss 0.00046319532 Test MSE 3.1015210228834185e-05 Test RE 0.01303314504963812\n",
      "146 Train Loss 0.00044977965 Test MSE 2.6670039208985685e-05 Test RE 0.012085752357791323\n",
      "147 Train Loss 0.0004417152 Test MSE 3.046343190823576e-05 Test RE 0.012916691229694187\n",
      "148 Train Loss 0.0004307159 Test MSE 2.5287551824056353e-05 Test RE 0.011768341349848648\n",
      "149 Train Loss 0.00042598188 Test MSE 2.3323120203485413e-05 Test RE 0.011301997042727425\n",
      "150 Train Loss 0.00042188374 Test MSE 2.1349166800913442e-05 Test RE 0.01081315253125128\n",
      "151 Train Loss 0.00041727413 Test MSE 2.139655960364013e-05 Test RE 0.010825147882649684\n",
      "152 Train Loss 0.00041418907 Test MSE 1.9527846383029978e-05 Test RE 0.010341631033575662\n",
      "153 Train Loss 0.00040924133 Test MSE 1.8965258233965185e-05 Test RE 0.010191573579891238\n",
      "154 Train Loss 0.00040459412 Test MSE 1.759453358871697e-05 Test RE 0.009816366018639961\n",
      "155 Train Loss 0.00039072396 Test MSE 1.595324847006712e-05 Test RE 0.009347305320205003\n",
      "156 Train Loss 0.00038051404 Test MSE 1.5718917311787098e-05 Test RE 0.009278401865675847\n",
      "157 Train Loss 0.00037035433 Test MSE 1.7962886791397362e-05 Test RE 0.00991858981824975\n",
      "158 Train Loss 0.00035777636 Test MSE 1.9032453226830483e-05 Test RE 0.010209612279556477\n",
      "159 Train Loss 0.00034993963 Test MSE 2.1836126733811097e-05 Test RE 0.010935777542446007\n",
      "160 Train Loss 0.00034279126 Test MSE 2.2775122739122144e-05 Test RE 0.011168432586322623\n",
      "161 Train Loss 0.00033650588 Test MSE 2.3179838669935057e-05 Test RE 0.011267227633685076\n",
      "162 Train Loss 0.00032892046 Test MSE 2.6067067377039714e-05 Test RE 0.011948350426115894\n",
      "163 Train Loss 0.00032259923 Test MSE 2.2729539102976272e-05 Test RE 0.011157250368692195\n",
      "164 Train Loss 0.00031974254 Test MSE 2.3164381017599982e-05 Test RE 0.011263470188788597\n",
      "165 Train Loss 0.00031741156 Test MSE 2.3679996781667326e-05 Test RE 0.011388137011995321\n",
      "166 Train Loss 0.00031486587 Test MSE 2.4638637780293384e-05 Test RE 0.01161636395346827\n",
      "167 Train Loss 0.00031307753 Test MSE 2.4794103781663632e-05 Test RE 0.011652955054952849\n",
      "168 Train Loss 0.00030805144 Test MSE 2.3056067503239144e-05 Test RE 0.011237106101927727\n",
      "169 Train Loss 0.00030430226 Test MSE 2.071957572519097e-05 Test RE 0.010652518401761242\n",
      "170 Train Loss 0.00029882387 Test MSE 1.9457580664156298e-05 Test RE 0.010323008473308743\n",
      "171 Train Loss 0.00028849993 Test MSE 1.886252038307733e-05 Test RE 0.010163931397768776\n",
      "172 Train Loss 0.0002776864 Test MSE 1.9357813406332603e-05 Test RE 0.01029650924295065\n",
      "173 Train Loss 0.00027003683 Test MSE 1.946348684460647e-05 Test RE 0.010324575084438136\n",
      "174 Train Loss 0.00026412177 Test MSE 2.1281754400597172e-05 Test RE 0.010796067159437817\n",
      "175 Train Loss 0.0002599989 Test MSE 2.1233259020754936e-05 Test RE 0.010783759480972604\n",
      "176 Train Loss 0.00025120002 Test MSE 1.7414010893046427e-05 Test RE 0.00976587744607587\n",
      "177 Train Loss 0.00024772718 Test MSE 1.5904073576574414e-05 Test RE 0.009332887958620924\n",
      "178 Train Loss 0.00024222708 Test MSE 1.466529836928273e-05 Test RE 0.008962049032438035\n",
      "179 Train Loss 0.00023812498 Test MSE 1.4309314421430657e-05 Test RE 0.008852608888455156\n",
      "180 Train Loss 0.00023518514 Test MSE 1.5055315124382918e-05 Test RE 0.009080437826058827\n",
      "181 Train Loss 0.00023224295 Test MSE 1.4874637859921048e-05 Test RE 0.009025786672449949\n",
      "182 Train Loss 0.00023171405 Test MSE 1.4722024392044181e-05 Test RE 0.008979365104797233\n",
      "183 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "184 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "185 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "186 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "187 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "188 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "189 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "190 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "191 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "192 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "193 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "194 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "195 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "196 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "197 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "198 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "199 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "200 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "201 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "202 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "203 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "204 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "205 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "206 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "207 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "208 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "209 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "210 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "211 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "212 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "213 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "214 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "215 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "216 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "217 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "218 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "219 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "220 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "221 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "222 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "223 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "224 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "225 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "226 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "227 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "228 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "229 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "230 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "231 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "232 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "233 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "234 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "235 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "236 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "237 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "238 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "239 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "240 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "241 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "242 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "243 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "244 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "245 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "246 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "247 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "248 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "249 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "250 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "251 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "252 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "253 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "254 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "255 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "256 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "257 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "258 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "259 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "260 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "261 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "262 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "263 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "264 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "265 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "266 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "267 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "268 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "269 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "270 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "271 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "272 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "273 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "274 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "275 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "276 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "277 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "278 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "279 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "280 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "281 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "282 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "283 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "284 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "285 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "286 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "287 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "288 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "289 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "290 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "291 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "292 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "293 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "294 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "295 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "296 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "297 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "298 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "299 Train Loss 0.00023167398 Test MSE 1.471208157769665e-05 Test RE 0.008976332395531281\n",
      "Training time: 135.38\n",
      "KG_stan_low\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 7208.492 Test MSE 3.6577319612202692 Test RE 4.475770429175297\n",
      "1 Train Loss 1419.1035 Test MSE 3.9930833872402545 Test RE 4.6764474002759835\n",
      "2 Train Loss 157.15308 Test MSE 2.5574291378737395 Test RE 3.742516024224935\n",
      "3 Train Loss 21.057533 Test MSE 0.4080746220668728 Test RE 1.4949671771399375\n",
      "4 Train Loss 6.7491865 Test MSE 0.3581394295707769 Test RE 1.400515542370128\n",
      "5 Train Loss 2.9078035 Test MSE 0.27897613223653206 Test RE 1.2360766100688159\n",
      "6 Train Loss 1.4852469 Test MSE 0.15109234707182884 Test RE 0.9096683777046431\n",
      "7 Train Loss 0.740057 Test MSE 0.09466771305439807 Test RE 0.7200502523129005\n",
      "8 Train Loss 0.47557423 Test MSE 0.0798602876807157 Test RE 0.6613438194092701\n",
      "9 Train Loss 0.33180037 Test MSE 0.05553354203294813 Test RE 0.551492424606772\n",
      "10 Train Loss 0.25687534 Test MSE 0.047748870647834014 Test RE 0.5113796200069286\n",
      "11 Train Loss 0.17734136 Test MSE 0.0367802036662918 Test RE 0.44881661808069917\n",
      "12 Train Loss 0.13223621 Test MSE 0.03293083846978507 Test RE 0.4246814175933364\n",
      "13 Train Loss 0.103513785 Test MSE 0.03070103347782716 Test RE 0.41005145914874885\n",
      "14 Train Loss 0.08006324 Test MSE 0.02449379948761518 Test RE 0.36626038128415717\n",
      "15 Train Loss 0.067069076 Test MSE 0.02277643210749762 Test RE 0.3531870007968546\n",
      "16 Train Loss 0.054689933 Test MSE 0.017058865397016114 Test RE 0.3056588221587866\n",
      "17 Train Loss 0.041789077 Test MSE 0.013878412196844638 Test RE 0.2756968189254678\n",
      "18 Train Loss 0.03433972 Test MSE 0.011342075608612409 Test RE 0.24923448519627675\n",
      "19 Train Loss 0.030873576 Test MSE 0.013608435643020967 Test RE 0.27300208627919864\n",
      "20 Train Loss 0.025521828 Test MSE 0.011741699876607354 Test RE 0.25358721361431874\n",
      "21 Train Loss 0.021752337 Test MSE 0.010822079629138889 Test RE 0.24345417497194916\n",
      "22 Train Loss 0.020130994 Test MSE 0.010807266798365765 Test RE 0.24328750273865432\n",
      "23 Train Loss 0.017468126 Test MSE 0.008518102711207051 Test RE 0.21598982882973838\n",
      "24 Train Loss 0.015169587 Test MSE 0.007403278587371876 Test RE 0.20136032810314455\n",
      "25 Train Loss 0.013634053 Test MSE 0.006476301341018539 Test RE 0.18833255060531778\n",
      "26 Train Loss 0.012432614 Test MSE 0.005910753854689938 Test RE 0.1799215985828132\n",
      "27 Train Loss 0.010149818 Test MSE 0.004855355880335966 Test RE 0.16306937169364724\n",
      "28 Train Loss 0.00831547 Test MSE 0.005276870149025676 Test RE 0.1700004487270741\n",
      "29 Train Loss 0.007605422 Test MSE 0.0047381586624365155 Test RE 0.16108928866496258\n",
      "30 Train Loss 0.006801585 Test MSE 0.00459158650146851 Test RE 0.1585781143180556\n",
      "31 Train Loss 0.006507799 Test MSE 0.004679496545775304 Test RE 0.1600889770567808\n",
      "32 Train Loss 0.005721706 Test MSE 0.004363845806846288 Test RE 0.15459539825547314\n",
      "33 Train Loss 0.005308851 Test MSE 0.0040677184525489555 Test RE 0.1492578930741772\n",
      "34 Train Loss 0.0051369364 Test MSE 0.003680355574348125 Test RE 0.14197332509771654\n",
      "35 Train Loss 0.004778927 Test MSE 0.00283666521871532 Test RE 0.12464242958848892\n",
      "36 Train Loss 0.0046787784 Test MSE 0.0024905335793492544 Test RE 0.11679064713039383\n",
      "37 Train Loss 0.0042622117 Test MSE 0.002116842262799788 Test RE 0.1076728262683779\n",
      "38 Train Loss 0.0038631095 Test MSE 0.001699762046133759 Test RE 0.09648413949221192\n",
      "39 Train Loss 0.003728159 Test MSE 0.0015933405757855763 Test RE 0.09341490404215594\n",
      "40 Train Loss 0.0032770305 Test MSE 0.0014331267595289426 Test RE 0.08859397067602963\n",
      "41 Train Loss 0.0032250248 Test MSE 0.001352873599755744 Test RE 0.08607766450376687\n",
      "42 Train Loss 0.0029563662 Test MSE 0.0010339451161742975 Test RE 0.07525071090395533\n",
      "43 Train Loss 0.0029133223 Test MSE 0.001005513315215961 Test RE 0.07420886291282491\n",
      "44 Train Loss 0.0026430872 Test MSE 0.0007386016261623778 Test RE 0.06360144661458847\n",
      "45 Train Loss 0.0025928414 Test MSE 0.0006984090226351118 Test RE 0.06184673604126469\n",
      "46 Train Loss 0.002457732 Test MSE 0.0006462875131371421 Test RE 0.05949421609406993\n",
      "47 Train Loss 0.0023615672 Test MSE 0.0006153582447924838 Test RE 0.058053161514738105\n",
      "48 Train Loss 0.0023162395 Test MSE 0.0005950866872237734 Test RE 0.05708894027373278\n",
      "49 Train Loss 0.0020652767 Test MSE 0.0005461904804888849 Test RE 0.054693274734359865\n",
      "50 Train Loss 0.0020196866 Test MSE 0.0005639855049852313 Test RE 0.05557709405509898\n",
      "51 Train Loss 0.0019684283 Test MSE 0.0005461219932321959 Test RE 0.05468984561035546\n",
      "52 Train Loss 0.0018278984 Test MSE 0.0005283217814286447 Test RE 0.053791186274384846\n",
      "53 Train Loss 0.0018017935 Test MSE 0.0005378856051625467 Test RE 0.05427587392453037\n",
      "54 Train Loss 0.0017817297 Test MSE 0.000526613303196047 Test RE 0.05370414132232858\n",
      "55 Train Loss 0.0017421272 Test MSE 0.0005065617520162573 Test RE 0.05267178805709213\n",
      "56 Train Loss 0.0015966233 Test MSE 0.00043377132068462686 Test RE 0.048740758280313844\n",
      "57 Train Loss 0.0015617312 Test MSE 0.0004274110129105021 Test RE 0.04838210037892628\n",
      "58 Train Loss 0.0015448652 Test MSE 0.00043515290233569 Test RE 0.04881831735301891\n",
      "59 Train Loss 0.0015316021 Test MSE 0.00045040773270188685 Test RE 0.04966664028736487\n",
      "60 Train Loss 0.0014532066 Test MSE 0.00041658678888723433 Test RE 0.04776553105988401\n",
      "61 Train Loss 0.0013901419 Test MSE 0.0003915604567543884 Test RE 0.04630856008258214\n",
      "62 Train Loss 0.0013745202 Test MSE 0.0003909437668553476 Test RE 0.04627207877553415\n",
      "63 Train Loss 0.0013329086 Test MSE 0.00039023044202500084 Test RE 0.04622984496132143\n",
      "64 Train Loss 0.0012458573 Test MSE 0.00037440592544918556 Test RE 0.045282794548452555\n",
      "65 Train Loss 0.0011837928 Test MSE 0.00033325469604648114 Test RE 0.042721845296493255\n",
      "66 Train Loss 0.0011152596 Test MSE 0.00027609096932784216 Test RE 0.03888552481947272\n",
      "67 Train Loss 0.0010783315 Test MSE 0.0002311754669720858 Test RE 0.03558219503493891\n",
      "68 Train Loss 0.0010395923 Test MSE 0.00021203412419500765 Test RE 0.0340772660089887\n",
      "69 Train Loss 0.0009956158 Test MSE 0.00021630401571647685 Test RE 0.03441867560955271\n",
      "70 Train Loss 0.00094816054 Test MSE 0.00022245985581191517 Test RE 0.034905003809315015\n",
      "71 Train Loss 0.0009247546 Test MSE 0.00020337329537037485 Test RE 0.03337404344378701\n",
      "72 Train Loss 0.0009134575 Test MSE 0.00018790372810771454 Test RE 0.03207964565014769\n",
      "73 Train Loss 0.0009013258 Test MSE 0.00017783576706883715 Test RE 0.031208394005957662\n",
      "74 Train Loss 0.00089253887 Test MSE 0.0001997192382139194 Test RE 0.033072864721364705\n",
      "75 Train Loss 0.0008798076 Test MSE 0.0001946231926632708 Test RE 0.032648193844057524\n",
      "76 Train Loss 0.00086268195 Test MSE 0.00017368810261863033 Test RE 0.03084231010682705\n",
      "77 Train Loss 0.0008357486 Test MSE 0.0001560222191377031 Test RE 0.029231768414889888\n",
      "78 Train Loss 0.00081128546 Test MSE 0.00016455364774422884 Test RE 0.030020340996616858\n",
      "79 Train Loss 0.00079187145 Test MSE 0.00016301661570598347 Test RE 0.02987980785773095\n",
      "80 Train Loss 0.0007846044 Test MSE 0.0001621850980840736 Test RE 0.029803504743121663\n",
      "81 Train Loss 0.00077581115 Test MSE 0.00017434918768714772 Test RE 0.030900949777266255\n",
      "82 Train Loss 0.00075997703 Test MSE 0.00015581411399172233 Test RE 0.02921226698965235\n",
      "83 Train Loss 0.0007107756 Test MSE 0.00011812847885361502 Test RE 0.025435435025454808\n",
      "84 Train Loss 0.0006800218 Test MSE 0.00010180217586934552 Test RE 0.023612414278473364\n",
      "85 Train Loss 0.0006717168 Test MSE 9.78150374760636e-05 Test RE 0.023145399263723655\n",
      "86 Train Loss 0.0006650857 Test MSE 9.181403534081597e-05 Test RE 0.022424171272242426\n",
      "87 Train Loss 0.0006467231 Test MSE 9.021939699848297e-05 Test RE 0.02222858532146037\n",
      "88 Train Loss 0.0006273852 Test MSE 7.947626700466437e-05 Test RE 0.020863184280090413\n",
      "89 Train Loss 0.00060273893 Test MSE 8.52610715189512e-05 Test RE 0.02160912875622659\n",
      "90 Train Loss 0.00058583013 Test MSE 7.986111639304466e-05 Test RE 0.020913636367919528\n",
      "91 Train Loss 0.00057181844 Test MSE 7.040233726109283e-05 Test RE 0.01963610757665286\n",
      "92 Train Loss 0.0005632314 Test MSE 6.870857144790647e-05 Test RE 0.01939846312258946\n",
      "93 Train Loss 0.00055688375 Test MSE 6.990676191558372e-05 Test RE 0.019566874390637208\n",
      "94 Train Loss 0.00055048213 Test MSE 6.931882877925649e-05 Test RE 0.019484419534603663\n",
      "95 Train Loss 0.0005422844 Test MSE 6.823124804409144e-05 Test RE 0.01933096442715498\n",
      "96 Train Loss 0.0005265399 Test MSE 6.261032256157485e-05 Test RE 0.018517605799600018\n",
      "97 Train Loss 0.0005027991 Test MSE 5.809453178792662e-05 Test RE 0.01783731541562204\n",
      "98 Train Loss 0.0004827036 Test MSE 5.883032569969874e-05 Test RE 0.017949918887542306\n",
      "99 Train Loss 0.0004737313 Test MSE 5.814748246476322e-05 Test RE 0.01784544253856993\n",
      "100 Train Loss 0.00046724683 Test MSE 5.4570055435249694e-05 Test RE 0.017287773405470986\n",
      "101 Train Loss 0.00045591153 Test MSE 5.4031038253723877e-05 Test RE 0.01720218129936479\n",
      "102 Train Loss 0.0004457203 Test MSE 5.54706257697951e-05 Test RE 0.017429839847538556\n",
      "103 Train Loss 0.00043773622 Test MSE 5.956951392457871e-05 Test RE 0.018062334974785058\n",
      "104 Train Loss 0.000429941 Test MSE 5.8320389647203856e-05 Test RE 0.01787195542120542\n",
      "105 Train Loss 0.00041918707 Test MSE 5.750595440402307e-05 Test RE 0.017746727135682074\n",
      "106 Train Loss 0.00041404445 Test MSE 5.381552751585335e-05 Test RE 0.017167840307332122\n",
      "107 Train Loss 0.0004096736 Test MSE 5.304743526525316e-05 Test RE 0.01704488438586577\n",
      "108 Train Loss 0.00040652926 Test MSE 5.200120113512317e-05 Test RE 0.01687596249856849\n",
      "109 Train Loss 0.0004017507 Test MSE 4.56380385262967e-05 Test RE 0.015809762627707263\n",
      "110 Train Loss 0.0003927363 Test MSE 4.5175347655472634e-05 Test RE 0.015729416625693916\n",
      "111 Train Loss 0.0003870597 Test MSE 4.747227733608701e-05 Test RE 0.016124338141733516\n",
      "112 Train Loss 0.00037962288 Test MSE 4.47278928879416e-05 Test RE 0.015651324062501165\n",
      "113 Train Loss 0.00036928602 Test MSE 4.396999672538688e-05 Test RE 0.015518154830662151\n",
      "114 Train Loss 0.00036273382 Test MSE 4.430695493586801e-05 Test RE 0.0155775020036752\n",
      "115 Train Loss 0.00035448084 Test MSE 3.8128789878695455e-05 Test RE 0.014450683028814996\n",
      "116 Train Loss 0.00035179086 Test MSE 3.640920158890019e-05 Test RE 0.014121064663931936\n",
      "117 Train Loss 0.00034936474 Test MSE 3.571993982579553e-05 Test RE 0.013986763236402943\n",
      "118 Train Loss 0.00034559087 Test MSE 3.4270164231706565e-05 Test RE 0.013699980748747972\n",
      "119 Train Loss 0.0003405769 Test MSE 3.255688993277808e-05 Test RE 0.013353137458058233\n",
      "120 Train Loss 0.00033219106 Test MSE 3.298797693601406e-05 Test RE 0.013441251434613234\n",
      "121 Train Loss 0.00032532818 Test MSE 3.205482035250779e-05 Test RE 0.013249776045814067\n",
      "122 Train Loss 0.00031960194 Test MSE 3.4669055872684676e-05 Test RE 0.013779481354215672\n",
      "123 Train Loss 0.00031438182 Test MSE 3.421267183024905e-05 Test RE 0.013688484226468432\n",
      "124 Train Loss 0.00030963452 Test MSE 3.5706591285824705e-05 Test RE 0.013984149565789169\n",
      "125 Train Loss 0.00030672195 Test MSE 3.706483425662567e-05 Test RE 0.014247638757442624\n",
      "126 Train Loss 0.00030339434 Test MSE 3.661285725175571e-05 Test RE 0.014160502832800383\n",
      "127 Train Loss 0.000301286 Test MSE 3.464489749427627e-05 Test RE 0.013774679551448938\n",
      "128 Train Loss 0.00029916424 Test MSE 3.3814861564920486e-05 Test RE 0.013608669625584758\n",
      "129 Train Loss 0.00029653078 Test MSE 3.509170113282184e-05 Test RE 0.013863218715110936\n",
      "130 Train Loss 0.0002940116 Test MSE 3.520849718059853e-05 Test RE 0.01388627009287972\n",
      "131 Train Loss 0.00029008367 Test MSE 3.491695628326353e-05 Test RE 0.013828658557527003\n",
      "132 Train Loss 0.00028360778 Test MSE 3.437972779233246e-05 Test RE 0.013721863061096417\n",
      "133 Train Loss 0.00027775677 Test MSE 3.358339547308079e-05 Test RE 0.013562013297888045\n",
      "134 Train Loss 0.0002739699 Test MSE 3.150092266313748e-05 Test RE 0.013134801118706718\n",
      "135 Train Loss 0.00027027234 Test MSE 3.0402788910500455e-05 Test RE 0.012903828314305641\n",
      "136 Train Loss 0.0002670138 Test MSE 2.9989191960842635e-05 Test RE 0.012815756467732486\n",
      "137 Train Loss 0.0002653931 Test MSE 2.9575213539844333e-05 Test RE 0.012726993096891025\n",
      "138 Train Loss 0.0002641223 Test MSE 2.9762054778524928e-05 Test RE 0.012767131155961087\n",
      "139 Train Loss 0.00026299182 Test MSE 2.9731466836499044e-05 Test RE 0.012760568761976425\n",
      "140 Train Loss 0.0002607328 Test MSE 2.9038269434442546e-05 Test RE 0.012610933318612298\n",
      "141 Train Loss 0.00025754343 Test MSE 3.0922580771615823e-05 Test RE 0.013013668220665171\n",
      "142 Train Loss 0.00025299084 Test MSE 2.9020562010862812e-05 Test RE 0.012607087683254243\n",
      "143 Train Loss 0.00024667275 Test MSE 2.886996601994935e-05 Test RE 0.012574334245578684\n",
      "144 Train Loss 0.00024176971 Test MSE 2.5121351840992107e-05 Test RE 0.01172960445493366\n",
      "145 Train Loss 0.0002373846 Test MSE 2.425516907819971e-05 Test RE 0.011525612580796998\n",
      "146 Train Loss 0.00023121359 Test MSE 2.4616328821409554e-05 Test RE 0.01161110376668234\n",
      "147 Train Loss 0.00022788625 Test MSE 2.4496933461057038e-05 Test RE 0.011582911159096505\n",
      "148 Train Loss 0.00022768695 Test MSE 2.4467833853233015e-05 Test RE 0.011576029515542157\n",
      "149 Train Loss 0.00022554051 Test MSE 2.521056791143517e-05 Test RE 0.011750414277616653\n",
      "150 Train Loss 0.00022392265 Test MSE 2.4094280532990365e-05 Test RE 0.011487323333869917\n",
      "151 Train Loss 0.00022197654 Test MSE 2.5779445199505274e-05 Test RE 0.011882248953892366\n",
      "152 Train Loss 0.00021829712 Test MSE 2.596987968252524e-05 Test RE 0.011926055685144555\n",
      "153 Train Loss 0.00021406592 Test MSE 2.555273316211767e-05 Test RE 0.011829885575626099\n",
      "154 Train Loss 0.0002071224 Test MSE 1.9977412879805163e-05 Test RE 0.010459995236355648\n",
      "155 Train Loss 0.00020279584 Test MSE 1.937236751790703e-05 Test RE 0.010300379214845048\n",
      "156 Train Loss 0.00020072711 Test MSE 2.0407690999786947e-05 Test RE 0.01057204003206763\n",
      "157 Train Loss 0.0001984984 Test MSE 2.1458241630584485e-05 Test RE 0.010840740027934762\n",
      "158 Train Loss 0.00019702065 Test MSE 2.0818836254800805e-05 Test RE 0.01067800423397412\n",
      "159 Train Loss 0.00019517234 Test MSE 2.0157493487742238e-05 Test RE 0.010507033770584458\n",
      "160 Train Loss 0.00019365376 Test MSE 1.9866595383818303e-05 Test RE 0.01043094336528823\n",
      "161 Train Loss 0.00019193567 Test MSE 1.9894181212874102e-05 Test RE 0.010438182814135602\n",
      "162 Train Loss 0.00018985258 Test MSE 1.8339528409169683e-05 Test RE 0.010022035712149765\n",
      "163 Train Loss 0.00018644333 Test MSE 1.940744071623402e-05 Test RE 0.010309699290829182\n",
      "164 Train Loss 0.00018204458 Test MSE 1.941400670333477e-05 Test RE 0.010311443148480396\n",
      "165 Train Loss 0.0001791886 Test MSE 1.8762326777003813e-05 Test RE 0.01013690115871589\n",
      "166 Train Loss 0.00017611639 Test MSE 1.8510510389165082e-05 Test RE 0.01006864574426831\n",
      "167 Train Loss 0.00017272636 Test MSE 1.645101455938101e-05 Test RE 0.009492010444083234\n",
      "168 Train Loss 0.00016839169 Test MSE 1.5131423630889951e-05 Test RE 0.009103360871374361\n",
      "169 Train Loss 0.00016612839 Test MSE 1.4491507745588601e-05 Test RE 0.008908788541869701\n",
      "170 Train Loss 0.00016468328 Test MSE 1.448626991793752e-05 Test RE 0.008907178394844322\n",
      "171 Train Loss 0.00016243054 Test MSE 1.4360901887875737e-05 Test RE 0.008868552098088638\n",
      "172 Train Loss 0.00016003144 Test MSE 1.4800478792303441e-05 Test RE 0.009003259055720012\n",
      "173 Train Loss 0.00015758155 Test MSE 1.5489014704934743e-05 Test RE 0.009210299654579857\n",
      "174 Train Loss 0.00015612731 Test MSE 1.673750689872588e-05 Test RE 0.009574304785242146\n",
      "175 Train Loss 0.00015353406 Test MSE 1.673911384286267e-05 Test RE 0.009574764381876443\n",
      "176 Train Loss 0.00015137097 Test MSE 1.6026475191696653e-05 Test RE 0.009368733209237841\n",
      "177 Train Loss 0.00014859857 Test MSE 1.6940701184907084e-05 Test RE 0.009632245766491349\n",
      "178 Train Loss 0.00014650573 Test MSE 1.5101411543997674e-05 Test RE 0.009094328460671496\n",
      "179 Train Loss 0.00014426291 Test MSE 1.5452414466098737e-05 Test RE 0.00919941133957568\n",
      "180 Train Loss 0.000142102 Test MSE 1.5297614923075593e-05 Test RE 0.009153216320724066\n",
      "181 Train Loss 0.0001390345 Test MSE 1.3610019704757047e-05 Test RE 0.008633586429700696\n",
      "182 Train Loss 0.00013559073 Test MSE 1.2938041202606645e-05 Test RE 0.008417752045741468\n",
      "183 Train Loss 0.00013341528 Test MSE 1.2373239289531532e-05 Test RE 0.008231966037868342\n",
      "184 Train Loss 0.00013225779 Test MSE 1.1908222031371135e-05 Test RE 0.008075795739317772\n",
      "185 Train Loss 0.00013118332 Test MSE 1.1924925542155988e-05 Test RE 0.008081457662250009\n",
      "186 Train Loss 0.00013039303 Test MSE 1.1907482951194908e-05 Test RE 0.008075545124526743\n",
      "187 Train Loss 0.00012862714 Test MSE 1.2438662102438326e-05 Test RE 0.008253700376705904\n",
      "188 Train Loss 0.0001265051 Test MSE 1.3263477409816263e-05 Test RE 0.008522962253841509\n",
      "189 Train Loss 0.0001250758 Test MSE 1.2812495796935083e-05 Test RE 0.008376811291824014\n",
      "190 Train Loss 0.00012358362 Test MSE 1.2319344340969728e-05 Test RE 0.008214018208999412\n",
      "191 Train Loss 0.00012138278 Test MSE 1.2255934107541146e-05 Test RE 0.008192851304228652\n",
      "192 Train Loss 0.00011947164 Test MSE 1.111889518154073e-05 Test RE 0.007803558350144306\n",
      "193 Train Loss 0.000117992306 Test MSE 1.0840127239437385e-05 Test RE 0.007705113739951492\n",
      "194 Train Loss 0.00011605592 Test MSE 1.0741078295757689e-05 Test RE 0.007669831186544417\n",
      "195 Train Loss 0.000114871415 Test MSE 1.0484945094245805e-05 Test RE 0.00757783150371158\n",
      "196 Train Loss 0.000113487964 Test MSE 1.0356486010170923e-05 Test RE 0.007531267535806246\n",
      "197 Train Loss 0.00011245288 Test MSE 1.0694656957817019e-05 Test RE 0.007653239307160375\n",
      "198 Train Loss 0.00011223644 Test MSE 1.0959309815965022e-05 Test RE 0.007747355170685176\n",
      "199 Train Loss 0.00011165186 Test MSE 1.107959889359658e-05 Test RE 0.0077897565159082485\n",
      "200 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "201 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "202 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "203 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "204 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "205 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "206 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "207 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "208 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "209 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "210 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "211 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "212 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "213 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "214 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "215 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "216 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "217 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "218 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "219 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "220 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "221 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "222 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "223 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "224 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "225 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "226 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "227 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "228 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "229 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "230 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "231 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "232 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "233 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "234 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "235 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "236 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "237 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "238 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "239 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "240 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "241 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "242 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "243 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "244 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "245 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "246 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "247 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "248 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "249 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "250 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "251 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "252 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "253 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "254 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "255 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "256 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "257 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "258 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "259 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "260 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "261 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "262 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "263 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "264 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "265 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "266 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "267 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "268 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "269 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "270 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "271 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "272 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "273 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "274 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "275 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "276 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "277 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "278 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "279 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "280 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "281 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "282 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "283 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "284 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "285 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "286 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "287 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "288 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "289 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "290 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "291 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "292 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "293 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "294 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "295 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "296 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "297 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "298 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "299 Train Loss 0.000111631 Test MSE 1.1086955234418141e-05 Test RE 0.007792342105681688\n",
      "Training time: 139.27\n",
      "KG_stan_low\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 3398.6792 Test MSE 1.6167560769647882 Test RE 2.9756655361133615\n",
      "1 Train Loss 415.17438 Test MSE 0.3091316200663504 Test RE 1.3011686141315226\n",
      "2 Train Loss 28.454256 Test MSE 0.8729285420688592 Test RE 2.186508706186776\n",
      "3 Train Loss 9.790768 Test MSE 0.4921710417998335 Test RE 1.6417986440932477\n",
      "4 Train Loss 5.167478 Test MSE 0.11438499316145517 Test RE 0.7914917443513407\n",
      "5 Train Loss 2.9390156 Test MSE 0.10387268517016975 Test RE 0.7542451796673408\n",
      "6 Train Loss 1.6623083 Test MSE 0.05489226403857119 Test RE 0.5482989773682985\n",
      "7 Train Loss 1.0159336 Test MSE 0.04494074893495465 Test RE 0.49611461018828773\n",
      "8 Train Loss 0.6104735 Test MSE 0.03309677458635695 Test RE 0.4257500425988615\n",
      "9 Train Loss 0.463319 Test MSE 0.04185264028224097 Test RE 0.4787659927243292\n",
      "10 Train Loss 0.35478795 Test MSE 0.057580846367828654 Test RE 0.5615661041740497\n",
      "11 Train Loss 0.2629122 Test MSE 0.06085103225367003 Test RE 0.5772923984942466\n",
      "12 Train Loss 0.2151442 Test MSE 0.0453805305475672 Test RE 0.4985361420075922\n",
      "13 Train Loss 0.18010949 Test MSE 0.03719334315053621 Test RE 0.4513302810158686\n",
      "14 Train Loss 0.15494664 Test MSE 0.03648115416957481 Test RE 0.44698829321938854\n",
      "15 Train Loss 0.13442224 Test MSE 0.029464254305115893 Test RE 0.4017071771383685\n",
      "16 Train Loss 0.11925604 Test MSE 0.025733610329168512 Test RE 0.37541552126583744\n",
      "17 Train Loss 0.10031324 Test MSE 0.018673694377814822 Test RE 0.319798916043612\n",
      "18 Train Loss 0.08854308 Test MSE 0.013673005086205024 Test RE 0.2736489913580061\n",
      "19 Train Loss 0.0814575 Test MSE 0.00974641651612678 Test RE 0.2310384953937201\n",
      "20 Train Loss 0.071141616 Test MSE 0.007670704816154345 Test RE 0.20496490203904585\n",
      "21 Train Loss 0.06277094 Test MSE 0.008343440462064313 Test RE 0.2137639419973191\n",
      "22 Train Loss 0.058123704 Test MSE 0.00849884305754708 Test RE 0.21574551131530983\n",
      "23 Train Loss 0.054596826 Test MSE 0.00919245627249449 Test RE 0.22437664522594794\n",
      "24 Train Loss 0.050662626 Test MSE 0.0071216405022349345 Test RE 0.19749308208154923\n",
      "25 Train Loss 0.04538996 Test MSE 0.005090715627863537 Test RE 0.16697493491359677\n",
      "26 Train Loss 0.041942336 Test MSE 0.005860478339448245 Test RE 0.17915477859719875\n",
      "27 Train Loss 0.03997419 Test MSE 0.004502752855482687 Test RE 0.15703661280513767\n",
      "28 Train Loss 0.034917235 Test MSE 0.003071503612631284 Test RE 0.12969922447661336\n",
      "29 Train Loss 0.031025147 Test MSE 0.0018200037484457437 Test RE 0.09983849030649043\n",
      "30 Train Loss 0.030365244 Test MSE 0.0014250489539915847 Test RE 0.0883439383095304\n",
      "31 Train Loss 0.027497511 Test MSE 0.0012133088998866788 Test RE 0.08151688125023453\n",
      "32 Train Loss 0.025596958 Test MSE 0.0011270294589756343 Test RE 0.07856506932585433\n",
      "33 Train Loss 0.024679216 Test MSE 0.001424181405296001 Test RE 0.08831704297498391\n",
      "34 Train Loss 0.022696648 Test MSE 0.0014416716331079882 Test RE 0.08885769445538964\n",
      "35 Train Loss 0.022128433 Test MSE 0.0013803942297130087 Test RE 0.08694876777768903\n",
      "36 Train Loss 0.02075961 Test MSE 0.0014512356289345916 Test RE 0.08915194656261743\n",
      "37 Train Loss 0.020003155 Test MSE 0.0013362128997251974 Test RE 0.08554599737628472\n",
      "38 Train Loss 0.018602401 Test MSE 0.0011511967716074866 Test RE 0.07940295142403511\n",
      "39 Train Loss 0.018096235 Test MSE 0.0010407047665219706 Test RE 0.07549629445038229\n",
      "40 Train Loss 0.016690442 Test MSE 0.0010220404451476294 Test RE 0.0748162446446546\n",
      "41 Train Loss 0.015878653 Test MSE 0.0011042228496630651 Test RE 0.07776608378546428\n",
      "42 Train Loss 0.015128571 Test MSE 0.0011688450395992665 Test RE 0.08000927463176521\n",
      "43 Train Loss 0.013681555 Test MSE 0.0008706380536959873 Test RE 0.06905270354304985\n",
      "44 Train Loss 0.013093313 Test MSE 0.0008787064708806773 Test RE 0.06937192986327324\n",
      "45 Train Loss 0.012929955 Test MSE 0.000833082386540663 Test RE 0.06754696501207821\n",
      "46 Train Loss 0.01179354 Test MSE 0.0008160302357131377 Test RE 0.06685209002616574\n",
      "47 Train Loss 0.011238881 Test MSE 0.0009339782600757805 Test RE 0.07152045154933898\n",
      "48 Train Loss 0.010952899 Test MSE 0.0010302070032646119 Test RE 0.07511455746680687\n",
      "49 Train Loss 0.009830173 Test MSE 0.0010353956342434955 Test RE 0.07530347688668788\n",
      "50 Train Loss 0.009186348 Test MSE 0.0009546460224604931 Test RE 0.07230745029994301\n",
      "51 Train Loss 0.0089621 Test MSE 0.0009462916110384799 Test RE 0.07199036227623366\n",
      "52 Train Loss 0.008532394 Test MSE 0.0009058197698757272 Test RE 0.07043406626467288\n",
      "53 Train Loss 0.007918257 Test MSE 0.0007939043849247449 Test RE 0.06593954777846975\n",
      "54 Train Loss 0.0071700155 Test MSE 0.0005416147428814545 Test RE 0.05446369509517365\n",
      "55 Train Loss 0.0069471463 Test MSE 0.0004624858473134121 Test RE 0.05032816403549727\n",
      "56 Train Loss 0.006734838 Test MSE 0.0004088925052443911 Test RE 0.04732236480549768\n",
      "57 Train Loss 0.0065578497 Test MSE 0.0004432822216838014 Test RE 0.04927220760304076\n",
      "58 Train Loss 0.006341987 Test MSE 0.00038510184152191535 Test RE 0.04592505252997005\n",
      "59 Train Loss 0.0059800637 Test MSE 0.0004424277272091881 Test RE 0.049224694826097426\n",
      "60 Train Loss 0.005550541 Test MSE 0.0003979997610846189 Test RE 0.04668778494191321\n",
      "61 Train Loss 0.00524909 Test MSE 0.0004160502621009014 Test RE 0.04773476226888951\n",
      "62 Train Loss 0.0050904425 Test MSE 0.00046965348449507795 Test RE 0.050716659249585606\n",
      "63 Train Loss 0.0049962434 Test MSE 0.00047241110800728107 Test RE 0.05086533562474171\n",
      "64 Train Loss 0.004939833 Test MSE 0.0004943794027340634 Test RE 0.052034579378361215\n",
      "65 Train Loss 0.0047629313 Test MSE 0.0006064181134945176 Test RE 0.057629910691573825\n",
      "66 Train Loss 0.004446741 Test MSE 0.0006663323623008534 Test RE 0.06040978878749853\n",
      "67 Train Loss 0.0041932263 Test MSE 0.0006751125568075062 Test RE 0.060806493086099006\n",
      "68 Train Loss 0.0041220584 Test MSE 0.0005446079175925071 Test RE 0.054613981576487405\n",
      "69 Train Loss 0.0040737144 Test MSE 0.0004368420416938516 Test RE 0.04891297497023265\n",
      "70 Train Loss 0.0040273652 Test MSE 0.00038226838673624845 Test RE 0.04575578976915189\n",
      "71 Train Loss 0.003965293 Test MSE 0.00032839371760513976 Test RE 0.04240912227498278\n",
      "72 Train Loss 0.0038623689 Test MSE 0.0002601835438184322 Test RE 0.03774868057436196\n",
      "73 Train Loss 0.0037480984 Test MSE 0.00027629975462471485 Test RE 0.03890022503143401\n",
      "74 Train Loss 0.0037098967 Test MSE 0.0002903721057591956 Test RE 0.039878545616940285\n",
      "75 Train Loss 0.0036693187 Test MSE 0.00028997820705731393 Test RE 0.03985148820028614\n",
      "76 Train Loss 0.003606373 Test MSE 0.0002637766141781152 Test RE 0.038008436825949954\n",
      "77 Train Loss 0.0034463464 Test MSE 0.0003147041843575221 Test RE 0.04151577243513722\n",
      "78 Train Loss 0.0033538947 Test MSE 0.0002621755493768899 Test RE 0.037892909916293495\n",
      "79 Train Loss 0.0033178385 Test MSE 0.00023991540030689182 Test RE 0.036248574079531734\n",
      "80 Train Loss 0.0032846162 Test MSE 0.00022528033714225605 Test RE 0.03512558029279818\n",
      "81 Train Loss 0.0031968951 Test MSE 0.00019713726202379774 Test RE 0.032858385784554474\n",
      "82 Train Loss 0.0031313829 Test MSE 0.00016999456364591998 Test RE 0.030512611579059355\n",
      "83 Train Loss 0.0030855765 Test MSE 0.00017082179150943453 Test RE 0.030586761744879416\n",
      "84 Train Loss 0.002983204 Test MSE 0.00014953418795107202 Test RE 0.028617527732008975\n",
      "85 Train Loss 0.0029169263 Test MSE 0.0001611771067707787 Test RE 0.02971074499633313\n",
      "86 Train Loss 0.002854767 Test MSE 0.00017239246766407684 Test RE 0.03072705991036054\n",
      "87 Train Loss 0.002837515 Test MSE 0.00016919975565930583 Test RE 0.030441197292542913\n",
      "88 Train Loss 0.0027863197 Test MSE 0.00016718496077514308 Test RE 0.030259410835502508\n",
      "89 Train Loss 0.0026701328 Test MSE 0.0001832731764914718 Test RE 0.03168190720438787\n",
      "90 Train Loss 0.0025094326 Test MSE 0.0001566370050787931 Test RE 0.029289303847197416\n",
      "91 Train Loss 0.002326829 Test MSE 0.00012757387051525563 Test RE 0.02643277322448108\n",
      "92 Train Loss 0.0022190153 Test MSE 0.00014124068920239282 Test RE 0.027812612056110814\n",
      "93 Train Loss 0.0021843216 Test MSE 0.00012577711423136567 Test RE 0.02624597296690439\n",
      "94 Train Loss 0.0021579303 Test MSE 0.00014276632653470873 Test RE 0.027962420125048116\n",
      "95 Train Loss 0.002122992 Test MSE 0.0001382160763651627 Test RE 0.027513202468773496\n",
      "96 Train Loss 0.0020922783 Test MSE 0.0001435533466370957 Test RE 0.028039387647488225\n",
      "97 Train Loss 0.0020244902 Test MSE 0.00016457951854121936 Test RE 0.030022700773001974\n",
      "98 Train Loss 0.0019733037 Test MSE 0.00015832560445948896 Test RE 0.02944675489395874\n",
      "99 Train Loss 0.0019386992 Test MSE 0.00013010712775938068 Test RE 0.026693923332138245\n",
      "100 Train Loss 0.0019217865 Test MSE 0.00012845197150374366 Test RE 0.026523586652410187\n",
      "101 Train Loss 0.0019114179 Test MSE 0.00011355428211340782 Test RE 0.024938114927683212\n",
      "102 Train Loss 0.0018954172 Test MSE 9.899307560290781e-05 Test RE 0.023284358256969166\n",
      "103 Train Loss 0.0018637674 Test MSE 8.002323051244294e-05 Test RE 0.020934852430607106\n",
      "104 Train Loss 0.0018159971 Test MSE 8.454721593705235e-05 Test RE 0.021518476473550954\n",
      "105 Train Loss 0.0017622645 Test MSE 7.94587369060915e-05 Test RE 0.02086088325451087\n",
      "106 Train Loss 0.0016970608 Test MSE 5.467019635472625e-05 Test RE 0.017303628438105848\n",
      "107 Train Loss 0.0016852667 Test MSE 5.634905675142645e-05 Test RE 0.017567306935760914\n",
      "108 Train Loss 0.001668593 Test MSE 5.2100842671621845e-05 Test RE 0.01689212310686176\n",
      "109 Train Loss 0.0016555496 Test MSE 4.616355114223467e-05 Test RE 0.015900525178100814\n",
      "110 Train Loss 0.0016155374 Test MSE 4.0775477718424025e-05 Test RE 0.014943811919965409\n",
      "111 Train Loss 0.0015443079 Test MSE 3.4297433394023625e-05 Test RE 0.013705430280721933\n",
      "112 Train Loss 0.0015039871 Test MSE 3.216656661508624e-05 Test RE 0.01327285096544415\n",
      "113 Train Loss 0.001446582 Test MSE 3.295914366172104e-05 Test RE 0.013435375960447239\n",
      "114 Train Loss 0.0013849307 Test MSE 4.191163621348621e-05 Test RE 0.015150576964566311\n",
      "115 Train Loss 0.0013059995 Test MSE 4.192599386118278e-05 Test RE 0.015153171805042614\n",
      "116 Train Loss 0.0012827609 Test MSE 3.904943997012762e-05 Test RE 0.01462410406845993\n",
      "117 Train Loss 0.0012758062 Test MSE 3.5466351416858004e-05 Test RE 0.013937026329834866\n",
      "118 Train Loss 0.001262722 Test MSE 3.781904424209318e-05 Test RE 0.014391867058013593\n",
      "119 Train Loss 0.0012410749 Test MSE 3.984388465843169e-05 Test RE 0.014772115721129284\n",
      "120 Train Loss 0.0011947514 Test MSE 2.7949683466456346e-05 Test RE 0.012372296263460404\n",
      "121 Train Loss 0.0011463962 Test MSE 2.3920851413979715e-05 Test RE 0.01144590615352366\n",
      "122 Train Loss 0.0011178465 Test MSE 2.5201656371148627e-05 Test RE 0.011748337300494656\n",
      "123 Train Loss 0.0010973667 Test MSE 2.3234599279613667e-05 Test RE 0.011280528767681815\n",
      "124 Train Loss 0.0010873142 Test MSE 2.3562184741566004e-05 Test RE 0.01135977272255995\n",
      "125 Train Loss 0.0010814283 Test MSE 2.3046817558345997e-05 Test RE 0.011234851748717793\n",
      "126 Train Loss 0.0010710768 Test MSE 2.7575213781072112e-05 Test RE 0.012289134800743394\n",
      "127 Train Loss 0.0010610687 Test MSE 2.9455120177301496e-05 Test RE 0.012701127144333817\n",
      "128 Train Loss 0.001028982 Test MSE 2.5177278853315062e-05 Test RE 0.011742653852772547\n",
      "129 Train Loss 0.0009798886 Test MSE 3.2025688784867676e-05 Test RE 0.013243753948679332\n",
      "130 Train Loss 0.0009545882 Test MSE 3.253719977684301e-05 Test RE 0.01334909891007119\n",
      "131 Train Loss 0.00094493025 Test MSE 3.224867304758124e-05 Test RE 0.013289779907694133\n",
      "132 Train Loss 0.00093743054 Test MSE 2.547174322520096e-05 Test RE 0.01181112315857077\n",
      "133 Train Loss 0.0009296288 Test MSE 2.529867156190072e-05 Test RE 0.011770928521766833\n",
      "134 Train Loss 0.0009228181 Test MSE 2.4484890657717027e-05 Test RE 0.011580063703328244\n",
      "135 Train Loss 0.00091635395 Test MSE 2.899900961660564e-05 Test RE 0.012602405427439114\n",
      "136 Train Loss 0.00091216335 Test MSE 2.7144587503057413e-05 Test RE 0.012192801043144947\n",
      "137 Train Loss 0.0009063808 Test MSE 2.576144716967876e-05 Test RE 0.011878100408243589\n",
      "138 Train Loss 0.00088730763 Test MSE 2.8431184741318397e-05 Test RE 0.012478412633959572\n",
      "139 Train Loss 0.0008537285 Test MSE 2.2367135302927117e-05 Test RE 0.01106794638000306\n",
      "140 Train Loss 0.0008306164 Test MSE 2.031121118966141e-05 Test RE 0.01054702013142166\n",
      "141 Train Loss 0.0008136702 Test MSE 2.2920076356337666e-05 Test RE 0.011203917289996987\n",
      "142 Train Loss 0.0008032772 Test MSE 2.2492605881905045e-05 Test RE 0.011098946316994119\n",
      "143 Train Loss 0.0007877129 Test MSE 2.770882690833071e-05 Test RE 0.012318871750786501\n",
      "144 Train Loss 0.00077277643 Test MSE 2.3423398179079412e-05 Test RE 0.01132626750445301\n",
      "145 Train Loss 0.00076470425 Test MSE 2.5790587794019125e-05 Test RE 0.01188481659600858\n",
      "146 Train Loss 0.0007594092 Test MSE 2.7538016216019683e-05 Test RE 0.01228084329376188\n",
      "147 Train Loss 0.0007513228 Test MSE 2.671187133988978e-05 Test RE 0.012095226934816116\n",
      "148 Train Loss 0.00074507564 Test MSE 2.2869009482298113e-05 Test RE 0.011191428935409383\n",
      "149 Train Loss 0.00073619693 Test MSE 2.4388402472016558e-05 Test RE 0.01155722426515545\n",
      "150 Train Loss 0.0007275174 Test MSE 2.2233059023902738e-05 Test RE 0.01103472398558154\n",
      "151 Train Loss 0.0007213094 Test MSE 2.232583016182961e-05 Test RE 0.011057722130556278\n",
      "152 Train Loss 0.0007160511 Test MSE 2.1369957722565046e-05 Test RE 0.010818416453295655\n",
      "153 Train Loss 0.0007090449 Test MSE 2.1892197093400384e-05 Test RE 0.010949808873825517\n",
      "154 Train Loss 0.000694212 Test MSE 2.2736538675901516e-05 Test RE 0.01115896817686569\n",
      "155 Train Loss 0.00067350076 Test MSE 2.468676064706148e-05 Test RE 0.011627702649374589\n",
      "156 Train Loss 0.00065596524 Test MSE 2.6865994354104905e-05 Test RE 0.012130070461434909\n",
      "157 Train Loss 0.0006392555 Test MSE 2.762084233802786e-05 Test RE 0.012299297980653134\n",
      "158 Train Loss 0.000623064 Test MSE 3.2179321776244265e-05 Test RE 0.01327548227787753\n",
      "159 Train Loss 0.000606893 Test MSE 3.262131708599175e-05 Test RE 0.013366343256261456\n",
      "160 Train Loss 0.00059437496 Test MSE 3.2958427131571105e-05 Test RE 0.013435229917449693\n",
      "161 Train Loss 0.00058897224 Test MSE 3.074222693859038e-05 Test RE 0.012975662058547676\n",
      "162 Train Loss 0.0005827203 Test MSE 3.2072270755119775e-05 Test RE 0.013253382094214254\n",
      "163 Train Loss 0.0005736885 Test MSE 3.3641850754644066e-05 Test RE 0.013573811191163328\n",
      "164 Train Loss 0.00056724105 Test MSE 3.4956956041577273e-05 Test RE 0.013836577126810638\n",
      "165 Train Loss 0.00056504953 Test MSE 3.527395026753026e-05 Test RE 0.013899171484509391\n",
      "166 Train Loss 0.0005627071 Test MSE 3.593006316753002e-05 Test RE 0.014027841636989405\n",
      "167 Train Loss 0.00056035543 Test MSE 3.643580334815185e-05 Test RE 0.014126222378967643\n",
      "168 Train Loss 0.0005528333 Test MSE 3.6373555935837146e-05 Test RE 0.014114150507483748\n",
      "169 Train Loss 0.00054800615 Test MSE 3.5099783456940996e-05 Test RE 0.01386481511215704\n",
      "170 Train Loss 0.0005455724 Test MSE 3.5052334471819316e-05 Test RE 0.013855440497496383\n",
      "171 Train Loss 0.0005415522 Test MSE 3.7519965098920076e-05 Test RE 0.014334847493391435\n",
      "172 Train Loss 0.00053699594 Test MSE 3.9341481986939294e-05 Test RE 0.014678687404128041\n",
      "173 Train Loss 0.00053056644 Test MSE 4.105771384059317e-05 Test RE 0.01499544111616829\n",
      "174 Train Loss 0.00052362384 Test MSE 4.352108958251234e-05 Test RE 0.015438736106354545\n",
      "175 Train Loss 0.00051300577 Test MSE 5.1275119074894306e-05 Test RE 0.016757730541526634\n",
      "176 Train Loss 0.0004944162 Test MSE 5.187499782798623e-05 Test RE 0.016855471663520874\n",
      "177 Train Loss 0.00048202474 Test MSE 5.6434789348736245e-05 Test RE 0.01758066579667946\n",
      "178 Train Loss 0.00047075524 Test MSE 5.3293793511062054e-05 Test RE 0.017084417718211495\n",
      "179 Train Loss 0.00046628527 Test MSE 5.365975394412704e-05 Test RE 0.017142975421893643\n",
      "180 Train Loss 0.0004618711 Test MSE 5.274062902493114e-05 Test RE 0.016995522337146084\n",
      "181 Train Loss 0.00045662507 Test MSE 5.248106808787734e-05 Test RE 0.0169536493562682\n",
      "182 Train Loss 0.00045415823 Test MSE 5.035304040374033e-05 Test RE 0.01660637013642492\n",
      "183 Train Loss 0.00045140888 Test MSE 5.259780940670252e-05 Test RE 0.01697249512320896\n",
      "184 Train Loss 0.00044545188 Test MSE 5.4860975856455755e-05 Test RE 0.017333793892615225\n",
      "185 Train Loss 0.00043881254 Test MSE 5.9011817286052164e-05 Test RE 0.017977585320933465\n",
      "186 Train Loss 0.00043340595 Test MSE 6.441948314051527e-05 Test RE 0.01878323889153713\n",
      "187 Train Loss 0.0004283087 Test MSE 6.9144456753344e-05 Test RE 0.019459897502911546\n",
      "188 Train Loss 0.00042496127 Test MSE 7.205571749335172e-05 Test RE 0.01986534388984604\n",
      "189 Train Loss 0.00042075466 Test MSE 6.949201022430199e-05 Test RE 0.019508743625644476\n",
      "190 Train Loss 0.00041161207 Test MSE 6.937396263803969e-05 Test RE 0.019492166619581232\n",
      "191 Train Loss 0.0004049241 Test MSE 7.315900175269578e-05 Test RE 0.020016850681739133\n",
      "192 Train Loss 0.0004002253 Test MSE 7.135146907819026e-05 Test RE 0.01976802691596038\n",
      "193 Train Loss 0.0003974887 Test MSE 7.45744475005148e-05 Test RE 0.02020956130630843\n",
      "194 Train Loss 0.0003947179 Test MSE 7.344121401143157e-05 Test RE 0.02005542121447236\n",
      "195 Train Loss 0.0003934024 Test MSE 7.46720548302549e-05 Test RE 0.02022278270008972\n",
      "196 Train Loss 0.00039063764 Test MSE 7.66136013660056e-05 Test RE 0.02048400168388488\n",
      "197 Train Loss 0.00038899563 Test MSE 7.319848381627686e-05 Test RE 0.02002225124731563\n",
      "198 Train Loss 0.00038551277 Test MSE 7.27125641004994e-05 Test RE 0.019955682880739158\n",
      "199 Train Loss 0.00038194665 Test MSE 7.350440599079536e-05 Test RE 0.020064047632750943\n",
      "200 Train Loss 0.0003791973 Test MSE 7.413764538694317e-05 Test RE 0.020150288031434\n",
      "201 Train Loss 0.0003770795 Test MSE 7.383547200344189e-05 Test RE 0.02010918140006293\n",
      "202 Train Loss 0.00037324865 Test MSE 7.315933645176304e-05 Test RE 0.02001689646977226\n",
      "203 Train Loss 0.0003691695 Test MSE 6.995420266058832e-05 Test RE 0.019573512587281416\n",
      "204 Train Loss 0.00036563768 Test MSE 6.723037168787119e-05 Test RE 0.019188658782252847\n",
      "205 Train Loss 0.00036336645 Test MSE 6.675656440520319e-05 Test RE 0.01912092301589169\n",
      "206 Train Loss 0.00036123378 Test MSE 6.938034927134385e-05 Test RE 0.019493063832676388\n",
      "207 Train Loss 0.00035915113 Test MSE 7.274226232872622e-05 Test RE 0.019959757746822966\n",
      "208 Train Loss 0.00035648188 Test MSE 7.225877339482958e-05 Test RE 0.01989331486573778\n",
      "209 Train Loss 0.0003530703 Test MSE 7.499795378637601e-05 Test RE 0.02026686484330286\n",
      "210 Train Loss 0.00034922993 Test MSE 6.669878922963511e-05 Test RE 0.019112647022217103\n",
      "211 Train Loss 0.00034603215 Test MSE 6.475112299821932e-05 Test RE 0.018831526099593727\n",
      "212 Train Loss 0.00034253366 Test MSE 6.831636863856942e-05 Test RE 0.019343018657139922\n",
      "213 Train Loss 0.00033849524 Test MSE 6.684104316454866e-05 Test RE 0.01913301771517136\n",
      "214 Train Loss 0.00033536102 Test MSE 6.33513445610152e-05 Test RE 0.01862686566132256\n",
      "215 Train Loss 0.00033318414 Test MSE 6.384964723731763e-05 Test RE 0.0186999788407551\n",
      "216 Train Loss 0.0003314124 Test MSE 6.16010124457402e-05 Test RE 0.01836774278587161\n",
      "217 Train Loss 0.00032957704 Test MSE 5.977763515629626e-05 Test RE 0.018093860141663764\n",
      "218 Train Loss 0.0003271698 Test MSE 5.936432735673009e-05 Test RE 0.01803120037898093\n",
      "219 Train Loss 0.0003248003 Test MSE 5.949977335126958e-05 Test RE 0.018051758704987025\n",
      "220 Train Loss 0.0003219568 Test MSE 5.8064294719033024e-05 Test RE 0.017832672824341846\n",
      "221 Train Loss 0.00031805216 Test MSE 6.209861481522034e-05 Test RE 0.018441779304479194\n",
      "222 Train Loss 0.00031331522 Test MSE 6.0937705184271094e-05 Test RE 0.0182685850633954\n",
      "223 Train Loss 0.0003094364 Test MSE 6.262967543641772e-05 Test RE 0.01852046747802664\n",
      "224 Train Loss 0.00030594374 Test MSE 6.327299573379715e-05 Test RE 0.018615343849202375\n",
      "225 Train Loss 0.00030288112 Test MSE 6.261097004104975e-05 Test RE 0.018517701548497256\n",
      "226 Train Loss 0.0003012903 Test MSE 6.086244607363733e-05 Test RE 0.018257300570306154\n",
      "227 Train Loss 0.00029803716 Test MSE 6.335747124600966e-05 Test RE 0.018627766338175724\n",
      "228 Train Loss 0.0002947477 Test MSE 5.6793333268288356e-05 Test RE 0.017636424494029346\n",
      "229 Train Loss 0.0002916757 Test MSE 5.059648423248683e-05 Test RE 0.01664646546829971\n",
      "230 Train Loss 0.0002892842 Test MSE 4.840598764153107e-05 Test RE 0.0162821370825673\n",
      "231 Train Loss 0.00028761127 Test MSE 4.708509554362908e-05 Test RE 0.016058448825042735\n",
      "232 Train Loss 0.00028640355 Test MSE 4.506172043436877e-05 Test RE 0.015709622476022388\n",
      "233 Train Loss 0.00028384262 Test MSE 4.368198797585362e-05 Test RE 0.01546724844577298\n",
      "234 Train Loss 0.00028153585 Test MSE 3.9958478873112184e-05 Test RE 0.014793343365037733\n",
      "235 Train Loss 0.00027821463 Test MSE 4.144322906077008e-05 Test RE 0.015065677173433933\n",
      "236 Train Loss 0.00027256645 Test MSE 4.751480658700999e-05 Test RE 0.016131559224668874\n",
      "237 Train Loss 0.00026902257 Test MSE 4.414344508319801e-05 Test RE 0.015548731923095908\n",
      "238 Train Loss 0.00026611442 Test MSE 4.540180185594268e-05 Test RE 0.015768791416705032\n",
      "239 Train Loss 0.00026273748 Test MSE 4.83098984467767e-05 Test RE 0.016265968477014094\n",
      "240 Train Loss 0.00025997643 Test MSE 5.0083027244858525e-05 Test RE 0.016561785283537266\n",
      "241 Train Loss 0.0002566543 Test MSE 5.1525902831989804e-05 Test RE 0.016798661119548537\n",
      "242 Train Loss 0.00025515934 Test MSE 5.320032752411947e-05 Test RE 0.017069429925169112\n",
      "243 Train Loss 0.00025311537 Test MSE 5.40126733879527e-05 Test RE 0.01719925758542337\n",
      "244 Train Loss 0.00025183996 Test MSE 5.1657790651412434e-05 Test RE 0.01682014665136947\n",
      "245 Train Loss 0.00025024547 Test MSE 4.917695258838445e-05 Test RE 0.0164112881314853\n",
      "246 Train Loss 0.00025007722 Test MSE 4.869912077119782e-05 Test RE 0.016331362706215446\n",
      "247 Train Loss 0.00024747968 Test MSE 4.65637824764324e-05 Test RE 0.01596930405475063\n",
      "248 Train Loss 0.00024535 Test MSE 4.36734578188913e-05 Test RE 0.015465738160814235\n",
      "249 Train Loss 0.0002440691 Test MSE 4.2989365914402875e-05 Test RE 0.015344134042792112\n",
      "250 Train Loss 0.00024264374 Test MSE 4.048026476050601e-05 Test RE 0.014889617325915351\n",
      "251 Train Loss 0.00024100067 Test MSE 3.922504261455149e-05 Test RE 0.014656948979384767\n",
      "252 Train Loss 0.00023924668 Test MSE 3.8066459339162895e-05 Test RE 0.014438866665334176\n",
      "253 Train Loss 0.00023902279 Test MSE 3.644456898634052e-05 Test RE 0.014127921503132104\n",
      "254 Train Loss 0.00023885924 Test MSE 3.6279406563067733e-05 Test RE 0.014095872126530731\n",
      "255 Train Loss 0.00023880407 Test MSE 3.610830795069708e-05 Test RE 0.014062593819490933\n",
      "256 Train Loss 0.00023880154 Test MSE 3.6073177484178096e-05 Test RE 0.014055751270925239\n",
      "257 Train Loss 0.00023785308 Test MSE 3.396109342149748e-05 Test RE 0.013638063124750228\n",
      "258 Train Loss 0.0002370048 Test MSE 3.448180253410232e-05 Test RE 0.013742218334520242\n",
      "259 Train Loss 0.00023679204 Test MSE 3.4476976289377195e-05 Test RE 0.013741256586224451\n",
      "260 Train Loss 0.00023620088 Test MSE 3.4335630720383875e-05 Test RE 0.013713060080726163\n",
      "261 Train Loss 0.0002355443 Test MSE 3.576577850110077e-05 Test RE 0.01399573482404796\n",
      "262 Train Loss 0.00023256257 Test MSE 3.522920693179108e-05 Test RE 0.01389035346685231\n",
      "263 Train Loss 0.00023075356 Test MSE 3.368196367291456e-05 Test RE 0.013581901158851665\n",
      "264 Train Loss 0.00022791587 Test MSE 3.5157731658378004e-05 Test RE 0.01387625549272167\n",
      "265 Train Loss 0.00022621146 Test MSE 3.663219988092598e-05 Test RE 0.014164242846686782\n",
      "266 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "267 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "268 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "269 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "270 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "271 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "272 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "273 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "274 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "275 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "276 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "277 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "278 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "279 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "280 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "281 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "282 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "283 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "284 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "285 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "286 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "287 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "288 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "289 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "290 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "291 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "292 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "293 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "294 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "295 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "296 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "297 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "298 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "299 Train Loss 0.00022469649 Test MSE 3.6363912737469546e-05 Test RE 0.014112279442478485\n",
      "Training time: 167.03\n",
      "KG_stan_low\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 3308.6548 Test MSE 3.84166915378898 Test RE 4.586927167029242\n",
      "1 Train Loss 342.2084 Test MSE 7.6488291020533135 Test RE 6.472310485977896\n",
      "2 Train Loss 86.11386 Test MSE 9.076843607596022 Test RE 7.050652173929066\n",
      "3 Train Loss 29.142393 Test MSE 10.314550570297474 Test RE 7.516004280639524\n",
      "4 Train Loss 17.418528 Test MSE 10.536980054724562 Test RE 7.596611961968796\n",
      "5 Train Loss 13.8628 Test MSE 10.645866514251304 Test RE 7.635761804284733\n",
      "6 Train Loss 12.554061 Test MSE 10.819637398746384 Test RE 7.697828252240237\n",
      "7 Train Loss 11.805938 Test MSE 10.819290745692918 Test RE 7.6977049349355635\n",
      "8 Train Loss 11.138503 Test MSE 10.542108616608406 Test RE 7.598460449623094\n",
      "9 Train Loss 10.492163 Test MSE 9.93367792495137 Test RE 7.375931954006134\n",
      "10 Train Loss 9.300645 Test MSE 8.697343181057605 Test RE 6.901685535770205\n",
      "11 Train Loss 7.9979877 Test MSE 8.114324691669589 Test RE 6.666349132698357\n",
      "12 Train Loss 7.236233 Test MSE 7.104602111117301 Test RE 6.23780428413918\n",
      "13 Train Loss 6.141565 Test MSE 5.317794233119555 Test RE 5.396691946330898\n",
      "14 Train Loss 4.9902554 Test MSE 4.110332028794997 Test RE 4.744607779843918\n",
      "15 Train Loss 3.934444 Test MSE 2.8553655443633894 Test RE 3.9545103936525283\n",
      "16 Train Loss 2.8878896 Test MSE 1.9684937808778187 Test RE 3.2834385102742263\n",
      "17 Train Loss 1.954064 Test MSE 1.0781262448206286 Test RE 2.4299462833171495\n",
      "18 Train Loss 1.15029 Test MSE 0.6116301325756406 Test RE 1.8302326587449655\n",
      "19 Train Loss 0.68517864 Test MSE 0.4140547478476384 Test RE 1.505881328580745\n",
      "20 Train Loss 0.45683047 Test MSE 0.36509687529658713 Test RE 1.4140537636416026\n",
      "21 Train Loss 0.37265858 Test MSE 0.2953670695300792 Test RE 1.271870519923155\n",
      "22 Train Loss 0.306862 Test MSE 0.27671386550400767 Test RE 1.231054626525744\n",
      "23 Train Loss 0.2516727 Test MSE 0.24834836355618298 Test RE 1.1662523056947127\n",
      "24 Train Loss 0.20956448 Test MSE 0.2257278585106019 Test RE 1.1118711068004847\n",
      "25 Train Loss 0.16969667 Test MSE 0.18150793788779587 Test RE 0.9970333271900156\n",
      "26 Train Loss 0.13646278 Test MSE 0.14357867015732367 Test RE 0.8867614958344582\n",
      "27 Train Loss 0.107290134 Test MSE 0.09219020010560883 Test RE 0.7105657052450163\n",
      "28 Train Loss 0.09376295 Test MSE 0.07493877659204212 Test RE 0.6406416402890901\n",
      "29 Train Loss 0.07995772 Test MSE 0.07128303476901991 Test RE 0.6248200459711177\n",
      "30 Train Loss 0.06595749 Test MSE 0.05293871996581169 Test RE 0.5384539684125582\n",
      "31 Train Loss 0.057357788 Test MSE 0.04060239186831271 Test RE 0.4715607755095356\n",
      "32 Train Loss 0.051471483 Test MSE 0.037703525248295316 Test RE 0.45441519295086813\n",
      "33 Train Loss 0.04438876 Test MSE 0.03575959069612585 Test RE 0.4425457085328875\n",
      "34 Train Loss 0.0401918 Test MSE 0.028472832405966375 Test RE 0.39489096740334473\n",
      "35 Train Loss 0.036511064 Test MSE 0.025186639479410827 Test RE 0.37140434220772994\n",
      "36 Train Loss 0.033211015 Test MSE 0.029400102791398187 Test RE 0.40126962719036885\n",
      "37 Train Loss 0.028070532 Test MSE 0.022145854175766228 Test RE 0.34826359757214304\n",
      "38 Train Loss 0.025957288 Test MSE 0.017997499221516906 Test RE 0.3139553916775535\n",
      "39 Train Loss 0.021658957 Test MSE 0.01361230012991285 Test RE 0.27304084672611023\n",
      "40 Train Loss 0.020807454 Test MSE 0.01235535929409395 Test RE 0.26012946853577557\n",
      "41 Train Loss 0.018045591 Test MSE 0.008928995966504032 Test RE 0.22113789814728968\n",
      "42 Train Loss 0.017436739 Test MSE 0.007876363947456923 Test RE 0.20769438321482755\n",
      "43 Train Loss 0.015780676 Test MSE 0.00718731298388646 Test RE 0.19840158745770803\n",
      "44 Train Loss 0.014907077 Test MSE 0.008684294076020924 Test RE 0.2180866717962533\n",
      "45 Train Loss 0.0135711245 Test MSE 0.00750740829312693 Test RE 0.20277148508844836\n",
      "46 Train Loss 0.012610091 Test MSE 0.006310599884912708 Test RE 0.18590761811385176\n",
      "47 Train Loss 0.011518115 Test MSE 0.0049343167093779065 Test RE 0.16438999213069805\n",
      "48 Train Loss 0.010768799 Test MSE 0.005225694199361423 Test RE 0.16917409423900662\n",
      "49 Train Loss 0.009512029 Test MSE 0.004790725852721461 Test RE 0.1619804210999054\n",
      "50 Train Loss 0.009356529 Test MSE 0.004415810813317409 Test RE 0.15551314106057118\n",
      "51 Train Loss 0.008633763 Test MSE 0.00454745886818773 Test RE 0.15781426384742495\n",
      "52 Train Loss 0.008042615 Test MSE 0.0038494645281195866 Test RE 0.14519846497720748\n",
      "53 Train Loss 0.007831564 Test MSE 0.003676644711292855 Test RE 0.14190173195597156\n",
      "54 Train Loss 0.007221732 Test MSE 0.0033135395456115988 Test RE 0.13471251464375908\n",
      "55 Train Loss 0.0066309343 Test MSE 0.003197529288801112 Test RE 0.1323332960405412\n",
      "56 Train Loss 0.0064090285 Test MSE 0.0027422492024730457 Test RE 0.12255056658765814\n",
      "57 Train Loss 0.0059837154 Test MSE 0.0020628884892647417 Test RE 0.10629179477035118\n",
      "58 Train Loss 0.00571433 Test MSE 0.0015235220970915568 Test RE 0.09134530765082026\n",
      "59 Train Loss 0.005496564 Test MSE 0.0014387706367283916 Test RE 0.08876824771465436\n",
      "60 Train Loss 0.005193702 Test MSE 0.0010443133709606173 Test RE 0.07562707145600515\n",
      "61 Train Loss 0.004985109 Test MSE 0.0011473851748547044 Test RE 0.07927139139274574\n",
      "62 Train Loss 0.0048726047 Test MSE 0.0009702966477142789 Test RE 0.07289775093123563\n",
      "63 Train Loss 0.0047654575 Test MSE 0.0009547161189450771 Test RE 0.07231010489909216\n",
      "64 Train Loss 0.004498842 Test MSE 0.0009440393780554297 Test RE 0.0719046404666254\n",
      "65 Train Loss 0.0041915644 Test MSE 0.0008191714265969171 Test RE 0.06698063518787738\n",
      "66 Train Loss 0.0041299844 Test MSE 0.0008159769962048907 Test RE 0.06684990920596057\n",
      "67 Train Loss 0.0039313715 Test MSE 0.0007466547435098281 Test RE 0.063947236095697\n",
      "68 Train Loss 0.0035945482 Test MSE 0.0006084931782261054 Test RE 0.057728426605217445\n",
      "69 Train Loss 0.0034887104 Test MSE 0.000530663806207637 Test RE 0.053910281291894666\n",
      "70 Train Loss 0.0034252214 Test MSE 0.0005316810958643705 Test RE 0.05396192991827565\n",
      "71 Train Loss 0.0032347732 Test MSE 0.00047455567881813613 Test RE 0.050980659748020546\n",
      "72 Train Loss 0.0030571327 Test MSE 0.00048256391109398957 Test RE 0.0514090151274939\n",
      "73 Train Loss 0.00298882 Test MSE 0.0004594498336762459 Test RE 0.05016270104809201\n",
      "74 Train Loss 0.002925773 Test MSE 0.00045022348968459976 Test RE 0.04965648097282859\n",
      "75 Train Loss 0.002778315 Test MSE 0.0004271843964277824 Test RE 0.048369272404457694\n",
      "76 Train Loss 0.0026572538 Test MSE 0.00043513523853569213 Test RE 0.04881732652227835\n",
      "77 Train Loss 0.0025905094 Test MSE 0.0004147677464281223 Test RE 0.04766113194246709\n",
      "78 Train Loss 0.0025487537 Test MSE 0.00042830922628985814 Test RE 0.048432911706710206\n",
      "79 Train Loss 0.00240218 Test MSE 0.0003881752977534811 Test RE 0.046107949778059605\n",
      "80 Train Loss 0.0022050904 Test MSE 0.0003843728768781549 Test RE 0.04588156585504673\n",
      "81 Train Loss 0.0021620258 Test MSE 0.00036527793637297775 Test RE 0.044727392888153375\n",
      "82 Train Loss 0.0021191023 Test MSE 0.0003644229809999037 Test RE 0.04467501862323224\n",
      "83 Train Loss 0.0020499425 Test MSE 0.00036039282249414095 Test RE 0.0444273010339811\n",
      "84 Train Loss 0.0019476861 Test MSE 0.00032535807388957587 Test RE 0.04221265401941332\n",
      "85 Train Loss 0.0018873478 Test MSE 0.0003177927247712935 Test RE 0.04171899514838357\n",
      "86 Train Loss 0.0017980437 Test MSE 0.00028355888360896085 Test RE 0.03940791819440024\n",
      "87 Train Loss 0.0017607487 Test MSE 0.00027629848482342226 Test RE 0.03890013564370936\n",
      "88 Train Loss 0.0017134062 Test MSE 0.00028718773130087283 Test RE 0.039659278172122864\n",
      "89 Train Loss 0.0016811228 Test MSE 0.00028847694173149955 Test RE 0.03974819545020234\n",
      "90 Train Loss 0.0016412801 Test MSE 0.0002860905181360757 Test RE 0.039583445677578225\n",
      "91 Train Loss 0.0015830839 Test MSE 0.0002802355628224343 Test RE 0.03917630642752913\n",
      "92 Train Loss 0.001535802 Test MSE 0.00028291856572910885 Test RE 0.039363398594608835\n",
      "93 Train Loss 0.001501297 Test MSE 0.0002915505676275754 Test RE 0.03995938630178002\n",
      "94 Train Loss 0.0014462805 Test MSE 0.00030132564889155737 Test RE 0.04062374096411747\n",
      "95 Train Loss 0.0014027983 Test MSE 0.00030731862088564666 Test RE 0.04102572851994588\n",
      "96 Train Loss 0.0013625857 Test MSE 0.00032482518410936235 Test RE 0.0421780707217366\n",
      "97 Train Loss 0.001339358 Test MSE 0.0003208506369706521 Test RE 0.04191923195991329\n",
      "98 Train Loss 0.0013198893 Test MSE 0.00031726709462585683 Test RE 0.04168447919687854\n",
      "99 Train Loss 0.0012830764 Test MSE 0.00031368341371870246 Test RE 0.041448387723145096\n",
      "100 Train Loss 0.0012550432 Test MSE 0.00031890911432251313 Test RE 0.04179220925107199\n",
      "101 Train Loss 0.0012266138 Test MSE 0.0003147515886453529 Test RE 0.041518899103954926\n",
      "102 Train Loss 0.0012004162 Test MSE 0.0003015992803136636 Test RE 0.04064218182639554\n",
      "103 Train Loss 0.0011873904 Test MSE 0.0002909183126356837 Test RE 0.03991603493109645\n",
      "104 Train Loss 0.0011755581 Test MSE 0.0002903561010351176 Test RE 0.039877446589345146\n",
      "105 Train Loss 0.0011521238 Test MSE 0.0002785052271969363 Test RE 0.039055170617558144\n",
      "106 Train Loss 0.0011236644 Test MSE 0.00027706537503930306 Test RE 0.03895408357198983\n",
      "107 Train Loss 0.0010786944 Test MSE 0.00026722958625738266 Test RE 0.03825640299490887\n",
      "108 Train Loss 0.0010502115 Test MSE 0.0002737752327626801 Test RE 0.03872210359167222\n",
      "109 Train Loss 0.0010310112 Test MSE 0.0002763110639550173 Test RE 0.03890102114323769\n",
      "110 Train Loss 0.0010142793 Test MSE 0.0002781678452166363 Test RE 0.039031507679755155\n",
      "111 Train Loss 0.0010044219 Test MSE 0.0002694701875549682 Test RE 0.03841644968220287\n",
      "112 Train Loss 0.0009987353 Test MSE 0.0002654202850725047 Test RE 0.03812667388242374\n",
      "113 Train Loss 0.0009814845 Test MSE 0.00026136338324741517 Test RE 0.037834172156488835\n",
      "114 Train Loss 0.00096565223 Test MSE 0.0002464635138897924 Test RE 0.03673991794829053\n",
      "115 Train Loss 0.00094279635 Test MSE 0.0002377143943780653 Test RE 0.03608191709241392\n",
      "116 Train Loss 0.0009288682 Test MSE 0.00023477456488082046 Test RE 0.0358581092612588\n",
      "117 Train Loss 0.0009106882 Test MSE 0.00022544011327565734 Test RE 0.035138034186317495\n",
      "118 Train Loss 0.00089248765 Test MSE 0.00022096673274282105 Test RE 0.034787667554551836\n",
      "119 Train Loss 0.000877442 Test MSE 0.00021810191581669337 Test RE 0.03456142211311267\n",
      "120 Train Loss 0.0008652332 Test MSE 0.00021940510708943467 Test RE 0.034664523141310986\n",
      "121 Train Loss 0.0008491889 Test MSE 0.00021200973999896131 Test RE 0.03407530648801632\n",
      "122 Train Loss 0.0008358132 Test MSE 0.00020812157601390104 Test RE 0.03376139763655884\n",
      "123 Train Loss 0.00082681235 Test MSE 0.00021338597416233537 Test RE 0.03418572533652648\n",
      "124 Train Loss 0.00081393105 Test MSE 0.0002105752954771151 Test RE 0.03395983515189452\n",
      "125 Train Loss 0.0007946571 Test MSE 0.00022272095016258428 Test RE 0.03492548127204745\n",
      "126 Train Loss 0.0007766225 Test MSE 0.00022252885801407518 Test RE 0.03491041677558175\n",
      "127 Train Loss 0.00075161515 Test MSE 0.0002223204520012145 Test RE 0.03489406553673613\n",
      "128 Train Loss 0.0007371315 Test MSE 0.000227498752794608 Test RE 0.03529810365335067\n",
      "129 Train Loss 0.0007259115 Test MSE 0.00023564493969804423 Test RE 0.035924515779282774\n",
      "130 Train Loss 0.0007145458 Test MSE 0.00023789373521284913 Test RE 0.03609552531568514\n",
      "131 Train Loss 0.00070492673 Test MSE 0.00023279663849873366 Test RE 0.03570674125772979\n",
      "132 Train Loss 0.00069585384 Test MSE 0.00023175984339708899 Test RE 0.035627139838441055\n",
      "133 Train Loss 0.00068860175 Test MSE 0.00023414866607414378 Test RE 0.03581027927984361\n",
      "134 Train Loss 0.0006776455 Test MSE 0.00022491203814888565 Test RE 0.035096856064702246\n",
      "135 Train Loss 0.00066845067 Test MSE 0.0002250400163602214 Test RE 0.03510683995469386\n",
      "136 Train Loss 0.0006604819 Test MSE 0.0002227712922244834 Test RE 0.03492942818722642\n",
      "137 Train Loss 0.0006544091 Test MSE 0.00022011761531076033 Test RE 0.03472076325923863\n",
      "138 Train Loss 0.0006488822 Test MSE 0.00021669463916291888 Test RE 0.03444973993619877\n",
      "139 Train Loss 0.0006416447 Test MSE 0.0002050343836645256 Test RE 0.033510060550446\n",
      "140 Train Loss 0.00063294865 Test MSE 0.00020287914475812348 Test RE 0.03333347313688325\n",
      "141 Train Loss 0.00061725924 Test MSE 0.00019302257202452613 Test RE 0.032513663986432975\n",
      "142 Train Loss 0.0006008509 Test MSE 0.0001782083150760722 Test RE 0.031241066123623668\n",
      "143 Train Loss 0.0005900763 Test MSE 0.00017318167012778492 Test RE 0.030797312925010107\n",
      "144 Train Loss 0.00058473716 Test MSE 0.0001760693993813147 Test RE 0.031053017311200783\n",
      "145 Train Loss 0.00057936343 Test MSE 0.00017367981176365422 Test RE 0.03084157398222221\n",
      "146 Train Loss 0.00057356816 Test MSE 0.00017301866896252114 Test RE 0.030782816068413023\n",
      "147 Train Loss 0.0005676599 Test MSE 0.00017238011163888818 Test RE 0.030725958727882523\n",
      "148 Train Loss 0.00055875804 Test MSE 0.00016913524722985955 Test RE 0.030435393794112066\n",
      "149 Train Loss 0.0005491064 Test MSE 0.0001699834572937738 Test RE 0.03051161481381836\n",
      "150 Train Loss 0.0005433044 Test MSE 0.00017353043067716955 Test RE 0.030828307791823665\n",
      "151 Train Loss 0.0005382049 Test MSE 0.00016955889220535692 Test RE 0.030473486793536217\n",
      "152 Train Loss 0.00053196395 Test MSE 0.0001709520289170904 Test RE 0.030598419454158685\n",
      "153 Train Loss 0.0005297126 Test MSE 0.0001722322567476801 Test RE 0.030712778675327696\n",
      "154 Train Loss 0.00052564504 Test MSE 0.00017188829130038454 Test RE 0.03068209506662899\n",
      "155 Train Loss 0.00052156765 Test MSE 0.00017584499416667716 Test RE 0.031033222046299994\n",
      "156 Train Loss 0.0005158735 Test MSE 0.00017939131588099803 Test RE 0.03134458843724516\n",
      "157 Train Loss 0.00051104696 Test MSE 0.0001802847295667419 Test RE 0.0314225434496109\n",
      "158 Train Loss 0.00050298526 Test MSE 0.00017600580921191681 Test RE 0.031047409167577932\n",
      "159 Train Loss 0.0004986344 Test MSE 0.00017354993091994646 Test RE 0.030830039887446106\n",
      "160 Train Loss 0.00049615 Test MSE 0.00017430281562436626 Test RE 0.030896840104902946\n",
      "161 Train Loss 0.00049593137 Test MSE 0.00017419479553732644 Test RE 0.030887264824701985\n",
      "162 Train Loss 0.00049335934 Test MSE 0.0001744269195949498 Test RE 0.03090783745522048\n",
      "163 Train Loss 0.0004924485 Test MSE 0.0001727398945551613 Test RE 0.030758006835856087\n",
      "164 Train Loss 0.00048821635 Test MSE 0.00017117170116037262 Test RE 0.03061807252748167\n",
      "165 Train Loss 0.00047995383 Test MSE 0.00016591432561426875 Test RE 0.030144203091086844\n",
      "166 Train Loss 0.00046887746 Test MSE 0.00016393482974899284 Test RE 0.029963840804670988\n",
      "167 Train Loss 0.0004614603 Test MSE 0.00016304438786559592 Test RE 0.02988235297084499\n",
      "168 Train Loss 0.0004504567 Test MSE 0.0001663442612561907 Test RE 0.03018323432671736\n",
      "169 Train Loss 0.00044307148 Test MSE 0.00016776231736516934 Test RE 0.030311614733004755\n",
      "170 Train Loss 0.00043784553 Test MSE 0.00016687479225992483 Test RE 0.03023132854380031\n",
      "171 Train Loss 0.00043021818 Test MSE 0.00016973978467629562 Test RE 0.030489737651322023\n",
      "172 Train Loss 0.00042199026 Test MSE 0.00017537955455207435 Test RE 0.030992124312550093\n",
      "173 Train Loss 0.00041681103 Test MSE 0.00017508559263252412 Test RE 0.03096613974092726\n",
      "174 Train Loss 0.00041068924 Test MSE 0.00017330813344307696 Test RE 0.030808555510712484\n",
      "175 Train Loss 0.00040500195 Test MSE 0.00017277995766030926 Test RE 0.03076157344050377\n",
      "176 Train Loss 0.00040109397 Test MSE 0.000171267480233523 Test RE 0.030626637496087575\n",
      "177 Train Loss 0.00039640197 Test MSE 0.0001646182509114574 Test RE 0.030026233357018317\n",
      "178 Train Loss 0.00038981604 Test MSE 0.00016141346049168673 Test RE 0.029732521267054567\n",
      "179 Train Loss 0.00038113768 Test MSE 0.0001650280126997875 Test RE 0.030063580237156322\n",
      "180 Train Loss 0.00037403268 Test MSE 0.00016719073496678706 Test RE 0.03025993337690746\n",
      "181 Train Loss 0.0003697851 Test MSE 0.00016947750766712136 Test RE 0.030466172614122978\n",
      "182 Train Loss 0.00036584365 Test MSE 0.00017188672758371086 Test RE 0.030681955504438932\n",
      "183 Train Loss 0.0003622986 Test MSE 0.00017312341822368048 Test RE 0.03079213295128017\n",
      "184 Train Loss 0.00036009526 Test MSE 0.0001740803824177366 Test RE 0.030877119605432626\n",
      "185 Train Loss 0.0003568687 Test MSE 0.0001733671735371248 Test RE 0.030813802769143372\n",
      "186 Train Loss 0.00035285388 Test MSE 0.00017119765177788464 Test RE 0.03062039337774816\n",
      "187 Train Loss 0.00034513528 Test MSE 0.00017378282917018893 Test RE 0.030850719397380707\n",
      "188 Train Loss 0.00034049994 Test MSE 0.0001729762952934671 Test RE 0.030779046357486482\n",
      "189 Train Loss 0.00033723438 Test MSE 0.00017666893049799048 Test RE 0.03110584144989135\n",
      "190 Train Loss 0.00033310938 Test MSE 0.00017063094981506472 Test RE 0.030569671241873056\n",
      "191 Train Loss 0.00032930053 Test MSE 0.0001691753569154925 Test RE 0.03043900239058041\n",
      "192 Train Loss 0.00032405986 Test MSE 0.00016196639808298868 Test RE 0.029783403558109076\n",
      "193 Train Loss 0.00031938893 Test MSE 0.0001591242095264247 Test RE 0.029520927191644925\n",
      "194 Train Loss 0.0003161231 Test MSE 0.0001568547691984962 Test RE 0.029309656458641985\n",
      "195 Train Loss 0.00031312913 Test MSE 0.000150087907169241 Test RE 0.028670463562429093\n",
      "196 Train Loss 0.0003106905 Test MSE 0.0001451500587966346 Test RE 0.02819489438354275\n",
      "197 Train Loss 0.00031034334 Test MSE 0.00014395282729157634 Test RE 0.02807837458627106\n",
      "198 Train Loss 0.0003102879 Test MSE 0.0001437626688096609 Test RE 0.028059823003645838\n",
      "199 Train Loss 0.00030826096 Test MSE 0.00014143234757958386 Test RE 0.027831476000412452\n",
      "200 Train Loss 0.00030529528 Test MSE 0.00014162920474030806 Test RE 0.027850838332629118\n",
      "201 Train Loss 0.0003010337 Test MSE 0.00013844185909081552 Test RE 0.027535665380376127\n",
      "202 Train Loss 0.0002957984 Test MSE 0.00013725715909133134 Test RE 0.02741759562943491\n",
      "203 Train Loss 0.00029271995 Test MSE 0.00013515904010491726 Test RE 0.027207235351612985\n",
      "204 Train Loss 0.000290756 Test MSE 0.00013491030120146527 Test RE 0.027182188509098232\n",
      "205 Train Loss 0.0002887515 Test MSE 0.0001346413039184268 Test RE 0.027155075741426598\n",
      "206 Train Loss 0.00028718016 Test MSE 0.0001341166992175486 Test RE 0.027102121768613197\n",
      "207 Train Loss 0.0002855638 Test MSE 0.00013467243606664464 Test RE 0.027158214997194268\n",
      "208 Train Loss 0.00028552348 Test MSE 0.00013460427851089517 Test RE 0.027151341757695357\n",
      "209 Train Loss 0.00028473517 Test MSE 0.00013420355605901839 Test RE 0.02711089630491294\n",
      "210 Train Loss 0.00028196667 Test MSE 0.0001334450675785463 Test RE 0.02703417538804364\n",
      "211 Train Loss 0.00027930623 Test MSE 0.00013410388525877083 Test RE 0.027100827023929044\n",
      "212 Train Loss 0.00027678566 Test MSE 0.00013372996996569738 Test RE 0.027063018696640045\n",
      "213 Train Loss 0.00027562698 Test MSE 0.00013190903163648796 Test RE 0.02687813494930874\n",
      "214 Train Loss 0.0002746812 Test MSE 0.0001314151027368528 Test RE 0.026827765620707666\n",
      "215 Train Loss 0.0002734326 Test MSE 0.0001313341329773498 Test RE 0.0268194995523966\n",
      "216 Train Loss 0.00027136327 Test MSE 0.0001298630312463789 Test RE 0.026668871081985332\n",
      "217 Train Loss 0.00026967132 Test MSE 0.00013009545120681217 Test RE 0.02669272547312004\n",
      "218 Train Loss 0.00026681577 Test MSE 0.00012930597092322685 Test RE 0.026611610228702603\n",
      "219 Train Loss 0.0002631144 Test MSE 0.00012921289653152496 Test RE 0.02660203099083882\n",
      "220 Train Loss 0.00026062748 Test MSE 0.00012825212042743688 Test RE 0.02650294535483575\n",
      "221 Train Loss 0.00025697783 Test MSE 0.00012481306713677957 Test RE 0.026145195394042614\n",
      "222 Train Loss 0.00025442432 Test MSE 0.00012353929440706373 Test RE 0.02601144160490499\n",
      "223 Train Loss 0.00025305184 Test MSE 0.0001226090639443288 Test RE 0.025913325629162015\n",
      "224 Train Loss 0.0002512978 Test MSE 0.00012241933221823087 Test RE 0.02589326804386139\n",
      "225 Train Loss 0.00024991517 Test MSE 0.00012335903034275128 Test RE 0.025992457200256818\n",
      "226 Train Loss 0.00024965408 Test MSE 0.00012350632852601085 Test RE 0.0260079708577795\n",
      "227 Train Loss 0.00024876025 Test MSE 0.00012280411723073823 Test RE 0.02593392961439874\n",
      "228 Train Loss 0.0002487529 Test MSE 0.00012284732339406515 Test RE 0.02593849137944529\n",
      "229 Train Loss 0.00024722042 Test MSE 0.00012415653342982724 Test RE 0.02607634108722369\n",
      "230 Train Loss 0.00024623092 Test MSE 0.00012390328529436075 Test RE 0.02604973291956678\n",
      "231 Train Loss 0.00024544023 Test MSE 0.00012423488435796102 Test RE 0.026084567731598757\n",
      "232 Train Loss 0.00024527553 Test MSE 0.00012428438931252748 Test RE 0.02608976428622317\n",
      "233 Train Loss 0.00024436467 Test MSE 0.00012474405243697106 Test RE 0.02613796597345551\n",
      "234 Train Loss 0.00024340753 Test MSE 0.00012490649428242436 Test RE 0.026154978881051925\n",
      "235 Train Loss 0.00024188543 Test MSE 0.00012434487998549108 Test RE 0.02609611261131851\n",
      "236 Train Loss 0.00024074456 Test MSE 0.00012313978713850287 Test RE 0.025969349026219522\n",
      "237 Train Loss 0.00023913773 Test MSE 0.00012196624018703651 Test RE 0.025845306219400694\n",
      "238 Train Loss 0.00023718577 Test MSE 0.00011932208880687905 Test RE 0.025563616145910885\n",
      "239 Train Loss 0.00023602897 Test MSE 0.00011829855911069355 Test RE 0.025453739287615313\n",
      "240 Train Loss 0.00023542745 Test MSE 0.00011849204721382744 Test RE 0.025474546741207766\n",
      "241 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "242 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "243 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "244 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "245 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "246 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "247 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "248 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "249 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "250 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "251 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "252 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "253 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "254 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "255 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "256 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "257 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "258 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "259 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "260 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "261 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "262 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "263 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "264 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "265 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "266 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "267 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "268 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "269 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "270 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "271 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "272 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "273 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "274 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "275 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "276 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "277 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "278 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "279 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "280 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "281 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "282 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "283 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "284 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "285 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "286 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "287 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "288 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "289 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "290 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "291 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "292 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "293 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "294 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "295 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "296 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "297 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "298 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "299 Train Loss 0.00023523578 Test MSE 0.00011879918327840715 Test RE 0.025507540889969295\n",
      "Training time: 153.56\n",
      "KG_stan_low\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 3620.2063 Test MSE 0.9694885402436045 Test RE 2.3042691422609614\n",
      "1 Train Loss 78.44832 Test MSE 0.13094414263494022 Test RE 0.8468469003567753\n",
      "2 Train Loss 15.758945 Test MSE 0.12184038542092064 Test RE 0.8168785571900269\n",
      "3 Train Loss 6.416374 Test MSE 0.11160059502072599 Test RE 0.7817990153336236\n",
      "4 Train Loss 3.8916233 Test MSE 0.045902343746665644 Test RE 0.501394186906634\n",
      "5 Train Loss 2.7251203 Test MSE 0.02422870770262976 Test RE 0.36427300579824984\n",
      "6 Train Loss 1.9590247 Test MSE 0.018496993507762002 Test RE 0.3182822621590461\n",
      "7 Train Loss 1.3511176 Test MSE 0.013815956447948436 Test RE 0.27507577284082246\n",
      "8 Train Loss 1.0154082 Test MSE 0.016106827253155084 Test RE 0.2970071226762322\n",
      "9 Train Loss 0.7713094 Test MSE 0.0188447773721091 Test RE 0.32126052860837256\n",
      "10 Train Loss 0.5910838 Test MSE 0.03279307886848304 Test RE 0.4237922016076622\n",
      "11 Train Loss 0.4905119 Test MSE 0.03757006906377714 Test RE 0.453610251273988\n",
      "12 Train Loss 0.41999096 Test MSE 0.03272590033171085 Test RE 0.4233578975347127\n",
      "13 Train Loss 0.3264027 Test MSE 0.03174752319279449 Test RE 0.41698150126993766\n",
      "14 Train Loss 0.23825416 Test MSE 0.029754491362097235 Test RE 0.40368083300452023\n",
      "15 Train Loss 0.20299979 Test MSE 0.0312437301861666 Test RE 0.4136597864173262\n",
      "16 Train Loss 0.1364544 Test MSE 0.022168145398365615 Test RE 0.34843882831178064\n",
      "17 Train Loss 0.11672248 Test MSE 0.023633626168506297 Test RE 0.35977173857045625\n",
      "18 Train Loss 0.095662825 Test MSE 0.024205611095682356 Test RE 0.3640993383335518\n",
      "19 Train Loss 0.084717155 Test MSE 0.019930418139664546 Test RE 0.3303848080962472\n",
      "20 Train Loss 0.07547986 Test MSE 0.019916617190388484 Test RE 0.33027039971918803\n",
      "21 Train Loss 0.06531531 Test MSE 0.022058459222351813 Test RE 0.34757573590339885\n",
      "22 Train Loss 0.05766364 Test MSE 0.021350397213966713 Test RE 0.3419517602548373\n",
      "23 Train Loss 0.05080317 Test MSE 0.02103975372522777 Test RE 0.33945498440406324\n",
      "24 Train Loss 0.03989555 Test MSE 0.01667193543492034 Test RE 0.3021724556202351\n",
      "25 Train Loss 0.03666212 Test MSE 0.015004033417180544 Test RE 0.28665919398899986\n",
      "26 Train Loss 0.030060338 Test MSE 0.011405334038302156 Test RE 0.24992854951554924\n",
      "27 Train Loss 0.028357867 Test MSE 0.010003765238063282 Test RE 0.23406884371731135\n",
      "28 Train Loss 0.026336009 Test MSE 0.010133827244019308 Test RE 0.23558553015990424\n",
      "29 Train Loss 0.022764718 Test MSE 0.008564992111737791 Test RE 0.2165834900492244\n",
      "30 Train Loss 0.019589208 Test MSE 0.008384162461945075 Test RE 0.21428496803937994\n",
      "31 Train Loss 0.0183325 Test MSE 0.008231703594171084 Test RE 0.2123277345614749\n",
      "32 Train Loss 0.015337863 Test MSE 0.006454251925345589 Test RE 0.18801167584665449\n",
      "33 Train Loss 0.014819183 Test MSE 0.005965468833701758 Test RE 0.1807524341678262\n",
      "34 Train Loss 0.013269046 Test MSE 0.00528412047536357 Test RE 0.17011719744441897\n",
      "35 Train Loss 0.012814893 Test MSE 0.00600830551027804 Test RE 0.1814002443885428\n",
      "36 Train Loss 0.011725918 Test MSE 0.0061519920940322536 Test RE 0.1835564916629572\n",
      "37 Train Loss 0.011027661 Test MSE 0.0061024149435731125 Test RE 0.1828153808236501\n",
      "38 Train Loss 0.009436493 Test MSE 0.005659712855646855 Test RE 0.1760593373755282\n",
      "39 Train Loss 0.009301196 Test MSE 0.005444945381315834 Test RE 0.17268659564408873\n",
      "40 Train Loss 0.008918612 Test MSE 0.005578743854578938 Test RE 0.17479543035289707\n",
      "41 Train Loss 0.008292999 Test MSE 0.005497998070802436 Test RE 0.17352584007859764\n",
      "42 Train Loss 0.007766612 Test MSE 0.00527394748432017 Test RE 0.1699533637018809\n",
      "43 Train Loss 0.0076470855 Test MSE 0.005435505658033465 Test RE 0.1725368401649237\n",
      "44 Train Loss 0.007056146 Test MSE 0.005037334089408879 Test RE 0.1660971733733362\n",
      "45 Train Loss 0.0069819707 Test MSE 0.004980311773759741 Test RE 0.16515439277258678\n",
      "46 Train Loss 0.0068520615 Test MSE 0.004861938008986638 Test RE 0.16317986617527014\n",
      "47 Train Loss 0.006462932 Test MSE 0.003946676836779557 Test RE 0.14702041605710914\n",
      "48 Train Loss 0.006161469 Test MSE 0.003670783219474197 Test RE 0.14178857340007187\n",
      "49 Train Loss 0.0060428954 Test MSE 0.0035065230030351486 Test RE 0.13857988932805745\n",
      "50 Train Loss 0.0056034653 Test MSE 0.0028644684838368523 Test RE 0.12525177471949825\n",
      "51 Train Loss 0.0054044337 Test MSE 0.0028365592053451972 Test RE 0.1246401004649473\n",
      "52 Train Loss 0.005372051 Test MSE 0.0028389208943004223 Test RE 0.12469197667875882\n",
      "53 Train Loss 0.005041576 Test MSE 0.0025514472814237507 Test RE 0.1182102575840087\n",
      "54 Train Loss 0.0049960115 Test MSE 0.002435358091667625 Test RE 0.11548970664335736\n",
      "55 Train Loss 0.004936924 Test MSE 0.0024306262334037256 Test RE 0.11537745484893615\n",
      "56 Train Loss 0.0046773357 Test MSE 0.0022676857314188484 Test RE 0.11144312911258386\n",
      "57 Train Loss 0.004579692 Test MSE 0.0020044497836606318 Test RE 0.10477543059705183\n",
      "58 Train Loss 0.004505783 Test MSE 0.0018731799781736783 Test RE 0.10128651246240873\n",
      "59 Train Loss 0.0043779705 Test MSE 0.0015738972097262501 Test RE 0.09284318845907655\n",
      "60 Train Loss 0.004153142 Test MSE 0.0014501948979118698 Test RE 0.0891199738646121\n",
      "61 Train Loss 0.00399065 Test MSE 0.0012623938378724224 Test RE 0.08314943394265058\n",
      "62 Train Loss 0.003967846 Test MSE 0.0012288189271195027 Test RE 0.08203625191992289\n",
      "63 Train Loss 0.0039089303 Test MSE 0.0010701609668026598 Test RE 0.0765572662909448\n",
      "64 Train Loss 0.0037561299 Test MSE 0.0010096547459017787 Test RE 0.07436152874764586\n",
      "65 Train Loss 0.0036120657 Test MSE 0.0010388313103341896 Test RE 0.07542831037082982\n",
      "66 Train Loss 0.003536664 Test MSE 0.0010058794553637566 Test RE 0.07422237261509661\n",
      "67 Train Loss 0.0035074619 Test MSE 0.0009538811957461402 Test RE 0.07227847948281181\n",
      "68 Train Loss 0.0034126204 Test MSE 0.0007436176500051904 Test RE 0.06381704765468177\n",
      "69 Train Loss 0.003319067 Test MSE 0.0005881208780453423 Test RE 0.05675382837222919\n",
      "70 Train Loss 0.0032212315 Test MSE 0.0005237455771219611 Test RE 0.05355771603660425\n",
      "71 Train Loss 0.0031228722 Test MSE 0.0005145059759521554 Test RE 0.05308319759430545\n",
      "72 Train Loss 0.0030624801 Test MSE 0.0005375949806394221 Test RE 0.054261209067266516\n",
      "73 Train Loss 0.0030373903 Test MSE 0.0005939449177300061 Test RE 0.05703414682296322\n",
      "74 Train Loss 0.0029918558 Test MSE 0.0005303525269378046 Test RE 0.053894467499419466\n",
      "75 Train Loss 0.002809297 Test MSE 0.0005167363205222662 Test RE 0.053198129001641725\n",
      "76 Train Loss 0.002699955 Test MSE 0.0004898677695410393 Test RE 0.05179660527334002\n",
      "77 Train Loss 0.0026501133 Test MSE 0.0005186634165308803 Test RE 0.05329723418765131\n",
      "78 Train Loss 0.002625941 Test MSE 0.0005475097772446487 Test RE 0.05475928937788354\n",
      "79 Train Loss 0.0026041977 Test MSE 0.0005209341497207067 Test RE 0.05341377568828814\n",
      "80 Train Loss 0.0025783558 Test MSE 0.0005174086280791314 Test RE 0.05323272486511108\n",
      "81 Train Loss 0.0025117542 Test MSE 0.0004510920377236971 Test RE 0.04970435526151266\n",
      "82 Train Loss 0.0023521695 Test MSE 0.0003648037854956546 Test RE 0.04469835415206713\n",
      "83 Train Loss 0.0022792446 Test MSE 0.00033033612649838634 Test RE 0.04253435975667236\n",
      "84 Train Loss 0.0022291215 Test MSE 0.0003055819776148192 Test RE 0.040909647050471336\n",
      "85 Train Loss 0.0021896735 Test MSE 0.00029732480776356384 Test RE 0.04035314959635916\n",
      "86 Train Loss 0.0021738778 Test MSE 0.0002886214546948754 Test RE 0.039758150163179413\n",
      "87 Train Loss 0.0021465989 Test MSE 0.0003026923840558106 Test RE 0.04071576611966544\n",
      "88 Train Loss 0.0021200094 Test MSE 0.0003039101300177925 Test RE 0.0407975846511197\n",
      "89 Train Loss 0.002059713 Test MSE 0.0003145225752133466 Test RE 0.04150379176831919\n",
      "90 Train Loss 0.0020028858 Test MSE 0.00031671508866731033 Test RE 0.041648200460942975\n",
      "91 Train Loss 0.0019247514 Test MSE 0.0002827304016094936 Test RE 0.03935030646832578\n",
      "92 Train Loss 0.0018779108 Test MSE 0.0002558979893114465 Test RE 0.03743650532062016\n",
      "93 Train Loss 0.0018272755 Test MSE 0.0002469447454744659 Test RE 0.03677576866431412\n",
      "94 Train Loss 0.0018037133 Test MSE 0.0002423384369488074 Test RE 0.03643116129790401\n",
      "95 Train Loss 0.0017933027 Test MSE 0.0002407521675756293 Test RE 0.03631173221560641\n",
      "96 Train Loss 0.00178221 Test MSE 0.00024688024901335187 Test RE 0.03677096584532405\n",
      "97 Train Loss 0.0017576916 Test MSE 0.0002482437619096526 Test RE 0.036872368548827944\n",
      "98 Train Loss 0.0017288363 Test MSE 0.0002541772682394653 Test RE 0.03731042687893107\n",
      "99 Train Loss 0.001678476 Test MSE 0.00023184112311531175 Test RE 0.035633386628217724\n",
      "100 Train Loss 0.001620411 Test MSE 0.0002432123551055887 Test RE 0.03649679100576692\n",
      "101 Train Loss 0.0015630848 Test MSE 0.00022637785716740944 Test RE 0.03521103868008499\n",
      "102 Train Loss 0.0015211867 Test MSE 0.00022039499640190963 Test RE 0.03474263304691319\n",
      "103 Train Loss 0.0014964489 Test MSE 0.0002282434587043472 Test RE 0.03535582974887845\n",
      "104 Train Loss 0.0014892195 Test MSE 0.0002305779194874246 Test RE 0.03553617845527732\n",
      "105 Train Loss 0.0014793656 Test MSE 0.00023218550900324595 Test RE 0.035659842421561797\n",
      "106 Train Loss 0.0014696345 Test MSE 0.00022856773564003784 Test RE 0.03538093673514525\n",
      "107 Train Loss 0.0014435826 Test MSE 0.000225845583063094 Test RE 0.03516961909496371\n",
      "108 Train Loss 0.0014040108 Test MSE 0.00021094631047699795 Test RE 0.03398973909490459\n",
      "109 Train Loss 0.0013801102 Test MSE 0.00019145093977037658 Test RE 0.03238102674094885\n",
      "110 Train Loss 0.0013512939 Test MSE 0.00018725395869199855 Test RE 0.032024132052950724\n",
      "111 Train Loss 0.0013134163 Test MSE 0.00018302317638775384 Test RE 0.03166029143078247\n",
      "112 Train Loss 0.0012947054 Test MSE 0.00017382743408539422 Test RE 0.030854678377217774\n",
      "113 Train Loss 0.0012848781 Test MSE 0.0001636934811491356 Test RE 0.029941775955253044\n",
      "114 Train Loss 0.0012735946 Test MSE 0.00016342567122047623 Test RE 0.02991727288019872\n",
      "115 Train Loss 0.0012668825 Test MSE 0.00016437794149240783 Test RE 0.030004309232860883\n",
      "116 Train Loss 0.0012526734 Test MSE 0.00017474152111091935 Test RE 0.03093569804011333\n",
      "117 Train Loss 0.0012249264 Test MSE 0.00018252248270238366 Test RE 0.03161695548624152\n",
      "118 Train Loss 0.0011410163 Test MSE 0.00019269820434851878 Test RE 0.03248633346247371\n",
      "119 Train Loss 0.0011125524 Test MSE 0.00020689272948130433 Test RE 0.03366157858087157\n",
      "120 Train Loss 0.0010814612 Test MSE 0.00019069284552692846 Test RE 0.0323168530707348\n",
      "121 Train Loss 0.001055777 Test MSE 0.00015739487599558097 Test RE 0.0293600748832401\n",
      "122 Train Loss 0.001012758 Test MSE 0.0001417144857173246 Test RE 0.027859222158801992\n",
      "123 Train Loss 0.0009886378 Test MSE 0.00012733066833620394 Test RE 0.026407565967255152\n",
      "124 Train Loss 0.0009686396 Test MSE 0.00011232678773856137 Test RE 0.024802961189593423\n",
      "125 Train Loss 0.0009635753 Test MSE 0.00011510891033003863 Test RE 0.02510824370868141\n",
      "126 Train Loss 0.0009591902 Test MSE 0.00011253438455934028 Test RE 0.0248258704134266\n",
      "127 Train Loss 0.0009466411 Test MSE 0.00011438114232725328 Test RE 0.025028745299769263\n",
      "128 Train Loss 0.0009318377 Test MSE 0.00010686582000141196 Test RE 0.024192529277777538\n",
      "129 Train Loss 0.0009099157 Test MSE 0.00010154442182596808 Test RE 0.02358250306826101\n",
      "130 Train Loss 0.00086050044 Test MSE 9.610472752569748e-05 Test RE 0.02294215660222954\n",
      "131 Train Loss 0.00083851046 Test MSE 8.922548505188924e-05 Test RE 0.02210580439551805\n",
      "132 Train Loss 0.00082964957 Test MSE 9.457743329011188e-05 Test RE 0.022759128393532946\n",
      "133 Train Loss 0.0008255484 Test MSE 9.670773040180225e-05 Test RE 0.023014018591528802\n",
      "134 Train Loss 0.000822863 Test MSE 9.725726554748197e-05 Test RE 0.023079313767131356\n",
      "135 Train Loss 0.0008178859 Test MSE 0.00011040169492693977 Test RE 0.024589502069461706\n",
      "136 Train Loss 0.00080044864 Test MSE 0.0001001381862301275 Test RE 0.023418642910728264\n",
      "137 Train Loss 0.00078225246 Test MSE 0.00010626503319183468 Test RE 0.024124429683437854\n",
      "138 Train Loss 0.00076480897 Test MSE 0.00010313150221918257 Test RE 0.02376607897283041\n",
      "139 Train Loss 0.0007465977 Test MSE 9.15184057226289e-05 Test RE 0.022388040662625446\n",
      "140 Train Loss 0.0007150725 Test MSE 7.80714985993668e-05 Test RE 0.02067798052449729\n",
      "141 Train Loss 0.00070364133 Test MSE 8.210909491924442e-05 Test RE 0.021205938449363557\n",
      "142 Train Loss 0.0006959397 Test MSE 8.690314907815782e-05 Test RE 0.021816225857670277\n",
      "143 Train Loss 0.0006913101 Test MSE 8.835107495627683e-05 Test RE 0.0219972192228279\n",
      "144 Train Loss 0.0006893174 Test MSE 9.184014523039278e-05 Test RE 0.022427359515816578\n",
      "145 Train Loss 0.000689191 Test MSE 9.295259715525051e-05 Test RE 0.022562781018987146\n",
      "146 Train Loss 0.00068903295 Test MSE 9.238524711531663e-05 Test RE 0.022493817976856668\n",
      "147 Train Loss 0.0006847886 Test MSE 8.94370751888991e-05 Test RE 0.022131999828759127\n",
      "148 Train Loss 0.0006797218 Test MSE 9.241804326764546e-05 Test RE 0.022497810200966428\n",
      "149 Train Loss 0.00065515336 Test MSE 8.604066376914266e-05 Test RE 0.021707696456190476\n",
      "150 Train Loss 0.00062164495 Test MSE 7.856569221196935e-05 Test RE 0.02074332322687397\n",
      "151 Train Loss 0.0006062568 Test MSE 7.327739614877125e-05 Test RE 0.020033040930793295\n",
      "152 Train Loss 0.0006006228 Test MSE 8.874934636610019e-05 Test RE 0.022046743309499028\n",
      "153 Train Loss 0.00059537496 Test MSE 9.210969235633731e-05 Test RE 0.022460247100844315\n",
      "154 Train Loss 0.00059159263 Test MSE 9.329516387323582e-05 Test RE 0.02260431912462114\n",
      "155 Train Loss 0.00058912183 Test MSE 9.18380856921175e-05 Test RE 0.022427108044827622\n",
      "156 Train Loss 0.00058670226 Test MSE 9.44672142796444e-05 Test RE 0.022745862967587665\n",
      "157 Train Loss 0.0005808426 Test MSE 0.00010096292964684089 Test RE 0.023514883748899172\n",
      "158 Train Loss 0.0005704964 Test MSE 9.56997460435218e-05 Test RE 0.022893766904684743\n",
      "159 Train Loss 0.0005639459 Test MSE 0.00010202820718912411 Test RE 0.023638613060012522\n",
      "160 Train Loss 0.0005548308 Test MSE 9.592684262050636e-05 Test RE 0.022920914392473075\n",
      "161 Train Loss 0.00054444297 Test MSE 0.00010036160566555494 Test RE 0.023444753154141046\n",
      "162 Train Loss 0.0005341364 Test MSE 8.911113340367292e-05 Test RE 0.02209163442151345\n",
      "163 Train Loss 0.00051873765 Test MSE 9.108770932687185e-05 Test RE 0.022335298158300498\n",
      "164 Train Loss 0.0005041163 Test MSE 9.99001781515978e-05 Test RE 0.023390795681238752\n",
      "165 Train Loss 0.00049981166 Test MSE 9.321538464215979e-05 Test RE 0.02259465227366491\n",
      "166 Train Loss 0.0004963793 Test MSE 9.174989144777525e-05 Test RE 0.022416336822159502\n",
      "167 Train Loss 0.00049348985 Test MSE 9.531829090562995e-05 Test RE 0.022848094554197885\n",
      "168 Train Loss 0.00048966816 Test MSE 0.00010253073249941114 Test RE 0.023696755854643793\n",
      "169 Train Loss 0.0004843788 Test MSE 0.00010558425751471547 Test RE 0.024047030219917206\n",
      "170 Train Loss 0.0004801634 Test MSE 9.585049633141847e-05 Test RE 0.02291179142422843\n",
      "171 Train Loss 0.00047627045 Test MSE 8.297192166809355e-05 Test RE 0.021317066419680626\n",
      "172 Train Loss 0.00047041924 Test MSE 7.909164698219178e-05 Test RE 0.020812640069499545\n",
      "173 Train Loss 0.0004620548 Test MSE 8.045224981148379e-05 Test RE 0.020990895219734882\n",
      "174 Train Loss 0.00045772677 Test MSE 7.653084869462527e-05 Test RE 0.020472935999653635\n",
      "175 Train Loss 0.00045034208 Test MSE 7.709439236865988e-05 Test RE 0.02054817515078516\n",
      "176 Train Loss 0.00044294185 Test MSE 7.912612819628914e-05 Test RE 0.020817176369636804\n",
      "177 Train Loss 0.00043756497 Test MSE 7.823309351844899e-05 Test RE 0.020699369439612814\n",
      "178 Train Loss 0.00043381695 Test MSE 7.850771541775524e-05 Test RE 0.020735668146789836\n",
      "179 Train Loss 0.0004309498 Test MSE 8.504301050442326e-05 Test RE 0.021581477653563257\n",
      "180 Train Loss 0.00042693352 Test MSE 8.069715180067169e-05 Test RE 0.02102281978233061\n",
      "181 Train Loss 0.000421736 Test MSE 7.815536177726354e-05 Test RE 0.020689083524624712\n",
      "182 Train Loss 0.00041767745 Test MSE 7.466216245218335e-05 Test RE 0.020221443122394926\n",
      "183 Train Loss 0.00041564397 Test MSE 6.773605407093025e-05 Test RE 0.019260688643605892\n",
      "184 Train Loss 0.0004127333 Test MSE 6.391194128704559e-05 Test RE 0.01870909880830076\n",
      "185 Train Loss 0.00041142557 Test MSE 6.598365850438402e-05 Test RE 0.019009909959835494\n",
      "186 Train Loss 0.0004103509 Test MSE 6.574908947495125e-05 Test RE 0.018976090175524256\n",
      "187 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "188 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "189 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "190 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "191 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "192 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "193 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "194 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "195 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "196 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "197 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "198 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "199 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "200 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "201 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "202 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "203 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "204 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "205 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "206 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "207 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "208 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "209 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "210 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "211 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "212 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "213 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "214 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "215 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "216 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "217 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "218 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "219 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "220 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "221 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "222 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "223 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "224 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "225 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "226 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "227 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "228 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "229 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "230 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "231 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "232 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "233 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "234 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "235 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "236 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "237 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "238 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "239 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "240 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "241 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "242 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "243 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "244 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "245 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "246 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "247 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "248 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "249 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "250 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "251 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "252 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "253 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "254 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "255 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "256 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "257 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "258 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "259 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "260 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "261 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "262 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "263 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "264 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "265 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "266 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "267 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "268 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "269 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "270 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "271 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "272 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "273 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "274 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "275 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "276 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "277 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "278 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "279 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "280 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "281 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "282 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "283 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "284 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "285 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "286 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "287 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "288 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "289 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "290 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "291 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "292 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "293 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "294 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "295 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "296 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "297 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "298 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "299 Train Loss 0.00040945844 Test MSE 6.38496392861737e-05 Test RE 0.018699977676408585\n",
      "Training time: 138.41\n",
      "KG_stan_low\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 5398.6885 Test MSE 7.09870410549091 Test RE 6.235214537173377\n",
      "1 Train Loss 308.4608 Test MSE 10.90248647819617 Test RE 7.727244291748083\n",
      "2 Train Loss 93.28245 Test MSE 12.62652323877982 Test RE 8.315794628812265\n",
      "3 Train Loss 41.646797 Test MSE 12.375017720871798 Test RE 8.232557615386167\n",
      "4 Train Loss 26.524784 Test MSE 12.224546717097141 Test RE 8.18235365170167\n",
      "5 Train Loss 20.068787 Test MSE 12.17414773356352 Test RE 8.165469253686595\n",
      "6 Train Loss 17.561382 Test MSE 12.355121418098214 Test RE 8.225936883474862\n",
      "7 Train Loss 15.787043 Test MSE 12.520074949807517 Test RE 8.280667156278021\n",
      "8 Train Loss 14.470646 Test MSE 12.312922352217386 Test RE 8.211876974552286\n",
      "9 Train Loss 13.506975 Test MSE 12.017005061021884 Test RE 8.112598559869577\n",
      "10 Train Loss 12.629269 Test MSE 11.704330731508875 Test RE 8.00636078758605\n",
      "11 Train Loss 11.696325 Test MSE 10.968539335942193 Test RE 7.750616750213421\n",
      "12 Train Loss 11.137299 Test MSE 10.46521147709314 Test RE 7.570697062294966\n",
      "13 Train Loss 10.272371 Test MSE 8.964089121107929 Test RE 7.0067229708656695\n",
      "14 Train Loss 9.4655485 Test MSE 7.936376067963681 Test RE 6.592846791322813\n",
      "15 Train Loss 8.135815 Test MSE 6.648097622651745 Test RE 6.034072974392698\n",
      "16 Train Loss 6.0877633 Test MSE 5.134859506133878 Test RE 5.303055187934429\n",
      "17 Train Loss 4.603569 Test MSE 3.6999394713014184 Test RE 4.501519893021753\n",
      "18 Train Loss 3.4487174 Test MSE 2.639639987007156 Test RE 3.802193485414959\n",
      "19 Train Loss 2.4828124 Test MSE 1.6152200803118175 Test RE 2.9742516869679134\n",
      "20 Train Loss 1.5746502 Test MSE 0.6470530660921712 Test RE 1.8824862545648033\n",
      "21 Train Loss 1.0846949 Test MSE 0.5124892522976467 Test RE 1.6753449659492694\n",
      "22 Train Loss 0.64245456 Test MSE 0.393113336879172 Test RE 1.4673062015238734\n",
      "23 Train Loss 0.46451697 Test MSE 0.34732461648528223 Test RE 1.3792076153452233\n",
      "24 Train Loss 0.36009312 Test MSE 0.3295483819112084 Test RE 1.34344983966061\n",
      "25 Train Loss 0.29514432 Test MSE 0.2809694232223161 Test RE 1.2404846483353174\n",
      "26 Train Loss 0.23863834 Test MSE 0.25412483233491884 Test RE 1.1797375873521425\n",
      "27 Train Loss 0.19365785 Test MSE 0.23067292917690196 Test RE 1.1239841300009727\n",
      "28 Train Loss 0.1636399 Test MSE 0.21742942186650097 Test RE 1.0912418661139653\n",
      "29 Train Loss 0.13186358 Test MSE 0.17916439477550877 Test RE 0.9905758082118451\n",
      "30 Train Loss 0.11325794 Test MSE 0.15459196365804295 Test RE 0.9201429879823033\n",
      "31 Train Loss 0.09796164 Test MSE 0.1399905551260762 Test RE 0.8756110465230822\n",
      "32 Train Loss 0.083413556 Test MSE 0.1346335725920713 Test RE 0.8586942388894381\n",
      "33 Train Loss 0.072087094 Test MSE 0.1239008672855912 Test RE 0.823756846603716\n",
      "34 Train Loss 0.060904965 Test MSE 0.10357755018476918 Test RE 0.7531728934986311\n",
      "35 Train Loss 0.05363841 Test MSE 0.08385542211450323 Test RE 0.6776843224160849\n",
      "36 Train Loss 0.050907392 Test MSE 0.07128648740911417 Test RE 0.6248351775702965\n",
      "37 Train Loss 0.04458464 Test MSE 0.06595411253646308 Test RE 0.6010115310865565\n",
      "38 Train Loss 0.037211973 Test MSE 0.04970914554130533 Test RE 0.5217710909330887\n",
      "39 Train Loss 0.035360537 Test MSE 0.039808850047539805 Test RE 0.46692989486094477\n",
      "40 Train Loss 0.033417214 Test MSE 0.04179439726820016 Test RE 0.4784327463357611\n",
      "41 Train Loss 0.030675761 Test MSE 0.037893553650303766 Test RE 0.4555588958401906\n",
      "42 Train Loss 0.027818792 Test MSE 0.028422585975892086 Test RE 0.3945423785689616\n",
      "43 Train Loss 0.025161088 Test MSE 0.02411542275193472 Test RE 0.36342040151970845\n",
      "44 Train Loss 0.023458492 Test MSE 0.026580993787887242 Test RE 0.3815464973407364\n",
      "45 Train Loss 0.021772647 Test MSE 0.02199442004227178 Test RE 0.3470708356434022\n",
      "46 Train Loss 0.020905357 Test MSE 0.015519625293933276 Test RE 0.2915429069340852\n",
      "47 Train Loss 0.019192692 Test MSE 0.01112250835020878 Test RE 0.24681027406202097\n",
      "48 Train Loss 0.01767288 Test MSE 0.011590703114274658 Test RE 0.2519513878627704\n",
      "49 Train Loss 0.016766636 Test MSE 0.01071036058380551 Test RE 0.24219429573574666\n",
      "50 Train Loss 0.015201094 Test MSE 0.007417118032029446 Test RE 0.2015484484036091\n",
      "51 Train Loss 0.0141232265 Test MSE 0.005884169157591394 Test RE 0.17951652744195298\n",
      "52 Train Loss 0.0132283205 Test MSE 0.006439339438464219 Test RE 0.18779435065942618\n",
      "53 Train Loss 0.012118599 Test MSE 0.005509966862297791 Test RE 0.1737146147456733\n",
      "54 Train Loss 0.011617514 Test MSE 0.00471220326637518 Test RE 0.16064746322833415\n",
      "55 Train Loss 0.011058343 Test MSE 0.006037151724191395 Test RE 0.18183517938328053\n",
      "56 Train Loss 0.010176717 Test MSE 0.00475797175613975 Test RE 0.1614257429476385\n",
      "57 Train Loss 0.009985666 Test MSE 0.004220685637269987 Test RE 0.15203842684864863\n",
      "58 Train Loss 0.009469549 Test MSE 0.0038625133615844496 Test RE 0.14544435212099702\n",
      "59 Train Loss 0.008824646 Test MSE 0.004205547388714906 Test RE 0.1517655253375549\n",
      "60 Train Loss 0.008531446 Test MSE 0.0039812111594083426 Test RE 0.1476622461644306\n",
      "61 Train Loss 0.007998805 Test MSE 0.003270142133577431 Test RE 0.1338274425570532\n",
      "62 Train Loss 0.0075655254 Test MSE 0.0028579285984073294 Test RE 0.12510871147110136\n",
      "63 Train Loss 0.0073281433 Test MSE 0.003245813024087292 Test RE 0.13332869039367068\n",
      "64 Train Loss 0.006925508 Test MSE 0.003937937051148098 Test RE 0.1468575399060138\n",
      "65 Train Loss 0.006476606 Test MSE 0.0035830223838360883 Test RE 0.14008338407003854\n",
      "66 Train Loss 0.0062705404 Test MSE 0.0033815381607938083 Test RE 0.13608774269905038\n",
      "67 Train Loss 0.006084823 Test MSE 0.002915929656778587 Test RE 0.12637186227837577\n",
      "68 Train Loss 0.005726741 Test MSE 0.0024009922500124927 Test RE 0.11467196198611591\n",
      "69 Train Loss 0.005492952 Test MSE 0.002423696795703279 Test RE 0.1152128734934123\n",
      "70 Train Loss 0.0052646077 Test MSE 0.002064287542784429 Test RE 0.10632783227442263\n",
      "71 Train Loss 0.004932114 Test MSE 0.002055381045076794 Test RE 0.10609820528053315\n",
      "72 Train Loss 0.0047132117 Test MSE 0.0018881045181175836 Test RE 0.10168921149071411\n",
      "73 Train Loss 0.004550286 Test MSE 0.0016724930369125847 Test RE 0.09570707052437374\n",
      "74 Train Loss 0.004476141 Test MSE 0.001306289571650089 Test RE 0.0845827096632227\n",
      "75 Train Loss 0.0044014635 Test MSE 0.001085025360104146 Test RE 0.07708711786030795\n",
      "76 Train Loss 0.004318488 Test MSE 0.0010380534567916663 Test RE 0.07540006557061019\n",
      "77 Train Loss 0.004159366 Test MSE 0.0009369080447172824 Test RE 0.07163253951819912\n",
      "78 Train Loss 0.0040359627 Test MSE 0.0008079522779974169 Test RE 0.06652037960892192\n",
      "79 Train Loss 0.003863373 Test MSE 0.0006011550739863405 Test RE 0.05737928372553212\n",
      "80 Train Loss 0.0037254668 Test MSE 0.0005418601203841412 Test RE 0.054476031033546514\n",
      "81 Train Loss 0.0036151672 Test MSE 0.0006848486924791082 Test RE 0.06124338398605341\n",
      "82 Train Loss 0.0035219435 Test MSE 0.0006743886149838236 Test RE 0.06077388210112572\n",
      "83 Train Loss 0.0034235714 Test MSE 0.0006086169960200422 Test RE 0.057734299672581875\n",
      "84 Train Loss 0.0032379243 Test MSE 0.0005437494934726881 Test RE 0.05457092266544156\n",
      "85 Train Loss 0.0030335197 Test MSE 0.0004873835954583217 Test RE 0.051665105168026984\n",
      "86 Train Loss 0.002933581 Test MSE 0.0004009262692595687 Test RE 0.04685911913774785\n",
      "87 Train Loss 0.0028980013 Test MSE 0.00039007022948779477 Test RE 0.04622035395251544\n",
      "88 Train Loss 0.0028345007 Test MSE 0.0003661249633531777 Test RE 0.04477922105451972\n",
      "89 Train Loss 0.0027686874 Test MSE 0.0003513232058442519 Test RE 0.04386471202915615\n",
      "90 Train Loss 0.0027018948 Test MSE 0.0004097416615064507 Test RE 0.047371477030267076\n",
      "91 Train Loss 0.0025528069 Test MSE 0.00046270866228546165 Test RE 0.050340286047670955\n",
      "92 Train Loss 0.0025049793 Test MSE 0.0004923785691389762 Test RE 0.05192917643506334\n",
      "93 Train Loss 0.0024582203 Test MSE 0.00040868276440587573 Test RE 0.047310226278276905\n",
      "94 Train Loss 0.0024036882 Test MSE 0.0002950478073669764 Test RE 0.04019833450694185\n",
      "95 Train Loss 0.0023200542 Test MSE 0.00022507782893666295 Test RE 0.03510978926196099\n",
      "96 Train Loss 0.0022589995 Test MSE 0.00018536159195645918 Test RE 0.031861905072803766\n",
      "97 Train Loss 0.0022031572 Test MSE 0.0001963938037867194 Test RE 0.032796368302933004\n",
      "98 Train Loss 0.002130289 Test MSE 0.00016653161966301993 Test RE 0.030200227672861645\n",
      "99 Train Loss 0.002076722 Test MSE 0.00017314765366715793 Test RE 0.03079428816196748\n",
      "100 Train Loss 0.0020093352 Test MSE 0.00017797214294871155 Test RE 0.03122035801246082\n",
      "101 Train Loss 0.0018991655 Test MSE 0.00015437244115998962 Test RE 0.029076809423425824\n",
      "102 Train Loss 0.001845258 Test MSE 0.00014137825427499413 Test RE 0.02782615317111378\n",
      "103 Train Loss 0.0018104116 Test MSE 0.0001273302557158786 Test RE 0.026407523179812705\n",
      "104 Train Loss 0.0017591123 Test MSE 0.000130424752337776 Test RE 0.026726486797199533\n",
      "105 Train Loss 0.0017296721 Test MSE 0.00013343150083439272 Test RE 0.027032801133191568\n",
      "106 Train Loss 0.0016776634 Test MSE 0.00013115926397888524 Test RE 0.02680163876827071\n",
      "107 Train Loss 0.001577977 Test MSE 0.00010782737752272822 Test RE 0.024301125341165998\n",
      "108 Train Loss 0.0015542823 Test MSE 0.00010674864102038719 Test RE 0.024179262016718713\n",
      "109 Train Loss 0.0015408264 Test MSE 0.00010779933453025898 Test RE 0.024297965102065514\n",
      "110 Train Loss 0.0015215157 Test MSE 0.00010964068284539018 Test RE 0.02450460632864377\n",
      "111 Train Loss 0.0014831675 Test MSE 0.0001137723641653565 Test RE 0.0249620503816328\n",
      "112 Train Loss 0.0014502713 Test MSE 0.00010196419108267493 Test RE 0.023631196045379475\n",
      "113 Train Loss 0.0014102783 Test MSE 9.364042076041705e-05 Test RE 0.022646106338095336\n",
      "114 Train Loss 0.0013724046 Test MSE 8.018300389908731e-05 Test RE 0.020955741142249587\n",
      "115 Train Loss 0.001347554 Test MSE 8.049546493519418e-05 Test RE 0.020996532118345883\n",
      "116 Train Loss 0.0013212828 Test MSE 8.008207919922976e-05 Test RE 0.02094254870923396\n",
      "117 Train Loss 0.001297716 Test MSE 8.7158889719132e-05 Test RE 0.021848302928245626\n",
      "118 Train Loss 0.001283346 Test MSE 8.396710051662901e-05 Test RE 0.021444525564343536\n",
      "119 Train Loss 0.0012681108 Test MSE 8.705582746261697e-05 Test RE 0.021835381690658903\n",
      "120 Train Loss 0.0012556722 Test MSE 9.189211755896405e-05 Test RE 0.022433704438496828\n",
      "121 Train Loss 0.0012390199 Test MSE 0.00010408400957743618 Test RE 0.02387557672938223\n",
      "122 Train Loss 0.0012103093 Test MSE 0.00010484745821995304 Test RE 0.02396297955854142\n",
      "123 Train Loss 0.0011906337 Test MSE 0.0001111372633697232 Test RE 0.02467128176681204\n",
      "124 Train Loss 0.0011489571 Test MSE 0.0001015266161019412 Test RE 0.023580435392149473\n",
      "125 Train Loss 0.001116012 Test MSE 9.42485782530516e-05 Test RE 0.022719526074395535\n",
      "126 Train Loss 0.0010977918 Test MSE 8.351692524705073e-05 Test RE 0.021386962726557015\n",
      "127 Train Loss 0.0010904451 Test MSE 7.229468438546957e-05 Test RE 0.01989825751749926\n",
      "128 Train Loss 0.001078732 Test MSE 6.835669041932281e-05 Test RE 0.019348726146588256\n",
      "129 Train Loss 0.0010568162 Test MSE 6.114097534698315e-05 Test RE 0.01829902899504397\n",
      "130 Train Loss 0.0010168971 Test MSE 6.103990119546229e-05 Test RE 0.018283897376330887\n",
      "131 Train Loss 0.0009804526 Test MSE 7.415143466613493e-05 Test RE 0.02015216187721854\n",
      "132 Train Loss 0.0009639369 Test MSE 7.572208016410423e-05 Test RE 0.020364470951223856\n",
      "133 Train Loss 0.00094766205 Test MSE 8.062420276312333e-05 Test RE 0.02101331547406882\n",
      "134 Train Loss 0.00093538914 Test MSE 7.93582920895461e-05 Test RE 0.020847693828858763\n",
      "135 Train Loss 0.0009197856 Test MSE 7.640259224762311e-05 Test RE 0.020455773723763664\n",
      "136 Train Loss 0.00091491133 Test MSE 7.714267002387144e-05 Test RE 0.020554607930324816\n",
      "137 Train Loss 0.0009052525 Test MSE 7.045851000733153e-05 Test RE 0.01964393966149496\n",
      "138 Train Loss 0.0008895311 Test MSE 7.185269916968149e-05 Test RE 0.019837338661749606\n",
      "139 Train Loss 0.000865634 Test MSE 7.302617094262228e-05 Test RE 0.019998670673752376\n",
      "140 Train Loss 0.0008445006 Test MSE 7.562151400707765e-05 Test RE 0.02035094347675367\n",
      "141 Train Loss 0.0008222695 Test MSE 6.935758160165196e-05 Test RE 0.019489865174415998\n",
      "142 Train Loss 0.00079846795 Test MSE 6.374014349945339e-05 Test RE 0.018683936494438023\n",
      "143 Train Loss 0.00077896897 Test MSE 6.674298525290956e-05 Test RE 0.019118978194935715\n",
      "144 Train Loss 0.00075827335 Test MSE 5.98046617566891e-05 Test RE 0.0180979499677796\n",
      "145 Train Loss 0.0007334997 Test MSE 5.9447853420242e-05 Test RE 0.018043880938692615\n",
      "146 Train Loss 0.0007182444 Test MSE 5.7089910081973156e-05 Test RE 0.017682413552219674\n",
      "147 Train Loss 0.00070520135 Test MSE 5.9589940517973115e-05 Test RE 0.018065431528077762\n",
      "148 Train Loss 0.000699856 Test MSE 6.266000551189536e-05 Test RE 0.018524951448135304\n",
      "149 Train Loss 0.00069218007 Test MSE 6.439548261554172e-05 Test RE 0.01877973956517756\n",
      "150 Train Loss 0.00067409617 Test MSE 6.771153342031034e-05 Test RE 0.019257202115100132\n",
      "151 Train Loss 0.00066301646 Test MSE 7.023661084069797e-05 Test RE 0.019612982355922307\n",
      "152 Train Loss 0.0006526221 Test MSE 7.165421250233886e-05 Test RE 0.019809920274831888\n",
      "153 Train Loss 0.0006450305 Test MSE 7.12799378714774e-05 Test RE 0.019758115519503742\n",
      "154 Train Loss 0.00063416094 Test MSE 6.704570011439225e-05 Test RE 0.01916228650064016\n",
      "155 Train Loss 0.00062183815 Test MSE 6.410943340136927e-05 Test RE 0.018737982686940744\n",
      "156 Train Loss 0.0006130706 Test MSE 6.099592414802641e-05 Test RE 0.018277309745249715\n",
      "157 Train Loss 0.00060760323 Test MSE 5.990310263968298e-05 Test RE 0.018112838820824647\n",
      "158 Train Loss 0.0006034824 Test MSE 5.938524939485166e-05 Test RE 0.01803437750778391\n",
      "159 Train Loss 0.0005988995 Test MSE 5.9915586029140964e-05 Test RE 0.018114726017251347\n",
      "160 Train Loss 0.00059317943 Test MSE 5.900784582604096e-05 Test RE 0.01797698037038481\n",
      "161 Train Loss 0.0005837685 Test MSE 6.289586337904584e-05 Test RE 0.018559783488563367\n",
      "162 Train Loss 0.0005682302 Test MSE 5.8061794669225896e-05 Test RE 0.01783228891327934\n",
      "163 Train Loss 0.00055487 Test MSE 5.896866218712574e-05 Test RE 0.017971010651656474\n",
      "164 Train Loss 0.00054696924 Test MSE 6.037545712056751e-05 Test RE 0.018184111261874095\n",
      "165 Train Loss 0.0005304025 Test MSE 5.909082703630888e-05 Test RE 0.017989616211286336\n",
      "166 Train Loss 0.0005127271 Test MSE 6.006673639762482e-05 Test RE 0.0181375608339942\n",
      "167 Train Loss 0.00050512893 Test MSE 5.71350892866147e-05 Test RE 0.017689408828530546\n",
      "168 Train Loss 0.00049800647 Test MSE 5.9262493313420315e-05 Test RE 0.018015728308024996\n",
      "169 Train Loss 0.00048840314 Test MSE 6.392285744946073e-05 Test RE 0.01871069649753672\n",
      "170 Train Loss 0.00048288968 Test MSE 6.387039799646541e-05 Test RE 0.018703017285377162\n",
      "171 Train Loss 0.0004748047 Test MSE 6.02806114564827e-05 Test RE 0.018169822658001763\n",
      "172 Train Loss 0.0004626751 Test MSE 5.625544458050992e-05 Test RE 0.017552708667341876\n",
      "173 Train Loss 0.00045406542 Test MSE 5.329898543952152e-05 Test RE 0.017085249887480104\n",
      "174 Train Loss 0.0004465166 Test MSE 5.194721476302656e-05 Test RE 0.01686720011849823\n",
      "175 Train Loss 0.00043708956 Test MSE 4.848725090150032e-05 Test RE 0.0162957984574496\n",
      "176 Train Loss 0.0004318023 Test MSE 4.792051764205026e-05 Test RE 0.016200283491032943\n",
      "177 Train Loss 0.00042606154 Test MSE 4.728375348196039e-05 Test RE 0.016092289475472584\n",
      "178 Train Loss 0.0004200707 Test MSE 4.5381563099712805e-05 Test RE 0.01576527639872958\n",
      "179 Train Loss 0.000414853 Test MSE 4.6284887260551704e-05 Test RE 0.01592140790780123\n",
      "180 Train Loss 0.00040928158 Test MSE 4.508870560200401e-05 Test RE 0.01571432561811145\n",
      "181 Train Loss 0.00040560152 Test MSE 4.5978462463002666e-05 Test RE 0.015868617287656324\n",
      "182 Train Loss 0.00040346893 Test MSE 4.642725996912676e-05 Test RE 0.015945876299365246\n",
      "183 Train Loss 0.00040086082 Test MSE 4.449548898520249e-05 Test RE 0.015610609355748106\n",
      "184 Train Loss 0.00039785658 Test MSE 4.494406772499363e-05 Test RE 0.01568910076006817\n",
      "185 Train Loss 0.00039444913 Test MSE 4.566828902436947e-05 Test RE 0.0158150013932725\n",
      "186 Train Loss 0.00038833386 Test MSE 4.19956956530404e-05 Test RE 0.015165762616983547\n",
      "187 Train Loss 0.0003805045 Test MSE 4.422555523795216e-05 Test RE 0.015563186114876405\n",
      "188 Train Loss 0.00037597274 Test MSE 4.325717023821236e-05 Test RE 0.015391853351466428\n",
      "189 Train Loss 0.00037177413 Test MSE 4.180343824053261e-05 Test RE 0.015131008162184148\n",
      "190 Train Loss 0.0003671549 Test MSE 4.189671999261105e-05 Test RE 0.01514788070305502\n",
      "191 Train Loss 0.00036260465 Test MSE 4.1552724519845606e-05 Test RE 0.015085566249554002\n",
      "192 Train Loss 0.00035490628 Test MSE 4.186957301725815e-05 Test RE 0.015142972373976913\n",
      "193 Train Loss 0.0003517365 Test MSE 4.04433335592972e-05 Test RE 0.014882823682964117\n",
      "194 Train Loss 0.00035022543 Test MSE 3.9369868316457035e-05 Test RE 0.014683982056263421\n",
      "195 Train Loss 0.00034665703 Test MSE 3.811503842825526e-05 Test RE 0.014448076917099232\n",
      "196 Train Loss 0.0003420391 Test MSE 4.016735084451704e-05 Test RE 0.014831957039511446\n",
      "197 Train Loss 0.00033979272 Test MSE 3.8637458086338674e-05 Test RE 0.014546755439231646\n",
      "198 Train Loss 0.0003381898 Test MSE 3.8473659329191534e-05 Test RE 0.014515888098565034\n",
      "199 Train Loss 0.00033435866 Test MSE 3.895537170087472e-05 Test RE 0.014606479057228752\n",
      "200 Train Loss 0.0003311341 Test MSE 3.9442277546961914e-05 Test RE 0.014697479274437849\n",
      "201 Train Loss 0.00032740453 Test MSE 4.044813901605328e-05 Test RE 0.014883707841550874\n",
      "202 Train Loss 0.00031917632 Test MSE 4.1206225436234525e-05 Test RE 0.015022536958485743\n",
      "203 Train Loss 0.0003157029 Test MSE 4.17392060338878e-05 Test RE 0.015119379074859203\n",
      "204 Train Loss 0.00031016805 Test MSE 4.2124806259915336e-05 Test RE 0.015189057363497255\n",
      "205 Train Loss 0.00030367685 Test MSE 4.2493037421010194e-05 Test RE 0.01525529997639792\n",
      "206 Train Loss 0.0003010507 Test MSE 4.2186113563367056e-05 Test RE 0.015200106216501271\n",
      "207 Train Loss 0.0002987362 Test MSE 4.1588726130259005e-05 Test RE 0.01509209996182725\n",
      "208 Train Loss 0.00029371958 Test MSE 4.4491823071605166e-05 Test RE 0.015609966275683512\n",
      "209 Train Loss 0.00028903704 Test MSE 4.7260785027752945e-05 Test RE 0.016088380522783323\n",
      "210 Train Loss 0.00028614438 Test MSE 4.551898383346546e-05 Test RE 0.015789127915677884\n",
      "211 Train Loss 0.0002837397 Test MSE 4.617168862276499e-05 Test RE 0.015901926548979945\n",
      "212 Train Loss 0.00028108517 Test MSE 4.7165374362787325e-05 Test RE 0.016072132606177007\n",
      "213 Train Loss 0.00027902133 Test MSE 4.568676823232661e-05 Test RE 0.015818200759265256\n",
      "214 Train Loss 0.00027632996 Test MSE 4.583586855886248e-05 Test RE 0.015843991353158723\n",
      "215 Train Loss 0.00027315633 Test MSE 4.541162198774805e-05 Test RE 0.015770496671026833\n",
      "216 Train Loss 0.00026948325 Test MSE 4.5899696434995945e-05 Test RE 0.015855019141347553\n",
      "217 Train Loss 0.00026418234 Test MSE 4.8642561026235444e-05 Test RE 0.016321876230390147\n",
      "218 Train Loss 0.00026057108 Test MSE 5.114097177945321e-05 Test RE 0.016735795180686023\n",
      "219 Train Loss 0.0002565378 Test MSE 4.8833418332620726e-05 Test RE 0.016353865701578284\n",
      "220 Train Loss 0.00025291415 Test MSE 4.698566647325864e-05 Test RE 0.016041484641026046\n",
      "221 Train Loss 0.00024914084 Test MSE 5.075521374329806e-05 Test RE 0.01667255637445329\n",
      "222 Train Loss 0.000245898 Test MSE 4.725123755902566e-05 Test RE 0.016086755379779275\n",
      "223 Train Loss 0.00024452625 Test MSE 4.6900556765475474e-05 Test RE 0.016026949305016212\n",
      "224 Train Loss 0.00024040276 Test MSE 4.3277167267833074e-05 Test RE 0.015395410632054584\n",
      "225 Train Loss 0.0002367581 Test MSE 4.138754001525287e-05 Test RE 0.015055551572241766\n",
      "226 Train Loss 0.00023527931 Test MSE 4.02568085968721e-05 Test RE 0.014848464172506683\n",
      "227 Train Loss 0.00023371013 Test MSE 4.128483808739394e-05 Test RE 0.015036860021642163\n",
      "228 Train Loss 0.00023266388 Test MSE 4.120029141557231e-05 Test RE 0.015021455237782637\n",
      "229 Train Loss 0.0002321717 Test MSE 4.0853892060124306e-05 Test RE 0.014958174061272712\n",
      "230 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "231 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "232 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "233 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "234 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "235 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "236 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "237 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "238 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "239 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "240 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "241 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "242 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "243 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "244 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "245 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "246 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "247 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "248 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "249 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "250 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "251 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "252 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "253 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "254 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "255 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "256 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "257 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "258 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "259 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "260 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "261 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "262 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "263 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "264 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "265 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "266 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "267 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "268 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "269 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "270 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "271 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "272 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "273 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "274 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "275 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "276 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "277 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "278 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "279 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "280 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "281 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "282 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "283 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "284 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "285 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "286 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "287 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "288 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "289 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "290 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "291 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "292 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "293 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "294 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "295 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "296 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "297 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "298 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "299 Train Loss 0.00023163213 Test MSE 4.140760957084482e-05 Test RE 0.01505920148242653\n",
      "Training time: 153.87\n",
      "KG_stan_low\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 6823.222 Test MSE 7.105797602494155 Test RE 6.238329079717766\n",
      "1 Train Loss 1447.5183 Test MSE 12.634611236952402 Test RE 8.318457569484215\n",
      "2 Train Loss 195.3845 Test MSE 14.470184372546338 Test RE 8.902231758515182\n",
      "3 Train Loss 57.203228 Test MSE 14.742512915801909 Test RE 8.985611187744762\n",
      "4 Train Loss 29.518488 Test MSE 15.114000567414138 Test RE 9.098118333663985\n",
      "5 Train Loss 23.474237 Test MSE 15.285386881468579 Test RE 9.149557309619617\n",
      "6 Train Loss 19.684788 Test MSE 15.254456556547089 Test RE 9.140295454119862\n",
      "7 Train Loss 17.9161 Test MSE 14.891401222878617 Test RE 9.030871163743317\n",
      "8 Train Loss 16.57441 Test MSE 14.42145172701682 Test RE 8.88722866069121\n",
      "9 Train Loss 14.84773 Test MSE 13.28696943549609 Test RE 8.530506771133608\n",
      "10 Train Loss 13.185535 Test MSE 12.355589310740934 Test RE 8.22609264151148\n",
      "11 Train Loss 12.0936365 Test MSE 11.57246983946269 Test RE 7.9611332466952165\n",
      "12 Train Loss 10.110643 Test MSE 9.798019079685178 Test RE 7.325394270728439\n",
      "13 Train Loss 8.713557 Test MSE 8.878064398682 Test RE 6.973021584072222\n",
      "14 Train Loss 7.4598517 Test MSE 7.358568599865843 Test RE 6.348315985549248\n",
      "15 Train Loss 6.273129 Test MSE 6.267221438463295 Test RE 5.858674689931367\n",
      "16 Train Loss 4.7680097 Test MSE 4.7795098061281704 Test RE 5.116271027006924\n",
      "17 Train Loss 3.8002908 Test MSE 3.423848562748982 Test RE 4.3303114945275105\n",
      "18 Train Loss 2.4240518 Test MSE 2.0961331758349555 Test RE 3.38821764542156\n",
      "19 Train Loss 1.6571944 Test MSE 1.520472397371273 Test RE 2.885699699498134\n",
      "20 Train Loss 1.1589572 Test MSE 1.0279261160534179 Test RE 2.3726999117183842\n",
      "21 Train Loss 0.772242 Test MSE 0.6690610279649507 Test RE 1.914232699788191\n",
      "22 Train Loss 0.4680637 Test MSE 0.35695164636083637 Test RE 1.3981911816969284\n",
      "23 Train Loss 0.33618432 Test MSE 0.24081822735946856 Test RE 1.1484353225562143\n",
      "24 Train Loss 0.25227147 Test MSE 0.22642967715203027 Test RE 1.1135982446831065\n",
      "25 Train Loss 0.21060814 Test MSE 0.2073389942674871 Test RE 1.0656199875137937\n",
      "26 Train Loss 0.17037755 Test MSE 0.16233429075513306 Test RE 0.9429029576052024\n",
      "27 Train Loss 0.14581455 Test MSE 0.16106201618594507 Test RE 0.9392007478166475\n",
      "28 Train Loss 0.11796047 Test MSE 0.12018422329233844 Test RE 0.8113076939840732\n",
      "29 Train Loss 0.106382355 Test MSE 0.11771913027268299 Test RE 0.8029442389768798\n",
      "30 Train Loss 0.09772107 Test MSE 0.09247745575472373 Test RE 0.7116718708682138\n",
      "31 Train Loss 0.09026605 Test MSE 0.09559112686386785 Test RE 0.7235535100341713\n",
      "32 Train Loss 0.076224744 Test MSE 0.08233442551078879 Test RE 0.6715101690521239\n",
      "33 Train Loss 0.07052254 Test MSE 0.08119251681858848 Test RE 0.6668372717758572\n",
      "34 Train Loss 0.064469196 Test MSE 0.07638600487745577 Test RE 0.6467981397534929\n",
      "35 Train Loss 0.059942473 Test MSE 0.0646619200006067 Test RE 0.5950948090934922\n",
      "36 Train Loss 0.054701634 Test MSE 0.06214675085987421 Test RE 0.5834062508150504\n",
      "37 Train Loss 0.050940525 Test MSE 0.05564059747968516 Test RE 0.5520237417101516\n",
      "38 Train Loss 0.046792217 Test MSE 0.0478367695259191 Test RE 0.5118500921540681\n",
      "39 Train Loss 0.04339824 Test MSE 0.04158187642470962 Test RE 0.47721480180611614\n",
      "40 Train Loss 0.040066164 Test MSE 0.035950507234966324 Test RE 0.44372548748963475\n",
      "41 Train Loss 0.036151126 Test MSE 0.0282714975821558 Test RE 0.3934923297612406\n",
      "42 Train Loss 0.03411567 Test MSE 0.024846299356192227 Test RE 0.3688864651345658\n",
      "43 Train Loss 0.030797357 Test MSE 0.019516380568669233 Test RE 0.3269350652935956\n",
      "44 Train Loss 0.029141035 Test MSE 0.017048267296485797 Test RE 0.30556385962349353\n",
      "45 Train Loss 0.027238443 Test MSE 0.019064529544843674 Test RE 0.32312823646606265\n",
      "46 Train Loss 0.02572918 Test MSE 0.016881286742917462 Test RE 0.30406374307561757\n",
      "47 Train Loss 0.023721462 Test MSE 0.01102104378424075 Test RE 0.24568193723388007\n",
      "48 Train Loss 0.022047365 Test MSE 0.010996927325412489 Test RE 0.245412987065497\n",
      "49 Train Loss 0.021259045 Test MSE 0.011902799129077563 Test RE 0.2553209292000447\n",
      "50 Train Loss 0.019112676 Test MSE 0.010116585443194985 Test RE 0.23538503098473956\n",
      "51 Train Loss 0.01822045 Test MSE 0.009023098595420505 Test RE 0.2223001294028507\n",
      "52 Train Loss 0.017669812 Test MSE 0.008574032295838 Test RE 0.2166977597545673\n",
      "53 Train Loss 0.016753593 Test MSE 0.009605902906977628 Test RE 0.22936701377384114\n",
      "54 Train Loss 0.015955362 Test MSE 0.008464662713760803 Test RE 0.21531123543659245\n",
      "55 Train Loss 0.015605781 Test MSE 0.008801898064200977 Test RE 0.21955838690525853\n",
      "56 Train Loss 0.014397313 Test MSE 0.0068692839072211475 Test RE 0.19396242137820005\n",
      "57 Train Loss 0.013219881 Test MSE 0.005440299418519892 Test RE 0.17261290650144714\n",
      "58 Train Loss 0.012802682 Test MSE 0.0042473578236642455 Test RE 0.1525180658423278\n",
      "59 Train Loss 0.012607352 Test MSE 0.003907945750116129 Test RE 0.14629723805502734\n",
      "60 Train Loss 0.01219005 Test MSE 0.0032796678200846 Test RE 0.13402221563002414\n",
      "61 Train Loss 0.01171043 Test MSE 0.0030470667880441137 Test RE 0.12918225188006807\n",
      "62 Train Loss 0.011453972 Test MSE 0.0030610412349430702 Test RE 0.12947814060994287\n",
      "63 Train Loss 0.011247584 Test MSE 0.0030201004372722947 Test RE 0.12860935410524652\n",
      "64 Train Loss 0.010929911 Test MSE 0.003378733650693342 Test RE 0.13603129817634624\n",
      "65 Train Loss 0.010314148 Test MSE 0.0028304170164126998 Test RE 0.12450508161455001\n",
      "66 Train Loss 0.0098211635 Test MSE 0.0025263959591473066 Test RE 0.11762850382684666\n",
      "67 Train Loss 0.009553177 Test MSE 0.0028447874794257522 Test RE 0.12482074718632473\n",
      "68 Train Loss 0.0093702795 Test MSE 0.0027133287373782636 Test RE 0.12190262883921672\n",
      "69 Train Loss 0.008861491 Test MSE 0.0024741350891385595 Test RE 0.11640551816013507\n",
      "70 Train Loss 0.00842357 Test MSE 0.002346319906282076 Test RE 0.11335886179721202\n",
      "71 Train Loss 0.008216162 Test MSE 0.0020611562713802522 Test RE 0.1062471585195773\n",
      "72 Train Loss 0.00808101 Test MSE 0.001999027107332374 Test RE 0.10463360912606723\n",
      "73 Train Loss 0.007804432 Test MSE 0.0017841810828302005 Test RE 0.09885105966214104\n",
      "74 Train Loss 0.0076211146 Test MSE 0.001748581113714077 Test RE 0.0978598973088997\n",
      "75 Train Loss 0.0074752746 Test MSE 0.0017849251036628885 Test RE 0.09887166843962132\n",
      "76 Train Loss 0.007339903 Test MSE 0.0018269697313696121 Test RE 0.10002937151114498\n",
      "77 Train Loss 0.0070442683 Test MSE 0.0016053828218099196 Test RE 0.09376724796698933\n",
      "78 Train Loss 0.0068677524 Test MSE 0.00159195960966636 Test RE 0.09337441339513439\n",
      "79 Train Loss 0.0066823536 Test MSE 0.0014841713602936379 Test RE 0.09015792078089528\n",
      "80 Train Loss 0.006567254 Test MSE 0.0014209179242490534 Test RE 0.08821579663891344\n",
      "81 Train Loss 0.0064150407 Test MSE 0.001368008241206903 Test RE 0.08655780224108969\n",
      "82 Train Loss 0.00629752 Test MSE 0.0012706027584430271 Test RE 0.0834193422096449\n",
      "83 Train Loss 0.00606438 Test MSE 0.001199686825810544 Test RE 0.08105798600522948\n",
      "84 Train Loss 0.0058167204 Test MSE 0.0011759532118167262 Test RE 0.0802521886430824\n",
      "85 Train Loss 0.0053113354 Test MSE 0.001189697217190183 Test RE 0.08071980180863693\n",
      "86 Train Loss 0.005036032 Test MSE 0.0011360478099035009 Test RE 0.07887877701810532\n",
      "87 Train Loss 0.004833118 Test MSE 0.0012720229363749386 Test RE 0.0834659489175429\n",
      "88 Train Loss 0.0047283187 Test MSE 0.0012631779070068126 Test RE 0.08317525186998512\n",
      "89 Train Loss 0.0046789055 Test MSE 0.0012758922726153982 Test RE 0.08359279906511953\n",
      "90 Train Loss 0.0046380195 Test MSE 0.001250692823837073 Test RE 0.08276318454887918\n",
      "91 Train Loss 0.004576983 Test MSE 0.0011792216175707721 Test RE 0.0803636364075935\n",
      "92 Train Loss 0.0044685244 Test MSE 0.0010870510298425734 Test RE 0.07715904255153858\n",
      "93 Train Loss 0.004372291 Test MSE 0.0011503130432667316 Test RE 0.07937246831627148\n",
      "94 Train Loss 0.004269297 Test MSE 0.001287348894632915 Test RE 0.08396726283123203\n",
      "95 Train Loss 0.0041407477 Test MSE 0.0013341123629660992 Test RE 0.08547873145362468\n",
      "96 Train Loss 0.0040842635 Test MSE 0.0013682726948984832 Test RE 0.08656616820830254\n",
      "97 Train Loss 0.004012162 Test MSE 0.001363798782886305 Test RE 0.08642452739176772\n",
      "98 Train Loss 0.0039527602 Test MSE 0.0013251430286268836 Test RE 0.08519090701083364\n",
      "99 Train Loss 0.0039085723 Test MSE 0.0012709593681457382 Test RE 0.08343104770124274\n",
      "100 Train Loss 0.003871261 Test MSE 0.0012469617064809274 Test RE 0.08263964110234756\n",
      "101 Train Loss 0.0037881213 Test MSE 0.00123198124206896 Test RE 0.08214174255405583\n",
      "102 Train Loss 0.0036863647 Test MSE 0.0011365046313012775 Test RE 0.07889463457761382\n",
      "103 Train Loss 0.0035979266 Test MSE 0.0010035253183732274 Test RE 0.0741354675763913\n",
      "104 Train Loss 0.00349846 Test MSE 0.000978458068872997 Test RE 0.07320369005486789\n",
      "105 Train Loss 0.0033433598 Test MSE 0.0008642783600802471 Test RE 0.0688000388774531\n",
      "106 Train Loss 0.00326047 Test MSE 0.0008114836604522916 Test RE 0.0666655941119436\n",
      "107 Train Loss 0.0032175037 Test MSE 0.0007686629268041264 Test RE 0.06488283707780007\n",
      "108 Train Loss 0.0031801744 Test MSE 0.0007395664976208061 Test RE 0.06364297589756672\n",
      "109 Train Loss 0.0031525972 Test MSE 0.0007083960676124814 Test RE 0.06228736155672546\n",
      "110 Train Loss 0.0031140891 Test MSE 0.0007064707881765546 Test RE 0.062202661646052176\n",
      "111 Train Loss 0.0030024077 Test MSE 0.0007112948887596966 Test RE 0.06241467422064449\n",
      "112 Train Loss 0.0029328675 Test MSE 0.0006834407162384772 Test RE 0.06118039664618632\n",
      "113 Train Loss 0.0028827342 Test MSE 0.0006517736753000427 Test RE 0.05974619773168162\n",
      "114 Train Loss 0.0028259861 Test MSE 0.0006009885710416367 Test RE 0.05737133695626674\n",
      "115 Train Loss 0.0027789571 Test MSE 0.0005613788165700823 Test RE 0.055448509233044604\n",
      "116 Train Loss 0.002735251 Test MSE 0.000517691945762454 Test RE 0.05324729720450509\n",
      "117 Train Loss 0.002705127 Test MSE 0.0005186370845068792 Test RE 0.053295881246786234\n",
      "118 Train Loss 0.0026827755 Test MSE 0.0005103119840269794 Test RE 0.052866401226660344\n",
      "119 Train Loss 0.0026414806 Test MSE 0.00046882787404639765 Test RE 0.05067206187800478\n",
      "120 Train Loss 0.0025524297 Test MSE 0.0004525320970529324 Test RE 0.049783629755421215\n",
      "121 Train Loss 0.00246666 Test MSE 0.00044012354739301487 Test RE 0.04909634548868205\n",
      "122 Train Loss 0.0023985351 Test MSE 0.00043825118273237927 Test RE 0.04899180184516488\n",
      "123 Train Loss 0.0023726088 Test MSE 0.00041905321678693916 Test RE 0.04790672177954053\n",
      "124 Train Loss 0.002345252 Test MSE 0.0004165913636386642 Test RE 0.047765793327960486\n",
      "125 Train Loss 0.002317576 Test MSE 0.00041039428245108315 Test RE 0.047409187764224536\n",
      "126 Train Loss 0.0022691975 Test MSE 0.0003776713317367427 Test RE 0.04547983431594261\n",
      "127 Train Loss 0.0021889654 Test MSE 0.0003730982440286145 Test RE 0.04520364614188303\n",
      "128 Train Loss 0.0021112822 Test MSE 0.00033598172219560855 Test RE 0.04289628578205027\n",
      "129 Train Loss 0.002037855 Test MSE 0.00030693903406854556 Test RE 0.04100038407879653\n",
      "130 Train Loss 0.0019211723 Test MSE 0.0003190072693366319 Test RE 0.04179864023581412\n",
      "131 Train Loss 0.0018656519 Test MSE 0.0003013266841006223 Test RE 0.04062381074581201\n",
      "132 Train Loss 0.0018428382 Test MSE 0.0002849123869423994 Test RE 0.03950185855935582\n",
      "133 Train Loss 0.0018193739 Test MSE 0.0002698238592299098 Test RE 0.038441651644391894\n",
      "134 Train Loss 0.0018051381 Test MSE 0.00026718050351236966 Test RE 0.03825288950763118\n",
      "135 Train Loss 0.001783441 Test MSE 0.0002554724890961109 Test RE 0.037405368170409826\n",
      "136 Train Loss 0.0017579566 Test MSE 0.00023013912621491593 Test RE 0.035502349410448206\n",
      "137 Train Loss 0.0017418317 Test MSE 0.0002228561786868226 Test RE 0.034936082440473394\n",
      "138 Train Loss 0.0017233543 Test MSE 0.00019753448839604967 Test RE 0.03289147351463891\n",
      "139 Train Loss 0.0017042287 Test MSE 0.00019616839979306815 Test RE 0.032777542467879936\n",
      "140 Train Loss 0.001670368 Test MSE 0.00019476832102343416 Test RE 0.03266036427399797\n",
      "141 Train Loss 0.0015780997 Test MSE 0.00017588518050980635 Test RE 0.03103676789778167\n",
      "142 Train Loss 0.0015379337 Test MSE 0.00017759202345963163 Test RE 0.03118699939279265\n",
      "143 Train Loss 0.0015019134 Test MSE 0.0001774650883611639 Test RE 0.03117585184124176\n",
      "144 Train Loss 0.0014824888 Test MSE 0.00017242926237145351 Test RE 0.030730338861211657\n",
      "145 Train Loss 0.0014631167 Test MSE 0.00015491320913212482 Test RE 0.029127693056081504\n",
      "146 Train Loss 0.0014317079 Test MSE 0.00014382934507733543 Test RE 0.028066329238555062\n",
      "147 Train Loss 0.0014116323 Test MSE 0.00014977092313360327 Test RE 0.028640171705575864\n",
      "148 Train Loss 0.001387451 Test MSE 0.000151962251288714 Test RE 0.028848930902446647\n",
      "149 Train Loss 0.0013755374 Test MSE 0.00015138296560723578 Test RE 0.02879389180768057\n",
      "150 Train Loss 0.0013668603 Test MSE 0.000152186433067762 Test RE 0.02887020270219396\n",
      "151 Train Loss 0.0013567135 Test MSE 0.00014358774505191782 Test RE 0.02804274686111123\n",
      "152 Train Loss 0.0013336268 Test MSE 0.00013384400617806225 Test RE 0.02707455502805668\n",
      "153 Train Loss 0.0013176636 Test MSE 0.00013734208948142104 Test RE 0.027426076888281182\n",
      "154 Train Loss 0.0012927335 Test MSE 0.00014093477389770637 Test RE 0.02778247585456483\n",
      "155 Train Loss 0.0012548793 Test MSE 0.0001293944135771067 Test RE 0.026620709573069848\n",
      "156 Train Loss 0.0012197336 Test MSE 0.00011478834400366851 Test RE 0.025073257411581378\n",
      "157 Train Loss 0.0011984955 Test MSE 0.00010830917727343989 Test RE 0.02435535658864901\n",
      "158 Train Loss 0.0011742966 Test MSE 0.00010752415230164769 Test RE 0.024266932253907234\n",
      "159 Train Loss 0.0011625534 Test MSE 0.00010551619385689833 Test RE 0.024039278151879194\n",
      "160 Train Loss 0.001150354 Test MSE 0.00011621671443962637 Test RE 0.0252287748339826\n",
      "161 Train Loss 0.001141989 Test MSE 0.00011859543034734656 Test RE 0.02548565746265962\n",
      "162 Train Loss 0.0011370826 Test MSE 0.00012057823313692117 Test RE 0.02569782231560724\n",
      "163 Train Loss 0.0011298694 Test MSE 0.0001225842179105281 Test RE 0.025910699901646992\n",
      "164 Train Loss 0.0011211738 Test MSE 0.0001176229198223643 Test RE 0.025380948156800844\n",
      "165 Train Loss 0.001088818 Test MSE 0.00011678018656575364 Test RE 0.025289861236362905\n",
      "166 Train Loss 0.0010732823 Test MSE 0.00011233202514536849 Test RE 0.024803539420691214\n",
      "167 Train Loss 0.0010484378 Test MSE 9.985060225553737e-05 Test RE 0.023384991069178997\n",
      "168 Train Loss 0.0010303176 Test MSE 9.554517753970834e-05 Test RE 0.022875271112090655\n",
      "169 Train Loss 0.0010097199 Test MSE 0.00010065095188845472 Test RE 0.023478524875823956\n",
      "170 Train Loss 0.000983778 Test MSE 8.670231268263408e-05 Test RE 0.021791002223148878\n",
      "171 Train Loss 0.00097378285 Test MSE 8.114585901150934e-05 Test RE 0.02108118624288659\n",
      "172 Train Loss 0.0009638033 Test MSE 8.525628653999877e-05 Test RE 0.02160852237939361\n",
      "173 Train Loss 0.00095240754 Test MSE 7.835884761609626e-05 Test RE 0.02071599913685662\n",
      "174 Train Loss 0.00094095065 Test MSE 7.372911351935937e-05 Test RE 0.02009469274870766\n",
      "175 Train Loss 0.00093585625 Test MSE 7.173324010680294e-05 Test RE 0.019820841468927142\n",
      "176 Train Loss 0.0009289466 Test MSE 6.538340777858509e-05 Test RE 0.01892324621671409\n",
      "177 Train Loss 0.000924592 Test MSE 6.476425706617162e-05 Test RE 0.01883343588888364\n",
      "178 Train Loss 0.0009193218 Test MSE 6.337678967002967e-05 Test RE 0.018630606032172932\n",
      "179 Train Loss 0.00090765615 Test MSE 5.6038133621774054e-05 Test RE 0.017518773402963497\n",
      "180 Train Loss 0.0008983665 Test MSE 5.18071391895132e-05 Test RE 0.016844443579630382\n",
      "181 Train Loss 0.0008900748 Test MSE 4.99907243243292e-05 Test RE 0.016546516576421384\n",
      "182 Train Loss 0.000882733 Test MSE 5.208448779436782e-05 Test RE 0.016889471611512098\n",
      "183 Train Loss 0.00087087747 Test MSE 5.106733023596016e-05 Test RE 0.016723741305498776\n",
      "184 Train Loss 0.0008529533 Test MSE 5.176766626624343e-05 Test RE 0.016838025293099333\n",
      "185 Train Loss 0.0008394797 Test MSE 4.8883461294953203e-05 Test RE 0.016362243021392817\n",
      "186 Train Loss 0.0008332078 Test MSE 4.641838812857604e-05 Test RE 0.015944352668301374\n",
      "187 Train Loss 0.00083292025 Test MSE 4.667157496368908e-05 Test RE 0.015987777381496798\n",
      "188 Train Loss 0.0008296914 Test MSE 4.2531856785263074e-05 Test RE 0.015262266598384183\n",
      "189 Train Loss 0.0008269101 Test MSE 4.267289435492894e-05 Test RE 0.015287550839573281\n",
      "190 Train Loss 0.0008225378 Test MSE 4.0236775436399756e-05 Test RE 0.01484476916175096\n",
      "191 Train Loss 0.00081648637 Test MSE 4.1054466128219767e-05 Test RE 0.014994848026122424\n",
      "192 Train Loss 0.0008057606 Test MSE 4.130433420457551e-05 Test RE 0.015040410063215241\n",
      "193 Train Loss 0.0007940392 Test MSE 4.199271142517131e-05 Test RE 0.015165223765384636\n",
      "194 Train Loss 0.00077383884 Test MSE 4.3656264962973366e-05 Test RE 0.0154626936757263\n",
      "195 Train Loss 0.0007541891 Test MSE 4.6100739559678826e-05 Test RE 0.015889704118143177\n",
      "196 Train Loss 0.00074307725 Test MSE 4.7373917694862743e-05 Test RE 0.016107625161324562\n",
      "197 Train Loss 0.00073107047 Test MSE 4.662684722684121e-05 Test RE 0.015980114596271997\n",
      "198 Train Loss 0.00072330056 Test MSE 4.63858135935593e-05 Test RE 0.0159387571376598\n",
      "199 Train Loss 0.0007160617 Test MSE 4.5249562507671166e-05 Test RE 0.015742331604168457\n",
      "200 Train Loss 0.00071020226 Test MSE 4.2118650851296075e-05 Test RE 0.015187947586638852\n",
      "201 Train Loss 0.00070427463 Test MSE 4.071079369027734e-05 Test RE 0.014931954185118406\n",
      "202 Train Loss 0.0007008723 Test MSE 3.9121430428184265e-05 Test RE 0.014637578156331751\n",
      "203 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "204 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "205 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "206 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "207 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "208 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "209 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "210 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "211 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "212 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "213 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "214 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "215 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "216 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "217 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "218 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "219 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "220 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "221 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "222 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "223 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "224 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "225 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "226 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "227 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "228 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "229 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "230 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "231 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "232 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "233 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "234 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "235 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "236 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "237 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "238 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "239 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "240 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "241 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "242 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "243 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "244 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "245 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "246 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "247 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "248 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "249 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "250 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "251 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "252 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "253 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "254 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "255 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "256 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "257 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "258 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "259 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "260 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "261 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "262 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "263 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "264 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "265 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "266 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "267 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "268 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "269 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "270 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "271 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "272 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "273 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "274 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "275 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "276 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "277 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "278 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "279 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "280 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "281 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "282 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "283 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "284 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "285 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "286 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "287 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "288 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "289 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "290 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "291 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "292 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "293 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "294 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "295 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "296 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "297 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "298 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "299 Train Loss 0.00070073194 Test MSE 3.920257614696375e-05 Test RE 0.014652750933804568\n",
      "Training time: 140.08\n",
      "KG_stan_low\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 6274.9937 Test MSE 2.015080748618297 Test RE 3.322064734901615\n",
      "1 Train Loss 92.112236 Test MSE 0.7323894366696346 Test RE 2.0027784048959494\n",
      "2 Train Loss 7.7476583 Test MSE 0.184185682905433 Test RE 1.0043609027358715\n",
      "3 Train Loss 2.3258615 Test MSE 0.1501322845581678 Test RE 0.9067736901803717\n",
      "4 Train Loss 0.903183 Test MSE 0.12392434063147122 Test RE 0.8238348743611561\n",
      "5 Train Loss 0.4352418 Test MSE 0.07954747196296422 Test RE 0.6600472943575769\n",
      "6 Train Loss 0.25756785 Test MSE 0.0584101943257289 Test RE 0.5655958179383096\n",
      "7 Train Loss 0.1642529 Test MSE 0.04379937565705096 Test RE 0.48977410983744224\n",
      "8 Train Loss 0.12066167 Test MSE 0.033698907026079514 Test RE 0.42960543964384484\n",
      "9 Train Loss 0.09299846 Test MSE 0.023806235144819467 Test RE 0.3610831508817633\n",
      "10 Train Loss 0.072319955 Test MSE 0.01977052246383496 Test RE 0.32905685092787873\n",
      "11 Train Loss 0.06101087 Test MSE 0.019955217909822413 Test RE 0.33059029600956324\n",
      "12 Train Loss 0.051531024 Test MSE 0.011831001865128851 Test RE 0.25454972105230594\n",
      "13 Train Loss 0.040541336 Test MSE 0.014073527073457666 Test RE 0.27762804858659856\n",
      "14 Train Loss 0.034901153 Test MSE 0.007898575760937774 Test RE 0.20798703227768886\n",
      "15 Train Loss 0.031064492 Test MSE 0.007798872583092951 Test RE 0.20667016039216748\n",
      "16 Train Loss 0.027252821 Test MSE 0.006517232439357768 Test RE 0.1889267567842913\n",
      "17 Train Loss 0.024112824 Test MSE 0.005175900032248394 Test RE 0.16836615885471795\n",
      "18 Train Loss 0.022004098 Test MSE 0.005396458266650157 Test RE 0.1719159911523943\n",
      "19 Train Loss 0.019948695 Test MSE 0.0036186360291210746 Test RE 0.14077784587296194\n",
      "20 Train Loss 0.018072592 Test MSE 0.0027430179223758987 Test RE 0.1225677423531471\n",
      "21 Train Loss 0.016800294 Test MSE 0.00278069639017614 Test RE 0.12340667485795526\n",
      "22 Train Loss 0.015192058 Test MSE 0.0018752083774408311 Test RE 0.1013413373862472\n",
      "23 Train Loss 0.014098426 Test MSE 0.0014615450747129902 Test RE 0.08946804981963748\n",
      "24 Train Loss 0.012774496 Test MSE 0.00111708293847598 Test RE 0.07821761572870779\n",
      "25 Train Loss 0.012119302 Test MSE 0.0012549322207722395 Test RE 0.0829033345360885\n",
      "26 Train Loss 0.011410177 Test MSE 0.0009841397031113727 Test RE 0.07341591915983466\n",
      "27 Train Loss 0.010441622 Test MSE 0.0007592115416158284 Test RE 0.06448270757926661\n",
      "28 Train Loss 0.009526675 Test MSE 0.0009385927754967015 Test RE 0.07169691474782003\n",
      "29 Train Loss 0.008829009 Test MSE 0.0009629146522315444 Test RE 0.07261991924781859\n",
      "30 Train Loss 0.008310279 Test MSE 0.0009307092959025907 Test RE 0.07139517950706886\n",
      "31 Train Loss 0.00762833 Test MSE 0.0010531461724643577 Test RE 0.07594622487655833\n",
      "32 Train Loss 0.007026501 Test MSE 0.0009568228993258546 Test RE 0.07238984460211971\n",
      "33 Train Loss 0.0064119482 Test MSE 0.0007249904606339978 Test RE 0.06301268857482585\n",
      "34 Train Loss 0.006177684 Test MSE 0.0006105200272941876 Test RE 0.05782449139145849\n",
      "35 Train Loss 0.0057555437 Test MSE 0.0006214102539980136 Test RE 0.058337937615076184\n",
      "36 Train Loss 0.005642357 Test MSE 0.0005600246860567361 Test RE 0.05538159376567494\n",
      "37 Train Loss 0.0053284816 Test MSE 0.0005209083341027952 Test RE 0.053412452174837345\n",
      "38 Train Loss 0.004988865 Test MSE 0.0005420406859302749 Test RE 0.05448510687673993\n",
      "39 Train Loss 0.0048663607 Test MSE 0.0004572016290739611 Test RE 0.050039821131645845\n",
      "40 Train Loss 0.00447914 Test MSE 0.00037656881105907003 Test RE 0.045413402074785406\n",
      "41 Train Loss 0.0042489325 Test MSE 0.00035613084575044686 Test RE 0.044163822891999265\n",
      "42 Train Loss 0.0041256105 Test MSE 0.00034219948936758027 Test RE 0.04329139122109475\n",
      "43 Train Loss 0.0036594104 Test MSE 0.0003012360737150429 Test RE 0.040617702398774956\n",
      "44 Train Loss 0.003545271 Test MSE 0.00030506754508325394 Test RE 0.04087519783639705\n",
      "45 Train Loss 0.0031868764 Test MSE 0.00022291643840415153 Test RE 0.03494080543305848\n",
      "46 Train Loss 0.0031181765 Test MSE 0.00021690449656161355 Test RE 0.03446641728301224\n",
      "47 Train Loss 0.0029349048 Test MSE 0.00020439794832368362 Test RE 0.03345801181079515\n",
      "48 Train Loss 0.00281183 Test MSE 0.00018401650031485862 Test RE 0.03174609031772048\n",
      "49 Train Loss 0.002705126 Test MSE 0.00014525243183642638 Test RE 0.028204835434584893\n",
      "50 Train Loss 0.0024943384 Test MSE 0.00010360665964618111 Test RE 0.02382076474510543\n",
      "51 Train Loss 0.0024506443 Test MSE 9.435358665726996e-05 Test RE 0.02273217919375757\n",
      "52 Train Loss 0.0023615165 Test MSE 9.685379646403247e-05 Test RE 0.023031392066735944\n",
      "53 Train Loss 0.002248275 Test MSE 8.883180890713541e-05 Test RE 0.022056983432012862\n",
      "54 Train Loss 0.0020336416 Test MSE 6.821587168639158e-05 Test RE 0.01932878612483487\n",
      "55 Train Loss 0.0020034076 Test MSE 5.6577493716918386e-05 Test RE 0.017602879521906162\n",
      "56 Train Loss 0.0019832838 Test MSE 5.244783066892783e-05 Test RE 0.016948279945795848\n",
      "57 Train Loss 0.001851122 Test MSE 6.446594930631875e-05 Test RE 0.018790011902748597\n",
      "58 Train Loss 0.0016776441 Test MSE 7.4351052596933e-05 Test RE 0.020179268764503634\n",
      "59 Train Loss 0.0016547182 Test MSE 7.414524446709765e-05 Test RE 0.020151320703361394\n",
      "60 Train Loss 0.0016178623 Test MSE 6.284195411245814e-05 Test RE 0.0185518278079307\n",
      "61 Train Loss 0.0015766756 Test MSE 7.157619361009644e-05 Test RE 0.019799132570115983\n",
      "62 Train Loss 0.0015026027 Test MSE 6.172158445462042e-05 Test RE 0.018385709641755513\n",
      "63 Train Loss 0.0014679808 Test MSE 6.484061375302113e-05 Test RE 0.018844534874771227\n",
      "64 Train Loss 0.0014167747 Test MSE 7.39677145058246e-05 Test RE 0.020127181547805212\n",
      "65 Train Loss 0.0013791854 Test MSE 6.822604069544202e-05 Test RE 0.019330226752005467\n",
      "66 Train Loss 0.0013234153 Test MSE 5.6268728188174585e-05 Test RE 0.017554780907056013\n",
      "67 Train Loss 0.0012633319 Test MSE 4.6434099253281846e-05 Test RE 0.015947050764141803\n",
      "68 Train Loss 0.0012254581 Test MSE 3.749694619805729e-05 Test RE 0.014330449527423173\n",
      "69 Train Loss 0.001199665 Test MSE 3.120850673305096e-05 Test RE 0.013073695288313297\n",
      "70 Train Loss 0.001175971 Test MSE 3.478630013177629e-05 Test RE 0.013802761502195313\n",
      "71 Train Loss 0.0011229808 Test MSE 2.7402108621721338e-05 Test RE 0.0122505011611208\n",
      "72 Train Loss 0.001076059 Test MSE 2.6301021181109585e-05 Test RE 0.012001849307289649\n",
      "73 Train Loss 0.001036453 Test MSE 2.3567735000137227e-05 Test RE 0.011361110585837214\n",
      "74 Train Loss 0.0010223931 Test MSE 2.1964431545498695e-05 Test RE 0.010967858731208471\n",
      "75 Train Loss 0.0010172318 Test MSE 2.1355329789155204e-05 Test RE 0.010814713166469194\n",
      "76 Train Loss 0.0010071378 Test MSE 2.124868464954298e-05 Test RE 0.010787675885644924\n",
      "77 Train Loss 0.0009806362 Test MSE 1.9224447908882043e-05 Test RE 0.010260979082805355\n",
      "78 Train Loss 0.0009409858 Test MSE 1.882487968610196e-05 Test RE 0.010153785126067608\n",
      "79 Train Loss 0.00091233884 Test MSE 1.832589113559364e-05 Test RE 0.010018308826246462\n",
      "80 Train Loss 0.00089287036 Test MSE 1.9083666446089917e-05 Test RE 0.010223339250035934\n",
      "81 Train Loss 0.0008859074 Test MSE 2.0941583706233198e-05 Test RE 0.01070943662295188\n",
      "82 Train Loss 0.00087765337 Test MSE 1.7582299727393264e-05 Test RE 0.009812952658948312\n",
      "83 Train Loss 0.0008652849 Test MSE 1.7671430784906354e-05 Test RE 0.00983779392535464\n",
      "84 Train Loss 0.0008375372 Test MSE 1.647003420572007e-05 Test RE 0.009497495896984136\n",
      "85 Train Loss 0.0008197669 Test MSE 1.3983634501514651e-05 Test RE 0.00875128637967442\n",
      "86 Train Loss 0.0008059038 Test MSE 1.4181747917804693e-05 Test RE 0.00881306036393174\n",
      "87 Train Loss 0.00079382147 Test MSE 1.4254076958106182e-05 Test RE 0.008835505746116173\n",
      "88 Train Loss 0.00078262924 Test MSE 1.7177336903881053e-05 Test RE 0.00969928634491223\n",
      "89 Train Loss 0.00077644305 Test MSE 2.0326299728519732e-05 Test RE 0.01055093692342777\n",
      "90 Train Loss 0.00076981355 Test MSE 2.3203419327527428e-05 Test RE 0.011272957205496677\n",
      "91 Train Loss 0.0007517518 Test MSE 2.4217529732426343e-05 Test RE 0.011516666344504265\n",
      "92 Train Loss 0.00073589844 Test MSE 1.9810317793973874e-05 Test RE 0.010416158630896002\n",
      "93 Train Loss 0.00072042854 Test MSE 2.0574459689708824e-05 Test RE 0.010615148730380487\n",
      "94 Train Loss 0.0007053941 Test MSE 1.936227260429459e-05 Test RE 0.010297695108528945\n",
      "95 Train Loss 0.0006910365 Test MSE 2.018590047821582e-05 Test RE 0.010514434693879759\n",
      "96 Train Loss 0.00067871733 Test MSE 1.6633864816013776e-05 Test RE 0.009544615722177104\n",
      "97 Train Loss 0.00065758784 Test MSE 1.6372986557278852e-05 Test RE 0.009469473143311603\n",
      "98 Train Loss 0.0006343781 Test MSE 1.4381602865498259e-05 Test RE 0.008874941724172795\n",
      "99 Train Loss 0.0006171031 Test MSE 1.610305307627324e-05 Test RE 0.009391089428738795\n",
      "100 Train Loss 0.0005939831 Test MSE 1.5343846781878122e-05 Test RE 0.009167037134188238\n",
      "101 Train Loss 0.0005695245 Test MSE 1.5599155513443178e-05 Test RE 0.009242988398067836\n",
      "102 Train Loss 0.00055834523 Test MSE 1.8055764943208523e-05 Test RE 0.009944199080403539\n",
      "103 Train Loss 0.00054811133 Test MSE 1.792685647950719e-05 Test RE 0.00990863737369967\n",
      "104 Train Loss 0.0005421012 Test MSE 1.6963290472340733e-05 Test RE 0.009638665603552988\n",
      "105 Train Loss 0.0005355728 Test MSE 1.571676572863007e-05 Test RE 0.00927776683668611\n",
      "106 Train Loss 0.0005279001 Test MSE 1.4989446505567427e-05 Test RE 0.009060552106854849\n",
      "107 Train Loss 0.0005212128 Test MSE 1.3659474189980795e-05 Test RE 0.008649258060489716\n",
      "108 Train Loss 0.00051504845 Test MSE 1.384006637724151e-05 Test RE 0.008706246326968904\n",
      "109 Train Loss 0.00050932204 Test MSE 1.3956409892709277e-05 Test RE 0.008742763329995344\n",
      "110 Train Loss 0.00050182163 Test MSE 1.3130216391336908e-05 Test RE 0.008480038144624254\n",
      "111 Train Loss 0.00048345374 Test MSE 1.1358716188615937e-05 Test RE 0.007887266007800741\n",
      "112 Train Loss 0.00046635466 Test MSE 1.0101480218547013e-05 Test RE 0.007437969152805085\n",
      "113 Train Loss 0.00045799505 Test MSE 9.48446139863964e-06 Test RE 0.007207226996874511\n",
      "114 Train Loss 0.00045554258 Test MSE 8.662859443603346e-06 Test RE 0.006887989842676329\n",
      "115 Train Loss 0.00045457785 Test MSE 8.615994510822837e-06 Test RE 0.006869333015134059\n",
      "116 Train Loss 0.00044995104 Test MSE 7.508787578432541e-06 Test RE 0.00641278638189995\n",
      "117 Train Loss 0.0004446627 Test MSE 8.847241667007093e-06 Test RE 0.006960906643601918\n",
      "118 Train Loss 0.0004344585 Test MSE 7.844567828146151e-06 Test RE 0.006554602741379534\n",
      "119 Train Loss 0.0004244827 Test MSE 7.208239655952782e-06 Test RE 0.006283136181163286\n",
      "120 Train Loss 0.00041771488 Test MSE 7.909464838685049e-06 Test RE 0.006581659552394101\n",
      "121 Train Loss 0.00041198175 Test MSE 8.793782731277802e-06 Test RE 0.006939844344640446\n",
      "122 Train Loss 0.00040921368 Test MSE 8.952689417205634e-06 Test RE 0.007002266300669995\n",
      "123 Train Loss 0.00040357836 Test MSE 8.541251994307333e-06 Test RE 0.006839472876685766\n",
      "124 Train Loss 0.00037761638 Test MSE 8.020217953539514e-06 Test RE 0.006627579552018024\n",
      "125 Train Loss 0.00036324325 Test MSE 7.277320333066045e-06 Test RE 0.006313171831660434\n",
      "126 Train Loss 0.00035816728 Test MSE 8.001179237716047e-06 Test RE 0.0066197084706721325\n",
      "127 Train Loss 0.0003519561 Test MSE 8.388084389852985e-06 Test RE 0.0067778703872548585\n",
      "128 Train Loss 0.00034796572 Test MSE 8.290812835124606e-06 Test RE 0.006738456351720843\n",
      "129 Train Loss 0.000345045 Test MSE 8.909098769521711e-06 Test RE 0.006985198481066489\n",
      "130 Train Loss 0.00034206072 Test MSE 9.666001461756557e-06 Test RE 0.007275876055993639\n",
      "131 Train Loss 0.00033571938 Test MSE 9.477464525783678e-06 Test RE 0.007204568050167181\n",
      "132 Train Loss 0.00032684015 Test MSE 9.257378072657655e-06 Test RE 0.00712042414860236\n",
      "133 Train Loss 0.0003208467 Test MSE 9.033623110109073e-06 Test RE 0.007033845873773697\n",
      "134 Train Loss 0.00031712116 Test MSE 8.441970150484632e-06 Test RE 0.006799606339868488\n",
      "135 Train Loss 0.00031366036 Test MSE 8.258407697033034e-06 Test RE 0.006725274628780731\n",
      "136 Train Loss 0.00030679116 Test MSE 8.030353214594823e-06 Test RE 0.006631765912107332\n",
      "137 Train Loss 0.00030123835 Test MSE 7.705958231162415e-06 Test RE 0.006496436374593317\n",
      "138 Train Loss 0.00029753972 Test MSE 7.769654445188113e-06 Test RE 0.006523230370059958\n",
      "139 Train Loss 0.00029458222 Test MSE 7.363830630765863e-06 Test RE 0.006350585385138815\n",
      "140 Train Loss 0.00029255077 Test MSE 7.166535131475916e-06 Test RE 0.0062649337259069295\n",
      "141 Train Loss 0.00029028818 Test MSE 6.67105085280633e-06 Test RE 0.00604448062271202\n",
      "142 Train Loss 0.00028717384 Test MSE 6.414723716800531e-06 Test RE 0.005927217199847844\n",
      "143 Train Loss 0.0002829239 Test MSE 6.103799633751466e-06 Test RE 0.005781785803866738\n",
      "144 Train Loss 0.00028102257 Test MSE 6.010502199038985e-06 Test RE 0.005737427943065182\n",
      "145 Train Loss 0.00027714865 Test MSE 5.876502840392579e-06 Test RE 0.005673111760196315\n",
      "146 Train Loss 0.00027310167 Test MSE 6.036906826795159e-06 Test RE 0.005750016627543772\n",
      "147 Train Loss 0.00026929803 Test MSE 5.7984163608671156e-06 Test RE 0.005635293791646182\n",
      "148 Train Loss 0.00026309871 Test MSE 5.952307231285188e-06 Test RE 0.005709584881313641\n",
      "149 Train Loss 0.00026116968 Test MSE 6.254115007069254e-06 Test RE 0.005852545458194698\n",
      "150 Train Loss 0.00025973018 Test MSE 6.239053013083105e-06 Test RE 0.005845493769614161\n",
      "151 Train Loss 0.00025835226 Test MSE 6.631897810425576e-06 Test RE 0.006026716699246263\n",
      "152 Train Loss 0.00025666764 Test MSE 7.355267664609425e-06 Test RE 0.006346891949722181\n",
      "153 Train Loss 0.00025481073 Test MSE 8.080296197019369e-06 Test RE 0.006652356338386014\n",
      "154 Train Loss 0.00025358095 Test MSE 7.844325612774656e-06 Test RE 0.006554501547927695\n",
      "155 Train Loss 0.00025027717 Test MSE 8.069005160560474e-06 Test RE 0.006647706864283266\n",
      "156 Train Loss 0.0002475254 Test MSE 8.022795483298597e-06 Test RE 0.006628644448965553\n",
      "157 Train Loss 0.00024112714 Test MSE 8.783088797611503e-06 Test RE 0.006935623361835585\n",
      "158 Train Loss 0.0002383663 Test MSE 9.598895781362024e-06 Test RE 0.007250575884758131\n",
      "159 Train Loss 0.00023630368 Test MSE 1.045063148104445e-05 Test RE 0.007565421526031362\n",
      "160 Train Loss 0.0002347423 Test MSE 1.09285200180785e-05 Test RE 0.007736464554317366\n",
      "161 Train Loss 0.00023331416 Test MSE 1.1916209201634103e-05 Test RE 0.008078503613889395\n",
      "162 Train Loss 0.0002316694 Test MSE 1.3205296306192425e-05 Test RE 0.00850424844568777\n",
      "163 Train Loss 0.00023053795 Test MSE 1.2713793253987159e-05 Test RE 0.008344483043129848\n",
      "164 Train Loss 0.0002302409 Test MSE 1.280967168021832e-05 Test RE 0.008375888037021093\n",
      "165 Train Loss 0.00023024087 Test MSE 1.2809671717018172e-05 Test RE 0.008375888049052291\n",
      "166 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "167 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "168 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "169 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "170 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "171 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "172 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "173 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "174 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "175 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "176 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "177 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "178 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "179 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "180 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "181 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "182 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "183 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "184 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "185 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "186 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "187 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "188 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "189 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "190 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "191 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "192 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "193 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "194 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "195 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "196 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "197 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "198 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "199 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "200 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "201 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "202 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "203 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "204 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "205 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "206 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "207 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "208 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "209 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "210 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "211 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "212 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "213 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "214 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "215 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "216 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "217 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "218 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "219 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "220 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "221 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "222 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "223 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "224 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "225 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "226 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "227 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "228 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "229 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "230 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "231 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "232 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "233 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "234 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "235 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "236 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "237 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "238 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "239 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "240 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "241 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "242 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "243 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "244 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "245 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "246 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "247 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "248 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "249 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "250 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "251 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "252 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "253 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "254 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "255 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "256 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "257 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "258 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "259 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "260 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "261 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "262 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "263 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "264 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "265 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "266 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "267 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "268 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "269 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "270 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "271 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "272 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "273 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "274 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "275 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "276 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "277 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "278 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "279 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "280 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "281 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "282 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "283 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "284 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "285 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "286 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "287 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "288 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "289 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "290 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "291 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "292 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "293 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "294 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "295 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "296 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "297 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "298 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "299 Train Loss 0.0002302407 Test MSE 1.2809671683010971e-05 Test RE 0.00837588803793411\n",
      "Training time: 106.49\n",
      "KG_stan_low\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 9079.806 Test MSE 3.4358478118514797 Test RE 4.337892881331118\n",
      "1 Train Loss 1961.2523 Test MSE 3.4653609521389863 Test RE 4.356483793482055\n",
      "2 Train Loss 443.3482 Test MSE 9.268458179345734 Test RE 7.124684073251628\n",
      "3 Train Loss 183.19109 Test MSE 9.213371739973232 Test RE 7.103479986831516\n",
      "4 Train Loss 78.15145 Test MSE 8.128024990612396 Test RE 6.671974521189938\n",
      "5 Train Loss 38.762604 Test MSE 6.924204432027975 Test RE 6.158100961573234\n",
      "6 Train Loss 22.05045 Test MSE 6.4493681905905484 Test RE 5.943201427714746\n",
      "7 Train Loss 15.481275 Test MSE 6.169221690010149 Test RE 5.812688534373061\n",
      "8 Train Loss 11.964396 Test MSE 5.428317968229167 Test RE 5.452485301258102\n",
      "9 Train Loss 8.208624 Test MSE 3.7889504591540355 Test RE 4.555345561591701\n",
      "10 Train Loss 5.681572 Test MSE 2.6346159626396166 Test RE 3.7985734063836043\n",
      "11 Train Loss 3.0345404 Test MSE 1.2486068155855579 Test RE 2.6150181929848837\n",
      "12 Train Loss 1.9666753 Test MSE 0.6713698561676342 Test RE 1.9175327187339335\n",
      "13 Train Loss 1.120463 Test MSE 0.24980828168207023 Test RE 1.169675195115353\n",
      "14 Train Loss 0.69063824 Test MSE 0.12367587811485567 Test RE 0.8230085847572847\n",
      "15 Train Loss 0.46562374 Test MSE 0.09052758765975755 Test RE 0.7041291726310991\n",
      "16 Train Loss 0.30646074 Test MSE 0.08498829533225613 Test RE 0.6822466678792837\n",
      "17 Train Loss 0.23530674 Test MSE 0.08270364235791591 Test RE 0.6730141300780755\n",
      "18 Train Loss 0.17482786 Test MSE 0.06963209361287016 Test RE 0.6175421289130166\n",
      "19 Train Loss 0.14710817 Test MSE 0.047692099452269696 Test RE 0.5110755262506648\n",
      "20 Train Loss 0.10253246 Test MSE 0.027565834072714734 Test RE 0.38855046485257\n",
      "21 Train Loss 0.084920675 Test MSE 0.021446153541066604 Test RE 0.34271772756212526\n",
      "22 Train Loss 0.070467874 Test MSE 0.0168277977196245 Test RE 0.30358164189831993\n",
      "23 Train Loss 0.05941777 Test MSE 0.014350916791245458 Test RE 0.2803507273691329\n",
      "24 Train Loss 0.052343458 Test MSE 0.011721398994660648 Test RE 0.25336789821484595\n",
      "25 Train Loss 0.043949198 Test MSE 0.008638058234091018 Test RE 0.21750534199167712\n",
      "26 Train Loss 0.03863852 Test MSE 0.007661563767961131 Test RE 0.20484273904309344\n",
      "27 Train Loss 0.03507172 Test MSE 0.007674509281773998 Test RE 0.20501572430883236\n",
      "28 Train Loss 0.032721736 Test MSE 0.008115925165768817 Test RE 0.21082925833935579\n",
      "29 Train Loss 0.029458214 Test MSE 0.0075353630284096165 Test RE 0.20314865627759363\n",
      "30 Train Loss 0.025995322 Test MSE 0.0053770583477021966 Test RE 0.1716066994885809\n",
      "31 Train Loss 0.023317441 Test MSE 0.005208115684408518 Test RE 0.16888931538141755\n",
      "32 Train Loss 0.020196097 Test MSE 0.0063497759928141054 Test RE 0.18648378112441624\n",
      "33 Train Loss 0.018572504 Test MSE 0.006346697041996541 Test RE 0.18643856346548468\n",
      "34 Train Loss 0.01639731 Test MSE 0.008019166133251685 Test RE 0.2095687241713483\n",
      "35 Train Loss 0.015620972 Test MSE 0.00795338747368033 Test RE 0.20870744165968086\n",
      "36 Train Loss 0.014520708 Test MSE 0.0073577177739414116 Test RE 0.2007397720502719\n",
      "37 Train Loss 0.013530204 Test MSE 0.00745450237170916 Test RE 0.20205574012796343\n",
      "38 Train Loss 0.012809123 Test MSE 0.006444703471178051 Test RE 0.18787255164241354\n",
      "39 Train Loss 0.012165883 Test MSE 0.006539769769073756 Test RE 0.18925313994778023\n",
      "40 Train Loss 0.011143702 Test MSE 0.005916068599607242 Test RE 0.18000247003912748\n",
      "41 Train Loss 0.010534668 Test MSE 0.0059858751525905946 Test RE 0.18106132379199955\n",
      "42 Train Loss 0.010226773 Test MSE 0.005817010747484516 Test RE 0.17848914004857705\n",
      "43 Train Loss 0.008802045 Test MSE 0.004807601800828437 Test RE 0.1622654687267961\n",
      "44 Train Loss 0.008532298 Test MSE 0.004488681874803529 Test RE 0.1567910532330839\n",
      "45 Train Loss 0.008174319 Test MSE 0.004055222055804411 Test RE 0.14902844988874553\n",
      "46 Train Loss 0.0071049733 Test MSE 0.002765369473324052 Test RE 0.12306610236309451\n",
      "47 Train Loss 0.0066618226 Test MSE 0.002022287586502131 Test RE 0.10524060160403012\n",
      "48 Train Loss 0.0064331777 Test MSE 0.0017065255831411543 Test RE 0.096675909326182\n",
      "49 Train Loss 0.0057884436 Test MSE 0.0008945340617670219 Test RE 0.06999391811612632\n",
      "50 Train Loss 0.005285886 Test MSE 0.0006593627010167605 Test RE 0.060093023036103886\n",
      "51 Train Loss 0.005050991 Test MSE 0.0007790228573927294 Test RE 0.06531861452212837\n",
      "52 Train Loss 0.0048109307 Test MSE 0.0008511306990506361 Test RE 0.0682747300434331\n",
      "53 Train Loss 0.004241829 Test MSE 0.0005609045296653822 Test RE 0.055425081150234604\n",
      "54 Train Loss 0.004055388 Test MSE 0.00036684768589841137 Test RE 0.044823395859105795\n",
      "55 Train Loss 0.003997916 Test MSE 0.00032685979785544267 Test RE 0.04230996031024314\n",
      "56 Train Loss 0.0038164463 Test MSE 0.00026910078798039435 Test RE 0.038390109315896384\n",
      "57 Train Loss 0.0034818084 Test MSE 0.00024725073670341606 Test RE 0.036798546186559866\n",
      "58 Train Loss 0.0033561 Test MSE 0.0002354197436902557 Test RE 0.03590734589797305\n",
      "59 Train Loss 0.0031921896 Test MSE 0.000262519348056037 Test RE 0.03791774683254762\n",
      "60 Train Loss 0.003108084 Test MSE 0.0002677522208801312 Test RE 0.038293794727412435\n",
      "61 Train Loss 0.0029674617 Test MSE 0.00025770866704752637 Test RE 0.03756871808345177\n",
      "62 Train Loss 0.0027569642 Test MSE 0.0002380434486774601 Test RE 0.036106881512587605\n",
      "63 Train Loss 0.0026745526 Test MSE 0.0002351445065189812 Test RE 0.03588634951403414\n",
      "64 Train Loss 0.0026280696 Test MSE 0.0002107022203504256 Test RE 0.03397006830493732\n",
      "65 Train Loss 0.0024579149 Test MSE 0.00022628767511484444 Test RE 0.03520402447805585\n",
      "66 Train Loss 0.002195698 Test MSE 0.0001856070816015718 Test RE 0.03188299676619841\n",
      "67 Train Loss 0.0020964493 Test MSE 0.00023168867125151105 Test RE 0.03562166897116835\n",
      "68 Train Loss 0.0020635691 Test MSE 0.00020876793883865374 Test RE 0.033813783352150205\n",
      "69 Train Loss 0.0020172948 Test MSE 0.00018527718508634216 Test RE 0.03185464987531681\n",
      "70 Train Loss 0.0019624722 Test MSE 0.0001951089651500794 Test RE 0.032688912810238904\n",
      "71 Train Loss 0.0018928203 Test MSE 0.00021585576503240403 Test RE 0.03438299389518499\n",
      "72 Train Loss 0.0018110155 Test MSE 0.00018465237311216114 Test RE 0.0318008926495473\n",
      "73 Train Loss 0.0017455873 Test MSE 0.00015999639844672912 Test RE 0.02960172143382149\n",
      "74 Train Loss 0.0017051903 Test MSE 0.00015809844910530862 Test RE 0.02942562316035522\n",
      "75 Train Loss 0.0016799438 Test MSE 0.00015200844488317227 Test RE 0.028853315328660575\n",
      "76 Train Loss 0.0016233147 Test MSE 0.00014435400348938933 Test RE 0.028117472597160645\n",
      "77 Train Loss 0.0015256543 Test MSE 0.00014843328383900507 Test RE 0.028511988805326308\n",
      "78 Train Loss 0.0014705153 Test MSE 0.00014607259517481652 Test RE 0.028284352208336798\n",
      "79 Train Loss 0.001455335 Test MSE 0.0001442387964720879 Test RE 0.02810625026647251\n",
      "80 Train Loss 0.0014069008 Test MSE 0.0001384224952496374 Test RE 0.027533739608429388\n",
      "81 Train Loss 0.0013275457 Test MSE 0.00013320221651567826 Test RE 0.027009565007025626\n",
      "82 Train Loss 0.0012671076 Test MSE 0.00013261921916320036 Test RE 0.026950392671627268\n",
      "83 Train Loss 0.0012428445 Test MSE 0.0001267178776496545 Test RE 0.026343944895439415\n",
      "84 Train Loss 0.0012229041 Test MSE 0.00013220335151007282 Test RE 0.026908103941593438\n",
      "85 Train Loss 0.0011717908 Test MSE 0.00012836142669100364 Test RE 0.02651423686773818\n",
      "86 Train Loss 0.0011067217 Test MSE 0.00013050019838722128 Test RE 0.02673421583746082\n",
      "87 Train Loss 0.0010759507 Test MSE 0.00012800135989465787 Test RE 0.026477023193108507\n",
      "88 Train Loss 0.0010571167 Test MSE 0.0001280868565733263 Test RE 0.02648586419163768\n",
      "89 Train Loss 0.0010481278 Test MSE 0.0001296334748621767 Test RE 0.026645289630855416\n",
      "90 Train Loss 0.0010348589 Test MSE 0.00012693748278791062 Test RE 0.026366762359859453\n",
      "91 Train Loss 0.0010173477 Test MSE 0.00012401436141508876 Test RE 0.026061406762897314\n",
      "92 Train Loss 0.0009973547 Test MSE 0.00011996574645740489 Test RE 0.025632472160858098\n",
      "93 Train Loss 0.0009480406 Test MSE 0.0001201233162357389 Test RE 0.02564930020434254\n",
      "94 Train Loss 0.0009047224 Test MSE 0.00010137700950257999 Test RE 0.023563055273243157\n",
      "95 Train Loss 0.00086804753 Test MSE 0.00010338604230070302 Test RE 0.023795389568949016\n",
      "96 Train Loss 0.00084965996 Test MSE 0.00010159569750764294 Test RE 0.023588456405171314\n",
      "97 Train Loss 0.0008378143 Test MSE 0.00010000591676233566 Test RE 0.023403171315431775\n",
      "98 Train Loss 0.0008256043 Test MSE 0.00010013039500104975 Test RE 0.023417731851882083\n",
      "99 Train Loss 0.00081446307 Test MSE 9.844581598904394e-05 Test RE 0.023219908047849208\n",
      "100 Train Loss 0.0007906222 Test MSE 9.370505229417028e-05 Test RE 0.022653920271995767\n",
      "101 Train Loss 0.00076032506 Test MSE 8.73779864246787e-05 Test RE 0.021875746409384465\n",
      "102 Train Loss 0.00072293356 Test MSE 7.970700677071802e-05 Test RE 0.02089344788872947\n",
      "103 Train Loss 0.00069678226 Test MSE 7.513751521221952e-05 Test RE 0.020285713077023215\n",
      "104 Train Loss 0.0006861403 Test MSE 7.338019922231127e-05 Test RE 0.020047088484851216\n",
      "105 Train Loss 0.00068182405 Test MSE 7.156737290360207e-05 Test RE 0.01979791255750224\n",
      "106 Train Loss 0.00067637314 Test MSE 7.104219654717246e-05 Test RE 0.01972513819095416\n",
      "107 Train Loss 0.00066624465 Test MSE 7.239630026324133e-05 Test RE 0.01991223689168955\n",
      "108 Train Loss 0.0006458777 Test MSE 6.741348057957197e-05 Test RE 0.019214772165118923\n",
      "109 Train Loss 0.00062552956 Test MSE 6.32596452762875e-05 Test RE 0.018613379848090587\n",
      "110 Train Loss 0.00060979906 Test MSE 6.924811333873511e-05 Test RE 0.019474478506193663\n",
      "111 Train Loss 0.0005995975 Test MSE 7.197838547691312e-05 Test RE 0.0198546810336948\n",
      "112 Train Loss 0.0005948701 Test MSE 7.271323527821443e-05 Test RE 0.019955774981594728\n",
      "113 Train Loss 0.0005869849 Test MSE 7.017617649433346e-05 Test RE 0.01960454264881143\n",
      "114 Train Loss 0.0005820859 Test MSE 6.883651454415325e-05 Test RE 0.019416515783723966\n",
      "115 Train Loss 0.0005730122 Test MSE 6.462981167125786e-05 Test RE 0.0188138773831662\n",
      "116 Train Loss 0.000562167 Test MSE 6.541765593946251e-05 Test RE 0.01892820161409436\n",
      "117 Train Loss 0.00054182234 Test MSE 6.30708508551727e-05 Test RE 0.018585583864711597\n",
      "118 Train Loss 0.0005282935 Test MSE 6.080013935268497e-05 Test RE 0.018247952902809974\n",
      "119 Train Loss 0.00052249775 Test MSE 5.9011591105360786e-05 Test RE 0.017977550868625774\n",
      "120 Train Loss 0.0005164484 Test MSE 5.6749574067368025e-05 Test RE 0.017629628761897723\n",
      "121 Train Loss 0.00051154394 Test MSE 5.552968221693185e-05 Test RE 0.017439115663123676\n",
      "122 Train Loss 0.00050602603 Test MSE 5.477703039145426e-05 Test RE 0.017320527172332654\n",
      "123 Train Loss 0.00049487804 Test MSE 5.483583933204806e-05 Test RE 0.017329822387851693\n",
      "124 Train Loss 0.0004820541 Test MSE 5.067158974802721e-05 Test RE 0.01665881590893566\n",
      "125 Train Loss 0.00047178072 Test MSE 4.793999812836952e-05 Test RE 0.01620357599860461\n",
      "126 Train Loss 0.00046259235 Test MSE 4.5100411494941134e-05 Test RE 0.015716365355925018\n",
      "127 Train Loss 0.0004549647 Test MSE 4.3281171490812966e-05 Test RE 0.015396122846312473\n",
      "128 Train Loss 0.00045076388 Test MSE 4.346517959427468e-05 Test RE 0.015428816123139665\n",
      "129 Train Loss 0.00044803714 Test MSE 4.313212180157236e-05 Test RE 0.015369589756676046\n",
      "130 Train Loss 0.00044282695 Test MSE 4.296368842761171e-05 Test RE 0.015339550843643546\n",
      "131 Train Loss 0.00043561222 Test MSE 4.373638962923433e-05 Test RE 0.015476876923168664\n",
      "132 Train Loss 0.0004253379 Test MSE 4.466332670639812e-05 Test RE 0.015640023382789185\n",
      "133 Train Loss 0.000417516 Test MSE 4.0342493500448474e-05 Test RE 0.014864257934870945\n",
      "134 Train Loss 0.00041548378 Test MSE 3.9874139229825814e-05 Test RE 0.014777723096329867\n",
      "135 Train Loss 0.00041279403 Test MSE 3.87320592664091e-05 Test RE 0.014564552921029563\n",
      "136 Train Loss 0.00041029582 Test MSE 3.937006086722561e-05 Test RE 0.014684017964544228\n",
      "137 Train Loss 0.00040582495 Test MSE 3.7020116773326585e-05 Test RE 0.014239041513686731\n",
      "138 Train Loss 0.00040260135 Test MSE 3.635260432873435e-05 Test RE 0.01411008496145162\n",
      "139 Train Loss 0.00039777465 Test MSE 3.672815434381419e-05 Test RE 0.014182781638525233\n",
      "140 Train Loss 0.00039336924 Test MSE 3.561697001586394e-05 Test RE 0.013966588877436754\n",
      "141 Train Loss 0.00038661767 Test MSE 3.546852096529698e-05 Test RE 0.013937452601358556\n",
      "142 Train Loss 0.00038077965 Test MSE 3.528197981350075e-05 Test RE 0.013900753355621754\n",
      "143 Train Loss 0.00037543298 Test MSE 3.4618399623035814e-05 Test RE 0.013769410817378301\n",
      "144 Train Loss 0.00036878884 Test MSE 3.397942635784836e-05 Test RE 0.013641743689549544\n",
      "145 Train Loss 0.00036263262 Test MSE 3.3331739179562716e-05 Test RE 0.013511104451979391\n",
      "146 Train Loss 0.00035770645 Test MSE 3.340708333593491e-05 Test RE 0.013526366304053253\n",
      "147 Train Loss 0.00035415744 Test MSE 3.4375764384224816e-05 Test RE 0.01372107208754425\n",
      "148 Train Loss 0.00035204258 Test MSE 3.228808592368032e-05 Test RE 0.013297898513197216\n",
      "149 Train Loss 0.00034873793 Test MSE 3.083654022224549e-05 Test RE 0.012995550665464366\n",
      "150 Train Loss 0.00034678777 Test MSE 3.0290076470140143e-05 Test RE 0.012879886884377615\n",
      "151 Train Loss 0.00034445862 Test MSE 2.965031985698145e-05 Test RE 0.012743142963138178\n",
      "152 Train Loss 0.00034116354 Test MSE 2.953052317341512e-05 Test RE 0.0127173737409427\n",
      "153 Train Loss 0.0003376081 Test MSE 2.8666594939846136e-05 Test RE 0.012529966762774434\n",
      "154 Train Loss 0.00033373653 Test MSE 2.8700653255426816e-05 Test RE 0.012537407878205191\n",
      "155 Train Loss 0.00032716 Test MSE 2.6275916098697594e-05 Test RE 0.01199611988427848\n",
      "156 Train Loss 0.00032318666 Test MSE 2.4902285556022363e-05 Test RE 0.011678349504621576\n",
      "157 Train Loss 0.00031909684 Test MSE 2.5182696905753202e-05 Test RE 0.011743917271513256\n",
      "158 Train Loss 0.00031430187 Test MSE 2.6272717838630102e-05 Test RE 0.011995389788349563\n",
      "159 Train Loss 0.0003107545 Test MSE 2.6753312815802317e-05 Test RE 0.012104605719800333\n",
      "160 Train Loss 0.00030695042 Test MSE 2.6656407220754737e-05 Test RE 0.012082663237998024\n",
      "161 Train Loss 0.00030494563 Test MSE 2.6007697460417562e-05 Test RE 0.01193473598816037\n",
      "162 Train Loss 0.00030155518 Test MSE 2.6560739530737094e-05 Test RE 0.012060961898743833\n",
      "163 Train Loss 0.0002990859 Test MSE 2.6991092085012893e-05 Test RE 0.012158278647768743\n",
      "164 Train Loss 0.00029708372 Test MSE 2.661279511015825e-05 Test RE 0.012072775068311259\n",
      "165 Train Loss 0.00029570458 Test MSE 2.7150730881317215e-05 Test RE 0.01219418070587128\n",
      "166 Train Loss 0.00029448117 Test MSE 2.7764105376911638e-05 Test RE 0.012331153560417082\n",
      "167 Train Loss 0.0002925145 Test MSE 2.867382856277483e-05 Test RE 0.012531547545878033\n",
      "168 Train Loss 0.000290511 Test MSE 2.7852646612121008e-05 Test RE 0.012350800267441592\n",
      "169 Train Loss 0.00028654037 Test MSE 2.8938615108925464e-05 Test RE 0.012589275448563964\n",
      "170 Train Loss 0.00028090496 Test MSE 2.826821871945467e-05 Test RE 0.012442598443897881\n",
      "171 Train Loss 0.00027732272 Test MSE 2.8272148763692713e-05 Test RE 0.012443463342095413\n",
      "172 Train Loss 0.00027562742 Test MSE 3.0094479961974014e-05 Test RE 0.012838233950876835\n",
      "173 Train Loss 0.00027241104 Test MSE 2.910242490173055e-05 Test RE 0.01262485656465932\n",
      "174 Train Loss 0.00027002956 Test MSE 2.9490126251563027e-05 Test RE 0.012708672259989753\n",
      "175 Train Loss 0.00026877114 Test MSE 2.9397493765395853e-05 Test RE 0.012688696729595626\n",
      "176 Train Loss 0.0002662721 Test MSE 3.0649912096314306e-05 Test RE 0.01295616531234768\n",
      "177 Train Loss 0.00026200328 Test MSE 3.2232413372620035e-05 Test RE 0.01328642915360563\n",
      "178 Train Loss 0.00025813354 Test MSE 3.0783276051356524e-05 Test RE 0.012984322161972093\n",
      "179 Train Loss 0.00025409894 Test MSE 3.0546117414612526e-05 Test RE 0.012934208944350763\n",
      "180 Train Loss 0.0002514588 Test MSE 2.9815863948612176e-05 Test RE 0.012778667296561807\n",
      "181 Train Loss 0.0002489129 Test MSE 2.6731219807883895e-05 Test RE 0.012099606668181795\n",
      "182 Train Loss 0.0002468564 Test MSE 2.4997233372818074e-05 Test RE 0.011700592018311778\n",
      "183 Train Loss 0.00024487465 Test MSE 2.579867869559877e-05 Test RE 0.011886680674130677\n",
      "184 Train Loss 0.00024432203 Test MSE 2.5022123946934393e-05 Test RE 0.011706415902631611\n",
      "185 Train Loss 0.0002442716 Test MSE 2.534502143088377e-05 Test RE 0.01178170638675162\n",
      "186 Train Loss 0.0002432758 Test MSE 2.4850893617778944e-05 Test RE 0.011666292719995345\n",
      "187 Train Loss 0.00023980338 Test MSE 2.6458983403540898e-05 Test RE 0.01203783651710032\n",
      "188 Train Loss 0.00023773381 Test MSE 2.6757774757969376e-05 Test RE 0.012105615086365045\n",
      "189 Train Loss 0.00023450056 Test MSE 2.6041075177788836e-05 Test RE 0.01194239192382055\n",
      "190 Train Loss 0.0002298961 Test MSE 2.329161381458862e-05 Test RE 0.011294360726315605\n",
      "191 Train Loss 0.00022354313 Test MSE 1.9284236024230708e-05 Test RE 0.010276922540823977\n",
      "192 Train Loss 0.00021950663 Test MSE 1.7718157207331563e-05 Test RE 0.009850791781869157\n",
      "193 Train Loss 0.00021438974 Test MSE 1.7869553305005282e-05 Test RE 0.009892788224578182\n",
      "194 Train Loss 0.00020887978 Test MSE 1.7034142748607077e-05 Test RE 0.00965877401878349\n",
      "195 Train Loss 0.00020434125 Test MSE 1.570103835140459e-05 Test RE 0.009273123659361646\n",
      "196 Train Loss 0.00019918683 Test MSE 1.4835215828485773e-05 Test RE 0.009013818283205615\n",
      "197 Train Loss 0.00019434055 Test MSE 1.5104668640612075e-05 Test RE 0.009095309147455096\n",
      "198 Train Loss 0.0001917354 Test MSE 1.447280763959859e-05 Test RE 0.00890303865469419\n",
      "199 Train Loss 0.00018969567 Test MSE 1.4108410683097499e-05 Test RE 0.008790243598896045\n",
      "200 Train Loss 0.0001885139 Test MSE 1.3606163900927195e-05 Test RE 0.008632363368512972\n",
      "201 Train Loss 0.0001875131 Test MSE 1.3056481032587052e-05 Test RE 0.008456193946095808\n",
      "202 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "203 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "204 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "205 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "206 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "207 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "208 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "209 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "210 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "211 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "212 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "213 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "214 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "215 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "216 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "217 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "218 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "219 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "220 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "221 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "222 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "223 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "224 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "225 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "226 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "227 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "228 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "229 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "230 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "231 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "232 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "233 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "234 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "235 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "236 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "237 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "238 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "239 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "240 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "241 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "242 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "243 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "244 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "245 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "246 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "247 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "248 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "249 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "250 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "251 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "252 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "253 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "254 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "255 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "256 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "257 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "258 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "259 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "260 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "261 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "262 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "263 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "264 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "265 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "266 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "267 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "268 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "269 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "270 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "271 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "272 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "273 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "274 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "275 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "276 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "277 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "278 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "279 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "280 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "281 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "282 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "283 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "284 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "285 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "286 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "287 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "288 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "289 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "290 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "291 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "292 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "293 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "294 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "295 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "296 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "297 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "298 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "299 Train Loss 0.0001871251 Test MSE 1.2883392927147062e-05 Test RE 0.008399955595236642\n",
      "Training time: 112.13\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f79b03bd4d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.013141175371636064\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
