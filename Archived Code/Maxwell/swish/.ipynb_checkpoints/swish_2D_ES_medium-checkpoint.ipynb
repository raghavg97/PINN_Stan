{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_thresh = 25000\n",
    "level = \"_medium\"\n",
    "label = \"ES_swish\" + level\n",
    "ES_val = 200.0\n",
    "\n",
    "x = np.linspace(0,1,500).reshape(-1,1)\n",
    "y = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xy = np.hstack((X,Y))\n",
    "\n",
    "# bound_pts_1 = (X == 0).reshape(-1,)\n",
    "# bound_pts_2 = np.logical_and(Y == 0,X != 0).reshape(-1,)\n",
    "# bound_pts_3 = np.logical_and(X == 1,Y != 0).reshape(-1,) \n",
    "# bound_pts_4 = np.logical_and(Y == 1,X != 1).reshape(-1,) \n",
    "\n",
    "# xy_bound_1 = xy[bound_pts_1,:]\n",
    "# xy_bound_2 = xy[bound_pts_2,:]\n",
    "# xy_bound_3 = xy[bound_pts_3,:]\n",
    "# xy_bound_4 = xy[bound_pts_4,:]\n",
    "\n",
    "# u_bound_1 = 1000*np.ones((np.shape(xy_bound_1)[0],1))\n",
    "# u_bound_2 = 800*np.ones((np.shape(xy_bound_2)[0],1))\n",
    "# u_bound_3 = 500*np.ones((np.shape(xy_bound_3)[0],1))\n",
    "# u_bound_4 = np.zeros((np.shape(xy_bound_4)[0],1))\n",
    "\n",
    "# xy_bound = np.vstack((xy_bound_1,xy_bound_2,xy_bound_3,xy_bound_4))\n",
    "# u_bound = np.vstack((u_bound_1,u_bound_2,u_bound_3,u_bound_4))\n",
    "\n",
    "# xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "\n",
    "lb_xy = xy[0]\n",
    "ub_xy = xy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_data = scipy.io.loadmat('./../ES_FEA' + level+'.mat')\n",
    "\n",
    "xy = np.array(fea_data['xy'])\n",
    "u_true = np.array(fea_data['u'])\n",
    "\n",
    "xy_test_tensor = torch.from_numpy(xy).float().to(device)\n",
    "u_true_norm = np.linalg.norm(u_true,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_T,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    N_t = int(N_T/4)\n",
    "    \n",
    "    x_BC1 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC1 = np.zeros((N_t,1))\n",
    "    u_BC1 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC2 = np.ones((N_t,1))\n",
    "    y_BC2 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC2 = ES_val*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC3 = np.random.uniform(size = N_t).reshape(-1,1)\n",
    "    y_BC3 = np.ones((N_t,1)) \n",
    "    u_BC3 = 0*np.ones((N_t,1))\n",
    "    \n",
    "    x_BC4 = np.zeros((N_t,1))\n",
    "    y_BC4 = np.random.uniform(size = N_t).reshape(-1,1) \n",
    "    u_BC4 = ES_val*np.ones((N_t,1))\n",
    "    \n",
    "    XY_corners = np.array([[0,0],[1,0],[0,1],[1,1]]).reshape(-1,2)\n",
    "    U_corners = ES_val*np.ones((4,1))\n",
    "    \n",
    "    XY_1 = np.hstack((x_BC1,y_BC1))\n",
    "    XY_2 = np.hstack((x_BC2,y_BC2))\n",
    "    XY_3 = np.hstack((x_BC3,y_BC3))\n",
    "    XY_4 = np.hstack((x_BC4,y_BC4))\n",
    "    \n",
    "    xy_BC = np.vstack((XY_1,XY_2,XY_3,XY_4,XY_corners)) #choose indices from  set 'idx' (x,t)\n",
    "    u_BC = np.vstack((u_BC1,u_BC2,u_BC3,u_BC4,U_corners))\n",
    "    \n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xy_coll = lb_xy + (ub_xy - lb_xy)*samples\n",
    "    \n",
    "    xy_coll = np.vstack((xy_coll, xy_BC)) # append training points to collocation points \n",
    "\n",
    "    return xy_coll, xy_BC, u_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xy):\n",
    "        if torch.is_tensor(xy) != True:         \n",
    "            xy = torch.from_numpy(xy)                \n",
    "        \n",
    "        ubxy = torch.from_numpy(ub_xy).float().to(device)\n",
    "        lbxy = torch.from_numpy(lb_xy).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xy = 2.0*(xy - lbxy)/(ubxy - lbxy) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xy.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xy,u):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xy), u)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xy_coll, f_hat):\n",
    "        \n",
    "        g = xy_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y = autograd.grad(u,g,torch.ones([xy_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy = autograd.grad(u_x_y,g,torch.ones(xy_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2u_dx2 + d2u_dy2\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xy_BC,u_BC,xy_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xy_BC,u_BC)\n",
    "        loss_f = self.loss_PDE(xy_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "       \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        u_pred = self.forward(xy_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "     \n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xy_BC,u_BC,xy_coll,f_hat,seed):\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xy_BC,u_BC,xy_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xy_coll_np_array, xy_BC_np_array, u_BC_np_array = trainingdata(N_T,N_f,rep*22)\n",
    "        \n",
    "    xy_coll = torch.from_numpy(xy_coll_np_array).float().to(device)\n",
    "    xy_BC = torch.from_numpy(xy_BC_np_array).float().to(device)\n",
    "    u_BC = torch.from_numpy(u_BC_np_array).float().to(device)\n",
    "        \n",
    "    f_hat = torch.zeros(xy_coll.shape[0],1).to(device)\n",
    "    \n",
    " \n",
    "    for i in range(max_iter):\n",
    "        train_step(xy_BC,u_BC,xy_coll,f_hat,i)\n",
    "        loss_np = PINN.loss(xy_BC,u_BC,xy_coll,f_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    " \n",
    "            \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES_swish_high\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 250066.88 Test MSE 75171.09694278447 Test RE 0.47969090662379876\n",
      "1 Train Loss 249993.88 Test MSE 75078.51309649259 Test RE 0.47939541198421715\n",
      "2 Train Loss 249993.88 Test MSE 75078.44800645448 Test RE 0.4793952041759434\n",
      "3 Train Loss 249993.77 Test MSE 75078.0076637304 Test RE 0.4793937983230972\n",
      "4 Train Loss 249993.72 Test MSE 75077.81724076005 Test RE 0.4793931903711031\n",
      "5 Train Loss 249993.56 Test MSE 75077.38107217227 Test RE 0.4793917978389131\n",
      "6 Train Loss 249973.2 Test MSE 75149.22974245185 Test RE 0.4796211307356139\n",
      "7 Train Loss 238283.17 Test MSE 68785.8133865955 Test RE 0.45886557830334285\n",
      "8 Train Loss 189570.94 Test MSE 48043.19690603729 Test RE 0.3834881876380458\n",
      "9 Train Loss 105014.77 Test MSE 20693.41548100728 Test RE 0.2516819850493006\n",
      "10 Train Loss 68320.305 Test MSE 11640.634221990185 Test RE 0.1887662565078219\n",
      "11 Train Loss 58267.867 Test MSE 13964.536202153844 Test RE 0.2067518003429984\n",
      "12 Train Loss 53477.29 Test MSE 9852.157166763025 Test RE 0.17366076407334022\n",
      "13 Train Loss 50237.95 Test MSE 8883.451793293758 Test RE 0.16490237736293967\n",
      "14 Train Loss 48947.727 Test MSE 8916.62198591042 Test RE 0.1652099575273644\n",
      "15 Train Loss 47626.066 Test MSE 7783.272856912879 Test RE 0.1543537445389581\n",
      "16 Train Loss 47067.375 Test MSE 7687.647117188227 Test RE 0.15340261459201623\n",
      "17 Train Loss 46657.555 Test MSE 7576.66812422804 Test RE 0.1522913281138013\n",
      "18 Train Loss 46285.062 Test MSE 7458.240989326568 Test RE 0.15109644552940968\n",
      "19 Train Loss 45936.19 Test MSE 7260.915925672939 Test RE 0.14908424348857846\n",
      "20 Train Loss 45709.684 Test MSE 7126.295716233104 Test RE 0.14769573754588242\n",
      "21 Train Loss 45415.39 Test MSE 6733.792159722886 Test RE 0.14357072572344945\n",
      "22 Train Loss 45128.06 Test MSE 6824.06039141278 Test RE 0.14452982360616617\n",
      "23 Train Loss 44759.44 Test MSE 6756.773511302552 Test RE 0.1438155089686886\n",
      "24 Train Loss 44469.97 Test MSE 6426.019595477474 Test RE 0.14025135463028554\n",
      "25 Train Loss 44055.887 Test MSE 6322.99333967092 Test RE 0.13912250986001712\n",
      "26 Train Loss 43810.777 Test MSE 6380.165008056778 Test RE 0.1397500581547175\n",
      "27 Train Loss 43654.87 Test MSE 6268.597160545444 Test RE 0.13852278761680903\n",
      "28 Train Loss 43422.113 Test MSE 6234.324096942493 Test RE 0.13814358735297766\n",
      "29 Train Loss 43214.105 Test MSE 6224.1875561992265 Test RE 0.13803123613913162\n",
      "30 Train Loss 43117.465 Test MSE 6251.405503818123 Test RE 0.1383327075103404\n",
      "31 Train Loss 42986.355 Test MSE 6229.130820181095 Test RE 0.1380860376220243\n",
      "32 Train Loss 42858.285 Test MSE 6175.599708903286 Test RE 0.13749142428380634\n",
      "33 Train Loss 42747.402 Test MSE 6249.188311698504 Test RE 0.13830817403631485\n",
      "34 Train Loss 42618.125 Test MSE 6230.624313304935 Test RE 0.13810259034773273\n",
      "35 Train Loss 42504.305 Test MSE 6179.6906189179745 Test RE 0.1375369560502164\n",
      "36 Train Loss 42438.51 Test MSE 6140.438699494831 Test RE 0.13709945927066886\n",
      "37 Train Loss 42325.51 Test MSE 6162.731657312574 Test RE 0.13734810465272085\n",
      "38 Train Loss 42277.33 Test MSE 6134.39041000176 Test RE 0.1370319216277144\n",
      "39 Train Loss 42242.293 Test MSE 6143.680830862668 Test RE 0.13713564852535795\n",
      "40 Train Loss 42214.61 Test MSE 6132.94029497942 Test RE 0.13701572411014248\n",
      "41 Train Loss 42161.48 Test MSE 6113.126071995076 Test RE 0.13679421074851067\n",
      "42 Train Loss 42115.836 Test MSE 6091.89670358266 Test RE 0.13655647801447407\n",
      "43 Train Loss 42076.164 Test MSE 6079.767933309783 Test RE 0.13642047050773268\n",
      "44 Train Loss 42004.445 Test MSE 6033.279491695317 Test RE 0.13589790574313942\n",
      "45 Train Loss 41900.246 Test MSE 6047.051968349074 Test RE 0.1360529278853943\n",
      "46 Train Loss 41859.74 Test MSE 6016.413867216968 Test RE 0.13570782611261492\n",
      "47 Train Loss 41801.72 Test MSE 5999.3692557057675 Test RE 0.1355154583828021\n",
      "48 Train Loss 41750.637 Test MSE 5975.01746029734 Test RE 0.1352401460825073\n",
      "49 Train Loss 41673.926 Test MSE 5939.665320912346 Test RE 0.13483946763647084\n",
      "50 Train Loss 41640.066 Test MSE 5923.989708127686 Test RE 0.13466141991879885\n",
      "51 Train Loss 41582.3 Test MSE 5925.411960535773 Test RE 0.13467758394373977\n",
      "52 Train Loss 41512.805 Test MSE 5881.047230731475 Test RE 0.13417245783554033\n",
      "53 Train Loss 41448.508 Test MSE 5868.9558866709485 Test RE 0.13403445859706647\n",
      "54 Train Loss 41404.94 Test MSE 5861.691718785516 Test RE 0.1339514838488275\n",
      "55 Train Loss 41364.45 Test MSE 5856.512361072944 Test RE 0.13389229138292955\n",
      "56 Train Loss 41325.76 Test MSE 5850.313893510782 Test RE 0.13382141756875066\n",
      "57 Train Loss 41286.65 Test MSE 5821.523922620744 Test RE 0.13349173728301086\n",
      "58 Train Loss 41256.1 Test MSE 5781.571870607862 Test RE 0.1330328840044097\n",
      "59 Train Loss 41231.86 Test MSE 5775.758689795668 Test RE 0.1329659870846063\n",
      "60 Train Loss 41167.21 Test MSE 5743.610951702826 Test RE 0.1325954279435144\n",
      "61 Train Loss 41128.676 Test MSE 5692.2628085024435 Test RE 0.1320013927083319\n",
      "62 Train Loss 41094.273 Test MSE 5667.678762191871 Test RE 0.13171603696708525\n",
      "63 Train Loss 41067.32 Test MSE 5679.138274069515 Test RE 0.1318491284280598\n",
      "64 Train Loss 40996.152 Test MSE 5666.009110109588 Test RE 0.1316966343012264\n",
      "65 Train Loss 40960.55 Test MSE 5660.357661603387 Test RE 0.13163093881641832\n",
      "66 Train Loss 40907.695 Test MSE 5639.088526464647 Test RE 0.1313834004686221\n",
      "67 Train Loss 40868.965 Test MSE 5644.273997822493 Test RE 0.13144379394431335\n",
      "68 Train Loss 40844.184 Test MSE 5628.482790034859 Test RE 0.13125979241602828\n",
      "69 Train Loss 40798.18 Test MSE 5635.120087203787 Test RE 0.13133716260549758\n",
      "70 Train Loss 40745.277 Test MSE 5624.248688999919 Test RE 0.1312104121652747\n",
      "71 Train Loss 40624.63 Test MSE 5625.227766043582 Test RE 0.13122183231391896\n",
      "72 Train Loss 40524.457 Test MSE 5574.658433497133 Test RE 0.1306306756803438\n",
      "73 Train Loss 40437.92 Test MSE 5579.589405812789 Test RE 0.13068843651681228\n",
      "74 Train Loss 40242.684 Test MSE 5569.838370814527 Test RE 0.13057418933092207\n",
      "75 Train Loss 40003.562 Test MSE 5615.850025235836 Test RE 0.13111240762258466\n",
      "76 Train Loss 39856.234 Test MSE 5610.968409333989 Test RE 0.13105541005663643\n",
      "77 Train Loss 39711.188 Test MSE 5656.285076986084 Test RE 0.13158357656217687\n",
      "78 Train Loss 39601.426 Test MSE 5700.700264541338 Test RE 0.13209918716811422\n",
      "79 Train Loss 39499.805 Test MSE 5734.041043880945 Test RE 0.13248491775747537\n",
      "80 Train Loss 39357.56 Test MSE 5756.549161066585 Test RE 0.132744687911384\n",
      "81 Train Loss 39266.613 Test MSE 5742.840932612545 Test RE 0.1325865394207767\n",
      "82 Train Loss 39150.613 Test MSE 5772.784991728693 Test RE 0.1329317533477972\n",
      "83 Train Loss 39006.004 Test MSE 5847.214563335089 Test RE 0.1337859654792287\n",
      "84 Train Loss 38810.633 Test MSE 5733.112831487926 Test RE 0.13247419415794934\n",
      "85 Train Loss 38669.47 Test MSE 5632.21205860756 Test RE 0.13130326967102024\n",
      "86 Train Loss 38390.426 Test MSE 5541.173355691627 Test RE 0.13023775773356625\n",
      "87 Train Loss 37888.53 Test MSE 5424.974996279355 Test RE 0.12886498047070158\n",
      "88 Train Loss 37154.44 Test MSE 5236.535322621346 Test RE 0.12660709981541732\n",
      "89 Train Loss 36329.973 Test MSE 4949.975117595369 Test RE 0.12309418855065588\n",
      "90 Train Loss 35685.582 Test MSE 4879.444079008756 Test RE 0.12221407199652914\n",
      "91 Train Loss 34726.477 Test MSE 4715.619554290874 Test RE 0.1201449225544817\n",
      "92 Train Loss 34100.58 Test MSE 4752.89951965486 Test RE 0.12061889855998742\n",
      "93 Train Loss 32711.172 Test MSE 4599.047995703951 Test RE 0.11865062023507979\n",
      "94 Train Loss 31794.324 Test MSE 4420.135311316 Test RE 0.11631984747285953\n",
      "95 Train Loss 30938.252 Test MSE 4095.6606417994785 Test RE 0.11196905792318125\n",
      "96 Train Loss 30013.066 Test MSE 4244.573901189076 Test RE 0.11398641413493336\n",
      "97 Train Loss 29084.19 Test MSE 3975.883328084136 Test RE 0.1103196455057032\n",
      "98 Train Loss 28372.883 Test MSE 4053.799748633132 Test RE 0.11139538210962913\n",
      "99 Train Loss 27616.621 Test MSE 3956.3311960251735 Test RE 0.11004805269462624\n",
      "100 Train Loss 27035.299 Test MSE 4151.510359615052 Test RE 0.11272989561087751\n",
      "101 Train Loss 26363.918 Test MSE 4204.34413066478 Test RE 0.1134449505158155\n",
      "102 Train Loss 25880.863 Test MSE 4089.469008370326 Test RE 0.11188439104828761\n",
      "103 Train Loss 25445.188 Test MSE 4291.602802848014 Test RE 0.11461614623194989\n",
      "104 Train Loss 25118.805 Test MSE 4134.914872379102 Test RE 0.11250435348930585\n",
      "105 Train Loss 24900.287 Test MSE 4126.950916950797 Test RE 0.11239595809055632\n",
      "106 Train Loss 24533.857 Test MSE 4291.577418132261 Test RE 0.11461580725572948\n",
      "107 Train Loss 24247.82 Test MSE 4015.7032616958386 Test RE 0.11087071506142551\n",
      "108 Train Loss 23920.447 Test MSE 3956.2564915449684 Test RE 0.11004701371166763\n",
      "109 Train Loss 23575.223 Test MSE 4158.304281114087 Test RE 0.11282209879869189\n",
      "110 Train Loss 23297.826 Test MSE 3906.5098281975165 Test RE 0.10935294975863594\n",
      "111 Train Loss 22987.406 Test MSE 4204.065961910183 Test RE 0.11344119756867269\n",
      "112 Train Loss 22579.195 Test MSE 4116.759854946863 Test RE 0.11225709743930719\n",
      "113 Train Loss 22389.229 Test MSE 4036.3628928968255 Test RE 0.1111555480579556\n",
      "114 Train Loss 22177.668 Test MSE 4116.436131654157 Test RE 0.11225268365845414\n",
      "115 Train Loss 21865.447 Test MSE 3975.7734889154885 Test RE 0.11031812163027241\n",
      "116 Train Loss 21755.705 Test MSE 3974.974072335944 Test RE 0.11030703013206603\n",
      "117 Train Loss 21622.145 Test MSE 4122.15049771585 Test RE 0.11233057026305766\n",
      "118 Train Loss 21527.207 Test MSE 4175.812203853099 Test RE 0.11305935967051914\n",
      "119 Train Loss 21431.477 Test MSE 4094.955764371509 Test RE 0.11195942237661748\n",
      "120 Train Loss 21346.559 Test MSE 4158.238158915023 Test RE 0.11282120178942712\n",
      "121 Train Loss 21276.617 Test MSE 4202.172434895785 Test RE 0.11341564752180558\n",
      "122 Train Loss 21233.033 Test MSE 4195.058387590345 Test RE 0.11331960362197883\n",
      "123 Train Loss 21154.203 Test MSE 4305.104974682237 Test RE 0.11479630637851578\n",
      "124 Train Loss 21104.19 Test MSE 4228.052340320419 Test RE 0.11376435773175844\n",
      "125 Train Loss 21031.264 Test MSE 4198.044523771115 Test RE 0.11335992815867638\n",
      "126 Train Loss 20953.11 Test MSE 4213.496813249634 Test RE 0.11356836585801806\n",
      "127 Train Loss 20909.652 Test MSE 4209.956865821828 Test RE 0.1135206488977433\n",
      "128 Train Loss 20844.607 Test MSE 4245.295582486564 Test RE 0.11399610396114786\n",
      "129 Train Loss 20799.092 Test MSE 4203.106608488186 Test RE 0.11342825338422755\n",
      "130 Train Loss 20720.756 Test MSE 4235.843880447367 Test RE 0.11386913310988356\n",
      "131 Train Loss 20668.354 Test MSE 4311.056537280756 Test RE 0.11487562865326736\n",
      "132 Train Loss 20643.037 Test MSE 4230.043387556591 Test RE 0.11379114116907199\n",
      "133 Train Loss 20621.398 Test MSE 4256.39522255487 Test RE 0.11414503231167064\n",
      "134 Train Loss 20609.477 Test MSE 4265.174064934065 Test RE 0.1142626841082476\n",
      "135 Train Loss 20591.238 Test MSE 4323.114893530748 Test RE 0.11503617444517646\n",
      "136 Train Loss 20548.346 Test MSE 4345.014264092064 Test RE 0.11532717266754298\n",
      "137 Train Loss 20509.59 Test MSE 4398.5371988261495 Test RE 0.11603531256107291\n",
      "138 Train Loss 20482.338 Test MSE 4452.148948309148 Test RE 0.11674032137281835\n",
      "139 Train Loss 20463.037 Test MSE 4419.537096496049 Test RE 0.11631197592524509\n",
      "140 Train Loss 20404.43 Test MSE 4409.966659159656 Test RE 0.11618597180571975\n",
      "141 Train Loss 20338.285 Test MSE 4397.334285786867 Test RE 0.11601944479315235\n",
      "142 Train Loss 20294.156 Test MSE 4376.698265321288 Test RE 0.11574689385982045\n",
      "143 Train Loss 20234.744 Test MSE 4413.683133073141 Test RE 0.11623491902350182\n",
      "144 Train Loss 20210.986 Test MSE 4414.294478681794 Test RE 0.11624296867780406\n",
      "145 Train Loss 20188.648 Test MSE 4448.040449067499 Test RE 0.11668644421932824\n",
      "146 Train Loss 20120.8 Test MSE 4382.567581580023 Test RE 0.11582447831701669\n",
      "147 Train Loss 20028.154 Test MSE 4345.912368710204 Test RE 0.11533909098453846\n",
      "148 Train Loss 19953.135 Test MSE 4393.363757985151 Test RE 0.11596705368130844\n",
      "149 Train Loss 19850.38 Test MSE 4366.880817762534 Test RE 0.11561700404987904\n",
      "150 Train Loss 19725.934 Test MSE 4240.042918383246 Test RE 0.11392555898218926\n",
      "151 Train Loss 19604.002 Test MSE 4340.916222858429 Test RE 0.11527277388186065\n",
      "152 Train Loss 19541.453 Test MSE 4526.063847018883 Test RE 0.11770539792136135\n",
      "153 Train Loss 19510.678 Test MSE 4583.8113310474655 Test RE 0.11845391218331854\n",
      "154 Train Loss 19488.318 Test MSE 4522.002531615669 Test RE 0.11765257652422349\n",
      "155 Train Loss 19456.387 Test MSE 4586.228390761951 Test RE 0.11848513864808173\n",
      "156 Train Loss 19404.285 Test MSE 4483.798829306181 Test RE 0.11715453415382679\n",
      "157 Train Loss 19372.664 Test MSE 4464.186626110041 Test RE 0.11689803552120974\n",
      "158 Train Loss 19319.04 Test MSE 4525.99306912732 Test RE 0.1177044775882925\n",
      "159 Train Loss 19257.416 Test MSE 4579.577668960567 Test RE 0.11839919683284517\n",
      "160 Train Loss 19192.42 Test MSE 4593.952025266923 Test RE 0.11858486666616988\n",
      "161 Train Loss 19158.668 Test MSE 4578.15228781449 Test RE 0.11838076968421338\n",
      "162 Train Loss 19129.34 Test MSE 4601.787645613602 Test RE 0.11868595502241439\n",
      "163 Train Loss 19032.74 Test MSE 4524.720700810627 Test RE 0.11768793160901694\n",
      "164 Train Loss 18955.14 Test MSE 4529.507097091475 Test RE 0.11775016221114638\n",
      "165 Train Loss 18887.383 Test MSE 4518.848340605129 Test RE 0.11761153680437673\n",
      "166 Train Loss 18849.865 Test MSE 4632.341837382509 Test RE 0.11907931888376365\n",
      "167 Train Loss 18798.082 Test MSE 4687.208625395366 Test RE 0.1197824478347371\n",
      "168 Train Loss 18745.812 Test MSE 4652.916416556968 Test RE 0.11934347171987553\n",
      "169 Train Loss 18699.926 Test MSE 4811.521438758789 Test RE 0.12136047132922356\n",
      "170 Train Loss 18650.268 Test MSE 4810.759045254311 Test RE 0.12135085606493842\n",
      "171 Train Loss 18610.38 Test MSE 4769.2421271396315 Test RE 0.12082609163461272\n",
      "172 Train Loss 18551.89 Test MSE 4675.377196132952 Test RE 0.11963117517726934\n",
      "173 Train Loss 18515.875 Test MSE 4713.456128118698 Test RE 0.12011735942245452\n",
      "174 Train Loss 18446.996 Test MSE 4596.819650022884 Test RE 0.11862187226033617\n",
      "175 Train Loss 18426.059 Test MSE 4657.979276884475 Test RE 0.11940838316466887\n",
      "176 Train Loss 18412.77 Test MSE 4619.632403907719 Test RE 0.11891585186915136\n",
      "177 Train Loss 18392.56 Test MSE 4604.7308286685575 Test RE 0.11872390317249538\n",
      "178 Train Loss 18353.938 Test MSE 4600.093717677702 Test RE 0.11866410873407844\n",
      "179 Train Loss 18299.973 Test MSE 4656.7939171658745 Test RE 0.11939318871176648\n",
      "180 Train Loss 18203.412 Test MSE 4625.603912850618 Test RE 0.11899268457804513\n",
      "181 Train Loss 18142.178 Test MSE 4565.05162335202 Test RE 0.11821127141173511\n",
      "182 Train Loss 18119.95 Test MSE 4618.890803799519 Test RE 0.11890630656982434\n",
      "183 Train Loss 18066.428 Test MSE 4589.497197201053 Test RE 0.1185273559084775\n",
      "184 Train Loss 18020.576 Test MSE 4544.5072643493495 Test RE 0.11794497504454236\n",
      "185 Train Loss 17931.994 Test MSE 4633.497848916589 Test RE 0.11909417621552418\n",
      "186 Train Loss 17884.762 Test MSE 4692.112021787879 Test RE 0.11984508503975046\n",
      "187 Train Loss 17867.924 Test MSE 4722.015385916869 Test RE 0.12022637169465278\n",
      "188 Train Loss 17859.406 Test MSE 4754.609378605112 Test RE 0.12064059297587944\n",
      "189 Train Loss 17856.375 Test MSE 4767.494859366984 Test RE 0.12080395657938954\n",
      "190 Train Loss 17845.777 Test MSE 4714.674074886039 Test RE 0.12013287745170712\n",
      "191 Train Loss 17831.832 Test MSE 4683.952564961724 Test RE 0.1197408360058962\n",
      "192 Train Loss 17792.385 Test MSE 4654.409718640887 Test RE 0.11936262116747566\n",
      "193 Train Loss 17761.152 Test MSE 4640.475913857687 Test RE 0.11918382061250941\n",
      "194 Train Loss 17744.791 Test MSE 4569.372914264865 Test RE 0.11826720774116749\n",
      "195 Train Loss 17726.791 Test MSE 4546.074102481886 Test RE 0.1179653056048997\n",
      "196 Train Loss 17711.08 Test MSE 4540.573218298546 Test RE 0.11789391324644534\n",
      "197 Train Loss 17694.096 Test MSE 4556.24518764773 Test RE 0.11809719575722104\n",
      "198 Train Loss 17680.066 Test MSE 4530.9138557434135 Test RE 0.11776844601073641\n",
      "199 Train Loss 17671.107 Test MSE 4536.541986494012 Test RE 0.11784156707747227\n",
      "Training time: 186.47\n",
      "Training time: 186.47\n",
      "ES_swish_high\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 249995.22 Test MSE 75078.70990986303 Test RE 0.47939604033553285\n",
      "1 Train Loss 249995.22 Test MSE 75078.78336754638 Test RE 0.4793962748581689\n",
      "2 Train Loss 248549.64 Test MSE 73918.88376562452 Test RE 0.47567874043210406\n",
      "3 Train Loss 197658.11 Test MSE 53899.985144171136 Test RE 0.4061910636958792\n",
      "4 Train Loss 135573.56 Test MSE 30395.573624160646 Test RE 0.305029058141165\n",
      "5 Train Loss 87425.04 Test MSE 19360.396272041864 Test RE 0.2434406858983768\n",
      "6 Train Loss 72116.28 Test MSE 15687.712219202498 Test RE 0.21913706910399036\n",
      "7 Train Loss 63021.367 Test MSE 12796.760290913448 Test RE 0.19791834889027404\n",
      "8 Train Loss 59217.582 Test MSE 11614.364693061316 Test RE 0.18855314091009204\n",
      "9 Train Loss 56505.91 Test MSE 11078.963458136042 Test RE 0.1841558870413686\n",
      "10 Train Loss 53865.4 Test MSE 10267.996602545543 Test RE 0.1772878200816615\n",
      "11 Train Loss 52863.54 Test MSE 9500.5600843801 Test RE 0.1705338694082765\n",
      "12 Train Loss 51460.6 Test MSE 9168.230551231676 Test RE 0.1675246829849912\n",
      "13 Train Loss 50750.867 Test MSE 8917.210802516478 Test RE 0.16521541232631856\n",
      "14 Train Loss 49744.098 Test MSE 8936.141843832575 Test RE 0.1653906936792219\n",
      "15 Train Loss 49145.004 Test MSE 8884.36505778388 Test RE 0.16491085355095111\n",
      "16 Train Loss 48584.637 Test MSE 8795.717343486822 Test RE 0.1640860551532616\n",
      "17 Train Loss 47984.918 Test MSE 8630.099405246898 Test RE 0.16253389421275136\n",
      "18 Train Loss 47351.86 Test MSE 8418.256770258458 Test RE 0.16052664386728022\n",
      "19 Train Loss 46595.055 Test MSE 8369.235849892431 Test RE 0.1600585746825107\n",
      "20 Train Loss 46338.38 Test MSE 8366.819608603344 Test RE 0.16003546814917527\n",
      "21 Train Loss 46127.996 Test MSE 8305.435290714739 Test RE 0.15944732635317346\n",
      "22 Train Loss 45865.434 Test MSE 8317.218772827962 Test RE 0.15956039560924992\n",
      "23 Train Loss 45741.457 Test MSE 8317.528329200364 Test RE 0.1595633648997673\n",
      "24 Train Loss 45339.516 Test MSE 8129.931523214676 Test RE 0.15775367513957977\n",
      "25 Train Loss 45164.676 Test MSE 8025.83783022627 Test RE 0.1567405014764486\n",
      "26 Train Loss 44882.13 Test MSE 7833.25932791678 Test RE 0.15484860388512378\n",
      "27 Train Loss 44672.277 Test MSE 7798.462488076616 Test RE 0.15450428748552703\n",
      "28 Train Loss 44329.88 Test MSE 7625.664999867483 Test RE 0.15278295414793358\n",
      "29 Train Loss 44156.9 Test MSE 7483.27672337425 Test RE 0.15134983243558475\n",
      "30 Train Loss 43773.723 Test MSE 7341.495286246285 Test RE 0.1499092060252787\n",
      "31 Train Loss 43592.746 Test MSE 7252.316419132529 Test RE 0.14899593295268393\n",
      "32 Train Loss 43498.83 Test MSE 7221.347040772019 Test RE 0.1486774658730358\n",
      "33 Train Loss 43331.344 Test MSE 7257.089494515562 Test RE 0.14904495534801968\n",
      "34 Train Loss 43211.44 Test MSE 7188.265779436712 Test RE 0.14833652644012854\n",
      "35 Train Loss 43157.45 Test MSE 7146.982897297689 Test RE 0.14790995783545874\n",
      "36 Train Loss 43130.492 Test MSE 7141.633489829486 Test RE 0.14785459330220865\n",
      "37 Train Loss 43078.51 Test MSE 7051.2167331888 Test RE 0.14691565433830195\n",
      "38 Train Loss 43002.445 Test MSE 6927.170982427626 Test RE 0.14561764245030623\n",
      "39 Train Loss 42891.242 Test MSE 6897.271464618265 Test RE 0.1453030403120704\n",
      "40 Train Loss 42789.24 Test MSE 6868.287789252395 Test RE 0.14499742309884428\n",
      "41 Train Loss 42718.48 Test MSE 6804.841989330466 Test RE 0.14432616255223726\n",
      "42 Train Loss 42588.168 Test MSE 6738.559222810632 Test RE 0.14362153584683462\n",
      "43 Train Loss 42537.54 Test MSE 6690.899440714822 Test RE 0.14311273886463427\n",
      "44 Train Loss 42492.242 Test MSE 6686.341022909073 Test RE 0.14306398018779298\n",
      "45 Train Loss 42447.223 Test MSE 6657.925662718604 Test RE 0.14275966256742498\n",
      "46 Train Loss 42329.69 Test MSE 6593.749872965361 Test RE 0.142069965876675\n",
      "47 Train Loss 42233.773 Test MSE 6594.645634500896 Test RE 0.14207961565801597\n",
      "48 Train Loss 42169.9 Test MSE 6581.761112406373 Test RE 0.141940751260539\n",
      "49 Train Loss 42103.97 Test MSE 6579.2594069098695 Test RE 0.14191377309311068\n",
      "50 Train Loss 41972.277 Test MSE 6553.669851387988 Test RE 0.14163752251843836\n",
      "51 Train Loss 41885.848 Test MSE 6528.180417322555 Test RE 0.14136181611296308\n",
      "52 Train Loss 41765.246 Test MSE 6516.067143263578 Test RE 0.14123060424516953\n",
      "53 Train Loss 41657.484 Test MSE 6522.149372173601 Test RE 0.14129650262278542\n",
      "54 Train Loss 41574.754 Test MSE 6499.448060926624 Test RE 0.14105038652553561\n",
      "55 Train Loss 41451.6 Test MSE 6494.6264760396725 Test RE 0.14099805803686058\n",
      "56 Train Loss 41351.586 Test MSE 6505.493795113466 Test RE 0.14111597324321118\n",
      "57 Train Loss 41265.16 Test MSE 6502.266876436752 Test RE 0.14108097003920883\n",
      "58 Train Loss 41178.164 Test MSE 6510.075494208783 Test RE 0.14116565718334725\n",
      "59 Train Loss 41069.383 Test MSE 6524.169874642504 Test RE 0.14131838711277378\n",
      "60 Train Loss 41003.816 Test MSE 6538.28995904128 Test RE 0.14147123024038577\n",
      "61 Train Loss 40934.266 Test MSE 6488.109943819332 Test RE 0.14092730346870624\n",
      "62 Train Loss 40871.305 Test MSE 6429.020730948031 Test RE 0.14028410151004103\n",
      "63 Train Loss 40788.266 Test MSE 6418.464396150688 Test RE 0.14016888222542503\n",
      "64 Train Loss 40663.258 Test MSE 6288.191570113087 Test RE 0.13873911627878782\n",
      "65 Train Loss 40496.18 Test MSE 6212.434799646276 Test RE 0.13790085654965153\n",
      "66 Train Loss 40297.516 Test MSE 6060.636224097469 Test RE 0.13620565858730177\n",
      "67 Train Loss 40060.703 Test MSE 6030.541049139534 Test RE 0.13586706092258874\n",
      "68 Train Loss 39885.83 Test MSE 5947.7601556108275 Test RE 0.13493131890321422\n",
      "69 Train Loss 39677.094 Test MSE 5856.338781169609 Test RE 0.13389030716589273\n",
      "70 Train Loss 39575.023 Test MSE 5776.676843980626 Test RE 0.1329765552569142\n",
      "71 Train Loss 39469.957 Test MSE 5832.395195809223 Test RE 0.13361632220966943\n",
      "72 Train Loss 39378.35 Test MSE 5922.622960991129 Test RE 0.13464588488784934\n",
      "73 Train Loss 39263.457 Test MSE 6133.08249399091 Test RE 0.1370173125315729\n",
      "74 Train Loss 39145.504 Test MSE 6311.884675194161 Test RE 0.1390002461953502\n",
      "75 Train Loss 38978.312 Test MSE 6510.5251987956335 Test RE 0.1411705328370409\n",
      "76 Train Loss 38770.742 Test MSE 6772.155786070262 Test RE 0.1439791190141596\n",
      "77 Train Loss 38604.746 Test MSE 6444.196462577728 Test RE 0.14044957453606127\n",
      "78 Train Loss 38545.453 Test MSE 6316.367663555648 Test RE 0.13904959959075314\n",
      "79 Train Loss 38474.027 Test MSE 6261.75579525272 Test RE 0.13844717710321616\n",
      "80 Train Loss 38394.285 Test MSE 6515.131410744416 Test RE 0.1412204632497663\n",
      "81 Train Loss 38265.63 Test MSE 6450.70666591224 Test RE 0.14052050071593006\n",
      "82 Train Loss 38184.695 Test MSE 6642.748083924942 Test RE 0.1425968504252497\n",
      "83 Train Loss 38136.004 Test MSE 6597.821309760109 Test RE 0.1421138210148518\n",
      "84 Train Loss 38067.195 Test MSE 6452.329889926574 Test RE 0.14053817954676456\n",
      "85 Train Loss 37892.27 Test MSE 6604.911766398271 Test RE 0.14219016298148499\n",
      "86 Train Loss 37570.95 Test MSE 6615.610911560059 Test RE 0.14230528167356557\n",
      "87 Train Loss 37377.47 Test MSE 6464.500152502347 Test RE 0.14067065733472742\n",
      "88 Train Loss 37094.86 Test MSE 6481.851916874602 Test RE 0.14085932222027234\n",
      "89 Train Loss 36796.383 Test MSE 6536.793102938373 Test RE 0.14145503531807996\n",
      "90 Train Loss 36543.27 Test MSE 6978.954668110827 Test RE 0.14616090739244586\n",
      "91 Train Loss 36211.285 Test MSE 6849.990802781278 Test RE 0.14480415912800643\n",
      "92 Train Loss 35496.652 Test MSE 7278.899885999494 Test RE 0.14926875650569135\n",
      "93 Train Loss 35142.523 Test MSE 7064.0230282795455 Test RE 0.1470490066239465\n",
      "94 Train Loss 34675.87 Test MSE 6909.122759227098 Test RE 0.14542782081833336\n",
      "95 Train Loss 33785.47 Test MSE 6345.635767136303 Test RE 0.13937138378192884\n",
      "96 Train Loss 33043.316 Test MSE 6165.840611310961 Test RE 0.13738274473786868\n",
      "97 Train Loss 31726.184 Test MSE 5224.2705222469585 Test RE 0.126458745893555\n",
      "98 Train Loss 30795.502 Test MSE 5057.594407040813 Test RE 0.12442511217671794\n",
      "99 Train Loss 29788.908 Test MSE 5634.283501452425 Test RE 0.13132741313472804\n",
      "100 Train Loss 29385.354 Test MSE 5803.293000314472 Test RE 0.1332825492882882\n",
      "101 Train Loss 28666.254 Test MSE 5952.324973387841 Test RE 0.13498308786596788\n",
      "102 Train Loss 28098.705 Test MSE 6808.960710178553 Test RE 0.14436983360695999\n",
      "103 Train Loss 27531.836 Test MSE 7185.3882209499825 Test RE 0.14830683292500693\n",
      "104 Train Loss 26628.658 Test MSE 6568.090826165721 Test RE 0.1417932695114578\n",
      "105 Train Loss 26028.156 Test MSE 6964.11766867116 Test RE 0.14600545838781478\n",
      "106 Train Loss 25355.059 Test MSE 6867.559840224422 Test RE 0.14498973897629872\n",
      "107 Train Loss 24560.834 Test MSE 6622.879096953785 Test RE 0.1423834314663741\n",
      "108 Train Loss 24001.16 Test MSE 6713.4416841386255 Test RE 0.1433536160107005\n",
      "109 Train Loss 23495.498 Test MSE 6394.104104168647 Test RE 0.1399026346696371\n",
      "110 Train Loss 22721.26 Test MSE 7649.0440861364295 Test RE 0.153016979135517\n",
      "111 Train Loss 22081.207 Test MSE 8306.404004155045 Test RE 0.15945662473784858\n",
      "112 Train Loss 20983.188 Test MSE 8458.23971834584 Test RE 0.16090740710852516\n",
      "113 Train Loss 19858.8 Test MSE 8904.415361603527 Test RE 0.16509683472442874\n",
      "114 Train Loss 19166.344 Test MSE 9310.976046674554 Test RE 0.16882379032102546\n",
      "115 Train Loss 18293.795 Test MSE 9002.900407222158 Test RE 0.16600733007105747\n",
      "116 Train Loss 17227.932 Test MSE 7234.0455677344235 Test RE 0.14880813093704076\n",
      "117 Train Loss 16762.055 Test MSE 6884.060407754857 Test RE 0.1451638166477192\n",
      "118 Train Loss 16350.649 Test MSE 7041.185820049402 Test RE 0.14681111758177973\n",
      "119 Train Loss 15741.316 Test MSE 7157.568799701801 Test RE 0.14801945725920732\n",
      "120 Train Loss 15253.42 Test MSE 6974.415427086467 Test RE 0.14611336678391346\n",
      "121 Train Loss 14945.257 Test MSE 6682.56771822549 Test RE 0.14302360682320558\n",
      "122 Train Loss 14391.356 Test MSE 6812.7052037807325 Test RE 0.14440952524559372\n",
      "123 Train Loss 14013.132 Test MSE 7248.090275291992 Test RE 0.1489525144110906\n",
      "124 Train Loss 13819.523 Test MSE 7485.3680292672925 Test RE 0.15137097936742866\n",
      "125 Train Loss 13703.421 Test MSE 7420.649929111324 Test RE 0.15071518601947537\n",
      "126 Train Loss 13535.113 Test MSE 7808.560779623187 Test RE 0.15460428954240668\n",
      "127 Train Loss 13418.989 Test MSE 8067.364942972823 Test RE 0.1571454799142608\n",
      "128 Train Loss 13243.59 Test MSE 8164.139686487707 Test RE 0.15808521536978576\n",
      "129 Train Loss 13071.125 Test MSE 8111.009395875142 Test RE 0.15756998515179718\n",
      "130 Train Loss 12948.036 Test MSE 8339.277095018173 Test RE 0.1597718427390512\n",
      "131 Train Loss 12867.11 Test MSE 8274.159315269091 Test RE 0.15914682588907447\n",
      "132 Train Loss 12814.627 Test MSE 8342.879359288469 Test RE 0.15980634682461123\n",
      "133 Train Loss 12714.429 Test MSE 8585.043746609084 Test RE 0.1621090639565784\n",
      "134 Train Loss 12641.832 Test MSE 8644.58381174124 Test RE 0.16267023215680246\n",
      "135 Train Loss 12559.879 Test MSE 8611.052968729946 Test RE 0.1623544408095856\n",
      "136 Train Loss 12463.1875 Test MSE 8562.349934709828 Test RE 0.16189466161185276\n",
      "137 Train Loss 12281.767 Test MSE 8370.329316702653 Test RE 0.16006903041741485\n",
      "138 Train Loss 12080.811 Test MSE 8440.44346838708 Test RE 0.16073804230241462\n",
      "139 Train Loss 11945.733 Test MSE 8224.501126134212 Test RE 0.15866853944512704\n",
      "140 Train Loss 11856.021 Test MSE 8044.787995181793 Test RE 0.15692543588363103\n",
      "141 Train Loss 11784.476 Test MSE 7841.29947279166 Test RE 0.15492805267194676\n",
      "142 Train Loss 11627.826 Test MSE 7886.1563523224595 Test RE 0.15537056085595444\n",
      "143 Train Loss 11537.1045 Test MSE 7899.086747459603 Test RE 0.15549788396640982\n",
      "144 Train Loss 11426.338 Test MSE 8296.234204135977 Test RE 0.15935898088102424\n",
      "145 Train Loss 11282.535 Test MSE 8197.309855733873 Test RE 0.15840603288138114\n",
      "146 Train Loss 11173.811 Test MSE 8368.579374299874 Test RE 0.16005229713160202\n",
      "147 Train Loss 11102.923 Test MSE 8266.973912017065 Test RE 0.15907770814248015\n",
      "148 Train Loss 11000.455 Test MSE 8108.604351547578 Test RE 0.15754662240637374\n",
      "149 Train Loss 10833.973 Test MSE 8177.672081411572 Test RE 0.15821617747354438\n",
      "150 Train Loss 10712.949 Test MSE 8394.091449760568 Test RE 0.16029607560454023\n",
      "151 Train Loss 10561.035 Test MSE 8556.931341735582 Test RE 0.161843426838991\n",
      "152 Train Loss 10464.138 Test MSE 8191.024294545798 Test RE 0.15834528967605288\n",
      "153 Train Loss 10349.708 Test MSE 8280.840302027014 Test RE 0.15921106463829413\n",
      "154 Train Loss 10227.745 Test MSE 8351.086194754462 Test RE 0.15988492772979537\n",
      "155 Train Loss 10146.877 Test MSE 8148.6589584775065 Test RE 0.15793526476025235\n",
      "156 Train Loss 10051.231 Test MSE 8210.602475532398 Test RE 0.15853441513624933\n",
      "157 Train Loss 9929.474 Test MSE 8244.83265240318 Test RE 0.15886453810099063\n",
      "158 Train Loss 9816.322 Test MSE 8124.552671490921 Test RE 0.15770148072556398\n",
      "159 Train Loss 9703.941 Test MSE 7999.510704599236 Test RE 0.15648321266872656\n",
      "160 Train Loss 9582.912 Test MSE 7850.795294348525 Test RE 0.15502183330231836\n",
      "161 Train Loss 9425.234 Test MSE 8291.179190277402 Test RE 0.15931042363297057\n",
      "162 Train Loss 9195.601 Test MSE 8271.789097413754 Test RE 0.1591240296355853\n",
      "163 Train Loss 9005.767 Test MSE 7915.577595419916 Test RE 0.15566011506209487\n",
      "164 Train Loss 8929.112 Test MSE 7972.444038814309 Test RE 0.15621825473711232\n",
      "165 Train Loss 8831.531 Test MSE 8107.712020838854 Test RE 0.15753795337092305\n",
      "166 Train Loss 8736.321 Test MSE 7917.042194013277 Test RE 0.15567451508775143\n",
      "167 Train Loss 8663.975 Test MSE 8253.04813668625 Test RE 0.15894366791520126\n",
      "168 Train Loss 8549.418 Test MSE 8020.52946973369 Test RE 0.1566886581220478\n",
      "169 Train Loss 8449.258 Test MSE 7965.893475715824 Test RE 0.15615406314049748\n",
      "170 Train Loss 8378.0 Test MSE 8148.205334789372 Test RE 0.1579308686887793\n",
      "171 Train Loss 8316.609 Test MSE 8583.24855498523 Test RE 0.16209211401098977\n",
      "172 Train Loss 8290.378 Test MSE 8580.835269519719 Test RE 0.16206932531740514\n",
      "173 Train Loss 8264.529 Test MSE 8482.919241969616 Test RE 0.16114198461903143\n",
      "174 Train Loss 8185.763 Test MSE 8360.394539130622 Test RE 0.15997400892530772\n",
      "175 Train Loss 8126.2295 Test MSE 8425.828106188137 Test RE 0.16059881605334073\n",
      "176 Train Loss 8079.6353 Test MSE 8546.624165949084 Test RE 0.1617459239360888\n",
      "177 Train Loss 7952.9624 Test MSE 8281.64808307326 Test RE 0.15921882982512714\n",
      "178 Train Loss 7907.9473 Test MSE 8121.087046800753 Test RE 0.15766784241571014\n",
      "179 Train Loss 7869.9395 Test MSE 7962.321561044585 Test RE 0.15611904939528032\n",
      "180 Train Loss 7760.613 Test MSE 7784.665997559587 Test RE 0.1543675579345483\n",
      "181 Train Loss 7669.8794 Test MSE 7846.379461171918 Test RE 0.15497822964079652\n",
      "182 Train Loss 7548.838 Test MSE 7894.1131632447505 Test RE 0.15544892238247485\n",
      "183 Train Loss 7448.444 Test MSE 7752.547627642436 Test RE 0.15404878003611064\n",
      "184 Train Loss 7375.5703 Test MSE 7505.745004681893 Test RE 0.15157687347905296\n",
      "185 Train Loss 7308.344 Test MSE 7821.309644933021 Test RE 0.15473044757980733\n",
      "186 Train Loss 7254.69 Test MSE 7714.261531132003 Test RE 0.15366792289509532\n",
      "187 Train Loss 7166.2153 Test MSE 7795.149713831713 Test RE 0.1544714674140315\n",
      "188 Train Loss 7102.1416 Test MSE 7704.614015483243 Test RE 0.15357180368227658\n",
      "189 Train Loss 7022.2437 Test MSE 7900.483099002108 Test RE 0.1555116273346125\n",
      "190 Train Loss 6915.462 Test MSE 7902.4727421434345 Test RE 0.15553120798308806\n",
      "191 Train Loss 6811.561 Test MSE 7888.268889326797 Test RE 0.1553913697307879\n",
      "192 Train Loss 6752.371 Test MSE 7970.195681169772 Test RE 0.15619622515167503\n",
      "193 Train Loss 6677.0884 Test MSE 8001.711654658063 Test RE 0.15650473823835973\n",
      "194 Train Loss 6631.4707 Test MSE 8346.915497777378 Test RE 0.15984499790227263\n",
      "195 Train Loss 6572.6084 Test MSE 8642.506481452574 Test RE 0.16265068580783903\n",
      "196 Train Loss 6480.9736 Test MSE 8748.00496639213 Test RE 0.1636404074963022\n",
      "197 Train Loss 6390.188 Test MSE 8881.406183304382 Test RE 0.16488339007175662\n",
      "198 Train Loss 6309.1787 Test MSE 9001.930528311068 Test RE 0.1659983878781097\n",
      "199 Train Loss 6252.2373 Test MSE 8996.335643623737 Test RE 0.16594679415671668\n",
      "Training time: 204.36\n",
      "Training time: 204.36\n",
      "ES_swish_high\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 250000.78 Test MSE 75088.5214014193 Test RE 0.4794273637063529\n",
      "1 Train Loss 249996.38 Test MSE 75079.5287553598 Test RE 0.47939865459341596\n",
      "2 Train Loss 249996.33 Test MSE 75079.35451479809 Test RE 0.4793980983116924\n",
      "3 Train Loss 249996.33 Test MSE 75079.30023449752 Test RE 0.4793979250158659\n",
      "4 Train Loss 249996.33 Test MSE 75079.24601235603 Test RE 0.4793977519056563\n",
      "5 Train Loss 249996.3 Test MSE 75079.1294250257 Test RE 0.479397379687442\n",
      "6 Train Loss 249996.28 Test MSE 75078.98788864948 Test RE 0.4793969278161938\n",
      "7 Train Loss 249996.17 Test MSE 75078.51858746681 Test RE 0.4793954295148507\n",
      "8 Train Loss 248490.0 Test MSE 74271.462108962 Test RE 0.47681183727187093\n",
      "9 Train Loss 238180.9 Test MSE 70166.4888362798 Test RE 0.4634478953373711\n",
      "10 Train Loss 154408.95 Test MSE 35381.8506418361 Test RE 0.32909881178978884\n",
      "11 Train Loss 95157.82 Test MSE 19667.21016904687 Test RE 0.24536206679156025\n",
      "12 Train Loss 71030.97 Test MSE 17127.501136830164 Test RE 0.22897235153882245\n",
      "13 Train Loss 56368.598 Test MSE 11082.276492762163 Test RE 0.18418341981677522\n",
      "14 Train Loss 51325.695 Test MSE 9177.587693329782 Test RE 0.16761014944964434\n",
      "15 Train Loss 49287.387 Test MSE 8847.860524269172 Test RE 0.16457170774296817\n",
      "16 Train Loss 47384.895 Test MSE 8177.438261637994 Test RE 0.15821391556239983\n",
      "17 Train Loss 46516.793 Test MSE 8149.961052922351 Test RE 0.15794788269023308\n",
      "18 Train Loss 46031.734 Test MSE 7841.530647111916 Test RE 0.15493033642117857\n",
      "19 Train Loss 45578.996 Test MSE 7578.1635516571505 Test RE 0.1523063564474439\n",
      "20 Train Loss 45099.81 Test MSE 7603.793081796668 Test RE 0.15256369092096805\n",
      "21 Train Loss 44592.86 Test MSE 7506.697674960953 Test RE 0.15158649265745958\n",
      "22 Train Loss 44248.8 Test MSE 7257.391827882022 Test RE 0.14904805995309792\n",
      "23 Train Loss 44025.438 Test MSE 7090.482681810481 Test RE 0.14732414934810625\n",
      "24 Train Loss 43641.29 Test MSE 6883.035979201106 Test RE 0.14515301521057364\n",
      "25 Train Loss 43381.355 Test MSE 6673.956182113952 Test RE 0.14293142294589514\n",
      "26 Train Loss 43094.074 Test MSE 6641.479202382064 Test RE 0.14258323052346172\n",
      "27 Train Loss 42894.133 Test MSE 6638.146030102781 Test RE 0.14254744676948308\n",
      "28 Train Loss 42711.492 Test MSE 6552.853178539836 Test RE 0.14162869730101718\n",
      "29 Train Loss 42376.67 Test MSE 6249.742539379174 Test RE 0.1383143070343291\n",
      "30 Train Loss 42060.785 Test MSE 6253.498953108023 Test RE 0.1383558677634828\n",
      "31 Train Loss 41679.297 Test MSE 6269.295283897619 Test RE 0.1385305009295343\n",
      "32 Train Loss 41549.316 Test MSE 6184.873610195488 Test RE 0.1375946210273389\n",
      "33 Train Loss 41435.945 Test MSE 6146.224341242724 Test RE 0.137164032963025\n",
      "34 Train Loss 41351.418 Test MSE 6161.866491461308 Test RE 0.13733846338750905\n",
      "35 Train Loss 41283.855 Test MSE 6173.092944135766 Test RE 0.13746351657791095\n",
      "36 Train Loss 41200.938 Test MSE 6155.287388747598 Test RE 0.1372651247997691\n",
      "37 Train Loss 41137.27 Test MSE 6142.178960944187 Test RE 0.13711888557008728\n",
      "38 Train Loss 41073.746 Test MSE 6166.259383502536 Test RE 0.1373874100462906\n",
      "39 Train Loss 41033.797 Test MSE 6155.906375360577 Test RE 0.1372720264384219\n",
      "40 Train Loss 40999.23 Test MSE 6169.599691613477 Test RE 0.1374246168939779\n",
      "41 Train Loss 40962.773 Test MSE 6178.449549971007 Test RE 0.13752314456460377\n",
      "42 Train Loss 40923.72 Test MSE 6164.7196054858305 Test RE 0.13737025545478224\n",
      "43 Train Loss 40898.0 Test MSE 6180.854808599651 Test RE 0.13754991070882894\n",
      "44 Train Loss 40869.54 Test MSE 6154.1968922166025 Test RE 0.137252965028555\n",
      "45 Train Loss 40822.08 Test MSE 6145.8798195940935 Test RE 0.13716018859952733\n",
      "46 Train Loss 40792.72 Test MSE 6128.792110174762 Test RE 0.13696937907354023\n",
      "47 Train Loss 40759.652 Test MSE 6092.435769256819 Test RE 0.13656251975197004\n",
      "48 Train Loss 40690.676 Test MSE 6074.527141159972 Test RE 0.1363616602473614\n",
      "49 Train Loss 40657.87 Test MSE 6070.6939023372515 Test RE 0.1363186289722156\n",
      "50 Train Loss 40633.555 Test MSE 6062.340040270522 Test RE 0.1362248028724359\n",
      "51 Train Loss 40611.31 Test MSE 6041.177936677566 Test RE 0.13598683176251417\n",
      "52 Train Loss 40593.797 Test MSE 6046.491166576718 Test RE 0.1360466189854085\n",
      "53 Train Loss 40567.266 Test MSE 6028.277796802452 Test RE 0.13584156318554708\n",
      "54 Train Loss 40534.89 Test MSE 5998.856258895483 Test RE 0.13550966440004233\n",
      "55 Train Loss 40500.32 Test MSE 5982.866493711856 Test RE 0.13532894549206922\n",
      "56 Train Loss 40474.223 Test MSE 5977.110028052725 Test RE 0.13526382587902555\n",
      "57 Train Loss 40452.42 Test MSE 5973.271630850332 Test RE 0.13522038685331678\n",
      "58 Train Loss 40422.24 Test MSE 5940.221627553819 Test RE 0.1348457819935102\n",
      "59 Train Loss 40373.61 Test MSE 5905.8664770431715 Test RE 0.13445527764267998\n",
      "60 Train Loss 40345.49 Test MSE 5901.84975753478 Test RE 0.1344095467581008\n",
      "61 Train Loss 40318.29 Test MSE 5901.779216446982 Test RE 0.13440874349943108\n",
      "62 Train Loss 40299.617 Test MSE 5888.242711944791 Test RE 0.13425451297291457\n",
      "63 Train Loss 40262.97 Test MSE 5845.169897072911 Test RE 0.1337625721553763\n",
      "64 Train Loss 40244.188 Test MSE 5837.063365145529 Test RE 0.13366978385263004\n",
      "65 Train Loss 40209.832 Test MSE 5831.486389296186 Test RE 0.13360591172559405\n",
      "66 Train Loss 40185.105 Test MSE 5823.184758490775 Test RE 0.13351077800653513\n",
      "67 Train Loss 40154.746 Test MSE 5779.629855987815 Test RE 0.13301053943185814\n",
      "68 Train Loss 40118.98 Test MSE 5788.243920818595 Test RE 0.13310962318292416\n",
      "69 Train Loss 40108.156 Test MSE 5782.610476097602 Test RE 0.13304483252655155\n",
      "70 Train Loss 40087.848 Test MSE 5776.01706852209 Test RE 0.13296896116991952\n",
      "71 Train Loss 40075.816 Test MSE 5764.316594749887 Test RE 0.13283421533044942\n",
      "72 Train Loss 40064.42 Test MSE 5769.019276660565 Test RE 0.1328883891163802\n",
      "73 Train Loss 40043.895 Test MSE 5738.404477913697 Test RE 0.1325353167046765\n",
      "74 Train Loss 40011.035 Test MSE 5734.9390789888785 Test RE 0.1324952918940154\n",
      "75 Train Loss 39993.457 Test MSE 5721.55722689097 Test RE 0.13234061998921853\n",
      "76 Train Loss 39962.98 Test MSE 5713.067007164891 Test RE 0.1322423934020081\n",
      "77 Train Loss 39926.1 Test MSE 5705.536927080227 Test RE 0.13215521394533195\n",
      "78 Train Loss 39900.695 Test MSE 5697.341048433591 Test RE 0.13206026080052471\n",
      "79 Train Loss 39872.258 Test MSE 5698.0584051039505 Test RE 0.13206857444423495\n",
      "80 Train Loss 39832.215 Test MSE 5673.013454037471 Test RE 0.13177801112177806\n",
      "81 Train Loss 39778.445 Test MSE 5671.420072234756 Test RE 0.13175950354793992\n",
      "82 Train Loss 39743.266 Test MSE 5647.433206578442 Test RE 0.13148057460858775\n",
      "83 Train Loss 39710.965 Test MSE 5616.3720450905275 Test RE 0.1311185012405775\n",
      "84 Train Loss 39652.21 Test MSE 5628.1833839193305 Test RE 0.13125630119923942\n",
      "85 Train Loss 39608.984 Test MSE 5621.840820609074 Test RE 0.13118232208216257\n",
      "86 Train Loss 39577.574 Test MSE 5592.106242337111 Test RE 0.1308349427642139\n",
      "87 Train Loss 39530.09 Test MSE 5570.192180569429 Test RE 0.13057833646098332\n",
      "88 Train Loss 39485.535 Test MSE 5546.414395348658 Test RE 0.1302993349378128\n",
      "89 Train Loss 39399.523 Test MSE 5597.256270503045 Test RE 0.13089517486177468\n",
      "90 Train Loss 39242.176 Test MSE 5543.997087192561 Test RE 0.13027093749497395\n",
      "91 Train Loss 39128.203 Test MSE 5494.365053574836 Test RE 0.12968650831352393\n",
      "92 Train Loss 39079.12 Test MSE 5485.587864478312 Test RE 0.1295828805095994\n",
      "93 Train Loss 38971.645 Test MSE 5485.270162548737 Test RE 0.12957912801047883\n",
      "94 Train Loss 38833.395 Test MSE 5434.608896367973 Test RE 0.12897935165874375\n",
      "95 Train Loss 38753.5 Test MSE 5457.4890714924795 Test RE 0.12925057362388354\n",
      "96 Train Loss 38617.58 Test MSE 5418.382445713872 Test RE 0.12878665686966295\n",
      "97 Train Loss 38450.508 Test MSE 5441.084489611321 Test RE 0.12905617127739535\n",
      "98 Train Loss 38212.586 Test MSE 5556.47506978617 Test RE 0.13041745677035116\n",
      "99 Train Loss 37921.785 Test MSE 5511.94665118725 Test RE 0.1298938366268894\n",
      "100 Train Loss 37575.19 Test MSE 5630.248300133688 Test RE 0.13128037721017427\n",
      "101 Train Loss 37210.9 Test MSE 5716.005993196169 Test RE 0.13227640390588385\n",
      "102 Train Loss 37077.336 Test MSE 5721.296169874659 Test RE 0.1323376008075417\n",
      "103 Train Loss 36949.703 Test MSE 5726.282571124105 Test RE 0.13239525772998192\n",
      "104 Train Loss 36781.64 Test MSE 5774.773302068727 Test RE 0.13295464410373858\n",
      "105 Train Loss 36492.016 Test MSE 5849.50075642219 Test RE 0.1338121173037409\n",
      "106 Train Loss 36199.95 Test MSE 5423.503856758522 Test RE 0.12884750654502317\n",
      "107 Train Loss 35898.527 Test MSE 5306.919922783691 Test RE 0.12745512672148787\n",
      "108 Train Loss 35822.4 Test MSE 5208.244844968448 Test RE 0.12626463806630814\n",
      "109 Train Loss 35441.22 Test MSE 5174.204793287418 Test RE 0.12585134138142562\n",
      "110 Train Loss 35267.63 Test MSE 5178.5364124931375 Test RE 0.12590400899558143\n",
      "111 Train Loss 35077.273 Test MSE 5039.240390977349 Test RE 0.12419913753545798\n",
      "112 Train Loss 34923.547 Test MSE 5039.441608721085 Test RE 0.12420161715726806\n",
      "113 Train Loss 34765.953 Test MSE 5054.582469789289 Test RE 0.12438805736251946\n",
      "114 Train Loss 34571.477 Test MSE 5122.07007900098 Test RE 0.1252157040881566\n",
      "115 Train Loss 34186.918 Test MSE 4858.768366152814 Test RE 0.12195486772245731\n",
      "116 Train Loss 33767.754 Test MSE 4952.4853683925885 Test RE 0.12312539659842928\n",
      "117 Train Loss 33461.215 Test MSE 4859.222019865693 Test RE 0.12196056093347643\n",
      "118 Train Loss 32609.969 Test MSE 4600.367781710484 Test RE 0.11866764356204118\n",
      "119 Train Loss 32122.496 Test MSE 4460.38033879258 Test RE 0.11684818966670528\n",
      "120 Train Loss 31706.975 Test MSE 4384.45375588226 Test RE 0.11584939996964877\n",
      "121 Train Loss 31306.045 Test MSE 4533.85758246271 Test RE 0.11780669677443345\n",
      "122 Train Loss 30874.697 Test MSE 4616.4241235749405 Test RE 0.11887455186755573\n",
      "123 Train Loss 30658.727 Test MSE 4734.4734999747325 Test RE 0.1203848641095465\n",
      "124 Train Loss 30353.797 Test MSE 4538.181476362956 Test RE 0.11786285891205049\n",
      "125 Train Loss 29762.232 Test MSE 4172.735832744789 Test RE 0.11301770590190334\n",
      "126 Train Loss 28957.59 Test MSE 4090.2306958288077 Test RE 0.11189481012340864\n",
      "127 Train Loss 28409.154 Test MSE 3872.2880830176637 Test RE 0.10887292017481884\n",
      "128 Train Loss 27805.527 Test MSE 4197.860429973594 Test RE 0.11335744258612772\n",
      "129 Train Loss 27041.574 Test MSE 4238.997757455305 Test RE 0.11391151692131941\n",
      "130 Train Loss 26690.13 Test MSE 4280.993833292828 Test RE 0.11447439131381262\n",
      "131 Train Loss 26087.639 Test MSE 4419.741357928554 Test RE 0.11631466373799516\n",
      "132 Train Loss 25582.857 Test MSE 4186.881692972144 Test RE 0.11320911269992034\n",
      "133 Train Loss 24928.104 Test MSE 3986.774624170168 Test RE 0.1104706436743748\n",
      "134 Train Loss 24562.254 Test MSE 3755.7383302328303 Test RE 0.10722195093750547\n",
      "135 Train Loss 24287.445 Test MSE 3741.860650207948 Test RE 0.10702367181150871\n",
      "136 Train Loss 23825.068 Test MSE 3901.1972727204534 Test RE 0.1092785686253613\n",
      "137 Train Loss 23429.545 Test MSE 4054.3030133695293 Test RE 0.11140229656412155\n",
      "138 Train Loss 22783.098 Test MSE 4230.790996375444 Test RE 0.11380119632623649\n",
      "139 Train Loss 22540.76 Test MSE 4033.0840020850746 Test RE 0.11111039094962194\n",
      "140 Train Loss 22338.643 Test MSE 3921.9200692543855 Test RE 0.10956842300417582\n",
      "141 Train Loss 22212.998 Test MSE 3936.929122955786 Test RE 0.10977788009922754\n",
      "142 Train Loss 22021.605 Test MSE 3929.9822190131117 Test RE 0.10968098311684996\n",
      "143 Train Loss 21755.123 Test MSE 4041.7961482788796 Test RE 0.11123033486431642\n",
      "144 Train Loss 21636.002 Test MSE 4255.568758848378 Test RE 0.11413395001064694\n",
      "145 Train Loss 21363.342 Test MSE 4170.527132673189 Test RE 0.11298779084542826\n",
      "146 Train Loss 21173.719 Test MSE 4173.047543032616 Test RE 0.11302192712811569\n",
      "147 Train Loss 21111.639 Test MSE 4246.966979335035 Test RE 0.11401854220784172\n",
      "148 Train Loss 20990.266 Test MSE 4427.273834231889 Test RE 0.1164137379144365\n",
      "149 Train Loss 20803.45 Test MSE 4327.29869211533 Test RE 0.11509182549857465\n",
      "150 Train Loss 20759.436 Test MSE 4299.7784904404425 Test RE 0.11472526862568179\n",
      "151 Train Loss 20684.777 Test MSE 4386.836720180533 Test RE 0.11588087794833413\n",
      "152 Train Loss 20636.514 Test MSE 4459.067701349648 Test RE 0.11683099487799481\n",
      "153 Train Loss 20587.912 Test MSE 4293.788085310875 Test RE 0.11464532376646398\n",
      "154 Train Loss 20548.875 Test MSE 4172.235769632779 Test RE 0.11301093364488546\n",
      "155 Train Loss 20438.293 Test MSE 4177.7271121463655 Test RE 0.11308527959706278\n",
      "156 Train Loss 20383.744 Test MSE 4368.320213706968 Test RE 0.1156360571157123\n",
      "157 Train Loss 20326.762 Test MSE 4308.466040691854 Test RE 0.11484110931451205\n",
      "158 Train Loss 20284.217 Test MSE 4295.713319938319 Test RE 0.1146710230332906\n",
      "159 Train Loss 20246.527 Test MSE 4303.5987007900685 Test RE 0.11477622210556966\n",
      "160 Train Loss 20207.23 Test MSE 4318.042338897186 Test RE 0.1149686654191673\n",
      "161 Train Loss 20167.572 Test MSE 4324.538476735864 Test RE 0.11505511334577394\n",
      "162 Train Loss 20103.176 Test MSE 4253.504961492541 Test RE 0.114106271229883\n",
      "163 Train Loss 20030.379 Test MSE 4360.814007727573 Test RE 0.11553666407518678\n",
      "164 Train Loss 19933.016 Test MSE 4366.2759685296605 Test RE 0.1156089968153341\n",
      "165 Train Loss 19882.88 Test MSE 4429.639838038693 Test RE 0.1164448404131728\n",
      "166 Train Loss 19872.734 Test MSE 4364.579139713393 Test RE 0.11558653056020306\n",
      "167 Train Loss 19848.742 Test MSE 4300.804125806391 Test RE 0.11473895064176359\n",
      "168 Train Loss 19831.393 Test MSE 4307.089438567075 Test RE 0.11482276135220573\n",
      "169 Train Loss 19816.78 Test MSE 4303.050790093215 Test RE 0.11476891553193823\n",
      "170 Train Loss 19768.695 Test MSE 4357.9961701881775 Test RE 0.1154993297428612\n",
      "171 Train Loss 19739.152 Test MSE 4349.667882180777 Test RE 0.11538891527175905\n",
      "172 Train Loss 19725.414 Test MSE 4305.800032695729 Test RE 0.1148055729205484\n",
      "173 Train Loss 19710.598 Test MSE 4377.665396653016 Test RE 0.11575968161184719\n",
      "174 Train Loss 19651.918 Test MSE 4401.489279635057 Test RE 0.11607424461373514\n",
      "175 Train Loss 19589.023 Test MSE 4438.562226821255 Test RE 0.11656205575330186\n",
      "176 Train Loss 19574.576 Test MSE 4468.56880117074 Test RE 0.11695539669876201\n",
      "177 Train Loss 19561.941 Test MSE 4434.733491889402 Test RE 0.11651177128329762\n",
      "178 Train Loss 19552.398 Test MSE 4389.60513001888 Test RE 0.11591743677034276\n",
      "179 Train Loss 19536.328 Test MSE 4369.0735531983355 Test RE 0.11564602770494711\n",
      "180 Train Loss 19516.064 Test MSE 4401.893175275515 Test RE 0.11607957017548591\n",
      "181 Train Loss 19492.057 Test MSE 4468.11723201461 Test RE 0.11694948711266524\n",
      "182 Train Loss 19458.37 Test MSE 4539.59103013829 Test RE 0.1178811615229488\n",
      "183 Train Loss 19433.098 Test MSE 4503.296730210979 Test RE 0.11740898240984768\n",
      "184 Train Loss 19355.656 Test MSE 4387.906527944101 Test RE 0.115895006888345\n",
      "185 Train Loss 19314.857 Test MSE 4403.866792051275 Test RE 0.11610558976574263\n",
      "186 Train Loss 19279.988 Test MSE 4368.720817974763 Test RE 0.11564135929523577\n",
      "187 Train Loss 19264.01 Test MSE 4390.244284550794 Test RE 0.11592587562259467\n",
      "188 Train Loss 19253.66 Test MSE 4418.001131934666 Test RE 0.1162917626547184\n",
      "189 Train Loss 19244.729 Test MSE 4450.641781001749 Test RE 0.11672055989459075\n",
      "190 Train Loss 19238.006 Test MSE 4444.01689297658 Test RE 0.11663365685383179\n",
      "191 Train Loss 19229.395 Test MSE 4430.920518720445 Test RE 0.11646167224214074\n",
      "192 Train Loss 19216.217 Test MSE 4440.67122240549 Test RE 0.11658974486226048\n",
      "193 Train Loss 19186.115 Test MSE 4495.9755312627185 Test RE 0.11731350522769184\n",
      "194 Train Loss 19156.773 Test MSE 4526.133949803425 Test RE 0.11770630946884257\n",
      "195 Train Loss 19134.791 Test MSE 4502.316683155327 Test RE 0.1173962059268032\n",
      "196 Train Loss 19091.045 Test MSE 4493.528517989852 Test RE 0.11728157591964516\n",
      "197 Train Loss 18992.766 Test MSE 4376.525415340515 Test RE 0.11574460822751236\n",
      "198 Train Loss 18897.135 Test MSE 4504.020887595086 Test RE 0.11741842206804748\n",
      "199 Train Loss 18796.268 Test MSE 4522.508119399625 Test RE 0.11765915348238055\n",
      "Training time: 201.04\n",
      "Training time: 201.04\n",
      "ES_swish_high\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 249999.02 Test MSE 75079.63300676021 Test RE 0.4793989874269098\n",
      "1 Train Loss 249999.02 Test MSE 75079.67573913198 Test RE 0.479399123854407\n",
      "2 Train Loss 249998.98 Test MSE 75079.74984204165 Test RE 0.47939936043548476\n",
      "3 Train Loss 249998.98 Test MSE 75079.78314321791 Test RE 0.47939946675283956\n",
      "4 Train Loss 249998.98 Test MSE 75079.8137915792 Test RE 0.4793995646007952\n",
      "5 Train Loss 249998.98 Test MSE 75079.84290383082 Test RE 0.4793996575445486\n",
      "6 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "7 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "8 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "9 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "10 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "11 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "12 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "13 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "14 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "15 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "16 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "17 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "18 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "19 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "20 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "21 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "22 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "23 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "24 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "25 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "26 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "27 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "28 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "29 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "30 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "31 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "32 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "33 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "34 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "35 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "36 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "37 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "38 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "39 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "40 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "41 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "42 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "43 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "44 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "45 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "46 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "47 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "48 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "49 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "50 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "51 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "52 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "53 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "54 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "55 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "56 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "57 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "58 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "59 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "60 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "61 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "62 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "63 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "64 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "65 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "66 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "67 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "68 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "69 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "70 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "71 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "72 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "73 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "74 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "75 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "76 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "77 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "78 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "79 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "80 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "81 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "82 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "83 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "84 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "85 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "86 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "87 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "88 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "89 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "90 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "91 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "92 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "93 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "94 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "95 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "96 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "97 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "98 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "99 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "100 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "101 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "102 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "103 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "104 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "105 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "106 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "107 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "108 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "109 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "110 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "111 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "112 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "113 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "114 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "115 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "116 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "117 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "118 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "119 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "120 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "121 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "122 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "123 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "124 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "125 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "126 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "127 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "128 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "129 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "130 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "131 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "132 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "133 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "134 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "135 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "136 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "137 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "138 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "139 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "140 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "141 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "142 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "143 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "144 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "145 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "146 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "147 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "148 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "149 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "150 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "151 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "152 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "153 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "154 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "155 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "156 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "157 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "158 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "159 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "160 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "161 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "162 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "163 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "164 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "165 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "166 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "167 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "168 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "169 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "170 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "171 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "172 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "173 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "174 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "175 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "176 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "177 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "178 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "179 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "180 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "181 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "182 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "183 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "184 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "185 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "186 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "187 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "188 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "189 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "190 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "191 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "192 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "193 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "194 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "195 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "196 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "197 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "198 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "199 Train Loss 249998.97 Test MSE 75079.87156276443 Test RE 0.4793997490410216\n",
      "Training time: 62.92\n",
      "Training time: 62.92\n",
      "ES_swish_high\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 250078.34 Test MSE 75179.60251293035 Test RE 0.47971804424326525\n",
      "1 Train Loss 250001.55 Test MSE 75084.06371948672 Test RE 0.4794131327268612\n",
      "2 Train Loss 250000.5 Test MSE 75080.90884809177 Test RE 0.4794030606650144\n",
      "3 Train Loss 250000.47 Test MSE 75080.8095911851 Test RE 0.4794027437796615\n",
      "4 Train Loss 250000.47 Test MSE 75080.76596712295 Test RE 0.47940260450640215\n",
      "5 Train Loss 250000.47 Test MSE 75080.72189274605 Test RE 0.47940246379543644\n",
      "6 Train Loss 250000.47 Test MSE 75080.67969035804 Test RE 0.4794023290609059\n",
      "7 Train Loss 250000.47 Test MSE 75080.63775139017 Test RE 0.479402195167328\n",
      "8 Train Loss 250000.45 Test MSE 75080.55339654443 Test RE 0.4794019258574847\n",
      "9 Train Loss 250000.45 Test MSE 75080.50915435782 Test RE 0.47940178461057303\n",
      "10 Train Loss 250000.42 Test MSE 75080.41807059619 Test RE 0.47940149381785185\n",
      "11 Train Loss 250000.42 Test MSE 75080.36967063871 Test RE 0.4794013392967646\n",
      "12 Train Loss 250000.42 Test MSE 75080.32073701809 Test RE 0.4794011830718607\n",
      "13 Train Loss 250000.39 Test MSE 75080.20789303018 Test RE 0.4794008228072727\n",
      "14 Train Loss 250000.22 Test MSE 75079.57553304928 Test RE 0.4793988039361082\n",
      "15 Train Loss 249988.9 Test MSE 75074.41974727207 Test RE 0.4793823432678641\n",
      "16 Train Loss 234054.1 Test MSE 67205.44162375182 Test RE 0.4535636708055192\n",
      "17 Train Loss 161592.31 Test MSE 40903.09008282046 Test RE 0.3538458456984484\n",
      "18 Train Loss 100442.09 Test MSE 20954.87555297432 Test RE 0.2532669876061196\n",
      "19 Train Loss 77836.87 Test MSE 22787.579682566124 Test RE 0.2641101804778031\n",
      "20 Train Loss 65634.57 Test MSE 13802.586489656993 Test RE 0.2055494317253336\n",
      "21 Train Loss 58897.297 Test MSE 12794.28150946667 Test RE 0.19789917919107086\n",
      "22 Train Loss 55645.613 Test MSE 10774.623226292892 Test RE 0.1816088833293356\n",
      "23 Train Loss 52619.074 Test MSE 10445.23555413187 Test RE 0.17881138251238396\n",
      "24 Train Loss 51499.527 Test MSE 9383.56033784087 Test RE 0.16948055101445716\n",
      "25 Train Loss 50917.44 Test MSE 9912.028885600166 Test RE 0.17418763447518523\n",
      "26 Train Loss 50384.285 Test MSE 9072.72889279696 Test RE 0.16664988130861363\n",
      "27 Train Loss 49467.87 Test MSE 9126.997961917225 Test RE 0.16714755131088582\n",
      "28 Train Loss 48516.03 Test MSE 8601.489190082963 Test RE 0.1622642571056765\n",
      "29 Train Loss 48408.3 Test MSE 8750.032373662756 Test RE 0.16365936876422604\n",
      "30 Train Loss 48149.48 Test MSE 8646.278924940145 Test RE 0.16268618034744245\n",
      "31 Train Loss 47910.33 Test MSE 8364.917895559109 Test RE 0.16001727970678375\n",
      "32 Train Loss 47390.18 Test MSE 8082.773070294355 Test RE 0.15729547700400132\n",
      "33 Train Loss 46974.3 Test MSE 7963.596556873964 Test RE 0.1561315484615093\n",
      "34 Train Loss 46832.793 Test MSE 8061.696200084348 Test RE 0.15709025904152304\n",
      "35 Train Loss 46472.48 Test MSE 7777.724655466387 Test RE 0.15429872023525948\n",
      "36 Train Loss 46160.934 Test MSE 7797.870495314644 Test RE 0.15449842305033168\n",
      "37 Train Loss 45939.57 Test MSE 7594.359400538522 Test RE 0.1524690221226165\n",
      "38 Train Loss 45744.047 Test MSE 7675.149898370318 Test RE 0.1532778764393942\n",
      "39 Train Loss 45525.93 Test MSE 7287.598136427013 Test RE 0.1493579176006666\n",
      "40 Train Loss 45214.312 Test MSE 7268.894562945923 Test RE 0.1491661314023622\n",
      "41 Train Loss 45059.945 Test MSE 7380.310244777087 Test RE 0.1503049734178025\n",
      "42 Train Loss 44856.234 Test MSE 7213.494137521385 Test RE 0.14859660371974542\n",
      "43 Train Loss 44589.957 Test MSE 7189.194167710935 Test RE 0.14834610520709032\n",
      "44 Train Loss 44426.72 Test MSE 7049.45771410658 Test RE 0.14689732817075654\n",
      "45 Train Loss 44050.48 Test MSE 7023.729916055002 Test RE 0.1466290238882876\n",
      "46 Train Loss 43859.633 Test MSE 7081.291923711032 Test RE 0.14722863683237314\n",
      "47 Train Loss 43717.473 Test MSE 7035.8714546618785 Test RE 0.14675570396157211\n",
      "48 Train Loss 43502.605 Test MSE 7131.656650167347 Test RE 0.14775128100551813\n",
      "49 Train Loss 43382.316 Test MSE 7194.855339132179 Test RE 0.14840450170104438\n",
      "50 Train Loss 43323.418 Test MSE 7235.50613879124 Test RE 0.14882315253716252\n",
      "51 Train Loss 43222.188 Test MSE 7252.070531585266 Test RE 0.14899340710074024\n",
      "52 Train Loss 43120.027 Test MSE 7100.714689931059 Test RE 0.14743040998833512\n",
      "53 Train Loss 43068.645 Test MSE 6991.260781821613 Test RE 0.14628971468683394\n",
      "54 Train Loss 42868.383 Test MSE 7004.208547331473 Test RE 0.14642511578371772\n",
      "55 Train Loss 42789.91 Test MSE 7014.321003932009 Test RE 0.14653077965356381\n",
      "56 Train Loss 42687.062 Test MSE 7006.537311382945 Test RE 0.14644945552211694\n",
      "57 Train Loss 42544.11 Test MSE 6869.978959611836 Test RE 0.14501527327189698\n",
      "58 Train Loss 42447.703 Test MSE 6784.018552391688 Test RE 0.14410516774825155\n",
      "59 Train Loss 42352.574 Test MSE 6703.475294943186 Test RE 0.14324716922535255\n",
      "60 Train Loss 42253.652 Test MSE 6698.823089357377 Test RE 0.14319745389751667\n",
      "61 Train Loss 42123.555 Test MSE 6638.849910177172 Test RE 0.1425550041241508\n",
      "62 Train Loss 42025.71 Test MSE 6547.230649871517 Test RE 0.14156792359857512\n",
      "63 Train Loss 41970.66 Test MSE 6476.559838236712 Test RE 0.1408018085008701\n",
      "64 Train Loss 41941.043 Test MSE 6530.291900689129 Test RE 0.14138467539171837\n",
      "65 Train Loss 41812.484 Test MSE 6432.907569437367 Test RE 0.14032650137774552\n",
      "66 Train Loss 41757.508 Test MSE 6418.985682206762 Test RE 0.1401745741320685\n",
      "67 Train Loss 41692.1 Test MSE 6385.201769068134 Test RE 0.13980520945400235\n",
      "68 Train Loss 41603.336 Test MSE 6340.995680929662 Test RE 0.13932041855776825\n",
      "69 Train Loss 41523.523 Test MSE 6270.007306203445 Test RE 0.13853836736441846\n",
      "70 Train Loss 41497.02 Test MSE 6248.952829411915 Test RE 0.1383055681433352\n",
      "71 Train Loss 41477.758 Test MSE 6214.976801607121 Test RE 0.13792906677700167\n",
      "72 Train Loss 41433.816 Test MSE 6185.608310120592 Test RE 0.13760279320369814\n",
      "73 Train Loss 41376.742 Test MSE 6188.2137182772285 Test RE 0.13763176963399223\n",
      "74 Train Loss 41308.254 Test MSE 6185.787107336797 Test RE 0.1376047819182551\n",
      "75 Train Loss 41283.414 Test MSE 6204.625919989618 Test RE 0.1378141602836239\n",
      "76 Train Loss 41243.703 Test MSE 6176.533740875808 Test RE 0.13750182137371328\n",
      "77 Train Loss 41202.934 Test MSE 6120.95562675628 Test RE 0.13688178419543573\n",
      "78 Train Loss 41168.57 Test MSE 6116.899613000821 Test RE 0.13683642474194868\n",
      "79 Train Loss 41136.895 Test MSE 6098.777970502032 Test RE 0.13663358178113083\n",
      "80 Train Loss 41125.99 Test MSE 6106.808442260423 Test RE 0.1367235072688091\n",
      "81 Train Loss 41103.79 Test MSE 6097.8880133162975 Test RE 0.1366236123680087\n",
      "82 Train Loss 41065.902 Test MSE 6051.682880553906 Test RE 0.1361050134792274\n",
      "83 Train Loss 41037.176 Test MSE 6040.550940741257 Test RE 0.13597977474447742\n",
      "84 Train Loss 40950.953 Test MSE 5999.61699101435 Test RE 0.13551825631170927\n",
      "85 Train Loss 40890.83 Test MSE 5964.127558199466 Test RE 0.13511684739578195\n",
      "86 Train Loss 40841.066 Test MSE 5918.327362422595 Test RE 0.1345970476086664\n",
      "87 Train Loss 40806.14 Test MSE 5894.826053449718 Test RE 0.13432954354177604\n",
      "88 Train Loss 40786.05 Test MSE 5913.504977951572 Test RE 0.13454220010300233\n",
      "89 Train Loss 40704.586 Test MSE 5881.284252987171 Test RE 0.13417516156643572\n",
      "90 Train Loss 40589.137 Test MSE 5888.4030304052585 Test RE 0.13425634062603464\n",
      "91 Train Loss 40530.19 Test MSE 5858.040328799423 Test RE 0.13390975653498774\n",
      "92 Train Loss 40508.09 Test MSE 5844.4246059316065 Test RE 0.13375404415363773\n",
      "93 Train Loss 40423.938 Test MSE 5818.855088120945 Test RE 0.13346113462638443\n",
      "94 Train Loss 40349.465 Test MSE 5814.536095143302 Test RE 0.13341159526731472\n",
      "95 Train Loss 40281.95 Test MSE 5811.410069949948 Test RE 0.13337572791093982\n",
      "96 Train Loss 40257.586 Test MSE 5815.559404443531 Test RE 0.13342333440848086\n",
      "97 Train Loss 40235.965 Test MSE 5797.5484997440135 Test RE 0.1332165668154511\n",
      "98 Train Loss 40173.98 Test MSE 5784.9306631271265 Test RE 0.13307152098655112\n",
      "99 Train Loss 40078.258 Test MSE 5762.058020469785 Test RE 0.13280818923254628\n",
      "100 Train Loss 39992.1 Test MSE 5714.847535811312 Test RE 0.13226299906148786\n",
      "101 Train Loss 39906.4 Test MSE 5732.249598992455 Test RE 0.13246422048940923\n",
      "102 Train Loss 39887.355 Test MSE 5731.467690860965 Test RE 0.13245518578308507\n",
      "103 Train Loss 39868.793 Test MSE 5728.314945604379 Test RE 0.13241875053432817\n",
      "104 Train Loss 39853.68 Test MSE 5726.760572488124 Test RE 0.13240078346088788\n",
      "105 Train Loss 39821.387 Test MSE 5732.382613414924 Test RE 0.132465757368541\n",
      "106 Train Loss 39776.934 Test MSE 5725.619160498994 Test RE 0.1323875882722076\n",
      "107 Train Loss 39750.508 Test MSE 5711.477158110064 Test RE 0.13222399172101437\n",
      "108 Train Loss 39738.668 Test MSE 5712.945977616523 Test RE 0.1322409926375942\n",
      "109 Train Loss 39704.023 Test MSE 5706.166846479829 Test RE 0.13216250903749333\n",
      "110 Train Loss 39668.188 Test MSE 5722.790586051462 Test RE 0.13235488312722313\n",
      "111 Train Loss 39650.07 Test MSE 5723.924661344344 Test RE 0.13236799674417662\n",
      "112 Train Loss 39620.203 Test MSE 5674.838169618883 Test RE 0.13179920250970228\n",
      "113 Train Loss 39569.6 Test MSE 5670.773749370238 Test RE 0.13175199558652737\n",
      "114 Train Loss 39491.176 Test MSE 5624.249659578997 Test RE 0.1312104234867936\n",
      "115 Train Loss 39457.273 Test MSE 5632.842107927706 Test RE 0.13131061360813337\n",
      "116 Train Loss 39331.395 Test MSE 5571.078198230496 Test RE 0.1305887212114689\n",
      "117 Train Loss 39143.22 Test MSE 5629.230627522344 Test RE 0.13126851214891783\n",
      "118 Train Loss 38833.12 Test MSE 5386.123854868583 Test RE 0.12840271590075233\n",
      "119 Train Loss 38561.38 Test MSE 5388.120410872494 Test RE 0.1284265121842349\n",
      "120 Train Loss 38270.785 Test MSE 5408.121009814462 Test RE 0.1286646497653186\n",
      "121 Train Loss 38013.26 Test MSE 5356.0326031701325 Test RE 0.12804353272450159\n",
      "122 Train Loss 37744.348 Test MSE 5402.761041111568 Test RE 0.12860087443060184\n",
      "123 Train Loss 37564.22 Test MSE 5369.491881760507 Test RE 0.1282043133236587\n",
      "124 Train Loss 37172.484 Test MSE 5281.479546137989 Test RE 0.12714926175551822\n",
      "125 Train Loss 36876.24 Test MSE 5207.464026584824 Test RE 0.12625517293468022\n",
      "126 Train Loss 36459.164 Test MSE 5117.34166703379 Test RE 0.12515789463518467\n",
      "127 Train Loss 35791.01 Test MSE 5032.07998807999 Test RE 0.12411086708856922\n",
      "128 Train Loss 35331.57 Test MSE 4929.9585683609985 Test RE 0.12284505428665235\n",
      "129 Train Loss 33990.83 Test MSE 4886.165346220225 Test RE 0.12229821588076484\n",
      "130 Train Loss 33438.207 Test MSE 4884.312935309481 Test RE 0.12227503123501617\n",
      "131 Train Loss 32537.479 Test MSE 4942.888874245432 Test RE 0.12300604792781417\n",
      "132 Train Loss 31995.385 Test MSE 4978.57273461611 Test RE 0.12344925404859906\n",
      "133 Train Loss 31500.395 Test MSE 4837.24456461701 Test RE 0.12168444467824988\n",
      "134 Train Loss 30891.486 Test MSE 4604.989259608919 Test RE 0.11872723469181798\n",
      "135 Train Loss 30665.69 Test MSE 4826.511260845457 Test RE 0.1215493676312236\n",
      "136 Train Loss 30391.975 Test MSE 4940.0140680783825 Test RE 0.12297027229279053\n",
      "137 Train Loss 30062.799 Test MSE 4716.994856699949 Test RE 0.1201624413082331\n",
      "138 Train Loss 29387.74 Test MSE 4819.271221508898 Test RE 0.1214581679609123\n",
      "139 Train Loss 28944.436 Test MSE 4968.668661899312 Test RE 0.12332640166434393\n",
      "140 Train Loss 28102.004 Test MSE 4520.9547839283305 Test RE 0.11763894568751418\n",
      "141 Train Loss 27446.219 Test MSE 4336.455808338447 Test RE 0.11521353563865427\n",
      "142 Train Loss 26945.084 Test MSE 4311.160741742833 Test RE 0.11487701699979573\n",
      "143 Train Loss 26139.055 Test MSE 4438.406015654352 Test RE 0.1165600045874035\n",
      "144 Train Loss 25698.213 Test MSE 4043.358154086211 Test RE 0.11125182600830433\n",
      "145 Train Loss 25233.303 Test MSE 3919.6544443841885 Test RE 0.10953677054807803\n",
      "146 Train Loss 24814.312 Test MSE 3784.1319141168956 Test RE 0.10762648965303792\n",
      "147 Train Loss 24275.625 Test MSE 3813.2409447750692 Test RE 0.10803964926796866\n",
      "148 Train Loss 23744.645 Test MSE 3879.377976048704 Test RE 0.10897254400726922\n",
      "149 Train Loss 23450.07 Test MSE 3961.0460695393062 Test RE 0.11011360688225548\n",
      "150 Train Loss 23165.24 Test MSE 3915.2474314228225 Test RE 0.10947517510152266\n",
      "151 Train Loss 22906.275 Test MSE 4000.264272101896 Test RE 0.11065738004524935\n",
      "152 Train Loss 22717.393 Test MSE 3955.330834327356 Test RE 0.11003413894332333\n",
      "153 Train Loss 22436.76 Test MSE 3888.9335327796593 Test RE 0.10910667026428822\n",
      "154 Train Loss 22263.895 Test MSE 3789.6509186166213 Test RE 0.10770494551476731\n",
      "155 Train Loss 22073.396 Test MSE 3717.945019204233 Test RE 0.10668110941440953\n",
      "156 Train Loss 21770.197 Test MSE 3822.0134546333557 Test RE 0.10816385259363366\n",
      "157 Train Loss 21581.686 Test MSE 3859.9077460479148 Test RE 0.10869873859454383\n",
      "158 Train Loss 21372.715 Test MSE 3855.0277727591715 Test RE 0.10863000447715791\n",
      "159 Train Loss 21111.688 Test MSE 4059.0426506068598 Test RE 0.11146739434375336\n",
      "160 Train Loss 20908.225 Test MSE 4273.25737141227 Test RE 0.11437090748744466\n",
      "161 Train Loss 20785.334 Test MSE 4167.601459730439 Test RE 0.11294815277256472\n",
      "162 Train Loss 20714.27 Test MSE 4152.006025040137 Test RE 0.11273662504656033\n",
      "163 Train Loss 20522.783 Test MSE 4218.323895746978 Test RE 0.11363340055204878\n",
      "164 Train Loss 20461.7 Test MSE 4091.560830501298 Test RE 0.11191300262640275\n",
      "165 Train Loss 20343.246 Test MSE 4159.647477047646 Test RE 0.11284031895989739\n",
      "166 Train Loss 20226.812 Test MSE 4158.77087742459 Test RE 0.11282842840985532\n",
      "167 Train Loss 20073.578 Test MSE 3947.608901485014 Test RE 0.10992667747237131\n",
      "168 Train Loss 20000.99 Test MSE 4004.110137945122 Test RE 0.1107105604317847\n",
      "169 Train Loss 19915.13 Test MSE 3925.720085436586 Test RE 0.10962149152251907\n",
      "170 Train Loss 19804.834 Test MSE 3998.2643348540505 Test RE 0.11062971493755344\n",
      "171 Train Loss 19713.889 Test MSE 4027.157970422772 Test RE 0.11102873064398944\n",
      "172 Train Loss 19670.164 Test MSE 4040.050990476808 Test RE 0.1112063188776487\n",
      "173 Train Loss 19563.766 Test MSE 4047.2267296673317 Test RE 0.1113050346513222\n",
      "174 Train Loss 19493.402 Test MSE 4094.545835730664 Test RE 0.11195381834507957\n",
      "175 Train Loss 19380.145 Test MSE 4050.9228634883375 Test RE 0.1113558477692773\n",
      "176 Train Loss 19315.652 Test MSE 4156.576298956394 Test RE 0.11279865476741432\n",
      "177 Train Loss 19255.377 Test MSE 4226.732247804042 Test RE 0.11374659645666514\n",
      "178 Train Loss 19144.96 Test MSE 4341.51021927026 Test RE 0.11528066038189383\n",
      "179 Train Loss 19029.852 Test MSE 4301.008768923991 Test RE 0.1147416803937557\n",
      "180 Train Loss 18898.623 Test MSE 4313.5861513639775 Test RE 0.11490932670272089\n",
      "181 Train Loss 18809.566 Test MSE 4326.385748248357 Test RE 0.11507968421527634\n",
      "182 Train Loss 18765.922 Test MSE 4330.100924919472 Test RE 0.11512908452736559\n",
      "183 Train Loss 18664.703 Test MSE 4347.501317873218 Test RE 0.11536017415281533\n",
      "184 Train Loss 18552.785 Test MSE 4428.042497391128 Test RE 0.11642384335078904\n",
      "185 Train Loss 18452.432 Test MSE 4374.37710280939 Test RE 0.11571619686339865\n",
      "186 Train Loss 18418.033 Test MSE 4355.91267286195 Test RE 0.11547171713099305\n",
      "187 Train Loss 18366.334 Test MSE 4319.6154490986755 Test RE 0.11498960568527125\n",
      "188 Train Loss 18305.734 Test MSE 4395.867467508866 Test RE 0.11600009288297031\n",
      "189 Train Loss 18215.664 Test MSE 4523.853218270229 Test RE 0.11767664946295713\n",
      "190 Train Loss 18170.176 Test MSE 4561.3868138625885 Test RE 0.11816381206108824\n",
      "191 Train Loss 18109.582 Test MSE 4548.657295367421 Test RE 0.1179988162621406\n",
      "192 Train Loss 18017.96 Test MSE 4601.193054736039 Test RE 0.11867828714730974\n",
      "193 Train Loss 17888.842 Test MSE 4420.088096117753 Test RE 0.1163192262159366\n",
      "194 Train Loss 17779.178 Test MSE 4452.389232909403 Test RE 0.11674347159570063\n",
      "195 Train Loss 17645.164 Test MSE 4509.824002822183 Test RE 0.11749404042214281\n",
      "196 Train Loss 17582.89 Test MSE 4501.560850951365 Test RE 0.11738635149367328\n",
      "197 Train Loss 17483.59 Test MSE 4403.804344127967 Test RE 0.11610476655979525\n",
      "198 Train Loss 17375.436 Test MSE 4506.270355078988 Test RE 0.11744773986634852\n",
      "199 Train Loss 17262.734 Test MSE 4239.106062469412 Test RE 0.11391297211313023\n",
      "Training time: 195.69\n",
      "Training time: 195.69\n",
      "ES_swish_high\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 249999.98 Test MSE 75080.00887973611 Test RE 0.47940018743875923\n",
      "1 Train Loss 249999.98 Test MSE 75080.04956870053 Test RE 0.4794003173421437\n",
      "2 Train Loss 249999.97 Test MSE 75080.11814882244 Test RE 0.47940053629061874\n",
      "3 Train Loss 249999.97 Test MSE 75080.14764454639 Test RE 0.47940063045845466\n",
      "4 Train Loss 249999.97 Test MSE 75080.17591414938 Test RE 0.4794007207117682\n",
      "5 Train Loss 249999.97 Test MSE 75080.20142392603 Test RE 0.4794008021540673\n",
      "6 Train Loss 249999.97 Test MSE 75080.2269900982 Test RE 0.47940088377640017\n",
      "7 Train Loss 249999.97 Test MSE 75080.25070201427 Test RE 0.4794009594788392\n",
      "8 Train Loss 249999.97 Test MSE 75080.27302265508 Test RE 0.4794010307394951\n",
      "9 Train Loss 249999.97 Test MSE 75080.29476844135 Test RE 0.4794011001648662\n",
      "10 Train Loss 249999.97 Test MSE 75080.31626988109 Test RE 0.47940116881012895\n",
      "11 Train Loss 249999.97 Test MSE 75080.3376879457 Test RE 0.4794012371891994\n",
      "12 Train Loss 249999.97 Test MSE 75080.35802984651 Test RE 0.4794013021325125\n",
      "13 Train Loss 249999.94 Test MSE 75080.40190689964 Test RE 0.47940144221384584\n",
      "14 Train Loss 249999.94 Test MSE 75080.42296016011 Test RE 0.4794015094282086\n",
      "15 Train Loss 249999.94 Test MSE 75080.44552026624 Test RE 0.4794015814532963\n",
      "16 Train Loss 249999.94 Test MSE 75080.4691122233 Test RE 0.4794016567726459\n",
      "17 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "18 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "19 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "20 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "21 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "22 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "23 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "24 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "25 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "26 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "27 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "28 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "29 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "30 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "31 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "32 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "33 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "34 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "35 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "36 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "37 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "38 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "39 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "40 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "41 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "42 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "43 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "44 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "45 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "46 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "47 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "48 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "49 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "50 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "51 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "52 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "53 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "54 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "55 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "56 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "57 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "58 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "59 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "60 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "61 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "62 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "63 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "64 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "65 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "66 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "67 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "68 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "69 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "70 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "71 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "72 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "73 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "74 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "75 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "76 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "77 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "78 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "79 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "80 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "81 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "82 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "83 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "84 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "85 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "86 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "87 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "88 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "89 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "90 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "91 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "92 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "93 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "94 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "95 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "96 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "97 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "98 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "99 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "100 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "101 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "102 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "103 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "104 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "105 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "106 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "107 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "108 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "109 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "110 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "111 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "112 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "113 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "114 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "115 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "116 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "117 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "118 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "119 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "120 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "121 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "122 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "123 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "124 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "125 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "126 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "127 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "128 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "129 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "130 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "131 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "132 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "133 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "134 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "135 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "136 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "137 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "138 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "139 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "140 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "141 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "142 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "143 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "144 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "145 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "146 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "147 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "148 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "149 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "150 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "151 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "152 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "153 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "154 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "155 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "156 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "157 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "158 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "159 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "160 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "161 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "162 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "163 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "164 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "165 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "166 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "167 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "168 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "169 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "170 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "171 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "172 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "173 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "174 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "175 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "176 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "177 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "178 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "179 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "180 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "181 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "182 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "183 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "184 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "185 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "186 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "187 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "188 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "189 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "190 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "191 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "192 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "193 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "194 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "195 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "196 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "197 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "198 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "199 Train Loss 249999.94 Test MSE 75080.49360671529 Test RE 0.4794017349734032\n",
      "Training time: 57.18\n",
      "Training time: 57.18\n",
      "ES_swish_high\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 250000.88 Test MSE 75080.31359431149 Test RE 0.479401160268135\n",
      "1 Train Loss 250000.88 Test MSE 75080.35380551954 Test RE 0.4794012886459766\n",
      "2 Train Loss 250000.88 Test MSE 75080.3923086289 Test RE 0.4794014115705297\n",
      "3 Train Loss 250000.88 Test MSE 75080.42999090452 Test RE 0.4794015318744687\n",
      "4 Train Loss 250000.86 Test MSE 75080.50471588183 Test RE 0.47940177044036186\n",
      "5 Train Loss 250000.83 Test MSE 75080.57640943925 Test RE 0.47940199932807553\n",
      "6 Train Loss 250000.83 Test MSE 75080.61224494861 Test RE 0.47940211373591307\n",
      "7 Train Loss 250000.83 Test MSE 75080.64883773612 Test RE 0.47940223056139586\n",
      "8 Train Loss 250000.83 Test MSE 75080.68613725252 Test RE 0.4794023496431395\n",
      "9 Train Loss 250000.83 Test MSE 75080.72555914315 Test RE 0.4794024755007035\n",
      "10 Train Loss 250000.81 Test MSE 75080.81301931042 Test RE 0.4794027547242204\n",
      "11 Train Loss 250000.81 Test MSE 75080.86032712513 Test RE 0.4794029057581011\n",
      "12 Train Loss 250000.78 Test MSE 75080.96308424624 Test RE 0.4794032338180446\n",
      "13 Train Loss 250000.78 Test MSE 75081.01980121159 Test RE 0.47940341489118454\n",
      "14 Train Loss 250000.67 Test MSE 75081.50667062326 Test RE 0.479404969255262\n",
      "15 Train Loss 250000.42 Test MSE 75082.34066977384 Test RE 0.4794076318431919\n",
      "16 Train Loss 249396.38 Test MSE 74666.66122222318 Test RE 0.47807871426426796\n",
      "17 Train Loss 239682.97 Test MSE 70529.29246495079 Test RE 0.46464450495563014\n",
      "18 Train Loss 172255.34 Test MSE 44268.14229794952 Test RE 0.36811345394689726\n",
      "19 Train Loss 103209.63 Test MSE 22817.26831192676 Test RE 0.26428217147268596\n",
      "20 Train Loss 83829.41 Test MSE 20113.639142155196 Test RE 0.24813119604791004\n",
      "21 Train Loss 69085.984 Test MSE 12878.042112860248 Test RE 0.19854591786190637\n",
      "22 Train Loss 60969.062 Test MSE 11414.889132027603 Test RE 0.1869269374564082\n",
      "23 Train Loss 57788.844 Test MSE 10366.20037141864 Test RE 0.17813359858580868\n",
      "24 Train Loss 53811.59 Test MSE 10550.9786437647 Test RE 0.17971420822473694\n",
      "25 Train Loss 50936.316 Test MSE 8464.848751321104 Test RE 0.16097025911674487\n",
      "26 Train Loss 49376.96 Test MSE 8235.152557768643 Test RE 0.15877125085824007\n",
      "27 Train Loss 48370.9 Test MSE 8714.006346031367 Test RE 0.1633221083958687\n",
      "28 Train Loss 47512.74 Test MSE 8307.084383718147 Test RE 0.15946315516949375\n",
      "29 Train Loss 47117.914 Test MSE 7464.6027698453545 Test RE 0.15116087342404483\n",
      "30 Train Loss 46303.812 Test MSE 7563.71785782037 Test RE 0.1521611220192041\n",
      "31 Train Loss 45976.73 Test MSE 7376.414405968497 Test RE 0.1502652974946472\n",
      "32 Train Loss 45660.707 Test MSE 7143.571897801045 Test RE 0.14787465755485216\n",
      "33 Train Loss 45264.484 Test MSE 7107.531307153351 Test RE 0.14750115889456697\n",
      "34 Train Loss 45087.477 Test MSE 6982.171567089026 Test RE 0.14619458942123095\n",
      "35 Train Loss 44786.35 Test MSE 6858.88296293289 Test RE 0.14489811576294254\n",
      "36 Train Loss 44539.664 Test MSE 6640.563286757799 Test RE 0.14257339847344433\n",
      "37 Train Loss 44227.25 Test MSE 6634.940931155823 Test RE 0.14251302949156314\n",
      "38 Train Loss 43849.176 Test MSE 6544.491490610565 Test RE 0.14153830667527603\n",
      "39 Train Loss 43555.586 Test MSE 6535.23654179649 Test RE 0.14143819246279296\n",
      "40 Train Loss 43379.637 Test MSE 6420.902937234371 Test RE 0.14019550659362598\n",
      "41 Train Loss 43205.176 Test MSE 6334.215857782647 Test RE 0.13924591760671012\n",
      "42 Train Loss 43111.793 Test MSE 6272.887837373287 Test RE 0.13857018696545811\n",
      "43 Train Loss 42992.26 Test MSE 6163.822039492241 Test RE 0.13736025472757663\n",
      "44 Train Loss 42855.49 Test MSE 6329.196420467839 Test RE 0.13919073519027114\n",
      "45 Train Loss 42777.902 Test MSE 6259.204800473155 Test RE 0.13841897303270717\n",
      "46 Train Loss 42650.605 Test MSE 6256.13713857352 Test RE 0.13838504902291923\n",
      "47 Train Loss 42555.77 Test MSE 6180.901171081829 Test RE 0.13755042658758052\n",
      "48 Train Loss 42474.887 Test MSE 6125.189647080482 Test RE 0.13692911831302662\n",
      "49 Train Loss 42380.883 Test MSE 6063.160391267864 Test RE 0.136234019476244\n",
      "50 Train Loss 42240.676 Test MSE 6107.743326423771 Test RE 0.13673397228922915\n",
      "51 Train Loss 42187.684 Test MSE 6063.387899596046 Test RE 0.1362365754108777\n",
      "52 Train Loss 42158.312 Test MSE 6069.815525410028 Test RE 0.1363087665518742\n",
      "53 Train Loss 42137.93 Test MSE 6047.856324533581 Test RE 0.13606197620973653\n",
      "54 Train Loss 42071.684 Test MSE 6009.362957095883 Test RE 0.13562828170142333\n",
      "55 Train Loss 41971.55 Test MSE 5993.70369158581 Test RE 0.13545145558227495\n",
      "56 Train Loss 41913.695 Test MSE 5986.815301048744 Test RE 0.13537359798313806\n",
      "57 Train Loss 41888.906 Test MSE 5992.438356381168 Test RE 0.13543715719928093\n",
      "58 Train Loss 41840.336 Test MSE 6004.680842008323 Test RE 0.13557543492131954\n",
      "59 Train Loss 41826.72 Test MSE 5994.486392119663 Test RE 0.13546029940165044\n",
      "60 Train Loss 41785.613 Test MSE 5994.583360052934 Test RE 0.13546139501279164\n",
      "61 Train Loss 41735.887 Test MSE 5988.445390622704 Test RE 0.135392026484815\n",
      "62 Train Loss 41699.887 Test MSE 5991.371025589778 Test RE 0.1354250951072754\n",
      "63 Train Loss 41675.406 Test MSE 5976.404334352779 Test RE 0.13525584061131543\n",
      "64 Train Loss 41624.707 Test MSE 5987.474810776086 Test RE 0.13538105417992685\n",
      "65 Train Loss 41568.152 Test MSE 5991.863819432143 Test RE 0.13543066439020407\n",
      "66 Train Loss 41550.805 Test MSE 5982.857482166113 Test RE 0.13532884357408034\n",
      "67 Train Loss 41533.426 Test MSE 5978.683179290227 Test RE 0.1352816251544711\n",
      "68 Train Loss 41512.883 Test MSE 5991.830991028325 Test RE 0.13543029338889603\n",
      "69 Train Loss 41505.61 Test MSE 5995.120258134036 Test RE 0.1354674611003142\n",
      "70 Train Loss 41487.316 Test MSE 5986.625898598959 Test RE 0.1353714565863687\n",
      "71 Train Loss 41470.5 Test MSE 5994.1670198867305 Test RE 0.13545669084941536\n",
      "72 Train Loss 41432.883 Test MSE 5975.313682859743 Test RE 0.13524349843138023\n",
      "73 Train Loss 41397.54 Test MSE 5979.687186312512 Test RE 0.1352929836757199\n",
      "74 Train Loss 41345.51 Test MSE 5987.465407457535 Test RE 0.1353809478720326\n",
      "75 Train Loss 41301.008 Test MSE 5986.815312360511 Test RE 0.13537359811102861\n",
      "76 Train Loss 41281.367 Test MSE 5993.724780200068 Test RE 0.13545169387241507\n",
      "77 Train Loss 41238.2 Test MSE 6000.841931535532 Test RE 0.13553208997238222\n",
      "78 Train Loss 41204.074 Test MSE 5998.836132506118 Test RE 0.1355094370798301\n",
      "79 Train Loss 41189.508 Test MSE 6003.727664565937 Test RE 0.1355646739351425\n",
      "80 Train Loss 41170.55 Test MSE 5997.985995924857 Test RE 0.1354998347495769\n",
      "81 Train Loss 41155.855 Test MSE 5983.430195091542 Test RE 0.1353353206398824\n",
      "82 Train Loss 41140.594 Test MSE 5970.799001666022 Test RE 0.13519239679162065\n",
      "83 Train Loss 41118.402 Test MSE 5975.326579201442 Test RE 0.13524364437731043\n",
      "84 Train Loss 41077.7 Test MSE 5962.776800991136 Test RE 0.13510154587944884\n",
      "85 Train Loss 41051.09 Test MSE 5947.302172085624 Test RE 0.13492612387944766\n",
      "86 Train Loss 41016.12 Test MSE 5941.542482165006 Test RE 0.13486077316590095\n",
      "87 Train Loss 40990.73 Test MSE 5934.583044425903 Test RE 0.13478176757476779\n",
      "88 Train Loss 40974.953 Test MSE 5957.706294163212 Test RE 0.13504409118787683\n",
      "89 Train Loss 40950.133 Test MSE 5955.3001074870235 Test RE 0.13501681776311755\n",
      "90 Train Loss 40913.574 Test MSE 5979.841996129684 Test RE 0.135294734983594\n",
      "91 Train Loss 40899.66 Test MSE 5962.539500134254 Test RE 0.13509885753200182\n",
      "92 Train Loss 40868.875 Test MSE 5934.696118086727 Test RE 0.13478305159044035\n",
      "93 Train Loss 40850.91 Test MSE 5937.6817452160585 Test RE 0.1348169506586294\n",
      "94 Train Loss 40819.01 Test MSE 5916.15250892823 Test RE 0.13457231462760844\n",
      "95 Train Loss 40774.402 Test MSE 5888.158337773985 Test RE 0.134253551085443\n",
      "96 Train Loss 40758.39 Test MSE 5865.251106147749 Test RE 0.1339921472685522\n",
      "97 Train Loss 40740.02 Test MSE 5885.357041399808 Test RE 0.1342216116652107\n",
      "98 Train Loss 40711.367 Test MSE 5849.721584345768 Test RE 0.1338146430896468\n",
      "99 Train Loss 40654.06 Test MSE 5813.707349903651 Test RE 0.13340208735794407\n",
      "100 Train Loss 40630.625 Test MSE 5810.529192573626 Test RE 0.13336561916690837\n",
      "101 Train Loss 40605.105 Test MSE 5783.886425833124 Test RE 0.13305951008058897\n",
      "102 Train Loss 40577.58 Test MSE 5762.36203527634 Test RE 0.13281169276576818\n",
      "103 Train Loss 40525.25 Test MSE 5754.872103495785 Test RE 0.1327253502236474\n",
      "104 Train Loss 40483.145 Test MSE 5722.481920940148 Test RE 0.13235131372476108\n",
      "105 Train Loss 40438.04 Test MSE 5737.0792877526865 Test RE 0.13252001239495892\n",
      "106 Train Loss 40391.734 Test MSE 5716.5005640118 Test RE 0.13228212631362882\n",
      "107 Train Loss 40349.758 Test MSE 5683.4325912693575 Test RE 0.1318989682944971\n",
      "108 Train Loss 40318.49 Test MSE 5671.641183390394 Test RE 0.1317620719709957\n",
      "109 Train Loss 40264.164 Test MSE 5698.062549943756 Test RE 0.13206862247840248\n",
      "110 Train Loss 40200.3 Test MSE 5687.496237295825 Test RE 0.1319461136539159\n",
      "111 Train Loss 40160.203 Test MSE 5665.763329026794 Test RE 0.13169377789102835\n",
      "112 Train Loss 40130.01 Test MSE 5667.379151561756 Test RE 0.13171255546715896\n",
      "113 Train Loss 40048.12 Test MSE 5661.361808793622 Test RE 0.13164261395991111\n",
      "114 Train Loss 40002.86 Test MSE 5640.890373658036 Test RE 0.13140438913572727\n",
      "115 Train Loss 39985.566 Test MSE 5636.260067503319 Test RE 0.13135044663532006\n",
      "116 Train Loss 39978.29 Test MSE 5632.541914396294 Test RE 0.1313071145643773\n",
      "117 Train Loss 39958.58 Test MSE 5638.099813665531 Test RE 0.13137188210502027\n",
      "118 Train Loss 39931.61 Test MSE 5639.11367922839 Test RE 0.13138369348157367\n",
      "119 Train Loss 39902.742 Test MSE 5625.444979529045 Test RE 0.13122436580034835\n",
      "120 Train Loss 39895.82 Test MSE 5619.98547330848 Test RE 0.13116067358131306\n",
      "121 Train Loss 39882.09 Test MSE 5627.031089972945 Test RE 0.13124286404082133\n",
      "122 Train Loss 39858.746 Test MSE 5616.665891600404 Test RE 0.13112193123147925\n",
      "123 Train Loss 39842.156 Test MSE 5626.292959028117 Test RE 0.13123425580720813\n",
      "124 Train Loss 39837.445 Test MSE 5630.92958292843 Test RE 0.13128831969797006\n",
      "125 Train Loss 39821.887 Test MSE 5624.6690843426995 Test RE 0.1312153158616191\n",
      "126 Train Loss 39808.29 Test MSE 5637.835734762954 Test RE 0.13136880545243815\n",
      "127 Train Loss 39801.246 Test MSE 5642.881111445358 Test RE 0.13142757418187315\n",
      "128 Train Loss 39793.953 Test MSE 5641.700398212103 Test RE 0.1314138235471186\n",
      "129 Train Loss 39787.53 Test MSE 5645.721439675251 Test RE 0.13146064686930253\n",
      "130 Train Loss 39781.44 Test MSE 5636.601026075162 Test RE 0.1313544195165281\n",
      "131 Train Loss 39763.77 Test MSE 5631.815311692229 Test RE 0.13129864492641585\n",
      "132 Train Loss 39755.438 Test MSE 5623.174878303847 Test RE 0.131197885881538\n",
      "133 Train Loss 39750.69 Test MSE 5614.014923852698 Test RE 0.13109098395400365\n",
      "134 Train Loss 39745.516 Test MSE 5613.365393534688 Test RE 0.13108340025208584\n",
      "135 Train Loss 39732.914 Test MSE 5615.560045798159 Test RE 0.13110902252568263\n",
      "136 Train Loss 39714.93 Test MSE 5616.9826663142385 Test RE 0.13112562875661354\n",
      "137 Train Loss 39692.01 Test MSE 5611.933360706978 Test RE 0.13106667875857925\n",
      "138 Train Loss 39672.543 Test MSE 5607.937071184186 Test RE 0.13102000378567774\n",
      "139 Train Loss 39656.32 Test MSE 5604.416711010666 Test RE 0.13097887368693092\n",
      "140 Train Loss 39641.465 Test MSE 5600.548158755106 Test RE 0.13093366058866593\n",
      "141 Train Loss 39628.09 Test MSE 5586.895882866357 Test RE 0.13077397683136008\n",
      "142 Train Loss 39616.656 Test MSE 5570.920276908401 Test RE 0.13058687032292285\n",
      "143 Train Loss 39587.516 Test MSE 5562.624398669735 Test RE 0.13048960305549515\n",
      "144 Train Loss 39565.367 Test MSE 5579.975119037555 Test RE 0.13069295364015954\n",
      "145 Train Loss 39527.062 Test MSE 5567.718622257017 Test RE 0.13054934024460513\n",
      "146 Train Loss 39507.73 Test MSE 5558.89646449343 Test RE 0.13044587026444562\n",
      "147 Train Loss 39498.56 Test MSE 5554.272984163945 Test RE 0.1303916113501371\n",
      "148 Train Loss 39491.83 Test MSE 5546.3450776223735 Test RE 0.1302985207107094\n",
      "149 Train Loss 39481.73 Test MSE 5553.466234369543 Test RE 0.13038214141356555\n",
      "150 Train Loss 39465.11 Test MSE 5556.335898890069 Test RE 0.1304158235021595\n",
      "151 Train Loss 39437.383 Test MSE 5557.786042090075 Test RE 0.13043284094719929\n",
      "152 Train Loss 39392.984 Test MSE 5523.914830756628 Test RE 0.13003478046187236\n",
      "153 Train Loss 39359.348 Test MSE 5530.393437910689 Test RE 0.130111012393281\n",
      "154 Train Loss 39352.953 Test MSE 5524.392272269767 Test RE 0.13004039990594393\n",
      "155 Train Loss 39334.227 Test MSE 5511.118963645596 Test RE 0.12988408367085866\n",
      "156 Train Loss 39315.367 Test MSE 5510.238179435771 Test RE 0.1298737042522727\n",
      "157 Train Loss 39299.11 Test MSE 5502.904553825388 Test RE 0.12978725043593095\n",
      "158 Train Loss 39281.297 Test MSE 5510.604446528133 Test RE 0.12987802055149933\n",
      "159 Train Loss 39253.902 Test MSE 5508.2917060383925 Test RE 0.12985076349809213\n",
      "160 Train Loss 39244.88 Test MSE 5499.513326723488 Test RE 0.12974725284304467\n",
      "161 Train Loss 39216.312 Test MSE 5462.770836074831 Test RE 0.12931310292998677\n",
      "162 Train Loss 39029.93 Test MSE 5426.884475823645 Test RE 0.12888765738586752\n",
      "163 Train Loss 38899.51 Test MSE 5415.616624743202 Test RE 0.12875378300857138\n",
      "164 Train Loss 38783.848 Test MSE 5372.827480200614 Test RE 0.1282441282376189\n",
      "165 Train Loss 38680.387 Test MSE 5367.151133738085 Test RE 0.12817636592081624\n",
      "166 Train Loss 38339.402 Test MSE 5434.456564721045 Test RE 0.1289775440056895\n",
      "167 Train Loss 38042.047 Test MSE 5329.27650486836 Test RE 0.12772331112519072\n",
      "168 Train Loss 37779.84 Test MSE 5319.419791740554 Test RE 0.12760514173702356\n",
      "169 Train Loss 37442.52 Test MSE 5217.303877563111 Test RE 0.12637440042881432\n",
      "170 Train Loss 36984.812 Test MSE 5140.0354280456295 Test RE 0.12543510510301406\n",
      "171 Train Loss 36616.84 Test MSE 5076.335953003576 Test RE 0.12465543537591504\n",
      "172 Train Loss 36253.5 Test MSE 5028.77312177695 Test RE 0.12407008022760724\n",
      "173 Train Loss 35786.63 Test MSE 4927.066836717609 Test RE 0.12280902081568153\n",
      "174 Train Loss 35212.234 Test MSE 4708.546035880402 Test RE 0.12005477891080617\n",
      "175 Train Loss 34701.64 Test MSE 4690.572334930232 Test RE 0.11982542022339442\n",
      "176 Train Loss 34287.688 Test MSE 4722.336842453158 Test RE 0.1202304638981015\n",
      "177 Train Loss 34099.56 Test MSE 4747.9978177150915 Test RE 0.12055668491521092\n",
      "178 Train Loss 33879.07 Test MSE 4766.118768348057 Test RE 0.12078652087761889\n",
      "179 Train Loss 33568.066 Test MSE 4791.55274262608 Test RE 0.12110837539284477\n",
      "180 Train Loss 33332.3 Test MSE 4765.903822922806 Test RE 0.12078379719362342\n",
      "181 Train Loss 32901.062 Test MSE 4702.7180959677635 Test RE 0.1199804578073379\n",
      "182 Train Loss 32435.973 Test MSE 4914.100989343129 Test RE 0.122647325021312\n",
      "183 Train Loss 32198.205 Test MSE 4900.023304902148 Test RE 0.12247152189059231\n",
      "184 Train Loss 31756.314 Test MSE 4865.583658526899 Test RE 0.12204036951628607\n",
      "185 Train Loss 31656.027 Test MSE 4833.948096645797 Test RE 0.12164297507376966\n",
      "186 Train Loss 31519.38 Test MSE 4899.364967689375 Test RE 0.12246329435128411\n",
      "187 Train Loss 31335.523 Test MSE 5014.362088507127 Test RE 0.12389217790347472\n",
      "188 Train Loss 31200.242 Test MSE 5025.740785801713 Test RE 0.1240326676330295\n",
      "189 Train Loss 31083.035 Test MSE 4920.35092342278 Test RE 0.12272529392399238\n",
      "190 Train Loss 30894.283 Test MSE 4924.916387249993 Test RE 0.12278221750400402\n",
      "191 Train Loss 30826.043 Test MSE 4901.806390776745 Test RE 0.12249380314970518\n",
      "192 Train Loss 30584.041 Test MSE 4676.180373606233 Test RE 0.1196414503844605\n",
      "193 Train Loss 30230.7 Test MSE 4515.418063728803 Test RE 0.11756688862224869\n",
      "194 Train Loss 29982.215 Test MSE 4500.0367780431825 Test RE 0.11736647833085459\n",
      "195 Train Loss 29778.545 Test MSE 4624.900927756667 Test RE 0.11898364216287233\n",
      "196 Train Loss 29454.342 Test MSE 4499.859969898522 Test RE 0.117364172621575\n",
      "197 Train Loss 29233.72 Test MSE 4439.4660415355 Test RE 0.11657392278740009\n",
      "198 Train Loss 29106.602 Test MSE 4530.280277592559 Test RE 0.1177602116759789\n",
      "199 Train Loss 29017.43 Test MSE 4392.552587361308 Test RE 0.11595634737345596\n",
      "Training time: 192.27\n",
      "Training time: 192.27\n",
      "ES_swish_high\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 250000.11 Test MSE 75079.916121626 Test RE 0.4793998912995487\n",
      "1 Train Loss 250000.06 Test MSE 75080.0608631161 Test RE 0.4794003534006323\n",
      "2 Train Loss 250000.06 Test MSE 75080.09705254165 Test RE 0.47940046893877314\n",
      "3 Train Loss 250000.06 Test MSE 75080.13072827543 Test RE 0.479400576451692\n",
      "4 Train Loss 250000.06 Test MSE 75080.16151903322 Test RE 0.47940067475403514\n",
      "5 Train Loss 250000.06 Test MSE 75080.1901215935 Test RE 0.4794007660703369\n",
      "6 Train Loss 250000.06 Test MSE 75080.2165119868 Test RE 0.479400850324077\n",
      "7 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "8 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "9 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "10 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "11 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "12 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "13 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "14 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "15 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "16 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "17 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "18 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "19 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "20 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "21 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "22 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "23 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "24 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "25 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "26 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "27 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "28 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "29 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "30 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "31 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "32 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "33 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "34 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "35 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "36 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "37 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "38 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "39 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "40 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "41 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "42 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "43 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "44 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "45 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "46 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "47 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "48 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "49 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "50 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "51 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "52 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "53 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "54 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "55 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "56 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "57 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "58 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "59 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "60 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "61 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "62 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "63 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "64 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "65 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "66 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "67 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "68 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "69 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "70 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "71 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "72 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "73 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "74 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "75 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "76 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "77 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "78 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "79 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "80 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "81 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "82 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "83 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "84 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "85 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "86 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "87 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "88 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "89 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "90 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "91 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "92 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "93 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "94 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "95 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "96 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "97 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "98 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "99 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "100 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "101 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "102 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "103 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "104 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "105 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "106 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "107 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "108 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "109 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "110 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "111 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "112 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "113 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "114 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "115 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "116 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "117 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "118 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "119 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "120 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "121 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "122 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "123 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "124 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "125 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "126 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "127 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "128 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "129 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "130 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "131 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "132 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "133 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "134 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "135 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "136 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "137 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "138 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "139 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "140 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "141 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "142 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "143 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "144 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "145 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "146 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "147 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "148 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "149 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "150 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "151 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "152 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "153 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "154 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "155 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "156 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "157 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "158 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "159 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "160 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "161 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "162 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "163 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "164 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "165 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "166 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "167 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "168 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "169 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "170 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "171 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "172 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "173 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "174 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "175 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "176 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "177 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "178 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "179 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "180 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "181 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "182 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "183 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "184 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "185 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "186 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "187 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "188 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "189 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "190 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "191 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "192 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "193 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "194 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "195 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "196 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "197 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "198 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "199 Train Loss 250000.03 Test MSE 75080.2639889475 Test RE 0.47940100189857143\n",
      "Training time: 57.34\n",
      "Training time: 57.34\n",
      "ES_swish_high\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 249997.56 Test MSE 75079.45496041827 Test RE 0.47939841899521113\n",
      "1 Train Loss 249997.56 Test MSE 75079.45491422934 Test RE 0.47939841884774803\n",
      "2 Train Loss 249997.56 Test MSE 75079.4549008899 Test RE 0.4793984188051605\n",
      "3 Train Loss 249997.56 Test MSE 75079.45416608822 Test RE 0.4793984164592273\n",
      "4 Train Loss 249997.56 Test MSE 75079.4536430911 Test RE 0.47939841478950296\n",
      "5 Train Loss 249997.56 Test MSE 75079.45343018626 Test RE 0.47939841410978135\n",
      "6 Train Loss 249997.56 Test MSE 75079.45359140511 Test RE 0.47939841462448984\n",
      "7 Train Loss 249997.56 Test MSE 75079.45226723167 Test RE 0.4793984103969242\n",
      "8 Train Loss 249997.56 Test MSE 75079.45255527647 Test RE 0.47939841131653815\n",
      "9 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "10 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "11 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "12 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "13 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "14 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "15 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "16 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "17 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "18 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "19 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "20 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "21 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "22 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "23 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "24 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "25 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "26 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "27 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "28 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "29 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "30 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "31 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "32 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "33 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "34 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "35 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "36 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "37 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "38 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "39 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "40 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "41 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "42 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "43 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "44 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "45 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "46 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "47 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "48 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "49 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "50 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "51 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "52 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "53 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "54 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "55 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "56 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "57 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "58 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "59 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "60 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "61 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "62 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "63 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "64 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "65 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "66 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "67 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "68 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "69 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "70 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "71 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "72 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "73 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "74 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "75 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "76 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "77 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "78 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "79 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "80 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "81 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "82 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "83 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "84 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "85 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "86 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "87 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "88 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "89 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "90 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "91 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "92 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "93 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "94 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "95 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "96 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "97 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "98 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "99 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "100 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "101 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "102 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "103 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "104 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "105 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "106 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "107 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "108 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "109 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "110 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "111 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "112 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "113 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "114 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "115 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "116 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "117 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "118 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "119 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "120 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "121 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "122 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "123 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "124 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "125 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "126 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "127 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "128 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "129 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "130 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "131 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "132 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "133 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "134 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "135 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "136 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "137 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "138 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "139 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "140 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "141 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "142 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "143 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "144 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "145 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "146 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "147 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "148 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "149 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "150 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "151 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "152 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "153 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "154 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "155 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "156 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "157 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "158 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "159 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "160 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "161 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "162 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "163 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "164 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "165 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "166 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "167 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "168 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "169 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "170 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "171 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "172 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "173 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "174 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "175 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "176 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "177 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "178 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "179 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "180 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "181 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "182 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "183 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "184 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "185 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "186 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "187 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "188 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "189 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "190 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "191 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "192 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "193 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "194 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "195 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "196 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "197 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "198 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "199 Train Loss 249997.53 Test MSE 75079.45186208084 Test RE 0.4793984091034365\n",
      "Training time: 30.23\n",
      "Training time: 30.23\n",
      "ES_swish_high\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 249997.36 Test MSE 75079.83939102945 Test RE 0.47939964632958254\n",
      "1 Train Loss 249205.75 Test MSE 75367.59485300336 Test RE 0.48031745556967004\n",
      "2 Train Loss 198961.52 Test MSE 56607.04199116287 Test RE 0.4162663189161533\n",
      "3 Train Loss 82268.945 Test MSE 15179.208025329704 Test RE 0.21555623939627414\n",
      "4 Train Loss 58245.016 Test MSE 12284.951968970629 Test RE 0.19392007625498106\n",
      "5 Train Loss 52801.715 Test MSE 9192.07595673095 Test RE 0.16774239674795402\n",
      "6 Train Loss 49957.59 Test MSE 8189.856407028276 Test RE 0.15833400072897091\n",
      "7 Train Loss 48223.15 Test MSE 8306.116805276775 Test RE 0.15945386806001333\n",
      "8 Train Loss 47652.953 Test MSE 8198.692532449548 Test RE 0.1584193918431606\n",
      "9 Train Loss 47228.043 Test MSE 7856.491111274195 Test RE 0.15507805791749088\n",
      "10 Train Loss 46637.55 Test MSE 7595.643902741641 Test RE 0.1524819158048788\n",
      "11 Train Loss 46207.17 Test MSE 7501.192532107378 Test RE 0.1515308984142861\n",
      "12 Train Loss 46044.227 Test MSE 7321.179142739517 Test RE 0.1497016402125321\n",
      "13 Train Loss 45919.3 Test MSE 7227.321084348099 Test RE 0.148738951772629\n",
      "14 Train Loss 45450.332 Test MSE 7194.924535004437 Test RE 0.14840521533278314\n",
      "15 Train Loss 45197.32 Test MSE 6997.73247234905 Test RE 0.146357407968205\n",
      "16 Train Loss 44987.91 Test MSE 6891.993702311656 Test RE 0.14524743704405163\n",
      "17 Train Loss 44711.438 Test MSE 6790.722718188942 Test RE 0.14417635463873052\n",
      "18 Train Loss 44527.6 Test MSE 6794.945140036992 Test RE 0.14422117157587808\n",
      "19 Train Loss 44380.75 Test MSE 6746.50494617096 Test RE 0.14370618604803057\n",
      "20 Train Loss 44238.83 Test MSE 6643.415263092417 Test RE 0.14260401126124927\n",
      "21 Train Loss 44135.242 Test MSE 6704.413826825609 Test RE 0.14325719666068276\n",
      "22 Train Loss 43942.832 Test MSE 6650.536039701449 Test RE 0.1426804161907304\n",
      "23 Train Loss 43852.977 Test MSE 6611.823679533403 Test RE 0.14226454316266596\n",
      "24 Train Loss 43698.96 Test MSE 6556.872633684195 Test RE 0.14167212746121133\n",
      "25 Train Loss 43348.207 Test MSE 6458.63995782302 Test RE 0.1406068825395441\n",
      "26 Train Loss 43000.81 Test MSE 6240.544526698886 Test RE 0.138212488024935\n",
      "27 Train Loss 42813.52 Test MSE 6236.152825421002 Test RE 0.13816384685386202\n",
      "28 Train Loss 42671.195 Test MSE 6193.6489006352695 Test RE 0.13769219818544615\n",
      "29 Train Loss 42563.945 Test MSE 6188.295814356528 Test RE 0.13763268257847944\n",
      "30 Train Loss 42392.184 Test MSE 6272.86444068391 Test RE 0.13856992854487668\n",
      "31 Train Loss 42204.273 Test MSE 6286.579155707071 Test RE 0.1387213274368224\n",
      "32 Train Loss 42033.92 Test MSE 6289.862035273767 Test RE 0.13875754315620376\n",
      "33 Train Loss 41938.66 Test MSE 6308.137352882897 Test RE 0.13895897832654955\n",
      "34 Train Loss 41816.68 Test MSE 6323.038957937465 Test RE 0.13912301172012906\n",
      "35 Train Loss 41705.0 Test MSE 6299.804069701901 Test RE 0.13886716301403615\n",
      "36 Train Loss 41444.066 Test MSE 6023.353664718434 Test RE 0.13578607151161845\n",
      "37 Train Loss 41362.516 Test MSE 5984.334052523068 Test RE 0.13534554213592287\n",
      "38 Train Loss 41211.28 Test MSE 6000.896248025431 Test RE 0.13553270335387285\n",
      "39 Train Loss 41086.293 Test MSE 5998.401950152734 Test RE 0.1355045330559797\n",
      "40 Train Loss 41058.543 Test MSE 5965.701962018488 Test RE 0.1351346802172108\n",
      "41 Train Loss 40922.49 Test MSE 5894.504734451209 Test RE 0.1343258824309807\n",
      "42 Train Loss 40802.77 Test MSE 5888.143377140329 Test RE 0.13425338052961247\n",
      "43 Train Loss 40702.887 Test MSE 5858.81848352819 Test RE 0.1339186502130962\n",
      "44 Train Loss 40563.707 Test MSE 5814.8279930888175 Test RE 0.13341494395078646\n",
      "45 Train Loss 40495.14 Test MSE 5814.0685411150425 Test RE 0.13340623126391274\n",
      "46 Train Loss 40467.62 Test MSE 5766.408867289343 Test RE 0.13285832054408733\n",
      "47 Train Loss 40437.24 Test MSE 5762.713267807703 Test RE 0.13281574033132823\n",
      "48 Train Loss 40380.18 Test MSE 5707.430095691183 Test RE 0.13217713750443227\n",
      "49 Train Loss 40361.15 Test MSE 5682.698516846311 Test RE 0.13189044995772228\n",
      "50 Train Loss 40324.59 Test MSE 5652.645402151691 Test RE 0.13154123441587987\n",
      "51 Train Loss 40271.0 Test MSE 5616.29400183215 Test RE 0.1311175902476325\n",
      "52 Train Loss 40224.176 Test MSE 5596.838198681968 Test RE 0.13089028634109817\n",
      "53 Train Loss 40179.42 Test MSE 5598.545119195565 Test RE 0.13091024424186992\n",
      "54 Train Loss 40123.305 Test MSE 5588.874920179572 Test RE 0.1307971367103044\n",
      "55 Train Loss 40094.277 Test MSE 5557.036354320781 Test RE 0.13042404363091514\n",
      "56 Train Loss 40052.71 Test MSE 5574.938120828143 Test RE 0.13063395258844637\n",
      "57 Train Loss 39955.824 Test MSE 5558.5693268290925 Test RE 0.1304420318780462\n",
      "58 Train Loss 39908.492 Test MSE 5566.695404168265 Test RE 0.13053734371664721\n",
      "59 Train Loss 39897.305 Test MSE 5574.499198576858 Test RE 0.1306288099952962\n",
      "60 Train Loss 39855.15 Test MSE 5559.954295414535 Test RE 0.1304582812809047\n",
      "61 Train Loss 39809.926 Test MSE 5572.147567438583 Test RE 0.13060125387137062\n",
      "62 Train Loss 39744.043 Test MSE 5578.539808581678 Test RE 0.1306761437957323\n",
      "63 Train Loss 39649.188 Test MSE 5536.340081920992 Test RE 0.13018094557282886\n",
      "64 Train Loss 39591.258 Test MSE 5503.618513899038 Test RE 0.12979566961789124\n",
      "65 Train Loss 39518.09 Test MSE 5496.9409415181735 Test RE 0.12971690479842607\n",
      "66 Train Loss 39458.84 Test MSE 5489.3952209709405 Test RE 0.1296278422033938\n",
      "67 Train Loss 39429.723 Test MSE 5474.004570353398 Test RE 0.12944599546971025\n",
      "68 Train Loss 39360.137 Test MSE 5454.624740320592 Test RE 0.1292166509690326\n",
      "69 Train Loss 39220.156 Test MSE 5406.1947881753385 Test RE 0.12864173434754494\n",
      "70 Train Loss 39078.68 Test MSE 5418.595824718909 Test RE 0.12878919269086395\n",
      "71 Train Loss 39036.29 Test MSE 5385.556760735063 Test RE 0.12839595609113305\n",
      "72 Train Loss 38941.637 Test MSE 5351.10128681958 Test RE 0.12798457410544734\n",
      "73 Train Loss 38799.605 Test MSE 5323.59342736052 Test RE 0.12765519164482658\n",
      "74 Train Loss 38659.836 Test MSE 5278.580484883128 Test RE 0.12711436016279298\n",
      "75 Train Loss 38462.715 Test MSE 5281.36752758712 Test RE 0.12714791335007186\n",
      "76 Train Loss 38143.31 Test MSE 5285.694034070558 Test RE 0.127199982596596\n",
      "77 Train Loss 38075.26 Test MSE 5287.0223392900425 Test RE 0.12721596439444763\n",
      "78 Train Loss 37915.547 Test MSE 5317.558667899525 Test RE 0.1275828169575146\n",
      "79 Train Loss 37544.16 Test MSE 5269.37510327659 Test RE 0.12700347364743406\n",
      "80 Train Loss 37286.61 Test MSE 5212.249106961959 Test RE 0.1263131668475071\n",
      "81 Train Loss 36984.33 Test MSE 5180.7684856210135 Test RE 0.12593113989290228\n",
      "82 Train Loss 36643.957 Test MSE 5175.170299134799 Test RE 0.12586308275453906\n",
      "83 Train Loss 35898.938 Test MSE 4865.124790250996 Test RE 0.12203461462866319\n",
      "84 Train Loss 35260.812 Test MSE 4846.177652992003 Test RE 0.12179675205584599\n",
      "85 Train Loss 34805.93 Test MSE 4762.907448601953 Test RE 0.12074582219619025\n",
      "86 Train Loss 34389.496 Test MSE 4734.949341407623 Test RE 0.12039091363828129\n",
      "87 Train Loss 33990.777 Test MSE 4678.797547218787 Test RE 0.11967492627951944\n",
      "88 Train Loss 33756.39 Test MSE 4717.658979206731 Test RE 0.12017090005956121\n",
      "89 Train Loss 32989.805 Test MSE 4504.375835754397 Test RE 0.11742304867089151\n",
      "90 Train Loss 32321.684 Test MSE 4609.777555011207 Test RE 0.11878894529894847\n",
      "91 Train Loss 31511.102 Test MSE 4313.045366527139 Test RE 0.11490212351179568\n",
      "92 Train Loss 30949.38 Test MSE 4180.139116374137 Test RE 0.11311791969140393\n",
      "93 Train Loss 30148.578 Test MSE 4083.400444522186 Test RE 0.1118013448571555\n",
      "94 Train Loss 29788.283 Test MSE 4133.896311654223 Test RE 0.1124904959399739\n",
      "95 Train Loss 29090.156 Test MSE 4232.733736071501 Test RE 0.11382732155050408\n",
      "96 Train Loss 28486.082 Test MSE 4140.092277151744 Test RE 0.11257476586477289\n",
      "97 Train Loss 27442.484 Test MSE 4244.514249497118 Test RE 0.1139856131703947\n",
      "98 Train Loss 27103.799 Test MSE 4356.685509833379 Test RE 0.11548196031776856\n",
      "99 Train Loss 26742.537 Test MSE 4832.7908080565385 Test RE 0.12162841301694191\n",
      "100 Train Loss 26393.062 Test MSE 4962.108643875206 Test RE 0.12324496228057988\n",
      "101 Train Loss 25543.545 Test MSE 4729.687960411335 Test RE 0.12032400705925783\n",
      "102 Train Loss 25013.916 Test MSE 4538.623648797266 Test RE 0.11786860068748571\n",
      "103 Train Loss 24859.588 Test MSE 4527.70121107813 Test RE 0.11772668674620419\n",
      "104 Train Loss 24234.803 Test MSE 4359.934589633112 Test RE 0.11552501370947402\n",
      "105 Train Loss 23911.066 Test MSE 4317.517121992751 Test RE 0.11496167320856711\n",
      "106 Train Loss 23808.129 Test MSE 4352.777493990308 Test RE 0.11543015412451509\n",
      "107 Train Loss 23411.201 Test MSE 4228.761885730765 Test RE 0.1137739032133488\n",
      "108 Train Loss 23251.076 Test MSE 4130.99689331546 Test RE 0.11245103991688293\n",
      "109 Train Loss 22859.332 Test MSE 4163.438226020292 Test RE 0.11289172378642667\n",
      "110 Train Loss 22668.244 Test MSE 4390.415372096005 Test RE 0.11592813441265025\n",
      "111 Train Loss 22538.074 Test MSE 4156.448805375167 Test RE 0.11279692483228287\n",
      "112 Train Loss 22467.797 Test MSE 4082.4330327377493 Test RE 0.11178810046112177\n",
      "113 Train Loss 22209.379 Test MSE 4054.9381388883867 Test RE 0.11141102206766525\n",
      "114 Train Loss 22002.299 Test MSE 3999.0562657414234 Test RE 0.11064067053517777\n",
      "115 Train Loss 21824.234 Test MSE 4068.8558672376976 Test RE 0.11160205582058609\n",
      "116 Train Loss 21767.188 Test MSE 4029.4994977199976 Test RE 0.11106100390302479\n",
      "117 Train Loss 21670.139 Test MSE 3935.273784424613 Test RE 0.10975479882765897\n",
      "118 Train Loss 21580.902 Test MSE 3957.8668780309113 Test RE 0.11006940864405697\n",
      "119 Train Loss 21571.277 Test MSE 3979.3815016170283 Test RE 0.11036816710234033\n",
      "120 Train Loss 21516.129 Test MSE 4011.5173769860885 Test RE 0.11081291534320654\n",
      "121 Train Loss 21398.578 Test MSE 3946.809440666195 Test RE 0.10991554585781103\n",
      "122 Train Loss 21316.59 Test MSE 4074.6908146736587 Test RE 0.11168204868064797\n",
      "123 Train Loss 21268.09 Test MSE 4105.6917889764145 Test RE 0.11210609212994767\n",
      "124 Train Loss 21242.008 Test MSE 4152.711112590686 Test RE 0.11274619702404956\n",
      "125 Train Loss 21208.81 Test MSE 4112.925955085435 Test RE 0.11220481327227277\n",
      "126 Train Loss 21176.389 Test MSE 4129.569270621136 Test RE 0.1124316073763729\n",
      "127 Train Loss 21141.326 Test MSE 4180.883071727739 Test RE 0.11312798525807533\n",
      "128 Train Loss 21088.838 Test MSE 4225.818101500083 Test RE 0.11373429538725324\n",
      "129 Train Loss 21002.666 Test MSE 4127.381868845533 Test RE 0.11240182634385519\n",
      "130 Train Loss 20967.125 Test MSE 4164.963131686663 Test RE 0.11291239581996435\n",
      "131 Train Loss 20948.484 Test MSE 4121.890488047365 Test RE 0.112327027513353\n",
      "132 Train Loss 20864.033 Test MSE 4168.622024979216 Test RE 0.11296198133855187\n",
      "133 Train Loss 20765.525 Test MSE 4224.456824159495 Test RE 0.11371597510157855\n",
      "134 Train Loss 20655.617 Test MSE 4129.870024297212 Test RE 0.11243570145996439\n",
      "135 Train Loss 20582.512 Test MSE 4231.167760797148 Test RE 0.11380626337958875\n",
      "136 Train Loss 20556.615 Test MSE 4168.655200906274 Test RE 0.11296243084092633\n",
      "137 Train Loss 20532.096 Test MSE 4144.14589648223 Test RE 0.1126298641053637\n",
      "138 Train Loss 20492.656 Test MSE 4185.30726561626 Test RE 0.1131878252243706\n",
      "139 Train Loss 20464.586 Test MSE 4248.317837213712 Test RE 0.1140366740418087\n",
      "140 Train Loss 20430.629 Test MSE 4266.115455350006 Test RE 0.11427529319047665\n",
      "141 Train Loss 20408.836 Test MSE 4303.763029068862 Test RE 0.11477841338783054\n",
      "142 Train Loss 20376.775 Test MSE 4352.127082866639 Test RE 0.11542152976212251\n",
      "143 Train Loss 20358.08 Test MSE 4345.4768531179125 Test RE 0.11533331161914907\n",
      "144 Train Loss 20338.027 Test MSE 4326.7619009057 Test RE 0.11508468684225959\n",
      "145 Train Loss 20332.639 Test MSE 4362.025682235018 Test RE 0.11555271418729965\n",
      "146 Train Loss 20318.895 Test MSE 4401.481363831404 Test RE 0.11607414023754745\n",
      "147 Train Loss 20274.887 Test MSE 4417.974232110196 Test RE 0.11629140862212867\n",
      "148 Train Loss 20257.316 Test MSE 4383.570306102482 Test RE 0.11583772778780559\n",
      "149 Train Loss 20236.197 Test MSE 4378.198284700645 Test RE 0.11576672704222883\n",
      "150 Train Loss 20200.75 Test MSE 4494.717012059811 Test RE 0.11729708480552828\n",
      "151 Train Loss 20143.156 Test MSE 4448.175191624914 Test RE 0.11668821157183122\n",
      "152 Train Loss 20109.475 Test MSE 4539.813101850117 Test RE 0.11788404479492362\n",
      "153 Train Loss 20083.283 Test MSE 4449.343315729279 Test RE 0.11670353216501504\n",
      "154 Train Loss 20070.67 Test MSE 4485.114248884668 Test RE 0.11717171780465217\n",
      "155 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "156 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "157 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "158 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "159 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "160 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "161 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "162 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "163 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "164 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "165 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "166 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "167 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "168 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "169 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "170 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "171 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "172 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "173 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "174 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "175 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "176 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "177 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "178 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "179 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "180 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "181 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "182 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "183 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "184 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "185 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "186 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "187 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "188 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "189 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "190 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "191 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "192 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "193 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "194 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "195 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "196 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "197 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "198 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "199 Train Loss 20070.098 Test MSE 4481.107352997396 Test RE 0.11711936687735017\n",
      "Training time: 163.98\n",
      "Training time: 163.98\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "max_iter = 200 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "N_T = 5000 #Total number of data points for 'y'\n",
    "N_f = 10000 #Total number of collocation points \n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.1, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-08, \n",
    "                              tolerance_change = 1e-08, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = PINN.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1541 into shape (500,500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2068/3689713413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflipud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1541 into shape (500,500)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "img3 = ax.imshow(np.transpose(np.flipud(np.transpose(u_pred.reshape(500,500)))),vmin = 0,vmax = 1000,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "for tune_reps in range(5):\n",
    "    label = \"MW_swish_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tune[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
