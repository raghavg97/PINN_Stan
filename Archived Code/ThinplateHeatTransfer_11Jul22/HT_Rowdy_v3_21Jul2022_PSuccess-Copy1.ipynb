{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "#device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "#     y = xt[:,0]*np.cos(xt[:,1])\n",
    "#     return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Material Properties This link - https://www.mathworks.com/help/pde/ug/nonlinear-heat-transfer-in-a-thin-plate.html#heatTransferThinPlateExample-1\n",
    "k = 400\n",
    "rho = 8960\n",
    "cp = 386\n",
    "t_z = 0.01\n",
    "stef_bolt = 5.670373e-8\n",
    "hc = 1\n",
    "Ta = 300\n",
    "emiss = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Heat_tanh\"\n",
    "\n",
    "x = np.linspace(0,1,100).reshape(-1,1)\n",
    "y = np.linspace(0,1,100).reshape(-1,1)\n",
    "t = np.linspace(0,1,100).reshape(-1,1) #t is actually from 0 to 5000, let us scale it to 0 to 1\n",
    "\n",
    "X,Y,T = np.meshgrid(x,y,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xyt = np.hstack((X,Y,T))\n",
    "\n",
    "initial_pts = np.logical_and(T==0,Y!=0).reshape(-1,)\n",
    "\n",
    "DBC_pts = (Y == 0).reshape(-1,)\n",
    "\n",
    "\n",
    "NBC_pts_x0 = (X == 0).reshape(-1,)\n",
    "NBC_pts_x1 = (X == 1).reshape(-1,)\n",
    "\n",
    "NBC_pts_y0 = (Y == 0).reshape(-1,)\n",
    "NBC_pts_y1 = (Y == 1).reshape(-1,)\n",
    "\n",
    "xyt_initial = xyt[initial_pts,:]\n",
    "xyt_DBC = xyt[DBC_pts,:]\n",
    "\n",
    "xyt_NBC_x0 = xyt[NBC_pts_x0,:]\n",
    "xyt_NBC_x1 = xyt[NBC_pts_x1,:]\n",
    "\n",
    "#xyt_NBC_y0 = xyt[NBC_pts_y0,:]\n",
    "xyt_NBC_y1 = xyt[NBC_pts_y1,:]\n",
    "\n",
    "u_initial = 300*np.ones((np.shape(xyt_initial)[0],1))\n",
    "u_DBC = 1000*np.ones((np.shape(xyt_DBC)[0],1))\n",
    "\n",
    "xyt_I_DBC = np.vstack((xyt_initial,xyt_DBC))\n",
    "#xyt_NBC = np.vstack((xyt_NBC_1,xyt_NBC_2,xyt_NBC_3,xyt_NBC_4))\n",
    "xyt_NBC_x = np.vstack((xyt_NBC_x0,xyt_NBC_x1))\n",
    "#xyt_NBC_y = np.vstack((xyt_NBC_y0,xyt_NBC_y1))\n",
    "xyt_NBC_y = np.vstack((xyt_NBC_y1))\n",
    "\n",
    "u_I_DBC = np.vstack((u_initial,u_DBC))\n",
    "\n",
    "xyt_test_tensor = torch.from_numpy(xyt).float().to(device)\n",
    "\n",
    "lb_xyt = xyt[0]\n",
    "ub_xyt = xyt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_D,N_N,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    #choose random N_u points for training\n",
    "    idx = np.random.choice(xyt_I_DBC.shape[0], N_D, replace=False) \n",
    "    xyt_D = xyt_I_DBC[idx,:] #choose indices from  set 'idx' (x,t)\n",
    "    u_D = u_I_DBC[idx].reshape(-1,1)      #choose corresponding u\n",
    "\n",
    "    idx = np.random.choice(xyt_NBC_x.shape[0], N_D, replace=False) \n",
    "    xyt_Nx = xyt_NBC_x[idx,:] #choose indices from  set 'idx' (x,t)\n",
    "\n",
    "    idx = np.random.choice(xyt_NBC_y.shape[0], N_D, replace=False) \n",
    "    xyt_Ny = xyt_NBC_y[idx,:] #choose indices from  set 'idx' (x,t)\n",
    "\n",
    "    '''Collocation Points'''\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xyt_coll = lb_xyt + (ub_xyt - lb_xyt)*samples\n",
    "    xyt_coll = np.vstack((xyt_coll, xyt_D,xyt_Nx,xyt_Ny)) # append training points to collocation points \n",
    "\n",
    "    return xyt_coll, xyt_D, u_D, xyt_Nx,xyt_Ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "        \n",
    "#         self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "#         self.beta.requiresGrad = True\n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(5,len(layers)-2))\n",
    "        self.omega = Parameter(torch.ones(5,len(layers)-2))\n",
    "        \n",
    "    \n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        \n",
    "        self.beta_val = []\n",
    "        \n",
    "        self.n = torch.tensor(1.0)\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xyt):\n",
    "        if torch.is_tensor(xyt) != True:         \n",
    "            xyt = torch.from_numpy(xyt)                \n",
    "        \n",
    "        ubxyt = torch.from_numpy(ub_xyt).float().to(device)\n",
    "        lbxyt = torch.from_numpy(lb_xyt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xyt = (xyt - lbxyt)/(ubxyt - lbxyt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xyt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "            #print(z.shape)\n",
    "            #z2 = torch.zeros(z1.shape).to(device)\n",
    "            for j in range(5):\n",
    "                #print(j)\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "                \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_D(self,xyt_D,u_D):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xyt_D), u_D)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_N(self,xyt_Nx,xyt_Ny,N_hat):\n",
    "        \n",
    "        g1 = xyt_Nx.clone()             \n",
    "        g1.requires_grad = True\n",
    "        u1 = self.forward(g1)\n",
    "        \n",
    "        u1_x_y_t = autograd.grad(u1,g1,torch.ones([xyt_Nx.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        du1_dx = u1_x_y_t[:,[0]]\n",
    "        \n",
    "        g2 = xyt_Ny.clone()             \n",
    "        g2.requires_grad = True\n",
    "        u2 = self.forward(g2)\n",
    "        \n",
    "        u2_x_y_t = autograd.grad(u2,g2,torch.ones([xyt_Ny.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        du2_dy = u2_x_y_t[:,[1]]\n",
    "               \n",
    "        loss_N1 = self.loss_function(du1_dx,N_hat)\n",
    "        loss_N2 = self.loss_function(du2_dy,N_hat)\n",
    "        \n",
    "        #return loss_N1+loss_N2       \n",
    "        return loss_N1 + loss_N2\n",
    "    \n",
    "    def loss_PDE(self, xyt_coll, f_hat):\n",
    "        \n",
    "        g = xyt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y_t = autograd.grad(u,g,torch.ones([xyt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy_tt = autograd.grad(u_x_y_t,g,torch.ones(xyt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        du_dt = u_x_y_t[:,[2]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy_tt[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = rho*cp*t_z*du_dt/3000 - k*t_z*(d2u_dx2+d2u_dy2) + 2*hc*(u-Ta) + 2*emiss*stef_bolt*(torch.pow(u,4)-Ta**4) \n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xyt_D,u_D,xyt_Nx,xyt_Ny,N_hat,xyt_coll,f_hat):\n",
    "\n",
    "        loss_D = self.loss_D(xyt_D,u_D)\n",
    "        loss_N = self.loss_N(xyt_Nx,xyt_Ny,N_hat)\n",
    "        loss_f = self.loss_PDE(xyt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_D + loss_N + loss_f\n",
    "        \n",
    "        #print(self.iter,\"loss_D:\",loss_D.cpu().detach().numpy(),\"loss_N:\",loss_N.cpu().detach().numpy(),\"loss_f:\",loss_f.cpu().detach().numpy())\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    'callable for optimizer'                                       \n",
    "    def closure(self):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = self.loss(xyt_D,u_D,xyt_Nx,xyt_Ny,N_hat,xyt_coll,f_hat)\n",
    "        self.train_loss.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        #u_pred = self.test(xyt_test_tensor)\n",
    "        #self.test_loss.append(np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))) #Commented because no true values yet\n",
    "        #self.beta_val.append(self.alpha.cpu().detach().numpy())\n",
    "        \n",
    "        #print(self.iter,\"Train Loss\",self.train_loss[-1],\"Test Loss\",self.test_loss[-1])\n",
    "        print(self.iter,\"Train Loss\",self.train_loss[-1])\n",
    "        \n",
    "        loss.backward()\n",
    "        self.iter += 1\n",
    "  \n",
    "\n",
    "        return loss        \n",
    "    'test neural network'\n",
    "    def test(self,xyt_test_tensor):\n",
    "        u_pred = self.forward(xyt_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_reps = 1\n",
    "\n",
    "train_loss_full = []\n",
    "test_loss_full = []\n",
    "#alpha_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "#for reps in range(max_reps):\n",
    "for reps in range(8,9):\n",
    "    print(reps)\n",
    "    \n",
    "    torch.manual_seed(reps*36)\n",
    "    N_D = 5000 #Total number of data points for 'y'\n",
    "    N_N = 3500\n",
    "    N_f = 10000#Total number of collocation points \n",
    "    \n",
    "    xyt_coll_np_array, xyt_D_np_array, u_D_np_array,xyt_Nx_np_array,xyt_Ny_np_array = trainingdata(N_D,N_N,N_f,(reps)*22)\n",
    "        \n",
    "    xyt_coll = torch.from_numpy(xyt_coll_np_array).float().to(device)\n",
    "    xyt_D = torch.from_numpy(xyt_D_np_array).float().to(device)\n",
    "    u_D = torch.from_numpy(u_D_np_array).float().to(device)\n",
    "    xyt_Nx = torch.from_numpy(xyt_Nx_np_array).float().to(device)\n",
    "    xyt_Ny = torch.from_numpy(xyt_Ny_np_array).float().to(device)\n",
    "        \n",
    "    N_hat = torch.zeros(xyt_Nx.shape[0],1).to(device)    \n",
    "    f_hat = torch.zeros(xyt_coll.shape[0],1).to(device)\n",
    "\n",
    "    layers = np.array([3,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "    #layers = np.array([3,100,100,100,100,100,100,100,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "   \n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                              max_iter = 10000, \n",
    "                              max_eval = None, \n",
    "                              tolerance_grad = -1, \n",
    "                              tolerance_change = -1, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "        \n",
    "    optimizer.step(PINN.closure)\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(PINN.train_loss)\n",
    "    test_loss_full.append(PINN.test_loss)\n",
    "    elapsed_time[reps] = time.time() - start_time\n",
    "    #alpha_full.append(PINN.alpha_val)\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "    \n",
    "mdic = {\"train_loss\": train_loss_full,\"test_loss\": test_loss_full,\"Time\": elapsed_time,  \"label\": label}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = np.array([3,50,50,50,50,50,50,50,50,50,1])\n",
    "model_pinn = Sequentialmodel(layers)\n",
    "model_pinn.load_state_dict(torch.load('Heat_rowdy_8.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xyt_Nx\n",
    "del xyt_Ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xyt_test_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xyt_test_tensor = torch.from_numpy(xyt[1:50000,:]).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = model_pinn.test(xyt_test_tensor)\n",
    "#u_pred2 = PINN.test(xyt_test_tensor[200000:,:])\n",
    "\n",
    "#u_pred = np.vstack((u_pred1,u_pred2))\n",
    "\n",
    "u_pred_3d = u_pred.reshape(100,100,100,order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f2d1d7161d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "img3 = ax.imshow(np.flipud(u_pred_3d[:,:,50]),vmax =1000,vmin=450,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n",
    "fig.colorbar(img3, orientation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_video():\n",
    "    for i in range(100):\n",
    "        #plt.imshow(img[i], cmap=cm.Greys_r)\n",
    "        img3 = ax.imshow(np.flipud(u_pred_3d[:,:,i]),vmax =1000,vmin=450,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n",
    "        \n",
    "        plt.savefig(\"stan_heat_%02d.png\" % i)\n",
    "\n",
    "    #os.chdir()\n",
    "    subprocess.call(['ffmpeg', '-framerate', '8', '-i', 'stan_heat_%02d.png', '-r', '10', '-pix_fmt', 'yuv420p','Stan_transient.mp4'])\n",
    "    for file_name in glob.glob(\"*.png\"):\n",
    "        os.remove(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "# img = [] # some array of images\n",
    "frames = [] # for storing the generated images\n",
    "# fig = plt.figure()\n",
    "for i in range(100):\n",
    "#     p1 = ax.imshow(np.flipud(u_pred_3d[:,:,i]),vmax =1000,vmin=450,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n",
    "#     fig.colorbar(p1, orientation='vertical',ax=ax)\n",
    "    frames.append([plt.imshow(np.flipud(u_pred_3d[:,:,i]),vmax =1000,vmin=450,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)])\n",
    "    print(i)\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, frames, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "#ani.save('movie.mp4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writergif = animation.PillowWriter(fps=10)\n",
    "ani.save('rowdy_Thinplate_movie.gif',writer=writergif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writervideo = animation.FFMpegWriter(fps=60) \n",
    "ani.save('Stan_Thinplate_movie1.gif',writer=writervideo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(u_pred_3d[:,:,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(u_pred_3d[50,99,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + train_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
