{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "#     y = xt[:,0]*np.cos(xt[:,1])\n",
    "#     return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Material Properties This link - https://www.mathworks.com/help/pde/ug/nonlinear-heat-transfer-in-a-thin-plate.html#heatTransferThinPlateExample-1\n",
    "k = 400\n",
    "rho = 8960\n",
    "cp = 386\n",
    "t_z = 0.01\n",
    "stef_bolt = 5.670373e-8\n",
    "hc = 1\n",
    "Ta = 300\n",
    "emiss = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Navier_tanh\"\n",
    "\n",
    "x = np.linspace(0,1,100).reshape(-1,1)\n",
    "y = np.linspace(0,1,100).reshape(-1,1)\n",
    "t = np.linspace(0,5000,100).reshape(-1,1)\n",
    "\n",
    "X,Y,T = np.meshgrid(x,y,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xyt = np.hstack((X,Y,T))\n",
    "\n",
    "initial_pts = (T==0).reshape(-1,)\n",
    "\n",
    "DBC_pts = np.logical_and(Y == 0,T != 0).reshape(-1,)\n",
    "\n",
    "\n",
    "NBC_pts_1 = (X == 0).reshape(-1,)\n",
    "NBC_pts_2 = (Y == 0).reshape(-1,)\n",
    "NBC_pts_3 = (X == 1).reshape(-1,)\n",
    "NBC_pts_4 = (Y == 1).reshape(-1,)\n",
    "\n",
    "xyt_initial = xyt[initial_pts,:]\n",
    "xyt_DBC = xyt[DBC_pts,:]\n",
    "\n",
    "xyt_NBC_1 = xyt[NBC_pts_1,:]\n",
    "xyt_NBC_2 = xyt[NBC_pts_2,:]\n",
    "xyt_NBC_3 = xyt[NBC_pts_3,:]\n",
    "xyt_NBC_4 = xyt[NBC_pts_4,:]\n",
    "\n",
    "u_initial = np.zeros((np.shape(xyt_initial)[0],1))\n",
    "u_DBC = 10*np.ones((np.shape(xyt_DBC)[0],1))\n",
    "\n",
    "xyt_I_DBC = np.vstack((xyt_initial,xyt_DBC))\n",
    "xyt_NBC = np.vstack((xyt_NBC_1,xyt_NBC_2,xyt_NBC_3,xyt_NBC_4))\n",
    "\n",
    "u_I_DBC = np.vstack((u_initial,u_DBC))\n",
    "\n",
    "xyt_test_tensor = torch.from_numpy(xyt).float().to(device)\n",
    "\n",
    "lb_xyt = xyt[0]\n",
    "ub_xyt = xyt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_D,N_N,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    #choose random N_u points for training\n",
    "    idx = np.random.choice(xyt_I_DBC.shape[0], N_D, replace=False) \n",
    "    xyt_D = xyt_I_DBC[idx,:] #choose indices from  set 'idx' (x,t)\n",
    "    u_D = u_I_DBC[idx].reshape(-1,1)      #choose corresponding u\n",
    "\n",
    "    idx = np.random.choice(xyt_NBC.shape[0], N_D, replace=False) \n",
    "    xyt_N = xyt_NBC[idx,:] #choose indices from  set 'idx' (x,t)\n",
    "\n",
    "\n",
    "    '''Collocation Points'''\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xyt_coll = lb_xyt + (ub_xyt - lb_xyt)*samples\n",
    "    xyt_coll = np.vstack((xyt_coll, xyt_D,xyt_N)) # append training points to collocation points \n",
    "\n",
    "    return xyt_coll, xyt_D, u_D, xyt_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        \n",
    "        #self.beta_val = []\n",
    "        \n",
    "        self.n = torch.tensor(1.0)\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xyt):\n",
    "        if torch.is_tensor(xyt) != True:         \n",
    "            xyt = torch.from_numpy(xyt)                \n",
    "        \n",
    "        ubxyt = torch.from_numpy(ub_xyt).float().to(device)\n",
    "        lbxyt = torch.from_numpy(lb_xyt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xyt = (xyt - lbxyt)/(ubxyt - lbxyt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xyt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            #a = self.activation(z) + self.beta[:,i]*z*self.activation(z)\n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_D(self,xyt_D,u_D):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xyt_D), u_D)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_N(self,xyt_N,N_hat):\n",
    "        \n",
    "        g = xyt_N.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g)\n",
    "        \n",
    "        u_x_y_t = autograd.grad(u,g,torch.ones([xyt_N.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        du_dx = u_x_y_t[:,[0]]\n",
    "        du_dy = u_x_y_t[:,[1]]\n",
    "        \n",
    "        loss_N1 = self.loss_function(du_dx,N_hat)\n",
    "        loss_N2 = self.loss_function(du_dy,N_hat)\n",
    "        \n",
    "        return loss_N1+loss_N2       \n",
    "        \n",
    "    \n",
    "    def loss_PDE(self, xyt_coll, f_hat):\n",
    "        \n",
    "        g = xyt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y_t = autograd.grad(u,g,torch.ones([xyt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy_tt = autograd.grad(u_x_y_t,g,torch.ones(xyt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        du_dt = u_x_y_t[:,[2]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy_tt[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = rho*cp*t_z*du_dt - k*t_z*(d2u_dx2+d2u_dy2) + 2*hc*(u-Ta) + 2*emiss*stef_bolt*(torch.pow(u,4)-Ta**4) \n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xyt_D,u_D,xyt_N,N_hat,xyt_coll,f_hat):\n",
    "\n",
    "        loss_D = self.loss_D(xyt_D,u_D)\n",
    "        loss_N = self.loss_N(xyt_N,N_hat)\n",
    "        loss_f = self.loss_PDE(xyt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_D + loss_N + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    'callable for optimizer'                                       \n",
    "    def closure(self):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = self.loss(xyt_D,u_D,xyt_N,N_hat,xyt_coll,f_hat)\n",
    "        self.train_loss.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        u_pred = self.test(xyt_test_tensor)\n",
    "        #self.test_loss.append(np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))) #Commented because no true values yet\n",
    "        #self.beta_val.append(self.beta.cpu().detach().numpy())\n",
    "        \n",
    "        #print(self.iter,\"Train Loss\",self.train_loss[-1],\"Test Loss\",self.test_loss[-1])\n",
    "        print(self.iter,\"Train Loss\",self.train_loss[-1])\n",
    "        \n",
    "        loss.backward()\n",
    "        self.iter += 1\n",
    "  \n",
    "\n",
    "        return loss        \n",
    "    'test neural network'\n",
    "    def test(self,xyt_test_tensor):\n",
    "        u_pred = self.forward(xyt_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0 Train Loss 1122968.0\n",
      "1 Train Loss 1121611.9\n",
      "2 Train Loss 1110361.1\n",
      "3 Train Loss 1084560.9\n",
      "4 Train Loss 1000752.7\n",
      "5 Train Loss 3233781.0\n",
      "6 Train Loss 990101.3\n",
      "7 Train Loss 954020.3\n",
      "8 Train Loss 918187.4\n",
      "9 Train Loss 880274.2\n",
      "10 Train Loss 842570.75\n",
      "11 Train Loss 903557.5\n",
      "12 Train Loss 975340.1\n",
      "13 Train Loss 787420.56\n",
      "14 Train Loss 711119.56\n",
      "15 Train Loss 665272.6\n",
      "16 Train Loss 597012.6\n",
      "17 Train Loss 569489.7\n",
      "18 Train Loss 1099622.1\n",
      "19 Train Loss 536149.2\n",
      "20 Train Loss 2467517.5\n",
      "21 Train Loss 492776.88\n",
      "22 Train Loss 434246.6\n",
      "23 Train Loss 489785.66\n",
      "24 Train Loss 419754.38\n",
      "25 Train Loss 401532.25\n",
      "26 Train Loss 386450.44\n",
      "27 Train Loss 341632.97\n",
      "28 Train Loss 321689.72\n",
      "29 Train Loss 294928.62\n",
      "30 Train Loss 799853.2\n",
      "31 Train Loss 360501.8\n",
      "32 Train Loss 275304.94\n",
      "33 Train Loss 254854.89\n",
      "34 Train Loss 212871.4\n",
      "35 Train Loss 207783.1\n",
      "36 Train Loss 200794.25\n",
      "37 Train Loss 235093.83\n",
      "38 Train Loss 194303.39\n",
      "39 Train Loss 188409.97\n",
      "40 Train Loss 181472.95\n",
      "41 Train Loss 173308.08\n",
      "42 Train Loss 153501.34\n",
      "43 Train Loss 129229.35\n",
      "44 Train Loss 99691.6\n",
      "45 Train Loss 98893.336\n",
      "46 Train Loss 94095.96\n",
      "47 Train Loss 89179.96\n",
      "48 Train Loss 82658.086\n",
      "49 Train Loss 75651.586\n",
      "50 Train Loss 63599.934\n",
      "51 Train Loss 53533.547\n",
      "52 Train Loss 46563.305\n",
      "53 Train Loss 42728.35\n",
      "54 Train Loss 36845.36\n",
      "55 Train Loss 30693.936\n",
      "56 Train Loss 28065.197\n",
      "57 Train Loss 25591.695\n",
      "58 Train Loss 21775.37\n",
      "59 Train Loss 20295.705\n",
      "60 Train Loss 18516.156\n",
      "61 Train Loss 16608.473\n",
      "62 Train Loss 15329.193\n",
      "63 Train Loss 13708.794\n",
      "64 Train Loss 12125.354\n",
      "65 Train Loss 10710.93\n",
      "66 Train Loss 9928.493\n",
      "67 Train Loss 8777.803\n",
      "68 Train Loss 8420.373\n",
      "69 Train Loss 7919.8545\n",
      "70 Train Loss 7748.4473\n",
      "71 Train Loss 7615.343\n",
      "72 Train Loss 7474.0605\n",
      "73 Train Loss 7293.8193\n",
      "74 Train Loss 6416.5625\n",
      "75 Train Loss 5493.5933\n",
      "76 Train Loss 4731.388\n",
      "77 Train Loss 4419.762\n",
      "78 Train Loss 4318.221\n",
      "79 Train Loss 4238.0703\n",
      "80 Train Loss 4163.2417\n",
      "81 Train Loss 4126.6816\n",
      "82 Train Loss 4037.539\n",
      "83 Train Loss 3905.2886\n",
      "84 Train Loss 3794.8892\n",
      "85 Train Loss 3513.3164\n",
      "86 Train Loss 3273.001\n",
      "87 Train Loss 3211.8232\n",
      "88 Train Loss 3169.8123\n",
      "89 Train Loss 3048.1187\n",
      "90 Train Loss 2954.272\n",
      "91 Train Loss 2865.3384\n",
      "92 Train Loss 2789.5452\n",
      "93 Train Loss 2754.138\n",
      "94 Train Loss 2722.6287\n",
      "95 Train Loss 2666.115\n",
      "96 Train Loss 2606.1548\n",
      "97 Train Loss 2505.2537\n",
      "98 Train Loss 2409.295\n",
      "99 Train Loss 2363.188\n",
      "100 Train Loss 2282.4424\n",
      "101 Train Loss 2233.2646\n",
      "102 Train Loss 2166.267\n",
      "103 Train Loss 2141.6958\n",
      "104 Train Loss 2122.472\n",
      "105 Train Loss 2105.665\n",
      "106 Train Loss 2094.9666\n",
      "107 Train Loss 2074.0305\n",
      "108 Train Loss 2046.3337\n",
      "109 Train Loss 2026.7256\n",
      "110 Train Loss 2012.2458\n",
      "111 Train Loss 1989.1511\n",
      "112 Train Loss 1937.406\n",
      "113 Train Loss 1846.9272\n",
      "114 Train Loss 1806.9625\n",
      "115 Train Loss 1786.9841\n",
      "116 Train Loss 1771.0691\n",
      "117 Train Loss 1754.844\n",
      "118 Train Loss 1736.5931\n",
      "119 Train Loss 1700.4556\n",
      "120 Train Loss 1650.95\n",
      "121 Train Loss 1624.3329\n",
      "122 Train Loss 1608.485\n",
      "123 Train Loss 1581.896\n",
      "124 Train Loss 1566.2971\n",
      "125 Train Loss 1550.2004\n",
      "126 Train Loss 1536.7212\n",
      "127 Train Loss 1530.6285\n",
      "128 Train Loss 1526.1301\n",
      "129 Train Loss 1519.1277\n",
      "130 Train Loss 1511.7178\n",
      "131 Train Loss 1502.662\n",
      "132 Train Loss 1483.5363\n",
      "133 Train Loss 1430.4303\n",
      "134 Train Loss 1391.0342\n",
      "135 Train Loss 1368.97\n",
      "136 Train Loss 1362.5415\n",
      "137 Train Loss 1351.6099\n",
      "138 Train Loss 1347.2449\n",
      "139 Train Loss 1344.8827\n",
      "140 Train Loss 1341.8024\n",
      "141 Train Loss 1338.8608\n",
      "142 Train Loss 1325.4277\n",
      "143 Train Loss 1307.7534\n",
      "144 Train Loss 1292.1971\n",
      "145 Train Loss 1319.3468\n",
      "146 Train Loss 1286.6864\n",
      "147 Train Loss 1279.8649\n",
      "148 Train Loss 1277.8849\n",
      "149 Train Loss 1276.2609\n",
      "150 Train Loss 1273.8884\n",
      "151 Train Loss 1268.1918\n",
      "152 Train Loss 1261.0375\n",
      "153 Train Loss 1254.8373\n",
      "154 Train Loss 1252.6206\n",
      "155 Train Loss 1251.3698\n",
      "156 Train Loss 1250.0663\n",
      "157 Train Loss 1247.1245\n",
      "158 Train Loss 1243.4448\n",
      "159 Train Loss 1240.6631\n",
      "160 Train Loss 1237.6953\n",
      "161 Train Loss 1236.2128\n",
      "162 Train Loss 1235.0408\n",
      "163 Train Loss 1234.2146\n",
      "164 Train Loss 1233.189\n",
      "165 Train Loss 1230.7638\n",
      "166 Train Loss 1227.9731\n",
      "167 Train Loss 1225.065\n",
      "168 Train Loss 1221.2672\n",
      "169 Train Loss 1218.0613\n",
      "170 Train Loss 1215.8888\n",
      "171 Train Loss 1214.1884\n",
      "172 Train Loss 1212.3876\n",
      "173 Train Loss 1207.4825\n",
      "174 Train Loss 1199.9327\n",
      "175 Train Loss 1192.5796\n",
      "176 Train Loss 1184.183\n",
      "177 Train Loss 1178.4868\n",
      "178 Train Loss 1174.7809\n",
      "179 Train Loss 1172.9944\n",
      "180 Train Loss 1171.0602\n",
      "181 Train Loss 1169.9553\n",
      "182 Train Loss 1168.3032\n",
      "183 Train Loss 1166.6901\n",
      "184 Train Loss 1165.2051\n",
      "185 Train Loss 1163.1882\n",
      "186 Train Loss 1160.6216\n",
      "187 Train Loss 1154.9894\n",
      "188 Train Loss 1149.2106\n",
      "189 Train Loss 1162.8398\n",
      "190 Train Loss 1146.0206\n",
      "191 Train Loss 1141.2991\n",
      "192 Train Loss 1138.1956\n",
      "193 Train Loss 1136.6547\n",
      "194 Train Loss 1133.9623\n",
      "195 Train Loss 1130.5017\n",
      "196 Train Loss 1127.3893\n",
      "197 Train Loss 1125.2526\n",
      "198 Train Loss 1123.1128\n",
      "199 Train Loss 1121.7708\n",
      "200 Train Loss 1121.2477\n",
      "201 Train Loss 1120.9325\n",
      "202 Train Loss 1120.7291\n",
      "203 Train Loss 1119.9489\n",
      "204 Train Loss 1118.5527\n",
      "205 Train Loss 1115.9998\n",
      "206 Train Loss 1112.7241\n",
      "207 Train Loss 1110.7847\n",
      "208 Train Loss 1108.2148\n",
      "209 Train Loss 1106.7212\n",
      "210 Train Loss 1105.0328\n",
      "211 Train Loss 1103.7997\n",
      "212 Train Loss 1102.5791\n",
      "213 Train Loss 1101.4595\n",
      "214 Train Loss 1096.4813\n",
      "215 Train Loss 1090.1638\n",
      "216 Train Loss 1085.107\n",
      "217 Train Loss 1081.6469\n",
      "218 Train Loss 1079.2101\n",
      "219 Train Loss 1077.7028\n",
      "220 Train Loss 1076.7295\n",
      "221 Train Loss 1076.0424\n",
      "222 Train Loss 1075.5099\n",
      "223 Train Loss 1072.659\n",
      "224 Train Loss 1072.359\n",
      "225 Train Loss 1071.609\n",
      "226 Train Loss 1070.1613\n",
      "227 Train Loss 1068.9382\n",
      "228 Train Loss 1068.3214\n",
      "229 Train Loss 1067.6487\n",
      "230 Train Loss 1066.5356\n",
      "231 Train Loss 1066.3154\n",
      "232 Train Loss 1063.7926\n",
      "233 Train Loss 1062.732\n",
      "234 Train Loss 1061.2759\n",
      "235 Train Loss 1059.061\n",
      "236 Train Loss 1055.0128\n",
      "237 Train Loss 1052.8048\n",
      "238 Train Loss 1049.9241\n",
      "239 Train Loss 1048.0403\n",
      "240 Train Loss 1044.8947\n",
      "241 Train Loss 1043.079\n",
      "242 Train Loss 1041.55\n",
      "243 Train Loss 1039.9696\n",
      "244 Train Loss 1039.2863\n",
      "245 Train Loss 1037.4952\n",
      "246 Train Loss 1036.8728\n",
      "247 Train Loss 1036.0599\n",
      "248 Train Loss 1034.245\n",
      "249 Train Loss 1033.251\n",
      "250 Train Loss 1032.0992\n",
      "251 Train Loss 1031.296\n",
      "252 Train Loss 1030.3276\n",
      "253 Train Loss 1028.8845\n",
      "254 Train Loss 1027.8053\n",
      "255 Train Loss 1027.1718\n",
      "256 Train Loss 1026.4644\n",
      "257 Train Loss 1025.4988\n",
      "258 Train Loss 1024.4625\n",
      "259 Train Loss 1023.5783\n",
      "260 Train Loss 1021.8228\n",
      "261 Train Loss 1019.3314\n",
      "262 Train Loss 1017.1792\n",
      "263 Train Loss 1017.4448\n",
      "264 Train Loss 1016.06067\n",
      "265 Train Loss 1017.0593\n",
      "266 Train Loss 1015.11597\n",
      "267 Train Loss 1013.76776\n",
      "268 Train Loss 1013.1655\n",
      "269 Train Loss 1011.7584\n",
      "270 Train Loss 1010.81024\n",
      "271 Train Loss 1009.64636\n",
      "272 Train Loss 1008.9962\n",
      "273 Train Loss 1008.4042\n",
      "274 Train Loss 1007.69366\n",
      "275 Train Loss 1007.32574\n",
      "276 Train Loss 1006.82385\n",
      "277 Train Loss 1006.2367\n",
      "278 Train Loss 1005.7473\n",
      "279 Train Loss 1005.0006\n",
      "280 Train Loss 1004.46844\n",
      "281 Train Loss 1004.11365\n",
      "282 Train Loss 1003.78375\n",
      "283 Train Loss 1003.4713\n",
      "284 Train Loss 1003.0283\n",
      "285 Train Loss 1002.6487\n",
      "286 Train Loss 1002.281\n",
      "287 Train Loss 1001.70215\n",
      "288 Train Loss 1000.4844\n",
      "289 Train Loss 999.2144\n",
      "290 Train Loss 996.4902\n",
      "291 Train Loss 994.0659\n",
      "292 Train Loss 991.89343\n",
      "293 Train Loss 991.28876\n",
      "294 Train Loss 990.9042\n",
      "295 Train Loss 990.5865\n",
      "296 Train Loss 990.3485\n",
      "297 Train Loss 990.1216\n",
      "298 Train Loss 989.9607\n",
      "299 Train Loss 989.63104\n",
      "300 Train Loss 989.12366\n",
      "301 Train Loss 988.5752\n",
      "302 Train Loss 988.0383\n",
      "303 Train Loss 987.4486\n",
      "304 Train Loss 986.518\n",
      "305 Train Loss 985.5815\n",
      "306 Train Loss 984.9035\n",
      "307 Train Loss 986.64374\n",
      "308 Train Loss 983.59125\n",
      "309 Train Loss 982.4659\n",
      "310 Train Loss 981.1221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 Train Loss 980.80334\n",
      "312 Train Loss 979.9132\n",
      "313 Train Loss 979.2357\n",
      "314 Train Loss 978.8792\n",
      "315 Train Loss 978.46564\n",
      "316 Train Loss 978.2256\n",
      "317 Train Loss 977.82196\n",
      "318 Train Loss 977.48425\n",
      "319 Train Loss 977.0516\n",
      "320 Train Loss 976.63306\n",
      "321 Train Loss 976.15607\n",
      "322 Train Loss 975.4573\n",
      "323 Train Loss 974.1024\n",
      "324 Train Loss 971.6377\n",
      "325 Train Loss 970.0775\n",
      "326 Train Loss 968.8229\n",
      "327 Train Loss 967.9541\n",
      "328 Train Loss 968.37146\n",
      "329 Train Loss 967.3831\n",
      "330 Train Loss 967.1449\n",
      "331 Train Loss 966.94586\n",
      "332 Train Loss 966.80286\n",
      "333 Train Loss 966.6529\n",
      "334 Train Loss 966.40424\n",
      "335 Train Loss 966.20215\n",
      "336 Train Loss 966.0421\n",
      "337 Train Loss 965.8933\n",
      "338 Train Loss 965.7155\n",
      "339 Train Loss 965.476\n",
      "340 Train Loss 965.15753\n",
      "341 Train Loss 964.945\n",
      "342 Train Loss 964.8008\n",
      "343 Train Loss 964.6269\n",
      "344 Train Loss 964.5191\n",
      "345 Train Loss 964.3508\n",
      "346 Train Loss 964.0862\n",
      "347 Train Loss 963.8558\n",
      "348 Train Loss 963.02423\n",
      "349 Train Loss 961.89606\n",
      "350 Train Loss 961.0698\n",
      "351 Train Loss 966.53613\n",
      "352 Train Loss 960.64154\n",
      "353 Train Loss 960.03\n",
      "354 Train Loss 959.14374\n",
      "355 Train Loss 958.0199\n",
      "356 Train Loss 962.2186\n",
      "357 Train Loss 956.93024\n",
      "358 Train Loss 959.56647\n",
      "359 Train Loss 956.2326\n",
      "360 Train Loss 955.6073\n",
      "361 Train Loss 955.15753\n",
      "362 Train Loss 954.2171\n",
      "363 Train Loss 952.89264\n",
      "364 Train Loss 952.29016\n",
      "365 Train Loss 951.62897\n",
      "366 Train Loss 951.0605\n",
      "367 Train Loss 950.86975\n",
      "368 Train Loss 950.6765\n",
      "369 Train Loss 950.4499\n",
      "370 Train Loss 950.31305\n",
      "371 Train Loss 950.23773\n",
      "372 Train Loss 950.0572\n",
      "373 Train Loss 949.8792\n",
      "374 Train Loss 949.71747\n",
      "375 Train Loss 949.6601\n",
      "376 Train Loss 949.5946\n",
      "377 Train Loss 949.5409\n",
      "378 Train Loss 949.467\n",
      "379 Train Loss 949.2804\n",
      "380 Train Loss 949.07886\n",
      "381 Train Loss 948.7074\n",
      "382 Train Loss 948.02484\n",
      "383 Train Loss 947.462\n",
      "384 Train Loss 947.164\n",
      "385 Train Loss 946.6727\n",
      "386 Train Loss 946.58307\n",
      "387 Train Loss 945.9889\n",
      "388 Train Loss 945.6877\n",
      "389 Train Loss 945.2382\n",
      "390 Train Loss 944.88855\n",
      "391 Train Loss 944.7922\n",
      "392 Train Loss 944.6638\n",
      "393 Train Loss 944.3603\n",
      "394 Train Loss 944.0434\n",
      "395 Train Loss 943.84143\n",
      "396 Train Loss 943.6087\n",
      "397 Train Loss 943.345\n",
      "398 Train Loss 943.1171\n",
      "399 Train Loss 942.9295\n",
      "400 Train Loss 942.692\n",
      "401 Train Loss 942.51843\n",
      "402 Train Loss 942.32465\n",
      "403 Train Loss 942.19275\n",
      "404 Train Loss 942.0808\n",
      "405 Train Loss 941.8694\n",
      "406 Train Loss 941.5865\n",
      "407 Train Loss 941.3999\n",
      "408 Train Loss 941.17944\n",
      "409 Train Loss 940.9452\n",
      "410 Train Loss 940.81824\n",
      "411 Train Loss 940.5043\n",
      "412 Train Loss 940.3029\n",
      "413 Train Loss 940.0359\n",
      "414 Train Loss 939.8543\n",
      "415 Train Loss 939.6117\n",
      "416 Train Loss 939.4823\n",
      "417 Train Loss 939.29694\n",
      "418 Train Loss 939.1343\n",
      "419 Train Loss 938.90704\n",
      "420 Train Loss 938.74176\n",
      "421 Train Loss 938.67566\n",
      "422 Train Loss 938.6287\n",
      "423 Train Loss 938.5902\n",
      "424 Train Loss 938.5405\n",
      "425 Train Loss 938.48676\n",
      "426 Train Loss 938.369\n",
      "427 Train Loss 938.15625\n",
      "428 Train Loss 937.66895\n",
      "429 Train Loss 936.97174\n",
      "430 Train Loss 936.4599\n",
      "431 Train Loss 936.84546\n",
      "432 Train Loss 936.1154\n",
      "433 Train Loss 935.9441\n",
      "434 Train Loss 935.82153\n",
      "435 Train Loss 935.7982\n",
      "436 Train Loss 935.4639\n",
      "437 Train Loss 935.1749\n",
      "438 Train Loss 934.5682\n",
      "439 Train Loss 934.0064\n",
      "440 Train Loss 933.60443\n",
      "441 Train Loss 933.8613\n",
      "442 Train Loss 933.3554\n",
      "443 Train Loss 932.9872\n",
      "444 Train Loss 932.62445\n",
      "445 Train Loss 932.3396\n",
      "446 Train Loss 932.03864\n",
      "447 Train Loss 931.70636\n",
      "448 Train Loss 931.4657\n",
      "449 Train Loss 931.14294\n",
      "450 Train Loss 930.8399\n",
      "451 Train Loss 930.6486\n",
      "452 Train Loss 930.6277\n",
      "453 Train Loss 930.5318\n",
      "454 Train Loss 930.2953\n",
      "455 Train Loss 930.1774\n",
      "456 Train Loss 930.08905\n",
      "457 Train Loss 930.0263\n",
      "458 Train Loss 929.969\n",
      "459 Train Loss 929.8907\n",
      "460 Train Loss 929.8082\n",
      "461 Train Loss 929.7284\n",
      "462 Train Loss 929.63245\n",
      "463 Train Loss 929.5677\n",
      "464 Train Loss 929.4972\n",
      "465 Train Loss 929.4211\n",
      "466 Train Loss 929.3552\n",
      "467 Train Loss 929.2618\n",
      "468 Train Loss 929.1989\n",
      "469 Train Loss 929.1112\n",
      "470 Train Loss 929.05676\n",
      "471 Train Loss 928.9956\n",
      "472 Train Loss 928.9199\n",
      "473 Train Loss 928.8509\n",
      "474 Train Loss 928.7629\n",
      "475 Train Loss 928.66486\n",
      "476 Train Loss 928.4829\n",
      "477 Train Loss 928.2905\n",
      "478 Train Loss 928.1372\n",
      "479 Train Loss 927.87024\n",
      "480 Train Loss 927.73224\n",
      "481 Train Loss 927.66876\n",
      "482 Train Loss 927.6182\n",
      "483 Train Loss 927.5762\n",
      "484 Train Loss 927.5308\n",
      "485 Train Loss 927.4833\n",
      "486 Train Loss 927.4473\n",
      "487 Train Loss 927.4165\n",
      "488 Train Loss 927.39685\n",
      "489 Train Loss 927.38696\n",
      "490 Train Loss 927.358\n",
      "491 Train Loss 927.2853\n",
      "492 Train Loss 927.1603\n",
      "493 Train Loss 927.099\n",
      "494 Train Loss 927.5031\n",
      "495 Train Loss 926.9992\n",
      "496 Train Loss 926.9963\n",
      "497 Train Loss 926.8915\n",
      "498 Train Loss 926.7885\n",
      "499 Train Loss 926.6468\n",
      "500 Train Loss 926.5293\n",
      "501 Train Loss 926.4825\n",
      "502 Train Loss 926.3613\n",
      "503 Train Loss 926.23944\n",
      "504 Train Loss 926.1467\n",
      "505 Train Loss 926.0301\n",
      "506 Train Loss 925.96344\n",
      "507 Train Loss 925.9076\n",
      "508 Train Loss 925.8939\n",
      "509 Train Loss 925.84106\n",
      "510 Train Loss 925.8089\n",
      "511 Train Loss 925.7742\n",
      "512 Train Loss 925.7439\n",
      "513 Train Loss 925.71234\n",
      "514 Train Loss 925.6647\n",
      "515 Train Loss 925.5941\n",
      "516 Train Loss 925.5469\n",
      "517 Train Loss 925.4877\n",
      "518 Train Loss 925.41425\n",
      "519 Train Loss 925.2021\n",
      "520 Train Loss 924.89923\n",
      "521 Train Loss 924.3493\n",
      "522 Train Loss 925.3467\n",
      "523 Train Loss 924.036\n",
      "524 Train Loss 924.11694\n",
      "525 Train Loss 923.5663\n",
      "526 Train Loss 923.7843\n",
      "527 Train Loss 923.34344\n",
      "528 Train Loss 923.437\n",
      "529 Train Loss 923.09283\n",
      "530 Train Loss 922.88434\n",
      "531 Train Loss 922.6791\n",
      "532 Train Loss 922.6606\n",
      "533 Train Loss 922.499\n",
      "534 Train Loss 922.2766\n",
      "535 Train Loss 922.6427\n",
      "536 Train Loss 922.1448\n",
      "537 Train Loss 921.9733\n",
      "538 Train Loss 921.8452\n",
      "539 Train Loss 921.7389\n",
      "540 Train Loss 921.4779\n",
      "541 Train Loss 921.4781\n",
      "542 Train Loss 921.3738\n",
      "543 Train Loss 921.30896\n",
      "544 Train Loss 921.161\n",
      "545 Train Loss 921.1463\n",
      "546 Train Loss 921.1194\n",
      "547 Train Loss 921.07935\n",
      "548 Train Loss 921.0188\n",
      "549 Train Loss 920.9488\n",
      "550 Train Loss 920.8494\n",
      "551 Train Loss 920.72455\n",
      "552 Train Loss 920.5931\n",
      "553 Train Loss 920.4497\n",
      "554 Train Loss 920.33844\n",
      "555 Train Loss 920.2796\n",
      "556 Train Loss 920.25116\n",
      "557 Train Loss 920.2188\n",
      "558 Train Loss 920.18646\n",
      "559 Train Loss 920.1459\n",
      "560 Train Loss 920.08826\n",
      "561 Train Loss 920.0209\n",
      "562 Train Loss 919.95514\n",
      "563 Train Loss 919.8946\n",
      "564 Train Loss 919.8346\n",
      "565 Train Loss 919.7756\n",
      "566 Train Loss 919.6926\n",
      "567 Train Loss 919.6493\n",
      "568 Train Loss 919.6641\n",
      "569 Train Loss 919.6045\n",
      "570 Train Loss 919.56555\n",
      "571 Train Loss 919.5037\n",
      "572 Train Loss 919.47845\n",
      "573 Train Loss 919.4605\n",
      "574 Train Loss 919.4352\n",
      "575 Train Loss 919.4238\n",
      "576 Train Loss 919.4135\n",
      "577 Train Loss 919.4017\n",
      "578 Train Loss 919.38153\n",
      "579 Train Loss 919.3595\n",
      "580 Train Loss 919.32324\n",
      "581 Train Loss 919.2791\n",
      "582 Train Loss 919.2188\n",
      "583 Train Loss 919.1356\n",
      "584 Train Loss 919.0615\n",
      "585 Train Loss 919.1733\n",
      "586 Train Loss 919.0174\n",
      "587 Train Loss 918.99054\n",
      "588 Train Loss 918.9693\n",
      "589 Train Loss 918.9516\n",
      "590 Train Loss 918.9239\n",
      "591 Train Loss 918.89136\n",
      "592 Train Loss 918.859\n",
      "593 Train Loss 918.852\n",
      "594 Train Loss 918.81976\n",
      "595 Train Loss 918.8015\n",
      "596 Train Loss 918.7919\n",
      "597 Train Loss 918.7661\n",
      "598 Train Loss 918.8707\n",
      "599 Train Loss 918.7441\n",
      "600 Train Loss 918.69006\n",
      "601 Train Loss 918.61224\n",
      "602 Train Loss 918.5603\n",
      "603 Train Loss 918.51013\n",
      "604 Train Loss 918.4821\n",
      "605 Train Loss 918.46716\n",
      "606 Train Loss 918.4565\n",
      "607 Train Loss 918.44275\n",
      "608 Train Loss 918.4285\n",
      "609 Train Loss 918.39923\n",
      "610 Train Loss 918.36487\n",
      "611 Train Loss 918.3236\n",
      "612 Train Loss 918.29205\n",
      "613 Train Loss 918.2636\n",
      "614 Train Loss 918.25287\n",
      "615 Train Loss 918.23236\n",
      "616 Train Loss 918.2268\n",
      "617 Train Loss 918.2222\n",
      "618 Train Loss 918.2061\n",
      "619 Train Loss 918.1643\n",
      "620 Train Loss 918.1117\n",
      "621 Train Loss 918.04156\n",
      "622 Train Loss 917.92926\n",
      "623 Train Loss 917.8003\n",
      "624 Train Loss 917.69214\n",
      "625 Train Loss 917.63495\n",
      "626 Train Loss 917.50543\n",
      "627 Train Loss 918.07904\n",
      "628 Train Loss 917.39166\n",
      "629 Train Loss 917.1355\n",
      "630 Train Loss 917.0004\n",
      "631 Train Loss 917.32825\n",
      "632 Train Loss 916.83417\n",
      "633 Train Loss 916.97205\n",
      "634 Train Loss 916.737\n",
      "635 Train Loss 916.6705\n",
      "636 Train Loss 916.58575\n",
      "637 Train Loss 916.5044\n",
      "638 Train Loss 916.3822\n",
      "639 Train Loss 916.2684\n",
      "640 Train Loss 916.22565\n",
      "641 Train Loss 916.21326\n",
      "642 Train Loss 916.138\n",
      "643 Train Loss 916.10046\n",
      "644 Train Loss 916.04553\n",
      "645 Train Loss 916.104\n",
      "646 Train Loss 916.0312\n",
      "647 Train Loss 916.007\n",
      "648 Train Loss 915.99023\n",
      "649 Train Loss 915.9513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 Train Loss 915.91895\n",
      "651 Train Loss 915.89526\n",
      "652 Train Loss 915.88257\n",
      "653 Train Loss 915.87164\n",
      "654 Train Loss 915.863\n",
      "655 Train Loss 915.8467\n",
      "656 Train Loss 915.8225\n",
      "657 Train Loss 915.7843\n",
      "658 Train Loss 915.7463\n",
      "659 Train Loss 915.71124\n",
      "660 Train Loss 915.6852\n",
      "661 Train Loss 915.6787\n",
      "662 Train Loss 915.6941\n",
      "663 Train Loss 915.6547\n",
      "664 Train Loss 915.63367\n",
      "665 Train Loss 915.6177\n",
      "666 Train Loss 915.5899\n",
      "667 Train Loss 915.5701\n",
      "668 Train Loss 915.5407\n",
      "669 Train Loss 915.5231\n",
      "670 Train Loss 915.5052\n",
      "671 Train Loss 915.4958\n",
      "672 Train Loss 915.48267\n",
      "673 Train Loss 915.47076\n",
      "674 Train Loss 915.46027\n",
      "675 Train Loss 915.45\n",
      "676 Train Loss 915.4395\n",
      "677 Train Loss 915.42395\n",
      "678 Train Loss 915.3938\n",
      "679 Train Loss 915.3582\n",
      "680 Train Loss 915.33093\n",
      "681 Train Loss 915.314\n",
      "682 Train Loss 915.2785\n",
      "683 Train Loss 915.25214\n",
      "684 Train Loss 915.21204\n",
      "685 Train Loss 915.1813\n",
      "686 Train Loss 915.14404\n",
      "687 Train Loss 915.1174\n",
      "688 Train Loss 915.1102\n",
      "689 Train Loss 915.099\n",
      "690 Train Loss 915.10254\n",
      "691 Train Loss 915.0761\n",
      "692 Train Loss 915.0505\n",
      "693 Train Loss 915.02966\n",
      "694 Train Loss 915.01807\n",
      "695 Train Loss 915.009\n",
      "696 Train Loss 915.0005\n",
      "697 Train Loss 914.9897\n",
      "698 Train Loss 914.9797\n",
      "699 Train Loss 914.96747\n",
      "700 Train Loss 914.95245\n",
      "701 Train Loss 914.93585\n",
      "702 Train Loss 914.91266\n",
      "703 Train Loss 914.8581\n",
      "704 Train Loss 914.8406\n",
      "705 Train Loss 914.76025\n",
      "706 Train Loss 914.6909\n",
      "707 Train Loss 914.63544\n",
      "708 Train Loss 914.58136\n",
      "709 Train Loss 914.51807\n",
      "710 Train Loss 914.4705\n",
      "711 Train Loss 914.3898\n",
      "712 Train Loss 914.359\n",
      "713 Train Loss 914.44446\n",
      "714 Train Loss 914.30835\n",
      "715 Train Loss 914.27905\n",
      "716 Train Loss 914.2435\n",
      "717 Train Loss 914.206\n",
      "718 Train Loss 914.175\n",
      "719 Train Loss 914.134\n",
      "720 Train Loss 914.1187\n",
      "721 Train Loss 914.0987\n",
      "722 Train Loss 914.12146\n",
      "723 Train Loss 914.08\n",
      "724 Train Loss 914.05707\n",
      "725 Train Loss 914.03033\n",
      "726 Train Loss 913.9999\n",
      "727 Train Loss 913.9778\n",
      "728 Train Loss 913.9652\n",
      "729 Train Loss 913.9648\n",
      "730 Train Loss 913.95074\n",
      "731 Train Loss 913.93207\n",
      "732 Train Loss 913.9127\n",
      "733 Train Loss 913.8824\n",
      "734 Train Loss 913.8669\n",
      "735 Train Loss 913.85065\n",
      "736 Train Loss 913.8254\n",
      "737 Train Loss 913.79694\n",
      "738 Train Loss 913.774\n",
      "739 Train Loss 913.74634\n",
      "740 Train Loss 913.7255\n",
      "741 Train Loss 913.70636\n",
      "742 Train Loss 913.692\n",
      "743 Train Loss 913.6839\n",
      "744 Train Loss 913.6708\n",
      "745 Train Loss 913.6566\n",
      "746 Train Loss 913.64215\n",
      "747 Train Loss 913.62805\n",
      "748 Train Loss 913.6171\n",
      "749 Train Loss 913.6245\n",
      "750 Train Loss 913.61066\n",
      "751 Train Loss 913.60266\n",
      "752 Train Loss 913.59033\n",
      "753 Train Loss 913.57825\n",
      "754 Train Loss 913.5627\n",
      "755 Train Loss 913.5329\n",
      "756 Train Loss 913.4967\n",
      "757 Train Loss 913.4596\n",
      "758 Train Loss 913.4208\n",
      "759 Train Loss 913.3749\n",
      "760 Train Loss 913.3422\n",
      "761 Train Loss 913.3013\n",
      "762 Train Loss 913.2886\n",
      "763 Train Loss 913.2218\n",
      "764 Train Loss 913.1924\n",
      "765 Train Loss 913.1356\n",
      "766 Train Loss 913.0641\n",
      "767 Train Loss 912.99646\n",
      "768 Train Loss 912.9635\n",
      "769 Train Loss 912.8634\n",
      "770 Train Loss 912.7908\n",
      "771 Train Loss 912.8788\n",
      "772 Train Loss 912.751\n",
      "773 Train Loss 912.7086\n",
      "774 Train Loss 912.70325\n",
      "775 Train Loss 912.67523\n",
      "776 Train Loss 912.6653\n",
      "777 Train Loss 912.6522\n",
      "778 Train Loss 912.6405\n",
      "779 Train Loss 912.6317\n",
      "780 Train Loss 912.6243\n",
      "781 Train Loss 912.61145\n",
      "782 Train Loss 912.58655\n",
      "783 Train Loss 912.5469\n",
      "784 Train Loss 912.5227\n",
      "785 Train Loss 912.50977\n",
      "786 Train Loss 912.49506\n",
      "787 Train Loss 912.4848\n",
      "788 Train Loss 912.47534\n",
      "789 Train Loss 912.4654\n",
      "790 Train Loss 912.4498\n",
      "791 Train Loss 912.41766\n",
      "792 Train Loss 912.3918\n",
      "793 Train Loss 912.37164\n",
      "794 Train Loss 912.3592\n",
      "795 Train Loss 912.33923\n",
      "796 Train Loss 912.3312\n",
      "797 Train Loss 912.3208\n",
      "798 Train Loss 912.2998\n",
      "799 Train Loss 912.2722\n",
      "800 Train Loss 912.2376\n",
      "801 Train Loss 912.21204\n",
      "802 Train Loss 912.1791\n",
      "803 Train Loss 912.13983\n",
      "804 Train Loss 912.0907\n",
      "805 Train Loss 912.0614\n",
      "806 Train Loss 912.0561\n",
      "807 Train Loss 912.0225\n",
      "808 Train Loss 911.9967\n",
      "809 Train Loss 911.95074\n",
      "810 Train Loss 911.88116\n",
      "811 Train Loss 911.8368\n",
      "812 Train Loss 911.7282\n",
      "813 Train Loss 911.6735\n",
      "814 Train Loss 911.625\n",
      "815 Train Loss 911.6498\n",
      "816 Train Loss 911.6113\n",
      "817 Train Loss 911.59235\n",
      "818 Train Loss 911.5733\n",
      "819 Train Loss 911.56604\n",
      "820 Train Loss 911.54944\n",
      "821 Train Loss 911.5348\n",
      "822 Train Loss 911.50977\n",
      "823 Train Loss 911.4997\n",
      "824 Train Loss 911.4886\n",
      "825 Train Loss 911.4805\n",
      "826 Train Loss 911.4677\n",
      "827 Train Loss 911.44104\n",
      "828 Train Loss 911.40857\n",
      "829 Train Loss 911.37354\n",
      "830 Train Loss 911.35706\n",
      "831 Train Loss 911.3418\n",
      "832 Train Loss 911.32935\n",
      "833 Train Loss 911.31866\n",
      "834 Train Loss 911.3083\n",
      "835 Train Loss 911.3008\n",
      "836 Train Loss 911.2939\n",
      "837 Train Loss 911.28595\n",
      "838 Train Loss 911.277\n",
      "839 Train Loss 911.2681\n",
      "840 Train Loss 911.255\n",
      "841 Train Loss 911.2431\n",
      "842 Train Loss 911.234\n",
      "843 Train Loss 911.22595\n",
      "844 Train Loss 911.2169\n",
      "845 Train Loss 911.2106\n",
      "846 Train Loss 911.1905\n",
      "847 Train Loss 911.1723\n",
      "848 Train Loss 911.13434\n",
      "849 Train Loss 911.10834\n",
      "850 Train Loss 911.07745\n",
      "851 Train Loss 911.0661\n",
      "852 Train Loss 911.05756\n",
      "853 Train Loss 911.04584\n",
      "854 Train Loss 911.0189\n",
      "855 Train Loss 910.98724\n",
      "856 Train Loss 910.96204\n",
      "857 Train Loss 910.92816\n",
      "858 Train Loss 910.89374\n",
      "859 Train Loss 910.85583\n",
      "860 Train Loss 910.7968\n",
      "861 Train Loss 910.75555\n",
      "862 Train Loss 910.70386\n",
      "863 Train Loss 910.6683\n",
      "864 Train Loss 910.59467\n",
      "865 Train Loss 910.5393\n",
      "866 Train Loss 910.4673\n",
      "867 Train Loss 910.7614\n",
      "868 Train Loss 910.4375\n",
      "869 Train Loss 910.3601\n",
      "870 Train Loss 910.43115\n",
      "871 Train Loss 910.28253\n",
      "872 Train Loss 910.18646\n",
      "873 Train Loss 910.34875\n",
      "874 Train Loss 910.111\n",
      "875 Train Loss 910.0109\n",
      "876 Train Loss 909.93604\n",
      "877 Train Loss 910.0339\n",
      "878 Train Loss 909.90106\n",
      "879 Train Loss 909.8397\n",
      "880 Train Loss 909.7862\n",
      "881 Train Loss 909.87634\n",
      "882 Train Loss 909.7321\n",
      "883 Train Loss 909.691\n",
      "884 Train Loss 909.6454\n",
      "885 Train Loss 909.615\n",
      "886 Train Loss 909.576\n",
      "887 Train Loss 909.49866\n",
      "888 Train Loss 909.4608\n",
      "889 Train Loss 909.44366\n",
      "890 Train Loss 909.4242\n",
      "891 Train Loss 909.4107\n",
      "892 Train Loss 909.38385\n",
      "893 Train Loss 909.3622\n",
      "894 Train Loss 909.3225\n",
      "895 Train Loss 909.2295\n",
      "896 Train Loss 909.1585\n",
      "897 Train Loss 909.0948\n",
      "898 Train Loss 909.02844\n",
      "899 Train Loss 912.9727\n",
      "900 Train Loss 909.01105\n",
      "901 Train Loss 908.99524\n",
      "902 Train Loss 908.96564\n",
      "903 Train Loss 908.9211\n",
      "904 Train Loss 908.91235\n",
      "905 Train Loss 908.8884\n",
      "906 Train Loss 908.8534\n",
      "907 Train Loss 908.80035\n",
      "908 Train Loss 908.7438\n",
      "909 Train Loss 908.8744\n",
      "910 Train Loss 908.7189\n",
      "911 Train Loss 908.6736\n",
      "912 Train Loss 908.6877\n",
      "913 Train Loss 908.6519\n",
      "914 Train Loss 908.636\n",
      "915 Train Loss 908.6092\n",
      "916 Train Loss 908.5711\n",
      "917 Train Loss 908.55597\n",
      "918 Train Loss 908.5201\n",
      "919 Train Loss 908.4936\n",
      "920 Train Loss 908.47363\n",
      "921 Train Loss 908.4489\n",
      "922 Train Loss 908.4096\n",
      "923 Train Loss 908.3972\n",
      "924 Train Loss 908.3717\n",
      "925 Train Loss 908.3504\n",
      "926 Train Loss 908.32745\n",
      "927 Train Loss 908.3101\n",
      "928 Train Loss 908.2945\n",
      "929 Train Loss 908.27496\n",
      "930 Train Loss 908.2559\n",
      "931 Train Loss 908.2421\n",
      "932 Train Loss 908.21454\n",
      "933 Train Loss 908.1907\n",
      "934 Train Loss 908.1733\n",
      "935 Train Loss 908.1635\n",
      "936 Train Loss 908.1518\n",
      "937 Train Loss 908.13995\n",
      "938 Train Loss 908.1316\n",
      "939 Train Loss 908.1245\n",
      "940 Train Loss 908.11676\n",
      "941 Train Loss 908.1051\n",
      "942 Train Loss 908.0947\n",
      "943 Train Loss 908.0824\n",
      "944 Train Loss 908.0888\n",
      "945 Train Loss 908.0731\n",
      "946 Train Loss 908.0561\n",
      "947 Train Loss 908.045\n",
      "948 Train Loss 908.0376\n",
      "949 Train Loss 908.0265\n",
      "950 Train Loss 908.0173\n",
      "951 Train Loss 908.0075\n",
      "952 Train Loss 907.9953\n",
      "953 Train Loss 907.98346\n",
      "954 Train Loss 907.974\n",
      "955 Train Loss 907.965\n",
      "956 Train Loss 907.9559\n",
      "957 Train Loss 907.9451\n",
      "958 Train Loss 907.9336\n",
      "959 Train Loss 907.9791\n",
      "960 Train Loss 907.9238\n",
      "961 Train Loss 907.9084\n",
      "962 Train Loss 907.8956\n",
      "963 Train Loss 907.88043\n",
      "964 Train Loss 907.8595\n",
      "965 Train Loss 907.8287\n",
      "966 Train Loss 907.81384\n",
      "967 Train Loss 907.7916\n",
      "968 Train Loss 907.7776\n",
      "969 Train Loss 907.7305\n",
      "970 Train Loss 907.7093\n",
      "971 Train Loss 907.68134\n",
      "972 Train Loss 907.65564\n",
      "973 Train Loss 907.6324\n",
      "974 Train Loss 907.6163\n",
      "975 Train Loss 907.5861\n",
      "976 Train Loss 907.57043\n",
      "977 Train Loss 907.53864\n",
      "978 Train Loss 907.5031\n",
      "979 Train Loss 907.46655\n",
      "980 Train Loss 907.45337\n",
      "981 Train Loss 907.4377\n",
      "982 Train Loss 907.4261\n",
      "983 Train Loss 907.36646\n",
      "984 Train Loss 907.3365\n",
      "985 Train Loss 907.3064\n",
      "986 Train Loss 907.29083\n",
      "987 Train Loss 907.26337\n",
      "988 Train Loss 907.25836\n",
      "989 Train Loss 907.2414\n",
      "990 Train Loss 907.22565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991 Train Loss 907.2075\n",
      "992 Train Loss 907.1774\n",
      "993 Train Loss 907.1599\n",
      "994 Train Loss 907.1767\n",
      "995 Train Loss 907.1457\n",
      "996 Train Loss 907.1169\n",
      "997 Train Loss 907.06354\n",
      "998 Train Loss 907.01996\n",
      "999 Train Loss 906.9643\n",
      "1000 Train Loss 906.94653\n",
      "1001 Train Loss 906.85004\n",
      "1002 Train Loss 907.03796\n",
      "1003 Train Loss 906.80786\n",
      "1004 Train Loss 906.7235\n",
      "1005 Train Loss 906.7162\n",
      "1006 Train Loss 906.97003\n",
      "1007 Train Loss 906.63684\n",
      "1008 Train Loss 906.75275\n",
      "1009 Train Loss 906.5992\n",
      "1010 Train Loss 906.5884\n",
      "1011 Train Loss 906.5448\n",
      "1012 Train Loss 906.52545\n",
      "1013 Train Loss 906.5067\n",
      "1014 Train Loss 906.4886\n",
      "1015 Train Loss 906.4665\n",
      "1016 Train Loss 906.4481\n",
      "1017 Train Loss 906.42145\n",
      "1018 Train Loss 906.3988\n",
      "1019 Train Loss 906.3743\n",
      "1020 Train Loss 906.3622\n",
      "1021 Train Loss 906.3419\n",
      "1022 Train Loss 906.3193\n",
      "1023 Train Loss 906.2932\n",
      "1024 Train Loss 906.2524\n",
      "1025 Train Loss 906.2265\n",
      "1026 Train Loss 906.20306\n",
      "1027 Train Loss 906.172\n",
      "1028 Train Loss 906.146\n",
      "1029 Train Loss 906.13544\n",
      "1030 Train Loss 906.1273\n",
      "1031 Train Loss 906.1276\n",
      "1032 Train Loss 906.11847\n",
      "1033 Train Loss 906.11334\n",
      "1034 Train Loss 906.1098\n",
      "1035 Train Loss 906.10455\n",
      "1036 Train Loss 906.09625\n",
      "1037 Train Loss 906.0871\n",
      "1038 Train Loss 906.0777\n",
      "1039 Train Loss 906.0667\n",
      "1040 Train Loss 906.0574\n",
      "1041 Train Loss 906.0487\n",
      "1042 Train Loss 906.03845\n",
      "1043 Train Loss 906.0236\n",
      "1044 Train Loss 906.004\n",
      "1045 Train Loss 905.99255\n",
      "1046 Train Loss 905.9783\n",
      "1047 Train Loss 905.95795\n",
      "1048 Train Loss 905.9414\n",
      "1049 Train Loss 905.9626\n",
      "1050 Train Loss 905.9138\n",
      "1051 Train Loss 905.8891\n",
      "1052 Train Loss 905.84937\n",
      "1053 Train Loss 905.84045\n",
      "1054 Train Loss 905.82623\n",
      "1055 Train Loss 905.7997\n",
      "1056 Train Loss 905.82715\n",
      "1057 Train Loss 905.77673\n",
      "1058 Train Loss 905.7443\n",
      "1059 Train Loss 905.7062\n",
      "1060 Train Loss 905.7507\n",
      "1061 Train Loss 905.668\n",
      "1062 Train Loss 905.59955\n",
      "1063 Train Loss 905.5715\n",
      "1064 Train Loss 905.64496\n",
      "1065 Train Loss 905.51746\n",
      "1066 Train Loss 905.48584\n",
      "1067 Train Loss 905.4755\n",
      "1068 Train Loss 905.5408\n",
      "1069 Train Loss 905.4548\n",
      "1070 Train Loss 905.4291\n",
      "1071 Train Loss 905.4054\n",
      "1072 Train Loss 905.38135\n",
      "1073 Train Loss 905.36914\n",
      "1074 Train Loss 905.348\n",
      "1075 Train Loss 905.315\n",
      "1076 Train Loss 905.3841\n",
      "1077 Train Loss 905.3029\n",
      "1078 Train Loss 905.2805\n",
      "1079 Train Loss 905.2661\n",
      "1080 Train Loss 905.24866\n",
      "1081 Train Loss 905.2341\n",
      "1082 Train Loss 905.2122\n",
      "1083 Train Loss 905.1979\n",
      "1084 Train Loss 905.1799\n",
      "1085 Train Loss 905.1675\n",
      "1086 Train Loss 905.15515\n",
      "1087 Train Loss 905.1349\n",
      "1088 Train Loss 905.12286\n",
      "1089 Train Loss 905.10455\n",
      "1090 Train Loss 905.0949\n",
      "1091 Train Loss 905.0762\n",
      "1092 Train Loss 905.0542\n",
      "1093 Train Loss 905.0359\n",
      "1094 Train Loss 905.01117\n",
      "1095 Train Loss 904.9932\n",
      "1096 Train Loss 904.97986\n",
      "1097 Train Loss 904.9621\n",
      "1098 Train Loss 904.94684\n",
      "1099 Train Loss 904.9236\n",
      "1100 Train Loss 904.9027\n",
      "1101 Train Loss 904.8797\n",
      "1102 Train Loss 904.86945\n",
      "1103 Train Loss 904.85754\n",
      "1104 Train Loss 904.84576\n",
      "1105 Train Loss 904.8404\n",
      "1106 Train Loss 904.81085\n",
      "1107 Train Loss 904.7932\n",
      "1108 Train Loss 904.7674\n",
      "1109 Train Loss 904.745\n",
      "1110 Train Loss 904.7386\n",
      "1111 Train Loss 904.7006\n",
      "1112 Train Loss 904.697\n",
      "1113 Train Loss 904.6857\n",
      "1114 Train Loss 904.67645\n",
      "1115 Train Loss 904.6621\n",
      "1116 Train Loss 904.63763\n",
      "1117 Train Loss 904.6247\n",
      "1118 Train Loss 904.61505\n",
      "1119 Train Loss 904.59454\n",
      "1120 Train Loss 904.5751\n",
      "1121 Train Loss 904.5331\n",
      "1122 Train Loss 904.49023\n",
      "1123 Train Loss 904.44293\n",
      "1124 Train Loss 904.4017\n",
      "1125 Train Loss 904.5969\n",
      "1126 Train Loss 904.38464\n",
      "1127 Train Loss 904.36053\n",
      "1128 Train Loss 904.33154\n",
      "1129 Train Loss 904.31\n",
      "1130 Train Loss 904.2822\n",
      "1131 Train Loss 904.2663\n",
      "1132 Train Loss 904.25415\n",
      "1133 Train Loss 904.2322\n",
      "1134 Train Loss 904.21454\n",
      "1135 Train Loss 904.20374\n",
      "1136 Train Loss 904.19147\n",
      "1137 Train Loss 904.1757\n",
      "1138 Train Loss 904.14606\n",
      "1139 Train Loss 904.1162\n",
      "1140 Train Loss 904.0861\n",
      "1141 Train Loss 904.05597\n",
      "1142 Train Loss 904.0305\n",
      "1143 Train Loss 904.0379\n",
      "1144 Train Loss 904.00854\n",
      "1145 Train Loss 903.9856\n",
      "1146 Train Loss 903.9597\n",
      "1147 Train Loss 903.9461\n",
      "1148 Train Loss 903.92004\n",
      "1149 Train Loss 903.90137\n",
      "1150 Train Loss 903.8741\n",
      "1151 Train Loss 903.8878\n",
      "1152 Train Loss 903.86865\n",
      "1153 Train Loss 903.8657\n",
      "1154 Train Loss 903.85626\n",
      "1155 Train Loss 903.8513\n",
      "1156 Train Loss 903.8372\n",
      "1157 Train Loss 903.8224\n",
      "1158 Train Loss 903.80524\n",
      "1159 Train Loss 903.7824\n",
      "1160 Train Loss 903.7482\n",
      "1161 Train Loss 903.72687\n",
      "1162 Train Loss 903.7677\n",
      "1163 Train Loss 903.7163\n",
      "1164 Train Loss 903.7024\n",
      "1165 Train Loss 903.6821\n",
      "1166 Train Loss 903.6661\n",
      "1167 Train Loss 903.6456\n",
      "1168 Train Loss 903.6238\n",
      "1169 Train Loss 903.6151\n",
      "1170 Train Loss 903.6018\n",
      "1171 Train Loss 903.5871\n",
      "1172 Train Loss 903.57227\n",
      "1173 Train Loss 903.55865\n",
      "1174 Train Loss 903.5451\n",
      "1175 Train Loss 903.5312\n",
      "1176 Train Loss 903.5195\n",
      "1177 Train Loss 903.5098\n",
      "1178 Train Loss 903.5011\n",
      "1179 Train Loss 903.4923\n",
      "1180 Train Loss 903.4811\n",
      "1181 Train Loss 903.47345\n",
      "1182 Train Loss 903.471\n",
      "1183 Train Loss 903.46295\n",
      "1184 Train Loss 903.4542\n",
      "1185 Train Loss 903.4444\n",
      "1186 Train Loss 903.4377\n",
      "1187 Train Loss 903.43286\n",
      "1188 Train Loss 903.42944\n",
      "1189 Train Loss 903.42596\n",
      "1190 Train Loss 903.4222\n",
      "1191 Train Loss 903.4217\n",
      "1192 Train Loss 903.41815\n",
      "1193 Train Loss 903.41534\n",
      "1194 Train Loss 903.4119\n",
      "1195 Train Loss 903.40857\n",
      "1196 Train Loss 903.40424\n",
      "1197 Train Loss 903.39777\n",
      "1198 Train Loss 903.3906\n",
      "1199 Train Loss 903.38367\n",
      "1200 Train Loss 903.3755\n",
      "1201 Train Loss 903.3636\n",
      "1202 Train Loss 903.35\n",
      "1203 Train Loss 903.3411\n",
      "1204 Train Loss 903.3254\n",
      "1205 Train Loss 903.3217\n",
      "1206 Train Loss 903.3138\n",
      "1207 Train Loss 903.3026\n",
      "1208 Train Loss 903.29456\n",
      "1209 Train Loss 903.2856\n",
      "1210 Train Loss 903.2783\n",
      "1211 Train Loss 903.2739\n",
      "1212 Train Loss 903.26776\n",
      "1213 Train Loss 903.2568\n",
      "1214 Train Loss 903.23975\n",
      "1215 Train Loss 903.2301\n",
      "1216 Train Loss 903.23083\n",
      "1217 Train Loss 903.2246\n",
      "1218 Train Loss 903.2195\n",
      "1219 Train Loss 903.2095\n",
      "1220 Train Loss 903.2011\n",
      "1221 Train Loss 903.1923\n",
      "1222 Train Loss 903.187\n",
      "1223 Train Loss 903.1877\n",
      "1224 Train Loss 903.18005\n",
      "1225 Train Loss 903.17664\n",
      "1226 Train Loss 903.17163\n",
      "1227 Train Loss 903.1664\n",
      "1228 Train Loss 903.1557\n",
      "1229 Train Loss 903.1429\n",
      "1230 Train Loss 903.1292\n",
      "1231 Train Loss 903.11066\n",
      "1232 Train Loss 903.09045\n",
      "1233 Train Loss 903.0613\n",
      "1234 Train Loss 903.03796\n",
      "1235 Train Loss 903.0127\n",
      "1236 Train Loss 902.9848\n",
      "1237 Train Loss 902.92505\n",
      "1238 Train Loss 902.8046\n",
      "1239 Train Loss 911.806\n",
      "1240 Train Loss 902.80975\n",
      "1241 Train Loss 902.7706\n",
      "1242 Train Loss 902.64026\n",
      "1243 Train Loss 917.1829\n",
      "1244 Train Loss 902.64636\n",
      "1245 Train Loss 902.5954\n",
      "1246 Train Loss 903.23596\n",
      "1247 Train Loss 902.48975\n",
      "1248 Train Loss 902.75287\n",
      "1249 Train Loss 902.40216\n",
      "1250 Train Loss 902.31494\n",
      "1251 Train Loss 913.29584\n",
      "1252 Train Loss 902.2746\n",
      "1253 Train Loss 902.3095\n",
      "1254 Train Loss 902.1616\n",
      "1255 Train Loss 902.1707\n",
      "1256 Train Loss 902.1227\n",
      "1257 Train Loss 902.12537\n",
      "1258 Train Loss 902.0944\n",
      "1259 Train Loss 902.0712\n",
      "1260 Train Loss 902.0357\n",
      "1261 Train Loss 902.0175\n",
      "1262 Train Loss 901.99023\n",
      "1263 Train Loss 901.977\n",
      "1264 Train Loss 901.9519\n",
      "1265 Train Loss 901.9322\n",
      "1266 Train Loss 901.91547\n",
      "1267 Train Loss 901.9068\n",
      "1268 Train Loss 901.89795\n",
      "1269 Train Loss 901.8925\n",
      "1270 Train Loss 901.88525\n",
      "1271 Train Loss 901.87726\n",
      "1272 Train Loss 901.8715\n",
      "1273 Train Loss 901.8659\n",
      "1274 Train Loss 901.8555\n",
      "1275 Train Loss 901.83966\n",
      "1276 Train Loss 901.83636\n",
      "1277 Train Loss 901.8293\n",
      "1278 Train Loss 901.8158\n",
      "1279 Train Loss 901.798\n",
      "1280 Train Loss 901.79016\n",
      "1281 Train Loss 902.0679\n",
      "1282 Train Loss 901.77893\n",
      "1283 Train Loss 901.76404\n",
      "1284 Train Loss 901.75006\n",
      "1285 Train Loss 901.7397\n",
      "1286 Train Loss 901.72687\n",
      "1287 Train Loss 901.71436\n",
      "1288 Train Loss 901.707\n",
      "1289 Train Loss 901.69617\n",
      "1290 Train Loss 901.6913\n",
      "1291 Train Loss 901.68506\n",
      "1292 Train Loss 901.68097\n",
      "1293 Train Loss 901.6788\n",
      "1294 Train Loss 901.6757\n",
      "1295 Train Loss 901.67303\n",
      "1296 Train Loss 901.6677\n",
      "1297 Train Loss 901.66113\n",
      "1298 Train Loss 901.65533\n",
      "1299 Train Loss 901.6515\n",
      "1300 Train Loss 901.64624\n",
      "1301 Train Loss 901.63885\n",
      "1302 Train Loss 901.6327\n",
      "1303 Train Loss 901.62537\n",
      "1304 Train Loss 901.6164\n",
      "1305 Train Loss 901.6099\n",
      "1306 Train Loss 901.6006\n",
      "1307 Train Loss 901.59406\n",
      "1308 Train Loss 901.59247\n",
      "1309 Train Loss 901.5887\n",
      "1310 Train Loss 901.588\n",
      "1311 Train Loss 901.58215\n",
      "1312 Train Loss 901.57495\n",
      "1313 Train Loss 901.5685\n",
      "1314 Train Loss 901.56573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1315 Train Loss 901.5613\n",
      "1316 Train Loss 901.5585\n",
      "1317 Train Loss 901.5553\n",
      "1318 Train Loss 901.55084\n",
      "1319 Train Loss 901.5474\n",
      "1320 Train Loss 901.5432\n",
      "1321 Train Loss 901.53937\n",
      "1322 Train Loss 901.5387\n",
      "1323 Train Loss 901.5363\n",
      "1324 Train Loss 901.53217\n",
      "1325 Train Loss 901.52704\n",
      "1326 Train Loss 901.5206\n",
      "1327 Train Loss 901.51544\n",
      "1328 Train Loss 901.71643\n",
      "1329 Train Loss 901.51056\n",
      "1330 Train Loss 901.50336\n",
      "1331 Train Loss 901.49066\n",
      "1332 Train Loss 901.50104\n",
      "1333 Train Loss 901.47925\n",
      "1334 Train Loss 901.46747\n",
      "1335 Train Loss 901.45636\n",
      "1336 Train Loss 901.4449\n",
      "1337 Train Loss 901.43207\n",
      "1338 Train Loss 901.42194\n",
      "1339 Train Loss 901.42474\n",
      "1340 Train Loss 901.4166\n",
      "1341 Train Loss 901.4094\n",
      "1342 Train Loss 901.4043\n",
      "1343 Train Loss 901.39856\n",
      "1344 Train Loss 901.3922\n",
      "1345 Train Loss 901.3823\n",
      "1346 Train Loss 901.3723\n",
      "1347 Train Loss 901.3569\n",
      "1348 Train Loss 901.34534\n",
      "1349 Train Loss 901.34155\n",
      "1350 Train Loss 901.3356\n",
      "1351 Train Loss 901.33356\n",
      "1352 Train Loss 901.3301\n",
      "1353 Train Loss 901.3245\n",
      "1354 Train Loss 901.31885\n",
      "1355 Train Loss 901.31213\n",
      "1356 Train Loss 901.3075\n",
      "1357 Train Loss 901.30566\n",
      "1358 Train Loss 901.30426\n",
      "1359 Train Loss 901.3035\n",
      "1360 Train Loss 901.3026\n",
      "1361 Train Loss 901.301\n",
      "1362 Train Loss 901.29913\n",
      "1363 Train Loss 901.29553\n",
      "1364 Train Loss 901.28864\n",
      "1365 Train Loss 901.2774\n",
      "1366 Train Loss 901.2877\n",
      "1367 Train Loss 901.2716\n",
      "1368 Train Loss 901.286\n",
      "1369 Train Loss 901.25714\n",
      "1370 Train Loss 901.249\n",
      "1371 Train Loss 901.2437\n",
      "1372 Train Loss 901.24274\n",
      "1373 Train Loss 901.2392\n",
      "1374 Train Loss 901.2362\n",
      "1375 Train Loss 901.23224\n",
      "1376 Train Loss 901.22675\n",
      "1377 Train Loss 901.22327\n",
      "1378 Train Loss 901.2192\n",
      "1379 Train Loss 901.2165\n",
      "1380 Train Loss 901.2129\n",
      "1381 Train Loss 901.2096\n",
      "1382 Train Loss 901.20544\n",
      "1383 Train Loss 901.1997\n",
      "1384 Train Loss 901.1866\n",
      "1385 Train Loss 901.17804\n",
      "1386 Train Loss 901.1569\n",
      "1387 Train Loss 901.17175\n",
      "1388 Train Loss 901.1374\n",
      "1389 Train Loss 901.1125\n",
      "1390 Train Loss 901.0991\n",
      "1391 Train Loss 901.0882\n",
      "1392 Train Loss 901.077\n",
      "1393 Train Loss 901.0642\n",
      "1394 Train Loss 901.0469\n",
      "1395 Train Loss 901.0301\n",
      "1396 Train Loss 901.01416\n",
      "1397 Train Loss 901.01465\n",
      "1398 Train Loss 901.001\n",
      "1399 Train Loss 900.9937\n",
      "1400 Train Loss 900.9862\n",
      "1401 Train Loss 900.97675\n",
      "1402 Train Loss 900.9725\n",
      "1403 Train Loss 900.9652\n",
      "1404 Train Loss 900.9592\n",
      "1405 Train Loss 900.95386\n",
      "1406 Train Loss 900.94495\n",
      "1407 Train Loss 900.9291\n",
      "1408 Train Loss 900.9155\n",
      "1409 Train Loss 900.90607\n",
      "1410 Train Loss 900.8952\n",
      "1411 Train Loss 900.88324\n",
      "1412 Train Loss 900.8697\n",
      "1413 Train Loss 900.8579\n",
      "1414 Train Loss 900.8529\n",
      "1415 Train Loss 900.8651\n",
      "1416 Train Loss 900.84515\n",
      "1417 Train Loss 900.8448\n",
      "1418 Train Loss 900.8373\n",
      "1419 Train Loss 900.8311\n",
      "1420 Train Loss 900.81946\n",
      "1421 Train Loss 900.7966\n",
      "1422 Train Loss 900.7837\n",
      "1423 Train Loss 900.74744\n",
      "1424 Train Loss 900.7405\n",
      "1425 Train Loss 900.73224\n",
      "1426 Train Loss 900.69855\n",
      "1427 Train Loss 900.6616\n",
      "1428 Train Loss 900.6482\n",
      "1429 Train Loss 900.6638\n",
      "1430 Train Loss 900.6181\n",
      "1431 Train Loss 900.6012\n",
      "1432 Train Loss 900.5734\n",
      "1433 Train Loss 900.5365\n",
      "1434 Train Loss 900.4904\n",
      "1435 Train Loss 900.4486\n",
      "1436 Train Loss 900.477\n",
      "1437 Train Loss 900.42395\n",
      "1438 Train Loss 900.3875\n",
      "1439 Train Loss 900.36194\n",
      "1440 Train Loss 900.3696\n",
      "1441 Train Loss 900.33484\n",
      "1442 Train Loss 900.3359\n",
      "1443 Train Loss 900.3114\n",
      "1444 Train Loss 900.27484\n",
      "1445 Train Loss 900.2557\n",
      "1446 Train Loss 900.22455\n",
      "1447 Train Loss 900.2006\n",
      "1448 Train Loss 900.1777\n",
      "1449 Train Loss 900.1476\n",
      "1450 Train Loss 900.1216\n",
      "1451 Train Loss 900.0842\n",
      "1452 Train Loss 900.0795\n",
      "1453 Train Loss 900.0644\n",
      "1454 Train Loss 900.06165\n",
      "1455 Train Loss 900.0528\n",
      "1456 Train Loss 900.0482\n",
      "1457 Train Loss 900.0451\n",
      "1458 Train Loss 900.0429\n",
      "1459 Train Loss 900.03973\n",
      "1460 Train Loss 900.03503\n",
      "1461 Train Loss 900.03394\n",
      "1462 Train Loss 900.0265\n",
      "1463 Train Loss 900.0188\n",
      "1464 Train Loss 900.00635\n",
      "1465 Train Loss 899.9925\n",
      "1466 Train Loss 899.9837\n",
      "1467 Train Loss 899.97455\n",
      "1468 Train Loss 899.9682\n",
      "1469 Train Loss 899.96686\n",
      "1470 Train Loss 899.96234\n",
      "1471 Train Loss 899.95624\n",
      "1472 Train Loss 899.948\n",
      "1473 Train Loss 899.9373\n",
      "1474 Train Loss 899.92725\n",
      "1475 Train Loss 899.91595\n",
      "1476 Train Loss 899.9103\n",
      "1477 Train Loss 899.9062\n",
      "1478 Train Loss 899.90405\n",
      "1479 Train Loss 899.90155\n",
      "1480 Train Loss 899.89984\n",
      "1481 Train Loss 899.89813\n",
      "1482 Train Loss 899.89685\n",
      "1483 Train Loss 899.89545\n",
      "1484 Train Loss 899.8936\n",
      "1485 Train Loss 899.89246\n",
      "1486 Train Loss 899.89594\n",
      "1487 Train Loss 899.89136\n",
      "1488 Train Loss 899.88873\n",
      "1489 Train Loss 899.8845\n",
      "1490 Train Loss 899.87976\n",
      "1491 Train Loss 899.8751\n",
      "1492 Train Loss 899.8707\n",
      "1493 Train Loss 899.8655\n",
      "1494 Train Loss 899.85986\n",
      "1495 Train Loss 899.8541\n",
      "1496 Train Loss 899.8481\n",
      "1497 Train Loss 899.8397\n",
      "1498 Train Loss 899.8294\n",
      "1499 Train Loss 899.8186\n",
      "1500 Train Loss 899.8119\n",
      "1501 Train Loss 899.8054\n",
      "1502 Train Loss 899.79816\n",
      "1503 Train Loss 899.78766\n",
      "1504 Train Loss 899.77673\n",
      "1505 Train Loss 899.7627\n",
      "1506 Train Loss 899.77844\n",
      "1507 Train Loss 899.75104\n",
      "1508 Train Loss 899.73706\n",
      "1509 Train Loss 899.72626\n",
      "1510 Train Loss 899.73114\n",
      "1511 Train Loss 899.7209\n",
      "1512 Train Loss 899.7154\n",
      "1513 Train Loss 899.71344\n",
      "1514 Train Loss 899.7065\n",
      "1515 Train Loss 899.7066\n",
      "1516 Train Loss 899.7049\n",
      "1517 Train Loss 899.7012\n",
      "1518 Train Loss 899.6969\n",
      "1519 Train Loss 899.694\n",
      "1520 Train Loss 899.69037\n",
      "1521 Train Loss 899.6848\n",
      "1522 Train Loss 899.68054\n",
      "1523 Train Loss 899.6742\n",
      "1524 Train Loss 899.6651\n",
      "1525 Train Loss 899.6518\n",
      "1526 Train Loss 899.6349\n",
      "1527 Train Loss 899.6256\n",
      "1528 Train Loss 899.6114\n",
      "1529 Train Loss 899.60254\n",
      "1530 Train Loss 899.59784\n",
      "1531 Train Loss 899.5794\n",
      "1532 Train Loss 899.5661\n",
      "1533 Train Loss 899.54736\n",
      "1534 Train Loss 899.5202\n",
      "1535 Train Loss 899.4986\n",
      "1536 Train Loss 899.48816\n",
      "1537 Train Loss 899.44904\n",
      "1538 Train Loss 899.42346\n",
      "1539 Train Loss 899.40576\n",
      "1540 Train Loss 899.38196\n",
      "1541 Train Loss 899.36743\n",
      "1542 Train Loss 899.3548\n",
      "1543 Train Loss 899.33734\n",
      "1544 Train Loss 899.33136\n",
      "1545 Train Loss 899.3155\n",
      "1546 Train Loss 899.3095\n",
      "1547 Train Loss 899.3057\n",
      "1548 Train Loss 899.3029\n",
      "1549 Train Loss 899.29877\n",
      "1550 Train Loss 899.29346\n",
      "1551 Train Loss 899.2889\n",
      "1552 Train Loss 899.28503\n",
      "1553 Train Loss 899.28174\n",
      "1554 Train Loss 899.2781\n",
      "1555 Train Loss 899.2729\n",
      "1556 Train Loss 899.26575\n",
      "1557 Train Loss 899.2595\n",
      "1558 Train Loss 899.25696\n",
      "1559 Train Loss 899.2524\n",
      "1560 Train Loss 899.24524\n",
      "1561 Train Loss 899.24146\n",
      "1562 Train Loss 899.2382\n",
      "1563 Train Loss 899.2348\n",
      "1564 Train Loss 899.23303\n",
      "1565 Train Loss 899.23145\n",
      "1566 Train Loss 899.23\n",
      "1567 Train Loss 899.2284\n",
      "1568 Train Loss 899.22565\n",
      "1569 Train Loss 899.2227\n",
      "1570 Train Loss 899.21436\n",
      "1571 Train Loss 899.21014\n",
      "1572 Train Loss 899.22015\n",
      "1573 Train Loss 899.2045\n",
      "1574 Train Loss 899.2009\n",
      "1575 Train Loss 899.193\n",
      "1576 Train Loss 899.18915\n",
      "1577 Train Loss 899.1861\n",
      "1578 Train Loss 899.1829\n",
      "1579 Train Loss 899.18\n",
      "1580 Train Loss 899.178\n",
      "1581 Train Loss 899.17456\n",
      "1582 Train Loss 899.17126\n",
      "1583 Train Loss 899.1695\n",
      "1584 Train Loss 899.16797\n",
      "1585 Train Loss 899.166\n",
      "1586 Train Loss 899.16345\n",
      "1587 Train Loss 899.161\n",
      "1588 Train Loss 899.15814\n",
      "1589 Train Loss 899.15216\n",
      "1590 Train Loss 899.14844\n",
      "1591 Train Loss 899.1434\n",
      "1592 Train Loss 899.1384\n",
      "1593 Train Loss 899.13324\n",
      "1594 Train Loss 899.12616\n",
      "1595 Train Loss 899.1233\n",
      "1596 Train Loss 899.1153\n",
      "1597 Train Loss 899.11066\n",
      "1598 Train Loss 899.1074\n",
      "1599 Train Loss 899.1029\n",
      "1600 Train Loss 899.1003\n",
      "1601 Train Loss 899.09906\n",
      "1602 Train Loss 899.0962\n",
      "1603 Train Loss 899.09436\n",
      "1604 Train Loss 899.0924\n",
      "1605 Train Loss 899.091\n",
      "1606 Train Loss 899.0876\n",
      "1607 Train Loss 899.0854\n",
      "1608 Train Loss 899.08185\n",
      "1609 Train Loss 899.07465\n",
      "1610 Train Loss 899.0704\n",
      "1611 Train Loss 899.0698\n",
      "1612 Train Loss 899.06854\n",
      "1613 Train Loss 899.0666\n",
      "1614 Train Loss 899.06494\n",
      "1615 Train Loss 899.0634\n",
      "1616 Train Loss 899.06274\n",
      "1617 Train Loss 899.06165\n",
      "1618 Train Loss 899.0605\n",
      "1619 Train Loss 899.0595\n",
      "1620 Train Loss 899.05774\n",
      "1621 Train Loss 899.05634\n",
      "1622 Train Loss 899.0535\n",
      "1623 Train Loss 899.0505\n",
      "1624 Train Loss 899.0485\n",
      "1625 Train Loss 899.0463\n",
      "1626 Train Loss 899.0446\n",
      "1627 Train Loss 899.0424\n",
      "1628 Train Loss 899.0398\n",
      "1629 Train Loss 899.0357\n",
      "1630 Train Loss 899.0269\n",
      "1631 Train Loss 899.0295\n",
      "1632 Train Loss 899.022\n",
      "1633 Train Loss 899.0126\n",
      "1634 Train Loss 899.0436\n",
      "1635 Train Loss 899.00696\n",
      "1636 Train Loss 899.00055\n",
      "1637 Train Loss 898.995\n",
      "1638 Train Loss 898.99225\n",
      "1639 Train Loss 898.9824\n",
      "1640 Train Loss 898.97034\n",
      "1641 Train Loss 898.96216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1642 Train Loss 898.96857\n",
      "1643 Train Loss 898.9562\n",
      "1644 Train Loss 898.9532\n",
      "1645 Train Loss 898.94696\n",
      "1646 Train Loss 898.94696\n",
      "1647 Train Loss 898.944\n",
      "1648 Train Loss 898.9404\n",
      "1649 Train Loss 898.9363\n",
      "1650 Train Loss 898.9449\n",
      "1651 Train Loss 898.9329\n",
      "1652 Train Loss 898.92804\n",
      "1653 Train Loss 898.9368\n",
      "1654 Train Loss 898.9265\n",
      "1655 Train Loss 898.92303\n",
      "1656 Train Loss 898.9213\n",
      "1657 Train Loss 898.9209\n",
      "1658 Train Loss 898.91956\n",
      "1659 Train Loss 898.91907\n",
      "1660 Train Loss 898.918\n",
      "1661 Train Loss 898.91724\n",
      "1662 Train Loss 898.9164\n",
      "1663 Train Loss 898.91473\n",
      "1664 Train Loss 898.91174\n",
      "1665 Train Loss 898.90814\n",
      "1666 Train Loss 898.90356\n",
      "1667 Train Loss 898.9008\n",
      "1668 Train Loss 898.8962\n",
      "1669 Train Loss 898.89233\n",
      "1670 Train Loss 898.8857\n",
      "1671 Train Loss 898.87506\n",
      "1672 Train Loss 898.9219\n",
      "1673 Train Loss 898.8725\n",
      "1674 Train Loss 898.868\n",
      "1675 Train Loss 898.86365\n",
      "1676 Train Loss 898.8596\n",
      "1677 Train Loss 898.8536\n",
      "1678 Train Loss 898.8501\n",
      "1679 Train Loss 898.8432\n",
      "1680 Train Loss 898.83777\n",
      "1681 Train Loss 898.8361\n",
      "1682 Train Loss 898.8514\n",
      "1683 Train Loss 898.8321\n",
      "1684 Train Loss 898.82947\n",
      "1685 Train Loss 898.827\n",
      "1686 Train Loss 898.82654\n",
      "1687 Train Loss 898.82196\n",
      "1688 Train Loss 898.81714\n",
      "1689 Train Loss 899.02094\n",
      "1690 Train Loss 898.81354\n",
      "1691 Train Loss 898.80396\n",
      "1692 Train Loss 898.8094\n",
      "1693 Train Loss 898.791\n",
      "1694 Train Loss 898.7733\n",
      "1695 Train Loss 898.7612\n",
      "1696 Train Loss 898.74646\n",
      "1697 Train Loss 898.7261\n",
      "1698 Train Loss 898.71625\n",
      "1699 Train Loss 898.7006\n",
      "1700 Train Loss 898.70154\n",
      "1701 Train Loss 898.69666\n",
      "1702 Train Loss 898.69073\n",
      "1703 Train Loss 898.68225\n",
      "1704 Train Loss 898.6761\n",
      "1705 Train Loss 898.67267\n",
      "1706 Train Loss 898.6669\n",
      "1707 Train Loss 898.6637\n",
      "1708 Train Loss 898.6591\n",
      "1709 Train Loss 898.654\n",
      "1710 Train Loss 898.649\n",
      "1711 Train Loss 898.6427\n",
      "1712 Train Loss 898.6426\n",
      "1713 Train Loss 898.638\n",
      "1714 Train Loss 898.62964\n",
      "1715 Train Loss 898.624\n",
      "1716 Train Loss 898.6173\n",
      "1717 Train Loss 898.6139\n",
      "1718 Train Loss 898.6089\n",
      "1719 Train Loss 898.60504\n",
      "1720 Train Loss 898.60205\n",
      "1721 Train Loss 898.60046\n",
      "1722 Train Loss 898.5996\n",
      "1723 Train Loss 898.5992\n",
      "1724 Train Loss 898.59875\n",
      "1725 Train Loss 898.59753\n",
      "1726 Train Loss 898.5969\n",
      "1727 Train Loss 898.5952\n",
      "1728 Train Loss 898.59314\n",
      "1729 Train Loss 898.5905\n",
      "1730 Train Loss 898.58765\n",
      "1731 Train Loss 898.5852\n",
      "1732 Train Loss 898.58386\n",
      "1733 Train Loss 898.5828\n",
      "1734 Train Loss 898.582\n",
      "1735 Train Loss 898.5804\n",
      "1736 Train Loss 898.5784\n",
      "1737 Train Loss 898.5746\n",
      "1738 Train Loss 898.5674\n",
      "1739 Train Loss 898.5577\n",
      "1740 Train Loss 898.55005\n",
      "1741 Train Loss 898.5419\n",
      "1742 Train Loss 898.5501\n",
      "1743 Train Loss 898.538\n",
      "1744 Train Loss 898.54126\n",
      "1745 Train Loss 898.5329\n",
      "1746 Train Loss 898.5273\n",
      "1747 Train Loss 898.5164\n",
      "1748 Train Loss 898.50696\n",
      "1749 Train Loss 898.5003\n",
      "1750 Train Loss 898.49335\n",
      "1751 Train Loss 898.4842\n",
      "1752 Train Loss 898.4711\n",
      "1753 Train Loss 898.4713\n",
      "1754 Train Loss 898.46094\n",
      "1755 Train Loss 898.4533\n",
      "1756 Train Loss 898.4999\n",
      "1757 Train Loss 898.44885\n",
      "1758 Train Loss 898.4432\n",
      "1759 Train Loss 898.44\n",
      "1760 Train Loss 898.436\n",
      "1761 Train Loss 898.4336\n",
      "1762 Train Loss 898.42975\n",
      "1763 Train Loss 898.42523\n",
      "1764 Train Loss 898.4142\n",
      "1765 Train Loss 898.4058\n",
      "1766 Train Loss 898.4001\n",
      "1767 Train Loss 898.41046\n",
      "1768 Train Loss 898.39\n",
      "1769 Train Loss 898.5186\n",
      "1770 Train Loss 898.3798\n",
      "1771 Train Loss 898.37305\n",
      "1772 Train Loss 898.36383\n",
      "1773 Train Loss 898.34955\n",
      "1774 Train Loss 898.3432\n",
      "1775 Train Loss 898.3338\n",
      "1776 Train Loss 898.32544\n",
      "1777 Train Loss 898.3191\n",
      "1778 Train Loss 898.3171\n",
      "1779 Train Loss 898.30896\n",
      "1780 Train Loss 898.30774\n",
      "1781 Train Loss 898.30035\n",
      "1782 Train Loss 898.2989\n",
      "1783 Train Loss 898.2966\n",
      "1784 Train Loss 898.29285\n",
      "1785 Train Loss 898.2908\n",
      "1786 Train Loss 898.28546\n",
      "1787 Train Loss 898.312\n",
      "1788 Train Loss 898.2844\n",
      "1789 Train Loss 898.2808\n",
      "1790 Train Loss 898.2763\n",
      "1791 Train Loss 898.27203\n",
      "1792 Train Loss 898.26886\n",
      "1793 Train Loss 898.2657\n",
      "1794 Train Loss 898.261\n",
      "1795 Train Loss 898.25244\n",
      "1796 Train Loss 898.25415\n",
      "1797 Train Loss 898.24744\n",
      "1798 Train Loss 898.2441\n",
      "1799 Train Loss 898.2402\n",
      "1800 Train Loss 898.23285\n",
      "1801 Train Loss 898.22675\n",
      "1802 Train Loss 898.2218\n",
      "1803 Train Loss 898.21814\n",
      "1804 Train Loss 898.2133\n",
      "1805 Train Loss 898.2101\n",
      "1806 Train Loss 898.2067\n",
      "1807 Train Loss 898.2035\n",
      "1808 Train Loss 898.2\n",
      "1809 Train Loss 898.1965\n",
      "1810 Train Loss 898.1924\n",
      "1811 Train Loss 898.1899\n",
      "1812 Train Loss 898.1866\n",
      "1813 Train Loss 898.18414\n",
      "1814 Train Loss 898.1798\n",
      "1815 Train Loss 898.1762\n",
      "1816 Train Loss 898.1707\n",
      "1817 Train Loss 898.163\n",
      "1818 Train Loss 898.1553\n",
      "1819 Train Loss 898.1607\n",
      "1820 Train Loss 898.1504\n",
      "1821 Train Loss 898.14496\n",
      "1822 Train Loss 898.13214\n",
      "1823 Train Loss 898.1219\n",
      "1824 Train Loss 898.1177\n",
      "1825 Train Loss 898.113\n",
      "1826 Train Loss 898.10315\n",
      "1827 Train Loss 898.08777\n",
      "1828 Train Loss 898.0793\n",
      "1829 Train Loss 898.0909\n",
      "1830 Train Loss 898.0683\n",
      "1831 Train Loss 898.05676\n",
      "1832 Train Loss 898.04553\n",
      "1833 Train Loss 898.0423\n",
      "1834 Train Loss 898.0371\n",
      "1835 Train Loss 898.0354\n",
      "1836 Train Loss 898.0376\n",
      "1837 Train Loss 898.02747\n",
      "1838 Train Loss 898.0275\n",
      "1839 Train Loss 898.0197\n",
      "1840 Train Loss 898.0144\n",
      "1841 Train Loss 898.005\n",
      "1842 Train Loss 898.0039\n",
      "1843 Train Loss 897.9982\n",
      "1844 Train Loss 897.9968\n",
      "1845 Train Loss 897.9926\n",
      "1846 Train Loss 897.987\n",
      "1847 Train Loss 897.9822\n",
      "1848 Train Loss 897.9744\n",
      "1849 Train Loss 897.9716\n",
      "1850 Train Loss 897.9647\n",
      "1851 Train Loss 897.95807\n",
      "1852 Train Loss 897.95\n",
      "1853 Train Loss 897.94446\n",
      "1854 Train Loss 897.9354\n",
      "1855 Train Loss 897.9244\n",
      "1856 Train Loss 897.9911\n",
      "1857 Train Loss 897.92017\n",
      "1858 Train Loss 897.9113\n",
      "1859 Train Loss 897.90454\n",
      "1860 Train Loss 897.90015\n",
      "1861 Train Loss 897.895\n",
      "1862 Train Loss 897.88824\n",
      "1863 Train Loss 897.8842\n",
      "1864 Train Loss 897.8753\n",
      "1865 Train Loss 897.8677\n",
      "1866 Train Loss 897.8607\n",
      "1867 Train Loss 897.8569\n",
      "1868 Train Loss 897.84515\n",
      "1869 Train Loss 897.8397\n",
      "1870 Train Loss 897.8305\n",
      "1871 Train Loss 897.8223\n",
      "1872 Train Loss 897.8184\n",
      "1873 Train Loss 897.81335\n",
      "1874 Train Loss 897.81024\n",
      "1875 Train Loss 897.8087\n",
      "1876 Train Loss 897.8061\n",
      "1877 Train Loss 897.80365\n",
      "1878 Train Loss 897.79956\n",
      "1879 Train Loss 897.7971\n",
      "1880 Train Loss 897.7951\n",
      "1881 Train Loss 897.7937\n",
      "1882 Train Loss 897.7915\n",
      "1883 Train Loss 897.7854\n",
      "1884 Train Loss 897.7805\n",
      "1885 Train Loss 897.77576\n",
      "1886 Train Loss 897.7697\n",
      "1887 Train Loss 897.7698\n",
      "1888 Train Loss 897.766\n",
      "1889 Train Loss 897.7623\n",
      "1890 Train Loss 897.7595\n",
      "1891 Train Loss 897.759\n",
      "1892 Train Loss 897.75793\n",
      "1893 Train Loss 897.75635\n",
      "1894 Train Loss 897.7552\n",
      "1895 Train Loss 897.754\n",
      "1896 Train Loss 897.7532\n",
      "1897 Train Loss 897.75226\n",
      "1898 Train Loss 897.75116\n",
      "1899 Train Loss 897.7494\n",
      "1900 Train Loss 897.7481\n",
      "1901 Train Loss 897.74615\n",
      "1902 Train Loss 897.7445\n",
      "1903 Train Loss 897.74274\n",
      "1904 Train Loss 897.74054\n",
      "1905 Train Loss 897.7394\n",
      "1906 Train Loss 897.7369\n",
      "1907 Train Loss 897.73517\n",
      "1908 Train Loss 897.7333\n",
      "1909 Train Loss 897.7315\n",
      "1910 Train Loss 897.72876\n",
      "1911 Train Loss 897.7269\n",
      "1912 Train Loss 897.7265\n",
      "1913 Train Loss 897.7246\n",
      "1914 Train Loss 897.72375\n",
      "1915 Train Loss 897.72296\n",
      "1916 Train Loss 897.7211\n",
      "1917 Train Loss 897.7206\n",
      "1918 Train Loss 897.71954\n",
      "1919 Train Loss 897.71826\n",
      "1920 Train Loss 897.7173\n",
      "1921 Train Loss 897.7146\n",
      "1922 Train Loss 897.71234\n",
      "1923 Train Loss 897.7108\n",
      "1924 Train Loss 897.7138\n",
      "1925 Train Loss 897.7102\n",
      "1926 Train Loss 897.7091\n",
      "1927 Train Loss 897.7077\n",
      "1928 Train Loss 897.7064\n",
      "1929 Train Loss 897.7047\n",
      "1930 Train Loss 897.7034\n",
      "1931 Train Loss 897.7016\n",
      "1932 Train Loss 897.6992\n",
      "1933 Train Loss 897.6969\n",
      "1934 Train Loss 897.6946\n",
      "1935 Train Loss 897.6932\n",
      "1936 Train Loss 897.69183\n",
      "1937 Train Loss 897.6903\n",
      "1938 Train Loss 897.6893\n",
      "1939 Train Loss 897.6882\n",
      "1940 Train Loss 897.6874\n",
      "1941 Train Loss 897.6868\n",
      "1942 Train Loss 897.6859\n",
      "1943 Train Loss 897.68555\n",
      "1944 Train Loss 897.68475\n",
      "1945 Train Loss 897.68317\n",
      "1946 Train Loss 897.68286\n",
      "1947 Train Loss 897.6803\n",
      "1948 Train Loss 897.67804\n",
      "1949 Train Loss 897.67596\n",
      "1950 Train Loss 897.6747\n",
      "1951 Train Loss 897.6732\n",
      "1952 Train Loss 897.67224\n",
      "1953 Train Loss 897.67126\n",
      "1954 Train Loss 897.67\n",
      "1955 Train Loss 897.6667\n",
      "1956 Train Loss 897.6625\n",
      "1957 Train Loss 897.66327\n",
      "1958 Train Loss 897.66016\n",
      "1959 Train Loss 897.65686\n",
      "1960 Train Loss 897.65393\n",
      "1961 Train Loss 897.6514\n",
      "1962 Train Loss 897.6509\n",
      "1963 Train Loss 897.64966\n",
      "1964 Train Loss 897.6488\n",
      "1965 Train Loss 897.6472\n",
      "1966 Train Loss 897.6447\n",
      "1967 Train Loss 897.64087\n",
      "1968 Train Loss 897.63605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969 Train Loss 897.65247\n",
      "1970 Train Loss 897.6333\n",
      "1971 Train Loss 897.628\n",
      "1972 Train Loss 897.625\n",
      "1973 Train Loss 897.62024\n",
      "1974 Train Loss 897.62244\n",
      "1975 Train Loss 897.61884\n",
      "1976 Train Loss 897.6166\n",
      "1977 Train Loss 897.6146\n",
      "1978 Train Loss 897.61163\n",
      "1979 Train Loss 897.6077\n",
      "1980 Train Loss 897.6059\n",
      "1981 Train Loss 897.60443\n",
      "1982 Train Loss 897.60394\n",
      "1983 Train Loss 897.6007\n",
      "1984 Train Loss 897.5993\n",
      "1985 Train Loss 897.5977\n",
      "1986 Train Loss 897.5959\n",
      "1987 Train Loss 897.5942\n",
      "1988 Train Loss 897.59283\n",
      "1989 Train Loss 897.59045\n",
      "1990 Train Loss 897.58795\n",
      "1991 Train Loss 897.5859\n",
      "1992 Train Loss 897.584\n",
      "1993 Train Loss 897.58264\n",
      "1994 Train Loss 897.5813\n",
      "1995 Train Loss 897.58044\n",
      "1996 Train Loss 897.5799\n",
      "1997 Train Loss 897.5792\n",
      "1998 Train Loss 897.5786\n",
      "1999 Train Loss 897.5777\n",
      "2000 Train Loss 897.5763\n",
      "2001 Train Loss 897.5761\n",
      "2002 Train Loss 897.5741\n",
      "2003 Train Loss 897.5728\n",
      "2004 Train Loss 897.57135\n",
      "2005 Train Loss 897.5696\n",
      "2006 Train Loss 897.5678\n",
      "2007 Train Loss 897.56586\n",
      "2008 Train Loss 897.5649\n",
      "2009 Train Loss 897.5637\n",
      "2010 Train Loss 897.5619\n",
      "2011 Train Loss 897.5598\n",
      "2012 Train Loss 897.5573\n",
      "2013 Train Loss 897.55615\n",
      "2014 Train Loss 897.5532\n",
      "2015 Train Loss 897.5513\n",
      "2016 Train Loss 897.54767\n",
      "2017 Train Loss 897.54486\n",
      "2018 Train Loss 897.54095\n",
      "2019 Train Loss 897.5366\n",
      "2020 Train Loss 897.5333\n",
      "2021 Train Loss 897.5322\n",
      "2022 Train Loss 897.5315\n",
      "2023 Train Loss 897.5288\n",
      "2024 Train Loss 897.52527\n",
      "2025 Train Loss 897.525\n",
      "2026 Train Loss 897.524\n",
      "2027 Train Loss 897.5244\n",
      "2028 Train Loss 897.5222\n",
      "2029 Train Loss 897.52106\n",
      "2030 Train Loss 897.51935\n",
      "2031 Train Loss 897.5184\n",
      "2032 Train Loss 897.51715\n",
      "2033 Train Loss 897.5161\n",
      "2034 Train Loss 897.51514\n",
      "2035 Train Loss 897.513\n",
      "2036 Train Loss 897.5094\n",
      "2037 Train Loss 897.50885\n",
      "2038 Train Loss 897.5083\n",
      "2039 Train Loss 897.5047\n",
      "2040 Train Loss 897.50085\n",
      "2041 Train Loss 897.4975\n",
      "2042 Train Loss 897.4921\n",
      "2043 Train Loss 897.48694\n",
      "2044 Train Loss 897.4783\n",
      "2045 Train Loss 897.497\n",
      "2046 Train Loss 897.4749\n",
      "2047 Train Loss 897.46515\n",
      "2048 Train Loss 897.46094\n",
      "2049 Train Loss 897.45483\n",
      "2050 Train Loss 897.44946\n",
      "2051 Train Loss 897.4453\n",
      "2052 Train Loss 897.44147\n",
      "2053 Train Loss 897.4377\n",
      "2054 Train Loss 897.43414\n",
      "2055 Train Loss 897.433\n",
      "2056 Train Loss 897.4284\n",
      "2057 Train Loss 897.4615\n",
      "2058 Train Loss 897.4252\n",
      "2059 Train Loss 897.4219\n",
      "2060 Train Loss 897.4201\n",
      "2061 Train Loss 897.41754\n",
      "2062 Train Loss 897.4156\n",
      "2063 Train Loss 897.4134\n",
      "2064 Train Loss 897.4115\n",
      "2065 Train Loss 897.4091\n",
      "2066 Train Loss 897.40674\n",
      "2067 Train Loss 897.40326\n",
      "2068 Train Loss 897.39996\n",
      "2069 Train Loss 897.39795\n",
      "2070 Train Loss 897.39417\n",
      "2071 Train Loss 897.3918\n",
      "2072 Train Loss 897.38794\n",
      "2073 Train Loss 897.3826\n",
      "2074 Train Loss 897.3854\n",
      "2075 Train Loss 897.38025\n",
      "2076 Train Loss 897.37506\n",
      "2077 Train Loss 897.3716\n",
      "2078 Train Loss 897.3691\n",
      "2079 Train Loss 897.36633\n",
      "2080 Train Loss 897.3638\n",
      "2081 Train Loss 897.362\n",
      "2082 Train Loss 897.35895\n",
      "2083 Train Loss 897.3555\n",
      "2084 Train Loss 897.3516\n",
      "2085 Train Loss 897.34766\n",
      "2086 Train Loss 897.3454\n",
      "2087 Train Loss 897.34265\n",
      "2088 Train Loss 897.3391\n",
      "2089 Train Loss 897.3348\n",
      "2090 Train Loss 897.3297\n",
      "2091 Train Loss 897.3252\n",
      "2092 Train Loss 897.32355\n",
      "2093 Train Loss 897.323\n",
      "2094 Train Loss 897.3208\n",
      "2095 Train Loss 897.3195\n",
      "2096 Train Loss 897.3185\n",
      "2097 Train Loss 897.31683\n",
      "2098 Train Loss 897.31494\n",
      "2099 Train Loss 897.32745\n",
      "2100 Train Loss 897.3139\n",
      "2101 Train Loss 897.3124\n",
      "2102 Train Loss 897.31036\n",
      "2103 Train Loss 897.3078\n",
      "2104 Train Loss 897.305\n",
      "2105 Train Loss 897.30145\n",
      "2106 Train Loss 897.29767\n",
      "2107 Train Loss 897.2937\n",
      "2108 Train Loss 897.2919\n",
      "2109 Train Loss 897.2896\n",
      "2110 Train Loss 897.28906\n",
      "2111 Train Loss 897.28845\n",
      "2112 Train Loss 897.28723\n",
      "2113 Train Loss 897.2866\n",
      "2114 Train Loss 897.2861\n",
      "2115 Train Loss 897.2848\n",
      "2116 Train Loss 897.28357\n",
      "2117 Train Loss 897.2809\n",
      "2118 Train Loss 897.2792\n",
      "2119 Train Loss 897.2777\n",
      "2120 Train Loss 897.27655\n",
      "2121 Train Loss 897.2753\n",
      "2122 Train Loss 897.27423\n",
      "2123 Train Loss 897.27246\n",
      "2124 Train Loss 897.2706\n",
      "2125 Train Loss 897.2688\n",
      "2126 Train Loss 897.26605\n",
      "2127 Train Loss 897.2612\n",
      "2128 Train Loss 897.25757\n",
      "2129 Train Loss 897.25885\n",
      "2130 Train Loss 897.2544\n",
      "2131 Train Loss 897.24976\n",
      "2132 Train Loss 897.2482\n",
      "2133 Train Loss 897.24677\n",
      "2134 Train Loss 897.2385\n",
      "2135 Train Loss 897.2338\n",
      "2136 Train Loss 897.22986\n",
      "2137 Train Loss 897.22675\n",
      "2138 Train Loss 897.22284\n",
      "2139 Train Loss 897.21967\n",
      "2140 Train Loss 897.2182\n",
      "2141 Train Loss 897.216\n",
      "2142 Train Loss 897.21814\n",
      "2143 Train Loss 897.21423\n",
      "2144 Train Loss 897.2123\n",
      "2145 Train Loss 897.21063\n",
      "2146 Train Loss 897.20874\n",
      "2147 Train Loss 897.20605\n",
      "2148 Train Loss 897.2029\n",
      "2149 Train Loss 897.19727\n",
      "2150 Train Loss 897.1913\n",
      "2151 Train Loss 897.1926\n",
      "2152 Train Loss 897.18695\n",
      "2153 Train Loss 897.18225\n",
      "2154 Train Loss 897.186\n",
      "2155 Train Loss 897.1763\n",
      "2156 Train Loss 897.17\n",
      "2157 Train Loss 897.1663\n",
      "2158 Train Loss 897.16254\n",
      "2159 Train Loss 897.1585\n",
      "2160 Train Loss 897.1548\n",
      "2161 Train Loss 897.1524\n",
      "2162 Train Loss 897.1501\n",
      "2163 Train Loss 897.1473\n",
      "2164 Train Loss 897.14026\n",
      "2165 Train Loss 897.1354\n",
      "2166 Train Loss 897.1383\n",
      "2167 Train Loss 897.12964\n",
      "2168 Train Loss 897.1196\n",
      "2169 Train Loss 897.1166\n",
      "2170 Train Loss 897.1289\n",
      "2171 Train Loss 897.11273\n",
      "2172 Train Loss 897.10767\n",
      "2173 Train Loss 897.1032\n",
      "2174 Train Loss 897.0985\n",
      "2175 Train Loss 897.0978\n",
      "2176 Train Loss 897.0962\n",
      "2177 Train Loss 897.09326\n",
      "2178 Train Loss 897.0922\n",
      "2179 Train Loss 897.0901\n",
      "2180 Train Loss 897.0861\n",
      "2181 Train Loss 897.0801\n",
      "2182 Train Loss 897.07886\n",
      "2183 Train Loss 897.07684\n",
      "2184 Train Loss 897.0732\n",
      "2185 Train Loss 897.06586\n",
      "2186 Train Loss 897.0624\n",
      "2187 Train Loss 897.05884\n",
      "2188 Train Loss 897.0561\n",
      "2189 Train Loss 897.0525\n",
      "2190 Train Loss 897.0481\n",
      "2191 Train Loss 897.0393\n",
      "2192 Train Loss 897.0324\n",
      "2193 Train Loss 897.0263\n",
      "2194 Train Loss 897.02325\n",
      "2195 Train Loss 897.0305\n",
      "2196 Train Loss 897.02216\n",
      "2197 Train Loss 897.0201\n",
      "2198 Train Loss 897.0161\n",
      "2199 Train Loss 897.01196\n",
      "2200 Train Loss 897.0078\n",
      "2201 Train Loss 897.0696\n",
      "2202 Train Loss 897.0068\n",
      "2203 Train Loss 897.0009\n",
      "2204 Train Loss 896.9961\n",
      "2205 Train Loss 896.99603\n",
      "2206 Train Loss 896.9928\n",
      "2207 Train Loss 896.99036\n",
      "2208 Train Loss 896.9879\n",
      "2209 Train Loss 896.9849\n",
      "2210 Train Loss 896.98175\n",
      "2211 Train Loss 896.9798\n",
      "2212 Train Loss 896.97815\n",
      "2213 Train Loss 896.9766\n",
      "2214 Train Loss 896.97516\n",
      "2215 Train Loss 896.97314\n",
      "2216 Train Loss 896.9705\n",
      "2217 Train Loss 896.96747\n",
      "2218 Train Loss 896.96484\n",
      "2219 Train Loss 896.9629\n",
      "2220 Train Loss 896.9601\n",
      "2221 Train Loss 896.95557\n",
      "2222 Train Loss 896.95166\n",
      "2223 Train Loss 896.9479\n",
      "2224 Train Loss 896.94617\n",
      "2225 Train Loss 896.94354\n",
      "2226 Train Loss 896.9426\n",
      "2227 Train Loss 896.9416\n",
      "2228 Train Loss 896.94055\n",
      "2229 Train Loss 896.9386\n",
      "2230 Train Loss 896.9365\n",
      "2231 Train Loss 896.93463\n",
      "2232 Train Loss 896.93365\n",
      "2233 Train Loss 896.9322\n",
      "2234 Train Loss 896.93005\n",
      "2235 Train Loss 896.92804\n",
      "2236 Train Loss 896.9205\n",
      "2237 Train Loss 896.9194\n",
      "2238 Train Loss 896.9146\n",
      "2239 Train Loss 896.9052\n",
      "2240 Train Loss 896.9788\n",
      "2241 Train Loss 896.9017\n",
      "2242 Train Loss 896.9027\n",
      "2243 Train Loss 896.89746\n",
      "2244 Train Loss 896.89813\n",
      "2245 Train Loss 896.89386\n",
      "2246 Train Loss 896.89374\n",
      "2247 Train Loss 896.89044\n",
      "2248 Train Loss 896.8874\n",
      "2249 Train Loss 896.88293\n",
      "2250 Train Loss 896.87756\n",
      "2251 Train Loss 896.9078\n",
      "2252 Train Loss 896.87506\n",
      "2253 Train Loss 896.8711\n",
      "2254 Train Loss 896.86633\n",
      "2255 Train Loss 896.86206\n",
      "2256 Train Loss 896.85785\n",
      "2257 Train Loss 896.8537\n",
      "2258 Train Loss 896.8477\n",
      "2259 Train Loss 896.8443\n",
      "2260 Train Loss 896.83997\n",
      "2261 Train Loss 896.8333\n",
      "2262 Train Loss 896.82404\n",
      "2263 Train Loss 896.8141\n",
      "2264 Train Loss 896.8224\n",
      "2265 Train Loss 896.805\n",
      "2266 Train Loss 896.8183\n",
      "2267 Train Loss 896.7943\n",
      "2268 Train Loss 896.806\n",
      "2269 Train Loss 896.7904\n",
      "2270 Train Loss 896.7816\n",
      "2271 Train Loss 896.7706\n",
      "2272 Train Loss 896.7597\n",
      "2273 Train Loss 896.75464\n",
      "2274 Train Loss 896.7471\n",
      "2275 Train Loss 896.7995\n",
      "2276 Train Loss 896.74426\n",
      "2277 Train Loss 896.75073\n",
      "2278 Train Loss 896.74097\n",
      "2279 Train Loss 896.7344\n",
      "2280 Train Loss 896.7359\n",
      "2281 Train Loss 896.7324\n",
      "2282 Train Loss 896.7287\n",
      "2283 Train Loss 896.72473\n",
      "2284 Train Loss 896.72107\n",
      "2285 Train Loss 896.7181\n",
      "2286 Train Loss 896.71533\n",
      "2287 Train Loss 896.7111\n",
      "2288 Train Loss 896.7072\n",
      "2289 Train Loss 896.7033\n",
      "2290 Train Loss 896.69885\n",
      "2291 Train Loss 896.69763\n",
      "2292 Train Loss 896.69476\n",
      "2293 Train Loss 896.6933\n",
      "2294 Train Loss 896.69183\n",
      "2295 Train Loss 896.6905\n",
      "2296 Train Loss 896.6896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2297 Train Loss 896.68854\n",
      "2298 Train Loss 896.6873\n",
      "2299 Train Loss 896.6855\n",
      "2300 Train Loss 896.6807\n",
      "2301 Train Loss 896.6773\n",
      "2302 Train Loss 896.672\n",
      "2303 Train Loss 896.6822\n",
      "2304 Train Loss 896.67017\n",
      "2305 Train Loss 896.665\n",
      "2306 Train Loss 896.6617\n",
      "2307 Train Loss 896.6548\n",
      "2308 Train Loss 896.64844\n",
      "2309 Train Loss 896.6434\n",
      "2310 Train Loss 896.6467\n",
      "2311 Train Loss 896.6411\n",
      "2312 Train Loss 896.6367\n",
      "2313 Train Loss 896.6341\n",
      "2314 Train Loss 896.6306\n",
      "2315 Train Loss 896.6271\n",
      "2316 Train Loss 896.62384\n",
      "2317 Train Loss 896.62213\n",
      "2318 Train Loss 896.6143\n",
      "2319 Train Loss 896.61\n",
      "2320 Train Loss 896.6104\n",
      "2321 Train Loss 896.60767\n",
      "2322 Train Loss 896.6051\n",
      "2323 Train Loss 896.6008\n",
      "2324 Train Loss 896.5974\n",
      "2325 Train Loss 896.5923\n",
      "2326 Train Loss 896.58636\n",
      "2327 Train Loss 896.58057\n",
      "2328 Train Loss 896.5704\n",
      "2329 Train Loss 896.58057\n",
      "2330 Train Loss 896.5641\n",
      "2331 Train Loss 896.55835\n",
      "2332 Train Loss 896.5497\n",
      "2333 Train Loss 896.545\n",
      "2334 Train Loss 896.54047\n",
      "2335 Train Loss 896.5361\n",
      "2336 Train Loss 896.5324\n",
      "2337 Train Loss 896.53064\n",
      "2338 Train Loss 896.52844\n",
      "2339 Train Loss 896.5264\n",
      "2340 Train Loss 896.52576\n",
      "2341 Train Loss 896.5247\n",
      "2342 Train Loss 896.52356\n",
      "2343 Train Loss 896.5217\n",
      "2344 Train Loss 896.5206\n",
      "2345 Train Loss 896.5192\n",
      "2346 Train Loss 896.5178\n",
      "2347 Train Loss 896.515\n",
      "2348 Train Loss 896.51074\n",
      "2349 Train Loss 896.5025\n",
      "2350 Train Loss 896.48676\n",
      "2351 Train Loss 896.4928\n",
      "2352 Train Loss 896.47705\n",
      "2353 Train Loss 896.5271\n",
      "2354 Train Loss 896.4659\n",
      "2355 Train Loss 896.45703\n",
      "2356 Train Loss 896.4492\n",
      "2357 Train Loss 896.4514\n",
      "2358 Train Loss 896.4438\n",
      "2359 Train Loss 896.4416\n",
      "2360 Train Loss 896.43567\n",
      "2361 Train Loss 896.42975\n",
      "2362 Train Loss 896.4225\n",
      "2363 Train Loss 896.4147\n",
      "2364 Train Loss 896.40796\n",
      "2365 Train Loss 896.39435\n",
      "2366 Train Loss 896.38635\n",
      "2367 Train Loss 896.3922\n",
      "2368 Train Loss 896.3832\n",
      "2369 Train Loss 896.3812\n",
      "2370 Train Loss 896.37604\n",
      "2371 Train Loss 896.37274\n",
      "2372 Train Loss 896.3678\n",
      "2373 Train Loss 896.3614\n",
      "2374 Train Loss 896.3559\n",
      "2375 Train Loss 896.35034\n",
      "2376 Train Loss 896.34106\n",
      "2377 Train Loss 896.32947\n",
      "2378 Train Loss 896.3413\n",
      "2379 Train Loss 896.3248\n",
      "2380 Train Loss 896.32886\n",
      "2381 Train Loss 896.3194\n",
      "2382 Train Loss 896.3151\n",
      "2383 Train Loss 896.3101\n",
      "2384 Train Loss 896.30566\n",
      "2385 Train Loss 896.29956\n",
      "2386 Train Loss 896.29315\n",
      "2387 Train Loss 896.28656\n",
      "2388 Train Loss 896.28284\n",
      "2389 Train Loss 896.2798\n",
      "2390 Train Loss 896.2765\n",
      "2391 Train Loss 896.27405\n",
      "2392 Train Loss 896.27045\n",
      "2393 Train Loss 896.2669\n",
      "2394 Train Loss 896.2613\n",
      "2395 Train Loss 896.29913\n",
      "2396 Train Loss 896.2563\n",
      "2397 Train Loss 896.25116\n",
      "2398 Train Loss 896.24927\n",
      "2399 Train Loss 896.24603\n",
      "2400 Train Loss 896.24426\n",
      "2401 Train Loss 896.2406\n",
      "2402 Train Loss 896.23834\n",
      "2403 Train Loss 896.2362\n",
      "2404 Train Loss 896.23303\n",
      "2405 Train Loss 896.23376\n",
      "2406 Train Loss 896.23193\n",
      "2407 Train Loss 896.2288\n",
      "2408 Train Loss 896.225\n",
      "2409 Train Loss 896.2208\n",
      "2410 Train Loss 896.21643\n",
      "2411 Train Loss 896.21576\n",
      "2412 Train Loss 896.2135\n",
      "2413 Train Loss 896.21216\n",
      "2414 Train Loss 896.21045\n",
      "2415 Train Loss 896.2091\n",
      "2416 Train Loss 896.2071\n",
      "2417 Train Loss 896.2044\n",
      "2418 Train Loss 896.2031\n",
      "2419 Train Loss 896.20166\n",
      "2420 Train Loss 896.20026\n",
      "2421 Train Loss 896.1987\n",
      "2422 Train Loss 896.1962\n",
      "2423 Train Loss 896.19275\n",
      "2424 Train Loss 896.18835\n",
      "2425 Train Loss 896.1837\n",
      "2426 Train Loss 896.1783\n",
      "2427 Train Loss 896.1742\n",
      "2428 Train Loss 896.17065\n",
      "2429 Train Loss 896.168\n",
      "2430 Train Loss 896.16583\n",
      "2431 Train Loss 896.1633\n",
      "2432 Train Loss 896.1603\n",
      "2433 Train Loss 896.1578\n",
      "2434 Train Loss 896.15576\n",
      "2435 Train Loss 896.15466\n",
      "2436 Train Loss 896.15173\n",
      "2437 Train Loss 896.15027\n",
      "2438 Train Loss 896.1482\n",
      "2439 Train Loss 896.147\n",
      "2440 Train Loss 896.14545\n",
      "2441 Train Loss 896.1442\n",
      "2442 Train Loss 896.1436\n",
      "2443 Train Loss 896.1418\n",
      "2444 Train Loss 896.1395\n",
      "2445 Train Loss 896.1435\n",
      "2446 Train Loss 896.13794\n",
      "2447 Train Loss 896.1336\n",
      "2448 Train Loss 896.12933\n",
      "2449 Train Loss 896.1266\n",
      "2450 Train Loss 896.12537\n",
      "2451 Train Loss 896.1196\n",
      "2452 Train Loss 896.1153\n",
      "2453 Train Loss 896.11536\n",
      "2454 Train Loss 896.11176\n",
      "2455 Train Loss 896.1054\n",
      "2456 Train Loss 896.1019\n",
      "2457 Train Loss 896.0982\n",
      "2458 Train Loss 896.09595\n",
      "2459 Train Loss 896.09357\n",
      "2460 Train Loss 896.0915\n",
      "2461 Train Loss 896.0893\n",
      "2462 Train Loss 896.0871\n",
      "2463 Train Loss 896.08466\n",
      "2464 Train Loss 896.0858\n",
      "2465 Train Loss 896.0837\n",
      "2466 Train Loss 896.0819\n",
      "2467 Train Loss 896.08026\n",
      "2468 Train Loss 896.07904\n",
      "2469 Train Loss 896.07764\n",
      "2470 Train Loss 896.0764\n",
      "2471 Train Loss 896.0744\n",
      "2472 Train Loss 896.07263\n",
      "2473 Train Loss 896.07\n",
      "2474 Train Loss 896.0674\n",
      "2475 Train Loss 896.0639\n",
      "2476 Train Loss 896.05884\n",
      "2477 Train Loss 896.05347\n",
      "2478 Train Loss 896.0494\n",
      "2479 Train Loss 896.04663\n",
      "2480 Train Loss 896.0489\n",
      "2481 Train Loss 896.04474\n",
      "2482 Train Loss 896.04315\n",
      "2483 Train Loss 896.04156\n",
      "2484 Train Loss 896.0397\n",
      "2485 Train Loss 896.0376\n",
      "2486 Train Loss 896.0352\n",
      "2487 Train Loss 896.0326\n",
      "2488 Train Loss 896.0285\n",
      "2489 Train Loss 896.03577\n",
      "2490 Train Loss 896.02637\n",
      "2491 Train Loss 896.02386\n",
      "2492 Train Loss 896.0217\n",
      "2493 Train Loss 896.0218\n",
      "2494 Train Loss 896.0206\n",
      "2495 Train Loss 896.0194\n",
      "2496 Train Loss 896.0181\n",
      "2497 Train Loss 896.0173\n",
      "2498 Train Loss 896.01575\n",
      "2499 Train Loss 896.01495\n",
      "2500 Train Loss 896.0147\n",
      "2501 Train Loss 896.01434\n",
      "2502 Train Loss 896.0139\n",
      "2503 Train Loss 896.0133\n",
      "2504 Train Loss 896.0126\n",
      "2505 Train Loss 896.01166\n",
      "2506 Train Loss 896.0109\n",
      "2507 Train Loss 896.01\n",
      "2508 Train Loss 896.0083\n",
      "2509 Train Loss 896.00635\n",
      "2510 Train Loss 896.0036\n",
      "2511 Train Loss 896.002\n",
      "2512 Train Loss 896.0011\n",
      "2513 Train Loss 896.0\n",
      "2514 Train Loss 895.999\n",
      "2515 Train Loss 895.99774\n",
      "2516 Train Loss 895.9963\n",
      "2517 Train Loss 895.99536\n",
      "2518 Train Loss 895.9945\n",
      "2519 Train Loss 895.9931\n",
      "2520 Train Loss 895.99426\n",
      "2521 Train Loss 895.9916\n",
      "2522 Train Loss 895.9894\n",
      "2523 Train Loss 895.98846\n",
      "2524 Train Loss 895.98706\n",
      "2525 Train Loss 895.9862\n",
      "2526 Train Loss 895.98517\n",
      "2527 Train Loss 895.98364\n",
      "2528 Train Loss 895.9818\n",
      "2529 Train Loss 895.9788\n",
      "2530 Train Loss 895.9754\n",
      "2531 Train Loss 895.9708\n",
      "2532 Train Loss 895.9651\n",
      "2533 Train Loss 895.9596\n",
      "2534 Train Loss 895.95294\n",
      "2535 Train Loss 895.9468\n",
      "2536 Train Loss 895.9397\n",
      "2537 Train Loss 895.9308\n",
      "2538 Train Loss 895.94135\n",
      "2539 Train Loss 895.92664\n",
      "2540 Train Loss 895.9192\n",
      "2541 Train Loss 895.9033\n",
      "2542 Train Loss 895.8858\n",
      "2543 Train Loss 895.8701\n",
      "2544 Train Loss 895.85266\n",
      "2545 Train Loss 895.88806\n",
      "2546 Train Loss 895.8333\n",
      "2547 Train Loss 895.82983\n",
      "2548 Train Loss 895.8216\n",
      "2549 Train Loss 895.81604\n",
      "2550 Train Loss 895.81146\n",
      "2551 Train Loss 895.79987\n",
      "2552 Train Loss 895.811\n",
      "2553 Train Loss 895.79474\n",
      "2554 Train Loss 895.78424\n",
      "2555 Train Loss 895.77374\n",
      "2556 Train Loss 895.76447\n",
      "2557 Train Loss 895.7579\n",
      "2558 Train Loss 895.7522\n",
      "2559 Train Loss 895.7442\n",
      "2560 Train Loss 895.7247\n",
      "2561 Train Loss 895.6953\n",
      "2562 Train Loss 895.68304\n",
      "2563 Train Loss 896.1079\n",
      "2564 Train Loss 895.6677\n",
      "2565 Train Loss 895.67944\n",
      "2566 Train Loss 895.65924\n",
      "2567 Train Loss 895.6537\n",
      "2568 Train Loss 895.641\n",
      "2569 Train Loss 895.63055\n",
      "2570 Train Loss 895.6238\n",
      "2571 Train Loss 895.6281\n",
      "2572 Train Loss 895.6121\n",
      "2573 Train Loss 895.6239\n",
      "2574 Train Loss 895.6083\n",
      "2575 Train Loss 895.60364\n",
      "2576 Train Loss 895.59985\n",
      "2577 Train Loss 895.59204\n",
      "2578 Train Loss 895.5856\n",
      "2579 Train Loss 895.5768\n",
      "2580 Train Loss 895.5657\n",
      "2581 Train Loss 895.56995\n",
      "2582 Train Loss 895.5589\n",
      "2583 Train Loss 895.5464\n",
      "2584 Train Loss 895.53613\n",
      "2585 Train Loss 895.5296\n",
      "2586 Train Loss 895.5437\n",
      "2587 Train Loss 895.5243\n",
      "2588 Train Loss 895.5196\n",
      "2589 Train Loss 895.511\n",
      "2590 Train Loss 895.50134\n",
      "2591 Train Loss 895.49445\n",
      "2592 Train Loss 895.4878\n",
      "2593 Train Loss 895.48083\n",
      "2594 Train Loss 895.4754\n",
      "2595 Train Loss 895.47046\n",
      "2596 Train Loss 895.4672\n",
      "2597 Train Loss 895.46124\n",
      "2598 Train Loss 895.4576\n",
      "2599 Train Loss 895.44977\n",
      "2600 Train Loss 895.4416\n",
      "2601 Train Loss 895.43054\n",
      "2602 Train Loss 895.42126\n",
      "2603 Train Loss 895.4145\n",
      "2604 Train Loss 895.4075\n",
      "2605 Train Loss 895.4014\n",
      "2606 Train Loss 895.3956\n",
      "2607 Train Loss 895.38654\n",
      "2608 Train Loss 895.373\n",
      "2609 Train Loss 895.3865\n",
      "2610 Train Loss 895.3683\n",
      "2611 Train Loss 895.36707\n",
      "2612 Train Loss 895.3648\n",
      "2613 Train Loss 895.3611\n",
      "2614 Train Loss 895.3563\n",
      "2615 Train Loss 895.35333\n",
      "2616 Train Loss 895.3501\n",
      "2617 Train Loss 895.346\n",
      "2618 Train Loss 895.3436\n",
      "2619 Train Loss 895.34015\n",
      "2620 Train Loss 895.33203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621 Train Loss 895.32513\n",
      "2622 Train Loss 895.3182\n",
      "2623 Train Loss 895.3118\n",
      "2624 Train Loss 895.3065\n",
      "2625 Train Loss 895.3012\n",
      "2626 Train Loss 895.2964\n",
      "2627 Train Loss 895.30084\n",
      "2628 Train Loss 895.2916\n",
      "2629 Train Loss 895.28485\n",
      "2630 Train Loss 895.27783\n",
      "2631 Train Loss 895.2766\n",
      "2632 Train Loss 895.26935\n",
      "2633 Train Loss 895.2648\n",
      "2634 Train Loss 895.2594\n",
      "2635 Train Loss 895.25214\n",
      "2636 Train Loss 895.2491\n",
      "2637 Train Loss 895.24414\n",
      "2638 Train Loss 895.23895\n",
      "2639 Train Loss 895.23395\n",
      "2640 Train Loss 895.2285\n",
      "2641 Train Loss 895.2222\n",
      "2642 Train Loss 895.21606\n",
      "2643 Train Loss 895.20703\n",
      "2644 Train Loss 895.2011\n",
      "2645 Train Loss 895.1951\n",
      "2646 Train Loss 895.1994\n",
      "2647 Train Loss 895.19104\n",
      "2648 Train Loss 895.1865\n",
      "2649 Train Loss 895.18225\n",
      "2650 Train Loss 895.1791\n",
      "2651 Train Loss 895.17554\n",
      "2652 Train Loss 895.1724\n",
      "2653 Train Loss 895.1694\n",
      "2654 Train Loss 895.1668\n",
      "2655 Train Loss 895.16534\n",
      "2656 Train Loss 895.1632\n",
      "2657 Train Loss 895.1613\n",
      "2658 Train Loss 895.1579\n",
      "2659 Train Loss 895.1533\n",
      "2660 Train Loss 895.1478\n",
      "2661 Train Loss 895.1437\n",
      "2662 Train Loss 895.13873\n",
      "2663 Train Loss 895.1326\n",
      "2664 Train Loss 895.1284\n",
      "2665 Train Loss 895.12573\n",
      "2666 Train Loss 895.12164\n",
      "2667 Train Loss 895.11816\n",
      "2668 Train Loss 895.1146\n",
      "2669 Train Loss 895.11127\n",
      "2670 Train Loss 895.1068\n",
      "2671 Train Loss 895.09937\n",
      "2672 Train Loss 895.0962\n",
      "2673 Train Loss 895.0932\n",
      "2674 Train Loss 895.09125\n",
      "2675 Train Loss 895.0886\n",
      "2676 Train Loss 895.08453\n",
      "2677 Train Loss 895.079\n",
      "2678 Train Loss 895.0715\n",
      "2679 Train Loss 895.06445\n",
      "2680 Train Loss 895.10724\n",
      "2681 Train Loss 895.06024\n",
      "2682 Train Loss 895.0544\n",
      "2683 Train Loss 895.05054\n",
      "2684 Train Loss 895.0459\n",
      "2685 Train Loss 895.0415\n",
      "2686 Train Loss 895.0373\n",
      "2687 Train Loss 895.0337\n",
      "2688 Train Loss 895.028\n",
      "2689 Train Loss 895.0256\n",
      "2690 Train Loss 895.0195\n",
      "2691 Train Loss 895.014\n",
      "2692 Train Loss 895.0082\n",
      "2693 Train Loss 895.02795\n",
      "2694 Train Loss 895.00543\n",
      "2695 Train Loss 895.00085\n",
      "2696 Train Loss 894.99677\n",
      "2697 Train Loss 895.00354\n",
      "2698 Train Loss 894.9941\n",
      "2699 Train Loss 894.9873\n",
      "2700 Train Loss 894.9848\n",
      "2701 Train Loss 894.99884\n",
      "2702 Train Loss 894.98193\n",
      "2703 Train Loss 895.006\n",
      "2704 Train Loss 894.9798\n",
      "2705 Train Loss 894.9767\n",
      "2706 Train Loss 894.9727\n",
      "2707 Train Loss 894.96747\n",
      "2708 Train Loss 894.9649\n",
      "2709 Train Loss 894.9616\n",
      "2710 Train Loss 894.96136\n",
      "2711 Train Loss 894.95856\n",
      "2712 Train Loss 894.9542\n",
      "2713 Train Loss 894.9477\n",
      "2714 Train Loss 894.9429\n",
      "2715 Train Loss 894.9415\n",
      "2716 Train Loss 894.94006\n",
      "2717 Train Loss 894.9363\n",
      "2718 Train Loss 894.9323\n",
      "2719 Train Loss 894.9278\n",
      "2720 Train Loss 894.9231\n",
      "2721 Train Loss 894.9195\n",
      "2722 Train Loss 894.9163\n",
      "2723 Train Loss 894.91327\n",
      "2724 Train Loss 894.90936\n",
      "2725 Train Loss 894.9042\n",
      "2726 Train Loss 894.89404\n",
      "2727 Train Loss 894.88855\n",
      "2728 Train Loss 894.8833\n",
      "2729 Train Loss 894.8792\n",
      "2730 Train Loss 894.8753\n",
      "2731 Train Loss 894.87134\n",
      "2732 Train Loss 894.8674\n",
      "2733 Train Loss 894.86096\n",
      "2734 Train Loss 894.8528\n",
      "2735 Train Loss 894.8436\n",
      "2736 Train Loss 894.8694\n",
      "2737 Train Loss 894.8395\n",
      "2738 Train Loss 894.8344\n",
      "2739 Train Loss 894.83405\n",
      "2740 Train Loss 894.82947\n",
      "2741 Train Loss 894.82556\n",
      "2742 Train Loss 894.8194\n",
      "2743 Train Loss 894.81415\n",
      "2744 Train Loss 894.8132\n",
      "2745 Train Loss 894.81146\n",
      "2746 Train Loss 894.8076\n",
      "2747 Train Loss 894.80383\n",
      "2748 Train Loss 894.8013\n",
      "2749 Train Loss 894.7983\n",
      "2750 Train Loss 894.79565\n",
      "2751 Train Loss 894.7937\n",
      "2752 Train Loss 894.79095\n",
      "2753 Train Loss 894.78925\n",
      "2754 Train Loss 894.78705\n",
      "2755 Train Loss 894.78467\n",
      "2756 Train Loss 894.7813\n",
      "2757 Train Loss 894.7798\n",
      "2758 Train Loss 894.778\n",
      "2759 Train Loss 894.7767\n",
      "2760 Train Loss 894.77466\n",
      "2761 Train Loss 894.7721\n",
      "2762 Train Loss 894.7708\n",
      "2763 Train Loss 894.7695\n",
      "2764 Train Loss 894.76855\n",
      "2765 Train Loss 894.76715\n",
      "2766 Train Loss 894.7654\n",
      "2767 Train Loss 894.7624\n",
      "2768 Train Loss 894.7579\n",
      "2769 Train Loss 894.7537\n",
      "2770 Train Loss 894.75195\n",
      "2771 Train Loss 894.74695\n",
      "2772 Train Loss 894.74475\n",
      "2773 Train Loss 894.7427\n",
      "2774 Train Loss 894.74054\n",
      "2775 Train Loss 894.73914\n",
      "2776 Train Loss 894.73706\n",
      "2777 Train Loss 894.73474\n",
      "2778 Train Loss 894.7317\n",
      "2779 Train Loss 894.7302\n",
      "2780 Train Loss 894.72675\n",
      "2781 Train Loss 894.72437\n",
      "2782 Train Loss 894.7215\n",
      "2783 Train Loss 894.7177\n",
      "2784 Train Loss 894.71423\n",
      "2785 Train Loss 894.7109\n",
      "2786 Train Loss 894.708\n",
      "2787 Train Loss 894.7066\n",
      "2788 Train Loss 894.70276\n",
      "2789 Train Loss 894.7011\n",
      "2790 Train Loss 894.6979\n",
      "2791 Train Loss 894.6912\n",
      "2792 Train Loss 894.6817\n",
      "2793 Train Loss 894.68195\n",
      "2794 Train Loss 894.67395\n",
      "2795 Train Loss 894.6881\n",
      "2796 Train Loss 894.6629\n",
      "2797 Train Loss 894.6665\n",
      "2798 Train Loss 894.65155\n",
      "2799 Train Loss 894.6407\n",
      "2800 Train Loss 894.62665\n",
      "2801 Train Loss 894.6139\n",
      "2802 Train Loss 894.6023\n",
      "2803 Train Loss 894.59155\n",
      "2804 Train Loss 894.60876\n",
      "2805 Train Loss 894.5888\n",
      "2806 Train Loss 894.58405\n",
      "2807 Train Loss 894.5785\n",
      "2808 Train Loss 894.5694\n",
      "2809 Train Loss 894.5607\n",
      "2810 Train Loss 894.57117\n",
      "2811 Train Loss 894.5534\n",
      "2812 Train Loss 894.5758\n",
      "2813 Train Loss 894.5499\n",
      "2814 Train Loss 894.5434\n",
      "2815 Train Loss 894.5327\n",
      "2816 Train Loss 894.5252\n",
      "2817 Train Loss 894.51807\n",
      "2818 Train Loss 894.51434\n",
      "2819 Train Loss 894.5139\n",
      "2820 Train Loss 894.5102\n",
      "2821 Train Loss 894.50494\n",
      "2822 Train Loss 894.4985\n",
      "2823 Train Loss 894.49255\n",
      "2824 Train Loss 894.4888\n",
      "2825 Train Loss 894.4823\n",
      "2826 Train Loss 894.4777\n",
      "2827 Train Loss 894.46893\n",
      "2828 Train Loss 894.4646\n",
      "2829 Train Loss 894.4605\n",
      "2830 Train Loss 894.45715\n",
      "2831 Train Loss 894.4534\n",
      "2832 Train Loss 894.44977\n",
      "2833 Train Loss 894.44543\n",
      "2834 Train Loss 894.44183\n",
      "2835 Train Loss 894.4389\n",
      "2836 Train Loss 894.4344\n",
      "2837 Train Loss 894.4323\n",
      "2838 Train Loss 894.4296\n",
      "2839 Train Loss 894.42444\n",
      "2840 Train Loss 894.4192\n",
      "2841 Train Loss 894.4158\n",
      "2842 Train Loss 894.4134\n",
      "2843 Train Loss 894.41205\n",
      "2844 Train Loss 894.40894\n",
      "2845 Train Loss 894.40656\n",
      "2846 Train Loss 894.4051\n",
      "2847 Train Loss 894.4019\n",
      "2848 Train Loss 894.4007\n",
      "2849 Train Loss 894.3981\n",
      "2850 Train Loss 894.39514\n",
      "2851 Train Loss 894.39166\n",
      "2852 Train Loss 894.38824\n",
      "2853 Train Loss 894.3861\n",
      "2854 Train Loss 894.3844\n",
      "2855 Train Loss 894.38245\n",
      "2856 Train Loss 894.38025\n",
      "2857 Train Loss 894.37854\n",
      "2858 Train Loss 894.37744\n",
      "2859 Train Loss 894.37585\n",
      "2860 Train Loss 894.37427\n",
      "2861 Train Loss 894.3799\n",
      "2862 Train Loss 894.37354\n",
      "2863 Train Loss 894.3722\n",
      "2864 Train Loss 894.37006\n",
      "2865 Train Loss 894.3673\n",
      "2866 Train Loss 894.36444\n",
      "2867 Train Loss 894.36206\n",
      "2868 Train Loss 894.36035\n",
      "2869 Train Loss 894.35815\n",
      "2870 Train Loss 894.3559\n",
      "2871 Train Loss 894.35364\n",
      "2872 Train Loss 894.35114\n",
      "2873 Train Loss 894.3492\n",
      "2874 Train Loss 894.3472\n",
      "2875 Train Loss 894.3438\n",
      "2876 Train Loss 894.3407\n",
      "2877 Train Loss 894.35156\n",
      "2878 Train Loss 894.33875\n",
      "2879 Train Loss 894.36053\n",
      "2880 Train Loss 894.3358\n",
      "2881 Train Loss 894.3319\n",
      "2882 Train Loss 894.3279\n",
      "2883 Train Loss 894.32434\n",
      "2884 Train Loss 894.31946\n",
      "2885 Train Loss 894.3151\n",
      "2886 Train Loss 894.3092\n",
      "2887 Train Loss 894.3108\n",
      "2888 Train Loss 894.3046\n",
      "2889 Train Loss 894.30084\n",
      "2890 Train Loss 894.2982\n",
      "2891 Train Loss 894.2927\n",
      "2892 Train Loss 894.28735\n",
      "2893 Train Loss 894.28204\n",
      "2894 Train Loss 894.27966\n",
      "2895 Train Loss 894.2771\n",
      "2896 Train Loss 894.2725\n",
      "2897 Train Loss 894.26874\n",
      "2898 Train Loss 894.2629\n",
      "2899 Train Loss 894.258\n",
      "2900 Train Loss 894.2527\n",
      "2901 Train Loss 894.2497\n",
      "2902 Train Loss 894.2502\n",
      "2903 Train Loss 894.2443\n",
      "2904 Train Loss 894.2434\n",
      "2905 Train Loss 894.23975\n",
      "2906 Train Loss 894.23663\n",
      "2907 Train Loss 894.2342\n",
      "2908 Train Loss 894.23114\n",
      "2909 Train Loss 894.2262\n",
      "2910 Train Loss 894.2166\n",
      "2911 Train Loss 894.2082\n",
      "2912 Train Loss 894.2111\n",
      "2913 Train Loss 894.19934\n",
      "2914 Train Loss 894.1881\n",
      "2915 Train Loss 894.1717\n",
      "2916 Train Loss 894.15643\n",
      "2917 Train Loss 894.14764\n",
      "2918 Train Loss 894.1423\n",
      "2919 Train Loss 894.1234\n",
      "2920 Train Loss 894.1197\n",
      "2921 Train Loss 894.09717\n",
      "2922 Train Loss 894.0786\n",
      "2923 Train Loss 894.0672\n",
      "2924 Train Loss 894.0564\n",
      "2925 Train Loss 894.04865\n",
      "2926 Train Loss 894.04156\n",
      "2927 Train Loss 894.031\n",
      "2928 Train Loss 894.028\n",
      "2929 Train Loss 894.0178\n",
      "2930 Train Loss 894.0114\n",
      "2931 Train Loss 894.0052\n",
      "2932 Train Loss 894.00037\n",
      "2933 Train Loss 893.9984\n",
      "2934 Train Loss 893.9959\n",
      "2935 Train Loss 893.99274\n",
      "2936 Train Loss 893.9909\n",
      "2937 Train Loss 893.9881\n",
      "2938 Train Loss 893.9857\n",
      "2939 Train Loss 893.98346\n",
      "2940 Train Loss 893.97974\n",
      "2941 Train Loss 893.9765\n",
      "2942 Train Loss 893.9725\n",
      "2943 Train Loss 893.9693\n",
      "2944 Train Loss 893.96655\n",
      "2945 Train Loss 893.96454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2946 Train Loss 893.9614\n",
      "2947 Train Loss 893.9573\n",
      "2948 Train Loss 893.96344\n",
      "2949 Train Loss 893.9557\n",
      "2950 Train Loss 893.95386\n",
      "2951 Train Loss 893.9512\n",
      "2952 Train Loss 893.95013\n",
      "2953 Train Loss 893.9493\n",
      "2954 Train Loss 893.9479\n",
      "2955 Train Loss 893.9463\n",
      "2956 Train Loss 893.94354\n",
      "2957 Train Loss 893.9428\n",
      "2958 Train Loss 893.93805\n",
      "2959 Train Loss 893.93304\n",
      "2960 Train Loss 893.9254\n",
      "2961 Train Loss 893.91724\n",
      "2962 Train Loss 893.9131\n",
      "2963 Train Loss 893.9134\n",
      "2964 Train Loss 893.9108\n",
      "2965 Train Loss 893.90845\n",
      "2966 Train Loss 893.9043\n",
      "2967 Train Loss 893.89667\n",
      "2968 Train Loss 893.8893\n",
      "2969 Train Loss 893.8796\n",
      "2970 Train Loss 893.8718\n",
      "2971 Train Loss 893.8725\n",
      "2972 Train Loss 893.8668\n",
      "2973 Train Loss 893.87915\n",
      "2974 Train Loss 893.86053\n",
      "2975 Train Loss 893.85266\n",
      "2976 Train Loss 893.8452\n",
      "2977 Train Loss 893.84033\n",
      "2978 Train Loss 893.83356\n",
      "2979 Train Loss 893.82587\n",
      "2980 Train Loss 893.8173\n",
      "2981 Train Loss 893.8071\n",
      "2982 Train Loss 893.79944\n",
      "2983 Train Loss 893.7942\n",
      "2984 Train Loss 893.7885\n",
      "2985 Train Loss 893.7839\n",
      "2986 Train Loss 893.7791\n",
      "2987 Train Loss 893.7753\n",
      "2988 Train Loss 893.77045\n",
      "2989 Train Loss 893.76697\n",
      "2990 Train Loss 893.76373\n",
      "2991 Train Loss 893.7608\n",
      "2992 Train Loss 893.7569\n",
      "2993 Train Loss 893.7535\n",
      "2994 Train Loss 893.75073\n",
      "2995 Train Loss 893.7474\n",
      "2996 Train Loss 893.74506\n",
      "2997 Train Loss 893.7414\n",
      "2998 Train Loss 893.7393\n",
      "2999 Train Loss 893.7352\n",
      "3000 Train Loss 893.7304\n",
      "3001 Train Loss 893.7235\n",
      "3002 Train Loss 893.7173\n",
      "3003 Train Loss 893.71027\n",
      "3004 Train Loss 893.7057\n",
      "3005 Train Loss 893.7008\n",
      "3006 Train Loss 893.6966\n",
      "3007 Train Loss 893.68945\n",
      "3008 Train Loss 893.6823\n",
      "3009 Train Loss 893.67126\n",
      "3010 Train Loss 893.6572\n",
      "3011 Train Loss 893.65106\n",
      "3012 Train Loss 893.64404\n",
      "3013 Train Loss 893.6279\n",
      "3014 Train Loss 893.61444\n",
      "3015 Train Loss 893.60675\n",
      "3016 Train Loss 893.5963\n",
      "3017 Train Loss 893.58386\n",
      "3018 Train Loss 893.5705\n",
      "3019 Train Loss 893.571\n",
      "3020 Train Loss 893.56305\n",
      "3021 Train Loss 893.5504\n",
      "3022 Train Loss 893.54144\n",
      "3023 Train Loss 893.53973\n",
      "3024 Train Loss 893.53406\n",
      "3025 Train Loss 893.5278\n",
      "3026 Train Loss 893.5236\n",
      "3027 Train Loss 893.5174\n",
      "3028 Train Loss 893.5109\n",
      "3029 Train Loss 893.5042\n",
      "3030 Train Loss 893.49695\n",
      "3031 Train Loss 893.50525\n",
      "3032 Train Loss 893.49316\n",
      "3033 Train Loss 893.48895\n",
      "3034 Train Loss 893.486\n",
      "3035 Train Loss 893.485\n",
      "3036 Train Loss 893.4825\n",
      "3037 Train Loss 893.4805\n",
      "3038 Train Loss 893.4768\n",
      "3039 Train Loss 893.5028\n",
      "3040 Train Loss 893.47473\n",
      "3041 Train Loss 893.4683\n",
      "3042 Train Loss 893.4627\n",
      "3043 Train Loss 893.4568\n",
      "3044 Train Loss 893.45215\n",
      "3045 Train Loss 893.4491\n",
      "3046 Train Loss 893.44635\n",
      "3047 Train Loss 893.443\n",
      "3048 Train Loss 893.43835\n",
      "3049 Train Loss 893.43207\n",
      "3050 Train Loss 893.4279\n",
      "3051 Train Loss 893.4247\n",
      "3052 Train Loss 893.42523\n",
      "3053 Train Loss 893.42053\n",
      "3054 Train Loss 893.4169\n",
      "3055 Train Loss 893.413\n",
      "3056 Train Loss 893.4233\n",
      "3057 Train Loss 893.4089\n",
      "3058 Train Loss 893.42206\n",
      "3059 Train Loss 893.4023\n",
      "3060 Train Loss 893.39514\n",
      "3061 Train Loss 893.387\n",
      "3062 Train Loss 893.3822\n",
      "3063 Train Loss 893.3783\n",
      "3064 Train Loss 893.37366\n",
      "3065 Train Loss 893.3684\n",
      "3066 Train Loss 893.36304\n",
      "3067 Train Loss 893.35675\n",
      "3068 Train Loss 893.34875\n",
      "3069 Train Loss 893.3352\n",
      "3070 Train Loss 893.3424\n",
      "3071 Train Loss 893.32825\n",
      "3072 Train Loss 893.3216\n",
      "3073 Train Loss 893.311\n",
      "3074 Train Loss 893.30206\n",
      "3075 Train Loss 893.2862\n",
      "3076 Train Loss 893.2639\n",
      "3077 Train Loss 893.2406\n",
      "3078 Train Loss 893.22546\n",
      "3079 Train Loss 893.25665\n",
      "3080 Train Loss 893.2167\n",
      "3081 Train Loss 893.2087\n",
      "3082 Train Loss 893.2054\n",
      "3083 Train Loss 893.1973\n",
      "3084 Train Loss 893.2001\n",
      "3085 Train Loss 893.19135\n",
      "3086 Train Loss 893.18567\n",
      "3087 Train Loss 893.18\n",
      "3088 Train Loss 893.1738\n",
      "3089 Train Loss 893.1729\n",
      "3090 Train Loss 893.1698\n",
      "3091 Train Loss 893.16846\n",
      "3092 Train Loss 893.16644\n",
      "3093 Train Loss 893.1576\n",
      "3094 Train Loss 893.1472\n",
      "3095 Train Loss 893.1268\n",
      "3096 Train Loss 893.1112\n",
      "3097 Train Loss 893.2278\n",
      "3098 Train Loss 893.1032\n",
      "3099 Train Loss 893.13104\n",
      "3100 Train Loss 893.0927\n",
      "3101 Train Loss 893.08374\n",
      "3102 Train Loss 893.0792\n",
      "3103 Train Loss 893.072\n",
      "3104 Train Loss 893.06506\n",
      "3105 Train Loss 893.05756\n",
      "3106 Train Loss 893.06433\n",
      "3107 Train Loss 893.0534\n",
      "3108 Train Loss 893.0481\n",
      "3109 Train Loss 893.0396\n",
      "3110 Train Loss 893.033\n",
      "3111 Train Loss 893.0258\n",
      "3112 Train Loss 893.02167\n",
      "3113 Train Loss 893.00964\n",
      "3114 Train Loss 893.00494\n",
      "3115 Train Loss 892.99915\n",
      "3116 Train Loss 892.9957\n",
      "3117 Train Loss 892.9897\n",
      "3118 Train Loss 892.9847\n",
      "3119 Train Loss 892.9801\n",
      "3120 Train Loss 892.9751\n",
      "3121 Train Loss 892.9701\n",
      "3122 Train Loss 892.9581\n",
      "3123 Train Loss 893.4065\n",
      "3124 Train Loss 892.9553\n",
      "3125 Train Loss 892.9464\n",
      "3126 Train Loss 892.9403\n",
      "3127 Train Loss 892.9343\n",
      "3128 Train Loss 892.9272\n",
      "3129 Train Loss 892.91895\n",
      "3130 Train Loss 892.9082\n",
      "3131 Train Loss 892.8979\n",
      "3132 Train Loss 892.8935\n",
      "3133 Train Loss 892.8846\n",
      "3134 Train Loss 892.8889\n",
      "3135 Train Loss 892.8801\n",
      "3136 Train Loss 892.8764\n",
      "3137 Train Loss 892.8718\n",
      "3138 Train Loss 892.8676\n",
      "3139 Train Loss 892.86145\n",
      "3140 Train Loss 892.8492\n",
      "3141 Train Loss 892.8385\n",
      "3142 Train Loss 892.8281\n",
      "3143 Train Loss 892.8162\n",
      "3144 Train Loss 892.80286\n",
      "3145 Train Loss 892.7947\n",
      "3146 Train Loss 892.7711\n",
      "3147 Train Loss 892.76465\n",
      "3148 Train Loss 892.7473\n",
      "3149 Train Loss 892.74426\n",
      "3150 Train Loss 892.7383\n",
      "3151 Train Loss 892.7338\n",
      "3152 Train Loss 892.70795\n",
      "3153 Train Loss 892.69775\n",
      "3154 Train Loss 892.68274\n",
      "3155 Train Loss 892.66144\n",
      "3156 Train Loss 892.66315\n",
      "3157 Train Loss 892.65027\n",
      "3158 Train Loss 892.638\n",
      "3159 Train Loss 892.62964\n",
      "3160 Train Loss 892.6236\n",
      "3161 Train Loss 892.61676\n",
      "3162 Train Loss 892.6142\n",
      "3163 Train Loss 892.6052\n",
      "3164 Train Loss 892.59595\n",
      "3165 Train Loss 892.63666\n",
      "3166 Train Loss 892.5909\n",
      "3167 Train Loss 892.5816\n",
      "3168 Train Loss 892.5877\n",
      "3169 Train Loss 892.5753\n",
      "3170 Train Loss 892.56964\n",
      "3171 Train Loss 892.5649\n",
      "3172 Train Loss 892.5613\n",
      "3173 Train Loss 892.55786\n",
      "3174 Train Loss 892.55383\n",
      "3175 Train Loss 892.54846\n",
      "3176 Train Loss 893.00323\n",
      "3177 Train Loss 892.54834\n",
      "3178 Train Loss 892.5476\n",
      "3179 Train Loss 892.54346\n",
      "3180 Train Loss 892.54065\n",
      "3181 Train Loss 892.5373\n",
      "3182 Train Loss 892.5304\n",
      "3183 Train Loss 892.52295\n",
      "3184 Train Loss 892.5104\n",
      "3185 Train Loss 892.50354\n",
      "3186 Train Loss 892.49927\n",
      "3187 Train Loss 892.4979\n",
      "3188 Train Loss 892.4992\n",
      "3189 Train Loss 892.4879\n",
      "3190 Train Loss 892.4837\n",
      "3191 Train Loss 892.47986\n",
      "3192 Train Loss 892.4766\n",
      "3193 Train Loss 892.47217\n",
      "3194 Train Loss 892.4689\n",
      "3195 Train Loss 892.4675\n",
      "3196 Train Loss 892.463\n",
      "3197 Train Loss 892.4596\n",
      "3198 Train Loss 892.4565\n",
      "3199 Train Loss 892.4528\n",
      "3200 Train Loss 892.4504\n",
      "3201 Train Loss 892.4464\n",
      "3202 Train Loss 892.4442\n",
      "3203 Train Loss 892.44147\n",
      "3204 Train Loss 892.4385\n",
      "3205 Train Loss 892.43506\n",
      "3206 Train Loss 892.4309\n",
      "3207 Train Loss 892.4276\n",
      "3208 Train Loss 892.422\n",
      "3209 Train Loss 892.4144\n",
      "3210 Train Loss 892.405\n",
      "3211 Train Loss 892.42676\n",
      "3212 Train Loss 892.3951\n",
      "3213 Train Loss 892.3852\n",
      "3214 Train Loss 892.3792\n",
      "3215 Train Loss 892.3653\n",
      "3216 Train Loss 892.3608\n",
      "3217 Train Loss 892.3538\n",
      "3218 Train Loss 892.3469\n",
      "3219 Train Loss 892.35114\n",
      "3220 Train Loss 892.34485\n",
      "3221 Train Loss 892.3392\n",
      "3222 Train Loss 892.3331\n",
      "3223 Train Loss 892.32806\n",
      "3224 Train Loss 892.3237\n",
      "3225 Train Loss 892.3193\n",
      "3226 Train Loss 892.3147\n",
      "3227 Train Loss 892.31134\n",
      "3228 Train Loss 892.3077\n",
      "3229 Train Loss 892.30505\n",
      "3230 Train Loss 892.3033\n",
      "3231 Train Loss 892.3016\n",
      "3232 Train Loss 892.3003\n",
      "3233 Train Loss 892.299\n",
      "3234 Train Loss 892.2977\n",
      "3235 Train Loss 892.2974\n",
      "3236 Train Loss 892.29663\n",
      "3237 Train Loss 892.3068\n",
      "3238 Train Loss 892.2931\n",
      "3239 Train Loss 892.2894\n",
      "3240 Train Loss 892.2848\n",
      "3241 Train Loss 892.2827\n",
      "3242 Train Loss 892.2787\n",
      "3243 Train Loss 892.27545\n",
      "3244 Train Loss 892.273\n",
      "3245 Train Loss 892.27155\n",
      "3246 Train Loss 892.26996\n",
      "3247 Train Loss 892.2684\n",
      "3248 Train Loss 892.2658\n",
      "3249 Train Loss 892.26324\n",
      "3250 Train Loss 892.26\n",
      "3251 Train Loss 892.25726\n",
      "3252 Train Loss 892.25446\n",
      "3253 Train Loss 892.25055\n",
      "3254 Train Loss 892.2439\n",
      "3255 Train Loss 892.2411\n",
      "3256 Train Loss 892.23596\n",
      "3257 Train Loss 892.23224\n",
      "3258 Train Loss 892.2282\n",
      "3259 Train Loss 892.2253\n",
      "3260 Train Loss 892.22235\n",
      "3261 Train Loss 892.2196\n",
      "3262 Train Loss 892.21765\n",
      "3263 Train Loss 892.21606\n",
      "3264 Train Loss 892.2143\n",
      "3265 Train Loss 892.2121\n",
      "3266 Train Loss 892.2093\n",
      "3267 Train Loss 892.20386\n",
      "3268 Train Loss 892.2016\n",
      "3269 Train Loss 892.1976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3270 Train Loss 892.1927\n",
      "3271 Train Loss 892.2381\n",
      "3272 Train Loss 892.19006\n",
      "3273 Train Loss 892.186\n",
      "3274 Train Loss 892.18225\n",
      "3275 Train Loss 892.18207\n",
      "3276 Train Loss 892.18\n",
      "3277 Train Loss 892.1775\n",
      "3278 Train Loss 892.1756\n",
      "3279 Train Loss 892.17316\n",
      "3280 Train Loss 892.1696\n",
      "3281 Train Loss 892.1652\n",
      "3282 Train Loss 892.15656\n",
      "3283 Train Loss 892.16034\n",
      "3284 Train Loss 892.15344\n",
      "3285 Train Loss 892.14453\n",
      "3286 Train Loss 892.1588\n",
      "3287 Train Loss 892.1407\n",
      "3288 Train Loss 892.136\n",
      "3289 Train Loss 892.13165\n",
      "3290 Train Loss 892.1291\n",
      "3291 Train Loss 892.1262\n",
      "3292 Train Loss 892.12225\n",
      "3293 Train Loss 892.11945\n",
      "3294 Train Loss 892.116\n",
      "3295 Train Loss 892.11975\n",
      "3296 Train Loss 892.1147\n",
      "3297 Train Loss 892.1128\n",
      "3298 Train Loss 892.1113\n",
      "3299 Train Loss 892.11017\n",
      "3300 Train Loss 892.108\n",
      "3301 Train Loss 892.1035\n",
      "3302 Train Loss 892.0988\n",
      "3303 Train Loss 892.0943\n",
      "3304 Train Loss 892.09216\n",
      "3305 Train Loss 892.087\n",
      "3306 Train Loss 892.084\n",
      "3307 Train Loss 892.08545\n",
      "3308 Train Loss 892.0802\n",
      "3309 Train Loss 892.07623\n",
      "3310 Train Loss 892.07227\n",
      "3311 Train Loss 892.0692\n",
      "3312 Train Loss 892.0676\n",
      "3313 Train Loss 892.0642\n",
      "3314 Train Loss 892.06226\n",
      "3315 Train Loss 892.0592\n",
      "3316 Train Loss 892.0535\n",
      "3317 Train Loss 892.0482\n",
      "3318 Train Loss 892.04126\n",
      "3319 Train Loss 892.1543\n",
      "3320 Train Loss 892.0376\n",
      "3321 Train Loss 892.0295\n",
      "3322 Train Loss 892.0232\n",
      "3323 Train Loss 892.0209\n",
      "3324 Train Loss 892.0168\n",
      "3325 Train Loss 892.0132\n",
      "3326 Train Loss 892.0092\n",
      "3327 Train Loss 892.0091\n",
      "3328 Train Loss 892.00775\n",
      "3329 Train Loss 892.00525\n",
      "3330 Train Loss 892.00183\n",
      "3331 Train Loss 891.9982\n",
      "3332 Train Loss 891.9926\n",
      "3333 Train Loss 891.983\n",
      "3334 Train Loss 891.97205\n",
      "3335 Train Loss 891.98035\n",
      "3336 Train Loss 891.96344\n",
      "3337 Train Loss 891.9553\n",
      "3338 Train Loss 891.94037\n",
      "3339 Train Loss 891.9268\n",
      "3340 Train Loss 891.92566\n",
      "3341 Train Loss 891.9175\n",
      "3342 Train Loss 891.9204\n",
      "3343 Train Loss 891.9119\n",
      "3344 Train Loss 891.9032\n",
      "3345 Train Loss 891.8873\n",
      "3346 Train Loss 891.89136\n",
      "3347 Train Loss 891.8791\n",
      "3348 Train Loss 891.97375\n",
      "3349 Train Loss 891.8664\n",
      "3350 Train Loss 891.857\n",
      "3351 Train Loss 891.85895\n",
      "3352 Train Loss 891.8415\n",
      "3353 Train Loss 891.83234\n",
      "3354 Train Loss 891.8207\n",
      "3355 Train Loss 891.8084\n",
      "3356 Train Loss 891.80774\n",
      "3357 Train Loss 891.8114\n",
      "3358 Train Loss 891.801\n",
      "3359 Train Loss 891.7972\n",
      "3360 Train Loss 891.79114\n",
      "3361 Train Loss 891.7833\n",
      "3362 Train Loss 891.7752\n",
      "3363 Train Loss 891.7709\n",
      "3364 Train Loss 891.7669\n",
      "3365 Train Loss 891.76385\n",
      "3366 Train Loss 891.7617\n",
      "3367 Train Loss 891.75977\n",
      "3368 Train Loss 891.7576\n",
      "3369 Train Loss 891.7528\n",
      "3370 Train Loss 891.7471\n",
      "3371 Train Loss 891.7413\n",
      "3372 Train Loss 891.73627\n",
      "3373 Train Loss 891.7325\n",
      "3374 Train Loss 891.7288\n",
      "3375 Train Loss 891.7256\n",
      "3376 Train Loss 891.72253\n",
      "3377 Train Loss 891.71985\n",
      "3378 Train Loss 891.7149\n",
      "3379 Train Loss 891.71185\n",
      "3380 Train Loss 891.7068\n",
      "3381 Train Loss 891.70215\n",
      "3382 Train Loss 891.69806\n",
      "3383 Train Loss 891.6946\n",
      "3384 Train Loss 891.6931\n",
      "3385 Train Loss 891.69147\n",
      "3386 Train Loss 891.6892\n",
      "3387 Train Loss 891.6875\n",
      "3388 Train Loss 891.6859\n",
      "3389 Train Loss 891.6849\n",
      "3390 Train Loss 891.68365\n",
      "3391 Train Loss 891.6812\n",
      "3392 Train Loss 891.6788\n",
      "3393 Train Loss 891.67474\n",
      "3394 Train Loss 891.67017\n",
      "3395 Train Loss 891.6681\n",
      "3396 Train Loss 891.6651\n",
      "3397 Train Loss 891.6614\n",
      "3398 Train Loss 891.65686\n",
      "3399 Train Loss 891.65094\n",
      "3400 Train Loss 891.64496\n",
      "3401 Train Loss 891.6392\n",
      "3402 Train Loss 891.63367\n",
      "3403 Train Loss 891.62976\n",
      "3404 Train Loss 891.62744\n",
      "3405 Train Loss 891.62286\n",
      "3406 Train Loss 891.6229\n",
      "3407 Train Loss 891.62054\n",
      "3408 Train Loss 891.6161\n",
      "3409 Train Loss 891.61053\n",
      "3410 Train Loss 891.6136\n",
      "3411 Train Loss 891.60614\n",
      "3412 Train Loss 891.6002\n",
      "3413 Train Loss 891.602\n",
      "3414 Train Loss 891.5971\n",
      "3415 Train Loss 891.5909\n",
      "3416 Train Loss 891.5868\n",
      "3417 Train Loss 891.58264\n",
      "3418 Train Loss 891.57874\n",
      "3419 Train Loss 891.5743\n",
      "3420 Train Loss 891.5735\n",
      "3421 Train Loss 891.5713\n",
      "3422 Train Loss 891.5711\n",
      "3423 Train Loss 891.5689\n",
      "3424 Train Loss 891.567\n",
      "3425 Train Loss 891.5622\n",
      "3426 Train Loss 891.5596\n",
      "3427 Train Loss 891.55676\n",
      "3428 Train Loss 891.5533\n",
      "3429 Train Loss 891.55054\n",
      "3430 Train Loss 891.5442\n",
      "3431 Train Loss 891.5395\n",
      "3432 Train Loss 891.5351\n",
      "3433 Train Loss 891.5308\n",
      "3434 Train Loss 891.5275\n",
      "3435 Train Loss 891.52356\n",
      "3436 Train Loss 891.51605\n",
      "3437 Train Loss 891.5241\n",
      "3438 Train Loss 891.5135\n",
      "3439 Train Loss 891.50653\n",
      "3440 Train Loss 891.5014\n",
      "3441 Train Loss 891.4942\n",
      "3442 Train Loss 891.48816\n",
      "3443 Train Loss 891.48145\n",
      "3444 Train Loss 891.4766\n",
      "3445 Train Loss 891.4723\n",
      "3446 Train Loss 891.465\n",
      "3447 Train Loss 891.4608\n",
      "3448 Train Loss 891.4547\n",
      "3449 Train Loss 891.4469\n",
      "3450 Train Loss 891.43976\n",
      "3451 Train Loss 891.4388\n",
      "3452 Train Loss 891.43524\n",
      "3453 Train Loss 891.43134\n",
      "3454 Train Loss 891.425\n",
      "3455 Train Loss 891.4202\n",
      "3456 Train Loss 891.4136\n",
      "3457 Train Loss 891.411\n",
      "3458 Train Loss 891.40594\n",
      "3459 Train Loss 891.402\n",
      "3460 Train Loss 891.3955\n",
      "3461 Train Loss 891.39105\n",
      "3462 Train Loss 891.38165\n",
      "3463 Train Loss 891.3759\n",
      "3464 Train Loss 891.3692\n",
      "3465 Train Loss 891.38873\n",
      "3466 Train Loss 891.36755\n",
      "3467 Train Loss 891.3625\n",
      "3468 Train Loss 891.3833\n",
      "3469 Train Loss 891.3596\n",
      "3470 Train Loss 891.35223\n",
      "3471 Train Loss 891.3473\n",
      "3472 Train Loss 891.34174\n",
      "3473 Train Loss 891.3422\n",
      "3474 Train Loss 891.33905\n",
      "3475 Train Loss 891.3361\n",
      "3476 Train Loss 891.33405\n",
      "3477 Train Loss 891.33124\n",
      "3478 Train Loss 891.32745\n",
      "3479 Train Loss 891.3493\n",
      "3480 Train Loss 891.32544\n",
      "3481 Train Loss 891.32117\n",
      "3482 Train Loss 891.31476\n",
      "3483 Train Loss 891.3097\n",
      "3484 Train Loss 891.3061\n",
      "3485 Train Loss 891.30005\n",
      "3486 Train Loss 891.2949\n",
      "3487 Train Loss 891.2915\n",
      "3488 Train Loss 891.29034\n",
      "3489 Train Loss 891.2886\n",
      "3490 Train Loss 891.28723\n",
      "3491 Train Loss 891.2861\n",
      "3492 Train Loss 891.2848\n",
      "3493 Train Loss 891.2829\n",
      "3494 Train Loss 891.28107\n",
      "3495 Train Loss 891.2779\n",
      "3496 Train Loss 891.274\n",
      "3497 Train Loss 891.2714\n",
      "3498 Train Loss 891.26764\n",
      "3499 Train Loss 891.2654\n",
      "3500 Train Loss 891.2618\n",
      "3501 Train Loss 891.26227\n",
      "3502 Train Loss 891.2601\n",
      "3503 Train Loss 891.2573\n",
      "3504 Train Loss 891.2541\n",
      "3505 Train Loss 891.2521\n",
      "3506 Train Loss 891.2509\n",
      "3507 Train Loss 891.2492\n",
      "3508 Train Loss 891.2481\n",
      "3509 Train Loss 891.24634\n",
      "3510 Train Loss 891.2441\n",
      "3511 Train Loss 891.24384\n",
      "3512 Train Loss 891.2429\n",
      "3513 Train Loss 891.2415\n",
      "3514 Train Loss 891.23987\n",
      "3515 Train Loss 891.2386\n",
      "3516 Train Loss 891.239\n",
      "3517 Train Loss 891.2378\n",
      "3518 Train Loss 891.23505\n",
      "3519 Train Loss 891.23206\n",
      "3520 Train Loss 891.22864\n",
      "3521 Train Loss 891.2268\n",
      "3522 Train Loss 891.22534\n",
      "3523 Train Loss 891.2239\n",
      "3524 Train Loss 891.22266\n",
      "3525 Train Loss 891.2211\n",
      "3526 Train Loss 891.2218\n",
      "3527 Train Loss 891.22095\n",
      "3528 Train Loss 891.22\n",
      "3529 Train Loss 891.21936\n",
      "3530 Train Loss 891.2185\n",
      "3531 Train Loss 891.2172\n",
      "3532 Train Loss 891.2147\n",
      "3533 Train Loss 891.21106\n",
      "3534 Train Loss 891.2085\n",
      "3535 Train Loss 891.20624\n",
      "3536 Train Loss 891.2038\n",
      "3537 Train Loss 891.2021\n",
      "3538 Train Loss 891.19934\n",
      "3539 Train Loss 891.1968\n",
      "3540 Train Loss 891.1929\n",
      "3541 Train Loss 891.1874\n",
      "3542 Train Loss 891.1799\n",
      "3543 Train Loss 891.17346\n",
      "3544 Train Loss 891.16376\n",
      "3545 Train Loss 891.15216\n",
      "3546 Train Loss 891.14813\n",
      "3547 Train Loss 891.1471\n",
      "3548 Train Loss 891.1316\n",
      "3549 Train Loss 891.12415\n",
      "3550 Train Loss 891.113\n",
      "3551 Train Loss 891.1046\n",
      "3552 Train Loss 891.09784\n",
      "3553 Train Loss 891.09314\n",
      "3554 Train Loss 891.0926\n",
      "3555 Train Loss 891.0908\n",
      "3556 Train Loss 891.0908\n",
      "3557 Train Loss 891.089\n",
      "3558 Train Loss 891.089\n",
      "3559 Train Loss 891.0877\n",
      "3560 Train Loss 891.0851\n",
      "3561 Train Loss 891.0828\n",
      "3562 Train Loss 891.0818\n",
      "3563 Train Loss 891.07996\n",
      "3564 Train Loss 891.07916\n",
      "3565 Train Loss 891.0773\n",
      "3566 Train Loss 891.0757\n",
      "3567 Train Loss 891.07416\n",
      "3568 Train Loss 891.0724\n",
      "3569 Train Loss 891.07025\n",
      "3570 Train Loss 891.068\n",
      "3571 Train Loss 891.06573\n",
      "3572 Train Loss 891.06354\n",
      "3573 Train Loss 891.06134\n",
      "3574 Train Loss 891.0597\n",
      "3575 Train Loss 891.0584\n",
      "3576 Train Loss 891.05725\n",
      "3577 Train Loss 891.0551\n",
      "3578 Train Loss 891.0522\n",
      "3579 Train Loss 891.0536\n",
      "3580 Train Loss 891.05023\n",
      "3581 Train Loss 891.0469\n",
      "3582 Train Loss 891.0426\n",
      "3583 Train Loss 891.0367\n",
      "3584 Train Loss 891.0329\n",
      "3585 Train Loss 891.0299\n",
      "3586 Train Loss 891.02936\n",
      "3587 Train Loss 891.02844\n",
      "3588 Train Loss 891.02637\n",
      "3589 Train Loss 891.02374\n",
      "3590 Train Loss 891.0222\n",
      "3591 Train Loss 891.0208\n",
      "3592 Train Loss 891.01874\n",
      "3593 Train Loss 891.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3594 Train Loss 891.01636\n",
      "3595 Train Loss 891.01605\n",
      "3596 Train Loss 891.0146\n",
      "3597 Train Loss 891.01385\n",
      "3598 Train Loss 891.0132\n",
      "3599 Train Loss 891.012\n",
      "3600 Train Loss 891.0114\n",
      "3601 Train Loss 891.0105\n",
      "3602 Train Loss 891.0097\n",
      "3603 Train Loss 891.009\n",
      "3604 Train Loss 891.00757\n",
      "3605 Train Loss 891.0058\n",
      "3606 Train Loss 891.0055\n",
      "3607 Train Loss 891.0051\n",
      "3608 Train Loss 891.00415\n",
      "3609 Train Loss 891.00354\n",
      "3610 Train Loss 891.0023\n",
      "3611 Train Loss 891.0021\n",
      "3612 Train Loss 890.99976\n",
      "3613 Train Loss 890.9988\n",
      "3614 Train Loss 890.9984\n",
      "3615 Train Loss 890.9966\n",
      "3616 Train Loss 890.9957\n",
      "3617 Train Loss 890.99493\n",
      "3618 Train Loss 890.9927\n",
      "3619 Train Loss 890.9917\n",
      "3620 Train Loss 890.99\n",
      "3621 Train Loss 890.9956\n",
      "3622 Train Loss 890.9885\n",
      "3623 Train Loss 890.9861\n",
      "3624 Train Loss 890.98376\n",
      "3625 Train Loss 890.9819\n",
      "3626 Train Loss 890.97925\n",
      "3627 Train Loss 890.97906\n",
      "3628 Train Loss 890.9773\n",
      "3629 Train Loss 890.97516\n",
      "3630 Train Loss 891.0037\n",
      "3631 Train Loss 890.9731\n",
      "3632 Train Loss 890.9718\n",
      "3633 Train Loss 890.9712\n",
      "3634 Train Loss 890.96936\n",
      "3635 Train Loss 890.96857\n",
      "3636 Train Loss 890.9668\n",
      "3637 Train Loss 890.96686\n",
      "3638 Train Loss 890.9658\n",
      "3639 Train Loss 890.96436\n",
      "3640 Train Loss 890.96265\n",
      "3641 Train Loss 890.961\n",
      "3642 Train Loss 890.9594\n",
      "3643 Train Loss 890.9583\n",
      "3644 Train Loss 890.9573\n",
      "3645 Train Loss 890.9561\n",
      "3646 Train Loss 890.9557\n",
      "3647 Train Loss 890.95544\n",
      "3648 Train Loss 890.9548\n",
      "3649 Train Loss 890.95435\n",
      "3650 Train Loss 890.95404\n",
      "3651 Train Loss 890.95355\n",
      "3652 Train Loss 890.95294\n",
      "3653 Train Loss 890.9521\n",
      "3654 Train Loss 890.9515\n",
      "3655 Train Loss 890.95087\n",
      "3656 Train Loss 890.95026\n",
      "3657 Train Loss 890.9491\n",
      "3658 Train Loss 890.9473\n",
      "3659 Train Loss 890.9538\n",
      "3660 Train Loss 890.9468\n",
      "3661 Train Loss 890.9452\n",
      "3662 Train Loss 890.94495\n",
      "3663 Train Loss 890.9445\n",
      "3664 Train Loss 890.9435\n",
      "3665 Train Loss 890.9425\n",
      "3666 Train Loss 890.9415\n",
      "3667 Train Loss 890.941\n",
      "3668 Train Loss 890.9401\n",
      "3669 Train Loss 890.9383\n",
      "3670 Train Loss 890.9363\n",
      "3671 Train Loss 890.9339\n",
      "3672 Train Loss 890.9324\n",
      "3673 Train Loss 890.9303\n",
      "3674 Train Loss 890.928\n",
      "3675 Train Loss 890.92474\n",
      "3676 Train Loss 890.9229\n",
      "3677 Train Loss 890.9198\n",
      "3678 Train Loss 890.9183\n",
      "3679 Train Loss 890.91583\n",
      "3680 Train Loss 890.91315\n",
      "3681 Train Loss 890.9095\n",
      "3682 Train Loss 890.9055\n",
      "3683 Train Loss 890.9006\n",
      "3684 Train Loss 890.89606\n",
      "3685 Train Loss 890.893\n",
      "3686 Train Loss 890.89233\n",
      "3687 Train Loss 890.8897\n",
      "3688 Train Loss 890.88586\n",
      "3689 Train Loss 890.88165\n",
      "3690 Train Loss 890.87616\n",
      "3691 Train Loss 890.8715\n",
      "3692 Train Loss 890.8655\n",
      "3693 Train Loss 890.8623\n",
      "3694 Train Loss 890.85675\n",
      "3695 Train Loss 890.8522\n",
      "3696 Train Loss 890.8526\n",
      "3697 Train Loss 890.8486\n",
      "3698 Train Loss 890.84436\n",
      "3699 Train Loss 890.8401\n",
      "3700 Train Loss 890.83594\n",
      "3701 Train Loss 890.8336\n",
      "3702 Train Loss 890.83057\n",
      "3703 Train Loss 890.8271\n",
      "3704 Train Loss 890.824\n",
      "3705 Train Loss 890.8195\n",
      "3706 Train Loss 890.8157\n",
      "3707 Train Loss 890.8128\n",
      "3708 Train Loss 890.81134\n",
      "3709 Train Loss 890.80975\n",
      "3710 Train Loss 890.8085\n",
      "3711 Train Loss 890.80743\n",
      "3712 Train Loss 890.80743\n",
      "3713 Train Loss 890.80536\n",
      "3714 Train Loss 890.80457\n",
      "3715 Train Loss 890.80383\n",
      "3716 Train Loss 890.80304\n",
      "3717 Train Loss 890.80237\n",
      "3718 Train Loss 890.8014\n",
      "3719 Train Loss 890.80035\n",
      "3720 Train Loss 890.7994\n",
      "3721 Train Loss 890.79755\n",
      "3722 Train Loss 890.796\n",
      "3723 Train Loss 890.7949\n",
      "3724 Train Loss 890.794\n",
      "3725 Train Loss 890.84344\n",
      "3726 Train Loss 890.7932\n",
      "3727 Train Loss 890.79126\n",
      "3728 Train Loss 890.7867\n",
      "3729 Train Loss 890.7813\n",
      "3730 Train Loss 890.7745\n",
      "3731 Train Loss 890.7737\n",
      "3732 Train Loss 890.7707\n",
      "3733 Train Loss 890.7646\n",
      "3734 Train Loss 890.7757\n",
      "3735 Train Loss 890.7631\n",
      "3736 Train Loss 890.7632\n",
      "3737 Train Loss 890.7604\n",
      "3738 Train Loss 890.7578\n",
      "3739 Train Loss 890.7549\n",
      "3740 Train Loss 890.75104\n",
      "3741 Train Loss 890.74756\n",
      "3742 Train Loss 890.742\n",
      "3743 Train Loss 890.7492\n",
      "3744 Train Loss 890.73975\n",
      "3745 Train Loss 890.73816\n",
      "3746 Train Loss 890.7345\n",
      "3747 Train Loss 890.73535\n",
      "3748 Train Loss 890.7334\n",
      "3749 Train Loss 890.7313\n",
      "3750 Train Loss 890.7283\n",
      "3751 Train Loss 890.72705\n",
      "3752 Train Loss 891.0875\n",
      "3753 Train Loss 890.7265\n",
      "3754 Train Loss 890.7512\n",
      "3755 Train Loss 890.7259\n",
      "3756 Train Loss 890.72253\n",
      "3757 Train Loss 890.7215\n",
      "3758 Train Loss 890.7188\n",
      "3759 Train Loss 890.7156\n",
      "3760 Train Loss 890.71246\n",
      "3761 Train Loss 890.7089\n",
      "3762 Train Loss 890.7055\n",
      "3763 Train Loss 890.70325\n",
      "3764 Train Loss 890.6971\n",
      "3765 Train Loss 890.694\n",
      "3766 Train Loss 890.6899\n",
      "3767 Train Loss 890.6861\n",
      "3768 Train Loss 890.68243\n",
      "3769 Train Loss 890.67896\n",
      "3770 Train Loss 890.6741\n",
      "3771 Train Loss 890.6739\n",
      "3772 Train Loss 890.6709\n",
      "3773 Train Loss 890.68994\n",
      "3774 Train Loss 890.6686\n",
      "3775 Train Loss 890.7637\n",
      "3776 Train Loss 890.66724\n",
      "3777 Train Loss 890.6654\n",
      "3778 Train Loss 890.6626\n",
      "3779 Train Loss 890.6615\n",
      "3780 Train Loss 890.6597\n",
      "3781 Train Loss 890.65826\n",
      "3782 Train Loss 890.6571\n",
      "3783 Train Loss 890.6565\n",
      "3784 Train Loss 890.65607\n",
      "3785 Train Loss 890.6551\n",
      "3786 Train Loss 890.65424\n",
      "3787 Train Loss 890.65326\n",
      "3788 Train Loss 890.6528\n",
      "3789 Train Loss 890.6515\n",
      "3790 Train Loss 890.65063\n",
      "3791 Train Loss 890.6495\n",
      "3792 Train Loss 890.6488\n",
      "3793 Train Loss 890.64825\n",
      "3794 Train Loss 890.64746\n",
      "3795 Train Loss 890.6466\n",
      "3796 Train Loss 890.6457\n",
      "3797 Train Loss 890.645\n",
      "3798 Train Loss 890.6439\n",
      "3799 Train Loss 890.643\n",
      "3800 Train Loss 890.64197\n",
      "3801 Train Loss 890.64044\n",
      "3802 Train Loss 890.6386\n",
      "3803 Train Loss 890.636\n",
      "3804 Train Loss 890.6346\n",
      "3805 Train Loss 890.63245\n",
      "3806 Train Loss 890.6292\n",
      "3807 Train Loss 890.6274\n",
      "3808 Train Loss 890.624\n",
      "3809 Train Loss 890.62256\n",
      "3810 Train Loss 890.6208\n",
      "3811 Train Loss 890.62585\n",
      "3812 Train Loss 890.6198\n",
      "3813 Train Loss 890.6182\n",
      "3814 Train Loss 890.61743\n",
      "3815 Train Loss 890.61584\n",
      "3816 Train Loss 890.61487\n",
      "3817 Train Loss 890.6133\n",
      "3818 Train Loss 890.6101\n",
      "3819 Train Loss 890.6079\n",
      "3820 Train Loss 890.60583\n",
      "3821 Train Loss 890.6032\n",
      "3822 Train Loss 890.60114\n",
      "3823 Train Loss 890.6\n",
      "3824 Train Loss 890.5977\n",
      "3825 Train Loss 890.595\n",
      "3826 Train Loss 890.5928\n",
      "3827 Train Loss 890.5904\n",
      "3828 Train Loss 890.5892\n",
      "3829 Train Loss 890.5873\n",
      "3830 Train Loss 890.5862\n",
      "3831 Train Loss 890.5849\n",
      "3832 Train Loss 890.5826\n",
      "3833 Train Loss 890.57947\n",
      "3834 Train Loss 890.5758\n",
      "3835 Train Loss 890.57245\n",
      "3836 Train Loss 890.5688\n",
      "3837 Train Loss 890.5659\n",
      "3838 Train Loss 890.56354\n",
      "3839 Train Loss 890.5601\n",
      "3840 Train Loss 890.5543\n",
      "3841 Train Loss 890.55023\n",
      "3842 Train Loss 890.5455\n",
      "3843 Train Loss 890.54016\n",
      "3844 Train Loss 890.5345\n",
      "3845 Train Loss 890.5331\n",
      "3846 Train Loss 890.5252\n",
      "3847 Train Loss 890.52246\n",
      "3848 Train Loss 890.5174\n",
      "3849 Train Loss 890.51306\n",
      "3850 Train Loss 890.506\n",
      "3851 Train Loss 890.5063\n",
      "3852 Train Loss 890.5028\n",
      "3853 Train Loss 890.50024\n",
      "3854 Train Loss 890.5033\n",
      "3855 Train Loss 890.49866\n",
      "3856 Train Loss 890.4962\n",
      "3857 Train Loss 890.4938\n",
      "3858 Train Loss 890.4913\n",
      "3859 Train Loss 890.4887\n",
      "3860 Train Loss 890.4862\n",
      "3861 Train Loss 890.4821\n",
      "3862 Train Loss 890.4787\n",
      "3863 Train Loss 890.4738\n",
      "3864 Train Loss 890.47046\n",
      "3865 Train Loss 890.46594\n",
      "3866 Train Loss 890.46356\n",
      "3867 Train Loss 890.4615\n",
      "3868 Train Loss 890.4608\n",
      "3869 Train Loss 890.459\n",
      "3870 Train Loss 890.4583\n",
      "3871 Train Loss 890.4571\n",
      "3872 Train Loss 890.4557\n",
      "3873 Train Loss 890.4549\n",
      "3874 Train Loss 890.4544\n",
      "3875 Train Loss 890.45215\n",
      "3876 Train Loss 890.45087\n",
      "3877 Train Loss 890.44995\n",
      "3878 Train Loss 890.4487\n",
      "3879 Train Loss 890.44696\n",
      "3880 Train Loss 890.44495\n",
      "3881 Train Loss 890.44305\n",
      "3882 Train Loss 890.44165\n",
      "3883 Train Loss 890.4407\n",
      "3884 Train Loss 890.43964\n",
      "3885 Train Loss 890.43866\n",
      "3886 Train Loss 890.4369\n",
      "3887 Train Loss 890.4355\n",
      "3888 Train Loss 890.45355\n",
      "3889 Train Loss 890.4351\n",
      "3890 Train Loss 890.43604\n",
      "3891 Train Loss 890.4344\n",
      "3892 Train Loss 890.4336\n",
      "3893 Train Loss 890.43243\n",
      "3894 Train Loss 890.43115\n",
      "3895 Train Loss 890.4304\n",
      "3896 Train Loss 890.42944\n",
      "3897 Train Loss 890.4273\n",
      "3898 Train Loss 890.42554\n",
      "3899 Train Loss 890.42346\n",
      "3900 Train Loss 890.42224\n",
      "3901 Train Loss 890.4199\n",
      "3902 Train Loss 890.41797\n",
      "3903 Train Loss 890.41656\n",
      "3904 Train Loss 890.4154\n",
      "3905 Train Loss 890.4146\n",
      "3906 Train Loss 890.4141\n",
      "3907 Train Loss 890.41345\n",
      "3908 Train Loss 890.4127\n",
      "3909 Train Loss 890.41156\n",
      "3910 Train Loss 890.40985\n",
      "3911 Train Loss 890.40735\n",
      "3912 Train Loss 890.4085\n",
      "3913 Train Loss 890.4059\n",
      "3914 Train Loss 890.40405\n",
      "3915 Train Loss 890.4015\n",
      "3916 Train Loss 890.39813\n",
      "3917 Train Loss 890.394\n",
      "3918 Train Loss 890.3924\n",
      "3919 Train Loss 890.4044\n",
      "3920 Train Loss 890.38965\n",
      "3921 Train Loss 890.38696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3922 Train Loss 890.3855\n",
      "3923 Train Loss 890.38434\n",
      "3924 Train Loss 890.383\n",
      "3925 Train Loss 890.3814\n",
      "3926 Train Loss 890.3793\n",
      "3927 Train Loss 890.37646\n",
      "3928 Train Loss 890.37524\n",
      "3929 Train Loss 890.3732\n",
      "3930 Train Loss 890.37177\n",
      "3931 Train Loss 890.3714\n",
      "3932 Train Loss 890.3697\n",
      "3933 Train Loss 890.36847\n",
      "3934 Train Loss 890.3664\n",
      "3935 Train Loss 890.3658\n",
      "3936 Train Loss 890.36334\n",
      "3937 Train Loss 890.362\n",
      "3938 Train Loss 890.35767\n",
      "3939 Train Loss 890.3541\n",
      "3940 Train Loss 890.3558\n",
      "3941 Train Loss 890.3527\n",
      "3942 Train Loss 890.3547\n",
      "3943 Train Loss 890.3505\n",
      "3944 Train Loss 890.3493\n",
      "3945 Train Loss 890.3484\n",
      "3946 Train Loss 890.34766\n",
      "3947 Train Loss 890.34674\n",
      "3948 Train Loss 890.34515\n",
      "3949 Train Loss 890.34357\n",
      "3950 Train Loss 890.34186\n",
      "3951 Train Loss 890.3396\n",
      "3952 Train Loss 890.34436\n",
      "3953 Train Loss 890.33875\n",
      "3954 Train Loss 890.33636\n",
      "3955 Train Loss 890.33276\n",
      "3956 Train Loss 890.3301\n",
      "3957 Train Loss 890.3277\n",
      "3958 Train Loss 890.32587\n",
      "3959 Train Loss 890.32404\n",
      "3960 Train Loss 890.3229\n",
      "3961 Train Loss 890.3214\n",
      "3962 Train Loss 890.3202\n",
      "3963 Train Loss 890.318\n",
      "3964 Train Loss 890.3161\n",
      "3965 Train Loss 890.3135\n",
      "3966 Train Loss 890.3116\n",
      "3967 Train Loss 890.3095\n",
      "3968 Train Loss 890.307\n",
      "3969 Train Loss 890.3041\n",
      "3970 Train Loss 890.3017\n",
      "3971 Train Loss 890.2995\n",
      "3972 Train Loss 890.2975\n",
      "3973 Train Loss 890.29504\n",
      "3974 Train Loss 890.29144\n",
      "3975 Train Loss 890.2877\n",
      "3976 Train Loss 890.2857\n",
      "3977 Train Loss 890.2841\n",
      "3978 Train Loss 890.2821\n",
      "3979 Train Loss 890.2771\n",
      "3980 Train Loss 890.274\n",
      "3981 Train Loss 890.27075\n",
      "3982 Train Loss 890.2665\n",
      "3983 Train Loss 890.26154\n",
      "3984 Train Loss 890.25885\n",
      "3985 Train Loss 890.25616\n",
      "3986 Train Loss 890.25366\n",
      "3987 Train Loss 890.2507\n",
      "3988 Train Loss 890.24817\n",
      "3989 Train Loss 890.2439\n",
      "3990 Train Loss 890.2397\n",
      "3991 Train Loss 890.23566\n",
      "3992 Train Loss 890.2379\n",
      "3993 Train Loss 890.23047\n",
      "3994 Train Loss 890.22705\n",
      "3995 Train Loss 890.2234\n",
      "3996 Train Loss 890.2205\n",
      "3997 Train Loss 890.21924\n",
      "3998 Train Loss 890.21783\n",
      "3999 Train Loss 890.2167\n",
      "4000 Train Loss 890.216\n",
      "4001 Train Loss 890.2153\n",
      "4002 Train Loss 890.21436\n",
      "4003 Train Loss 890.2137\n",
      "4004 Train Loss 890.2178\n",
      "4005 Train Loss 890.213\n",
      "4006 Train Loss 890.2122\n",
      "4007 Train Loss 890.2106\n",
      "4008 Train Loss 890.2098\n",
      "4009 Train Loss 890.2085\n",
      "4010 Train Loss 890.2067\n",
      "4011 Train Loss 890.2063\n",
      "4012 Train Loss 890.2061\n",
      "4013 Train Loss 890.20526\n",
      "4014 Train Loss 890.2034\n",
      "4015 Train Loss 890.2012\n",
      "4016 Train Loss 890.1988\n",
      "4017 Train Loss 890.1988\n",
      "4018 Train Loss 890.19794\n",
      "4019 Train Loss 890.19684\n",
      "4020 Train Loss 890.196\n",
      "4021 Train Loss 890.1957\n",
      "4022 Train Loss 890.1955\n",
      "4023 Train Loss 890.19476\n",
      "4024 Train Loss 890.195\n",
      "4025 Train Loss 890.1947\n",
      "4026 Train Loss 890.19434\n",
      "4027 Train Loss 890.19385\n",
      "4028 Train Loss 890.1934\n",
      "4029 Train Loss 890.193\n",
      "4030 Train Loss 890.1918\n",
      "4031 Train Loss 890.19073\n",
      "4032 Train Loss 890.1935\n",
      "4033 Train Loss 890.1902\n",
      "4034 Train Loss 890.18866\n",
      "4035 Train Loss 890.1874\n",
      "4036 Train Loss 890.18555\n",
      "4037 Train Loss 890.1828\n",
      "4038 Train Loss 890.18024\n",
      "4039 Train Loss 890.179\n",
      "4040 Train Loss 890.1776\n",
      "4041 Train Loss 890.1734\n",
      "4042 Train Loss 890.16815\n",
      "4043 Train Loss 890.16394\n",
      "4044 Train Loss 890.1723\n",
      "4045 Train Loss 890.16077\n",
      "4046 Train Loss 890.15643\n",
      "4047 Train Loss 890.1789\n",
      "4048 Train Loss 890.15356\n",
      "4049 Train Loss 890.14795\n",
      "4050 Train Loss 890.14417\n",
      "4051 Train Loss 890.14105\n",
      "4052 Train Loss 890.13885\n",
      "4053 Train Loss 890.1334\n",
      "4054 Train Loss 890.1304\n",
      "4055 Train Loss 890.12445\n",
      "4056 Train Loss 890.1468\n",
      "4057 Train Loss 890.12036\n",
      "4058 Train Loss 890.11694\n",
      "4059 Train Loss 890.1141\n",
      "4060 Train Loss 890.1113\n",
      "4061 Train Loss 890.10956\n",
      "4062 Train Loss 890.10724\n",
      "4063 Train Loss 890.106\n",
      "4064 Train Loss 890.10486\n",
      "4065 Train Loss 890.1038\n",
      "4066 Train Loss 890.1027\n",
      "4067 Train Loss 890.10077\n",
      "4068 Train Loss 890.1016\n",
      "4069 Train Loss 890.0999\n",
      "4070 Train Loss 890.09894\n",
      "4071 Train Loss 890.0962\n",
      "4072 Train Loss 890.09344\n",
      "4073 Train Loss 890.0901\n",
      "4074 Train Loss 890.0857\n",
      "4075 Train Loss 890.0829\n",
      "4076 Train Loss 890.08014\n",
      "4077 Train Loss 890.0783\n",
      "4078 Train Loss 890.07556\n",
      "4079 Train Loss 890.0732\n",
      "4080 Train Loss 890.0726\n",
      "4081 Train Loss 890.0695\n",
      "4082 Train Loss 890.068\n",
      "4083 Train Loss 890.0652\n",
      "4084 Train Loss 890.0627\n",
      "4085 Train Loss 890.06134\n",
      "4086 Train Loss 890.0603\n",
      "4087 Train Loss 890.05927\n",
      "4088 Train Loss 890.0578\n",
      "4089 Train Loss 890.05707\n",
      "4090 Train Loss 890.05566\n",
      "4091 Train Loss 890.05817\n",
      "4092 Train Loss 890.05493\n",
      "4093 Train Loss 890.0538\n",
      "4094 Train Loss 890.0522\n",
      "4095 Train Loss 890.05066\n",
      "4096 Train Loss 890.04974\n",
      "4097 Train Loss 890.04865\n",
      "4098 Train Loss 890.0485\n",
      "4099 Train Loss 890.04785\n",
      "4100 Train Loss 890.047\n",
      "4101 Train Loss 890.0457\n",
      "4102 Train Loss 890.045\n",
      "4103 Train Loss 890.044\n",
      "4104 Train Loss 890.0419\n",
      "4105 Train Loss 890.04\n",
      "4106 Train Loss 890.0363\n",
      "4107 Train Loss 890.0342\n",
      "4108 Train Loss 890.03375\n",
      "4109 Train Loss 890.0322\n",
      "4110 Train Loss 890.03125\n",
      "4111 Train Loss 890.03076\n",
      "4112 Train Loss 890.02814\n",
      "4113 Train Loss 890.02686\n",
      "4114 Train Loss 890.02563\n",
      "4115 Train Loss 890.02313\n",
      "4116 Train Loss 890.0212\n",
      "4117 Train Loss 890.018\n",
      "4118 Train Loss 890.0145\n",
      "4119 Train Loss 890.01154\n",
      "4120 Train Loss 890.01\n",
      "4121 Train Loss 890.0074\n",
      "4122 Train Loss 890.00507\n",
      "4123 Train Loss 890.0023\n",
      "4124 Train Loss 889.99695\n",
      "4125 Train Loss 889.99\n",
      "4126 Train Loss 889.9858\n",
      "4127 Train Loss 889.98175\n",
      "4128 Train Loss 889.976\n",
      "4129 Train Loss 889.97034\n",
      "4130 Train Loss 889.963\n",
      "4131 Train Loss 889.9572\n",
      "4132 Train Loss 889.9512\n",
      "4133 Train Loss 889.9431\n",
      "4134 Train Loss 889.9391\n",
      "4135 Train Loss 889.93494\n",
      "4136 Train Loss 889.9321\n",
      "4137 Train Loss 889.9347\n",
      "4138 Train Loss 889.93085\n",
      "4139 Train Loss 889.9295\n",
      "4140 Train Loss 889.9281\n",
      "4141 Train Loss 889.92535\n",
      "4142 Train Loss 889.92236\n",
      "4143 Train Loss 889.91876\n",
      "4144 Train Loss 889.91345\n",
      "4145 Train Loss 889.9126\n",
      "4146 Train Loss 889.9088\n",
      "4147 Train Loss 889.9079\n",
      "4148 Train Loss 889.9049\n",
      "4149 Train Loss 889.9005\n",
      "4150 Train Loss 889.9001\n",
      "4151 Train Loss 889.89874\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-abc4568d1db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPINN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPINN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n\u001b[0;32m--> 426\u001b[0;31m                         obj_func, x_init, t, d, loss, flat_grad, gtd)\n\u001b[0m\u001b[1;32m    427\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mopt_cond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mtolerance_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# evaluate objective and gradient using initial step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mf_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mls_func_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mgtd_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                     \u001b[0;32mdef\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_directional_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36m_directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_directional_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mflat_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_flat_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36m_add_grad\u001b[0;34m(self, step_size, update)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mnumel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;31m# view as to avoid deprecated pointwise semantics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_reps = 10\n",
    "\n",
    "train_loss_full = []\n",
    "test_loss_full = []\n",
    "#beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(reps)\n",
    "    \n",
    "    torch.manual_seed(reps*36)\n",
    "    N_D = 500 #Total number of data points for 'y'\n",
    "    N_N = 500\n",
    "    N_f = 10000 #Total number of collocation points \n",
    "    \n",
    "    xyt_coll_np_array, xyt_D_np_array, u_D_np_array,xyt_N_np_array = trainingdata(N_D,N_N,N_f,(reps)*22)\n",
    "        \n",
    "    xyt_coll = torch.from_numpy(xyt_coll_np_array).float().to(device)\n",
    "    xyt_D = torch.from_numpy(xyt_D_np_array).float().to(device)\n",
    "    u_D = torch.from_numpy(u_D_np_array).float().to(device)\n",
    "    xyt_N = torch.from_numpy(xyt_N_np_array).float().to(device)\n",
    "        \n",
    "    N_hat = torch.zeros(xyt_N.shape[0],1).to(device)    \n",
    "    f_hat = torch.zeros(xyt_coll.shape[0],1).to(device)\n",
    "\n",
    "    layers = np.array([3,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "   \n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                              max_iter = 10000, \n",
    "                              max_eval = None, \n",
    "                              tolerance_grad = -1, \n",
    "                              tolerance_change = -1, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "        \n",
    "    optimizer.step(PINN.closure)\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(PINN.train_loss)\n",
    "    test_loss_full.append(PINN.test_loss)\n",
    "    elapsed_time[reps] = time.time() - start_time\n",
    "    #beta_full.append(PINN.beta_val)\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "    \n",
    "mdic = {\"train_loss\": train_loss_full,\"test_loss\": test_loss_full,\"Time\": elapsed_time, \"label\": label}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = PINN.test(xyt_test_tensor)\n",
    "u_pred_3d = u_pred.reshape(100,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_pred_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "#img3 = ax.imshow(u_pred_3d[75,:,:],vmin = 0,vmax = 10,cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n",
    "img3 = ax.imshow(np.transpose(u_pred_3d[99,:,:]),cmap = cmap,extent=[0,1,0,1],aspect = 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + test_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(10):\n",
    "    a = a + train_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
